diff --git a/hibernate-core/src/main/java/org/hibernate/boot/jaxb/hbm/spi/SubEntityInfo.java b/hibernate-core/src/main/java/org/hibernate/boot/jaxb/hbm/spi/SubEntityInfo.java
index b62772101c..9fcc50dc73 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/jaxb/hbm/spi/SubEntityInfo.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/jaxb/hbm/spi/SubEntityInfo.java
@@ -1,33 +1,33 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.jaxb.hbm.spi;
 
 /**
  * Common interface for all sub-entity mappings.
  *
  * @author Steve Ebersole
  */
 public interface SubEntityInfo extends EntityInfo {
-    String getExtends();
+	String getExtends();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/Oracle8iDialect.java b/hibernate-core/src/main/java/org/hibernate/dialect/Oracle8iDialect.java
index 1484b04aa1..bdb4e93b25 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/Oracle8iDialect.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/Oracle8iDialect.java
@@ -1,686 +1,685 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect;
 
 import java.sql.CallableStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 import java.util.List;
 import java.util.Locale;
 
 import org.hibernate.JDBCException;
 import org.hibernate.QueryTimeoutException;
 import org.hibernate.annotations.common.util.StringHelper;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.function.NoArgSQLFunction;
 import org.hibernate.dialect.function.NvlFunction;
 import org.hibernate.dialect.function.SQLFunctionTemplate;
 import org.hibernate.dialect.function.StandardSQLFunction;
 import org.hibernate.dialect.function.VarArgsSQLFunction;
 import org.hibernate.dialect.pagination.AbstractLimitHandler;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.exception.ConstraintViolationException;
 import org.hibernate.exception.LockAcquisitionException;
 import org.hibernate.exception.LockTimeoutException;
 import org.hibernate.exception.spi.SQLExceptionConversionDelegate;
 import org.hibernate.exception.spi.TemplatedViolatedConstraintNameExtracter;
 import org.hibernate.exception.spi.ViolatedConstraintNameExtracter;
 import org.hibernate.hql.spi.id.IdTableSupportStandardImpl;
-import org.hibernate.hql.spi.id.global.GlobalTemporaryTableBulkIdStrategy;
 import org.hibernate.hql.spi.id.MultiTableBulkIdStrategy;
+import org.hibernate.hql.spi.id.global.GlobalTemporaryTableBulkIdStrategy;
 import org.hibernate.hql.spi.id.local.AfterUseAction;
 import org.hibernate.internal.util.JdbcExceptionHelper;
 import org.hibernate.procedure.internal.StandardCallableStatementSupport;
 import org.hibernate.procedure.spi.CallableStatementSupport;
 import org.hibernate.sql.CaseFragment;
 import org.hibernate.sql.DecodeCaseFragment;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.OracleJoinFragment;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.descriptor.sql.BitTypeDescriptor;
 import org.hibernate.type.descriptor.sql.SqlTypeDescriptor;
 
 /**
  * A dialect for Oracle 8i.
  *
  * @author Steve Ebersole
  */
 @SuppressWarnings("deprecation")
 public class Oracle8iDialect extends Dialect {
 
 	private static final AbstractLimitHandler LIMIT_HANDLER = new AbstractLimitHandler() {
 		@Override
 		public String processSql(String sql, RowSelection selection) {
 			final boolean hasOffset = LimitHelper.hasFirstRow( selection );
 			sql = sql.trim();
 			boolean isForUpdate = false;
-			if (sql.toLowerCase(Locale.ROOT
-                        ).endsWith( " for update" )) {
+			if (sql.toLowerCase(Locale.ROOT).endsWith( " for update" )) {
 				sql = sql.substring( 0, sql.length() - 11 );
 				isForUpdate = true;
 			}
 
 			final StringBuilder pagingSelect = new StringBuilder( sql.length() + 100 );
 			if (hasOffset) {
 				pagingSelect.append( "select * from ( select row_.*, rownum rownum_ from ( " );
 			}
 			else {
 				pagingSelect.append( "select * from ( " );
 			}
 			pagingSelect.append( sql );
 			if (hasOffset) {
 				pagingSelect.append( " ) row_ ) where rownum_ <= ? and rownum_ > ?" );
 			}
 			else {
 				pagingSelect.append( " ) where rownum <= ?" );
 			}
 
 			if (isForUpdate) {
 				pagingSelect.append( " for update" );
 			}
 
 			return pagingSelect.toString();
 		}
 
 		@Override
 		public boolean supportsLimit() {
 			return true;
 		}
 
 		@Override
 		public boolean bindLimitParametersInReverseOrder() {
 			return true;
 		}
 
 		@Override
 		public boolean useMaxForLimit() {
 			return true;
 		}
 	};
 
 	private static final int PARAM_LIST_SIZE_LIMIT = 1000;
 
 	/**
 	 * Constructs a Oracle8iDialect
 	 */
 	public Oracle8iDialect() {
 		super();
 		registerCharacterTypeMappings();
 		registerNumericTypeMappings();
 		registerDateTimeTypeMappings();
 		registerLargeObjectTypeMappings();
 		registerReverseHibernateTypeMappings();
 		registerFunctions();
 		registerDefaultProperties();
 	}
 
 	protected void registerCharacterTypeMappings() {
 		registerColumnType( Types.CHAR, "char(1)" );
 		registerColumnType( Types.VARCHAR, 4000, "varchar2($l)" );
 		registerColumnType( Types.VARCHAR, "long" );
 	}
 
 	protected void registerNumericTypeMappings() {
 		registerColumnType( Types.BIT, "number(1,0)" );
 		registerColumnType( Types.BIGINT, "number(19,0)" );
 		registerColumnType( Types.SMALLINT, "number(5,0)" );
 		registerColumnType( Types.TINYINT, "number(3,0)" );
 		registerColumnType( Types.INTEGER, "number(10,0)" );
 
 		registerColumnType( Types.FLOAT, "float" );
 		registerColumnType( Types.DOUBLE, "double precision" );
 		registerColumnType( Types.NUMERIC, "number($p,$s)" );
 		registerColumnType( Types.DECIMAL, "number($p,$s)" );
 
 		registerColumnType( Types.BOOLEAN, "number(1,0)" );
 	}
 
 	protected void registerDateTimeTypeMappings() {
 		registerColumnType( Types.DATE, "date" );
 		registerColumnType( Types.TIME, "date" );
 		registerColumnType( Types.TIMESTAMP, "date" );
 	}
 
 	protected void registerLargeObjectTypeMappings() {
 		registerColumnType( Types.BINARY, 2000, "raw($l)" );
 		registerColumnType( Types.BINARY, "long raw" );
 
 		registerColumnType( Types.VARBINARY, 2000, "raw($l)" );
 		registerColumnType( Types.VARBINARY, "long raw" );
 
 		registerColumnType( Types.BLOB, "blob" );
 		registerColumnType( Types.CLOB, "clob" );
 
 		registerColumnType( Types.LONGVARCHAR, "long" );
 		registerColumnType( Types.LONGVARBINARY, "long raw" );
 	}
 
 	protected void registerReverseHibernateTypeMappings() {
 	}
 
 	protected void registerFunctions() {
 		registerFunction( "abs", new StandardSQLFunction("abs") );
 		registerFunction( "sign", new StandardSQLFunction("sign", StandardBasicTypes.INTEGER) );
 
 		registerFunction( "acos", new StandardSQLFunction("acos", StandardBasicTypes.DOUBLE) );
 		registerFunction( "asin", new StandardSQLFunction("asin", StandardBasicTypes.DOUBLE) );
 		registerFunction( "atan", new StandardSQLFunction("atan", StandardBasicTypes.DOUBLE) );
 		registerFunction( "bitand", new StandardSQLFunction("bitand") );
 		registerFunction( "cos", new StandardSQLFunction("cos", StandardBasicTypes.DOUBLE) );
 		registerFunction( "cosh", new StandardSQLFunction("cosh", StandardBasicTypes.DOUBLE) );
 		registerFunction( "exp", new StandardSQLFunction("exp", StandardBasicTypes.DOUBLE) );
 		registerFunction( "ln", new StandardSQLFunction("ln", StandardBasicTypes.DOUBLE) );
 		registerFunction( "sin", new StandardSQLFunction("sin", StandardBasicTypes.DOUBLE) );
 		registerFunction( "sinh", new StandardSQLFunction("sinh", StandardBasicTypes.DOUBLE) );
 		registerFunction( "stddev", new StandardSQLFunction("stddev", StandardBasicTypes.DOUBLE) );
 		registerFunction( "sqrt", new StandardSQLFunction("sqrt", StandardBasicTypes.DOUBLE) );
 		registerFunction( "tan", new StandardSQLFunction("tan", StandardBasicTypes.DOUBLE) );
 		registerFunction( "tanh", new StandardSQLFunction("tanh", StandardBasicTypes.DOUBLE) );
 		registerFunction( "variance", new StandardSQLFunction("variance", StandardBasicTypes.DOUBLE) );
 
 		registerFunction( "round", new StandardSQLFunction("round") );
 		registerFunction( "trunc", new StandardSQLFunction("trunc") );
 		registerFunction( "ceil", new StandardSQLFunction("ceil") );
 		registerFunction( "floor", new StandardSQLFunction("floor") );
 
 		registerFunction( "chr", new StandardSQLFunction("chr", StandardBasicTypes.CHARACTER) );
 		registerFunction( "initcap", new StandardSQLFunction("initcap") );
 		registerFunction( "lower", new StandardSQLFunction("lower") );
 		registerFunction( "ltrim", new StandardSQLFunction("ltrim") );
 		registerFunction( "rtrim", new StandardSQLFunction("rtrim") );
 		registerFunction( "soundex", new StandardSQLFunction("soundex") );
 		registerFunction( "upper", new StandardSQLFunction("upper") );
 		registerFunction( "ascii", new StandardSQLFunction("ascii", StandardBasicTypes.INTEGER) );
 
 		registerFunction( "to_char", new StandardSQLFunction("to_char", StandardBasicTypes.STRING) );
 		registerFunction( "to_date", new StandardSQLFunction("to_date", StandardBasicTypes.TIMESTAMP) );
 
 		registerFunction( "current_date", new NoArgSQLFunction("current_date", StandardBasicTypes.DATE, false) );
 		registerFunction( "current_time", new NoArgSQLFunction("current_timestamp", StandardBasicTypes.TIME, false) );
 		registerFunction( "current_timestamp", new NoArgSQLFunction("current_timestamp", StandardBasicTypes.TIMESTAMP, false) );
 
 		registerFunction( "last_day", new StandardSQLFunction("last_day", StandardBasicTypes.DATE) );
 		registerFunction( "sysdate", new NoArgSQLFunction("sysdate", StandardBasicTypes.DATE, false) );
 		registerFunction( "systimestamp", new NoArgSQLFunction("systimestamp", StandardBasicTypes.TIMESTAMP, false) );
 		registerFunction( "uid", new NoArgSQLFunction("uid", StandardBasicTypes.INTEGER, false) );
 		registerFunction( "user", new NoArgSQLFunction("user", StandardBasicTypes.STRING, false) );
 
 		registerFunction( "rowid", new NoArgSQLFunction("rowid", StandardBasicTypes.LONG, false) );
 		registerFunction( "rownum", new NoArgSQLFunction("rownum", StandardBasicTypes.LONG, false) );
 
 		// Multi-param string dialect functions...
 		registerFunction( "concat", new VarArgsSQLFunction(StandardBasicTypes.STRING, "", "||", "") );
 		registerFunction( "instr", new StandardSQLFunction("instr", StandardBasicTypes.INTEGER) );
 		registerFunction( "instrb", new StandardSQLFunction("instrb", StandardBasicTypes.INTEGER) );
 		registerFunction( "lpad", new StandardSQLFunction("lpad", StandardBasicTypes.STRING) );
 		registerFunction( "replace", new StandardSQLFunction("replace", StandardBasicTypes.STRING) );
 		registerFunction( "rpad", new StandardSQLFunction("rpad", StandardBasicTypes.STRING) );
 		registerFunction( "substr", new StandardSQLFunction("substr", StandardBasicTypes.STRING) );
 		registerFunction( "substrb", new StandardSQLFunction("substrb", StandardBasicTypes.STRING) );
 		registerFunction( "translate", new StandardSQLFunction("translate", StandardBasicTypes.STRING) );
 
 		registerFunction( "substring", new StandardSQLFunction( "substr", StandardBasicTypes.STRING ) );
 		registerFunction( "locate", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "instr(?2,?1)" ) );
 		registerFunction( "bit_length", new SQLFunctionTemplate( StandardBasicTypes.INTEGER, "vsize(?1)*8" ) );
 		registerFunction( "coalesce", new NvlFunction() );
 
 		// Multi-param numeric dialect functions...
 		registerFunction( "atan2", new StandardSQLFunction("atan2", StandardBasicTypes.FLOAT) );
 		registerFunction( "log", new StandardSQLFunction("log", StandardBasicTypes.INTEGER) );
 		registerFunction( "mod", new StandardSQLFunction("mod", StandardBasicTypes.INTEGER) );
 		registerFunction( "nvl", new StandardSQLFunction("nvl") );
 		registerFunction( "nvl2", new StandardSQLFunction("nvl2") );
 		registerFunction( "power", new StandardSQLFunction("power", StandardBasicTypes.FLOAT) );
 
 		// Multi-param date dialect functions...
 		registerFunction( "add_months", new StandardSQLFunction("add_months", StandardBasicTypes.DATE) );
 		registerFunction( "months_between", new StandardSQLFunction("months_between", StandardBasicTypes.FLOAT) );
 		registerFunction( "next_day", new StandardSQLFunction("next_day", StandardBasicTypes.DATE) );
 
 		registerFunction( "str", new StandardSQLFunction("to_char", StandardBasicTypes.STRING) );
 	}
 
 	protected void registerDefaultProperties() {
 		getDefaultProperties().setProperty( Environment.USE_STREAMS_FOR_BINARY, "true" );
 		getDefaultProperties().setProperty( Environment.STATEMENT_BATCH_SIZE, DEFAULT_BATCH_SIZE );
 		// Oracle driver reports to support getGeneratedKeys(), but they only
 		// support the version taking an array of the names of the columns to
 		// be returned (via its RETURNING clause).  No other driver seems to
 		// support this overloaded version.
 		getDefaultProperties().setProperty( Environment.USE_GET_GENERATED_KEYS, "false" );
 	}
 
 	@Override
 	protected SqlTypeDescriptor getSqlTypeDescriptorOverride(int sqlCode) {
 		return sqlCode == Types.BOOLEAN ? BitTypeDescriptor.INSTANCE : super.getSqlTypeDescriptorOverride( sqlCode );
 	}
 
 
 	// features which change between 8i, 9i, and 10g ~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public JoinFragment createOuterJoinFragment() {
 		return new OracleJoinFragment();
 	}
 
 	@Override
 	public String getCrossJoinSeparator() {
 		return ", ";
 	}
 
 	/**
 	 * Map case support to the Oracle DECODE function.  Oracle did not
 	 * add support for CASE until 9i.
 	 * <p/>
 	 * {@inheritDoc}
 	 */
 	@Override
 	public CaseFragment createCaseFragment() {
 		return new DecodeCaseFragment();
 	}
 
 	@Override
 	public LimitHandler getLimitHandler() {
 		return LIMIT_HANDLER;
 	}
 
 	@Override
 	public String getLimitString(String sql, boolean hasOffset) {
 		sql = sql.trim();
 		boolean isForUpdate = false;
 		if ( sql.toLowerCase(Locale.ROOT).endsWith( " for update" ) ) {
 			sql = sql.substring( 0, sql.length()-11 );
 			isForUpdate = true;
 		}
 
 		final StringBuilder pagingSelect = new StringBuilder( sql.length()+100 );
 		if (hasOffset) {
 			pagingSelect.append( "select * from ( select row_.*, rownum rownum_ from ( " );
 		}
 		else {
 			pagingSelect.append( "select * from ( " );
 		}
 		pagingSelect.append( sql );
 		if (hasOffset) {
 			pagingSelect.append( " ) row_ ) where rownum_ <= ? and rownum_ > ?" );
 		}
 		else {
 			pagingSelect.append( " ) where rownum <= ?" );
 		}
 
 		if ( isForUpdate ) {
 			pagingSelect.append( " for update" );
 		}
 
 		return pagingSelect.toString();
 	}
 
 	/**
 	 * Allows access to the basic {@link Dialect#getSelectClauseNullString}
 	 * implementation...
 	 *
 	 * @param sqlType The {@link java.sql.Types} mapping type code
 	 * @return The appropriate select cluse fragment
 	 */
 	public String getBasicSelectClauseNullString(int sqlType) {
 		return super.getSelectClauseNullString( sqlType );
 	}
 
 	@Override
 	public String getSelectClauseNullString(int sqlType) {
 		switch(sqlType) {
 			case Types.VARCHAR:
 			case Types.CHAR:
 				return "to_char(null)";
 			case Types.DATE:
 			case Types.TIMESTAMP:
 			case Types.TIME:
 				return "to_date(null)";
 			default:
 				return "to_number(null)";
 		}
 	}
 
 	@Override
 	public String getCurrentTimestampSelectString() {
 		return "select sysdate from dual";
 	}
 
 	@Override
 	public String getCurrentTimestampSQLFunctionName() {
 		return "sysdate";
 	}
 
 
 	// features which remain constant across 8i, 9i, and 10g ~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public String getAddColumnString() {
 		return "add";
 	}
 
 	@Override
 	public String getSequenceNextValString(String sequenceName) {
 		return "select " + getSelectSequenceNextValString( sequenceName ) + " from dual";
 	}
 
 	@Override
 	public String getSelectSequenceNextValString(String sequenceName) {
 		return sequenceName + ".nextval";
 	}
 
 	@Override
 	public String getCreateSequenceString(String sequenceName) {
 		//starts with 1, implicitly
 		return "create sequence " + sequenceName;
 	}
 
 	@Override
 	public String getDropSequenceString(String sequenceName) {
 		return "drop sequence " + sequenceName;
 	}
 
 	@Override
 	public String getCascadeConstraintsString() {
 		return " cascade constraints";
 	}
 
 	@Override
 	public boolean dropConstraints() {
 		return false;
 	}
 
 	@Override
 	public String getForUpdateNowaitString() {
 		return " for update nowait";
 	}
 
 	@Override
 	public boolean supportsSequences() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsPooledSequences() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsLimit() {
 		return true;
 	}
 
 	@Override
 	public String getForUpdateString(String aliases) {
 		return getForUpdateString() + " of " + aliases;
 	}
 
 	@Override
 	public String getForUpdateNowaitString(String aliases) {
 		return getForUpdateString() + " of " + aliases + " nowait";
 	}
 
 	@Override
 	public boolean bindLimitParametersInReverseOrder() {
 		return true;
 	}
 
 	@Override
 	public boolean useMaxForLimit() {
 		return true;
 	}
 
 	@Override
 	public boolean forUpdateOfColumns() {
 		return true;
 	}
 
 	@Override
 	public String getQuerySequencesString() {
 		return    " select sequence_name from all_sequences"
 				+ "  union"
 				+ " select synonym_name"
 				+ "   from all_synonyms us, all_sequences asq"
 				+ "  where asq.sequence_name = us.table_name"
 				+ "    and asq.sequence_owner = us.table_owner";
 	}
 
 	@Override
 	public String getSelectGUIDString() {
 		return "select rawtohex(sys_guid()) from dual";
 	}
 
 	@Override
 	public ViolatedConstraintNameExtracter getViolatedConstraintNameExtracter() {
 		return EXTRACTER;
 	}
 
 	private static final ViolatedConstraintNameExtracter EXTRACTER = new TemplatedViolatedConstraintNameExtracter() {
 
 		/**
 		 * Extract the name of the violated constraint from the given SQLException.
 		 *
 		 * @param sqle The exception that was the result of the constraint violation.
 		 * @return The extracted constraint name.
 		 */
 		public String extractConstraintName(SQLException sqle) {
 			final int errorCode = JdbcExceptionHelper.extractErrorCode( sqle );
 			if ( errorCode == 1 || errorCode == 2291 || errorCode == 2292 ) {
 				return extractUsingTemplate( "(", ")", sqle.getMessage() );
 			}
 			else if ( errorCode == 1400 ) {
 				// simple nullability constraint
 				return null;
 			}
 			else {
 				return null;
 			}
 		}
 
 	};
 
 	@Override
 	public SQLExceptionConversionDelegate buildSQLExceptionConversionDelegate() {
 		return new SQLExceptionConversionDelegate() {
 			@Override
 			public JDBCException convert(SQLException sqlException, String message, String sql) {
 				// interpreting Oracle exceptions is much much more precise based on their specific vendor codes.
 
 				final int errorCode = JdbcExceptionHelper.extractErrorCode( sqlException );
 
 
 				// lock timeouts ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 				if ( errorCode == 30006 ) {
 					// ORA-30006: resource busy; acquire with WAIT timeout expired
 					throw new LockTimeoutException( message, sqlException, sql );
 				}
 				else if ( errorCode == 54 ) {
 					// ORA-00054: resource busy and acquire with NOWAIT specified or timeout expired
 					throw new LockTimeoutException( message, sqlException, sql );
 				}
 				else if ( 4021 == errorCode ) {
 					// ORA-04021 timeout occurred while waiting to lock object
 					throw new LockTimeoutException( message, sqlException, sql );
 				}
 
 
 				// deadlocks ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 				if ( 60 == errorCode ) {
 					// ORA-00060: deadlock detected while waiting for resource
 					return new LockAcquisitionException( message, sqlException, sql );
 				}
 				else if ( 4020 == errorCode ) {
 					// ORA-04020 deadlock detected while trying to lock object
 					return new LockAcquisitionException( message, sqlException, sql );
 				}
 
 
 				// query cancelled ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 				if ( 1013 == errorCode ) {
 					// ORA-01013: user requested cancel of current operation
 					throw new QueryTimeoutException(  message, sqlException, sql );
 				}
 
 
 				// data integrity violation ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 				if ( 1407 == errorCode ) {
 					// ORA-01407: cannot update column to NULL
 					final String constraintName = getViolatedConstraintNameExtracter().extractConstraintName( sqlException );
 					return new ConstraintViolationException( message, sqlException, sql, constraintName );
 				}
 
 				return null;
 			}
 		};
 	}
 
 	@Override
 	public int registerResultSetOutParameter(CallableStatement statement, int col) throws SQLException {
 		//	register the type of the out param - an Oracle specific type
 		statement.registerOutParameter( col, OracleTypesHelper.INSTANCE.getOracleCursorTypeSqlType() );
 		col++;
 		return col;
 	}
 
 	@Override
 	public ResultSet getResultSet(CallableStatement ps) throws SQLException {
 		ps.execute();
 		return (ResultSet) ps.getObject( 1 );
 	}
 
 	@Override
 	public boolean supportsUnionAll() {
 		return true;
 	}
 
 	@Override
 	public boolean supportsCommentOn() {
 		return true;
 	}
 
 	@Override
 	public MultiTableBulkIdStrategy getDefaultMultiTableBulkIdStrategy() {
 		return new GlobalTemporaryTableBulkIdStrategy(
 				new IdTableSupportStandardImpl() {
 					@Override
 					public String generateIdTableName(String baseName) {
 						final String name = super.generateIdTableName( baseName );
 						return name.length() > 30 ? name.substring( 0, 30 ) : name;
 					}
 
 					@Override
 					public String getCreateIdTableCommand() {
 						return "create global temporary table";
 					}
 
 					@Override
 					public String getCreateIdTableStatementOptions() {
 						return "on commit delete rows";
 					}
 				},
 				AfterUseAction.CLEAN
 		);
 	}
 
 	@Override
 	public boolean supportsCurrentTimestampSelection() {
 		return true;
 	}
 
 	@Override
 	public boolean isCurrentTimestampSelectStringCallable() {
 		return false;
 	}
 
 	@Override
 	public boolean supportsEmptyInList() {
 		return false;
 	}
 	
 	@Override
 	public boolean supportsExistsInSelect() {
 		return false;
 	}
 
 	@Override
 	public int getInExpressionCountLimit() {
 		return PARAM_LIST_SIZE_LIMIT;
 	}
 	
 	@Override
 	public boolean forceLobAsLastValue() {
 		return true;
 	}
 
 	@Override
 	public boolean useFollowOnLocking() {
 		return true;
 	}
 	
 	@Override
 	public String getNotExpression( String expression ) {
 		return "not (" + expression + ")";
 	}
 	
 	@Override
 	public String getQueryHintString(String sql, List<String> hints) {
 		final String hint = StringHelper.join( ", ", hints.iterator() );
 		
 		if ( StringHelper.isEmpty( hint ) ) {
 			return sql;
 		}
 
 		final int pos = sql.indexOf( "select" );
 		if ( pos > -1 ) {
 			final StringBuilder buffer = new StringBuilder( sql.length() + hint.length() + 8 );
 			if ( pos > 0 ) {
 				buffer.append( sql.substring( 0, pos ) );
 			}
 			buffer.append( "select /*+ " ).append( hint ).append( " */" )
 					.append( sql.substring( pos + "select".length() ) );
 			sql = buffer.toString();
 		}
 
 		return sql;
 	}
 	
 	@Override
 	public int getMaxAliasLength() {
 		// Oracle's max identifier length is 30, but Hibernate needs to add "uniqueing info" so we account for that,
 		return 20;
 	}
 
 	@Override
 	public CallableStatementSupport getCallableStatementSupport() {
 		// Oracle supports returning cursors
 		return StandardCallableStatementSupport.REF_CURSOR_INSTANCE;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/DotNode.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/DotNode.java
index c91b5d308f..712f6be874 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/DotNode.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/DotNode.java
@@ -1,765 +1,764 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.internal.ast.tree;
 
 import org.hibernate.QueryException;
 import org.hibernate.engine.internal.JoinSequence;
 import org.hibernate.hql.internal.CollectionProperties;
 import org.hibernate.hql.internal.antlr.SqlTokenTypes;
 import org.hibernate.hql.internal.ast.util.ASTUtil;
 import org.hibernate.hql.internal.ast.util.ColumnHelper;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Queryable;
-import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.JoinType;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 import antlr.SemanticException;
 import antlr.collections.AST;
 
 /**
  * Represents a reference to a property or alias expression.  This should duplicate the relevant behaviors in
  * PathExpressionParser.
  *
  * @author Joshua Davis
  */
 public class DotNode extends FromReferenceNode implements DisplayableNode, SelectExpression {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( DotNode.class );
 
 	///////////////////////////////////////////////////////////////////////////
 	// USED ONLY FOR REGRESSION TESTING!!!!
 	//
 	// todo : obviously get rid of all this junk ;)
 	///////////////////////////////////////////////////////////////////////////
 	public static boolean useThetaStyleImplicitJoins;
 	public static boolean regressionStyleJoinSuppression;
 
-	public static interface IllegalCollectionDereferenceExceptionBuilder {
-		public QueryException buildIllegalCollectionDereferenceException(
+	public interface IllegalCollectionDereferenceExceptionBuilder {
+		QueryException buildIllegalCollectionDereferenceException(
 				String collectionPropertyName,
 				FromReferenceNode lhs);
 	}
 
 	public static final IllegalCollectionDereferenceExceptionBuilder DEF_ILLEGAL_COLL_DEREF_EXCP_BUILDER = new IllegalCollectionDereferenceExceptionBuilder() {
 		public QueryException buildIllegalCollectionDereferenceException(String propertyName, FromReferenceNode lhs) {
 			String lhsPath = ASTUtil.getPathText( lhs );
 			return new QueryException( "illegal attempt to dereference collection [" + lhsPath + "] with element property reference [" + propertyName + "]" );
 		}
 	};
 	public static IllegalCollectionDereferenceExceptionBuilder ILLEGAL_COLL_DEREF_EXCP_BUILDER = DEF_ILLEGAL_COLL_DEREF_EXCP_BUILDER;
 	///////////////////////////////////////////////////////////////////////////
 
 	public static enum DereferenceType {
 		UNKNOWN,
 		ENTITY,
 		COMPONENT,
 		COLLECTION,
 		PRIMITIVE,
 		IDENTIFIER,
 		JAVA_CONSTANT
 	}
 
 	/**
 	 * The identifier that is the name of the property.
 	 */
 	private String propertyName;
 	/**
 	 * The full path, to the root alias of this dot node.
 	 */
 	private String path;
 	/**
 	 * The unresolved property path relative to this dot node.
 	 */
 	private String propertyPath;
 
 	/**
 	 * The column names that this resolves to.
 	 */
 	private String[] columns;
 
 	/**
 	 * The type of join to create.   Default is an inner join.
 	 */
 	private JoinType joinType = JoinType.INNER_JOIN;
 
 	/**
 	 * Fetch join or not.
 	 */
 	private boolean fetch;
 
 	/**
 	 * The type of dereference that hapened
 	 */
 	private DereferenceType dereferenceType = DereferenceType.UNKNOWN;
 
 	private FromElement impliedJoin;
 
 	/**
 	 * Sets the join type for this '.' node structure.
 	 *
 	 * @param joinType The type of join to use.
 	 *
-	 * @see JoinFragment
+	 * @see org.hibernate.sql.JoinFragment
 	 */
 	public void setJoinType(JoinType joinType) {
 		this.joinType = joinType;
 	}
 
 	private String[] getColumns() throws QueryException {
 		if ( columns == null ) {
 			// Use the table fromElement and the property name to get the array of column names.
 			String tableAlias = getLhs().getFromElement().getTableAlias();
 			columns = getFromElement().toColumns( tableAlias, propertyPath, false );
 		}
 		return columns;
 	}
 
 	@Override
 	public String getDisplayText() {
 		StringBuilder buf = new StringBuilder();
 		FromElement fromElement = getFromElement();
 		buf.append( "{propertyName=" ).append( propertyName );
 		buf.append( ",dereferenceType=" ).append( dereferenceType.name() );
 		buf.append( ",getPropertyPath=" ).append( propertyPath );
 		buf.append( ",path=" ).append( getPath() );
 		if ( fromElement != null ) {
 			buf.append( ",tableAlias=" ).append( fromElement.getTableAlias() );
 			buf.append( ",className=" ).append( fromElement.getClassName() );
 			buf.append( ",classAlias=" ).append( fromElement.getClassAlias() );
 		}
 		else {
 			buf.append( ",no from element" );
 		}
 		buf.append( '}' );
 		return buf.toString();
 	}
 
 	/**
 	 * Resolves the left hand side of the DOT.
 	 *
 	 * @throws SemanticException
 	 */
 	@Override
 	public void resolveFirstChild() throws SemanticException {
 		FromReferenceNode lhs = (FromReferenceNode) getFirstChild();
 		SqlNode property = (SqlNode) lhs.getNextSibling();
 
 		// Set the attributes of the property reference expression.
 		String propName = property.getText();
 		propertyName = propName;
 		// If the uresolved property path isn't set yet, just use the property name.
 		if ( propertyPath == null ) {
 			propertyPath = propName;
 		}
 		// Resolve the LHS fully, generate implicit joins.  Pass in the property name so that the resolver can
 		// discover foreign key (id) properties.
 		lhs.resolve( true, true, null, this );
 		setFromElement( lhs.getFromElement() );            // The 'from element' that the property is in.
 
 		checkSubclassOrSuperclassPropertyReference( lhs, propName );
 	}
 
 	@Override
 	public void resolveInFunctionCall(boolean generateJoin, boolean implicitJoin) throws SemanticException {
 		if ( isResolved() ) {
 			return;
 		}
 		Type propertyType = prepareLhs();            // Prepare the left hand side and get the data type.
 		if ( propertyType != null && propertyType.isCollectionType() ) {
 			resolveIndex( null );
 		}
 		else {
 			resolveFirstChild();
 			super.resolve( generateJoin, implicitJoin );
 		}
 	}
 
 
 	public void resolveIndex(AST parent) throws SemanticException {
 		if ( isResolved() ) {
 			return;
 		}
 		Type propertyType = prepareLhs();            // Prepare the left hand side and get the data type.
 		dereferenceCollection( (CollectionType) propertyType, true, true, null, parent );
 	}
 
 	public void resolve(boolean generateJoin, boolean implicitJoin, String classAlias, AST parent)
 			throws SemanticException {
 		// If this dot has already been resolved, stop now.
 		if ( isResolved() ) {
 			return;
 		}
 		Type propertyType = prepareLhs(); // Prepare the left hand side and get the data type.
 
 		// If there is no data type for this node, and we're at the end of the path (top most dot node), then
 		// this might be a Java constant.
 		if ( propertyType == null ) {
 			if ( parent == null ) {
 				getWalker().getLiteralProcessor().lookupConstant( this );
 			}
 			// If the propertyType is null and there isn't a parent, just
 			// stop now... there was a problem resolving the node anyway.
 			return;
 		}
 
 		if ( propertyType.isComponentType() ) {
 			// The property is a component...
 			checkLhsIsNotCollection();
 			dereferenceComponent( parent );
 			initText();
 		}
 		else if ( propertyType.isEntityType() ) {
 			// The property is another class..
 			checkLhsIsNotCollection();
 			dereferenceEntity( (EntityType) propertyType, implicitJoin, classAlias, generateJoin, parent );
 			initText();
 		}
 		else if ( propertyType.isCollectionType() ) {
 			// The property is a collection...
 			checkLhsIsNotCollection();
 			dereferenceCollection( (CollectionType) propertyType, implicitJoin, false, classAlias, parent );
 		}
 		else {
 			// Otherwise, this is a primitive type.
 			if ( !CollectionProperties.isAnyCollectionProperty( propertyName ) ) {
 				checkLhsIsNotCollection();
 			}
 			dereferenceType = DereferenceType.PRIMITIVE;
 			initText();
 		}
 		setResolved();
 	}
 
 	private void initText() {
 		String[] cols = getColumns();
 		String text = StringHelper.join( ", ", cols );
 		boolean countDistinct = getWalker().isInCountDistinct()
 				&& getWalker().getSessionFactoryHelper().getFactory().getDialect().requiresParensForTupleDistinctCounts();
 		if ( cols.length > 1 &&
 				( getWalker().isComparativeExpressionClause() || countDistinct ) ) {
 			text = "(" + text + ")";
 		}
 		setText( text );
 	}
 
 	private Type prepareLhs() throws SemanticException {
 		FromReferenceNode lhs = getLhs();
 		lhs.prepareForDot( propertyName );
 		return getDataType();
 	}
 
 	private void dereferenceCollection(
 			CollectionType collectionType,
 			boolean implicitJoin,
 			boolean indexed,
 			String classAlias,
 			AST parent)
 			throws SemanticException {
 
 		dereferenceType = DereferenceType.COLLECTION;
 		String role = collectionType.getRole();
 
 		//foo.bars.size (also handles deprecated stuff like foo.bars.maxelement for backwardness)
 		boolean isSizeProperty = getNextSibling() != null &&
 				CollectionProperties.isAnyCollectionProperty( getNextSibling().getText() );
 
 		if ( isSizeProperty ) {
 			indexed = true; //yuck!
 		}
 
 		QueryableCollection queryableCollection = getSessionFactoryHelper().requireQueryableCollection( role );
 		String propName = getPath();
 		FromClause currentFromClause = getWalker().getCurrentFromClause();
 
 		// If the lhs of the join is a "component join", we need to go back to the
 		// first non-component-join as the origin to properly link aliases and
 		// join columns
 		FromElement lhsFromElement = getLhs().getFromElement();
 		while ( lhsFromElement != null && ComponentJoin.class.isInstance( lhsFromElement ) ) {
 			lhsFromElement = lhsFromElement.getOrigin();
 		}
 		if ( lhsFromElement == null ) {
 			throw new QueryException( "Unable to locate appropriate lhs" );
 		}
 
 		// determine whether we should use the table name or table alias to qualify the column names...
 		// we need to use the table-name when:
 		//		1) the top-level statement is not a SELECT
 		//		2) the LHS FromElement is *the* FromElement from the top-level statement
 		//
 		// there is a caveat here.. if the update/delete statement are "multi-table" we should continue to use
 		// the alias also, even if the FromElement is the root one...
 		//
 		// in all other cases, we should use the table alias
 		if ( getWalker().getStatementType() != SqlTokenTypes.SELECT ) {
 			if ( isFromElementUpdateOrDeleteRoot( lhsFromElement ) ) {
 				// at this point we know we have the 2 conditions above,
 				// lets see if we have the mentioned "multi-table" caveat...
 				boolean useAlias = false;
 				if ( getWalker().getStatementType() != SqlTokenTypes.INSERT ) {
 					final Queryable persister = lhsFromElement.getQueryable();
 					if ( persister.isMultiTable() ) {
 						useAlias = true;
 					}
 				}
 				if ( !useAlias ) {
 					final String lhsTableName = lhsFromElement.getQueryable().getTableName();
 					columns = getFromElement().toColumns( lhsTableName, propertyPath, false, true );
 				}
 			}
 		}
 
 		// We do not look for an existing join on the same path, because
 		// it makes sense to join twice on the same collection role
 		FromElementFactory factory = new FromElementFactory(
 				currentFromClause,
 				lhsFromElement,
 				propName,
 				classAlias,
 				getColumns(),
 				implicitJoin
 		);
 		FromElement elem = factory.createCollection( queryableCollection, role, joinType, fetch, indexed );
 
 		LOG.debugf( "dereferenceCollection() : Created new FROM element for %s : %s", propName, elem );
 
 		setImpliedJoin( elem );
 		setFromElement( elem );    // This 'dot' expression now refers to the resulting from element.
 
 		if ( isSizeProperty ) {
 			elem.setText( "" );
 			elem.setUseWhereFragment( false );
 		}
 
 		if ( !implicitJoin ) {
 			EntityPersister entityPersister = elem.getEntityPersister();
 			if ( entityPersister != null ) {
 				getWalker().addQuerySpaces( entityPersister.getQuerySpaces() );
 			}
 		}
 		getWalker().addQuerySpaces( queryableCollection.getCollectionSpaces() );    // Always add the collection's query spaces.
 	}
 
 	private void dereferenceEntity(
 			EntityType entityType,
 			boolean implicitJoin,
 			String classAlias,
 			boolean generateJoin,
 			AST parent) throws SemanticException {
 		checkForCorrelatedSubquery( "dereferenceEntity" );
 		// three general cases we check here as to whether to render a physical SQL join:
 		// 1) is our parent a DotNode as well?  If so, our property reference is
 		// 		being further de-referenced...
 		// 2) is this a DML statement
 		// 3) we were asked to generate any needed joins (generateJoins==true) *OR*
 		//		we are currently processing a select or from clause
 		// (an additional check is the regressionStyleJoinSuppression check solely intended for the test suite)
 		//
 		// The regressionStyleJoinSuppression is an additional check
 		// intended solely for use within the test suite.  This forces the
 		// implicit join resolution to behave more like the classic parser.
 		// The underlying issue is that classic translator is simply wrong
 		// about its decisions on whether or not to render an implicit join
 		// into a physical SQL join in a lot of cases.  The piece it generally
 		// tends to miss is that INNER joins effect the results by further
 		// restricting the data set!  A particular manifestation of this is
 		// the fact that the classic translator will skip the physical join
 		// for ToOne implicit joins *if the query is shallow*; the result
 		// being that Query.list() and Query.iterate() could return
 		// different number of results!
 		DotNode parentAsDotNode = null;
 		String property = propertyName;
 		final boolean joinIsNeeded;
 
 		if ( isDotNode( parent ) ) {
 			// our parent is another dot node, meaning we are being further dereferenced.
 			// thus we need to generate a join unless the parent refers to the associated
 			// entity's PK (because 'our' table would know the FK).
 			parentAsDotNode = (DotNode) parent;
 			property = parentAsDotNode.propertyName;
 			joinIsNeeded = generateJoin && !isReferenceToPrimaryKey( parentAsDotNode.propertyName, entityType );
 		}
 		else if ( !getWalker().isSelectStatement() ) {
 			// in non-select queries, the only time we should need to join is if we are in a subquery from clause
 			joinIsNeeded = getWalker().getCurrentStatementType() == SqlTokenTypes.SELECT && getWalker().isInFrom();
 		}
 		else if ( regressionStyleJoinSuppression ) {
 			// this is the regression style determination which matches the logic of the classic translator
 			joinIsNeeded = generateJoin && ( !getWalker().isInSelect() || !getWalker().isShallowQuery() );
 		}
 		else {
 			joinIsNeeded = generateJoin || ( getWalker().isInSelect() || getWalker().isInFrom() );
 		}
 
 		if ( joinIsNeeded ) {
 			dereferenceEntityJoin( classAlias, entityType, implicitJoin, parent );
 		}
 		else {
 			dereferenceEntityIdentifier( property, parentAsDotNode );
 		}
 
 	}
 
 	private boolean isDotNode(AST n) {
 		return n != null && n.getType() == SqlTokenTypes.DOT;
 	}
 
 	private void dereferenceEntityJoin(String classAlias, EntityType propertyType, boolean impliedJoin, AST parent)
 			throws SemanticException {
 		dereferenceType = DereferenceType.ENTITY;
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"dereferenceEntityJoin() : generating join for %s in %s (%s) parent = %s",
 					propertyName,
 					getFromElement().getClassName(),
 					classAlias == null ? "<no alias>" : classAlias,
 					ASTUtil.getDebugString( parent )
 			);
 		}
 		// Create a new FROM node for the referenced class.
 		String associatedEntityName = propertyType.getAssociatedEntityName();
 		String tableAlias = getAliasGenerator().createName( associatedEntityName );
 
 		String[] joinColumns = getColumns();
 		String joinPath = getPath();
 
 		if ( impliedJoin && getWalker().isInFrom() ) {
 			joinType = getWalker().getImpliedJoinType();
 		}
 
 		FromClause currentFromClause = getWalker().getCurrentFromClause();
 		FromElement elem = currentFromClause.findJoinByPath( joinPath );
 
 ///////////////////////////////////////////////////////////////////////////////
 //
 // This is the piece which recognizes the condition where an implicit join path
 // resolved earlier in a correlated subquery is now being referenced in the
 // outer query.  For 3.0final, we just let this generate a second join (which
 // is exactly how the old parser handles this).  Eventually we need to add this
 // logic back in and complete the logic in FromClause.promoteJoin; however,
 // FromClause.promoteJoin has its own difficulties (see the comments in
 // FromClause.promoteJoin).
 //
 //		if ( elem == null ) {
 //			// see if this joinPath has been used in a "child" FromClause, and if so
 //			// promote that element to the outer query
 //			FromClause currentNodeOwner = getFromElement().getFromClause();
 //			FromClause currentJoinOwner = currentNodeOwner.locateChildFromClauseWithJoinByPath( joinPath );
 //			if ( currentJoinOwner != null && currentNodeOwner != currentJoinOwner ) {
 //				elem = currentJoinOwner.findJoinByPathLocal( joinPath );
 //				if ( elem != null ) {
 //					currentFromClause.promoteJoin( elem );
 //					// EARLY EXIT!!!
 //					return;
 //				}
 //			}
 //		}
 //
 ///////////////////////////////////////////////////////////////////////////////
 
 		boolean found = elem != null;
 		// even though we might find a pre-existing element by join path, we may not be able to reuse it...
 		boolean useFoundFromElement = found && canReuse( elem );
 
 		if ( !useFoundFromElement ) {
 			// If this is an implied join in a from element, then use the impled join type which is part of the
 			// tree parser's state (set by the gramamar actions).
 			JoinSequence joinSequence = getSessionFactoryHelper()
 					.createJoinSequence( impliedJoin, propertyType, tableAlias, joinType, joinColumns );
 
 			// If the lhs of the join is a "component join", we need to go back to the
 			// first non-component-join as the origin to properly link aliases and
 			// join columns
 			FromElement lhsFromElement = getLhs().getFromElement();
 			while ( lhsFromElement != null && ComponentJoin.class.isInstance( lhsFromElement ) ) {
 				lhsFromElement = lhsFromElement.getOrigin();
 			}
 			if ( lhsFromElement == null ) {
 				throw new QueryException( "Unable to locate appropriate lhs" );
 			}
 
 			String role = lhsFromElement.getClassName() + "." + propertyName;
 
 			FromElementFactory factory = new FromElementFactory(
 					currentFromClause,
 					lhsFromElement,
 					joinPath,
 					classAlias,
 					joinColumns,
 					impliedJoin
 			);
 			elem = factory.createEntityJoin(
 					associatedEntityName,
 					tableAlias,
 					joinSequence,
 					fetch,
 					getWalker().isInFrom(),
 					propertyType,
 					role,
 					joinPath
 			);
 		}
 		else {
 			// NOTE : addDuplicateAlias() already performs nullness checks on the alias.
 			currentFromClause.addDuplicateAlias( classAlias, elem );
 		}
 		setImpliedJoin( elem );
 		getWalker().addQuerySpaces( elem.getEntityPersister().getQuerySpaces() );
 		setFromElement( elem );    // This 'dot' expression now refers to the resulting from element.
 	}
 
 	private boolean canReuse(FromElement fromElement) {
 		// if the from-clauses are the same, we can be a little more aggressive in terms of what we reuse
 		if ( fromElement.getFromClause() == getWalker().getCurrentFromClause() ) {
 			return true;
 		}
 
 		// otherwise (subquery case) dont reuse the fromElement if we are processing the from-clause of the subquery
 		return getWalker().getCurrentClauseType() != SqlTokenTypes.FROM;
 	}
 
 	private void setImpliedJoin(FromElement elem) {
 		this.impliedJoin = elem;
 		if ( getFirstChild().getType() == SqlTokenTypes.DOT ) {
 			DotNode dotLhs = (DotNode) getFirstChild();
 			if ( dotLhs.getImpliedJoin() != null ) {
 				this.impliedJoin = dotLhs.getImpliedJoin();
 			}
 		}
 	}
 
 	@Override
 	public FromElement getImpliedJoin() {
 		return impliedJoin;
 	}
 
 	/**
 	 * Is the given property name a reference to the primary key of the associated
 	 * entity construed by the given entity type?
 	 * <p/>
 	 * For example, consider a fragment like order.customer.id
 	 * (where order is a from-element alias).  Here, we'd have:
 	 * propertyName = "id" AND
 	 * owningType = ManyToOneType(Customer)
 	 * and are being asked to determine whether "customer.id" is a reference
 	 * to customer's PK...
 	 *
 	 * @param propertyName The name of the property to check.
 	 * @param owningType The type represeting the entity "owning" the property
 	 *
 	 * @return True if propertyName references the entity's (owningType->associatedEntity)
 	 *         primary key; false otherwise.
 	 */
 	private boolean isReferenceToPrimaryKey(String propertyName, EntityType owningType) {
 		EntityPersister persister = getSessionFactoryHelper()
 				.getFactory()
 				.getEntityPersister( owningType.getAssociatedEntityName() );
 		if ( persister.getEntityMetamodel().hasNonIdentifierPropertyNamedId() ) {
 			// only the identifier property field name can be a reference to the associated entity's PK...
 			return propertyName.equals( persister.getIdentifierPropertyName() ) && owningType.isReferenceToPrimaryKey();
 		}
 		// here, we have two possibilities:
 		// 1) the property-name matches the explicitly identifier property name
 		// 2) the property-name matches the implicit 'id' property name
 		// the referenced node text is the special 'id'
 		if ( EntityPersister.ENTITY_ID.equals( propertyName ) ) {
 			return owningType.isReferenceToPrimaryKey();
 		}
 		String keyPropertyName = getSessionFactoryHelper().getIdentifierOrUniqueKeyPropertyName( owningType );
 		return keyPropertyName != null && keyPropertyName.equals( propertyName ) && owningType.isReferenceToPrimaryKey();
 	}
 
 	private void checkForCorrelatedSubquery(String methodName) {
 		if ( isCorrelatedSubselect() ) {
 			LOG.debugf( "%s() : correlated subquery", methodName );
 		}
 	}
 
 	private boolean isCorrelatedSubselect() {
 		return getWalker().isSubQuery() &&
 				getFromElement().getFromClause() != getWalker().getCurrentFromClause();
 	}
 
 	private void checkLhsIsNotCollection() throws SemanticException {
 		if ( getLhs().getDataType() != null && getLhs().getDataType().isCollectionType() ) {
 			throw ILLEGAL_COLL_DEREF_EXCP_BUILDER.buildIllegalCollectionDereferenceException( propertyName, getLhs() );
 		}
 	}
 
 	private void dereferenceComponent(AST parent) {
 		dereferenceType = DereferenceType.COMPONENT;
 		setPropertyNameAndPath( parent );
 	}
 
 	private void dereferenceEntityIdentifier(String propertyName, DotNode dotParent) {
 		// special shortcut for id properties, skip the join!
 		// this must only occur at the _end_ of a path expression
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"dereferenceShortcut() : property %s in %s does not require a join.",
 					propertyName,
 					getFromElement().getClassName()
 			);
 		}
 
 		initText();
 		setPropertyNameAndPath( dotParent ); // Set the unresolved path in this node and the parent.
 		// Set the text for the parent.
 		if ( dotParent != null ) {
 			dotParent.dereferenceType = DereferenceType.IDENTIFIER;
 			dotParent.setText( getText() );
 			dotParent.columns = getColumns();
 		}
 	}
 
 	private void setPropertyNameAndPath(AST parent) {
 		if ( isDotNode( parent ) ) {
 			DotNode dotNode = (DotNode) parent;
 			AST lhs = dotNode.getFirstChild();
 			AST rhs = lhs.getNextSibling();
 			propertyName = rhs.getText();
 			propertyPath = propertyPath + "." + propertyName; // Append the new property name onto the unresolved path.
 			dotNode.propertyPath = propertyPath;
 			LOG.debugf( "Unresolved property path is now '%s'", dotNode.propertyPath );
 		}
 		else {
 			LOG.debugf( "Terminal getPropertyPath = [%s]", propertyPath );
 		}
 	}
 
 	@Override
 	public Type getDataType() {
 		if ( super.getDataType() == null ) {
 			FromElement fromElement = getLhs().getFromElement();
 			if ( fromElement == null ) {
 				return null;
 			}
 			// If the lhs is a collection, use CollectionPropertyMapping
 			Type propertyType = fromElement.getPropertyType( propertyName, propertyPath );
 			LOG.debugf( "getDataType() : %s -> %s", propertyPath, propertyType );
 			super.setDataType( propertyType );
 		}
 		return super.getDataType();
 	}
 
 	public void setPropertyPath(String propertyPath) {
 		this.propertyPath = propertyPath;
 	}
 
 	public String getPropertyPath() {
 		return propertyPath;
 	}
 
 	public FromReferenceNode getLhs() {
 		FromReferenceNode lhs = ( (FromReferenceNode) getFirstChild() );
 		if ( lhs == null ) {
 			throw new IllegalStateException( "DOT node with no left-hand-side!" );
 		}
 		return lhs;
 	}
 
 	/**
 	 * Returns the full path of the node.
 	 *
 	 * @return the full path of the node.
 	 */
 	@Override
 	public String getPath() {
 		if ( path == null ) {
 			FromReferenceNode lhs = getLhs();
 			if ( lhs == null ) {
 				path = getText();
 			}
 			else {
 				SqlNode rhs = (SqlNode) lhs.getNextSibling();
 				path = lhs.getPath() + "." + rhs.getOriginalText();
 			}
 		}
 		return path;
 	}
 
 	public void setFetch(boolean fetch) {
 		this.fetch = fetch;
 	}
 
 	public void setScalarColumnText(int i) throws SemanticException {
 		String[] sqlColumns = getColumns();
 		ColumnHelper.generateScalarColumns( this, sqlColumns, i );
 	}
 
 	/**
 	 * Special method to resolve expressions in the SELECT list.
 	 *
 	 * @throws SemanticException if this cannot be resolved.
 	 */
 	public void resolveSelectExpression() throws SemanticException {
 		if ( getWalker().isShallowQuery() || getWalker().getCurrentFromClause().isSubQuery() ) {
 			resolve( false, true );
 		}
 		else {
 			resolve( true, false );
 			Type type = getDataType();
 			if ( type.isEntityType() ) {
 				FromElement fromElement = getFromElement();
 				fromElement.setIncludeSubclasses( true ); // Tell the destination fromElement to 'includeSubclasses'.
 				if ( useThetaStyleImplicitJoins ) {
 					fromElement.getJoinSequence().setUseThetaStyle( true );    // Use theta style (for regression)
 					// Move the node up, after the origin node.
 					FromElement origin = fromElement.getOrigin();
 					if ( origin != null ) {
 						ASTUtil.makeSiblingOfParent( origin, fromElement );
 					}
 				}
 			}
 		}
 
 		FromReferenceNode lhs = getLhs();
 		while ( lhs != null ) {
 			checkSubclassOrSuperclassPropertyReference( lhs, lhs.getNextSibling().getText() );
 			lhs = (FromReferenceNode) lhs.getFirstChild();
 		}
 	}
 
 	public void setResolvedConstant(String text) {
 		path = text;
 		dereferenceType = DereferenceType.JAVA_CONSTANT;
 		setResolved(); // Don't resolve the node again.
 	}
 
 	private boolean checkSubclassOrSuperclassPropertyReference(FromReferenceNode lhs, String propertyName) {
 		if ( lhs != null && !( lhs instanceof IndexNode ) ) {
 			final FromElement source = lhs.getFromElement();
 			if ( source != null ) {
 				source.handlePropertyBeingDereferenced( lhs.getDataType(), propertyName );
 			}
 		}
 		return false;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/PreprocessingParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/PreprocessingParser.java
index a8210ab430..127b3719b5 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/PreprocessingParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/PreprocessingParser.java
@@ -1,156 +1,158 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.classic;
 
 import java.util.HashSet;
 import java.util.Locale;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.QueryException;
 import org.hibernate.hql.internal.CollectionProperties;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  *
  */
 public class PreprocessingParser implements Parser {
 
 	private static final Set<String> HQL_OPERATORS;
 
 	static {
 		HQL_OPERATORS = new HashSet<String>();
 		HQL_OPERATORS.add( "<=" );
 		HQL_OPERATORS.add( ">=" );
 		HQL_OPERATORS.add( "=>" );
 		HQL_OPERATORS.add( "=<" );
 		HQL_OPERATORS.add( "!=" );
 		HQL_OPERATORS.add( "<>" );
 		HQL_OPERATORS.add( "!#" );
 		HQL_OPERATORS.add( "!~" );
 		HQL_OPERATORS.add( "!<" );
 		HQL_OPERATORS.add( "!>" );
 		HQL_OPERATORS.add( "is not" );
 		HQL_OPERATORS.add( "not like" );
 		HQL_OPERATORS.add( "not in" );
 		HQL_OPERATORS.add( "not between" );
 		HQL_OPERATORS.add( "not exists" );
 	}
 
 	private Map replacements;
 	private boolean quoted;
 	private StringBuilder quotedString;
 	private ClauseParser parser = new ClauseParser();
 	private String lastToken;
 	private String currentCollectionProp;
 
 	public PreprocessingParser(Map replacements) {
 		this.replacements = replacements;
 	}
 
 	public void token(String token, QueryTranslatorImpl q) throws QueryException {
 
 		//handle quoted strings
 		if ( quoted ) {
 			quotedString.append( token );
 		}
 		if ( "'".equals( token ) ) {
 			if ( quoted ) {
 				token = quotedString.toString();
 			}
 			else {
 				quotedString = new StringBuilder( 20 ).append( token );
 			}
 			quoted = !quoted;
 		}
 		if ( quoted ) {
 			return;
 		}
 
 		//ignore whitespace
-		if ( ParserHelper.isWhitespace( token ) ) return;
+		if ( ParserHelper.isWhitespace( token ) ) {
+			return;
+		}
 
 		//do replacements
 		String substoken = ( String ) replacements.get( token );
 		token = ( substoken == null ) ? token : substoken;
 
 		//handle HQL2 collection syntax
 		if ( currentCollectionProp != null ) {
 			if ( "(".equals( token ) ) {
 				return;
 			}
 			else if ( ")".equals( token ) ) {
 				currentCollectionProp = null;
 				return;
 			}
 			else {
 				token = StringHelper.qualify( token, currentCollectionProp );
 			}
 		}
 		else {
 			String prop = CollectionProperties.getNormalizedPropertyName( token.toLowerCase(Locale.ROOT) );
 			if ( prop != null ) {
 				currentCollectionProp = prop;
 				return;
 			}
 		}
 
 
 		//handle <=, >=, !=, is not, not between, not in
 		if ( lastToken == null ) {
 			lastToken = token;
 		}
 		else {
 			String doubleToken = ( token.length() > 1 ) ?
 					lastToken + ' ' + token :
 					lastToken + token;
 			if ( HQL_OPERATORS.contains( doubleToken.toLowerCase(Locale.ROOT) ) ) {
 				parser.token( doubleToken, q );
 				lastToken = null;
 			}
 			else {
 				parser.token( lastToken, q );
 				lastToken = token;
 			}
 		}
 
 	}
 
 	public void start(QueryTranslatorImpl q) throws QueryException {
 		quoted = false;
 		parser.start( q );
 	}
 
 	public void end(QueryTranslatorImpl q) throws QueryException {
 		if ( lastToken != null ) {
 			parser.token( lastToken, q );
 		}
 		parser.end( q );
 		lastToken = null;
 		currentCollectionProp = null;
 	}
 
 }
 
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/CacheImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/CacheImpl.java
index 7dd2ef6375..67634241f6 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/CacheImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/CacheImpl.java
@@ -1,370 +1,369 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.io.Serializable;
 import java.util.HashMap;
-import java.util.Iterator;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 
 import org.hibernate.HibernateException;
 import org.hibernate.boot.spi.SessionFactoryOptions;
 import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.cache.spi.QueryCache;
 import org.hibernate.cache.spi.Region;
 import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cache.spi.UpdateTimestampsCache;
 import org.hibernate.engine.spi.CacheImplementor;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 
 /**
  * @author Strong Liu <stliu@hibernate.org>
  */
 public class CacheImpl implements CacheImplementor {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( CacheImpl.class );
 
 	private final SessionFactoryImplementor sessionFactory;
 	private final SessionFactoryOptions settings;
 	private final transient QueryCache queryCache;
 	private final transient RegionFactory regionFactory;
 	private final transient UpdateTimestampsCache updateTimestampsCache;
 	private final transient ConcurrentMap<String, QueryCache> queryCaches;
 	private final transient ConcurrentMap<String, Region> allCacheRegions = new ConcurrentHashMap<String, Region>();
 
 	public CacheImpl(SessionFactoryImplementor sessionFactory) {
 		this.sessionFactory = sessionFactory;
 		this.settings = sessionFactory.getSessionFactoryOptions();
 		//todo should get this from service registry
 		this.regionFactory = settings.getServiceRegistry().getService( RegionFactory.class );
 		regionFactory.start( settings, sessionFactory.getProperties() );
 		if ( settings.isQueryCacheEnabled() ) {
 			updateTimestampsCache = new UpdateTimestampsCache(
 					settings,
 					sessionFactory.getProperties(),
 					sessionFactory
 			);
 			queryCache = settings.getQueryCacheFactory()
 					.getQueryCache( null, updateTimestampsCache, settings, sessionFactory.getProperties() );
 			queryCaches = new ConcurrentHashMap<String, QueryCache>();
 			allCacheRegions.put( updateTimestampsCache.getRegion().getName(), updateTimestampsCache.getRegion() );
 			allCacheRegions.put( queryCache.getRegion().getName(), queryCache.getRegion() );
 		}
 		else {
 			updateTimestampsCache = null;
 			queryCache = null;
 			queryCaches = null;
 		}
 	}
 
 	@Override
 	public boolean containsEntity(Class entityClass, Serializable identifier) {
 		return containsEntity( entityClass.getName(), identifier );
 	}
 
 	@Override
 	public boolean containsEntity(String entityName, Serializable identifier) {
 		EntityPersister p = sessionFactory.getEntityPersister( entityName );
 		return p.hasCache() &&
 				p.getCacheAccessStrategy().getRegion().contains( buildCacheKey( identifier, p ) );
 	}
 
 	@Override
 	public void evictEntity(Class entityClass, Serializable identifier) {
 		evictEntity( entityClass.getName(), identifier );
 	}
 
 	@Override
 	public void evictEntity(String entityName, Serializable identifier) {
 		EntityPersister p = sessionFactory.getEntityPersister( entityName );
 		if ( p.hasCache() ) {
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf(
 						"Evicting second-level cache: %s",
 						MessageHelper.infoString( p, identifier, sessionFactory )
 				);
 			}
 			p.getCacheAccessStrategy().evict( buildCacheKey( identifier, p ) );
 		}
 	}
 
 	private CacheKey buildCacheKey(Serializable identifier, EntityPersister p) {
 		return new CacheKey(
 				identifier,
 				p.getIdentifierType(),
 				p.getRootEntityName(),
 				null,                         // have to assume non tenancy
 				sessionFactory
 		);
 	}
 
 	@Override
 	public void evictEntityRegion(Class entityClass) {
 		evictEntityRegion( entityClass.getName() );
 	}
 
 	@Override
 	public void evictEntityRegion(String entityName) {
 		EntityPersister p = sessionFactory.getEntityPersister( entityName );
 		if ( p.hasCache() ) {
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Evicting second-level cache: %s", p.getEntityName() );
 			}
 			p.getCacheAccessStrategy().evictAll();
 		}
 	}
 
 	@Override
 	public void evictEntityRegions() {
 		for ( String s : sessionFactory.getEntityPersisters().keySet() ) {
 			evictEntityRegion( s );
 		}
 	}
 
 	@Override
 	public void evictNaturalIdRegion(Class entityClass) {
 		evictNaturalIdRegion( entityClass.getName() );
 	}
 
 	@Override
 	public void evictNaturalIdRegion(String entityName) {
 		EntityPersister p = sessionFactory.getEntityPersister( entityName );
 		if ( p.hasNaturalIdCache() ) {
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Evicting natural-id cache: %s", p.getEntityName() );
 			}
 			p.getNaturalIdCacheAccessStrategy().evictAll();
 		}
 	}
 
 	@Override
 	public void evictNaturalIdRegions() {
 		for ( String s : sessionFactory.getEntityPersisters().keySet() ) {
 			evictNaturalIdRegion( s );
 		}
 	}
 
 	@Override
 	public boolean containsCollection(String role, Serializable ownerIdentifier) {
 		CollectionPersister p = sessionFactory.getCollectionPersister( role );
 		return p.hasCache() &&
 				p.getCacheAccessStrategy().getRegion().contains( buildCacheKey( ownerIdentifier, p ) );
 	}
 
 	@Override
 	public void evictCollection(String role, Serializable ownerIdentifier) {
 		CollectionPersister p = sessionFactory.getCollectionPersister( role );
 		if ( p.hasCache() ) {
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf(
 						"Evicting second-level cache: %s",
 						MessageHelper.collectionInfoString( p, ownerIdentifier, sessionFactory )
 				);
 			}
 			CacheKey cacheKey = buildCacheKey( ownerIdentifier, p );
 			p.getCacheAccessStrategy().evict( cacheKey );
 		}
 	}
 
 	private CacheKey buildCacheKey(Serializable ownerIdentifier, CollectionPersister p) {
 		return new CacheKey(
 				ownerIdentifier,
 				p.getKeyType(),
 				p.getRole(),
 				null,                        // have to assume non tenancy
 				sessionFactory
 		);
 	}
 
 	@Override
 	public void evictCollectionRegion(String role) {
 		CollectionPersister p = sessionFactory.getCollectionPersister( role );
 		if ( p.hasCache() ) {
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Evicting second-level cache: %s", p.getRole() );
 			}
 			p.getCacheAccessStrategy().evictAll();
 		}
 	}
 
 	@Override
 	public void evictCollectionRegions() {
 		for ( String s : sessionFactory.getCollectionPersisters().keySet() ) {
 			evictCollectionRegion( s );
 		}
 	}
 
 	@Override
 	public boolean containsQuery(String regionName) {
 		return queryCaches.containsKey( regionName );
 	}
 
 	@Override
 	public void evictDefaultQueryRegion() {
 		if ( sessionFactory.getSessionFactoryOptions().isQueryCacheEnabled() ) {
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debug( "Evicting default query region cache." );
 			}
 			sessionFactory.getQueryCache().clear();
 		}
 	}
 
 	@Override
 	public void evictQueryRegion(String regionName) {
 		if ( regionName == null ) {
 			throw new NullPointerException(
 					"Region-name cannot be null (use Cache#evictDefaultQueryRegion to evict the default query cache)"
 			);
 		}
 		if ( sessionFactory.getSessionFactoryOptions().isQueryCacheEnabled() ) {
 			QueryCache namedQueryCache = queryCaches.get( regionName );
 			// TODO : cleanup entries in queryCaches + allCacheRegions ?
 			if ( namedQueryCache != null ) {
 				if ( LOG.isDebugEnabled() ) {
 					LOG.debugf( "Evicting query cache, region: %s", regionName );
 				}
 				namedQueryCache.clear();
 			}
 		}
 	}
 
 	@Override
 	public void evictQueryRegions() {
 		evictDefaultQueryRegion();
 
 		if ( CollectionHelper.isEmpty( queryCaches ) ) {
 			return;
 		}
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debug( "Evicting cache of all query regions." );
 		}
 		for ( QueryCache queryCache : queryCaches.values() ) {
 			queryCache.clear();
 		}
 	}
 
 	@Override
 	public void close() {
 		if ( settings.isQueryCacheEnabled() ) {
 			queryCache.destroy();
 
 			for ( QueryCache cache : queryCaches.values() ) {
 				cache.destroy();
 			}
 			updateTimestampsCache.destroy();
 		}
 
 		regionFactory.stop();
 	}
 
 	@Override
 	public QueryCache getQueryCache() {
 		return queryCache;
 	}
 
 	@Override
 	public QueryCache getQueryCache(String regionName) throws HibernateException {
 		if ( regionName == null ) {
 			return getQueryCache();
 		}
 
 		if ( !settings.isQueryCacheEnabled() ) {
 			return null;
 		}
 
 		QueryCache currentQueryCache = queryCaches.get( regionName );
 		if ( currentQueryCache == null ) {
 			synchronized (allCacheRegions) {
 				currentQueryCache = queryCaches.get( regionName );
 				if ( currentQueryCache == null ) {
 					currentQueryCache = settings.getQueryCacheFactory()
 							.getQueryCache(
 									regionName,
 									updateTimestampsCache,
 									settings,
 									sessionFactory.getProperties()
 							);
 					queryCaches.put( regionName, currentQueryCache );
 					allCacheRegions.put( currentQueryCache.getRegion().getName(), currentQueryCache.getRegion() );
 				}
 				else {
 					return currentQueryCache;
 				}
 			}
 		}
 		return currentQueryCache;
 	}
 
 	@Override
 	public void addCacheRegion(String name, Region region) {
 		allCacheRegions.put( name, region );
 	}
 
 	@Override
 	public UpdateTimestampsCache getUpdateTimestampsCache() {
 		return updateTimestampsCache;
 	}
 
 	@Override
 	public void evictQueries() throws HibernateException {
 		if ( settings.isQueryCacheEnabled() ) {
 			queryCache.clear();
 		}
 	}
 
 	@Override
 	public Region getSecondLevelCacheRegion(String regionName) {
 		return allCacheRegions.get( regionName );
 	}
 
 	@Override
 	public Region getNaturalIdCacheRegion(String regionName) {
 		return allCacheRegions.get( regionName );
 	}
 
 	@SuppressWarnings({"unchecked"})
 	@Override
 	public Map<String, Region> getAllSecondLevelCacheRegions() {
 		return new HashMap<String, Region>( allCacheRegions );
 	}
 
 	@Override
 	public RegionFactory getRegionFactory() {
 		return regionFactory;
 	}
 
 	@Override
 	public void evictAllRegions() {
 		evictCollectionRegions();
 		evictDefaultQueryRegion();
 		evictEntityRegions();
 		evictQueryRegions();
 		evictNaturalIdRegions();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/SessionImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/SessionImpl.java
index 82c7987736..415dddb020 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/SessionImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/SessionImpl.java
@@ -1,1172 +1,1171 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2005-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Reader;
 import java.io.Serializable;
 import java.sql.Blob;
 import java.sql.Clob;
 import java.sql.Connection;
 import java.sql.NClob;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import javax.persistence.EntityNotFoundException;
 import javax.transaction.SystemException;
 
 import org.hibernate.CacheMode;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.Criteria;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.Filter;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.IdentifierLoadAccess;
 import org.hibernate.Interceptor;
 import org.hibernate.LobHelper;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.NaturalIdLoadAccess;
 import org.hibernate.ObjectDeletedException;
 import org.hibernate.ObjectNotFoundException;
 import org.hibernate.Query;
 import org.hibernate.QueryException;
 import org.hibernate.ReplicationMode;
 import org.hibernate.SQLQuery;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
-import org.hibernate.Session;
 import org.hibernate.SessionBuilder;
 import org.hibernate.SessionEventListener;
 import org.hibernate.SessionException;
 import org.hibernate.SharedSessionBuilder;
 import org.hibernate.SimpleNaturalIdLoadAccess;
 import org.hibernate.Transaction;
 import org.hibernate.TransactionException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.TypeHelper;
 import org.hibernate.UnknownProfileException;
 import org.hibernate.UnresolvableObjectException;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.criterion.NaturalIdentifier;
 import org.hibernate.engine.internal.SessionEventListenerManagerImpl;
 import org.hibernate.engine.internal.StatefulPersistenceContext;
 import org.hibernate.engine.jdbc.LobCreator;
 import org.hibernate.engine.jdbc.NonContextualLobCreator;
 import org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.engine.query.spi.FilterQueryPlan;
 import org.hibernate.engine.query.spi.HQLQueryPlan;
 import org.hibernate.engine.query.spi.NativeSQLQueryPlan;
 import org.hibernate.engine.query.spi.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.spi.ActionQueue;
 import org.hibernate.engine.spi.CollectionEntry;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionOwner;
 import org.hibernate.engine.spi.Status;
 import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
 import org.hibernate.engine.transaction.spi.TransactionObserver;
 import org.hibernate.event.service.spi.EventListenerGroup;
 import org.hibernate.event.service.spi.EventListenerRegistry;
 import org.hibernate.event.spi.AutoFlushEvent;
 import org.hibernate.event.spi.AutoFlushEventListener;
 import org.hibernate.event.spi.ClearEvent;
 import org.hibernate.event.spi.ClearEventListener;
 import org.hibernate.event.spi.DeleteEvent;
 import org.hibernate.event.spi.DeleteEventListener;
 import org.hibernate.event.spi.DirtyCheckEvent;
 import org.hibernate.event.spi.DirtyCheckEventListener;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.event.spi.EventType;
 import org.hibernate.event.spi.EvictEvent;
 import org.hibernate.event.spi.EvictEventListener;
 import org.hibernate.event.spi.FlushEvent;
 import org.hibernate.event.spi.FlushEventListener;
 import org.hibernate.event.spi.InitializeCollectionEvent;
 import org.hibernate.event.spi.InitializeCollectionEventListener;
 import org.hibernate.event.spi.LoadEvent;
 import org.hibernate.event.spi.LoadEventListener;
 import org.hibernate.event.spi.LoadEventListener.LoadType;
 import org.hibernate.event.spi.LockEvent;
 import org.hibernate.event.spi.LockEventListener;
 import org.hibernate.event.spi.MergeEvent;
 import org.hibernate.event.spi.MergeEventListener;
 import org.hibernate.event.spi.PersistEvent;
 import org.hibernate.event.spi.PersistEventListener;
 import org.hibernate.event.spi.RefreshEvent;
 import org.hibernate.event.spi.RefreshEventListener;
 import org.hibernate.event.spi.ReplicateEvent;
 import org.hibernate.event.spi.ReplicateEventListener;
 import org.hibernate.event.spi.ResolveNaturalIdEvent;
 import org.hibernate.event.spi.ResolveNaturalIdEventListener;
 import org.hibernate.event.spi.SaveOrUpdateEvent;
 import org.hibernate.event.spi.SaveOrUpdateEventListener;
 import org.hibernate.internal.CriteriaImpl.CriterionEntry;
 import org.hibernate.jdbc.ReturningWork;
 import org.hibernate.jdbc.Work;
 import org.hibernate.jdbc.WorkExecutor;
 import org.hibernate.jdbc.WorkExecutorVisitable;
 import org.hibernate.loader.criteria.CriteriaLoader;
 import org.hibernate.loader.custom.CustomLoader;
 import org.hibernate.loader.custom.CustomQuery;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.procedure.ProcedureCall;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.LazyInitializer;
 import org.hibernate.resource.jdbc.spi.JdbcSessionContext;
 import org.hibernate.resource.jdbc.spi.StatementInspector;
 import org.hibernate.resource.transaction.TransactionCoordinator;
 import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorImpl;
 import org.hibernate.resource.transaction.backend.jta.internal.synchronization.AfterCompletionAction;
 import org.hibernate.resource.transaction.backend.jta.internal.synchronization.ExceptionMapper;
 import org.hibernate.resource.transaction.backend.jta.internal.synchronization.ManagedFlushChecker;
 import org.hibernate.resource.transaction.spi.TransactionStatus;
 import org.hibernate.stat.SessionStatistics;
 import org.hibernate.stat.internal.SessionStatisticsImpl;
 
 /**
  * Concrete implementation of a Session.
  * <p/>
  * Exposes two interfaces:<ul>
- * <li>{@link Session} to the application</li>
+ * <li>{@link org.hibernate.Session} to the application</li>
  * <li>{@link org.hibernate.engine.spi.SessionImplementor} to other Hibernate components (SPI)</li>
  * </ul>
  * <p/>
  * This class is not thread-safe.
  *
  * @author Gavin King
  * @author Steve Ebersole
  * @author Brett Meyer
  */
 public final class SessionImpl extends AbstractSessionImpl implements EventSource {
 
 	// todo : need to find a clean way to handle the "event source" role
 	// a separate class responsible for generating/dispatching events just duplicates most of the Session methods...
 	// passing around separate interceptor, factory, actionQueue, and persistentContext is not manageable...
 
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( SessionImpl.class );
 	private static final boolean TRACE_ENABLED = LOG.isTraceEnabled();
 
 	private transient long timestamp;
 
 	private transient SessionOwner sessionOwner;
 
 	private transient ActionQueue actionQueue;
 	private transient StatefulPersistenceContext persistenceContext;
 	private transient TransactionCoordinator transactionCoordinator;
 	private transient JdbcCoordinatorImpl jdbcCoordinator;
 	private transient Interceptor interceptor;
 	private StatementInspector statementInspector;
 	private transient EntityNameResolver entityNameResolver = new CoordinatingEntityNameResolver();
 
 	private transient ConnectionReleaseMode connectionReleaseMode;
 	private transient FlushMode flushMode = FlushMode.AUTO;
 	private transient CacheMode cacheMode = CacheMode.NORMAL;
 
 	private transient boolean autoClear; //for EJB3
 	private transient boolean autoJoinTransactions = true;
 	private transient boolean flushBeforeCompletionEnabled;
 	private transient boolean autoCloseSessionEnabled;
 
 	private transient int dontFlushFromFind;
 
 	private transient LoadQueryInfluencers loadQueryInfluencers;
 
 	private final transient boolean isTransactionCoordinatorShared;
 	private transient TransactionObserver transactionObserver;
 
 	private SessionEventListenerManagerImpl sessionEventsManager = new SessionEventListenerManagerImpl();
 
 	private transient JdbcSessionContext jdbcSessionContext;
 
 	private transient ExceptionMapper exceptionMapper;
 	private transient ManagedFlushChecker managedFlushChecker;
 	private transient AfterCompletionAction afterCompletionAction;
 
 	/**
 	 * Constructor used for openSession(...) processing, as well as construction
 	 * of sessions for getCurrentSession().
 	 *
 	 * @param connection The user-supplied connection to use for this session.
 	 * @param factory The factory from which this session was obtained
 	 * @param transactionCoordinator The transaction coordinator to use, may be null to indicate that a new transaction
 	 * coordinator should get created.
 	 * @param autoJoinTransactions Should the session automatically join JTA transactions?
 	 * @param timestamp The timestamp for this session
 	 * @param interceptor The interceptor to be applied to this session
 	 * @param flushBeforeCompletionEnabled Should we auto flush before completion of transaction
 	 * @param autoCloseSessionEnabled Should we auto close after completion of transaction
 	 * @param connectionReleaseMode The mode by which we should release JDBC connections.
 	 * @param tenantIdentifier The tenant identifier to use.  May be null
 	 */
 	SessionImpl(
 			final Connection connection,
 			final SessionFactoryImpl factory,
 			final SessionOwner sessionOwner,
 			final TransactionCoordinator transactionCoordinator,
 			final JdbcCoordinatorImpl jdbcCoordinator,
 			final Transaction transaction,
 			final ActionQueue.TransactionCompletionProcesses transactionCompletionProcesses,
 			final boolean autoJoinTransactions,
 			final long timestamp,
 			final Interceptor interceptor,
 			final StatementInspector statementInspector,
 			final boolean flushBeforeCompletionEnabled,
 			final boolean autoCloseSessionEnabled,
 			final ConnectionReleaseMode connectionReleaseMode,
 			final String tenantIdentifier) {
 		super( factory, tenantIdentifier );
 		this.timestamp = timestamp;
 		this.sessionOwner = sessionOwner;
 		this.interceptor = interceptor == null ? EmptyInterceptor.INSTANCE : interceptor;
 		this.actionQueue = new ActionQueue( this );
 		this.persistenceContext = new StatefulPersistenceContext( this );
 
 		this.autoCloseSessionEnabled = autoCloseSessionEnabled;
 		this.flushBeforeCompletionEnabled = flushBeforeCompletionEnabled;
 
 		initializeFromSessionOwner( sessionOwner );
 
 		if ( statementInspector == null ) {
 			this.statementInspector = new StatementInspector() {
 				@Override
 				@SuppressWarnings("deprecation")
 				public String inspect(String sql) {
 					return SessionImpl.this.interceptor.onPrepareStatement( sql );
 				}
 			};
 		}
 		else {
 			this.statementInspector = statementInspector;
 		}
 		this.jdbcSessionContext = new JdbcSessionContextImpl( factory, this.statementInspector );
 
 		if ( transactionCoordinator == null ) {
 			this.isTransactionCoordinatorShared = false;
 			this.connectionReleaseMode = connectionReleaseMode;
 			this.autoJoinTransactions = autoJoinTransactions;
 
 			this.jdbcCoordinator = new JdbcCoordinatorImpl( connection, this );
 			this.transactionCoordinator = getTransactionCoordinatorBuilder().buildTransactionCoordinator(
 					this.jdbcCoordinator,
 					this
 			);
 			this.currentHibernateTransaction = getTransaction();
 		}
 		else {
 			if ( connection != null ) {
 				throw new SessionException( "Cannot simultaneously share transaction context and specify connection" );
 			}
 			this.transactionCoordinator = transactionCoordinator;
 			this.jdbcCoordinator = jdbcCoordinator;
 			this.currentHibernateTransaction = transaction;
 			this.isTransactionCoordinatorShared = true;
 			this.autoJoinTransactions = false;
 			if ( transactionCompletionProcesses != null ) {
 				actionQueue.setTransactionCompletionProcesses( transactionCompletionProcesses, true );
 			}
 			if ( autoJoinTransactions ) {
 				LOG.debug(
 						"Session creation specified 'autoJoinTransactions', which is invalid in conjunction " +
 								"with sharing JDBC connection between sessions; ignoring"
 				);
 			}
 			if ( connectionReleaseMode != this.jdbcCoordinator.getConnectionReleaseMode() ) {
 				LOG.debug(
 						"Session creation specified 'getConnectionReleaseMode', which is invalid in conjunction " +
 								"with sharing JDBC connection between sessions; ignoring"
 				);
 			}
 			this.connectionReleaseMode = this.jdbcCoordinator.getConnectionReleaseMode();
 
 			transactionObserver = new TransactionObserver() {
 				@Override
 				public void afterBegin() {
 				}
 
 				@Override
 				public void beforeCompletion() {
 					if ( isOpen() && flushBeforeCompletionEnabled ) {
 						SessionImpl.this.managedFlush();
 					}
 					actionQueue.beforeTransactionCompletion();
 					try {
 						SessionImpl.this.interceptor.beforeTransactionCompletion( currentHibernateTransaction );
 					}
 					catch (Throwable t) {
 						LOG.exceptionInBeforeTransactionCompletionInterceptor( t );
 					}
 				}
 
 				@Override
 				public void afterCompletion(boolean successful, boolean delayed) {
 					afterTransactionCompletion( successful, delayed );
 					if ( !isClosed() && autoCloseSessionEnabled ) {
 						managedClose();
 					}
 				}
 			};
 
 			transactionCoordinator.addObserver( transactionObserver );
 		}
 
 		loadQueryInfluencers = new LoadQueryInfluencers( factory );
 
 		if ( factory.getStatistics().isStatisticsEnabled() ) {
 			factory.getStatisticsImplementor().openSession();
 		}
 
 		if ( TRACE_ENABLED ) {
 			LOG.tracef( "Opened session at timestamp: %s", timestamp );
 		}
 
 	}
 
 	private void initializeFromSessionOwner(SessionOwner sessionOwner) {
 		if ( sessionOwner != null ) {
 			if ( sessionOwner.getExceptionMapper() != null ) {
 				exceptionMapper = sessionOwner.getExceptionMapper();
 			}
 			else {
 				exceptionMapper = STANDARD_EXCEPTION_MAPPER;
 			}
 			if ( sessionOwner.getAfterCompletionAction() != null ) {
 				afterCompletionAction = sessionOwner.getAfterCompletionAction();
 			}
 			else {
 				afterCompletionAction = STANDARD_AFTER_COMPLETION_ACTION;
 			}
 			if ( sessionOwner.getManagedFlushChecker() != null ) {
 				managedFlushChecker = sessionOwner.getManagedFlushChecker();
 			}
 			else {
 				managedFlushChecker = STANDARD_MANAGED_FLUSH_CHECKER;
 			}
 		}
 		else {
 			exceptionMapper = STANDARD_EXCEPTION_MAPPER;
 			afterCompletionAction = STANDARD_AFTER_COMPLETION_ACTION;
 			managedFlushChecker = STANDARD_MANAGED_FLUSH_CHECKER;
 		}
 	}
 
 	@Override
 	public SharedSessionBuilder sessionWithOptions() {
 		return new SharedSessionBuilderImpl( this );
 	}
 
 	@Override
 	public void clear() {
 		errorIfClosed();
 		// Do not call checkTransactionSynchStatus() here -- if a delayed
 		// afterCompletion exists, it can cause an infinite loop.
 		pulseTransactionCoordinator();
 		internalClear();
 	}
 
 	private void internalClear() {
 		persistenceContext.clear();
 		actionQueue.clear();
 
 		final ClearEvent event = new ClearEvent( this );
 		for ( ClearEventListener listener : listeners( EventType.CLEAR ) ) {
 			listener.onClear( event );
 		}
 	}
 
 	@Override
 	public long getTimestamp() {
 		checkTransactionSynchStatus();
 		return timestamp;
 	}
 
 	@Override
 	public void close() throws HibernateException {
 		LOG.trace( "Closing session" );
 		if ( isClosed() ) {
 			throw new SessionException( "Session was already closed" );
 		}
 
 		if ( factory.getStatistics().isStatisticsEnabled() ) {
 			factory.getStatisticsImplementor().closeSession();
 		}
 		getEventListenerManager().end();
 
 		try {
 			if ( !isTransactionCoordinatorShared ) {
 				jdbcCoordinator.close();
 				return;
 			}
 			else {
 				if ( getActionQueue().hasBeforeTransactionActions() || getActionQueue().hasAfterTransactionActions() ) {
 					LOG.warn(
 							"On close, shared Session had before / after transaction actions that have not yet been processed"
 					);
 				}
 				return;
 			}
 		}
 		finally {
 			setClosed();
 			cleanup();
 		}
 	}
 
 	@Override
 	public boolean isAutoCloseSessionEnabled() {
 		return autoCloseSessionEnabled;
 	}
 
 	@Override
 	public boolean shouldAutoJoinTransaction() {
 		return autoJoinTransactions;
 	}
 
 	@Override
 	public boolean isOpen() {
 		checkTransactionSynchStatus();
 		return !isClosed();
 	}
 
 	private boolean isFlushModeNever() {
 		return FlushMode.isManualFlushMode( getFlushMode() );
 	}
 
 	private void managedFlush() {
 		if ( isClosed() ) {
 			LOG.trace( "Skipping auto-flush due to session closed" );
 			return;
 		}
 		LOG.trace( "Automatically flushing session" );
 		flush();
 	}
 
 	@Override
 	public boolean shouldAutoClose() {
 		if ( isClosed() ) {
 			return false;
 		}
 		else if ( sessionOwner != null ) {
 			return sessionOwner.shouldAutoCloseSession();
 		}
 		else {
 			return isAutoCloseSessionEnabled();
 		}
 	}
 
 	private void managedClose() {
 		LOG.trace( "Automatically closing session" );
 		close();
 	}
 
 	@Override
 	public Connection connection() throws HibernateException {
 		errorIfClosed();
 		return this.jdbcCoordinator.getLogicalConnection().getPhysicalConnection();
 	}
 
 	@Override
 	public boolean isConnected() {
 		checkTransactionSynchStatus();
 		return !isClosed() && this.jdbcCoordinator.getLogicalConnection().isOpen();
 	}
 
 	@Override
 	public boolean isTransactionInProgress() {
 		checkTransactionSynchStatus();
 		return !isClosed() && transactionCoordinator.getTransactionDriverControl()
 				.getStatus() == TransactionStatus.ACTIVE && transactionCoordinator.isJoined();
 	}
 
 	@Override
 	public Connection disconnect() throws HibernateException {
 		errorIfClosed();
 		LOG.debug( "Disconnecting session" );
 		return this.jdbcCoordinator.getLogicalConnection().manualDisconnect();
 	}
 
 	@Override
 	public void reconnect(Connection conn) throws HibernateException {
 		errorIfClosed();
 		LOG.debug( "Reconnecting session" );
 		checkTransactionSynchStatus();
 		this.jdbcCoordinator.getLogicalConnection().manualReconnect( conn );
 	}
 
 	@Override
 	public void setAutoClear(boolean enabled) {
 		errorIfClosed();
 		autoClear = enabled;
 	}
 
 	@Override
 	public void disableTransactionAutoJoin() {
 		errorIfClosed();
 		autoJoinTransactions = false;
 	}
 
 	/**
 	 * Check if there is a Hibernate or JTA transaction in progress and,
 	 * if there is not, flush if necessary, make sure the connection has
 	 * been committed (if it is not in autocommit mode) and run the after
 	 * completion processing
 	 *
 	 * @param success Was the operation a success
 	 */
 	public void afterOperation(boolean success) {
 		if ( !isTransactionInProgress() ) {
 			jdbcCoordinator.afterTransaction();
 		}
 	}
 
 	@Override
 	public SessionEventListenerManagerImpl getEventListenerManager() {
 		return sessionEventsManager;
 	}
 
 	@Override
 	public void addEventListeners(SessionEventListener... listeners) {
 		getEventListenerManager().addListener( listeners );
 	}
 
 	/**
 	 * clear all the internal collections, just
 	 * to help the garbage collector, does not
 	 * clear anything that is needed during the
 	 * afterTransactionCompletion() phase
 	 */
 	private void cleanup() {
 		persistenceContext.clear();
 	}
 
 	@Override
 	public LockMode getCurrentLockMode(Object object) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		if ( object == null ) {
 			throw new NullPointerException( "null object passed to getCurrentLockMode()" );
 		}
 		if ( object instanceof HibernateProxy ) {
 			object = ( (HibernateProxy) object ).getHibernateLazyInitializer().getImplementation( this );
 			if ( object == null ) {
 				return LockMode.NONE;
 			}
 		}
 		EntityEntry e = persistenceContext.getEntry( object );
 		if ( e == null ) {
 			throw new TransientObjectException( "Given object not associated with the session" );
 		}
 		if ( e.getStatus() != Status.MANAGED ) {
 			throw new ObjectDeletedException(
 					"The given object was deleted",
 					e.getId(),
 					e.getPersister().getEntityName()
 			);
 		}
 		return e.getLockMode();
 	}
 
 	@Override
 	public Object getEntityUsingInterceptor(EntityKey key) throws HibernateException {
 		errorIfClosed();
 		// todo : should this get moved to PersistentContext?
 		// logically, is PersistentContext the "thing" to which an interceptor gets attached?
 		final Object result = persistenceContext.getEntity( key );
 		if ( result == null ) {
 			final Object newObject = interceptor.getEntity( key.getEntityName(), key.getIdentifier() );
 			if ( newObject != null ) {
 				lock( newObject, LockMode.NONE );
 			}
 			return newObject;
 		}
 		else {
 			return result;
 		}
 	}
 
 	private void checkNoUnresolvedActionsBeforeOperation() {
 		if ( persistenceContext.getCascadeLevel() == 0 && actionQueue.hasUnresolvedEntityInsertActions() ) {
 			throw new IllegalStateException( "There are delayed insert actions before operation as cascade level 0." );
 		}
 	}
 
 	private void checkNoUnresolvedActionsAfterOperation() {
 		if ( persistenceContext.getCascadeLevel() == 0 ) {
 			actionQueue.checkNoUnresolvedActionsAfterOperation();
 		}
 		delayedAfterCompletion();
 	}
 
 	private void delayedAfterCompletion() {
 		if ( transactionCoordinator instanceof JtaTransactionCoordinatorImpl ) {
 			( (JtaTransactionCoordinatorImpl) transactionCoordinator ).getSynchronizationCallbackCoordinator()
 					.processAnyDelayedAfterCompletion();
 		}
 	}
 
 	// saveOrUpdate() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void saveOrUpdate(Object object) throws HibernateException {
 		saveOrUpdate( null, object );
 	}
 
 	@Override
 	public void saveOrUpdate(String entityName, Object obj) throws HibernateException {
 		fireSaveOrUpdate( new SaveOrUpdateEvent( entityName, obj, this ) );
 	}
 
 	private void fireSaveOrUpdate(SaveOrUpdateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( SaveOrUpdateEventListener listener : listeners( EventType.SAVE_UPDATE ) ) {
 			listener.onSaveOrUpdate( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 	}
 
 	private <T> Iterable<T> listeners(EventType<T> type) {
 		return eventListenerGroup( type ).listeners();
 	}
 
 	private <T> EventListenerGroup<T> eventListenerGroup(EventType<T> type) {
 		return factory.getServiceRegistry().getService( EventListenerRegistry.class ).getEventListenerGroup( type );
 	}
 
 
 	// save() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public Serializable save(Object obj) throws HibernateException {
 		return save( null, obj );
 	}
 
 	@Override
 	public Serializable save(String entityName, Object object) throws HibernateException {
 		return fireSave( new SaveOrUpdateEvent( entityName, object, this ) );
 	}
 
 	private Serializable fireSave(SaveOrUpdateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( SaveOrUpdateEventListener listener : listeners( EventType.SAVE ) ) {
 			listener.onSaveOrUpdate( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 		return event.getResultId();
 	}
 
 
 	// update() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void update(Object obj) throws HibernateException {
 		update( null, obj );
 	}
 
 	@Override
 	public void update(String entityName, Object object) throws HibernateException {
 		fireUpdate( new SaveOrUpdateEvent( entityName, object, this ) );
 	}
 
 	private void fireUpdate(SaveOrUpdateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( SaveOrUpdateEventListener listener : listeners( EventType.UPDATE ) ) {
 			listener.onSaveOrUpdate( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 	}
 
 
 	// lock() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void lock(String entityName, Object object, LockMode lockMode) throws HibernateException {
 		fireLock( new LockEvent( entityName, object, lockMode, this ) );
 	}
 
 	@Override
 	public LockRequest buildLockRequest(LockOptions lockOptions) {
 		return new LockRequestImpl( lockOptions );
 	}
 
 	@Override
 	public void lock(Object object, LockMode lockMode) throws HibernateException {
 		fireLock( new LockEvent( object, lockMode, this ) );
 	}
 
 	private void fireLock(String entityName, Object object, LockOptions options) {
 		fireLock( new LockEvent( entityName, object, options, this ) );
 	}
 
 	private void fireLock(Object object, LockOptions options) {
 		fireLock( new LockEvent( object, options, this ) );
 	}
 
 	private void fireLock(LockEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( LockEventListener listener : listeners( EventType.LOCK ) ) {
 			listener.onLock( event );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// persist() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void persist(String entityName, Object object) throws HibernateException {
 		firePersist( new PersistEvent( entityName, object, this ) );
 	}
 
 	@Override
 	public void persist(Object object) throws HibernateException {
 		persist( null, object );
 	}
 
 	@Override
 	public void persist(String entityName, Object object, Map copiedAlready) throws HibernateException {
 		firePersist( copiedAlready, new PersistEvent( entityName, object, this ) );
 	}
 
 	private void firePersist(Map copiedAlready, PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST ) ) {
 			listener.onPersist( event, copiedAlready );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void firePersist(PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST ) ) {
 			listener.onPersist( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 	}
 
 
 	// persistOnFlush() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void persistOnFlush(String entityName, Object object)
 			throws HibernateException {
 		firePersistOnFlush( new PersistEvent( entityName, object, this ) );
 	}
 
 	public void persistOnFlush(Object object) throws HibernateException {
 		persist( null, object );
 	}
 
 	@Override
 	public void persistOnFlush(String entityName, Object object, Map copiedAlready)
 			throws HibernateException {
 		firePersistOnFlush( copiedAlready, new PersistEvent( entityName, object, this ) );
 	}
 
 	private void firePersistOnFlush(Map copiedAlready, PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST_ONFLUSH ) ) {
 			listener.onPersist( event, copiedAlready );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void firePersistOnFlush(PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST_ONFLUSH ) ) {
 			listener.onPersist( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 	}
 
 
 	// merge() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public Object merge(String entityName, Object object) throws HibernateException {
 		return fireMerge( new MergeEvent( entityName, object, this ) );
 	}
 
 	@Override
 	public Object merge(Object object) throws HibernateException {
 		return merge( null, object );
 	}
 
 	@Override
 	public void merge(String entityName, Object object, Map copiedAlready) throws HibernateException {
 		fireMerge( copiedAlready, new MergeEvent( entityName, object, this ) );
 	}
 
 	private Object fireMerge(MergeEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( MergeEventListener listener : listeners( EventType.MERGE ) ) {
 			listener.onMerge( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 		return event.getResult();
 	}
 
 	private void fireMerge(Map copiedAlready, MergeEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( MergeEventListener listener : listeners( EventType.MERGE ) ) {
 			listener.onMerge( event, copiedAlready );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// delete() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void delete(Object object) throws HibernateException {
 		fireDelete( new DeleteEvent( object, this ) );
 	}
 
 	@Override
 	public void delete(String entityName, Object object) throws HibernateException {
 		fireDelete( new DeleteEvent( entityName, object, this ) );
 	}
 
 	@Override
 	public void delete(String entityName, Object object, boolean isCascadeDeleteEnabled, Set transientEntities)
 			throws HibernateException {
 		if ( TRACE_ENABLED && persistenceContext.isRemovingOrphanBeforeUpates() ) {
 			logRemoveOrphanBeforeUpdates( "before continuing", entityName, object );
 		}
 		fireDelete(
 				new DeleteEvent(
 						entityName,
 						object,
 						isCascadeDeleteEnabled,
 						persistenceContext.isRemovingOrphanBeforeUpates(),
 						this
 				),
 				transientEntities
 		);
 		if ( TRACE_ENABLED && persistenceContext.isRemovingOrphanBeforeUpates() ) {
 			logRemoveOrphanBeforeUpdates( "after continuing", entityName, object );
 		}
 	}
 
 	@Override
 	public void removeOrphanBeforeUpdates(String entityName, Object child) {
 		// TODO: The removeOrphan concept is a temporary "hack" for HHH-6484.  This should be removed once action/task
 		// ordering is improved.
 		if ( TRACE_ENABLED ) {
 			logRemoveOrphanBeforeUpdates( "begin", entityName, child );
 		}
 		persistenceContext.beginRemoveOrphanBeforeUpdates();
 		try {
 			fireDelete( new DeleteEvent( entityName, child, false, true, this ) );
 		}
 		finally {
 			persistenceContext.endRemoveOrphanBeforeUpdates();
 			if ( TRACE_ENABLED ) {
 				logRemoveOrphanBeforeUpdates( "end", entityName, child );
 			}
 		}
 	}
 
 	private void logRemoveOrphanBeforeUpdates(String timing, String entityName, Object entity) {
 		final EntityEntry entityEntry = persistenceContext.getEntry( entity );
 		LOG.tracef(
 				"%s remove orphan before updates: [%s]",
 				timing,
 				entityEntry == null ? entityName : MessageHelper.infoString( entityName, entityEntry.getId() )
 		);
 	}
 
 	private void fireDelete(DeleteEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( DeleteEventListener listener : listeners( EventType.DELETE ) ) {
 			listener.onDelete( event );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void fireDelete(DeleteEvent event, Set transientEntities) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( DeleteEventListener listener : listeners( EventType.DELETE ) ) {
 			listener.onDelete( event, transientEntities );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// load()/get() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void load(Object object, Serializable id) throws HibernateException {
 		LoadEvent event = new LoadEvent( id, object, this );
 		fireLoad( event, LoadEventListener.RELOAD );
 	}
 
 	@Override
 	public <T> T load(Class<T> entityClass, Serializable id) throws HibernateException {
 		return this.byId( entityClass ).getReference( id );
 	}
 
 	@Override
 	public Object load(String entityName, Serializable id) throws HibernateException {
 		return this.byId( entityName ).getReference( id );
 	}
 
 	@Override
 	public <T> T get(Class<T> entityClass, Serializable id) throws HibernateException {
 		return this.byId( entityClass ).load( id );
 	}
 
 	@Override
 	public Object get(String entityName, Serializable id) throws HibernateException {
 		return this.byId( entityName ).load( id );
 	}
 
 	/**
 	 * Load the data for the object with the specified id into a newly created object.
 	 * This is only called when lazily initializing a proxy.
 	 * Do NOT return a proxy.
 	 */
 	@Override
 	public Object immediateLoad(String entityName, Serializable id) throws HibernateException {
 		if ( LOG.isDebugEnabled() ) {
 			EntityPersister persister = getFactory().getEntityPersister( entityName );
 			LOG.debugf( "Initializing proxy: %s", MessageHelper.infoString( persister, id, getFactory() ) );
 		}
 
 		LoadEvent event = new LoadEvent( id, entityName, true, this );
 		fireLoad( event, LoadEventListener.IMMEDIATE_LOAD );
 		return event.getResult();
 	}
 
 	@Override
 	public Object internalLoad(String entityName, Serializable id, boolean eager, boolean nullable)
 			throws HibernateException {
 		// todo : remove
 		LoadEventListener.LoadType type = nullable
 				? LoadEventListener.INTERNAL_LOAD_NULLABLE
 				: eager
 				? LoadEventListener.INTERNAL_LOAD_EAGER
 				: LoadEventListener.INTERNAL_LOAD_LAZY;
 		LoadEvent event = new LoadEvent( id, entityName, true, this );
 		fireLoad( event, type );
 		if ( !nullable ) {
 			UnresolvableObjectException.throwIfNull( event.getResult(), id, entityName );
 		}
 		return event.getResult();
 	}
 
 	@Override
 	public <T> T load(Class<T> entityClass, Serializable id, LockMode lockMode) throws HibernateException {
 		return this.byId( entityClass ).with( new LockOptions( lockMode ) ).getReference( id );
 	}
 
 	@Override
 	public <T> T load(Class<T> entityClass, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return this.byId( entityClass ).with( lockOptions ).getReference( id );
 	}
 
 	@Override
 	public Object load(String entityName, Serializable id, LockMode lockMode) throws HibernateException {
 		return this.byId( entityName ).with( new LockOptions( lockMode ) ).getReference( id );
 	}
 
 	@Override
 	public Object load(String entityName, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return this.byId( entityName ).with( lockOptions ).getReference( id );
 	}
 
 	@Override
 	public <T> T get(Class<T> entityClass, Serializable id, LockMode lockMode) throws HibernateException {
 		return this.byId( entityClass ).with( new LockOptions( lockMode ) ).load( id );
 	}
 
 	@Override
 	public <T> T get(Class<T> entityClass, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return this.byId( entityClass ).with( lockOptions ).load( id );
 	}
 
 	@Override
 	public Object get(String entityName, Serializable id, LockMode lockMode) throws HibernateException {
 		return this.byId( entityName ).with( new LockOptions( lockMode ) ).load( id );
 	}
 
 	@Override
 	public Object get(String entityName, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return this.byId( entityName ).with( lockOptions ).load( id );
 	}
 
 	@Override
 	public IdentifierLoadAccessImpl byId(String entityName) {
 		return new IdentifierLoadAccessImpl( entityName );
 	}
 
 	@Override
 	public <T> IdentifierLoadAccessImpl<T> byId(Class<T> entityClass) {
 		return new IdentifierLoadAccessImpl<T>( entityClass );
 	}
 
 	@Override
 	public NaturalIdLoadAccess byNaturalId(String entityName) {
 		return new NaturalIdLoadAccessImpl( entityName );
 	}
 
 	@Override
 	public <T> NaturalIdLoadAccess<T> byNaturalId(Class<T> entityClass) {
 		return new NaturalIdLoadAccessImpl<T>( entityClass );
 	}
 
 	@Override
 	public SimpleNaturalIdLoadAccess bySimpleNaturalId(String entityName) {
 		return new SimpleNaturalIdLoadAccessImpl( entityName );
 	}
 
 	@Override
 	public <T> SimpleNaturalIdLoadAccess<T> bySimpleNaturalId(Class<T> entityClass) {
 		return new SimpleNaturalIdLoadAccessImpl<T>( entityClass );
 	}
 
 	private void fireLoad(LoadEvent event, LoadType loadType) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( LoadEventListener listener : listeners( EventType.LOAD ) ) {
 			listener.onLoad( event, loadType );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void fireResolveNaturalId(ResolveNaturalIdEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( ResolveNaturalIdEventListener listener : listeners( EventType.RESOLVE_NATURAL_ID ) ) {
 			listener.onResolveNaturalId( event );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// refresh() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void refresh(Object object) throws HibernateException {
 		refresh( null, object );
 	}
 
 	@Override
 	public void refresh(String entityName, Object object) throws HibernateException {
 		fireRefresh( new RefreshEvent( entityName, object, this ) );
 	}
 
 	@Override
 	public void refresh(Object object, LockMode lockMode) throws HibernateException {
 		fireRefresh( new RefreshEvent( object, lockMode, this ) );
 	}
 
 	@Override
 	public void refresh(Object object, LockOptions lockOptions) throws HibernateException {
 		refresh( null, object, lockOptions );
 	}
 
 	@Override
 	public void refresh(String entityName, Object object, LockOptions lockOptions) throws HibernateException {
 		fireRefresh( new RefreshEvent( entityName, object, lockOptions, this ) );
 	}
 
 	@Override
 	public void refresh(String entityName, Object object, Map refreshedAlready) throws HibernateException {
 		fireRefresh( refreshedAlready, new RefreshEvent( entityName, object, this ) );
 	}
 
 	private void fireRefresh(RefreshEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( RefreshEventListener listener : listeners( EventType.REFRESH ) ) {
 			listener.onRefresh( event );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void fireRefresh(Map refreshedAlready, RefreshEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( RefreshEventListener listener : listeners( EventType.REFRESH ) ) {
 			listener.onRefresh( event, refreshedAlready );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// replicate() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void replicate(Object obj, ReplicationMode replicationMode) throws HibernateException {
 		fireReplicate( new ReplicateEvent( obj, replicationMode, this ) );
 	}
 
 	@Override
 	public void replicate(String entityName, Object obj, ReplicationMode replicationMode)
 			throws HibernateException {
 		fireReplicate( new ReplicateEvent( entityName, obj, replicationMode, this ) );
 	}
 
 	private void fireReplicate(ReplicateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( ReplicateEventListener listener : listeners( EventType.REPLICATE ) ) {
 			listener.onReplicate( event );
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/BoundedConcurrentHashMap.java b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/BoundedConcurrentHashMap.java
index ebadbb78bd..28a03773a9 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/BoundedConcurrentHashMap.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/BoundedConcurrentHashMap.java
@@ -507,1986 +507,1984 @@ public class BoundedConcurrentHashMap<K, V> extends AbstractMap<K, V>
 		}
 
 		@Override
 		public void clear() {
 			super.clear();
 			accessQueue.clear();
 		}
 
 		@Override
 		public Eviction strategy() {
 			return Eviction.LRU;
 		}
 
 		protected boolean isAboveThreshold() {
 			return size() > trimDownSize;
 		}
 
 		protected boolean removeEldestEntry(Map.Entry<HashEntry<K, V>, V> eldest) {
 			boolean aboveThreshold = isAboveThreshold();
 			if ( aboveThreshold ) {
 				HashEntry<K, V> evictedEntry = eldest.getKey();
 				segment.evictionListener.onEntryChosenForEviction( evictedEntry.value );
 				segment.remove( evictedEntry.key, evictedEntry.hash, null );
 				evicted.add( evictedEntry );
 			}
 			return aboveThreshold;
 		}
 
 		@Override
 		public HashEntry<K, V> createNewEntry(K key, int hash, HashEntry<K, V> next, V value) {
 			return new HashEntry<K, V>( key, hash, next, value );
 		}
 	}
 
 	/**
 	 * Adapted to Infinispan BoundedConcurrentHashMap using LIRS implementation ideas from Charles Fry (fry@google.com)
 	 * See http://code.google.com/p/concurrentlinkedhashmap/source/browse/trunk/src/test/java/com/googlecode/concurrentlinkedhashmap/caches/LirsMap.java
 	 * for original sources
 	 */
 	private static final class LIRSHashEntry<K, V> extends HashEntry<K, V> {
 
 		// LIRS stack S
 		private LIRSHashEntry<K, V> previousInStack;
 		private LIRSHashEntry<K, V> nextInStack;
 
 		// LIRS queue Q
 		private LIRSHashEntry<K, V> previousInQueue;
 		private LIRSHashEntry<K, V> nextInQueue;
 		volatile Recency state;
 
 		LIRS<K, V> owner;
 
 
 		LIRSHashEntry(LIRS<K, V> owner, K key, int hash, HashEntry<K, V> next, V value) {
 			super( key, hash, next, value );
 			this.owner = owner;
 			this.state = Recency.HIR_RESIDENT;
 
 			// initially point everything back to self
 			this.previousInStack = this;
 			this.nextInStack = this;
 			this.previousInQueue = this;
 			this.nextInQueue = this;
 		}
 
 		@Override
 		public int hashCode() {
 			int result = 17;
 			result = result * 31 + hash;
 			result = result * 31 + key.hashCode();
 			return result;
 		}
 
 		@Override
 		public boolean equals(Object o) {
 			// HashEntry is internal class, never leaks out of CHM, hence slight optimization
 			if ( this == o ) {
 				return true;
 			}
 			if ( o == null ) {
 				return false;
 			}
 			HashEntry<?, ?> other = (HashEntry<?, ?>) o;
 			return hash == other.hash && key.equals( other.key );
 		}
 
 		/**
 		 * Returns true if this entry is in the stack, false otherwise.
 		 */
 		public boolean inStack() {
 			return ( nextInStack != null );
 		}
 
 		/**
 		 * Returns true if this entry is in the queue, false otherwise.
 		 */
 		public boolean inQueue() {
 			return ( nextInQueue != null );
 		}
 
 		/**
 		 * Records a cache hit.
 		 */
 		public void hit(Set<HashEntry<K, V>> evicted) {
 			switch ( state ) {
 				case LIR_RESIDENT:
 					hotHit( evicted );
 					break;
 				case HIR_RESIDENT:
 					coldHit( evicted );
 					break;
 				case HIR_NONRESIDENT:
 					throw new IllegalStateException( "Can't hit a non-resident entry!" );
 				default:
 					throw new AssertionError( "Hit with unknown status: " + state );
 			}
 		}
 
 		/**
 		 * Records a cache hit on a hot block.
 		 */
 		private void hotHit(Set<HashEntry<K, V>> evicted) {
 			// See section 3.3 case 1:
 			// "Upon accessing an LIR block X:
 			// This access is guaranteed to be a hit in the cache."
 
 			// "We move it to the top of stack S."
 			boolean onBottom = ( owner.stackBottom() == this );
 			moveToStackTop();
 
 			// "If the LIR block is originally located in the bottom of the stack,
 			// we conduct a stack pruning."
 			if ( onBottom ) {
 				owner.pruneStack( evicted );
 			}
 		}
 
 		/**
 		 * Records a cache hit on a cold block.
 		 */
 		private void coldHit(Set<HashEntry<K, V>> evicted) {
 			// See section 3.3 case 2:
 			// "Upon accessing an HIR resident block X:
 			// This is a hit in the cache."
 
 			// "We move it to the top of stack S."
 			boolean inStack = inStack();
 			moveToStackTop();
 
 			// "There are two cases for block X:"
 			if ( inStack ) {
 				// "(1) If X is in the stack S, we change its status to LIR."
 				hot();
 
 				// "This block is also removed from list Q."
 				removeFromQueue();
 
 				// "The LIR block in the bottom of S is moved to the end of list Q
 				// with its status changed to HIR."
 				owner.stackBottom().migrateToQueue();
 
 				// "A stack pruning is then conducted."
 				owner.pruneStack( evicted );
 			}
 			else {
 				// "(2) If X is not in stack S, we leave its status in HIR and move
 				// it to the end of list Q."
 				moveToQueueEnd();
 			}
 		}
 
 		/**
 		 * Records a cache miss. This is how new entries join the LIRS stack and
 		 * queue. This is called both when a new entry is first created, and when a
 		 * non-resident entry is re-computed.
 		 */
 		private Set<HashEntry<K, V>> miss() {
 			Set<HashEntry<K, V>> evicted = Collections.emptySet();
 			if ( owner.hotSize < owner.maximumHotSize ) {
 				warmupMiss();
 			}
 			else {
 				evicted = new HashSet<HashEntry<K, V>>();
 				fullMiss( evicted );
 			}
 
 			// now the missed item is in the cache
 			owner.size++;
 			return evicted;
 		}
 
 		/**
 		 * Records a miss when the hot entry set is not full.
 		 */
 		private void warmupMiss() {
 			// See section 3.3:
 			// "When LIR block set is not full, all the referenced blocks are
 			// given an LIR status until its size reaches L_lirs."
 			hot();
 			moveToStackTop();
 		}
 
 		/**
 		 * Records a miss when the hot entry set is full.
 		 */
 		private void fullMiss(Set<HashEntry<K, V>> evicted) {
 			// See section 3.3 case 3:
 			// "Upon accessing an HIR non-resident block X:
 			// This is a miss."
 
 			// This condition is unspecified in the paper, but appears to be
 			// necessary.
 			if ( owner.size >= owner.maximumSize ) {
 				// "We remove the HIR resident block at the front of list Q (it then
 				// becomes a non-resident block), and replace it out of the cache."
 				LIRSHashEntry<K, V> evictedNode = owner.queueFront();
 				evicted.add( evictedNode );
 			}
 
 			// "Then we load the requested block X into the freed buffer and place
 			// it on the top of stack S."
 			boolean inStack = inStack();
 			moveToStackTop();
 
 			// "There are two cases for block X:"
 			if ( inStack ) {
 				// "(1) If X is in stack S, we change its status to LIR and move the
 				// LIR block in the bottom of stack S to the end of list Q with its
 				// status changed to HIR. A stack pruning is then conducted.
 				hot();
 				owner.stackBottom().migrateToQueue();
 				owner.pruneStack( evicted );
 			}
 			else {
 				// "(2) If X is not in stack S, we leave its status in HIR and place
 				// it in the end of list Q."
 				cold();
 			}
 		}
 
 		/**
 		 * Marks this entry as hot.
 		 */
 		private void hot() {
 			if ( state != Recency.LIR_RESIDENT ) {
 				owner.hotSize++;
 			}
 			state = Recency.LIR_RESIDENT;
 		}
 
 		/**
 		 * Marks this entry as cold.
 		 */
 		private void cold() {
 			if ( state == Recency.LIR_RESIDENT ) {
 				owner.hotSize--;
 			}
 			state = Recency.HIR_RESIDENT;
 			moveToQueueEnd();
 		}
 
 		/**
 		 * Marks this entry as non-resident.
 		 */
 		@SuppressWarnings("fallthrough")
 		private void nonResident() {
 			switch ( state ) {
 				case LIR_RESIDENT:
 					owner.hotSize--;
 					// fallthrough
 				case HIR_RESIDENT:
 					owner.size--;
 					break;
 			}
 			state = Recency.HIR_NONRESIDENT;
 		}
 
 		/**
 		 * Returns true if this entry is resident in the cache, false otherwise.
 		 */
 		public boolean isResident() {
 			return ( state != Recency.HIR_NONRESIDENT );
 		}
 
 
 		/**
 		 * Temporarily removes this entry from the stack, fixing up neighbor links.
 		 * This entry's links remain unchanged, meaning that {@link #inStack()} will
 		 * continue to return true. This should only be called if this node's links
 		 * will be subsequently changed.
 		 */
 		private void tempRemoveFromStack() {
 			if ( inStack() ) {
 				previousInStack.nextInStack = nextInStack;
 				nextInStack.previousInStack = previousInStack;
 			}
 		}
 
 		/**
 		 * Removes this entry from the stack.
 		 */
 		private void removeFromStack() {
 			tempRemoveFromStack();
 			previousInStack = null;
 			nextInStack = null;
 		}
 
 		/**
 		 * Inserts this entry before the specified existing entry in the stack.
 		 */
 		private void addToStackBefore(LIRSHashEntry<K, V> existingEntry) {
 			previousInStack = existingEntry.previousInStack;
 			nextInStack = existingEntry;
 			previousInStack.nextInStack = this;
 			nextInStack.previousInStack = this;
 		}
 
 		/**
 		 * Moves this entry to the top of the stack.
 		 */
 		private void moveToStackTop() {
 			tempRemoveFromStack();
 			addToStackBefore( owner.header.nextInStack );
 		}
 
 		/**
 		 * Moves this entry to the bottom of the stack.
 		 */
 		private void moveToStackBottom() {
 			tempRemoveFromStack();
 			addToStackBefore( owner.header );
 		}
 
 		/**
 		 * Temporarily removes this entry from the queue, fixing up neighbor links.
 		 * This entry's links remain unchanged. This should only be called if this
 		 * node's links will be subsequently changed.
 		 */
 		private void tempRemoveFromQueue() {
 			if ( inQueue() ) {
 				previousInQueue.nextInQueue = nextInQueue;
 				nextInQueue.previousInQueue = previousInQueue;
 			}
 		}
 
 		/**
 		 * Removes this entry from the queue.
 		 */
 		private void removeFromQueue() {
 			tempRemoveFromQueue();
 			previousInQueue = null;
 			nextInQueue = null;
 		}
 
 		/**
 		 * Inserts this entry before the specified existing entry in the queue.
 		 */
 		private void addToQueueBefore(LIRSHashEntry<K, V> existingEntry) {
 			previousInQueue = existingEntry.previousInQueue;
 			nextInQueue = existingEntry;
 			previousInQueue.nextInQueue = this;
 			nextInQueue.previousInQueue = this;
 		}
 
 		/**
 		 * Moves this entry to the end of the queue.
 		 */
 		private void moveToQueueEnd() {
 			tempRemoveFromQueue();
 			addToQueueBefore( owner.header );
 		}
 
 
 		/**
 		 * Moves this entry from the stack to the queue, marking it cold
 		 * (as hot entries must remain in the stack). This should only be called
 		 * on resident entries, as non-resident entries should not be made resident.
 		 * The bottom entry on the queue is always hot due to stack pruning.
 		 */
 		private void migrateToQueue() {
 			removeFromStack();
 			cold();
 		}
 
 		/**
 		 * Moves this entry from the queue to the stack, marking it hot (as cold
 		 * resident entries must remain in the queue).
 		 */
 		private void migrateToStack() {
 			removeFromQueue();
 			if ( !inStack() ) {
 				moveToStackBottom();
 			}
 			hot();
 		}
 
 		/**
 		 * Evicts this entry, removing it from the queue and setting its status to
 		 * cold non-resident. If the entry is already absent from the stack, it is
 		 * removed from the backing map; otherwise it remains in order for its
 		 * recency to be maintained.
 		 */
 		private void evict() {
 			removeFromQueue();
 			removeFromStack();
 			nonResident();
 			owner = null;
 		}
 
 		/**
 		 * Removes this entry from the cache. This operation is not specified in
 		 * the paper, which does not account for forced eviction.
 		 */
 		private V remove() {
 			boolean wasHot = ( state == Recency.LIR_RESIDENT );
 			V result = value;
 			LIRSHashEntry<K, V> end = owner != null ? owner.queueEnd() : null;
 			evict();
 
 			// attempt to maintain a constant number of hot entries
 			if ( wasHot ) {
 				if ( end != null ) {
 					end.migrateToStack();
 				}
 			}
 
 			return result;
 		}
 	}
 
 
 	static final class LIRS<K, V> implements EvictionPolicy<K, V> {
 
 		/**
 		 * The percentage of the cache which is dedicated to hot blocks.
 		 * See section 5.1
 		 */
 		private static final float L_LIRS = 0.95f;
 
 		/**
 		 * The owning segment
 		 */
 		private final Segment<K, V> segment;
 
 		/**
 		 * The accessQueue for reducing lock contention
 		 * See "BP-Wrapper: a system framework making any replacement algorithms
 		 * (almost) lock contention free"
 		 * <p/>
 		 * http://www.cse.ohio-state.edu/hpcs/WWW/HTML/publications/abs09-1.html
 		 */
 		private final ConcurrentLinkedQueue<LIRSHashEntry<K, V>> accessQueue;
 
 		/**
 		 * The maxBatchQueueSize
 		 * <p/>
 		 * See "BP-Wrapper: a system framework making any replacement algorithms (almost) lock
 		 * contention free"
 		 */
 		private final int maxBatchQueueSize;
 
 		/**
 		 * The number of LIRS entries in a segment
 		 */
 		private int size;
 
 		private final float batchThresholdFactor;
 
 
 		/**
 		 * This header encompasses two data structures:
 		 * <p/>
 		 * <ul>
 		 * <li>The LIRS stack, S, which is maintains recency information. All hot
 		 * entries are on the stack. All cold and non-resident entries which are more
 		 * recent than the least recent hot entry are also stored in the stack (the
 		 * stack is always pruned such that the last entry is hot, and all entries
 		 * accessed more recently than the last hot entry are present in the stack).
 		 * The stack is ordered by recency, with its most recently accessed entry
 		 * at the top, and its least recently accessed entry at the bottom.</li>
 		 * <p/>
 		 * <li>The LIRS queue, Q, which enqueues all cold entries for eviction. Cold
 		 * entries (by definition in the queue) may be absent from the stack (due to
 		 * pruning of the stack). Cold entries are added to the end of the queue
 		 * and entries are evicted from the front of the queue.</li>
 		 * </ul>
 		 */
 		private final LIRSHashEntry<K, V> header = new LIRSHashEntry<K, V>( null, null, 0, null, null );
 
 		/**
 		 * The maximum number of hot entries (L_lirs in the paper).
 		 */
 		private final int maximumHotSize;
 
 		/**
 		 * The maximum number of resident entries (L in the paper).
 		 */
 		private final int maximumSize;
 
 		/**
 		 * The actual number of hot entries.
 		 */
 		private int hotSize;
 
 
 		public LIRS(Segment<K, V> s, int capacity, int maxBatchSize, float batchThresholdFactor) {
 			this.segment = s;
 			this.maximumSize = capacity;
 			this.maximumHotSize = calculateLIRSize( capacity );
 			this.maxBatchQueueSize = maxBatchSize > MAX_BATCH_SIZE ? MAX_BATCH_SIZE : maxBatchSize;
 			this.batchThresholdFactor = batchThresholdFactor;
 			this.accessQueue = new ConcurrentLinkedQueue<LIRSHashEntry<K, V>>();
 		}
 
 		private static int calculateLIRSize(int maximumSize) {
 			int result = (int) ( L_LIRS * maximumSize );
 			return ( result == maximumSize ) ? maximumSize - 1 : result;
 		}
 
 		@Override
 		public Set<HashEntry<K, V>> execute() {
 			Set<HashEntry<K, V>> evicted = new HashSet<HashEntry<K, V>>();
 			try {
 				for ( LIRSHashEntry<K, V> e : accessQueue ) {
 					if ( e.isResident() ) {
 						e.hit( evicted );
 					}
 				}
 				removeFromSegment( evicted );
 			}
 			finally {
 				accessQueue.clear();
 			}
 			return evicted;
 		}
 
 		/**
 		 * Prunes HIR blocks in the bottom of the stack until an HOT block sits in
 		 * the stack bottom. If pruned blocks were resident, then they
 		 * remain in the queue; otherwise they are no longer referenced, and are thus
 		 * removed from the backing map.
 		 */
 		private void pruneStack(Set<HashEntry<K, V>> evicted) {
 			// See section 3.3:
 			// "We define an operation called "stack pruning" on the LIRS
 			// stack S, which removes the HIR blocks in the bottom of
 			// the stack until an LIR block sits in the stack bottom. This
 			// operation serves for two purposes: (1) We ensure the block in
 			// the bottom of the stack always belongs to the LIR block set.
 			// (2) After the LIR block in the bottom is removed, those HIR
 			// blocks contiguously located above it will not have chances to
 			// change their status from HIR to LIR, because their recencies
 			// are larger than the new maximum recency of LIR blocks."
 			LIRSHashEntry<K, V> bottom = stackBottom();
 			while ( bottom != null && bottom.state != Recency.LIR_RESIDENT ) {
 				bottom.removeFromStack();
 				if ( bottom.state == Recency.HIR_NONRESIDENT ) {
 					evicted.add( bottom );
 				}
 				bottom = stackBottom();
 			}
 		}
 
 		@Override
 		public Set<HashEntry<K, V>> onEntryMiss(HashEntry<K, V> en) {
 			LIRSHashEntry<K, V> e = (LIRSHashEntry<K, V>) en;
 			Set<HashEntry<K, V>> evicted = e.miss();
 			removeFromSegment( evicted );
 			return evicted;
 		}
 
 		private void removeFromSegment(Set<HashEntry<K, V>> evicted) {
 			for ( HashEntry<K, V> e : evicted ) {
 				( (LIRSHashEntry<K, V>) e ).evict();
 				segment.evictionListener.onEntryChosenForEviction( e.value );
 				segment.remove( e.key, e.hash, null );
 			}
 		}
 
 		/*
 			   * Invoked without holding a lock on Segment
 			   */
 		@Override
 		public boolean onEntryHit(HashEntry<K, V> e) {
 			accessQueue.add( (LIRSHashEntry<K, V>) e );
 			return accessQueue.size() >= maxBatchQueueSize * batchThresholdFactor;
 		}
 
 		/*
 			   * Invoked without holding a lock on Segment
 			   */
 		@Override
 		public boolean thresholdExpired() {
 			return accessQueue.size() >= maxBatchQueueSize;
 		}
 
 		@Override
 		public void onEntryRemove(HashEntry<K, V> e) {
 
 			( (LIRSHashEntry<K, V>) e ).remove();
 			// we could have multiple instances of e in accessQueue; remove them all
 			while ( accessQueue.remove( e ) ) {
 			}
 		}
 
 		@Override
 		public void clear() {
 			accessQueue.clear();
 		}
 
 		@Override
 		public Eviction strategy() {
 			return Eviction.LIRS;
 		}
 
 		/**
 		 * Returns the entry at the bottom of the stack.
 		 */
 		private LIRSHashEntry<K, V> stackBottom() {
 			LIRSHashEntry<K, V> bottom = header.previousInStack;
 			return ( bottom == header ) ? null : bottom;
 		}
 
 		/**
 		 * Returns the entry at the front of the queue.
 		 */
 		private LIRSHashEntry<K, V> queueFront() {
 			LIRSHashEntry<K, V> front = header.nextInQueue;
 			return ( front == header ) ? null : front;
 		}
 
 		/**
 		 * Returns the entry at the end of the queue.
 		 */
 		private LIRSHashEntry<K, V> queueEnd() {
 			LIRSHashEntry<K, V> end = header.previousInQueue;
 			return ( end == header ) ? null : end;
 		}
 
 
 		@Override
 		public HashEntry<K, V> createNewEntry(K key, int hash, HashEntry<K, V> next, V value) {
 			return new LIRSHashEntry<K, V>( this, key, hash, next, value );
 		}
 	}
 
 	/**
 	 * Segments are specialized versions of hash tables.  This
 	 * subclasses from ReentrantLock opportunistically, just to
 	 * simplify some locking and avoid separate construction.
 	 */
 	static final class Segment<K, V> extends ReentrantLock {
 		/*
 			   * Segments maintain a table of entry lists that are ALWAYS
 			   * kept in a consistent state, so can be read without locking.
 			   * Next fields of nodes are immutable (final).  All list
 			   * additions are performed at the front of each bin. This
 			   * makes it easy to check changes, and also fast to traverse.
 			   * When nodes would otherwise be changed, new nodes are
 			   * created to replace them. This works well for hash tables
 			   * since the bin lists tend to be short. (The average length
 			   * is less than two for the default load factor threshold.)
 			   *
 			   * Read operations can thus proceed without locking, but rely
 			   * on selected uses of volatiles to ensure that completed
 			   * write operations performed by other threads are
 			   * noticed. For most purposes, the "count" field, tracking the
 			   * number of elements, serves as that volatile variable
 			   * ensuring visibility.  This is convenient because this field
 			   * needs to be read in many read operations anyway:
 			   *
 			   *   - All (unsynchronized) read operations must first read the
 			   *     "count" field, and should not look at table entries if
 			   *     it is 0.
 			   *
 			   *   - All (synchronized) write operations should write to
 			   *     the "count" field after structurally changing any bin.
 			   *     The operations must not take any action that could even
 			   *     momentarily cause a concurrent read operation to see
 			   *     inconsistent data. This is made easier by the nature of
 			   *     the read operations in Map. For example, no operation
 			   *     can reveal that the table has grown but the threshold
 			   *     has not yet been updated, so there are no atomicity
 			   *     requirements for this with respect to reads.
 			   *
 			   * As a guide, all critical volatile reads and writes to the
 			   * count field are marked in code comments.
 			   */
 
 		private static final long serialVersionUID = 2249069246763182397L;
 
 		/**
 		 * The number of elements in this segment's region.
 		 */
 		transient volatile int count;
 
 		/**
 		 * Number of updates that alter the size of the table. This is
 		 * used during bulk-read methods to make sure they see a
 		 * consistent snapshot: If modCounts change during a traversal
 		 * of segments computing size or checking containsValue, then
 		 * we might have an inconsistent view of state so (usually)
 		 * must retry.
 		 */
 		transient int modCount;
 
 		/**
 		 * The table is rehashed when its size exceeds this threshold.
 		 * (The value of this field is always <tt>(int)(capacity *
 		 * loadFactor)</tt>.)
 		 */
 		transient int threshold;
 
 		/**
 		 * The per-segment table.
 		 */
 		transient volatile HashEntry<K, V>[] table;
 
 		/**
 		 * The load factor for the hash table.  Even though this value
 		 * is same for all segments, it is replicated to avoid needing
 		 * links to outer object.
 		 *
 		 * @serial
 		 */
 		final float loadFactor;
 
 		final int evictCap;
 
 		transient final EvictionPolicy<K, V> eviction;
 
 		transient final EvictionListener<K, V> evictionListener;
 
 		Segment(int cap, int evictCap, float lf, Eviction es, EvictionListener<K, V> listener) {
 			loadFactor = lf;
 			this.evictCap = evictCap;
 			eviction = es.make( this, evictCap, lf );
 			evictionListener = listener;
 			setTable( HashEntry.<K, V>newArray( cap ) );
 		}
 
 		@SuppressWarnings("unchecked")
 		static <K, V> Segment<K, V>[] newArray(int i) {
 			return new Segment[i];
 		}
 
 		EvictionListener<K, V> getEvictionListener() {
 			return evictionListener;
 		}
 
 		/**
 		 * Sets table to new HashEntry array.
 		 * Call only while holding lock or in constructor.
 		 */
 		void setTable(HashEntry<K, V>[] newTable) {
 			threshold = (int) ( newTable.length * loadFactor );
 			table = newTable;
 		}
 
 		/**
 		 * Returns properly casted first entry of bin for given hash.
 		 */
 		HashEntry<K, V> getFirst(int hash) {
 			HashEntry<K, V>[] tab = table;
 			return tab[hash & tab.length - 1];
 		}
 
 		/**
 		 * Reads value field of an entry under lock. Called if value
 		 * field ever appears to be null. This is possible only if a
 		 * compiler happens to reorder a HashEntry initialization with
 		 * its table assignment, which is legal under memory model
 		 * but is not known to ever occur.
 		 */
 		V readValueUnderLock(HashEntry<K, V> e) {
 			lock();
 			try {
 				return e.value;
 			}
 			finally {
 				unlock();
 			}
 		}
 
 		/* Specialized implementations of map methods */
 
 		V get(Object key, int hash) {
 			int c = count;
 			if ( c != 0 ) { // read-volatile
 				V result = null;
 				HashEntry<K, V> e = getFirst( hash );
 				while ( e != null ) {
 					if ( e.hash == hash && key.equals( e.key ) ) {
 						V v = e.value;
 						if ( v != null ) {
 							result = v;
 							break;
 						}
 						else {
 							result = readValueUnderLock( e ); // recheck
 							break;
 						}
 					}
 					e = e.next;
 				}
 				// a hit
 				if ( result != null ) {
 					if ( eviction.onEntryHit( e ) ) {
 						Set<HashEntry<K, V>> evicted = attemptEviction( false );
 						notifyEvictionListener( evicted );
 					}
 				}
 				return result;
 			}
 			return null;
 		}
 
 		boolean containsKey(Object key, int hash) {
 			if ( count != 0 ) { // read-volatile
 				HashEntry<K, V> e = getFirst( hash );
 				while ( e != null ) {
 					if ( e.hash == hash && key.equals( e.key ) ) {
 						return true;
 					}
 					e = e.next;
 				}
 			}
 			return false;
 		}
 
 		boolean containsValue(Object value) {
 			if ( count != 0 ) { // read-volatile
 				HashEntry<K, V>[] tab = table;
 				int len = tab.length;
 				for ( int i = 0; i < len; i++ ) {
 					for ( HashEntry<K, V> e = tab[i]; e != null; e = e.next ) {
 						V v = e.value;
 						if ( v == null ) {
 							v = readValueUnderLock( e );
 						}
 						if ( value.equals( v ) ) {
 							return true;
 						}
 					}
 				}
 			}
 			return false;
 		}
 
 		boolean replace(K key, int hash, V oldValue, V newValue) {
 			lock();
 			Set<HashEntry<K, V>> evicted = null;
 			try {
 				HashEntry<K, V> e = getFirst( hash );
 				while ( e != null && ( e.hash != hash || !key.equals( e.key ) ) ) {
 					e = e.next;
 				}
 
 				boolean replaced = false;
 				if ( e != null && oldValue.equals( e.value ) ) {
 					replaced = true;
 					e.value = newValue;
 					if ( eviction.onEntryHit( e ) ) {
 						evicted = attemptEviction( true );
 					}
 				}
 				return replaced;
 			}
 			finally {
 				unlock();
 				notifyEvictionListener( evicted );
 			}
 		}
 
 		V replace(K key, int hash, V newValue) {
 			lock();
 			Set<HashEntry<K, V>> evicted = null;
 			try {
 				HashEntry<K, V> e = getFirst( hash );
 				while ( e != null && ( e.hash != hash || !key.equals( e.key ) ) ) {
 					e = e.next;
 				}
 
 				V oldValue = null;
 				if ( e != null ) {
 					oldValue = e.value;
 					e.value = newValue;
 					if ( eviction.onEntryHit( e ) ) {
 						evicted = attemptEviction( true );
 					}
 				}
 				return oldValue;
 			}
 			finally {
 				unlock();
 				notifyEvictionListener( evicted );
 			}
 		}
 
 		V put(K key, int hash, V value, boolean onlyIfAbsent) {
 			lock();
 			Set<HashEntry<K, V>> evicted = null;
 			try {
 				int c = count;
 				if ( c++ > threshold && eviction.strategy() == Eviction.NONE ) {
 					rehash();
 				}
 				HashEntry<K, V>[] tab = table;
 				int index = hash & tab.length - 1;
 				HashEntry<K, V> first = tab[index];
 				HashEntry<K, V> e = first;
 				while ( e != null && ( e.hash != hash || !key.equals( e.key ) ) ) {
 					e = e.next;
 				}
 
 				V oldValue;
 				if ( e != null ) {
 					oldValue = e.value;
 					if ( !onlyIfAbsent ) {
 						e.value = value;
 						eviction.onEntryHit( e );
 					}
 				}
 				else {
 					oldValue = null;
 					++modCount;
 					count = c; // write-volatile
 					if ( eviction.strategy() != Eviction.NONE ) {
 						if ( c > evictCap ) {
 							// remove entries;lower count
 							evicted = eviction.execute();
 							// re-read first
 							first = tab[index];
 						}
 						// add a new entry
 						tab[index] = eviction.createNewEntry( key, hash, first, value );
 						// notify a miss
 						Set<HashEntry<K, V>> newlyEvicted = eviction.onEntryMiss( tab[index] );
 						if ( !newlyEvicted.isEmpty() ) {
 							if ( evicted != null ) {
 								evicted.addAll( newlyEvicted );
 							}
 							else {
 								evicted = newlyEvicted;
 							}
 						}
 					}
 					else {
 						tab[index] = eviction.createNewEntry( key, hash, first, value );
 					}
 				}
 				return oldValue;
 			}
 			finally {
 				unlock();
 				notifyEvictionListener( evicted );
 			}
 		}
 
 		void rehash() {
 			HashEntry<K, V>[] oldTable = table;
 			int oldCapacity = oldTable.length;
 			if ( oldCapacity >= MAXIMUM_CAPACITY ) {
 				return;
 			}
 
 			/*
 					  * Reclassify nodes in each list to new Map.  Because we are
 					  * using power-of-two expansion, the elements from each bin
 					  * must either stay at same index, or move with a power of two
 					  * offset. We eliminate unnecessary node creation by catching
 					  * cases where old nodes can be reused because their next
 					  * fields won't change. Statistically, at the default
 					  * threshold, only about one-sixth of them need cloning when
 					  * a table doubles. The nodes they replace will be garbage
 					  * collectable as soon as they are no longer referenced by any
 					  * reader thread that may be in the midst of traversing table
 					  * right now.
 					  */
 
 			HashEntry<K, V>[] newTable = HashEntry.newArray( oldCapacity << 1 );
 			threshold = (int) ( newTable.length * loadFactor );
 			int sizeMask = newTable.length - 1;
 			for ( int i = 0; i < oldCapacity; i++ ) {
 				// We need to guarantee that any existing reads of old Map can
 				//  proceed. So we cannot yet null out each bin.
 				HashEntry<K, V> e = oldTable[i];
 
 				if ( e != null ) {
 					HashEntry<K, V> next = e.next;
 					int idx = e.hash & sizeMask;
 
 					//  Single node on list
 					if ( next == null ) {
 						newTable[idx] = e;
 					}
 					else {
 						// Reuse trailing consecutive sequence at same slot
 						HashEntry<K, V> lastRun = e;
 						int lastIdx = idx;
-						for ( HashEntry<K, V> last = next;
-							  last != null;
-							  last = last.next ) {
+						for ( HashEntry<K, V> last = next; last != null; last = last.next ) {
 							int k = last.hash & sizeMask;
 							if ( k != lastIdx ) {
 								lastIdx = k;
 								lastRun = last;
 							}
 						}
 						newTable[lastIdx] = lastRun;
 
 						// Clone all remaining nodes
 						for ( HashEntry<K, V> p = e; p != lastRun; p = p.next ) {
 							int k = p.hash & sizeMask;
 							HashEntry<K, V> n = newTable[k];
 							newTable[k] = eviction.createNewEntry( p.key, p.hash, n, p.value );
 						}
 					}
 				}
 			}
 			table = newTable;
 		}
 
 		/**
 		 * Remove; match on key only if value null, else match both.
 		 */
 		V remove(Object key, int hash, Object value) {
 			lock();
 			try {
 				int c = count - 1;
 				HashEntry<K, V>[] tab = table;
 				int index = hash & tab.length - 1;
 				HashEntry<K, V> first = tab[index];
 				HashEntry<K, V> e = first;
 				while ( e != null && ( e.hash != hash || !key.equals( e.key ) ) ) {
 					e = e.next;
 				}
 
 				V oldValue = null;
 				if ( e != null ) {
 					V v = e.value;
 					if ( value == null || value.equals( v ) ) {
 						oldValue = v;
 						// All entries following removed node can stay
 						// in list, but all preceding ones need to be
 						// cloned.
 						++modCount;
 
 						// e was removed
 						eviction.onEntryRemove( e );
 
 						HashEntry<K, V> newFirst = e.next;
 						for ( HashEntry<K, V> p = first; p != e; p = p.next ) {
 							// TODO A remove operation makes the map behave like all the other keys in the bucket were just added???
 							// allow p to be GC-ed
 							eviction.onEntryRemove( p );
 							newFirst = eviction.createNewEntry( p.key, p.hash, newFirst, p.value );
 							// and notify eviction algorithm about new hash entries
 							eviction.onEntryMiss( newFirst );
 						}
 
 						tab[index] = newFirst;
 						count = c; // write-volatile
 					}
 				}
 				return oldValue;
 			}
 			finally {
 				unlock();
 			}
 		}
 
 		void clear() {
 			if ( count != 0 ) {
 				lock();
 				try {
 					HashEntry<K, V>[] tab = table;
 					for ( int i = 0; i < tab.length; i++ ) {
 						tab[i] = null;
 					}
 					++modCount;
 					eviction.clear();
 					count = 0; // write-volatile
 				}
 				finally {
 					unlock();
 				}
 			}
 		}
 
 		private Set<HashEntry<K, V>> attemptEviction(boolean lockedAlready) {
 			Set<HashEntry<K, V>> evicted = null;
 			boolean obtainedLock = lockedAlready || tryLock();
 			if ( !obtainedLock && eviction.thresholdExpired() ) {
 				lock();
 				obtainedLock = true;
 			}
 			if ( obtainedLock ) {
 				try {
 					if ( eviction.thresholdExpired() ) {
 						evicted = eviction.execute();
 					}
 				}
 				finally {
 					if ( !lockedAlready ) {
 						unlock();
 					}
 				}
 			}
 			return evicted;
 		}
 
 		private void notifyEvictionListener(Set<HashEntry<K, V>> evicted) {
 			// piggyback listener invocation on callers thread outside lock
 			if ( evicted != null ) {
 				Map<K, V> evictedCopy;
 				if ( evicted.size() == 1 ) {
 					HashEntry<K, V> evictedEntry = evicted.iterator().next();
 					evictedCopy = singletonMap( evictedEntry.key, evictedEntry.value );
 				}
 				else {
 					evictedCopy = new HashMap<K, V>( evicted.size() );
 					for ( HashEntry<K, V> he : evicted ) {
 						evictedCopy.put( he.key, he.value );
 					}
 					evictedCopy = unmodifiableMap( evictedCopy );
 				}
 				evictionListener.onEntryEviction( evictedCopy );
 			}
 		}
 	}
 
 
 	/* ---------------- Public operations -------------- */
 
 
 	/**
 	 * Creates a new, empty map with the specified maximum capacity, load factor and concurrency
 	 * level.
 	 *
 	 * @param capacity is the upper bound capacity for the number of elements in this map
 	 * @param concurrencyLevel the estimated number of concurrently updating threads. The implementation performs
 	 * internal sizing to try to accommodate this many threads.
 	 * @param evictionStrategy the algorithm used to evict elements from this map
 	 * @param evictionListener the evicton listener callback to be notified about evicted elements
 	 *
 	 * @throws IllegalArgumentException if the initial capacity is negative or the load factor or concurrencyLevel are
 	 * nonpositive.
 	 */
 	public BoundedConcurrentHashMap(
 			int capacity, int concurrencyLevel,
 			Eviction evictionStrategy, EvictionListener<K, V> evictionListener) {
 		if ( capacity < 0 || concurrencyLevel <= 0 ) {
 			throw new IllegalArgumentException();
 		}
 
 		concurrencyLevel = Math.min( capacity / 2, concurrencyLevel ); // concurrencyLevel cannot be > capacity/2
 		concurrencyLevel = Math.max( concurrencyLevel, 1 ); // concurrencyLevel cannot be less than 1
 
 		// minimum two elements per segment
 		if ( capacity < concurrencyLevel * 2 && capacity != 1 ) {
 			throw new IllegalArgumentException( "Maximum capacity has to be at least twice the concurrencyLevel" );
 		}
 
 		if ( evictionStrategy == null || evictionListener == null ) {
 			throw new IllegalArgumentException();
 		}
 
 		if ( concurrencyLevel > MAX_SEGMENTS ) {
 			concurrencyLevel = MAX_SEGMENTS;
 		}
 
 		// Find power-of-two sizes best matching arguments
 		int sshift = 0;
 		int ssize = 1;
 		while ( ssize < concurrencyLevel ) {
 			++sshift;
 			ssize <<= 1;
 		}
 		segmentShift = 32 - sshift;
 		segmentMask = ssize - 1;
 		this.segments = Segment.newArray( ssize );
 
 		if ( capacity > MAXIMUM_CAPACITY ) {
 			capacity = MAXIMUM_CAPACITY;
 		}
 		int c = capacity / ssize;
 		int cap = 1;
 		while ( cap < c ) {
 			cap <<= 1;
 		}
 
 		for ( int i = 0; i < this.segments.length; ++i ) {
 			this.segments[i] = new Segment<K, V>( cap, c, DEFAULT_LOAD_FACTOR, evictionStrategy, evictionListener );
 		}
 	}
 
 	/**
 	 * Creates a new, empty map with the specified maximum capacity, load factor, concurrency
 	 * level and LRU eviction policy.
 	 *
 	 * @param capacity is the upper bound capacity for the number of elements in this map
 	 * @param concurrencyLevel the estimated number of concurrently updating threads. The implementation performs
 	 * internal sizing to try to accommodate this many threads.
 	 *
 	 * @throws IllegalArgumentException if the initial capacity is negative or the load factor or concurrencyLevel are
 	 * nonpositive.
 	 */
 	public BoundedConcurrentHashMap(int capacity, int concurrencyLevel) {
 		this( capacity, concurrencyLevel, Eviction.LRU );
 	}
 
 	/**
 	 * Creates a new, empty map with the specified maximum capacity, load factor, concurrency
 	 * level and eviction strategy.
 	 *
 	 * @param capacity is the upper bound capacity for the number of elements in this map
 	 * @param concurrencyLevel the estimated number of concurrently updating threads. The implementation performs
 	 * internal sizing to try to accommodate this many threads.
 	 * @param evictionStrategy the algorithm used to evict elements from this map
 	 *
 	 * @throws IllegalArgumentException if the initial capacity is negative or the load factor or concurrencyLevel are
 	 * nonpositive.
 	 */
 	public BoundedConcurrentHashMap(int capacity, int concurrencyLevel, Eviction evictionStrategy) {
 		this( capacity, concurrencyLevel, evictionStrategy, new NullEvictionListener<K, V>() );
 	}
 
 	/**
 	 * Creates a new, empty map with the specified maximum capacity, default concurrency
 	 * level and LRU eviction policy.
 	 *
 	 * @param capacity is the upper bound capacity for the number of elements in this map
 	 *
 	 * @throws IllegalArgumentException if the initial capacity of
 	 * elements is negative or the load factor is nonpositive
 	 * @since 1.6
 	 */
 	public BoundedConcurrentHashMap(int capacity) {
 		this( capacity, DEFAULT_CONCURRENCY_LEVEL );
 	}
 
 	/**
 	 * Creates a new, empty map with the default maximum capacity
 	 */
 	public BoundedConcurrentHashMap() {
 		this( DEFAULT_MAXIMUM_CAPACITY, DEFAULT_CONCURRENCY_LEVEL );
 	}
 
 	/**
 	 * Returns <tt>true</tt> if this map contains no key-value mappings.
 	 *
 	 * @return <tt>true</tt> if this map contains no key-value mappings
 	 */
 	@Override
 	public boolean isEmpty() {
 		final Segment<K, V>[] segments = this.segments;
 		/*
 			   * We keep track of per-segment modCounts to avoid ABA
 			   * problems in which an element in one segment was added and
 			   * in another removed during traversal, in which case the
 			   * table was never actually empty at any point. Note the
 			   * similar use of modCounts in the size() and containsValue()
 			   * methods, which are the only other methods also susceptible
 			   * to ABA problems.
 			   */
 		int[] mc = new int[segments.length];
 		int mcsum = 0;
 		for ( int i = 0; i < segments.length; ++i ) {
 			if ( segments[i].count != 0 ) {
 				return false;
 			}
 			else {
 				mcsum += mc[i] = segments[i].modCount;
 			}
 		}
 		// If mcsum happens to be zero, then we know we got a snapshot
 		// before any modifications at all were made.  This is
 		// probably common enough to bother tracking.
 		if ( mcsum != 0 ) {
 			for ( int i = 0; i < segments.length; ++i ) {
 				if ( segments[i].count != 0 || mc[i] != segments[i].modCount ) {
 					return false;
 				}
 			}
 		}
 		return true;
 	}
 
 	/**
 	 * Returns the number of key-value mappings in this map.  If the
 	 * map contains more than <tt>Integer.MAX_VALUE</tt> elements, returns
 	 * <tt>Integer.MAX_VALUE</tt>.
 	 *
 	 * @return the number of key-value mappings in this map
 	 */
 	@Override
 	public int size() {
 		final Segment<K, V>[] segments = this.segments;
 		long sum = 0;
 		long check = 0;
 		int[] mc = new int[segments.length];
 		// Try a few times to get accurate count. On failure due to
 		// continuous async changes in table, resort to locking.
 		for ( int k = 0; k < RETRIES_BEFORE_LOCK; ++k ) {
 			check = 0;
 			sum = 0;
 			int mcsum = 0;
 			for ( int i = 0; i < segments.length; ++i ) {
 				sum += segments[i].count;
 				mcsum += mc[i] = segments[i].modCount;
 			}
 			if ( mcsum != 0 ) {
 				for ( int i = 0; i < segments.length; ++i ) {
 					check += segments[i].count;
 					if ( mc[i] != segments[i].modCount ) {
 						check = -1; // force retry
 						break;
 					}
 				}
 			}
 			if ( check == sum ) {
 				break;
 			}
 		}
 		if ( check != sum ) { // Resort to locking all segments
 			sum = 0;
 			for ( int i = 0; i < segments.length; ++i ) {
 				segments[i].lock();
 			}
 			try {
 				for ( int i = 0; i < segments.length; ++i ) {
 					sum += segments[i].count;
 				}
 			}
 			finally {
 				for ( int i = 0; i < segments.length; ++i ) {
 					segments[i].unlock();
 				}
 			}
 		}
 		if ( sum > Integer.MAX_VALUE ) {
 			return Integer.MAX_VALUE;
 		}
 		else {
 			return (int) sum;
 		}
 	}
 
 	/**
 	 * Returns the value to which the specified key is mapped,
 	 * or {@code null} if this map contains no mapping for the key.
 	 * <p/>
 	 * <p>More formally, if this map contains a mapping from a key
 	 * {@code k} to a value {@code v} such that {@code key.equals(k)},
 	 * then this method returns {@code v}; otherwise it returns
 	 * {@code null}.  (There can be at most one such mapping.)
 	 *
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public V get(Object key) {
 		int hash = hash( key.hashCode() );
 		return segmentFor( hash ).get( key, hash );
 	}
 
 	/**
 	 * Tests if the specified object is a key in this table.
 	 *
 	 * @param key possible key
 	 *
 	 * @return <tt>true</tt> if and only if the specified object
 	 * is a key in this table, as determined by the
 	 * <tt>equals</tt> method; <tt>false</tt> otherwise.
 	 *
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public boolean containsKey(Object key) {
 		int hash = hash( key.hashCode() );
 		return segmentFor( hash ).containsKey( key, hash );
 	}
 
 	/**
 	 * Returns <tt>true</tt> if this map maps one or more keys to the
 	 * specified value. Note: This method requires a full internal
 	 * traversal of the hash table, and so is much slower than
 	 * method <tt>containsKey</tt>.
 	 *
 	 * @param value value whose presence in this map is to be tested
 	 *
 	 * @return <tt>true</tt> if this map maps one or more keys to the
 	 * specified value
 	 *
 	 * @throws NullPointerException if the specified value is null
 	 */
 	@Override
 	public boolean containsValue(Object value) {
 		if ( value == null ) {
 			throw new NullPointerException();
 		}
 
 		// See explanation of modCount use above
 
 		final Segment<K, V>[] segments = this.segments;
 		int[] mc = new int[segments.length];
 
 		// Try a few times without locking
 		for ( int k = 0; k < RETRIES_BEFORE_LOCK; ++k ) {
 			int mcsum = 0;
 			for ( int i = 0; i < segments.length; ++i ) {
 				@SuppressWarnings("unused")
 				int c = segments[i].count; // read-volatile
 				mcsum += mc[i] = segments[i].modCount;
 				if ( segments[i].containsValue( value ) ) {
 					return true;
 				}
 			}
 			boolean cleanSweep = true;
 			if ( mcsum != 0 ) {
 				for ( int i = 0; i < segments.length; ++i ) {
 					@SuppressWarnings("unused")
 					int c = segments[i].count; // read-volatile
 					if ( mc[i] != segments[i].modCount ) {
 						cleanSweep = false;
 						break;
 					}
 				}
 			}
 			if ( cleanSweep ) {
 				return false;
 			}
 		}
 		// Resort to locking all segments
 		for ( int i = 0; i < segments.length; ++i ) {
 			segments[i].lock();
 		}
 		boolean found = false;
 		try {
 			for ( int i = 0; i < segments.length; ++i ) {
 				if ( segments[i].containsValue( value ) ) {
 					found = true;
 					break;
 				}
 			}
 		}
 		finally {
 			for ( int i = 0; i < segments.length; ++i ) {
 				segments[i].unlock();
 			}
 		}
 		return found;
 	}
 
 	/**
 	 * Legacy method testing if some key maps into the specified value
 	 * in this table.  This method is identical in functionality to
 	 * {@link #containsValue}, and exists solely to ensure
 	 * full compatibility with class {@link java.util.Hashtable},
 	 * which supported this method prior to introduction of the
 	 * Java Collections framework.
 	 *
 	 * @param value a value to search for
 	 *
 	 * @return <tt>true</tt> if and only if some key maps to the
 	 * <tt>value</tt> argument in this table as
 	 * determined by the <tt>equals</tt> method;
 	 * <tt>false</tt> otherwise
 	 *
 	 * @throws NullPointerException if the specified value is null
 	 */
 	public boolean contains(Object value) {
 		return containsValue( value );
 	}
 
 	/**
 	 * Maps the specified key to the specified value in this table.
 	 * Neither the key nor the value can be null.
 	 * <p/>
 	 * <p> The value can be retrieved by calling the <tt>get</tt> method
 	 * with a key that is equal to the original key.
 	 *
 	 * @param key key with which the specified value is to be associated
 	 * @param value value to be associated with the specified key
 	 *
 	 * @return the previous value associated with <tt>key</tt>, or
 	 * <tt>null</tt> if there was no mapping for <tt>key</tt>
 	 *
 	 * @throws NullPointerException if the specified key or value is null
 	 */
 	@Override
 	public V put(K key, V value) {
 		if ( value == null ) {
 			throw new NullPointerException();
 		}
 		int hash = hash( key.hashCode() );
 		return segmentFor( hash ).put( key, hash, value, false );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @return the previous value associated with the specified key,
 	 * or <tt>null</tt> if there was no mapping for the key
 	 *
 	 * @throws NullPointerException if the specified key or value is null
 	 */
 	@Override
 	public V putIfAbsent(K key, V value) {
 		if ( value == null ) {
 			throw new NullPointerException();
 		}
 		int hash = hash( key.hashCode() );
 		return segmentFor( hash ).put( key, hash, value, true );
 	}
 
 	/**
 	 * Copies all of the mappings from the specified map to this one.
 	 * These mappings replace any mappings that this map had for any of the
 	 * keys currently in the specified map.
 	 *
 	 * @param m mappings to be stored in this map
 	 */
 	@Override
 	public void putAll(Map<? extends K, ? extends V> m) {
 		for ( Map.Entry<? extends K, ? extends V> e : m.entrySet() ) {
 			put( e.getKey(), e.getValue() );
 		}
 	}
 
 	/**
 	 * Removes the key (and its corresponding value) from this map.
 	 * This method does nothing if the key is not in the map.
 	 *
 	 * @param key the key that needs to be removed
 	 *
 	 * @return the previous value associated with <tt>key</tt>, or
 	 * <tt>null</tt> if there was no mapping for <tt>key</tt>
 	 *
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public V remove(Object key) {
 		int hash = hash( key.hashCode() );
 		return segmentFor( hash ).remove( key, hash, null );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public boolean remove(Object key, Object value) {
 		int hash = hash( key.hashCode() );
 		if ( value == null ) {
 			return false;
 		}
 		return segmentFor( hash ).remove( key, hash, value ) != null;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @throws NullPointerException if any of the arguments are null
 	 */
 	@Override
 	public boolean replace(K key, V oldValue, V newValue) {
 		if ( oldValue == null || newValue == null ) {
 			throw new NullPointerException();
 		}
 		int hash = hash( key.hashCode() );
 		return segmentFor( hash ).replace( key, hash, oldValue, newValue );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @return the previous value associated with the specified key,
 	 * or <tt>null</tt> if there was no mapping for the key
 	 *
 	 * @throws NullPointerException if the specified key or value is null
 	 */
 	@Override
 	public V replace(K key, V value) {
 		if ( value == null ) {
 			throw new NullPointerException();
 		}
 		int hash = hash( key.hashCode() );
 		return segmentFor( hash ).replace( key, hash, value );
 	}
 
 	/**
 	 * Removes all of the mappings from this map.
 	 */
 	@Override
 	public void clear() {
 		for ( int i = 0; i < segments.length; ++i ) {
 			segments[i].clear();
 		}
 	}
 
 	/**
 	 * Returns a {@link Set} view of the keys contained in this map.
 	 * The set is backed by the map, so changes to the map are
 	 * reflected in the set, and vice-versa.  The set supports element
 	 * removal, which removes the corresponding mapping from this map,
 	 * via the <tt>Iterator.remove</tt>, <tt>Set.remove</tt>,
 	 * <tt>removeAll</tt>, <tt>retainAll</tt>, and <tt>clear</tt>
 	 * operations.  It does not support the <tt>add</tt> or
 	 * <tt>addAll</tt> operations.
 	 * <p/>
 	 * <p>The view's <tt>iterator</tt> is a "weakly consistent" iterator
 	 * that will never throw {@link java.util.ConcurrentModificationException},
 	 * and guarantees to traverse elements as they existed upon
 	 * construction of the iterator, and may (but is not guaranteed to)
 	 * reflect any modifications subsequent to construction.
 	 */
 	@Override
 	public Set<K> keySet() {
 		Set<K> ks = keySet;
 		return ks != null ? ks : ( keySet = new KeySet() );
 	}
 
 	/**
 	 * Returns a {@link Collection} view of the values contained in this map.
 	 * The collection is backed by the map, so changes to the map are
 	 * reflected in the collection, and vice-versa.  The collection
 	 * supports element removal, which removes the corresponding
 	 * mapping from this map, via the <tt>Iterator.remove</tt>,
 	 * <tt>Collection.remove</tt>, <tt>removeAll</tt>,
 	 * <tt>retainAll</tt>, and <tt>clear</tt> operations.  It does not
 	 * support the <tt>add</tt> or <tt>addAll</tt> operations.
 	 * <p/>
 	 * <p>The view's <tt>iterator</tt> is a "weakly consistent" iterator
 	 * that will never throw {@link java.util.ConcurrentModificationException},
 	 * and guarantees to traverse elements as they existed upon
 	 * construction of the iterator, and may (but is not guaranteed to)
 	 * reflect any modifications subsequent to construction.
 	 */
 	@Override
 	public Collection<V> values() {
 		Collection<V> vs = values;
 		return vs != null ? vs : ( values = new Values() );
 	}
 
 	/**
 	 * Returns a {@link Set} view of the mappings contained in this map.
 	 * The set is backed by the map, so changes to the map are
 	 * reflected in the set, and vice-versa.  The set supports element
 	 * removal, which removes the corresponding mapping from the map,
 	 * via the <tt>Iterator.remove</tt>, <tt>Set.remove</tt>,
 	 * <tt>removeAll</tt>, <tt>retainAll</tt>, and <tt>clear</tt>
 	 * operations.  It does not support the <tt>add</tt> or
 	 * <tt>addAll</tt> operations.
 	 * <p/>
 	 * <p>The view's <tt>iterator</tt> is a "weakly consistent" iterator
 	 * that will never throw {@link java.util.ConcurrentModificationException},
 	 * and guarantees to traverse elements as they existed upon
 	 * construction of the iterator, and may (but is not guaranteed to)
 	 * reflect any modifications subsequent to construction.
 	 */
 	@Override
 	public Set<Map.Entry<K, V>> entrySet() {
 		Set<Map.Entry<K, V>> es = entrySet;
 		return es != null ? es : ( entrySet = new EntrySet() );
 	}
 
 	/**
 	 * Returns an enumeration of the keys in this table.
 	 *
 	 * @return an enumeration of the keys in this table
 	 *
 	 * @see #keySet()
 	 */
 	public Enumeration<K> keys() {
 		return new KeyIterator();
 	}
 
 	/**
 	 * Returns an enumeration of the values in this table.
 	 *
 	 * @return an enumeration of the values in this table
 	 *
 	 * @see #values()
 	 */
 	public Enumeration<V> elements() {
 		return new ValueIterator();
 	}
 
 	/* ---------------- Iterator Support -------------- */
 
 	abstract class HashIterator {
 		int nextSegmentIndex;
 
 		int nextTableIndex;
 
 		HashEntry<K, V>[] currentTable;
 
 		HashEntry<K, V> nextEntry;
 
 		HashEntry<K, V> lastReturned;
 
 		HashIterator() {
 			nextSegmentIndex = segments.length - 1;
 			nextTableIndex = -1;
 			advance();
 		}
 
 		public boolean hasMoreElements() {
 			return hasNext();
 		}
 
 		final void advance() {
 			if ( nextEntry != null && ( nextEntry = nextEntry.next ) != null ) {
 				return;
 			}
 
 			while ( nextTableIndex >= 0 ) {
 				if ( ( nextEntry = currentTable[nextTableIndex--] ) != null ) {
 					return;
 				}
 			}
 
 			while ( nextSegmentIndex >= 0 ) {
 				Segment<K, V> seg = segments[nextSegmentIndex--];
 				if ( seg.count != 0 ) {
 					currentTable = seg.table;
 					for ( int j = currentTable.length - 1; j >= 0; --j ) {
 						if ( ( nextEntry = currentTable[j] ) != null ) {
 							nextTableIndex = j - 1;
 							return;
 						}
 					}
 				}
 			}
 		}
 
 		public boolean hasNext() {
 			return nextEntry != null;
 		}
 
 		HashEntry<K, V> nextEntry() {
 			if ( nextEntry == null ) {
 				throw new NoSuchElementException();
 			}
 			lastReturned = nextEntry;
 			advance();
 			return lastReturned;
 		}
 
 		public void remove() {
 			if ( lastReturned == null ) {
 				throw new IllegalStateException();
 			}
 			BoundedConcurrentHashMap.this.remove( lastReturned.key );
 			lastReturned = null;
 		}
 	}
 
 	final class KeyIterator extends HashIterator implements Iterator<K>, Enumeration<K> {
 		@Override
 		public K next() {
 			return super.nextEntry().key;
 		}
 
 		@Override
 		public K nextElement() {
 			return super.nextEntry().key;
 		}
 	}
 
 	final class ValueIterator extends HashIterator implements Iterator<V>, Enumeration<V> {
 		@Override
 		public V next() {
 			return super.nextEntry().value;
 		}
 
 		@Override
 		public V nextElement() {
 			return super.nextEntry().value;
 		}
 	}
 
 	/**
 	 * Custom Entry class used by EntryIterator.next(), that relays
 	 * setValue changes to the underlying map.
 	 */
 	final class WriteThroughEntry extends AbstractMap.SimpleEntry<K, V> {
 
 		private static final long serialVersionUID = -7041346694785573824L;
 
 		WriteThroughEntry(K k, V v) {
 			super( k, v );
 		}
 
 		/**
 		 * Set our entry's value and write through to the map. The
 		 * value to return is somewhat arbitrary here. Since a
 		 * WriteThroughEntry does not necessarily track asynchronous
 		 * changes, the most recent "previous" value could be
 		 * different from what we return (or could even have been
 		 * removed in which case the put will re-establish). We do not
 		 * and cannot guarantee more.
 		 */
 		@Override
 		public V setValue(V value) {
 			if ( value == null ) {
 				throw new NullPointerException();
 			}
 			V v = super.setValue( value );
 			BoundedConcurrentHashMap.this.put( getKey(), value );
 			return v;
 		}
 	}
 
 	final class EntryIterator extends HashIterator implements Iterator<Entry<K, V>> {
 		@Override
 		public Map.Entry<K, V> next() {
 			HashEntry<K, V> e = super.nextEntry();
 			return new WriteThroughEntry( e.key, e.value );
 		}
 	}
 
 	final class KeySet extends AbstractSet<K> {
 		@Override
 		public Iterator<K> iterator() {
 			return new KeyIterator();
 		}
 
 		@Override
 		public int size() {
 			return BoundedConcurrentHashMap.this.size();
 		}
 
 		@Override
 		public boolean isEmpty() {
 			return BoundedConcurrentHashMap.this.isEmpty();
 		}
 
 		@Override
 		public boolean contains(Object o) {
 			return BoundedConcurrentHashMap.this.containsKey( o );
 		}
 
 		@Override
 		public boolean remove(Object o) {
 			return BoundedConcurrentHashMap.this.remove( o ) != null;
 		}
 
 		@Override
 		public void clear() {
 			BoundedConcurrentHashMap.this.clear();
 		}
 	}
 
 	final class Values extends AbstractCollection<V> {
 		@Override
 		public Iterator<V> iterator() {
 			return new ValueIterator();
 		}
 
 		@Override
 		public int size() {
 			return BoundedConcurrentHashMap.this.size();
 		}
 
 		@Override
 		public boolean isEmpty() {
 			return BoundedConcurrentHashMap.this.isEmpty();
 		}
 
 		@Override
 		public boolean contains(Object o) {
 			return BoundedConcurrentHashMap.this.containsValue( o );
 		}
 
 		@Override
 		public void clear() {
 			BoundedConcurrentHashMap.this.clear();
 		}
 	}
 
 	final class EntrySet extends AbstractSet<Map.Entry<K, V>> {
 		@Override
 		public Iterator<Map.Entry<K, V>> iterator() {
 			return new EntryIterator();
 		}
 
 		@Override
 		public boolean contains(Object o) {
 			if ( !( o instanceof Map.Entry ) ) {
 				return false;
 			}
 			Map.Entry<?, ?> e = (Map.Entry<?, ?>) o;
 			V v = BoundedConcurrentHashMap.this.get( e.getKey() );
 			return v != null && v.equals( e.getValue() );
 		}
 
 		@Override
 		public boolean remove(Object o) {
 			if ( !( o instanceof Map.Entry ) ) {
 				return false;
 			}
 			Map.Entry<?, ?> e = (Map.Entry<?, ?>) o;
 			return BoundedConcurrentHashMap.this.remove( e.getKey(), e.getValue() );
 		}
 
 		@Override
 		public int size() {
 			return BoundedConcurrentHashMap.this.size();
 		}
 
 		@Override
 		public boolean isEmpty() {
 			return BoundedConcurrentHashMap.this.isEmpty();
 		}
 
 		@Override
 		public void clear() {
 			BoundedConcurrentHashMap.this.clear();
 		}
 	}
 
 	/* ---------------- Serialization Support -------------- */
 
 	/**
 	 * Save the state of the <tt>ConcurrentHashMap</tt> instance to a
 	 * stream (i.e., serialize it).
 	 *
 	 * @param s the stream
 	 *
 	 * @serialData the key (Object) and value (Object)
 	 * for each key-value mapping, followed by a null pair.
 	 * The key-value mappings are emitted in no particular order.
 	 */
 	private void writeObject(java.io.ObjectOutputStream s) throws IOException {
 		s.defaultWriteObject();
 
 		for ( int k = 0; k < segments.length; ++k ) {
 			Segment<K, V> seg = segments[k];
 			seg.lock();
 			try {
 				HashEntry<K, V>[] tab = seg.table;
 				for ( int i = 0; i < tab.length; ++i ) {
 					for ( HashEntry<K, V> e = tab[i]; e != null; e = e.next ) {
 						s.writeObject( e.key );
 						s.writeObject( e.value );
 					}
 				}
 			}
 			finally {
 				seg.unlock();
 			}
 		}
 		s.writeObject( null );
 		s.writeObject( null );
 	}
 
 	/**
 	 * Reconstitute the <tt>ConcurrentHashMap</tt> instance from a
 	 * stream (i.e., deserialize it).
 	 *
 	 * @param s the stream
 	 */
 	@SuppressWarnings("unchecked")
 	private void readObject(java.io.ObjectInputStream s) throws IOException,
 			ClassNotFoundException {
 		s.defaultReadObject();
 
 		// Initialize each segment to be minimally sized, and let grow.
 		for ( int i = 0; i < segments.length; ++i ) {
 			segments[i].setTable( new HashEntry[1] );
 		}
 
 		// Read the keys and values, and put the mappings in the table
 		for (; ; ) {
 			K key = (K) s.readObject();
 			V value = (V) s.readObject();
 			if ( key == null ) {
 				break;
 			}
 			put( key, value );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/ConcurrentReferenceHashMap.java b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/ConcurrentReferenceHashMap.java
index a216939605..5823d7ca8f 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/ConcurrentReferenceHashMap.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/ConcurrentReferenceHashMap.java
@@ -1,1946 +1,1942 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 
 /*
  * Written by Doug Lea with assistance from members of JCP JSR-166
  * Expert Group and released to the public domain, as explained at
  * http://creativecommons.org/licenses/publicdomain
  */
 
 package org.hibernate.internal.util.collections;
 
 import java.io.IOException;
 import java.io.Serializable;
 import java.lang.ref.Reference;
 import java.lang.ref.ReferenceQueue;
 import java.lang.ref.SoftReference;
 import java.lang.ref.WeakReference;
 import java.util.AbstractCollection;
 import java.util.AbstractMap;
 import java.util.AbstractSet;
 import java.util.Collection;
 import java.util.EnumSet;
 import java.util.Enumeration;
-import java.util.IdentityHashMap;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.NoSuchElementException;
 import java.util.Set;
 import java.util.concurrent.locks.ReentrantLock;
 
 /**
  * An advanced hash table supporting configurable garbage collection semantics
  * of keys and values, optional referential-equality, full concurrency of
  * retrievals, and adjustable expected concurrency for updates.
  * <p/>
  * This table is designed around specific advanced use-cases. If there is any
  * doubt whether this table is for you, you most likely should be using
  * {@link java.util.concurrent.ConcurrentHashMap} instead.
  * <p/>
  * This table supports strong, weak, and soft keys and values. By default keys
  * are weak, and values are strong. Such a configuration offers similar behavior
  * to {@link java.util.WeakHashMap}, entries of this table are periodically
  * removed once their corresponding keys are no longer referenced outside of
  * this table. In other words, this table will not prevent a key from being
  * discarded by the garbage collector. Once a key has been discarded by the
  * collector, the corresponding entry is no longer visible to this table;
  * however, the entry may occupy space until a future table operation decides to
  * reclaim it. For this reason, summary functions such as <tt>size</tt> and
  * <tt>isEmpty</tt> might return a value greater than the observed number of
  * entries. In order to support a high level of concurrency, stale entries are
  * only reclaimed during blocking (usually mutating) operations.
  * <p/>
  * Enabling soft keys allows entries in this table to remain until their space
  * is absolutely needed by the garbage collector. This is unlike weak keys which
  * can be reclaimed as soon as they are no longer referenced by a normal strong
  * reference. The primary use case for soft keys is a cache, which ideally
  * occupies memory that is not in use for as long as possible.
  * <p/>
  * By default, values are held using a normal strong reference. This provides
  * the commonly desired guarantee that a value will always have at least the
  * same life-span as it's key. For this reason, care should be taken to ensure
  * that a value never refers, either directly or indirectly, to its key, thereby
  * preventing reclamation. If this is unavoidable, then it is recommended to use
  * the same reference type in use for the key. However, it should be noted that
  * non-strong values may disappear before their corresponding key.
  * <p/>
  * While this table does allow the use of both strong keys and values, it is
  * recommended to use {@link java.util.concurrent.ConcurrentHashMap} for such a
  * configuration, since it is optimized for that case.
  * <p/>
  * Just like {@link java.util.concurrent.ConcurrentHashMap}, this class obeys
  * the same functional specification as {@link java.util.Hashtable}, and
  * includes versions of methods corresponding to each method of
  * <tt>Hashtable</tt>. However, even though all operations are thread-safe,
  * retrieval operations do <em>not</em> entail locking, and there is
  * <em>not</em> any support for locking the entire table in a way that
  * prevents all access. This class is fully interoperable with
  * <tt>Hashtable</tt> in programs that rely on its thread safety but not on
  * its synchronization details.
  * <p/>
  * <p/>
  * Retrieval operations (including <tt>get</tt>) generally do not block, so
  * may overlap with update operations (including <tt>put</tt> and
  * <tt>remove</tt>). Retrievals reflect the results of the most recently
  * <em>completed</em> update operations holding upon their onset. For
  * aggregate operations such as <tt>putAll</tt> and <tt>clear</tt>,
  * concurrent retrievals may reflect insertion or removal of only some entries.
  * Similarly, Iterators and Enumerations return elements reflecting the state of
  * the hash table at some point at or since the creation of the
  * iterator/enumeration. They do <em>not</em> throw
  * {@link java.util.ConcurrentModificationException}. However, iterators are designed to
  * be used by only one thread at a time.
  * <p/>
  * <p/>
  * The allowed concurrency among update operations is guided by the optional
  * <tt>concurrencyLevel</tt> constructor argument (default <tt>16</tt>),
  * which is used as a hint for internal sizing. The table is internally
  * partitioned to try to permit the indicated number of concurrent updates
  * without contention. Because placement in hash tables is essentially random,
  * the actual concurrency will vary. Ideally, you should choose a value to
  * accommodate as many threads as will ever concurrently modify the table. Using
  * a significantly higher value than you need can waste space and time, and a
  * significantly lower value can lead to thread contention. But overestimates
  * and underestimates within an order of magnitude do not usually have much
  * noticeable impact. A value of one is appropriate when it is known that only
  * one thread will modify and all others will only read. Also, resizing this or
  * any other kind of hash table is a relatively slow operation, so, when
  * possible, it is a good idea to provide estimates of expected table sizes in
  * constructors.
  * <p/>
  * <p/>
  * This class and its views and iterators implement all of the <em>optional</em>
  * methods of the {@link Map} and {@link Iterator} interfaces.
  * <p/>
  * <p/>
  * Like {@link java.util.Hashtable} but unlike {@link java.util.HashMap}, this class does
  * <em>not</em> allow <tt>null</tt> to be used as a key or value.
  * <p/>
  * <p/>
  * This class is a member of the <a href="{@docRoot}/../technotes/guides/collections/index.html">
  * Java Collections Framework</a>.
  *
  * @param <K> the type of keys maintained by this map
  * @param <V> the type of mapped values
  *
  * @author Doug Lea
  * @author Jason T. Greene
  */
 public class ConcurrentReferenceHashMap<K, V> extends AbstractMap<K, V>
 		implements java.util.concurrent.ConcurrentMap<K, V>, Serializable {
 	private static final long serialVersionUID = 7249069246763182397L;
 
 	/*
 		 * The basic strategy is to subdivide the table among Segments,
 		 * each of which itself is a concurrently readable hash table.
 		 */
 
 	/**
 	 * An option specifying which Java reference type should be used to refer
 	 * to a key and/or value.
 	 */
 	public static enum ReferenceType {
 		/**
 		 * Indicates a normal Java strong reference should be used
 		 */
 		STRONG,
 		/**
 		 * Indicates a {@link WeakReference} should be used
 		 */
 		WEAK,
 		/**
 		 * Indicates a {@link SoftReference} should be used
 		 */
 		SOFT
 	}
 
 	;
 
 
 	public static enum Option {
 		/**
 		 * Indicates that referential-equality (== instead of .equals()) should
-		 * be used when locating keys. This offers similar behavior to {@link IdentityHashMap}
+		 * be used when locating keys. This offers similar behavior to {@link java.util.IdentityHashMap}
 		 */
 		IDENTITY_COMPARISONS
 	}
 
 	;
 
 	/* ---------------- Constants -------------- */
 
 	static final ReferenceType DEFAULT_KEY_TYPE = ReferenceType.WEAK;
 
 	static final ReferenceType DEFAULT_VALUE_TYPE = ReferenceType.STRONG;
 
 
 	/**
 	 * The default initial capacity for this table,
 	 * used when not otherwise specified in a constructor.
 	 */
 	static final int DEFAULT_INITIAL_CAPACITY = 16;
 
 	/**
 	 * The default load factor for this table, used when not
 	 * otherwise specified in a constructor.
 	 */
 	static final float DEFAULT_LOAD_FACTOR = 0.75f;
 
 	/**
 	 * The default concurrency level for this table, used when not
 	 * otherwise specified in a constructor.
 	 */
 	static final int DEFAULT_CONCURRENCY_LEVEL = 16;
 
 	/**
 	 * The maximum capacity, used if a higher value is implicitly
 	 * specified by either of the constructors with arguments.  MUST
 	 * be a power of two <= 1<<30 to ensure that entries are indexable
 	 * using ints.
 	 */
 	static final int MAXIMUM_CAPACITY = 1 << 30;
 
 	/**
 	 * The maximum number of segments to allow; used to bound
 	 * constructor arguments.
 	 */
 	static final int MAX_SEGMENTS = 1 << 16; // slightly conservative
 
 	/**
 	 * Number of unsynchronized retries in size and containsValue
 	 * methods before resorting to locking. This is used to avoid
 	 * unbounded retries if tables undergo continuous modification
 	 * which would make it impossible to obtain an accurate result.
 	 */
 	static final int RETRIES_BEFORE_LOCK = 2;
 
 	/* ---------------- Fields -------------- */
 
 	/**
 	 * Mask value for indexing into segments. The upper bits of a
 	 * key's hash code are used to choose the segment.
 	 */
 	final int segmentMask;
 
 	/**
 	 * Shift value for indexing within segments.
 	 */
 	final int segmentShift;
 
 	/**
 	 * The segments, each of which is a specialized hash table
 	 */
 	final Segment<K, V>[] segments;
 
 	boolean identityComparisons;
 
 	transient Set<K> keySet;
 	transient Set<Map.Entry<K, V>> entrySet;
 	transient Collection<V> values;
 
 	/* ---------------- Small Utilities -------------- */
 
 	/**
 	 * Applies a supplemental hash function to a given hashCode, which
 	 * defends against poor quality hash functions.  This is critical
 	 * because ConcurrentReferenceHashMap uses power-of-two length hash tables,
 	 * that otherwise encounter collisions for hashCodes that do not
 	 * differ in lower or upper bits.
 	 */
 	private static int hash(int h) {
 		// Spread bits to regularize both segment and index locations,
 		// using variant of single-word Wang/Jenkins hash.
 		h += ( h << 15 ) ^ 0xffffcd7d;
 		h ^= ( h >>> 10 );
 		h += ( h << 3 );
 		h ^= ( h >>> 6 );
 		h += ( h << 2 ) + ( h << 14 );
 		return h ^ ( h >>> 16 );
 	}
 
 	/**
 	 * Returns the segment that should be used for key with given hash
 	 *
 	 * @param hash the hash code for the key
 	 *
 	 * @return the segment
 	 */
 	final Segment<K, V> segmentFor(int hash) {
 		return segments[( hash >>> segmentShift ) & segmentMask];
 	}
 
 	private int hashOf(Object key) {
 		return hash(
 				identityComparisons ?
 						System.identityHashCode( key ) : key.hashCode()
 		);
 	}
 
 	/* ---------------- Inner Classes -------------- */
 
 	static interface KeyReference {
 		int keyHash();
 
 		Object keyRef();
 	}
 
 	/**
 	 * A weak-key reference which stores the key hash needed for reclamation.
 	 */
 	static final class WeakKeyReference<K> extends WeakReference<K> implements KeyReference {
 		final int hash;
 
 		WeakKeyReference(K key, int hash, ReferenceQueue<Object> refQueue) {
 			super( key, refQueue );
 			this.hash = hash;
 		}
 
 		@Override
 		public final int keyHash() {
 			return hash;
 		}
 
 		@Override
 		public final Object keyRef() {
 			return this;
 		}
 	}
 
 	/**
 	 * A soft-key reference which stores the key hash needed for reclamation.
 	 */
 	static final class SoftKeyReference<K> extends SoftReference<K> implements KeyReference {
 		final int hash;
 
 		SoftKeyReference(K key, int hash, ReferenceQueue<Object> refQueue) {
 			super( key, refQueue );
 			this.hash = hash;
 		}
 
 		@Override
 		public final int keyHash() {
 			return hash;
 		}
 
 		@Override
 		public final Object keyRef() {
 			return this;
 		}
 	}
 
 	static final class WeakValueReference<V> extends WeakReference<V> implements KeyReference {
 		final Object keyRef;
 		final int hash;
 
 		WeakValueReference(V value, Object keyRef, int hash, ReferenceQueue<Object> refQueue) {
 			super( value, refQueue );
 			this.keyRef = keyRef;
 			this.hash = hash;
 		}
 
 		@Override
 		public final int keyHash() {
 			return hash;
 		}
 
 		@Override
 		public final Object keyRef() {
 			return keyRef;
 		}
 	}
 
 	static final class SoftValueReference<V> extends SoftReference<V> implements KeyReference {
 		final Object keyRef;
 		final int hash;
 
 		SoftValueReference(V value, Object keyRef, int hash, ReferenceQueue<Object> refQueue) {
 			super( value, refQueue );
 			this.keyRef = keyRef;
 			this.hash = hash;
 		}
 
 		@Override
 		public final int keyHash() {
 			return hash;
 		}
 
 		@Override
 		public final Object keyRef() {
 			return keyRef;
 		}
 	}
 
 	/**
 	 * ConcurrentReferenceHashMap list entry. Note that this is never exported
 	 * out as a user-visible Map.Entry.
 	 * <p/>
 	 * Because the value field is volatile, not final, it is legal wrt
 	 * the Java Memory Model for an unsynchronized reader to see null
 	 * instead of initial value when read via a data race.  Although a
 	 * reordering leading to this is not likely to ever actually
 	 * occur, the Segment.readValueUnderLock method is used as a
 	 * backup in case a null (pre-initialized) value is ever seen in
 	 * an unsynchronized access method.
 	 */
 	static final class HashEntry<K, V> {
 		final Object keyRef;
 		final int hash;
 		volatile Object valueRef;
 		final HashEntry<K, V> next;
 
 		HashEntry(
 				K key, int hash, HashEntry<K, V> next, V value,
 				ReferenceType keyType, ReferenceType valueType,
 				ReferenceQueue<Object> refQueue) {
 			this.hash = hash;
 			this.next = next;
 			this.keyRef = newKeyReference( key, keyType, refQueue );
 			this.valueRef = newValueReference( value, valueType, refQueue );
 		}
 
 		final Object newKeyReference(
 				K key, ReferenceType keyType,
 				ReferenceQueue<Object> refQueue) {
 			if ( keyType == ReferenceType.WEAK ) {
 				return new WeakKeyReference<K>( key, hash, refQueue );
 			}
 			if ( keyType == ReferenceType.SOFT ) {
 				return new SoftKeyReference<K>( key, hash, refQueue );
 			}
 
 			return key;
 		}
 
 		final Object newValueReference(
 				V value, ReferenceType valueType,
 				ReferenceQueue<Object> refQueue) {
 			if ( valueType == ReferenceType.WEAK ) {
 				return new WeakValueReference<V>( value, keyRef, hash, refQueue );
 			}
 			if ( valueType == ReferenceType.SOFT ) {
 				return new SoftValueReference<V>( value, keyRef, hash, refQueue );
 			}
 
 			return value;
 		}
 
 		@SuppressWarnings("unchecked")
 		final K key() {
 			if ( keyRef instanceof KeyReference ) {
 				return ( (Reference<K>) keyRef ).get();
 			}
 
 			return (K) keyRef;
 		}
 
 		final V value() {
 			return dereferenceValue( valueRef );
 		}
 
 		@SuppressWarnings("unchecked")
 		final V dereferenceValue(Object value) {
 			if ( value instanceof KeyReference ) {
 				return ( (Reference<V>) value ).get();
 			}
 
 			return (V) value;
 		}
 
 		final void setValue(V value, ReferenceType valueType, ReferenceQueue<Object> refQueue) {
 			this.valueRef = newValueReference( value, valueType, refQueue );
 		}
 
 		@SuppressWarnings("unchecked")
 		static final <K, V> HashEntry<K, V>[] newArray(int i) {
 			return new HashEntry[i];
 		}
 	}
 
 	/**
 	 * Segments are specialized versions of hash tables.  This
 	 * subclasses from ReentrantLock opportunistically, just to
 	 * simplify some locking and avoid separate construction.
 	 */
 	static final class Segment<K, V> extends ReentrantLock implements Serializable {
 		/*
 				 * Segments maintain a table of entry lists that are ALWAYS
 				 * kept in a consistent state, so can be read without locking.
 				 * Next fields of nodes are immutable (final).  All list
 				 * additions are performed at the front of each bin. This
 				 * makes it easy to check changes, and also fast to traverse.
 				 * When nodes would otherwise be changed, new nodes are
 				 * created to replace them. This works well for hash tables
 				 * since the bin lists tend to be short. (The average length
 				 * is less than two for the default load factor threshold.)
 				 *
 				 * Read operations can thus proceed without locking, but rely
 				 * on selected uses of volatiles to ensure that completed
 				 * write operations performed by other threads are
 				 * noticed. For most purposes, the "count" field, tracking the
 				 * number of elements, serves as that volatile variable
 				 * ensuring visibility.  This is convenient because this field
 				 * needs to be read in many read operations anyway:
 				 *
 				 *   - All (unsynchronized) read operations must first read the
 				 *     "count" field, and should not look at table entries if
 				 *     it is 0.
 				 *
 				 *   - All (synchronized) write operations should write to
 				 *     the "count" field after structurally changing any bin.
 				 *     The operations must not take any action that could even
 				 *     momentarily cause a concurrent read operation to see
 				 *     inconsistent data. This is made easier by the nature of
 				 *     the read operations in Map. For example, no operation
 				 *     can reveal that the table has grown but the threshold
 				 *     has not yet been updated, so there are no atomicity
 				 *     requirements for this with respect to reads.
 				 *
 				 * As a guide, all critical volatile reads and writes to the
 				 * count field are marked in code comments.
 				 */
 
 		private static final long serialVersionUID = 2249069246763182397L;
 
 		/**
 		 * The number of elements in this segment's region.
 		 */
 		transient volatile int count;
 
 		/**
 		 * Number of updates that alter the size of the table. This is
 		 * used during bulk-read methods to make sure they see a
 		 * consistent snapshot: If modCounts change during a traversal
 		 * of segments computing size or checking containsValue, then
 		 * we might have an inconsistent view of state so (usually)
 		 * must retry.
 		 */
 		transient int modCount;
 
 		/**
 		 * The table is rehashed when its size exceeds this threshold.
 		 * (The value of this field is always <tt>(int)(capacity *
 		 * loadFactor)</tt>.)
 		 */
 		transient int threshold;
 
 		/**
 		 * The per-segment table.
 		 */
 		transient volatile HashEntry<K, V>[] table;
 
 		/**
 		 * The load factor for the hash table.  Even though this value
 		 * is same for all segments, it is replicated to avoid needing
 		 * links to outer object.
 		 *
 		 * @serial
 		 */
 		final float loadFactor;
 
 		/**
 		 * The collected weak-key reference queue for this segment.
 		 * This should be (re)initialized whenever table is assigned,
 		 */
 		transient volatile ReferenceQueue<Object> refQueue;
 
 		final ReferenceType keyType;
 
 		final ReferenceType valueType;
 
 		final boolean identityComparisons;
 
 		Segment(
 				int initialCapacity, float lf, ReferenceType keyType,
 				ReferenceType valueType, boolean identityComparisons) {
 			loadFactor = lf;
 			this.keyType = keyType;
 			this.valueType = valueType;
 			this.identityComparisons = identityComparisons;
 			setTable( HashEntry.<K, V>newArray( initialCapacity ) );
 		}
 
 		@SuppressWarnings("unchecked")
 		static final <K, V> Segment<K, V>[] newArray(int i) {
 			return new Segment[i];
 		}
 
 		private boolean keyEq(Object src, Object dest) {
 			return identityComparisons ? src == dest : src.equals( dest );
 		}
 
 		/**
 		 * Sets table to new HashEntry array.
 		 * Call only while holding lock or in constructor.
 		 */
 		void setTable(HashEntry<K, V>[] newTable) {
 			threshold = (int) ( newTable.length * loadFactor );
 			table = newTable;
 			refQueue = new ReferenceQueue<Object>();
 		}
 
 		/**
 		 * Returns properly casted first entry of bin for given hash.
 		 */
 		HashEntry<K, V> getFirst(int hash) {
 			HashEntry<K, V>[] tab = table;
 			return tab[hash & ( tab.length - 1 )];
 		}
 
 		HashEntry<K, V> newHashEntry(K key, int hash, HashEntry<K, V> next, V value) {
 			return new HashEntry<K, V>( key, hash, next, value, keyType, valueType, refQueue );
 		}
 
 		/**
 		 * Reads value field of an entry under lock. Called if value
 		 * field ever appears to be null. This is possible only if a
 		 * compiler happens to reorder a HashEntry initialization with
 		 * its table assignment, which is legal under memory model
 		 * but is not known to ever occur.
 		 */
 		V readValueUnderLock(HashEntry<K, V> e) {
 			lock();
 			try {
 				removeStale();
 				return e.value();
 			}
 			finally {
 				unlock();
 			}
 		}
 
 		/* Specialized implementations of map methods */
 
 		V get(Object key, int hash) {
 			if ( count != 0 ) { // read-volatile
 				HashEntry<K, V> e = getFirst( hash );
 				while ( e != null ) {
 					if ( e.hash == hash && keyEq( key, e.key() ) ) {
 						Object opaque = e.valueRef;
 						if ( opaque != null ) {
 							return e.dereferenceValue( opaque );
 						}
 
 						return readValueUnderLock( e );  // recheck
 					}
 					e = e.next;
 				}
 			}
 			return null;
 		}
 
 		boolean containsKey(Object key, int hash) {
 			if ( count != 0 ) { // read-volatile
 				HashEntry<K, V> e = getFirst( hash );
 				while ( e != null ) {
 					if ( e.hash == hash && keyEq( key, e.key() ) ) {
 						return true;
 					}
 					e = e.next;
 				}
 			}
 			return false;
 		}
 
 		boolean containsValue(Object value) {
 			if ( count != 0 ) { // read-volatile
 				HashEntry<K, V>[] tab = table;
 				int len = tab.length;
 				for ( int i = 0; i < len; i++ ) {
 					for ( HashEntry<K, V> e = tab[i]; e != null; e = e.next ) {
 						Object opaque = e.valueRef;
 						V v;
 
 						if ( opaque == null ) {
 							v = readValueUnderLock( e ); // recheck
 						}
 						else {
 							v = e.dereferenceValue( opaque );
 						}
 
 						if ( value.equals( v ) ) {
 							return true;
 						}
 					}
 				}
 			}
 			return false;
 		}
 
 		boolean replace(K key, int hash, V oldValue, V newValue) {
 			lock();
 			try {
 				removeStale();
 				HashEntry<K, V> e = getFirst( hash );
 				while ( e != null && ( e.hash != hash || !keyEq( key, e.key() ) ) ) {
 					e = e.next;
 				}
 
 				boolean replaced = false;
 				if ( e != null && oldValue.equals( e.value() ) ) {
 					replaced = true;
 					e.setValue( newValue, valueType, refQueue );
 				}
 				return replaced;
 			}
 			finally {
 				unlock();
 			}
 		}
 
 		V replace(K key, int hash, V newValue) {
 			lock();
 			try {
 				removeStale();
 				HashEntry<K, V> e = getFirst( hash );
 				while ( e != null && ( e.hash != hash || !keyEq( key, e.key() ) ) ) {
 					e = e.next;
 				}
 
 				V oldValue = null;
 				if ( e != null ) {
 					oldValue = e.value();
 					e.setValue( newValue, valueType, refQueue );
 				}
 				return oldValue;
 			}
 			finally {
 				unlock();
 			}
 		}
 
 
 		V put(K key, int hash, V value, boolean onlyIfAbsent) {
 			lock();
 			try {
 				removeStale();
 				int c = count;
 				if ( c++ > threshold ) {// ensure capacity
 					int reduced = rehash();
 					if ( reduced > 0 ) {
 						// adjust from possible weak cleanups
 						count = ( c -= reduced ) - 1; // write-volatile
 					}
 				}
 
 				HashEntry<K, V>[] tab = table;
 				int index = hash & ( tab.length - 1 );
 				HashEntry<K, V> first = tab[index];
 				HashEntry<K, V> e = first;
 				while ( e != null && ( e.hash != hash || !keyEq( key, e.key() ) ) ) {
 					e = e.next;
 				}
 
 				V oldValue;
 				if ( e != null ) {
 					oldValue = e.value();
 					if ( !onlyIfAbsent ) {
 						e.setValue( value, valueType, refQueue );
 					}
 				}
 				else {
 					oldValue = null;
 					++modCount;
 					tab[index] = newHashEntry( key, hash, first, value );
 					count = c; // write-volatile
 				}
 				return oldValue;
 			}
 			finally {
 				unlock();
 			}
 		}
 
 		int rehash() {
 			HashEntry<K, V>[] oldTable = table;
 			int oldCapacity = oldTable.length;
 			if ( oldCapacity >= MAXIMUM_CAPACITY ) {
 				return 0;
 			}
 
 			/*
 						 * Reclassify nodes in each list to new Map.  Because we are
 						 * using power-of-two expansion, the elements from each bin
 						 * must either stay at same index, or move with a power of two
 						 * offset. We eliminate unnecessary node creation by catching
 						 * cases where old nodes can be reused because their next
 						 * fields won't change. Statistically, at the default
 						 * threshold, only about one-sixth of them need cloning when
 						 * a table doubles. The nodes they replace will be garbage
 						 * collectable as soon as they are no longer referenced by any
 						 * reader thread that may be in the midst of traversing table
 						 * right now.
 						 */
 
 			HashEntry<K, V>[] newTable = HashEntry.newArray( oldCapacity << 1 );
 			threshold = (int) ( newTable.length * loadFactor );
 			int sizeMask = newTable.length - 1;
 			int reduce = 0;
 			for ( int i = 0; i < oldCapacity; i++ ) {
 				// We need to guarantee that any existing reads of old Map can
 				//  proceed. So we cannot yet null out each bin.
 				HashEntry<K, V> e = oldTable[i];
 
 				if ( e != null ) {
 					HashEntry<K, V> next = e.next;
 					int idx = e.hash & sizeMask;
 
 					//  Single node on list
 					if ( next == null ) {
 						newTable[idx] = e;
 					}
 
 					else {
 						// Reuse trailing consecutive sequence at same slot
 						HashEntry<K, V> lastRun = e;
 						int lastIdx = idx;
-						for ( HashEntry<K, V> last = next;
-							  last != null;
-							  last = last.next ) {
+						for ( HashEntry<K, V> last = next; last != null; last = last.next ) {
 							int k = last.hash & sizeMask;
 							if ( k != lastIdx ) {
 								lastIdx = k;
 								lastRun = last;
 							}
 						}
 						newTable[lastIdx] = lastRun;
 						// Clone all remaining nodes
 						for ( HashEntry<K, V> p = e; p != lastRun; p = p.next ) {
 							// Skip GC'd weak refs
 							K key = p.key();
 							if ( key == null ) {
 								reduce++;
 								continue;
 							}
 							int k = p.hash & sizeMask;
 							HashEntry<K, V> n = newTable[k];
 							newTable[k] = newHashEntry( key, p.hash, n, p.value() );
 						}
 					}
 				}
 			}
 			table = newTable;
 			return reduce;
 		}
 
 		/**
 		 * Remove; match on key only if value null, else match both.
 		 */
 		V remove(Object key, int hash, Object value, boolean refRemove) {
 			lock();
 			try {
 				if ( !refRemove ) {
 					removeStale();
 				}
 				int c = count - 1;
 				HashEntry<K, V>[] tab = table;
 				int index = hash & ( tab.length - 1 );
 				HashEntry<K, V> first = tab[index];
 				HashEntry<K, V> e = first;
 				// a ref remove operation compares the Reference instance
 				while ( e != null && key != e.keyRef
 						&& ( refRemove || hash != e.hash || !keyEq( key, e.key() ) ) ) {
 					e = e.next;
 				}
 
 				V oldValue = null;
 				if ( e != null ) {
 					V v = e.value();
 					if ( value == null || value.equals( v ) ) {
 						oldValue = v;
 						// All entries following removed node can stay
 						// in list, but all preceding ones need to be
 						// cloned.
 						++modCount;
 						HashEntry<K, V> newFirst = e.next;
 						for ( HashEntry<K, V> p = first; p != e; p = p.next ) {
 							K pKey = p.key();
 							if ( pKey == null ) { // Skip GC'd keys
 								c--;
 								continue;
 							}
 
 							newFirst = newHashEntry( pKey, p.hash, newFirst, p.value() );
 						}
 						tab[index] = newFirst;
 						count = c; // write-volatile
 					}
 				}
 				return oldValue;
 			}
 			finally {
 				unlock();
 			}
 		}
 
 		final void removeStale() {
 			KeyReference ref;
 			while ( ( ref = (KeyReference) refQueue.poll() ) != null ) {
 				remove( ref.keyRef(), ref.keyHash(), null, true );
 			}
 		}
 
 		void clear() {
 			if ( count != 0 ) {
 				lock();
 				try {
 					HashEntry<K, V>[] tab = table;
 					for ( int i = 0; i < tab.length; i++ ) {
 						tab[i] = null;
 					}
 					++modCount;
 					// replace the reference queue to avoid unnecessary stale cleanups
 					refQueue = new ReferenceQueue<Object>();
 					count = 0; // write-volatile
 				}
 				finally {
 					unlock();
 				}
 			}
 		}
 	}
 
 
 	/* ---------------- Public operations -------------- */
 
 	/**
 	 * Creates a new, empty map with the specified initial
 	 * capacity, reference types, load factor and concurrency level.
 	 * <p/>
 	 * Behavioral changing options such as {@link Option#IDENTITY_COMPARISONS}
 	 * can also be specified.
 	 *
 	 * @param initialCapacity the initial capacity. The implementation
 	 * performs internal sizing to accommodate this many elements.
 	 * @param loadFactor the load factor threshold, used to control resizing.
 	 * Resizing may be performed when the average number of elements per
 	 * bin exceeds this threshold.
 	 * @param concurrencyLevel the estimated number of concurrently
 	 * updating threads. The implementation performs internal sizing
 	 * to try to accommodate this many threads.
 	 * @param keyType the reference type to use for keys
 	 * @param valueType the reference type to use for values
 	 * @param options the behavioral options
 	 *
 	 * @throws IllegalArgumentException if the initial capacity is
 	 * negative or the load factor or concurrencyLevel are
 	 * nonpositive.
 	 */
 	public ConcurrentReferenceHashMap(
 			int initialCapacity,
 			float loadFactor, int concurrencyLevel,
 			ReferenceType keyType, ReferenceType valueType,
 			EnumSet<Option> options) {
 		if ( !( loadFactor > 0 ) || initialCapacity < 0 || concurrencyLevel <= 0 ) {
 			throw new IllegalArgumentException();
 		}
 
 		if ( concurrencyLevel > MAX_SEGMENTS ) {
 			concurrencyLevel = MAX_SEGMENTS;
 		}
 
 		// Find power-of-two sizes best matching arguments
 		int sshift = 0;
 		int ssize = 1;
 		while ( ssize < concurrencyLevel ) {
 			++sshift;
 			ssize <<= 1;
 		}
 		segmentShift = 32 - sshift;
 		segmentMask = ssize - 1;
 		this.segments = Segment.newArray( ssize );
 
 		if ( initialCapacity > MAXIMUM_CAPACITY ) {
 			initialCapacity = MAXIMUM_CAPACITY;
 		}
 		int c = initialCapacity / ssize;
 		if ( c * ssize < initialCapacity ) {
 			++c;
 		}
 		int cap = 1;
 		while ( cap < c ) {
 			cap <<= 1;
 		}
 
 		identityComparisons = options != null && options.contains( Option.IDENTITY_COMPARISONS );
 
 		for ( int i = 0; i < this.segments.length; ++i ) {
 			this.segments[i] = new Segment<K, V>(
 					cap, loadFactor,
 					keyType, valueType, identityComparisons
 			);
 		}
 	}
 
 	/**
 	 * Creates a new, empty map with the specified initial
 	 * capacity, load factor and concurrency level.
 	 *
 	 * @param initialCapacity the initial capacity. The implementation
 	 * performs internal sizing to accommodate this many elements.
 	 * @param loadFactor the load factor threshold, used to control resizing.
 	 * Resizing may be performed when the average number of elements per
 	 * bin exceeds this threshold.
 	 * @param concurrencyLevel the estimated number of concurrently
 	 * updating threads. The implementation performs internal sizing
 	 * to try to accommodate this many threads.
 	 *
 	 * @throws IllegalArgumentException if the initial capacity is
 	 * negative or the load factor or concurrencyLevel are
 	 * nonpositive.
 	 */
 	public ConcurrentReferenceHashMap(
 			int initialCapacity,
 			float loadFactor, int concurrencyLevel) {
 		this(
 				initialCapacity, loadFactor, concurrencyLevel,
 				DEFAULT_KEY_TYPE, DEFAULT_VALUE_TYPE, null
 		);
 	}
 
 	/**
 	 * Creates a new, empty map with the specified initial capacity
 	 * and load factor and with the default reference types (weak keys,
 	 * strong values), and concurrencyLevel (16).
 	 *
 	 * @param initialCapacity The implementation performs internal
 	 * sizing to accommodate this many elements.
 	 * @param loadFactor the load factor threshold, used to control resizing.
 	 * Resizing may be performed when the average number of elements per
 	 * bin exceeds this threshold.
 	 *
 	 * @throws IllegalArgumentException if the initial capacity of
 	 * elements is negative or the load factor is nonpositive
 	 * @since 1.6
 	 */
 	public ConcurrentReferenceHashMap(int initialCapacity, float loadFactor) {
 		this( initialCapacity, loadFactor, DEFAULT_CONCURRENCY_LEVEL );
 	}
 
 
 	/**
 	 * Creates a new, empty map with the specified initial capacity,
 	 * reference types and with default load factor (0.75) and concurrencyLevel (16).
 	 *
 	 * @param initialCapacity the initial capacity. The implementation
 	 * performs internal sizing to accommodate this many elements.
 	 * @param keyType the reference type to use for keys
 	 * @param valueType the reference type to use for values
 	 *
 	 * @throws IllegalArgumentException if the initial capacity of
 	 * elements is negative.
 	 */
 	public ConcurrentReferenceHashMap(
 			int initialCapacity,
 			ReferenceType keyType, ReferenceType valueType) {
 		this(
 				initialCapacity, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL,
 				keyType, valueType, null
 		);
 	}
 
 	/**
 	 * Creates a new, empty map with the specified initial capacity,
 	 * and with default reference types (weak keys, strong values),
 	 * load factor (0.75) and concurrencyLevel (16).
 	 *
 	 * @param initialCapacity the initial capacity. The implementation
 	 * performs internal sizing to accommodate this many elements.
 	 *
 	 * @throws IllegalArgumentException if the initial capacity of
 	 * elements is negative.
 	 */
 	public ConcurrentReferenceHashMap(int initialCapacity) {
 		this( initialCapacity, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL );
 	}
 
 	/**
 	 * Creates a new, empty map with a default initial capacity (16),
 	 * reference types (weak keys, strong values), default
 	 * load factor (0.75) and concurrencyLevel (16).
 	 */
 	public ConcurrentReferenceHashMap() {
 		this( DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL );
 	}
 
 	/**
 	 * Creates a new map with the same mappings as the given map.
 	 * The map is created with a capacity of 1.5 times the number
 	 * of mappings in the given map or 16 (whichever is greater),
 	 * and a default load factor (0.75) and concurrencyLevel (16).
 	 *
 	 * @param m the map
 	 */
 	public ConcurrentReferenceHashMap(Map<? extends K, ? extends V> m) {
 		this(
 				Math.max(
 						(int) ( m.size() / DEFAULT_LOAD_FACTOR ) + 1,
 						DEFAULT_INITIAL_CAPACITY
 				),
 				DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL
 		);
 		putAll( m );
 	}
 
 	/**
 	 * Returns <tt>true</tt> if this map contains no key-value mappings.
 	 *
 	 * @return <tt>true</tt> if this map contains no key-value mappings
 	 */
 	@Override
 	public boolean isEmpty() {
 		final Segment<K, V>[] segments = this.segments;
 		/*
 				 * We keep track of per-segment modCounts to avoid ABA
 				 * problems in which an element in one segment was added and
 				 * in another removed during traversal, in which case the
 				 * table was never actually empty at any point. Note the
 				 * similar use of modCounts in the size() and containsValue()
 				 * methods, which are the only other methods also susceptible
 				 * to ABA problems.
 				 */
 		int[] mc = new int[segments.length];
 		int mcsum = 0;
 		for ( int i = 0; i < segments.length; ++i ) {
 			if ( segments[i].count != 0 ) {
 				return false;
 			}
 			else {
 				mcsum += mc[i] = segments[i].modCount;
 			}
 		}
 		// If mcsum happens to be zero, then we know we got a snapshot
 		// before any modifications at all were made.  This is
 		// probably common enough to bother tracking.
 		if ( mcsum != 0 ) {
 			for ( int i = 0; i < segments.length; ++i ) {
 				if ( segments[i].count != 0 ||
 						mc[i] != segments[i].modCount ) {
 					return false;
 				}
 			}
 		}
 		return true;
 	}
 
 	/**
 	 * Returns the number of key-value mappings in this map.  If the
 	 * map contains more than <tt>Integer.MAX_VALUE</tt> elements, returns
 	 * <tt>Integer.MAX_VALUE</tt>.
 	 *
 	 * @return the number of key-value mappings in this map
 	 */
 	@Override
 	public int size() {
 		final Segment<K, V>[] segments = this.segments;
 		long sum = 0;
 		long check = 0;
 		int[] mc = new int[segments.length];
 		// Try a few times to get accurate count. On failure due to
 		// continuous async changes in table, resort to locking.
 		for ( int k = 0; k < RETRIES_BEFORE_LOCK; ++k ) {
 			check = 0;
 			sum = 0;
 			int mcsum = 0;
 			for ( int i = 0; i < segments.length; ++i ) {
 				sum += segments[i].count;
 				mcsum += mc[i] = segments[i].modCount;
 			}
 			if ( mcsum != 0 ) {
 				for ( int i = 0; i < segments.length; ++i ) {
 					check += segments[i].count;
 					if ( mc[i] != segments[i].modCount ) {
 						check = -1; // force retry
 						break;
 					}
 				}
 			}
 			if ( check == sum ) {
 				break;
 			}
 		}
 		if ( check != sum ) { // Resort to locking all segments
 			sum = 0;
 			for ( int i = 0; i < segments.length; ++i ) {
 				segments[i].lock();
 			}
 			for ( int i = 0; i < segments.length; ++i ) {
 				sum += segments[i].count;
 			}
 			for ( int i = 0; i < segments.length; ++i ) {
 				segments[i].unlock();
 			}
 		}
 		if ( sum > Integer.MAX_VALUE ) {
 			return Integer.MAX_VALUE;
 		}
 		else {
 			return (int) sum;
 		}
 	}
 
 	/**
 	 * Returns the value to which the specified key is mapped,
 	 * or {@code null} if this map contains no mapping for the key.
 	 * <p/>
 	 * <p>More formally, if this map contains a mapping from a key
 	 * {@code k} to a value {@code v} such that {@code key.equals(k)},
 	 * then this method returns {@code v}; otherwise it returns
 	 * {@code null}.  (There can be at most one such mapping.)
 	 *
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public V get(Object key) {
 		if ( key == null ) {
 			return null;
 		}
 		int hash = hashOf( key );
 		return segmentFor( hash ).get( key, hash );
 	}
 
 	/**
 	 * Tests if the specified object is a key in this table.
 	 *
 	 * @param key possible key
 	 *
 	 * @return <tt>true</tt> if and only if the specified object
 	 * is a key in this table, as determined by the
 	 * <tt>equals</tt> method; <tt>false</tt> otherwise.
 	 *
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public boolean containsKey(Object key) {
 		if ( key == null ) {
 			return false;
 		}
 		int hash = hashOf( key );
 		return segmentFor( hash ).containsKey( key, hash );
 	}
 
 	/**
 	 * Returns <tt>true</tt> if this map maps one or more keys to the
 	 * specified value. Note: This method requires a full internal
 	 * traversal of the hash table, and so is much slower than
 	 * method <tt>containsKey</tt>.
 	 *
 	 * @param value value whose presence in this map is to be tested
 	 *
 	 * @return <tt>true</tt> if this map maps one or more keys to the
 	 * specified value
 	 */
 	@Override
 	public boolean containsValue(Object value) {
 		if ( value == null ) {
 			return false;
 		}
 
 		// See explanation of modCount use above
 
 		final Segment<K, V>[] segments = this.segments;
 		int[] mc = new int[segments.length];
 
 		// Try a few times without locking
 		for ( int k = 0; k < RETRIES_BEFORE_LOCK; ++k ) {
 			int sum = 0;
 			int mcsum = 0;
 			for ( int i = 0; i < segments.length; ++i ) {
 				int c = segments[i].count;
 				mcsum += mc[i] = segments[i].modCount;
 				if ( segments[i].containsValue( value ) ) {
 					return true;
 				}
 			}
 			boolean cleanSweep = true;
 			if ( mcsum != 0 ) {
 				for ( int i = 0; i < segments.length; ++i ) {
 					int c = segments[i].count;
 					if ( mc[i] != segments[i].modCount ) {
 						cleanSweep = false;
 						break;
 					}
 				}
 			}
 			if ( cleanSweep ) {
 				return false;
 			}
 		}
 		// Resort to locking all segments
 		for ( int i = 0; i < segments.length; ++i ) {
 			segments[i].lock();
 		}
 		boolean found = false;
 		try {
 			for ( int i = 0; i < segments.length; ++i ) {
 				if ( segments[i].containsValue( value ) ) {
 					found = true;
 					break;
 				}
 			}
 		}
 		finally {
 			for ( int i = 0; i < segments.length; ++i ) {
 				segments[i].unlock();
 			}
 		}
 		return found;
 	}
 
 	/**
 	 * Legacy method testing if some key maps into the specified value
 	 * in this table.  This method is identical in functionality to
 	 * {@link #containsValue}, and exists solely to ensure
 	 * full compatibility with class {@link java.util.Hashtable},
 	 * which supported this method prior to introduction of the
 	 * Java Collections framework.
 	 *
 	 * @param value a value to search for
 	 *
 	 * @return <tt>true</tt> if and only if some key maps to the
 	 * <tt>value</tt> argument in this table as
 	 * determined by the <tt>equals</tt> method;
 	 * <tt>false</tt> otherwise
 	 *
 	 * @throws NullPointerException if the specified value is null
 	 */
 	public boolean contains(Object value) {
 		return containsValue( value );
 	}
 
 	/**
 	 * Maps the specified key to the specified value in this table.
 	 * Neither the key nor the value can be null.
 	 * <p/>
 	 * <p> The value can be retrieved by calling the <tt>get</tt> method
 	 * with a key that is equal to the original key.
 	 *
 	 * @param key key with which the specified value is to be associated
 	 * @param value value to be associated with the specified key
 	 *
 	 * @return the previous value associated with <tt>key</tt>, or
 	 * <tt>null</tt> if there was no mapping for <tt>key</tt>
 	 *
 	 * @throws NullPointerException if the specified key or value is null
 	 */
 	@Override
 	public V put(K key, V value) {
 		if ( key == null || value == null ) {
 			return null;
 		}
 		int hash = hashOf( key );
 		return segmentFor( hash ).put( key, hash, value, false );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @return the previous value associated with the specified key,
 	 * or <tt>null</tt> if there was no mapping for the key
 	 *
 	 * @throws NullPointerException if the specified key or value is null
 	 */
 	@Override
 	public V putIfAbsent(K key, V value) {
 		if ( key == null || value == null ) {
 			return null;
 		}
 		int hash = hashOf( key );
 		return segmentFor( hash ).put( key, hash, value, true );
 	}
 
 	/**
 	 * Copies all of the mappings from the specified map to this one.
 	 * These mappings replace any mappings that this map had for any of the
 	 * keys currently in the specified map.
 	 *
 	 * @param m mappings to be stored in this map
 	 */
 	@Override
 	public void putAll(Map<? extends K, ? extends V> m) {
 		for ( Map.Entry<? extends K, ? extends V> e : m.entrySet() ) {
 			put( e.getKey(), e.getValue() );
 		}
 	}
 
 	/**
 	 * Removes the key (and its corresponding value) from this map.
 	 * This method does nothing if the key is not in the map.
 	 *
 	 * @param key the key that needs to be removed
 	 *
 	 * @return the previous value associated with <tt>key</tt>, or
 	 * <tt>null</tt> if there was no mapping for <tt>key</tt>
 	 *
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public V remove(Object key) {
 		if ( key == null ) {
 			return null;
 		}
 		int hash = hashOf( key );
 		return segmentFor( hash ).remove( key, hash, null, false );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public boolean remove(Object key, Object value) {
 		if ( key == null || value == null ) {
 			return false;
 		}
 		int hash = hashOf( key );
 		return segmentFor( hash ).remove( key, hash, value, false ) != null;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @throws NullPointerException if any of the arguments are null
 	 */
 	@Override
 	public boolean replace(K key, V oldValue, V newValue) {
 		if ( key == null || oldValue == null || newValue == null ) {
 			throw new NullPointerException();
 		}
 		int hash = hashOf( key );
 		return segmentFor( hash ).replace( key, hash, oldValue, newValue );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @return the previous value associated with the specified key,
 	 * or <tt>null</tt> if there was no mapping for the key
 	 *
 	 * @throws NullPointerException if the specified key or value is null
 	 */
 	@Override
 	public V replace(K key, V value) {
 		if ( key == null || value == null ) {
 			return null;
 		}
 		int hash = hashOf( key );
 		return segmentFor( hash ).replace( key, hash, value );
 	}
 
 	/**
 	 * Removes all of the mappings from this map.
 	 */
 	@Override
 	public void clear() {
 		for ( int i = 0; i < segments.length; ++i ) {
 			segments[i].clear();
 		}
 	}
 
 	/**
 	 * Removes any stale entries whose keys have been finalized. Use of this
 	 * method is normally not necessary since stale entries are automatically
 	 * removed lazily, when blocking operations are required. However, there
 	 * are some cases where this operation should be performed eagerly, such
 	 * as cleaning up old references to a ClassLoader in a multi-classloader
 	 * environment.
 	 * <p/>
 	 * Note: this method will acquire locks, one at a time, across all segments
 	 * of this table, so if it is to be used, it should be used sparingly.
 	 */
 	public void purgeStaleEntries() {
 		for ( int i = 0; i < segments.length; ++i ) {
 			segments[i].removeStale();
 		}
 	}
 
 
 	/**
 	 * Returns a {@link Set} view of the keys contained in this map.
 	 * The set is backed by the map, so changes to the map are
 	 * reflected in the set, and vice-versa.  The set supports element
 	 * removal, which removes the corresponding mapping from this map,
 	 * via the <tt>Iterator.remove</tt>, <tt>Set.remove</tt>,
 	 * <tt>removeAll</tt>, <tt>retainAll</tt>, and <tt>clear</tt>
 	 * operations.  It does not support the <tt>add</tt> or
 	 * <tt>addAll</tt> operations.
 	 * <p/>
 	 * <p>The view's <tt>iterator</tt> is a "weakly consistent" iterator
 	 * that will never throw {@link java.util.ConcurrentModificationException},
 	 * and guarantees to traverse elements as they existed upon
 	 * construction of the iterator, and may (but is not guaranteed to)
 	 * reflect any modifications subsequent to construction.
 	 */
 	@Override
 	public Set<K> keySet() {
 		Set<K> ks = keySet;
 		return ( ks != null ) ? ks : ( keySet = new KeySet() );
 	}
 
 	/**
 	 * Returns a {@link Collection} view of the values contained in this map.
 	 * The collection is backed by the map, so changes to the map are
 	 * reflected in the collection, and vice-versa.  The collection
 	 * supports element removal, which removes the corresponding
 	 * mapping from this map, via the <tt>Iterator.remove</tt>,
 	 * <tt>Collection.remove</tt>, <tt>removeAll</tt>,
 	 * <tt>retainAll</tt>, and <tt>clear</tt> operations.  It does not
 	 * support the <tt>add</tt> or <tt>addAll</tt> operations.
 	 * <p/>
 	 * <p>The view's <tt>iterator</tt> is a "weakly consistent" iterator
 	 * that will never throw {@link java.util.ConcurrentModificationException},
 	 * and guarantees to traverse elements as they existed upon
 	 * construction of the iterator, and may (but is not guaranteed to)
 	 * reflect any modifications subsequent to construction.
 	 */
 	@Override
 	public Collection<V> values() {
 		Collection<V> vs = values;
 		return ( vs != null ) ? vs : ( values = new Values() );
 	}
 
 	/**
 	 * Returns a {@link Set} view of the mappings contained in this map.
 	 * The set is backed by the map, so changes to the map are
 	 * reflected in the set, and vice-versa.  The set supports element
 	 * removal, which removes the corresponding mapping from the map,
 	 * via the <tt>Iterator.remove</tt>, <tt>Set.remove</tt>,
 	 * <tt>removeAll</tt>, <tt>retainAll</tt>, and <tt>clear</tt>
 	 * operations.  It does not support the <tt>add</tt> or
 	 * <tt>addAll</tt> operations.
 	 * <p/>
 	 * <p>The view's <tt>iterator</tt> is a "weakly consistent" iterator
 	 * that will never throw {@link java.util.ConcurrentModificationException},
 	 * and guarantees to traverse elements as they existed upon
 	 * construction of the iterator, and may (but is not guaranteed to)
 	 * reflect any modifications subsequent to construction.
 	 */
 	@Override
 	public Set<Map.Entry<K, V>> entrySet() {
 		Set<Map.Entry<K, V>> es = entrySet;
 		return ( es != null ) ? es : ( entrySet = new EntrySet() );
 	}
 
 	/**
 	 * Returns an enumeration of the keys in this table.
 	 *
 	 * @return an enumeration of the keys in this table
 	 *
 	 * @see #keySet()
 	 */
 	public Enumeration<K> keys() {
 		return new KeyIterator();
 	}
 
 	/**
 	 * Returns an enumeration of the values in this table.
 	 *
 	 * @return an enumeration of the values in this table
 	 *
 	 * @see #values()
 	 */
 	public Enumeration<V> elements() {
 		return new ValueIterator();
 	}
 
 	/* ---------------- Iterator Support -------------- */
 
 	abstract class HashIterator {
 		int nextSegmentIndex;
 		int nextTableIndex;
 		HashEntry<K, V>[] currentTable;
 		HashEntry<K, V> nextEntry;
 		HashEntry<K, V> lastReturned;
 		K currentKey; // Strong reference to weak key (prevents gc)
 
 		HashIterator() {
 			nextSegmentIndex = segments.length - 1;
 			nextTableIndex = -1;
 			advance();
 		}
 
 		public boolean hasMoreElements() {
 			return hasNext();
 		}
 
 		final void advance() {
 			if ( nextEntry != null && ( nextEntry = nextEntry.next ) != null ) {
 				return;
 			}
 
 			while ( nextTableIndex >= 0 ) {
 				if ( ( nextEntry = currentTable[nextTableIndex--] ) != null ) {
 					return;
 				}
 			}
 
 			while ( nextSegmentIndex >= 0 ) {
 				Segment<K, V> seg = segments[nextSegmentIndex--];
 				if ( seg.count != 0 ) {
 					currentTable = seg.table;
 					for ( int j = currentTable.length - 1; j >= 0; --j ) {
 						if ( ( nextEntry = currentTable[j] ) != null ) {
 							nextTableIndex = j - 1;
 							return;
 						}
 					}
 				}
 			}
 		}
 
 		public boolean hasNext() {
 			while ( nextEntry != null ) {
 				if ( nextEntry.key() != null ) {
 					return true;
 				}
 				advance();
 			}
 
 			return false;
 		}
 
 		HashEntry<K, V> nextEntry() {
 			do {
 				if ( nextEntry == null ) {
 					throw new NoSuchElementException();
 				}
 
 				lastReturned = nextEntry;
 				currentKey = lastReturned.key();
 				advance();
 			} while ( currentKey == null ); // Skip GC'd keys
 
 			return lastReturned;
 		}
 
 		public void remove() {
 			if ( lastReturned == null ) {
 				throw new IllegalStateException();
 			}
 			ConcurrentReferenceHashMap.this.remove( currentKey );
 			lastReturned = null;
 		}
 	}
 
 	final class KeyIterator
 			extends HashIterator
 			implements Iterator<K>, Enumeration<K> {
 		@Override
 		public K next() {
 			return super.nextEntry().key();
 		}
 
 		@Override
 		public K nextElement() {
 			return super.nextEntry().key();
 		}
 	}
 
 	final class ValueIterator
 			extends HashIterator
 			implements Iterator<V>, Enumeration<V> {
 		@Override
 		public V next() {
 			return super.nextEntry().value();
 		}
 
 		@Override
 		public V nextElement() {
 			return super.nextEntry().value();
 		}
 	}
 
 	/*
 		  * This class is needed for JDK5 compatibility.
 		  */
-	static class SimpleEntry<K, V> implements Entry<K, V>,
-											  java.io.Serializable {
+	static class SimpleEntry<K, V> implements Entry<K, V>, java.io.Serializable {
 		private static final long serialVersionUID = -8499721149061103585L;
 
 		private final K key;
 		private V value;
 
 		public SimpleEntry(K key, V value) {
 			this.key = key;
 			this.value = value;
 		}
 
 		public SimpleEntry(Entry<? extends K, ? extends V> entry) {
 			this.key = entry.getKey();
 			this.value = entry.getValue();
 		}
 
 		@Override
 		public K getKey() {
 			return key;
 		}
 
 		@Override
 		public V getValue() {
 			return value;
 		}
 
 		@Override
 		public V setValue(V value) {
 			V oldValue = this.value;
 			this.value = value;
 			return oldValue;
 		}
 
 		@Override
 		public boolean equals(Object o) {
 			if ( !( o instanceof Map.Entry ) ) {
 				return false;
 			}
 			@SuppressWarnings("unchecked")
 			Map.Entry e = (Map.Entry) o;
 			return eq( key, e.getKey() ) && eq( value, e.getValue() );
 		}
 
 		@Override
 		public int hashCode() {
 			return ( key == null ? 0 : key.hashCode() )
 					^ ( value == null ? 0 : value.hashCode() );
 		}
 
 		@Override
 		public String toString() {
 			return key + "=" + value;
 		}
 
 		private static boolean eq(Object o1, Object o2) {
 			return o1 == null ? o2 == null : o1.equals( o2 );
 		}
 	}
 
 
 	/**
 	 * Custom Entry class used by EntryIterator.next(), that relays setValue
 	 * changes to the underlying map.
 	 */
 	final class WriteThroughEntry extends SimpleEntry<K, V> {
 		private static final long serialVersionUID = -7900634345345313646L;
 
 		WriteThroughEntry(K k, V v) {
 			super( k, v );
 		}
 
 		/**
 		 * Set our entry's value and write through to the map. The
 		 * value to return is somewhat arbitrary here. Since a
 		 * WriteThroughEntry does not necessarily track asynchronous
 		 * changes, the most recent "previous" value could be
 		 * different from what we return (or could even have been
 		 * removed in which case the put will re-establish). We do not
 		 * and cannot guarantee more.
 		 */
 		@Override
 		public V setValue(V value) {
 			if ( value == null ) {
 				throw new NullPointerException();
 			}
 			V v = super.setValue( value );
 			ConcurrentReferenceHashMap.this.put( getKey(), value );
 			return v;
 		}
 	}
 
 	final class EntryIterator
 			extends HashIterator
 			implements Iterator<Entry<K, V>> {
 		@Override
 		public Map.Entry<K, V> next() {
 			HashEntry<K, V> e = super.nextEntry();
 			return new WriteThroughEntry( e.key(), e.value() );
 		}
 	}
 
 	final class KeySet extends AbstractSet<K> {
 		@Override
 		public Iterator<K> iterator() {
 			return new KeyIterator();
 		}
 
 		@Override
 		public int size() {
 			return ConcurrentReferenceHashMap.this.size();
 		}
 
 		@Override
 		public boolean isEmpty() {
 			return ConcurrentReferenceHashMap.this.isEmpty();
 		}
 
 		@Override
 		public boolean contains(Object o) {
 			return ConcurrentReferenceHashMap.this.containsKey( o );
 		}
 
 		@Override
 		public boolean remove(Object o) {
 			return ConcurrentReferenceHashMap.this.remove( o ) != null;
 		}
 
 		@Override
 		public void clear() {
 			ConcurrentReferenceHashMap.this.clear();
 		}
 	}
 
 	final class Values extends AbstractCollection<V> {
 		@Override
 		public Iterator<V> iterator() {
 			return new ValueIterator();
 		}
 
 		@Override
 		public int size() {
 			return ConcurrentReferenceHashMap.this.size();
 		}
 
 		@Override
 		public boolean isEmpty() {
 			return ConcurrentReferenceHashMap.this.isEmpty();
 		}
 
 		@Override
 		public boolean contains(Object o) {
 			return ConcurrentReferenceHashMap.this.containsValue( o );
 		}
 
 		@Override
 		public void clear() {
 			ConcurrentReferenceHashMap.this.clear();
 		}
 	}
 
 	final class EntrySet extends AbstractSet<Map.Entry<K, V>> {
 		@Override
 		public Iterator<Map.Entry<K, V>> iterator() {
 			return new EntryIterator();
 		}
 
 		@Override
 		public boolean contains(Object o) {
 			if ( !( o instanceof Map.Entry ) ) {
 				return false;
 			}
 			Map.Entry<?, ?> e = (Map.Entry<?, ?>) o;
 			V v = ConcurrentReferenceHashMap.this.get( e.getKey() );
 			return v != null && v.equals( e.getValue() );
 		}
 
 		@Override
 		public boolean remove(Object o) {
 			if ( !( o instanceof Map.Entry ) ) {
 				return false;
 			}
 			Map.Entry<?, ?> e = (Map.Entry<?, ?>) o;
 			return ConcurrentReferenceHashMap.this.remove( e.getKey(), e.getValue() );
 		}
 
 		@Override
 		public int size() {
 			return ConcurrentReferenceHashMap.this.size();
 		}
 
 		@Override
 		public boolean isEmpty() {
 			return ConcurrentReferenceHashMap.this.isEmpty();
 		}
 
 		@Override
 		public void clear() {
 			ConcurrentReferenceHashMap.this.clear();
 		}
 	}
 
 	/* ---------------- Serialization Support -------------- */
 
 	/**
 	 * Save the state of the <tt>ConcurrentReferenceHashMap</tt> instance to a
 	 * stream (i.e., serialize it).
 	 *
 	 * @param s the stream
 	 *
 	 * @serialData the key (Object) and value (Object)
 	 * for each key-value mapping, followed by a null pair.
 	 * The key-value mappings are emitted in no particular order.
 	 */
 	private void writeObject(java.io.ObjectOutputStream s) throws IOException {
 		s.defaultWriteObject();
 
 		for ( int k = 0; k < segments.length; ++k ) {
 			Segment<K, V> seg = segments[k];
 			seg.lock();
 			try {
 				HashEntry<K, V>[] tab = seg.table;
 				for ( int i = 0; i < tab.length; ++i ) {
 					for ( HashEntry<K, V> e = tab[i]; e != null; e = e.next ) {
 						K key = e.key();
 						if ( key == null ) {
 							// Skip GC'd keys
 							continue;
 						}
 
 						s.writeObject( key );
 						s.writeObject( e.value() );
 					}
 				}
 			}
 			finally {
 				seg.unlock();
 			}
 		}
 		s.writeObject( null );
 		s.writeObject( null );
 	}
 
 	/**
 	 * Reconstitute the <tt>ConcurrentReferenceHashMap</tt> instance from a
 	 * stream (i.e., deserialize it).
 	 *
 	 * @param s the stream
 	 */
 	@SuppressWarnings("unchecked")
 	private void readObject(java.io.ObjectInputStream s)
 			throws IOException, ClassNotFoundException {
 		s.defaultReadObject();
 
 		// Initialize each segment to be minimally sized, and let grow.
 		for ( int i = 0; i < segments.length; ++i ) {
 			segments[i].setTable( new HashEntry[1] );
 		}
 
 		// Read the keys and values, and put the mappings in the table
 		for (; ; ) {
 			K key = (K) s.readObject();
 			V value = (V) s.readObject();
 			if ( key == null ) {
 				break;
 			}
 			put( key, value );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/SingletonIterator.java b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/SingletonIterator.java
index 42f9b42a63..d221512a4d 100755
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/SingletonIterator.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/SingletonIterator.java
@@ -1,59 +1,58 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal.util.collections;
 
 import java.util.Iterator;
 
 /**
  * @author Gavin King
  */
-public final class SingletonIterator implements Iterator {
-
-	private Object value;
+public final class SingletonIterator<T> implements Iterator<T> {
+	private T value;
 	private boolean hasNext = true;
 
 	public boolean hasNext() {
 		return hasNext;
 	}
 
-	public Object next() {
+	public T next() {
 		if (hasNext) {
 			hasNext = false;
 			return value;
 		}
 		else {
 			throw new IllegalStateException();
 		}
 	}
 
 	public void remove() {
 		throw new UnsupportedOperationException();
 	}
 
-	public SingletonIterator(Object value) {
+	public SingletonIterator(T value) {
 		this.value = value;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/Loader.java b/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
index 8f306450f8..46e5aac3d5 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
@@ -1,2716 +1,2808 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 
 import java.io.Serializable;
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.WrongClassException;
 import org.hibernate.cache.spi.FilterKey;
 import org.hibernate.cache.spi.QueryCache;
 import org.hibernate.cache.spi.QueryKey;
 import org.hibernate.cache.spi.entry.CacheEntry;
 import org.hibernate.cache.spi.entry.ReferenceCacheEntryImpl;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.dialect.pagination.NoopLimitHandler;
 import org.hibernate.engine.internal.CacheHelper;
 import org.hibernate.engine.internal.TwoPhaseLoad;
 import org.hibernate.engine.jdbc.ColumnNameCache;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.EntityUniqueKey;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.SubselectFetch;
 import org.hibernate.engine.spi.TypedValue;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.event.spi.PostLoadEvent;
 import org.hibernate.event.spi.PreLoadEvent;
 import org.hibernate.hql.internal.HolderInstantiator;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.FetchingScrollableResultsImpl;
 import org.hibernate.internal.ScrollableResultsImpl;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.loader.spi.AfterLoadAction;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.UniqueKeyLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.transform.CacheableResultTransformer;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 
-import org.jboss.logging.Logger;
-
 /**
  * Abstract superclass of object loading (and querying) strategies. This class implements
  * useful common functionality that concrete loaders delegate to. It is not intended that this
  * functionality would be directly accessed by client code. (Hence, all methods of this class
  * are declared <tt>protected</tt> or <tt>private</tt>.) This class relies heavily upon the
  * <tt>Loadable</tt> interface, which is the contract between this class and
  * <tt>EntityPersister</tt>s that may be loaded by it.<br>
  * <br>
  * The present implementation is able to load any number of columns of entities and at most
  * one collection role per query.
  *
  * @author Gavin King
  * @see org.hibernate.persister.entity.Loadable
  */
 public abstract class Loader {
 	protected static final CoreMessageLogger LOG = CoreLogging.messageLogger( Loader.class );
 	protected static final boolean DEBUG_ENABLED = LOG.isDebugEnabled();
 
 	private final SessionFactoryImplementor factory;
 	private volatile ColumnNameCache columnNameCache;
 
 	private final boolean referenceCachingEnabled;
 
 	public Loader(SessionFactoryImplementor factory) {
 		this.factory = factory;
 		this.referenceCachingEnabled = factory.getSessionFactoryOptions().isDirectReferenceCacheEntriesEnabled();
 	}
 
 	/**
 	 * The SQL query string to be called; implemented by all subclasses
 	 *
 	 * @return The sql command this loader should use to get its {@link ResultSet}.
 	 */
 	public abstract String getSQLString();
 
 	/**
 	 * An array of persisters of entity classes contained in each row of results;
 	 * implemented by all subclasses
 	 *
 	 * @return The entity persisters.
 	 */
 	protected abstract Loadable[] getEntityPersisters();
 
 	/**
 	 * An array indicating whether the entities have eager property fetching
 	 * enabled.
 	 *
 	 * @return Eager property fetching indicators.
 	 */
 	protected boolean[] getEntityEagerPropertyFetches() {
 		return null;
 	}
 
 	/**
 	 * An array of indexes of the entity that owns a one-to-one association
 	 * to the entity at the given index (-1 if there is no "owner").  The
 	 * indexes contained here are relative to the result of
 	 * {@link #getEntityPersisters}.
 	 *
 	 * @return The owner indicators (see discussion above).
 	 */
 	protected int[] getOwners() {
 		return null;
 	}
 
 	/**
 	 * An array of the owner types corresponding to the {@link #getOwners()}
 	 * returns.  Indices indicating no owner would be null here.
 	 *
 	 * @return The types for the owners.
 	 */
 	protected EntityType[] getOwnerAssociationTypes() {
 		return null;
 	}
 
 	/**
 	 * An (optional) persister for a collection to be initialized; only
 	 * collection loaders return a non-null value
 	 */
 	protected CollectionPersister[] getCollectionPersisters() {
 		return null;
 	}
 
 	/**
 	 * Get the index of the entity that owns the collection, or -1
 	 * if there is no owner in the query results (ie. in the case of a
 	 * collection initializer) or no collection.
 	 */
 	protected int[] getCollectionOwners() {
 		return null;
 	}
 
 	protected int[][] getCompositeKeyManyToOneTargetIndices() {
 		return null;
 	}
 
 	/**
 	 * What lock options does this load entities with?
 	 *
 	 * @param lockOptions a collection of lock options specified dynamically via the Query interface
 	 */
 	//protected abstract LockOptions[] getLockOptions(Map lockOptions);
 	protected abstract LockMode[] getLockModes(LockOptions lockOptions);
 
 	/**
 	 * Append <tt>FOR UPDATE OF</tt> clause, if necessary. This
 	 * empty superclass implementation merely returns its first
 	 * argument.
 	 */
 	protected String applyLocks(
 			String sql,
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) throws HibernateException {
 		return sql;
 	}
 
 	/**
 	 * Does this query return objects that might be already cached
 	 * by the session, whose lock mode may need upgrading
 	 */
 	protected boolean upgradeLocks() {
 		return false;
 	}
 
 	/**
 	 * Return false is this loader is a batch entity loader
 	 */
 	protected boolean isSingleRowLoader() {
 		return false;
 	}
 
 	/**
 	 * Get the SQL table aliases of entities whose
 	 * associations are subselect-loadable, returning
 	 * null if this loader does not support subselect
 	 * loading
 	 */
 	protected String[] getAliases() {
 		return null;
 	}
 
 	/**
 	 * Modify the SQL, adding lock hints and comments, if necessary
 	 */
 	protected String preprocessSQL(
 			String sql,
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) throws HibernateException {
 		sql = applyLocks( sql, parameters, dialect, afterLoadActions );
-		
+
 		// Keep this here, rather than moving to Select.  Some Dialects may need the hint to be appended to the very
 		// end or beginning of the finalized SQL statement, so wait until everything is processed.
 		if ( parameters.getQueryHints() != null && parameters.getQueryHints().size() > 0 ) {
 			sql = dialect.getQueryHintString( sql, parameters.getQueryHints() );
 		}
-		
+
 		return getFactory().getSessionFactoryOptions().isCommentsEnabled()
 				? prependComment( sql, parameters )
 				: sql;
 	}
 
 	protected boolean shouldUseFollowOnLocking(
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) {
 		if ( dialect.useFollowOnLocking() ) {
 			// currently only one lock mode is allowed in follow-on locking
 			final LockMode lockMode = determineFollowOnLockMode( parameters.getLockOptions() );
 			final LockOptions lockOptions = new LockOptions( lockMode );
 			if ( lockOptions.getLockMode() != LockMode.UPGRADE_SKIPLOCKED ) {
 				LOG.usingFollowOnLocking();
 				lockOptions.setTimeOut( parameters.getLockOptions().getTimeOut() );
 				lockOptions.setScope( parameters.getLockOptions().getScope() );
 				afterLoadActions.add(
 						new AfterLoadAction() {
 							@Override
 							public void afterLoad(SessionImplementor session, Object entity, Loadable persister) {
-								( (Session) session ).buildLockRequest( lockOptions ).lock( persister.getEntityName(), entity );
+								( (Session) session ).buildLockRequest( lockOptions ).lock(
+										persister.getEntityName(),
+										entity
+								);
 							}
 						}
 				);
 				parameters.setLockOptions( new LockOptions() );
 				return true;
 			}
 		}
 		return false;
 	}
 
 	protected LockMode determineFollowOnLockMode(LockOptions lockOptions) {
 		final LockMode lockModeToUse = lockOptions.findGreatestLockMode();
 
 		if ( lockOptions.hasAliasSpecificLockModes() ) {
 			LOG.aliasSpecificLockingWithFollowOnLocking( lockModeToUse );
 		}
 
 		return lockModeToUse;
 	}
 
 	private String prependComment(String sql, QueryParameters parameters) {
 		String comment = parameters.getComment();
 		if ( comment == null ) {
 			return sql;
 		}
 		else {
 			return "/* " + comment + " */ " + sql;
 		}
 	}
 
 	/**
 	 * Execute an SQL query and attempt to instantiate instances of the class mapped by the given
 	 * persister from each row of the <tt>ResultSet</tt>. If an object is supplied, will attempt to
 	 * initialize that object. If a collection is supplied, attempt to initialize that collection.
 	 */
 	public List doQueryAndInitializeNonLazyCollections(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies) throws HibernateException, SQLException {
 		return doQueryAndInitializeNonLazyCollections(
 				session,
 				queryParameters,
 				returnProxies,
 				null
 		);
 	}
 
 	public List doQueryAndInitializeNonLazyCollections(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final ResultTransformer forcedResultTransformer)
 			throws HibernateException, SQLException {
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		boolean defaultReadOnlyOrig = persistenceContext.isDefaultReadOnly();
 		if ( queryParameters.isReadOnlyInitialized() ) {
 			// The read-only/modifiable mode for the query was explicitly set.
 			// Temporarily set the default read-only/modifiable setting to the query's setting.
 			persistenceContext.setDefaultReadOnly( queryParameters.isReadOnly() );
 		}
 		else {
 			// The read-only/modifiable setting for the query was not initialized.
 			// Use the default read-only/modifiable from the persistence context instead.
 			queryParameters.setReadOnly( persistenceContext.isDefaultReadOnly() );
 		}
 		persistenceContext.beforeLoad();
 		List result;
 		try {
 			try {
 				result = doQuery( session, queryParameters, returnProxies, forcedResultTransformer );
 			}
 			finally {
 				persistenceContext.afterLoad();
 			}
 			persistenceContext.initializeNonLazyCollections();
 		}
 		finally {
 			// Restore the original default
 			persistenceContext.setDefaultReadOnly( defaultReadOnlyOrig );
 		}
 		return result;
 	}
 
 	/**
 	 * Loads a single row from the result set.  This is the processing used from the
 	 * ScrollableResults where no collection fetches were encountered.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
+	 *
 	 * @return The loaded "row".
+	 *
 	 * @throws HibernateException
 	 */
 	public Object loadSingleRow(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies) throws HibernateException {
 
 		final int entitySpan = getEntityPersisters().length;
 		final List hydratedObjects = entitySpan == 0 ?
 				null : new ArrayList( entitySpan );
 
 		final Object result;
 		try {
 			result = getRowFromResultSet(
 					resultSet,
 					session,
 					queryParameters,
 					getLockModes( queryParameters.getLockOptions() ),
 					null,
 					hydratedObjects,
 					new EntityKey[entitySpan],
 					returnProxies
-				);
+			);
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not read next row of results",
 					getSQLString()
-				);
+			);
 		}
 
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				resultSet,
 				session,
 				queryParameters.isReadOnly( session )
 		);
 		session.getPersistenceContext().initializeNonLazyCollections();
 		return result;
 	}
 
 	private Object sequentialLoad(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final EntityKey keyToRead) throws HibernateException {
 
 		final int entitySpan = getEntityPersisters().length;
 		final List hydratedObjects = entitySpan == 0 ?
 				null : new ArrayList( entitySpan );
 
 		Object result = null;
 		final EntityKey[] loadedKeys = new EntityKey[entitySpan];
 
 		try {
 			do {
 				Object loaded = getRowFromResultSet(
 						resultSet,
 						session,
 						queryParameters,
 						getLockModes( queryParameters.getLockOptions() ),
 						null,
 						hydratedObjects,
 						loadedKeys,
 						returnProxies
 				);
-				if ( ! keyToRead.equals( loadedKeys[0] ) ) {
+				if ( !keyToRead.equals( loadedKeys[0] ) ) {
 					throw new AssertionFailure(
 							String.format(
 									"Unexpected key read for row; expected [%s]; actual [%s]",
 									keyToRead,
-									loadedKeys[0] )
+									loadedKeys[0]
+							)
 					);
 				}
 				if ( result == null ) {
 					result = loaded;
 				}
 			}
 			while ( resultSet.next() &&
 					isCurrentRowForSameEntity( keyToRead, 0, resultSet, session ) );
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not doAfterTransactionCompletion sequential read of results (forward)",
 					getSQLString()
-				);
+			);
 		}
 
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				resultSet,
 				session,
 				queryParameters.isReadOnly( session )
 		);
 		session.getPersistenceContext().initializeNonLazyCollections();
 		return result;
 	}
 
 	private boolean isCurrentRowForSameEntity(
 			final EntityKey keyToRead,
 			final int persisterIndex,
 			final ResultSet resultSet,
 			final SessionImplementor session) throws SQLException {
 		EntityKey currentRowKey = getKeyFromResultSet(
 				persisterIndex, getEntityPersisters()[persisterIndex], null, resultSet, session
 		);
 		return keyToRead.equals( currentRowKey );
 	}
 
 	/**
 	 * Loads a single logical row from the result set moving forward.  This is the
 	 * processing used from the ScrollableResults where there were collection fetches
 	 * encountered; thus a single logical row may have multiple rows in the underlying
 	 * result set.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
+	 *
 	 * @return The loaded "row".
+	 *
 	 * @throws HibernateException
 	 */
 	public Object loadSequentialRowsForward(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies) throws HibernateException {
 
 		// note that for sequential scrolling, we make the assumption that
 		// the first persister element is the "root entity"
 
 		try {
 			if ( resultSet.isAfterLast() ) {
 				// don't even bother trying to read further
 				return null;
 			}
 
 			if ( resultSet.isBeforeFirst() ) {
 				resultSet.next();
 			}
 
 			// We call getKeyFromResultSet() here so that we can know the
 			// key value upon which to perform the breaking logic.  However,
 			// it is also then called from getRowFromResultSet() which is certainly
 			// not the most efficient.  But the call here is needed, and there
 			// currently is no other way without refactoring of the doQuery()/getRowFromResultSet()
 			// methods
 			final EntityKey currentKey = getKeyFromResultSet(
 					0,
 					getEntityPersisters()[0],
 					null,
 					resultSet,
 					session
-				);
+			);
 
 			return sequentialLoad( resultSet, session, queryParameters, returnProxies, currentKey );
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not perform sequential read of results (forward)",
 					getSQLString()
-				);
+			);
 		}
 	}
 
 	/**
 	 * Loads a single logical row from the result set moving forward.  This is the
 	 * processing used from the ScrollableResults where there were collection fetches
 	 * encountered; thus a single logical row may have multiple rows in the underlying
 	 * result set.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
+	 *
 	 * @return The loaded "row".
+	 *
 	 * @throws HibernateException
 	 */
 	public Object loadSequentialRowsReverse(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final boolean isLogicallyAfterLast) throws HibernateException {
 
 		// note that for sequential scrolling, we make the assumption that
 		// the first persister element is the "root entity"
 
 		try {
 			if ( resultSet.isFirst() ) {
 				// don't even bother trying to read any further
 				return null;
 			}
 
 			EntityKey keyToRead = null;
 			// This check is needed since processing leaves the cursor
 			// after the last physical row for the current logical row;
 			// thus if we are after the last physical row, this might be
 			// caused by either:
 			//      1) scrolling to the last logical row
 			//      2) scrolling past the last logical row
 			// In the latter scenario, the previous logical row
 			// really is the last logical row.
 			//
 			// In all other cases, we should process back two
 			// logical records (the current logic row, plus the
 			// previous logical row).
 			if ( resultSet.isAfterLast() && isLogicallyAfterLast ) {
 				// position cursor to the last row
 				resultSet.last();
 				keyToRead = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
-					);
+				);
 			}
 			else {
 				// Since the result set cursor is always left at the first
 				// physical row after the "last processed", we need to jump
 				// back one position to get the key value we are interested
 				// in skipping
 				resultSet.previous();
 
 				// sequentially read the result set in reverse until we recognize
 				// a change in the key value.  At that point, we are pointed at
 				// the last physical sequential row for the logical row in which
 				// we are interested in processing
 				boolean firstPass = true;
 				final EntityKey lastKey = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
-					);
+				);
 				while ( resultSet.previous() ) {
 					EntityKey checkKey = getKeyFromResultSet(
 							0,
 							getEntityPersisters()[0],
 							null,
 							resultSet,
 							session
-						);
+					);
 
 					if ( firstPass ) {
 						firstPass = false;
 						keyToRead = checkKey;
 					}
 
 					if ( !lastKey.equals( checkKey ) ) {
 						break;
 					}
 				}
 
 			}
 
 			// Read backwards until we read past the first physical sequential
 			// row with the key we are interested in loading
 			while ( resultSet.previous() ) {
 				EntityKey checkKey = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
-					);
+				);
 
 				if ( !keyToRead.equals( checkKey ) ) {
 					break;
 				}
 			}
 
 			// Finally, read ahead one row to position result set cursor
 			// at the first physical row we are interested in loading
 			resultSet.next();
 
 			// and doAfterTransactionCompletion the load
 			return sequentialLoad( resultSet, session, queryParameters, returnProxies, keyToRead );
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not doAfterTransactionCompletion sequential read of results (forward)",
 					getSQLString()
-				);
+			);
 		}
 	}
 
 	private static EntityKey getOptionalObjectKey(QueryParameters queryParameters, SessionImplementor session) {
 		final Object optionalObject = queryParameters.getOptionalObject();
 		final Serializable optionalId = queryParameters.getOptionalId();
 		final String optionalEntityName = queryParameters.getOptionalEntityName();
 
 		if ( optionalObject != null && optionalEntityName != null ) {
-			return session.generateEntityKey( optionalId, session.getEntityPersister( optionalEntityName, optionalObject ) );
+			return session.generateEntityKey(
+					optionalId, session.getEntityPersister(
+							optionalEntityName,
+							optionalObject
+					)
+			);
 		}
 		else {
 			return null;
 		}
 
 	}
 
 	private Object getRowFromResultSet(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final LockMode[] lockModesArray,
 			final EntityKey optionalObjectKey,
 			final List hydratedObjects,
 			final EntityKey[] keys,
 			boolean returnProxies) throws SQLException, HibernateException {
 		return getRowFromResultSet(
 				resultSet,
 				session,
 				queryParameters,
 				lockModesArray,
 				optionalObjectKey,
 				hydratedObjects,
 				keys,
 				returnProxies,
 				null
 		);
 	}
 
 	private Object getRowFromResultSet(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final LockMode[] lockModesArray,
 			final EntityKey optionalObjectKey,
 			final List hydratedObjects,
 			final EntityKey[] keys,
 			boolean returnProxies,
 			ResultTransformer forcedResultTransformer) throws SQLException, HibernateException {
 		final Loadable[] persisters = getEntityPersisters();
 		final int entitySpan = persisters.length;
-		extractKeysFromResultSet( persisters, queryParameters, resultSet, session, keys, lockModesArray, hydratedObjects );
+		extractKeysFromResultSet(
+				persisters,
+				queryParameters,
+				resultSet,
+				session,
+				keys,
+				lockModesArray,
+				hydratedObjects
+		);
 
 		registerNonExists( keys, persisters, session );
 
 		// this call is side-effecty
 		Object[] row = getRow(
 				resultSet,
 				persisters,
 				keys,
 				queryParameters.getOptionalObject(),
 				optionalObjectKey,
 				lockModesArray,
 				hydratedObjects,
 				session
 		);
 
 		readCollectionElements( row, resultSet, session );
 
 		if ( returnProxies ) {
 			// now get an existing proxy for each row element (if there is one)
 			for ( int i = 0; i < entitySpan; i++ ) {
 				Object entity = row[i];
 				Object proxy = session.getPersistenceContext().proxyFor( persisters[i], keys[i], entity );
 				if ( entity != proxy ) {
 					// force the proxy to resolve itself
-					( (HibernateProxy) proxy ).getHibernateLazyInitializer().setImplementation(entity);
+					( (HibernateProxy) proxy ).getHibernateLazyInitializer().setImplementation( entity );
 					row[i] = proxy;
 				}
 			}
 		}
 
 		applyPostLoadLocks( row, lockModesArray, session );
 
 		return forcedResultTransformer == null
 				? getResultColumnOrRow( row, queryParameters.getResultTransformer(), resultSet, session )
-				: forcedResultTransformer.transformTuple( getResultRow( row, resultSet, session ), getResultRowAliases() )
-		;
+				: forcedResultTransformer.transformTuple(
+				getResultRow( row, resultSet, session ),
+				getResultRowAliases()
+		)
+				;
 	}
 
 	protected void extractKeysFromResultSet(
 			Loadable[] persisters,
 			QueryParameters queryParameters,
 			ResultSet resultSet,
 			SessionImplementor session,
 			EntityKey[] keys,
 			LockMode[] lockModes,
 			List hydratedObjects) throws SQLException {
 		final int entitySpan = persisters.length;
 
 		final int numberOfPersistersToProcess;
 		final Serializable optionalId = queryParameters.getOptionalId();
 		if ( isSingleRowLoader() && optionalId != null ) {
-			keys[ entitySpan - 1 ] = session.generateEntityKey( optionalId, persisters[ entitySpan - 1 ] );
+			keys[entitySpan - 1] = session.generateEntityKey( optionalId, persisters[entitySpan - 1] );
 			// skip the last persister below...
 			numberOfPersistersToProcess = entitySpan - 1;
 		}
 		else {
 			numberOfPersistersToProcess = entitySpan;
 		}
 
 		final Object[] hydratedKeyState = new Object[numberOfPersistersToProcess];
 
 		for ( int i = 0; i < numberOfPersistersToProcess; i++ ) {
 			final Type idType = persisters[i].getIdentifierType();
-			hydratedKeyState[i] = idType.hydrate( resultSet, getEntityAliases()[i].getSuffixedKeyAliases(), session, null );
+			hydratedKeyState[i] = idType.hydrate(
+					resultSet,
+					getEntityAliases()[i].getSuffixedKeyAliases(),
+					session,
+					null
+			);
 		}
 
 		for ( int i = 0; i < numberOfPersistersToProcess; i++ ) {
 			final Type idType = persisters[i].getIdentifierType();
 			if ( idType.isComponentType() && getCompositeKeyManyToOneTargetIndices() != null ) {
 				// we may need to force resolve any key-many-to-one(s)
 				int[] keyManyToOneTargetIndices = getCompositeKeyManyToOneTargetIndices()[i];
 				// todo : better solution is to order the index processing based on target indices
 				//		that would account for multiple levels whereas this scheme does not
 				if ( keyManyToOneTargetIndices != null ) {
 					for ( int targetIndex : keyManyToOneTargetIndices ) {
 						if ( targetIndex < numberOfPersistersToProcess ) {
 							final Type targetIdType = persisters[targetIndex].getIdentifierType();
 							final Serializable targetId = (Serializable) targetIdType.resolve(
 									hydratedKeyState[targetIndex],
 									session,
 									null
 							);
 							// todo : need a way to signal that this key is resolved and its data resolved
 							keys[targetIndex] = session.generateEntityKey( targetId, persisters[targetIndex] );
 						}
 
 						// this part copied from #getRow, this section could be refactored out
 						Object object = session.getEntityUsingInterceptor( keys[targetIndex] );
 						if ( object != null ) {
 							//its already loaded so don't need to hydrate it
 							instanceAlreadyLoaded(
 									resultSet,
 									targetIndex,
 									persisters[targetIndex],
 									keys[targetIndex],
 									object,
 									lockModes[targetIndex],
 									session
 							);
 						}
 						else {
 							instanceNotYetLoaded(
 									resultSet,
 									targetIndex,
 									persisters[targetIndex],
 									getEntityAliases()[targetIndex].getRowIdAlias(),
 									keys[targetIndex],
 									lockModes[targetIndex],
 									getOptionalObjectKey( queryParameters, session ),
 									queryParameters.getOptionalObject(),
 									hydratedObjects,
 									session
 							);
 						}
 					}
 				}
 			}
 			final Serializable resolvedId = (Serializable) idType.resolve( hydratedKeyState[i], session, null );
 			keys[i] = resolvedId == null ? null : session.generateEntityKey( resolvedId, persisters[i] );
 		}
 	}
 
 	protected void applyPostLoadLocks(Object[] row, LockMode[] lockModesArray, SessionImplementor session) {
 	}
 
 	/**
 	 * Read any collection elements contained in a single row of the result set
 	 */
 	private void readCollectionElements(Object[] row, ResultSet resultSet, SessionImplementor session)
 			throws SQLException, HibernateException {
 
 		//TODO: make this handle multiple collection roles!
 
 		final CollectionPersister[] collectionPersisters = getCollectionPersisters();
 		if ( collectionPersisters != null ) {
 
 			final CollectionAliases[] descriptors = getCollectionAliases();
 			final int[] collectionOwners = getCollectionOwners();
 
-			for ( int i=0; i<collectionPersisters.length; i++ ) {
+			for ( int i = 0; i < collectionPersisters.length; i++ ) {
 
-				final boolean hasCollectionOwners = collectionOwners !=null &&
+				final boolean hasCollectionOwners = collectionOwners != null &&
 						collectionOwners[i] > -1;
 				//true if this is a query and we are loading multiple instances of the same collection role
 				//otherwise this is a CollectionInitializer and we are loading up a single collection or batch
 
 				final Object owner = hasCollectionOwners ?
-						row[ collectionOwners[i] ] :
+						row[collectionOwners[i]] :
 						null; //if null, owner will be retrieved from session
 
 				final CollectionPersister collectionPersister = collectionPersisters[i];
 				final Serializable key;
 				if ( owner == null ) {
 					key = null;
 				}
 				else {
 					key = collectionPersister.getCollectionType().getKeyOfOwner( owner, session );
 					//TODO: old version did not require hashmap lookup:
 					//keys[collectionOwner].getIdentifier()
 				}
 
 				readCollectionElement(
 						owner,
 						key,
 						collectionPersister,
 						descriptors[i],
 						resultSet,
 						session
-					);
+				);
 
 			}
 
 		}
 	}
 
 	private List doQuery(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final ResultTransformer forcedResultTransformer) throws SQLException, HibernateException {
 
 		final RowSelection selection = queryParameters.getRowSelection();
 		final int maxRows = LimitHelper.hasMaxRows( selection ) ?
 				selection.getMaxRows() :
 				Integer.MAX_VALUE;
 
 		final List<AfterLoadAction> afterLoadActions = new ArrayList<AfterLoadAction>();
 
 		final SqlStatementWrapper wrapper = executeQueryStatement( queryParameters, false, afterLoadActions, session );
 		final ResultSet rs = wrapper.getResultSet();
 		final Statement st = wrapper.getStatement();
 
 // would be great to move all this below here into another method that could also be used
 // from the new scrolling stuff.
 //
 // Would need to change the way the max-row stuff is handled (i.e. behind an interface) so
 // that I could do the control breaking at the means to know when to stop
 
 		try {
-			return processResultSet( rs, queryParameters, session, returnProxies, forcedResultTransformer, maxRows, afterLoadActions );
+			return processResultSet(
+					rs,
+					queryParameters,
+					session,
+					returnProxies,
+					forcedResultTransformer,
+					maxRows,
+					afterLoadActions
+			);
 		}
 		finally {
 			session.getJdbcCoordinator().getResourceRegistry().release( st );
 			session.getJdbcCoordinator().afterStatementExecution();
 		}
 
 	}
 
 	protected List processResultSet(
 			ResultSet rs,
 			QueryParameters queryParameters,
 			SessionImplementor session,
 			boolean returnProxies,
 			ResultTransformer forcedResultTransformer,
 			int maxRows,
 			List<AfterLoadAction> afterLoadActions) throws SQLException {
 		final int entitySpan = getEntityPersisters().length;
 		final EntityKey optionalObjectKey = getOptionalObjectKey( queryParameters, session );
 		final LockMode[] lockModesArray = getLockModes( queryParameters.getLockOptions() );
 		final boolean createSubselects = isSubselectLoadingEnabled();
 		final List subselectResultKeys = createSubselects ? new ArrayList() : null;
 		final ArrayList hydratedObjects = entitySpan == 0 ? null : new ArrayList( entitySpan * 10 );
 		final List results = new ArrayList();
 
 		handleEmptyCollections( queryParameters.getCollectionKeys(), rs, session );
 		EntityKey[] keys = new EntityKey[entitySpan]; //we can reuse it for each row
 		LOG.trace( "Processing result set" );
 		int count;
 
 		for ( count = 0; count < maxRows && rs.next(); count++ ) {
 			if ( DEBUG_ENABLED ) {
 				LOG.debugf( "Result set row: %s", count );
 			}
 			Object result = getRowFromResultSet(
 					rs,
 					session,
 					queryParameters,
 					lockModesArray,
 					optionalObjectKey,
 					hydratedObjects,
 					keys,
 					returnProxies,
 					forcedResultTransformer
 			);
 			results.add( result );
 			if ( createSubselects ) {
-				subselectResultKeys.add(keys);
+				subselectResultKeys.add( keys );
 				keys = new EntityKey[entitySpan]; //can't reuse in this case
 			}
 		}
 
 		LOG.tracev( "Done processing result set ({0} rows)", count );
 
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				rs,
 				session,
 				queryParameters.isReadOnly( session ),
 				afterLoadActions
 		);
 		if ( createSubselects ) {
 			createSubselects( subselectResultKeys, queryParameters, session );
 		}
 		return results;
 	}
 
 	protected boolean isSubselectLoadingEnabled() {
 		return false;
 	}
 
 	protected boolean hasSubselectLoadableCollections() {
 		final Loadable[] loadables = getEntityPersisters();
 		for ( Loadable loadable : loadables ) {
 			if ( loadable.hasSubselectLoadableCollections() ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
-	private static Set[] transpose( List keys ) {
-		Set[] result = new Set[ ( ( EntityKey[] ) keys.get(0) ).length ];
-		for ( int j=0; j<result.length; j++ ) {
+	private static Set[] transpose(List keys) {
+		Set[] result = new Set[( (EntityKey[]) keys.get( 0 ) ).length];
+		for ( int j = 0; j < result.length; j++ ) {
 			result[j] = new HashSet( keys.size() );
 			for ( Object key : keys ) {
 				result[j].add( ( (EntityKey[]) key )[j] );
 			}
 		}
 		return result;
 	}
 
 	private void createSubselects(List keys, QueryParameters queryParameters, SessionImplementor session) {
 		if ( keys.size() > 1 ) { //if we only returned one entity, query by key is more efficient
 
-			Set[] keySets = transpose(keys);
+			Set[] keySets = transpose( keys );
 
 			Map namedParameterLocMap = buildNamedParameterLocMap( queryParameters );
 
 			final Loadable[] loadables = getEntityPersisters();
 			final String[] aliases = getAliases();
 			for ( Object key : keys ) {
 				final EntityKey[] rowKeys = (EntityKey[]) key;
 				for ( int i = 0; i < rowKeys.length; i++ ) {
 
 					if ( rowKeys[i] != null && loadables[i].hasSubselectLoadableCollections() ) {
 
 						SubselectFetch subselectFetch = new SubselectFetch(
 								//getSQLString(),
 								aliases[i],
 								loadables[i],
 								queryParameters,
 								keySets[i],
 								namedParameterLocMap
 						);
 
 						session.getPersistenceContext()
 								.getBatchFetchQueue()
 								.addSubselect( rowKeys[i], subselectFetch );
 					}
 
 				}
 
 			}
 		}
 	}
 
 	private Map buildNamedParameterLocMap(QueryParameters queryParameters) {
-		if ( queryParameters.getNamedParameters()!=null ) {
+		if ( queryParameters.getNamedParameters() != null ) {
 			final Map namedParameterLocMap = new HashMap();
-			for(String name : queryParameters.getNamedParameters().keySet()){
+			for ( String name : queryParameters.getNamedParameters().keySet() ) {
 				namedParameterLocMap.put(
 						name,
-						getNamedParameterLocs(name)
+						getNamedParameterLocs( name )
 				);
 			}
 			return namedParameterLocMap;
 		}
 		else {
 			return null;
 		}
 	}
 
 	private void initializeEntitiesAndCollections(
 			final List hydratedObjects,
 			final Object resultSetId,
 			final SessionImplementor session,
 			final boolean readOnly) throws HibernateException {
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				resultSetId,
 				session,
 				readOnly,
 				Collections.<AfterLoadAction>emptyList()
 		);
 	}
 
 	private void initializeEntitiesAndCollections(
 			final List hydratedObjects,
 			final Object resultSetId,
 			final SessionImplementor session,
 			final boolean readOnly,
 			List<AfterLoadAction> afterLoadActions) throws HibernateException {
 
 		final CollectionPersister[] collectionPersisters = getCollectionPersisters();
 		if ( collectionPersisters != null ) {
 			for ( CollectionPersister collectionPersister : collectionPersisters ) {
 				if ( collectionPersister.isArray() ) {
 					//for arrays, we should end the collection load before resolving
 					//the entities, since the actual array instances are not instantiated
 					//during loading
 					//TODO: or we could do this polymorphically, and have two
 					//      different operations implemented differently for arrays
 					endCollectionLoad( resultSetId, session, collectionPersister );
 				}
 			}
 		}
 
 		//important: reuse the same event instances for performance!
 		final PreLoadEvent pre;
 		final PostLoadEvent post;
 		if ( session.isEventSource() ) {
 			pre = new PreLoadEvent( (EventSource) session );
 			post = new PostLoadEvent( (EventSource) session );
 		}
 		else {
 			pre = null;
 			post = null;
 		}
 
-		if ( hydratedObjects!=null ) {
+		if ( hydratedObjects != null ) {
 			int hydratedObjectsSize = hydratedObjects.size();
 			LOG.tracev( "Total objects hydrated: {0}", hydratedObjectsSize );
 			for ( Object hydratedObject : hydratedObjects ) {
 				TwoPhaseLoad.initializeEntity( hydratedObject, readOnly, session, pre );
 			}
 		}
 
 		if ( collectionPersisters != null ) {
 			for ( CollectionPersister collectionPersister : collectionPersisters ) {
 				if ( !collectionPersister.isArray() ) {
 					//for sets, we should end the collection load after resolving
 					//the entities, since we might call hashCode() on the elements
 					//TODO: or we could do this polymorphically, and have two
 					//      different operations implemented differently for arrays
 					endCollectionLoad( resultSetId, session, collectionPersister );
 				}
 			}
 		}
-		
+
 		// Until this entire method is refactored w/ polymorphism, postLoad was
 		// split off from initializeEntity.  It *must* occur after
 		// endCollectionLoad to ensure the collection is in the
 		// persistence context.
 		if ( hydratedObjects != null ) {
 			for ( Object hydratedObject : hydratedObjects ) {
 				TwoPhaseLoad.postLoad( hydratedObject, session, post );
 				if ( afterLoadActions != null ) {
 					for ( AfterLoadAction afterLoadAction : afterLoadActions ) {
 						final EntityEntry entityEntry = session.getPersistenceContext().getEntry( hydratedObject );
 						if ( entityEntry == null ) {
 							// big problem
-							throw new HibernateException( "Could not locate EntityEntry immediately after two-phase load" );
+							throw new HibernateException(
+									"Could not locate EntityEntry immediately after two-phase load"
+							);
 						}
 						afterLoadAction.afterLoad( session, hydratedObject, (Loadable) entityEntry.getPersister() );
 					}
 				}
 			}
 		}
 	}
 
 	private void endCollectionLoad(
 			final Object resultSetId,
 			final SessionImplementor session,
 			final CollectionPersister collectionPersister) {
 		//this is a query and we are loading multiple instances of the same collection role
 		session.getPersistenceContext()
 				.getLoadContexts()
-				.getCollectionLoadContext( ( ResultSet ) resultSetId )
+				.getCollectionLoadContext( (ResultSet) resultSetId )
 				.endLoadingCollections( collectionPersister );
 	}
 
 	/**
 	 * Determine the actual ResultTransformer that will be used to
 	 * transform query results.
 	 *
 	 * @param resultTransformer the specified result transformer
+	 *
 	 * @return the actual result transformer
 	 */
 	protected ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer) {
 		return resultTransformer;
 	}
 
 	protected List getResultList(List results, ResultTransformer resultTransformer) throws QueryException {
 		return results;
 	}
 
 	/**
 	 * Are rows transformed immediately after being read from the ResultSet?
+	 *
 	 * @return true, if getResultColumnOrRow() transforms the results; false, otherwise
 	 */
 	protected boolean areResultSetRowsTransformedImmediately() {
 		return false;
 	}
 
 	/**
 	 * Returns the aliases that corresponding to a result row.
+	 *
 	 * @return Returns the aliases that corresponding to a result row.
 	 */
 	protected String[] getResultRowAliases() {
-		 return null;
+		return null;
 	}
 
 	/**
 	 * Get the actual object that is returned in the user-visible result list.
 	 * This empty implementation merely returns its first argument. This is
 	 * overridden by some subclasses.
 	 */
 	protected Object getResultColumnOrRow(
 			Object[] row,
 			ResultTransformer transformer,
 			ResultSet rs,
 			SessionImplementor session) throws SQLException, HibernateException {
 		return row;
 	}
 
 	protected boolean[] includeInResultRow() {
 		return null;
 	}
 
 	protected Object[] getResultRow(
 			Object[] row,
 			ResultSet rs,
 			SessionImplementor session) throws SQLException, HibernateException {
 		return row;
 	}
 
 	/**
 	 * For missing objects associated by one-to-one with another object in the
 	 * result set, register the fact that the the object is missing with the
 	 * session.
 	 */
 	private void registerNonExists(
 			final EntityKey[] keys,
 			final Loadable[] persisters,
 			final SessionImplementor session) {
 
 		final int[] owners = getOwners();
 		if ( owners != null ) {
 
 			EntityType[] ownerAssociationTypes = getOwnerAssociationTypes();
 			for ( int i = 0; i < keys.length; i++ ) {
 
 				int owner = owners[i];
 				if ( owner > -1 ) {
 					EntityKey ownerKey = keys[owner];
 					if ( keys[i] == null && ownerKey != null ) {
 
 						final PersistenceContext persistenceContext = session.getPersistenceContext();
 
 						/*final boolean isPrimaryKey;
 						final boolean isSpecialOneToOne;
 						if ( ownerAssociationTypes == null || ownerAssociationTypes[i] == null ) {
 							isPrimaryKey = true;
 							isSpecialOneToOne = false;
 						}
 						else {
 							isPrimaryKey = ownerAssociationTypes[i].getRHSUniqueKeyPropertyName()==null;
 							isSpecialOneToOne = ownerAssociationTypes[i].getLHSPropertyName()!=null;
 						}*/
 
 						//TODO: can we *always* use the "null property" approach for everything?
 						/*if ( isPrimaryKey && !isSpecialOneToOne ) {
 							persistenceContext.addNonExistantEntityKey(
 									new EntityKey( ownerKey.getIdentifier(), persisters[i], session.getEntityMode() )
 							);
 						}
 						else if ( isSpecialOneToOne ) {*/
-						boolean isOneToOneAssociation = ownerAssociationTypes!=null &&
-								ownerAssociationTypes[i]!=null &&
+						boolean isOneToOneAssociation = ownerAssociationTypes != null &&
+								ownerAssociationTypes[i] != null &&
 								ownerAssociationTypes[i].isOneToOne();
 						if ( isOneToOneAssociation ) {
-							persistenceContext.addNullProperty( ownerKey,
-									ownerAssociationTypes[i].getPropertyName() );
+							persistenceContext.addNullProperty(
+									ownerKey,
+									ownerAssociationTypes[i].getPropertyName()
+							);
 						}
 						/*}
 						else {
 							persistenceContext.addNonExistantEntityUniqueKey( new EntityUniqueKey(
 									persisters[i].getEntityName(),
 									ownerAssociationTypes[i].getRHSUniqueKeyPropertyName(),
 									ownerKey.getIdentifier(),
 									persisters[owner].getIdentifierType(),
 									session.getEntityMode()
 							) );
 						}*/
 					}
 				}
 			}
 		}
 	}
 
 	/**
 	 * Read one collection element from the current row of the JDBC result set
 	 */
 	private void readCollectionElement(
 			final Object optionalOwner,
 			final Serializable optionalKey,
 			final CollectionPersister persister,
 			final CollectionAliases descriptor,
 			final ResultSet rs,
 			final SessionImplementor session)
-	throws HibernateException, SQLException {
+			throws HibernateException, SQLException {
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 
 		final Serializable collectionRowKey = (Serializable) persister.readKey(
 				rs,
 				descriptor.getSuffixedKeyAliases(),
 				session
-			);
+		);
 
 		if ( collectionRowKey != null ) {
 			// we found a collection element in the result set
 
 			if ( LOG.isDebugEnabled() ) {
-				LOG.debugf( "Found row of collection: %s",
-						MessageHelper.collectionInfoString( persister, collectionRowKey, getFactory() ) );
+				LOG.debugf(
+						"Found row of collection: %s",
+						MessageHelper.collectionInfoString( persister, collectionRowKey, getFactory() )
+				);
 			}
 
 			Object owner = optionalOwner;
 			if ( owner == null ) {
 				owner = persistenceContext.getCollectionOwner( collectionRowKey, persister );
 				if ( owner == null ) {
 					//TODO: This is assertion is disabled because there is a bug that means the
 					//	  original owner of a transient, uninitialized collection is not known
 					//	  if the collection is re-referenced by a different object associated
 					//	  with the current Session
 					//throw new AssertionFailure("bug loading unowned collection");
 				}
 			}
 
 			PersistentCollection rowCollection = persistenceContext.getLoadContexts()
 					.getCollectionLoadContext( rs )
 					.getLoadingCollection( persister, collectionRowKey );
 
 			if ( rowCollection != null ) {
 				rowCollection.readFrom( rs, persister, descriptor, owner );
 			}
 
 		}
 		else if ( optionalKey != null ) {
 			// we did not find a collection element in the result set, so we
 			// ensure that a collection is created with the owner's identifier,
 			// since what we have is an empty collection
 
 			if ( LOG.isDebugEnabled() ) {
-				LOG.debugf( "Result set contains (possibly empty) collection: %s",
-						MessageHelper.collectionInfoString( persister, optionalKey, getFactory() ) );
+				LOG.debugf(
+						"Result set contains (possibly empty) collection: %s",
+						MessageHelper.collectionInfoString( persister, optionalKey, getFactory() )
+				);
 			}
 
 			persistenceContext.getLoadContexts()
 					.getCollectionLoadContext( rs )
 					.getLoadingCollection( persister, optionalKey ); // handle empty collection
 
 		}
 
 		// else no collection element, but also no owner
 
 	}
 
 	/**
 	 * If this is a collection initializer, we need to tell the session that a collection
 	 * is being initialized, to account for the possibility of the collection having
 	 * no elements (hence no rows in the result set).
 	 */
 	private void handleEmptyCollections(
 			final Serializable[] keys,
 			final Object resultSetId,
 			final SessionImplementor session) {
 
 		if ( keys != null ) {
 			final boolean debugEnabled = LOG.isDebugEnabled();
 			// this is a collection initializer, so we must create a collection
 			// for each of the passed-in keys, to account for the possibility
 			// that the collection is empty and has no rows in the result set
 			CollectionPersister[] collectionPersisters = getCollectionPersisters();
-			for ( CollectionPersister collectionPersister : collectionPersisters )
+			for ( CollectionPersister collectionPersister : collectionPersisters ) {
 				for ( Serializable key : keys ) {
 					//handle empty collections
 					if ( debugEnabled ) {
 						LOG.debugf(
 								"Result set contains (possibly empty) collection: %s",
 								MessageHelper.collectionInfoString( collectionPersister, key, getFactory() )
 						);
 					}
 
 					session.getPersistenceContext()
 							.getLoadContexts()
 							.getCollectionLoadContext( (ResultSet) resultSetId )
 							.getLoadingCollection( collectionPersister, key );
 				}
+			}
 		}
 
 		// else this is not a collection initializer (and empty collections will
 		// be detected by looking for the owner's identifier in the result set)
 	}
 
 	/**
 	 * Read a row of <tt>Key</tt>s from the <tt>ResultSet</tt> into the given array.
 	 * Warning: this method is side-effecty.
 	 * <p/>
 	 * If an <tt>id</tt> is given, don't bother going to the <tt>ResultSet</tt>.
 	 */
 	private EntityKey getKeyFromResultSet(
 			final int i,
 			final Loadable persister,
 			final Serializable id,
 			final ResultSet rs,
 			final SessionImplementor session) throws HibernateException, SQLException {
 
 		Serializable resultId;
 
 		// if we know there is exactly 1 row, we can skip.
 		// it would be great if we could _always_ skip this;
 		// it is a problem for <key-many-to-one>
 
 		if ( isSingleRowLoader() && id != null ) {
 			resultId = id;
 		}
 		else {
 			final Type idType = persister.getIdentifierType();
 			resultId = (Serializable) idType.nullSafeGet(
 					rs,
 					getEntityAliases()[i].getSuffixedKeyAliases(),
 					session,
 					null //problematic for <key-many-to-one>!
 			);
 
 			final boolean idIsResultId = id != null &&
 					resultId != null &&
 					idType.isEqual( id, resultId, factory );
 
 			if ( idIsResultId ) {
 				resultId = id; //use the id passed in
 			}
 		}
 
 		return resultId == null ? null : session.generateEntityKey( resultId, persister );
 	}
 
 	/**
 	 * Check the version of the object in the <tt>ResultSet</tt> against
 	 * the object version in the session cache, throwing an exception
 	 * if the version numbers are different
 	 */
 	private void checkVersion(
 			final int i,
 			final Loadable persister,
 			final Serializable id,
 			final Object entity,
 			final ResultSet rs,
 			final SessionImplementor session) throws HibernateException, SQLException {
 
 		Object version = session.getPersistenceContext().getEntry( entity ).getVersion();
 
 		if ( version != null ) { //null version means the object is in the process of being loaded somewhere else in the ResultSet
 			final VersionType versionType = persister.getVersionType();
 			final Object currentVersion = versionType.nullSafeGet(
 					rs,
 					getEntityAliases()[i].getSuffixedVersionAliases(),
 					session,
 					null
 			);
-			if ( !versionType.isEqual(version, currentVersion) ) {
+			if ( !versionType.isEqual( version, currentVersion ) ) {
 				if ( session.getFactory().getStatistics().isStatisticsEnabled() ) {
 					session.getFactory().getStatisticsImplementor()
 							.optimisticFailure( persister.getEntityName() );
 				}
 				throw new StaleObjectStateException( persister.getEntityName(), id );
 			}
 		}
 
 	}
 
 	/**
 	 * Resolve any IDs for currently loaded objects, duplications within the
 	 * <tt>ResultSet</tt>, etc. Instantiate empty objects to be initialized from the
 	 * <tt>ResultSet</tt>. Return an array of objects (a row of results) and an
 	 * array of booleans (by side-effect) that determine whether the corresponding
 	 * object should be initialized.
 	 */
 	private Object[] getRow(
 			final ResultSet rs,
 			final Loadable[] persisters,
 			final EntityKey[] keys,
 			final Object optionalObject,
 			final EntityKey optionalObjectKey,
 			final LockMode[] lockModes,
 			final List hydratedObjects,
 			final SessionImplementor session) throws HibernateException, SQLException {
 		final int cols = persisters.length;
 		final EntityAliases[] descriptors = getEntityAliases();
 
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "Result row: %s", StringHelper.toString( keys ) );
 		}
 
 		final Object[] rowResults = new Object[cols];
 
 		for ( int i = 0; i < cols; i++ ) {
 
 			Object object = null;
 			EntityKey key = keys[i];
 
 			if ( keys[i] == null ) {
 				//do nothing
 			}
 			else {
 				//If the object is already loaded, return the loaded one
 				object = session.getEntityUsingInterceptor( key );
 				if ( object != null ) {
 					//its already loaded so don't need to hydrate it
 					instanceAlreadyLoaded(
 							rs,
 							i,
 							persisters[i],
 							key,
 							object,
 							lockModes[i],
 							session
 					);
 				}
 				else {
 					object = instanceNotYetLoaded(
 							rs,
 							i,
 							persisters[i],
 							descriptors[i].getRowIdAlias(),
 							key,
 							lockModes[i],
 							optionalObjectKey,
 							optionalObject,
 							hydratedObjects,
 							session
 					);
 				}
 			}
 
 			rowResults[i] = object;
 
 		}
 
 		return rowResults;
 	}
 
 	/**
 	 * The entity instance is already in the session cache
 	 */
 	private void instanceAlreadyLoaded(
 			final ResultSet rs,
 			final int i,
 			final Loadable persister,
 			final EntityKey key,
 			final Object object,
 			final LockMode requestedLockMode,
 			final SessionImplementor session)
 			throws HibernateException, SQLException {
 		if ( !persister.isInstance( object ) ) {
 			throw new WrongClassException(
 					"loaded object was of wrong class " + object.getClass(),
 					key.getIdentifier(),
 					persister.getEntityName()
 			);
 		}
 
 		if ( LockMode.NONE != requestedLockMode && upgradeLocks() ) { //no point doing this if NONE was requested
 			final EntityEntry entry = session.getPersistenceContext().getEntry( object );
 			if ( entry.getLockMode().lessThan( requestedLockMode ) ) {
 				//we only check the version when _upgrading_ lock modes
 				if ( persister.isVersioned() ) {
 					checkVersion( i, persister, key.getIdentifier(), object, rs, session );
 				}
 				//we need to upgrade the lock mode to the mode requested
 				entry.setLockMode( requestedLockMode );
 			}
 		}
 	}
 
 
 	/**
 	 * The entity instance is not in the session cache
 	 */
 	private Object instanceNotYetLoaded(
 			final ResultSet rs,
 			final int i,
 			final Loadable persister,
 			final String rowIdAlias,
 			final EntityKey key,
 			final LockMode lockMode,
 			final EntityKey optionalObjectKey,
 			final Object optionalObject,
 			final List hydratedObjects,
 			final SessionImplementor session)
-	throws HibernateException, SQLException {
+			throws HibernateException, SQLException {
 		final String instanceClass = getInstanceClass(
 				rs,
 				i,
 				persister,
 				key.getIdentifier(),
 				session
 		);
 
 		// see if the entity defines reference caching, and if so use the cached reference (if one).
 		if ( session.getCacheMode().isGetEnabled() && persister.canUseReferenceCacheEntries() ) {
 			final Object cachedEntry = CacheHelper.fromSharedCache(
 					session,
 					session.generateCacheKey(
 							key.getIdentifier(),
 							persister.getEntityMetamodel().getEntityType(),
 							key.getEntityName()
 					),
 					persister.getCacheAccessStrategy()
 			);
 			if ( cachedEntry != null ) {
 				CacheEntry entry = (CacheEntry) persister.getCacheEntryStructure().destructure( cachedEntry, factory );
 				return ( (ReferenceCacheEntryImpl) entry ).getReference();
 			}
 		}
 
 		final Object object;
 		if ( optionalObjectKey != null && key.equals( optionalObjectKey ) ) {
 			//its the given optional object
 			object = optionalObject;
 		}
 		else {
 			// instantiate a new instance
 			object = session.instantiate( instanceClass, key.getIdentifier() );
 		}
 
 		//need to hydrate it.
 
 		// grab its state from the ResultSet and keep it in the Session
 		// (but don't yet initialize the object itself)
 		// note that we acquire LockMode.READ even if it was not requested
 		LockMode acquiredLockMode = lockMode == LockMode.NONE ? LockMode.READ : lockMode;
 		loadFromResultSet(
 				rs,
 				i,
 				object,
 				instanceClass,
 				key,
 				rowIdAlias,
 				acquiredLockMode,
 				persister,
 				session
 		);
 
 		//materialize associations (and initialize the object) later
 		hydratedObjects.add( object );
 
 		return object;
 	}
 
 	private boolean isEagerPropertyFetchEnabled(int i) {
 		boolean[] array = getEntityEagerPropertyFetches();
-		return array!=null && array[i];
+		return array != null && array[i];
 	}
 
 
 	/**
 	 * Hydrate the state an object from the SQL <tt>ResultSet</tt>, into
 	 * an array or "hydrated" values (do not resolve associations yet),
 	 * and pass the hydrates state to the session.
 	 */
 	private void loadFromResultSet(
 			final ResultSet rs,
 			final int i,
 			final Object object,
 			final String instanceEntityName,
 			final EntityKey key,
 			final String rowIdAlias,
 			final LockMode lockMode,
 			final Loadable rootPersister,
 			final SessionImplementor session) throws SQLException, HibernateException {
 
 		final Serializable id = key.getIdentifier();
 
 		// Get the persister for the _subclass_
 		final Loadable persister = (Loadable) getFactory().getEntityPersister( instanceEntityName );
 
 		if ( LOG.isTraceEnabled() ) {
-			LOG.tracev( "Initializing object from ResultSet: {0}", MessageHelper.infoString( persister, id, getFactory() ) );
+			LOG.tracev(
+					"Initializing object from ResultSet: {0}", MessageHelper.infoString(
+							persister,
+							id,
+							getFactory()
+					)
+			);
 		}
 
-		boolean eagerPropertyFetch = isEagerPropertyFetchEnabled(i);
+		boolean eagerPropertyFetch = isEagerPropertyFetchEnabled( i );
 
 		// add temp entry so that the next step is circular-reference
 		// safe - only needed because some types don't take proper
 		// advantage of two-phase-load (esp. components)
 		TwoPhaseLoad.addUninitializedEntity(
 				key,
 				object,
 				persister,
 				lockMode,
 				!eagerPropertyFetch,
 				session
 		);
 
 		//This is not very nice (and quite slow):
 		final String[][] cols = persister == rootPersister ?
 				getEntityAliases()[i].getSuffixedPropertyAliases() :
-				getEntityAliases()[i].getSuffixedPropertyAliases(persister);
+				getEntityAliases()[i].getSuffixedPropertyAliases( persister );
 
 		final Object[] values = persister.hydrate(
 				rs,
 				id,
 				object,
 				rootPersister,
 				cols,
 				eagerPropertyFetch,
 				session
 		);
 
-		final Object rowId = persister.hasRowId() ? rs.getObject(rowIdAlias) : null;
+		final Object rowId = persister.hasRowId() ? rs.getObject( rowIdAlias ) : null;
 
 		final AssociationType[] ownerAssociationTypes = getOwnerAssociationTypes();
 		if ( ownerAssociationTypes != null && ownerAssociationTypes[i] != null ) {
 			String ukName = ownerAssociationTypes[i].getRHSUniqueKeyPropertyName();
-			if (ukName!=null) {
-				final int index = ( (UniqueKeyLoadable) persister ).getPropertyIndex(ukName);
+			if ( ukName != null ) {
+				final int index = ( (UniqueKeyLoadable) persister ).getPropertyIndex( ukName );
 				final Type type = persister.getPropertyTypes()[index];
 
 				// polymorphism not really handled completely correctly,
 				// perhaps...well, actually its ok, assuming that the
 				// entity name used in the lookup is the same as the
 				// the one used here, which it will be
 
 				EntityUniqueKey euk = new EntityUniqueKey(
 						rootPersister.getEntityName(), //polymorphism comment above
 						ukName,
 						type.semiResolve( values[index], session, object ),
 						type,
 						persister.getEntityMode(),
 						session.getFactory()
 				);
 				session.getPersistenceContext().addEntity( euk, object );
 			}
 		}
 
 		TwoPhaseLoad.postHydrate(
 				persister,
 				id,
 				values,
 				rowId,
 				object,
 				lockMode,
 				!eagerPropertyFetch,
 				session
 		);
 
 	}
 
 	/**
 	 * Determine the concrete class of an instance in the <tt>ResultSet</tt>
 	 */
 	private String getInstanceClass(
-	        final ResultSet rs,
-	        final int i,
-	        final Loadable persister,
-	        final Serializable id,
-	        final SessionImplementor session) throws HibernateException, SQLException {
+			final ResultSet rs,
+			final int i,
+			final Loadable persister,
+			final Serializable id,
+			final SessionImplementor session) throws HibernateException, SQLException {
 
 		if ( persister.hasSubclasses() ) {
 
 			// Code to handle subclasses of topClass
 			final Object discriminatorValue = persister.getDiscriminatorType().nullSafeGet(
 					rs,
 					getEntityAliases()[i].getSuffixedDiscriminatorAlias(),
 					session,
 					null
 			);
 
 			final String result = persister.getSubclassForDiscriminatorValue( discriminatorValue );
 
 			if ( result == null ) {
 				//woops we got an instance of another class hierarchy branch
 				throw new WrongClassException(
 						"Discriminator: " + discriminatorValue,
 						id,
 						persister.getEntityName()
-					);
+				);
 			}
 
 			return result;
 
 		}
 		else {
 			return persister.getEntityName();
 		}
 	}
 
 	/**
 	 * Advance the cursor to the first required row of the <tt>ResultSet</tt>
 	 */
 	private void advance(final ResultSet rs, final RowSelection selection) throws SQLException {
 
 		final int firstRow = LimitHelper.getFirstRow( selection );
 		if ( firstRow != 0 ) {
 			if ( getFactory().getSessionFactoryOptions().isScrollableResultSetsEnabled() ) {
 				// we can go straight to the first required row
 				rs.absolute( firstRow );
 			}
 			else {
 				// we need to step through the rows one row at a time (slow)
 				for ( int m = 0; m < firstRow; m++ ) {
 					rs.next();
 				}
 			}
 		}
 	}
 
 	/**
 	 * Build LIMIT clause handler applicable for given selection criteria. Returns {@link NoopLimitHandler} delegate
 	 * if dialect does not support LIMIT expression or processed query does not use pagination.
 	 *
 	 * @param selection Selection criteria.
+	 *
 	 * @return LIMIT clause delegate.
 	 */
 	protected LimitHandler getLimitHandler(RowSelection selection) {
 		final LimitHandler limitHandler = getFactory().getDialect().getLimitHandler();
 		return LimitHelper.useLimit( limitHandler, selection ) ? limitHandler : NoopLimitHandler.INSTANCE;
 	}
 
-	private ScrollMode getScrollMode(boolean scroll, boolean hasFirstRow, boolean useLimitOffSet, QueryParameters queryParameters) {
+	private ScrollMode getScrollMode(
+			boolean scroll,
+			boolean hasFirstRow,
+			boolean useLimitOffSet,
+			QueryParameters queryParameters) {
 		final boolean canScroll = getFactory().getSessionFactoryOptions().isScrollableResultSetsEnabled();
 		if ( canScroll ) {
 			if ( scroll ) {
 				return queryParameters.getScrollMode();
 			}
 			if ( hasFirstRow && !useLimitOffSet ) {
 				return ScrollMode.SCROLL_INSENSITIVE;
 			}
 		}
 		return null;
 	}
 
 	/**
 	 * Process query string by applying filters, LIMIT clause, locks and comments if necessary.
 	 * Finally execute SQL statement and advance to the first row.
 	 */
 	protected SqlStatementWrapper executeQueryStatement(
 			final QueryParameters queryParameters,
 			final boolean scroll,
 			List<AfterLoadAction> afterLoadActions,
 			final SessionImplementor session) throws SQLException {
 		return executeQueryStatement( getSQLString(), queryParameters, scroll, afterLoadActions, session );
 	}
 
 	protected SqlStatementWrapper executeQueryStatement(
 			String sqlStatement,
 			QueryParameters queryParameters,
 			boolean scroll,
 			List<AfterLoadAction> afterLoadActions,
 			SessionImplementor session) throws SQLException {
 
 		// Processing query filters.
 		queryParameters.processFilters( sqlStatement, session );
 
 		// Applying LIMIT clause.
 		final LimitHandler limitHandler = getLimitHandler(
 				queryParameters.getRowSelection()
 		);
 		String sql = limitHandler.processSql( queryParameters.getFilteredSQL(), queryParameters.getRowSelection() );
 
 		// Adding locks and comments.
 		sql = preprocessSQL( sql, queryParameters, getFactory().getDialect(), afterLoadActions );
 
 		final PreparedStatement st = prepareQueryStatement( sql, queryParameters, limitHandler, scroll, session );
-		return new SqlStatementWrapper( st, getResultSet( st, queryParameters.getRowSelection(), limitHandler, queryParameters.hasAutoDiscoverScalarTypes(), session ) );
+		return new SqlStatementWrapper(
+				st, getResultSet(
+				st,
+				queryParameters.getRowSelection(),
+				limitHandler,
+				queryParameters.hasAutoDiscoverScalarTypes(),
+				session
+		)
+		);
 	}
 
 	/**
 	 * Obtain a <tt>PreparedStatement</tt> with all parameters pre-bound.
 	 * Bind JDBC-style <tt>?</tt> parameters, named parameters, and
 	 * limit parameters.
 	 */
 	protected final PreparedStatement prepareQueryStatement(
-	        String sql,
-	        final QueryParameters queryParameters,
-	        final LimitHandler limitHandler,
-	        final boolean scroll,
-	        final SessionImplementor session) throws SQLException, HibernateException {
+			String sql,
+			final QueryParameters queryParameters,
+			final LimitHandler limitHandler,
+			final boolean scroll,
+			final SessionImplementor session) throws SQLException, HibernateException {
 		final Dialect dialect = getFactory().getDialect();
 		final RowSelection selection = queryParameters.getRowSelection();
 		final boolean useLimit = LimitHelper.useLimit( limitHandler, selection );
 		final boolean hasFirstRow = LimitHelper.hasFirstRow( selection );
 		final boolean useLimitOffset = hasFirstRow && useLimit && limitHandler.supportsLimitOffset();
 		final boolean callable = queryParameters.isCallable();
 		final ScrollMode scrollMode = getScrollMode( scroll, hasFirstRow, useLimitOffset, queryParameters );
-		
+
 		PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareQueryStatement(
 				sql,
 				callable,
 				scrollMode
 		);
 
 		try {
 
 			int col = 1;
 			//TODO: can we limit stored procedures ?!
 			col += limitHandler.bindLimitParametersAtStartOfQuery( selection, st, col );
 
-			if (callable) {
-				col = dialect.registerResultSetOutParameter( (CallableStatement)st, col );
+			if ( callable ) {
+				col = dialect.registerResultSetOutParameter( (CallableStatement) st, col );
 			}
 
 			col += bindParameterValues( st, queryParameters, col, session );
 
 			col += limitHandler.bindLimitParametersAtEndOfQuery( selection, st, col );
 
 			limitHandler.setMaxRows( selection, st );
 
 			if ( selection != null ) {
 				if ( selection.getTimeout() != null ) {
 					st.setQueryTimeout( selection.getTimeout() );
 				}
 				if ( selection.getFetchSize() != null ) {
 					st.setFetchSize( selection.getFetchSize() );
 				}
 			}
 
 			// handle lock timeout...
 			LockOptions lockOptions = queryParameters.getLockOptions();
 			if ( lockOptions != null ) {
 				if ( lockOptions.getTimeOut() != LockOptions.WAIT_FOREVER ) {
 					if ( !dialect.supportsLockTimeouts() ) {
 						if ( LOG.isDebugEnabled() ) {
 							LOG.debugf(
 									"Lock timeout [%s] requested but dialect reported to not support lock timeouts",
 									lockOptions.getTimeOut()
 							);
 						}
 					}
 					else if ( dialect.isLockTimeoutParameterized() ) {
 						st.setInt( col++, lockOptions.getTimeOut() );
 					}
 				}
 			}
 
-			if ( LOG.isTraceEnabled() )
-			   LOG.tracev( "Bound [{0}] parameters total", col );
+			if ( LOG.isTraceEnabled() ) {
+				LOG.tracev( "Bound [{0}] parameters total", col );
+			}
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			session.getJdbcCoordinator().getResourceRegistry().release( st );
 			session.getJdbcCoordinator().afterStatementExecution();
 			throw sqle;
 		}
-		catch ( HibernateException he ) {
+		catch (HibernateException he) {
 			session.getJdbcCoordinator().getResourceRegistry().release( st );
 			session.getJdbcCoordinator().afterStatementExecution();
 			throw he;
 		}
 
 		return st;
 	}
 
 	/**
 	 * Bind all parameter values into the prepared statement in preparation
 	 * for execution.
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param queryParameters The encapsulation of the parameter values to be bound.
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
+	 *
 	 * @return The number of JDBC bind positions actually bound during this method execution.
+	 *
 	 * @throws SQLException Indicates problems performing the binding.
 	 */
 	protected int bindParameterValues(
 			PreparedStatement statement,
 			QueryParameters queryParameters,
 			int startIndex,
 			SessionImplementor session) throws SQLException {
 		int span = 0;
 		span += bindPositionalParameters( statement, queryParameters, startIndex, session );
 		span += bindNamedParameters( statement, queryParameters.getNamedParameters(), startIndex + span, session );
 		return span;
 	}
 
 	/**
 	 * Bind positional parameter values to the JDBC prepared statement.
 	 * <p/>
 	 * Positional parameters are those specified by JDBC-style ? parameters
 	 * in the source query.  It is (currently) expected that these come
 	 * before any named parameters in the source query.
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param queryParameters The encapsulation of the parameter values to be bound.
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
+	 *
 	 * @return The number of JDBC bind positions actually bound during this method execution.
+	 *
 	 * @throws SQLException Indicates problems performing the binding.
 	 * @throws org.hibernate.HibernateException Indicates problems delegating binding to the types.
 	 */
 	protected int bindPositionalParameters(
 			final PreparedStatement statement,
 			final QueryParameters queryParameters,
 			final int startIndex,
 			final SessionImplementor session) throws SQLException, HibernateException {
 		final Object[] values = queryParameters.getFilteredPositionalParameterValues();
 		final Type[] types = queryParameters.getFilteredPositionalParameterTypes();
 		int span = 0;
 		for ( int i = 0; i < values.length; i++ ) {
 			types[i].nullSafeSet( statement, values[i], startIndex + span, session );
 			span += types[i].getColumnSpan( getFactory() );
 		}
 		return span;
 	}
 
 	/**
 	 * Bind named parameters to the JDBC prepared statement.
 	 * <p/>
 	 * This is a generic implementation, the problem being that in the
 	 * general case we do not know enough information about the named
 	 * parameters to perform this in a complete manner here.  Thus this
 	 * is generally overridden on subclasses allowing named parameters to
 	 * apply the specific behavior.  The most usual limitation here is that
 	 * we need to assume the type span is always one...
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param namedParams A map of parameter names to values
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
+	 *
 	 * @return The number of JDBC bind positions actually bound during this method execution.
+	 *
 	 * @throws SQLException Indicates problems performing the binding.
 	 * @throws org.hibernate.HibernateException Indicates problems delegating binding to the types.
 	 */
 	protected int bindNamedParameters(
 			final PreparedStatement statement,
 			final Map<String, TypedValue> namedParams,
 			final int startIndex,
 			final SessionImplementor session) throws SQLException, HibernateException {
 		int result = 0;
 		if ( CollectionHelper.isEmpty( namedParams ) ) {
 			return result;
 		}
 
 		for ( String name : namedParams.keySet() ) {
 			TypedValue typedValue = namedParams.get( name );
 			int columnSpan = typedValue.getType().getColumnSpan( getFactory() );
 			int[] locs = getNamedParameterLocs( name );
 			for ( int loc : locs ) {
 				if ( DEBUG_ENABLED ) {
 					LOG.debugf(
 							"bindNamedParameters() %s -> %s [%s]",
 							typedValue.getValue(),
 							name,
 							loc + startIndex
 					);
 				}
 				int start = loc * columnSpan + startIndex;
 				typedValue.getType().nullSafeSet( statement, typedValue.getValue(), start, session );
 			}
 			result += locs.length;
 		}
 		return result;
 	}
 
 	public int[] getNamedParameterLocs(String name) {
-		throw new AssertionFailure("no named parameters");
+		throw new AssertionFailure( "no named parameters" );
 	}
 
 	/**
 	 * Execute given <tt>PreparedStatement</tt>, advance to the first result and return SQL <tt>ResultSet</tt>.
 	 */
 	protected final ResultSet getResultSet(
 			final PreparedStatement st,
 			final RowSelection selection,
 			final LimitHandler limitHandler,
 			final boolean autodiscovertypes,
 			final SessionImplementor session) throws SQLException, HibernateException {
 		try {
 			ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
-			rs = wrapResultSetIfEnabled( rs , session );
+			rs = wrapResultSetIfEnabled( rs, session );
 
 			if ( !limitHandler.supportsLimitOffset() || !LimitHelper.useLimit( limitHandler, selection ) ) {
 				advance( rs, selection );
 			}
 
 			if ( autodiscovertypes ) {
 				autoDiscoverTypes( rs );
 			}
 			return rs;
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			session.getJdbcCoordinator().getResourceRegistry().release( st );
 			session.getJdbcCoordinator().afterStatementExecution();
 			throw sqle;
 		}
 	}
 
 	protected void autoDiscoverTypes(ResultSet rs) {
-		throw new AssertionFailure("Auto discover types not supported in this loader");
+		throw new AssertionFailure( "Auto discover types not supported in this loader" );
 
 	}
 
 	private ResultSet wrapResultSetIfEnabled(final ResultSet rs, final SessionImplementor session) {
 		if ( session.getFactory().getSessionFactoryOptions().isWrapResultSetsEnabled() ) {
 			try {
 				LOG.debugf( "Wrapping result set [%s]", rs );
 				return session.getFactory()
 						.getServiceRegistry()
 						.getService( JdbcServices.class )
 						.getResultSetWrapper().wrap( rs, retreiveColumnNameToIndexCache( rs ) );
 			}
-			catch(SQLException e) {
+			catch (SQLException e) {
 				LOG.unableToWrapResultSet( e );
 				return rs;
 			}
 		}
 		else {
 			return rs;
 		}
 	}
 
 	private ColumnNameCache retreiveColumnNameToIndexCache(final ResultSet rs) throws SQLException {
 		final ColumnNameCache cache = columnNameCache;
 		if ( cache == null ) {
 			//there is no need for a synchronized second check, as in worst case
 			//we'll have allocated an unnecessary ColumnNameCache
 			LOG.trace( "Building columnName -> columnIndex cache" );
 			columnNameCache = new ColumnNameCache( rs.getMetaData().getColumnCount() );
 			return columnNameCache;
 		}
 		else {
 			return cache;
 		}
 	}
 
 	/**
 	 * Called by subclasses that load entities
 	 */
 	protected final List loadEntity(
 			final SessionImplementor session,
 			final Object id,
 			final Type identifierType,
 			final Object optionalObject,
 			final String optionalEntityName,
 			final Serializable optionalIdentifier,
 			final EntityPersister persister,
 			LockOptions lockOptions) throws HibernateException {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "Loading entity: %s", MessageHelper.infoString( persister, id, identifierType, getFactory() ) );
 		}
 
 		List result;
 		try {
 			QueryParameters qp = new QueryParameters();
-			qp.setPositionalParameterTypes( new Type[] { identifierType } );
-			qp.setPositionalParameterValues( new Object[] { id } );
+			qp.setPositionalParameterTypes( new Type[] {identifierType} );
+			qp.setPositionalParameterValues( new Object[] {id} );
 			qp.setOptionalObject( optionalObject );
 			qp.setOptionalEntityName( optionalEntityName );
 			qp.setOptionalId( optionalIdentifier );
 			qp.setLockOptions( lockOptions );
 			result = doQueryAndInitializeNonLazyCollections( session, qp, false );
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			final Loadable[] persisters = getEntityPersisters();
 			throw factory.getSQLExceptionHelper().convert(
-			        sqle,
-			        "could not load an entity: " +
-			        MessageHelper.infoString( persisters[persisters.length-1], id, identifierType, getFactory() ),
-			        getSQLString()
+					sqle,
+					"could not load an entity: " +
+							MessageHelper.infoString(
+									persisters[persisters.length - 1],
+									id,
+									identifierType,
+									getFactory()
+							),
+					getSQLString()
 			);
 		}
 
 		LOG.debug( "Done entity load" );
 
 		return result;
 
 	}
 
 	/**
 	 * Called by subclasses that load entities
+	 *
 	 * @param persister only needed for logging
 	 */
 	protected final List loadEntity(
-	        final SessionImplementor session,
-	        final Object key,
-	        final Object index,
-	        final Type keyType,
-	        final Type indexType,
-	        final EntityPersister persister) throws HibernateException {
+			final SessionImplementor session,
+			final Object key,
+			final Object index,
+			final Type keyType,
+			final Type indexType,
+			final EntityPersister persister) throws HibernateException {
 		LOG.debug( "Loading collection element by index" );
 
 		List result;
 		try {
 			result = doQueryAndInitializeNonLazyCollections(
 					session,
 					new QueryParameters(
-							new Type[] { keyType, indexType },
-							new Object[] { key, index }
+							new Type[] {keyType, indexType},
+							new Object[] {key, index}
 					),
 					false
 			);
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw factory.getSQLExceptionHelper().convert(
-			        sqle,
-			        "could not load collection element by index",
-			        getSQLString()
+					sqle,
+					"could not load collection element by index",
+					getSQLString()
 			);
 		}
 
 		LOG.debug( "Done entity load" );
 
 		return result;
 
 	}
 
 	/**
 	 * Called by wrappers that batch load entities
 	 */
 	public final List loadEntityBatch(
 			final SessionImplementor session,
 			final Serializable[] ids,
 			final Type idType,
 			final Object optionalObject,
 			final String optionalEntityName,
 			final Serializable optionalId,
 			final EntityPersister persister,
 			LockOptions lockOptions) throws HibernateException {
-		if ( LOG.isDebugEnabled() )
+		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "Batch loading entity: %s", MessageHelper.infoString( persister, ids, getFactory() ) );
+		}
 
 		Type[] types = new Type[ids.length];
 		Arrays.fill( types, idType );
 		List result;
 		try {
 			QueryParameters qp = new QueryParameters();
 			qp.setPositionalParameterTypes( types );
 			qp.setPositionalParameterValues( ids );
 			qp.setOptionalObject( optionalObject );
 			qp.setOptionalEntityName( optionalEntityName );
 			qp.setOptionalId( optionalId );
 			qp.setLockOptions( lockOptions );
 			result = doQueryAndInitializeNonLazyCollections( session, qp, false );
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw factory.getSQLExceptionHelper().convert(
-			        sqle,
-			        "could not load an entity batch: " +
-			        MessageHelper.infoString( getEntityPersisters()[0], ids, getFactory() ),
-			        getSQLString()
+					sqle,
+					"could not load an entity batch: " +
+							MessageHelper.infoString( getEntityPersisters()[0], ids, getFactory() ),
+					getSQLString()
 			);
 		}
 
 		LOG.debug( "Done entity batch load" );
 
 		return result;
 
 	}
 
 	/**
 	 * Called by subclasses that initialize collections
 	 */
 	public final void loadCollection(
-	        final SessionImplementor session,
-	        final Serializable id,
-	        final Type type) throws HibernateException {
+			final SessionImplementor session,
+			final Serializable id,
+			final Type type) throws HibernateException {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"Loading collection: %s",
 					MessageHelper.collectionInfoString( getCollectionPersisters()[0], id, getFactory() )
 			);
 		}
 
-		Serializable[] ids = new Serializable[]{id};
+		Serializable[] ids = new Serializable[] {id};
 		try {
 			doQueryAndInitializeNonLazyCollections(
 					session,
-					new QueryParameters( new Type[]{type}, ids, ids ),
+					new QueryParameters( new Type[] {type}, ids, ids ),
 					true
 			);
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not initialize a collection: " +
-					MessageHelper.collectionInfoString( getCollectionPersisters()[0], id, getFactory() ),
+							MessageHelper.collectionInfoString( getCollectionPersisters()[0], id, getFactory() ),
 					getSQLString()
 			);
 		}
 
 		LOG.debug( "Done loading collection" );
 	}
 
 	/**
 	 * Called by wrappers that batch initialize collections
 	 */
 	public final void loadCollectionBatch(
 			final SessionImplementor session,
 			final Serializable[] ids,
 			final Type type) throws HibernateException {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"Batch loading collection: %s",
 					MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() )
 			);
 		}
 
 		Type[] idTypes = new Type[ids.length];
 		Arrays.fill( idTypes, type );
 		try {
 			doQueryAndInitializeNonLazyCollections(
 					session,
 					new QueryParameters( idTypes, ids, ids ),
 					true
 			);
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not initialize a collection batch: " +
-					MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() ),
+							MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() ),
 					getSQLString()
 			);
 		}
 
 		LOG.debug( "Done batch load" );
 	}
 
 	/**
 	 * Called by subclasses that batch initialize collections
 	 */
 	protected final void loadCollectionSubselect(
 			final SessionImplementor session,
 			final Serializable[] ids,
 			final Object[] parameterValues,
 			final Type[] parameterTypes,
 			final Map<String, TypedValue> namedParameters,
 			final Type type) throws HibernateException {
 		final Type[] idTypes = new Type[ids.length];
 		Arrays.fill( idTypes, type );
 		try {
-			doQueryAndInitializeNonLazyCollections( session,
+			doQueryAndInitializeNonLazyCollections(
+					session,
 					new QueryParameters( parameterTypes, parameterValues, namedParameters, ids ),
 					true
 			);
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not load collection by subselect: " +
-					MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() ),
+							MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() ),
 					getSQLString()
 			);
 		}
 	}
 
 	/**
 	 * Return the query results, using the query cache, called
 	 * by subclasses that implement cacheable queries
 	 */
 	protected List list(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final Set<Serializable> querySpaces,
 			final Type[] resultTypes) throws HibernateException {
 		final boolean cacheable = factory.getSessionFactoryOptions().isQueryCacheEnabled() &&
-			queryParameters.isCacheable();
+				queryParameters.isCacheable();
 
 		if ( cacheable ) {
 			return listUsingQueryCache( session, queryParameters, querySpaces, resultTypes );
 		}
 		else {
 			return listIgnoreQueryCache( session, queryParameters );
 		}
 	}
 
 	private List listIgnoreQueryCache(SessionImplementor session, QueryParameters queryParameters) {
 		return getResultList( doList( session, queryParameters ), queryParameters.getResultTransformer() );
 	}
 
 	private List listUsingQueryCache(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final Set<Serializable> querySpaces,
 			final Type[] resultTypes) {
 
 		QueryCache queryCache = factory.getQueryCache( queryParameters.getCacheRegion() );
 
 		QueryKey key = generateQueryKey( session, queryParameters );
 
 		if ( querySpaces == null || querySpaces.size() == 0 ) {
 			LOG.tracev( "Unexpected querySpaces is {0}", ( querySpaces == null ? querySpaces : "empty" ) );
 		}
 		else {
 			LOG.tracev( "querySpaces is {0}", querySpaces );
 		}
 
 		List result = getResultFromQueryCache(
 				session,
 				queryParameters,
 				querySpaces,
 				resultTypes,
 				queryCache,
 				key
 		);
 
 		if ( result == null ) {
 			result = doList( session, queryParameters, key.getResultTransformer() );
 
 			putResultInQueryCache(
 					session,
 					queryParameters,
 					resultTypes,
 					queryCache,
 					key,
 					result
 			);
 		}
 
 		ResultTransformer resolvedTransformer = resolveResultTransformer( queryParameters.getResultTransformer() );
 		if ( resolvedTransformer != null ) {
 			result = (
 					areResultSetRowsTransformedImmediately() ?
 							key.getResultTransformer().retransformResults(
 									result,
 									getResultRowAliases(),
 									queryParameters.getResultTransformer(),
 									includeInResultRow()
 							) :
 							key.getResultTransformer().untransformToTuples(
 									result
 							)
 			);
 		}
 
 		return getResultList( result, queryParameters.getResultTransformer() );
 	}
 
 	private QueryKey generateQueryKey(
 			SessionImplementor session,
 			QueryParameters queryParameters) {
 		return QueryKey.generateQueryKey(
 				getSQLString(),
 				queryParameters,
 				FilterKey.createFilterKeys( session.getLoadQueryInfluencers().getEnabledFilters() ),
 				session,
 				createCacheableResultTransformer( queryParameters )
 		);
 	}
 
 	private CacheableResultTransformer createCacheableResultTransformer(QueryParameters queryParameters) {
 		return CacheableResultTransformer.create(
 				queryParameters.getResultTransformer(),
 				getResultRowAliases(),
 				includeInResultRow()
 		);
 	}
 
 	private List getResultFromQueryCache(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final Set<Serializable> querySpaces,
 			final Type[] resultTypes,
 			final QueryCache queryCache,
 			final QueryKey key) {
 		List result = null;
 
 		if ( session.getCacheMode().isGetEnabled() ) {
 			boolean isImmutableNaturalKeyLookup =
 					queryParameters.isNaturalKeyLookup() &&
 							resultTypes.length == 1 &&
 							resultTypes[0].isEntityType() &&
 							getEntityPersister( EntityType.class.cast( resultTypes[0] ) )
 									.getEntityMetamodel()
 									.hasImmutableNaturalId();
 
 			final PersistenceContext persistenceContext = session.getPersistenceContext();
 			boolean defaultReadOnlyOrig = persistenceContext.isDefaultReadOnly();
 			if ( queryParameters.isReadOnlyInitialized() ) {
 				// The read-only/modifiable mode for the query was explicitly set.
 				// Temporarily set the default read-only/modifiable setting to the query's setting.
 				persistenceContext.setDefaultReadOnly( queryParameters.isReadOnly() );
 			}
 			else {
 				// The read-only/modifiable setting for the query was not initialized.
 				// Use the default read-only/modifiable from the persistence context instead.
 				queryParameters.setReadOnly( persistenceContext.isDefaultReadOnly() );
 			}
 			try {
 				result = queryCache.get(
 						key,
 						key.getResultTransformer().getCachedResultTypes( resultTypes ),
 						isImmutableNaturalKeyLookup,
 						querySpaces,
 						session
 				);
 			}
 			finally {
 				persistenceContext.setDefaultReadOnly( defaultReadOnlyOrig );
 			}
 
 			if ( factory.getStatistics().isStatisticsEnabled() ) {
 				if ( result == null ) {
 					factory.getStatisticsImplementor()
 							.queryCacheMiss( getQueryIdentifier(), queryCache.getRegion().getName() );
 				}
 				else {
 					factory.getStatisticsImplementor()
 							.queryCacheHit( getQueryIdentifier(), queryCache.getRegion().getName() );
 				}
 			}
 		}
 
 		return result;
 	}
 
 	private EntityPersister getEntityPersister(EntityType entityType) {
 		return factory.getEntityPersister( entityType.getAssociatedEntityName() );
 	}
 
 	protected void putResultInQueryCache(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final Type[] resultTypes,
 			final QueryCache queryCache,
 			final QueryKey key,
 			final List result) {
 		if ( session.getCacheMode().isPutEnabled() ) {
 			boolean put = queryCache.put(
 					key,
 					key.getResultTransformer().getCachedResultTypes( resultTypes ),
 					result,
 					queryParameters.isNaturalKeyLookup(),
 					session
 			);
 			if ( put && factory.getStatistics().isStatisticsEnabled() ) {
 				factory.getStatisticsImplementor()
 						.queryCachePut( getQueryIdentifier(), queryCache.getRegion().getName() );
 			}
 		}
 	}
 
 	/**
 	 * Actually execute a query, ignoring the query cache
 	 */
 
 	protected List doList(final SessionImplementor session, final QueryParameters queryParameters)
 			throws HibernateException {
-		return doList( session, queryParameters, null);
+		return doList( session, queryParameters, null );
 	}
 
-	private List doList(final SessionImplementor session,
-						final QueryParameters queryParameters,
-						final ResultTransformer forcedResultTransformer)
+	private List doList(
+			final SessionImplementor session,
+			final QueryParameters queryParameters,
+			final ResultTransformer forcedResultTransformer)
 			throws HibernateException {
 
 		final boolean stats = getFactory().getStatistics().isStatisticsEnabled();
 		long startTime = 0;
 		if ( stats ) {
 			startTime = System.nanoTime();
 		}
 
 		List result;
 		try {
 			result = doQueryAndInitializeNonLazyCollections( session, queryParameters, true, forcedResultTransformer );
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not execute query",
 					getSQLString()
 			);
 		}
 
 		if ( stats ) {
 			final long endTime = System.nanoTime();
 			final long milliseconds = TimeUnit.MILLISECONDS.convert( endTime - startTime, TimeUnit.NANOSECONDS );
 			getFactory().getStatisticsImplementor().queryExecuted(
 					getQueryIdentifier(),
 					result.size(),
 					milliseconds
 			);
 		}
 
 		return result;
 	}
 
 	/**
 	 * Check whether the current loader can support returning ScrollableResults.
 	 *
 	 * @throws HibernateException
 	 */
 	protected void checkScrollability() throws HibernateException {
 		// Allows various loaders (ok mainly the QueryLoader :) to check
 		// whether scrolling of their result set should be allowed.
 		//
 		// By default it is allowed.
 	}
 
 	/**
 	 * Does the result set to be scrolled contain collection fetches?
 	 *
 	 * @return True if it does, and thus needs the special fetching scroll
 	 * functionality; false otherwise.
 	 */
 	protected boolean needsFetchingScroll() {
 		return false;
 	}
 
 	/**
 	 * Return the query results, as an instance of <tt>ScrollableResults</tt>
 	 *
 	 * @param queryParameters The parameters with which the query should be executed.
 	 * @param returnTypes The expected return types of the query
 	 * @param holderInstantiator If the return values are expected to be wrapped
 	 * in a holder, this is the thing that knows how to wrap them.
 	 * @param session The session from which the scroll request originated.
+	 *
 	 * @return The ScrollableResults instance.
+	 *
 	 * @throws HibernateException Indicates an error executing the query, or constructing
 	 * the ScrollableResults.
 	 */
 	protected ScrollableResults scroll(
 			final QueryParameters queryParameters,
 			final Type[] returnTypes,
 			final HolderInstantiator holderInstantiator,
 			final SessionImplementor session) throws HibernateException {
 		checkScrollability();
 
 		final boolean stats = getQueryIdentifier() != null &&
 				getFactory().getStatistics().isStatisticsEnabled();
 		long startTime = 0;
 		if ( stats ) {
 			startTime = System.nanoTime();
 		}
 
 		try {
 			// Don't use Collections#emptyList() here -- follow on locking potentially adds AfterLoadActions,
 			// so the list cannot be immutable.
-			final SqlStatementWrapper wrapper = executeQueryStatement( queryParameters, true, new ArrayList<AfterLoadAction>(), session );
+			final SqlStatementWrapper wrapper = executeQueryStatement(
+					queryParameters,
+					true,
+					new ArrayList<AfterLoadAction>(),
+					session
+			);
 			final ResultSet rs = wrapper.getResultSet();
 			final PreparedStatement st = (PreparedStatement) wrapper.getStatement();
 
 			if ( stats ) {
 				final long endTime = System.nanoTime();
 				final long milliseconds = TimeUnit.MILLISECONDS.convert( endTime - startTime, TimeUnit.NANOSECONDS );
 				getFactory().getStatisticsImplementor().queryExecuted(
 						getQueryIdentifier(),
 						0,
 						milliseconds
 				);
 			}
 
 			if ( needsFetchingScroll() ) {
 				return new FetchingScrollableResultsImpl(
 						rs,
 						st,
 						session,
 						this,
 						queryParameters,
 						returnTypes,
 						holderInstantiator
 				);
 			}
 			else {
 				return new ScrollableResultsImpl(
 						rs,
 						st,
 						session,
 						this,
 						queryParameters,
 						returnTypes,
 						holderInstantiator
 				);
 			}
 
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not execute query using scroll",
 					getSQLString()
 			);
 		}
 
 	}
 
 	/**
 	 * Calculate and cache select-clause suffixes. Must be
 	 * called by subclasses after instantiation.
 	 */
-	protected void postInstantiate() {}
+	protected void postInstantiate() {
+	}
 
 	/**
 	 * Get the result set descriptor
 	 */
 	protected abstract EntityAliases[] getEntityAliases();
 
 	protected abstract CollectionAliases[] getCollectionAliases();
 
 	/**
 	 * Identifies the query for statistics reporting, if null,
 	 * no statistics will be reported
 	 */
 	protected String getQueryIdentifier() {
 		return null;
 	}
 
 	public final SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	@Override
 	public String toString() {
 		return getClass().getName() + '(' + getSQLString() + ')';
 	}
 
 	/**
 	 * Wrapper class for {@link Statement} and associated {@link ResultSet}.
 	 */
 	protected static class SqlStatementWrapper {
 		private final Statement statement;
 		private final ResultSet resultSet;
 
 		private SqlStatementWrapper(Statement statement, ResultSet resultSet) {
 			this.resultSet = resultSet;
 			this.statement = statement;
 		}
 
 		public ResultSet getResultSet() {
 			return resultSet;
 		}
 
 		public Statement getStatement() {
 			return statement;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/ExpandingCollectionQuerySpace.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/ExpandingCollectionQuerySpace.java
index 63f2231a55..cf1c97ae2f 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/ExpandingCollectionQuerySpace.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/ExpandingCollectionQuerySpace.java
@@ -1,55 +1,54 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.build.spi;
 
 import org.hibernate.loader.plan.spi.CollectionQuerySpace;
 import org.hibernate.loader.plan.spi.Join;
-import org.hibernate.persister.collection.CollectionPropertyNames;
 
 /**
  * Describes a collection query space that allows adding joins with other
  * query spaces; used while building a {@link CollectionQuerySpace}.
  *
  * @see org.hibernate.loader.plan.spi.Join
  *
  * @author Gail Badner
  */
 public interface ExpandingCollectionQuerySpace extends CollectionQuerySpace, ExpandingQuerySpace {
 
 	/**
-	 * Adds a join with another query space for either a collection element or index. If {@code join}
-	 * is an instance of {@link org.hibernate.loader.plan.spi.JoinDefinedByMetadata}, then the only valid
+	 * Adds a join with another query space for either a collection element or index.
+	 *
+	 * If {@code join} is an instance of {@link org.hibernate.loader.plan.spi.JoinDefinedByMetadata}, then the only valid
 	 * values returned by {@link org.hibernate.loader.plan.spi.JoinDefinedByMetadata#getJoinedPropertyName}
-	 * are {@link CollectionPropertyNames#COLLECTION_ELEMENTS} and {@link CollectionPropertyNames#COLLECTION_INDICES},
-	 * for the collection element or index, respectively.
+	 * are {@code "elements"} and {@code "indices"} for the collection element or index, respectively.
 	 *
 	 * @param join The element or index join to add.
 	 *
 	 * @throws java.lang.IllegalArgumentException if {@code join} is an instance of
 	 * {@link org.hibernate.loader.plan.spi.JoinDefinedByMetadata} and {@code join.getJoinedPropertyName()
-	 * is neither {@link CollectionPropertyNames#COLLECTION_ELEMENTS} nor {@link CollectionPropertyNames#COLLECTION_INDICES}}.
+	 * is neither {@code "elements"} and {@code "indices"}.
 	 * @throws java.lang.IllegalStateException if there is already an existing join with the same joined property name.
 	 */
-	public void addJoin(Join join);
+	void addJoin(Join join);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ResultSetProcessingContextImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ResultSetProcessingContextImpl.java
index b400f4764c..db2db2cc9f 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ResultSetProcessingContextImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/process/internal/ResultSetProcessingContextImpl.java
@@ -1,378 +1,366 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.exec.process.internal;
 
 import java.sql.ResultSet;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.IdentityHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.LockMode;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.SubselectFetch;
 import org.hibernate.loader.plan.exec.process.spi.ResultSetProcessingContext;
 import org.hibernate.loader.plan.exec.query.spi.NamedParameterContext;
 import org.hibernate.loader.plan.spi.EntityFetch;
 import org.hibernate.loader.plan.spi.EntityReference;
 import org.hibernate.loader.plan.spi.Fetch;
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.type.EntityType;
 
-import org.jboss.logging.Logger;
-
 /**
  * @author Steve Ebersole
  */
 public class ResultSetProcessingContextImpl implements ResultSetProcessingContext {
-	private static final Logger LOG = Logger.getLogger( ResultSetProcessingContextImpl.class );
-
 	private final ResultSet resultSet;
 	private final SessionImplementor session;
 	private final LoadPlan loadPlan;
 	private final boolean readOnly;
 	private final boolean shouldUseOptionalEntityInformation;
 	private final boolean forceFetchLazyAttributes;
 	private final boolean shouldReturnProxies;
 	private final QueryParameters queryParameters;
 	private final NamedParameterContext namedParameterContext;
 	private final boolean hadSubselectFetches;
 
 	private List<HydratedEntityRegistration> currentRowHydratedEntityRegistrationList;
 
 	private Map<EntityPersister,Set<EntityKey>> subselectLoadableEntityKeyMap;
 	private List<HydratedEntityRegistration> hydratedEntityRegistrationList;
 
 	/**
 	 * Builds a ResultSetProcessingContextImpl
 	 *
-	 * @param resultSet
-	 * @param session
-	 * @param loadPlan
-	 * @param readOnly
 	 * @param shouldUseOptionalEntityInformation There are times when the "optional entity information" on
 	 * QueryParameters should be used and times when they should not.  Collection initializers, batch loaders, etc
 	 * are times when it should NOT be used.
-	 * @param forceFetchLazyAttributes
-	 * @param shouldReturnProxies
-	 * @param queryParameters
-	 * @param namedParameterContext
-	 * @param hadSubselectFetches
 	 */
 	public ResultSetProcessingContextImpl(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final LoadPlan loadPlan,
 			final boolean readOnly,
 			final boolean shouldUseOptionalEntityInformation,
 			final boolean forceFetchLazyAttributes,
 			final boolean shouldReturnProxies,
 			final QueryParameters queryParameters,
 			final NamedParameterContext namedParameterContext,
 			final boolean hadSubselectFetches) {
 		this.resultSet = resultSet;
 		this.session = session;
 		this.loadPlan = loadPlan;
 		this.readOnly = readOnly;
 		this.shouldUseOptionalEntityInformation = shouldUseOptionalEntityInformation;
 		this.forceFetchLazyAttributes = forceFetchLazyAttributes;
 		this.shouldReturnProxies = shouldReturnProxies;
 		this.queryParameters = queryParameters;
 		this.namedParameterContext = namedParameterContext;
 		this.hadSubselectFetches = hadSubselectFetches;
 
 		if ( shouldUseOptionalEntityInformation ) {
 			if ( queryParameters.getOptionalId() != null ) {
 				// make sure we have only one return
 				if ( loadPlan.getReturns().size() > 1 ) {
 					throw new IllegalStateException( "Cannot specify 'optional entity' values with multi-return load plans" );
 				}
 			}
 		}
 	}
 
 	@Override
 	public SessionImplementor getSession() {
 		return session;
 	}
 
 	@Override
 	public boolean shouldUseOptionalEntityInformation() {
 		return shouldUseOptionalEntityInformation;
 	}
 
 	@Override
 	public QueryParameters getQueryParameters() {
 		return queryParameters;
 	}
 
 	@Override
 	public boolean shouldReturnProxies() {
 		return shouldReturnProxies;
 	}
 
 	@Override
 	public LoadPlan getLoadPlan() {
 		return loadPlan;
 	}
 
 	public ResultSet getResultSet() {
 		return resultSet;
 	}
 
 	@Override
 	public LockMode resolveLockMode(EntityReference entityReference) {
 		if ( queryParameters.getLockOptions() != null && queryParameters.getLockOptions()
 				.getLockMode() != null ) {
 			return queryParameters.getLockOptions().getLockMode();
 		}
 		return LockMode.READ;
 	}
 
 	private Map<EntityReference,EntityReferenceProcessingState> identifierResolutionContextMap;
 
 	@Override
 	public EntityReferenceProcessingState getProcessingState(final EntityReference entityReference) {
 		if ( identifierResolutionContextMap == null ) {
 			identifierResolutionContextMap = new IdentityHashMap<EntityReference, EntityReferenceProcessingState>();
 		}
 
 		EntityReferenceProcessingState context = identifierResolutionContextMap.get( entityReference );
 		if ( context == null ) {
 			context = new EntityReferenceProcessingState() {
 				private boolean wasMissingIdentifier;
 				private Object identifierHydratedForm;
 				private EntityKey entityKey;
 				private Object[] hydratedState;
 				private Object entityInstance;
 
 				@Override
 				public EntityReference getEntityReference() {
 					return entityReference;
 				}
 
 				@Override
 				public void registerMissingIdentifier() {
 					if ( !EntityFetch.class.isInstance( entityReference ) ) {
 						throw new IllegalStateException( "Missing return row identifier" );
 					}
 					ResultSetProcessingContextImpl.this.registerNonExists( (EntityFetch) entityReference );
 					wasMissingIdentifier = true;
 				}
 
 				@Override
 				public boolean isMissingIdentifier() {
 					return wasMissingIdentifier;
 				}
 
 				@Override
 				public void registerIdentifierHydratedForm(Object identifierHydratedForm) {
 					this.identifierHydratedForm = identifierHydratedForm;
 				}
 
 				@Override
 				public Object getIdentifierHydratedForm() {
 					return identifierHydratedForm;
 				}
 
 				@Override
 				public void registerEntityKey(EntityKey entityKey) {
 					this.entityKey = entityKey;
 				}
 
 				@Override
 				public EntityKey getEntityKey() {
 					return entityKey;
 				}
 
 				@Override
 				public void registerHydratedState(Object[] hydratedState) {
 					this.hydratedState = hydratedState;
 				}
 
 				@Override
 				public Object[] getHydratedState() {
 					return hydratedState;
 				}
 
 				@Override
 				public void registerEntityInstance(Object entityInstance) {
 					this.entityInstance = entityInstance;
 				}
 
 				@Override
 				public Object getEntityInstance() {
 					return entityInstance;
 				}
 			};
 			identifierResolutionContextMap.put( entityReference, context );
 		}
 
 		return context;
 	}
 
 	private void registerNonExists(EntityFetch fetch) {
 		final EntityType fetchedType = fetch.getFetchedType();
 		if ( ! fetchedType.isOneToOne() ) {
 			return;
 		}
 
 		final EntityReferenceProcessingState fetchOwnerState = getOwnerProcessingState( fetch );
 		if ( fetchOwnerState == null ) {
 			throw new IllegalStateException( "Could not locate fetch owner state" );
 		}
 
 		final EntityKey ownerEntityKey = fetchOwnerState.getEntityKey();
 		if ( ownerEntityKey == null ) {
 			throw new IllegalStateException( "Could not locate fetch owner EntityKey" );
 		}
 
 		session.getPersistenceContext().addNullProperty(
 				ownerEntityKey,
 				fetchedType.getPropertyName()
 		);
 	}
 
 	@Override
 	public EntityReferenceProcessingState getOwnerProcessingState(Fetch fetch) {
 		return getProcessingState( fetch.getSource().resolveEntityReference() );
 	}
 
 	@Override
 	public void registerHydratedEntity(EntityReference entityReference, EntityKey entityKey, Object entityInstance) {
 		if ( currentRowHydratedEntityRegistrationList == null ) {
 			currentRowHydratedEntityRegistrationList = new ArrayList<HydratedEntityRegistration>();
 		}
 		currentRowHydratedEntityRegistrationList.add(
 				new HydratedEntityRegistration(
 						entityReference,
 						entityKey,
 						entityInstance
 				)
 		);
 	}
 
 	/**
 	 * Package-protected
 	 */
 	void finishUpRow() {
 		if ( currentRowHydratedEntityRegistrationList == null ) {
 			if ( identifierResolutionContextMap != null ) {
 				identifierResolutionContextMap.clear();
 			}
 			return;
 		}
 
 
 		// managing the running list of registrations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		if ( hydratedEntityRegistrationList == null ) {
 			hydratedEntityRegistrationList = new ArrayList<HydratedEntityRegistration>();
 		}
 		hydratedEntityRegistrationList.addAll( currentRowHydratedEntityRegistrationList );
 
 
 		// managing the map forms needed for subselect fetch generation ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		if ( hadSubselectFetches ) {
 			if ( subselectLoadableEntityKeyMap == null ) {
 				subselectLoadableEntityKeyMap = new HashMap<EntityPersister, Set<EntityKey>>();
 			}
 			for ( HydratedEntityRegistration registration : currentRowHydratedEntityRegistrationList ) {
-				Set<EntityKey> entityKeys = subselectLoadableEntityKeyMap.get( registration.getEntityReference()
-																					   .getEntityPersister() );
+				Set<EntityKey> entityKeys = subselectLoadableEntityKeyMap.get(
+						registration.getEntityReference().getEntityPersister()
+				);
 				if ( entityKeys == null ) {
 					entityKeys = new HashSet<EntityKey>();
 					subselectLoadableEntityKeyMap.put( registration.getEntityReference().getEntityPersister(), entityKeys );
 				}
 				entityKeys.add( registration.getKey() );
 			}
 		}
 
 		// release the currentRowHydratedEntityRegistrationList entries
 		currentRowHydratedEntityRegistrationList.clear();
 
 		identifierResolutionContextMap.clear();
 	}
 
 	public List<HydratedEntityRegistration> getHydratedEntityRegistrationList() {
 		return hydratedEntityRegistrationList;
 	}
 
 	/**
 	 * Package-protected
 	 */
 	void wrapUp() {
 		createSubselects();
 
 		if ( hydratedEntityRegistrationList != null ) {
 			hydratedEntityRegistrationList.clear();
 			hydratedEntityRegistrationList = null;
 		}
 
 		if ( subselectLoadableEntityKeyMap != null ) {
 			subselectLoadableEntityKeyMap.clear();
 			subselectLoadableEntityKeyMap = null;
 		}
 	}
 
 	private void createSubselects() {
 		if ( subselectLoadableEntityKeyMap == null || subselectLoadableEntityKeyMap.size() <= 1 ) {
 			// if we only returned one entity, query by key is more efficient; so do nothing here
 			return;
 		}
 
 		final Map<String, int[]> namedParameterLocMap =
 				ResultSetProcessorHelper.buildNamedParameterLocMap( queryParameters, namedParameterContext );
 
 		for ( Map.Entry<EntityPersister, Set<EntityKey>> entry : subselectLoadableEntityKeyMap.entrySet() ) {
 			if ( ! entry.getKey().hasSubselectLoadableCollections() ) {
 				continue;
 			}
 
 			SubselectFetch subselectFetch = new SubselectFetch(
 					//getSQLString(),
 					null, // aliases[i],
 					(Loadable) entry.getKey(),
 					queryParameters,
 					entry.getValue(),
 					namedParameterLocMap
 			);
 
 			for ( EntityKey key : entry.getValue() ) {
 				session.getPersistenceContext().getBatchFetchQueue().addSubselect( key, subselectFetch );
 			}
 
 		}
 	}
 
 	public boolean isReadOnly() {
 		return readOnly;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/Array.java b/hibernate-core/src/main/java/org/hibernate/mapping/Array.java
index 9b3ce7cb52..f8ffc1fbcf 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/Array.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/Array.java
@@ -1,90 +1,91 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import org.hibernate.MappingException;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.PrimitiveType;
 
 /**
  * An array mapping has a primary key consisting of the key columns + index column.
  *
  * @author Gavin King
  */
 public class Array extends List {
 	private String elementClassName;
 
 	public Array(MetadataImplementor metadata, PersistentClass owner) {
 		super( metadata, owner );
 	}
 
 	public Class getElementClass() throws MappingException {
-		if (elementClassName==null) {
+		if ( elementClassName == null ) {
 			org.hibernate.type.Type elementType = getElement().getType();
-			return isPrimitiveArray() ?
-				( (PrimitiveType) elementType ).getPrimitiveClass() :
-				elementType.getReturnedClass();
+			return isPrimitiveArray()
+					? ( (PrimitiveType) elementType ).getPrimitiveClass()
+					: elementType.getReturnedClass();
 		}
 		else {
 			try {
-				return ReflectHelper.classForName(elementClassName);
+				return ReflectHelper.classForName( elementClassName );
 			}
 			catch (ClassNotFoundException cnfe) {
-				throw new MappingException(cnfe);
+				throw new MappingException( cnfe );
 			}
 		}
 	}
 
 	@Override
-    public CollectionType getDefaultCollectionType() throws MappingException {
+	public CollectionType getDefaultCollectionType() throws MappingException {
 		return getMetadata().getTypeResolver()
 				.getTypeFactory()
 				.array( getRole(), getReferencedPropertyName(), getElementClass() );
 	}
 
 	@Override
-    public boolean isArray() {
+	public boolean isArray() {
 		return true;
 	}
 
 	/**
 	 * @return Returns the elementClassName.
 	 */
 	public String getElementClassName() {
 		return elementClassName;
 	}
+
 	/**
 	 * @param elementClassName The elementClassName to set.
 	 */
 	public void setElementClassName(String elementClassName) {
 		this.elementClassName = elementClassName;
 	}
 
 	@Override
-    public Object accept(ValueVisitor visitor) {
-		return visitor.accept(this);
+	public Object accept(ValueVisitor visitor) {
+		return visitor.accept( this );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/Collection.java b/hibernate-core/src/main/java/org/hibernate/mapping/Collection.java
index a5c93e370a..a9bbf28a3f 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/Collection.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/Collection.java
@@ -1,694 +1,734 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Comparator;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Properties;
 
 import org.hibernate.FetchMode;
 import org.hibernate.MappingException;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.internal.FilterConfiguration;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.Type;
 
 /**
  * Mapping for a collection. Subclasses specialize to particular collection styles.
- * 
+ *
  * @author Gavin King
  */
 public abstract class Collection implements Fetchable, Value, Filterable {
 
 	public static final String DEFAULT_ELEMENT_COLUMN_NAME = "elt";
 	public static final String DEFAULT_KEY_COLUMN_NAME = "id";
 
 	private final MetadataImplementor metadata;
 	private PersistentClass owner;
 
 	private KeyValue key;
 	private Value element;
 	private Table collectionTable;
 	private String role;
 	private boolean lazy;
 	private boolean extraLazy;
 	private boolean inverse;
 	private boolean mutable = true;
 	private boolean subselectLoadable;
 	private String cacheConcurrencyStrategy;
 	private String cacheRegionName;
 	private String orderBy;
 	private String where;
 	private String manyToManyWhere;
 	private String manyToManyOrderBy;
 	private String referencedPropertyName;
 	private String nodeName;
 	private String elementNodeName;
 	private String mappedByProperty;
 	private boolean sorted;
 	private Comparator comparator;
 	private String comparatorClassName;
 	private boolean orphanDelete;
 	private int batchSize = -1;
 	private FetchMode fetchMode;
 	private boolean embedded = true;
 	private boolean optimisticLocked = true;
 	private Class collectionPersisterClass;
 	private String typeName;
 	private Properties typeParameters;
 	private final java.util.List filters = new ArrayList();
 	private final java.util.List manyToManyFilters = new ArrayList();
 	private final java.util.Set<String> synchronizedTables = new HashSet<String>();
 
 	private String customSQLInsert;
 	private boolean customInsertCallable;
 	private ExecuteUpdateResultCheckStyle insertCheckStyle;
 	private String customSQLUpdate;
 	private boolean customUpdateCallable;
 	private ExecuteUpdateResultCheckStyle updateCheckStyle;
 	private String customSQLDelete;
 	private boolean customDeleteCallable;
 	private ExecuteUpdateResultCheckStyle deleteCheckStyle;
 	private String customSQLDeleteAll;
 	private boolean customDeleteAllCallable;
 	private ExecuteUpdateResultCheckStyle deleteAllCheckStyle;
 
 	private String loaderName;
 
 	protected Collection(MetadataImplementor metadata, PersistentClass owner) {
 		this.metadata = metadata;
 		this.owner = owner;
 	}
 
 	public MetadataImplementor getMetadata() {
 		return metadata;
 	}
 
 	public boolean isSet() {
 		return false;
 	}
 
 	public KeyValue getKey() {
 		return key;
 	}
 
 	public Value getElement() {
 		return element;
 	}
 
 	public boolean isIndexed() {
 		return false;
 	}
 
 	public Table getCollectionTable() {
 		return collectionTable;
 	}
 
 	public void setCollectionTable(Table table) {
 		this.collectionTable = table;
 	}
 
 	public boolean isSorted() {
 		return sorted;
 	}
 
 	public Comparator getComparator() {
 		if ( comparator == null && comparatorClassName != null ) {
 			try {
 				setComparator( (Comparator) ReflectHelper.classForName( comparatorClassName ).newInstance() );
 			}
-			catch ( Exception e ) {
+			catch (Exception e) {
 				throw new MappingException(
 						"Could not instantiate comparator class [" + comparatorClassName
-						+ "] for collection " + getRole()  
+								+ "] for collection " + getRole()
 				);
 			}
 		}
 		return comparator;
 	}
 
 	public boolean isLazy() {
 		return lazy;
 	}
 
 	public void setLazy(boolean lazy) {
 		this.lazy = lazy;
 	}
 
 	public String getRole() {
 		return role;
 	}
 
 	public abstract CollectionType getDefaultCollectionType() throws MappingException;
 
 	public boolean isPrimitiveArray() {
 		return false;
 	}
 
 	public boolean isArray() {
 		return false;
 	}
 
 	public boolean hasFormula() {
 		return false;
 	}
 
 	public boolean isOneToMany() {
 		return element instanceof OneToMany;
 	}
 
 	public boolean isInverse() {
 		return inverse;
 	}
 
 	public String getOwnerEntityName() {
 		return owner.getEntityName();
 	}
 
 	public String getOrderBy() {
 		return orderBy;
 	}
 
 	public void setComparator(Comparator comparator) {
 		this.comparator = comparator;
 	}
 
 	public void setElement(Value element) {
 		this.element = element;
 	}
 
 	public void setKey(KeyValue key) {
 		this.key = key;
 	}
 
 	public void setOrderBy(String orderBy) {
 		this.orderBy = orderBy;
 	}
 
 	public void setRole(String role) {
 		this.role = role;
 	}
 
 	public void setSorted(boolean sorted) {
 		this.sorted = sorted;
 	}
 
 	public void setInverse(boolean inverse) {
 		this.inverse = inverse;
 	}
 
 	public PersistentClass getOwner() {
 		return owner;
 	}
 
 	/**
-	 * @deprecated Inject the owner into constructor.
-	 *
 	 * @param owner The owner
+	 *
+	 * @deprecated Inject the owner into constructor.
 	 */
 	@Deprecated
-    public void setOwner(PersistentClass owner) {
+	public void setOwner(PersistentClass owner) {
 		this.owner = owner;
 	}
 
 	public String getWhere() {
 		return where;
 	}
 
 	public void setWhere(String where) {
 		this.where = where;
 	}
 
 	public String getManyToManyWhere() {
 		return manyToManyWhere;
 	}
 
 	public void setManyToManyWhere(String manyToManyWhere) {
 		this.manyToManyWhere = manyToManyWhere;
 	}
 
 	public String getManyToManyOrdering() {
 		return manyToManyOrderBy;
 	}
 
 	public void setManyToManyOrdering(String orderFragment) {
 		this.manyToManyOrderBy = orderFragment;
 	}
 
 	public boolean isIdentified() {
 		return false;
 	}
 
 	public boolean hasOrphanDelete() {
 		return orphanDelete;
 	}
 
 	public void setOrphanDelete(boolean orphanDelete) {
 		this.orphanDelete = orphanDelete;
 	}
 
 	public int getBatchSize() {
 		return batchSize;
 	}
 
 	public void setBatchSize(int i) {
 		batchSize = i;
 	}
 
 	public FetchMode getFetchMode() {
 		return fetchMode;
 	}
 
 	public void setFetchMode(FetchMode fetchMode) {
 		this.fetchMode = fetchMode;
 	}
 
 	public void setCollectionPersisterClass(Class persister) {
 		this.collectionPersisterClass = persister;
 	}
 
 	public Class getCollectionPersisterClass() {
 		return collectionPersisterClass;
 	}
 
 	public void validate(Mapping mapping) throws MappingException {
 		assert getKey() != null : "Collection key not bound : " + getRole();
 		assert getElement() != null : "Collection element not bound : " + getRole();
 
 		if ( getKey().isCascadeDeleteEnabled() && ( !isInverse() || !isOneToMany() ) ) {
 			throw new MappingException(
-				"only inverse one-to-many associations may use on-delete=\"cascade\": " 
-				+ getRole() );
+					"only inverse one-to-many associations may use on-delete=\"cascade\": "
+							+ getRole()
+			);
 		}
 		if ( !getKey().isValid( mapping ) ) {
 			throw new MappingException(
-				"collection foreign key mapping has wrong number of columns: "
-				+ getRole()
-				+ " type: "
-				+ getKey().getType().getName() );
+					"collection foreign key mapping has wrong number of columns: "
+							+ getRole()
+							+ " type: "
+							+ getKey().getType().getName()
+			);
 		}
 		if ( !getElement().isValid( mapping ) ) {
-			throw new MappingException( 
-				"collection element mapping has wrong number of columns: "
-				+ getRole()
-				+ " type: "
-				+ getElement().getType().getName() );
+			throw new MappingException(
+					"collection element mapping has wrong number of columns: "
+							+ getRole()
+							+ " type: "
+							+ getElement().getType().getName()
+			);
 		}
 
 		checkColumnDuplication();
-		
-		if ( elementNodeName!=null && elementNodeName.startsWith("@") ) {
-			throw new MappingException("element node must not be an attribute: " + elementNodeName );
+
+		if ( elementNodeName != null && elementNodeName.startsWith( "@" ) ) {
+			throw new MappingException( "element node must not be an attribute: " + elementNodeName );
 		}
-		if ( elementNodeName!=null && elementNodeName.equals(".") ) {
-			throw new MappingException("element node must not be the parent: " + elementNodeName );
+		if ( elementNodeName != null && elementNodeName.equals( "." ) ) {
+			throw new MappingException( "element node must not be the parent: " + elementNodeName );
 		}
-		if ( nodeName!=null && nodeName.indexOf('@')>-1 ) {
-			throw new MappingException("collection node must not be an attribute: " + elementNodeName );
+		if ( nodeName != null && nodeName.indexOf( '@' ) > -1 ) {
+			throw new MappingException( "collection node must not be an attribute: " + elementNodeName );
 		}
 	}
 
 	private void checkColumnDuplication(java.util.Set distinctColumns, Iterator columns)
 			throws MappingException {
 		while ( columns.hasNext() ) {
 			Selectable s = (Selectable) columns.next();
 			if ( !s.isFormula() ) {
 				Column col = (Column) s;
 				if ( !distinctColumns.add( col.getName() ) ) {
-					throw new MappingException( "Repeated column in mapping for collection: "
-						+ getRole()
-						+ " column: "
-						+ col.getName() );
+					throw new MappingException(
+							"Repeated column in mapping for collection: "
+									+ getRole()
+									+ " column: "
+									+ col.getName()
+					);
 				}
 			}
 		}
 	}
 
 	private void checkColumnDuplication() throws MappingException {
 		HashSet cols = new HashSet();
 		checkColumnDuplication( cols, getKey().getColumnIterator() );
 		if ( isIndexed() ) {
-			checkColumnDuplication( cols, ( (IndexedCollection) this )
-				.getIndex()
-				.getColumnIterator() );
+			checkColumnDuplication(
+					cols, ( (IndexedCollection) this )
+							.getIndex()
+							.getColumnIterator()
+			);
 		}
 		if ( isIdentified() ) {
-			checkColumnDuplication( cols, ( (IdentifierCollection) this )
-				.getIdentifier()
-				.getColumnIterator() );
+			checkColumnDuplication(
+					cols, ( (IdentifierCollection) this )
+							.getIdentifier()
+							.getColumnIterator()
+			);
 		}
 		if ( !isOneToMany() ) {
 			checkColumnDuplication( cols, getElement().getColumnIterator() );
 		}
 	}
 
 	public Iterator<Selectable> getColumnIterator() {
 		return Collections.<Selectable>emptyList().iterator();
 	}
 
 	public int getColumnSpan() {
 		return 0;
 	}
 
 	public Type getType() throws MappingException {
 		return getCollectionType();
 	}
 
 	public CollectionType getCollectionType() {
 		if ( typeName == null ) {
 			return getDefaultCollectionType();
 		}
 		else {
 			return metadata.getTypeResolver()
 					.getTypeFactory()
 					.customCollection( typeName, typeParameters, role, referencedPropertyName );
 		}
 	}
 
 	public boolean isNullable() {
 		return true;
 	}
 
 	public boolean isAlternateUniqueKey() {
 		return false;
 	}
 
 	public Table getTable() {
 		return owner.getTable();
 	}
 
 	public void createForeignKey() {
 	}
 
 	public boolean isSimpleValue() {
 		return false;
 	}
 
 	public boolean isValid(Mapping mapping) throws MappingException {
 		return true;
 	}
 
 	private void createForeignKeys() throws MappingException {
 		// if ( !isInverse() ) { // for inverse collections, let the "other end" handle it
 		if ( referencedPropertyName == null ) {
 			getElement().createForeignKey();
 			key.createForeignKeyOfEntity( getOwner().getEntityName() );
 		}
 		// }
 	}
 
 	abstract void createPrimaryKey();
 
 	public void createAllKeys() throws MappingException {
 		createForeignKeys();
 		if ( !isInverse() ) {
 			createPrimaryKey();
 		}
 	}
 
 	public String getCacheConcurrencyStrategy() {
 		return cacheConcurrencyStrategy;
 	}
 
 	public void setCacheConcurrencyStrategy(String cacheConcurrencyStrategy) {
 		this.cacheConcurrencyStrategy = cacheConcurrencyStrategy;
 	}
 
 	public void setTypeUsingReflection(String className, String propertyName) {
 	}
 
 	public String getCacheRegionName() {
 		return cacheRegionName == null ? role : cacheRegionName;
 	}
 
 	public void setCacheRegionName(String cacheRegionName) {
 		this.cacheRegionName = cacheRegionName;
 	}
 
 
-
 	public void setCustomSQLInsert(String customSQLInsert, boolean callable, ExecuteUpdateResultCheckStyle checkStyle) {
 		this.customSQLInsert = customSQLInsert;
 		this.customInsertCallable = callable;
 		this.insertCheckStyle = checkStyle;
 	}
 
 	public String getCustomSQLInsert() {
 		return customSQLInsert;
 	}
 
 	public boolean isCustomInsertCallable() {
 		return customInsertCallable;
 	}
 
 	public ExecuteUpdateResultCheckStyle getCustomSQLInsertCheckStyle() {
 		return insertCheckStyle;
 	}
 
 	public void setCustomSQLUpdate(String customSQLUpdate, boolean callable, ExecuteUpdateResultCheckStyle checkStyle) {
 		this.customSQLUpdate = customSQLUpdate;
 		this.customUpdateCallable = callable;
 		this.updateCheckStyle = checkStyle;
 	}
 
 	public String getCustomSQLUpdate() {
 		return customSQLUpdate;
 	}
 
 	public boolean isCustomUpdateCallable() {
 		return customUpdateCallable;
 	}
 
 	public ExecuteUpdateResultCheckStyle getCustomSQLUpdateCheckStyle() {
 		return updateCheckStyle;
 	}
 
 	public void setCustomSQLDelete(String customSQLDelete, boolean callable, ExecuteUpdateResultCheckStyle checkStyle) {
 		this.customSQLDelete = customSQLDelete;
 		this.customDeleteCallable = callable;
 		this.deleteCheckStyle = checkStyle;
 	}
 
 	public String getCustomSQLDelete() {
 		return customSQLDelete;
 	}
 
 	public boolean isCustomDeleteCallable() {
 		return customDeleteCallable;
 	}
 
 	public ExecuteUpdateResultCheckStyle getCustomSQLDeleteCheckStyle() {
 		return deleteCheckStyle;
 	}
 
-	public void setCustomSQLDeleteAll(String customSQLDeleteAll, boolean callable, ExecuteUpdateResultCheckStyle checkStyle) {
+	public void setCustomSQLDeleteAll(
+			String customSQLDeleteAll,
+			boolean callable,
+			ExecuteUpdateResultCheckStyle checkStyle) {
 		this.customSQLDeleteAll = customSQLDeleteAll;
 		this.customDeleteAllCallable = callable;
 		this.deleteAllCheckStyle = checkStyle;
 	}
 
 	public String getCustomSQLDeleteAll() {
 		return customSQLDeleteAll;
 	}
 
 	public boolean isCustomDeleteAllCallable() {
 		return customDeleteAllCallable;
 	}
 
 	public ExecuteUpdateResultCheckStyle getCustomSQLDeleteAllCheckStyle() {
 		return deleteAllCheckStyle;
 	}
 
-	public void addFilter(String name, String condition, boolean autoAliasInjection, java.util.Map<String,String> aliasTableMap, java.util.Map<String,String> aliasEntityMap) {
-		filters.add(new FilterConfiguration(name, condition, autoAliasInjection, aliasTableMap, aliasEntityMap, null));
+	public void addFilter(
+			String name,
+			String condition,
+			boolean autoAliasInjection,
+			java.util.Map<String, String> aliasTableMap,
+			java.util.Map<String, String> aliasEntityMap) {
+		filters.add(
+				new FilterConfiguration(
+						name,
+						condition,
+						autoAliasInjection,
+						aliasTableMap,
+						aliasEntityMap,
+						null
+				)
+		);
 	}
+
 	public java.util.List getFilters() {
 		return filters;
 	}
 
-	public void addManyToManyFilter(String name, String condition, boolean autoAliasInjection, java.util.Map<String,String> aliasTableMap, java.util.Map<String,String> aliasEntityMap) {
-		manyToManyFilters.add(new FilterConfiguration(name, condition, autoAliasInjection, aliasTableMap, aliasEntityMap, null));
+	public void addManyToManyFilter(
+			String name,
+			String condition,
+			boolean autoAliasInjection,
+			java.util.Map<String, String> aliasTableMap,
+			java.util.Map<String, String> aliasEntityMap) {
+		manyToManyFilters.add(
+				new FilterConfiguration(
+						name,
+						condition,
+						autoAliasInjection,
+						aliasTableMap,
+						aliasEntityMap,
+						null
+				)
+		);
 	}
 
 	public java.util.List getManyToManyFilters() {
 		return manyToManyFilters;
 	}
 
 	@Override
-    public String toString() {
+	public String toString() {
 		return getClass().getName() + '(' + getRole() + ')';
 	}
 
 	public java.util.Set<String> getSynchronizedTables() {
 		return synchronizedTables;
 	}
 
 	public String getLoaderName() {
 		return loaderName;
 	}
 
 	public void setLoaderName(String name) {
 		this.loaderName = name;
 	}
 
 	public String getReferencedPropertyName() {
 		return referencedPropertyName;
 	}
 
 	public void setReferencedPropertyName(String propertyRef) {
 		this.referencedPropertyName = propertyRef;
 	}
 
 	public boolean isOptimisticLocked() {
 		return optimisticLocked;
 	}
 
 	public void setOptimisticLocked(boolean optimisticLocked) {
 		this.optimisticLocked = optimisticLocked;
 	}
 
 	public boolean isMap() {
 		return false;
 	}
 
 	public String getTypeName() {
 		return typeName;
 	}
 
 	public void setTypeName(String typeName) {
 		this.typeName = typeName;
 	}
 
 	public Properties getTypeParameters() {
 		return typeParameters;
 	}
 
 	public void setTypeParameters(Properties parameterMap) {
 		this.typeParameters = parameterMap;
 	}
 
 	public void setTypeParameters(java.util.Map parameterMap) {
 		if ( parameterMap instanceof Properties ) {
 			this.typeParameters = (Properties) parameterMap;
 		}
 		else {
 			this.typeParameters = new Properties();
 			typeParameters.putAll( parameterMap );
 		}
 	}
 
 	public boolean[] getColumnInsertability() {
 		return ArrayHelper.EMPTY_BOOLEAN_ARRAY;
 	}
 
 	public boolean[] getColumnUpdateability() {
 		return ArrayHelper.EMPTY_BOOLEAN_ARRAY;
 	}
 
 	public String getNodeName() {
 		return nodeName;
 	}
 
 	public void setNodeName(String nodeName) {
 		this.nodeName = nodeName;
 	}
 
 	public String getElementNodeName() {
 		return elementNodeName;
 	}
 
 	public void setElementNodeName(String elementNodeName) {
 		this.elementNodeName = elementNodeName;
 	}
 
 	/**
 	 * @deprecated To be removed in 5.  Removed as part of removing the notion of DOM entity-mode.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public boolean isEmbedded() {
 		return embedded;
 	}
 
 	/**
 	 * @deprecated To be removed in 5.  Removed as part of removing the notion of DOM entity-mode.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public void setEmbedded(boolean embedded) {
 		this.embedded = embedded;
 	}
 
 	public boolean isSubselectLoadable() {
 		return subselectLoadable;
 	}
-	
+
 
 	public void setSubselectLoadable(boolean subqueryLoadable) {
 		this.subselectLoadable = subqueryLoadable;
 	}
 
 	public boolean isMutable() {
 		return mutable;
 	}
 
 	public void setMutable(boolean mutable) {
 		this.mutable = mutable;
 	}
 
 	public boolean isExtraLazy() {
 		return extraLazy;
 	}
 
 	public void setExtraLazy(boolean extraLazy) {
 		this.extraLazy = extraLazy;
 	}
-	
+
 	public boolean hasOrder() {
-		return orderBy!=null || manyToManyOrderBy!=null;
+		return orderBy != null || manyToManyOrderBy != null;
 	}
 
 	public void setComparatorClassName(String comparatorClassName) {
-		this.comparatorClassName = comparatorClassName;		
+		this.comparatorClassName = comparatorClassName;
 	}
-	
+
 	public String getComparatorClassName() {
 		return comparatorClassName;
 	}
 
 	public String getMappedByProperty() {
 		return mappedByProperty;
 	}
 
 	public void setMappedByProperty(String mappedByProperty) {
 		this.mappedByProperty = mappedByProperty;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/Column.java b/hibernate-core/src/main/java/org/hibernate/mapping/Column.java
index cd5c0ea641..dd653f8df3 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/Column.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/Column.java
@@ -1,382 +1,397 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
+
 import java.io.Serializable;
 import java.util.Locale;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.sql.Template;
 
 /**
  * A column of a relational database table
+ *
  * @author Gavin King
  */
 public class Column implements Selectable, Serializable, Cloneable {
 
 	public static final int DEFAULT_LENGTH = 255;
 	public static final int DEFAULT_PRECISION = 19;
 	public static final int DEFAULT_SCALE = 2;
 
-	private int length=DEFAULT_LENGTH;
-	private int precision=DEFAULT_PRECISION;
-	private int scale=DEFAULT_SCALE;
+	private int length = DEFAULT_LENGTH;
+	private int precision = DEFAULT_PRECISION;
+	private int scale = DEFAULT_SCALE;
 	private Value value;
 	private int typeIndex;
 	private String name;
-	private boolean nullable=true;
+	private boolean nullable = true;
 	private boolean unique;
 	private String sqlType;
 	private Integer sqlTypeCode;
 	private boolean quoted;
 	int uniqueInteger;
 	private String checkConstraint;
 	private String comment;
 	private String defaultValue;
 	private String customWrite;
 	private String customRead;
 
 	public Column() {
 	}
 
 	public Column(String columnName) {
-		setName(columnName);
+		setName( columnName );
 	}
 
 	public int getLength() {
 		return length;
 	}
+
 	public void setLength(int length) {
 		this.length = length;
 	}
+
 	public Value getValue() {
 		return value;
 	}
+
 	public void setValue(Value value) {
-		this.value= value;
+		this.value = value;
 	}
+
 	public String getName() {
 		return name;
 	}
+
 	public void setName(String name) {
 		if (
-			StringHelper.isNotEmpty( name ) &&
-			Dialect.QUOTE.indexOf( name.charAt(0) ) > -1 //TODO: deprecated, remove eventually
-		) {
-			quoted=true;
-			this.name=name.substring( 1, name.length()-1 );
+				StringHelper.isNotEmpty( name ) &&
+						Dialect.QUOTE.indexOf( name.charAt( 0 ) ) > -1 //TODO: deprecated, remove eventually
+				) {
+			quoted = true;
+			this.name = name.substring( 1, name.length() - 1 );
 		}
 		else {
 			this.name = name;
 		}
 	}
 
-	/** returns quoted name as it would be in the mapping file. */
+	/**
+	 * returns quoted name as it would be in the mapping file.
+	 */
 	public String getQuotedName() {
 		return quoted ?
 				"`" + name + "`" :
 				name;
 	}
 
 	public String getQuotedName(Dialect d) {
 		return quoted ?
-			d.openQuote() + name + d.closeQuote() :
-			name;
+				d.openQuote() + name + d.closeQuote() :
+				name;
 	}
-	
+
 	@Override
 	public String getAlias(Dialect dialect) {
 		final int lastLetter = StringHelper.lastIndexOfLetter( name );
-		final String suffix = Integer.toString(uniqueInteger) + '_';
+		final String suffix = Integer.toString( uniqueInteger ) + '_';
 
 		String alias = name;
 		if ( lastLetter == -1 ) {
 			alias = "column";
 		}
 		else if ( name.length() > lastLetter + 1 ) {
 			alias = name.substring( 0, lastLetter + 1 );
 		}
 
 		boolean useRawName = name.length() + suffix.length() <= dialect.getMaxAliasLength()
-				&& !quoted && !name.toLowerCase(Locale.ROOT).equals( "rowid" );
+				&& !quoted && !name.toLowerCase( Locale.ROOT ).equals( "rowid" );
 		if ( !useRawName ) {
 			if ( suffix.length() >= dialect.getMaxAliasLength() ) {
-				throw new MappingException( String.format(
-						"Unique suffix [%s] length must be less than maximum [%d]",
-						suffix, dialect.getMaxAliasLength() ) );
+				throw new MappingException(
+						String.format(
+								"Unique suffix [%s] length must be less than maximum [%d]",
+								suffix, dialect.getMaxAliasLength()
+						)
+				);
 			}
 			if ( alias.length() + suffix.length() > dialect.getMaxAliasLength() ) {
 				alias = alias.substring( 0, dialect.getMaxAliasLength() - suffix.length() );
 			}
 		}
 		return alias + suffix;
 	}
-	
+
 	/**
 	 * Generate a column alias that is unique across multiple tables
 	 */
 	@Override
 	public String getAlias(Dialect dialect, Table table) {
-		return getAlias(dialect) + table.getUniqueInteger() + '_';
+		return getAlias( dialect ) + table.getUniqueInteger() + '_';
 	}
 
 	public boolean isNullable() {
 		return nullable;
 	}
 
 	public void setNullable(boolean nullable) {
-		this.nullable=nullable;
+		this.nullable = nullable;
 	}
 
 	public int getTypeIndex() {
 		return typeIndex;
 	}
+
 	public void setTypeIndex(int typeIndex) {
 		this.typeIndex = typeIndex;
 	}
 
 	public boolean isUnique() {
 		return unique;
 	}
 
 	@Override
 	public int hashCode() {
 		//used also for generation of FK names!
 		return isQuoted() ?
-			name.hashCode() :
-			name.toLowerCase(Locale.ROOT).hashCode();
+				name.hashCode() :
+				name.toLowerCase( Locale.ROOT ).hashCode();
 	}
 
 	@Override
 	public boolean equals(Object object) {
 		return object instanceof Column && equals( (Column) object );
 	}
 
 	@SuppressWarnings("SimplifiableIfStatement")
 	public boolean equals(Column column) {
-		if (null == column) {
+		if ( null == column ) {
 			return false;
 		}
-		if (this == column) {
+		if ( this == column ) {
 			return true;
 		}
 
 		return isQuoted() ?
-			name.equals(column.name) :
-			name.equalsIgnoreCase(column.name);
-	}
-
-    public int getSqlTypeCode(Mapping mapping) throws MappingException {
-        org.hibernate.type.Type type = getValue().getType();
-        try {
-            int sqlTypeCode = type.sqlTypes( mapping )[getTypeIndex()];
-            if ( getSqlTypeCode() != null && getSqlTypeCode() != sqlTypeCode ) {
-                throw new MappingException( "SQLType code's does not match. mapped as " + sqlTypeCode + " but is " + getSqlTypeCode() );
-            }
-            return sqlTypeCode;
-        }
-        catch ( Exception e ) {
-            throw new MappingException(
-                    "Could not determine type for column " +
-                            name +
-                            " of type " +
-                            type.getClass().getName() +
-                            ": " +
-                            e.getClass().getName(),
-                    e
-            );
-        }
-    }
-
-    /**
-     * Returns the underlying columns sqltypecode.
-     * If null, it is because the sqltype code is unknown.
-     *
-     * Use #getSqlTypeCode(Mapping) to retreive the sqltypecode used
-     * for the columns associated Value/Type.
-     *
-     * @return sqlTypeCode if it is set, otherwise null.
-     */
-    public Integer getSqlTypeCode() {
-        return sqlTypeCode;
-    }
-
-    public void setSqlTypeCode(Integer typeCode) {
-        sqlTypeCode=typeCode;
-    }
-
-    public String getSqlType(Dialect dialect, Mapping mapping) throws HibernateException {
-        if ( sqlType == null ) {
-            sqlType = dialect.getTypeName( getSqlTypeCode( mapping ), getLength(), getPrecision(), getScale() );
-        }
-        return sqlType;
-    }
+				name.equals( column.name ) :
+				name.equalsIgnoreCase( column.name );
+	}
+
+	public int getSqlTypeCode(Mapping mapping) throws MappingException {
+		org.hibernate.type.Type type = getValue().getType();
+		try {
+			int sqlTypeCode = type.sqlTypes( mapping )[getTypeIndex()];
+			if ( getSqlTypeCode() != null && getSqlTypeCode() != sqlTypeCode ) {
+				throw new MappingException( "SQLType code's does not match. mapped as " + sqlTypeCode + " but is " + getSqlTypeCode() );
+			}
+			return sqlTypeCode;
+		}
+		catch (Exception e) {
+			throw new MappingException(
+					"Could not determine type for column " +
+							name +
+							" of type " +
+							type.getClass().getName() +
+							": " +
+							e.getClass().getName(),
+					e
+			);
+		}
+	}
+
+	/**
+	 * Returns the underlying columns sqltypecode.
+	 * If null, it is because the sqltype code is unknown.
+	 * <p/>
+	 * Use #getSqlTypeCode(Mapping) to retreive the sqltypecode used
+	 * for the columns associated Value/Type.
+	 *
+	 * @return sqlTypeCode if it is set, otherwise null.
+	 */
+	public Integer getSqlTypeCode() {
+		return sqlTypeCode;
+	}
+
+	public void setSqlTypeCode(Integer typeCode) {
+		sqlTypeCode = typeCode;
+	}
+
+	public String getSqlType(Dialect dialect, Mapping mapping) throws HibernateException {
+		if ( sqlType == null ) {
+			sqlType = dialect.getTypeName( getSqlTypeCode( mapping ), getLength(), getPrecision(), getScale() );
+		}
+		return sqlType;
+	}
 
 	public String getSqlType() {
 		return sqlType;
 	}
 
 	public void setSqlType(String sqlType) {
 		this.sqlType = sqlType;
 	}
 
 	public void setUnique(boolean unique) {
 		this.unique = unique;
 	}
 
 	public boolean isQuoted() {
 		return quoted;
 	}
 
 	@Override
 	public String toString() {
 		return getClass().getName() + '(' + getName() + ')';
 	}
 
 	public String getCheckConstraint() {
 		return checkConstraint;
 	}
 
 	public void setCheckConstraint(String checkConstraint) {
 		this.checkConstraint = checkConstraint;
 	}
 
 	public boolean hasCheckConstraint() {
-		return checkConstraint!=null;
+		return checkConstraint != null;
 	}
 
 	@Override
 	public String getTemplate(Dialect dialect, SQLFunctionRegistry functionRegistry) {
 		return hasCustomRead()
 				? Template.renderWhereStringTemplate( customRead, dialect, functionRegistry )
 				: Template.TEMPLATE + '.' + getQuotedName( dialect );
 	}
 
 	public boolean hasCustomRead() {
 		return ( customRead != null && customRead.length() > 0 );
 	}
 
 	public String getReadExpr(Dialect dialect) {
 		return hasCustomRead() ? customRead : getQuotedName( dialect );
 	}
-	
+
 	public String getWriteExpr() {
 		return ( customWrite != null && customWrite.length() > 0 ) ? customWrite : "?";
 	}
 
 	@Override
 	public boolean isFormula() {
 		return false;
 	}
 
 	@Override
 	public String getText(Dialect d) {
-		return getQuotedName(d);
+		return getQuotedName( d );
 	}
 
 	@Override
 	public String getText() {
 		return getName();
 	}
-	
+
 	public int getPrecision() {
 		return precision;
 	}
+
 	public void setPrecision(int scale) {
 		this.precision = scale;
 	}
 
 	public int getScale() {
 		return scale;
 	}
+
 	public void setScale(int scale) {
 		this.scale = scale;
 	}
 
 	public String getComment() {
 		return comment;
 	}
 
 	public void setComment(String comment) {
 		this.comment = comment;
 	}
 
 	public String getDefaultValue() {
 		return defaultValue;
 	}
 
 	public void setDefaultValue(String defaultValue) {
 		this.defaultValue = defaultValue;
 	}
 
 	public String getCustomWrite() {
 		return customWrite;
 	}
 
 	public void setCustomWrite(String customWrite) {
 		this.customWrite = customWrite;
 	}
 
 	public String getCustomRead() {
 		return customRead;
 	}
 
 	public void setCustomRead(String customRead) {
 		this.customRead = customRead;
 	}
 
 	public String getCanonicalName() {
-		return quoted ? name : name.toLowerCase(Locale.ROOT);
+		return quoted ? name : name.toLowerCase( Locale.ROOT );
 	}
 
 	/**
 	 * Shallow copy, the value is not copied
 	 */
 	@Override
 	public Column clone() {
 		Column copy = new Column();
 		copy.setLength( length );
 		copy.setScale( scale );
 		copy.setValue( value );
 		copy.setTypeIndex( typeIndex );
 		copy.setName( getQuotedName() );
 		copy.setNullable( nullable );
 		copy.setPrecision( precision );
 		copy.setUnique( unique );
 		copy.setSqlType( sqlType );
 		copy.setSqlTypeCode( sqlTypeCode );
 		copy.uniqueInteger = uniqueInteger; //usually useless
 		copy.setCheckConstraint( checkConstraint );
 		copy.setComment( comment );
 		copy.setDefaultValue( defaultValue );
 		copy.setCustomRead( customRead );
 		copy.setCustomWrite( customWrite );
 		return copy;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/DenormalizedTable.java b/hibernate-core/src/main/java/org/hibernate/mapping/DenormalizedTable.java
index 042f11d240..45c50fb4cd 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/DenormalizedTable.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/DenormalizedTable.java
@@ -1,154 +1,159 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 
 import org.hibernate.boot.model.naming.Identifier;
 import org.hibernate.boot.model.relational.Schema;
 import org.hibernate.internal.util.collections.JoinedIterator;
 
 /**
  * @author Gavin King
  */
 @SuppressWarnings("unchecked")
 public class DenormalizedTable extends Table {
-	
+
 	private final Table includedTable;
-	
+
 	public DenormalizedTable(Table includedTable) {
 		this.includedTable = includedTable;
 		includedTable.setHasDenormalizedTables();
 	}
 
 	public DenormalizedTable(Schema schema, Identifier physicalTableName, boolean isAbstract, Table includedTable) {
 		super( schema, physicalTableName, isAbstract );
 		this.includedTable = includedTable;
 		includedTable.setHasDenormalizedTables();
 	}
 
-	public DenormalizedTable(Schema schema, Identifier physicalTableName, String subselectFragment, boolean isAbstract, Table includedTable) {
+	public DenormalizedTable(
+			Schema schema,
+			Identifier physicalTableName,
+			String subselectFragment,
+			boolean isAbstract,
+			Table includedTable) {
 		super( schema, physicalTableName, subselectFragment, isAbstract );
 		this.includedTable = includedTable;
 		includedTable.setHasDenormalizedTables();
 	}
 
 	public DenormalizedTable(Schema schema, String subselect, boolean isAbstract, Table includedTable) {
 		super( schema, subselect, isAbstract );
 		this.includedTable = includedTable;
 		includedTable.setHasDenormalizedTables();
 	}
 
 	@Override
-    public void createForeignKeys() {
+	public void createForeignKeys() {
 		includedTable.createForeignKeys();
 		Iterator iter = includedTable.getForeignKeyIterator();
 		while ( iter.hasNext() ) {
 			ForeignKey fk = (ForeignKey) iter.next();
-			createForeignKey( 
+			createForeignKey(
 					Constraint.generateName(
 							fk.generatedConstraintNamePrefix(),
 							this,
 							fk.getColumns()
 					),
-					fk.getColumns(), 
+					fk.getColumns(),
 					fk.getReferencedEntityName(),
 					fk.getReferencedColumns()
-				);
+			);
 		}
 	}
 
 	@Override
-    public Column getColumn(Column column) {
+	public Column getColumn(Column column) {
 		Column superColumn = super.getColumn( column );
-		if (superColumn != null) {
+		if ( superColumn != null ) {
 			return superColumn;
 		}
 		else {
 			return includedTable.getColumn( column );
 		}
 	}
 
 	public Column getColumn(Identifier name) {
 		Column superColumn = super.getColumn( name );
 		if ( superColumn != null ) {
 			return superColumn;
 		}
 		else {
 			return includedTable.getColumn( name );
 		}
 	}
 
 	@Override
-    public Iterator getColumnIterator() {
+	public Iterator getColumnIterator() {
 		return new JoinedIterator(
 				includedTable.getColumnIterator(),
 				super.getColumnIterator()
-			);
+		);
 	}
 
 	@Override
-    public boolean containsColumn(Column column) {
-		return super.containsColumn(column) || includedTable.containsColumn(column);
+	public boolean containsColumn(Column column) {
+		return super.containsColumn( column ) || includedTable.containsColumn( column );
 	}
 
 	@Override
-    public PrimaryKey getPrimaryKey() {
+	public PrimaryKey getPrimaryKey() {
 		return includedTable.getPrimaryKey();
 	}
 
 	@Override
-    public Iterator getUniqueKeyIterator() {
+	public Iterator getUniqueKeyIterator() {
 		Iterator iter = includedTable.getUniqueKeyIterator();
 		while ( iter.hasNext() ) {
 			UniqueKey uk = (UniqueKey) iter.next();
 			createUniqueKey( uk.getColumns() );
 		}
 		return getUniqueKeys().values().iterator();
 	}
 
 	@Override
-    public Iterator getIndexIterator() {
+	public Iterator getIndexIterator() {
 		List indexes = new ArrayList();
 		Iterator iter = includedTable.getIndexIterator();
 		while ( iter.hasNext() ) {
 			Index parentIndex = (Index) iter.next();
 			Index index = new Index();
 			index.setName( getName() + parentIndex.getName() );
-			index.setTable(this);
+			index.setTable( this );
 			index.addColumns( parentIndex.getColumnIterator() );
 			indexes.add( index );
 		}
 		return new JoinedIterator(
 				indexes.iterator(),
 				super.getIndexIterator()
-			);
+		);
 	}
 
 	public Table getIncludedTable() {
 		return includedTable;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/ForeignKey.java b/hibernate-core/src/main/java/org/hibernate/mapping/ForeignKey.java
index 9e93c07b39..c7d4768b32 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/ForeignKey.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/ForeignKey.java
@@ -1,233 +1,245 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
+
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 
 import org.hibernate.MappingException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * A foreign key constraint
+ *
  * @author Gavin King
  */
 public class ForeignKey extends Constraint {
 	private Table referencedTable;
 	private String referencedEntityName;
 	private boolean cascadeDeleteEnabled;
 	private List<Column> referencedColumns = new ArrayList<Column>();
 	private boolean creationEnabled = true;
 
 	public ForeignKey() {
 	}
 
 	@Override
 	public String getExportIdentifier() {
 		// NOt sure name is always set.  Might need some implicit naming
 		return StringHelper.qualify( getTable().getName(), "FK-" + getName() );
 	}
 
 	public void disableCreation() {
 		creationEnabled = false;
 	}
 
 	public boolean isCreationEnabled() {
 		return creationEnabled;
 	}
 
 	@Override
 	public void setName(String name) {
 		super.setName( name );
 		// the FK name "none" is a magic value in the hbm.xml binding that indicated to
 		// not create a FK.
 		if ( "none".equals( name ) ) {
 			disableCreation();
 		}
 	}
 
-	public String sqlConstraintString(Dialect dialect, String constraintName, String defaultCatalog, String defaultSchema) {
-		String[] columnNames = new String[ getColumnSpan() ];
-		String[] referencedColumnNames = new String[ getColumnSpan() ];
+	public String sqlConstraintString(
+			Dialect dialect,
+			String constraintName,
+			String defaultCatalog,
+			String defaultSchema) {
+		String[] columnNames = new String[getColumnSpan()];
+		String[] referencedColumnNames = new String[getColumnSpan()];
 
 		final Iterator<Column> referencedColumnItr;
 		if ( isReferenceToPrimaryKey() ) {
 			referencedColumnItr = referencedTable.getPrimaryKey().getColumnIterator();
-		} 
+		}
 		else {
 			referencedColumnItr = referencedColumns.iterator();
 		}
-		
+
 		Iterator columnItr = getColumnIterator();
-		int i=0;
+		int i = 0;
 		while ( columnItr.hasNext() ) {
-			columnNames[i] = ( (Column) columnItr.next() ).getQuotedName(dialect);
-			referencedColumnNames[i] = referencedColumnItr.next().getQuotedName(dialect);
+			columnNames[i] = ( (Column) columnItr.next() ).getQuotedName( dialect );
+			referencedColumnNames[i] = referencedColumnItr.next().getQuotedName( dialect );
 			i++;
 		}
 
 		final String result = dialect.getAddForeignKeyConstraintString(
-			constraintName,
-			columnNames,
-			referencedTable.getQualifiedName(dialect, defaultCatalog, defaultSchema),
-			referencedColumnNames,
-			isReferenceToPrimaryKey()
+				constraintName,
+				columnNames,
+				referencedTable.getQualifiedName( dialect, defaultCatalog, defaultSchema ),
+				referencedColumnNames,
+				isReferenceToPrimaryKey()
 		);
 		return cascadeDeleteEnabled && dialect.supportsCascadeDelete()
 				? result + " on delete cascade"
 				: result;
 	}
 
 	public Table getReferencedTable() {
 		return referencedTable;
 	}
 
 	private void appendColumns(StringBuilder buf, Iterator columns) {
-		while( columns.hasNext() ) {
+		while ( columns.hasNext() ) {
 			Column column = (Column) columns.next();
 			buf.append( column.getName() );
 			if ( columns.hasNext() ) {
-				buf.append(",");
+				buf.append( "," );
 			}
 		}
 	}
 
 	public void setReferencedTable(Table referencedTable) throws MappingException {
 		//if( isReferenceToPrimaryKey() ) alignColumns(referencedTable); // TODO: possibly remove to allow more piecemal building of a foreignkey.  
-		
+
 		this.referencedTable = referencedTable;
 	}
 
 	/**
 	 * Validates that columnspan of the foreignkey and the primarykey is the same.
-	 * 
+	 * <p/>
 	 * Furthermore it aligns the length of the underlying tables columns.
 	 */
 	public void alignColumns() {
 		if ( isReferenceToPrimaryKey() ) {
-			alignColumns(referencedTable);
+			alignColumns( referencedTable );
 		}
 	}
-	
+
 	private void alignColumns(Table referencedTable) {
 		final int referencedPkColumnSpan = referencedTable.getPrimaryKey().getColumnSpan();
 		if ( referencedPkColumnSpan != getColumnSpan() ) {
 			StringBuilder sb = new StringBuilder();
 			sb.append( "Foreign key (" ).append( getName() ).append( ":" )
 					.append( getTable().getName() )
 					.append( " [" );
 			appendColumns( sb, getColumnIterator() );
-			sb.append("])")
+			sb.append( "])" )
 					.append( ") must have same number of columns as the referenced primary key (" )
 					.append( referencedTable.getName() )
 					.append( " [" );
 			appendColumns( sb, referencedTable.getPrimaryKey().getColumnIterator() );
-			sb.append("])");
+			sb.append( "])" );
 			throw new MappingException( sb.toString() );
 		}
-		
+
 		Iterator fkCols = getColumnIterator();
 		Iterator pkCols = referencedTable.getPrimaryKey().getColumnIterator();
 		while ( pkCols.hasNext() ) {
 			( (Column) fkCols.next() ).setLength( ( (Column) pkCols.next() ).getLength() );
 		}
 
 	}
 
 	public String getReferencedEntityName() {
 		return referencedEntityName;
 	}
 
 	public void setReferencedEntityName(String referencedEntityName) {
 		this.referencedEntityName = referencedEntityName;
 	}
 
 	public String sqlDropString(Dialect dialect, String defaultCatalog, String defaultSchema) {
 		final StringBuilder buf = new StringBuilder( "alter table " );
-		buf.append( getTable().getQualifiedName(dialect, defaultCatalog, defaultSchema) );
+		buf.append( getTable().getQualifiedName( dialect, defaultCatalog, defaultSchema ) );
 		buf.append( dialect.getDropForeignKeyString() );
 		if ( dialect.supportsIfExistsBeforeConstraintName() ) {
 			buf.append( "if exists " );
 		}
 		buf.append( dialect.quote( getName() ) );
 		if ( dialect.supportsIfExistsAfterConstraintName() ) {
 			buf.append( " if exists" );
 		}
 		return buf.toString();
 	}
 
 	public boolean isCascadeDeleteEnabled() {
 		return cascadeDeleteEnabled;
 	}
 
 	public void setCascadeDeleteEnabled(boolean cascadeDeleteEnabled) {
 		this.cascadeDeleteEnabled = cascadeDeleteEnabled;
 	}
-	
+
 	public boolean isPhysicalConstraint() {
 		return referencedTable.isPhysicalTable()
 				&& getTable().isPhysicalTable()
 				&& !referencedTable.hasDenormalizedTables();
 	}
 
-	/** Returns the referenced columns if the foreignkey does not refer to the primary key */
+	/**
+	 * Returns the referenced columns if the foreignkey does not refer to the primary key
+	 */
 	public List getReferencedColumns() {
-		return referencedColumns;		
+		return referencedColumns;
 	}
 
-	/** Does this foreignkey reference the primary key of the reference table */ 
+	/**
+	 * Does this foreignkey reference the primary key of the reference table
+	 */
 	public boolean isReferenceToPrimaryKey() {
 		return referencedColumns.isEmpty();
 	}
 
 	public void addReferencedColumns(Iterator referencedColumnsIterator) {
 		while ( referencedColumnsIterator.hasNext() ) {
 			Selectable col = (Selectable) referencedColumnsIterator.next();
-			if ( !col.isFormula() ) addReferencedColumn( (Column) col );
+			if ( !col.isFormula() ) {
+				addReferencedColumn( (Column) col );
+			}
 		}
 	}
 
 	private void addReferencedColumn(Column column) {
-		if ( !referencedColumns.contains(column) ) {
+		if ( !referencedColumns.contains( column ) ) {
 			referencedColumns.add( column );
 		}
 	}
-	
+
 	public String toString() {
-		if(!isReferenceToPrimaryKey() ) {
+		if ( !isReferenceToPrimaryKey() ) {
 			return getClass().getName()
 					+ '(' + getTable().getName() + getColumns()
 					+ " ref-columns:" + '(' + getReferencedColumns() + ") as " + getName() + ")";
-		} 
+		}
 		else {
 			return super.toString();
 		}
-		
+
 	}
-	
+
 	public String generatedConstraintNamePrefix() {
 		return "FK_";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/Index.java b/hibernate-core/src/main/java/org/hibernate/mapping/Index.java
index d667145afa..417f8fcb47 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/Index.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/Index.java
@@ -1,249 +1,251 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.Iterator;
 
 import org.hibernate.HibernateException;
 import org.hibernate.boot.Metadata;
 import org.hibernate.boot.model.relational.Exportable;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * A relational table index
  *
  * @author Gavin King
  */
 public class Index implements RelationalModel, Exportable, Serializable {
 	private Table table;
 	private java.util.List<Column> columns = new ArrayList<Column>();
 	private java.util.Map<Column, String> columnOrderMap = new HashMap<Column, String>(  );
 	private String name;
 
 	public String sqlCreateString(Dialect dialect, Mapping mapping, String defaultCatalog, String defaultSchema)
 			throws HibernateException {
 		return buildSqlCreateIndexString(
 				dialect,
 				getName(),
 				getTable(),
 				getColumnIterator(),
 				columnOrderMap,
 				false,
 				defaultCatalog,
 				defaultSchema
 		);
 	}
 
 	public static String buildSqlDropIndexString(
 			Dialect dialect,
 			Table table,
 			String name,
 			String defaultCatalog,
 			String defaultSchema) {
 		return buildSqlDropIndexString( name, table.getQualifiedName( dialect, defaultCatalog, defaultSchema ) );
 	}
 
 	public static String buildSqlDropIndexString(
 			String name,
 			String tableName) {
 		return "drop index " + StringHelper.qualify( tableName, name );
 	}
 
 	public static String buildSqlCreateIndexString(
 			Dialect dialect,
 			String name,
 			Table table,
 			Iterator<Column> columns,
 			java.util.Map<Column, String> columnOrderMap,
 			boolean unique,
 			String defaultCatalog,
 			String defaultSchema) {
 		return buildSqlCreateIndexString(
 				dialect,
 				name,
 				table.getQualifiedName( dialect, defaultCatalog, defaultSchema ),
 				columns,
 				columnOrderMap,
 				unique
 		);
 	}
 
 	public static String buildSqlCreateIndexString(
 			Dialect dialect,
 			String name,
 			String tableName,
 			Iterator<Column> columns,
 			java.util.Map<Column, String> columnOrderMap,
 			boolean unique) {
 		StringBuilder buf = new StringBuilder( "create" )
 				.append( unique ? " unique" : "" )
 				.append( " index " )
 				.append( dialect.qualifyIndexName() ? name : StringHelper.unqualify( name ) )
 				.append( " on " )
 				.append( tableName )
 				.append( " (" );
 		while ( columns.hasNext() ) {
 			Column column = columns.next();
 			buf.append( column.getQuotedName( dialect ) );
 			if ( columnOrderMap.containsKey( column ) ) {
 				buf.append( " " ).append( columnOrderMap.get( column ) );
 			}
 			if ( columns.hasNext() ) {
 				buf.append( ", " );
 			}
 		}
 		buf.append( ")" );
 		return buf.toString();
 	}
 
 	public static String buildSqlCreateIndexString(
 			Dialect dialect,
 			String name,
 			Table table,
 			Iterator<Column> columns,
 			boolean unique,
 			String defaultCatalog,
 			String defaultSchema) {
 		return buildSqlCreateIndexString(
 				dialect,
 				name,
 				table,
 				columns,
 				Collections.EMPTY_MAP,
 				unique,
 				defaultCatalog,
 				defaultSchema
 		);
 	}
 
 	public static String buildSqlCreateIndexString(
 			Dialect dialect,
 			String name,
 			Table table,
 			Iterator<Column> columns,
 			java.util.Map<Column, String> columnOrderMap,
 			boolean unique,
 			Metadata metadata) {
 		final JdbcEnvironment jdbcEnvironment = metadata.getDatabase().getJdbcEnvironment();
 
 		final String tableName = jdbcEnvironment.getQualifiedObjectNameFormatter().format(
 				table.getQualifiedTableName(),
 				dialect
 		);
 
 		return buildSqlCreateIndexString(
 				dialect,
 				name,
 				tableName,
 				columns,
 				columnOrderMap,
 				unique
 		);
 	}
 
 
 	// Used only in Table for sqlCreateString (but commented out at the moment)
 	public String sqlConstraintString(Dialect dialect) {
 		StringBuilder buf = new StringBuilder( " index (" );
 		Iterator iter = getColumnIterator();
 		while ( iter.hasNext() ) {
 			buf.append( ( (Column) iter.next() ).getQuotedName( dialect ) );
-			if ( iter.hasNext() ) buf.append( ", " );
+			if ( iter.hasNext() ) {
+				buf.append( ", " );
+			}
 		}
 		return buf.append( ')' ).toString();
 	}
 
+	@Override
 	public String sqlDropString(Dialect dialect, String defaultCatalog, String defaultSchema) {
 		return "drop index " +
 				StringHelper.qualify(
 						table.getQualifiedName( dialect, defaultCatalog, defaultSchema ),
 						name
 				);
 	}
 
 	public Table getTable() {
 		return table;
 	}
 
 	public void setTable(Table table) {
 		this.table = table;
 	}
 
 	public int getColumnSpan() {
 		return columns.size();
 	}
 
 	public Iterator<Column> getColumnIterator() {
 		return columns.iterator();
 	}
 
 	public void addColumn(Column column) {
 		if ( !columns.contains( column ) ) {
 			columns.add( column );
 		}
 	}
 
 	public void addColumn(Column column, String order) {
 		addColumn( column );
 		if ( StringHelper.isNotEmpty( order ) ) {
 			columnOrderMap.put( column, order );
 		}
 	}
 
 	public void addColumns(Iterator extraColumns) {
-		while ( extraColumns.hasNext() ) addColumn( (Column) extraColumns.next() );
+		while ( extraColumns.hasNext() ) {
+			addColumn( (Column) extraColumns.next() );
+		}
 	}
 
-	/**
-	 * @param column
-	 * @return true if this constraint already contains a column with same name.
-	 */
 	public boolean containsColumn(Column column) {
 		return columns.contains( column );
 	}
 
 	public String getName() {
 		return name;
 	}
 
 	public void setName(String name) {
 		this.name = name;
 	}
 
+	@Override
 	public String toString() {
 		return getClass().getName() + "(" + getName() + ")";
 	}
 
 	@Override
 	public String getExportIdentifier() {
 		return StringHelper.qualify( getTable().getName(), "IDX-" + getName() );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/OneToMany.java b/hibernate-core/src/main/java/org/hibernate/mapping/OneToMany.java
index db00797614..69c41e218d 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/OneToMany.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/OneToMany.java
@@ -1,180 +1,182 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.util.Iterator;
 
 import org.hibernate.FetchMode;
 import org.hibernate.MappingException;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 /**
  * A mapping for a one-to-many association
+ *
  * @author Gavin King
  */
 public class OneToMany implements Value {
 	private final MetadataImplementor metadata;
 	private final Table referencingTable;
 
 	private String referencedEntityName;
 	private PersistentClass associatedClass;
 	private boolean embedded;
 	private boolean ignoreNotFound;
 
 	public OneToMany(MetadataImplementor metadata, PersistentClass owner) throws MappingException {
 		this.metadata = metadata;
-		this.referencingTable = (owner==null) ? null : owner.getTable();
+		this.referencingTable = ( owner == null ) ? null : owner.getTable();
 	}
 
 	private EntityType getEntityType() {
 		return metadata.getTypeResolver().getTypeFactory().manyToOne(
 				getReferencedEntityName(),
-				true, 
-				null, 
+				true,
+				null,
 				false,
 				false,
 				isIgnoreNotFound(),
 				false
-			);
+		);
 	}
 
 	public PersistentClass getAssociatedClass() {
 		return associatedClass;
 	}
 
-    /**
-     * Associated entity on the many side
-     */
+	/**
+	 * Associated entity on the many side
+	 */
 	public void setAssociatedClass(PersistentClass associatedClass) {
 		this.associatedClass = associatedClass;
 	}
 
 	public void createForeignKey() {
 		// no foreign key element of for a one-to-many
 	}
 
 	public Iterator<Selectable> getColumnIterator() {
 		return associatedClass.getKey().getColumnIterator();
 	}
 
 	public int getColumnSpan() {
 		return associatedClass.getKey().getColumnSpan();
 	}
 
 	public FetchMode getFetchMode() {
 		return FetchMode.JOIN;
 	}
 
-    /** 
-     * Table of the owner entity (the "one" side)
-     */
+	/**
+	 * Table of the owner entity (the "one" side)
+	 */
 	public Table getTable() {
 		return referencingTable;
 	}
 
 	public Type getType() {
 		return getEntityType();
 	}
 
 	public boolean isNullable() {
 		return false;
 	}
 
 	public boolean isSimpleValue() {
 		return false;
 	}
 
 	public boolean isAlternateUniqueKey() {
 		return false;
 	}
 
 	public boolean hasFormula() {
 		return false;
 	}
-	
+
 	public boolean isValid(Mapping mapping) throws MappingException {
-		if (referencedEntityName==null) {
-			throw new MappingException("one to many association must specify the referenced entity");
+		if ( referencedEntityName == null ) {
+			throw new MappingException( "one to many association must specify the referenced entity" );
 		}
 		return true;
 	}
 
-    public String getReferencedEntityName() {
+	public String getReferencedEntityName() {
 		return referencedEntityName;
 	}
 
-    /** 
-     * Associated entity on the "many" side
-     */    
+	/**
+	 * Associated entity on the "many" side
+	 */
 	public void setReferencedEntityName(String referencedEntityName) {
-		this.referencedEntityName = referencedEntityName==null ? null : referencedEntityName.intern();
+		this.referencedEntityName = referencedEntityName == null ? null : referencedEntityName.intern();
+	}
+
+	public void setTypeUsingReflection(String className, String propertyName) {
 	}
 
-	public void setTypeUsingReflection(String className, String propertyName) {}
-	
 	public Object accept(ValueVisitor visitor) {
-		return visitor.accept(this);
+		return visitor.accept( this );
 	}
-	
-	
+
+
 	public boolean[] getColumnInsertability() {
 		//TODO: we could just return all false...
 		throw new UnsupportedOperationException();
 	}
-	
+
 	public boolean[] getColumnUpdateability() {
 		//TODO: we could just return all false...
 		throw new UnsupportedOperationException();
 	}
 
 	/**
 	 * @deprecated To be removed in 5.  Removed as part of removing the notion of DOM entity-mode.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public boolean isEmbedded() {
 		return embedded;
 	}
 
 	/**
 	 * @deprecated To be removed in 5.  Removed as part of removing the notion of DOM entity-mode.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public void setEmbedded(boolean embedded) {
 		this.embedded = embedded;
 	}
 
 	public boolean isIgnoreNotFound() {
 		return ignoreNotFound;
 	}
 
 	public void setIgnoreNotFound(boolean ignoreNotFound) {
 		this.ignoreNotFound = ignoreNotFound;
 	}
-	
+
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/PersistentClass.java b/hibernate-core/src/main/java/org/hibernate/mapping/PersistentClass.java
index 77fc5431d9..0cf7b07ed1 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/PersistentClass.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/PersistentClass.java
@@ -1,886 +1,933 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Set;
 import java.util.StringTokenizer;
 
 import org.hibernate.EntityMode;
 import org.hibernate.MappingException;
-import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.OptimisticLockStyle;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.internal.FilterConfiguration;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.EmptyIterator;
 import org.hibernate.internal.util.collections.JoinedIterator;
 import org.hibernate.internal.util.collections.SingletonIterator;
 import org.hibernate.sql.Alias;
 
 /**
  * Mapping for an entity.
  *
  * @author Gavin King
  */
 public abstract class PersistentClass implements AttributeContainer, Serializable, Filterable, MetaAttributable {
 
-	private static final Alias PK_ALIAS = new Alias(15, "PK");
+	private static final Alias PK_ALIAS = new Alias( 15, "PK" );
 
 	public static final String NULL_DISCRIMINATOR_MAPPING = "null";
 	public static final String NOT_NULL_DISCRIMINATOR_MAPPING = "not null";
 
 	private String entityName;
 
 	private String className;
 	private transient Class mappedClass;
-	
+
 	private String proxyInterfaceName;
 	private transient Class proxyInterface;
-	
+
 	private String nodeName;
 	private String jpaEntityName;
 
 	private String discriminatorValue;
 	private boolean lazy;
 	private ArrayList properties = new ArrayList();
 	private ArrayList declaredProperties = new ArrayList();
 	private final ArrayList<Subclass> subclasses = new ArrayList<Subclass>();
 	private final ArrayList subclassProperties = new ArrayList();
 	private final ArrayList subclassTables = new ArrayList();
 	private boolean dynamicInsert;
 	private boolean dynamicUpdate;
-	private int batchSize=-1;
+	private int batchSize = -1;
 	private boolean selectBeforeUpdate;
 	private java.util.Map metaAttributes;
 	private ArrayList<Join> joins = new ArrayList<Join>();
 	private final ArrayList subclassJoins = new ArrayList();
 	private final java.util.List filters = new ArrayList();
 	protected final java.util.Set synchronizedTables = new HashSet();
 	private String loaderName;
 	private Boolean isAbstract;
 	private boolean hasSubselectLoadableCollections;
 	private Component identifierMapper;
 
 	// Custom SQL
 	private String customSQLInsert;
 	private boolean customInsertCallable;
 	private ExecuteUpdateResultCheckStyle insertCheckStyle;
 	private String customSQLUpdate;
 	private boolean customUpdateCallable;
 	private ExecuteUpdateResultCheckStyle updateCheckStyle;
 	private String customSQLDelete;
 	private boolean customDeleteCallable;
 	private ExecuteUpdateResultCheckStyle deleteCheckStyle;
 
 	private java.util.Map tuplizerImpls;
 
 	private MappedSuperclass superMappedSuperclass;
 	private Component declaredIdentifierMapper;
 	private OptimisticLockStyle optimisticLockStyle;
 
 	public String getClassName() {
 		return className;
 	}
 
 	public void setClassName(String className) {
-		this.className = className==null ? null : className.intern();
+		this.className = className == null ? null : className.intern();
 		this.mappedClass = null;
 	}
 
 	public String getProxyInterfaceName() {
 		return proxyInterfaceName;
 	}
 
 	public void setProxyInterfaceName(String proxyInterfaceName) {
 		this.proxyInterfaceName = proxyInterfaceName;
 		this.proxyInterface = null;
 	}
 
 	public Class getMappedClass() throws MappingException {
-		if (className==null) {
+		if ( className == null ) {
 			return null;
 		}
 		try {
-			if (mappedClass == null) {
-				mappedClass = ReflectHelper.classForName(className);
+			if ( mappedClass == null ) {
+				mappedClass = ReflectHelper.classForName( className );
 			}
 			return mappedClass;
 		}
 		catch (ClassNotFoundException cnfe) {
-			throw new MappingException("entity class not found: " + className, cnfe);
+			throw new MappingException( "entity class not found: " + className, cnfe );
 		}
 	}
 
 	public Class getProxyInterface() {
-		if (proxyInterfaceName==null) {
+		if ( proxyInterfaceName == null ) {
 			return null;
 		}
 		try {
-			if (proxyInterface == null) {
+			if ( proxyInterface == null ) {
 				proxyInterface = ReflectHelper.classForName( proxyInterfaceName );
 			}
 			return proxyInterface;
 		}
 		catch (ClassNotFoundException cnfe) {
-			throw new MappingException("proxy class not found: " + proxyInterfaceName, cnfe);
+			throw new MappingException( "proxy class not found: " + proxyInterfaceName, cnfe );
 		}
 	}
 
 	public boolean useDynamicInsert() {
 		return dynamicInsert;
 	}
 
 	abstract int nextSubclassId();
+
 	public abstract int getSubclassId();
-	
+
 	public boolean useDynamicUpdate() {
 		return dynamicUpdate;
 	}
 
 	public void setDynamicInsert(boolean dynamicInsert) {
 		this.dynamicInsert = dynamicInsert;
 	}
 
 	public void setDynamicUpdate(boolean dynamicUpdate) {
 		this.dynamicUpdate = dynamicUpdate;
 	}
 
 
 	public String getDiscriminatorValue() {
 		return discriminatorValue;
 	}
 
 	public void addSubclass(Subclass subclass) throws MappingException {
 		// inheritance cycle detection (paranoid check)
 		PersistentClass superclass = getSuperclass();
-		while (superclass!=null) {
+		while ( superclass != null ) {
 			if ( subclass.getEntityName().equals( superclass.getEntityName() ) ) {
 				throw new MappingException(
-					"Circular inheritance mapping detected: " +
-					subclass.getEntityName() +
-					" will have it self as superclass when extending " +
-					getEntityName()
+						"Circular inheritance mapping detected: " +
+								subclass.getEntityName() +
+								" will have it self as superclass when extending " +
+								getEntityName()
 				);
 			}
 			superclass = superclass.getSuperclass();
 		}
-		subclasses.add(subclass);
+		subclasses.add( subclass );
 	}
 
 	public boolean hasSubclasses() {
 		return subclasses.size() > 0;
 	}
 
 	public int getSubclassSpan() {
 		int n = subclasses.size();
-		Iterator iter = subclasses.iterator();
-		while ( iter.hasNext() ) {
-			n += ( (Subclass) iter.next() ).getSubclassSpan();
+		for ( Subclass subclass : subclasses ) {
+			n += subclass.getSubclassSpan();
 		}
 		return n;
 	}
+
 	/**
 	 * Iterate over subclasses in a special 'order', most derived subclasses
 	 * first.
 	 */
-	public Iterator getSubclassIterator() {
-		Iterator[] iters = new Iterator[ subclasses.size() + 1 ];
+	public Iterator<Subclass> getSubclassIterator() {
+		Iterator[] iters = new Iterator[subclasses.size() + 1];
 		Iterator iter = subclasses.iterator();
-		int i=0;
+		int i = 0;
 		while ( iter.hasNext() ) {
 			iters[i++] = ( (Subclass) iter.next() ).getSubclassIterator();
 		}
 		iters[i] = subclasses.iterator();
-		return new JoinedIterator(iters);
+		return new JoinedIterator( iters );
 	}
 
 	public Iterator getSubclassClosureIterator() {
 		ArrayList iters = new ArrayList();
-		iters.add( new SingletonIterator(this) );
+		iters.add( new SingletonIterator( this ) );
 		Iterator iter = getSubclassIterator();
 		while ( iter.hasNext() ) {
-			PersistentClass clazz = (PersistentClass)  iter.next();
+			PersistentClass clazz = (PersistentClass) iter.next();
 			iters.add( clazz.getSubclassClosureIterator() );
 		}
-		return new JoinedIterator(iters);
+		return new JoinedIterator( iters );
 	}
-	
+
 	public Table getIdentityTable() {
 		return getRootTable();
 	}
-	
+
 	public Iterator getDirectSubclasses() {
 		return subclasses.iterator();
 	}
 
 	@Override
 	public void addProperty(Property p) {
-		properties.add(p);
-		declaredProperties.add(p);
-		p.setPersistentClass(this);
+		properties.add( p );
+		declaredProperties.add( p );
+		p.setPersistentClass( this );
 	}
 
 	public abstract Table getTable();
 
 	public String getEntityName() {
 		return entityName;
 	}
 
 	public abstract boolean isMutable();
+
 	public abstract boolean hasIdentifierProperty();
+
 	public abstract Property getIdentifierProperty();
+
 	public abstract Property getDeclaredIdentifierProperty();
+
 	public abstract KeyValue getIdentifier();
+
 	public abstract Property getVersion();
+
 	public abstract Property getDeclaredVersion();
+
 	public abstract Value getDiscriminator();
+
 	public abstract boolean isInherited();
+
 	public abstract boolean isPolymorphic();
+
 	public abstract boolean isVersioned();
+
 	public abstract String getNaturalIdCacheRegionName();
+
 	public abstract String getCacheConcurrencyStrategy();
+
 	public abstract PersistentClass getSuperclass();
+
 	public abstract boolean isExplicitPolymorphism();
+
 	public abstract boolean isDiscriminatorInsertable();
 
 	public abstract Iterator getPropertyClosureIterator();
+
 	public abstract Iterator getTableClosureIterator();
+
 	public abstract Iterator getKeyClosureIterator();
 
 	protected void addSubclassProperty(Property prop) {
-		subclassProperties.add(prop);
+		subclassProperties.add( prop );
 	}
+
 	protected void addSubclassJoin(Join join) {
-		subclassJoins.add(join);
+		subclassJoins.add( join );
 	}
+
 	protected void addSubclassTable(Table subclassTable) {
-		subclassTables.add(subclassTable);
+		subclassTables.add( subclassTable );
 	}
+
 	public Iterator getSubclassPropertyClosureIterator() {
 		ArrayList iters = new ArrayList();
 		iters.add( getPropertyClosureIterator() );
 		iters.add( subclassProperties.iterator() );
-		for ( int i=0; i<subclassJoins.size(); i++ ) {
-			Join join = (Join) subclassJoins.get(i);
+		for ( int i = 0; i < subclassJoins.size(); i++ ) {
+			Join join = (Join) subclassJoins.get( i );
 			iters.add( join.getPropertyIterator() );
 		}
-		return new JoinedIterator(iters);
+		return new JoinedIterator( iters );
 	}
+
 	public Iterator getSubclassJoinClosureIterator() {
 		return new JoinedIterator( getJoinClosureIterator(), subclassJoins.iterator() );
 	}
+
 	public Iterator getSubclassTableClosureIterator() {
 		return new JoinedIterator( getTableClosureIterator(), subclassTables.iterator() );
 	}
 
 	public boolean isClassOrSuperclassJoin(Join join) {
-		return joins.contains(join);
+		return joins.contains( join );
 	}
 
 	public boolean isClassOrSuperclassTable(Table closureTable) {
-		return getTable()==closureTable;
+		return getTable() == closureTable;
 	}
 
 	public boolean isLazy() {
 		return lazy;
 	}
 
 	public void setLazy(boolean lazy) {
 		this.lazy = lazy;
 	}
 
 	public abstract boolean hasEmbeddedIdentifier();
+
 	public abstract Class getEntityPersisterClass();
+
 	public abstract void setEntityPersisterClass(Class classPersisterClass);
+
 	public abstract Table getRootTable();
+
 	public abstract RootClass getRootClass();
+
 	public abstract KeyValue getKey();
 
 	public void setDiscriminatorValue(String discriminatorValue) {
 		this.discriminatorValue = discriminatorValue;
 	}
 
 	public void setEntityName(String entityName) {
-		this.entityName = entityName==null ? null : entityName.intern();
+		this.entityName = entityName == null ? null : entityName.intern();
 	}
 
 	public void createPrimaryKey() {
 		//Primary key constraint
 		PrimaryKey pk = new PrimaryKey();
 		Table table = getTable();
-		pk.setTable(table);
+		pk.setTable( table );
 		pk.setName( PK_ALIAS.toAliasString( table.getName() ) );
-		table.setPrimaryKey(pk);
+		table.setPrimaryKey( pk );
 
 		pk.addColumns( getKey().getColumnIterator() );
 	}
 
 	public abstract String getWhere();
 
 	public int getBatchSize() {
 		return batchSize;
 	}
 
 	public void setBatchSize(int batchSize) {
 		this.batchSize = batchSize;
 	}
 
 	public boolean hasSelectBeforeUpdate() {
 		return selectBeforeUpdate;
 	}
 
 	public void setSelectBeforeUpdate(boolean selectBeforeUpdate) {
 		this.selectBeforeUpdate = selectBeforeUpdate;
 	}
 
 	/**
 	 * Build an iterator of properties which are "referenceable".
 	 *
-	 * @see #getReferencedProperty for a discussion of "referenceable"
 	 * @return The property iterator.
+	 *
+	 * @see #getReferencedProperty for a discussion of "referenceable"
 	 */
 	public Iterator getReferenceablePropertyIterator() {
 		return getPropertyClosureIterator();
 	}
 
 	/**
 	 * Given a property path, locate the appropriate referenceable property reference.
 	 * <p/>
 	 * A referenceable property is a property  which can be a target of a foreign-key
 	 * mapping (an identifier or explcitly named in a property-ref).
 	 *
 	 * @param propertyPath The property path to resolve into a property reference.
+	 *
 	 * @return The property reference (never null).
+	 *
 	 * @throws MappingException If the property could not be found.
 	 */
 	public Property getReferencedProperty(String propertyPath) throws MappingException {
 		try {
 			return getRecursiveProperty( propertyPath, getReferenceablePropertyIterator() );
 		}
-		catch ( MappingException e ) {
+		catch (MappingException e) {
 			throw new MappingException(
 					"property-ref [" + propertyPath + "] not found on entity [" + getEntityName() + "]", e
 			);
 		}
 	}
 
 	public Property getRecursiveProperty(String propertyPath) throws MappingException {
 		try {
 			return getRecursiveProperty( propertyPath, getPropertyIterator() );
 		}
-		catch ( MappingException e ) {
+		catch (MappingException e) {
 			throw new MappingException(
 					"property [" + propertyPath + "] not found on entity [" + getEntityName() + "]", e
 			);
 		}
 	}
 
 	private Property getRecursiveProperty(String propertyPath, Iterator iter) throws MappingException {
 		Property property = null;
 		StringTokenizer st = new StringTokenizer( propertyPath, ".", false );
 		try {
 			while ( st.hasMoreElements() ) {
-				final String element = ( String ) st.nextElement();
+				final String element = (String) st.nextElement();
 				if ( property == null ) {
 					Property identifierProperty = getIdentifierProperty();
 					if ( identifierProperty != null && identifierProperty.getName().equals( element ) ) {
 						// we have a mapped identifier property and the root of
 						// the incoming property path matched that identifier
 						// property
 						property = identifierProperty;
 					}
 					else if ( identifierProperty == null && getIdentifierMapper() != null ) {
 						// we have an embedded composite identifier
 						try {
 							identifierProperty = getProperty( element, getIdentifierMapper().getPropertyIterator() );
 							if ( identifierProperty != null ) {
 								// the root of the incoming property path matched one
 								// of the embedded composite identifier properties
 								property = identifierProperty;
 							}
 						}
-						catch( MappingException ignore ) {
+						catch (MappingException ignore) {
 							// ignore it...
 						}
 					}
 
 					if ( property == null ) {
 						property = getProperty( element, iter );
 					}
 				}
 				else {
 					//flat recursive algorithm
-					property = ( ( Component ) property.getValue() ).getProperty( element );
+					property = ( (Component) property.getValue() ).getProperty( element );
 				}
 			}
 		}
-		catch ( MappingException e ) {
+		catch (MappingException e) {
 			throw new MappingException( "property [" + propertyPath + "] not found on entity [" + getEntityName() + "]" );
 		}
 
 		return property;
 	}
 
 	private Property getProperty(String propertyName, Iterator iterator) throws MappingException {
-		if(iterator.hasNext()) {
-			String root = StringHelper.root(propertyName);
+		if ( iterator.hasNext() ) {
+			String root = StringHelper.root( propertyName );
 			while ( iterator.hasNext() ) {
 				Property prop = (Property) iterator.next();
 				if ( prop.getName().equals( root ) ) {
 					return prop;
 				}
 			}
 		}
 		throw new MappingException( "property [" + propertyName + "] not found on entity [" + getEntityName() + "]" );
 	}
 
 	public Property getProperty(String propertyName) throws MappingException {
 		Iterator iter = getPropertyClosureIterator();
 		Property identifierProperty = getIdentifierProperty();
 		if ( identifierProperty != null
-				&& identifierProperty.getName().equals( StringHelper.root(propertyName) ) ) {
+				&& identifierProperty.getName().equals( StringHelper.root( propertyName ) ) ) {
 			return identifierProperty;
 		}
 		else {
 			return getProperty( propertyName, iter );
 		}
 	}
 
 	/**
 	 * @deprecated prefer {@link #getOptimisticLockStyle}
 	 */
 	@Deprecated
 	public int getOptimisticLockMode() {
 		return getOptimisticLockStyle().getOldCode();
 	}
 
 	/**
 	 * @deprecated prefer {@link #setOptimisticLockStyle}
 	 */
 	@Deprecated
 	public void setOptimisticLockMode(int optimisticLockMode) {
 		setOptimisticLockStyle( OptimisticLockStyle.interpretOldCode( optimisticLockMode ) );
 	}
 
 	public OptimisticLockStyle getOptimisticLockStyle() {
 		return optimisticLockStyle;
 	}
 
 	public void setOptimisticLockStyle(OptimisticLockStyle optimisticLockStyle) {
 		this.optimisticLockStyle = optimisticLockStyle;
 	}
 
 	public void validate(Mapping mapping) throws MappingException {
 		Iterator iter = getPropertyIterator();
 		while ( iter.hasNext() ) {
 			Property prop = (Property) iter.next();
-			if ( !prop.isValid(mapping) ) {
+			if ( !prop.isValid( mapping ) ) {
 				throw new MappingException(
 						"property mapping has wrong number of columns: " +
-						StringHelper.qualify( getEntityName(), prop.getName() ) +
-						" type: " +
-						prop.getType().getName()
+								StringHelper.qualify( getEntityName(), prop.getName() ) +
+								" type: " +
+								prop.getType().getName()
 				);
 			}
 		}
 		checkPropertyDuplication();
 		checkColumnDuplication();
 	}
-	
+
 	private void checkPropertyDuplication() throws MappingException {
 		HashSet<String> names = new HashSet<String>();
 		Iterator iter = getPropertyIterator();
 		while ( iter.hasNext() ) {
 			Property prop = (Property) iter.next();
 			if ( !names.add( prop.getName() ) ) {
-				throw new MappingException( "Duplicate property mapping of " + prop.getName() + " found in " + getEntityName());
+				throw new MappingException( "Duplicate property mapping of " + prop.getName() + " found in " + getEntityName() );
 			}
 		}
 	}
 
 	public boolean isDiscriminatorValueNotNull() {
 		return NOT_NULL_DISCRIMINATOR_MAPPING.equals( getDiscriminatorValue() );
 	}
+
 	public boolean isDiscriminatorValueNull() {
 		return NULL_DISCRIMINATOR_MAPPING.equals( getDiscriminatorValue() );
 	}
 
 	public java.util.Map getMetaAttributes() {
 		return metaAttributes;
 	}
 
 	public void setMetaAttributes(java.util.Map metas) {
 		this.metaAttributes = metas;
 	}
 
 	public MetaAttribute getMetaAttribute(String name) {
 		return metaAttributes == null
 				? null
 				: (MetaAttribute) metaAttributes.get( name );
 	}
 
 	@Override
-    public String toString() {
+	public String toString() {
 		return getClass().getName() + '(' + getEntityName() + ')';
 	}
-	
+
 	public Iterator getJoinIterator() {
 		return joins.iterator();
 	}
 
 	public Iterator getJoinClosureIterator() {
 		return joins.iterator();
 	}
 
 	public void addJoin(Join join) {
-		joins.add(join);
-		join.setPersistentClass(this);
+		joins.add( join );
+		join.setPersistentClass( this );
 	}
 
 	public int getJoinClosureSpan() {
 		return joins.size();
 	}
 
 	public int getPropertyClosureSpan() {
 		int span = properties.size();
 		for ( Join join : joins ) {
 			span += join.getPropertySpan();
 		}
 		return span;
 	}
 
 	public int getJoinNumber(Property prop) {
-		int result=1;
+		int result = 1;
 		Iterator iter = getSubclassJoinClosureIterator();
 		while ( iter.hasNext() ) {
 			Join join = (Join) iter.next();
-			if ( join.containsProperty(prop) ) {
+			if ( join.containsProperty( prop ) ) {
 				return result;
 			}
 			result++;
 		}
 		return 0;
 	}
 
 	/**
 	 * Build an iterator over the properties defined on this class.  The returned
 	 * iterator only accounts for "normal" properties (i.e. non-identifier
 	 * properties).
 	 * <p/>
 	 * Differs from {@link #getUnjoinedPropertyIterator} in that the iterator
 	 * we return here will include properties defined as part of a join.
 	 *
 	 * @return An iterator over the "normal" properties.
 	 */
 	public Iterator getPropertyIterator() {
 		ArrayList iterators = new ArrayList();
 		iterators.add( properties.iterator() );
 		for ( int i = 0; i < joins.size(); i++ ) {
-			Join join = ( Join ) joins.get( i );
+			Join join = (Join) joins.get( i );
 			iterators.add( join.getPropertyIterator() );
 		}
 		return new JoinedIterator( iterators );
 	}
 
 	/**
 	 * Build an iterator over the properties defined on this class <b>which
 	 * are not defined as part of a join</b>.  As with {@link #getPropertyIterator},
 	 * the returned iterator only accounts for non-identifier properties.
 	 *
 	 * @return An iterator over the non-joined "normal" properties.
 	 */
 	public Iterator getUnjoinedPropertyIterator() {
 		return properties.iterator();
 	}
 
 	public void setCustomSQLInsert(String customSQLInsert, boolean callable, ExecuteUpdateResultCheckStyle checkStyle) {
 		this.customSQLInsert = customSQLInsert;
 		this.customInsertCallable = callable;
 		this.insertCheckStyle = checkStyle;
 	}
 
 	public String getCustomSQLInsert() {
 		return customSQLInsert;
 	}
 
 	public boolean isCustomInsertCallable() {
 		return customInsertCallable;
 	}
 
 	public ExecuteUpdateResultCheckStyle getCustomSQLInsertCheckStyle() {
 		return insertCheckStyle;
 	}
 
 	public void setCustomSQLUpdate(String customSQLUpdate, boolean callable, ExecuteUpdateResultCheckStyle checkStyle) {
 		this.customSQLUpdate = customSQLUpdate;
 		this.customUpdateCallable = callable;
 		this.updateCheckStyle = checkStyle;
 	}
 
 	public String getCustomSQLUpdate() {
 		return customSQLUpdate;
 	}
 
 	public boolean isCustomUpdateCallable() {
 		return customUpdateCallable;
 	}
 
 	public ExecuteUpdateResultCheckStyle getCustomSQLUpdateCheckStyle() {
 		return updateCheckStyle;
 	}
 
 	public void setCustomSQLDelete(String customSQLDelete, boolean callable, ExecuteUpdateResultCheckStyle checkStyle) {
 		this.customSQLDelete = customSQLDelete;
 		this.customDeleteCallable = callable;
 		this.deleteCheckStyle = checkStyle;
 	}
 
 	public String getCustomSQLDelete() {
 		return customSQLDelete;
 	}
 
 	public boolean isCustomDeleteCallable() {
 		return customDeleteCallable;
 	}
 
 	public ExecuteUpdateResultCheckStyle getCustomSQLDeleteCheckStyle() {
 		return deleteCheckStyle;
 	}
 
-	public void addFilter(String name, String condition, boolean autoAliasInjection, java.util.Map<String,String> aliasTableMap, java.util.Map<String,String> aliasEntityMap) {
-		filters.add(new FilterConfiguration(name, condition, autoAliasInjection, aliasTableMap, aliasEntityMap,  this));
+	public void addFilter(
+			String name,
+			String condition,
+			boolean autoAliasInjection,
+			java.util.Map<String, String> aliasTableMap,
+			java.util.Map<String, String> aliasEntityMap) {
+		filters.add(
+				new FilterConfiguration(
+						name,
+						condition,
+						autoAliasInjection,
+						aliasTableMap,
+						aliasEntityMap,
+						this
+				)
+		);
 	}
 
 	public java.util.List getFilters() {
 		return filters;
 	}
 
 	public boolean isForceDiscriminator() {
 		return false;
 	}
 
 	public abstract boolean isJoinedSubclass();
 
 	public String getLoaderName() {
 		return loaderName;
 	}
 
 	public void setLoaderName(String loaderName) {
-		this.loaderName = loaderName==null ? null : loaderName.intern();
+		this.loaderName = loaderName == null ? null : loaderName.intern();
 	}
 
 	public abstract java.util.Set getSynchronizedTables();
-	
+
 	public void addSynchronizedTable(String table) {
-		synchronizedTables.add(table);
+		synchronizedTables.add( table );
 	}
 
 	public Boolean isAbstract() {
 		return isAbstract;
 	}
 
 	public void setAbstract(Boolean isAbstract) {
 		this.isAbstract = isAbstract;
 	}
 
-	protected void checkColumnDuplication(Set distinctColumns, Iterator columns) 
-	throws MappingException {
+	protected void checkColumnDuplication(Set distinctColumns, Iterator columns)
+			throws MappingException {
 		while ( columns.hasNext() ) {
 			Selectable columnOrFormula = (Selectable) columns.next();
 			if ( !columnOrFormula.isFormula() ) {
 				Column col = (Column) columnOrFormula;
 				if ( !distinctColumns.add( col.getName() ) ) {
-					throw new MappingException( 
+					throw new MappingException(
 							"Repeated column in mapping for entity: " +
-							getEntityName() +
-							" column: " +
-							col.getName() + 
-							" (should be mapped with insert=\"false\" update=\"false\")"
-						);
+									getEntityName() +
+									" column: " +
+									col.getName() +
+									" (should be mapped with insert=\"false\" update=\"false\")"
+					);
 				}
 			}
 		}
 	}
-	
-	protected void checkPropertyColumnDuplication(Set distinctColumns, Iterator properties) 
-	throws MappingException {
+
+	protected void checkPropertyColumnDuplication(Set distinctColumns, Iterator properties)
+			throws MappingException {
 		while ( properties.hasNext() ) {
 			Property prop = (Property) properties.next();
 			if ( prop.getValue() instanceof Component ) { //TODO: remove use of instanceof!
 				Component component = (Component) prop.getValue();
 				checkPropertyColumnDuplication( distinctColumns, component.getPropertyIterator() );
 			}
 			else {
 				if ( prop.isUpdateable() || prop.isInsertable() ) {
 					checkColumnDuplication( distinctColumns, prop.getColumnIterator() );
 				}
 			}
 		}
 	}
-	
+
 	protected Iterator getNonDuplicatedPropertyIterator() {
 		return getUnjoinedPropertyIterator();
 	}
-	
+
 	protected Iterator getDiscriminatorColumnIterator() {
 		return EmptyIterator.INSTANCE;
 	}
-	
+
 	protected void checkColumnDuplication() {
 		HashSet cols = new HashSet();
-		if (getIdentifierMapper() == null ) {
+		if ( getIdentifierMapper() == null ) {
 			//an identifier mapper => getKey will be included in the getNonDuplicatedPropertyIterator()
 			//and checked later, so it needs to be excluded
 			checkColumnDuplication( cols, getKey().getColumnIterator() );
 		}
 		checkColumnDuplication( cols, getDiscriminatorColumnIterator() );
 		checkPropertyColumnDuplication( cols, getNonDuplicatedPropertyIterator() );
 		Iterator iter = getJoinIterator();
 		while ( iter.hasNext() ) {
 			cols.clear();
 			Join join = (Join) iter.next();
 			checkColumnDuplication( cols, join.getKey().getColumnIterator() );
 			checkPropertyColumnDuplication( cols, join.getPropertyIterator() );
 		}
 	}
-	
+
 	public abstract Object accept(PersistentClassVisitor mv);
-	
+
 	public String getNodeName() {
 		return nodeName;
 	}
-	
+
 	public void setNodeName(String nodeName) {
 		this.nodeName = nodeName;
 	}
 
 	public String getJpaEntityName() {
 		return jpaEntityName;
 	}
-	
+
 	public void setJpaEntityName(String jpaEntityName) {
 		this.jpaEntityName = jpaEntityName;
 	}
-	
+
 	public boolean hasPojoRepresentation() {
-		return getClassName()!=null;
+		return getClassName() != null;
 	}
 
 	public boolean hasDom4jRepresentation() {
-		return getNodeName()!=null;
+		return getNodeName() != null;
 	}
 
 	public boolean hasSubselectLoadableCollections() {
 		return hasSubselectLoadableCollections;
 	}
-	
+
 	public void setSubselectLoadableCollections(boolean hasSubselectCollections) {
 		this.hasSubselectLoadableCollections = hasSubselectCollections;
 	}
 
 	public Component getIdentifierMapper() {
 		return identifierMapper;
 	}
 
 	public Component getDeclaredIdentifierMapper() {
 		return declaredIdentifierMapper;
 	}
 
 	public void setDeclaredIdentifierMapper(Component declaredIdentifierMapper) {
 		this.declaredIdentifierMapper = declaredIdentifierMapper;
 	}
 
 	public boolean hasIdentifierMapper() {
 		return identifierMapper != null;
 	}
 
 	public void setIdentifierMapper(Component handle) {
 		this.identifierMapper = handle;
 	}
 
 	public void addTuplizer(EntityMode entityMode, String implClassName) {
 		if ( tuplizerImpls == null ) {
 			tuplizerImpls = new HashMap();
 		}
 		tuplizerImpls.put( entityMode, implClassName );
 	}
 
 	public String getTuplizerImplClassName(EntityMode mode) {
-		if ( tuplizerImpls == null ) return null;
-		return ( String ) tuplizerImpls.get( mode );
+		if ( tuplizerImpls == null ) {
+			return null;
+		}
+		return (String) tuplizerImpls.get( mode );
 	}
 
 	public java.util.Map getTuplizerMap() {
 		if ( tuplizerImpls == null ) {
 			return null;
 		}
 		return java.util.Collections.unmodifiableMap( tuplizerImpls );
 	}
 
 	public boolean hasNaturalId() {
 		Iterator props = getRootClass().getPropertyIterator();
 		while ( props.hasNext() ) {
 			if ( ( (Property) props.next() ).isNaturalIdentifier() ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	public abstract boolean isLazyPropertiesCacheable();
 
 	// The following methods are added to support @MappedSuperclass in the metamodel
 	public Iterator getDeclaredPropertyIterator() {
 		ArrayList iterators = new ArrayList();
 		iterators.add( declaredProperties.iterator() );
 		for ( int i = 0; i < joins.size(); i++ ) {
-			Join join = ( Join ) joins.get( i );
+			Join join = (Join) joins.get( i );
 			iterators.add( join.getDeclaredPropertyIterator() );
 		}
 		return new JoinedIterator( iterators );
 	}
 
 	public void addMappedsuperclassProperty(Property p) {
-		properties.add(p);
-		p.setPersistentClass(this);
+		properties.add( p );
+		p.setPersistentClass( this );
 	}
 
 	public MappedSuperclass getSuperMappedSuperclass() {
 		return superMappedSuperclass;
 	}
 
 	public void setSuperMappedSuperclass(MappedSuperclass superMappedSuperclass) {
 		this.superMappedSuperclass = superMappedSuperclass;
 	}
 
 	// End of @Mappedsuperclass support
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/Property.java b/hibernate-core/src/main/java/org/hibernate/mapping/Property.java
index 6ad8fd1f89..a033651da3 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/Property.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/Property.java
@@ -1,352 +1,352 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.io.Serializable;
 import java.util.Iterator;
 import java.util.StringTokenizer;
 
 import org.hibernate.EntityMode;
 import org.hibernate.MappingException;
 import org.hibernate.PropertyNotFoundException;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.CascadeStyles;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.property.Getter;
 import org.hibernate.property.PropertyAccessor;
 import org.hibernate.property.PropertyAccessorFactory;
 import org.hibernate.property.Setter;
 import org.hibernate.tuple.ValueGeneration;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.Type;
 
 /**
  * Represents a property as part of an entity or a component.
  *
  * @author Gavin King
  */
 public class Property implements Serializable, MetaAttributable {
 	private String name;
 	private Value value;
 	private String cascade;
 	private boolean updateable = true;
 	private boolean insertable = true;
 	private boolean selectable = true;
 	private boolean optimisticLocked = true;
 	private ValueGeneration valueGenerationStrategy;
 	private String propertyAccessorName;
 	private boolean lazy;
 	private boolean optional;
 	private String nodeName;
 	private java.util.Map metaAttributes;
 	private PersistentClass persistentClass;
 	private boolean naturalIdentifier;
 	private boolean lob;
 
 	public boolean isBackRef() {
 		return false;
 	}
 
 	/**
 	 * Does this property represent a synthetic property?  A synthetic property is one we create during
 	 * metamodel binding to represent a collection of columns but which does not represent a property
 	 * physically available on the entity.
 	 *
 	 * @return True if synthetic; false otherwise.
 	 */
 	public boolean isSynthetic() {
 		return false;
 	}
 
 	public Type getType() throws MappingException {
 		return value.getType();
 	}
 	
 	public int getColumnSpan() {
 		return value.getColumnSpan();
 	}
 	
 	public Iterator getColumnIterator() {
 		return value.getColumnIterator();
 	}
 	
 	public String getName() {
 		return name;
 	}
 	
 	public boolean isComposite() {
 		return value instanceof Component;
 	}
 
 	public Value getValue() {
 		return value;
 	}
 	
 	public boolean isPrimitive(Class clazz) {
 		return getGetter(clazz).getReturnType().isPrimitive();
 	}
 
 	public CascadeStyle getCascadeStyle() throws MappingException {
 		Type type = value.getType();
 		if ( type.isComponentType() ) {
 			return getCompositeCascadeStyle( (CompositeType) type, cascade );
 		}
 		else if ( type.isCollectionType() ) {
 			return getCollectionCascadeStyle( ( (Collection) value ).getElement().getType(), cascade );
 		}
 		else {
 			return getCascadeStyle( cascade );			
 		}
 	}
 
 	private static CascadeStyle getCompositeCascadeStyle(CompositeType compositeType, String cascade) {
 		if ( compositeType.isAnyType() ) {
 			return getCascadeStyle( cascade );
 		}
 		int length = compositeType.getSubtypes().length;
 		for ( int i=0; i<length; i++ ) {
 			if ( compositeType.getCascadeStyle(i) != CascadeStyles.NONE ) {
 				return CascadeStyles.ALL;
 			}
 		}
 		return getCascadeStyle( cascade );
 	}
 
 	private static CascadeStyle getCollectionCascadeStyle(Type elementType, String cascade) {
 		if ( elementType.isComponentType() ) {
 			return getCompositeCascadeStyle( (CompositeType) elementType, cascade );
 		}
 		else {
 			return getCascadeStyle( cascade );
 		}
 	}
 	
 	private static CascadeStyle getCascadeStyle(String cascade) {
 		if ( cascade==null || cascade.equals("none") ) {
 			return CascadeStyles.NONE;
 		}
 		else {
 			StringTokenizer tokens = new StringTokenizer(cascade, ", ");
 			CascadeStyle[] styles = new CascadeStyle[ tokens.countTokens() ] ;
 			int i=0;
 			while ( tokens.hasMoreTokens() ) {
 				styles[i++] = CascadeStyles.getCascadeStyle( tokens.nextToken() );
 			}
 			return new CascadeStyles.MultipleCascadeStyle(styles);
 		}		
 	}
 	
 	public String getCascade() {
 		return cascade;
 	}
 
 	public void setCascade(String cascade) {
 		this.cascade = cascade;
 	}
 
 	public void setName(String name) {
 		this.name = name==null ? null : name.intern();
 	}
 
 	public void setValue(Value value) {
 		this.value = value;
 	}
 
 	public boolean isUpdateable() {
 		// if the property mapping consists of all formulas,
 		// make it non-updateable
 		return updateable && !ArrayHelper.isAllFalse( value.getColumnUpdateability() );
 	}
 
 	public boolean isInsertable() {
 		// if the property mapping consists of all formulas, 
 		// make it non-insertable
 		final boolean[] columnInsertability = value.getColumnInsertability();
 		return insertable && (
 				columnInsertability.length==0 ||
 				!ArrayHelper.isAllFalse( columnInsertability )
 			);
 	}
 
 	public ValueGeneration getValueGenerationStrategy() {
 		return valueGenerationStrategy;
 	}
 
 	public void setValueGenerationStrategy(ValueGeneration valueGenerationStrategy) {
 		this.valueGenerationStrategy = valueGenerationStrategy;
 	}
 
-    public void setUpdateable(boolean mutable) {
+	public void setUpdateable(boolean mutable) {
 		this.updateable = mutable;
 	}
 
 	public void setInsertable(boolean insertable) {
 		this.insertable = insertable;
 	}
 
 	public String getPropertyAccessorName() {
 		return propertyAccessorName;
 	}
 
 	public void setPropertyAccessorName(String string) {
 		propertyAccessorName = string;
 	}
 
 	/**
 	 * Approximate!
 	 */
 	boolean isNullable() {
 		return value==null || value.isNullable();
 	}
 
 	public boolean isBasicPropertyAccessor() {
 		return propertyAccessorName==null || "property".equals(propertyAccessorName);
 	}
 
 	public java.util.Map getMetaAttributes() {
 		return metaAttributes;
 	}
 
 	public MetaAttribute getMetaAttribute(String attributeName) {
 		return metaAttributes==null?null:(MetaAttribute) metaAttributes.get(attributeName);
 	}
 
 	public void setMetaAttributes(java.util.Map metas) {
 		this.metaAttributes = metas;
 	}
 
 	public boolean isValid(Mapping mapping) throws MappingException {
 		return getValue().isValid(mapping);
 	}
 
 	public String toString() {
 		return getClass().getName() + '(' + name + ')';
 	}
 	
 	public void setLazy(boolean lazy) {
 		this.lazy=lazy;
 	}
 	
 	public boolean isLazy() {
 		if ( value instanceof ToOne ) {
 			// both many-to-one and one-to-one are represented as a
 			// Property.  EntityPersister is relying on this value to
 			// determine "lazy fetch groups" in terms of field-level
 			// interception.  So we need to make sure that we return
 			// true here for the case of many-to-one and one-to-one
 			// with lazy="no-proxy"
 			//
 			// * impl note - lazy="no-proxy" currently forces both
 			// lazy and unwrap to be set to true.  The other case we
 			// are extremely interested in here is that of lazy="proxy"
 			// where lazy is set to true, but unwrap is set to false.
 			// thus we use both here under the assumption that this
 			// return is really only ever used during persister
 			// construction to determine the lazy property/field fetch
 			// groupings.  If that assertion changes then this check
 			// needs to change as well.  Partially, this is an issue with
 			// the overloading of the term "lazy" here...
 			ToOne toOneValue = ( ToOne ) value;
 			return toOneValue.isLazy() && toOneValue.isUnwrapProxy();
 		}
 		return lazy;
 	}
 	
 	public boolean isOptimisticLocked() {
 		return optimisticLocked;
 	}
 
 	public void setOptimisticLocked(boolean optimisticLocked) {
 		this.optimisticLocked = optimisticLocked;
 	}
 	
 	public boolean isOptional() {
 		return optional || isNullable();
 	}
 	
 	public void setOptional(boolean optional) {
 		this.optional = optional;
 	}
 
 	public PersistentClass getPersistentClass() {
 		return persistentClass;
 	}
 
 	public void setPersistentClass(PersistentClass persistentClass) {
 		this.persistentClass = persistentClass;
 	}
 
 	public boolean isSelectable() {
 		return selectable;
 	}
 	
 	public void setSelectable(boolean selectable) {
 		this.selectable = selectable;
 	}
 
 	public String getNodeName() {
 		return nodeName;
 	}
 
 	public void setNodeName(String nodeName) {
 		this.nodeName = nodeName;
 	}
 
 	public String getAccessorPropertyName( EntityMode mode ) {
 		return getName();
 	}
 
 	// todo : remove
 	public Getter getGetter(Class clazz) throws PropertyNotFoundException, MappingException {
 		return getPropertyAccessor(clazz).getGetter( clazz, name );
 	}
 
 	// todo : remove
 	public Setter getSetter(Class clazz) throws PropertyNotFoundException, MappingException {
 		return getPropertyAccessor(clazz).getSetter(clazz, name);
 	}
 
 	// todo : remove
 	public PropertyAccessor getPropertyAccessor(Class clazz) throws MappingException {
 		return PropertyAccessorFactory.getPropertyAccessor( clazz, getPropertyAccessorName() );
 	}
 
 	public boolean isNaturalIdentifier() {
 		return naturalIdentifier;
 	}
 
 	public void setNaturalIdentifier(boolean naturalIdentifier) {
 		this.naturalIdentifier = naturalIdentifier;
 	}
 
 	public boolean isLob() {
 		return lob;
 	}
 
 	public void setLob(boolean lob) {
 		this.lob = lob;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/RootClass.java b/hibernate-core/src/main/java/org/hibernate/mapping/RootClass.java
index 8478a005ef..faa6bac267 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/RootClass.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/RootClass.java
@@ -1,374 +1,382 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.io.Serializable;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Set;
 
 import org.hibernate.MappingException;
 import org.hibernate.engine.spi.Mapping;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.collections.SingletonIterator;
 
-import org.jboss.logging.Logger;
-
 /**
  * The root class of an inheritance hierarchy
+ *
  * @author Gavin King
  */
 public class RootClass extends PersistentClass implements TableOwner {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, RootClass.class.getName());
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( RootClass.class );
 
 	public static final String DEFAULT_IDENTIFIER_COLUMN_NAME = "id";
 	public static final String DEFAULT_DISCRIMINATOR_COLUMN_NAME = "class";
 
 	private Property identifierProperty;
 	private KeyValue identifier;
 	private Property version;
 	private boolean polymorphic;
 	private String cacheConcurrencyStrategy;
 	private String cacheRegionName;
 	private String naturalIdCacheRegionName;
 	private boolean lazyPropertiesCacheable = true;
 	private Value discriminator;
 	private boolean mutable = true;
 	private boolean embeddedIdentifier;
 	private boolean explicitPolymorphism;
 	private Class entityPersisterClass;
 	private boolean forceDiscriminator;
 	private String where;
 	private Table table;
 	private boolean discriminatorInsertable = true;
 	private int nextSubclassId;
 	private Property declaredIdentifierProperty;
 	private Property declaredVersion;
 	private boolean cachingExplicitlyRequested;
 
 	@Override
-    int nextSubclassId() {
+	int nextSubclassId() {
 		return ++nextSubclassId;
 	}
 
 	@Override
-    public int getSubclassId() {
+	public int getSubclassId() {
 		return 0;
 	}
 
 	public void setTable(Table table) {
-		this.table=table;
+		this.table = table;
 	}
+
 	@Override
-    public Table getTable() {
+	public Table getTable() {
 		return table;
 	}
 
 	@Override
-    public Property getIdentifierProperty() {
+	public Property getIdentifierProperty() {
 		return identifierProperty;
 	}
 
 	@Override
-    public Property getDeclaredIdentifierProperty() {
+	public Property getDeclaredIdentifierProperty() {
 		return declaredIdentifierProperty;
 	}
 
 	public void setDeclaredIdentifierProperty(Property declaredIdentifierProperty) {
 		this.declaredIdentifierProperty = declaredIdentifierProperty;
 	}
 
 	@Override
-    public KeyValue getIdentifier() {
+	public KeyValue getIdentifier() {
 		return identifier;
 	}
+
 	@Override
-    public boolean hasIdentifierProperty() {
-		return identifierProperty!=null;
+	public boolean hasIdentifierProperty() {
+		return identifierProperty != null;
 	}
 
 	@Override
-    public Value getDiscriminator() {
+	public Value getDiscriminator() {
 		return discriminator;
 	}
 
 	@Override
-    public boolean isInherited() {
+	public boolean isInherited() {
 		return false;
 	}
+
 	@Override
-    public boolean isPolymorphic() {
+	public boolean isPolymorphic() {
 		return polymorphic;
 	}
 
 	public void setPolymorphic(boolean polymorphic) {
 		this.polymorphic = polymorphic;
 	}
 
 	@Override
-    public RootClass getRootClass() {
+	public RootClass getRootClass() {
 		return this;
 	}
 
 	@Override
-    public Iterator getPropertyClosureIterator() {
+	public Iterator getPropertyClosureIterator() {
 		return getPropertyIterator();
 	}
+
 	@Override
-    public Iterator getTableClosureIterator() {
+	public Iterator getTableClosureIterator() {
 		return new SingletonIterator( getTable() );
 	}
+
 	@Override
-    public Iterator getKeyClosureIterator() {
+	public Iterator getKeyClosureIterator() {
 		return new SingletonIterator( getKey() );
 	}
 
 	@Override
-    public void addSubclass(Subclass subclass) throws MappingException {
-		super.addSubclass(subclass);
-		setPolymorphic(true);
+	public void addSubclass(Subclass subclass) throws MappingException {
+		super.addSubclass( subclass );
+		setPolymorphic( true );
 	}
 
 	@Override
-    public boolean isExplicitPolymorphism() {
+	public boolean isExplicitPolymorphism() {
 		return explicitPolymorphism;
 	}
 
 	@Override
-    public Property getVersion() {
+	public Property getVersion() {
 		return version;
 	}
 
 	@Override
-    public Property getDeclaredVersion() {
+	public Property getDeclaredVersion() {
 		return declaredVersion;
 	}
 
 	public void setDeclaredVersion(Property declaredVersion) {
 		this.declaredVersion = declaredVersion;
 	}
 
 	public void setVersion(Property version) {
 		this.version = version;
 	}
+
 	@Override
-    public boolean isVersioned() {
-		return version!=null;
+	public boolean isVersioned() {
+		return version != null;
 	}
 
 	@Override
-    public boolean isMutable() {
+	public boolean isMutable() {
 		return mutable;
 	}
+
 	@Override
-    public boolean hasEmbeddedIdentifier() {
+	public boolean hasEmbeddedIdentifier() {
 		return embeddedIdentifier;
 	}
 
 	@Override
-    public Class getEntityPersisterClass() {
+	public Class getEntityPersisterClass() {
 		return entityPersisterClass;
 	}
 
 	@Override
-    public Table getRootTable() {
+	public Table getRootTable() {
 		return getTable();
 	}
 
 	@Override
-    public void setEntityPersisterClass(Class persister) {
+	public void setEntityPersisterClass(Class persister) {
 		this.entityPersisterClass = persister;
 	}
 
 	@Override
-    public PersistentClass getSuperclass() {
+	public PersistentClass getSuperclass() {
 		return null;
 	}
 
 	@Override
-    public KeyValue getKey() {
+	public KeyValue getKey() {
 		return getIdentifier();
 	}
 
 	public void setDiscriminator(Value discriminator) {
 		this.discriminator = discriminator;
 	}
 
 	public void setEmbeddedIdentifier(boolean embeddedIdentifier) {
 		this.embeddedIdentifier = embeddedIdentifier;
 	}
 
 	public void setExplicitPolymorphism(boolean explicitPolymorphism) {
 		this.explicitPolymorphism = explicitPolymorphism;
 	}
 
 	public void setIdentifier(KeyValue identifier) {
 		this.identifier = identifier;
 	}
 
 	public void setIdentifierProperty(Property identifierProperty) {
 		this.identifierProperty = identifierProperty;
-		identifierProperty.setPersistentClass(this);
+		identifierProperty.setPersistentClass( this );
 
 	}
 
 	public void setMutable(boolean mutable) {
 		this.mutable = mutable;
 	}
 
 	@Override
-    public boolean isDiscriminatorInsertable() {
+	public boolean isDiscriminatorInsertable() {
 		return discriminatorInsertable;
 	}
 
 	public void setDiscriminatorInsertable(boolean insertable) {
 		this.discriminatorInsertable = insertable;
 	}
 
 	@Override
-    public boolean isForceDiscriminator() {
+	public boolean isForceDiscriminator() {
 		return forceDiscriminator;
 	}
 
 	public void setForceDiscriminator(boolean forceDiscriminator) {
 		this.forceDiscriminator = forceDiscriminator;
 	}
 
 	@Override
-    public String getWhere() {
+	public String getWhere() {
 		return where;
 	}
 
 	public void setWhere(String string) {
 		where = string;
 	}
 
 	@Override
-    public void validate(Mapping mapping) throws MappingException {
-		super.validate(mapping);
-		if ( !getIdentifier().isValid(mapping) ) {
+	public void validate(Mapping mapping) throws MappingException {
+		super.validate( mapping );
+		if ( !getIdentifier().isValid( mapping ) ) {
 			throw new MappingException(
-				"identifier mapping has wrong number of columns: " +
-				getEntityName() +
-				" type: " +
-				getIdentifier().getType().getName()
+					"identifier mapping has wrong number of columns: " +
+							getEntityName() +
+							" type: " +
+							getIdentifier().getType().getName()
 			);
 		}
 		checkCompositeIdentifier();
 	}
 
 	private void checkCompositeIdentifier() {
 		if ( getIdentifier() instanceof Component ) {
 			Component id = (Component) getIdentifier();
 			if ( !id.isDynamic() ) {
 				final Class idClass = id.getComponentClass();
 				if ( idClass != null ) {
 					final String idComponentClassName = idClass.getName();
 					if ( !ReflectHelper.overridesEquals( idClass ) ) {
 						LOG.compositeIdClassDoesNotOverrideEquals( idComponentClassName );
 					}
 					if ( !ReflectHelper.overridesHashCode( idClass ) ) {
 						LOG.compositeIdClassDoesNotOverrideHashCode( idComponentClassName );
 					}
 					if ( !Serializable.class.isAssignableFrom( idClass ) ) {
 						throw new MappingException(
 								"Composite-id class must implement Serializable: " + idComponentClassName
 						);
 					}
 				}
 			}
 		}
 	}
 
 	@Override
-    public String getCacheConcurrencyStrategy() {
+	public String getCacheConcurrencyStrategy() {
 		return cacheConcurrencyStrategy;
 	}
 
 	public void setCacheConcurrencyStrategy(String cacheConcurrencyStrategy) {
 		this.cacheConcurrencyStrategy = cacheConcurrencyStrategy;
 	}
 
 	public String getCacheRegionName() {
-		return cacheRegionName==null ? getEntityName() : cacheRegionName;
+		return cacheRegionName == null ? getEntityName() : cacheRegionName;
 	}
+
 	public void setCacheRegionName(String cacheRegionName) {
 		this.cacheRegionName = cacheRegionName;
 	}
-	
+
 	@Override
 	public String getNaturalIdCacheRegionName() {
 		return naturalIdCacheRegionName;
 	}
+
 	public void setNaturalIdCacheRegionName(String naturalIdCacheRegionName) {
 		this.naturalIdCacheRegionName = naturalIdCacheRegionName;
 	}
-	
+
 	@Override
-    public boolean isLazyPropertiesCacheable() {
+	public boolean isLazyPropertiesCacheable() {
 		return lazyPropertiesCacheable;
 	}
 
 	public void setLazyPropertiesCacheable(boolean lazyPropertiesCacheable) {
 		this.lazyPropertiesCacheable = lazyPropertiesCacheable;
 	}
 
 	@Override
-    public boolean isJoinedSubclass() {
+	public boolean isJoinedSubclass() {
 		return false;
 	}
 
 	@Override
-    public java.util.Set getSynchronizedTables() {
+	public java.util.Set getSynchronizedTables() {
 		return synchronizedTables;
 	}
 
 	@SuppressWarnings("UnnecessaryUnboxing")
 	public Set<Table> getIdentityTables() {
 		Set<Table> tables = new HashSet<Table>();
 		Iterator iter = getSubclassClosureIterator();
 		while ( iter.hasNext() ) {
 			PersistentClass clazz = (PersistentClass) iter.next();
 			if ( clazz.isAbstract() == null || !clazz.isAbstract().booleanValue() ) {
 				tables.add( clazz.getIdentityTable() );
 			}
 		}
 		return tables;
 	}
 
 	@Override
-    public Object accept(PersistentClassVisitor mv) {
-		return mv.accept(this);
+	public Object accept(PersistentClassVisitor mv) {
+		return mv.accept( this );
 	}
 
 	public void setCachingExplicitlyRequested(boolean explicitlyRequested) {
 		this.cachingExplicitlyRequested = explicitlyRequested;
 	}
 
 	public boolean isCachingExplicitlyRequested() {
 		return cachingExplicitlyRequested;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/SimpleValue.java b/hibernate-core/src/main/java/org/hibernate/mapping/SimpleValue.java
index dbbb8714ff..fb81390032 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/SimpleValue.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/SimpleValue.java
@@ -1,648 +1,650 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.lang.annotation.Annotation;
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Properties;
 import javax.persistence.AttributeConverter;
 
 import org.hibernate.FetchMode;
 import org.hibernate.MappingException;
 import org.hibernate.annotations.common.reflection.XProperty;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.cfg.AttributeConverterDefinition;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.config.spi.ConfigurationService;
 import org.hibernate.engine.config.spi.StandardConverters;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.IdentityGenerator;
 import org.hibernate.id.PersistentIdentifierGenerator;
 import org.hibernate.id.factory.IdentifierGeneratorFactory;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.type.Type;
 import org.hibernate.type.descriptor.converter.AttributeConverterSqlTypeDescriptorAdapter;
 import org.hibernate.type.descriptor.converter.AttributeConverterTypeAdapter;
 import org.hibernate.type.descriptor.java.JavaTypeDescriptor;
 import org.hibernate.type.descriptor.java.JavaTypeDescriptorRegistry;
 import org.hibernate.type.descriptor.sql.JdbcTypeJavaClassMappings;
 import org.hibernate.type.descriptor.sql.NationalizedTypeMappings;
 import org.hibernate.type.descriptor.sql.SqlTypeDescriptor;
 import org.hibernate.type.descriptor.sql.SqlTypeDescriptorRegistry;
 import org.hibernate.usertype.DynamicParameterizedType;
 
 /**
  * Any value that maps to columns.
  * @author Gavin King
  */
 public class SimpleValue implements KeyValue {
 	private static final CoreMessageLogger log = CoreLogging.messageLogger( SimpleValue.class );
 
 	public static final String DEFAULT_ID_GEN_STRATEGY = "assigned";
 
 	private final MetadataImplementor metadata;
 
 	private final List<Selectable> columns = new ArrayList<Selectable>();
 
 	private String typeName;
 	private Properties typeParameters;
 	private boolean isNationalized;
 
 	private Properties identifierGeneratorProperties;
 	private String identifierGeneratorStrategy = DEFAULT_ID_GEN_STRATEGY;
 	private String nullValue;
 	private Table table;
 	private String foreignKeyName;
 	private boolean alternateUniqueKey;
 	private boolean cascadeDeleteEnabled;
 
 	private AttributeConverterDefinition attributeConverterDefinition;
 	private Type type;
 
 	public SimpleValue(MetadataImplementor metadata) {
 		this.metadata = metadata;
 	}
 
 	public SimpleValue(MetadataImplementor metadata, Table table) {
 		this( metadata );
 		this.table = table;
 	}
 
 	public MetadataImplementor getMetadata() {
 		return metadata;
 	}
 
 	@Override
 	public boolean isCascadeDeleteEnabled() {
 		return cascadeDeleteEnabled;
 	}
 
 	public void setCascadeDeleteEnabled(boolean cascadeDeleteEnabled) {
 		this.cascadeDeleteEnabled = cascadeDeleteEnabled;
 	}
 	
 	public void addColumn(Column column) {
 		if ( !columns.contains(column) ) {
 			columns.add(column);
 		}
 		column.setValue(this);
 		column.setTypeIndex( columns.size()-1 );
 	}
 	
 	public void addFormula(Formula formula) {
 		columns.add(formula);
 	}
 
 	@Override
 	public boolean hasFormula() {
 		Iterator iter = getColumnIterator();
 		while ( iter.hasNext() ) {
 			Object o = iter.next();
 			if (o instanceof Formula) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	@Override
 	public int getColumnSpan() {
 		return columns.size();
 	}
 
 	@Override
 	public Iterator<Selectable> getColumnIterator() {
 		return columns.iterator();
 	}
 
 	public List getConstraintColumns() {
 		return columns;
 	}
 
 	public String getTypeName() {
 		return typeName;
 	}
 
 	public void setTypeName(String typeName) {
 		if ( typeName != null && typeName.startsWith( AttributeConverterTypeAdapter.NAME_PREFIX ) ) {
 			final String converterClassName = typeName.substring( AttributeConverterTypeAdapter.NAME_PREFIX.length() );
 			final ClassLoaderService cls = getMetadata().getMetadataBuildingOptions()
 					.getServiceRegistry()
 					.getService( ClassLoaderService.class );
 			try {
 				final Class<AttributeConverter> converterClass = cls.classForName( converterClassName );
 				attributeConverterDefinition = new AttributeConverterDefinition( converterClass.newInstance(), false );
 				return;
 			}
 			catch (Exception e) {
 				log.logBadHbmAttributeConverterType( typeName, e.getMessage() );
 			}
 		}
 
 		this.typeName = typeName;
 	}
 
 	public void makeNationalized() {
 		this.isNationalized = true;
 	}
 
 	public boolean isNationalized() {
 		return isNationalized;
 	}
 
 	public void setTable(Table table) {
 		this.table = table;
 	}
 
 	@Override
 	public void createForeignKey() throws MappingException {}
 
 	@Override
 	public void createForeignKeyOfEntity(String entityName) {
 		if ( !hasFormula() && !"none".equals(getForeignKeyName())) {
 			ForeignKey fk = table.createForeignKey( getForeignKeyName(), getConstraintColumns(), entityName );
 			fk.setCascadeDeleteEnabled(cascadeDeleteEnabled);
 		}
 	}
 
 	@Override
 	public IdentifierGenerator createIdentifierGenerator(
 			IdentifierGeneratorFactory identifierGeneratorFactory,
 			Dialect dialect, 
 			String defaultCatalog, 
 			String defaultSchema, 
 			RootClass rootClass) throws MappingException {
 		
 		Properties params = new Properties();
 		
 		//if the hibernate-mapping did not specify a schema/catalog, use the defaults
 		//specified by properties - but note that if the schema/catalog were specified
 		//in hibernate-mapping, or as params, they will already be initialized and
 		//will override the values set here (they are in identifierGeneratorProperties)
 		if ( defaultSchema!=null ) {
 			params.setProperty(PersistentIdentifierGenerator.SCHEMA, defaultSchema);
 		}
 		if ( defaultCatalog!=null ) {
 			params.setProperty(PersistentIdentifierGenerator.CATALOG, defaultCatalog);
 		}
 		
 		//pass the entity-name, if not a collection-id
 		if (rootClass!=null) {
 			params.setProperty( IdentifierGenerator.ENTITY_NAME, rootClass.getEntityName() );
 			params.setProperty( IdentifierGenerator.JPA_ENTITY_NAME, rootClass.getJpaEntityName() );
 		}
 		
 		//init the table here instead of earlier, so that we can get a quoted table name
 		//TODO: would it be better to simply pass the qualified table name, instead of
 		//      splitting it up into schema/catalog/table names
 		String tableName = getTable().getQuotedName(dialect);
 		params.setProperty( PersistentIdentifierGenerator.TABLE, tableName );
 		
 		//pass the column name (a generated id almost always has a single column)
 		String columnName = ( (Column) getColumnIterator().next() ).getQuotedName(dialect);
 		params.setProperty( PersistentIdentifierGenerator.PK, columnName );
 		
 		if (rootClass!=null) {
 			StringBuilder tables = new StringBuilder();
 			Iterator iter = rootClass.getIdentityTables().iterator();
 			while ( iter.hasNext() ) {
 				Table table= (Table) iter.next();
 				tables.append( table.getQuotedName(dialect) );
-				if ( iter.hasNext() ) tables.append(", ");
+				if ( iter.hasNext() ) {
+					tables.append(", ");
+				}
 			}
 			params.setProperty( PersistentIdentifierGenerator.TABLES, tables.toString() );
 		}
 		else {
 			params.setProperty( PersistentIdentifierGenerator.TABLES, tableName );
 		}
 
 		if (identifierGeneratorProperties!=null) {
 			params.putAll(identifierGeneratorProperties);
 		}
 
 		// TODO : we should pass along all settings once "config lifecycle" is hashed out...
 		final ConfigurationService cs = metadata.getMetadataBuildingOptions().getServiceRegistry()
 				.getService( ConfigurationService.class );
 
 		params.put(
 				AvailableSettings.PREFER_POOLED_VALUES_LO,
 				cs.getSetting( AvailableSettings.PREFER_POOLED_VALUES_LO, StandardConverters.BOOLEAN, false )
 		);
 
 		identifierGeneratorFactory.setDialect( dialect );
 		return identifierGeneratorFactory.createIdentifierGenerator( identifierGeneratorStrategy, getType(), params );
 	}
 
 	public boolean isUpdateable() {
 		//needed to satisfy KeyValue
 		return true;
 	}
 	
 	public FetchMode getFetchMode() {
 		return FetchMode.SELECT;
 	}
 
 	public Properties getIdentifierGeneratorProperties() {
 		return identifierGeneratorProperties;
 	}
 
 	public String getNullValue() {
 		return nullValue;
 	}
 
 	public Table getTable() {
 		return table;
 	}
 
 	/**
 	 * Returns the identifierGeneratorStrategy.
 	 * @return String
 	 */
 	public String getIdentifierGeneratorStrategy() {
 		return identifierGeneratorStrategy;
 	}
 	
 	public boolean isIdentityColumn(IdentifierGeneratorFactory identifierGeneratorFactory, Dialect dialect) {
 		identifierGeneratorFactory.setDialect( dialect );
 		return identifierGeneratorFactory.getIdentifierGeneratorClass( identifierGeneratorStrategy )
 				.equals( IdentityGenerator.class );
 	}
 
 	/**
 	 * Sets the identifierGeneratorProperties.
 	 * @param identifierGeneratorProperties The identifierGeneratorProperties to set
 	 */
 	public void setIdentifierGeneratorProperties(Properties identifierGeneratorProperties) {
 		this.identifierGeneratorProperties = identifierGeneratorProperties;
 	}
 
 	/**
 	 * Sets the identifierGeneratorStrategy.
 	 * @param identifierGeneratorStrategy The identifierGeneratorStrategy to set
 	 */
 	public void setIdentifierGeneratorStrategy(String identifierGeneratorStrategy) {
 		this.identifierGeneratorStrategy = identifierGeneratorStrategy;
 	}
 
 	/**
 	 * Sets the nullValue.
 	 * @param nullValue The nullValue to set
 	 */
 	public void setNullValue(String nullValue) {
 		this.nullValue = nullValue;
 	}
 
 	public String getForeignKeyName() {
 		return foreignKeyName;
 	}
 
 	public void setForeignKeyName(String foreignKeyName) {
 		this.foreignKeyName = foreignKeyName;
 	}
 
 	public boolean isAlternateUniqueKey() {
 		return alternateUniqueKey;
 	}
 
 	public void setAlternateUniqueKey(boolean unique) {
 		this.alternateUniqueKey = unique;
 	}
 
 	public boolean isNullable() {
 		Iterator itr = getColumnIterator();
 		while ( itr.hasNext() ) {
 			final Object selectable = itr.next();
 			if ( selectable instanceof Formula ) {
 				// if there are *any* formulas, then the Value overall is
 				// considered nullable
 				return true;
 			}
 			else if ( !( (Column) selectable ).isNullable() ) {
 				// if there is a single non-nullable column, the Value
 				// overall is considered non-nullable.
 				return false;
 			}
 		}
 		// nullable by default
 		return true;
 	}
 
 	public boolean isSimpleValue() {
 		return true;
 	}
 
 	public boolean isValid(Mapping mapping) throws MappingException {
 		return getColumnSpan()==getType().getColumnSpan(mapping);
 	}
 
 	public Type getType() throws MappingException {
 		if ( type != null ) {
 			return type;
 		}
 
 		if ( typeName == null ) {
 			throw new MappingException( "No type name" );
 		}
 
 		if ( typeParameters != null
 				&& Boolean.valueOf( typeParameters.getProperty( DynamicParameterizedType.IS_DYNAMIC ) )
 				&& typeParameters.get( DynamicParameterizedType.PARAMETER_TYPE ) == null ) {
 			createParameterImpl();
 		}
 
 		Type result = metadata.getTypeResolver().heuristicType( typeName, typeParameters );
 		if ( result == null ) {
 			String msg = "Could not determine type for: " + typeName;
 			if ( table != null ) {
 				msg += ", at table: " + table.getName();
 			}
 			if ( columns != null && columns.size() > 0 ) {
 				msg += ", for columns: " + columns;
 			}
 			throw new MappingException( msg );
 		}
 
 		return result;
 	}
 
 	public void setTypeUsingReflection(String className, String propertyName) throws MappingException {
 		// NOTE : this is called as the last piece in setting SimpleValue type information, and implementations
 		// rely on that fact, using it as a signal that all information it is going to get is defined at this point...
 
 		if ( typeName != null ) {
 			// assume either (a) explicit type was specified or (b) determine was already performed
 			return;
 		}
 
 		if ( type != null ) {
 			return;
 		}
 
 		if ( attributeConverterDefinition == null ) {
 			// this is here to work like legacy.  This should change when we integrate with metamodel to
 			// look for SqlTypeDescriptor and JavaTypeDescriptor individually and create the BasicType (well, really
 			// keep a registry of [SqlTypeDescriptor,JavaTypeDescriptor] -> BasicType...)
 			if ( className == null ) {
 				throw new MappingException( "Attribute types for a dynamic entity must be explicitly specified: " + propertyName );
 			}
 			typeName = ReflectHelper.reflectedPropertyClass( className, propertyName ).getName();
 			// todo : to fully support isNationalized here we need do the process hinted at above
 			// 		essentially, much of the logic from #buildAttributeConverterTypeAdapter wrt resolving
 			//		a (1) SqlTypeDescriptor, a (2) JavaTypeDescriptor and dynamically building a BasicType
 			// 		combining them.
 			return;
 		}
 
 		// we had an AttributeConverter...
 		type = buildAttributeConverterTypeAdapter();
 	}
 
 	/**
 	 * Build a Hibernate Type that incorporates the JPA AttributeConverter.  AttributeConverter works totally in
 	 * memory, meaning it converts between one Java representation (the entity attribute representation) and another
 	 * (the value bound into JDBC statements or extracted from results).  However, the Hibernate Type system operates
 	 * at the lower level of actually dealing directly with those JDBC objects.  So even though we have an
 	 * AttributeConverter, we still need to "fill out" the rest of the BasicType data and bridge calls
 	 * to bind/extract through the converter.
 	 * <p/>
 	 * Essentially the idea here is that an intermediate Java type needs to be used.  Let's use an example as a means
 	 * to illustrate...  Consider an {@code AttributeConverter<Integer,String>}.  This tells Hibernate that the domain
 	 * model defines this attribute as an Integer value (the 'entityAttributeJavaType'), but that we need to treat the
 	 * value as a String (the 'databaseColumnJavaType') when dealing with JDBC (aka, the database type is a
 	 * VARCHAR/CHAR):<ul>
 	 *     <li>
 	 *         When binding values to PreparedStatements we need to convert the Integer value from the entity
 	 *         into a String and pass that String to setString.  The conversion is handled by calling
 	 *         {@link AttributeConverter#convertToDatabaseColumn(Object)}
 	 *     </li>
 	 *     <li>
 	 *         When extracting values from ResultSets (or CallableStatement parameters) we need to handle the
 	 *         value via getString, and convert that returned String to an Integer.  That conversion is handled
 	 *         by calling {@link AttributeConverter#convertToEntityAttribute(Object)}
 	 *     </li>
 	 * </ul>
 	 *
 	 * @return The built AttributeConverter -> Type adapter
 	 *
 	 * @todo : ultimately I want to see attributeConverterJavaType and attributeConverterJdbcTypeCode specify-able separately
 	 * then we can "play them against each other" in terms of determining proper typing
 	 *
 	 * @todo : see if we already have previously built a custom on-the-fly BasicType for this AttributeConverter; see note below about caching
 	 */
 	@SuppressWarnings("unchecked")
 	private Type buildAttributeConverterTypeAdapter() {
 		// todo : validate the number of columns present here?
 
 		final Class entityAttributeJavaType = attributeConverterDefinition.getEntityAttributeType();
 		final Class databaseColumnJavaType = attributeConverterDefinition.getDatabaseColumnType();
 
 
 		// resolve the JavaTypeDescriptor ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// For the JavaTypeDescriptor portion we simply resolve the "entity attribute representation" part of
 		// the AttributeConverter to resolve the corresponding descriptor.
 		final JavaTypeDescriptor entityAttributeJavaTypeDescriptor = JavaTypeDescriptorRegistry.INSTANCE.getDescriptor( entityAttributeJavaType );
 
 
 		// build the SqlTypeDescriptor adapter ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// Going back to the illustration, this should be a SqlTypeDescriptor that handles the Integer <-> String
 		//		conversions.  This is the more complicated piece.  First we need to determine the JDBC type code
 		//		corresponding to the AttributeConverter's declared "databaseColumnJavaType" (how we read that value out
 		// 		of ResultSets).  See JdbcTypeJavaClassMappings for details.  Again, given example, this should return
 		// 		VARCHAR/CHAR
 		int jdbcTypeCode = JdbcTypeJavaClassMappings.INSTANCE.determineJdbcTypeCodeForJavaClass( databaseColumnJavaType );
 		if ( isNationalized() ) {
 			jdbcTypeCode = NationalizedTypeMappings.INSTANCE.getCorrespondingNationalizedCode( jdbcTypeCode );
 		}
 		// find the standard SqlTypeDescriptor for that JDBC type code.
 		final SqlTypeDescriptor sqlTypeDescriptor = SqlTypeDescriptorRegistry.INSTANCE.getDescriptor( jdbcTypeCode );
 		// find the JavaTypeDescriptor representing the "intermediate database type representation".  Back to the
 		// 		illustration, this should be the type descriptor for Strings
 		final JavaTypeDescriptor intermediateJavaTypeDescriptor = JavaTypeDescriptorRegistry.INSTANCE.getDescriptor( databaseColumnJavaType );
 		// and finally construct the adapter, which injects the AttributeConverter calls into the binding/extraction
 		// 		process...
 		final SqlTypeDescriptor sqlTypeDescriptorAdapter = new AttributeConverterSqlTypeDescriptorAdapter(
 				attributeConverterDefinition.getAttributeConverter(),
 				sqlTypeDescriptor,
 				intermediateJavaTypeDescriptor
 		);
 
 		// todo : cache the AttributeConverterTypeAdapter in case that AttributeConverter is applied multiple times.
 
 		final String name = AttributeConverterTypeAdapter.NAME_PREFIX + attributeConverterDefinition.getAttributeConverter().getClass().getName();
 		final String description = String.format(
 				"BasicType adapter for AttributeConverter<%s,%s>",
 				entityAttributeJavaType.getSimpleName(),
 				databaseColumnJavaType.getSimpleName()
 		);
 		return new AttributeConverterTypeAdapter(
 				name,
 				description,
 				attributeConverterDefinition.getAttributeConverter(),
 				sqlTypeDescriptorAdapter,
 				entityAttributeJavaType,
 				databaseColumnJavaType,
 				entityAttributeJavaTypeDescriptor
 		);
 	}
 
 	public boolean isTypeSpecified() {
 		return typeName!=null;
 	}
 
 	public void setTypeParameters(Properties parameterMap) {
 		this.typeParameters = parameterMap;
 	}
 	
 	public Properties getTypeParameters() {
 		return typeParameters;
 	}
 
 	@Override
-    public String toString() {
+	public String toString() {
 		return getClass().getName() + '(' + columns.toString() + ')';
 	}
 
 	public Object accept(ValueVisitor visitor) {
 		return visitor.accept(this);
 	}
 	
 	public boolean[] getColumnInsertability() {
 		boolean[] result = new boolean[ getColumnSpan() ];
 		int i = 0;
 		Iterator iter = getColumnIterator();
 		while ( iter.hasNext() ) {
 			Selectable s = (Selectable) iter.next();
 			result[i++] = !s.isFormula();
 		}
 		return result;
 	}
 	
 	public boolean[] getColumnUpdateability() {
 		return getColumnInsertability();
 	}
 
 	public void setJpaAttributeConverterDefinition(AttributeConverterDefinition attributeConverterDefinition) {
 		this.attributeConverterDefinition = attributeConverterDefinition;
 	}
 
 	private void createParameterImpl() {
 		try {
 			String[] columnsNames = new String[columns.size()];
 			for ( int i = 0; i < columns.size(); i++ ) {
 				Selectable column = columns.get(i);
 				if (column instanceof Column){
 					columnsNames[i] = ((Column) column).getName();
 				}
 			}
 
 			final XProperty xProperty = (XProperty) typeParameters.get( DynamicParameterizedType.XPROPERTY );
 			// todo : not sure this works for handling @MapKeyEnumerated
 			final Annotation[] annotations = xProperty == null
 					? null
 					: xProperty.getAnnotations();
 
 			typeParameters.put(
 					DynamicParameterizedType.PARAMETER_TYPE,
 					new ParameterTypeImpl(
 							ReflectHelper.classForName(
 									typeParameters.getProperty( DynamicParameterizedType.RETURNED_CLASS )
 							),
 							annotations,
 							table.getCatalog(),
 							table.getSchema(),
 							table.getName(),
 							Boolean.valueOf( typeParameters.getProperty( DynamicParameterizedType.IS_PRIMARY_KEY ) ),
 							columnsNames
 					)
 			);
 		}
 		catch ( ClassNotFoundException cnfe ) {
 			throw new MappingException( "Could not create DynamicParameterizedType for type: " + typeName, cnfe );
 		}
 	}
 
 	private final class ParameterTypeImpl implements DynamicParameterizedType.ParameterType {
 
 		private final Class returnedClass;
 		private final Annotation[] annotationsMethod;
 		private final String catalog;
 		private final String schema;
 		private final String table;
 		private final boolean primaryKey;
 		private final String[] columns;
 
 		private ParameterTypeImpl(Class returnedClass, Annotation[] annotationsMethod, String catalog, String schema,
 				String table, boolean primaryKey, String[] columns) {
 			this.returnedClass = returnedClass;
 			this.annotationsMethod = annotationsMethod;
 			this.catalog = catalog;
 			this.schema = schema;
 			this.table = table;
 			this.primaryKey = primaryKey;
 			this.columns = columns;
 		}
 
 		@Override
 		public Class getReturnedClass() {
 			return returnedClass;
 		}
 
 		@Override
 		public Annotation[] getAnnotationsMethod() {
 			return annotationsMethod;
 		}
 
 		@Override
 		public String getCatalog() {
 			return catalog;
 		}
 
 		@Override
 		public String getSchema() {
 			return schema;
 		}
 
 		@Override
 		public String getTable() {
 			return table;
 		}
 
 		@Override
 		public boolean isPrimaryKey() {
 			return primaryKey;
 		}
 
 		@Override
 		public String[] getColumns() {
 			return columns;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/SingleTableSubclass.java b/hibernate-core/src/main/java/org/hibernate/mapping/SingleTableSubclass.java
index 897126004f..b5e57acb45 100755
--- a/hibernate-core/src/main/java/org/hibernate/mapping/SingleTableSubclass.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/SingleTableSubclass.java
@@ -1,66 +1,72 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
+
 import java.util.Iterator;
 
 import org.hibernate.MappingException;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.internal.util.collections.JoinedIterator;
 
 /**
  * @author Gavin King
  */
 public class SingleTableSubclass extends Subclass {
-	
+
 	public SingleTableSubclass(PersistentClass superclass) {
-		super(superclass);
+		super( superclass );
 	}
-	
+
+	@SuppressWarnings("unchecked")
 	protected Iterator getNonDuplicatedPropertyIterator() {
 		return new JoinedIterator(
 				getSuperclass().getUnjoinedPropertyIterator(),
 				getUnjoinedPropertyIterator()
 		);
 	}
-	
+
 	protected Iterator getDiscriminatorColumnIterator() {
 		if ( isDiscriminatorInsertable() && !getDiscriminator().hasFormula() ) {
 			return getDiscriminator().getColumnIterator();
 		}
 		else {
 			return super.getDiscriminatorColumnIterator();
 		}
 	}
 
 	public Object accept(PersistentClassVisitor mv) {
-		return mv.accept(this);
+		return mv.accept( this );
+	}
+
+	public void validate(Mapping mapping) throws MappingException {
+		if ( getDiscriminator() == null ) {
+			throw new MappingException(
+					"No discriminator found for " + getEntityName()
+							+ ". Discriminator is needed when 'single-table-per-hierarchy' "
+							+ "is used and a class has subclasses"
+			);
+		}
+		super.validate( mapping );
 	}
-    
-    public void validate(Mapping mapping) throws MappingException {
-        if(getDiscriminator()==null) {
-            throw new MappingException("No discriminator found for " + getEntityName() + ". Discriminator is needed when 'single-table-per-hierarchy' is used and a class has subclasses");
-        }
-        super.validate(mapping);
-    }
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/UniqueKey.java b/hibernate-core/src/main/java/org/hibernate/mapping/UniqueKey.java
index f336aa9d71..1cfa8ea151 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/UniqueKey.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/UniqueKey.java
@@ -1,89 +1,94 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * A relational unique key constraint
  *
  * @author Brett Meyer
  */
 public class UniqueKey extends Constraint {
-	private java.util.Map<Column, String> columnOrderMap = new HashMap<Column, String>(  );
+	private java.util.Map<Column, String> columnOrderMap = new HashMap<Column, String>();
 
 	@Override
-    public String sqlConstraintString(
+	public String sqlConstraintString(
 			Dialect dialect,
 			String constraintName,
 			String defaultCatalog,
 			String defaultSchema) {
 //		return dialect.getUniqueDelegate().uniqueConstraintSql( this );
 		// Not used.
 		return "";
 	}
 
 	@Override
-    public String sqlCreateString(Dialect dialect, Mapping p,
-    		String defaultCatalog, String defaultSchema) {
+	public String sqlCreateString(
+			Dialect dialect,
+			Mapping p,
+			String defaultCatalog,
+			String defaultSchema) {
 		return null;
 //		return dialect.getUniqueDelegate().getAlterTableToAddUniqueKeyCommand(
 //				this, defaultCatalog, defaultSchema
 //		);
 	}
 
 	@Override
-    public String sqlDropString(Dialect dialect, String defaultCatalog,
-    		String defaultSchema) {
+	public String sqlDropString(
+			Dialect dialect,
+			String defaultCatalog,
+			String defaultSchema) {
 		return null;
 //		return dialect.getUniqueDelegate().getAlterTableToDropUniqueKeyCommand(
 //				this, defaultCatalog, defaultSchema
 //		);
 	}
 
 	public void addColumn(Column column, String order) {
 		addColumn( column );
 		if ( StringHelper.isNotEmpty( order ) ) {
 			columnOrderMap.put( column, order );
 		}
 	}
 
 	public Map<Column, String> getColumnOrderMap() {
 		return columnOrderMap;
 	}
-	
+
 	public String generatedConstraintNamePrefix() {
 		return "UK_";
 	}
 
 	@Override
 	public String getExportIdentifier() {
 		return StringHelper.qualify( getTable().getName(), "UK-" + getName() );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/param/NamedParameterSpecification.java b/hibernate-core/src/main/java/org/hibernate/param/NamedParameterSpecification.java
index 3c347654c8..34ab0ca84d 100644
--- a/hibernate-core/src/main/java/org/hibernate/param/NamedParameterSpecification.java
+++ b/hibernate-core/src/main/java/org/hibernate/param/NamedParameterSpecification.java
@@ -1,84 +1,87 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.param;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.TypedValue;
 
 /**
  * Parameter bind specification for an explicit named parameter.
  *
  * @author Steve Ebersole
  */
 public class NamedParameterSpecification extends AbstractExplicitParameterSpecification {
 	private final String name;
 
 	/**
 	 * Constructs a named parameter bind specification.
 	 *
 	 * @param sourceLine See {@link #getSourceLine()}
 	 * @param sourceColumn See {@link #getSourceColumn()} 
 	 * @param name The named parameter name.
 	 */
 	public NamedParameterSpecification(int sourceLine, int sourceColumn, String name) {
 		super( sourceLine, sourceColumn );
 		this.name = name;
 	}
 
 	/**
 	 * Bind the appropriate value into the given statement at the specified position.
 	 *
 	 * @param statement The statement into which the value should be bound.
 	 * @param qp The defined values for the current query execution.
 	 * @param session The session against which the current execution is occuring.
 	 * @param position The position from which to start binding value(s).
 	 *
 	 * @return The number of sql bind positions "eaten" by this bind operation.
 	 */
 	@Override
-	public int bind(PreparedStatement statement, QueryParameters qp, SessionImplementor session, int position)
-	        throws SQLException {
+	public int bind(
+			PreparedStatement statement,
+			QueryParameters qp,
+			SessionImplementor session,
+			int position) throws SQLException {
 		TypedValue typedValue = qp.getNamedParameters().get( name );
 		typedValue.getType().nullSafeSet( statement, typedValue.getValue(), position, session );
 		return typedValue.getType().getColumnSpan( session.getFactory() );
 	}
 
 	@Override
 	public String renderDisplayInfo() {
 		return "name=" + name + ", expectedType=" + getExpectedType();
 	}
 
 	/**
 	 * Getter for property 'name'.
 	 *
 	 * @return Value for property 'name'.
 	 */
 	public String getName() {
 		return name;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/param/VersionTypeSeedParameterSpecification.java b/hibernate-core/src/main/java/org/hibernate/param/VersionTypeSeedParameterSpecification.java
index 2407e23bb0..9ed49e21e4 100644
--- a/hibernate-core/src/main/java/org/hibernate/param/VersionTypeSeedParameterSpecification.java
+++ b/hibernate-core/src/main/java/org/hibernate/param/VersionTypeSeedParameterSpecification.java
@@ -1,72 +1,75 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.param;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 
 /**
  * Parameter bind specification used for optimisitc lock version seeding (from insert statements).
  *
  * @author Steve Ebersole
  */
 public class VersionTypeSeedParameterSpecification implements ParameterSpecification {
 	private final VersionType type;
 
 	/**
 	 * Constructs a version seed parameter bind specification.
 	 *
 	 * @param type The version type.
 	 */
 	public VersionTypeSeedParameterSpecification(VersionType type) {
 		this.type = type;
 	}
 
 	@Override
-	public int bind(PreparedStatement statement, QueryParameters qp, SessionImplementor session, int position)
-	        throws SQLException {
+	public int bind(
+			PreparedStatement statement,
+			QueryParameters qp,
+			SessionImplementor session,
+			int position) throws SQLException {
 		type.nullSafeSet( statement, type.seed( session ), position, session );
 		return 1;
 	}
 
 	@Override
 	public Type getExpectedType() {
 		return type;
 	}
 
 	@Override
 	public void setExpectedType(Type expectedType) {
 		// expected type is intrinsic here...
 	}
 
 	@Override
 	public String renderDisplayInfo() {
 		return "version-seed, type=" + type;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
index ae729d57c9..5d783b2c1e 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
@@ -1,1922 +1,1922 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.collection;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.FetchMode;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.cache.spi.entry.CacheEntryStructure;
 import org.hibernate.cache.spi.entry.StructuredCollectionCacheEntry;
 import org.hibernate.cache.spi.entry.StructuredMapCacheEntry;
 import org.hibernate.cache.spi.entry.UnstructuredCacheEntry;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.SubselectFetch;
 import org.hibernate.exception.spi.SQLExceptionConverter;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.FilterAliasGenerator;
 import org.hibernate.internal.FilterHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.loader.collection.CollectionInitializer;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Formula;
 import org.hibernate.mapping.IdentifierCollection;
 import org.hibernate.mapping.IndexedCollection;
 import org.hibernate.mapping.List;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.mapping.Table;
 import org.hibernate.metadata.CollectionMetadata;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.persister.walking.internal.CompositionSingularSubAttributesHelper;
 import org.hibernate.persister.walking.internal.StandardAnyTypeDefinition;
 import org.hibernate.persister.walking.spi.AnyMappingDefinition;
 import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.AttributeSource;
 import org.hibernate.persister.walking.spi.CollectionDefinition;
 import org.hibernate.persister.walking.spi.CollectionElementDefinition;
 import org.hibernate.persister.walking.spi.CollectionIndexDefinition;
 import org.hibernate.persister.walking.spi.CompositeCollectionElementDefinition;
 import org.hibernate.persister.walking.spi.CompositionDefinition;
 import org.hibernate.persister.walking.spi.EntityDefinition;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Alias;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.SimpleSelect;
 import org.hibernate.sql.Template;
 import org.hibernate.sql.ordering.antlr.ColumnMapper;
 import org.hibernate.sql.ordering.antlr.ColumnReference;
 import org.hibernate.sql.ordering.antlr.FormulaReference;
 import org.hibernate.sql.ordering.antlr.OrderByAliasResolver;
 import org.hibernate.sql.ordering.antlr.OrderByTranslation;
 import org.hibernate.sql.ordering.antlr.SqlValueReference;
 import org.hibernate.type.AnyType;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * Base implementation of the <tt>QueryableCollection</tt> interface.
  *
  * @author Gavin King
  * @see BasicCollectionPersister
  * @see OneToManyPersister
  */
 public abstract class AbstractCollectionPersister
 		implements CollectionMetadata, SQLLoadableCollection {
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class,
 			AbstractCollectionPersister.class.getName() );
 
 	// TODO: encapsulate the protected instance variables!
 
 	private final String role;
 
 	// SQL statements
 	private final String sqlDeleteString;
 	private final String sqlInsertRowString;
 	private final String sqlUpdateRowString;
 	private final String sqlDeleteRowString;
 	private final String sqlSelectSizeString;
 	private final String sqlSelectRowByIndexString;
 	private final String sqlDetectRowByIndexString;
 	private final String sqlDetectRowByElementString;
 
 	protected final boolean hasWhere;
 	protected final String sqlWhereString;
 	private final String sqlWhereStringTemplate;
 
 	private final boolean hasOrder;
 	private final OrderByTranslation orderByTranslation;
 
 	private final boolean hasManyToManyOrder;
 	private final OrderByTranslation manyToManyOrderByTranslation;
 
 	private final int baseIndex;
 
 	private final String nodeName;
 	private final String elementNodeName;
 	private final String indexNodeName;
 	private String mappedByProperty;
 
 	protected final boolean indexContainsFormula;
 	protected final boolean elementIsPureFormula;
 
 	// types
 	private final Type keyType;
 	private final Type indexType;
 	protected final Type elementType;
 	private final Type identifierType;
 
 	// columns
 	protected final String[] keyColumnNames;
 	protected final String[] indexColumnNames;
 	protected final String[] indexFormulaTemplates;
 	protected final String[] indexFormulas;
 	protected final boolean[] indexColumnIsSettable;
 	protected final String[] elementColumnNames;
 	protected final String[] elementColumnWriters;
 	protected final String[] elementColumnReaders;
 	protected final String[] elementColumnReaderTemplates;
 	protected final String[] elementFormulaTemplates;
 	protected final String[] elementFormulas;
 	protected final boolean[] elementColumnIsSettable;
 	protected final boolean[] elementColumnIsInPrimaryKey;
 	protected final String[] indexColumnAliases;
 	protected final String[] elementColumnAliases;
 	protected final String[] keyColumnAliases;
 
 	protected final String identifierColumnName;
 	private final String identifierColumnAlias;
 	// private final String unquotedIdentifierColumnName;
 
 	protected final String qualifiedTableName;
 
 	private final String queryLoaderName;
 
 	private final boolean isPrimitiveArray;
 	private final boolean isArray;
 	protected final boolean hasIndex;
 	protected final boolean hasIdentifier;
 	private final boolean isLazy;
 	private final boolean isExtraLazy;
 	protected final boolean isInverse;
 	private final boolean isMutable;
 	private final boolean isVersioned;
 	protected final int batchSize;
 	private final FetchMode fetchMode;
 	private final boolean hasOrphanDelete;
 	private final boolean subselectLoadable;
 
 	// extra information about the element type
 	private final Class elementClass;
 	private final String entityName;
 
 	private final Dialect dialect;
 	protected final SqlExceptionHelper sqlExceptionHelper;
 	private final SessionFactoryImplementor factory;
 	private final EntityPersister ownerPersister;
 	private final IdentifierGenerator identifierGenerator;
 	private final PropertyMapping elementPropertyMapping;
 	private final EntityPersister elementPersister;
 	private final CollectionRegionAccessStrategy cacheAccessStrategy;
 	private final CollectionType collectionType;
 	private CollectionInitializer initializer;
 
 	private final CacheEntryStructure cacheEntryStructure;
 
 	// dynamic filters for the collection
 	private final FilterHelper filterHelper;
 
 	// dynamic filters specifically for many-to-many inside the collection
 	private final FilterHelper manyToManyFilterHelper;
 
 	private final String manyToManyWhereString;
 	private final String manyToManyWhereTemplate;
 
 	// custom sql
 	private final boolean insertCallable;
 	private final boolean updateCallable;
 	private final boolean deleteCallable;
 	private final boolean deleteAllCallable;
 	private ExecuteUpdateResultCheckStyle insertCheckStyle;
 	private ExecuteUpdateResultCheckStyle updateCheckStyle;
 	private ExecuteUpdateResultCheckStyle deleteCheckStyle;
 	private ExecuteUpdateResultCheckStyle deleteAllCheckStyle;
 
 	private final Serializable[] spaces;
 
 	private Map collectionPropertyColumnAliases = new HashMap();
 	private Map collectionPropertyColumnNames = new HashMap();
 
 	public AbstractCollectionPersister(
 			Collection collectionBinding,
 			CollectionRegionAccessStrategy cacheAccessStrategy,
 			PersisterCreationContext creationContext) throws MappingException, CacheException {
 
 		this.factory = creationContext.getSessionFactory();
 		this.cacheAccessStrategy = cacheAccessStrategy;
 		if ( factory.getSettings().isStructuredCacheEntriesEnabled() ) {
 			cacheEntryStructure = collectionBinding.isMap()
 					? StructuredMapCacheEntry.INSTANCE
 					: StructuredCollectionCacheEntry.INSTANCE;
 		}
 		else {
 			cacheEntryStructure = UnstructuredCacheEntry.INSTANCE;
 		}
 
 		dialect = factory.getDialect();
 		sqlExceptionHelper = factory.getSQLExceptionHelper();
 		collectionType = collectionBinding.getCollectionType();
 		role = collectionBinding.getRole();
 		entityName = collectionBinding.getOwnerEntityName();
 		ownerPersister = factory.getEntityPersister( entityName );
 		queryLoaderName = collectionBinding.getLoaderName();
 		nodeName = collectionBinding.getNodeName();
 		isMutable = collectionBinding.isMutable();
 		mappedByProperty = collectionBinding.getMappedByProperty();
 
 		Table table = collectionBinding.getCollectionTable();
 		fetchMode = collectionBinding.getElement().getFetchMode();
 		elementType = collectionBinding.getElement().getType();
 		// isSet = collectionBinding.isSet();
 		// isSorted = collectionBinding.isSorted();
 		isPrimitiveArray = collectionBinding.isPrimitiveArray();
 		isArray = collectionBinding.isArray();
 		subselectLoadable = collectionBinding.isSubselectLoadable();
 
 		qualifiedTableName = table.getQualifiedName(
 				dialect,
 				factory.getSettings().getDefaultCatalogName(),
 				factory.getSettings().getDefaultSchemaName()
 				);
 
 		int spacesSize = 1 + collectionBinding.getSynchronizedTables().size();
 		spaces = new String[spacesSize];
 		spaces[0] = qualifiedTableName;
 		Iterator iter = collectionBinding.getSynchronizedTables().iterator();
 		for ( int i = 1; i < spacesSize; i++ ) {
 			spaces[i] = (String) iter.next();
 		}
 
 		sqlWhereString = StringHelper.isNotEmpty( collectionBinding.getWhere() ) ? "( " + collectionBinding.getWhere() + ") " : null;
 		hasWhere = sqlWhereString != null;
 		sqlWhereStringTemplate = hasWhere ?
 				Template.renderWhereStringTemplate( sqlWhereString, dialect, factory.getSqlFunctionRegistry() ) :
 				null;
 
 		hasOrphanDelete = collectionBinding.hasOrphanDelete();
 
 		int batch = collectionBinding.getBatchSize();
 		if ( batch == -1 ) {
 			batch = factory.getSettings().getDefaultBatchFetchSize();
 		}
 		batchSize = batch;
 
 		isVersioned = collectionBinding.isOptimisticLocked();
 
 		// KEY
 
 		keyType = collectionBinding.getKey().getType();
 		iter = collectionBinding.getKey().getColumnIterator();
 		int keySpan = collectionBinding.getKey().getColumnSpan();
 		keyColumnNames = new String[keySpan];
 		keyColumnAliases = new String[keySpan];
 		int k = 0;
 		while ( iter.hasNext() ) {
 			// NativeSQL: collect key column and auto-aliases
 			Column col = ( (Column) iter.next() );
 			keyColumnNames[k] = col.getQuotedName( dialect );
 			keyColumnAliases[k] = col.getAlias( dialect, collectionBinding.getOwner().getRootTable() );
 			k++;
 		}
 
 		// unquotedKeyColumnNames = StringHelper.unQuote(keyColumnAliases);
 
 		// ELEMENT
 
 		String elemNode = collectionBinding.getElementNodeName();
 		if ( elementType.isEntityType() ) {
 			String entityName = ( (EntityType) elementType ).getAssociatedEntityName();
 			elementPersister = factory.getEntityPersister( entityName );
 			if ( elemNode == null ) {
 				elemNode = creationContext.getMetadata().getEntityBinding( entityName ).getNodeName();
 			}
 			// NativeSQL: collect element column and auto-aliases
 
 		}
 		else {
 			elementPersister = null;
 		}
 		elementNodeName = elemNode;
 
 		int elementSpan = collectionBinding.getElement().getColumnSpan();
 		elementColumnAliases = new String[elementSpan];
 		elementColumnNames = new String[elementSpan];
 		elementColumnWriters = new String[elementSpan];
 		elementColumnReaders = new String[elementSpan];
 		elementColumnReaderTemplates = new String[elementSpan];
 		elementFormulaTemplates = new String[elementSpan];
 		elementFormulas = new String[elementSpan];
 		elementColumnIsSettable = new boolean[elementSpan];
 		elementColumnIsInPrimaryKey = new boolean[elementSpan];
 		boolean isPureFormula = true;
 		boolean hasNotNullableColumns = false;
 		int j = 0;
 		iter = collectionBinding.getElement().getColumnIterator();
 		while ( iter.hasNext() ) {
 			Selectable selectable = (Selectable) iter.next();
 			elementColumnAliases[j] = selectable.getAlias( dialect, table );
 			if ( selectable.isFormula() ) {
 				Formula form = (Formula) selectable;
 				elementFormulaTemplates[j] = form.getTemplate( dialect, factory.getSqlFunctionRegistry() );
 				elementFormulas[j] = form.getFormula();
 			}
 			else {
 				Column col = (Column) selectable;
 				elementColumnNames[j] = col.getQuotedName( dialect );
 				elementColumnWriters[j] = col.getWriteExpr();
 				elementColumnReaders[j] = col.getReadExpr( dialect );
 				elementColumnReaderTemplates[j] = col.getTemplate( dialect, factory.getSqlFunctionRegistry() );
 				elementColumnIsSettable[j] = true;
 				elementColumnIsInPrimaryKey[j] = !col.isNullable();
 				if ( !col.isNullable() ) {
 					hasNotNullableColumns = true;
 				}
 				isPureFormula = false;
 			}
 			j++;
 		}
 		elementIsPureFormula = isPureFormula;
 
 		// workaround, for backward compatibility of sets with no
 		// not-null columns, assume all columns are used in the
 		// row locator SQL
 		if ( !hasNotNullableColumns ) {
 			Arrays.fill( elementColumnIsInPrimaryKey, true );
 		}
 
 		// INDEX AND ROW SELECT
 
 		hasIndex = collectionBinding.isIndexed();
 		if ( hasIndex ) {
 			// NativeSQL: collect index column and auto-aliases
 			IndexedCollection indexedCollection = (IndexedCollection) collectionBinding;
 			indexType = indexedCollection.getIndex().getType();
 			int indexSpan = indexedCollection.getIndex().getColumnSpan();
 			iter = indexedCollection.getIndex().getColumnIterator();
 			indexColumnNames = new String[indexSpan];
 			indexFormulaTemplates = new String[indexSpan];
 			indexFormulas = new String[indexSpan];
 			indexColumnIsSettable = new boolean[indexSpan];
 			indexColumnAliases = new String[indexSpan];
 			int i = 0;
 			boolean hasFormula = false;
 			while ( iter.hasNext() ) {
 				Selectable s = (Selectable) iter.next();
 				indexColumnAliases[i] = s.getAlias( dialect );
 				if ( s.isFormula() ) {
 					Formula indexForm = (Formula) s;
 					indexFormulaTemplates[i] = indexForm.getTemplate( dialect, factory.getSqlFunctionRegistry() );
 					indexFormulas[i] = indexForm.getFormula();
 					hasFormula = true;
 				}
 				else {
 					Column indexCol = (Column) s;
 					indexColumnNames[i] = indexCol.getQuotedName( dialect );
 					indexColumnIsSettable[i] = true;
 				}
 				i++;
 			}
 			indexContainsFormula = hasFormula;
 			baseIndex = indexedCollection.isList() ?
 					( (List) indexedCollection ).getBaseIndex() : 0;
 
 			indexNodeName = indexedCollection.getIndexNodeName();
 
 		}
 		else {
 			indexContainsFormula = false;
 			indexColumnIsSettable = null;
 			indexFormulaTemplates = null;
 			indexFormulas = null;
 			indexType = null;
 			indexColumnNames = null;
 			indexColumnAliases = null;
 			baseIndex = 0;
 			indexNodeName = null;
 		}
 
 		hasIdentifier = collectionBinding.isIdentified();
 		if ( hasIdentifier ) {
 			if ( collectionBinding.isOneToMany() ) {
 				throw new MappingException( "one-to-many collections with identifiers are not supported" );
 			}
 			IdentifierCollection idColl = (IdentifierCollection) collectionBinding;
 			identifierType = idColl.getIdentifier().getType();
 			iter = idColl.getIdentifier().getColumnIterator();
 			Column col = (Column) iter.next();
 			identifierColumnName = col.getQuotedName( dialect );
 			identifierColumnAlias = col.getAlias( dialect );
 			// unquotedIdentifierColumnName = identifierColumnAlias;
 			identifierGenerator = idColl.getIdentifier().createIdentifierGenerator(
 					creationContext.getMetadata().getIdentifierGeneratorFactory(),
 					factory.getDialect(),
 					factory.getSettings().getDefaultCatalogName(),
 					factory.getSettings().getDefaultSchemaName(),
 					null
 					);
 		}
 		else {
 			identifierType = null;
 			identifierColumnName = null;
 			identifierColumnAlias = null;
 			// unquotedIdentifierColumnName = null;
 			identifierGenerator = null;
 		}
 
 		// GENERATE THE SQL:
 
 		// sqlSelectString = sqlSelectString();
 		// sqlSelectRowString = sqlSelectRowString();
 
 		if ( collectionBinding.getCustomSQLInsert() == null ) {
 			sqlInsertRowString = generateInsertRowString();
 			insertCallable = false;
 			insertCheckStyle = ExecuteUpdateResultCheckStyle.COUNT;
 		}
 		else {
 			sqlInsertRowString = collectionBinding.getCustomSQLInsert();
 			insertCallable = collectionBinding.isCustomInsertCallable();
 			insertCheckStyle = collectionBinding.getCustomSQLInsertCheckStyle() == null
 					? ExecuteUpdateResultCheckStyle.determineDefault( collectionBinding.getCustomSQLInsert(), insertCallable )
 					: collectionBinding.getCustomSQLInsertCheckStyle();
 		}
 
 		if ( collectionBinding.getCustomSQLUpdate() == null ) {
 			sqlUpdateRowString = generateUpdateRowString();
 			updateCallable = false;
 			updateCheckStyle = ExecuteUpdateResultCheckStyle.COUNT;
 		}
 		else {
 			sqlUpdateRowString = collectionBinding.getCustomSQLUpdate();
 			updateCallable = collectionBinding.isCustomUpdateCallable();
 			updateCheckStyle = collectionBinding.getCustomSQLUpdateCheckStyle() == null
 					? ExecuteUpdateResultCheckStyle.determineDefault( collectionBinding.getCustomSQLUpdate(), insertCallable )
 					: collectionBinding.getCustomSQLUpdateCheckStyle();
 		}
 
 		if ( collectionBinding.getCustomSQLDelete() == null ) {
 			sqlDeleteRowString = generateDeleteRowString();
 			deleteCallable = false;
 			deleteCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 		else {
 			sqlDeleteRowString = collectionBinding.getCustomSQLDelete();
 			deleteCallable = collectionBinding.isCustomDeleteCallable();
 			deleteCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 
 		if ( collectionBinding.getCustomSQLDeleteAll() == null ) {
 			sqlDeleteString = generateDeleteString();
 			deleteAllCallable = false;
 			deleteAllCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 		else {
 			sqlDeleteString = collectionBinding.getCustomSQLDeleteAll();
 			deleteAllCallable = collectionBinding.isCustomDeleteAllCallable();
 			deleteAllCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 
 		sqlSelectSizeString = generateSelectSizeString( collectionBinding.isIndexed() && !collectionBinding.isMap() );
 		sqlDetectRowByIndexString = generateDetectRowByIndexString();
 		sqlDetectRowByElementString = generateDetectRowByElementString();
 		sqlSelectRowByIndexString = generateSelectRowByIndexString();
 
 		logStaticSQL();
 
 		isLazy = collectionBinding.isLazy();
 		isExtraLazy = collectionBinding.isExtraLazy();
 
 		isInverse = collectionBinding.isInverse();
 
 		if ( collectionBinding.isArray() ) {
 			elementClass = ( (org.hibernate.mapping.Array) collectionBinding ).getElementClass();
 		}
 		else {
 			// for non-arrays, we don't need to know the element class
 			elementClass = null; // elementType.returnedClass();
 		}
 
 		if ( elementType.isComponentType() ) {
 			elementPropertyMapping = new CompositeElementPropertyMapping(
 					elementColumnNames,
 					elementColumnReaders,
 					elementColumnReaderTemplates,
 					elementFormulaTemplates,
 					(CompositeType) elementType,
 					factory
 					);
 		}
 		else if ( !elementType.isEntityType() ) {
 			elementPropertyMapping = new ElementPropertyMapping(
 					elementColumnNames,
 					elementType
 					);
 		}
 		else {
 			if ( elementPersister instanceof PropertyMapping ) { // not all classpersisters implement PropertyMapping!
 				elementPropertyMapping = (PropertyMapping) elementPersister;
 			}
 			else {
 				elementPropertyMapping = new ElementPropertyMapping(
 						elementColumnNames,
 						elementType
 						);
 			}
 		}
 
 		hasOrder = collectionBinding.getOrderBy() != null;
 		if ( hasOrder ) {
 			orderByTranslation = Template.translateOrderBy(
 					collectionBinding.getOrderBy(),
 					new ColumnMapperImpl(),
 					factory,
 					dialect,
 					factory.getSqlFunctionRegistry()
 			);
 		}
 		else {
 			orderByTranslation = null;
 		}
 
 		// Handle any filters applied to this collectionBinding
 		filterHelper = new FilterHelper( collectionBinding.getFilters(), factory);
 
 		// Handle any filters applied to this collectionBinding for many-to-many
 		manyToManyFilterHelper = new FilterHelper( collectionBinding.getManyToManyFilters(), factory);
 		manyToManyWhereString = StringHelper.isNotEmpty( collectionBinding.getManyToManyWhere() ) ?
 				"( " + collectionBinding.getManyToManyWhere() + ")" :
 				null;
 		manyToManyWhereTemplate = manyToManyWhereString == null ?
 				null :
 				Template.renderWhereStringTemplate( manyToManyWhereString, factory.getDialect(), factory.getSqlFunctionRegistry() );
 
 		hasManyToManyOrder = collectionBinding.getManyToManyOrdering() != null;
 		if ( hasManyToManyOrder ) {
 			manyToManyOrderByTranslation = Template.translateOrderBy(
 					collectionBinding.getManyToManyOrdering(),
 					new ColumnMapperImpl(),
 					factory,
 					dialect,
 					factory.getSqlFunctionRegistry()
 			);
 		}
 		else {
 			manyToManyOrderByTranslation = null;
 		}
 
 		initCollectionPropertyMap();
 	}
 
 	private class ColumnMapperImpl implements ColumnMapper {
 		@Override
 		public SqlValueReference[] map(String reference) {
 			final String[] columnNames;
 			final String[] formulaTemplates;
 
 			// handle the special "$element$" property name...
 			if ( "$element$".equals( reference ) ) {
 				columnNames = elementColumnNames;
 				formulaTemplates = elementFormulaTemplates;
 			}
 			else {
 				columnNames = elementPropertyMapping.toColumns( reference );
 				formulaTemplates = formulaTemplates( reference, columnNames.length );
 			}
 
 			final SqlValueReference[] result = new SqlValueReference[ columnNames.length ];
 			int i = 0;
 			for ( final String columnName : columnNames ) {
 				if ( columnName == null ) {
 					// if the column name is null, it indicates that this index in the property value mapping is
 					// actually represented by a formula.
 //					final int propertyIndex = elementPersister.getEntityMetamodel().getPropertyIndex( reference );
 					final String formulaTemplate = formulaTemplates[i];
 					result[i] = new FormulaReference() {
 						@Override
 						public String getFormulaFragment() {
 							return formulaTemplate;
 						}
 					};
 				}
 				else {
 					result[i] = new ColumnReference() {
 						@Override
 						public String getColumnName() {
 							return columnName;
 						}
 					};
 				}
 				i++;
 			}
 			return result;
 		}
 	}
 
 	private String[] formulaTemplates(String reference, int expectedSize) {
 		try {
 			final int propertyIndex = elementPersister.getEntityMetamodel().getPropertyIndex( reference );
 			return  ( (Queryable) elementPersister ).getSubclassPropertyFormulaTemplateClosure()[propertyIndex];
 		}
 		catch (Exception e) {
 			return new String[expectedSize];
 		}
 	}
 
 	@Override
 	public void postInstantiate() throws MappingException {
 		initializer = queryLoaderName == null ?
 				createCollectionInitializer( LoadQueryInfluencers.NONE ) :
 				new NamedQueryCollectionInitializer( queryLoaderName, this );
 	}
 
 	protected void logStaticSQL() {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "Static SQL for collection: %s", getRole() );
 			if ( getSQLInsertRowString() != null ) {
 				LOG.debugf( " Row insert: %s", getSQLInsertRowString() );
 			}
 			if ( getSQLUpdateRowString() != null ) {
 				LOG.debugf( " Row update: %s", getSQLUpdateRowString() );
 			}
 			if ( getSQLDeleteRowString() != null ) {
 				LOG.debugf( " Row delete: %s", getSQLDeleteRowString() );
 			}
 			if ( getSQLDeleteString() != null ) {
 				LOG.debugf( " One-shot delete: %s", getSQLDeleteString() );
 			}
 		}
 	}
 
 	@Override
 	public void initialize(Serializable key, SessionImplementor session) throws HibernateException {
 		getAppropriateInitializer( key, session ).initialize( key, session );
 	}
 
 	protected CollectionInitializer getAppropriateInitializer(Serializable key, SessionImplementor session) {
 		if ( queryLoaderName != null ) {
 			// if there is a user-specified loader, return that
 			// TODO: filters!?
 			return initializer;
 		}
 		CollectionInitializer subselectInitializer = getSubselectInitializer( key, session );
 		if ( subselectInitializer != null ) {
 			return subselectInitializer;
 		}
 		else if ( session.getLoadQueryInfluencers().getEnabledFilters().isEmpty() ) {
 			return initializer;
 		}
 		else {
 			return createCollectionInitializer( session.getLoadQueryInfluencers() );
 		}
 	}
 
 	private CollectionInitializer getSubselectInitializer(Serializable key, SessionImplementor session) {
 
 		if ( !isSubselectLoadable() ) {
 			return null;
 		}
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 
 		SubselectFetch subselect = persistenceContext.getBatchFetchQueue()
 				.getSubselect( session.generateEntityKey( key, getOwnerEntityPersister() ) );
 
 		if ( subselect == null ) {
 			return null;
 		}
 		else {
 
 			// Take care of any entities that might have
 			// been evicted!
 			Iterator iter = subselect.getResult().iterator();
 			while ( iter.hasNext() ) {
 				if ( !persistenceContext.containsEntity( (EntityKey) iter.next() ) ) {
 					iter.remove();
 				}
 			}
 
 			// Run a subquery loader
 			return createSubselectInitializer( subselect, session );
 		}
 	}
 
 	protected abstract CollectionInitializer createSubselectInitializer(SubselectFetch subselect, SessionImplementor session);
 
 	protected abstract CollectionInitializer createCollectionInitializer(LoadQueryInfluencers loadQueryInfluencers)
 			throws MappingException;
 
 	@Override
 	public CollectionRegionAccessStrategy getCacheAccessStrategy() {
 		return cacheAccessStrategy;
 	}
 
 	@Override
 	public boolean hasCache() {
 		return cacheAccessStrategy != null;
 	}
 
 	@Override
 	public CollectionType getCollectionType() {
 		return collectionType;
 	}
 
 	protected String getSQLWhereString(String alias) {
 		return StringHelper.replace( sqlWhereStringTemplate, Template.TEMPLATE, alias );
 	}
 
 	@Override
 	public String getSQLOrderByString(String alias) {
 		return hasOrdering()
 				? orderByTranslation.injectAliases( new StandardOrderByAliasResolver( alias ) )
 				: "";
 	}
 
 	@Override
 	public String getManyToManyOrderByString(String alias) {
 		return hasManyToManyOrdering()
 				? manyToManyOrderByTranslation.injectAliases( new StandardOrderByAliasResolver( alias ) )
 				: "";
 	}
 
 	@Override
 	public FetchMode getFetchMode() {
 		return fetchMode;
 	}
 
 	@Override
 	public boolean hasOrdering() {
 		return hasOrder;
 	}
 
 	@Override
 	public boolean hasManyToManyOrdering() {
 		return isManyToMany() && hasManyToManyOrder;
 	}
 
 	@Override
 	public boolean hasWhere() {
 		return hasWhere;
 	}
 
 	protected String getSQLDeleteString() {
 		return sqlDeleteString;
 	}
 
 	protected String getSQLInsertRowString() {
 		return sqlInsertRowString;
 	}
 
 	protected String getSQLUpdateRowString() {
 		return sqlUpdateRowString;
 	}
 
 	protected String getSQLDeleteRowString() {
 		return sqlDeleteRowString;
 	}
 
 	@Override
 	public Type getKeyType() {
 		return keyType;
 	}
 
 	@Override
 	public Type getIndexType() {
 		return indexType;
 	}
 
 	@Override
 	public Type getElementType() {
 		return elementType;
 	}
 
 	/**
 	 * Return the element class of an array, or null otherwise.  needed by arrays
 	 */
 	@Override
 	public Class getElementClass() {
 		return elementClass;
 	}
 
 	@Override
 	public Object readElement(ResultSet rs, Object owner, String[] aliases, SessionImplementor session)
 			throws HibernateException, SQLException {
 		return getElementType().nullSafeGet( rs, aliases, session, owner );
 	}
 
 	@Override
 	public Object readIndex(ResultSet rs, String[] aliases, SessionImplementor session)
 			throws HibernateException, SQLException {
 		Object index = getIndexType().nullSafeGet( rs, aliases, session, null );
 		if ( index == null ) {
 			throw new HibernateException( "null index column for collection: " + role );
 		}
 		index = decrementIndexByBase( index );
 		return index;
 	}
 
 	protected Object decrementIndexByBase(Object index) {
 		if ( baseIndex != 0 ) {
-            index = (Integer)index - baseIndex;
+			index = (Integer)index - baseIndex;
 		}
 		return index;
 	}
 
 	@Override
 	public Object readIdentifier(ResultSet rs, String alias, SessionImplementor session)
 			throws HibernateException, SQLException {
 		Object id = getIdentifierType().nullSafeGet( rs, alias, session, null );
 		if ( id == null ) {
 			throw new HibernateException( "null identifier column for collection: " + role );
 		}
 		return id;
 	}
 
 	@Override
 	public Object readKey(ResultSet rs, String[] aliases, SessionImplementor session)
 			throws HibernateException, SQLException {
 		return getKeyType().nullSafeGet( rs, aliases, session, null );
 	}
 
 	/**
 	 * Write the key to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeKey(PreparedStatement st, Serializable key, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 
 		if ( key == null ) {
 			throw new NullPointerException( "null key for collection: " + role ); // an assertion
 		}
 		getKeyType().nullSafeSet( st, key, i, session );
 		return i + keyColumnAliases.length;
 	}
 
 	/**
 	 * Write the element to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeElement(PreparedStatement st, Object elt, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		getElementType().nullSafeSet( st, elt, i, elementColumnIsSettable, session );
 		return i + ArrayHelper.countTrue( elementColumnIsSettable );
 
 	}
 
 	/**
 	 * Write the index to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeIndex(PreparedStatement st, Object index, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		getIndexType().nullSafeSet( st, incrementIndexByBase( index ), i, indexColumnIsSettable, session );
 		return i + ArrayHelper.countTrue( indexColumnIsSettable );
 	}
 
 	protected Object incrementIndexByBase(Object index) {
 		if ( baseIndex != 0 ) {
-            index = (Integer)index + baseIndex;
+			index = (Integer)index + baseIndex;
 		}
 		return index;
 	}
 
 	/**
 	 * Write the element to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeElementToWhere(PreparedStatement st, Object elt, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		if ( elementIsPureFormula ) {
 			throw new AssertionFailure( "cannot use a formula-based element in the where condition" );
 		}
 		getElementType().nullSafeSet( st, elt, i, elementColumnIsInPrimaryKey, session );
 		return i + elementColumnAliases.length;
 
 	}
 
 	/**
 	 * Write the index to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeIndexToWhere(PreparedStatement st, Object index, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		if ( indexContainsFormula ) {
 			throw new AssertionFailure( "cannot use a formula-based index in the where condition" );
 		}
 		getIndexType().nullSafeSet( st, incrementIndexByBase( index ), i, session );
 		return i + indexColumnAliases.length;
 	}
 
 	/**
 	 * Write the identifier to a JDBC <tt>PreparedStatement</tt>
 	 */
 	public int writeIdentifier(PreparedStatement st, Object id, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 
 		getIdentifierType().nullSafeSet( st, id, i, session );
 		return i + 1;
 	}
 
 	@Override
 	public boolean isPrimitiveArray() {
 		return isPrimitiveArray;
 	}
 
 	@Override
 	public boolean isArray() {
 		return isArray;
 	}
 
 	@Override
 	public String[] getKeyColumnAliases(String suffix) {
 		return new Alias( suffix ).toAliasStrings( keyColumnAliases );
 	}
 
 	@Override
 	public String[] getElementColumnAliases(String suffix) {
 		return new Alias( suffix ).toAliasStrings( elementColumnAliases );
 	}
 
 	@Override
 	public String[] getIndexColumnAliases(String suffix) {
 		if ( hasIndex ) {
 			return new Alias( suffix ).toAliasStrings( indexColumnAliases );
 		}
 		else {
 			return null;
 		}
 	}
 
 	@Override
 	public String getIdentifierColumnAlias(String suffix) {
 		if ( hasIdentifier ) {
 			return new Alias( suffix ).toAliasString( identifierColumnAlias );
 		}
 		else {
 			return null;
 		}
 	}
 
 	@Override
 	public String getIdentifierColumnName() {
 		if ( hasIdentifier ) {
 			return identifierColumnName;
 		}
 		else {
 			return null;
 		}
 	}
 
 	/**
 	 * Generate a list of collection index, key and element columns
 	 */
 	@Override
 	public String selectFragment(String alias, String columnSuffix) {
 		SelectFragment frag = generateSelectFragment( alias, columnSuffix );
 		appendElementColumns( frag, alias );
 		appendIndexColumns( frag, alias );
 		appendIdentifierColumns( frag, alias );
 
 		return frag.toFragmentString()
 				.substring( 2 ); // strip leading ','
 	}
 
 	protected String generateSelectSizeString(boolean isIntegerIndexed) {
 		String selectValue = isIntegerIndexed ?
 				"max(" + getIndexColumnNames()[0] + ") + 1" : // lists, arrays
 				"count(" + getElementColumnNames()[0] + ")"; // sets, maps, bags
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addColumn( selectValue )
 				.toStatementString();
 	}
 
 	protected String generateDetectRowByIndexString() {
 		if ( !hasIndex() ) {
 			return null;
 		}
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getIndexColumnNames(), "=?" )
 				.addCondition( indexFormulas, "=?" )
 				.addColumn( "1" )
 				.toStatementString();
 	}
 
 	protected String generateSelectRowByIndexString() {
 		if ( !hasIndex() ) {
 			return null;
 		}
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getIndexColumnNames(), "=?" )
 				.addCondition( indexFormulas, "=?" )
 				.addColumns( getElementColumnNames(), elementColumnAliases )
 				.addColumns( indexFormulas, indexColumnAliases )
 				.toStatementString();
 	}
 
 	protected String generateDetectRowByElementString() {
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getElementColumnNames(), "=?" )
 				.addCondition( elementFormulas, "=?" )
 				.addColumn( "1" )
 				.toStatementString();
 	}
 
 	protected SelectFragment generateSelectFragment(String alias, String columnSuffix) {
 		return new SelectFragment()
 				.setSuffix( columnSuffix )
 				.addColumns( alias, keyColumnNames, keyColumnAliases );
 	}
 
 	protected void appendElementColumns(SelectFragment frag, String elemAlias) {
 		for ( int i = 0; i < elementColumnIsSettable.length; i++ ) {
 			if ( elementColumnIsSettable[i] ) {
 				frag.addColumnTemplate( elemAlias, elementColumnReaderTemplates[i], elementColumnAliases[i] );
 			}
 			else {
 				frag.addFormula( elemAlias, elementFormulaTemplates[i], elementColumnAliases[i] );
 			}
 		}
 	}
 
 	protected void appendIndexColumns(SelectFragment frag, String alias) {
 		if ( hasIndex ) {
 			for ( int i = 0; i < indexColumnIsSettable.length; i++ ) {
 				if ( indexColumnIsSettable[i] ) {
 					frag.addColumn( alias, indexColumnNames[i], indexColumnAliases[i] );
 				}
 				else {
 					frag.addFormula( alias, indexFormulaTemplates[i], indexColumnAliases[i] );
 				}
 			}
 		}
 	}
 
 	protected void appendIdentifierColumns(SelectFragment frag, String alias) {
 		if ( hasIdentifier ) {
 			frag.addColumn( alias, identifierColumnName, identifierColumnAlias );
 		}
 	}
 
 	@Override
 	public String[] getIndexColumnNames() {
 		return indexColumnNames;
 	}
 
 	@Override
 	public String[] getIndexFormulas() {
 		return indexFormulas;
 	}
 
 	@Override
 	public String[] getIndexColumnNames(String alias) {
 		return qualify( alias, indexColumnNames, indexFormulaTemplates );
 	}
 
 	@Override
 	public String[] getElementColumnNames(String alias) {
 		return qualify( alias, elementColumnNames, elementFormulaTemplates );
 	}
 
 	private static String[] qualify(String alias, String[] columnNames, String[] formulaTemplates) {
 		int span = columnNames.length;
 		String[] result = new String[span];
 		for ( int i = 0; i < span; i++ ) {
 			if ( columnNames[i] == null ) {
 				result[i] = StringHelper.replace( formulaTemplates[i], Template.TEMPLATE, alias );
 			}
 			else {
 				result[i] = StringHelper.qualify( alias, columnNames[i] );
 			}
 		}
 		return result;
 	}
 
 	@Override
 	public String[] getElementColumnNames() {
 		return elementColumnNames; // TODO: something with formulas...
 	}
 
 	@Override
 	public String[] getKeyColumnNames() {
 		return keyColumnNames;
 	}
 
 	@Override
 	public boolean hasIndex() {
 		return hasIndex;
 	}
 
 	@Override
 	public boolean isLazy() {
 		return isLazy;
 	}
 
 	@Override
 	public boolean isInverse() {
 		return isInverse;
 	}
 
 	@Override
 	public String getTableName() {
 		return qualifiedTableName;
 	}
 
 	private BasicBatchKey removeBatchKey;
 
 	@Override
 	public void remove(Serializable id, SessionImplementor session) throws HibernateException {
 		if ( !isInverse && isRowDeleteEnabled() ) {
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Deleting collection: %s",
 						MessageHelper.collectionInfoString( this, id, getFactory() ) );
 			}
 
 			// Remove all the old entries
 
 			try {
 				int offset = 1;
 				PreparedStatement st = null;
 				Expectation expectation = Expectations.appropriateExpectation( getDeleteAllCheckStyle() );
 				boolean callable = isDeleteAllCallable();
 				boolean useBatch = expectation.canBeBatched();
 				String sql = getSQLDeleteString();
 				if ( useBatch ) {
 					if ( removeBatchKey == null ) {
 						removeBatchKey = new BasicBatchKey(
 								getRole() + "#REMOVE",
 								expectation
 								);
 					}
 					st = session
 							.getJdbcCoordinator()
 							.getBatch( removeBatchKey )
 							.getBatchStatement( sql, callable );
 				}
 				else {
 					st = session
 							.getJdbcCoordinator()
 							.getStatementPreparer()
 							.prepareStatement( sql, callable );
 				}
 
 				try {
 					offset += expectation.prepare( st );
 
 					writeKey( st, id, offset, session );
 					if ( useBatch ) {
 						session
 								.getJdbcCoordinator()
 								.getBatch( removeBatchKey )
 								.addToBatch();
 					}
 					else {
 						expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 					}
 				}
 				catch ( SQLException sqle ) {
 					if ( useBatch ) {
 						session.getJdbcCoordinator().abortBatch();
 					}
 					throw sqle;
 				}
 				finally {
 					if ( !useBatch ) {
 						session.getJdbcCoordinator().getResourceRegistry().release( st );
 						session.getJdbcCoordinator().afterStatementExecution();
 					}
 				}
 
 				LOG.debug( "Done deleting collection" );
 			}
 			catch ( SQLException sqle ) {
 				throw sqlExceptionHelper.convert(
 						sqle,
 						"could not delete collection: " +
 								MessageHelper.collectionInfoString( this, id, getFactory() ),
 						getSQLDeleteString()
 						);
 			}
 
 		}
 
 	}
 
 	protected BasicBatchKey recreateBatchKey;
 
 	@Override
 	public void recreate(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( isInverse ) {
 			return;
 		}
 
 		if ( !isRowInsertEnabled() ) {
 			return;
 		}
 
 
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"Inserting collection: %s",
 					MessageHelper.collectionInfoString( this, collection, id, session )
 			);
 		}
 
 		try {
 			// create all the new entries
 			Iterator entries = collection.entries( this );
 			if ( entries.hasNext() ) {
 				Expectation expectation = Expectations.appropriateExpectation( getInsertCheckStyle() );
 				collection.preInsert( this );
 				int i = 0;
 				int count = 0;
 				while ( entries.hasNext() ) {
 
 					final Object entry = entries.next();
 					if ( collection.entryExists( entry, i ) ) {
 						int offset = 1;
 						PreparedStatement st = null;
 						boolean callable = isInsertCallable();
 						boolean useBatch = expectation.canBeBatched();
 						String sql = getSQLInsertRowString();
 
 						if ( useBatch ) {
 							if ( recreateBatchKey == null ) {
 								recreateBatchKey = new BasicBatchKey(
 										getRole() + "#RECREATE",
 										expectation
 								);
 							}
 							st = session
 									.getJdbcCoordinator()
 									.getBatch( recreateBatchKey )
 									.getBatchStatement( sql, callable );
 						}
 						else {
 							st = session
 									.getJdbcCoordinator()
 									.getStatementPreparer()
 									.prepareStatement( sql, callable );
 						}
 
 						try {
 							offset += expectation.prepare( st );
 
 							// TODO: copy/paste from insertRows()
 							int loc = writeKey( st, id, offset, session );
 							if ( hasIdentifier ) {
 								loc = writeIdentifier( st, collection.getIdentifier( entry, i ), loc, session );
 							}
 							if ( hasIndex /* && !indexIsFormula */) {
 								loc = writeIndex( st, collection.getIndex( entry, i, this ), loc, session );
 							}
 							loc = writeElement( st, collection.getElement( entry ), loc, session );
 
 							if ( useBatch ) {
 								session
 										.getJdbcCoordinator()
 										.getBatch( recreateBatchKey )
 										.addToBatch();
 							}
 							else {
 								expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 							}
 
 							collection.afterRowInsert( this, entry, i );
 							count++;
 						}
 						catch ( SQLException sqle ) {
 							if ( useBatch ) {
 								session.getJdbcCoordinator().abortBatch();
 							}
 							throw sqle;
 						}
 						finally {
 							if ( !useBatch ) {
 								session.getJdbcCoordinator().getResourceRegistry().release( st );
 								session.getJdbcCoordinator().afterStatementExecution();
 							}
 						}
 
 					}
 					i++;
 				}
 
 				LOG.debugf( "Done inserting collection: %s rows inserted", count );
 
 			}
 			else {
 				LOG.debug( "Collection was empty" );
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw sqlExceptionHelper.convert(
 					sqle,
 					"could not insert collection: " +
 							MessageHelper.collectionInfoString( this, collection, id, session ),
 					getSQLInsertRowString()
 			);
 		}
 	}
 
 	protected boolean isRowDeleteEnabled() {
 		return true;
 	}
 
 	private BasicBatchKey deleteBatchKey;
 
 	@Override
 	public void deleteRows(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( isInverse ) {
 			return;
 		}
 
 		if ( !isRowDeleteEnabled() ) {
 			return;
 		}
 
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"Deleting rows of collection: %s",
 					MessageHelper.collectionInfoString( this, collection, id, session )
 			);
 		}
 
 		boolean deleteByIndex = !isOneToMany() && hasIndex && !indexContainsFormula;
 		final Expectation expectation = Expectations.appropriateExpectation( getDeleteCheckStyle() );
 		try {
 			// delete all the deleted entries
 			Iterator deletes = collection.getDeletes( this, !deleteByIndex );
 			if ( deletes.hasNext() ) {
 				int offset = 1;
 				int count = 0;
 				while ( deletes.hasNext() ) {
 					PreparedStatement st = null;
 					boolean callable = isDeleteCallable();
 					boolean useBatch = expectation.canBeBatched();
 					String sql = getSQLDeleteRowString();
 
 					if ( useBatch ) {
 						if ( deleteBatchKey == null ) {
 							deleteBatchKey = new BasicBatchKey(
 									getRole() + "#DELETE",
 									expectation
 									);
 						}
 						st = session
 								.getJdbcCoordinator()
 								.getBatch( deleteBatchKey )
 								.getBatchStatement( sql, callable );
 					}
 					else {
 						st = session
 								.getJdbcCoordinator()
 								.getStatementPreparer()
 								.prepareStatement( sql, callable );
 					}
 
 					try {
 						expectation.prepare( st );
 
 						Object entry = deletes.next();
 						int loc = offset;
 						if ( hasIdentifier ) {
 							writeIdentifier( st, entry, loc, session );
 						}
 						else {
 							loc = writeKey( st, id, loc, session );
 							if ( deleteByIndex ) {
 								writeIndexToWhere( st, entry, loc, session );
 							}
 							else {
 								writeElementToWhere( st, entry, loc, session );
 							}
 						}
 
 						if ( useBatch ) {
 							session
 									.getJdbcCoordinator()
 									.getBatch( deleteBatchKey )
 									.addToBatch();
 						}
 						else {
 							expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 						}
 						count++;
 					}
 					catch ( SQLException sqle ) {
 						if ( useBatch ) {
 							session.getJdbcCoordinator().abortBatch();
 						}
 						throw sqle;
 					}
 					finally {
 						if ( !useBatch ) {
 							session.getJdbcCoordinator().getResourceRegistry().release( st );
 							session.getJdbcCoordinator().afterStatementExecution();
 						}
 					}
 
 					LOG.debugf( "Done deleting collection rows: %s deleted", count );
 				}
 			}
 			else {
 				LOG.debug( "No rows to delete" );
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw sqlExceptionHelper.convert(
 					sqle,
 					"could not delete collection rows: " +
 							MessageHelper.collectionInfoString( this, collection, id, session ),
 					getSQLDeleteRowString()
 			);
 		}
 	}
 
 	protected boolean isRowInsertEnabled() {
 		return true;
 	}
 
 	private BasicBatchKey insertBatchKey;
 
 	@Override
 	public void insertRows(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( isInverse ) {
 			return;
 		}
 
 		if ( !isRowInsertEnabled() ) {
 			return;
 		}
 
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"Inserting rows of collection: %s",
 					MessageHelper.collectionInfoString( this, collection, id, session )
 			);
 		}
 
 		try {
 			// insert all the new entries
 			collection.preInsert( this );
 			Iterator entries = collection.entries( this );
 			Expectation expectation = Expectations.appropriateExpectation( getInsertCheckStyle() );
 			boolean callable = isInsertCallable();
 			boolean useBatch = expectation.canBeBatched();
 			String sql = getSQLInsertRowString();
 			int i = 0;
 			int count = 0;
 			while ( entries.hasNext() ) {
 				int offset = 1;
 				Object entry = entries.next();
 				PreparedStatement st = null;
 				if ( collection.needsInserting( entry, i, elementType ) ) {
 
 					if ( useBatch ) {
 						if ( insertBatchKey == null ) {
 							insertBatchKey = new BasicBatchKey(
 									getRole() + "#INSERT",
 									expectation
 									);
 						}
 						if ( st == null ) {
 							st = session
 									.getJdbcCoordinator()
 									.getBatch( insertBatchKey )
 									.getBatchStatement( sql, callable );
 						}
 					}
 					else {
 						st = session
 								.getJdbcCoordinator()
 								.getStatementPreparer()
 								.prepareStatement( sql, callable );
 					}
 
 					try {
 						offset += expectation.prepare( st );
 						// TODO: copy/paste from recreate()
 						offset = writeKey( st, id, offset, session );
 						if ( hasIdentifier ) {
 							offset = writeIdentifier( st, collection.getIdentifier( entry, i ), offset, session );
 						}
 						if ( hasIndex /* && !indexIsFormula */) {
 							offset = writeIndex( st, collection.getIndex( entry, i, this ), offset, session );
 						}
 						writeElement( st, collection.getElement( entry ), offset, session );
 
 						if ( useBatch ) {
 							session.getJdbcCoordinator().getBatch( insertBatchKey ).addToBatch();
 						}
 						else {
 							expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 						}
 						collection.afterRowInsert( this, entry, i );
 						count++;
 					}
 					catch ( SQLException sqle ) {
 						if ( useBatch ) {
 							session.getJdbcCoordinator().abortBatch();
 						}
 						throw sqle;
 					}
 					finally {
 						if ( !useBatch ) {
 							session.getJdbcCoordinator().getResourceRegistry().release( st );
 							session.getJdbcCoordinator().afterStatementExecution();
 						}
 					}
 				}
 				i++;
 			}
 			LOG.debugf( "Done inserting rows: %s inserted", count );
 		}
 		catch ( SQLException sqle ) {
 			throw sqlExceptionHelper.convert(
 					sqle,
 					"could not insert collection rows: " +
 							MessageHelper.collectionInfoString( this, collection, id, session ),
 					getSQLInsertRowString()
 			);
 		}
 	}
 
 	@Override
 	public String getRole() {
 		return role;
 	}
 
 	public String getOwnerEntityName() {
 		return entityName;
 	}
 
 	@Override
 	public EntityPersister getOwnerEntityPersister() {
 		return ownerPersister;
 	}
 
 	@Override
 	public IdentifierGenerator getIdentifierGenerator() {
 		return identifierGenerator;
 	}
 
 	@Override
 	public Type getIdentifierType() {
 		return identifierType;
 	}
 
 	@Override
 	public boolean hasOrphanDelete() {
 		return hasOrphanDelete;
 	}
 
 	@Override
 	public Type toType(String propertyName) throws QueryException {
 		if ( "index".equals( propertyName ) ) {
 			return indexType;
 		}
 		return elementPropertyMapping.toType( propertyName );
 	}
 
 	@Override
 	public abstract boolean isManyToMany();
 
 	@Override
 	public String getManyToManyFilterFragment(String alias, Map enabledFilters) {
 		StringBuilder buffer = new StringBuilder();
 		manyToManyFilterHelper.render( buffer, elementPersister.getFilterAliasGenerator(alias), enabledFilters );
 
 		if ( manyToManyWhereString != null ) {
 			buffer.append( " and " )
 					.append( StringHelper.replace( manyToManyWhereTemplate, Template.TEMPLATE, alias ) );
 		}
 
 		return buffer.toString();
 	}
 
 	@Override
 	public String[] toColumns(String alias, String propertyName) throws QueryException {
 		if ( "index".equals( propertyName ) ) {
 			return qualify( alias, indexColumnNames, indexFormulaTemplates );
 		}
 		return elementPropertyMapping.toColumns( alias, propertyName );
 	}
 
 	private String[] indexFragments;
 
 	@Override
 	public String[] toColumns(String propertyName) throws QueryException {
 		if ( "index".equals( propertyName ) ) {
 			if ( indexFragments == null ) {
 				String[] tmp = new String[indexColumnNames.length];
 				for ( int i = 0; i < indexColumnNames.length; i++ ) {
 					tmp[i] = indexColumnNames[i] == null
 							? indexFormulas[i]
 							: indexColumnNames[i];
 					indexFragments = tmp;
 				}
 			}
 			return indexFragments;
 		}
 
 		return elementPropertyMapping.toColumns( propertyName );
 	}
 
 	@Override
 	public Type getType() {
 		return elementPropertyMapping.getType(); // ==elementType ??
 	}
 
 	@Override
 	public String getName() {
 		return getRole();
 	}
 
 	@Override
 	public EntityPersister getElementPersister() {
 		if ( elementPersister == null ) {
 			throw new AssertionFailure( "not an association" );
 		}
 		return elementPersister;
 	}
 
 	@Override
 	public boolean isCollection() {
 		return true;
 	}
 
 	@Override
 	public Serializable[] getCollectionSpaces() {
 		return spaces;
 	}
 
 	protected abstract String generateDeleteString();
 
 	protected abstract String generateDeleteRowString();
 
 	protected abstract String generateUpdateRowString();
 
 	protected abstract String generateInsertRowString();
 
 	@Override
 	public void updateRows(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( !isInverse && collection.isRowUpdatePossible() ) {
 
 			LOG.debugf( "Updating rows of collection: %s#%s", role, id );
 
 			// update all the modified entries
 			int count = doUpdateRows( id, collection, session );
 
 			LOG.debugf( "Done updating rows: %s updated", count );
 		}
 	}
 
 	protected abstract int doUpdateRows(Serializable key, PersistentCollection collection, SessionImplementor session)
 			throws HibernateException;
 
 	@Override
 	public void processQueuedOps(PersistentCollection collection, Serializable key, SessionImplementor session)
 			throws HibernateException {
 		if ( collection.hasQueuedOperations() ) {
 			doProcessQueuedOps( collection, key, session );
 		}
 	}
 
 	/**
 	 * Process queued operations within the PersistentCollection.
 	 *
 	 * @param collection The collection
 	 * @param key The collection key
 	 * @param nextIndex The next index to write
 	 * @param session The session
 	 * @throws HibernateException
 	 *
 	 * @deprecated Use {@link #doProcessQueuedOps(org.hibernate.collection.spi.PersistentCollection, java.io.Serializable, org.hibernate.engine.spi.SessionImplementor)}
 	 */
 	@Deprecated
 	protected void doProcessQueuedOps(PersistentCollection collection, Serializable key,
 			int nextIndex, SessionImplementor session)
 			throws HibernateException {
 		doProcessQueuedOps( collection, key, session );
 	}
 
 	protected abstract void doProcessQueuedOps(PersistentCollection collection, Serializable key, SessionImplementor session)
 			throws HibernateException;
 
 	@Override
 	public CollectionMetadata getCollectionMetadata() {
 		return this;
 	}
 
 	@Override
 	public SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	protected String filterFragment(String alias) throws MappingException {
 		return hasWhere() ? " and " + getSQLWhereString( alias ) : "";
 	}
 
 	protected String filterFragment(String alias, Set<String> treatAsDeclarations) throws MappingException {
 		return hasWhere() ? " and " + getSQLWhereString( alias ) : "";
 	}
 
 	@Override
 	public String filterFragment(String alias, Map enabledFilters) throws MappingException {
 		StringBuilder sessionFilterFragment = new StringBuilder();
 		filterHelper.render( sessionFilterFragment, getFilterAliasGenerator(alias), enabledFilters );
 
 		return sessionFilterFragment.append( filterFragment( alias ) ).toString();
 	}
 
 	@Override
 	public String filterFragment(
 			String alias,
 			Map enabledFilters,
 			Set<String> treatAsDeclarations) {
 		StringBuilder sessionFilterFragment = new StringBuilder();
 		filterHelper.render( sessionFilterFragment, getFilterAliasGenerator(alias), enabledFilters );
 
 		return sessionFilterFragment.append( filterFragment( alias, treatAsDeclarations ) ).toString();
 	}
 
 	@Override
 	public String oneToManyFilterFragment(String alias) throws MappingException {
 		return "";
 	}
 
 	@Override
 	public String oneToManyFilterFragment(String alias, Set<String> treatAsDeclarations) {
 		return oneToManyFilterFragment( alias );
 	}
 
 	protected boolean isInsertCallable() {
 		return insertCallable;
 	}
 
 	protected ExecuteUpdateResultCheckStyle getInsertCheckStyle() {
 		return insertCheckStyle;
 	}
 
 	protected boolean isUpdateCallable() {
 		return updateCallable;
 	}
 
 	protected ExecuteUpdateResultCheckStyle getUpdateCheckStyle() {
 		return updateCheckStyle;
 	}
 
 	protected boolean isDeleteCallable() {
 		return deleteCallable;
 	}
 
 	protected ExecuteUpdateResultCheckStyle getDeleteCheckStyle() {
 		return deleteCheckStyle;
 	}
 
 	protected boolean isDeleteAllCallable() {
 		return deleteAllCallable;
 	}
 
 	protected ExecuteUpdateResultCheckStyle getDeleteAllCheckStyle() {
 		return deleteAllCheckStyle;
 	}
 
 	@Override
 	public String toString() {
 		return StringHelper.unqualify( getClass().getName() ) + '(' + role + ')';
 	}
 
 	@Override
 	public boolean isVersioned() {
 		return isVersioned && getOwnerEntityPersister().isVersioned();
 	}
 
 	@Override
 	public String getNodeName() {
 		return nodeName;
 	}
 
 	@Override
 	public String getElementNodeName() {
 		return elementNodeName;
 	}
 
 	@Override
 	public String getIndexNodeName() {
 		return indexNodeName;
 	}
 
 	// TODO: deprecate???
 	protected SQLExceptionConverter getSQLExceptionConverter() {
 		return getSQLExceptionHelper().getSqlExceptionConverter();
 	}
 
 	// TODO: needed???
 	protected SqlExceptionHelper getSQLExceptionHelper() {
 		return sqlExceptionHelper;
 	}
 
 	@Override
 	public CacheEntryStructure getCacheEntryStructure() {
 		return cacheEntryStructure;
 	}
 
 	@Override
 	public boolean isAffectedByEnabledFilters(SessionImplementor session) {
 		return filterHelper.isAffectedBy( session.getLoadQueryInfluencers().getEnabledFilters() ) ||
 				( isManyToMany() && manyToManyFilterHelper.isAffectedBy( session.getLoadQueryInfluencers().getEnabledFilters() ) );
 	}
 
 	public boolean isSubselectLoadable() {
 		return subselectLoadable;
 	}
 
 	@Override
 	public boolean isMutable() {
 		return isMutable;
 	}
 
 	@Override
 	public String[] getCollectionPropertyColumnAliases(String propertyName, String suffix) {
 		String[] rawAliases = (String[]) collectionPropertyColumnAliases.get( propertyName );
 
 		if ( rawAliases == null ) {
 			return null;
 		}
 
 		String[] result = new String[rawAliases.length];
 		for ( int i = 0; i < rawAliases.length; i++ ) {
 			result[i] = new Alias( suffix ).toUnquotedAliasString( rawAliases[i] );
 		}
 		return result;
 	}
 
 	// TODO: formulas ?
 	public void initCollectionPropertyMap() {
 
 		initCollectionPropertyMap( "key", keyType, keyColumnAliases, keyColumnNames );
 		initCollectionPropertyMap( "element", elementType, elementColumnAliases, elementColumnNames );
 		if ( hasIndex ) {
 			initCollectionPropertyMap( "index", indexType, indexColumnAliases, indexColumnNames );
 		}
 		if ( hasIdentifier ) {
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/BasicCollectionPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/BasicCollectionPersister.java
index d8332ebe97..6d3cda57ec 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/BasicCollectionPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/BasicCollectionPersister.java
@@ -1,382 +1,400 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.collection;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Iterator;
 import java.util.Set;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.SubselectFetch;
 import org.hibernate.internal.FilterAliasGenerator;
 import org.hibernate.internal.StaticFilterAliasGenerator;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.loader.collection.BatchingCollectionInitializerBuilder;
 import org.hibernate.loader.collection.CollectionInitializer;
 import org.hibernate.loader.collection.SubselectCollectionLoader;
 import org.hibernate.mapping.Collection;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Delete;
 import org.hibernate.sql.Insert;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.Update;
 import org.hibernate.type.AssociationType;
 
 /**
  * Collection persister for collections of values and many-to-many associations.
  *
  * @author Gavin King
  */
 public class BasicCollectionPersister extends AbstractCollectionPersister {
 
 	public boolean isCascadeDeleteEnabled() {
 		return false;
 	}
 
 	public BasicCollectionPersister(
 			Collection collectionBinding,
 			CollectionRegionAccessStrategy cacheAccessStrategy,
 			PersisterCreationContext creationContext) throws MappingException, CacheException {
 		super( collectionBinding, cacheAccessStrategy, creationContext );
 	}
 
 	/**
 	 * Generate the SQL DELETE that deletes all rows
 	 */
 	@Override
-    protected String generateDeleteString() {
+	protected String generateDeleteString() {
 		final Delete delete = new Delete()
 				.setTableName( qualifiedTableName )
 				.addPrimaryKeyColumns( keyColumnNames );
-		
+
 		if ( hasWhere ) {
 			delete.setWhere( sqlWhereString );
 		}
-		
+
 		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			delete.setComment( "delete collection " + getRole() );
 		}
-		
+
 		return delete.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL INSERT that creates a new row
 	 */
 	@Override
-    protected String generateInsertRowString() {
+	protected String generateInsertRowString() {
 		final Insert insert = new Insert( getDialect() )
 				.setTableName( qualifiedTableName )
 				.addColumns( keyColumnNames );
-		
-		if ( hasIdentifier) {
+
+		if ( hasIdentifier ) {
 			insert.addColumn( identifierColumnName );
 		}
-		
+
 		if ( hasIndex /*&& !indexIsFormula*/ ) {
 			insert.addColumns( indexColumnNames, indexColumnIsSettable );
 		}
-		
+
 		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			insert.setComment( "insert collection row " + getRole() );
 		}
-		
+
 		//if ( !elementIsFormula ) {
-			insert.addColumns( elementColumnNames, elementColumnIsSettable, elementColumnWriters );
+		insert.addColumns( elementColumnNames, elementColumnIsSettable, elementColumnWriters );
 		//}
-		
+
 		return insert.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that updates a row
 	 */
 	@Override
-    protected String generateUpdateRowString() {
+	protected String generateUpdateRowString() {
 		final Update update = new Update( getDialect() )
-			.setTableName( qualifiedTableName );
-		
+				.setTableName( qualifiedTableName );
+
 		//if ( !elementIsFormula ) {
-			update.addColumns( elementColumnNames, elementColumnIsSettable, elementColumnWriters );
+		update.addColumns( elementColumnNames, elementColumnIsSettable, elementColumnWriters );
 		//}
-		
+
 		if ( hasIdentifier ) {
-			update.addPrimaryKeyColumns( new String[]{ identifierColumnName } );
+			update.addPrimaryKeyColumns( new String[] {identifierColumnName} );
 		}
 		else if ( hasIndex && !indexContainsFormula ) {
 			update.addPrimaryKeyColumns( ArrayHelper.join( keyColumnNames, indexColumnNames ) );
 		}
 		else {
 			update.addPrimaryKeyColumns( keyColumnNames );
 			update.addPrimaryKeyColumns( elementColumnNames, elementColumnIsInPrimaryKey, elementColumnWriters );
 		}
-		
+
 		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			update.setComment( "update collection row " + getRole() );
 		}
-		
+
 		return update.toStatementString();
 	}
-	
+
 	@Override
 	protected void doProcessQueuedOps(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 		// nothing to do
 	}
 
 	/**
 	 * Generate the SQL DELETE that deletes a particular row
 	 */
 	@Override
-    protected String generateDeleteRowString() {
+	protected String generateDeleteRowString() {
 		final Delete delete = new Delete().setTableName( qualifiedTableName );
-		
+
 		if ( hasIdentifier ) {
-			delete.addPrimaryKeyColumns( new String[]{ identifierColumnName } );
+			delete.addPrimaryKeyColumns( new String[] {identifierColumnName} );
 		}
 		else if ( hasIndex && !indexContainsFormula ) {
 			delete.addPrimaryKeyColumns( ArrayHelper.join( keyColumnNames, indexColumnNames ) );
 		}
 		else {
 			delete.addPrimaryKeyColumns( keyColumnNames );
 			delete.addPrimaryKeyColumns( elementColumnNames, elementColumnIsInPrimaryKey, elementColumnWriters );
 		}
-		
+
 		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			delete.setComment( "delete collection row " + getRole() );
 		}
-		
+
 		return delete.toStatementString();
 	}
 
 	public boolean consumesEntityAlias() {
 		return false;
 	}
 
 	public boolean consumesCollectionAlias() {
 //		return !isOneToMany();
 		return true;
 	}
 
 	public boolean isOneToMany() {
 		return false;
 	}
 
 	@Override
-    public boolean isManyToMany() {
+	public boolean isManyToMany() {
 		return elementType.isEntityType(); //instanceof AssociationType;
 	}
 
 	private BasicBatchKey updateBatchKey;
 
 	@Override
-    protected int doUpdateRows(Serializable id, PersistentCollection collection, SessionImplementor session) throws HibernateException {
-		if ( ArrayHelper.isAllFalse(elementColumnIsSettable) ) {
+	protected int doUpdateRows(Serializable id, PersistentCollection collection, SessionImplementor session)
+			throws HibernateException {
+		if ( ArrayHelper.isAllFalse( elementColumnIsSettable ) ) {
 			return 0;
 		}
 
 		try {
 			PreparedStatement st = null;
 			Expectation expectation = Expectations.appropriateExpectation( getUpdateCheckStyle() );
 			boolean callable = isUpdateCallable();
 			boolean useBatch = expectation.canBeBatched();
 			Iterator entries = collection.entries( this );
 			String sql = getSQLUpdateRowString();
 			int i = 0;
 			int count = 0;
 			while ( entries.hasNext() ) {
 				Object entry = entries.next();
 				if ( collection.needsUpdating( entry, i, elementType ) ) {
 					int offset = 1;
 
 					if ( useBatch ) {
 						if ( updateBatchKey == null ) {
 							updateBatchKey = new BasicBatchKey(
 									getRole() + "#UPDATE",
 									expectation
 							);
 						}
 						st = session
 								.getJdbcCoordinator()
 								.getBatch( updateBatchKey )
 								.getBatchStatement( sql, callable );
 					}
 					else {
 						st = session
 								.getJdbcCoordinator()
 								.getStatementPreparer()
 								.prepareStatement( sql, callable );
 					}
 
 					try {
-						offset+= expectation.prepare( st );
+						offset += expectation.prepare( st );
 						int loc = writeElement( st, collection.getElement( entry ), offset, session );
 						if ( hasIdentifier ) {
 							writeIdentifier( st, collection.getIdentifier( entry, i ), loc, session );
 						}
 						else {
 							loc = writeKey( st, id, loc, session );
 							if ( hasIndex && !indexContainsFormula ) {
 								writeIndexToWhere( st, collection.getIndex( entry, i, this ), loc, session );
 							}
 							else {
 								writeElementToWhere( st, collection.getSnapshotElement( entry, i ), loc, session );
 							}
 						}
 
 						if ( useBatch ) {
 							session.getJdbcCoordinator()
 									.getBatch( updateBatchKey )
 									.addToBatch();
 						}
 						else {
-							expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
+							expectation.verifyOutcome(
+									session.getJdbcCoordinator().getResultSetReturn().executeUpdate(
+											st
+									), st, -1
+							);
 						}
 					}
-					catch ( SQLException sqle ) {
+					catch (SQLException sqle) {
 						if ( useBatch ) {
 							session.getJdbcCoordinator().abortBatch();
 						}
 						throw sqle;
 					}
 					finally {
 						if ( !useBatch ) {
 							session.getJdbcCoordinator().getResourceRegistry().release( st );
 							session.getJdbcCoordinator().afterStatementExecution();
 						}
 					}
 					count++;
 				}
 				i++;
 			}
 			return count;
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw getSQLExceptionHelper().convert(
 					sqle,
-					"could not update collection rows: " + MessageHelper.collectionInfoString( this, collection, id, session ),
+					"could not update collection rows: " + MessageHelper.collectionInfoString(
+							this,
+							collection,
+							id,
+							session
+					),
 					getSQLUpdateRowString()
 			);
 		}
 	}
 
 	public String selectFragment(
-	        Joinable rhs,
-	        String rhsAlias,
-	        String lhsAlias,
-	        String entitySuffix,
-	        String collectionSuffix,
-	        boolean includeCollectionColumns) {
+			Joinable rhs,
+			String rhsAlias,
+			String lhsAlias,
+			String entitySuffix,
+			String collectionSuffix,
+			boolean includeCollectionColumns) {
 		// we need to determine the best way to know that two joinables
 		// represent a single many-to-many...
 		if ( rhs != null && isManyToMany() && !rhs.isCollection() ) {
-			AssociationType elementType = ( ( AssociationType ) getElementType() );
+			AssociationType elementType = ( (AssociationType) getElementType() );
 			if ( rhs.equals( elementType.getAssociatedJoinable( getFactory() ) ) ) {
 				return manyToManySelectFragment( rhs, rhsAlias, lhsAlias, collectionSuffix );
 			}
 		}
 		return includeCollectionColumns ? selectFragment( lhsAlias, collectionSuffix ) : "";
 	}
 
 	private String manyToManySelectFragment(
-	        Joinable rhs,
-	        String rhsAlias,
-	        String lhsAlias,
-	        String collectionSuffix) {
+			Joinable rhs,
+			String rhsAlias,
+			String lhsAlias,
+			String collectionSuffix) {
 		SelectFragment frag = generateSelectFragment( lhsAlias, collectionSuffix );
 
 		String[] elementColumnNames = rhs.getKeyColumnNames();
 		frag.addColumns( rhsAlias, elementColumnNames, elementColumnAliases );
 		appendIndexColumns( frag, lhsAlias );
 		appendIdentifierColumns( frag, lhsAlias );
 
 		return frag.toFragmentString()
 				.substring( 2 ); //strip leading ','
 	}
 
 	/**
 	 * Create the <tt>CollectionLoader</tt>
 	 *
 	 * @see org.hibernate.loader.collection.BasicCollectionLoader
 	 */
 	@Override
-    protected CollectionInitializer createCollectionInitializer(LoadQueryInfluencers loadQueryInfluencers)
+	protected CollectionInitializer createCollectionInitializer(LoadQueryInfluencers loadQueryInfluencers)
 			throws MappingException {
 		return BatchingCollectionInitializerBuilder.getBuilder( getFactory() )
 				.createBatchingCollectionInitializer( this, batchSize, getFactory(), loadQueryInfluencers );
 	}
 
 	@Override
 	public String fromJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		return "";
 	}
 
 	@Override
-	public String fromJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses, Set<String> treatAsDeclarations) {
+	public String fromJoinFragment(
+			String alias,
+			boolean innerJoin,
+			boolean includeSubclasses,
+			Set<String> treatAsDeclarations) {
 		return "";
 	}
 
 	@Override
 	public String whereJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		return "";
 	}
 
 	@Override
-	public String whereJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses, Set<String> treatAsDeclarations) {
+	public String whereJoinFragment(
+			String alias,
+			boolean innerJoin,
+			boolean includeSubclasses,
+			Set<String> treatAsDeclarations) {
 		return "";
 	}
 
 	@Override
-    protected CollectionInitializer createSubselectInitializer(SubselectFetch subselect, SessionImplementor session) {
-		return new SubselectCollectionLoader( 
+	protected CollectionInitializer createSubselectInitializer(SubselectFetch subselect, SessionImplementor session) {
+		return new SubselectCollectionLoader(
 				this,
 				subselect.toSubselectString( getCollectionType().getLHSPropertyName() ),
 				subselect.getResult(),
 				subselect.getQueryParameters(),
 				subselect.getNamedParameterLocMap(),
 				session.getFactory(),
-				session.getLoadQueryInfluencers() 
+				session.getLoadQueryInfluencers()
 		);
 	}
 
 	@Override
 	public FilterAliasGenerator getFilterAliasGenerator(String rootAlias) {
-		return new StaticFilterAliasGenerator(rootAlias);
+		return new StaticFilterAliasGenerator( rootAlias );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/CollectionPropertyMapping.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/CollectionPropertyMapping.java
index 884ad24f5b..68faa32a59 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/CollectionPropertyMapping.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/CollectionPropertyMapping.java
@@ -1,136 +1,138 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.collection;
 
 import org.hibernate.QueryException;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.Type;
 
 /**
  * @author Gavin King
  */
 public class CollectionPropertyMapping implements PropertyMapping {
 	private final QueryableCollection memberPersister;
 
 	public CollectionPropertyMapping(QueryableCollection memberPersister) {
 		this.memberPersister = memberPersister;
 	}
 
 	public Type toType(String propertyName) throws QueryException {
 		if ( propertyName.equals(CollectionPropertyNames.COLLECTION_ELEMENTS) ) {
 			return memberPersister.getElementType();
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_INDICES) ) {
-			if ( !memberPersister.hasIndex() ) throw new QueryException("unindexed collection before indices()");
+			if ( !memberPersister.hasIndex() ) {
+				throw new QueryException("unindexed collection before indices()");
+			}
 			return memberPersister.getIndexType();
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_SIZE) ) {
 			return StandardBasicTypes.INTEGER;
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_MAX_INDEX) ) {
 			return memberPersister.getIndexType();
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_MIN_INDEX) ) {
 			return memberPersister.getIndexType();
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_MAX_ELEMENT) ) {
 			return memberPersister.getElementType();
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_MIN_ELEMENT) ) {
 			return memberPersister.getElementType();
 		}
 		else {
 			//return memberPersister.getPropertyType(propertyName);
 			throw new QueryException("illegal syntax near collection: " + propertyName);
 		}
 	}
 
 	public String[] toColumns(String alias, String propertyName) throws QueryException {
 		if ( propertyName.equals(CollectionPropertyNames.COLLECTION_ELEMENTS) ) {
 			return memberPersister.getElementColumnNames(alias);
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_INDICES) ) {
 			if ( !memberPersister.hasIndex() ) {
 				throw new QueryException("unindexed collection in indices()");
 			}
 			return memberPersister.getIndexColumnNames(alias);
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_SIZE) ) {
 			String[] cols = memberPersister.getKeyColumnNames();
 			return new String[] { "count(" + alias + '.' + cols[0] + ')' };
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_MAX_INDEX) ) {
 			if ( !memberPersister.hasIndex() ) {
 				throw new QueryException("unindexed collection in maxIndex()");
 			}
 			String[] cols = memberPersister.getIndexColumnNames(alias);
 			if ( cols.length!=1 ) {
 				throw new QueryException("composite collection index in maxIndex()");
 			}
 			return new String[] { "max(" + cols[0] + ')' };
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_MIN_INDEX) ) {
 			if ( !memberPersister.hasIndex() ) {
 				throw new QueryException("unindexed collection in minIndex()");
 			}
 			String[] cols = memberPersister.getIndexColumnNames(alias);
 			if ( cols.length!=1 ) {
 				throw new QueryException("composite collection index in minIndex()");
 			}
 			return new String[] { "min(" + cols[0] + ')' };
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_MAX_ELEMENT) ) {
 			String[] cols = memberPersister.getElementColumnNames(alias);
 			if ( cols.length!=1 ) {
 				throw new QueryException("composite collection element in maxElement()");
 			}
 			return new String[] { "max(" + cols[0] + ')' };
 		}
 		else if ( propertyName.equals(CollectionPropertyNames.COLLECTION_MIN_ELEMENT) ) {
 			String[] cols = memberPersister.getElementColumnNames(alias);
 			if ( cols.length!=1 ) {
 				throw new QueryException("composite collection element in minElement()");
 			}
 			return new String[] { "min(" + cols[0] + ')' };
 		}
 		else {
 			//return memberPersister.toColumns(alias, propertyName);
 			throw new QueryException("illegal syntax near collection: " + propertyName);
 		}
 	}
 
 	/**
 	 * Given a property path, return the corresponding column name(s).
 	 */
 	public String[] toColumns(String propertyName) throws QueryException, UnsupportedOperationException {
 		throw new UnsupportedOperationException( "References to collections must be define a SQL alias" );
 	}
 
 	public Type getType() {
 		//return memberPersister.getType();
 		return memberPersister.getCollectionType();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/NamedQueryCollectionInitializer.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/NamedQueryCollectionInitializer.java
index 05cc9963f0..444bd42b31 100755
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/NamedQueryCollectionInitializer.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/NamedQueryCollectionInitializer.java
@@ -1,78 +1,72 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.collection;
 
 import java.io.Serializable;
 
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.AbstractQueryImpl;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.loader.collection.CollectionInitializer;
 
-import org.jboss.logging.Logger;
-
 /**
  * A wrapper around a named query.
+ *
  * @author Gavin King
  */
 public final class NamedQueryCollectionInitializer implements CollectionInitializer {
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( NamedQueryCollectionInitializer.class );
 
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
-                                                                       NamedQueryCollectionInitializer.class.getName());
-
-    private final String queryName;
+	private final String queryName;
 	private final CollectionPersister persister;
 
 	public NamedQueryCollectionInitializer(String queryName, CollectionPersister persister) {
 		super();
 		this.queryName = queryName;
 		this.persister = persister;
 	}
 
-	public void initialize(Serializable key, SessionImplementor session)
-	throws HibernateException {
-
-        LOG.debugf("Initializing collection: %s using named query: %s", persister.getRole(), queryName);
+	public void initialize(Serializable key, SessionImplementor session) throws HibernateException {
+		LOG.debugf( "Initializing collection: %s using named query: %s", persister.getRole(), queryName );
 
 		//TODO: is there a more elegant way than downcasting?
-		AbstractQueryImpl query = (AbstractQueryImpl) session.getNamedSQLQuery(queryName);
-		if ( query.getNamedParameters().length>0 ) {
+		AbstractQueryImpl query = (AbstractQueryImpl) session.getNamedSQLQuery( queryName );
+		if ( query.getNamedParameters().length > 0 ) {
 			query.setParameter(
 					query.getNamedParameters()[0],
 					key,
 					persister.getKeyType()
-				);
+			);
 		}
 		else {
 			query.setParameter( 0, key, persister.getKeyType() );
 		}
-		query.setCollectionKey( key )
-				.setFlushMode( FlushMode.MANUAL )
-				.list();
 
+		query.setCollectionKey( key ).setFlushMode( FlushMode.MANUAL ).list();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/OneToManyPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/OneToManyPersister.java
index f45f2abf0f..52a95d4587 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/OneToManyPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/OneToManyPersister.java
@@ -1,567 +1,604 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.collection;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Iterator;
 import java.util.Set;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.SubselectFetch;
 import org.hibernate.internal.FilterAliasGenerator;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.loader.collection.BatchingCollectionInitializerBuilder;
 import org.hibernate.loader.collection.CollectionInitializer;
 import org.hibernate.loader.collection.SubselectOneToManyLoader;
 import org.hibernate.loader.entity.CollectionElementLoader;
 import org.hibernate.mapping.Collection;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Update;
 
 /**
  * Collection persister for one-to-many associations.
  *
  * @author Gavin King
  * @author Brett Meyer
  */
 public class OneToManyPersister extends AbstractCollectionPersister {
 
 	private final boolean cascadeDeleteEnabled;
 	private final boolean keyIsNullable;
 	private final boolean keyIsUpdateable;
 
 	@Override
-    protected boolean isRowDeleteEnabled() {
+	protected boolean isRowDeleteEnabled() {
 		return keyIsUpdateable && keyIsNullable;
 	}
 
 	@Override
-    protected boolean isRowInsertEnabled() {
+	protected boolean isRowInsertEnabled() {
 		return keyIsUpdateable;
 	}
 
 	public boolean isCascadeDeleteEnabled() {
 		return cascadeDeleteEnabled;
 	}
 
 	public OneToManyPersister(
 			Collection collectionBinding,
 			CollectionRegionAccessStrategy cacheAccessStrategy,
 			PersisterCreationContext creationContext) throws MappingException, CacheException {
 		super( collectionBinding, cacheAccessStrategy, creationContext );
 		cascadeDeleteEnabled = collectionBinding.getKey().isCascadeDeleteEnabled()
 				&& creationContext.getSessionFactory().getDialect().supportsCascadeDelete();
 		keyIsNullable = collectionBinding.getKey().isNullable();
 		keyIsUpdateable = collectionBinding.getKey().isUpdateable();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that updates all the foreign keys to null
 	 */
 	@Override
-    protected String generateDeleteString() {
+	protected String generateDeleteString() {
 		final Update update = new Update( getDialect() )
 				.setTableName( qualifiedTableName )
 				.addColumns( keyColumnNames, "null" )
 				.addPrimaryKeyColumns( keyColumnNames );
-		
+
 		if ( hasIndex && !indexContainsFormula ) {
 			update.addColumns( indexColumnNames, "null" );
 		}
-		
+
 		if ( hasWhere ) {
 			update.setWhere( sqlWhereString );
 		}
-		
+
 		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			update.setComment( "delete one-to-many " + getRole() );
 		}
-		
+
 		return update.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that updates a foreign key to a value
 	 */
 	@Override
-    protected String generateInsertRowString() {
+	protected String generateInsertRowString() {
 		final Update update = new Update( getDialect() )
 				.setTableName( qualifiedTableName )
 				.addColumns( keyColumnNames );
-		
+
 		if ( hasIndex && !indexContainsFormula ) {
 			update.addColumns( indexColumnNames );
 		}
-		
+
 		//identifier collections not supported for 1-to-many
 
 		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			update.setComment( "create one-to-many row " + getRole() );
 		}
-		
+
 		return update.addPrimaryKeyColumns( elementColumnNames, elementColumnWriters )
 				.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that inserts a collection index
 	 */
 	@Override
-    protected String generateUpdateRowString() {
+	protected String generateUpdateRowString() {
 		final Update update = new Update( getDialect() ).setTableName( qualifiedTableName );
 		update.addPrimaryKeyColumns( elementColumnNames, elementColumnIsSettable, elementColumnWriters );
 		if ( hasIdentifier ) {
-			update.addPrimaryKeyColumns( new String[]{ identifierColumnName } );
+			update.addPrimaryKeyColumns( new String[] {identifierColumnName} );
 		}
 		if ( hasIndex && !indexContainsFormula ) {
 			update.addColumns( indexColumnNames );
 		}
-		
+
 		return update.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that updates a particular row's foreign
 	 * key to null
 	 */
 	@Override
-    protected String generateDeleteRowString() {
+	protected String generateDeleteRowString() {
 		final Update update = new Update( getDialect() )
 				.setTableName( qualifiedTableName )
 				.addColumns( keyColumnNames, "null" );
-		
+
 		if ( hasIndex && !indexContainsFormula ) {
 			update.addColumns( indexColumnNames, "null" );
 		}
-		
+
 		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			update.setComment( "delete one-to-many row " + getRole() );
 		}
-		
+
 		//use a combination of foreign key columns and pk columns, since
 		//the ordering of removal and addition is not guaranteed when
 		//a child moves from one parent to another
 		String[] rowSelectColumnNames = ArrayHelper.join( keyColumnNames, elementColumnNames );
 		return update.addPrimaryKeyColumns( rowSelectColumnNames )
 				.toStatementString();
 	}
-	
+
 	@Override
 	public void recreate(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 		super.recreate( collection, id, session );
 		writeIndex( collection, collection.entries( this ), id, true, session );
 	}
-	
+
 	@Override
 	public void insertRows(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 		super.insertRows( collection, id, session );
 		writeIndex( collection, collection.entries( this ), id, true, session );
 	}
-	
+
 	@Override
 	protected void doProcessQueuedOps(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 		writeIndex( collection, collection.queuedAdditionIterator(), id, false, session );
 	}
 
 	private void writeIndex(
 			PersistentCollection collection,
 			Iterator entries,
 			Serializable id,
 			boolean resetIndex,
 			SessionImplementor session) {
 		// If one-to-many and inverse, still need to create the index.  See HHH-5732.
 		if ( isInverse && hasIndex && !indexContainsFormula ) {
 			try {
 				if ( entries.hasNext() ) {
 					int nextIndex = resetIndex ? 0 : getSize( id, session );
 					Expectation expectation = Expectations.appropriateExpectation( getUpdateCheckStyle() );
 					while ( entries.hasNext() ) {
 
 						final Object entry = entries.next();
 						if ( entry != null && collection.entryExists( entry, nextIndex ) ) {
 							int offset = 1;
 							PreparedStatement st = null;
 							boolean callable = isUpdateCallable();
 							boolean useBatch = expectation.canBeBatched();
 							String sql = getSQLUpdateRowString();
 
 							if ( useBatch ) {
 								if ( recreateBatchKey == null ) {
 									recreateBatchKey = new BasicBatchKey(
 											getRole() + "#RECREATE",
 											expectation
-											);
+									);
 								}
 								st = session
 										.getJdbcCoordinator()
 										.getBatch( recreateBatchKey )
 										.getBatchStatement( sql, callable );
 							}
 							else {
 								st = session
 										.getJdbcCoordinator()
 										.getStatementPreparer()
 										.prepareStatement( sql, callable );
 							}
 
 							try {
 								offset += expectation.prepare( st );
 								if ( hasIdentifier ) {
-									offset = writeIdentifier( st, collection.getIdentifier( entry, nextIndex ), offset, session );
+									offset = writeIdentifier(
+											st,
+											collection.getIdentifier( entry, nextIndex ),
+											offset,
+											session
+									);
 								}
-								offset = writeIndex( st, collection.getIndex( entry, nextIndex, this ), offset, session );
+								offset = writeIndex(
+										st,
+										collection.getIndex( entry, nextIndex, this ),
+										offset,
+										session
+								);
 								offset = writeElement( st, collection.getElement( entry ), offset, session );
 
 								if ( useBatch ) {
 									session.getJdbcCoordinator()
 											.getBatch( recreateBatchKey )
 											.addToBatch();
 								}
 								else {
-									expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
+									expectation.verifyOutcome(
+											session.getJdbcCoordinator()
+													.getResultSetReturn()
+													.executeUpdate( st ), st, -1
+									);
 								}
 							}
-							catch ( SQLException sqle ) {
+							catch (SQLException sqle) {
 								if ( useBatch ) {
 									session.getJdbcCoordinator().abortBatch();
 								}
 								throw sqle;
 							}
 							finally {
 								if ( !useBatch ) {
 									session.getJdbcCoordinator().getResourceRegistry().release( st );
 									session.getJdbcCoordinator().afterStatementExecution();
 								}
 							}
 
 						}
 						nextIndex++;
 					}
 				}
 			}
-			catch ( SQLException sqle ) {
+			catch (SQLException sqle) {
 				throw sqlExceptionHelper.convert(
 						sqle,
 						"could not update collection: " +
 								MessageHelper.collectionInfoString( this, collection, id, session ),
 						getSQLUpdateRowString()
 				);
 			}
 		}
 	}
 
 	public boolean consumesEntityAlias() {
 		return true;
 	}
+
 	public boolean consumesCollectionAlias() {
 		return true;
 	}
 
 	public boolean isOneToMany() {
 		return true;
 	}
 
 	@Override
-    public boolean isManyToMany() {
+	public boolean isManyToMany() {
 		return false;
 	}
 
 	private BasicBatchKey deleteRowBatchKey;
 	private BasicBatchKey insertRowBatchKey;
 
 	@Override
-    protected int doUpdateRows(Serializable id, PersistentCollection collection, SessionImplementor session) {
+	protected int doUpdateRows(Serializable id, PersistentCollection collection, SessionImplementor session) {
 
 		// we finish all the "removes" first to take care of possible unique
 		// constraints and so that we can take better advantage of batching
-		
+
 		try {
 			int count = 0;
 			if ( isRowDeleteEnabled() ) {
 				final Expectation deleteExpectation = Expectations.appropriateExpectation( getDeleteCheckStyle() );
 				final boolean useBatch = deleteExpectation.canBeBatched();
 				if ( useBatch && deleteRowBatchKey == null ) {
 					deleteRowBatchKey = new BasicBatchKey(
 							getRole() + "#DELETEROW",
 							deleteExpectation
 					);
 				}
 				final String sql = getSQLDeleteRowString();
 
 				PreparedStatement st = null;
 				// update removed rows fks to null
 				try {
 					int i = 0;
 					Iterator entries = collection.entries( this );
 					int offset = 1;
 					while ( entries.hasNext() ) {
 						Object entry = entries.next();
-						if ( collection.needsUpdating( entry, i, elementType ) ) {  // will still be issued when it used to be null
+						if ( collection.needsUpdating(
+								entry,
+								i,
+								elementType
+						) ) {  // will still be issued when it used to be null
 							if ( useBatch ) {
 								st = session
 										.getJdbcCoordinator()
 										.getBatch( deleteRowBatchKey )
 										.getBatchStatement( sql, isDeleteCallable() );
 							}
 							else {
 								st = session
 										.getJdbcCoordinator()
 										.getStatementPreparer()
 										.prepareStatement( sql, isDeleteCallable() );
 							}
 							int loc = writeKey( st, id, offset, session );
-							writeElementToWhere( st, collection.getSnapshotElement(entry, i), loc, session );
+							writeElementToWhere( st, collection.getSnapshotElement( entry, i ), loc, session );
 							if ( useBatch ) {
 								session
 										.getJdbcCoordinator()
 										.getBatch( deleteRowBatchKey )
 										.addToBatch();
 							}
 							else {
-								deleteExpectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
+								deleteExpectation.verifyOutcome(
+										session.getJdbcCoordinator()
+												.getResultSetReturn()
+												.executeUpdate( st ), st, -1
+								);
 							}
 							count++;
 						}
 						i++;
 					}
 				}
-				catch ( SQLException e ) {
+				catch (SQLException e) {
 					if ( useBatch ) {
 						session.getJdbcCoordinator().abortBatch();
 					}
 					throw e;
 				}
 				finally {
 					if ( !useBatch ) {
 						session.getJdbcCoordinator().getResourceRegistry().release( st );
 						session.getJdbcCoordinator().afterStatementExecution();
 					}
 				}
 			}
-			
+
 			if ( isRowInsertEnabled() ) {
 				final Expectation insertExpectation = Expectations.appropriateExpectation( getInsertCheckStyle() );
 				boolean useBatch = insertExpectation.canBeBatched();
 				boolean callable = isInsertCallable();
 				if ( useBatch && insertRowBatchKey == null ) {
 					insertRowBatchKey = new BasicBatchKey(
 							getRole() + "#INSERTROW",
 							insertExpectation
 					);
 				}
 				final String sql = getSQLInsertRowString();
 
 				PreparedStatement st = null;
 				// now update all changed or added rows fks
 				try {
 					int i = 0;
 					Iterator entries = collection.entries( this );
 					while ( entries.hasNext() ) {
 						Object entry = entries.next();
 						int offset = 1;
 						if ( collection.needsUpdating( entry, i, elementType ) ) {
 							if ( useBatch ) {
 								st = session
 										.getJdbcCoordinator()
 										.getBatch( insertRowBatchKey )
 										.getBatchStatement( sql, callable );
 							}
 							else {
 								st = session
 										.getJdbcCoordinator()
 										.getStatementPreparer()
 										.prepareStatement( sql, callable );
 							}
 
 							offset += insertExpectation.prepare( st );
 
 							int loc = writeKey( st, id, offset, session );
 							if ( hasIndex && !indexContainsFormula ) {
 								loc = writeIndexToWhere( st, collection.getIndex( entry, i, this ), loc, session );
 							}
 
 							writeElementToWhere( st, collection.getElement( entry ), loc, session );
 
 							if ( useBatch ) {
 								session.getJdbcCoordinator().getBatch( insertRowBatchKey ).addToBatch();
 							}
 							else {
-								insertExpectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
+								insertExpectation.verifyOutcome(
+										session.getJdbcCoordinator()
+												.getResultSetReturn()
+												.executeUpdate( st ), st, -1
+								);
 							}
 							count++;
 						}
 						i++;
 					}
 				}
-				catch ( SQLException sqle ) {
+				catch (SQLException sqle) {
 					if ( useBatch ) {
 						session.getJdbcCoordinator().abortBatch();
 					}
 					throw sqle;
 				}
 				finally {
 					if ( !useBatch ) {
 						session.getJdbcCoordinator().getResourceRegistry().release( st );
 						session.getJdbcCoordinator().afterStatementExecution();
 					}
 				}
 			}
 
 			return count;
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
-					"could not update collection rows: " + 
-					MessageHelper.collectionInfoString( this, collection, id, session ),
+					"could not update collection rows: " +
+							MessageHelper.collectionInfoString( this, collection, id, session ),
 					getSQLInsertRowString()
 			);
 		}
 	}
 
 	public String selectFragment(
-	        Joinable rhs,
-	        String rhsAlias,
-	        String lhsAlias,
-	        String entitySuffix,
-	        String collectionSuffix,
-	        boolean includeCollectionColumns) {
+			Joinable rhs,
+			String rhsAlias,
+			String lhsAlias,
+			String entitySuffix,
+			String collectionSuffix,
+			boolean includeCollectionColumns) {
 		StringBuilder buf = new StringBuilder();
 		if ( includeCollectionColumns ) {
 //			buf.append( selectFragment( lhsAlias, "" ) )//ignore suffix for collection columns!
 			buf.append( selectFragment( lhsAlias, collectionSuffix ) )
 					.append( ", " );
 		}
-		OuterJoinLoadable ojl = ( OuterJoinLoadable ) getElementPersister();
+		OuterJoinLoadable ojl = (OuterJoinLoadable) getElementPersister();
 		return buf.append( ojl.selectFragment( lhsAlias, entitySuffix ) )//use suffix for the entity columns
 				.toString();
 	}
 
 	/**
 	 * Create the <tt>OneToManyLoader</tt>
 	 *
 	 * @see org.hibernate.loader.collection.OneToManyLoader
 	 */
 	@Override
-    protected CollectionInitializer createCollectionInitializer(LoadQueryInfluencers loadQueryInfluencers)
+	protected CollectionInitializer createCollectionInitializer(LoadQueryInfluencers loadQueryInfluencers)
 			throws MappingException {
 		return BatchingCollectionInitializerBuilder.getBuilder( getFactory() )
 				.createBatchingOneToManyInitializer( this, batchSize, getFactory(), loadQueryInfluencers );
 	}
 
 	@Override
 	public String fromJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		return ( (Joinable) getElementPersister() ).fromJoinFragment( alias, innerJoin, includeSubclasses );
 	}
 
 	@Override
 	public String fromJoinFragment(
 			String alias,
 			boolean innerJoin,
 			boolean includeSubclasses,
 			Set<String> treatAsDeclarations) {
-		return ( (Joinable) getElementPersister() ).fromJoinFragment( alias, innerJoin, includeSubclasses, treatAsDeclarations );
+		return ( (Joinable) getElementPersister() ).fromJoinFragment(
+				alias,
+				innerJoin,
+				includeSubclasses,
+				treatAsDeclarations
+		);
 	}
 
 	@Override
 	public String whereJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		return ( (Joinable) getElementPersister() ).whereJoinFragment( alias, innerJoin, includeSubclasses );
 	}
 
 	@Override
 	public String whereJoinFragment(
 			String alias,
 			boolean innerJoin,
 			boolean includeSubclasses,
 			Set<String> treatAsDeclarations) {
-		return ( (Joinable) getElementPersister() ).whereJoinFragment( alias, innerJoin, includeSubclasses, treatAsDeclarations );
+		return ( (Joinable) getElementPersister() ).whereJoinFragment(
+				alias,
+				innerJoin,
+				includeSubclasses,
+				treatAsDeclarations
+		);
 	}
 
 	@Override
-    public String getTableName() {
+	public String getTableName() {
 		return ( (Joinable) getElementPersister() ).getTableName();
 	}
 
 	@Override
-    public String filterFragment(String alias) throws MappingException {
+	public String filterFragment(String alias) throws MappingException {
 		String result = super.filterFragment( alias );
 		if ( getElementPersister() instanceof Joinable ) {
-			result += ( ( Joinable ) getElementPersister() ).oneToManyFilterFragment( alias );
+			result += ( (Joinable) getElementPersister() ).oneToManyFilterFragment( alias );
 		}
 		return result;
 
 	}
 
 	@Override
 	protected String filterFragment(String alias, Set<String> treatAsDeclarations) throws MappingException {
 		String result = super.filterFragment( alias );
 		if ( getElementPersister() instanceof Joinable ) {
-			result += ( ( Joinable ) getElementPersister() ).oneToManyFilterFragment( alias, treatAsDeclarations );
+			result += ( (Joinable) getElementPersister() ).oneToManyFilterFragment( alias, treatAsDeclarations );
 		}
 		return result;
 	}
 
 	@Override
-    protected CollectionInitializer createSubselectInitializer(SubselectFetch subselect, SessionImplementor session) {
-		return new SubselectOneToManyLoader( 
+	protected CollectionInitializer createSubselectInitializer(SubselectFetch subselect, SessionImplementor session) {
+		return new SubselectOneToManyLoader(
 				this,
 				subselect.toSubselectString( getCollectionType().getLHSPropertyName() ),
 				subselect.getResult(),
 				subselect.getQueryParameters(),
 				subselect.getNamedParameterLocMap(),
 				session.getFactory(),
 				session.getLoadQueryInfluencers()
-			);
+		);
 	}
 
 	@Override
-    public Object getElementByIndex(Serializable key, Object index, SessionImplementor session, Object owner) {
+	public Object getElementByIndex(Serializable key, Object index, SessionImplementor session, Object owner) {
 		return new CollectionElementLoader( this, getFactory(), session.getLoadQueryInfluencers() )
-				.loadElement( session, key, incrementIndexByBase(index) );
+				.loadElement( session, key, incrementIndexByBase( index ) );
 	}
 
 	@Override
 	public FilterAliasGenerator getFilterAliasGenerator(String rootAlias) {
-		return getElementPersister().getFilterAliasGenerator(rootAlias);
+		return getElementPersister().getFilterAliasGenerator( rootAlias );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
index cf5e286bb3..a6bacb044d 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
@@ -1,5129 +1,5332 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.entity;
 
+import java.io.Serializable;
+import java.sql.PreparedStatement;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
 import org.hibernate.AssertionFailure;
 import org.hibernate.EntityMode;
 import org.hibernate.FetchMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.Session;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.StaleStateException;
 import org.hibernate.bytecode.instrumentation.spi.FieldInterceptor;
 import org.hibernate.bytecode.instrumentation.spi.LazyPropertyInitializer;
 import org.hibernate.bytecode.spi.EntityInstrumentationMetadata;
 import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.cache.spi.entry.CacheEntry;
 import org.hibernate.cache.spi.entry.CacheEntryStructure;
 import org.hibernate.cache.spi.entry.ReferenceCacheEntryImpl;
 import org.hibernate.cache.spi.entry.StandardCacheEntryImpl;
 import org.hibernate.cache.spi.entry.StructuredCacheEntry;
 import org.hibernate.cache.spi.entry.UnstructuredCacheEntry;
 import org.hibernate.dialect.lock.LockingStrategy;
 import org.hibernate.engine.OptimisticLockStyle;
 import org.hibernate.engine.internal.CacheHelper;
-import org.hibernate.engine.internal.MutableEntityEntryFactory;
 import org.hibernate.engine.internal.ImmutableEntityEntryFactory;
+import org.hibernate.engine.internal.MutableEntityEntryFactory;
 import org.hibernate.engine.internal.StatefulPersistenceContext;
 import org.hibernate.engine.internal.Versioning;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.engine.spi.CachedNaturalIdValueSource;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.CascadingActions;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.EntityEntryFactory;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.PersistenceContext.NaturalIdHelper;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.ValueInclusion;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.PostInsertIdentifierGenerator;
 import org.hibernate.id.PostInsertIdentityPersister;
 import org.hibernate.id.insert.Binder;
 import org.hibernate.id.insert.InsertGeneratedIdentifierDelegate;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.FilterHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.jdbc.TooManyRowsAffectedException;
 import org.hibernate.loader.entity.BatchingEntityLoaderBuilder;
 import org.hibernate.loader.entity.CascadeEntityLoader;
 import org.hibernate.loader.entity.EntityLoader;
 import org.hibernate.loader.entity.UniqueEntityLoader;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.persister.walking.internal.EntityIdentifierDefinitionHelper;
 import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.EntityIdentifierDefinition;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.property.BackrefPropertyAccessor;
 import org.hibernate.sql.Alias;
 import org.hibernate.sql.Delete;
 import org.hibernate.sql.Insert;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.JoinType;
 import org.hibernate.sql.Select;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.SimpleSelect;
 import org.hibernate.sql.Template;
 import org.hibernate.sql.Update;
 import org.hibernate.tuple.GenerationTiming;
 import org.hibernate.tuple.InDatabaseValueGenerationStrategy;
 import org.hibernate.tuple.InMemoryValueGenerationStrategy;
 import org.hibernate.tuple.NonIdentifierAttribute;
 import org.hibernate.tuple.ValueGeneration;
 import org.hibernate.tuple.entity.EntityMetamodel;
 import org.hibernate.tuple.entity.EntityTuplizer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeHelper;
 import org.hibernate.type.VersionType;
-import org.jboss.logging.Logger;
-
-import java.io.Serializable;
-import java.sql.PreparedStatement;
-import java.sql.ResultSet;
-import java.sql.SQLException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
 
 /**
  * Basic functionality for persisting an entity via JDBC
  * through either generated or custom SQL
  *
  * @author Gavin King
  */
 public abstract class AbstractEntityPersister
 		implements OuterJoinLoadable, Queryable, ClassMetadata, UniqueKeyLoadable,
-		SQLLoadable, LazyPropertyInitializer, PostInsertIdentityPersister, Lockable {
+				SQLLoadable, LazyPropertyInitializer, PostInsertIdentityPersister, Lockable {
 
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, AbstractEntityPersister.class.getName() );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( AbstractEntityPersister.class );
 
 	public static final String ENTITY_CLASS = "class";
 
 	// moved up from AbstractEntityPersister ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	private final SessionFactoryImplementor factory;
 	private final EntityRegionAccessStrategy cacheAccessStrategy;
 	private final NaturalIdRegionAccessStrategy naturalIdRegionAccessStrategy;
 	private final boolean isLazyPropertiesCacheable;
 	private final CacheEntryHelper cacheEntryHelper;
 	private final EntityMetamodel entityMetamodel;
 	private final EntityTuplizer entityTuplizer;
 	private final EntityEntryFactory entityEntryFactory;
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private final String[] rootTableKeyColumnNames;
 	private final String[] rootTableKeyColumnReaders;
 	private final String[] rootTableKeyColumnReaderTemplates;
 	private final String[] identifierAliases;
 	private final int identifierColumnSpan;
 	private final String versionColumnName;
 	private final boolean hasFormulaProperties;
 	private final int batchSize;
 	private final boolean hasSubselectLoadableCollections;
 	protected final String rowIdName;
 
 	private final Set lazyProperties;
 
 	// The optional SQL string defined in the where attribute
 	private final String sqlWhereString;
 	private final String sqlWhereStringTemplate;
 
 	//information about properties of this class,
 	//including inherited properties
 	//(only really needed for updatable/insertable properties)
 	private final int[] propertyColumnSpans;
 	private final String[] propertySubclassNames;
 	private final String[][] propertyColumnAliases;
 	private final String[][] propertyColumnNames;
 	private final String[][] propertyColumnFormulaTemplates;
 	private final String[][] propertyColumnReaderTemplates;
 	private final String[][] propertyColumnWriters;
 	private final boolean[][] propertyColumnUpdateable;
 	private final boolean[][] propertyColumnInsertable;
 	private final boolean[] propertyUniqueness;
 	private final boolean[] propertySelectable;
-	
+
 	private final List<Integer> lobProperties = new ArrayList<Integer>();
 
 	//information about lazy properties of this class
 	private final String[] lazyPropertyNames;
 	private final int[] lazyPropertyNumbers;
 	private final Type[] lazyPropertyTypes;
 	private final String[][] lazyPropertyColumnAliases;
 
 	//information about all properties in class hierarchy
 	private final String[] subclassPropertyNameClosure;
 	private final String[] subclassPropertySubclassNameClosure;
 	private final Type[] subclassPropertyTypeClosure;
 	private final String[][] subclassPropertyFormulaTemplateClosure;
 	private final String[][] subclassPropertyColumnNameClosure;
 	private final String[][] subclassPropertyColumnReaderClosure;
 	private final String[][] subclassPropertyColumnReaderTemplateClosure;
 	private final FetchMode[] subclassPropertyFetchModeClosure;
 	private final boolean[] subclassPropertyNullabilityClosure;
 	private final boolean[] propertyDefinedOnSubclass;
 	private final int[][] subclassPropertyColumnNumberClosure;
 	private final int[][] subclassPropertyFormulaNumberClosure;
 	private final CascadeStyle[] subclassPropertyCascadeStyleClosure;
 
 	//information about all columns/formulas in class hierarchy
 	private final String[] subclassColumnClosure;
 	private final boolean[] subclassColumnLazyClosure;
 	private final String[] subclassColumnAliasClosure;
 	private final boolean[] subclassColumnSelectableClosure;
 	private final String[] subclassColumnReaderTemplateClosure;
 	private final String[] subclassFormulaClosure;
 	private final String[] subclassFormulaTemplateClosure;
 	private final String[] subclassFormulaAliasClosure;
 	private final boolean[] subclassFormulaLazyClosure;
 
 	// dynamic filters attached to the class-level
 	private final FilterHelper filterHelper;
 
 	private final Set<String> affectingFetchProfileNames = new HashSet<String>();
 
 	private final Map uniqueKeyLoaders = new HashMap();
 	private final Map lockers = new HashMap();
 	private final Map loaders = new HashMap();
 
 	// SQL strings
 	private String sqlVersionSelectString;
 	private String sqlSnapshotSelectString;
 	private String sqlLazySelectString;
 
 	private String sqlIdentityInsertString;
 	private String sqlUpdateByRowIdString;
 	private String sqlLazyUpdateByRowIdString;
 
 	private String[] sqlDeleteStrings;
 	private String[] sqlInsertStrings;
 	private String[] sqlUpdateStrings;
 	private String[] sqlLazyUpdateStrings;
 
 	private String sqlInsertGeneratedValuesSelectString;
 	private String sqlUpdateGeneratedValuesSelectString;
 
 	//Custom SQL (would be better if these were private)
 	protected boolean[] insertCallable;
 	protected boolean[] updateCallable;
 	protected boolean[] deleteCallable;
 	protected String[] customSQLInsert;
 	protected String[] customSQLUpdate;
 	protected String[] customSQLDelete;
 	protected ExecuteUpdateResultCheckStyle[] insertResultCheckStyles;
 	protected ExecuteUpdateResultCheckStyle[] updateResultCheckStyles;
 	protected ExecuteUpdateResultCheckStyle[] deleteResultCheckStyles;
 
 	private InsertGeneratedIdentifierDelegate identityDelegate;
 
 	private boolean[] tableHasColumns;
 
 	private final String loaderName;
 
 	private UniqueEntityLoader queryLoader;
 
 	private final Map subclassPropertyAliases = new HashMap();
 	private final Map subclassPropertyColumnNames = new HashMap();
 
 	protected final BasicEntityPropertyMapping propertyMapping;
 
 	private final boolean useReferenceCacheEntries;
 
-	protected void addDiscriminatorToInsert(Insert insert) {}
+	protected void addDiscriminatorToInsert(Insert insert) {
+	}
 
-	protected void addDiscriminatorToSelect(SelectFragment select, String name, String suffix) {}
+	protected void addDiscriminatorToSelect(SelectFragment select, String name, String suffix) {
+	}
 
 	protected abstract int[] getSubclassColumnTableNumberClosure();
 
 	protected abstract int[] getSubclassFormulaTableNumberClosure();
 
 	public abstract String getSubclassTableName(int j);
 
 	protected abstract String[] getSubclassTableKeyColumns(int j);
 
 	protected abstract boolean isClassOrSuperclassTable(int j);
 
 	protected abstract int getSubclassTableSpan();
 
 	protected abstract int getTableSpan();
 
 	protected abstract boolean isTableCascadeDeleteEnabled(int j);
 
 	protected abstract String getTableName(int j);
 
 	protected abstract String[] getKeyColumns(int j);
 
 	protected abstract boolean isPropertyOfTable(int property, int j);
 
 	protected abstract int[] getPropertyTableNumbersInSelect();
 
 	protected abstract int[] getPropertyTableNumbers();
 
 	protected abstract int getSubclassPropertyTableNumber(int i);
 
 	protected abstract String filterFragment(String alias) throws MappingException;
 
 	protected abstract String filterFragment(String alias, Set<String> treatAsDeclarations);
 
 	private static final String DISCRIMINATOR_ALIAS = "clazz_";
 
 	public String getDiscriminatorColumnName() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	public String getDiscriminatorColumnReaders() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	public String getDiscriminatorColumnReaderTemplate() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	protected String getDiscriminatorAlias() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	protected String getDiscriminatorFormulaTemplate() {
 		return null;
 	}
 
 	protected boolean isInverseTable(int j) {
 		return false;
 	}
 
 	protected boolean isNullableTable(int j) {
 		return false;
 	}
 
 	protected boolean isNullableSubclassTable(int j) {
 		return false;
 	}
 
 	protected boolean isInverseSubclassTable(int j) {
 		return false;
 	}
 
 	public boolean isSubclassEntityName(String entityName) {
-		return entityMetamodel.getSubclassEntityNames().contains(entityName);
+		return entityMetamodel.getSubclassEntityNames().contains( entityName );
 	}
 
 	private boolean[] getTableHasColumns() {
 		return tableHasColumns;
 	}
 
 	public String[] getRootTableKeyColumnNames() {
 		return rootTableKeyColumnNames;
 	}
 
 	protected String[] getSQLUpdateByRowIdStrings() {
 		if ( sqlUpdateByRowIdString == null ) {
 			throw new AssertionFailure( "no update by row id" );
 		}
 		String[] result = new String[getTableSpan() + 1];
 		result[0] = sqlUpdateByRowIdString;
 		System.arraycopy( sqlUpdateStrings, 0, result, 1, getTableSpan() );
 		return result;
 	}
 
 	protected String[] getSQLLazyUpdateByRowIdStrings() {
 		if ( sqlLazyUpdateByRowIdString == null ) {
 			throw new AssertionFailure( "no update by row id" );
 		}
 		String[] result = new String[getTableSpan()];
 		result[0] = sqlLazyUpdateByRowIdString;
-		for ( int i = 1; i < getTableSpan(); i++ ) {
-			result[i] = sqlLazyUpdateStrings[i];
-		}
+		System.arraycopy( sqlLazyUpdateStrings, 1, result, 1, getTableSpan() - 1 );
 		return result;
 	}
 
 	protected String getSQLSnapshotSelectString() {
 		return sqlSnapshotSelectString;
 	}
 
 	protected String getSQLLazySelectString() {
 		return sqlLazySelectString;
 	}
 
 	protected String[] getSQLDeleteStrings() {
 		return sqlDeleteStrings;
 	}
 
 	protected String[] getSQLInsertStrings() {
 		return sqlInsertStrings;
 	}
 
 	protected String[] getSQLUpdateStrings() {
 		return sqlUpdateStrings;
 	}
 
 	protected String[] getSQLLazyUpdateStrings() {
 		return sqlLazyUpdateStrings;
 	}
 
 	/**
 	 * The query that inserts a row, letting the database generate an id
 	 *
 	 * @return The IDENTITY-based insertion query.
 	 */
 	protected String getSQLIdentityInsertString() {
 		return sqlIdentityInsertString;
 	}
 
 	protected String getVersionSelectString() {
 		return sqlVersionSelectString;
 	}
 
 	protected boolean isInsertCallable(int j) {
 		return insertCallable[j];
 	}
 
 	protected boolean isUpdateCallable(int j) {
 		return updateCallable[j];
 	}
 
 	protected boolean isDeleteCallable(int j) {
 		return deleteCallable[j];
 	}
 
 	protected boolean isSubclassPropertyDeferred(String propertyName, String entityName) {
 		return false;
 	}
 
 	protected boolean isSubclassTableSequentialSelect(int j) {
 		return false;
 	}
 
 	public boolean hasSequentialSelect() {
 		return false;
 	}
 
 	/**
 	 * Decide which tables need to be updated.
 	 * <p/>
 	 * The return here is an array of boolean values with each index corresponding
 	 * to a given table in the scope of this persister.
 	 *
 	 * @param dirtyProperties The indices of all the entity properties considered dirty.
 	 * @param hasDirtyCollection Whether any collections owned by the entity which were considered dirty.
 	 *
 	 * @return Array of booleans indicating which table require updating.
 	 */
 	protected boolean[] getTableUpdateNeeded(final int[] dirtyProperties, boolean hasDirtyCollection) {
 
 		if ( dirtyProperties == null ) {
 			return getTableHasColumns(); // for objects that came in via update()
 		}
 		else {
 			boolean[] updateability = getPropertyUpdateability();
 			int[] propertyTableNumbers = getPropertyTableNumbers();
-			boolean[] tableUpdateNeeded = new boolean[ getTableSpan() ];
-			for ( int i = 0; i < dirtyProperties.length; i++ ) {
-				int property = dirtyProperties[i];
+			boolean[] tableUpdateNeeded = new boolean[getTableSpan()];
+			for ( int property : dirtyProperties ) {
 				int table = propertyTableNumbers[property];
 				tableUpdateNeeded[table] = tableUpdateNeeded[table] ||
-						( getPropertyColumnSpan(property) > 0 && updateability[property] );
+						( getPropertyColumnSpan( property ) > 0 && updateability[property] );
 			}
 			if ( isVersioned() ) {
 				tableUpdateNeeded[0] = tableUpdateNeeded[0] ||
-					Versioning.isVersionIncrementRequired( dirtyProperties, hasDirtyCollection, getPropertyVersionability() );
+						Versioning.isVersionIncrementRequired(
+								dirtyProperties,
+								hasDirtyCollection,
+								getPropertyVersionability()
+						);
 			}
 			return tableUpdateNeeded;
 		}
 	}
 
 	public boolean hasRowId() {
 		return rowIdName != null;
 	}
 
 	protected boolean[][] getPropertyColumnUpdateable() {
 		return propertyColumnUpdateable;
 	}
 
 	protected boolean[][] getPropertyColumnInsertable() {
 		return propertyColumnInsertable;
 	}
 
 	protected boolean[] getPropertySelectable() {
 		return propertySelectable;
 	}
 
+	@SuppressWarnings("UnnecessaryBoxing")
 	public AbstractEntityPersister(
 			final PersistentClass persistentClass,
 			final EntityRegionAccessStrategy cacheAccessStrategy,
 			final NaturalIdRegionAccessStrategy naturalIdRegionAccessStrategy,
 			final PersisterCreationContext creationContext) throws HibernateException {
 
 		// moved up from AbstractEntityPersister ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		this.factory = creationContext.getSessionFactory();
 		this.cacheAccessStrategy = cacheAccessStrategy;
 		this.naturalIdRegionAccessStrategy = naturalIdRegionAccessStrategy;
 		isLazyPropertiesCacheable = persistentClass.isLazyPropertiesCacheable();
 
 		this.entityMetamodel = new EntityMetamodel( persistentClass, this, factory );
 		this.entityTuplizer = this.entityMetamodel.getTuplizer();
 
-		if( entityMetamodel.isMutable() ) {
+		if ( entityMetamodel.isMutable() ) {
 			this.entityEntryFactory = MutableEntityEntryFactory.INSTANCE;
 		}
 		else {
 			this.entityEntryFactory = ImmutableEntityEntryFactory.INSTANCE;
 		}
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		int batch = persistentClass.getBatchSize();
 		if ( batch == -1 ) {
-			batch = factory.getSettings().getDefaultBatchFetchSize();
+			batch = factory.getSessionFactoryOptions().getDefaultBatchFetchSize();
 		}
 		batchSize = batch;
 		hasSubselectLoadableCollections = persistentClass.hasSubselectLoadableCollections();
 
 		propertyMapping = new BasicEntityPropertyMapping( this );
 
 		// IDENTIFIER
 
 		identifierColumnSpan = persistentClass.getIdentifier().getColumnSpan();
 		rootTableKeyColumnNames = new String[identifierColumnSpan];
 		rootTableKeyColumnReaders = new String[identifierColumnSpan];
 		rootTableKeyColumnReaderTemplates = new String[identifierColumnSpan];
 		identifierAliases = new String[identifierColumnSpan];
 
 		rowIdName = persistentClass.getRootTable().getRowId();
 
 		loaderName = persistentClass.getLoaderName();
 
 		Iterator iter = persistentClass.getIdentifier().getColumnIterator();
 		int i = 0;
 		while ( iter.hasNext() ) {
-			Column col = ( Column ) iter.next();
+			Column col = (Column) iter.next();
 			rootTableKeyColumnNames[i] = col.getQuotedName( factory.getDialect() );
 			rootTableKeyColumnReaders[i] = col.getReadExpr( factory.getDialect() );
-			rootTableKeyColumnReaderTemplates[i] = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
+			rootTableKeyColumnReaderTemplates[i] = col.getTemplate(
+					factory.getDialect(),
+					factory.getSqlFunctionRegistry()
+			);
 			identifierAliases[i] = col.getAlias( factory.getDialect(), persistentClass.getRootTable() );
 			i++;
 		}
 
 		// VERSION
 
 		if ( persistentClass.isVersioned() ) {
-			versionColumnName = ( ( Column ) persistentClass.getVersion().getColumnIterator().next() ).getQuotedName( factory.getDialect() );
+			versionColumnName = ( (Column) persistentClass.getVersion().getColumnIterator().next() ).getQuotedName(
+					factory.getDialect()
+			);
 		}
 		else {
 			versionColumnName = null;
 		}
 
 		//WHERE STRING
 
-		sqlWhereString = StringHelper.isNotEmpty( persistentClass.getWhere() ) ? "( " + persistentClass.getWhere() + ") " : null;
+		sqlWhereString = StringHelper.isNotEmpty( persistentClass.getWhere() ) ?
+				"( " + persistentClass.getWhere() + ") " :
+				null;
 		sqlWhereStringTemplate = sqlWhereString == null ?
 				null :
-				Template.renderWhereStringTemplate( sqlWhereString, factory.getDialect(), factory.getSqlFunctionRegistry() );
+				Template.renderWhereStringTemplate(
+						sqlWhereString,
+						factory.getDialect(),
+						factory.getSqlFunctionRegistry()
+				);
 
 		// PROPERTIES
 
 		final boolean lazyAvailable = isInstrumented();
 
 		int hydrateSpan = entityMetamodel.getPropertySpan();
 		propertyColumnSpans = new int[hydrateSpan];
 		propertySubclassNames = new String[hydrateSpan];
 		propertyColumnAliases = new String[hydrateSpan][];
 		propertyColumnNames = new String[hydrateSpan][];
 		propertyColumnFormulaTemplates = new String[hydrateSpan][];
 		propertyColumnReaderTemplates = new String[hydrateSpan][];
 		propertyColumnWriters = new String[hydrateSpan][];
 		propertyUniqueness = new boolean[hydrateSpan];
 		propertySelectable = new boolean[hydrateSpan];
 		propertyColumnUpdateable = new boolean[hydrateSpan][];
 		propertyColumnInsertable = new boolean[hydrateSpan][];
 		HashSet thisClassProperties = new HashSet();
 
 		lazyProperties = new HashSet();
 		ArrayList lazyNames = new ArrayList();
 		ArrayList lazyNumbers = new ArrayList();
 		ArrayList lazyTypes = new ArrayList();
 		ArrayList lazyColAliases = new ArrayList();
 
 		iter = persistentClass.getPropertyClosureIterator();
 		i = 0;
 		boolean foundFormula = false;
 		while ( iter.hasNext() ) {
-			Property prop = ( Property ) iter.next();
+			Property prop = (Property) iter.next();
 			thisClassProperties.add( prop );
 
 			int span = prop.getColumnSpan();
 			propertyColumnSpans[i] = span;
 			propertySubclassNames[i] = prop.getPersistentClass().getEntityName();
 			String[] colNames = new String[span];
 			String[] colAliases = new String[span];
 			String[] colReaderTemplates = new String[span];
 			String[] colWriters = new String[span];
 			String[] formulaTemplates = new String[span];
 			Iterator colIter = prop.getColumnIterator();
 			int k = 0;
 			while ( colIter.hasNext() ) {
-				Selectable thing = ( Selectable ) colIter.next();
-				colAliases[k] = thing.getAlias( factory.getDialect() , prop.getValue().getTable() );
+				Selectable thing = (Selectable) colIter.next();
+				colAliases[k] = thing.getAlias( factory.getDialect(), prop.getValue().getTable() );
 				if ( thing.isFormula() ) {
 					foundFormula = true;
 					formulaTemplates[k] = thing.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 				}
 				else {
-					Column col = (Column)thing;
+					Column col = (Column) thing;
 					colNames[k] = col.getQuotedName( factory.getDialect() );
 					colReaderTemplates[k] = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					colWriters[k] = col.getWriteExpr();
 				}
 				k++;
 			}
 			propertyColumnNames[i] = colNames;
 			propertyColumnFormulaTemplates[i] = formulaTemplates;
 			propertyColumnReaderTemplates[i] = colReaderTemplates;
 			propertyColumnWriters[i] = colWriters;
 			propertyColumnAliases[i] = colAliases;
 
 			if ( lazyAvailable && prop.isLazy() ) {
 				lazyProperties.add( prop.getName() );
 				lazyNames.add( prop.getName() );
 				lazyNumbers.add( i );
 				lazyTypes.add( prop.getValue().getType() );
 				lazyColAliases.add( colAliases );
 			}
 
 			propertyColumnUpdateable[i] = prop.getValue().getColumnUpdateability();
 			propertyColumnInsertable[i] = prop.getValue().getColumnInsertability();
 
 			propertySelectable[i] = prop.isSelectable();
 
 			propertyUniqueness[i] = prop.getValue().isAlternateUniqueKey();
-			
-			if (prop.isLob() && getFactory().getDialect().forceLobAsLastValue() ) {
+
+			if ( prop.isLob() && getFactory().getDialect().forceLobAsLastValue() ) {
 				lobProperties.add( i );
 			}
 
 			i++;
 
 		}
 		hasFormulaProperties = foundFormula;
 		lazyPropertyColumnAliases = ArrayHelper.to2DStringArray( lazyColAliases );
 		lazyPropertyNames = ArrayHelper.toStringArray( lazyNames );
 		lazyPropertyNumbers = ArrayHelper.toIntArray( lazyNumbers );
 		lazyPropertyTypes = ArrayHelper.toTypeArray( lazyTypes );
 
 		// SUBCLASS PROPERTY CLOSURE
 
 		ArrayList columns = new ArrayList();
 		ArrayList columnsLazy = new ArrayList();
 		ArrayList columnReaderTemplates = new ArrayList();
 		ArrayList aliases = new ArrayList();
 		ArrayList formulas = new ArrayList();
 		ArrayList formulaAliases = new ArrayList();
 		ArrayList formulaTemplates = new ArrayList();
 		ArrayList formulasLazy = new ArrayList();
 		ArrayList types = new ArrayList();
 		ArrayList names = new ArrayList();
 		ArrayList classes = new ArrayList();
 		ArrayList templates = new ArrayList();
 		ArrayList propColumns = new ArrayList();
 		ArrayList propColumnReaders = new ArrayList();
 		ArrayList propColumnReaderTemplates = new ArrayList();
 		ArrayList joinedFetchesList = new ArrayList();
 		ArrayList cascades = new ArrayList();
 		ArrayList definedBySubclass = new ArrayList();
 		ArrayList propColumnNumbers = new ArrayList();
 		ArrayList propFormulaNumbers = new ArrayList();
 		ArrayList columnSelectables = new ArrayList();
 		ArrayList propNullables = new ArrayList();
 
 		iter = persistentClass.getSubclassPropertyClosureIterator();
 		while ( iter.hasNext() ) {
-			Property prop = ( Property ) iter.next();
+			Property prop = (Property) iter.next();
 			names.add( prop.getName() );
 			classes.add( prop.getPersistentClass().getEntityName() );
 			boolean isDefinedBySubclass = !thisClassProperties.contains( prop );
 			definedBySubclass.add( Boolean.valueOf( isDefinedBySubclass ) );
 			propNullables.add( Boolean.valueOf( prop.isOptional() || isDefinedBySubclass ) ); //TODO: is this completely correct?
 			types.add( prop.getType() );
 
 			Iterator colIter = prop.getColumnIterator();
 			String[] cols = new String[prop.getColumnSpan()];
 			String[] readers = new String[prop.getColumnSpan()];
 			String[] readerTemplates = new String[prop.getColumnSpan()];
 			String[] forms = new String[prop.getColumnSpan()];
 			int[] colnos = new int[prop.getColumnSpan()];
 			int[] formnos = new int[prop.getColumnSpan()];
 			int l = 0;
 			Boolean lazy = Boolean.valueOf( prop.isLazy() && lazyAvailable );
 			while ( colIter.hasNext() ) {
-				Selectable thing = ( Selectable ) colIter.next();
+				Selectable thing = (Selectable) colIter.next();
 				if ( thing.isFormula() ) {
 					String template = thing.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					formnos[l] = formulaTemplates.size();
 					colnos[l] = -1;
 					formulaTemplates.add( template );
 					forms[l] = template;
 					formulas.add( thing.getText( factory.getDialect() ) );
 					formulaAliases.add( thing.getAlias( factory.getDialect() ) );
 					formulasLazy.add( lazy );
 				}
 				else {
-					Column col = (Column)thing;
+					Column col = (Column) thing;
 					String colName = col.getQuotedName( factory.getDialect() );
 					colnos[l] = columns.size(); //before add :-)
 					formnos[l] = -1;
 					columns.add( colName );
 					cols[l] = colName;
 					aliases.add( thing.getAlias( factory.getDialect(), prop.getValue().getTable() ) );
 					columnsLazy.add( lazy );
 					columnSelectables.add( Boolean.valueOf( prop.isSelectable() ) );
 
 					readers[l] = col.getReadExpr( factory.getDialect() );
 					String readerTemplate = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					readerTemplates[l] = readerTemplate;
 					columnReaderTemplates.add( readerTemplate );
 				}
 				l++;
 			}
 			propColumns.add( cols );
 			propColumnReaders.add( readers );
 			propColumnReaderTemplates.add( readerTemplates );
 			templates.add( forms );
 			propColumnNumbers.add( colnos );
 			propFormulaNumbers.add( formnos );
 
 			joinedFetchesList.add( prop.getValue().getFetchMode() );
 			cascades.add( prop.getCascadeStyle() );
 		}
 		subclassColumnClosure = ArrayHelper.toStringArray( columns );
 		subclassColumnAliasClosure = ArrayHelper.toStringArray( aliases );
 		subclassColumnLazyClosure = ArrayHelper.toBooleanArray( columnsLazy );
 		subclassColumnSelectableClosure = ArrayHelper.toBooleanArray( columnSelectables );
 		subclassColumnReaderTemplateClosure = ArrayHelper.toStringArray( columnReaderTemplates );
 
 		subclassFormulaClosure = ArrayHelper.toStringArray( formulas );
 		subclassFormulaTemplateClosure = ArrayHelper.toStringArray( formulaTemplates );
 		subclassFormulaAliasClosure = ArrayHelper.toStringArray( formulaAliases );
 		subclassFormulaLazyClosure = ArrayHelper.toBooleanArray( formulasLazy );
 
 		subclassPropertyNameClosure = ArrayHelper.toStringArray( names );
 		subclassPropertySubclassNameClosure = ArrayHelper.toStringArray( classes );
 		subclassPropertyTypeClosure = ArrayHelper.toTypeArray( types );
 		subclassPropertyNullabilityClosure = ArrayHelper.toBooleanArray( propNullables );
 		subclassPropertyFormulaTemplateClosure = ArrayHelper.to2DStringArray( templates );
 		subclassPropertyColumnNameClosure = ArrayHelper.to2DStringArray( propColumns );
 		subclassPropertyColumnReaderClosure = ArrayHelper.to2DStringArray( propColumnReaders );
 		subclassPropertyColumnReaderTemplateClosure = ArrayHelper.to2DStringArray( propColumnReaderTemplates );
 		subclassPropertyColumnNumberClosure = ArrayHelper.to2DIntArray( propColumnNumbers );
 		subclassPropertyFormulaNumberClosure = ArrayHelper.to2DIntArray( propFormulaNumbers );
 
 		subclassPropertyCascadeStyleClosure = new CascadeStyle[cascades.size()];
 		iter = cascades.iterator();
 		int j = 0;
 		while ( iter.hasNext() ) {
-			subclassPropertyCascadeStyleClosure[j++] = ( CascadeStyle ) iter.next();
+			subclassPropertyCascadeStyleClosure[j++] = (CascadeStyle) iter.next();
 		}
 		subclassPropertyFetchModeClosure = new FetchMode[joinedFetchesList.size()];
 		iter = joinedFetchesList.iterator();
 		j = 0;
 		while ( iter.hasNext() ) {
-			subclassPropertyFetchModeClosure[j++] = ( FetchMode ) iter.next();
+			subclassPropertyFetchModeClosure[j++] = (FetchMode) iter.next();
 		}
 
 		propertyDefinedOnSubclass = new boolean[definedBySubclass.size()];
 		iter = definedBySubclass.iterator();
 		j = 0;
 		while ( iter.hasNext() ) {
 			propertyDefinedOnSubclass[j++] = (Boolean) iter.next();
 		}
 
 		// Handle any filters applied to the class level
 		filterHelper = new FilterHelper( persistentClass.getFilters(), factory );
 
 		// Check if we can use Reference Cached entities in 2lc
 		// todo : should really validate that the cache access type is read-only
 		boolean refCacheEntries = true;
-		if ( ! factory.getSettings().isDirectReferenceCacheEntriesEnabled() ) {
+		if ( !factory.getSessionFactoryOptions().isDirectReferenceCacheEntriesEnabled() ) {
 			refCacheEntries = false;
 		}
 
 		// for now, limit this to just entities that:
 		// 		1) are immutable
 		if ( entityMetamodel.isMutable() ) {
-			refCacheEntries =  false;
+			refCacheEntries = false;
 		}
 
 		//		2)  have no associations.  Eventually we want to be a little more lenient with associations.
 		for ( Type type : getSubclassPropertyTypeClosure() ) {
 			if ( type.isAssociationType() ) {
-				refCacheEntries =  false;
+				refCacheEntries = false;
 			}
 		}
 
 		useReferenceCacheEntries = refCacheEntries;
 
 		this.cacheEntryHelper = buildCacheEntryHelper();
 
 	}
 
 	protected CacheEntryHelper buildCacheEntryHelper() {
 		if ( cacheAccessStrategy == null ) {
 			// the entity defined no caching...
 			return NoopCacheEntryHelper.INSTANCE;
 		}
 
 		if ( canUseReferenceCacheEntries() ) {
 			entityMetamodel.setLazy( false );
 			// todo : do we also need to unset proxy factory?
 			return new ReferenceCacheEntryHelper( this );
 		}
 
-		return factory.getSettings().isStructuredCacheEntriesEnabled()
+		return factory.getSessionFactoryOptions().isStructuredCacheEntriesEnabled()
 				? new StructuredCacheEntryHelper( this )
 				: new StandardCacheEntryHelper( this );
 	}
 
 	public boolean canUseReferenceCacheEntries() {
 		return useReferenceCacheEntries;
 	}
 
 	protected static String getTemplateFromString(String string, SessionFactoryImplementor factory) {
 		return string == null ?
 				null :
 				Template.renderWhereStringTemplate( string, factory.getDialect(), factory.getSqlFunctionRegistry() );
 	}
 
 	protected String generateLazySelectString() {
 
 		if ( !entityMetamodel.hasLazyProperties() ) {
 			return null;
 		}
 
 		HashSet tableNumbers = new HashSet();
 		ArrayList columnNumbers = new ArrayList();
 		ArrayList formulaNumbers = new ArrayList();
-		for ( int i = 0; i < lazyPropertyNames.length; i++ ) {
+		for ( String lazyPropertyName : lazyPropertyNames ) {
 			// all this only really needs to consider properties
 			// of this class, not its subclasses, but since we
 			// are reusing code used for sequential selects, we
 			// use the subclass closure
-			int propertyNumber = getSubclassPropertyIndex( lazyPropertyNames[i] );
+			int propertyNumber = getSubclassPropertyIndex( lazyPropertyName );
 
 			int tableNumber = getSubclassPropertyTableNumber( propertyNumber );
-			tableNumbers.add(  tableNumber );
+			tableNumbers.add( tableNumber );
 
 			int[] colNumbers = subclassPropertyColumnNumberClosure[propertyNumber];
-			for ( int j = 0; j < colNumbers.length; j++ ) {
-				if ( colNumbers[j]!=-1 ) {
-					columnNumbers.add( colNumbers[j] );
+			for ( int colNumber : colNumbers ) {
+				if ( colNumber != -1 ) {
+					columnNumbers.add( colNumber );
 				}
 			}
 			int[] formNumbers = subclassPropertyFormulaNumberClosure[propertyNumber];
-			for ( int j = 0; j < formNumbers.length; j++ ) {
-				if ( formNumbers[j]!=-1 ) {
-					formulaNumbers.add( formNumbers[j] );
+			for ( int formNumber : formNumbers ) {
+				if ( formNumber != -1 ) {
+					formulaNumbers.add( formNumber );
 				}
 			}
 		}
 
-		if ( columnNumbers.size()==0 && formulaNumbers.size()==0 ) {
+		if ( columnNumbers.size() == 0 && formulaNumbers.size() == 0 ) {
 			// only one-to-one is lazy fetched
 			return null;
 		}
 
 		return renderSelect(
 				ArrayHelper.toIntArray( tableNumbers ),
 				ArrayHelper.toIntArray( columnNumbers ),
 				ArrayHelper.toIntArray( formulaNumbers )
 		);
 
 	}
 
 	public Object initializeLazyProperty(String fieldName, Object entity, SessionImplementor session)
 			throws HibernateException {
 
 		final Serializable id = session.getContextEntityIdentifier( entity );
 
 		final EntityEntry entry = session.getPersistenceContext().getEntry( entity );
 		if ( entry == null ) {
 			throw new HibernateException( "entity is not associated with the session: " + id );
 		}
 
 		if ( LOG.isTraceEnabled() ) {
-			LOG.tracev( "Initializing lazy properties of: {0}, field access: {1}", MessageHelper.infoString( this, id, getFactory() ), fieldName );
+			LOG.tracev(
+					"Initializing lazy properties of: {0}, field access: {1}", MessageHelper.infoString(
+							this,
+							id,
+							getFactory()
+					), fieldName
+			);
 		}
 
 		if ( session.getCacheMode().isGetEnabled() && hasCache() ) {
 			final CacheKey cacheKey = session.generateCacheKey( id, getIdentifierType(), getEntityName() );
 			final Object ce = CacheHelper.fromSharedCache( session, cacheKey, getCacheAccessStrategy() );
 			if ( ce != null ) {
-				final CacheEntry cacheEntry = (CacheEntry) getCacheEntryStructure().destructure(ce, factory);
+				final CacheEntry cacheEntry = (CacheEntry) getCacheEntryStructure().destructure( ce, factory );
 				if ( !cacheEntry.areLazyPropertiesUnfetched() ) {
 					//note early exit here:
 					return initializeLazyPropertiesFromCache( fieldName, entity, session, entry, cacheEntry );
 				}
 			}
 		}
 
 		return initializeLazyPropertiesFromDatastore( fieldName, entity, session, id, entry );
 
 	}
 
 	private Object initializeLazyPropertiesFromDatastore(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final Serializable id,
 			final EntityEntry entry) {
 
 		if ( !hasLazyProperties() ) {
 			throw new AssertionFailure( "no lazy properties" );
 		}
 
 		LOG.trace( "Initializing lazy properties from datastore" );
 
 		try {
 
 			Object result = null;
 			PreparedStatement ps = null;
 			try {
 				final String lazySelect = getSQLLazySelectString();
 				ResultSet rs = null;
 				try {
 					if ( lazySelect != null ) {
 						// null sql means that the only lazy properties
 						// are shared PK one-to-one associations which are
 						// handled differently in the Type#nullSafeGet code...
 						ps = session.getJdbcCoordinator()
 								.getStatementPreparer()
 								.prepareStatement( lazySelect );
 						getIdentifierType().nullSafeSet( ps, id, 1, session );
 						rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 						rs.next();
 					}
 					final Object[] snapshot = entry.getLoadedState();
 					for ( int j = 0; j < lazyPropertyNames.length; j++ ) {
-						Object propValue = lazyPropertyTypes[j].nullSafeGet( rs, lazyPropertyColumnAliases[j], session, entity );
+						Object propValue = lazyPropertyTypes[j].nullSafeGet(
+								rs,
+								lazyPropertyColumnAliases[j],
+								session,
+								entity
+						);
 						if ( initializeLazyProperty( fieldName, entity, session, snapshot, j, propValue ) ) {
 							result = propValue;
 						}
 					}
 				}
 				finally {
 					if ( rs != null ) {
 						session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 					}
 				}
 			}
 			finally {
 				if ( ps != null ) {
 					session.getJdbcCoordinator().getResourceRegistry().release( ps );
 					session.getJdbcCoordinator().afterStatementExecution();
 				}
 			}
 
 			LOG.trace( "Done initializing lazy properties" );
 
 			return result;
 
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not initialize lazy properties: " +
-					MessageHelper.infoString( this, id, getFactory() ),
+							MessageHelper.infoString( this, id, getFactory() ),
 					getSQLLazySelectString()
-				);
+			);
 		}
 	}
 
 	private Object initializeLazyPropertiesFromCache(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final EntityEntry entry,
 			final CacheEntry cacheEntry
 	) {
 
 		LOG.trace( "Initializing lazy properties from second-level cache" );
 
 		Object result = null;
 		Serializable[] disassembledValues = cacheEntry.getDisassembledState();
 		final Object[] snapshot = entry.getLoadedState();
 		for ( int j = 0; j < lazyPropertyNames.length; j++ ) {
 			final Object propValue = lazyPropertyTypes[j].assemble(
-					disassembledValues[ lazyPropertyNumbers[j] ],
+					disassembledValues[lazyPropertyNumbers[j]],
 					session,
 					entity
-				);
+			);
 			if ( initializeLazyProperty( fieldName, entity, session, snapshot, j, propValue ) ) {
 				result = propValue;
 			}
 		}
 
 		LOG.trace( "Done initializing lazy properties" );
 
 		return result;
 	}
 
 	private boolean initializeLazyProperty(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final Object[] snapshot,
 			final int j,
 			final Object propValue) {
 		setPropertyValue( entity, lazyPropertyNumbers[j], propValue );
 		if ( snapshot != null ) {
 			// object have been loaded with setReadOnly(true); HHH-2236
-			snapshot[ lazyPropertyNumbers[j] ] = lazyPropertyTypes[j].deepCopy( propValue, factory );
+			snapshot[lazyPropertyNumbers[j]] = lazyPropertyTypes[j].deepCopy( propValue, factory );
 		}
 		return fieldName.equals( lazyPropertyNames[j] );
 	}
 
 	public boolean isBatchable() {
 		return optimisticLockStyle() == OptimisticLockStyle.NONE
 				|| ( !isVersioned() && optimisticLockStyle() == OptimisticLockStyle.VERSION )
-				|| getFactory().getSettings().isJdbcBatchVersionedData();
+				|| getFactory().getSessionFactoryOptions().isJdbcBatchVersionedData();
 	}
 
 	public Serializable[] getQuerySpaces() {
 		return getPropertySpaces();
 	}
 
 	protected Set getLazyProperties() {
 		return lazyProperties;
 	}
 
 	public boolean isBatchLoadable() {
 		return batchSize > 1;
 	}
 
 	public String[] getIdentifierColumnNames() {
 		return rootTableKeyColumnNames;
 	}
 
 	public String[] getIdentifierColumnReaders() {
 		return rootTableKeyColumnReaders;
 	}
 
 	public String[] getIdentifierColumnReaderTemplates() {
 		return rootTableKeyColumnReaderTemplates;
 	}
 
 	protected int getIdentifierColumnSpan() {
 		return identifierColumnSpan;
 	}
 
 	protected String[] getIdentifierAliases() {
 		return identifierAliases;
 	}
 
 	public String getVersionColumnName() {
 		return versionColumnName;
 	}
 
 	protected String getVersionedTableName() {
 		return getTableName( 0 );
 	}
 
 	protected boolean[] getSubclassColumnLazyiness() {
 		return subclassColumnLazyClosure;
 	}
 
 	protected boolean[] getSubclassFormulaLazyiness() {
 		return subclassFormulaLazyClosure;
 	}
 
 	/**
 	 * We can't immediately add to the cache if we have formulas
 	 * which must be evaluated, or if we have the possibility of
 	 * two concurrent updates to the same item being merged on
 	 * the database. This can happen if (a) the item is not
 	 * versioned and either (b) we have dynamic update enabled
 	 * or (c) we have multiple tables holding the state of the
 	 * item.
 	 */
 	public boolean isCacheInvalidationRequired() {
 		return hasFormulaProperties() ||
 				( !isVersioned() && ( entityMetamodel.isDynamicUpdate() || getTableSpan() > 1 ) );
 	}
 
 	public boolean isLazyPropertiesCacheable() {
 		return isLazyPropertiesCacheable;
 	}
 
 	public String selectFragment(String alias, String suffix) {
 		return identifierSelectFragment( alias, suffix ) +
 				propertySelectFragment( alias, suffix, false );
 	}
 
 	public String[] getIdentifierAliases(String suffix) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		// was toUnqotedAliasStrings( getIdentiferColumnNames() ) before - now tried
 		// to remove that unqoting and missing aliases..
 		return new Alias( suffix ).toAliasStrings( getIdentifierAliases() );
 	}
 
 	public String[] getPropertyAliases(String suffix, int i) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		return new Alias( suffix ).toUnquotedAliasStrings( propertyColumnAliases[i] );
 	}
 
 	public String getDiscriminatorAlias(String suffix) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		// was toUnqotedAliasStrings( getdiscriminatorColumnName() ) before - now tried
 		// to remove that unqoting and missing aliases..
 		return entityMetamodel.hasSubclasses() ?
 				new Alias( suffix ).toAliasString( getDiscriminatorAlias() ) :
 				null;
 	}
 
 	public String identifierSelectFragment(String name, String suffix) {
 		return new SelectFragment()
 				.setSuffix( suffix )
 				.addColumns( name, getIdentifierColumnNames(), getIdentifierAliases() )
 				.toFragmentString()
 				.substring( 2 ); //strip leading ", "
 	}
 
 
 	public String propertySelectFragment(String tableAlias, String suffix, boolean allProperties) {
 		return propertySelectFragmentFragment( tableAlias, suffix, allProperties ).toFragmentString();
 	}
 
 	public SelectFragment propertySelectFragmentFragment(
 			String tableAlias,
 			String suffix,
 			boolean allProperties) {
 		SelectFragment select = new SelectFragment()
 				.setSuffix( suffix )
 				.setUsedAliases( getIdentifierAliases() );
 
 		int[] columnTableNumbers = getSubclassColumnTableNumberClosure();
 		String[] columnAliases = getSubclassColumnAliasClosure();
 		String[] columnReaderTemplates = getSubclassColumnReaderTemplateClosure();
 		for ( int i = 0; i < getSubclassColumnClosure().length; i++ ) {
 			boolean selectable = ( allProperties || !subclassColumnLazyClosure[i] ) &&
-				!isSubclassTableSequentialSelect( columnTableNumbers[i] ) &&
-				subclassColumnSelectableClosure[i];
+					!isSubclassTableSequentialSelect( columnTableNumbers[i] ) &&
+					subclassColumnSelectableClosure[i];
 			if ( selectable ) {
 				String subalias = generateTableAlias( tableAlias, columnTableNumbers[i] );
 				select.addColumnTemplate( subalias, columnReaderTemplates[i], columnAliases[i] );
 			}
 		}
 
 		int[] formulaTableNumbers = getSubclassFormulaTableNumberClosure();
 		String[] formulaTemplates = getSubclassFormulaTemplateClosure();
 		String[] formulaAliases = getSubclassFormulaAliasClosure();
 		for ( int i = 0; i < getSubclassFormulaTemplateClosure().length; i++ ) {
 			boolean selectable = ( allProperties || !subclassFormulaLazyClosure[i] )
-				&& !isSubclassTableSequentialSelect( formulaTableNumbers[i] );
+					&& !isSubclassTableSequentialSelect( formulaTableNumbers[i] );
 			if ( selectable ) {
 				String subalias = generateTableAlias( tableAlias, formulaTableNumbers[i] );
 				select.addFormula( subalias, formulaTemplates[i], formulaAliases[i] );
 			}
 		}
 
 		if ( entityMetamodel.hasSubclasses() ) {
 			addDiscriminatorToSelect( select, tableAlias, suffix );
 		}
 
 		if ( hasRowId() ) {
 			select.addColumn( tableAlias, rowIdName, ROWID_ALIAS );
 		}
 
 		return select;
 	}
 
 	public Object[] getDatabaseSnapshot(Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
-			LOG.tracev( "Getting current persistent state for: {0}", MessageHelper.infoString( this, id, getFactory() ) );
+			LOG.tracev(
+					"Getting current persistent state for: {0}", MessageHelper.infoString(
+							this,
+							id,
+							getFactory()
+					)
+			);
 		}
 
 		try {
 			PreparedStatement ps = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( getSQLSnapshotSelectString() );
 			try {
 				getIdentifierType().nullSafeSet( ps, id, 1, session );
 				//if ( isVersioned() ) getVersionType().nullSafeSet( ps, version, getIdentifierColumnSpan()+1, session );
 				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					//if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 					//otherwise return the "hydrated" state (ie. associations are not resolved)
 					Type[] types = getPropertyTypes();
 					Object[] values = new Object[types.length];
 					boolean[] includeProperty = getPropertyUpdateability();
 					for ( int i = 0; i < types.length; i++ ) {
 						if ( includeProperty[i] ) {
-							values[i] = types[i].hydrate( rs, getPropertyAliases( "", i ), session, null ); //null owner ok??
+							values[i] = types[i].hydrate(
+									rs,
+									getPropertyAliases( "", i ),
+									session,
+									null
+							); //null owner ok??
 						}
 					}
 					return values;
 				}
 				finally {
 					session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( ps );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
-		catch ( SQLException e ) {
+		catch (SQLException e) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not retrieve snapshot: " + MessageHelper.infoString( this, id, getFactory() ),
-			        getSQLSnapshotSelectString()
+					getSQLSnapshotSelectString()
 			);
 		}
 
 	}
 
 	@Override
-	public Serializable getIdByUniqueKey(Serializable key, String uniquePropertyName, SessionImplementor session) throws HibernateException {
+	public Serializable getIdByUniqueKey(Serializable key, String uniquePropertyName, SessionImplementor session)
+			throws HibernateException {
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracef(
 					"resolving unique key [%s] to identifier for entity [%s]",
 					key,
 					getEntityName()
 			);
 		}
 
 		int propertyIndex = getSubclassPropertyIndex( uniquePropertyName );
 		if ( propertyIndex < 0 ) {
 			throw new HibernateException(
 					"Could not determine Type for property [" + uniquePropertyName + "] on entity [" + getEntityName() + "]"
 			);
 		}
 		Type propertyType = getSubclassPropertyType( propertyIndex );
 
 		try {
 			PreparedStatement ps = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( generateIdByUniqueKeySelectString( uniquePropertyName ) );
 			try {
 				propertyType.nullSafeSet( ps, key, 1, session );
 				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					//if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 					return (Serializable) getIdentifierType().nullSafeGet( rs, getIdentifierAliases(), session, null );
 				}
 				finally {
 					session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( ps );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
-		catch ( SQLException e ) {
+		catch (SQLException e) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					String.format(
 							"could not resolve unique property [%s] to identifier for entity [%s]",
 							uniquePropertyName,
 							getEntityName()
 					),
 					getSQLSnapshotSelectString()
 			);
 		}
 
 	}
 
 	protected String generateIdByUniqueKeySelectString(String uniquePropertyName) {
 		Select select = new Select( getFactory().getDialect() );
 
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			select.setComment( "resolve id by unique property [" + getEntityName() + "." + uniquePropertyName + "]" );
 		}
 
 		final String rooAlias = getRootAlias();
 
 		select.setFromClause( fromTableFragment( rooAlias ) + fromJoinFragment( rooAlias, true, false ) );
 
 		SelectFragment selectFragment = new SelectFragment();
 		selectFragment.addColumns( rooAlias, getIdentifierColumnNames(), getIdentifierAliases() );
 		select.setSelectClause( selectFragment );
 
 		StringBuilder whereClauseBuffer = new StringBuilder();
 		final int uniquePropertyIndex = getSubclassPropertyIndex( uniquePropertyName );
 		final String uniquePropertyTableAlias = generateTableAlias(
 				rooAlias,
 				getSubclassPropertyTableNumber( uniquePropertyIndex )
 		);
 		String sep = "";
 		for ( String columnTemplate : getSubclassPropertyColumnReaderTemplateClosure()[uniquePropertyIndex] ) {
 			if ( columnTemplate == null ) {
 				continue;
 			}
-			final String columnReference = StringHelper.replace( columnTemplate, Template.TEMPLATE, uniquePropertyTableAlias );
+			final String columnReference = StringHelper.replace(
+					columnTemplate,
+					Template.TEMPLATE,
+					uniquePropertyTableAlias
+			);
 			whereClauseBuffer.append( sep ).append( columnReference ).append( "=?" );
 			sep = " and ";
 		}
 		for ( String formulaTemplate : getSubclassPropertyFormulaTemplateClosure()[uniquePropertyIndex] ) {
 			if ( formulaTemplate == null ) {
 				continue;
 			}
-			final String formulaReference = StringHelper.replace( formulaTemplate, Template.TEMPLATE, uniquePropertyTableAlias );
+			final String formulaReference = StringHelper.replace(
+					formulaTemplate,
+					Template.TEMPLATE,
+					uniquePropertyTableAlias
+			);
 			whereClauseBuffer.append( sep ).append( formulaReference ).append( "=?" );
 			sep = " and ";
 		}
 		whereClauseBuffer.append( whereJoinFragment( rooAlias, true, false ) );
 
 		select.setWhereClause( whereClauseBuffer.toString() );
 
 		return select.setOuterJoins( "", "" ).toStatementString();
 	}
 
 
 	/**
 	 * Generate the SQL that selects the version number by id
 	 */
 	protected String generateSelectVersionString() {
 		SimpleSelect select = new SimpleSelect( getFactory().getDialect() )
 				.setTableName( getVersionedTableName() );
 		if ( isVersioned() ) {
 			select.addColumn( versionColumnName );
 		}
 		else {
 			select.addColumns( rootTableKeyColumnNames );
 		}
 		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			select.setComment( "get version " + getEntityName() );
 		}
 		return select.addCondition( rootTableKeyColumnNames, "=?" ).toStatementString();
 	}
 
 	public boolean[] getPropertyUniqueness() {
 		return propertyUniqueness;
 	}
 
 	protected String generateInsertGeneratedValuesSelectString() {
 		return generateGeneratedValuesSelectString( GenerationTiming.INSERT );
 	}
 
 	protected String generateUpdateGeneratedValuesSelectString() {
 		return generateGeneratedValuesSelectString( GenerationTiming.ALWAYS );
 	}
 
 	private String generateGeneratedValuesSelectString(final GenerationTiming generationTimingToMatch) {
 		Select select = new Select( getFactory().getDialect() );
 
 		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			select.setComment( "get generated state " + getEntityName() );
 		}
 
 		String[] aliasedIdColumns = StringHelper.qualify( getRootAlias(), getIdentifierColumnNames() );
 
 		// Here we render the select column list based on the properties defined as being generated.
 		// For partial component generation, we currently just re-select the whole component
 		// rather than trying to handle the individual generated portions.
 		String selectClause = concretePropertySelectFragment(
 				getRootAlias(),
 				new InclusionChecker() {
 					@Override
 					public boolean includeProperty(int propertyNumber) {
 						final InDatabaseValueGenerationStrategy generationStrategy
 								= entityMetamodel.getInDatabaseValueGenerationStrategies()[propertyNumber];
 						return generationStrategy != null
 								&& timingsMatch( generationStrategy.getGenerationTiming(), generationTimingToMatch );
 					}
 				}
 		);
 		selectClause = selectClause.substring( 2 );
 
 		String fromClause = fromTableFragment( getRootAlias() ) +
 				fromJoinFragment( getRootAlias(), true, false );
 
 		String whereClause = new StringBuilder()
 				.append( StringHelper.join( "=? and ", aliasedIdColumns ) )
 				.append( "=?" )
 				.append( whereJoinFragment( getRootAlias(), true, false ) )
 				.toString();
 
 		return select.setSelectClause( selectClause )
 				.setFromClause( fromClause )
 				.setOuterJoins( "", "" )
 				.setWhereClause( whereClause )
 				.toStatementString();
 	}
 
 	protected static interface InclusionChecker {
 		public boolean includeProperty(int propertyNumber);
 	}
 
 	protected String concretePropertySelectFragment(String alias, final boolean[] includeProperty) {
 		return concretePropertySelectFragment(
 				alias,
 				new InclusionChecker() {
 					public boolean includeProperty(int propertyNumber) {
 						return includeProperty[propertyNumber];
 					}
 				}
 		);
 	}
 
 	protected String concretePropertySelectFragment(String alias, InclusionChecker inclusionChecker) {
 		int propertyCount = getPropertyNames().length;
 		int[] propertyTableNumbers = getPropertyTableNumbersInSelect();
 		SelectFragment frag = new SelectFragment();
 		for ( int i = 0; i < propertyCount; i++ ) {
 			if ( inclusionChecker.includeProperty( i ) ) {
 				frag.addColumnTemplates(
 						generateTableAlias( alias, propertyTableNumbers[i] ),
 						propertyColumnReaderTemplates[i],
 						propertyColumnAliases[i]
 				);
 				frag.addFormulas(
 						generateTableAlias( alias, propertyTableNumbers[i] ),
 						propertyColumnFormulaTemplates[i],
 						propertyColumnAliases[i]
 				);
 			}
 		}
 		return frag.toFragmentString();
 	}
 
 	protected String generateSnapshotSelectString() {
 
 		//TODO: should we use SELECT .. FOR UPDATE?
 
 		Select select = new Select( getFactory().getDialect() );
 
 		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			select.setComment( "get current state " + getEntityName() );
 		}
 
 		String[] aliasedIdColumns = StringHelper.qualify( getRootAlias(), getIdentifierColumnNames() );
 		String selectClause = StringHelper.join( ", ", aliasedIdColumns ) +
 				concretePropertySelectFragment( getRootAlias(), getPropertyUpdateability() );
 
 		String fromClause = fromTableFragment( getRootAlias() ) +
 				fromJoinFragment( getRootAlias(), true, false );
 
 		String whereClause = new StringBuilder()
-			.append( StringHelper.join( "=? and ",
-					aliasedIdColumns ) )
-			.append( "=?" )
-			.append( whereJoinFragment( getRootAlias(), true, false ) )
-			.toString();
+				.append(
+						StringHelper.join(
+								"=? and ",
+								aliasedIdColumns
+						)
+				)
+				.append( "=?" )
+				.append( whereJoinFragment( getRootAlias(), true, false ) )
+				.toString();
 
 		/*if ( isVersioned() ) {
 			where.append(" and ")
 				.append( getVersionColumnName() )
 				.append("=?");
 		}*/
 
 		return select.setSelectClause( selectClause )
 				.setFromClause( fromClause )
 				.setOuterJoins( "", "" )
 				.setWhereClause( whereClause )
 				.toStatementString();
 	}
 
 	public Object forceVersionIncrement(Serializable id, Object currentVersion, SessionImplementor session) {
 		if ( !isVersioned() ) {
 			throw new AssertionFailure( "cannot force version increment on non-versioned entity" );
 		}
 
 		if ( isVersionPropertyGenerated() ) {
 			// the difficulty here is exactly what do we update in order to
 			// force the version to be incremented in the db...
 			throw new HibernateException( "LockMode.FORCE is currently not supported for generated version properties" );
 		}
 
 		Object nextVersion = getVersionType().next( currentVersion, session );
-        if ( LOG.isTraceEnabled() ) {
+		if ( LOG.isTraceEnabled() ) {
 			LOG.trace(
 					"Forcing version increment [" + MessageHelper.infoString( this, id, getFactory() ) + "; "
 							+ getVersionType().toLoggableString( currentVersion, getFactory() ) + " -> "
 							+ getVersionType().toLoggableString( nextVersion, getFactory() ) + "]"
 			);
 		}
 
 		// todo : cache this sql...
 		String versionIncrementString = generateVersionIncrementUpdateString();
 		PreparedStatement st = null;
 		try {
 			st = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( versionIncrementString, false );
 			try {
 				getVersionType().nullSafeSet( st, nextVersion, 1, session );
 				getIdentifierType().nullSafeSet( st, id, 2, session );
 				getVersionType().nullSafeSet( st, currentVersion, 2 + getIdentifierColumnSpan(), session );
 				int rows = session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st );
 				if ( rows != 1 ) {
 					throw new StaleObjectStateException( getEntityName(), id );
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( st );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not retrieve version: " +
-					MessageHelper.infoString( this, id, getFactory() ),
+							MessageHelper.infoString( this, id, getFactory() ),
 					getVersionSelectString()
 			);
 		}
 
 		return nextVersion;
 	}
 
 	private String generateVersionIncrementUpdateString() {
 		Update update = new Update( getFactory().getDialect() );
 		update.setTableName( getTableName( 0 ) );
 		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			update.setComment( "forced version increment" );
 		}
 		update.addColumn( getVersionColumnName() );
 		update.addPrimaryKeyColumns( getIdentifierColumnNames() );
 		update.setVersionColumnName( getVersionColumnName() );
 		return update.toStatementString();
 	}
 
 	/**
 	 * Retrieve the version number
 	 */
 	public Object getCurrentVersion(Serializable id, SessionImplementor session) throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Getting version: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		try {
 			PreparedStatement st = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( getVersionSelectString() );
 			try {
 				getIdentifierType().nullSafeSet( st, id, 1, session );
 				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
 					if ( !rs.next() ) {
 						return null;
 					}
 					if ( !isVersioned() ) {
 						return this;
 					}
 					return getVersionType().nullSafeGet( rs, getVersionColumnName(), session, null );
 				}
 				finally {
 					session.getJdbcCoordinator().getResourceRegistry().release( rs, st );
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( st );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
-		catch ( SQLException e ) {
+		catch (SQLException e) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not retrieve version: " + MessageHelper.infoString( this, id, getFactory() ),
 					getVersionSelectString()
 			);
 		}
 	}
 
 	protected void initLockers() {
 		lockers.put( LockMode.READ, generateLocker( LockMode.READ ) );
 		lockers.put( LockMode.UPGRADE, generateLocker( LockMode.UPGRADE ) );
 		lockers.put( LockMode.UPGRADE_NOWAIT, generateLocker( LockMode.UPGRADE_NOWAIT ) );
 		lockers.put( LockMode.UPGRADE_SKIPLOCKED, generateLocker( LockMode.UPGRADE_SKIPLOCKED ) );
 		lockers.put( LockMode.FORCE, generateLocker( LockMode.FORCE ) );
 		lockers.put( LockMode.PESSIMISTIC_READ, generateLocker( LockMode.PESSIMISTIC_READ ) );
 		lockers.put( LockMode.PESSIMISTIC_WRITE, generateLocker( LockMode.PESSIMISTIC_WRITE ) );
 		lockers.put( LockMode.PESSIMISTIC_FORCE_INCREMENT, generateLocker( LockMode.PESSIMISTIC_FORCE_INCREMENT ) );
 		lockers.put( LockMode.OPTIMISTIC, generateLocker( LockMode.OPTIMISTIC ) );
 		lockers.put( LockMode.OPTIMISTIC_FORCE_INCREMENT, generateLocker( LockMode.OPTIMISTIC_FORCE_INCREMENT ) );
 	}
 
 	protected LockingStrategy generateLocker(LockMode lockMode) {
 		return factory.getDialect().getLockingStrategy( this, lockMode );
 	}
 
 	private LockingStrategy getLocker(LockMode lockMode) {
-		return ( LockingStrategy ) lockers.get( lockMode );
+		return (LockingStrategy) lockers.get( lockMode );
 	}
 
 	public void lock(
 			Serializable id,
-	        Object version,
-	        Object object,
-	        LockMode lockMode,
-	        SessionImplementor session) throws HibernateException {
+			Object version,
+			Object object,
+			LockMode lockMode,
+			SessionImplementor session) throws HibernateException {
 		getLocker( lockMode ).lock( id, version, object, LockOptions.WAIT_FOREVER, session );
 	}
 
 	public void lock(
 			Serializable id,
-	        Object version,
-	        Object object,
-	        LockOptions lockOptions,
-	        SessionImplementor session) throws HibernateException {
+			Object version,
+			Object object,
+			LockOptions lockOptions,
+			SessionImplementor session) throws HibernateException {
 		getLocker( lockOptions.getLockMode() ).lock( id, version, object, lockOptions.getTimeOut(), session );
 	}
 
 	public String getRootTableName() {
 		return getSubclassTableName( 0 );
 	}
 
 	public String getRootTableAlias(String drivingAlias) {
 		return drivingAlias;
 	}
 
 	public String[] getRootTableIdentifierColumnNames() {
 		return getRootTableKeyColumnNames();
 	}
 
 	public String[] toColumns(String alias, String propertyName) throws QueryException {
 		return propertyMapping.toColumns( alias, propertyName );
 	}
 
 	public String[] toColumns(String propertyName) throws QueryException {
 		return propertyMapping.getColumnNames( propertyName );
 	}
 
 	public Type toType(String propertyName) throws QueryException {
 		return propertyMapping.toType( propertyName );
 	}
 
 	public String[] getPropertyColumnNames(String propertyName) {
 		return propertyMapping.getColumnNames( propertyName );
 	}
 
 	/**
 	 * Warning:
 	 * When there are duplicated property names in the subclasses
 	 * of the class, this method may return the wrong table
 	 * number for the duplicated subclass property (note that
 	 * SingleTableEntityPersister defines an overloaded form
 	 * which takes the entity name.
 	 */
 	public int getSubclassPropertyTableNumber(String propertyPath) {
 		String rootPropertyName = StringHelper.root( propertyPath );
-		Type type = propertyMapping.toType(rootPropertyName);
+		Type type = propertyMapping.toType( rootPropertyName );
 		if ( type.isAssociationType() ) {
-			AssociationType assocType = ( AssociationType ) type;
+			AssociationType assocType = (AssociationType) type;
 			if ( assocType.useLHSPrimaryKey() ) {
 				// performance op to avoid the array search
 				return 0;
 			}
 			else if ( type.isCollectionType() ) {
 				// properly handle property-ref-based associations
 				rootPropertyName = assocType.getLHSPropertyName();
 			}
 		}
 		//Enable for HHH-440, which we don't like:
 		/*if ( type.isComponentType() && !propertyName.equals(rootPropertyName) ) {
 			String unrooted = StringHelper.unroot(propertyName);
 			int idx = ArrayHelper.indexOf( getSubclassColumnClosure(), unrooted );
 			if ( idx != -1 ) {
 				return getSubclassColumnTableNumberClosure()[idx];
 			}
 		}*/
-		int index = ArrayHelper.indexOf( getSubclassPropertyNameClosure(), rootPropertyName); //TODO: optimize this better!
-		return index==-1 ? 0 : getSubclassPropertyTableNumber(index);
+		int index = ArrayHelper.indexOf(
+				getSubclassPropertyNameClosure(),
+				rootPropertyName
+		); //TODO: optimize this better!
+		return index == -1 ? 0 : getSubclassPropertyTableNumber( index );
 	}
 
 	public Declarer getSubclassPropertyDeclarer(String propertyPath) {
 		int tableIndex = getSubclassPropertyTableNumber( propertyPath );
 		if ( tableIndex == 0 ) {
 			return Declarer.CLASS;
 		}
 		else if ( isClassOrSuperclassTable( tableIndex ) ) {
 			return Declarer.SUPERCLASS;
 		}
 		else {
 			return Declarer.SUBCLASS;
 		}
 	}
 
 	private DiscriminatorMetadata discriminatorMetadata;
 
 	public DiscriminatorMetadata getTypeDiscriminatorMetadata() {
 		if ( discriminatorMetadata == null ) {
 			discriminatorMetadata = buildTypeDiscriminatorMetadata();
 		}
 		return discriminatorMetadata;
 	}
 
 	private DiscriminatorMetadata buildTypeDiscriminatorMetadata() {
 		return new DiscriminatorMetadata() {
 			public String getSqlFragment(String sqlQualificationAlias) {
 				return toColumns( sqlQualificationAlias, ENTITY_CLASS )[0];
 			}
 
 			public Type getResolutionType() {
 				return new DiscriminatorType( getDiscriminatorType(), AbstractEntityPersister.this );
 			}
 		};
 	}
 
 	public static String generateTableAlias(String rootAlias, int tableNumber) {
 		if ( tableNumber == 0 ) {
 			return rootAlias;
 		}
 		StringBuilder buf = new StringBuilder().append( rootAlias );
 		if ( !rootAlias.endsWith( "_" ) ) {
 			buf.append( '_' );
 		}
 		return buf.append( tableNumber ).append( '_' ).toString();
 	}
 
 	public String[] toColumns(String name, final int i) {
 		final String alias = generateTableAlias( name, getSubclassPropertyTableNumber( i ) );
 		String[] cols = getSubclassPropertyColumnNames( i );
 		String[] templates = getSubclassPropertyFormulaTemplateClosure()[i];
 		String[] result = new String[cols.length];
 		for ( int j = 0; j < cols.length; j++ ) {
 			if ( cols[j] == null ) {
 				result[j] = StringHelper.replace( templates[j], Template.TEMPLATE, alias );
 			}
 			else {
 				result[j] = StringHelper.qualify( alias, cols[j] );
 			}
 		}
 		return result;
 	}
 
 	private int getSubclassPropertyIndex(String propertyName) {
-		return ArrayHelper.indexOf(subclassPropertyNameClosure, propertyName);
+		return ArrayHelper.indexOf( subclassPropertyNameClosure, propertyName );
 	}
 
 	protected String[] getPropertySubclassNames() {
 		return propertySubclassNames;
 	}
 
 	public String[] getPropertyColumnNames(int i) {
 		return propertyColumnNames[i];
 	}
 
 	public String[] getPropertyColumnWriters(int i) {
 		return propertyColumnWriters[i];
 	}
 
 	protected int getPropertyColumnSpan(int i) {
 		return propertyColumnSpans[i];
 	}
 
 	protected boolean hasFormulaProperties() {
 		return hasFormulaProperties;
 	}
 
 	public FetchMode getFetchMode(int i) {
 		return subclassPropertyFetchModeClosure[i];
 	}
 
 	public CascadeStyle getCascadeStyle(int i) {
 		return subclassPropertyCascadeStyleClosure[i];
 	}
 
 	public Type getSubclassPropertyType(int i) {
 		return subclassPropertyTypeClosure[i];
 	}
 
 	public String getSubclassPropertyName(int i) {
 		return subclassPropertyNameClosure[i];
 	}
 
 	public int countSubclassProperties() {
 		return subclassPropertyTypeClosure.length;
 	}
 
 	public String[] getSubclassPropertyColumnNames(int i) {
 		return subclassPropertyColumnNameClosure[i];
 	}
 
 	public boolean isDefinedOnSubclass(int i) {
 		return propertyDefinedOnSubclass[i];
 	}
 
 	@Override
 	public String[][] getSubclassPropertyFormulaTemplateClosure() {
 		return subclassPropertyFormulaTemplateClosure;
 	}
 
 	protected Type[] getSubclassPropertyTypeClosure() {
 		return subclassPropertyTypeClosure;
 	}
 
 	protected String[][] getSubclassPropertyColumnNameClosure() {
 		return subclassPropertyColumnNameClosure;
 	}
 
 	public String[][] getSubclassPropertyColumnReaderClosure() {
 		return subclassPropertyColumnReaderClosure;
 	}
 
 	public String[][] getSubclassPropertyColumnReaderTemplateClosure() {
 		return subclassPropertyColumnReaderTemplateClosure;
 	}
 
 	protected String[] getSubclassPropertyNameClosure() {
 		return subclassPropertyNameClosure;
 	}
 
 	@Override
 	public int[] resolveAttributeIndexes(Set<String> properties) {
 		Iterator<String> iter = properties.iterator();
 		int[] fields = new int[properties.size()];
 		int counter = 0;
-		while(iter.hasNext()) {
+		while ( iter.hasNext() ) {
 			Integer index = entityMetamodel.getPropertyIndexOrNull( iter.next() );
 			if ( index != null ) {
 				fields[counter++] = index;
 			}
 		}
 		return fields;
 	}
 
 	protected String[] getSubclassPropertySubclassNameClosure() {
 		return subclassPropertySubclassNameClosure;
 	}
 
 	protected String[] getSubclassColumnClosure() {
 		return subclassColumnClosure;
 	}
 
 	protected String[] getSubclassColumnAliasClosure() {
 		return subclassColumnAliasClosure;
 	}
 
 	public String[] getSubclassColumnReaderTemplateClosure() {
 		return subclassColumnReaderTemplateClosure;
 	}
 
 	protected String[] getSubclassFormulaClosure() {
 		return subclassFormulaClosure;
 	}
 
 	protected String[] getSubclassFormulaTemplateClosure() {
 		return subclassFormulaTemplateClosure;
 	}
 
 	protected String[] getSubclassFormulaAliasClosure() {
 		return subclassFormulaAliasClosure;
 	}
 
 	public String[] getSubclassPropertyColumnAliases(String propertyName, String suffix) {
-		String[] rawAliases = ( String[] ) subclassPropertyAliases.get( propertyName );
+		String[] rawAliases = (String[]) subclassPropertyAliases.get( propertyName );
 
 		if ( rawAliases == null ) {
 			return null;
 		}
 
 		String[] result = new String[rawAliases.length];
 		for ( int i = 0; i < rawAliases.length; i++ ) {
 			result[i] = new Alias( suffix ).toUnquotedAliasString( rawAliases[i] );
 		}
 		return result;
 	}
 
 	public String[] getSubclassPropertyColumnNames(String propertyName) {
 		//TODO: should we allow suffixes on these ?
-		return ( String[] ) subclassPropertyColumnNames.get( propertyName );
+		return (String[]) subclassPropertyColumnNames.get( propertyName );
 	}
 
 
-
 	//This is really ugly, but necessary:
+
 	/**
 	 * Must be called by subclasses, at the end of their constructors
 	 */
 	protected void initSubclassPropertyAliasesMap(PersistentClass model) throws MappingException {
 
 		// ALIASES
 		internalInitSubclassPropertyAliasesMap( null, model.getSubclassPropertyClosureIterator() );
 
 		// aliases for identifier ( alias.id ); skip if the entity defines a non-id property named 'id'
-		if ( ! entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
+		if ( !entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 			subclassPropertyAliases.put( ENTITY_ID, getIdentifierAliases() );
 			subclassPropertyColumnNames.put( ENTITY_ID, getIdentifierColumnNames() );
 		}
 
 		// aliases named identifier ( alias.idname )
 		if ( hasIdentifierProperty() ) {
 			subclassPropertyAliases.put( getIdentifierPropertyName(), getIdentifierAliases() );
 			subclassPropertyColumnNames.put( getIdentifierPropertyName(), getIdentifierColumnNames() );
 		}
 
 		// aliases for composite-id's
 		if ( getIdentifierType().isComponentType() ) {
 			// Fetch embedded identifiers propertynames from the "virtual" identifier component
-			CompositeType componentId = ( CompositeType ) getIdentifierType();
+			CompositeType componentId = (CompositeType) getIdentifierType();
 			String[] idPropertyNames = componentId.getPropertyNames();
 			String[] idAliases = getIdentifierAliases();
 			String[] idColumnNames = getIdentifierColumnNames();
 
 			for ( int i = 0; i < idPropertyNames.length; i++ ) {
 				if ( entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 					subclassPropertyAliases.put(
 							ENTITY_ID + "." + idPropertyNames[i],
-							new String[] { idAliases[i] }
+							new String[] {idAliases[i]}
 					);
 					subclassPropertyColumnNames.put(
 							ENTITY_ID + "." + getIdentifierPropertyName() + "." + idPropertyNames[i],
-							new String[] { idColumnNames[i] }
+							new String[] {idColumnNames[i]}
 					);
 				}
 //				if (hasIdentifierProperty() && !ENTITY_ID.equals( getIdentifierPropertyName() ) ) {
 				if ( hasIdentifierProperty() ) {
 					subclassPropertyAliases.put(
 							getIdentifierPropertyName() + "." + idPropertyNames[i],
-							new String[] { idAliases[i] }
+							new String[] {idAliases[i]}
 					);
 					subclassPropertyColumnNames.put(
 							getIdentifierPropertyName() + "." + idPropertyNames[i],
-							new String[] { idColumnNames[i] }
+							new String[] {idColumnNames[i]}
 					);
 				}
 				else {
 					// embedded composite ids ( alias.idname1, alias.idname2 )
-					subclassPropertyAliases.put( idPropertyNames[i], new String[] { idAliases[i] } );
-					subclassPropertyColumnNames.put( idPropertyNames[i],  new String[] { idColumnNames[i] } );
+					subclassPropertyAliases.put( idPropertyNames[i], new String[] {idAliases[i]} );
+					subclassPropertyColumnNames.put( idPropertyNames[i], new String[] {idColumnNames[i]} );
 				}
 			}
 		}
 
 		if ( entityMetamodel.isPolymorphic() ) {
-			subclassPropertyAliases.put( ENTITY_CLASS, new String[] { getDiscriminatorAlias() } );
-			subclassPropertyColumnNames.put( ENTITY_CLASS, new String[] { getDiscriminatorColumnName() } );
+			subclassPropertyAliases.put( ENTITY_CLASS, new String[] {getDiscriminatorAlias()} );
+			subclassPropertyColumnNames.put( ENTITY_CLASS, new String[] {getDiscriminatorColumnName()} );
 		}
 
 	}
 
 	private void internalInitSubclassPropertyAliasesMap(String path, Iterator propertyIterator) {
 		while ( propertyIterator.hasNext() ) {
 
-			Property prop = ( Property ) propertyIterator.next();
+			Property prop = (Property) propertyIterator.next();
 			String propname = path == null ? prop.getName() : path + "." + prop.getName();
 			if ( prop.isComposite() ) {
-				Component component = ( Component ) prop.getValue();
+				Component component = (Component) prop.getValue();
 				Iterator compProps = component.getPropertyIterator();
 				internalInitSubclassPropertyAliasesMap( propname, compProps );
 			}
 			else {
 				String[] aliases = new String[prop.getColumnSpan()];
 				String[] cols = new String[prop.getColumnSpan()];
 				Iterator colIter = prop.getColumnIterator();
 				int l = 0;
 				while ( colIter.hasNext() ) {
-					Selectable thing = ( Selectable ) colIter.next();
+					Selectable thing = (Selectable) colIter.next();
 					aliases[l] = thing.getAlias( getFactory().getDialect(), prop.getValue().getTable() );
 					cols[l] = thing.getText( getFactory().getDialect() ); // TODO: skip formulas?
 					l++;
 				}
 
 				subclassPropertyAliases.put( propname, aliases );
 				subclassPropertyColumnNames.put( propname, cols );
 			}
 		}
 
 	}
 
 	public Object loadByUniqueKey(
 			String propertyName,
 			Object uniqueKey,
 			SessionImplementor session) throws HibernateException {
 		return getAppropriateUniqueKeyLoader( propertyName, session ).loadByUniqueKey( session, uniqueKey );
 	}
 
 	private EntityLoader getAppropriateUniqueKeyLoader(String propertyName, SessionImplementor session) {
 		final boolean useStaticLoader = !session.getLoadQueryInfluencers().hasEnabledFilters()
 				&& !session.getLoadQueryInfluencers().hasEnabledFetchProfiles()
-				&& propertyName.indexOf('.')<0; //ugly little workaround for fact that createUniqueKeyLoaders() does not handle component properties
+				&& propertyName.indexOf( '.' ) < 0; //ugly little workaround for fact that createUniqueKeyLoaders() does not handle component properties
 
 		if ( useStaticLoader ) {
-			return ( EntityLoader ) uniqueKeyLoaders.get( propertyName );
+			return (EntityLoader) uniqueKeyLoaders.get( propertyName );
 		}
 		else {
 			return createUniqueKeyLoader(
 					propertyMapping.toType( propertyName ),
 					propertyMapping.toColumns( propertyName ),
 					session.getLoadQueryInfluencers()
 			);
 		}
 	}
 
 	public int getPropertyIndex(String propertyName) {
-		return entityMetamodel.getPropertyIndex(propertyName);
+		return entityMetamodel.getPropertyIndex( propertyName );
 	}
 
 	protected void createUniqueKeyLoaders() throws MappingException {
 		Type[] propertyTypes = getPropertyTypes();
 		String[] propertyNames = getPropertyNames();
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( propertyUniqueness[i] ) {
 				//don't need filters for the static loaders
 				uniqueKeyLoaders.put(
 						propertyNames[i],
 						createUniqueKeyLoader(
 								propertyTypes[i],
 								getPropertyColumnNames( i ),
 								LoadQueryInfluencers.NONE
 						)
 				);
 				//TODO: create uk loaders for component properties
 			}
 		}
 	}
 
 	private EntityLoader createUniqueKeyLoader(
 			Type uniqueKeyType,
 			String[] columns,
 			LoadQueryInfluencers loadQueryInfluencers) {
 		if ( uniqueKeyType.isEntityType() ) {
-			String className = ( ( EntityType ) uniqueKeyType ).getAssociatedEntityName();
+			String className = ( (EntityType) uniqueKeyType ).getAssociatedEntityName();
 			uniqueKeyType = getFactory().getEntityPersister( className ).getIdentifierType();
 		}
 		return new EntityLoader(
 				this,
 				columns,
 				uniqueKeyType,
 				1,
 				LockMode.NONE,
 				getFactory(),
 				loadQueryInfluencers
 		);
 	}
 
 	protected String getSQLWhereString(String alias) {
 		return StringHelper.replace( sqlWhereStringTemplate, Template.TEMPLATE, alias );
 	}
 
 	protected boolean hasWhere() {
 		return sqlWhereString != null;
 	}
 
 	private void initOrdinaryPropertyPaths(Mapping mapping) throws MappingException {
 		for ( int i = 0; i < getSubclassPropertyNameClosure().length; i++ ) {
 			propertyMapping.initPropertyPaths(
 					getSubclassPropertyNameClosure()[i],
 					getSubclassPropertyTypeClosure()[i],
 					getSubclassPropertyColumnNameClosure()[i],
 					getSubclassPropertyColumnReaderClosure()[i],
 					getSubclassPropertyColumnReaderTemplateClosure()[i],
 					getSubclassPropertyFormulaTemplateClosure()[i],
 					mapping
 			);
 		}
 	}
 
 	private void initIdentifierPropertyPaths(Mapping mapping) throws MappingException {
 		String idProp = getIdentifierPropertyName();
 		if ( idProp != null ) {
-			propertyMapping.initPropertyPaths( idProp, getIdentifierType(), getIdentifierColumnNames(),
-					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping );
+			propertyMapping.initPropertyPaths(
+					idProp, getIdentifierType(), getIdentifierColumnNames(),
+					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping
+			);
 		}
 		if ( entityMetamodel.getIdentifierProperty().isEmbedded() ) {
-			propertyMapping.initPropertyPaths( null, getIdentifierType(), getIdentifierColumnNames(),
-					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping );
+			propertyMapping.initPropertyPaths(
+					null, getIdentifierType(), getIdentifierColumnNames(),
+					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping
+			);
 		}
-		if ( ! entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
-			propertyMapping.initPropertyPaths( ENTITY_ID, getIdentifierType(), getIdentifierColumnNames(),
-					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping );
+		if ( !entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
+			propertyMapping.initPropertyPaths(
+					ENTITY_ID, getIdentifierType(), getIdentifierColumnNames(),
+					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping
+			);
 		}
 	}
 
 	private void initDiscriminatorPropertyPath(Mapping mapping) throws MappingException {
 		propertyMapping.initPropertyPaths(
 				ENTITY_CLASS,
 				getDiscriminatorType(),
 				new String[] {getDiscriminatorColumnName()},
 				new String[] {getDiscriminatorColumnReaders()},
 				new String[] {getDiscriminatorColumnReaderTemplate()},
 				new String[] {getDiscriminatorFormulaTemplate()},
 				getFactory()
 		);
 	}
 
 	protected void initPropertyPaths(Mapping mapping) throws MappingException {
-		initOrdinaryPropertyPaths(mapping);
-		initOrdinaryPropertyPaths(mapping); //do two passes, for collection property-ref!
-		initIdentifierPropertyPaths(mapping);
+		initOrdinaryPropertyPaths( mapping );
+		initOrdinaryPropertyPaths( mapping ); //do two passes, for collection property-ref!
+		initIdentifierPropertyPaths( mapping );
 		if ( entityMetamodel.isPolymorphic() ) {
 			initDiscriminatorPropertyPath( mapping );
 		}
 	}
 
 	protected UniqueEntityLoader createEntityLoader(
 			LockMode lockMode,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		//TODO: disable batch loading if lockMode > READ?
 		return BatchingEntityLoaderBuilder.getBuilder( getFactory() )
 				.buildLoader( this, batchSize, lockMode, getFactory(), loadQueryInfluencers );
 	}
 
 	protected UniqueEntityLoader createEntityLoader(
 			LockOptions lockOptions,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		//TODO: disable batch loading if lockMode > READ?
 		return BatchingEntityLoaderBuilder.getBuilder( getFactory() )
 				.buildLoader( this, batchSize, lockOptions, getFactory(), loadQueryInfluencers );
 	}
 
 	/**
 	 * Used internally to create static loaders.  These are the default set of loaders used to handle get()/load()
 	 * processing.  lock() handling is done by the LockingStrategy instances (see {@link #getLocker})
 	 *
 	 * @param lockMode The lock mode to apply to the thing being loaded.
+	 *
 	 * @return
 	 *
 	 * @throws MappingException
 	 */
 	protected UniqueEntityLoader createEntityLoader(LockMode lockMode) throws MappingException {
 		return createEntityLoader( lockMode, LoadQueryInfluencers.NONE );
 	}
 
-	protected boolean check(int rows, Serializable id, int tableNumber, Expectation expectation, PreparedStatement statement) throws HibernateException {
+	protected boolean check(
+			int rows,
+			Serializable id,
+			int tableNumber,
+			Expectation expectation,
+			PreparedStatement statement) throws HibernateException {
 		try {
 			expectation.verifyOutcome( rows, statement, -1 );
 		}
-		catch( StaleStateException e ) {
+		catch (StaleStateException e) {
 			if ( !isNullableTable( tableNumber ) ) {
 				if ( getFactory().getStatistics().isStatisticsEnabled() ) {
 					getFactory().getStatisticsImplementor()
 							.optimisticFailure( getEntityName() );
 				}
 				throw new StaleObjectStateException( getEntityName(), id );
 			}
 			return false;
 		}
-		catch( TooManyRowsAffectedException e ) {
+		catch (TooManyRowsAffectedException e) {
 			throw new HibernateException(
 					"Duplicate identifier in table for: " +
-					MessageHelper.infoString( this, id, getFactory() )
+							MessageHelper.infoString( this, id, getFactory() )
 			);
 		}
-		catch ( Throwable t ) {
+		catch (Throwable t) {
 			return false;
 		}
 		return true;
 	}
 
 	protected String generateUpdateString(boolean[] includeProperty, int j, boolean useRowId) {
 		return generateUpdateString( includeProperty, j, null, useRowId );
 	}
 
 	/**
 	 * Generate the SQL that updates a row by id (and version)
 	 */
-	protected String generateUpdateString(final boolean[] includeProperty,
-										  final int j,
-										  final Object[] oldFields,
-										  final boolean useRowId) {
+	protected String generateUpdateString(
+			final boolean[] includeProperty,
+			final int j,
+			final Object[] oldFields,
+			final boolean useRowId) {
 
 		Update update = new Update( getFactory().getDialect() ).setTableName( getTableName( j ) );
 
 		// select the correct row by either pk or rowid
 		if ( useRowId ) {
-			update.addPrimaryKeyColumns( new String[]{rowIdName} ); //TODO: eventually, rowIdName[j]
+			update.addPrimaryKeyColumns( new String[] {rowIdName} ); //TODO: eventually, rowIdName[j]
 		}
 		else {
 			update.addPrimaryKeyColumns( getKeyColumns( j ) );
 		}
 
 		boolean hasColumns = false;
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
-			if ( includeProperty[i] && isPropertyOfTable( i, j ) 
+			if ( includeProperty[i] && isPropertyOfTable( i, j )
 					&& !lobProperties.contains( i ) ) {
 				// this is a property of the table, which we are updating
-				update.addColumns( getPropertyColumnNames(i),
-						propertyColumnUpdateable[i], propertyColumnWriters[i] );
+				update.addColumns(
+						getPropertyColumnNames( i ),
+						propertyColumnUpdateable[i], propertyColumnWriters[i]
+				);
 				hasColumns = hasColumns || getPropertyColumnSpan( i ) > 0;
 			}
 		}
-		
+
 		// HHH-4635
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) ) {
 				// this property belongs on the table and is to be inserted
-				update.addColumns( getPropertyColumnNames(i),
-						propertyColumnUpdateable[i], propertyColumnWriters[i] );
+				update.addColumns(
+						getPropertyColumnNames( i ),
+						propertyColumnUpdateable[i], propertyColumnWriters[i]
+				);
 				hasColumns = true;
 			}
 		}
 
 		if ( j == 0 && isVersioned() && entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.VERSION ) {
 			// this is the root (versioned) table, and we are using version-based
 			// optimistic locking;  if we are not updating the version, also don't
 			// check it (unless this is a "generated" version column)!
 			if ( checkVersion( includeProperty ) ) {
 				update.setVersionColumnName( getVersionColumnName() );
 				hasColumns = true;
 			}
 		}
 		else if ( isAllOrDirtyOptLocking() && oldFields != null ) {
 			// we are using "all" or "dirty" property-based optimistic locking
 
 			boolean[] includeInWhere = entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.ALL
-					? getPropertyUpdateability() //optimistic-lock="all", include all updatable properties
-					: includeProperty; 			 //optimistic-lock="dirty", include all properties we are updating this time
+					?
+					getPropertyUpdateability()
+					//optimistic-lock="all", include all updatable properties
+					:
+					includeProperty;             //optimistic-lock="dirty", include all properties we are updating this time
 
 			boolean[] versionability = getPropertyVersionability();
 			Type[] types = getPropertyTypes();
 			for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 				boolean include = includeInWhere[i] &&
 						isPropertyOfTable( i, j ) &&
 						versionability[i];
 				if ( include ) {
 					// this property belongs to the table, and it is not specifically
 					// excluded from optimistic locking by optimistic-lock="false"
 					String[] propertyColumnNames = getPropertyColumnNames( i );
 					String[] propertyColumnWriters = getPropertyColumnWriters( i );
 					boolean[] propertyNullness = types[i].toColumnNullness( oldFields[i], getFactory() );
-					for ( int k=0; k<propertyNullness.length; k++ ) {
+					for ( int k = 0; k < propertyNullness.length; k++ ) {
 						if ( propertyNullness[k] ) {
 							update.addWhereColumn( propertyColumnNames[k], "=" + propertyColumnWriters[k] );
 						}
 						else {
 							update.addWhereColumn( propertyColumnNames[k], " is null" );
 						}
 					}
 				}
 			}
 
 		}
 
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			update.setComment( "update " + getEntityName() );
 		}
 
 		return hasColumns ? update.toStatementString() : null;
 	}
 
 	private boolean checkVersion(final boolean[] includeProperty) {
-		return includeProperty[ getVersionProperty() ]
+		return includeProperty[getVersionProperty()]
 				|| entityMetamodel.isVersionGenerated();
 	}
 
 	protected String generateInsertString(boolean[] includeProperty, int j) {
 		return generateInsertString( false, includeProperty, j );
 	}
 
 	protected String generateInsertString(boolean identityInsert, boolean[] includeProperty) {
 		return generateInsertString( identityInsert, includeProperty, 0 );
 	}
 
 	/**
 	 * Generate the SQL that inserts a row
 	 */
 	protected String generateInsertString(boolean identityInsert, boolean[] includeProperty, int j) {
 
 		// todo : remove the identityInsert param and variations;
 		//   identity-insert strings are now generated from generateIdentityInsertString()
 
 		Insert insert = new Insert( getFactory().getDialect() )
 				.setTableName( getTableName( j ) );
 
 		// add normal properties
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			// the incoming 'includeProperty' array only accounts for insertable defined at the root level, it
 			// does not account for partially generated composites etc.  We also need to account for generation
 			// values
 			if ( isPropertyOfTable( i, j ) ) {
 				if ( !lobProperties.contains( i ) ) {
 					final InDatabaseValueGenerationStrategy generationStrategy = entityMetamodel.getInDatabaseValueGenerationStrategies()[i];
 					if ( generationStrategy != null && generationStrategy.getGenerationTiming().includesInsert() ) {
 						if ( generationStrategy.referenceColumnsInSql() ) {
 							final String[] values;
 							if ( generationStrategy.getReferencedColumnValues() == null ) {
 								values = propertyColumnWriters[i];
 							}
 							else {
 								final int numberOfColumns = propertyColumnWriters[i].length;
-								values = new String[ numberOfColumns ];
+								values = new String[numberOfColumns];
 								for ( int x = 0; x < numberOfColumns; x++ ) {
 									if ( generationStrategy.getReferencedColumnValues()[x] != null ) {
 										values[x] = generationStrategy.getReferencedColumnValues()[x];
 									}
 									else {
 										values[x] = propertyColumnWriters[i][x];
 									}
 								}
 							}
-							insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], values );
+							insert.addColumns( getPropertyColumnNames( i ), propertyColumnInsertable[i], values );
 						}
 					}
 					else if ( includeProperty[i] ) {
-						insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], propertyColumnWriters[i] );
+						insert.addColumns(
+								getPropertyColumnNames( i ),
+								propertyColumnInsertable[i],
+								propertyColumnWriters[i]
+						);
 					}
 				}
 			}
 		}
 
 		// add the discriminator
 		if ( j == 0 ) {
 			addDiscriminatorToInsert( insert );
 		}
 
 		// add the primary key
 		if ( j == 0 && identityInsert ) {
 			insert.addIdentityColumn( getKeyColumns( 0 )[0] );
 		}
 		else {
 			insert.addColumns( getKeyColumns( j ) );
 		}
 
 		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			insert.setComment( "insert " + getEntityName() );
 		}
-		
+
 		// HHH-4635
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) ) {
 				// this property belongs on the table and is to be inserted
 				insert.addColumns(
-						getPropertyColumnNames(i),
+						getPropertyColumnNames( i ),
 						propertyColumnInsertable[i],
 						propertyColumnWriters[i]
 				);
 			}
 		}
 
 		String result = insert.toStatementString();
 
 		// append the SQL to return the generated identifier
 		if ( j == 0 && identityInsert && useInsertSelectIdentity() ) { //TODO: suck into Insert
 			result = getFactory().getDialect().appendIdentitySelectToInsert( result );
 		}
 
 		return result;
 	}
 
 	/**
 	 * Used to generate an insery statement against the root table in the
 	 * case of identifier generation strategies where the insert statement
 	 * executions actually generates the identifier value.
 	 *
 	 * @param includeProperty indices of the properties to include in the
 	 * insert statement.
+	 *
 	 * @return The insert SQL statement string
 	 */
 	protected String generateIdentityInsertString(boolean[] includeProperty) {
 		Insert insert = identityDelegate.prepareIdentifierGeneratingInsert();
 		insert.setTableName( getTableName( 0 ) );
 
 		// add normal properties except lobs
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, 0 ) && !lobProperties.contains( i ) ) {
 				// this property belongs on the table and is to be inserted
-				insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], propertyColumnWriters[i] );
+				insert.addColumns( getPropertyColumnNames( i ), propertyColumnInsertable[i], propertyColumnWriters[i] );
 			}
 		}
 
 		// HHH-4635 & HHH-8103
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, 0 ) ) {
-				insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], propertyColumnWriters[i] );
+				insert.addColumns( getPropertyColumnNames( i ), propertyColumnInsertable[i], propertyColumnWriters[i] );
 			}
 		}
 
 		// add the discriminator
 		addDiscriminatorToInsert( insert );
 
 		// delegate already handles PK columns
 
 		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			insert.setComment( "insert " + getEntityName() );
 		}
 
 		return insert.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL that deletes a row by id (and version)
 	 */
 	protected String generateDeleteString(int j) {
 		final Delete delete = new Delete()
 				.setTableName( getTableName( j ) )
 				.addPrimaryKeyColumns( getKeyColumns( j ) );
 		if ( j == 0 ) {
 			delete.setVersionColumnName( getVersionColumnName() );
 		}
 		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			delete.setComment( "delete " + getEntityName() );
 		}
 		return delete.toStatementString();
 	}
 
 	protected int dehydrate(
 			Serializable id,
 			Object[] fields,
 			boolean[] includeProperty,
 			boolean[][] includeColumns,
 			int j,
 			PreparedStatement st,
 			SessionImplementor session,
 			boolean isUpdate) throws HibernateException, SQLException {
 		return dehydrate( id, fields, null, includeProperty, includeColumns, j, st, session, 1, isUpdate );
 	}
 
 	/**
 	 * Marshall the fields of a persistent instance to a prepared statement
 	 */
 	protected int dehydrate(
 			final Serializable id,
 			final Object[] fields,
 			final Object rowId,
 			final boolean[] includeProperty,
 			final boolean[][] includeColumns,
 			final int j,
 			final PreparedStatement ps,
 			final SessionImplementor session,
 			int index,
-			boolean isUpdate ) throws SQLException, HibernateException {
+			boolean isUpdate) throws SQLException, HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Dehydrating entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j )
-					&& !lobProperties.contains( i )) {
+					&& !lobProperties.contains( i ) ) {
 				getPropertyTypes()[i].nullSafeSet( ps, fields[i], index, includeColumns[i], session );
 				index += ArrayHelper.countTrue( includeColumns[i] ); //TODO:  this is kinda slow...
 			}
 		}
-		
+
 		if ( !isUpdate ) {
 			index += dehydrateId( id, rowId, ps, session, index );
 		}
-		
+
 		// HHH-4635
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) ) {
 				getPropertyTypes()[i].nullSafeSet( ps, fields[i], index, includeColumns[i], session );
 				index += ArrayHelper.countTrue( includeColumns[i] ); //TODO:  this is kinda slow...
 			}
 		}
-		
+
 		if ( isUpdate ) {
 			index += dehydrateId( id, rowId, ps, session, index );
 		}
 
 		return index;
 
 	}
-	
-	private int dehydrateId( 
+
+	private int dehydrateId(
 			final Serializable id,
 			final Object rowId,
 			final PreparedStatement ps,
 			final SessionImplementor session,
-			int index ) throws SQLException {
+			int index) throws SQLException {
 		if ( rowId != null ) {
 			ps.setObject( index, rowId );
 			return 1;
 		}
 		else if ( id != null ) {
 			getIdentifierType().nullSafeSet( ps, id, index, session );
 			return getIdentifierColumnSpan();
 		}
 		return 0;
 	}
 
 	/**
 	 * Unmarshall the fields of a persistent instance from a result set,
 	 * without resolving associations or collections. Question: should
 	 * this really be here, or should it be sent back to Loader?
 	 */
 	public Object[] hydrate(
 			final ResultSet rs,
 			final Serializable id,
 			final Object object,
 			final Loadable rootLoadable,
 			final String[][] suffixedPropertyColumns,
 			final boolean allProperties,
 			final SessionImplementor session) throws SQLException, HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Hydrating entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		final AbstractEntityPersister rootPersister = (AbstractEntityPersister) rootLoadable;
 
 		final boolean hasDeferred = rootPersister.hasSequentialSelect();
 		PreparedStatement sequentialSelect = null;
 		ResultSet sequentialResultSet = null;
 		boolean sequentialSelectEmpty = false;
 		try {
 
 			if ( hasDeferred ) {
 				final String sql = rootPersister.getSequentialSelect( getEntityName() );
 				if ( sql != null ) {
 					//TODO: I am not so sure about the exception handling in this bit!
 					sequentialSelect = session
 							.getJdbcCoordinator()
 							.getStatementPreparer()
 							.prepareStatement( sql );
 					rootPersister.getIdentifierType().nullSafeSet( sequentialSelect, id, 1, session );
 					sequentialResultSet = session.getJdbcCoordinator().getResultSetReturn().extract( sequentialSelect );
 					if ( !sequentialResultSet.next() ) {
 						// TODO: Deal with the "optional" attribute in the <join> mapping;
 						// this code assumes that optional defaults to "true" because it
 						// doesn't actually seem to work in the fetch="join" code
 						//
 						// Note that actual proper handling of optional-ality here is actually
 						// more involved than this patch assumes.  Remember that we might have
 						// multiple <join/> mappings associated with a single entity.  Really
 						// a couple of things need to happen to properly handle optional here:
 						//  1) First and foremost, when handling multiple <join/>s, we really
 						//      should be using the entity root table as the driving table;
 						//      another option here would be to choose some non-optional joined
 						//      table to use as the driving table.  In all likelihood, just using
 						//      the root table is much simplier
 						//  2) Need to add the FK columns corresponding to each joined table
 						//      to the generated select list; these would then be used when
 						//      iterating the result set to determine whether all non-optional
 						//      data is present
 						// My initial thoughts on the best way to deal with this would be
 						// to introduce a new SequentialSelect abstraction that actually gets
 						// generated in the persisters (ok, SingleTable...) and utilized here.
 						// It would encapsulated all this required optional-ality checking...
 						sequentialSelectEmpty = true;
 					}
 				}
 			}
 
 			final String[] propNames = getPropertyNames();
 			final Type[] types = getPropertyTypes();
 			final Object[] values = new Object[types.length];
 			final boolean[] laziness = getPropertyLaziness();
 			final String[] propSubclassNames = getSubclassPropertySubclassNameClosure();
 
 			for ( int i = 0; i < types.length; i++ ) {
 				if ( !propertySelectable[i] ) {
 					values[i] = BackrefPropertyAccessor.UNKNOWN;
 				}
 				else if ( allProperties || !laziness[i] ) {
 					//decide which ResultSet to get the property value from:
 					final boolean propertyIsDeferred = hasDeferred &&
 							rootPersister.isSubclassPropertyDeferred( propNames[i], propSubclassNames[i] );
 					if ( propertyIsDeferred && sequentialSelectEmpty ) {
 						values[i] = null;
 					}
 					else {
 						final ResultSet propertyResultSet = propertyIsDeferred ? sequentialResultSet : rs;
-						final String[] cols = propertyIsDeferred ? propertyColumnAliases[i] : suffixedPropertyColumns[i];
+						final String[] cols = propertyIsDeferred ?
+								propertyColumnAliases[i] :
+								suffixedPropertyColumns[i];
 						values[i] = types[i].hydrate( propertyResultSet, cols, session, object );
 					}
 				}
 				else {
 					values[i] = LazyPropertyInitializer.UNFETCHED_PROPERTY;
 				}
 			}
 
 			if ( sequentialResultSet != null ) {
 				session.getJdbcCoordinator().getResourceRegistry().release( sequentialResultSet, sequentialSelect );
 			}
 
 			return values;
 
 		}
 		finally {
 			if ( sequentialSelect != null ) {
 				session.getJdbcCoordinator().getResourceRegistry().release( sequentialSelect );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 	}
 
 	protected boolean useInsertSelectIdentity() {
 		return !useGetGeneratedKeys() && getFactory().getDialect().supportsInsertSelectIdentity();
 	}
 
 	protected boolean useGetGeneratedKeys() {
-		return getFactory().getSettings().isGetGeneratedKeysEnabled();
+		return getFactory().getSessionFactoryOptions().isGetGeneratedKeysEnabled();
 	}
 
 	protected String getSequentialSelect(String entityName) {
-		throw new UnsupportedOperationException("no sequential selects");
+		throw new UnsupportedOperationException( "no sequential selects" );
 	}
 
 	/**
 	 * Perform an SQL INSERT, and then retrieve a generated identifier.
 	 * <p/>
 	 * This form is used for PostInsertIdentifierGenerator-style ids (IDENTITY,
 	 * select, etc).
 	 */
 	protected Serializable insert(
 			final Object[] fields,
 			final boolean[] notNull,
 			String sql,
 			final Object object,
 			final SessionImplementor session) throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Inserting entity: {0} (native id)", getEntityName() );
 			if ( isVersioned() ) {
 				LOG.tracev( "Version: {0}", Versioning.getVersion( fields, this ) );
 			}
 		}
 
 		Binder binder = new Binder() {
 			public void bindValues(PreparedStatement ps) throws SQLException {
 				dehydrate( null, fields, notNull, propertyColumnInsertable, 0, ps, session, false );
 			}
+
 			public Object getEntity() {
 				return object;
 			}
 		};
 
 		return identityDelegate.performInsert( sql, session, binder );
 	}
 
 	public String getIdentitySelectString() {
 		//TODO: cache this in an instvar
 		return getFactory().getDialect().getIdentitySelectString(
 				getTableName( 0 ),
 				getKeyColumns( 0 )[0],
 				getIdentifierType().sqlTypes( getFactory() )[0]
 		);
 	}
 
 	public String getSelectByUniqueKeyString(String propertyName) {
 		return new SimpleSelect( getFactory().getDialect() )
-			.setTableName( getTableName(0) )
-			.addColumns( getKeyColumns(0) )
-			.addCondition( getPropertyColumnNames(propertyName), "=?" )
-			.toStatementString();
+				.setTableName( getTableName( 0 ) )
+				.addColumns( getKeyColumns( 0 ) )
+				.addCondition( getPropertyColumnNames( propertyName ), "=?" )
+				.toStatementString();
 	}
 
 	private BasicBatchKey inserBatchKey;
 
 	/**
 	 * Perform an SQL INSERT.
 	 * <p/>
 	 * This for is used for all non-root tables as well as the root table
 	 * in cases where the identifier value is known before the insert occurs.
 	 */
 	protected void insert(
 			final Serializable id,
 			final Object[] fields,
 			final boolean[] notNull,
 			final int j,
 			final String sql,
 			final Object object,
 			final SessionImplementor session) throws HibernateException {
 
 		if ( isInverseTable( j ) ) {
 			return;
 		}
 
 		//note: it is conceptually possible that a UserType could map null to
 		//	  a non-null value, so the following is arguable:
 		if ( isNullableTable( j ) && isAllNull( fields, j ) ) {
 			return;
 		}
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Inserting entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 			if ( j == 0 && isVersioned() ) {
 				LOG.tracev( "Version: {0}", Versioning.getVersion( fields, this ) );
 			}
 		}
 
 		// TODO : shouldn't inserts be Expectations.NONE?
 		final Expectation expectation = Expectations.appropriateExpectation( insertResultCheckStyles[j] );
 		// we can't batch joined inserts, *especially* not if it is an identity insert;
 		// nor can we batch statements where the expectation is based on an output param
 		final boolean useBatch = j == 0 && expectation.canBeBatched();
 		if ( useBatch && inserBatchKey == null ) {
 			inserBatchKey = new BasicBatchKey(
 					getEntityName() + "#INSERT",
 					expectation
 			);
 		}
 		final boolean callable = isInsertCallable( j );
 
 		try {
 			// Render the SQL query
 			final PreparedStatement insert;
 			if ( useBatch ) {
 				insert = session
 						.getJdbcCoordinator()
 						.getBatch( inserBatchKey )
 						.getBatchStatement( sql, callable );
 			}
 			else {
 				insert = session
 						.getJdbcCoordinator()
 						.getStatementPreparer()
 						.prepareStatement( sql, callable );
 			}
 
 			try {
 				int index = 1;
 				index += expectation.prepare( insert );
 
 				// Write the values of fields onto the prepared statement - we MUST use the state at the time the
 				// insert was issued (cos of foreign key constraints). Not necessarily the object's current state
 
 				dehydrate( id, fields, null, notNull, propertyColumnInsertable, j, insert, session, index, false );
 
 				if ( useBatch ) {
 					session.getJdbcCoordinator().getBatch( inserBatchKey ).addToBatch();
 				}
 				else {
-					expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( insert ), insert, -1 );
+					expectation.verifyOutcome(
+							session.getJdbcCoordinator()
+									.getResultSetReturn()
+									.executeUpdate( insert ), insert, -1
+					);
 				}
 
 			}
-			catch ( SQLException e ) {
+			catch (SQLException e) {
 				if ( useBatch ) {
 					session.getJdbcCoordinator().abortBatch();
 				}
 				throw e;
 			}
 			finally {
 				if ( !useBatch ) {
 					session.getJdbcCoordinator().getResourceRegistry().release( insert );
 					session.getJdbcCoordinator().afterStatementExecution();
 				}
 			}
 		}
-		catch ( SQLException e ) {
+		catch (SQLException e) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not insert: " + MessageHelper.infoString( this ),
 					sql
 			);
 		}
 
 	}
 
 	/**
 	 * Perform an SQL UPDATE or SQL INSERT
 	 */
 	protected void updateOrInsert(
 			final Serializable id,
 			final Object[] fields,
 			final Object[] oldFields,
 			final Object rowId,
 			final boolean[] includeProperty,
 			final int j,
 			final Object oldVersion,
 			final Object object,
 			final String sql,
 			final SessionImplementor session) throws HibernateException {
 
 		if ( !isInverseTable( j ) ) {
 
 			final boolean isRowToUpdate;
 			if ( isNullableTable( j ) && oldFields != null && isAllNull( oldFields, j ) ) {
 				//don't bother trying to update, we know there is no row there yet
 				isRowToUpdate = false;
 			}
 			else if ( isNullableTable( j ) && isAllNull( fields, j ) ) {
 				//if all fields are null, we might need to delete existing row
 				isRowToUpdate = true;
 				delete( id, oldVersion, j, object, getSQLDeleteStrings()[j], session, null );
 			}
 			else {
 				//there is probably a row there, so try to update
 				//if no rows were updated, we will find out
-				isRowToUpdate = update( id, fields, oldFields, rowId, includeProperty, j, oldVersion, object, sql, session );
+				isRowToUpdate = update(
+						id,
+						fields,
+						oldFields,
+						rowId,
+						includeProperty,
+						j,
+						oldVersion,
+						object,
+						sql,
+						session
+				);
 			}
 
 			if ( !isRowToUpdate && !isAllNull( fields, j ) ) {
 				// assume that the row was not there since it previously had only null
 				// values, so do an INSERT instead
 				//TODO: does not respect dynamic-insert
 				insert( id, fields, getPropertyInsertability(), j, getSQLInsertStrings()[j], object, session );
 			}
 
 		}
 
 	}
 
 	private BasicBatchKey updateBatchKey;
 
 	protected boolean update(
 			final Serializable id,
 			final Object[] fields,
 			final Object[] oldFields,
 			final Object rowId,
 			final boolean[] includeProperty,
 			final int j,
 			final Object oldVersion,
 			final Object object,
 			final String sql,
 			final SessionImplementor session) throws HibernateException {
 
 		final Expectation expectation = Expectations.appropriateExpectation( updateResultCheckStyles[j] );
 		final boolean useBatch = j == 0 && expectation.canBeBatched() && isBatchable(); //note: updates to joined tables can't be batched...
 		if ( useBatch && updateBatchKey == null ) {
 			updateBatchKey = new BasicBatchKey(
 					getEntityName() + "#UPDATE",
 					expectation
 			);
 		}
 		final boolean callable = isUpdateCallable( j );
 		final boolean useVersion = j == 0 && isVersioned();
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Updating entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
-			if ( useVersion )
+			if ( useVersion ) {
 				LOG.tracev( "Existing version: {0} -> New version:{1}", oldVersion, fields[getVersionProperty()] );
+			}
 		}
 
 		try {
 			int index = 1; // starting index
 			final PreparedStatement update;
 			if ( useBatch ) {
 				update = session
 						.getJdbcCoordinator()
 						.getBatch( updateBatchKey )
 						.getBatchStatement( sql, callable );
 			}
 			else {
 				update = session
 						.getJdbcCoordinator()
 						.getStatementPreparer()
 						.prepareStatement( sql, callable );
 			}
 
 			try {
-				index+= expectation.prepare( update );
+				index += expectation.prepare( update );
 
 				//Now write the values of fields onto the prepared statement
-				index = dehydrate( id, fields, rowId, includeProperty, propertyColumnUpdateable, j, update, session, index, true );
+				index = dehydrate(
+						id,
+						fields,
+						rowId,
+						includeProperty,
+						propertyColumnUpdateable,
+						j,
+						update,
+						session,
+						index,
+						true
+				);
 
 				// Write any appropriate versioning conditional parameters
 				if ( useVersion && entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.VERSION ) {
 					if ( checkVersion( includeProperty ) ) {
 						getVersionType().nullSafeSet( update, oldVersion, index, session );
 					}
 				}
 				else if ( isAllOrDirtyOptLocking() && oldFields != null ) {
 					boolean[] versionability = getPropertyVersionability(); //TODO: is this really necessary????
 					boolean[] includeOldField = entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.ALL
 							? getPropertyUpdateability()
 							: includeProperty;
 					Type[] types = getPropertyTypes();
 					for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 						boolean include = includeOldField[i] &&
 								isPropertyOfTable( i, j ) &&
 								versionability[i]; //TODO: is this really necessary????
 						if ( include ) {
 							boolean[] settable = types[i].toColumnNullness( oldFields[i], getFactory() );
 							types[i].nullSafeSet(
 									update,
 									oldFields[i],
 									index,
 									settable,
 									session
-								);
-							index += ArrayHelper.countTrue(settable);
+							);
+							index += ArrayHelper.countTrue( settable );
 						}
 					}
 				}
 
 				if ( useBatch ) {
 					session.getJdbcCoordinator().getBatch( updateBatchKey ).addToBatch();
 					return true;
 				}
 				else {
-					return check( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( update ), id, j, expectation, update );
+					return check(
+							session.getJdbcCoordinator().getResultSetReturn().executeUpdate( update ),
+							id,
+							j,
+							expectation,
+							update
+					);
 				}
 
 			}
-			catch ( SQLException e ) {
+			catch (SQLException e) {
 				if ( useBatch ) {
 					session.getJdbcCoordinator().abortBatch();
 				}
 				throw e;
 			}
 			finally {
 				if ( !useBatch ) {
 					session.getJdbcCoordinator().getResourceRegistry().release( update );
 					session.getJdbcCoordinator().afterStatementExecution();
 				}
 			}
 
 		}
-		catch ( SQLException e ) {
+		catch (SQLException e) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not update: " + MessageHelper.infoString( this, id, getFactory() ),
 					sql
 			);
 		}
 	}
 
 	private BasicBatchKey deleteBatchKey;
 
 	/**
 	 * Perform an SQL DELETE
 	 */
 	protected void delete(
 			final Serializable id,
 			final Object version,
 			final int j,
 			final Object object,
 			final String sql,
 			final SessionImplementor session,
 			final Object[] loadedState) throws HibernateException {
 
 		if ( isInverseTable( j ) ) {
 			return;
 		}
 
 		final boolean useVersion = j == 0 && isVersioned();
 		final boolean callable = isDeleteCallable( j );
 		final Expectation expectation = Expectations.appropriateExpectation( deleteResultCheckStyles[j] );
 		final boolean useBatch = j == 0 && isBatchable() && expectation.canBeBatched();
 		if ( useBatch && deleteBatchKey == null ) {
 			deleteBatchKey = new BasicBatchKey(
 					getEntityName() + "#DELETE",
 					expectation
 			);
 		}
 
 		final boolean traceEnabled = LOG.isTraceEnabled();
 		if ( traceEnabled ) {
 			LOG.tracev( "Deleting entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
-			if ( useVersion )
+			if ( useVersion ) {
 				LOG.tracev( "Version: {0}", version );
+			}
 		}
 
 		if ( isTableCascadeDeleteEnabled( j ) ) {
 			if ( traceEnabled ) {
 				LOG.tracev( "Delete handled by foreign key constraint: {0}", getTableName( j ) );
 			}
 			return; //EARLY EXIT!
 		}
 
 		try {
 			//Render the SQL query
 			PreparedStatement delete;
 			int index = 1;
 			if ( useBatch ) {
 				delete = session
 						.getJdbcCoordinator()
 						.getBatch( deleteBatchKey )
 						.getBatchStatement( sql, callable );
 			}
 			else {
 				delete = session
 						.getJdbcCoordinator()
 						.getStatementPreparer()
 						.prepareStatement( sql, callable );
 			}
 
 			try {
 
 				index += expectation.prepare( delete );
 
 				// Do the key. The key is immutable so we can use the _current_ object state - not necessarily
 				// the state at the time the delete was issued
 				getIdentifierType().nullSafeSet( delete, id, index, session );
 				index += getIdentifierColumnSpan();
 
 				// We should use the _current_ object state (ie. after any updates that occurred during flush)
 
 				if ( useVersion ) {
 					getVersionType().nullSafeSet( delete, version, index, session );
 				}
 				else if ( isAllOrDirtyOptLocking() && loadedState != null ) {
 					boolean[] versionability = getPropertyVersionability();
 					Type[] types = getPropertyTypes();
 					for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 						if ( isPropertyOfTable( i, j ) && versionability[i] ) {
 							// this property belongs to the table and it is not specifically
 							// excluded from optimistic locking by optimistic-lock="false"
 							boolean[] settable = types[i].toColumnNullness( loadedState[i], getFactory() );
 							types[i].nullSafeSet( delete, loadedState[i], index, settable, session );
 							index += ArrayHelper.countTrue( settable );
 						}
 					}
 				}
 
 				if ( useBatch ) {
 					session.getJdbcCoordinator().getBatch( deleteBatchKey ).addToBatch();
 				}
 				else {
-					check( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( delete ), id, j, expectation, delete );
+					check(
+							session.getJdbcCoordinator().getResultSetReturn().executeUpdate( delete ),
+							id,
+							j,
+							expectation,
+							delete
+					);
 				}
 
 			}
-			catch ( SQLException sqle ) {
+			catch (SQLException sqle) {
 				if ( useBatch ) {
 					session.getJdbcCoordinator().abortBatch();
 				}
 				throw sqle;
 			}
 			finally {
 				if ( !useBatch ) {
 					session.getJdbcCoordinator().getResourceRegistry().release( delete );
 					session.getJdbcCoordinator().afterStatementExecution();
 				}
 			}
 
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not delete: " +
-					MessageHelper.infoString( this, id, getFactory() ),
+							MessageHelper.infoString( this, id, getFactory() ),
 					sql
 			);
 
 		}
 
 	}
 
 	private String[] getUpdateStrings(boolean byRowId, boolean lazy) {
 		if ( byRowId ) {
 			return lazy ? getSQLLazyUpdateByRowIdStrings() : getSQLUpdateByRowIdStrings();
 		}
 		else {
 			return lazy ? getSQLLazyUpdateStrings() : getSQLUpdateStrings();
 		}
 	}
 
 	/**
 	 * Update an object
 	 */
 	public void update(
 			final Serializable id,
 			final Object[] fields,
 			final int[] dirtyFields,
 			final boolean hasDirtyCollection,
 			final Object[] oldFields,
 			final Object oldVersion,
 			final Object object,
 			final Object rowId,
 			final SessionImplementor session) throws HibernateException {
 
 		// apply any pre-update in-memory value generation
 		if ( getEntityMetamodel().hasPreUpdateGeneratedValues() ) {
 			final InMemoryValueGenerationStrategy[] strategies = getEntityMetamodel().getInMemoryValueGenerationStrategies();
 			for ( int i = 0; i < strategies.length; i++ ) {
 				if ( strategies[i] != null && strategies[i].getGenerationTiming().includesUpdate() ) {
 					fields[i] = strategies[i].getValueGenerator().generateValue( (Session) session, object );
 					setPropertyValue( object, i, fields[i] );
 					// todo : probably best to add to dirtyFields if not-null
 				}
 			}
 		}
 
 		//note: dirtyFields==null means we had no snapshot, and we couldn't get one using select-before-update
 		//	  oldFields==null just means we had no snapshot to begin with (we might have used select-before-update to get the dirtyFields)
 
 		final boolean[] tableUpdateNeeded = getTableUpdateNeeded( dirtyFields, hasDirtyCollection );
 		final int span = getTableSpan();
 
 		final boolean[] propsToUpdate;
 		final String[] updateStrings;
 		EntityEntry entry = session.getPersistenceContext().getEntry( object );
 
 		// Ensure that an immutable or non-modifiable entity is not being updated unless it is
 		// in the process of being deleted.
-		if ( entry == null && ! isMutable() ) {
+		if ( entry == null && !isMutable() ) {
 			throw new IllegalStateException( "Updating immutable entity that is not in session yet!" );
 		}
 		if ( ( entityMetamodel.isDynamicUpdate() && dirtyFields != null ) ) {
 			// We need to generate the UPDATE SQL when dynamic-update="true"
 			propsToUpdate = getPropertiesToUpdate( dirtyFields, hasDirtyCollection );
 			// don't need to check laziness (dirty checking algorithm handles that)
 			updateStrings = new String[span];
 			for ( int j = 0; j < span; j++ ) {
 				updateStrings[j] = tableUpdateNeeded[j] ?
 						generateUpdateString( propsToUpdate, j, oldFields, j == 0 && rowId != null ) :
 						null;
 			}
 		}
-		else if ( ! isModifiableEntity( entry ) ) {
+		else if ( !isModifiableEntity( entry ) ) {
 			// We need to generate UPDATE SQL when a non-modifiable entity (e.g., read-only or immutable)
 			// needs:
 			// - to have references to transient entities set to null before being deleted
 			// - to have version incremented do to a "dirty" association
 			// If dirtyFields == null, then that means that there are no dirty properties to
 			// to be updated; an empty array for the dirty fields needs to be passed to
 			// getPropertiesToUpdate() instead of null.
 			propsToUpdate = getPropertiesToUpdate(
 					( dirtyFields == null ? ArrayHelper.EMPTY_INT_ARRAY : dirtyFields ),
 					hasDirtyCollection
 			);
 			// don't need to check laziness (dirty checking algorithm handles that)
 			updateStrings = new String[span];
 			for ( int j = 0; j < span; j++ ) {
 				updateStrings[j] = tableUpdateNeeded[j] ?
 						generateUpdateString( propsToUpdate, j, oldFields, j == 0 && rowId != null ) :
 						null;
 			}
 		}
 		else {
 			// For the case of dynamic-update="false", or no snapshot, we use the static SQL
 			updateStrings = getUpdateStrings(
 					rowId != null,
 					hasUninitializedLazyProperties( object )
 			);
 			propsToUpdate = getPropertyUpdateability( object );
 		}
 
 		for ( int j = 0; j < span; j++ ) {
 			// Now update only the tables with dirty properties (and the table with the version number)
 			if ( tableUpdateNeeded[j] ) {
 				updateOrInsert(
 						id,
 						fields,
 						oldFields,
 						j == 0 ? rowId : null,
 						propsToUpdate,
 						j,
 						oldVersion,
 						object,
 						updateStrings[j],
 						session
 				);
 			}
 		}
 	}
 
 	public Serializable insert(Object[] fields, Object object, SessionImplementor session)
 			throws HibernateException {
 		// apply any pre-insert in-memory value generation
 		preInsertInMemoryValueGeneration( fields, object, session );
-		
+
 		final int span = getTableSpan();
 		final Serializable id;
 		if ( entityMetamodel.isDynamicInsert() ) {
 			// For the case of dynamic-insert="true", we need to generate the INSERT SQL
 			boolean[] notNull = getPropertiesToInsert( fields );
 			id = insert( fields, notNull, generateInsertString( true, notNull ), object, session );
 			for ( int j = 1; j < span; j++ ) {
 				insert( id, fields, notNull, j, generateInsertString( notNull, j ), object, session );
 			}
 		}
 		else {
 			// For the case of dynamic-insert="false", use the static SQL
 			id = insert( fields, getPropertyInsertability(), getSQLIdentityInsertString(), object, session );
 			for ( int j = 1; j < span; j++ ) {
 				insert( id, fields, getPropertyInsertability(), j, getSQLInsertStrings()[j], object, session );
 			}
 		}
 		return id;
 	}
 
 	public void insert(Serializable id, Object[] fields, Object object, SessionImplementor session) {
 		// apply any pre-insert in-memory value generation
 		preInsertInMemoryValueGeneration( fields, object, session );
 
 		final int span = getTableSpan();
 		if ( entityMetamodel.isDynamicInsert() ) {
 			// For the case of dynamic-insert="true", we need to generate the INSERT SQL
 			boolean[] notNull = getPropertiesToInsert( fields );
 			for ( int j = 0; j < span; j++ ) {
 				insert( id, fields, notNull, j, generateInsertString( notNull, j ), object, session );
 			}
 		}
 		else {
 			// For the case of dynamic-insert="false", use the static SQL
 			for ( int j = 0; j < span; j++ ) {
 				insert( id, fields, getPropertyInsertability(), j, getSQLInsertStrings()[j], object, session );
 			}
 		}
 	}
-	
+
 	private void preInsertInMemoryValueGeneration(Object[] fields, Object object, SessionImplementor session) {
 		if ( getEntityMetamodel().hasPreInsertGeneratedValues() ) {
 			final InMemoryValueGenerationStrategy[] strategies = getEntityMetamodel().getInMemoryValueGenerationStrategies();
 			for ( int i = 0; i < strategies.length; i++ ) {
 				if ( strategies[i] != null && strategies[i].getGenerationTiming().includesInsert() ) {
 					fields[i] = strategies[i].getValueGenerator().generateValue( (Session) session, object );
 					setPropertyValue( object, i, fields[i] );
 				}
 			}
 		}
 	}
 
 	/**
 	 * Delete an object
 	 */
 	public void delete(Serializable id, Object version, Object object, SessionImplementor session)
 			throws HibernateException {
 		final int span = getTableSpan();
 		boolean isImpliedOptimisticLocking = !entityMetamodel.isVersioned() && isAllOrDirtyOptLocking();
 		Object[] loadedState = null;
 		if ( isImpliedOptimisticLocking ) {
 			// need to treat this as if it where optimistic-lock="all" (dirty does *not* make sense);
 			// first we need to locate the "loaded" state
 			//
 			// Note, it potentially could be a proxy, so doAfterTransactionCompletion the location the safe way...
 			final EntityKey key = session.generateEntityKey( id, this );
 			Object entity = session.getPersistenceContext().getEntity( key );
 			if ( entity != null ) {
 				EntityEntry entry = session.getPersistenceContext().getEntry( entity );
 				loadedState = entry.getLoadedState();
 			}
 		}
 
 		final String[] deleteStrings;
 		if ( isImpliedOptimisticLocking && loadedState != null ) {
 			// we need to utilize dynamic delete statements
 			deleteStrings = generateSQLDeletStrings( loadedState );
 		}
 		else {
 			// otherwise, utilize the static delete statements
 			deleteStrings = getSQLDeleteStrings();
 		}
 
 		for ( int j = span - 1; j >= 0; j-- ) {
 			delete( id, version, j, object, deleteStrings[j], session, loadedState );
 		}
 
 	}
 
 	private boolean isAllOrDirtyOptLocking() {
 		return entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.DIRTY
 				|| entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.ALL;
 	}
 
 	private String[] generateSQLDeletStrings(Object[] loadedState) {
 		int span = getTableSpan();
 		String[] deleteStrings = new String[span];
 		for ( int j = span - 1; j >= 0; j-- ) {
 			Delete delete = new Delete()
 					.setTableName( getTableName( j ) )
 					.addPrimaryKeyColumns( getKeyColumns( j ) );
 			if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 				delete.setComment( "delete " + getEntityName() + " [" + j + "]" );
 			}
 
 			boolean[] versionability = getPropertyVersionability();
 			Type[] types = getPropertyTypes();
 			for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 				if ( isPropertyOfTable( i, j ) && versionability[i] ) {
 					// this property belongs to the table and it is not specifically
 					// excluded from optimistic locking by optimistic-lock="false"
 					String[] propertyColumnNames = getPropertyColumnNames( i );
 					boolean[] propertyNullness = types[i].toColumnNullness( loadedState[i], getFactory() );
 					for ( int k = 0; k < propertyNullness.length; k++ ) {
 						if ( propertyNullness[k] ) {
 							delete.addWhereFragment( propertyColumnNames[k] + " = ?" );
 						}
 						else {
 							delete.addWhereFragment( propertyColumnNames[k] + " is null" );
 						}
 					}
 				}
 			}
 			deleteStrings[j] = delete.toStatementString();
 		}
 		return deleteStrings;
 	}
 
 	protected void logStaticSQL() {
-        if ( LOG.isDebugEnabled() ) {
-            LOG.debugf( "Static SQL for entity: %s", getEntityName() );
-            if ( sqlLazySelectString != null ) {
+		if ( LOG.isDebugEnabled() ) {
+			LOG.debugf( "Static SQL for entity: %s", getEntityName() );
+			if ( sqlLazySelectString != null ) {
 				LOG.debugf( " Lazy select: %s", sqlLazySelectString );
 			}
-            if ( sqlVersionSelectString != null ) {
+			if ( sqlVersionSelectString != null ) {
 				LOG.debugf( " Version select: %s", sqlVersionSelectString );
 			}
-            if ( sqlSnapshotSelectString != null ) {
+			if ( sqlSnapshotSelectString != null ) {
 				LOG.debugf( " Snapshot select: %s", sqlSnapshotSelectString );
 			}
 			for ( int j = 0; j < getTableSpan(); j++ ) {
-                LOG.debugf( " Insert %s: %s", j, getSQLInsertStrings()[j] );
-                LOG.debugf( " Update %s: %s", j, getSQLUpdateStrings()[j] );
-                LOG.debugf( " Delete %s: %s", j, getSQLDeleteStrings()[j] );
+				LOG.debugf( " Insert %s: %s", j, getSQLInsertStrings()[j] );
+				LOG.debugf( " Update %s: %s", j, getSQLUpdateStrings()[j] );
+				LOG.debugf( " Delete %s: %s", j, getSQLDeleteStrings()[j] );
 			}
-            if ( sqlIdentityInsertString != null ) {
+			if ( sqlIdentityInsertString != null ) {
 				LOG.debugf( " Identity insert: %s", sqlIdentityInsertString );
 			}
-            if ( sqlUpdateByRowIdString != null ) {
+			if ( sqlUpdateByRowIdString != null ) {
 				LOG.debugf( " Update by row id (all fields): %s", sqlUpdateByRowIdString );
 			}
-            if ( sqlLazyUpdateByRowIdString != null ) {
+			if ( sqlLazyUpdateByRowIdString != null ) {
 				LOG.debugf( " Update by row id (non-lazy fields): %s", sqlLazyUpdateByRowIdString );
 			}
-            if ( sqlInsertGeneratedValuesSelectString != null ) {
+			if ( sqlInsertGeneratedValuesSelectString != null ) {
 				LOG.debugf( " Insert-generated property select: %s", sqlInsertGeneratedValuesSelectString );
 			}
-            if ( sqlUpdateGeneratedValuesSelectString != null ) {
+			if ( sqlUpdateGeneratedValuesSelectString != null ) {
 				LOG.debugf( " Update-generated property select: %s", sqlUpdateGeneratedValuesSelectString );
 			}
 		}
 	}
 
 	@Override
 	public String filterFragment(String alias, Map enabledFilters) throws MappingException {
 		final StringBuilder sessionFilterFragment = new StringBuilder();
-		filterHelper.render( sessionFilterFragment, getFilterAliasGenerator(alias), enabledFilters );
+		filterHelper.render( sessionFilterFragment, getFilterAliasGenerator( alias ), enabledFilters );
 		return sessionFilterFragment.append( filterFragment( alias ) ).toString();
 	}
 
 	@Override
 	public String filterFragment(String alias, Map enabledFilters, Set<String> treatAsDeclarations) {
 		final StringBuilder sessionFilterFragment = new StringBuilder();
-		filterHelper.render( sessionFilterFragment, getFilterAliasGenerator(alias), enabledFilters );
+		filterHelper.render( sessionFilterFragment, getFilterAliasGenerator( alias ), enabledFilters );
 		return sessionFilterFragment.append( filterFragment( alias, treatAsDeclarations ) ).toString();
 	}
 
 	public String generateFilterConditionAlias(String rootAlias) {
 		return rootAlias;
 	}
 
 	public String oneToManyFilterFragment(String alias) throws MappingException {
 		return "";
 	}
 
 	@Override
 	public String oneToManyFilterFragment(String alias, Set<String> treatAsDeclarations) {
 		return oneToManyFilterFragment( alias );
 	}
 
 	@Override
 	public String fromJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		// NOTE : Not calling createJoin here is just a performance optimization
 		return getSubclassTableSpan() == 1
 				? ""
-				: createJoin( alias, innerJoin, includeSubclasses, Collections.<String>emptySet() ).toFromFragmentString();
+				: createJoin(
+				alias,
+				innerJoin,
+				includeSubclasses,
+				Collections.<String>emptySet()
+		).toFromFragmentString();
 	}
 
 	@Override
 	public String fromJoinFragment(
 			String alias,
 			boolean innerJoin,
 			boolean includeSubclasses,
 			Set<String> treatAsDeclarations) {
 		// NOTE : Not calling createJoin here is just a performance optimization
 		return getSubclassTableSpan() == 1
 				? ""
 				: createJoin( alias, innerJoin, includeSubclasses, treatAsDeclarations ).toFromFragmentString();
 	}
 
 	@Override
 	public String whereJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		// NOTE : Not calling createJoin here is just a performance optimization
 		return getSubclassTableSpan() == 1
 				? ""
-				: createJoin( alias, innerJoin, includeSubclasses, Collections.<String>emptySet() ).toWhereFragmentString();
+				: createJoin(
+				alias,
+				innerJoin,
+				includeSubclasses,
+				Collections.<String>emptySet()
+		).toWhereFragmentString();
 	}
 
 	@Override
 	public String whereJoinFragment(
 			String alias,
 			boolean innerJoin,
 			boolean includeSubclasses,
 			Set<String> treatAsDeclarations) {
 		// NOTE : Not calling createJoin here is just a performance optimization
 		return getSubclassTableSpan() == 1
 				? ""
 				: createJoin( alias, innerJoin, includeSubclasses, treatAsDeclarations ).toWhereFragmentString();
 	}
 
 	protected boolean isSubclassTableLazy(int j) {
 		return false;
 	}
 
-	protected JoinFragment createJoin(String name, boolean innerJoin, boolean includeSubclasses, Set<String> treatAsDeclarations) {
+	protected JoinFragment createJoin(
+			String name,
+			boolean innerJoin,
+			boolean includeSubclasses,
+			Set<String> treatAsDeclarations) {
 		// IMPL NOTE : all joins join to the pk of the driving table
 		final String[] idCols = StringHelper.qualify( name, getIdentifierColumnNames() );
 		final JoinFragment join = getFactory().getDialect().createOuterJoinFragment();
 		final int tableSpan = getSubclassTableSpan();
 		// IMPL NOTE : notice that we skip the first table; it is the driving table!
 		for ( int j = 1; j < tableSpan; j++ ) {
 			final JoinType joinType = determineSubclassTableJoinType(
 					j,
 					innerJoin,
 					includeSubclasses,
 					treatAsDeclarations
 			);
 
 			if ( joinType != null && joinType != JoinType.NONE ) {
 				join.addJoin(
 						getSubclassTableName( j ),
 						generateTableAlias( name, j ),
 						idCols,
 						getSubclassTableKeyColumns( j ),
 						joinType
 				);
 			}
 		}
 		return join;
 	}
 
 	protected JoinType determineSubclassTableJoinType(
 			int subclassTableNumber,
 			boolean canInnerJoin,
 			boolean includeSubclasses,
 			Set<String> treatAsDeclarations) {
 
 		if ( isClassOrSuperclassTable( subclassTableNumber ) ) {
 			final boolean shouldInnerJoin = canInnerJoin
 					&& !isInverseTable( subclassTableNumber )
 					&& !isNullableTable( subclassTableNumber );
 			// the table is either this persister's driving table or (one of) its super class persister's driving
 			// tables which can be inner joined as long as the `shouldInnerJoin` condition resolves to true
 			return shouldInnerJoin ? JoinType.INNER_JOIN : JoinType.LEFT_OUTER_JOIN;
 		}
 
 		// otherwise we have a subclass table and need to look a little deeper...
 
 		// IMPL NOTE : By default includeSubclasses indicates that all subclasses should be joined and that each
 		// subclass ought to be joined by outer-join.  However, TREAT-AS always requires that an inner-join be used
 		// so we give TREAT-AS higher precedence...
 
 		if ( isSubclassTableIndicatedByTreatAsDeclarations( subclassTableNumber, treatAsDeclarations ) ) {
 			return JoinType.INNER_JOIN;
 		}
 
 		if ( includeSubclasses
 				&& !isSubclassTableSequentialSelect( subclassTableNumber )
 				&& !isSubclassTableLazy( subclassTableNumber ) ) {
 			return JoinType.LEFT_OUTER_JOIN;
 		}
 
 		return JoinType.NONE;
 	}
 
 	protected boolean isSubclassTableIndicatedByTreatAsDeclarations(
 			int subclassTableNumber,
 			Set<String> treatAsDeclarations) {
 		return false;
 	}
 
 
 	protected JoinFragment createJoin(int[] tableNumbers, String drivingAlias) {
 		final String[] keyCols = StringHelper.qualify( drivingAlias, getSubclassTableKeyColumns( tableNumbers[0] ) );
 		final JoinFragment jf = getFactory().getDialect().createOuterJoinFragment();
 		// IMPL NOTE : notice that we skip the first table; it is the driving table!
 		for ( int i = 1; i < tableNumbers.length; i++ ) {
 			final int j = tableNumbers[i];
-			jf.addJoin( getSubclassTableName( j ),
+			jf.addJoin(
+					getSubclassTableName( j ),
 					generateTableAlias( getRootAlias(), j ),
 					keyCols,
 					getSubclassTableKeyColumns( j ),
 					isInverseSubclassTable( j ) || isNullableSubclassTable( j )
 							? JoinType.LEFT_OUTER_JOIN
 							: JoinType.INNER_JOIN
 			);
 		}
 		return jf;
 	}
 
-	protected SelectFragment createSelect(final int[] subclassColumnNumbers,
-										  final int[] subclassFormulaNumbers) {
+	protected SelectFragment createSelect(
+			final int[] subclassColumnNumbers,
+			final int[] subclassFormulaNumbers) {
 
 		SelectFragment selectFragment = new SelectFragment();
 
 		int[] columnTableNumbers = getSubclassColumnTableNumberClosure();
 		String[] columnAliases = getSubclassColumnAliasClosure();
 		String[] columnReaderTemplates = getSubclassColumnReaderTemplateClosure();
 		for ( int i = 0; i < subclassColumnNumbers.length; i++ ) {
 			int columnNumber = subclassColumnNumbers[i];
 			if ( subclassColumnSelectableClosure[columnNumber] ) {
 				final String subalias = generateTableAlias( getRootAlias(), columnTableNumbers[columnNumber] );
-				selectFragment.addColumnTemplate( subalias, columnReaderTemplates[columnNumber], columnAliases[columnNumber] );
+				selectFragment.addColumnTemplate(
+						subalias,
+						columnReaderTemplates[columnNumber],
+						columnAliases[columnNumber]
+				);
 			}
 		}
 
 		int[] formulaTableNumbers = getSubclassFormulaTableNumberClosure();
 		String[] formulaTemplates = getSubclassFormulaTemplateClosure();
 		String[] formulaAliases = getSubclassFormulaAliasClosure();
 		for ( int i = 0; i < subclassFormulaNumbers.length; i++ ) {
 			int formulaNumber = subclassFormulaNumbers[i];
 			final String subalias = generateTableAlias( getRootAlias(), formulaTableNumbers[formulaNumber] );
 			selectFragment.addFormula( subalias, formulaTemplates[formulaNumber], formulaAliases[formulaNumber] );
 		}
 
 		return selectFragment;
 	}
 
 	protected String createFrom(int tableNumber, String alias) {
 		return getSubclassTableName( tableNumber ) + ' ' + alias;
 	}
 
 	protected String createWhereByKey(int tableNumber, String alias) {
 		//TODO: move to .sql package, and refactor with similar things!
-		return StringHelper.join( "=? and ",
-				StringHelper.qualify( alias, getSubclassTableKeyColumns( tableNumber ) ) ) + "=?";
+		return StringHelper.join(
+				"=? and ",
+				StringHelper.qualify( alias, getSubclassTableKeyColumns( tableNumber ) )
+		) + "=?";
 	}
 
 	protected String renderSelect(
 			final int[] tableNumbers,
-	        final int[] columnNumbers,
-	        final int[] formulaNumbers) {
+			final int[] columnNumbers,
+			final int[] formulaNumbers) {
 
 		Arrays.sort( tableNumbers ); //get 'em in the right order (not that it really matters)
 
 		//render the where and from parts
 		int drivingTable = tableNumbers[0];
-		final String drivingAlias = generateTableAlias( getRootAlias(), drivingTable ); //we *could* regerate this inside each called method!
+		final String drivingAlias = generateTableAlias(
+				getRootAlias(),
+				drivingTable
+		); //we *could* regerate this inside each called method!
 		final String where = createWhereByKey( drivingTable, drivingAlias );
 		final String from = createFrom( drivingTable, drivingAlias );
 
 		//now render the joins
 		JoinFragment jf = createJoin( tableNumbers, drivingAlias );
 
 		//now render the select clause
 		SelectFragment selectFragment = createSelect( columnNumbers, formulaNumbers );
 
 		//now tie it all together
 		Select select = new Select( getFactory().getDialect() );
 		select.setSelectClause( selectFragment.toFragmentString().substring( 2 ) );
 		select.setFromClause( from );
 		select.setWhereClause( where );
 		select.setOuterJoins( jf.toFromFragmentString(), jf.toWhereFragmentString() );
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			select.setComment( "sequential select " + getEntityName() );
 		}
 		return select.toStatementString();
 	}
 
 	private String getRootAlias() {
 		return StringHelper.generateAlias( getEntityName() );
 	}
 
 	/**
 	 * Post-construct is a callback for AbstractEntityPersister subclasses to call after they are all done with their
 	 * constructor processing.  It allows AbstractEntityPersister to extend its construction after all subclass-specific
 	 * details have been handled.
 	 *
 	 * @param mapping The mapping
 	 *
 	 * @throws MappingException Indicates a problem accessing the Mapping
 	 */
 	protected void postConstruct(Mapping mapping) throws MappingException {
 		initPropertyPaths( mapping );
 
 		//doLateInit();
 		prepareEntityIdentifierDefinition();
 	}
 
 	private void doLateInit() {
 		//insert/update/delete SQL
 		final int joinSpan = getTableSpan();
 		sqlDeleteStrings = new String[joinSpan];
 		sqlInsertStrings = new String[joinSpan];
 		sqlUpdateStrings = new String[joinSpan];
 		sqlLazyUpdateStrings = new String[joinSpan];
 
 		sqlUpdateByRowIdString = rowIdName == null ?
 				null :
 				generateUpdateString( getPropertyUpdateability(), 0, true );
 		sqlLazyUpdateByRowIdString = rowIdName == null ?
 				null :
 				generateUpdateString( getNonLazyPropertyUpdateability(), 0, true );
 
 		for ( int j = 0; j < joinSpan; j++ ) {
 			sqlInsertStrings[j] = customSQLInsert[j] == null ?
 					generateInsertString( getPropertyInsertability(), j ) :
 					customSQLInsert[j];
 			sqlUpdateStrings[j] = customSQLUpdate[j] == null ?
 					generateUpdateString( getPropertyUpdateability(), j, false ) :
 					customSQLUpdate[j];
 			sqlLazyUpdateStrings[j] = customSQLUpdate[j] == null ?
 					generateUpdateString( getNonLazyPropertyUpdateability(), j, false ) :
 					customSQLUpdate[j];
 			sqlDeleteStrings[j] = customSQLDelete[j] == null ?
 					generateDeleteString( j ) :
 					customSQLDelete[j];
 		}
 
 		tableHasColumns = new boolean[joinSpan];
 		for ( int j = 0; j < joinSpan; j++ ) {
 			tableHasColumns[j] = sqlUpdateStrings[j] != null;
 		}
 
 		//select SQL
 		sqlSnapshotSelectString = generateSnapshotSelectString();
 		sqlLazySelectString = generateLazySelectString();
 		sqlVersionSelectString = generateSelectVersionString();
 		if ( hasInsertGeneratedProperties() ) {
 			sqlInsertGeneratedValuesSelectString = generateInsertGeneratedValuesSelectString();
 		}
 		if ( hasUpdateGeneratedProperties() ) {
 			sqlUpdateGeneratedValuesSelectString = generateUpdateGeneratedValuesSelectString();
 		}
 		if ( isIdentifierAssignedByInsert() ) {
-			identityDelegate = ( ( PostInsertIdentifierGenerator ) getIdentifierGenerator() )
+			identityDelegate = ( (PostInsertIdentifierGenerator) getIdentifierGenerator() )
 					.getInsertGeneratedIdentifierDelegate( this, getFactory().getDialect(), useGetGeneratedKeys() );
 			sqlIdentityInsertString = customSQLInsert[0] == null
 					? generateIdentityInsertString( getPropertyInsertability() )
 					: customSQLInsert[0];
 		}
 		else {
 			sqlIdentityInsertString = null;
 		}
 
 		logStaticSQL();
 	}
 
 	public final void postInstantiate() throws MappingException {
 		doLateInit();
 
 		createLoaders();
 		createUniqueKeyLoaders();
 		createQueryLoader();
 
 		doPostInstantiate();
 	}
 
 	protected void doPostInstantiate() {
 	}
 
 	//needed by subclasses to override the createLoader strategy
 	protected Map getLoaders() {
 		return loaders;
 	}
 
 	//Relational based Persisters should be content with this implementation
 	protected void createLoaders() {
 		final Map loaders = getLoaders();
 		loaders.put( LockMode.NONE, createEntityLoader( LockMode.NONE ) );
 
 		UniqueEntityLoader readLoader = createEntityLoader( LockMode.READ );
 		loaders.put( LockMode.READ, readLoader );
 
 		//TODO: inexact, what we really need to know is: are any outer joins used?
 		boolean disableForUpdate = getSubclassTableSpan() > 1 &&
 				hasSubclasses() &&
 				!getFactory().getDialect().supportsOuterJoinForUpdate();
 
 		loaders.put(
 				LockMode.UPGRADE,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.UPGRADE )
-			);
+		);
 		loaders.put(
 				LockMode.UPGRADE_NOWAIT,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.UPGRADE_NOWAIT )
-			);
+		);
 		loaders.put(
 				LockMode.UPGRADE_SKIPLOCKED,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.UPGRADE_SKIPLOCKED )
-			);
+		);
 		loaders.put(
 				LockMode.FORCE,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.FORCE )
-			);
+		);
 		loaders.put(
 				LockMode.PESSIMISTIC_READ,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.PESSIMISTIC_READ )
-			);
+		);
 		loaders.put(
 				LockMode.PESSIMISTIC_WRITE,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.PESSIMISTIC_WRITE )
-			);
+		);
 		loaders.put(
 				LockMode.PESSIMISTIC_FORCE_INCREMENT,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.PESSIMISTIC_FORCE_INCREMENT )
-			);
-		loaders.put( LockMode.OPTIMISTIC, createEntityLoader( LockMode.OPTIMISTIC) );
-		loaders.put( LockMode.OPTIMISTIC_FORCE_INCREMENT, createEntityLoader(LockMode.OPTIMISTIC_FORCE_INCREMENT) );
+		);
+		loaders.put( LockMode.OPTIMISTIC, createEntityLoader( LockMode.OPTIMISTIC ) );
+		loaders.put( LockMode.OPTIMISTIC_FORCE_INCREMENT, createEntityLoader( LockMode.OPTIMISTIC_FORCE_INCREMENT ) );
 
 		loaders.put(
 				"merge",
 				new CascadeEntityLoader( this, CascadingActions.MERGE, getFactory() )
-			);
+		);
 		loaders.put(
 				"refresh",
 				new CascadeEntityLoader( this, CascadingActions.REFRESH, getFactory() )
-			);
+		);
 	}
 
 	protected void createQueryLoader() {
 		if ( loaderName != null ) {
 			queryLoader = new NamedQueryLoader( loaderName, this );
 		}
 	}
 
 	/**
 	 * Load an instance using either the <tt>forUpdateLoader</tt> or the outer joining <tt>loader</tt>,
 	 * depending upon the value of the <tt>lock</tt> parameter
 	 */
 	public Object load(Serializable id, Object optionalObject, LockMode lockMode, SessionImplementor session) {
-		return load( id, optionalObject, new LockOptions().setLockMode(lockMode), session );
+		return load( id, optionalObject, new LockOptions().setLockMode( lockMode ), session );
 	}
 
 	/**
 	 * Load an instance using either the <tt>forUpdateLoader</tt> or the outer joining <tt>loader</tt>,
 	 * depending upon the value of the <tt>lock</tt> parameter
 	 */
 	public Object load(Serializable id, Object optionalObject, LockOptions lockOptions, SessionImplementor session)
 			throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Fetching entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
-		final UniqueEntityLoader loader = getAppropriateLoader(lockOptions, session );
+		final UniqueEntityLoader loader = getAppropriateLoader( lockOptions, session );
 		return loader.load( id, optionalObject, session, lockOptions );
 	}
 
 	public void registerAffectingFetchProfile(String fetchProfileName) {
 		affectingFetchProfileNames.add( fetchProfileName );
 	}
 
 	private boolean isAffectedByEntityGraph(SessionImplementor session) {
 		return session.getLoadQueryInfluencers().getFetchGraph() != null || session.getLoadQueryInfluencers()
 				.getLoadGraph() != null;
 	}
 
 	private boolean isAffectedByEnabledFetchProfiles(SessionImplementor session) {
 		for ( String s : session.getLoadQueryInfluencers().getEnabledFetchProfileNames() ) {
 			if ( affectingFetchProfileNames.contains( s ) ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	private boolean isAffectedByEnabledFilters(SessionImplementor session) {
 		return session.getLoadQueryInfluencers().hasEnabledFilters()
 				&& filterHelper.isAffectedBy( session.getLoadQueryInfluencers().getEnabledFilters() );
 	}
 
 	private UniqueEntityLoader getAppropriateLoader(LockOptions lockOptions, SessionImplementor session) {
 		if ( queryLoader != null ) {
 			// if the user specified a custom query loader we need to that
 			// regardless of any other consideration
 			return queryLoader;
 		}
 		else if ( isAffectedByEnabledFilters( session ) ) {
 			// because filters affect the rows returned (because they add
 			// restrictions) these need to be next in precedence
-			return createEntityLoader(lockOptions, session.getLoadQueryInfluencers() );
+			return createEntityLoader( lockOptions, session.getLoadQueryInfluencers() );
 		}
-		else if ( session.getLoadQueryInfluencers().getInternalFetchProfile() != null && LockMode.UPGRADE.greaterThan( lockOptions.getLockMode() ) ) {
+		else if ( session.getLoadQueryInfluencers().getInternalFetchProfile() != null && LockMode.UPGRADE.greaterThan(
+				lockOptions.getLockMode()
+		) ) {
 			// Next, we consider whether an 'internal' fetch profile has been set.
 			// This indicates a special fetch profile Hibernate needs applied
 			// (for its merge loading process e.g.).
-			return ( UniqueEntityLoader ) getLoaders().get( session.getLoadQueryInfluencers().getInternalFetchProfile() );
+			return (UniqueEntityLoader) getLoaders().get( session.getLoadQueryInfluencers().getInternalFetchProfile() );
 		}
 		else if ( isAffectedByEnabledFetchProfiles( session ) ) {
 			// If the session has associated influencers we need to adjust the
 			// SQL query used for loading based on those influencers
-			return createEntityLoader(lockOptions, session.getLoadQueryInfluencers() );
+			return createEntityLoader( lockOptions, session.getLoadQueryInfluencers() );
 		}
 		else if ( isAffectedByEntityGraph( session ) ) {
 			return createEntityLoader( lockOptions, session.getLoadQueryInfluencers() );
 		}
 		else if ( lockOptions.getTimeOut() != LockOptions.WAIT_FOREVER ) {
 			return createEntityLoader( lockOptions, session.getLoadQueryInfluencers() );
 		}
 		else {
-			return ( UniqueEntityLoader ) getLoaders().get( lockOptions.getLockMode() );
+			return (UniqueEntityLoader) getLoaders().get( lockOptions.getLockMode() );
 		}
 	}
 
 	private boolean isAllNull(Object[] array, int tableNumber) {
 		for ( int i = 0; i < array.length; i++ ) {
 			if ( isPropertyOfTable( i, tableNumber ) && array[i] != null ) {
 				return false;
 			}
 		}
 		return true;
 	}
 
 	public boolean isSubclassPropertyNullable(int i) {
 		return subclassPropertyNullabilityClosure[i];
 	}
 
 	/**
 	 * Transform the array of property indexes to an array of booleans,
 	 * true when the property is dirty
 	 */
 	protected final boolean[] getPropertiesToUpdate(final int[] dirtyProperties, final boolean hasDirtyCollection) {
-		final boolean[] propsToUpdate = new boolean[ entityMetamodel.getPropertySpan() ];
+		final boolean[] propsToUpdate = new boolean[entityMetamodel.getPropertySpan()];
 		final boolean[] updateability = getPropertyUpdateability(); //no need to check laziness, dirty checking handles that
 		for ( int j = 0; j < dirtyProperties.length; j++ ) {
 			int property = dirtyProperties[j];
 			if ( updateability[property] ) {
 				propsToUpdate[property] = true;
 			}
 		}
-		if ( isVersioned() && updateability[getVersionProperty() ]) {
-			propsToUpdate[ getVersionProperty() ] =
-				Versioning.isVersionIncrementRequired( dirtyProperties, hasDirtyCollection, getPropertyVersionability() );
+		if ( isVersioned() && updateability[getVersionProperty()] ) {
+			propsToUpdate[getVersionProperty()] =
+					Versioning.isVersionIncrementRequired(
+							dirtyProperties,
+							hasDirtyCollection,
+							getPropertyVersionability()
+					);
 		}
 		return propsToUpdate;
 	}
 
 	/**
 	 * Transform the array of property indexes to an array of booleans,
 	 * true when the property is insertable and non-null
 	 */
 	protected boolean[] getPropertiesToInsert(Object[] fields) {
 		boolean[] notNull = new boolean[fields.length];
 		boolean[] insertable = getPropertyInsertability();
 		for ( int i = 0; i < fields.length; i++ ) {
 			notNull[i] = insertable[i] && fields[i] != null;
 		}
 		return notNull;
 	}
 
 	/**
 	 * Locate the property-indices of all properties considered to be dirty.
 	 *
 	 * @param currentState The current state of the entity (the state to be checked).
 	 * @param previousState The previous state of the entity (the state to be checked against).
 	 * @param entity The entity for which we are checking state dirtiness.
 	 * @param session The session in which the check is occurring.
+	 *
 	 * @return <tt>null</tt> or the indices of the dirty properties
+	 *
 	 * @throws HibernateException
 	 */
 	public int[] findDirty(Object[] currentState, Object[] previousState, Object entity, SessionImplementor session)
-	throws HibernateException {
+			throws HibernateException {
 		int[] props = TypeHelper.findDirty(
 				entityMetamodel.getProperties(),
 				currentState,
 				previousState,
 				propertyColumnUpdateable,
 				hasUninitializedLazyProperties( entity ),
 				session
 		);
 		if ( props == null ) {
 			return null;
 		}
 		else {
 			logDirtyProperties( props );
 			return props;
 		}
 	}
 
 	/**
 	 * Locate the property-indices of all properties considered to be dirty.
 	 *
 	 * @param old The old state of the entity.
 	 * @param current The current state of the entity.
 	 * @param entity The entity for which we are checking state modification.
 	 * @param session The session in which the check is occurring.
+	 *
 	 * @return <tt>null</tt> or the indices of the modified properties
+	 *
 	 * @throws HibernateException
 	 */
 	public int[] findModified(Object[] old, Object[] current, Object entity, SessionImplementor session)
-	throws HibernateException {
+			throws HibernateException {
 		int[] props = TypeHelper.findModified(
 				entityMetamodel.getProperties(),
 				current,
 				old,
 				propertyColumnUpdateable,
 				hasUninitializedLazyProperties( entity ),
 				session
 		);
 		if ( props == null ) {
 			return null;
 		}
 		else {
 			logDirtyProperties( props );
 			return props;
 		}
 	}
 
 	/**
 	 * Which properties appear in the SQL update?
 	 * (Initialized, updateable ones!)
 	 */
 	protected boolean[] getPropertyUpdateability(Object entity) {
 		return hasUninitializedLazyProperties( entity )
 				? getNonLazyPropertyUpdateability()
 				: getPropertyUpdateability();
 	}
 
 	private void logDirtyProperties(int[] props) {
 		if ( LOG.isTraceEnabled() ) {
 			for ( int i = 0; i < props.length; i++ ) {
-				String propertyName = entityMetamodel.getProperties()[ props[i] ].getName();
+				String propertyName = entityMetamodel.getProperties()[props[i]].getName();
 				LOG.trace( StringHelper.qualify( getEntityName(), propertyName ) + " is dirty" );
 			}
 		}
 	}
 
 	public SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	public EntityMetamodel getEntityMetamodel() {
 		return entityMetamodel;
 	}
 
 	public boolean hasCache() {
 		return cacheAccessStrategy != null;
 	}
 
 	public EntityRegionAccessStrategy getCacheAccessStrategy() {
 		return cacheAccessStrategy;
 	}
 
 	@Override
 	public CacheEntryStructure getCacheEntryStructure() {
 		return cacheEntryHelper.getCacheEntryStructure();
 	}
 
 	@Override
 	public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 		return cacheEntryHelper.buildCacheEntry( entity, state, version, session );
 	}
 
 	public boolean hasNaturalIdCache() {
 		return naturalIdRegionAccessStrategy != null;
 	}
-	
+
 	public NaturalIdRegionAccessStrategy getNaturalIdCacheAccessStrategy() {
 		return naturalIdRegionAccessStrategy;
 	}
 
 	public Comparator getVersionComparator() {
 		return isVersioned() ? getVersionType().getComparator() : null;
 	}
 
 	// temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	public final String getEntityName() {
 		return entityMetamodel.getName();
 	}
 
 	public EntityType getEntityType() {
 		return entityMetamodel.getEntityType();
 	}
 
 	public boolean isPolymorphic() {
 		return entityMetamodel.isPolymorphic();
 	}
 
 	public boolean isInherited() {
 		return entityMetamodel.isInherited();
 	}
 
 	public boolean hasCascades() {
 		return entityMetamodel.hasCascades();
 	}
 
 	public boolean hasIdentifierProperty() {
 		return !entityMetamodel.getIdentifierProperty().isVirtual();
 	}
 
 	public VersionType getVersionType() {
-		return ( VersionType ) locateVersionType();
+		return (VersionType) locateVersionType();
 	}
 
 	private Type locateVersionType() {
 		return entityMetamodel.getVersionProperty() == null ?
 				null :
 				entityMetamodel.getVersionProperty().getType();
 	}
 
 	public int getVersionProperty() {
 		return entityMetamodel.getVersionPropertyIndex();
 	}
 
 	public boolean isVersioned() {
 		return entityMetamodel.isVersioned();
 	}
 
 	public boolean isIdentifierAssignedByInsert() {
 		return entityMetamodel.getIdentifierProperty().isIdentifierAssignedByInsert();
 	}
 
 	public boolean hasLazyProperties() {
 		return entityMetamodel.hasLazyProperties();
 	}
 
 //	public boolean hasUninitializedLazyProperties(Object entity) {
 //		if ( hasLazyProperties() ) {
 //			InterceptFieldCallback callback = ( ( InterceptFieldEnabled ) entity ).getInterceptFieldCallback();
 //			return callback != null && !( ( FieldInterceptor ) callback ).isInitialized();
 //		}
 //		else {
 //			return false;
 //		}
 //	}
 
 	public void afterReassociate(Object entity, SessionImplementor session) {
 		if ( getEntityMetamodel().getInstrumentationMetadata().isInstrumented() ) {
-			FieldInterceptor interceptor = getEntityMetamodel().getInstrumentationMetadata().extractInterceptor( entity );
+			FieldInterceptor interceptor = getEntityMetamodel().getInstrumentationMetadata()
+					.extractInterceptor( entity );
 			if ( interceptor != null ) {
 				interceptor.setSession( session );
 			}
 			else {
 				FieldInterceptor fieldInterceptor = getEntityMetamodel().getInstrumentationMetadata().injectInterceptor(
 						entity,
 						getEntityName(),
 						null,
 						session
 				);
 				fieldInterceptor.dirty();
 			}
 		}
 
 		handleNaturalIdReattachment( entity, session );
 	}
 
 	private void handleNaturalIdReattachment(Object entity, SessionImplementor session) {
-		if ( ! hasNaturalIdentifier() ) {
+		if ( !hasNaturalIdentifier() ) {
 			return;
 		}
 
 		if ( getEntityMetamodel().hasImmutableNaturalId() ) {
 			// we assume there were no changes to natural id during detachment for now, that is validated later
 			// during flush.
 			return;
 		}
 
 		final NaturalIdHelper naturalIdHelper = session.getPersistenceContext().getNaturalIdHelper();
 		final Serializable id = getIdentifier( entity, session );
 
 		// for reattachment of mutable natural-ids, we absolutely positively have to grab the snapshot from the
 		// database, because we have no other way to know if the state changed while detached.
 		final Object[] naturalIdSnapshot;
 		final Object[] entitySnapshot = session.getPersistenceContext().getDatabaseSnapshot( id, this );
 		if ( entitySnapshot == StatefulPersistenceContext.NO_ROW ) {
 			naturalIdSnapshot = null;
 		}
 		else {
 			naturalIdSnapshot = naturalIdHelper.extractNaturalIdValues( entitySnapshot, this );
 		}
 
 		naturalIdHelper.removeSharedNaturalIdCrossReference( this, id, naturalIdSnapshot );
 		naturalIdHelper.manageLocalNaturalIdCrossReference(
 				this,
 				id,
 				naturalIdHelper.extractNaturalIdValues( entity, this ),
 				naturalIdSnapshot,
 				CachedNaturalIdValueSource.UPDATE
 		);
 	}
 
 	public Boolean isTransient(Object entity, SessionImplementor session) throws HibernateException {
 		final Serializable id;
 		if ( canExtractIdOutOfEntity() ) {
 			id = getIdentifier( entity, session );
 		}
 		else {
 			id = null;
 		}
 		// we *always* assume an instance with a null
 		// identifier or no identifier property is unsaved!
 		if ( id == null ) {
 			return Boolean.TRUE;
 		}
 
 		// check the version unsaved-value, if appropriate
 		final Object version = getVersion( entity );
 		if ( isVersioned() ) {
 			// let this take precedence if defined, since it works for
 			// assigned identifiers
 			Boolean result = entityMetamodel.getVersionProperty()
 					.getUnsavedValue().isUnsaved( version );
 			if ( result != null ) {
 				return result;
 			}
 		}
 
 		// check the id unsaved-value
 		Boolean result = entityMetamodel.getIdentifierProperty()
 				.getUnsavedValue().isUnsaved( id );
 		if ( result != null ) {
 			return result;
 		}
 
 		// check to see if it is in the second-level cache
 		if ( session.getCacheMode().isGetEnabled() && hasCache() ) {
 			final CacheKey ck = session.generateCacheKey( id, getIdentifierType(), getRootEntityName() );
 			final Object ce = CacheHelper.fromSharedCache( session, ck, getCacheAccessStrategy() );
 			if ( ce != null ) {
 				return Boolean.FALSE;
 			}
 		}
 
 		return null;
 	}
 
 	public boolean hasCollections() {
 		return entityMetamodel.hasCollections();
 	}
 
 	public boolean hasMutableProperties() {
 		return entityMetamodel.hasMutableProperties();
 	}
 
 	public boolean isMutable() {
 		return entityMetamodel.isMutable();
 	}
 
 	private boolean isModifiableEntity(EntityEntry entry) {
 		return ( entry == null ? isMutable() : entry.isModifiableEntity() );
 	}
 
 	public boolean isAbstract() {
 		return entityMetamodel.isAbstract();
 	}
 
 	public boolean hasSubclasses() {
 		return entityMetamodel.hasSubclasses();
 	}
 
 	public boolean hasProxy() {
 		return entityMetamodel.isLazy();
 	}
 
 	public IdentifierGenerator getIdentifierGenerator() throws HibernateException {
 		return entityMetamodel.getIdentifierProperty().getIdentifierGenerator();
 	}
 
 	public String getRootEntityName() {
 		return entityMetamodel.getRootName();
 	}
 
 	public ClassMetadata getClassMetadata() {
 		return this;
 	}
 
 	public String getMappedSuperclass() {
 		return entityMetamodel.getSuperclass();
 	}
 
 	public boolean isExplicitPolymorphism() {
 		return entityMetamodel.isExplicitPolymorphism();
 	}
 
 	protected boolean useDynamicUpdate() {
 		return entityMetamodel.isDynamicUpdate();
 	}
 
 	protected boolean useDynamicInsert() {
 		return entityMetamodel.isDynamicInsert();
 	}
 
 	protected boolean hasEmbeddedCompositeIdentifier() {
 		return entityMetamodel.getIdentifierProperty().isEmbedded();
 	}
 
 	public boolean canExtractIdOutOfEntity() {
 		return hasIdentifierProperty() || hasEmbeddedCompositeIdentifier() || hasIdentifierMapper();
 	}
 
 	private boolean hasIdentifierMapper() {
 		return entityMetamodel.getIdentifierProperty().hasIdentifierMapper();
 	}
 
 	public String[] getKeyColumnNames() {
 		return getIdentifierColumnNames();
 	}
 
 	public String getName() {
 		return getEntityName();
 	}
 
 	public boolean isCollection() {
 		return false;
 	}
 
 	public boolean consumesEntityAlias() {
 		return true;
 	}
 
 	public boolean consumesCollectionAlias() {
 		return false;
 	}
 
 	public Type getPropertyType(String propertyName) throws MappingException {
 		return propertyMapping.toType( propertyName );
 	}
 
 	public Type getType() {
 		return entityMetamodel.getEntityType();
 	}
 
 	public boolean isSelectBeforeUpdateRequired() {
 		return entityMetamodel.isSelectBeforeUpdate();
 	}
 
 	protected final OptimisticLockStyle optimisticLockStyle() {
 		return entityMetamodel.getOptimisticLockStyle();
 	}
 
 	public Object createProxy(Serializable id, SessionImplementor session) throws HibernateException {
 		return entityMetamodel.getTuplizer().createProxy( id, session );
 	}
 
 	public String toString() {
 		return StringHelper.unqualify( getClass().getName() ) +
 				'(' + entityMetamodel.getName() + ')';
 	}
 
 	public final String selectFragment(
 			Joinable rhs,
 			String rhsAlias,
 			String lhsAlias,
 			String entitySuffix,
 			String collectionSuffix,
 			boolean includeCollectionColumns) {
 		return selectFragment( lhsAlias, entitySuffix );
 	}
 
 	public boolean isInstrumented() {
 		return entityMetamodel.isInstrumented();
 	}
 
 	public boolean hasInsertGeneratedProperties() {
 		return entityMetamodel.hasInsertGeneratedValues();
 	}
 
 	public boolean hasUpdateGeneratedProperties() {
 		return entityMetamodel.hasUpdateGeneratedValues();
 	}
 
 	public boolean isVersionPropertyGenerated() {
 		return isVersioned() && getEntityMetamodel().isVersionGenerated();
 	}
 
 	public boolean isVersionPropertyInsertable() {
-		return isVersioned() && getPropertyInsertability() [ getVersionProperty() ];
+		return isVersioned() && getPropertyInsertability()[getVersionProperty()];
 	}
 
 	public void afterInitialize(Object entity, boolean lazyPropertiesAreUnfetched, SessionImplementor session) {
 		getEntityTuplizer().afterInitialize( entity, lazyPropertiesAreUnfetched, session );
 	}
 
 	public String[] getPropertyNames() {
 		return entityMetamodel.getPropertyNames();
 	}
 
 	public Type[] getPropertyTypes() {
 		return entityMetamodel.getPropertyTypes();
 	}
 
 	public boolean[] getPropertyLaziness() {
 		return entityMetamodel.getPropertyLaziness();
 	}
 
 	public boolean[] getPropertyUpdateability() {
 		return entityMetamodel.getPropertyUpdateability();
 	}
 
 	public boolean[] getPropertyCheckability() {
 		return entityMetamodel.getPropertyCheckability();
 	}
 
 	public boolean[] getNonLazyPropertyUpdateability() {
 		return entityMetamodel.getNonlazyPropertyUpdateability();
 	}
 
 	public boolean[] getPropertyInsertability() {
 		return entityMetamodel.getPropertyInsertability();
 	}
 
 	/**
 	 * @deprecated no simple, direct replacement
 	 */
 	@Deprecated
 	public ValueInclusion[] getPropertyInsertGenerationInclusions() {
 		return null;
 	}
 
 	/**
 	 * @deprecated no simple, direct replacement
 	 */
 	@Deprecated
 	public ValueInclusion[] getPropertyUpdateGenerationInclusions() {
 		return null;
 	}
 
 	public boolean[] getPropertyNullability() {
 		return entityMetamodel.getPropertyNullability();
 	}
 
 	public boolean[] getPropertyVersionability() {
 		return entityMetamodel.getPropertyVersionability();
 	}
 
 	public CascadeStyle[] getPropertyCascadeStyles() {
 		return entityMetamodel.getCascadeStyles();
 	}
 
 	public final Class getMappedClass() {
 		return getEntityTuplizer().getMappedClass();
 	}
 
 	public boolean implementsLifecycle() {
 		return getEntityTuplizer().isLifecycleImplementor();
 	}
 
 	public Class getConcreteProxyClass() {
 		return getEntityTuplizer().getConcreteProxyClass();
 	}
 
 	public void setPropertyValues(Object object, Object[] values) {
 		getEntityTuplizer().setPropertyValues( object, values );
 	}
 
 	public void setPropertyValue(Object object, int i, Object value) {
 		getEntityTuplizer().setPropertyValue( object, i, value );
 	}
 
 	public Object[] getPropertyValues(Object object) {
 		return getEntityTuplizer().getPropertyValues( object );
 	}
 
 	@Override
 	public Object getPropertyValue(Object object, int i) {
 		return getEntityTuplizer().getPropertyValue( object, i );
 	}
 
 	@Override
 	public Object getPropertyValue(Object object, String propertyName) {
 		return getEntityTuplizer().getPropertyValue( object, propertyName );
 	}
 
 	@Override
 	public Serializable getIdentifier(Object object) {
 		return getEntityTuplizer().getIdentifier( object, null );
 	}
 
 	@Override
 	public Serializable getIdentifier(Object entity, SessionImplementor session) {
 		return getEntityTuplizer().getIdentifier( entity, session );
 	}
 
 	@Override
 	public void setIdentifier(Object entity, Serializable id, SessionImplementor session) {
 		getEntityTuplizer().setIdentifier( entity, id, session );
 	}
 
 	@Override
 	public Object getVersion(Object object) {
 		return getEntityTuplizer().getVersion( object );
 	}
 
 	@Override
 	public Object instantiate(Serializable id, SessionImplementor session) {
 		return getEntityTuplizer().instantiate( id, session );
 	}
 
 	@Override
 	public boolean isInstance(Object object) {
 		return getEntityTuplizer().isInstance( object );
 	}
 
 	@Override
 	public boolean hasUninitializedLazyProperties(Object object) {
 		return getEntityTuplizer().hasUninitializedLazyProperties( object );
 	}
 
 	@Override
-	public void resetIdentifier(Object entity, Serializable currentId, Object currentVersion, SessionImplementor session) {
+	public void resetIdentifier(
+			Object entity,
+			Serializable currentId,
+			Object currentVersion,
+			SessionImplementor session) {
 		getEntityTuplizer().resetIdentifier( entity, currentId, currentVersion, session );
 	}
 
 	@Override
 	public EntityPersister getSubclassEntityPersister(Object instance, SessionFactoryImplementor factory) {
 		if ( !hasSubclasses() ) {
 			return this;
 		}
 		else {
 			final String concreteEntityName = getEntityTuplizer().determineConcreteSubclassEntityName(
 					instance,
 					factory
 			);
 			if ( concreteEntityName == null || getEntityName().equals( concreteEntityName ) ) {
 				// the contract of EntityTuplizer.determineConcreteSubclassEntityName says that returning null
 				// is an indication that the specified entity-name (this.getEntityName) should be used.
 				return this;
 			}
 			else {
 				return factory.getEntityPersister( concreteEntityName );
 			}
 		}
 	}
 
 	public boolean isMultiTable() {
 		return false;
 	}
 
 	protected int getPropertySpan() {
 		return entityMetamodel.getPropertySpan();
 	}
 
-	public Object[] getPropertyValuesToInsert(Object object, Map mergeMap, SessionImplementor session) throws HibernateException {
+	public Object[] getPropertyValuesToInsert(Object object, Map mergeMap, SessionImplementor session)
+			throws HibernateException {
 		return getEntityTuplizer().getPropertyValuesToInsert( object, mergeMap, session );
 	}
 
-	public void processInsertGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session) {
+	public void processInsertGeneratedProperties(
+			Serializable id,
+			Object entity,
+			Object[] state,
+			SessionImplementor session) {
 		if ( !hasInsertGeneratedProperties() ) {
-			throw new AssertionFailure("no insert-generated properties");
+			throw new AssertionFailure( "no insert-generated properties" );
 		}
-		processGeneratedProperties( id, entity, state, session, sqlInsertGeneratedValuesSelectString, GenerationTiming.INSERT );
+		processGeneratedProperties(
+				id,
+				entity,
+				state,
+				session,
+				sqlInsertGeneratedValuesSelectString,
+				GenerationTiming.INSERT
+		);
 	}
 
-	public void processUpdateGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session) {
+	public void processUpdateGeneratedProperties(
+			Serializable id,
+			Object entity,
+			Object[] state,
+			SessionImplementor session) {
 		if ( !hasUpdateGeneratedProperties() ) {
-			throw new AssertionFailure("no update-generated properties");
+			throw new AssertionFailure( "no update-generated properties" );
 		}
-		processGeneratedProperties( id, entity, state, session, sqlUpdateGeneratedValuesSelectString, GenerationTiming.ALWAYS );
+		processGeneratedProperties(
+				id,
+				entity,
+				state,
+				session,
+				sqlUpdateGeneratedValuesSelectString,
+				GenerationTiming.ALWAYS
+		);
 	}
 
 	private void processGeneratedProperties(
 			Serializable id,
-	        Object entity,
-	        Object[] state,
-	        SessionImplementor session,
-	        String selectionSQL,
+			Object entity,
+			Object[] state,
+			SessionImplementor session,
+			String selectionSQL,
 			GenerationTiming matchTiming) {
 		// force immediate execution of the insert batch (if one)
 		session.getJdbcCoordinator().executeBatch();
 
 		try {
 			PreparedStatement ps = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( selectionSQL );
 			try {
 				getIdentifierType().nullSafeSet( ps, id, 1, session );
 				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					if ( !rs.next() ) {
 						throw new HibernateException(
 								"Unable to locate row for retrieval of generated properties: " +
-								MessageHelper.infoString( this, id, getFactory() )
-							);
+										MessageHelper.infoString( this, id, getFactory() )
+						);
 					}
 					int propertyIndex = -1;
 					for ( NonIdentifierAttribute attribute : entityMetamodel.getProperties() ) {
 						propertyIndex++;
 						final ValueGeneration valueGeneration = attribute.getValueGenerationStrategy();
 						if ( isReadRequired( valueGeneration, matchTiming ) ) {
 							final Object hydratedState = attribute.getType().hydrate(
 									rs, getPropertyAliases(
-									"",
-									propertyIndex
-							), session, entity
+											"",
+											propertyIndex
+									), session, entity
 							);
 							state[propertyIndex] = attribute.getType().resolve( hydratedState, session, entity );
 							setPropertyValue( entity, propertyIndex, state[propertyIndex] );
 						}
 					}
 //					for ( int i = 0; i < getPropertySpan(); i++ ) {
 //						if ( includeds[i] != ValueInclusion.NONE ) {
 //							Object hydratedState = getPropertyTypes()[i].hydrate( rs, getPropertyAliases( "", i ), session, entity );
 //							state[i] = getPropertyTypes()[i].resolve( hydratedState, session, entity );
 //							setPropertyValue( entity, i, state[i] );
 //						}
 //					}
 				}
 				finally {
 					if ( rs != null ) {
 						session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 					}
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( ps );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
-		catch( SQLException e ) {
+		catch (SQLException e) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"unable to select generated column values",
 					selectionSQL
 			);
 		}
 
 	}
 
 	/**
 	 * Whether the given value generation strategy requires to read the value from the database or not.
 	 */
 	private boolean isReadRequired(ValueGeneration valueGeneration, GenerationTiming matchTiming) {
 		return valueGeneration != null &&
 				valueGeneration.getValueGenerator() == null &&
 				timingsMatch( valueGeneration.getGenerationTiming(), matchTiming );
 	}
 
 	private boolean timingsMatch(GenerationTiming timing, GenerationTiming matchTiming) {
 		return
-				(matchTiming == GenerationTiming.INSERT && timing.includesInsert()) ||
-						(matchTiming == GenerationTiming.ALWAYS && timing.includesUpdate());
+				( matchTiming == GenerationTiming.INSERT && timing.includesInsert() ) ||
+						( matchTiming == GenerationTiming.ALWAYS && timing.includesUpdate() );
 	}
 
 	public String getIdentifierPropertyName() {
 		return entityMetamodel.getIdentifierProperty().getName();
 	}
 
 	public Type getIdentifierType() {
 		return entityMetamodel.getIdentifierProperty().getType();
 	}
 
 	public boolean hasSubselectLoadableCollections() {
 		return hasSubselectLoadableCollections;
 	}
 
 	public int[] getNaturalIdentifierProperties() {
 		return entityMetamodel.getNaturalIdentifierProperties();
 	}
 
-	public Object[] getNaturalIdentifierSnapshot(Serializable id, SessionImplementor session) throws HibernateException {
+	public Object[] getNaturalIdentifierSnapshot(Serializable id, SessionImplementor session)
+			throws HibernateException {
 		if ( !hasNaturalIdentifier() ) {
-			throw new MappingException( "persistent class did not define a natural-id : " + MessageHelper.infoString( this ) );
+			throw new MappingException(
+					"persistent class did not define a natural-id : " + MessageHelper.infoString(
+							this
+					)
+			);
 		}
 		if ( LOG.isTraceEnabled() ) {
-			LOG.tracev( "Getting current natural-id snapshot state for: {0}",
-					MessageHelper.infoString( this, id, getFactory() ) );
+			LOG.tracev(
+					"Getting current natural-id snapshot state for: {0}",
+					MessageHelper.infoString( this, id, getFactory() )
+			);
 		}
 
 		int[] naturalIdPropertyIndexes = getNaturalIdentifierProperties();
 		int naturalIdPropertyCount = naturalIdPropertyIndexes.length;
-		boolean[] naturalIdMarkers = new boolean[ getPropertySpan() ];
-		Type[] extractionTypes = new Type[ naturalIdPropertyCount ];
+		boolean[] naturalIdMarkers = new boolean[getPropertySpan()];
+		Type[] extractionTypes = new Type[naturalIdPropertyCount];
 		for ( int i = 0; i < naturalIdPropertyCount; i++ ) {
-			extractionTypes[i] = getPropertyTypes()[ naturalIdPropertyIndexes[i] ];
-			naturalIdMarkers[ naturalIdPropertyIndexes[i] ] = true;
+			extractionTypes[i] = getPropertyTypes()[naturalIdPropertyIndexes[i]];
+			naturalIdMarkers[naturalIdPropertyIndexes[i]] = true;
 		}
 
 		///////////////////////////////////////////////////////////////////////
 		// TODO : look at perhaps caching this...
 		Select select = new Select( getFactory().getDialect() );
-		if ( getFactory().getSettings().isCommentsEnabled() ) {
+		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			select.setComment( "get current natural-id state " + getEntityName() );
 		}
 		select.setSelectClause( concretePropertySelectFragmentSansLeadingComma( getRootAlias(), naturalIdMarkers ) );
 		select.setFromClause( fromTableFragment( getRootAlias() ) + fromJoinFragment( getRootAlias(), true, false ) );
 
 		String[] aliasedIdColumns = StringHelper.qualify( getRootAlias(), getIdentifierColumnNames() );
 		String whereClause = new StringBuilder()
-			.append( StringHelper.join( "=? and ",
-					aliasedIdColumns ) )
-			.append( "=?" )
-			.append( whereJoinFragment( getRootAlias(), true, false ) )
-			.toString();
+				.append(
+						StringHelper.join(
+								"=? and ",
+								aliasedIdColumns
+						)
+				)
+				.append( "=?" )
+				.append( whereJoinFragment( getRootAlias(), true, false ) )
+				.toString();
 
 		String sql = select.setOuterJoins( "", "" )
 				.setWhereClause( whereClause )
 				.toStatementString();
 		///////////////////////////////////////////////////////////////////////
 
-		Object[] snapshot = new Object[ naturalIdPropertyCount ];
+		Object[] snapshot = new Object[naturalIdPropertyCount];
 		try {
 			PreparedStatement ps = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( sql );
 			try {
 				getIdentifierType().nullSafeSet( ps, id, 1, session );
 				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					//if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 					final EntityKey key = session.generateEntityKey( id, this );
 					Object owner = session.getPersistenceContext().getEntity( key );
 					for ( int i = 0; i < naturalIdPropertyCount; i++ ) {
-						snapshot[i] = extractionTypes[i].hydrate( rs, getPropertyAliases( "", naturalIdPropertyIndexes[i] ), session, null );
-						if (extractionTypes[i].isEntityType()) {
-							snapshot[i] = extractionTypes[i].resolve(snapshot[i], session, owner);
+						snapshot[i] = extractionTypes[i].hydrate(
+								rs, getPropertyAliases(
+										"",
+										naturalIdPropertyIndexes[i]
+								), session, null
+						);
+						if ( extractionTypes[i].isEntityType() ) {
+							snapshot[i] = extractionTypes[i].resolve( snapshot[i], session, owner );
 						}
 					}
 					return snapshot;
 				}
 				finally {
 					session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( ps );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
-		catch ( SQLException e ) {
+		catch (SQLException e) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not retrieve snapshot: " + MessageHelper.infoString( this, id, getFactory() ),
-			        sql
+					sql
 			);
 		}
 	}
 
 	@Override
 	public Serializable loadEntityIdByNaturalId(
 			Object[] naturalIdValues,
 			LockOptions lockOptions,
 			SessionImplementor session) {
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracef(
 					"Resolving natural-id [%s] to id : %s ",
 					naturalIdValues,
 					MessageHelper.infoString( this )
 			);
 		}
 
 		final boolean[] valueNullness = determineValueNullness( naturalIdValues );
 		final String sqlEntityIdByNaturalIdString = determinePkByNaturalIdQuery( valueNullness );
 
 		try {
 			PreparedStatement ps = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( sqlEntityIdByNaturalIdString );
 			try {
 				int positions = 1;
 				int loop = 0;
 				for ( int idPosition : getNaturalIdentifierProperties() ) {
 					final Object naturalIdValue = naturalIdValues[loop++];
 					if ( naturalIdValue != null ) {
 						final Type type = getPropertyTypes()[idPosition];
 						type.nullSafeSet( ps, naturalIdValue, positions, session );
 						positions += type.getColumnSpan( session.getFactory() );
 					}
 				}
 				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					// if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 
 					final Object hydratedId = getIdentifierType().hydrate( rs, getIdentifierAliases(), session, null );
 					return (Serializable) getIdentifierType().resolve( hydratedId, session, null );
 				}
 				finally {
 					session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 				}
 			}
 			finally {
 				session.getJdbcCoordinator().getResourceRegistry().release( ps );
 				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
-		catch ( SQLException e ) {
+		catch (SQLException e) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					String.format(
 							"could not resolve natural-id [%s] to id : %s",
 							naturalIdValues,
 							MessageHelper.infoString( this )
 					),
 					sqlEntityIdByNaturalIdString
 			);
 		}
 	}
 
 	private boolean[] determineValueNullness(Object[] naturalIdValues) {
-		boolean[] nullness = new boolean[ naturalIdValues.length ];
+		boolean[] nullness = new boolean[naturalIdValues.length];
 		for ( int i = 0; i < naturalIdValues.length; i++ ) {
 			nullness[i] = naturalIdValues[i] == null;
 		}
 		return nullness;
 	}
 
 	private Boolean naturalIdIsNonNullable;
 	private String cachedPkByNonNullableNaturalIdQuery;
 
 	private String determinePkByNaturalIdQuery(boolean[] valueNullness) {
-		if ( ! hasNaturalIdentifier() ) {
-			throw new HibernateException( "Attempt to build natural-id -> PK resolution query for entity that does not define natural id" );
+		if ( !hasNaturalIdentifier() ) {
+			throw new HibernateException(
+					"Attempt to build natural-id -> PK resolution query for entity that does not define natural id"
+			);
 		}
 
 		// performance shortcut for cases where the natural-id is defined as completely non-nullable
 		if ( isNaturalIdNonNullable() ) {
-			if ( valueNullness != null && ! ArrayHelper.isAllFalse( valueNullness ) ) {
+			if ( valueNullness != null && !ArrayHelper.isAllFalse( valueNullness ) ) {
 				throw new HibernateException( "Null value(s) passed to lookup by non-nullable natural-id" );
 			}
 			if ( cachedPkByNonNullableNaturalIdQuery == null ) {
 				cachedPkByNonNullableNaturalIdQuery = generateEntityIdByNaturalIdSql( null );
 			}
 			return cachedPkByNonNullableNaturalIdQuery;
 		}
 
 		// Otherwise, regenerate it each time
 		return generateEntityIdByNaturalIdSql( valueNullness );
 	}
 
 	protected boolean isNaturalIdNonNullable() {
 		if ( naturalIdIsNonNullable == null ) {
 			naturalIdIsNonNullable = determineNaturalIdNullability();
 		}
 		return naturalIdIsNonNullable;
 	}
 
 	private boolean determineNaturalIdNullability() {
 		boolean[] nullability = getPropertyNullability();
 		for ( int position : getNaturalIdentifierProperties() ) {
 			// if any individual property is nullable, return false
 			if ( nullability[position] ) {
 				return false;
 			}
 		}
 		// return true if we found no individually nullable properties
 		return true;
 	}
 
 	private String generateEntityIdByNaturalIdSql(boolean[] valueNullness) {
 		EntityPersister rootPersister = getFactory().getEntityPersister( getRootEntityName() );
 		if ( rootPersister != this ) {
 			if ( rootPersister instanceof AbstractEntityPersister ) {
 				return ( (AbstractEntityPersister) rootPersister ).generateEntityIdByNaturalIdSql( valueNullness );
 			}
 		}
 
 		Select select = new Select( getFactory().getDialect() );
 		if ( getFactory().getSessionFactoryOptions().isCommentsEnabled() ) {
 			select.setComment( "get current natural-id->entity-id state " + getEntityName() );
 		}
 
 		final String rootAlias = getRootAlias();
 
 		select.setSelectClause( identifierSelectFragment( rootAlias, "" ) );
 		select.setFromClause( fromTableFragment( rootAlias ) + fromJoinFragment( rootAlias, true, false ) );
 
 		final StringBuilder whereClause = new StringBuilder();
 		final int[] propertyTableNumbers = getPropertyTableNumbers();
 		final int[] naturalIdPropertyIndexes = this.getNaturalIdentifierProperties();
 		int valuesIndex = -1;
 		for ( int propIdx = 0; propIdx < naturalIdPropertyIndexes.length; propIdx++ ) {
 			valuesIndex++;
 			if ( propIdx > 0 ) {
 				whereClause.append( " and " );
 			}
 
 			final int naturalIdIdx = naturalIdPropertyIndexes[propIdx];
 			final String tableAlias = generateTableAlias( rootAlias, propertyTableNumbers[naturalIdIdx] );
 			final String[] propertyColumnNames = getPropertyColumnNames( naturalIdIdx );
 			final String[] aliasedPropertyColumns = StringHelper.qualify( tableAlias, propertyColumnNames );
 
 			if ( valueNullness != null && valueNullness[valuesIndex] ) {
 				whereClause.append( StringHelper.join( " is null and ", aliasedPropertyColumns ) ).append( " is null" );
 			}
 			else {
 				whereClause.append( StringHelper.join( "=? and ", aliasedPropertyColumns ) ).append( "=?" );
 			}
 		}
 
 		whereClause.append( whereJoinFragment( getRootAlias(), true, false ) );
 
 		return select.setOuterJoins( "", "" ).setWhereClause( whereClause.toString() ).toStatementString();
 	}
 
 	protected String concretePropertySelectFragmentSansLeadingComma(String alias, boolean[] include) {
 		String concretePropertySelectFragment = concretePropertySelectFragment( alias, include );
 		int firstComma = concretePropertySelectFragment.indexOf( ", " );
 		if ( firstComma == 0 ) {
 			concretePropertySelectFragment = concretePropertySelectFragment.substring( 2 );
 		}
 		return concretePropertySelectFragment;
 	}
 
 	public boolean hasNaturalIdentifier() {
 		return entityMetamodel.hasNaturalIdentifier();
 	}
 
 	public void setPropertyValue(Object object, String propertyName, Object value) {
 		getEntityTuplizer().setPropertyValue( object, propertyName, value );
 	}
-	
+
 	public static int getTableId(String tableName, String[] tables) {
 		for ( int j = 0; j < tables.length; j++ ) {
 			if ( tableName.equalsIgnoreCase( tables[j] ) ) {
 				return j;
 			}
 		}
 		throw new AssertionFailure( "Table " + tableName + " not found" );
 	}
-	
+
 	@Override
 	public EntityMode getEntityMode() {
 		return entityMetamodel.getEntityMode();
 	}
 
 	@Override
 	public EntityTuplizer getEntityTuplizer() {
 		return entityTuplizer;
 	}
 
 	@Override
 	public EntityInstrumentationMetadata getInstrumentationMetadata() {
 		return entityMetamodel.getInstrumentationMetadata();
 	}
 
 	@Override
 	public String getTableAliasForColumn(String columnName, String rootAlias) {
 		return generateTableAlias( rootAlias, determineTableNumberForColumn( columnName ) );
 	}
 
 	public int determineTableNumberForColumn(String columnName) {
 		return 0;
 	}
 
 	@Override
 	public EntityEntryFactory getEntityEntryFactory() {
 		return this.entityEntryFactory;
 	}
 
 	/**
 	 * Consolidated these onto a single helper because the 2 pieces work in tandem.
 	 */
 	public interface CacheEntryHelper {
 		CacheEntryStructure getCacheEntryStructure();
+
 		CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session);
 	}
 
 	private static class StandardCacheEntryHelper implements CacheEntryHelper {
 		private final EntityPersister persister;
 
 		private StandardCacheEntryHelper(EntityPersister persister) {
 			this.persister = persister;
 		}
 
 		@Override
 		public CacheEntryStructure getCacheEntryStructure() {
 			return UnstructuredCacheEntry.INSTANCE;
 		}
 
 		@Override
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 			return new StandardCacheEntryImpl(
 					state,
 					persister,
 					persister.hasUninitializedLazyProperties( entity ),
 					version,
 					session,
 					entity
 			);
 		}
 	}
 
 	private static class ReferenceCacheEntryHelper implements CacheEntryHelper {
 		private final EntityPersister persister;
 
 		private ReferenceCacheEntryHelper(EntityPersister persister) {
 			this.persister = persister;
 		}
 
 		@Override
 		public CacheEntryStructure getCacheEntryStructure() {
 			return UnstructuredCacheEntry.INSTANCE;
 		}
 
 		@Override
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 			return new ReferenceCacheEntryImpl( entity, persister );
 		}
 	}
 
 	private static class StructuredCacheEntryHelper implements CacheEntryHelper {
 		private final EntityPersister persister;
 		private final StructuredCacheEntry structure;
 
 		private StructuredCacheEntryHelper(EntityPersister persister) {
 			this.persister = persister;
 			this.structure = new StructuredCacheEntry( persister );
 		}
 
 		@Override
 		public CacheEntryStructure getCacheEntryStructure() {
 			return structure;
 		}
 
 		@Override
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 			return new StandardCacheEntryImpl(
 					state,
 					persister,
 					persister.hasUninitializedLazyProperties( entity ),
 					version,
 					session,
 					entity
 			);
 		}
 	}
 
 	private static class NoopCacheEntryHelper implements CacheEntryHelper {
 		public static final NoopCacheEntryHelper INSTANCE = new NoopCacheEntryHelper();
 
 		@Override
 		public CacheEntryStructure getCacheEntryStructure() {
 			return UnstructuredCacheEntry.INSTANCE;
 		}
 
 		@Override
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 			throw new HibernateException( "Illegal attempt to build cache entry for non-cached entity" );
 		}
 	}
 
 
 	// EntityDefinition impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private EntityIdentifierDefinition entityIdentifierDefinition;
 	private Iterable<AttributeDefinition> embeddedCompositeIdentifierAttributes;
 	private Iterable<AttributeDefinition> attributeDefinitions;
 
 	@Override
 	public void generateEntityDefinition() {
 		prepareEntityIdentifierDefinition();
 		collectAttributeDefinitions();
 	}
 
 	@Override
 	public EntityPersister getEntityPersister() {
 		return this;
 	}
 
 	@Override
 	public EntityIdentifierDefinition getEntityKeyDefinition() {
 		return entityIdentifierDefinition;
 	}
 
 	@Override
 	public Iterable<AttributeDefinition> getAttributes() {
 		return attributeDefinitions;
 	}
 
 
 	private void prepareEntityIdentifierDefinition() {
 		if ( entityIdentifierDefinition != null ) {
 			return;
 		}
 		final Type idType = getIdentifierType();
 
 		if ( !idType.isComponentType() ) {
 			entityIdentifierDefinition =
 					EntityIdentifierDefinitionHelper.buildSimpleEncapsulatedIdentifierDefinition( this );
 			return;
 		}
 
 		final CompositeType cidType = (CompositeType) idType;
 		if ( !cidType.isEmbedded() ) {
 			entityIdentifierDefinition =
 					EntityIdentifierDefinitionHelper.buildEncapsulatedCompositeIdentifierDefinition( this );
 			return;
 		}
 
 		entityIdentifierDefinition =
 				EntityIdentifierDefinitionHelper.buildNonEncapsulatedCompositeIdentifierDefinition( this );
 	}
 
 	private void collectAttributeDefinitions(
-			Map<String,AttributeDefinition> attributeDefinitionsByName,
+			Map<String, AttributeDefinition> attributeDefinitionsByName,
 			EntityMetamodel metamodel) {
 		for ( int i = 0; i < metamodel.getPropertySpan(); i++ ) {
 			final AttributeDefinition attributeDefinition = metamodel.getProperties()[i];
 			// Don't replace an attribute definition if it is already in attributeDefinitionsByName
 			// because the new value will be from a subclass.
 			final AttributeDefinition oldAttributeDefinition = attributeDefinitionsByName.get(
 					attributeDefinition.getName()
 			);
 			if ( oldAttributeDefinition != null ) {
 				if ( LOG.isTraceEnabled() ) {
-						LOG.tracef(
-								"Ignoring subclass attribute definition [%s.%s] because it is defined in a superclass ",
-								entityMetamodel.getName(),
-								attributeDefinition.getName()
-						);
+					LOG.tracef(
+							"Ignoring subclass attribute definition [%s.%s] because it is defined in a superclass ",
+							entityMetamodel.getName(),
+							attributeDefinition.getName()
+					);
 				}
 			}
 			else {
 				attributeDefinitionsByName.put( attributeDefinition.getName(), attributeDefinition );
 			}
 		}
 
 		// see if there are any subclass persisters...
 		final Set<String> subClassEntityNames = metamodel.getSubclassEntityNames();
 		if ( subClassEntityNames == null ) {
 			return;
 		}
 
 		// see if we can find the persisters...
 		for ( String subClassEntityName : subClassEntityNames ) {
 			if ( metamodel.getName().equals( subClassEntityName ) ) {
 				// skip it
 				continue;
 			}
 			try {
 				final EntityPersister subClassEntityPersister = factory.getEntityPersister( subClassEntityName );
 				collectAttributeDefinitions( attributeDefinitionsByName, subClassEntityPersister.getEntityMetamodel() );
 			}
 			catch (MappingException e) {
 				throw new IllegalStateException(
 						String.format(
 								"Could not locate subclass EntityPersister [%s] while processing EntityPersister [%s]",
 								subClassEntityName,
 								metamodel.getName()
 						),
 						e
 				);
 			}
 		}
 	}
 
 	private void collectAttributeDefinitions() {
 		// todo : I think this works purely based on luck atm
 		// 		specifically in terms of the sub/super class entity persister(s) being available.  Bit of chicken-egg
 		// 		problem there:
 		//			* If I do this during postConstruct (as it is now), it works as long as the
 		//			super entity persister is already registered, but I don't think that is necessarily true.
 		//			* If I do this during postInstantiate then lots of stuff in postConstruct breaks if we want
 		//			to try and drive SQL generation on these (which we do ultimately).  A possible solution there
 		//			would be to delay all SQL generation until postInstantiate
 
-		Map<String,AttributeDefinition> attributeDefinitionsByName = new LinkedHashMap<String,AttributeDefinition>();
+		Map<String, AttributeDefinition> attributeDefinitionsByName = new LinkedHashMap<String, AttributeDefinition>();
 		collectAttributeDefinitions( attributeDefinitionsByName, getEntityMetamodel() );
 
 
 //		EntityMetamodel currentEntityMetamodel = this.getEntityMetamodel();
 //		while ( currentEntityMetamodel != null ) {
 //			for ( int i = 0; i < currentEntityMetamodel.getPropertySpan(); i++ ) {
 //				attributeDefinitions.add( currentEntityMetamodel.getProperties()[i] );
 //			}
 //			// see if there is a super class EntityMetamodel
 //			final String superEntityName = currentEntityMetamodel.getSuperclass();
 //			if ( superEntityName != null ) {
 //				currentEntityMetamodel = factory.getEntityPersister( superEntityName ).getEntityMetamodel();
 //			}
 //			else {
 //				currentEntityMetamodel = null;
 //			}
 //		}
 
 		this.attributeDefinitions = Collections.unmodifiableList(
 				new ArrayList<AttributeDefinition>( attributeDefinitionsByName.values() )
 		);
 //		// todo : leverage the attribute definitions housed on EntityMetamodel
 //		// 		for that to work, we'd have to be able to walk our super entity persister(s)
 //		this.attributeDefinitions = new Iterable<AttributeDefinition>() {
 //			@Override
 //			public Iterator<AttributeDefinition> iterator() {
 //				return new Iterator<AttributeDefinition>() {
 ////					private final int numberOfAttributes = countSubclassProperties();
 ////					private final int numberOfAttributes = entityMetamodel.getPropertySpan();
 //
 //					EntityMetamodel currentEntityMetamodel = entityMetamodel;
 //					int numberOfAttributesInCurrentEntityMetamodel = currentEntityMetamodel.getPropertySpan();
 //
 //					private int currentAttributeNumber;
 //
 //					@Override
 //					public boolean hasNext() {
 //						return currentEntityMetamodel != null
 //								&& currentAttributeNumber < numberOfAttributesInCurrentEntityMetamodel;
 //					}
 //
 //					@Override
 //					public AttributeDefinition next() {
 //						final int attributeNumber = currentAttributeNumber;
 //						currentAttributeNumber++;
 //						final AttributeDefinition next = currentEntityMetamodel.getProperties()[ attributeNumber ];
 //
 //						if ( currentAttributeNumber >= numberOfAttributesInCurrentEntityMetamodel ) {
 //							// see if there is a super class EntityMetamodel
 //							final String superEntityName = currentEntityMetamodel.getSuperclass();
 //							if ( superEntityName != null ) {
 //								currentEntityMetamodel = factory.getEntityPersister( superEntityName ).getEntityMetamodel();
 //								if ( currentEntityMetamodel != null ) {
 //									numberOfAttributesInCurrentEntityMetamodel = currentEntityMetamodel.getPropertySpan();
 //									currentAttributeNumber = 0;
 //								}
 //							}
 //						}
 //
 //						return next;
 //					}
 //
 //					@Override
 //					public void remove() {
 //						throw new UnsupportedOperationException( "Remove operation not supported here" );
 //					}
 //				};
 //			}
 //		};
 	}
 
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractPropertyMapping.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractPropertyMapping.java
index 6b77d61c0d..8ea772b8b6 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractPropertyMapping.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractPropertyMapping.java
@@ -1,299 +1,330 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.entity;
 
 import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.sql.Template;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
-import org.jboss.logging.Logger;
-
 /**
  * Basic implementation of the {@link PropertyMapping} contract.
  *
  * @author Gavin King
  */
 public abstract class AbstractPropertyMapping implements PropertyMapping {
-    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( AbstractPropertyMapping.class );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( AbstractPropertyMapping.class );
 
-	private final Map typesByPropertyPath = new HashMap();
-	private final Map columnsByPropertyPath = new HashMap();
-	private final Map columnReadersByPropertyPath = new HashMap();
-	private final Map columnReaderTemplatesByPropertyPath = new HashMap();
-	private final Map formulaTemplatesByPropertyPath = new HashMap();
+	private final Map<String, Type> typesByPropertyPath = new HashMap<String, Type>();
+	private final Map<String, String[]> columnsByPropertyPath = new HashMap<String, String[]>();
+	private final Map<String, String[]> columnReadersByPropertyPath = new HashMap<String, String[]>();
+	private final Map<String, String[]> columnReaderTemplatesByPropertyPath = new HashMap<String, String[]>();
+	private final Map<String, String[]> formulaTemplatesByPropertyPath = new HashMap<String, String[]>();
 
 	public String[] getIdentifierColumnNames() {
-		throw new UnsupportedOperationException("one-to-one is not supported here");
+		throw new UnsupportedOperationException( "one-to-one is not supported here" );
 	}
 
 	public String[] getIdentifierColumnReaderTemplates() {
-		throw new UnsupportedOperationException("one-to-one is not supported here");
+		throw new UnsupportedOperationException( "one-to-one is not supported here" );
 	}
 
 	public String[] getIdentifierColumnReaders() {
-		throw new UnsupportedOperationException("one-to-one is not supported here");
+		throw new UnsupportedOperationException( "one-to-one is not supported here" );
 	}
 
 	protected abstract String getEntityName();
 
 	public Type toType(String propertyName) throws QueryException {
-		Type type = (Type) typesByPropertyPath.get(propertyName);
+		Type type = typesByPropertyPath.get( propertyName );
 		if ( type == null ) {
 			throw propertyException( propertyName );
 		}
 		return type;
 	}
 
 	protected final QueryException propertyException(String propertyName) throws QueryException {
 		return new QueryException( "could not resolve property: " + propertyName + " of: " + getEntityName() );
 	}
 
 	public String[] getColumnNames(String propertyName) {
-		String[] cols = (String[]) columnsByPropertyPath.get(propertyName);
-		if (cols==null) {
-			throw new MappingException("unknown property: " + propertyName);
+		String[] cols = columnsByPropertyPath.get( propertyName );
+		if ( cols == null ) {
+			throw new MappingException( "unknown property: " + propertyName );
 		}
 		return cols;
 	}
 
 	public String[] toColumns(String alias, String propertyName) throws QueryException {
 		//TODO: *two* hashmap lookups here is one too many...
-		String[] columns = (String[]) columnsByPropertyPath.get(propertyName);
+		String[] columns = columnsByPropertyPath.get( propertyName );
 		if ( columns == null ) {
 			throw propertyException( propertyName );
 		}
-		String[] formulaTemplates = (String[]) formulaTemplatesByPropertyPath.get(propertyName);
-		String[] columnReaderTemplates = (String[]) columnReaderTemplatesByPropertyPath.get(propertyName);
+		String[] formulaTemplates = formulaTemplatesByPropertyPath.get( propertyName );
+		String[] columnReaderTemplates = columnReaderTemplatesByPropertyPath.get( propertyName );
 		String[] result = new String[columns.length];
-		for ( int i=0; i<columns.length; i++ ) {
-			if ( columnReaderTemplates[i]==null ) {
+		for ( int i = 0; i < columns.length; i++ ) {
+			if ( columnReaderTemplates[i] == null ) {
 				result[i] = StringHelper.replace( formulaTemplates[i], Template.TEMPLATE, alias );
 			}
 			else {
 				result[i] = StringHelper.replace( columnReaderTemplates[i], Template.TEMPLATE, alias );
 			}
 		}
 		return result;
 	}
 
 	public String[] toColumns(String propertyName) throws QueryException {
-		String[] columns = (String[]) columnsByPropertyPath.get(propertyName);
+		String[] columns = columnsByPropertyPath.get( propertyName );
 		if ( columns == null ) {
 			throw propertyException( propertyName );
 		}
-		String[] formulaTemplates = (String[]) formulaTemplatesByPropertyPath.get(propertyName);
-		String[] columnReaders = (String[]) columnReadersByPropertyPath.get(propertyName);
+		String[] formulaTemplates = formulaTemplatesByPropertyPath.get( propertyName );
+		String[] columnReaders = columnReadersByPropertyPath.get( propertyName );
 		String[] result = new String[columns.length];
-		for ( int i=0; i<columns.length; i++ ) {
-			if ( columnReaders[i]==null ) {
+		for ( int i = 0; i < columns.length; i++ ) {
+			if ( columnReaders[i] == null ) {
 				result[i] = StringHelper.replace( formulaTemplates[i], Template.TEMPLATE, "" );
 			}
 			else {
 				result[i] = columnReaders[i];
 			}
 		}
 		return result;
 	}
 
 	protected void addPropertyPath(
 			String path,
 			Type type,
 			String[] columns,
 			String[] columnReaders,
 			String[] columnReaderTemplates,
 			String[] formulaTemplates) {
 		// TODO : not quite sure yet of the difference, but this is only needed from annotations for @Id @ManyToOne support
 		if ( typesByPropertyPath.containsKey( path ) ) {
 			if ( LOG.isTraceEnabled() ) {
-				LOG.tracev( "Skipping duplicate registration of path [{0}], existing type = [{1}], incoming type = [{2}]", path, typesByPropertyPath.get( path ), type );
+				LOG.tracev(
+						"Skipping duplicate registration of path [{0}], existing type = [{1}], incoming type = [{2}]",
+						path,
+						typesByPropertyPath.get( path ),
+						type
+				);
 			}
 			return;
 		}
-		typesByPropertyPath.put(path, type);
-		columnsByPropertyPath.put(path, columns);
-		columnReadersByPropertyPath.put(path, columnReaders);
-		columnReaderTemplatesByPropertyPath.put(path, columnReaderTemplates);
-		if (formulaTemplates!=null) {
-			formulaTemplatesByPropertyPath.put(path, formulaTemplates);
+		typesByPropertyPath.put( path, type );
+		columnsByPropertyPath.put( path, columns );
+		columnReadersByPropertyPath.put( path, columnReaders );
+		columnReaderTemplatesByPropertyPath.put( path, columnReaderTemplates );
+		if ( formulaTemplates != null ) {
+			formulaTemplatesByPropertyPath.put( path, formulaTemplates );
 		}
 	}
 
 	/*protected void initPropertyPaths(
 			final String path,
 			final Type type,
 			final String[] columns,
 			final String[] formulaTemplates,
 			final Mapping factory)
 	throws MappingException {
 		//addFormulaPropertyPath(path, type, formulaTemplates);
 		initPropertyPaths(path, type, columns, formulaTemplates, factory);
 	}*/
 
 	protected void initPropertyPaths(
 			final String path,
 			final Type type,
 			String[] columns,
 			String[] columnReaders,
 			String[] columnReaderTemplates,
 			final String[] formulaTemplates,
 			final Mapping factory) throws MappingException {
 		assert columns != null : "Incoming columns should not be null : " + path;
 		assert type != null : "Incoming type should not be null : " + path;
 
-		if ( columns.length!=type.getColumnSpan(factory) ) {
+		if ( columns.length != type.getColumnSpan( factory ) ) {
 			throw new MappingException(
 					"broken column mapping for: " + path +
-					" of: " + getEntityName()
-				);
+							" of: " + getEntityName()
+			);
 		}
 
 		if ( type.isAssociationType() ) {
 			AssociationType actype = (AssociationType) type;
 			if ( actype.useLHSPrimaryKey() ) {
 				columns = getIdentifierColumnNames();
 				columnReaders = getIdentifierColumnReaders();
 				columnReaderTemplates = getIdentifierColumnReaderTemplates();
 			}
 			else {
 				String foreignKeyProperty = actype.getLHSPropertyName();
-				if ( foreignKeyProperty!=null && !path.equals(foreignKeyProperty) ) {
+				if ( foreignKeyProperty != null && !path.equals( foreignKeyProperty ) ) {
 					//TODO: this requires that the collection is defined after the
 					//      referenced property in the mapping file (ok?)
-					columns = (String[]) columnsByPropertyPath.get(foreignKeyProperty);
-					if (columns==null) return; //get em on the second pass!
-					columnReaders = (String[]) columnReadersByPropertyPath.get(foreignKeyProperty);
-					columnReaderTemplates = (String[]) columnReaderTemplatesByPropertyPath.get(foreignKeyProperty);
+					columns = columnsByPropertyPath.get( foreignKeyProperty );
+					if ( columns == null ) {
+						return; //get em on the second pass!
+					}
+					columnReaders = columnReadersByPropertyPath.get( foreignKeyProperty );
+					columnReaderTemplates = columnReaderTemplatesByPropertyPath.get( foreignKeyProperty );
 				}
 			}
 		}
 
-		if (path!=null) {
-			addPropertyPath(path, type, columns, columnReaders, columnReaderTemplates, formulaTemplates);
+		if ( path != null ) {
+			addPropertyPath( path, type, columns, columnReaders, columnReaderTemplates, formulaTemplates );
 		}
 
 		if ( type.isComponentType() ) {
 			CompositeType actype = (CompositeType) type;
-			initComponentPropertyPaths( path, actype, columns, columnReaders, columnReaderTemplates, formulaTemplates, factory );
+			initComponentPropertyPaths(
+					path,
+					actype,
+					columns,
+					columnReaders,
+					columnReaderTemplates,
+					formulaTemplates,
+					factory
+			);
 			if ( actype.isEmbedded() ) {
 				initComponentPropertyPaths(
-						path==null ? null : StringHelper.qualifier(path),
+						path == null ? null : StringHelper.qualifier( path ),
 						actype,
 						columns,
 						columnReaders,
 						columnReaderTemplates,
 						formulaTemplates,
 						factory
-					);
+				);
 			}
 		}
 		else if ( type.isEntityType() ) {
-			initIdentifierPropertyPaths( path, (EntityType) type, columns, columnReaders, columnReaderTemplates, factory );
+			initIdentifierPropertyPaths(
+					path,
+					(EntityType) type,
+					columns,
+					columnReaders,
+					columnReaderTemplates,
+					factory
+			);
 		}
 	}
 
 	protected void initIdentifierPropertyPaths(
 			final String path,
 			final EntityType etype,
 			final String[] columns,
 			final String[] columnReaders,
 			final String[] columnReaderTemplates,
 			final Mapping factory) throws MappingException {
 
 		Type idtype = etype.getIdentifierOrUniqueKeyType( factory );
-		String idPropName = etype.getIdentifierOrUniqueKeyPropertyName(factory);
+		String idPropName = etype.getIdentifierOrUniqueKeyPropertyName( factory );
 		boolean hasNonIdentifierPropertyNamedId = hasNonIdentifierPropertyNamedId( etype, factory );
 
 		if ( etype.isReferenceToPrimaryKey() ) {
 			if ( !hasNonIdentifierPropertyNamedId ) {
-				String idpath1 = extendPath(path, EntityPersister.ENTITY_ID);
-				addPropertyPath(idpath1, idtype, columns, columnReaders, columnReaderTemplates, null);
-				initPropertyPaths(idpath1, idtype, columns, columnReaders, columnReaderTemplates, null, factory);
+				String idpath1 = extendPath( path, EntityPersister.ENTITY_ID );
+				addPropertyPath( idpath1, idtype, columns, columnReaders, columnReaderTemplates, null );
+				initPropertyPaths( idpath1, idtype, columns, columnReaders, columnReaderTemplates, null, factory );
 			}
 		}
 
-		if (idPropName!=null) {
-			String idpath2 = extendPath(path, idPropName);
-			addPropertyPath(idpath2, idtype, columns, columnReaders, columnReaderTemplates, null);
-			initPropertyPaths(idpath2, idtype, columns, columnReaders, columnReaderTemplates, null, factory);
+		if ( idPropName != null ) {
+			String idpath2 = extendPath( path, idPropName );
+			addPropertyPath( idpath2, idtype, columns, columnReaders, columnReaderTemplates, null );
+			initPropertyPaths( idpath2, idtype, columns, columnReaders, columnReaderTemplates, null, factory );
 		}
 	}
 
 	private boolean hasNonIdentifierPropertyNamedId(final EntityType entityType, final Mapping factory) {
 		// TODO : would be great to have a Mapping#hasNonIdentifierPropertyNamedId method
 		// I don't believe that Mapping#getReferencedPropertyType accounts for the identifier property; so
 		// if it returns for a property named 'id', then we should have a non-id field named id
 		try {
-			return factory.getReferencedPropertyType( entityType.getAssociatedEntityName(), EntityPersister.ENTITY_ID ) != null;
+			return factory.getReferencedPropertyType(
+					entityType.getAssociatedEntityName(),
+					EntityPersister.ENTITY_ID
+			) != null;
 		}
-		catch( MappingException e ) {
+		catch (MappingException e) {
 			return false;
 		}
 	}
 
 	protected void initComponentPropertyPaths(
 			final String path,
 			final CompositeType type,
 			final String[] columns,
 			final String[] columnReaders,
 			final String[] columnReaderTemplates,
 			String[] formulaTemplates, final Mapping factory) throws MappingException {
 
 		Type[] types = type.getSubtypes();
 		String[] properties = type.getPropertyNames();
-		int begin=0;
-		for ( int i=0; i<properties.length; i++ ) {
+		int begin = 0;
+		for ( int i = 0; i < properties.length; i++ ) {
 			String subpath = extendPath( path, properties[i] );
 			try {
-				int length = types[i].getColumnSpan(factory);
-				String[] columnSlice = ArrayHelper.slice(columns, begin, length);
-				String[] columnReaderSlice = ArrayHelper.slice(columnReaders, begin, length);
+				int length = types[i].getColumnSpan( factory );
+				String[] columnSlice = ArrayHelper.slice( columns, begin, length );
+				String[] columnReaderSlice = ArrayHelper.slice( columnReaders, begin, length );
 				String[] columnReaderTemplateSlice = ArrayHelper.slice( columnReaderTemplates, begin, length );
-				String[] formulaSlice = formulaTemplates==null ?
-						null : ArrayHelper.slice(formulaTemplates, begin, length);
-				initPropertyPaths(subpath, types[i], columnSlice, columnReaderSlice, columnReaderTemplateSlice, formulaSlice, factory);
-				begin+=length;
+				String[] formulaSlice = formulaTemplates == null ?
+						null : ArrayHelper.slice( formulaTemplates, begin, length );
+				initPropertyPaths(
+						subpath,
+						types[i],
+						columnSlice,
+						columnReaderSlice,
+						columnReaderTemplateSlice,
+						formulaSlice,
+						factory
+				);
+				begin += length;
 			}
 			catch (Exception e) {
-				throw new MappingException("bug in initComponentPropertyPaths", e);
+				throw new MappingException( "bug in initComponentPropertyPaths", e );
 			}
 		}
 	}
 
 	private static String extendPath(String path, String property) {
 		return StringHelper.isEmpty( path ) ? property : StringHelper.qualify( path, property );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/DiscriminatorType.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/DiscriminatorType.java
index a0a9b983d1..972c6be668 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/DiscriminatorType.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/DiscriminatorType.java
@@ -1,166 +1,166 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.entity;
 
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Map;
 
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
+import org.hibernate.engine.jdbc.Size;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.internal.util.compare.EqualsHelper;
-import org.hibernate.engine.jdbc.Size;
 import org.hibernate.type.AbstractType;
 import org.hibernate.type.Type;
 
 import org.dom4j.Node;
 
 /**
  * TODO : javadoc
  *
  * @author Steve Ebersole
  */
 public class DiscriminatorType extends AbstractType {
 	private final Type underlyingType;
 	private final Loadable persister;
 
 	public DiscriminatorType(Type underlyingType, Loadable persister) {
 		this.underlyingType = underlyingType;
 		this.persister = persister;
 	}
 
 	public Class getReturnedClass() {
 		return Class.class;
 	}
 
 	public String getName() {
 		return getClass().getName();
 	}
 
 	public boolean isMutable() {
 		return false;
 	}
 
 	public Object nullSafeGet(
 			ResultSet rs,
 			String[] names,
 			SessionImplementor session,
 			Object owner) throws HibernateException, SQLException {
 		return nullSafeGet( rs, names[0], session, owner );
 	}
 
 	public Object nullSafeGet(
 			ResultSet rs,
 			String name,
 			SessionImplementor session,
 			Object owner) throws HibernateException, SQLException {
 		final Object discriminatorValue = underlyingType.nullSafeGet( rs, name, session, owner );
 		final String entityName = persister.getSubclassForDiscriminatorValue( discriminatorValue );
 		if ( entityName == null ) {
 			throw new HibernateException( "Unable to resolve discriminator value [" + discriminatorValue + "] to entity name" );
 		}
 		final EntityPersister entityPersister = session.getEntityPersister( entityName, null );
-        return ( EntityMode.POJO == entityPersister.getEntityMode() ) ? entityPersister.getMappedClass() : entityName;
+		return ( EntityMode.POJO == entityPersister.getEntityMode() ) ? entityPersister.getMappedClass() : entityName;
 	}
 
 	public void nullSafeSet(
 			PreparedStatement st,
 			Object value,
 			int index,
 			boolean[] settable,
 			SessionImplementor session) throws HibernateException, SQLException {
 		nullSafeSet( st, value, index, session );
 	}
 
 	public void nullSafeSet(
 			PreparedStatement st,
 			Object value,
 			int index,
 			SessionImplementor session) throws HibernateException, SQLException {
 		String entityName = session.getFactory().getClassMetadata((Class) value).getEntityName();
 		Loadable entityPersister = (Loadable) session.getFactory().getEntityPersister(entityName);
 		underlyingType.nullSafeSet(st, entityPersister.getDiscriminatorValue(), index, session);
 	}
 
 	public String toLoggableString(Object value, SessionFactoryImplementor factory) throws HibernateException {
 		return value == null ? "[null]" : value.toString();
 	}
 
 	public Object deepCopy(Object value, SessionFactoryImplementor factory)
 			throws HibernateException {
 		return value;
 	}
 
 	public Object replace(Object original, Object target, SessionImplementor session, Object owner, Map copyCache)
 			throws HibernateException {
 		return original;
 	}
 
 	public boolean[] toColumnNullness(Object value, Mapping mapping) {
 		return value == null
 				? ArrayHelper.FALSE
 				: ArrayHelper.TRUE;
 	}
 
 	public boolean isDirty(Object old, Object current, boolean[] checkable, SessionImplementor session)
 			throws HibernateException {
 		return EqualsHelper.equals( old, current );
 	}
 
 
 	// simple delegation ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public int[] sqlTypes(Mapping mapping) throws MappingException {
 		return underlyingType.sqlTypes( mapping );
 	}
 
 	@Override
 	public Size[] dictatedSizes(Mapping mapping) throws MappingException {
 		return underlyingType.dictatedSizes( mapping );
 	}
 
 	@Override
 	public Size[] defaultSizes(Mapping mapping) throws MappingException {
 		return underlyingType.defaultSizes( mapping );
 	}
 
 	public int getColumnSpan(Mapping mapping) throws MappingException {
 		return underlyingType.getColumnSpan( mapping );
 	}
 
 	public void setToXMLNode(Node node, Object value, SessionFactoryImplementor factory) throws HibernateException {
 	}
 
 	public Object fromXMLNode(Node xml, Mapping factory) throws HibernateException {
 		// todo : ???
 		return null;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/SingleTableEntityPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/SingleTableEntityPersister.java
index 36cfdd4b6f..1d612a5a93 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/SingleTableEntityPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/SingleTableEntityPersister.java
@@ -1,837 +1,845 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.entity;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.DynamicFilterAliasGenerator;
 import org.hibernate.internal.FilterAliasGenerator;
 import org.hibernate.internal.util.MarkerObject;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Formula;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.mapping.Subclass;
 import org.hibernate.mapping.Table;
 import org.hibernate.mapping.Value;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.sql.InFragment;
 import org.hibernate.sql.Insert;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.DiscriminatorType;
 import org.hibernate.type.Type;
 
 /**
  * The default implementation of the <tt>EntityPersister</tt> interface.
  * Implements the "table-per-class-hierarchy" or "roll-up" mapping strategy
  * for an entity class and its inheritence hierarchy.  This is implemented
  * as a single table holding all classes in the hierarchy with a discrimator
  * column used to determine which concrete class is referenced.
  *
  * @author Gavin King
  */
 public class SingleTableEntityPersister extends AbstractEntityPersister {
 
 	// the class hierarchy structure
 	private final int joinSpan;
 	private final String[] qualifiedTableNames;
 	private final boolean[] isInverseTable;
 	private final boolean[] isNullableTable;
 	private final String[][] keyColumnNames;
 	private final boolean[] cascadeDeleteEnabled;
 	private final boolean hasSequentialSelects;
-	
+
 	private final String[] spaces;
 
 	private final String[] subclassClosure;
 
 	private final String[] subclassTableNameClosure;
 	private final boolean[] subclassTableIsLazyClosure;
 	private final boolean[] isInverseSubclassTable;
 	private final boolean[] isNullableSubclassTable;
 	private final boolean[] subclassTableSequentialSelect;
 	private final String[][] subclassTableKeyColumnClosure;
 	private final boolean[] isClassOrSuperclassTable;
 
 	// properties of this class, including inherited properties
 	private final int[] propertyTableNumbers;
 
 	// the closure of all columns used by the entire hierarchy including
 	// subclasses and superclasses of this class
 	private final int[] subclassPropertyTableNumberClosure;
 
 	private final int[] subclassColumnTableNumberClosure;
 	private final int[] subclassFormulaTableNumberClosure;
 
 	// discriminator column
-	private final Map subclassesByDiscriminatorValue = new HashMap();
+	private final Map<Object, String> subclassesByDiscriminatorValue = new HashMap<Object, String>();
 	private final boolean forceDiscriminator;
 	private final String discriminatorColumnName;
 	private final String discriminatorColumnReaders;
 	private final String discriminatorColumnReaderTemplate;
 	private final String discriminatorFormula;
 	private final String discriminatorFormulaTemplate;
 	private final String discriminatorAlias;
 	private final Type discriminatorType;
 	private final Object discriminatorValue;
 	private final String discriminatorSQLValue;
 	private final boolean discriminatorInsertable;
 
 	private final String[] constraintOrderedTableNames;
 	private final String[][] constraintOrderedKeyColumnNames;
 
 	//private final Map propertyTableNumbersByName = new HashMap();
-	private final Map propertyTableNumbersByNameAndSubclass = new HashMap();
-	
-	private final Map sequentialSelectStringsByEntityName = new HashMap();
+	private final Map<String, Integer> propertyTableNumbersByNameAndSubclass = new HashMap<String, Integer>();
+
+	private final Map<String, String> sequentialSelectStringsByEntityName = new HashMap<String, String>();
 
-	private static final Object NULL_DISCRIMINATOR = new MarkerObject("<null discriminator>");
-	private static final Object NOT_NULL_DISCRIMINATOR = new MarkerObject("<not null discriminator>");
+	private static final Object NULL_DISCRIMINATOR = new MarkerObject( "<null discriminator>" );
+	private static final Object NOT_NULL_DISCRIMINATOR = new MarkerObject( "<not null discriminator>" );
 	private static final String NULL_STRING = "null";
 	private static final String NOT_NULL_STRING = "not null";
 
 	//INITIALIZATION:
 
 	public SingleTableEntityPersister(
-			final PersistentClass persistentClass, 
+			final PersistentClass persistentClass,
 			final EntityRegionAccessStrategy cacheAccessStrategy,
 			final NaturalIdRegionAccessStrategy naturalIdRegionAccessStrategy,
 			final PersisterCreationContext creationContext) throws HibernateException {
 
 		super( persistentClass, cacheAccessStrategy, naturalIdRegionAccessStrategy, creationContext );
 
 		final SessionFactoryImplementor factory = creationContext.getSessionFactory();
 
 		// CLASS + TABLE
 
-		joinSpan = persistentClass.getJoinClosureSpan()+1;
+		joinSpan = persistentClass.getJoinClosureSpan() + 1;
 		qualifiedTableNames = new String[joinSpan];
 		isInverseTable = new boolean[joinSpan];
 		isNullableTable = new boolean[joinSpan];
 		keyColumnNames = new String[joinSpan][];
 		final Table table = persistentClass.getRootTable();
-		qualifiedTableNames[0] = table.getQualifiedName( 
-				factory.getDialect(), 
-				factory.getSettings().getDefaultCatalogName(), 
-				factory.getSettings().getDefaultSchemaName() 
+		qualifiedTableNames[0] = table.getQualifiedName(
+				factory.getDialect(),
+				factory.getSettings().getDefaultCatalogName(),
+				factory.getSettings().getDefaultSchemaName()
 		);
 		isInverseTable[0] = false;
 		isNullableTable[0] = false;
 		keyColumnNames[0] = getIdentifierColumnNames();
 		cascadeDeleteEnabled = new boolean[joinSpan];
 
 		// Custom sql
 		customSQLInsert = new String[joinSpan];
 		customSQLUpdate = new String[joinSpan];
 		customSQLDelete = new String[joinSpan];
 		insertCallable = new boolean[joinSpan];
 		updateCallable = new boolean[joinSpan];
 		deleteCallable = new boolean[joinSpan];
 		insertResultCheckStyles = new ExecuteUpdateResultCheckStyle[joinSpan];
 		updateResultCheckStyles = new ExecuteUpdateResultCheckStyle[joinSpan];
 		deleteResultCheckStyles = new ExecuteUpdateResultCheckStyle[joinSpan];
 
 		customSQLInsert[0] = persistentClass.getCustomSQLInsert();
 		insertCallable[0] = customSQLInsert[0] != null && persistentClass.isCustomInsertCallable();
 		insertResultCheckStyles[0] = persistentClass.getCustomSQLInsertCheckStyle() == null
-									  ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLInsert[0], insertCallable[0] )
-									  : persistentClass.getCustomSQLInsertCheckStyle();
+				? ExecuteUpdateResultCheckStyle.determineDefault( customSQLInsert[0], insertCallable[0] )
+				: persistentClass.getCustomSQLInsertCheckStyle();
 		customSQLUpdate[0] = persistentClass.getCustomSQLUpdate();
 		updateCallable[0] = customSQLUpdate[0] != null && persistentClass.isCustomUpdateCallable();
 		updateResultCheckStyles[0] = persistentClass.getCustomSQLUpdateCheckStyle() == null
-									  ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLUpdate[0], updateCallable[0] )
-									  : persistentClass.getCustomSQLUpdateCheckStyle();
+				? ExecuteUpdateResultCheckStyle.determineDefault( customSQLUpdate[0], updateCallable[0] )
+				: persistentClass.getCustomSQLUpdateCheckStyle();
 		customSQLDelete[0] = persistentClass.getCustomSQLDelete();
 		deleteCallable[0] = customSQLDelete[0] != null && persistentClass.isCustomDeleteCallable();
 		deleteResultCheckStyles[0] = persistentClass.getCustomSQLDeleteCheckStyle() == null
-									  ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLDelete[0], deleteCallable[0] )
-									  : persistentClass.getCustomSQLDeleteCheckStyle();
+				? ExecuteUpdateResultCheckStyle.determineDefault( customSQLDelete[0], deleteCallable[0] )
+				: persistentClass.getCustomSQLDeleteCheckStyle();
 
 		// JOINS
 
 		Iterator joinIter = persistentClass.getJoinClosureIterator();
 		int j = 1;
 		while ( joinIter.hasNext() ) {
 			Join join = (Join) joinIter.next();
-			qualifiedTableNames[j] = join.getTable().getQualifiedName( 
-					factory.getDialect(), 
-					factory.getSettings().getDefaultCatalogName(), 
-					factory.getSettings().getDefaultSchemaName() 
+			qualifiedTableNames[j] = join.getTable().getQualifiedName(
+					factory.getDialect(),
+					factory.getSettings().getDefaultCatalogName(),
+					factory.getSettings().getDefaultSchemaName()
 			);
 			isInverseTable[j] = join.isInverse();
 			isNullableTable[j] = join.isOptional();
-			cascadeDeleteEnabled[j] = join.getKey().isCascadeDeleteEnabled() && 
-				factory.getDialect().supportsCascadeDelete();
+			cascadeDeleteEnabled[j] = join.getKey().isCascadeDeleteEnabled() &&
+					factory.getDialect().supportsCascadeDelete();
 
 			customSQLInsert[j] = join.getCustomSQLInsert();
 			insertCallable[j] = customSQLInsert[j] != null && join.isCustomInsertCallable();
 			insertResultCheckStyles[j] = join.getCustomSQLInsertCheckStyle() == null
-			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLInsert[j], insertCallable[j] )
-		                                  : join.getCustomSQLInsertCheckStyle();
+					? ExecuteUpdateResultCheckStyle.determineDefault( customSQLInsert[j], insertCallable[j] )
+					: join.getCustomSQLInsertCheckStyle();
 			customSQLUpdate[j] = join.getCustomSQLUpdate();
 			updateCallable[j] = customSQLUpdate[j] != null && join.isCustomUpdateCallable();
 			updateResultCheckStyles[j] = join.getCustomSQLUpdateCheckStyle() == null
-			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLUpdate[j], updateCallable[j] )
-		                                  : join.getCustomSQLUpdateCheckStyle();
+					? ExecuteUpdateResultCheckStyle.determineDefault( customSQLUpdate[j], updateCallable[j] )
+					: join.getCustomSQLUpdateCheckStyle();
 			customSQLDelete[j] = join.getCustomSQLDelete();
 			deleteCallable[j] = customSQLDelete[j] != null && join.isCustomDeleteCallable();
 			deleteResultCheckStyles[j] = join.getCustomSQLDeleteCheckStyle() == null
-			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLDelete[j], deleteCallable[j] )
-		                                  : join.getCustomSQLDeleteCheckStyle();
+					? ExecuteUpdateResultCheckStyle.determineDefault( customSQLDelete[j], deleteCallable[j] )
+					: join.getCustomSQLDeleteCheckStyle();
 
 			Iterator iter = join.getKey().getColumnIterator();
-			keyColumnNames[j] = new String[ join.getKey().getColumnSpan() ];
+			keyColumnNames[j] = new String[join.getKey().getColumnSpan()];
 			int i = 0;
 			while ( iter.hasNext() ) {
 				Column col = (Column) iter.next();
 				keyColumnNames[j][i++] = col.getQuotedName( factory.getDialect() );
 			}
 
 			j++;
 		}
 
 		constraintOrderedTableNames = new String[qualifiedTableNames.length];
 		constraintOrderedKeyColumnNames = new String[qualifiedTableNames.length][];
 		for ( int i = qualifiedTableNames.length - 1, position = 0; i >= 0; i--, position++ ) {
 			constraintOrderedTableNames[position] = qualifiedTableNames[i];
 			constraintOrderedKeyColumnNames[position] = keyColumnNames[i];
 		}
 
 		spaces = ArrayHelper.join(
-				qualifiedTableNames, 
+				qualifiedTableNames,
 				ArrayHelper.toStringArray( persistentClass.getSynchronizedTables() )
 		);
-		
+
 		final boolean lazyAvailable = isInstrumented();
 
 		boolean hasDeferred = false;
-		ArrayList subclassTables = new ArrayList();
-		ArrayList joinKeyColumns = new ArrayList();
+		ArrayList<String> subclassTables = new ArrayList<String>();
+		ArrayList<String[]> joinKeyColumns = new ArrayList<String[]>();
 		ArrayList<Boolean> isConcretes = new ArrayList<Boolean>();
 		ArrayList<Boolean> isDeferreds = new ArrayList<Boolean>();
 		ArrayList<Boolean> isInverses = new ArrayList<Boolean>();
 		ArrayList<Boolean> isNullables = new ArrayList<Boolean>();
 		ArrayList<Boolean> isLazies = new ArrayList<Boolean>();
 		subclassTables.add( qualifiedTableNames[0] );
 		joinKeyColumns.add( getIdentifierColumnNames() );
-		isConcretes.add(Boolean.TRUE);
-		isDeferreds.add(Boolean.FALSE);
-		isInverses.add(Boolean.FALSE);
-		isNullables.add(Boolean.FALSE);
-		isLazies.add(Boolean.FALSE);
+		isConcretes.add( Boolean.TRUE );
+		isDeferreds.add( Boolean.FALSE );
+		isInverses.add( Boolean.FALSE );
+		isNullables.add( Boolean.FALSE );
+		isLazies.add( Boolean.FALSE );
 		joinIter = persistentClass.getSubclassJoinClosureIterator();
 		while ( joinIter.hasNext() ) {
 			Join join = (Join) joinIter.next();
-			isConcretes.add( persistentClass.isClassOrSuperclassJoin(join) );
+			isConcretes.add( persistentClass.isClassOrSuperclassJoin( join ) );
 			isDeferreds.add( join.isSequentialSelect() );
 			isInverses.add( join.isInverse() );
 			isNullables.add( join.isOptional() );
 			isLazies.add( lazyAvailable && join.isLazy() );
-			if ( join.isSequentialSelect() && !persistentClass.isClassOrSuperclassJoin(join) ) {
+			if ( join.isSequentialSelect() && !persistentClass.isClassOrSuperclassJoin( join ) ) {
 				hasDeferred = true;
 			}
-			subclassTables.add( join.getTable().getQualifiedName( 
-					factory.getDialect(), 
-					factory.getSettings().getDefaultCatalogName(), 
-					factory.getSettings().getDefaultSchemaName() 
-			) );
+			subclassTables.add(
+					join.getTable().getQualifiedName(
+							factory.getDialect(),
+							factory.getSettings().getDefaultCatalogName(),
+							factory.getSettings().getDefaultSchemaName()
+					)
+			);
 			Iterator iter = join.getKey().getColumnIterator();
-			String[] keyCols = new String[ join.getKey().getColumnSpan() ];
+			String[] keyCols = new String[join.getKey().getColumnSpan()];
 			int i = 0;
 			while ( iter.hasNext() ) {
 				Column col = (Column) iter.next();
 				keyCols[i++] = col.getQuotedName( factory.getDialect() );
 			}
-			joinKeyColumns.add(keyCols);
+			joinKeyColumns.add( keyCols );
 		}
-		
-		subclassTableSequentialSelect = ArrayHelper.toBooleanArray(isDeferreds);
-		subclassTableNameClosure = ArrayHelper.toStringArray(subclassTables);
-		subclassTableIsLazyClosure = ArrayHelper.toBooleanArray(isLazies);
+
+		subclassTableSequentialSelect = ArrayHelper.toBooleanArray( isDeferreds );
+		subclassTableNameClosure = ArrayHelper.toStringArray( subclassTables );
+		subclassTableIsLazyClosure = ArrayHelper.toBooleanArray( isLazies );
 		subclassTableKeyColumnClosure = ArrayHelper.to2DStringArray( joinKeyColumns );
-		isClassOrSuperclassTable = ArrayHelper.toBooleanArray(isConcretes);
-		isInverseSubclassTable = ArrayHelper.toBooleanArray(isInverses);
-		isNullableSubclassTable = ArrayHelper.toBooleanArray(isNullables);
+		isClassOrSuperclassTable = ArrayHelper.toBooleanArray( isConcretes );
+		isInverseSubclassTable = ArrayHelper.toBooleanArray( isInverses );
+		isNullableSubclassTable = ArrayHelper.toBooleanArray( isNullables );
 		hasSequentialSelects = hasDeferred;
 
 		// DISCRIMINATOR
 
 		if ( persistentClass.isPolymorphic() ) {
 			Value discrimValue = persistentClass.getDiscriminator();
-			if (discrimValue==null) {
-				throw new MappingException("discriminator mapping required for single table polymorphic persistence");
+			if ( discrimValue == null ) {
+				throw new MappingException( "discriminator mapping required for single table polymorphic persistence" );
 			}
 			forceDiscriminator = persistentClass.isForceDiscriminator();
 			Selectable selectable = (Selectable) discrimValue.getColumnIterator().next();
 			if ( discrimValue.hasFormula() ) {
 				Formula formula = (Formula) selectable;
 				discriminatorFormula = formula.getFormula();
-				discriminatorFormulaTemplate = formula.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
+				discriminatorFormulaTemplate = formula.getTemplate(
+						factory.getDialect(),
+						factory.getSqlFunctionRegistry()
+				);
 				discriminatorColumnName = null;
 				discriminatorColumnReaders = null;
 				discriminatorColumnReaderTemplate = null;
 				discriminatorAlias = "clazz_";
 			}
 			else {
 				Column column = (Column) selectable;
 				discriminatorColumnName = column.getQuotedName( factory.getDialect() );
 				discriminatorColumnReaders = column.getReadExpr( factory.getDialect() );
-				discriminatorColumnReaderTemplate = column.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
+				discriminatorColumnReaderTemplate = column.getTemplate(
+						factory.getDialect(),
+						factory.getSqlFunctionRegistry()
+				);
 				discriminatorAlias = column.getAlias( factory.getDialect(), persistentClass.getRootTable() );
 				discriminatorFormula = null;
 				discriminatorFormulaTemplate = null;
 			}
 			discriminatorType = persistentClass.getDiscriminator().getType();
 			if ( persistentClass.isDiscriminatorValueNull() ) {
 				discriminatorValue = NULL_DISCRIMINATOR;
 				discriminatorSQLValue = InFragment.NULL;
 				discriminatorInsertable = false;
 			}
 			else if ( persistentClass.isDiscriminatorValueNotNull() ) {
 				discriminatorValue = NOT_NULL_DISCRIMINATOR;
 				discriminatorSQLValue = InFragment.NOT_NULL;
 				discriminatorInsertable = false;
 			}
 			else {
 				discriminatorInsertable = persistentClass.isDiscriminatorInsertable() && !discrimValue.hasFormula();
 				try {
 					DiscriminatorType dtype = (DiscriminatorType) discriminatorType;
 					discriminatorValue = dtype.stringToObject( persistentClass.getDiscriminatorValue() );
 					discriminatorSQLValue = dtype.objectToSQLString( discriminatorValue, factory.getDialect() );
 				}
 				catch (ClassCastException cce) {
-					throw new MappingException("Illegal discriminator type: " + discriminatorType.getName() );
+					throw new MappingException( "Illegal discriminator type: " + discriminatorType.getName() );
 				}
 				catch (Exception e) {
-					throw new MappingException("Could not format discriminator value to SQL string", e);
+					throw new MappingException( "Could not format discriminator value to SQL string", e );
 				}
 			}
 		}
 		else {
 			forceDiscriminator = false;
 			discriminatorInsertable = false;
 			discriminatorColumnName = null;
 			discriminatorColumnReaders = null;
 			discriminatorColumnReaderTemplate = null;
 			discriminatorAlias = null;
 			discriminatorType = null;
 			discriminatorValue = null;
 			discriminatorSQLValue = null;
 			discriminatorFormula = null;
 			discriminatorFormulaTemplate = null;
 		}
 
 		// PROPERTIES
 
-		propertyTableNumbers = new int[ getPropertySpan() ];
+		propertyTableNumbers = new int[getPropertySpan()];
 		Iterator iter = persistentClass.getPropertyClosureIterator();
-		int i=0;
-		while( iter.hasNext() ) {
+		int i = 0;
+		while ( iter.hasNext() ) {
 			Property prop = (Property) iter.next();
-			propertyTableNumbers[i++] = persistentClass.getJoinNumber(prop);
+			propertyTableNumbers[i++] = persistentClass.getJoinNumber( prop );
 
 		}
 
 		//TODO: code duplication with JoinedSubclassEntityPersister
-		
-		ArrayList columnJoinNumbers = new ArrayList();
-		ArrayList formulaJoinedNumbers = new ArrayList();
-		ArrayList propertyJoinNumbers = new ArrayList();
-		
+
+		ArrayList<Integer> columnJoinNumbers = new ArrayList<Integer>();
+		ArrayList<Integer> formulaJoinedNumbers = new ArrayList<Integer>();
+		ArrayList<Integer> propertyJoinNumbers = new ArrayList<Integer>();
+
 		iter = persistentClass.getSubclassPropertyClosureIterator();
 		while ( iter.hasNext() ) {
 			Property prop = (Property) iter.next();
-			Integer join = persistentClass.getJoinNumber(prop);
-			propertyJoinNumbers.add(join);
+			Integer join = persistentClass.getJoinNumber( prop );
+			propertyJoinNumbers.add( join );
 
 			//propertyTableNumbersByName.put( prop.getName(), join );
-			propertyTableNumbersByNameAndSubclass.put( 
-					prop.getPersistentClass().getEntityName() + '.' + prop.getName(), 
-					join 
+			propertyTableNumbersByNameAndSubclass.put(
+					prop.getPersistentClass().getEntityName() + '.' + prop.getName(),
+					join
 			);
 
 			Iterator citer = prop.getColumnIterator();
 			while ( citer.hasNext() ) {
 				Selectable thing = (Selectable) citer.next();
 				if ( thing.isFormula() ) {
-					formulaJoinedNumbers.add(join);
+					formulaJoinedNumbers.add( join );
 				}
 				else {
-					columnJoinNumbers.add(join);
+					columnJoinNumbers.add( join );
 				}
 			}
 		}
-		subclassColumnTableNumberClosure = ArrayHelper.toIntArray(columnJoinNumbers);
-		subclassFormulaTableNumberClosure = ArrayHelper.toIntArray(formulaJoinedNumbers);
-		subclassPropertyTableNumberClosure = ArrayHelper.toIntArray(propertyJoinNumbers);
+		subclassColumnTableNumberClosure = ArrayHelper.toIntArray( columnJoinNumbers );
+		subclassFormulaTableNumberClosure = ArrayHelper.toIntArray( formulaJoinedNumbers );
+		subclassPropertyTableNumberClosure = ArrayHelper.toIntArray( propertyJoinNumbers );
 
 		int subclassSpan = persistentClass.getSubclassSpan() + 1;
 		subclassClosure = new String[subclassSpan];
 		subclassClosure[0] = getEntityName();
 		if ( persistentClass.isPolymorphic() ) {
 			addSubclassByDiscriminatorValue( discriminatorValue, getEntityName() );
 		}
 
 		// SUBCLASSES
 		if ( persistentClass.isPolymorphic() ) {
 			iter = persistentClass.getSubclassIterator();
-			int k=1;
+			int k = 1;
 			while ( iter.hasNext() ) {
 				Subclass sc = (Subclass) iter.next();
 				subclassClosure[k++] = sc.getEntityName();
 				if ( sc.isDiscriminatorValueNull() ) {
 					addSubclassByDiscriminatorValue( NULL_DISCRIMINATOR, sc.getEntityName() );
 				}
 				else if ( sc.isDiscriminatorValueNotNull() ) {
 					addSubclassByDiscriminatorValue( NOT_NULL_DISCRIMINATOR, sc.getEntityName() );
 				}
 				else {
 					try {
 						DiscriminatorType dtype = (DiscriminatorType) discriminatorType;
 						addSubclassByDiscriminatorValue(
-							dtype.stringToObject( sc.getDiscriminatorValue() ),
-							sc.getEntityName()
+								dtype.stringToObject( sc.getDiscriminatorValue() ),
+								sc.getEntityName()
 						);
 					}
 					catch (ClassCastException cce) {
-						throw new MappingException("Illegal discriminator type: " + discriminatorType.getName() );
+						throw new MappingException( "Illegal discriminator type: " + discriminatorType.getName() );
 					}
 					catch (Exception e) {
-						throw new MappingException("Error parsing discriminator value", e);
+						throw new MappingException( "Error parsing discriminator value", e );
 					}
 				}
 			}
 		}
 
 		initLockers();
 
 		initSubclassPropertyAliasesMap( persistentClass );
-		
+
 		postConstruct( creationContext.getMetadata() );
 
 	}
 
 	private void addSubclassByDiscriminatorValue(Object discriminatorValue, String entityName) {
-		String mappedEntityName = (String) subclassesByDiscriminatorValue.put( discriminatorValue, entityName );
+		String mappedEntityName = subclassesByDiscriminatorValue.put( discriminatorValue, entityName );
 		if ( mappedEntityName != null ) {
 			throw new MappingException(
 					"Entities [" + entityName + "] and [" + mappedEntityName
 							+ "] are mapped with the same discriminator value '" + discriminatorValue + "'."
 			);
 		}
 	}
 
 	protected boolean isInverseTable(int j) {
 		return isInverseTable[j];
 	}
 
 	protected boolean isInverseSubclassTable(int j) {
 		return isInverseSubclassTable[j];
 	}
 
 	public String getDiscriminatorColumnName() {
 		return discriminatorColumnName;
 	}
 
 	public String getDiscriminatorColumnReaders() {
 		return discriminatorColumnReaders;
-	}			
-	
+	}
+
 	public String getDiscriminatorColumnReaderTemplate() {
 		return discriminatorColumnReaderTemplate;
-	}	
-	
+	}
+
 	protected String getDiscriminatorAlias() {
 		return discriminatorAlias;
 	}
 
 	protected String getDiscriminatorFormulaTemplate() {
 		return discriminatorFormulaTemplate;
 	}
 
 	public String getTableName() {
 		return qualifiedTableNames[0];
 	}
 
 	public Type getDiscriminatorType() {
 		return discriminatorType;
 	}
 
 	public Object getDiscriminatorValue() {
 		return discriminatorValue;
 	}
 
 	public String getDiscriminatorSQLValue() {
 		return discriminatorSQLValue;
 	}
 
 	public String[] getSubclassClosure() {
 		return subclassClosure;
 	}
 
 	public String getSubclassForDiscriminatorValue(Object value) {
-		if (value==null) {
-			return (String) subclassesByDiscriminatorValue.get(NULL_DISCRIMINATOR);
+		if ( value == null ) {
+			return subclassesByDiscriminatorValue.get( NULL_DISCRIMINATOR );
 		}
 		else {
-			String result = (String) subclassesByDiscriminatorValue.get(value);
-			if (result==null) {
-				result = (String) subclassesByDiscriminatorValue.get(NOT_NULL_DISCRIMINATOR);
+			String result = subclassesByDiscriminatorValue.get( value );
+			if ( result == null ) {
+				result = subclassesByDiscriminatorValue.get( NOT_NULL_DISCRIMINATOR );
 			}
 			return result;
 		}
 	}
 
 	public Serializable[] getPropertySpaces() {
 		return spaces;
 	}
 
 	//Access cached SQL
 
 	protected boolean isDiscriminatorFormula() {
-		return discriminatorColumnName==null;
+		return discriminatorColumnName == null;
 	}
 
 	protected String getDiscriminatorFormula() {
 		return discriminatorFormula;
 	}
 
 	protected String getTableName(int j) {
 		return qualifiedTableNames[j];
 	}
-	
+
 	protected String[] getKeyColumns(int j) {
 		return keyColumnNames[j];
 	}
-	
+
 	protected boolean isTableCascadeDeleteEnabled(int j) {
 		return cascadeDeleteEnabled[j];
 	}
-	
+
 	protected boolean isPropertyOfTable(int property, int j) {
-		return propertyTableNumbers[property]==j;
+		return propertyTableNumbers[property] == j;
 	}
 
 	protected boolean isSubclassTableSequentialSelect(int j) {
 		return subclassTableSequentialSelect[j] && !isClassOrSuperclassTable[j];
 	}
-	
+
 	// Execute the SQL:
 
 	public String fromTableFragment(String name) {
 		return getTableName() + ' ' + name;
 	}
 
 	@Override
 	public String filterFragment(String alias) throws MappingException {
-		String result = discriminatorFilterFragment(alias);
+		String result = discriminatorFilterFragment( alias );
 		if ( hasWhere() ) {
-			result += " and " + getSQLWhereString(alias);
+			result += " and " + getSQLWhereString( alias );
 		}
 		return result;
 	}
 
 	private String discriminatorFilterFragment(String alias) throws MappingException {
 		return discriminatorFilterFragment( alias, null );
 	}
-	
+
 	public String oneToManyFilterFragment(String alias) throws MappingException {
 		return forceDiscriminator
 				? discriminatorFilterFragment( alias, null )
 				: "";
 	}
 
 	@Override
 	public String oneToManyFilterFragment(String alias, Set<String> treatAsDeclarations) {
 		return needsDiscriminator()
 				? discriminatorFilterFragment( alias, treatAsDeclarations )
 				: "";
 	}
 
 	@Override
 	public String filterFragment(String alias, Set<String> treatAsDeclarations) {
 		String result = discriminatorFilterFragment( alias, treatAsDeclarations );
 		if ( hasWhere() ) {
 			result += " and " + getSQLWhereString( alias );
 		}
 		return result;
 	}
 
-	private String discriminatorFilterFragment(String alias, Set<String> treatAsDeclarations)  {
+	private String discriminatorFilterFragment(String alias, Set<String> treatAsDeclarations) {
 		final boolean hasTreatAs = treatAsDeclarations != null && !treatAsDeclarations.isEmpty();
 
-		if ( !needsDiscriminator() && !hasTreatAs) {
+		if ( !needsDiscriminator() && !hasTreatAs ) {
 			return "";
 		}
 
 		final InFragment frag = new InFragment();
 		if ( isDiscriminatorFormula() ) {
 			frag.setFormula( alias, getDiscriminatorFormulaTemplate() );
 		}
 		else {
 			frag.setColumn( alias, getDiscriminatorColumnName() );
 		}
 
 		if ( hasTreatAs ) {
 			frag.addValues( decodeTreatAsRequests( treatAsDeclarations ) );
 		}
 		else {
 			frag.addValues( fullDiscriminatorValues() );
 		}
 
 		return " and " + frag.toFragmentString();
 	}
 
 	private boolean needsDiscriminator() {
 		return forceDiscriminator || isInherited();
 	}
 
 	private String[] decodeTreatAsRequests(Set<String> treatAsDeclarations) {
 		final List<String> values = new ArrayList<String>();
 		for ( String subclass : treatAsDeclarations ) {
 			final Queryable queryable = (Queryable) getFactory().getEntityPersister( subclass );
 			if ( !queryable.isAbstract() ) {
 				values.add( queryable.getDiscriminatorSQLValue() );
 			}
 		}
-		return values.toArray( new String[ values.size() ] );
+		return values.toArray( new String[values.size()] );
 	}
 
 	private String[] fullDiscriminatorValues;
 
 	private String[] fullDiscriminatorValues() {
 		if ( fullDiscriminatorValues == null ) {
 			// first access; build it
 			final List<String> values = new ArrayList<String>();
 			for ( String subclass : getSubclassClosure() ) {
 				final Queryable queryable = (Queryable) getFactory().getEntityPersister( subclass );
 				if ( !queryable.isAbstract() ) {
 					values.add( queryable.getDiscriminatorSQLValue() );
 				}
 			}
-			fullDiscriminatorValues = values.toArray( new String[values.size() ] );
+			fullDiscriminatorValues = values.toArray( new String[values.size()] );
 		}
 
 		return fullDiscriminatorValues;
 	}
 
 	public String getSubclassPropertyTableName(int i) {
-		return subclassTableNameClosure[ subclassPropertyTableNumberClosure[i] ];
+		return subclassTableNameClosure[subclassPropertyTableNumberClosure[i]];
 	}
 
 	protected void addDiscriminatorToSelect(SelectFragment select, String name, String suffix) {
 		if ( isDiscriminatorFormula() ) {
 			select.addFormula( name, getDiscriminatorFormulaTemplate(), getDiscriminatorAlias() );
 		}
 		else {
-			select.addColumn( name, getDiscriminatorColumnName(),  getDiscriminatorAlias() );
+			select.addColumn( name, getDiscriminatorColumnName(), getDiscriminatorAlias() );
 		}
 	}
-	
+
 	protected int[] getPropertyTableNumbersInSelect() {
 		return propertyTableNumbers;
 	}
 
 	protected int getSubclassPropertyTableNumber(int i) {
 		return subclassPropertyTableNumberClosure[i];
 	}
 
 	public int getTableSpan() {
 		return joinSpan;
 	}
 
 	protected void addDiscriminatorToInsert(Insert insert) {
 
-		if (discriminatorInsertable) {
+		if ( discriminatorInsertable ) {
 			insert.addColumn( getDiscriminatorColumnName(), discriminatorSQLValue );
 		}
 
 	}
 
 	protected int[] getSubclassColumnTableNumberClosure() {
 		return subclassColumnTableNumberClosure;
 	}
 
 	protected int[] getSubclassFormulaTableNumberClosure() {
 		return subclassFormulaTableNumberClosure;
 	}
 
 	protected int[] getPropertyTableNumbers() {
 		return propertyTableNumbers;
 	}
-		
+
 	protected boolean isSubclassPropertyDeferred(String propertyName, String entityName) {
-		return hasSequentialSelects && 
-			isSubclassTableSequentialSelect( getSubclassPropertyTableNumber(propertyName, entityName) );
+		return hasSequentialSelects &&
+				isSubclassTableSequentialSelect( getSubclassPropertyTableNumber( propertyName, entityName ) );
 	}
-	
+
 	public boolean hasSequentialSelect() {
 		return hasSequentialSelects;
 	}
-	
+
 	private int getSubclassPropertyTableNumber(String propertyName, String entityName) {
-		Type type = propertyMapping.toType(propertyName);
+		Type type = propertyMapping.toType( propertyName );
 		if ( type.isAssociationType() && ( (AssociationType) type ).useLHSPrimaryKey() ) {
 			return 0;
 		}
-		final Integer tabnum = (Integer) propertyTableNumbersByNameAndSubclass.get(entityName + '.' + propertyName);
-		return tabnum==null ? 0 : tabnum;
+		final Integer tabnum = propertyTableNumbersByNameAndSubclass.get( entityName + '.' + propertyName );
+		return tabnum == null ? 0 : tabnum;
 	}
-	
+
 	protected String getSequentialSelect(String entityName) {
-		return (String) sequentialSelectStringsByEntityName.get(entityName);
+		return sequentialSelectStringsByEntityName.get( entityName );
 	}
 
 	private String generateSequentialSelect(Loadable persister) {
 		//if ( this==persister || !hasSequentialSelects ) return null;
 
 		//note that this method could easily be moved up to BasicEntityPersister,
 		//if we ever needed to reuse it from other subclasses
-		
+
 		//figure out which tables need to be fetched
 		AbstractEntityPersister subclassPersister = (AbstractEntityPersister) persister;
-		HashSet tableNumbers = new HashSet();
+		HashSet<Integer> tableNumbers = new HashSet<Integer>();
 		String[] props = subclassPersister.getPropertyNames();
 		String[] classes = subclassPersister.getPropertySubclassNames();
-		for ( int i=0; i<props.length; i++ ) {
+		for ( int i = 0; i < props.length; i++ ) {
 			int propTableNumber = getSubclassPropertyTableNumber( props[i], classes[i] );
-			if ( isSubclassTableSequentialSelect(propTableNumber) && !isSubclassTableLazy(propTableNumber) ) {
-				tableNumbers.add( propTableNumber);
+			if ( isSubclassTableSequentialSelect( propTableNumber ) && !isSubclassTableLazy( propTableNumber ) ) {
+				tableNumbers.add( propTableNumber );
 			}
 		}
 		if ( tableNumbers.isEmpty() ) {
 			return null;
 		}
-		
+
 		//figure out which columns are needed
-		ArrayList columnNumbers = new ArrayList();
+		ArrayList<Integer> columnNumbers = new ArrayList<Integer>();
 		final int[] columnTableNumbers = getSubclassColumnTableNumberClosure();
-		for ( int i=0; i<getSubclassColumnClosure().length; i++ ) {
+		for ( int i = 0; i < getSubclassColumnClosure().length; i++ ) {
 			if ( tableNumbers.contains( columnTableNumbers[i] ) ) {
 				columnNumbers.add( i );
 			}
 		}
-		
+
 		//figure out which formulas are needed
-		ArrayList formulaNumbers = new ArrayList();
+		ArrayList<Integer> formulaNumbers = new ArrayList<Integer>();
 		final int[] formulaTableNumbers = getSubclassColumnTableNumberClosure();
-		for ( int i=0; i<getSubclassFormulaTemplateClosure().length; i++ ) {
+		for ( int i = 0; i < getSubclassFormulaTemplateClosure().length; i++ ) {
 			if ( tableNumbers.contains( formulaTableNumbers[i] ) ) {
 				formulaNumbers.add( i );
 			}
 		}
-		
+
 		//render the SQL
-		return renderSelect( 
-			ArrayHelper.toIntArray(tableNumbers),
-			ArrayHelper.toIntArray(columnNumbers),
-			ArrayHelper.toIntArray(formulaNumbers)
+		return renderSelect(
+				ArrayHelper.toIntArray( tableNumbers ),
+				ArrayHelper.toIntArray( columnNumbers ),
+				ArrayHelper.toIntArray( formulaNumbers )
 		);
 	}
-		
-		
+
+
 	protected String[] getSubclassTableKeyColumns(int j) {
 		return subclassTableKeyColumnClosure[j];
 	}
 
 	public String getSubclassTableName(int j) {
 		return subclassTableNameClosure[j];
 	}
 
 	public int getSubclassTableSpan() {
 		return subclassTableNameClosure.length;
 	}
 
 	protected boolean isClassOrSuperclassTable(int j) {
 		return isClassOrSuperclassTable[j];
 	}
 
 	protected boolean isSubclassTableLazy(int j) {
 		return subclassTableIsLazyClosure[j];
 	}
-	
+
 	protected boolean isNullableTable(int j) {
 		return isNullableTable[j];
 	}
-	
+
 	protected boolean isNullableSubclassTable(int j) {
 		return isNullableSubclassTable[j];
 	}
 
 	public String getPropertyTableName(String propertyName) {
-		Integer index = getEntityMetamodel().getPropertyIndexOrNull(propertyName);
-		if (index==null) {
+		Integer index = getEntityMetamodel().getPropertyIndexOrNull( propertyName );
+		if ( index == null ) {
 			return null;
 		}
-		return qualifiedTableNames[ propertyTableNumbers[index] ];
+		return qualifiedTableNames[propertyTableNumbers[index]];
 	}
-	
+
 	protected void doPostInstantiate() {
-		if (hasSequentialSelects) {
+		if ( hasSequentialSelects ) {
 			String[] entityNames = getSubclassClosure();
-			for ( int i=1; i<entityNames.length; i++ ) {
+			for ( int i = 1; i < entityNames.length; i++ ) {
 				Loadable loadable = (Loadable) getFactory().getEntityPersister( entityNames[i] );
 				if ( !loadable.isAbstract() ) { //perhaps not really necessary...
-					String sequentialSelect = generateSequentialSelect(loadable);
+					String sequentialSelect = generateSequentialSelect( loadable );
 					sequentialSelectStringsByEntityName.put( entityNames[i], sequentialSelect );
 				}
 			}
 		}
 	}
 
 	public boolean isMultiTable() {
 		return getTableSpan() > 1;
 	}
 
 	public String[] getConstraintOrderedTableNameClosure() {
 		return constraintOrderedTableNames;
 	}
 
 	public String[][] getContraintOrderedTableKeyColumnClosure() {
 		return constraintOrderedKeyColumnNames;
 	}
 
 	@Override
 	public FilterAliasGenerator getFilterAliasGenerator(String rootAlias) {
-		return new DynamicFilterAliasGenerator(qualifiedTableNames, rootAlias);
+		return new DynamicFilterAliasGenerator( qualifiedTableNames, rootAlias );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/UnionSubclassEntityPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/UnionSubclassEntityPersister.java
index 696dbddcf4..dd736281bd 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/UnionSubclassEntityPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/UnionSubclassEntityPersister.java
@@ -1,514 +1,518 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.entity;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashSet;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.MappingException;
 import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.cfg.Settings;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.id.IdentityGenerator;
 import org.hibernate.internal.FilterAliasGenerator;
 import org.hibernate.internal.StaticFilterAliasGenerator;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.internal.util.collections.JoinedIterator;
 import org.hibernate.internal.util.collections.SingletonIterator;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Subclass;
 import org.hibernate.mapping.Table;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.SimpleSelect;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.Type;
 
 /**
- * Implementation of the "table-per-concrete-class" or "roll-down" mapping 
+ * Implementation of the "table-per-concrete-class" or "roll-down" mapping
  * strategy for an entity and its inheritence hierarchy.
  *
  * @author Gavin King
  */
 public class UnionSubclassEntityPersister extends AbstractEntityPersister {
 
 	// the class hierarchy structure
 	private final String subquery;
 	private final String tableName;
 	//private final String rootTableName;
 	private final String[] subclassClosure;
 	private final String[] spaces;
 	private final String[] subclassSpaces;
 	private final Object discriminatorValue;
 	private final String discriminatorSQLValue;
 	private final Map subclassByDiscriminatorValue = new HashMap();
 
 	private final String[] constraintOrderedTableNames;
 	private final String[][] constraintOrderedKeyColumnNames;
 
 	//INITIALIZATION:
 
 	public UnionSubclassEntityPersister(
-			final PersistentClass persistentClass, 
+			final PersistentClass persistentClass,
 			final EntityRegionAccessStrategy cacheAccessStrategy,
 			final NaturalIdRegionAccessStrategy naturalIdRegionAccessStrategy,
 			final PersisterCreationContext creationContext) throws HibernateException {
 
 		super( persistentClass, cacheAccessStrategy, naturalIdRegionAccessStrategy, creationContext );
 
 		final SessionFactoryImplementor factory = creationContext.getSessionFactory();
 
 		if ( getIdentifierGenerator() instanceof IdentityGenerator ) {
 			throw new MappingException(
-					"Cannot use identity column key generation with <union-subclass> mapping for: " + 
-					getEntityName() 
+					"Cannot use identity column key generation with <union-subclass> mapping for: " +
+							getEntityName()
 			);
 		}
 
 		// TABLE
 
-		tableName = persistentClass.getTable().getQualifiedName( 
-				factory.getDialect(), 
-				factory.getSettings().getDefaultCatalogName(), 
-				factory.getSettings().getDefaultSchemaName() 
+		tableName = persistentClass.getTable().getQualifiedName(
+				factory.getDialect(),
+				factory.getSettings().getDefaultCatalogName(),
+				factory.getSettings().getDefaultSchemaName()
 		);
 		/*rootTableName = persistentClass.getRootTable().getQualifiedName( 
 				factory.getDialect(), 
 				factory.getDefaultCatalog(), 
 				factory.getDefaultSchema() 
 		);*/
 
 		//Custom SQL
 
 		String sql;
 		boolean callable = false;
 		ExecuteUpdateResultCheckStyle checkStyle = null;
 		sql = persistentClass.getCustomSQLInsert();
 		callable = sql != null && persistentClass.isCustomInsertCallable();
 		checkStyle = sql == null
 				? ExecuteUpdateResultCheckStyle.COUNT
-	            : persistentClass.getCustomSQLInsertCheckStyle() == null
-						? ExecuteUpdateResultCheckStyle.determineDefault( sql, callable )
-	                    : persistentClass.getCustomSQLInsertCheckStyle();
-		customSQLInsert = new String[] { sql };
-		insertCallable = new boolean[] { callable };
-		insertResultCheckStyles = new ExecuteUpdateResultCheckStyle[] { checkStyle };
+				: persistentClass.getCustomSQLInsertCheckStyle() == null
+				? ExecuteUpdateResultCheckStyle.determineDefault( sql, callable )
+				: persistentClass.getCustomSQLInsertCheckStyle();
+		customSQLInsert = new String[] {sql};
+		insertCallable = new boolean[] {callable};
+		insertResultCheckStyles = new ExecuteUpdateResultCheckStyle[] {checkStyle};
 
 		sql = persistentClass.getCustomSQLUpdate();
 		callable = sql != null && persistentClass.isCustomUpdateCallable();
 		checkStyle = sql == null
 				? ExecuteUpdateResultCheckStyle.COUNT
-	            : persistentClass.getCustomSQLUpdateCheckStyle() == null
-						? ExecuteUpdateResultCheckStyle.determineDefault( sql, callable )
-	                    : persistentClass.getCustomSQLUpdateCheckStyle();
-		customSQLUpdate = new String[] { sql };
-		updateCallable = new boolean[] { callable };
-		updateResultCheckStyles = new ExecuteUpdateResultCheckStyle[] { checkStyle };
+				: persistentClass.getCustomSQLUpdateCheckStyle() == null
+				? ExecuteUpdateResultCheckStyle.determineDefault( sql, callable )
+				: persistentClass.getCustomSQLUpdateCheckStyle();
+		customSQLUpdate = new String[] {sql};
+		updateCallable = new boolean[] {callable};
+		updateResultCheckStyles = new ExecuteUpdateResultCheckStyle[] {checkStyle};
 
 		sql = persistentClass.getCustomSQLDelete();
 		callable = sql != null && persistentClass.isCustomDeleteCallable();
 		checkStyle = sql == null
 				? ExecuteUpdateResultCheckStyle.COUNT
-	            : persistentClass.getCustomSQLDeleteCheckStyle() == null
-						? ExecuteUpdateResultCheckStyle.determineDefault( sql, callable )
-	                    : persistentClass.getCustomSQLDeleteCheckStyle();
-		customSQLDelete = new String[] { sql };
-		deleteCallable = new boolean[] { callable };
-		deleteResultCheckStyles = new ExecuteUpdateResultCheckStyle[] { checkStyle };
+				: persistentClass.getCustomSQLDeleteCheckStyle() == null
+				? ExecuteUpdateResultCheckStyle.determineDefault( sql, callable )
+				: persistentClass.getCustomSQLDeleteCheckStyle();
+		customSQLDelete = new String[] {sql};
+		deleteCallable = new boolean[] {callable};
+		deleteResultCheckStyles = new ExecuteUpdateResultCheckStyle[] {checkStyle};
 
 		discriminatorValue = persistentClass.getSubclassId();
 		discriminatorSQLValue = String.valueOf( persistentClass.getSubclassId() );
 
 		// PROPERTIES
 
 		int subclassSpan = persistentClass.getSubclassSpan() + 1;
 		subclassClosure = new String[subclassSpan];
 		subclassClosure[0] = getEntityName();
 
 		// SUBCLASSES
-		subclassByDiscriminatorValue.put( 
+		subclassByDiscriminatorValue.put(
 				persistentClass.getSubclassId(),
-				persistentClass.getEntityName() 
+				persistentClass.getEntityName()
 		);
 		if ( persistentClass.isPolymorphic() ) {
 			Iterator iter = persistentClass.getSubclassIterator();
-			int k=1;
+			int k = 1;
 			while ( iter.hasNext() ) {
 				Subclass sc = (Subclass) iter.next();
 				subclassClosure[k++] = sc.getEntityName();
 				subclassByDiscriminatorValue.put( sc.getSubclassId(), sc.getEntityName() );
 			}
 		}
-		
+
 		//SPACES
 		//TODO: i'm not sure, but perhaps we should exclude
 		//      abstract denormalized tables?
-		
+
 		int spacesSize = 1 + persistentClass.getSynchronizedTables().size();
 		spaces = new String[spacesSize];
 		spaces[0] = tableName;
 		Iterator iter = persistentClass.getSynchronizedTables().iterator();
-		for ( int i=1; i<spacesSize; i++ ) {
+		for ( int i = 1; i < spacesSize; i++ ) {
 			spaces[i] = (String) iter.next();
 		}
-		
+
 		HashSet subclassTables = new HashSet();
 		iter = persistentClass.getSubclassTableClosureIterator();
 		while ( iter.hasNext() ) {
 			Table table = (Table) iter.next();
-			subclassTables.add( table.getQualifiedName(
-					factory.getDialect(), 
-					factory.getSettings().getDefaultCatalogName(), 
-					factory.getSettings().getDefaultSchemaName() 
-			) );
+			subclassTables.add(
+					table.getQualifiedName(
+							factory.getDialect(),
+							factory.getSettings().getDefaultCatalogName(),
+							factory.getSettings().getDefaultSchemaName()
+					)
+			);
 		}
-		subclassSpaces = ArrayHelper.toStringArray(subclassTables);
+		subclassSpaces = ArrayHelper.toStringArray( subclassTables );
 
 		subquery = generateSubquery( persistentClass, creationContext.getMetadata() );
 
 		if ( isMultiTable() ) {
 			int idColumnSpan = getIdentifierColumnSpan();
 			ArrayList tableNames = new ArrayList();
 			ArrayList keyColumns = new ArrayList();
 			if ( !isAbstract() ) {
 				tableNames.add( tableName );
 				keyColumns.add( getIdentifierColumnNames() );
 			}
 			iter = persistentClass.getSubclassTableClosureIterator();
 			while ( iter.hasNext() ) {
-				Table tab = ( Table ) iter.next();
+				Table tab = (Table) iter.next();
 				if ( !tab.isAbstractUnionTable() ) {
 					String tableName = tab.getQualifiedName(
 							factory.getDialect(),
 							factory.getSettings().getDefaultCatalogName(),
 							factory.getSettings().getDefaultSchemaName()
 					);
 					tableNames.add( tableName );
 					String[] key = new String[idColumnSpan];
 					Iterator citer = tab.getPrimaryKey().getColumnIterator();
-					for ( int k=0; k<idColumnSpan; k++ ) {
-						key[k] = ( ( Column ) citer.next() ).getQuotedName( factory.getDialect() );
+					for ( int k = 0; k < idColumnSpan; k++ ) {
+						key[k] = ( (Column) citer.next() ).getQuotedName( factory.getDialect() );
 					}
 					keyColumns.add( key );
 				}
 			}
 
 			constraintOrderedTableNames = ArrayHelper.toStringArray( tableNames );
 			constraintOrderedKeyColumnNames = ArrayHelper.to2DStringArray( keyColumns );
 		}
 		else {
-			constraintOrderedTableNames = new String[] { tableName };
-			constraintOrderedKeyColumnNames = new String[][] { getIdentifierColumnNames() };
+			constraintOrderedTableNames = new String[] {tableName};
+			constraintOrderedKeyColumnNames = new String[][] {getIdentifierColumnNames()};
 		}
 
 		initLockers();
 
 		initSubclassPropertyAliasesMap( persistentClass );
-		
+
 		postConstruct( creationContext.getMetadata() );
 
 	}
 
 	public Serializable[] getQuerySpaces() {
 		return subclassSpaces;
 	}
-	
+
 	public String getTableName() {
 		return subquery;
 	}
 
 	public Type getDiscriminatorType() {
 		return StandardBasicTypes.INTEGER;
 	}
 
 	public Object getDiscriminatorValue() {
 		return discriminatorValue;
 	}
 
 	public String getDiscriminatorSQLValue() {
 		return discriminatorSQLValue;
 	}
 
 	public String[] getSubclassClosure() {
 		return subclassClosure;
 	}
 
 	public String getSubclassForDiscriminatorValue(Object value) {
-		return (String) subclassByDiscriminatorValue.get(value);
+		return (String) subclassByDiscriminatorValue.get( value );
 	}
 
 	public Serializable[] getPropertySpaces() {
 		return spaces;
 	}
 
 	protected boolean isDiscriminatorFormula() {
 		return false;
 	}
 
 	/**
 	 * Generate the SQL that selects a row by id
 	 */
 	protected String generateSelectString(LockMode lockMode) {
 		SimpleSelect select = new SimpleSelect( getFactory().getDialect() )
-			.setLockMode(lockMode)
-			.setTableName( getTableName() )
-			.addColumns( getIdentifierColumnNames() )
-			.addColumns( 
-					getSubclassColumnClosure(), 
-					getSubclassColumnAliasClosure(),
-					getSubclassColumnLazyiness()
-			)
-			.addColumns( 
-					getSubclassFormulaClosure(), 
-					getSubclassFormulaAliasClosure(),
-					getSubclassFormulaLazyiness()
-			);
+				.setLockMode( lockMode )
+				.setTableName( getTableName() )
+				.addColumns( getIdentifierColumnNames() )
+				.addColumns(
+						getSubclassColumnClosure(),
+						getSubclassColumnAliasClosure(),
+						getSubclassColumnLazyiness()
+				)
+				.addColumns(
+						getSubclassFormulaClosure(),
+						getSubclassFormulaAliasClosure(),
+						getSubclassFormulaLazyiness()
+				);
 		//TODO: include the rowids!!!!
 		if ( hasSubclasses() ) {
 			if ( isDiscriminatorFormula() ) {
 				select.addColumn( getDiscriminatorFormula(), getDiscriminatorAlias() );
 			}
 			else {
 				select.addColumn( getDiscriminatorColumnName(), getDiscriminatorAlias() );
 			}
 		}
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "load " + getEntityName() );
 		}
 		return select.addCondition( getIdentifierColumnNames(), "=?" ).toStatementString();
 	}
 
 	protected String getDiscriminatorFormula() {
 		return null;
 	}
 
 	protected String getTableName(int j) {
 		return tableName;
 	}
 
 	protected String[] getKeyColumns(int j) {
 		return getIdentifierColumnNames();
 	}
-	
+
 	protected boolean isTableCascadeDeleteEnabled(int j) {
 		return false;
 	}
-	
+
 	protected boolean isPropertyOfTable(int property, int j) {
 		return true;
 	}
 
 	// Execute the SQL:
 
 	public String fromTableFragment(String name) {
-		return getTableName() + ' '  + name;
+		return getTableName() + ' ' + name;
 	}
 
 	@Override
 	public String filterFragment(String name) {
 		return hasWhere()
 				? " and " + getSQLWhereString( name )
 				: "";
 	}
 
 	@Override
 	protected String filterFragment(String alias, Set<String> treatAsDeclarations) {
 		return filterFragment( alias );
 	}
 
 	public String getSubclassPropertyTableName(int i) {
 		return getTableName();//ie. the subquery! yuck!
 	}
 
 	protected void addDiscriminatorToSelect(SelectFragment select, String name, String suffix) {
-		select.addColumn( name, getDiscriminatorColumnName(),  getDiscriminatorAlias() );
+		select.addColumn( name, getDiscriminatorColumnName(), getDiscriminatorAlias() );
 	}
-	
+
 	protected int[] getPropertyTableNumbersInSelect() {
-		return new int[ getPropertySpan() ];
+		return new int[getPropertySpan()];
 	}
 
 	protected int getSubclassPropertyTableNumber(int i) {
 		return 0;
 	}
 
 	public int getSubclassPropertyTableNumber(String propertyName) {
 		return 0;
 	}
 
 	public boolean isMultiTable() {
 		// This could also just be true all the time...
 		return isAbstract() || hasSubclasses();
 	}
 
 	public int getTableSpan() {
 		return 1;
 	}
 
 	protected int[] getSubclassColumnTableNumberClosure() {
-		return new int[ getSubclassColumnClosure().length ];
+		return new int[getSubclassColumnClosure().length];
 	}
 
 	protected int[] getSubclassFormulaTableNumberClosure() {
-		return new int[ getSubclassFormulaClosure().length ];
+		return new int[getSubclassFormulaClosure().length];
 	}
 
 	protected boolean[] getTableHasColumns() {
-		return new boolean[] { true };
+		return new boolean[] {true};
 	}
 
 	protected int[] getPropertyTableNumbers() {
-		return new int[ getPropertySpan() ];
+		return new int[getPropertySpan()];
 	}
 
 	protected String generateSubquery(PersistentClass model, Mapping mapping) {
 
 		Dialect dialect = getFactory().getDialect();
 		Settings settings = getFactory().getSettings();
-		
+
 		if ( !model.hasSubclasses() ) {
 			return model.getTable().getQualifiedName(
 					dialect,
 					settings.getDefaultCatalogName(),
 					settings.getDefaultSchemaName()
-				);
+			);
 		}
 
 		HashSet columns = new LinkedHashSet();
 		Iterator titer = model.getSubclassTableClosureIterator();
 		while ( titer.hasNext() ) {
 			Table table = (Table) titer.next();
 			if ( !table.isAbstractUnionTable() ) {
 				Iterator citer = table.getColumnIterator();
 				while ( citer.hasNext() ) {
 					columns.add( citer.next() );
 				}
 			}
 		}
 
 		StringBuilder buf = new StringBuilder()
-			.append("( ");
+				.append( "( " );
 
 		Iterator siter = new JoinedIterator(
-			new SingletonIterator(model),
-			model.getSubclassIterator()
+				new SingletonIterator( model ),
+				model.getSubclassIterator()
 		);
 
 		while ( siter.hasNext() ) {
 			PersistentClass clazz = (PersistentClass) siter.next();
 			Table table = clazz.getTable();
 			if ( !table.isAbstractUnionTable() ) {
 				//TODO: move to .sql package!!
-				buf.append("select ");
+				buf.append( "select " );
 				Iterator citer = columns.iterator();
 				while ( citer.hasNext() ) {
 					Column col = (Column) citer.next();
-					if ( !table.containsColumn(col) ) {
-						int sqlType = col.getSqlTypeCode(mapping);
-						buf.append( dialect.getSelectClauseNullString(sqlType) )
-							.append(" as ");
+					if ( !table.containsColumn( col ) ) {
+						int sqlType = col.getSqlTypeCode( mapping );
+						buf.append( dialect.getSelectClauseNullString( sqlType ) )
+								.append( " as " );
 					}
-					buf.append( col.getQuotedName(dialect) );
-					buf.append(", ");
+					buf.append( col.getQuotedName( dialect ) );
+					buf.append( ", " );
 				}
 				buf.append( clazz.getSubclassId() )
-					.append(" as clazz_");
-				buf.append(" from ")
-					.append( table.getQualifiedName(
-							dialect,
-							settings.getDefaultCatalogName(),
-							settings.getDefaultSchemaName()
-					) );
-				buf.append(" union ");
+						.append( " as clazz_" );
+				buf.append( " from " )
+						.append(
+								table.getQualifiedName(
+										dialect,
+										settings.getDefaultCatalogName(),
+										settings.getDefaultSchemaName()
+								)
+						);
+				buf.append( " union " );
 				if ( dialect.supportsUnionAll() ) {
-					buf.append("all ");
+					buf.append( "all " );
 				}
 			}
 		}
-		
+
 		if ( buf.length() > 2 ) {
 			//chop the last union (all)
 			buf.setLength( buf.length() - ( dialect.supportsUnionAll() ? 11 : 7 ) );
 		}
 
-		return buf.append(" )").toString();
+		return buf.append( " )" ).toString();
 	}
 
 	protected String[] getSubclassTableKeyColumns(int j) {
-		if (j!=0) {
-			throw new AssertionFailure("only one table");
+		if ( j != 0 ) {
+			throw new AssertionFailure( "only one table" );
 		}
 		return getIdentifierColumnNames();
 	}
 
 	public String getSubclassTableName(int j) {
-		if (j!=0) {
-			throw new AssertionFailure("only one table");
+		if ( j != 0 ) {
+			throw new AssertionFailure( "only one table" );
 		}
 		return tableName;
 	}
 
 	public int getSubclassTableSpan() {
 		return 1;
 	}
 
 	protected boolean isClassOrSuperclassTable(int j) {
-		if (j!=0) {
-			throw new AssertionFailure("only one table");
+		if ( j != 0 ) {
+			throw new AssertionFailure( "only one table" );
 		}
 		return true;
 	}
 
 	public String getPropertyTableName(String propertyName) {
 		//TODO: check this....
 		return getTableName();
 	}
 
 	public String[] getConstraintOrderedTableNameClosure() {
 		return constraintOrderedTableNames;
 	}
 
 	public String[][] getContraintOrderedTableKeyColumnClosure() {
 		return constraintOrderedKeyColumnNames;
 	}
 
 	@Override
 	public FilterAliasGenerator getFilterAliasGenerator(String rootAlias) {
-		return new StaticFilterAliasGenerator(rootAlias);
+		return new StaticFilterAliasGenerator( rootAlias );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/internal/StandardPersisterClassResolver.java b/hibernate-core/src/main/java/org/hibernate/persister/internal/StandardPersisterClassResolver.java
index 4c296a040f..e90f4441f0 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/internal/StandardPersisterClassResolver.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/internal/StandardPersisterClassResolver.java
@@ -1,99 +1,99 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.internal;
 
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.JoinedSubclass;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.mapping.SingleTableSubclass;
 import org.hibernate.mapping.UnionSubclass;
 import org.hibernate.persister.collection.BasicCollectionPersister;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.OneToManyPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.JoinedSubclassEntityPersister;
 import org.hibernate.persister.entity.SingleTableEntityPersister;
 import org.hibernate.persister.entity.UnionSubclassEntityPersister;
 import org.hibernate.persister.spi.PersisterClassResolver;
 import org.hibernate.persister.spi.UnknownPersisterException;
 
 /**
  * @author Steve Ebersole
  */
 public class StandardPersisterClassResolver implements PersisterClassResolver {
 
 	@Override
 	public Class<? extends EntityPersister> getEntityPersisterClass(PersistentClass metadata) {
 		// todo : make sure this is based on an attribute kept on the metamodel in the new code, not the concrete PersistentClass impl found!
 		if ( RootClass.class.isInstance( metadata ) ) {
-            if ( metadata.hasSubclasses() ) {
-                //If the class has children, we need to find of which kind
-                metadata = (PersistentClass) metadata.getDirectSubclasses().next();
-            }
-            else {
-			    return singleTableEntityPersister();
-            }
+			if ( metadata.hasSubclasses() ) {
+				//If the class has children, we need to find of which kind
+				metadata = (PersistentClass) metadata.getDirectSubclasses().next();
+			}
+			else {
+				return singleTableEntityPersister();
+			}
 		}
 		if ( JoinedSubclass.class.isInstance( metadata ) ) {
 			return joinedSubclassEntityPersister();
 		}
 		else if ( UnionSubclass.class.isInstance( metadata ) ) {
 			return unionSubclassEntityPersister();
 		}
-        else if ( SingleTableSubclass.class.isInstance( metadata ) ) {
+		else if ( SingleTableSubclass.class.isInstance( metadata ) ) {
 			return singleTableEntityPersister();
 		}
 		else {
 			throw new UnknownPersisterException(
 					"Could not determine persister implementation for entity [" + metadata.getEntityName() + "]"
 			);
 		}
 	}
 
-    public Class<? extends EntityPersister> singleTableEntityPersister() {
+	public Class<? extends EntityPersister> singleTableEntityPersister() {
 		return SingleTableEntityPersister.class;
 	}
 
 	public Class<? extends EntityPersister> joinedSubclassEntityPersister() {
 		return JoinedSubclassEntityPersister.class;
 	}
 
 	public Class<? extends EntityPersister> unionSubclassEntityPersister() {
 		return UnionSubclassEntityPersister.class;
 	}
 
 	@Override
 	public Class<? extends CollectionPersister> getCollectionPersisterClass(Collection metadata) {
 		return metadata.isOneToMany() ? oneToManyPersister() : basicCollectionPersister();
 	}
 
 	private Class<OneToManyPersister> oneToManyPersister() {
 		return OneToManyPersister.class;
 	}
 
 	private Class<BasicCollectionPersister> basicCollectionPersister() {
 		return BasicCollectionPersister.class;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/pretty/MessageHelper.java b/hibernate-core/src/main/java/org/hibernate/pretty/MessageHelper.java
index f181f72ff0..41b188c46b 100644
--- a/hibernate-core/src/main/java/org/hibernate/pretty/MessageHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/pretty/MessageHelper.java
@@ -1,411 +1,413 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.pretty;
 import java.io.Serializable;
 
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.type.Type;
 
 /**
  * MessageHelper methods for rendering log messages relating to managed
  * entities and collections typically used in log statements and exception
  * messages.
  *
  * @author Max Andersen, Gavin King
  */
 public final class MessageHelper {
 
 	private MessageHelper() {
 	}
 
 
 	// entities ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Generate an info message string relating to a particular entity,
 	 * based on the given entityName and id.
 	 *
 	 * @param entityName The defined entity name.
 	 * @param id The entity id value.
 	 * @return An info string, in the form [FooBar#1].
 	 */
 	public static String infoString(String entityName, Serializable id) {
 		StringBuilder s = new StringBuilder();
 		s.append( '[' );
 		if( entityName == null ) {
 			s.append( "<null entity name>" );
 		}
 		else {
 			s.append( entityName );
 		}
 		s.append( '#' );
 
 		if ( id == null ) {
 			s.append( "<null>" );
 		}
 		else {
 			s.append( id );
 		}
 		s.append( ']' );
 
 		return s.toString();
 	}
 
 	/**
 	 * Generate an info message string relating to a particular entity.
 	 *
 	 * @param persister The persister for the entity
 	 * @param id The entity id value
 	 * @param factory The session factory - Could be null!
 	 * @return An info string, in the form [FooBar#1]
 	 */
 	public static String infoString(
 			EntityPersister persister,
 			Object id, 
 			SessionFactoryImplementor factory) {
 		StringBuilder s = new StringBuilder();
 		s.append( '[' );
 		Type idType;
 		if( persister == null ) {
 			s.append( "<null EntityPersister>" );
 			idType = null;
 		}
 		else {
 			s.append( persister.getEntityName() );
 			idType = persister.getIdentifierType();
 		}
 		s.append( '#' );
 
 		if ( id == null ) {
 			s.append( "<null>" );
 		}
 		else {
 			if ( idType == null ) {
 				s.append( id );
 			}
 			else {
 				if ( factory != null ) {
 					s.append( idType.toLoggableString( id, factory ) );
 				}
 				else {
 					s.append( "<not loggable>" );
 				}
 			}
 		}
 		s.append( ']' );
 
 		return s.toString();
 
 	}
 
 	/**
 	 * Generate an info message string relating to a particular entity,.
 	 *
 	 * @param persister The persister for the entity
 	 * @param id The entity id value
 	 * @param identifierType The entity identifier type mapping
 	 * @param factory The session factory
 	 * @return An info string, in the form [FooBar#1]
 	 */
 	public static String infoString(
 			EntityPersister persister, 
 			Object id, 
 			Type identifierType,
 			SessionFactoryImplementor factory) {
 		StringBuilder s = new StringBuilder();
 		s.append( '[' );
 		if( persister == null ) {
 			s.append( "<null EntityPersister>" );
 		}
 		else {
 			s.append( persister.getEntityName() );
 		}
 		s.append( '#' );
 
 		if ( id == null ) {
 			s.append( "<null>" );
 		}
 		else {
 			s.append( identifierType.toLoggableString( id, factory ) );
 		}
 		s.append( ']' );
 
 		return s.toString();
 	}
 
 	/**
 	 * Generate an info message string relating to a series of entities.
 	 *
 	 * @param persister The persister for the entities
 	 * @param ids The entity id values
 	 * @param factory The session factory
 	 * @return An info string, in the form [FooBar#<1,2,3>]
 	 */
 	public static String infoString(
 			EntityPersister persister, 
 			Serializable[] ids, 
 			SessionFactoryImplementor factory) {
 		StringBuilder s = new StringBuilder();
 		s.append( '[' );
 		if( persister == null ) {
 			s.append( "<null EntityPersister>" );
 		}
 		else {
 			s.append( persister.getEntityName() );
 			s.append( "#<" );
 			for ( int i=0; i<ids.length; i++ ) {
 				s.append( persister.getIdentifierType().toLoggableString( ids[i], factory ) );
 				if ( i < ids.length-1 ) {
 					s.append( ", " );
 				}
 			}
 			s.append( '>' );
 		}
 		s.append( ']' );
 
 		return s.toString();
 
 	}
 
 	/**
 	 * Generate an info message string relating to given entity persister.
 	 *
 	 * @param persister The persister.
 	 * @return An info string, in the form [FooBar]
 	 */
 	public static String infoString(EntityPersister persister) {
 		StringBuilder s = new StringBuilder();
 		s.append( '[' );
 		if ( persister == null ) {
 			s.append( "<null EntityPersister>" );
 		}
 		else {
 			s.append( persister.getEntityName() );
 		}
 		s.append( ']' );
 		return s.toString();
 	}
 
 	/**
 	 * Generate an info message string relating to a given property value
 	 * for an entity.
 	 *
 	 * @param entityName The entity name
 	 * @param propertyName The name of the property
 	 * @param key The property value.
 	 * @return An info string, in the form [Foo.bars#1]
 	 */
 	public static String infoString(String entityName, String propertyName, Object key) {
 		StringBuilder s = new StringBuilder()
 				.append( '[' )
 				.append( entityName )
 				.append( '.' )
 				.append( propertyName )
 				.append( '#' );
 
 		if ( key == null ) {
 			s.append( "<null>" );
 		}
 		else {
 			s.append( key );
 		}
 		s.append( ']' );
 		return s.toString();
 	}
 
 
 	// collections ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	
 	/**
 	 * Generate an info message string relating to a particular managed
 	 * collection.  Attempts to intelligently handle property-refs issues
 	 * where the collection key is not the same as the owner key.
 	 *
 	 * @param persister The persister for the collection
 	 * @param collection The collection itself
 	 * @param collectionKey The collection key
 	 * @param session The session
 	 * @return An info string, in the form [Foo.bars#1]
 	 */
 	public static String collectionInfoString( 
 			CollectionPersister persister,
 			PersistentCollection collection,
 			Serializable collectionKey,
 			SessionImplementor session ) {
 		
 		StringBuilder s = new StringBuilder();
 		s.append( '[' );
 		if ( persister == null ) {
 			s.append( "<unreferenced>" );
 		}
 		else {
 			s.append( persister.getRole() );
 			s.append( '#' );
 			
 			Type ownerIdentifierType = persister.getOwnerEntityPersister()
 					.getIdentifierType();
 			Serializable ownerKey;
 			// TODO: Is it redundant to attempt to use the collectionKey,
 			// or is always using the owner id sufficient?
 			if ( collectionKey.getClass().isAssignableFrom( 
 					ownerIdentifierType.getReturnedClass() ) ) {
 				ownerKey = collectionKey;
-			} else {
+			}
+			else {
 				ownerKey = session.getPersistenceContext()
 						.getEntry( collection.getOwner() ).getId();
 			}
 			s.append( ownerIdentifierType.toLoggableString( 
 					ownerKey, session.getFactory() ) );
 		}
 		s.append( ']' );
 
 		return s.toString();
 	}
 
 	/**
 	 * Generate an info message string relating to a series of managed
 	 * collections.
 	 *
 	 * @param persister The persister for the collections
 	 * @param ids The id values of the owners
 	 * @param factory The session factory
 	 * @return An info string, in the form [Foo.bars#<1,2,3>]
 	 */
 	public static String collectionInfoString(
 			CollectionPersister persister, 
 			Serializable[] ids, 
 			SessionFactoryImplementor factory) {
 		StringBuilder s = new StringBuilder();
 		s.append( '[' );
 		if ( persister == null ) {
 			s.append( "<unreferenced>" );
 		}
 		else {
 			s.append( persister.getRole() );
 			s.append( "#<" );
 			for ( int i = 0; i < ids.length; i++ ) {
 				addIdToCollectionInfoString( persister, ids[i], factory, s );
 				if ( i < ids.length-1 ) {
 					s.append( ", " );
 				}
 			}
 			s.append( '>' );
 		}
 		s.append( ']' );
 		return s.toString();
 	}
 
 	/**
 	 * Generate an info message string relating to a particular managed
 	 * collection.
 	 *
 	 * @param persister The persister for the collection
 	 * @param id The id value of the owner
 	 * @param factory The session factory
 	 * @return An info string, in the form [Foo.bars#1]
 	 */
 	public static String collectionInfoString(
 			CollectionPersister persister, 
 			Serializable id, 
 			SessionFactoryImplementor factory) {
 		StringBuilder s = new StringBuilder();
 		s.append( '[' );
 		if ( persister == null ) {
 			s.append( "<unreferenced>" );
 		}
 		else {
 			s.append( persister.getRole() );
 			s.append( '#' );
 
 			if ( id == null ) {
 				s.append( "<null>" );
 			}
 			else {
 				addIdToCollectionInfoString( persister, id, factory, s );
 			}
 		}
 		s.append( ']' );
 
 		return s.toString();
 	}
 	
 	private static void addIdToCollectionInfoString(
 			CollectionPersister persister,
 			Serializable id,
 			SessionFactoryImplementor factory,
 			StringBuilder s ) {
 		// Need to use the identifier type of the collection owner
 		// since the incoming is value is actually the owner's id.
 		// Using the collection's key type causes problems with
 		// property-ref keys.
 		// Also need to check that the expected identifier type matches
 		// the given ID.  Due to property-ref keys, the collection key
 		// may not be the owner key.
 		Type ownerIdentifierType = persister.getOwnerEntityPersister()
 				.getIdentifierType();
 		if ( id.getClass().isAssignableFrom( 
 				ownerIdentifierType.getReturnedClass() ) ) {
 			s.append( ownerIdentifierType.toLoggableString( id, factory ) );
-		} else {
+		}
+		else {
 			// TODO: This is a crappy backup if a property-ref is used.
 			// If the reference is an object w/o toString(), this isn't going to work.
 			s.append( id.toString() );
 		}
 	}
 
 	/**
 	 * Generate an info message string relating to a particular managed
 	 * collection.
 	 *
 	 * @param role The role-name of the collection
 	 * @param id The id value of the owner
 	 * @return An info string, in the form [Foo.bars#1]
 	 */
 	public static String collectionInfoString(String role, Serializable id) {
 		StringBuilder s = new StringBuilder();
 		s.append( '[' );
 		if( role == null ) {
 			s.append( "<unreferenced>" );
 		}
 		else {
 			s.append( role );
 			s.append( '#' );
 
 			if ( id == null ) {
 				s.append( "<null>" );
 			}
 			else {
 				s.append( id );
 			}
 		}
 		s.append( ']' );
 		return s.toString();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/property/BasicPropertyAccessor.java b/hibernate-core/src/main/java/org/hibernate/property/BasicPropertyAccessor.java
index 78eb107b73..2fb6473e9b 100644
--- a/hibernate-core/src/main/java/org/hibernate/property/BasicPropertyAccessor.java
+++ b/hibernate-core/src/main/java/org/hibernate/property/BasicPropertyAccessor.java
@@ -1,378 +1,375 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.property;
 
 import java.beans.Introspector;
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Member;
 import java.lang.reflect.Method;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.PropertyAccessException;
 import org.hibernate.PropertyNotFoundException;
 import org.hibernate.PropertySetterAccessException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
-import org.hibernate.internal.util.ReflectHelper;
-
-import org.jboss.logging.Logger;
 
 /**
  * Accesses property values via a get/set pair, which may be nonpublic.
  * The default (and recommended strategy).
  *
  * @author Gavin King
  */
 public class BasicPropertyAccessor implements PropertyAccessor {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( BasicPropertyAccessor.class );
 
 	public static final class BasicSetter implements Setter {
 		private Class clazz;
 		private final transient Method method;
 		private final String propertyName;
 
 		private BasicSetter(Class clazz, Method method, String propertyName) {
-			this.clazz=clazz;
-			this.method=method;
-			this.propertyName=propertyName;
+			this.clazz = clazz;
+			this.method = method;
+			this.propertyName = propertyName;
 		}
 
 		@Override
 		public void set(Object target, Object value, SessionFactoryImplementor factory)
-		throws HibernateException {
+				throws HibernateException {
 			try {
 				method.invoke( target, value );
 			}
 			catch (NullPointerException npe) {
-				if ( value==null && method.getParameterTypes()[0].isPrimitive() ) {
+				if ( value == null && method.getParameterTypes()[0].isPrimitive() ) {
 					throw new PropertyAccessException(
 							npe,
 							"Null value was assigned to a property of primitive type",
 							true,
 							clazz,
 							propertyName
 					);
 				}
 				else {
 					throw new PropertyAccessException(
 							npe,
 							"NullPointerException occurred while calling",
 							true,
 							clazz,
 							propertyName
 					);
 				}
 			}
 			catch (InvocationTargetException ite) {
 				throw new PropertyAccessException(
 						ite,
 						"Exception occurred inside",
 						true,
 						clazz,
 						propertyName
 				);
 			}
 			catch (IllegalAccessException iae) {
 				throw new PropertyAccessException(
 						iae,
 						"IllegalAccessException occurred while calling",
 						true,
 						clazz,
 						propertyName
 				);
 				//cannot occur
 			}
 			catch (IllegalArgumentException iae) {
-				if ( value==null && method.getParameterTypes()[0].isPrimitive() ) {
+				if ( value == null && method.getParameterTypes()[0].isPrimitive() ) {
 					throw new PropertyAccessException(
 							iae,
 							"Null value was assigned to a property of primitive type",
 							true,
 							clazz,
 							propertyName
 					);
 				}
 				else {
 					final Class expectedType = method.getParameterTypes()[0];
 					LOG.illegalPropertySetterArgument( clazz.getName(), propertyName );
 					LOG.expectedType( expectedType.getName(), value == null ? null : value.getClass().getName() );
 					throw new PropertySetterAccessException(
 							iae,
 							clazz,
 							propertyName,
 							expectedType,
 							target,
 							value
 					);
 				}
 			}
 		}
 
 		@Override
 		public Method getMethod() {
 			return method;
 		}
 
 		@Override
 		public String getMethodName() {
 			return method.getName();
 		}
 
 		Object readResolve() {
-			return createSetter(clazz, propertyName);
+			return createSetter( clazz, propertyName );
 		}
 
 		@Override
-        public String toString() {
+		public String toString() {
 			return "BasicSetter(" + clazz.getName() + '.' + propertyName + ')';
 		}
 	}
 
 	public static final class BasicGetter implements Getter {
 		private Class clazz;
 		private final transient Method method;
 		private final String propertyName;
 
 		private BasicGetter(Class clazz, Method method, String propertyName) {
-			this.clazz=clazz;
-			this.method=method;
-			this.propertyName=propertyName;
+			this.clazz = clazz;
+			this.method = method;
+			this.propertyName = propertyName;
 		}
 
 		@Override
 		public Object get(Object target) throws HibernateException {
 			try {
 				return method.invoke( target, (Object[]) null );
 			}
 			catch (InvocationTargetException ite) {
 				throw new PropertyAccessException(
 						ite,
 						"Exception occurred inside",
 						false,
 						clazz,
 						propertyName
 				);
 			}
 			catch (IllegalAccessException iae) {
 				throw new PropertyAccessException(
 						iae,
 						"IllegalAccessException occurred while calling",
 						false,
 						clazz,
 						propertyName
 				);
 				//cannot occur
 			}
 			catch (IllegalArgumentException iae) {
-                LOG.illegalPropertyGetterArgument(clazz.getName(), propertyName);
+				LOG.illegalPropertyGetterArgument( clazz.getName(), propertyName );
 				throw new PropertyAccessException(
 						iae,
 						"IllegalArgumentException occurred calling",
 						false,
 						clazz,
 						propertyName
 				);
 			}
 		}
 
 		@Override
 		public Object getForInsert(Object target, Map mergeMap, SessionImplementor session) {
 			return get( target );
 		}
 
 		@Override
 		public Class getReturnType() {
 			return method.getReturnType();
 		}
 
 		@Override
 		public Member getMember() {
 			return method;
 		}
 
 		@Override
 		public Method getMethod() {
 			return method;
 		}
 
 		@Override
 		public String getMethodName() {
 			return method.getName();
 		}
 
 		@Override
-        public String toString() {
+		public String toString() {
 			return "BasicGetter(" + clazz.getName() + '.' + propertyName + ')';
 		}
 
 		Object readResolve() {
-			return createGetter(clazz, propertyName);
+			return createGetter( clazz, propertyName );
 		}
 	}
 
 
 	@Override
 	public Setter getSetter(Class theClass, String propertyName) throws PropertyNotFoundException {
-		return createSetter(theClass, propertyName);
+		return createSetter( theClass, propertyName );
 	}
 
 	private static Setter createSetter(Class theClass, String propertyName) throws PropertyNotFoundException {
-		BasicSetter result = getSetterOrNull(theClass, propertyName);
-		if (result==null) {
+		BasicSetter result = getSetterOrNull( theClass, propertyName );
+		if ( result == null ) {
 			throw new PropertyNotFoundException(
 					"Could not find a setter for property " +
-					propertyName +
-					" in class " +
-					theClass.getName()
+							propertyName +
+							" in class " +
+							theClass.getName()
 			);
 		}
 		return result;
 	}
 
 	private static BasicSetter getSetterOrNull(Class theClass, String propertyName) {
-		if (theClass==Object.class || theClass==null) {
+		if ( theClass == Object.class || theClass == null ) {
 			return null;
 		}
 
-		Method method = setterMethod(theClass, propertyName);
+		Method method = setterMethod( theClass, propertyName );
 
-		if (method!=null) {
-			method.setAccessible(true);
-			return new BasicSetter(theClass, method, propertyName);
+		if ( method != null ) {
+			method.setAccessible( true );
+			return new BasicSetter( theClass, method, propertyName );
 		}
 		else {
 			BasicSetter setter = getSetterOrNull( theClass.getSuperclass(), propertyName );
-			if (setter==null) {
+			if ( setter == null ) {
 				Class[] interfaces = theClass.getInterfaces();
-				for ( int i=0; setter==null && i<interfaces.length; i++ ) {
-					setter=getSetterOrNull( interfaces[i], propertyName );
+				for ( int i = 0; setter == null && i < interfaces.length; i++ ) {
+					setter = getSetterOrNull( interfaces[i], propertyName );
 				}
 			}
 			return setter;
 		}
 
 	}
 
 	private static Method setterMethod(Class theClass, String propertyName) {
-		BasicGetter getter = getGetterOrNull(theClass, propertyName);
-		Class returnType = (getter==null) ? null : getter.getReturnType();
+		BasicGetter getter = getGetterOrNull( theClass, propertyName );
+		Class returnType = ( getter == null ) ? null : getter.getReturnType();
 
 		Method[] methods = theClass.getDeclaredMethods();
 		Method potentialSetter = null;
 		for ( Method method : methods ) {
 			final String methodName = method.getName();
 			if ( method.getParameterTypes().length == 1 && methodName.startsWith( "set" ) ) {
 				String testStdMethod = Introspector.decapitalize( methodName.substring( 3 ) );
 				String testOldMethod = methodName.substring( 3 );
 				if ( testStdMethod.equals( propertyName ) || testOldMethod.equals( propertyName ) ) {
 					potentialSetter = method;
 					if ( returnType == null || method.getParameterTypes()[0].equals( returnType ) ) {
 						return potentialSetter;
 					}
 				}
 			}
 		}
 		return potentialSetter;
 	}
 
 	@Override
 	public Getter getGetter(Class theClass, String propertyName) throws PropertyNotFoundException {
-		return createGetter(theClass, propertyName);
+		return createGetter( theClass, propertyName );
 	}
 
 	public static Getter createGetter(Class theClass, String propertyName) throws PropertyNotFoundException {
-		BasicGetter result = getGetterOrNull(theClass, propertyName);
-		if (result==null) {
+		BasicGetter result = getGetterOrNull( theClass, propertyName );
+		if ( result == null ) {
 			throw new PropertyNotFoundException(
 					"Could not find a getter for " +
-					propertyName +
-					" in class " +
-					theClass.getName()
+							propertyName +
+							" in class " +
+							theClass.getName()
 			);
 		}
 		return result;
 	}
 
 	private static BasicGetter getGetterOrNull(Class theClass, String propertyName) {
-		if (theClass==Object.class || theClass==null) {
+		if ( theClass == Object.class || theClass == null ) {
 			return null;
 		}
 
-		Method method = getterMethod(theClass, propertyName);
+		Method method = getterMethod( theClass, propertyName );
 
-		if (method!=null) {
-			method.setAccessible(true);
-			return new BasicGetter(theClass, method, propertyName);
+		if ( method != null ) {
+			method.setAccessible( true );
+			return new BasicGetter( theClass, method, propertyName );
 		}
 		else {
 			BasicGetter getter = getGetterOrNull( theClass.getSuperclass(), propertyName );
-			if (getter==null) {
+			if ( getter == null ) {
 				Class[] interfaces = theClass.getInterfaces();
-				for ( int i=0; getter==null && i<interfaces.length; i++ ) {
-					getter=getGetterOrNull( interfaces[i], propertyName );
+				for ( int i = 0; getter == null && i < interfaces.length; i++ ) {
+					getter = getGetterOrNull( interfaces[i], propertyName );
 				}
 			}
 			return getter;
 		}
 	}
 
 	private static Method getterMethod(Class theClass, String propertyName) {
 		Method[] methods = theClass.getDeclaredMethods();
 		for ( Method method : methods ) {
 			// if the method has parameters, skip it
 			if ( method.getParameterTypes().length != 0 ) {
 				continue;
 			}
 			// if the method is a "bridge", skip it
 			if ( method.isBridge() ) {
 				continue;
 			}
 
 			final String methodName = method.getName();
 
 			// try "get"
 			if ( methodName.startsWith( "get" ) ) {
 				String testStdMethod = Introspector.decapitalize( methodName.substring( 3 ) );
 				String testOldMethod = methodName.substring( 3 );
 				if ( testStdMethod.equals( propertyName ) || testOldMethod.equals( propertyName ) ) {
 					return method;
 				}
 			}
 
 			// if not "get", then try "is"
 			if ( methodName.startsWith( "is" ) ) {
 				String testStdMethod = Introspector.decapitalize( methodName.substring( 2 ) );
 				String testOldMethod = methodName.substring( 2 );
 				if ( testStdMethod.equals( propertyName ) || testOldMethod.equals( propertyName ) ) {
 					return method;
 				}
 			}
 		}
 
 		return null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/property/ChainedPropertyAccessor.java b/hibernate-core/src/main/java/org/hibernate/property/ChainedPropertyAccessor.java
index 2a02f03b92..ad19a19c15 100644
--- a/hibernate-core/src/main/java/org/hibernate/property/ChainedPropertyAccessor.java
+++ b/hibernate-core/src/main/java/org/hibernate/property/ChainedPropertyAccessor.java
@@ -1,69 +1,69 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.property;
+
 import org.hibernate.PropertyNotFoundException;
 
 /**
  * @author max
- *
  */
 public class ChainedPropertyAccessor implements PropertyAccessor {
 
 	final PropertyAccessor[] chain;
-	
+
 	public ChainedPropertyAccessor(PropertyAccessor[] chain) {
 		this.chain = chain;
 	}
-	
+
 	public Getter getGetter(Class theClass, String propertyName)
 			throws PropertyNotFoundException {
 		Getter result = null;
-		for (int i = 0; i < chain.length; i++) {
-			PropertyAccessor candidate = chain[i];
+		for ( PropertyAccessor candidate : chain ) {
 			try {
-				result = candidate.getGetter(theClass, propertyName);
+				result = candidate.getGetter( theClass, propertyName );
 				return result;
-			} catch (PropertyNotFoundException pnfe) {
+			}
+			catch (PropertyNotFoundException pnfe) {
 				// ignore
 			}
 		}
-		throw new PropertyNotFoundException("Could not find getter for " + propertyName + " on " + theClass);
+		throw new PropertyNotFoundException( "Could not find getter for " + propertyName + " on " + theClass );
 	}
 
 	public Setter getSetter(Class theClass, String propertyName)
 			throws PropertyNotFoundException {
 		Setter result = null;
-		for (int i = 0; i < chain.length; i++) {
-			PropertyAccessor candidate = chain[i];
+		for ( PropertyAccessor candidate : chain ) {
 			try {
-				result = candidate.getSetter(theClass, propertyName);
+				result = candidate.getSetter( theClass, propertyName );
 				return result;
-			} catch (PropertyNotFoundException pnfe) {
-				//
+			}
+			catch (PropertyNotFoundException pnfe) {
+				// ignore
 			}
 		}
-		throw new PropertyNotFoundException("Could not find setter for " + propertyName + " on " + theClass);
+		throw new PropertyNotFoundException( "Could not find setter for " + propertyName + " on " + theClass );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/property/DirectPropertyAccessor.java b/hibernate-core/src/main/java/org/hibernate/property/DirectPropertyAccessor.java
index 89a358a996..89ad3f2ff7 100644
--- a/hibernate-core/src/main/java/org/hibernate/property/DirectPropertyAccessor.java
+++ b/hibernate-core/src/main/java/org/hibernate/property/DirectPropertyAccessor.java
@@ -1,189 +1,190 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.property;
+
 import java.lang.reflect.Field;
 import java.lang.reflect.Member;
 import java.lang.reflect.Method;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.PropertyAccessException;
 import org.hibernate.PropertyNotFoundException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.internal.util.ReflectHelper;
 
 /**
  * Accesses fields directly.
  * @author Gavin King
  */
 public class DirectPropertyAccessor implements PropertyAccessor {
 
 	public static final class DirectGetter implements Getter {
 		private final transient Field field;
 		private final Class clazz;
 		private final String name;
 
 		DirectGetter(Field field, Class clazz, String name) {
 			this.field = field;
 			this.clazz = clazz;
 			this.name = name;
 		}
 
 		@Override
 		public Object get(Object target) throws HibernateException {
 			try {
 				return field.get(target);
 			}
 			catch (Exception e) {
 				throw new PropertyAccessException(e, "could not get a field value by reflection", false, clazz, name);
 			}
 		}
 
 		@Override
 		public Object getForInsert(Object target, Map mergeMap, SessionImplementor session) {
 			return get( target );
 		}
 
 		@Override
 		public Member getMember() {
 			return field;
 		}
 
 		@Override
 		public Method getMethod() {
 			return null;
 		}
 
 		@Override
 		public String getMethodName() {
 			return null;
 		}
 
 		@Override
 		public Class getReturnType() {
 			return field.getType();
 		}
 
 		Object readResolve() {
 			return new DirectGetter( getField(clazz, name), clazz, name );
 		}
 
 		@Override
 		public String toString() {
 			return "DirectGetter(" + clazz.getName() + '.' + name + ')';
 		}
 	}
 
 	public static final class DirectSetter implements Setter {
 		private final transient Field field;
 		private final Class clazz;
 		private final String name;
 		DirectSetter(Field field, Class clazz, String name) {
 			this.field = field;
 			this.clazz = clazz;
 			this.name = name;
 		}
 
 		@Override
 		public Method getMethod() {
 			return null;
 		}
 
 		@Override
 		public String getMethodName() {
 			return null;
 		}
 
 		@Override
 		public void set(Object target, Object value, SessionFactoryImplementor factory) throws HibernateException {
 			try {
 				field.set(target, value);
 			}
 			catch (Exception e) {
 				if(value == null && field.getType().isPrimitive()) {
 					throw new PropertyAccessException(
 							e, 
 							"Null value was assigned to a property of primitive type", 
 							true, 
 							clazz, 
 							name
 						);					
-				} else {
+				}
+				else {
 					throw new PropertyAccessException(e, "could not set a field value by reflection", true, clazz, name);
 				}
 			}
 		}
 
 		@Override
 		public String toString() {
 			return "DirectSetter(" + clazz.getName() + '.' + name + ')';
 		}
 		
 		Object readResolve() {
 			return new DirectSetter( getField(clazz, name), clazz, name );
 		}
 	}
 
 	private static Field getField(Class clazz, String name) throws PropertyNotFoundException {
 		if ( clazz==null || clazz==Object.class ) {
 			throw new PropertyNotFoundException("field not found: " + name); 
 		}
 		Field field;
 		try {
 			field = clazz.getDeclaredField(name);
 		}
 		catch (NoSuchFieldException nsfe) {
 			field = getField( clazz, clazz.getSuperclass(), name );
 		}
 		field.setAccessible(true);
 		return field;
 	}
 
 	private static Field getField(Class root, Class clazz, String name) throws PropertyNotFoundException {
 		if ( clazz==null || clazz==Object.class ) {
 			throw new PropertyNotFoundException("field [" + name + "] not found on " + root.getName()); 
 		}
 		Field field;
 		try {
 			field = clazz.getDeclaredField(name);
 		}
 		catch (NoSuchFieldException nsfe) {
 			field = getField( root, clazz.getSuperclass(), name );
 		}
 		field.setAccessible(true);
 		return field;
 	}
 
 	@Override
 	public Getter getGetter(Class theClass, String propertyName) throws PropertyNotFoundException {
 		return new DirectGetter( getField(theClass, propertyName), theClass, propertyName );
 	}
 
 	@Override
 	public Setter getSetter(Class theClass, String propertyName) throws PropertyNotFoundException {
 		return new DirectSetter( getField(theClass, propertyName), theClass, propertyName );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/property/PropertyAccessorFactory.java b/hibernate-core/src/main/java/org/hibernate/property/PropertyAccessorFactory.java
index 99044e9c80..ba70ed43ba 100644
--- a/hibernate-core/src/main/java/org/hibernate/property/PropertyAccessorFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/property/PropertyAccessorFactory.java
@@ -1,157 +1,161 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.property;
 
 import java.util.Map;
 
 import org.hibernate.EntityMode;
 import org.hibernate.MappingException;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.Property;
 
 /**
  * A factory for building/retrieving PropertyAccessor instances.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public final class PropertyAccessorFactory {
 	private static final PropertyAccessor BASIC_PROPERTY_ACCESSOR = new BasicPropertyAccessor();
 	private static final PropertyAccessor DIRECT_PROPERTY_ACCESSOR = new DirectPropertyAccessor();
 	private static final PropertyAccessor MAP_ACCESSOR = new MapAccessor();
 	private static final PropertyAccessor NOOP_ACCESSOR = new NoopAccessor();
 	private static final PropertyAccessor EMBEDDED_PROPERTY_ACCESSOR = new EmbeddedPropertyAccessor();
 
 	//TODO: ideally we need the construction of PropertyAccessor to take the following:
 	//      1) EntityMode
 	//      2) EntityMode-specific data (i.e., the classname for pojo entities)
 	//      3) Property-specific data based on the EntityMode (i.e., property-name or dom4j-node-name)
 	// The easiest way, with the introduction of the new runtime-metamodel classes, would be the
 	// the following predicates:
 	//      1) PropertyAccessorFactory.getPropertyAccessor() takes references to both a
 	//          org.hibernate.metadata.EntityModeMetadata and org.hibernate.metadata.Property
 	//      2) What is now termed a "PropertyAccessor" stores any values needed from those two
 	//          pieces of information
 	//      3) Code can then simply call PropertyAccess.getGetter() with no parameters; likewise with
 	//          PropertyAccessor.getSetter()
 
-    /**
-     * Retrieves a PropertyAccessor instance based on the given property definition and
-     * entity mode.
-     *
-     * @param property The property for which to retrieve an accessor.
-     * @param mode The mode for the resulting entity.
-     * @return An appropriate accessor.
-     * @throws MappingException
-     */
+	/**
+	 * Retrieves a PropertyAccessor instance based on the given property definition and
+	 * entity mode.
+	 *
+	 * @param property The property for which to retrieve an accessor.
+	 * @param mode The mode for the resulting entity.
+	 *
+	 * @return An appropriate accessor.
+	 *
+	 * @throws MappingException
+	 */
 	public static PropertyAccessor getPropertyAccessor(Property property, EntityMode mode) throws MappingException {
 		//TODO: this is temporary in that the end result will probably not take a Property reference per-se.
-	    if ( null == mode || EntityMode.POJO.equals( mode ) ) {
-		    return getPojoPropertyAccessor( property.getPropertyAccessorName() );
-	    }
-	    else if ( EntityMode.MAP.equals( mode ) ) {
-		    return getDynamicMapPropertyAccessor();
-	    }
-	    else {
-		    throw new MappingException( "Unknown entity mode [" + mode + "]" );
-	    }
+		if ( null == mode || EntityMode.POJO.equals( mode ) ) {
+			return getPojoPropertyAccessor( property.getPropertyAccessorName() );
+		}
+		else if ( EntityMode.MAP.equals( mode ) ) {
+			return getDynamicMapPropertyAccessor();
+		}
+		else {
+			throw new MappingException( "Unknown entity mode [" + mode + "]" );
+		}
 	}
 
 
 	/**
 	 * Retreives a PropertyAccessor specific for a PojoRepresentation with the given access strategy.
 	 *
 	 * @param pojoAccessorStrategy The access strategy.
+	 *
 	 * @return An appropriate accessor.
 	 */
 	private static PropertyAccessor getPojoPropertyAccessor(String pojoAccessorStrategy) {
 		if ( StringHelper.isEmpty( pojoAccessorStrategy ) || "property".equals( pojoAccessorStrategy ) ) {
 			return BASIC_PROPERTY_ACCESSOR;
 		}
 		else if ( "field".equals( pojoAccessorStrategy ) ) {
 			return DIRECT_PROPERTY_ACCESSOR;
 		}
 		else if ( "embedded".equals( pojoAccessorStrategy ) ) {
 			return EMBEDDED_PROPERTY_ACCESSOR;
 		}
-		else if ( "noop".equals(pojoAccessorStrategy) ) {
+		else if ( "noop".equals( pojoAccessorStrategy ) ) {
 			return NOOP_ACCESSOR;
 		}
 		else {
 			return resolveCustomAccessor( pojoAccessorStrategy );
 		}
 	}
 
 	public static PropertyAccessor getDynamicMapPropertyAccessor() throws MappingException {
 		return MAP_ACCESSOR;
 	}
 
 	private static PropertyAccessor resolveCustomAccessor(String accessorName) {
 		Class accessorClass;
 		try {
 			accessorClass = ReflectHelper.classForName( accessorName );
 		}
 		catch (ClassNotFoundException cnfe) {
-			throw new MappingException("could not find PropertyAccessor class: " + accessorName, cnfe);
+			throw new MappingException( "could not find PropertyAccessor class: " + accessorName, cnfe );
 		}
 		try {
 			return (PropertyAccessor) accessorClass.newInstance();
 		}
 		catch (Exception e) {
-			throw new MappingException("could not instantiate PropertyAccessor class: " + accessorName, e);
+			throw new MappingException( "could not instantiate PropertyAccessor class: " + accessorName, e );
 		}
 	}
 
-	private PropertyAccessorFactory() {}
+	private PropertyAccessorFactory() {
+	}
 
 	// todo : this eventually needs to be removed
 	public static PropertyAccessor getPropertyAccessor(Class optionalClass, String type) throws MappingException {
-		if ( type==null ) {
-			type = optionalClass==null || optionalClass==Map.class ? "map" : "property";
+		if ( type == null ) {
+			type = optionalClass == null || optionalClass == Map.class ? "map" : "property";
 		}
-		return getPropertyAccessor(type);
+		return getPropertyAccessor( type );
 	}
 
 	// todo : this eventually needs to be removed
 	public static PropertyAccessor getPropertyAccessor(String type) throws MappingException {
-		if ( type==null || "property".equals(type) ) {
+		if ( type == null || "property".equals( type ) ) {
 			return BASIC_PROPERTY_ACCESSOR;
 		}
-		if ( "field".equals(type) ) {
+		if ( "field".equals( type ) ) {
 			return DIRECT_PROPERTY_ACCESSOR;
 		}
-		if ( "map".equals(type) ) {
+		if ( "map".equals( type ) ) {
 			return MAP_ACCESSOR;
 		}
-		if ( "embedded".equals(type) ) {
+		if ( "embedded".equals( type ) ) {
 			return EMBEDDED_PROPERTY_ACCESSOR;
 		}
-		if ( "noop".equals(type)) {
+		if ( "noop".equals( type ) ) {
 			return NOOP_ACCESSOR;
 		}
 
-		return resolveCustomAccessor(type);
+		return resolveCustomAccessor( type );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/proxy/pojo/BasicLazyInitializer.java b/hibernate-core/src/main/java/org/hibernate/proxy/pojo/BasicLazyInitializer.java
index 78002d762b..5cbeeab2b7 100644
--- a/hibernate-core/src/main/java/org/hibernate/proxy/pojo/BasicLazyInitializer.java
+++ b/hibernate-core/src/main/java/org/hibernate/proxy/pojo/BasicLazyInitializer.java
@@ -1,139 +1,139 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.proxy.pojo;
 
 import java.io.Serializable;
 import java.lang.reflect.Method;
 
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.MarkerObject;
 import org.hibernate.proxy.AbstractLazyInitializer;
 import org.hibernate.type.CompositeType;
 
 /**
  * Lazy initializer for POJOs
  *
  * @author Gavin King
  */
 public abstract class BasicLazyInitializer extends AbstractLazyInitializer {
 
-	protected static final Object INVOKE_IMPLEMENTATION = new MarkerObject("INVOKE_IMPLEMENTATION");
+	protected static final Object INVOKE_IMPLEMENTATION = new MarkerObject( "INVOKE_IMPLEMENTATION" );
 
 	protected final Class persistentClass;
 	protected final Method getIdentifierMethod;
 	protected final Method setIdentifierMethod;
 	protected final boolean overridesEquals;
 	protected final CompositeType componentIdType;
 
 	private Object replacement;
 
 	protected BasicLazyInitializer(
 			String entityName,
-	        Class persistentClass,
-	        Serializable id,
-	        Method getIdentifierMethod,
-	        Method setIdentifierMethod,
-	        CompositeType componentIdType,
-	        SessionImplementor session,
-	        boolean overridesEquals) {
-		super(entityName, id, session);
+			Class persistentClass,
+			Serializable id,
+			Method getIdentifierMethod,
+			Method setIdentifierMethod,
+			CompositeType componentIdType,
+			SessionImplementor session,
+			boolean overridesEquals) {
+		super( entityName, id, session );
 		this.persistentClass = persistentClass;
 		this.getIdentifierMethod = getIdentifierMethod;
 		this.setIdentifierMethod = setIdentifierMethod;
 		this.componentIdType = componentIdType;
 		this.overridesEquals = overridesEquals;
 	}
 
 	protected abstract Object serializableProxy();
 
 	protected final Object invoke(Method method, Object[] args, Object proxy) throws Throwable {
 		String methodName = method.getName();
 		int params = args.length;
 
-		if ( params==0 ) {
-			if ( "writeReplace".equals(methodName) ) {
+		if ( params == 0 ) {
+			if ( "writeReplace".equals( methodName ) ) {
 				return getReplacement();
 			}
-			else if ( !overridesEquals && "hashCode".equals(methodName) ) {
-				return System.identityHashCode(proxy);
+			else if ( !overridesEquals && "hashCode".equals( methodName ) ) {
+				return System.identityHashCode( proxy );
 			}
-			else if ( isUninitialized() && method.equals(getIdentifierMethod) ) {
+			else if ( isUninitialized() && method.equals( getIdentifierMethod ) ) {
 				return getIdentifier();
 			}
-			else if ( "getHibernateLazyInitializer".equals(methodName) ) {
+			else if ( "getHibernateLazyInitializer".equals( methodName ) ) {
 				return this;
 			}
 		}
-		else if ( params==1 ) {
-			if ( !overridesEquals && "equals".equals(methodName) ) {
-				return args[0]==proxy;
+		else if ( params == 1 ) {
+			if ( !overridesEquals && "equals".equals( methodName ) ) {
+				return args[0] == proxy;
 			}
-			else if ( method.equals(setIdentifierMethod) ) {
+			else if ( method.equals( setIdentifierMethod ) ) {
 				initialize();
 				setIdentifier( (Serializable) args[0] );
 				return INVOKE_IMPLEMENTATION;
 			}
 		}
 
 		//if it is a property of an embedded component, invoke on the "identifier"
-		if ( componentIdType!=null && componentIdType.isMethodOf(method) ) {
+		if ( componentIdType != null && componentIdType.isMethodOf( method ) ) {
 			return method.invoke( getIdentifier(), args );
 		}
 
 		// otherwise:
 		return INVOKE_IMPLEMENTATION;
 
 	}
 
 	private Object getReplacement() {
 		final SessionImplementor session = getSession();
-		if ( isUninitialized() && session != null && session.isOpen()) {
+		if ( isUninitialized() && session != null && session.isOpen() ) {
 			final EntityKey key = session.generateEntityKey(
 					getIdentifier(),
 					session.getFactory().getEntityPersister( getEntityName() )
 			);
-			final Object entity = session.getPersistenceContext().getEntity(key);
-			if (entity!=null) {
+			final Object entity = session.getPersistenceContext().getEntity( key );
+			if ( entity != null ) {
 				setImplementation( entity );
 			}
 		}
 
 		if ( isUninitialized() ) {
-			if (replacement==null) {
+			if ( replacement == null ) {
 				replacement = serializableProxy();
 			}
 			return replacement;
 		}
 		else {
 			return getTarget();
 		}
 
 	}
 
 	public final Class getPersistentClass() {
 		return persistentClass;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/jdbc/internal/LogicalConnectionProvidedImpl.java b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/internal/LogicalConnectionProvidedImpl.java
index 32251ffda8..ff2d71ed86 100644
--- a/hibernate-core/src/main/java/org/hibernate/resource/jdbc/internal/LogicalConnectionProvidedImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/internal/LogicalConnectionProvidedImpl.java
@@ -1,164 +1,162 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.resource.jdbc.internal;
 
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.sql.Connection;
 
-import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
 import org.hibernate.resource.jdbc.LogicalConnection;
 import org.hibernate.resource.jdbc.ResourceRegistry;
-import org.hibernate.resource.jdbc.spi.JdbcSessionContext;
 import org.hibernate.resource.jdbc.spi.LogicalConnectionImplementor;
 
 import org.jboss.logging.Logger;
 
 /**
  * @author Steve Ebersole
  */
 public class LogicalConnectionProvidedImpl extends AbstractLogicalConnectionImplementor {
 	private static final Logger log = Logger.getLogger( LogicalConnection.class );
 
 	private transient Connection providedConnection;
 	private final boolean initiallyAutoCommit;
 	private boolean closed;
 
 	public LogicalConnectionProvidedImpl(Connection providedConnection) {
 		this( providedConnection, new ResourceRegistryStandardImpl() );
 	}
 
 	public LogicalConnectionProvidedImpl(Connection providedConnection, ResourceRegistry resourceRegistry) {
 		this.resourceRegistry = resourceRegistry;
 		if ( providedConnection == null ) {
 			throw new IllegalArgumentException( "Provided Connection cannot be null" );
 		}
 
 		this.providedConnection = providedConnection;
 		this.initiallyAutoCommit = determineInitialAutoCommitMode( providedConnection );
 	}
 
 	private LogicalConnectionProvidedImpl(boolean closed, boolean initiallyAutoCommit) {
 		this.resourceRegistry = new ResourceRegistryStandardImpl();
 		this.closed = closed;
 		this.initiallyAutoCommit = initiallyAutoCommit;
 	}
 
 	@Override
 	public boolean isOpen() {
 		return !closed;
 	}
 
 	@Override
 	public Connection close() {
 		log.trace( "Closing logical connection" );
 
 		getResourceRegistry().releaseResources();
 
 		try {
 			return providedConnection;
 		}
 		finally {
 			providedConnection = null;
 			closed = true;
 			log.trace( "Logical connection closed" );
 		}
 	}
 
 	@Override
 	public boolean isPhysicallyConnected() {
 		return providedConnection != null;
 	}
 
 	@Override
 	public Connection getPhysicalConnection() {
 		errorIfClosed();
 		return providedConnection;
 	}
 
 	@Override
 	public LogicalConnectionImplementor makeShareableCopy() {
 		errorIfClosed();
 
 		return new LogicalConnectionProvidedImpl( providedConnection );
 	}
 
 	@Override
 	public void serialize(ObjectOutputStream oos) throws IOException {
 		oos.writeBoolean( closed );
 		oos.writeBoolean( initiallyAutoCommit );
 	}
 
 	public static LogicalConnectionProvidedImpl deserialize(
 			ObjectInputStream ois) throws IOException, ClassNotFoundException {
 		final boolean isClosed = ois.readBoolean();
 		final boolean initiallyAutoCommit = ois.readBoolean();
 		return new LogicalConnectionProvidedImpl( isClosed, initiallyAutoCommit );
 	}
 
 	@Override
 	public Connection manualDisconnect() {
 		errorIfClosed();
 		try {
 			resourceRegistry.releaseResources();
 			return providedConnection;
 		}
 		finally {
 			this.providedConnection = null;
 		}
 	}
 
 	@Override
 	public void manualReconnect(Connection connection) {
 		errorIfClosed();
 
 		if ( connection == null ) {
 			throw new IllegalArgumentException( "cannot reconnect using a null connection" );
 		}
 		else if ( connection == providedConnection ) {
 			// likely an unmatched reconnect call (no matching disconnect call)
 			log.debug( "reconnecting the same connection that is already connected; should this connection have been disconnected?" );
 		}
 		else if ( providedConnection != null ) {
 			throw new IllegalArgumentException(
 					"cannot reconnect to a new user-supplied connection because currently connected; must disconnect before reconnecting."
 			);
 		}
 		providedConnection = connection;
 		log.debug( "Manually reconnected logical connection" );
 	}
 
 	@Override
 	protected Connection getConnectionForTransactionManagement() {
 		return providedConnection;
 	}
 
 	@Override
 	protected void afterCompletion() {
 		afterTransaction();
 
 		resetConnection( initiallyAutoCommit );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/LogicalConnectionImplementor.java b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/LogicalConnectionImplementor.java
index e83709307f..3074ab968d 100644
--- a/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/LogicalConnectionImplementor.java
+++ b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/LogicalConnectionImplementor.java
@@ -1,86 +1,93 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.resource.jdbc.spi;
 
 import java.io.IOException;
 import java.io.ObjectOutputStream;
 import java.sql.Connection;
 
-import org.hibernate.engine.jdbc.spi.ConnectionObserver;
 import org.hibernate.resource.jdbc.LogicalConnection;
 
 /**
+ * SPI contract for LogicalConnection
+ *
  * @author Steve Ebersole
  */
 public interface LogicalConnectionImplementor extends LogicalConnection {
-	// todo : expose the Connection as below?  or accept(WorkInConnection) where WorkInConnection is given access to Connection?
-	public Connection getPhysicalConnection();
+	/**
+	 * Exposes access to the "real" Connection.
+	 *
+	 * @todo : expose Connection as here?  or accept(WorkInConnection) where WorkInConnection is given access to Connection?
+	 *
+	 * @return The connection
+	 */
+	Connection getPhysicalConnection();
 
 	/**
 	 * Notification indicating a JDBC statement has been executed to trigger
 	 * {@link org.hibernate.ConnectionReleaseMode#AFTER_STATEMENT} releasing if needed
 	 */
-	public void afterStatement();
+	void afterStatement();
 
 	/**
 	 * Notification indicating a transaction has completed to trigger
 	 * {@link org.hibernate.ConnectionReleaseMode#AFTER_TRANSACTION} releasing if needed
 	 */
-	public void afterTransaction();
+	void afterTransaction();
 
 	/**
 	 * Manually disconnect the underlying JDBC Connection.  The assumption here
 	 * is that the manager will be reconnected at a later point in time.
 	 *
 	 * @return The connection maintained here at time of disconnect.  {@code null} if
 	 * there was no connection cached internally.
 	 */
-	public Connection manualDisconnect();
+	Connection manualDisconnect();
 
 	/**
 	 * Manually reconnect the underlying JDBC Connection.  Should be called at some point after manualDisconnect().
 	 *
 	 * @param suppliedConnection For user supplied connection strategy the user needs to hand us the connection
 	 * with which to reconnect.  It is an error to pass a connection in the other strategies.
 	 */
-	public void manualReconnect(Connection suppliedConnection);
+	void manualReconnect(Connection suppliedConnection);
 
 	/**
 	 * Creates a shareable copy of itself for use in "shared sessions"
 	 *
 	 * @return The shareable copy.
 	 */
-	public LogicalConnectionImplementor makeShareableCopy();
+	LogicalConnectionImplementor makeShareableCopy();
 
-	public PhysicalJdbcTransaction getPhysicalJdbcTransaction();
+	PhysicalJdbcTransaction getPhysicalJdbcTransaction();
 
 	/**
 	 * Serialization hook
 	 *
 	 * @param oos The stream to write out state to
 	 *
 	 * @throws java.io.IOException Problem accessing stream
 	 */
-	public void serialize(ObjectOutputStream oos) throws IOException;
+	void serialize(ObjectOutputStream oos) throws IOException;
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jdbc/internal/JdbcResourceLocalTransactionCoordinatorImpl.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jdbc/internal/JdbcResourceLocalTransactionCoordinatorImpl.java
index 5e3f8a2d6e..866bb57874 100644
--- a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jdbc/internal/JdbcResourceLocalTransactionCoordinatorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jdbc/internal/JdbcResourceLocalTransactionCoordinatorImpl.java
@@ -1,254 +1,252 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.resource.transaction.backend.jdbc.internal;
 
-import javax.transaction.Status;
-
 import java.util.ArrayList;
 import java.util.List;
+import javax.transaction.Status;
 
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.transaction.spi.IsolationDelegate;
 import org.hibernate.engine.transaction.spi.TransactionObserver;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.resource.jdbc.spi.JdbcSessionOwner;
 import org.hibernate.resource.transaction.SynchronizationRegistry;
 import org.hibernate.resource.transaction.TransactionCoordinator;
 import org.hibernate.resource.transaction.TransactionCoordinatorBuilder;
 import org.hibernate.resource.transaction.backend.jdbc.spi.JdbcResourceTransaction;
 import org.hibernate.resource.transaction.backend.jdbc.spi.JdbcResourceTransactionAccess;
-import org.hibernate.resource.transaction.backend.jta.internal.synchronization.ExceptionMapper;
 import org.hibernate.resource.transaction.internal.SynchronizationRegistryStandardImpl;
 import org.hibernate.resource.transaction.spi.TransactionCoordinatorOwner;
 import org.hibernate.resource.transaction.spi.TransactionStatus;
 
 import static org.hibernate.internal.CoreLogging.messageLogger;
 
 /**
  * An implementation of TransactionCoordinator based on managing a transaction through the JDBC Connection
  * via {@link org.hibernate.resource.transaction.backend.jdbc.spi.JdbcResourceTransaction}
  *
  * @author Steve Ebersole
  *
  * @see org.hibernate.resource.transaction.backend.jdbc.spi.JdbcResourceTransaction
  */
 public class JdbcResourceLocalTransactionCoordinatorImpl implements TransactionCoordinator {
 	private static final CoreMessageLogger log = messageLogger( JdbcResourceLocalTransactionCoordinatorImpl.class );
 
 	private final TransactionCoordinatorBuilder transactionCoordinatorBuilder;
 	private final JdbcResourceTransactionAccess jdbcResourceTransactionAccess;
 	private final TransactionCoordinatorOwner transactionCoordinatorOwner;
 	private final SynchronizationRegistryStandardImpl synchronizationRegistry = new SynchronizationRegistryStandardImpl();
 
 	private TransactionDriverControlImpl physicalTransactionDelegate;
 
 	private int timeOut = -1;
 
 	private final transient List<TransactionObserver> observers;
 
 	/**
 	 * Construct a ResourceLocalTransactionCoordinatorImpl instance.  package-protected to ensure access goes through
 	 * builder.
 	 *
 	 * @param owner The transactionCoordinatorOwner
 	 */
 	JdbcResourceLocalTransactionCoordinatorImpl(
 			TransactionCoordinatorBuilder transactionCoordinatorBuilder,
 			TransactionCoordinatorOwner owner,
 			JdbcResourceTransactionAccess jdbcResourceTransactionAccess) {
 		this.observers = new ArrayList<TransactionObserver>();
 		this.transactionCoordinatorBuilder = transactionCoordinatorBuilder;
 		this.jdbcResourceTransactionAccess = jdbcResourceTransactionAccess;
 		this.transactionCoordinatorOwner = owner;
 	}
 
 	@Override
 	public TransactionDriver getTransactionDriverControl() {
 		// Again, this PhysicalTransactionDelegate will act as the bridge from the local transaction back into the
 		// coordinator.  We lazily build it as we invalidate each delegate after each transaction (a delegate is
 		// valid for just one transaction)
 		if ( physicalTransactionDelegate == null ) {
 			physicalTransactionDelegate = new TransactionDriverControlImpl( jdbcResourceTransactionAccess.getResourceLocalTransaction() );
 		}
 		return physicalTransactionDelegate;
 	}
 
 	@Override
 	public void explicitJoin() {
 		// nothing to do here, but log a warning
 		log.callingJoinTransactionOnNonJtaEntityManager();
 	}
 
 	@Override
 	public boolean isJoined() {
 		log.debug( "Calling TransactionCoordinator#isJoined in resource-local mode always returns false" );
 		return isActive();
 	}
 
 	@Override
 	public void pulse() {
 		// nothing to do here
 	}
 
 	@Override
 	public SynchronizationRegistry getLocalSynchronizations() {
 		return synchronizationRegistry;
 	}
 
 	@Override
 	public boolean isActive() {
 		return transactionCoordinatorOwner.isActive();
 	}
 
 	@Override
 	public IsolationDelegate createIsolationDelegate() {
 		final JdbcSessionOwner jdbcSessionOwner = transactionCoordinatorOwner.getJdbcSessionOwner();
 
 		return new JdbcIsolationDelegate(
 				jdbcSessionOwner.getJdbcConnectionAccess(),
 				jdbcSessionOwner.getJdbcSessionContext().getServiceRegistry().getService( JdbcServices.class ).getSqlExceptionHelper()
 		);
 	}
 
 	@Override
 	public TransactionCoordinatorBuilder getTransactionCoordinatorBuilder() {
 		return this.transactionCoordinatorBuilder;
 	}
 
 	@Override
 	public void setTimeOut(int seconds) {
 		this.timeOut = seconds;
 	}
 
 	@Override
 	public int getTimeOut() {
 		return this.timeOut;
 	}
 
 	// PhysicalTransactionDelegate ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private void afterBeginCallback() {
 		if(this.timeOut > 0) {
 			transactionCoordinatorOwner.setTransactionTimeOut( this.timeOut );
 		}
 		for ( TransactionObserver observer : observers ) {
 			observer.afterBegin();
 		}
 		log.trace( "ResourceLocalTransactionCoordinatorImpl#afterBeginCallback" );
 	}
 
 	private void beforeCompletionCallback() {
 		log.trace( "ResourceLocalTransactionCoordinatorImpl#beforeCompletionCallback" );
 		transactionCoordinatorOwner.beforeTransactionCompletion();
 		synchronizationRegistry.notifySynchronizationsBeforeTransactionCompletion();
 		for ( TransactionObserver observer : observers ) {
 			observer.beforeCompletion();
 		}
 	}
 
 	private void afterCompletionCallback(boolean successful) {
 		log.tracef( "ResourceLocalTransactionCoordinatorImpl#afterCompletionCallback(%s)", successful );
 		final int statusToSend = successful ? Status.STATUS_COMMITTED : Status.STATUS_UNKNOWN;
 		synchronizationRegistry.notifySynchronizationsAfterTransactionCompletion( statusToSend );
 
 		transactionCoordinatorOwner.afterTransactionCompletion( successful, false );
 		for ( TransactionObserver observer : observers ) {
 			observer.afterCompletion( successful, false );
 		}
 		invalidateDelegate();
 	}
 
 	private void invalidateDelegate() {
 		if ( physicalTransactionDelegate == null ) {
 			throw new IllegalStateException( "Physical-transaction delegate not known on attempt to invalidate" );
 		}
 
 		physicalTransactionDelegate.invalidate();
 		physicalTransactionDelegate = null;
 	}
 
 	public void addObserver(TransactionObserver observer) {
 		observers.add( observer );
 	}
 
 	@Override
 	public void removeObserver(TransactionObserver observer) {
 		observers.remove( observer );
 	}
 
 	/**
 	 * The delegate bridging between the local (application facing) transaction and the "physical" notion of a
 	 * transaction via the JDBC Connection.
 	 */
 	public class TransactionDriverControlImpl implements TransactionDriver {
 		private final JdbcResourceTransaction jdbcResourceTransaction;
 		private boolean invalid;
 
 		public TransactionDriverControlImpl(JdbcResourceTransaction jdbcResourceTransaction) {
 			super();
 			this.jdbcResourceTransaction = jdbcResourceTransaction;
 		}
 
 		protected void invalidate() {
 			invalid = true;
 		}
 
 		@Override
 		public void begin() {
 			errorIfInvalid();
 
 			jdbcResourceTransaction.begin();
 			JdbcResourceLocalTransactionCoordinatorImpl.this.afterBeginCallback();
 		}
 
 		protected void errorIfInvalid() {
 			if ( invalid ) {
 				throw new IllegalStateException( "Physical-transaction delegate is no longer valid" );
 			}
 		}
 
 		@Override
 		public void commit() {
 			JdbcResourceLocalTransactionCoordinatorImpl.this.beforeCompletionCallback();
 			jdbcResourceTransaction.commit();
 			JdbcResourceLocalTransactionCoordinatorImpl.this.afterCompletionCallback( true );
 		}
 
 		@Override
 		public void rollback() {
 			jdbcResourceTransaction.rollback();
 			JdbcResourceLocalTransactionCoordinatorImpl.this.afterCompletionCallback( false );
 		}
 
 		@Override
 		public TransactionStatus getStatus() {
 			return jdbcResourceTransaction.getStatus();
 		}
 
 		@Override
 		public void markRollbackOnly() {
 
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/AfterCompletionAction.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/AfterCompletionAction.java
index 4d847a30b2..c1491a5db5 100644
--- a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/AfterCompletionAction.java
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/AfterCompletionAction.java
@@ -1,40 +1,37 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) {DATE}, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.resource.transaction.backend.jta.internal.synchronization;
 
-import javax.persistence.spi.PersistenceUnitTransactionType;
 import java.io.Serializable;
 
-import org.hibernate.engine.spi.SessionImplementor;
-
 /**
  * A pluggable strategy for defining any actions to be performed during
  * {@link javax.transaction.Synchronization#afterCompletion} processing from the the
  * {@link javax.transaction.Synchronization} registered by Hibernate with the underlying JTA platform.
  *
  * @author Steve Ebersole
  */
 public interface AfterCompletionAction extends Serializable {
-	public void doAction(boolean successful);
+	void doAction(boolean successful);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/spi/TransactionStatus.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/spi/TransactionStatus.java
index db4f419927..a9487bb164 100644
--- a/hibernate-core/src/main/java/org/hibernate/resource/transaction/spi/TransactionStatus.java
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/spi/TransactionStatus.java
@@ -1,67 +1,67 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) {DATE}, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.resource.transaction.spi;
 
 /**
  * Enumeration of statuses in which a transaction facade ({@link org.hibernate.Transaction}) might be.
  *
  * @author Andrea Boriero
  */
 public enum TransactionStatus {
 	/**
 	 * The transaction has not yet been begun
 	 */
 	NOT_ACTIVE,
 	/**
 	 * The transaction has been begun, but not yet completed.
 	 */
 	ACTIVE,
 	/**
 	 * The transaction has been competed successfully.
 	 */
 	COMMITTED,
 	/**
 	 * The transaction has been rolled back.
 	 */
 	ROLLED_BACK,
 	/**
 	 * The transaction  has been marked for  rollback only.
 	 */
 	MARKED_ROLLBACK,
 	/**
 	 * The transaction attempted to commit, but failed.
 	 */
 	FAILED_COMMIT,
 	/**
 	 * Status code indicating a transaction that has begun the second
 	 * phase of the two-phase commit protocol, but not yet completed
 	 * this phase
 	 */
 	COMMITTING,
 	/**
 	 *  Status code indicating a transaction that is in the process of
 	 *  rolling back.
 	 */
-	 ROLLING_BACK
+	ROLLING_BACK
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/service/internal/AbstractServiceRegistryImpl.java b/hibernate-core/src/main/java/org/hibernate/service/internal/AbstractServiceRegistryImpl.java
index 23af9653ab..4c57d9eecf 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/internal/AbstractServiceRegistryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/internal/AbstractServiceRegistryImpl.java
@@ -1,420 +1,420 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.internal;
 
 import java.lang.reflect.Method;
 import java.util.HashSet;
 import java.util.List;
 import java.util.ListIterator;
 import java.util.Set;
 
 import org.hibernate.boot.registry.BootstrapServiceRegistry;
 import org.hibernate.cfg.Environment;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.jmx.spi.JmxService;
 import org.hibernate.service.Service;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.service.UnknownServiceException;
 import org.hibernate.service.spi.InjectService;
 import org.hibernate.service.spi.Manageable;
 import org.hibernate.service.spi.ServiceBinding;
 import org.hibernate.service.spi.ServiceException;
 import org.hibernate.service.spi.ServiceInitiator;
 import org.hibernate.service.spi.ServiceRegistryAwareService;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.spi.Startable;
 import org.hibernate.service.spi.Stoppable;
 
 /**
  * Basic implementation of the ServiceRegistry and ServiceRegistryImplementor contracts
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractServiceRegistryImpl
 		implements ServiceRegistryImplementor, ServiceBinding.ServiceLifecycleOwner {
 
 	private static final CoreMessageLogger log = CoreLogging.messageLogger( AbstractServiceRegistryImpl.class );
 
 	public static final String ALLOW_CRAWLING = "hibernate.service.allow_crawling";
 
 	private final ServiceRegistryImplementor parent;
 	private final boolean allowCrawling;
 
 	private final ConcurrentServiceBinding<Class,ServiceBinding> serviceBindingMap = new ConcurrentServiceBinding<Class,ServiceBinding>();
 	private ConcurrentServiceBinding<Class,Class> roleXref;
 
 	// IMPL NOTE : the list used for ordered destruction.  Cannot used map above because we need to
 	// iterate it in reverse order which is only available through ListIterator
 	// assume 20 services for initial sizing
 	private final List<ServiceBinding> serviceBindingList = CollectionHelper.arrayList( 20 );
 
 	private boolean autoCloseRegistry;
 	private Set<ServiceRegistryImplementor> childRegistries;
 
 	@SuppressWarnings( {"UnusedDeclaration"})
 	protected AbstractServiceRegistryImpl() {
 		this( (ServiceRegistryImplementor) null );
 	}
 
 	@SuppressWarnings( {"UnusedDeclaration"})
 	protected AbstractServiceRegistryImpl(boolean autoCloseRegistry) {
 		this( (ServiceRegistryImplementor) null, autoCloseRegistry );
 	}
 
 	protected AbstractServiceRegistryImpl(ServiceRegistryImplementor parent) {
 		this( parent, true );
 	}
 
 	protected AbstractServiceRegistryImpl(
 			ServiceRegistryImplementor parent,
 			boolean autoCloseRegistry) {
 		this.parent = parent;
 		this.allowCrawling = ConfigurationHelper.getBoolean( ALLOW_CRAWLING, Environment.getProperties(), true );
 
 		this.autoCloseRegistry = autoCloseRegistry;
 		this.parent.registerChild( this );
 	}
 
 	public AbstractServiceRegistryImpl(BootstrapServiceRegistry bootstrapServiceRegistry) {
 		this( bootstrapServiceRegistry, true );
 	}
 
 	public AbstractServiceRegistryImpl(
 			BootstrapServiceRegistry bootstrapServiceRegistry,
 			boolean autoCloseRegistry) {
 		if ( ! ServiceRegistryImplementor.class.isInstance( bootstrapServiceRegistry ) ) {
 			throw new IllegalArgumentException( "ServiceRegistry parent needs to implement ServiceRegistryImplementor" );
 		}
 		this.parent = (ServiceRegistryImplementor) bootstrapServiceRegistry;
 		this.allowCrawling = ConfigurationHelper.getBoolean( ALLOW_CRAWLING, Environment.getProperties(), true );
 
 		this.autoCloseRegistry = autoCloseRegistry;
 		this.parent.registerChild( this );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	protected <R extends Service> void createServiceBinding(ServiceInitiator<R> initiator) {
 		final ServiceBinding serviceBinding = new ServiceBinding( this, initiator );
 		serviceBindingMap.put( initiator.getServiceInitiated(), serviceBinding );
 	}
 
 	protected <R extends Service> void createServiceBinding(ProvidedService<R> providedService) {
 		ServiceBinding<R> binding = locateServiceBinding( providedService.getServiceRole(), false );
 		if ( binding == null ) {
 			binding = new ServiceBinding<R>( this, providedService.getServiceRole(), providedService.getService() );
 			serviceBindingMap.put( providedService.getServiceRole(), binding );
 		}
 		registerService( binding, providedService.getService() );
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public ServiceRegistry getParentServiceRegistry() {
 		return parent;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public <R extends Service> ServiceBinding<R> locateServiceBinding(Class<R> serviceRole) {
 		return locateServiceBinding( serviceRole, true );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	protected <R extends Service> ServiceBinding<R> locateServiceBinding(Class<R> serviceRole, boolean checkParent) {
 		ServiceBinding<R> serviceBinding = serviceBindingMap.get( serviceRole );
 		if ( serviceBinding == null && checkParent && parent != null ) {
 			// look in parent
 			serviceBinding = parent.locateServiceBinding( serviceRole );
 		}
 
 		if ( serviceBinding != null ) {
 			return serviceBinding;
 		}
 
 		if ( !allowCrawling ) {
 			return null;
 		}
 
 		// look for a previously resolved alternate registration
 		if ( roleXref != null ) {
 			final Class alternative = roleXref.get( serviceRole );
 			if ( alternative != null ) {
 				return serviceBindingMap.get( alternative );
 			}
 		}
 
 		// perform a crawl looking for an alternate registration
 		for ( ServiceBinding binding : serviceBindingMap.values() ) {
 			if ( serviceRole.isAssignableFrom( binding.getServiceRole() ) ) {
 				// we found an alternate...
 				log.alternateServiceRole( serviceRole.getName(), binding.getServiceRole().getName() );
 				registerAlternate( serviceRole, binding.getServiceRole() );
 				return binding;
 			}
 
 			if ( binding.getService() != null && serviceRole.isInstance( binding.getService() ) ) {
 				// we found an alternate...
 				log.alternateServiceRole( serviceRole.getName(), binding.getServiceRole().getName() );
 				registerAlternate( serviceRole, binding.getServiceRole() );
 				return binding;
 			}
 		}
 
 		return null;
 	}
 
 	private void registerAlternate(Class alternate, Class target) {
 		if ( roleXref == null ) {
 			roleXref = new ConcurrentServiceBinding<Class,Class>();
 		}
 		roleXref.put( alternate, target );
 	}
 
 	@Override
 	public <R extends Service> R getService(Class<R> serviceRole) {
 		final ServiceBinding<R> serviceBinding = locateServiceBinding( serviceRole );
 		if ( serviceBinding == null ) {
 			throw new UnknownServiceException( serviceRole );
 		}
 
 		R service = serviceBinding.getService();
 		if ( service == null ) {
 			service = initializeService( serviceBinding );
 		}
 
 		return service;
 	}
 
 	protected <R extends Service> void registerService(ServiceBinding<R> serviceBinding, R service) {
 		serviceBinding.setService( service );
 		synchronized ( serviceBindingList ) {
 			serviceBindingList.add( serviceBinding );
 		}
 	}
 
 	private <R extends Service> R initializeService(ServiceBinding<R> serviceBinding) {
 		if ( log.isTraceEnabled() ) {
 			log.tracev( "Initializing service [role={0}]", serviceBinding.getServiceRole().getName() );
 		}
 
 		// PHASE 1 : create service
 		R service = createService( serviceBinding );
 		if ( service == null ) {
 			return null;
 		}
 
 		// PHASE 2 : inject service (***potentially recursive***)
 		serviceBinding.getLifecycleOwner().injectDependencies( serviceBinding );
 
 		// PHASE 3 : configure service
 		serviceBinding.getLifecycleOwner().configureService( serviceBinding );
 
 		// PHASE 4 : Start service
 		serviceBinding.getLifecycleOwner().startService( serviceBinding );
 
 		return service;
 	}
 
 	@SuppressWarnings( {"unchecked"})
 	protected <R extends Service> R createService(ServiceBinding<R> serviceBinding) {
 		final ServiceInitiator<R> serviceInitiator = serviceBinding.getServiceInitiator();
 		if ( serviceInitiator == null ) {
 			// this condition should never ever occur
 			throw new UnknownServiceException( serviceBinding.getServiceRole() );
 		}
 
 		try {
 			R service = serviceBinding.getLifecycleOwner().initiateService( serviceInitiator );
 			// IMPL NOTE : the register call here is important to avoid potential stack overflow issues
 			//		from recursive calls through #configureService
 			registerService( serviceBinding, service );
 			return service;
 		}
 		catch ( ServiceException e ) {
 			throw e;
 		}
 		catch ( Exception e ) {
 			throw new ServiceException( "Unable to create requested service [" + serviceBinding.getServiceRole().getName() + "]", e );
 		}
 	}
 
 	@Override
 	public <R extends Service> void injectDependencies(ServiceBinding<R> serviceBinding) {
 		final R service = serviceBinding.getService();
 
 		applyInjections( service );
 
 		if ( ServiceRegistryAwareService.class.isInstance( service ) ) {
 			( (ServiceRegistryAwareService) service ).injectServices( this );
 		}
 	}
 
 	private <R extends Service> void applyInjections(R service) {
 		try {
 			for ( Method method : service.getClass().getMethods() ) {
 				InjectService injectService = method.getAnnotation( InjectService.class );
 				if ( injectService == null ) {
 					continue;
 				}
 
 				processInjection( service, method, injectService );
 			}
 		}
 		catch (NullPointerException e) {
-            log.error( "NPE injecting service deps : " + service.getClass().getName() );
+			log.error( "NPE injecting service deps : " + service.getClass().getName() );
 		}
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	private <T extends Service> void processInjection(T service, Method injectionMethod, InjectService injectService) {
 		if ( injectionMethod.getParameterTypes() == null || injectionMethod.getParameterTypes().length != 1 ) {
 			throw new ServiceDependencyException(
 					"Encountered @InjectService on method with unexpected number of parameters"
 			);
 		}
 
 		Class dependentServiceRole = injectService.serviceRole();
 		if ( dependentServiceRole == null || dependentServiceRole.equals( Void.class ) ) {
 			dependentServiceRole = injectionMethod.getParameterTypes()[0];
 		}
 
 		// todo : because of the use of proxies, this is no longer returning null here...
 
 		final Service dependantService = getService( dependentServiceRole );
 		if ( dependantService == null ) {
 			if ( injectService.required() ) {
 				throw new ServiceDependencyException(
 						"Dependency [" + dependentServiceRole + "] declared by service [" + service + "] not found"
 				);
 			}
 		}
 		else {
 			try {
 				injectionMethod.invoke( service, dependantService );
 			}
 			catch ( Exception e ) {
 				throw new ServiceDependencyException( "Cannot inject dependency service", e );
 			}
 		}
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public <R extends Service> void startService(ServiceBinding<R> serviceBinding) {
 		if ( Startable.class.isInstance( serviceBinding.getService() ) ) {
 			( (Startable) serviceBinding.getService() ).start();
 		}
 
 		if ( Manageable.class.isInstance( serviceBinding.getService() ) ) {
 			getService( JmxService.class ).registerService(
 					(Manageable) serviceBinding.getService(),
 					serviceBinding.getServiceRole()
 			);
 		}
 	}
 
 	private boolean active = true;
 
 	public boolean isActive() {
 		return active;
 	}
 
 	@Override
-    @SuppressWarnings( {"unchecked"})
+	@SuppressWarnings( {"unchecked"})
 	public void destroy() {
 		if ( !active ) {
 			return;
 		}
 
 		active = false;
 		try {
 			synchronized (serviceBindingList) {
 				ListIterator<ServiceBinding> serviceBindingsIterator = serviceBindingList.listIterator(
 						serviceBindingList.size()
 				);
 				while ( serviceBindingsIterator.hasPrevious() ) {
 					final ServiceBinding serviceBinding = serviceBindingsIterator.previous();
 					serviceBinding.getLifecycleOwner().stopService( serviceBinding );
 				}
 				serviceBindingList.clear();
 			}
 			serviceBindingMap.clear();
 		}
 		finally {
 			parent.deRegisterChild( this );
 		}
 	}
 
 	@Override
 	public <R extends Service> void stopService(ServiceBinding<R> binding) {
 		final Service service = binding.getService();
 		if ( Stoppable.class.isInstance( service ) ) {
 			try {
 				( (Stoppable) service ).stop();
 			}
 			catch ( Exception e ) {
 				log.unableToStopService( service.getClass(), e.toString() );
 			}
 		}
 	}
 
 	@Override
 	public void registerChild(ServiceRegistryImplementor child) {
 		if ( childRegistries == null ) {
 			childRegistries = new HashSet<ServiceRegistryImplementor>();
 		}
 		if ( !childRegistries.add( child ) ) {
 			log.warnf(
 					"Child ServiceRegistry [%s] was already registered; this will end badly later...",
 					child
 			);
 		}
 	}
 
 	@Override
 	public void deRegisterChild(ServiceRegistryImplementor child) {
 		if ( childRegistries == null ) {
 			throw new IllegalStateException( "No child ServiceRegistry registrations found" );
 		}
 		childRegistries.remove( child );
 		if ( childRegistries.isEmpty() ) {
 			if ( autoCloseRegistry ) {
 				log.debug(
 						"Implicitly destroying ServiceRegistry on de-registration " +
 								"of all child ServiceRegistries"
 				);
 				destroy();
 			}
 			else {
 				log.debug(
 						"Skipping implicitly destroying ServiceRegistry on de-registration " +
 								"of all child ServiceRegistries"
 				);
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/service/internal/ConcurrentServiceBinding.java b/hibernate-core/src/main/java/org/hibernate/service/internal/ConcurrentServiceBinding.java
index aef9b5eae6..d00b98dfa4 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/internal/ConcurrentServiceBinding.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/internal/ConcurrentServiceBinding.java
@@ -1,221 +1,227 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.internal;
 
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
 
 /**
  * Since Service lookup is a very hot operation and essentially it's a read only
- * data structure, to achieve threadsafety we can use immutability.
+ * data structure, to achieve thread-safety we can use immutability.
  * For our use case we just need reference equality, and the expectation is that a limited
  * number of elements will be contained in this custom collection (<32).
  * So the following structure is functionally equivalent to an Identity based ConcurrentMap,
  * but heavily tuned for reads, at cost of structural reorganization at writes.
  * The implementation is a binary tree basing the comparison order on the identityHashCode
  * of each key.
  *
  * @author Sanne Grinovero
  */
 public class ConcurrentServiceBinding<K,V> {
 
 	@SuppressWarnings({ "unchecked", "rawtypes" })
 	private static final Node EMPTY_LEAF = new Node( new Entry( 0, null, null ), null, null );
 
 	@SuppressWarnings("unchecked")
 	private volatile Node<K,V> treeRoot = EMPTY_LEAF;
 
 	@SuppressWarnings("unchecked")
 	public synchronized void clear() {
 		treeRoot = EMPTY_LEAF;
 	}
 
 	public synchronized void put(final K key, final V value) {
 		final int code = hashKey( key );
 		final Entry<K,V> newEntry = new Entry<K, V>( code, key, value );
 		final ArrayList<Entry<K, V>> list = convertToArrayList( treeRoot, key );
 		list.add( newEntry );
 		Collections.sort( list );
 		final int size = list.size();
 		@SuppressWarnings("unchecked")
 		Entry<K, V>[] array = list.toArray( new Entry[size] );
 		treeRoot = treeFromRange( array, 0, size );
 	}
 
 	private Node<K, V> treeFromRange(final Entry<K, V>[] array, final int minInclusive, final int maxExclusive) {
 		if ( minInclusive == maxExclusive ) {
 			return null;
 		}
 		//find the midpoint, rounding down to avoid the exclusion range:
 		int mid = ( minInclusive + maxExclusive ) / 2;
 		//shift to the right to make sure we won't have left children with the same hash:
 		while ( mid > minInclusive && array[mid].hash == array[mid-1].hash ) {
 			mid--;
 		}
 		return new Node( array[mid], treeFromRange( array, minInclusive, mid ), treeFromRange( array, mid + 1, maxExclusive ) );
 	}
 
 	public V get(final K key) {
 		final int hash = hashKey( key );
 		final Node<K,V> root = treeRoot;
 		return root.get( key, hash );
 	}
 
 	protected int hashKey(final K key) {
 		return System.identityHashCode( key );
 	}
 
 	public Iterable<V> values() {
 		@SuppressWarnings("rawtypes")
 		ArrayList<V> list = new ArrayList();
 		treeRoot.collectAllValuesInto( list );
 		return list;
 	}
 
 	private final ArrayList<Entry<K, V>> convertToArrayList(final Node<K, V> treeRoot, K exceptKey) {
 		@SuppressWarnings("rawtypes")
 		ArrayList<Entry<K, V>> list = new ArrayList();
 		if ( treeRoot != EMPTY_LEAF ) {
 			treeRoot.collectAllEntriesInto( list, exceptKey );
 		}
 		return list;
 	}
 
 	private static final class Entry<K,V> implements Comparable<Entry<K,V>> {
 
 		private final int hash;
 		private final K key;
 		private final V value;
 
 		Entry(int keyHashCode, K key, V value) {
 			this.hash = keyHashCode;
 			this.key = key;
 			this.value = value;
 		}
 
 		@Override
 		public int compareTo(Entry o) {
 			//Sorting by the identity hashcode
 			//Note: this class has a natural ordering that is inconsistent with equals.
 			return ( hash < o.hash ) ? -1 : ( (hash == o.hash) ? 0 : 1 );
 		}
 
 		@Override
+		public int hashCode() {
+			return hash;
+		}
+
+		@Override
+		@SuppressWarnings({"unchecked", "EqualsWhichDoesntCheckParameterClass"})
 		public boolean equals(Object obj) {
 			//A ClassCastException is really not expected here,
 			//as it's an internal private class,
 			//so just let it happen as a form of assertion.
 			final Entry<K,V> other = (Entry<K,V>)obj;
 			//Reference equality on the key only!
 			return other.key == this.key;
 		}
 
 		@Override
 		public String toString() {
 			return "<" + key + ", " + value + ">";
 		}
 	}
 
 	private static final class Node<K,V> {
 
 		private final Entry<K,V> entry;
 		private final Node<K, V> left;
 		private final Node<K, V> right;
 
 		Node(Entry<K,V> entry, Node<K,V> left, Node<K,V> right) {
 			this.entry = entry;
 			this.left = left;
 			this.right = right;
 		}
 
 		public V get(final K key, final int hash) {
 			if ( entry.key == key ) {
 				return entry.value;
 			}
 			//Note that same-hashcode childs need to be on the right
 			//as we don't test for equality, nor want to chase both
 			//branches:
 			else if ( hash < this.entry.hash ) {
 				return left == null ? null : left.get( key, hash );
 			}
 			else {
 				return right == null ? null : right.get( key, hash );
 			}
 		}
 
 		public void collectAllEntriesInto(final List<Entry<K,V>> list, final K exceptKey) {
 			if ( entry != null && exceptKey != entry.key ) {
 				list.add( entry );
 			}
 			if ( left != null ) {
 				left.collectAllEntriesInto( list, exceptKey );
 			}
 			if ( right != null ) {
 				right.collectAllEntriesInto( list, exceptKey );
 			}
 		}
 
 		public void collectAllValuesInto(final List<V> list) {
 			if ( entry != null && entry.value != null ) {
 				list.add( entry.value );
 			}
 			if ( left != null ) {
 				left.collectAllValuesInto( list );
 			}
 			if ( right != null ) {
 				right.collectAllValuesInto( list );
 			}
 		}
 
 		/**
 		 * Helper to visualize the tree via toString
 		 */
 		private void renderToStringBuilder(final StringBuilder sb, final int indent) {
 			sb.append( entry );
 			appendIndented( sb, indent, "L-> ", left );
 			appendIndented( sb, indent, "R-> ", right );
 		}
 
 		private void appendIndented(final StringBuilder sb, final int indent, final String label, Node<K, V> node) {
 			if ( node == null ) {
 				return;
 			}
 			sb.append( "\n" );
 			for ( int i = 0; i < indent; i++ ) {
 				sb.append( "\t" );
 			}
 			sb.append( label );
 			node.renderToStringBuilder( sb, indent + 1 );
 		}
 
 		@Override
 		public String toString() {
 			StringBuilder sb = new StringBuilder();
 			renderToStringBuilder( sb, 0 );
 			return sb.toString();
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/service/internal/SessionFactoryServiceRegistryFactoryImpl.java b/hibernate-core/src/main/java/org/hibernate/service/internal/SessionFactoryServiceRegistryFactoryImpl.java
index 0619877f07..faf8e502ef 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/internal/SessionFactoryServiceRegistryFactoryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/internal/SessionFactoryServiceRegistryFactoryImpl.java
@@ -1,51 +1,50 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.internal;
 
 import org.hibernate.boot.spi.SessionFactoryOptions;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.service.Service;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.spi.SessionFactoryServiceRegistryFactory;
 
 /**
- * Acts as a {@link Service} in the {@link org.hibernate.boot.registry.internal.StandardServiceRegistryImpl} whose function is as a factory for
- * {@link SessionFactoryServiceRegistryImpl} implementations.
+ * Acts as a service in the {@link org.hibernate.boot.registry.internal.StandardServiceRegistryImpl} whose
+ * function is to act as a factory for {@link SessionFactoryServiceRegistryImpl} implementations.
  *
  * @author Steve Ebersole
  */
 public class SessionFactoryServiceRegistryFactoryImpl implements SessionFactoryServiceRegistryFactory {
 	private final ServiceRegistryImplementor theBasicServiceRegistry;
 
 	public SessionFactoryServiceRegistryFactoryImpl(ServiceRegistryImplementor theBasicServiceRegistry) {
 		this.theBasicServiceRegistry = theBasicServiceRegistry;
 	}
 
 	@Override
 	public SessionFactoryServiceRegistryImpl buildServiceRegistry(
 			SessionFactoryImplementor sessionFactory,
 			SessionFactoryOptions options) {
 		return new SessionFactoryServiceRegistryImpl( theBasicServiceRegistry, sessionFactory, options );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/QuerySelect.java b/hibernate-core/src/main/java/org/hibernate/sql/QuerySelect.java
index 45d5db0aff..53df543acc 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/QuerySelect.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/QuerySelect.java
@@ -1,228 +1,233 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
+
 import java.util.HashSet;
 import java.util.Iterator;
 
 import org.hibernate.dialect.Dialect;
 
 /**
  * A translated HQL query
+ *
  * @author Gavin King
  */
 public class QuerySelect {
 	private Dialect dialect;
 	private JoinFragment joins;
 	private StringBuilder select = new StringBuilder();
 	private StringBuilder where = new StringBuilder();
 	private StringBuilder groupBy = new StringBuilder();
 	private StringBuilder orderBy = new StringBuilder();
 	private StringBuilder having = new StringBuilder();
 	private String comment;
 	private boolean distinct;
 
 	private static final HashSet<String> DONT_SPACE_TOKENS = new HashSet<String>();
+
 	static {
 		//dontSpace.add("'");
-		DONT_SPACE_TOKENS.add(".");
-		DONT_SPACE_TOKENS.add("+");
-		DONT_SPACE_TOKENS.add("-");
-		DONT_SPACE_TOKENS.add("/");
-		DONT_SPACE_TOKENS.add("*");
-		DONT_SPACE_TOKENS.add("<");
-		DONT_SPACE_TOKENS.add(">");
-		DONT_SPACE_TOKENS.add("=");
-		DONT_SPACE_TOKENS.add("#");
-		DONT_SPACE_TOKENS.add("~");
-		DONT_SPACE_TOKENS.add("|");
-		DONT_SPACE_TOKENS.add("&");
-		DONT_SPACE_TOKENS.add("<=");
-		DONT_SPACE_TOKENS.add(">=");
-		DONT_SPACE_TOKENS.add("=>");
-		DONT_SPACE_TOKENS.add("=<");
-		DONT_SPACE_TOKENS.add("!=");
-		DONT_SPACE_TOKENS.add("<>");
-		DONT_SPACE_TOKENS.add("!#");
-		DONT_SPACE_TOKENS.add("!~");
-		DONT_SPACE_TOKENS.add("!<");
-		DONT_SPACE_TOKENS.add("!>");
-		DONT_SPACE_TOKENS.add("("); //for MySQL
-		DONT_SPACE_TOKENS.add(")");
+		DONT_SPACE_TOKENS.add( "." );
+		DONT_SPACE_TOKENS.add( "+" );
+		DONT_SPACE_TOKENS.add( "-" );
+		DONT_SPACE_TOKENS.add( "/" );
+		DONT_SPACE_TOKENS.add( "*" );
+		DONT_SPACE_TOKENS.add( "<" );
+		DONT_SPACE_TOKENS.add( ">" );
+		DONT_SPACE_TOKENS.add( "=" );
+		DONT_SPACE_TOKENS.add( "#" );
+		DONT_SPACE_TOKENS.add( "~" );
+		DONT_SPACE_TOKENS.add( "|" );
+		DONT_SPACE_TOKENS.add( "&" );
+		DONT_SPACE_TOKENS.add( "<=" );
+		DONT_SPACE_TOKENS.add( ">=" );
+		DONT_SPACE_TOKENS.add( "=>" );
+		DONT_SPACE_TOKENS.add( "=<" );
+		DONT_SPACE_TOKENS.add( "!=" );
+		DONT_SPACE_TOKENS.add( "<>" );
+		DONT_SPACE_TOKENS.add( "!#" );
+		DONT_SPACE_TOKENS.add( "!~" );
+		DONT_SPACE_TOKENS.add( "!<" );
+		DONT_SPACE_TOKENS.add( "!>" );
+		DONT_SPACE_TOKENS.add( "(" ); //for MySQL
+		DONT_SPACE_TOKENS.add( ")" );
 	}
 
 	public QuerySelect(Dialect dialect) {
 		this.dialect = dialect;
-		joins = new QueryJoinFragment(dialect, false);
+		joins = new QueryJoinFragment( dialect, false );
 	}
 
 	public JoinFragment getJoinFragment() {
 		return joins;
 	}
 
 	public void addSelectFragmentString(String fragment) {
-		if ( fragment.length()>0 && fragment.charAt(0)==',' ) {
-			fragment = fragment.substring(1);
+		if ( fragment.length() > 0 && fragment.charAt( 0 ) == ',' ) {
+			fragment = fragment.substring( 1 );
 		}
 		fragment = fragment.trim();
-		if ( fragment.length()>0 ) {
-			if ( select.length()>0 ) {
-				select.append(", ");
+		if ( fragment.length() > 0 ) {
+			if ( select.length() > 0 ) {
+				select.append( ", " );
 			}
-			select.append(fragment);
+			select.append( fragment );
 		}
 	}
 
 	public void addSelectColumn(String columnName, String alias) {
-		addSelectFragmentString(columnName + ' ' + alias);
+		addSelectFragmentString( columnName + ' ' + alias );
 	}
 
 	public void setDistinct(boolean distinct) {
 		this.distinct = distinct;
 	}
 
 	public void setWhereTokens(Iterator tokens) {
 		//if ( conjunctiveWhere.length()>0 ) conjunctiveWhere.append(" and ");
-		appendTokens(where, tokens);
+		appendTokens( where, tokens );
 	}
 
 	public void prependWhereConditions(String conditions) {
-		if (where.length() > 0) {
-			where.insert(0, conditions + " and ");
+		if ( where.length() > 0 ) {
+			where.insert( 0, conditions + " and " );
 		}
 		else {
-			where.append(conditions);
+			where.append( conditions );
 		}
 	}
 
 	public void setGroupByTokens(Iterator tokens) {
 		//if ( groupBy.length()>0 ) groupBy.append(" and ");
-		appendTokens(groupBy, tokens);
+		appendTokens( groupBy, tokens );
 	}
 
 	public void setOrderByTokens(Iterator tokens) {
 		//if ( orderBy.length()>0 ) orderBy.append(" and ");
-		appendTokens(orderBy, tokens);
+		appendTokens( orderBy, tokens );
 	}
 
 	public void setHavingTokens(Iterator tokens) {
 		//if ( having.length()>0 ) having.append(" and ");
-		appendTokens(having, tokens);
+		appendTokens( having, tokens );
 	}
 
 	public void addOrderBy(String orderByString) {
 		if ( orderBy.length() > 0 ) {
-			orderBy.append(", ");
+			orderBy.append( ", " );
 		}
-		orderBy.append(orderByString);
+		orderBy.append( orderByString );
 	}
 
 	public String toQueryString() {
-		StringBuilder buf = new StringBuilder(50);
-		if (comment!=null) {
-			buf.append("/* ").append(comment).append(" */ ");
+		StringBuilder buf = new StringBuilder( 50 );
+		if ( comment != null ) {
+			buf.append( "/* " ).append( comment ).append( " */ " );
 		}
-		buf.append("select ");
-		if (distinct) {
-			buf.append("distinct ");
+		buf.append( "select " );
+		if ( distinct ) {
+			buf.append( "distinct " );
 		}
 		String from = joins.toFromFragmentString();
-		if ( from.startsWith(",") ) {
-			from = from.substring(1);
+		if ( from.startsWith( "," ) ) {
+			from = from.substring( 1 );
 		}
-		else if ( from.startsWith(" inner join") ){
-			from = from.substring(11);
+		else if ( from.startsWith( " inner join" ) ) {
+			from = from.substring( 11 );
 		}
 
 		buf.append( select.toString() )
-			.append(" from")
-			.append(from);
+				.append( " from" )
+				.append( from );
 
 		String outerJoinsAfterWhere = joins.toWhereFragmentString().trim();
 		String whereConditions = where.toString().trim();
 		boolean hasOuterJoinsAfterWhere = outerJoinsAfterWhere.length() > 0;
 		boolean hasWhereConditions = whereConditions.length() > 0;
-		if (hasOuterJoinsAfterWhere || hasWhereConditions) {
-			buf.append(" where ");
-			if (hasOuterJoinsAfterWhere) {
-				buf.append( outerJoinsAfterWhere.substring(4) );
+		if ( hasOuterJoinsAfterWhere || hasWhereConditions ) {
+			buf.append( " where " );
+			if ( hasOuterJoinsAfterWhere ) {
+				buf.append( outerJoinsAfterWhere.substring( 4 ) );
 			}
-			if (hasWhereConditions) {
-				if (hasOuterJoinsAfterWhere) {
-					buf.append(" and (");
+			if ( hasWhereConditions ) {
+				if ( hasOuterJoinsAfterWhere ) {
+					buf.append( " and (" );
 				}
-				buf.append(whereConditions);
-				if (hasOuterJoinsAfterWhere) {
-					buf.append(")");
+				buf.append( whereConditions );
+				if ( hasOuterJoinsAfterWhere ) {
+					buf.append( ")" );
 				}
 			}
 		}
 
 		if ( groupBy.length() > 0 ) {
-			buf.append(" group by ").append( groupBy.toString() );
+			buf.append( " group by " ).append( groupBy.toString() );
 		}
 		if ( having.length() > 0 ) {
-			buf.append(" having ").append( having.toString() );
+			buf.append( " having " ).append( having.toString() );
 		}
 		if ( orderBy.length() > 0 ) {
-			buf.append(" order by ").append( orderBy.toString() );
+			buf.append( " order by " ).append( orderBy.toString() );
 		}
 
 		return dialect.transformSelectString( buf.toString() );
 	}
 
 	private static void appendTokens(StringBuilder buf, Iterator iter) {
-		boolean lastSpaceable=true;
-		boolean lastQuoted=false;
+		boolean lastSpaceable = true;
+		boolean lastQuoted = false;
 		while ( iter.hasNext() ) {
 			String token = (String) iter.next();
-			boolean spaceable = !DONT_SPACE_TOKENS.contains(token);
-			boolean quoted = token.startsWith("'");
-			if (spaceable && lastSpaceable) {
-				if ( !quoted || !lastQuoted ) buf.append(' ');
+			boolean spaceable = !DONT_SPACE_TOKENS.contains( token );
+			boolean quoted = token.startsWith( "'" );
+			if ( spaceable && lastSpaceable ) {
+				if ( !quoted || !lastQuoted ) {
+					buf.append( ' ' );
+				}
 			}
 			lastSpaceable = spaceable;
-			buf.append(token);
-			lastQuoted = token.endsWith("'");
+			buf.append( token );
+			lastQuoted = token.endsWith( "'" );
 		}
 	}
 
 	public void setComment(String comment) {
 		this.comment = comment;
 	}
 
 	public QuerySelect copy() {
-		QuerySelect copy = new QuerySelect(dialect);
+		QuerySelect copy = new QuerySelect( dialect );
 		copy.joins = this.joins.copy();
 		copy.select.append( this.select.toString() );
 		copy.where.append( this.where.toString() );
 		copy.groupBy.append( this.groupBy.toString() );
 		copy.orderBy.append( this.orderBy.toString() );
 		copy.having.append( this.having.toString() );
 		copy.comment = this.comment;
 		copy.distinct = this.distinct;
 		return copy;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/SelectFragment.java b/hibernate-core/src/main/java/org/hibernate/sql/SelectFragment.java
index db764b787d..9085ac3eb2 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/SelectFragment.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/SelectFragment.java
@@ -1,177 +1,179 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
 
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * A fragment of an SQL <tt>SELECT</tt> clause
  *
  * @author Gavin King
  */
 public class SelectFragment {
 	private String suffix;
-	private List columns = new ArrayList();
+	private List<String> columns = new ArrayList<String>();
 	//private List aliases = new ArrayList();
-	private List columnAliases = new ArrayList();
+	private List<String> columnAliases = new ArrayList<String>();
 	private String extraSelectList;
 	private String[] usedAliases;
 
 	public SelectFragment() {}
 
-	public List getColumns() {
+	public List<String> getColumns() {
 		return columns;
 	}
 
 	public String getExtraSelectList() {
 		return extraSelectList;
 	}
 
 	public SelectFragment setUsedAliases(String[] aliases) {
 		usedAliases = aliases;
 		return this;
 	}
 
 	public SelectFragment setExtraSelectList(String extraSelectList) {
 		this.extraSelectList = extraSelectList;
 		return this;
 	}
 
 	public SelectFragment setExtraSelectList(CaseFragment caseFragment, String fragmentAlias) {
 		setExtraSelectList( caseFragment.setReturnColumnName(fragmentAlias, suffix).toFragmentString() );
 		return this;
 	}
 
 	public SelectFragment setSuffix(String suffix) {
 		this.suffix = suffix;
 		return this;
 	}
 
 	public SelectFragment addColumn(String columnName) {
 		addColumn(null, columnName);
 		return this;
 	}
 
 	public SelectFragment addColumns(String[] columnNames) {
 		for ( String columnName : columnNames ) {
 			addColumn( columnName );
 		}
 		return this;
 	}
 
 	public SelectFragment addColumn(String tableAlias, String columnName) {
 		return addColumn(tableAlias, columnName, columnName);
 	}
 
 	public SelectFragment addColumn(String tableAlias, String columnName, String columnAlias) {
 		columns.add( StringHelper.qualify(tableAlias, columnName) );
 		//columns.add(columnName);
 		//aliases.add(tableAlias);
 		columnAliases.add(columnAlias);
 		return this;
 	}
 
 	public SelectFragment addColumns(String tableAlias, String[] columnNames) {
 		for ( String columnName : columnNames ) {
 			addColumn( tableAlias, columnName );
 		}
 		return this;
 	}
 
 	public SelectFragment addColumns(String tableAlias, String[] columnNames, String[] columnAliases) {
 		for (int i=0; i<columnNames.length; i++) {
 			if ( columnNames[i]!=null ) {
 				addColumn( tableAlias, columnNames[i], columnAliases[i] );
 			}
 		}
 		return this;
 	}
 
 	public SelectFragment addFormulas(String tableAlias, String[] formulas, String[] formulaAliases) {
 		for ( int i=0; i<formulas.length; i++ ) {
-			if ( formulas[i]!=null ) addFormula( tableAlias, formulas[i], formulaAliases[i] );
+			if ( formulas[i]!=null ) {
+				addFormula( tableAlias, formulas[i], formulaAliases[i] );
+			}
 		}
 		return this;
 	}
 
 	public SelectFragment addFormula(String tableAlias, String formula, String formulaAlias) {
 		columns.add( StringHelper.replace( formula, Template.TEMPLATE, tableAlias ) );
 		columnAliases.add(formulaAlias);
 		return this;
 	}
 
 	public SelectFragment addColumnTemplate(String tableAlias, String columnTemplate, String columnAlias) {
 		// In this context, there's no difference between a column template and a formula.
 		return addFormula( tableAlias, columnTemplate, columnAlias );
 	}
 
 	public SelectFragment addColumnTemplates(String tableAlias, String[] columnTemplates, String[] columnAliases) {
 		// In this context, there's no difference between a column template and a formula.
 		return addFormulas( tableAlias, columnTemplates, columnAliases );
 	}
 
 	public String toFragmentString() {
 		StringBuilder buf = new StringBuilder( columns.size() * 10 );
-		Iterator iter = columns.iterator();
-		Iterator columnAliasIter = columnAliases.iterator();
+		Iterator<String> iter = columns.iterator();
+		Iterator<String> columnAliasIter = columnAliases.iterator();
 		//HashMap columnsUnique = new HashMap();
-		HashSet columnsUnique = new HashSet();
+		HashSet<String> columnsUnique = new HashSet<String>();
 		if (usedAliases!=null) {
 			columnsUnique.addAll( Arrays.asList(usedAliases) );
 		}
 		while ( iter.hasNext() ) {
-			String column = (String) iter.next();
-			String columnAlias = (String) columnAliasIter.next();
+			String column = iter.next();
+			String columnAlias = columnAliasIter.next();
 			//TODO: eventually put this back in, once we think all is fixed
 			//Object otherAlias = columnsUnique.put(qualifiedColumn, columnAlias);
 			/*if ( otherAlias!=null && !columnAlias.equals(otherAlias) ) {
 				throw new AssertionFailure("bug in Hibernate SQL alias generation");
 			}*/
 			if ( columnsUnique.add(columnAlias) ) {
 				buf.append(", ")
 					.append(column)
 					.append(" as ");
 				if (suffix==null) {
 					buf.append(columnAlias);
 				}
 				else {
 					buf.append( new Alias(suffix).toAliasString(columnAlias) );
 				}
 			}
 		}
 		if (extraSelectList!=null) {
 			buf.append(", ")
 				.append(extraSelectList);
 		}
 		return buf.toString();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/SimpleSelect.java b/hibernate-core/src/main/java/org/hibernate/sql/SimpleSelect.java
index bd81b008d8..9ba887e52e 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/SimpleSelect.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/SimpleSelect.java
@@ -1,224 +1,228 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
-import org.hibernate.LockMode;
-import org.hibernate.LockOptions;
-import org.hibernate.dialect.Dialect;
 
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
+import org.hibernate.LockMode;
+import org.hibernate.LockOptions;
+import org.hibernate.dialect.Dialect;
+
 /**
  * An SQL <tt>SELECT</tt> statement with no table joins
  *
  * @author Gavin King
  */
 public class SimpleSelect {
 
 	public SimpleSelect(Dialect dialect) {
 		this.dialect = dialect;
 	}
 
 	//private static final Alias DEFAULT_ALIAS = new Alias(10, null);
 
 	private String tableName;
 	private String orderBy;
 	private Dialect dialect;
-	private LockOptions lockOptions = new LockOptions( LockMode.READ);
+	private LockOptions lockOptions = new LockOptions( LockMode.READ );
 	private String comment;
 
-	private List columns = new ArrayList();
-	private Map aliases = new HashMap();
-	private List whereTokens = new ArrayList();
+	private List<String> columns = new ArrayList<String>();
+	private Map<String, String> aliases = new HashMap<String, String>();
+	private List<String> whereTokens = new ArrayList<String>();
 
 	public SimpleSelect addColumns(String[] columnNames, String[] columnAliases) {
-		for ( int i=0; i<columnNames.length; i++ ) {
-			if ( columnNames[i]!=null  ) {
+		for ( int i = 0; i < columnNames.length; i++ ) {
+			if ( columnNames[i] != null ) {
 				addColumn( columnNames[i], columnAliases[i] );
 			}
 		}
 		return this;
 	}
 
 	public SimpleSelect addColumns(String[] columns, String[] aliases, boolean[] ignore) {
-		for ( int i=0; i<ignore.length; i++ ) {
-			if ( !ignore[i] && columns[i]!=null ) {
+		for ( int i = 0; i < ignore.length; i++ ) {
+			if ( !ignore[i] && columns[i] != null ) {
 				addColumn( columns[i], aliases[i] );
 			}
 		}
 		return this;
 	}
 
 	public SimpleSelect addColumns(String[] columnNames) {
 		for ( String columnName : columnNames ) {
 			if ( columnName != null ) {
 				addColumn( columnName );
 			}
 		}
 		return this;
 	}
+
 	public SimpleSelect addColumn(String columnName) {
-		columns.add(columnName);
+		columns.add( columnName );
 		//aliases.put( columnName, DEFAULT_ALIAS.toAliasString(columnName) );
 		return this;
 	}
 
 	public SimpleSelect addColumn(String columnName, String alias) {
-		columns.add(columnName);
-		aliases.put(columnName, alias);
+		columns.add( columnName );
+		aliases.put( columnName, alias );
 		return this;
 	}
 
 	public SimpleSelect setTableName(String tableName) {
 		this.tableName = tableName;
 		return this;
 	}
 
-	public SimpleSelect setLockOptions( LockOptions lockOptions ) {
-	   LockOptions.copy(lockOptions, this.lockOptions);
+	public SimpleSelect setLockOptions(LockOptions lockOptions) {
+		LockOptions.copy( lockOptions, this.lockOptions );
 		return this;
 	}
 
 	public SimpleSelect setLockMode(LockMode lockMode) {
 		this.lockOptions.setLockMode( lockMode );
 		return this;
 	}
 
 	public SimpleSelect addWhereToken(String token) {
-		whereTokens.add(token);
+		whereTokens.add( token );
 		return this;
 	}
-	
+
 	private void and() {
-		if ( whereTokens.size()>0 ) {
-			whereTokens.add("and");
+		if ( whereTokens.size() > 0 ) {
+			whereTokens.add( "and" );
 		}
 	}
 
 	public SimpleSelect addCondition(String lhs, String op, String rhs) {
 		and();
 		whereTokens.add( lhs + ' ' + op + ' ' + rhs );
 		return this;
 	}
 
 	public SimpleSelect addCondition(String lhs, String condition) {
 		and();
 		whereTokens.add( lhs + ' ' + condition );
 		return this;
 	}
 
 	public SimpleSelect addCondition(String[] lhs, String op, String[] rhs) {
-		for ( int i=0; i<lhs.length; i++ ) {
+		for ( int i = 0; i < lhs.length; i++ ) {
 			addCondition( lhs[i], op, rhs[i] );
 		}
 		return this;
 	}
 
 	public SimpleSelect addCondition(String[] lhs, String condition) {
 		for ( String lh : lhs ) {
 			if ( lh != null ) {
 				addCondition( lh, condition );
 			}
 		}
 		return this;
 	}
 
 	public String toStatementString() {
-		StringBuilder buf = new StringBuilder( 
-				columns.size()*10 + 
-				tableName.length() + 
-				whereTokens.size() * 10 + 
-				10 
+		StringBuilder buf = new StringBuilder(
+				columns.size() * 10 +
+						tableName.length() +
+						whereTokens.size() * 10 +
+						10
 		);
-		
-		if ( comment!=null ) {
-			buf.append("/* ").append(comment).append(" */ ");
+
+		if ( comment != null ) {
+			buf.append( "/* " ).append( comment ).append( " */ " );
 		}
-		
-		buf.append("select ");
-		Set uniqueColumns = new HashSet();
-		Iterator iter = columns.iterator();
+
+		buf.append( "select " );
+		Set<String> uniqueColumns = new HashSet<String>();
+		Iterator<String> iter = columns.iterator();
 		boolean appendComma = false;
 		while ( iter.hasNext() ) {
-			String col = (String) iter.next();
-			String alias = (String) aliases.get(col);
-			if ( uniqueColumns.add(alias==null ? col : alias) ) {
-				if (appendComma) buf.append(", ");
-				buf.append(col);
-				if ( alias!=null && !alias.equals(col) ) {
-					buf.append(" as ")
-						.append(alias);
+			String col = iter.next();
+			String alias = aliases.get( col );
+			if ( uniqueColumns.add( alias == null ? col : alias ) ) {
+				if ( appendComma ) {
+					buf.append( ", " );
+				}
+				buf.append( col );
+				if ( alias != null && !alias.equals( col ) ) {
+					buf.append( " as " )
+							.append( alias );
 				}
 				appendComma = true;
 			}
 		}
-		
-		buf.append(" from ")
-			.append( dialect.appendLockHint(lockOptions, tableName) );
-		
+
+		buf.append( " from " )
+				.append( dialect.appendLockHint( lockOptions, tableName ) );
+
 		if ( whereTokens.size() > 0 ) {
-			buf.append(" where ")
-				.append( toWhereClause() );
+			buf.append( " where " )
+					.append( toWhereClause() );
 		}
-		
-		if (orderBy!=null) {
-			buf.append(orderBy);
+
+		if ( orderBy != null ) {
+			buf.append( orderBy );
 		}
-		
-		if (lockOptions!=null) {
-			buf.append( dialect.getForUpdateString(lockOptions) );
+
+		if ( lockOptions != null ) {
+			buf.append( dialect.getForUpdateString( lockOptions ) );
 		}
 
 		return dialect.transformSelectString( buf.toString() );
 	}
 
 	public String toWhereClause() {
 		StringBuilder buf = new StringBuilder( whereTokens.size() * 5 );
-		Iterator iter = whereTokens.iterator();
+		Iterator<String> iter = whereTokens.iterator();
 		while ( iter.hasNext() ) {
 			buf.append( iter.next() );
 			if ( iter.hasNext() ) {
-				buf.append(' ');
+				buf.append( ' ' );
 			}
 		}
 		return buf.toString();
 	}
 
 	public SimpleSelect setOrderBy(String orderBy) {
 		this.orderBy = orderBy;
 		return this;
 	}
 
 	public SimpleSelect setComment(String comment) {
 		this.comment = comment;
 		return this;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/Template.java b/hibernate-core/src/main/java/org/hibernate/sql/Template.java
index 060c72f0e2..b0395789d5 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/Template.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/Template.java
@@ -1,767 +1,767 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
 
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Locale;
 import java.util.Set;
 import java.util.StringTokenizer;
 
 import org.hibernate.HibernateException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.sql.ordering.antlr.ColumnMapper;
 import org.hibernate.sql.ordering.antlr.OrderByAliasResolver;
 import org.hibernate.sql.ordering.antlr.OrderByFragmentTranslator;
 import org.hibernate.sql.ordering.antlr.OrderByTranslation;
 import org.hibernate.sql.ordering.antlr.SqlValueReference;
 import org.hibernate.sql.ordering.antlr.TranslationContext;
 
 /**
  * Parses SQL fragments specified in mapping documents
  *
  * @author Gavin King
  */
 public final class Template {
 
 	private static final Set<String> KEYWORDS = new HashSet<String>();
 	private static final Set<String> BEFORE_TABLE_KEYWORDS = new HashSet<String>();
 	private static final Set<String> FUNCTION_KEYWORDS = new HashSet<String>();
 	static {
 		KEYWORDS.add("and");
 		KEYWORDS.add("or");
 		KEYWORDS.add("not");
 		KEYWORDS.add("like");
 		KEYWORDS.add("escape");
 		KEYWORDS.add("is");
 		KEYWORDS.add("in");
 		KEYWORDS.add("between");
 		KEYWORDS.add("null");
 		KEYWORDS.add("select");
 		KEYWORDS.add("distinct");
 		KEYWORDS.add("from");
 		KEYWORDS.add("join");
 		KEYWORDS.add("inner");
 		KEYWORDS.add("outer");
 		KEYWORDS.add("left");
 		KEYWORDS.add("right");
 		KEYWORDS.add("on");
 		KEYWORDS.add("where");
 		KEYWORDS.add("having");
 		KEYWORDS.add("group");
 		KEYWORDS.add("order");
 		KEYWORDS.add("by");
 		KEYWORDS.add("desc");
 		KEYWORDS.add("asc");
 		KEYWORDS.add("limit");
 		KEYWORDS.add("any");
 		KEYWORDS.add("some");
 		KEYWORDS.add("exists");
 		KEYWORDS.add("all");
 		KEYWORDS.add("union");
 		KEYWORDS.add("minus");
 
 		BEFORE_TABLE_KEYWORDS.add("from");
 		BEFORE_TABLE_KEYWORDS.add("join");
 
 		FUNCTION_KEYWORDS.add("as");
 		FUNCTION_KEYWORDS.add("leading");
 		FUNCTION_KEYWORDS.add("trailing");
 		FUNCTION_KEYWORDS.add("from");
 		FUNCTION_KEYWORDS.add("case");
 		FUNCTION_KEYWORDS.add("when");
 		FUNCTION_KEYWORDS.add("then");
 		FUNCTION_KEYWORDS.add("else");
 		FUNCTION_KEYWORDS.add("end");
 	}
 
 	public static final String TEMPLATE = "$PlaceHolder$";
 
 	private Template() {}
 
 	public static String renderWhereStringTemplate(String sqlWhereString, Dialect dialect, SQLFunctionRegistry functionRegistry) {
 		return renderWhereStringTemplate(sqlWhereString, TEMPLATE, dialect, functionRegistry);
 	}
 
 	/**
 	 * Same functionality as {@link #renderWhereStringTemplate(String, String, Dialect, SQLFunctionRegistry)},
 	 * except that a SQLFunctionRegistry is not provided (i.e., only the dialect-defined functions are
 	 * considered).  This is only intended for use by the annotations project until the
 	 * many-to-many/map-key-from-target-table feature is pulled into core.
 	 *
 	 * @deprecated Only intended for annotations usage; use {@link #renderWhereStringTemplate(String, String, Dialect, SQLFunctionRegistry)} instead
 	 */
 	@Deprecated
-    @SuppressWarnings({ "JavaDoc" })
+	@SuppressWarnings({ "JavaDoc" })
 	public static String renderWhereStringTemplate(String sqlWhereString, String placeholder, Dialect dialect) {
 		return renderWhereStringTemplate(
 				sqlWhereString,
 				placeholder,
 				dialect,
 				new SQLFunctionRegistry( dialect, java.util.Collections.<String, SQLFunction>emptyMap() )
 		);
 	}
 
 	/**
 	 * Takes the where condition provided in the mapping attribute and interpolates the alias.
 	 * Handles sub-selects, quoted identifiers, quoted strings, expressions, SQL functions,
 	 * named parameters.
 	 *
 	 * @param sqlWhereString The string into which to interpolate the placeholder value
 	 * @param placeholder The value to be interpolated into the the sqlWhereString
 	 * @param dialect The dialect to apply
 	 * @param functionRegistry The registry of all sql functions
 	 * @return The rendered sql fragment
 	 */
 	public static String renderWhereStringTemplate(String sqlWhereString, String placeholder, Dialect dialect, SQLFunctionRegistry functionRegistry ) {
 
 		// IMPL NOTE : The basic process here is to tokenize the incoming string and to iterate over each token
 		//		in turn.  As we process each token, we set a series of flags used to indicate the type of context in
 		// 		which the tokens occur.  Depending on the state of those flags we decide whether we need to qualify
 		//		identifier references.
 
 		String symbols = new StringBuilder()
 				.append( "=><!+-*/()',|&`" )
 				.append( StringHelper.WHITESPACE )
 				.append( dialect.openQuote() )
 				.append( dialect.closeQuote() )
 				.toString();
 		StringTokenizer tokens = new StringTokenizer( sqlWhereString, symbols, true );
 		StringBuilder result = new StringBuilder();
 
 		boolean quoted = false;
 		boolean quotedIdentifier = false;
 		boolean beforeTable = false;
 		boolean inFromClause = false;
 		boolean afterFromTable = false;
 
 		boolean hasMore = tokens.hasMoreTokens();
 		String nextToken = hasMore ? tokens.nextToken() : null;
 		while ( hasMore ) {
 			String token = nextToken;
 			String lcToken = token.toLowerCase(Locale.ROOT);
 			hasMore = tokens.hasMoreTokens();
 			nextToken = hasMore ? tokens.nextToken() : null;
 
 			boolean isQuoteCharacter = false;
 
 			if ( !quotedIdentifier && "'".equals(token) ) {
 				quoted = !quoted;
 				isQuoteCharacter = true;
 			}
 
 			if ( !quoted ) {
 				boolean isOpenQuote;
 				if ( "`".equals(token) ) {
 					isOpenQuote = !quotedIdentifier;
 					token = lcToken = isOpenQuote
 							? Character.toString( dialect.openQuote() )
 							: Character.toString( dialect.closeQuote() );
 					quotedIdentifier = isOpenQuote;
 					isQuoteCharacter = true;
 				}
 				else if ( !quotedIdentifier && ( dialect.openQuote()==token.charAt(0) ) ) {
 					isOpenQuote = true;
 					quotedIdentifier = true;
 					isQuoteCharacter = true;
 				}
 				else if ( quotedIdentifier && ( dialect.closeQuote()==token.charAt(0) ) ) {
 					quotedIdentifier = false;
 					isQuoteCharacter = true;
 					isOpenQuote = false;
 				}
 				else {
 					isOpenQuote = false;
 				}
 
 				if ( isOpenQuote ) {
 					result.append( placeholder ).append( '.' );
 				}
 			}
 
 			// Special processing for ANSI SQL EXTRACT function
 			if ( "extract".equals( lcToken ) && "(".equals( nextToken ) ) {
 				final String field = extractUntil( tokens, "from" );
 				final String source = renderWhereStringTemplate(
 						extractUntil( tokens, ")" ),
 						placeholder,
 						dialect,
 						functionRegistry
 				);
 				result.append( "extract(" ).append( field ).append( " from " ).append( source ).append( ')' );
 
 				hasMore = tokens.hasMoreTokens();
 				nextToken = hasMore ? tokens.nextToken() : null;
 
 				continue;
 			}
 
 			// Special processing for ANSI SQL TRIM function
 			if ( "trim".equals( lcToken ) && "(".equals( nextToken ) ) {
 				List<String> operands = new ArrayList<String>();
 				StringBuilder builder = new StringBuilder();
 
 				boolean hasMoreOperands = true;
 				String operandToken = tokens.nextToken();
 				boolean quotedOperand = false;
 				while ( hasMoreOperands ) {
 					final boolean isQuote = "'".equals( operandToken );
 					if ( isQuote ) {
 						quotedOperand = !quotedOperand;
 						if ( !quotedOperand ) {
 							operands.add( builder.append( '\'' ).toString() );
 							builder.setLength( 0 );
 						}
 						else {
 							builder.append( '\'' );
 						}
 					}
 					else if ( quotedOperand ) {
 						builder.append( operandToken );
 					}
 					else if ( operandToken.length() == 1 && Character.isWhitespace( operandToken.charAt( 0 ) ) ) {
 						// do nothing
 					}
 					else {
 						operands.add( operandToken );
 					}
 					operandToken = tokens.nextToken();
 					hasMoreOperands = tokens.hasMoreTokens() && ! ")".equals( operandToken );
 				}
 
 				TrimOperands trimOperands = new TrimOperands( operands );
 				result.append( "trim(" );
 				if ( trimOperands.trimSpec != null ) {
 					result.append( trimOperands.trimSpec ).append( ' ' );
 				}
 				if ( trimOperands.trimChar != null ) {
 					if ( trimOperands.trimChar.startsWith( "'" ) && trimOperands.trimChar.endsWith( "'" ) ) {
 						result.append( trimOperands.trimChar );
 					}
 					else {
 						result.append(
 								renderWhereStringTemplate( trimOperands.trimSpec, placeholder, dialect, functionRegistry )
 						);
 					}
 					result.append( ' ' );
 				}
 				if ( trimOperands.from != null ) {
 					result.append( trimOperands.from ).append( ' ' );
 				}
 				else if ( trimOperands.trimSpec != null || trimOperands.trimChar != null ) {
 					// I think ANSI SQL says that the 'from' is not optional if either trim-spec or trim-char are specified
 					result.append( "from " );
 				}
 
 				result.append( renderWhereStringTemplate( trimOperands.trimSource, placeholder, dialect, functionRegistry ) )
 						.append( ')' );
 
 				hasMore = tokens.hasMoreTokens();
 				nextToken = hasMore ? tokens.nextToken() : null;
 
 				continue;
 			}
 
 			boolean quotedOrWhitespace = quoted || quotedIdentifier || isQuoteCharacter
 					|| Character.isWhitespace( token.charAt(0) );
 
 			if ( quotedOrWhitespace ) {
 				result.append( token );
 			}
 			else if ( beforeTable ) {
 				result.append( token );
 				beforeTable = false;
 				afterFromTable = true;
 			}
 			else if ( afterFromTable ) {
 				if ( !"as".equals(lcToken) ) {
 					afterFromTable = false;
 				}
 				result.append(token);
 			}
 			else if ( isNamedParameter(token) ) {
 				result.append(token);
 			}
 			else if ( isIdentifier(token)
 					&& !isFunctionOrKeyword(lcToken, nextToken, dialect , functionRegistry) ) {
 				result.append(placeholder)
 						.append('.')
 						.append( dialect.quote(token) );
 			}
 			else {
 				if ( BEFORE_TABLE_KEYWORDS.contains(lcToken) ) {
 					beforeTable = true;
 					inFromClause = true;
 				}
 				else if ( inFromClause && ",".equals(lcToken) ) {
 					beforeTable = true;
 				}
 				result.append(token);
 			}
 
 			//Yuck:
 			if ( inFromClause
 					&& KEYWORDS.contains( lcToken ) //"as" is not in KEYWORDS
 					&& !BEFORE_TABLE_KEYWORDS.contains( lcToken ) ) {
 				inFromClause = false;
 			}
 		}
 
 		return result.toString();
 	}
 
 //	/**
 //	 * Takes the where condition provided in the mapping attribute and interpolates the alias.
 //	 * Handles sub-selects, quoted identifiers, quoted strings, expressions, SQL functions,
 //	 * named parameters.
 //	 *
 //	 * @param sqlWhereString The string into which to interpolate the placeholder value
 //	 * @param placeholder The value to be interpolated into the the sqlWhereString
 //	 * @param dialect The dialect to apply
 //	 * @param functionRegistry The registry of all sql functions
 //	 *
 //	 * @return The rendered sql fragment
 //	 */
 //	public static String renderWhereStringTemplate(
 //			String sqlWhereString,
 //			String placeholder,
 //			Dialect dialect,
 //			SQLFunctionRegistry functionRegistry) {
 //
 //		// IMPL NOTE : The basic process here is to tokenize the incoming string and to iterate over each token
 //		//		in turn.  As we process each token, we set a series of flags used to indicate the type of context in
 //		// 		which the tokens occur.  Depending on the state of those flags we decide whether we need to qualify
 //		//		identifier references.
 //
 //		final String dialectOpenQuote = Character.toString( dialect.openQuote() );
 //		final String dialectCloseQuote = Character.toString( dialect.closeQuote() );
 //
 //		String symbols = new StringBuilder()
 //				.append( "=><!+-*/()',|&`" )
 //				.append( StringHelper.WHITESPACE )
 //				.append( dialect.openQuote() )
 //				.append( dialect.closeQuote() )
 //				.toString();
 //		StringTokenizer tokens = new StringTokenizer( sqlWhereString, symbols, true );
 //		ProcessingState state = new ProcessingState();
 //
 //		StringBuilder quotedBuffer = new StringBuilder();
 //		StringBuilder result = new StringBuilder();
 //
 //		boolean hasMore = tokens.hasMoreTokens();
 //		String nextToken = hasMore ? tokens.nextToken() : null;
 //		while ( hasMore ) {
 //			String token = nextToken;
 //			String lcToken = token.toLowerCase(Locale.ROOT);
 //			hasMore = tokens.hasMoreTokens();
 //			nextToken = hasMore ? tokens.nextToken() : null;
 //
 //			// First, determine quoting which might be based on either:
 //			// 		1) back-tick
 //			// 		2) single quote (ANSI SQL standard)
 //			// 		3) or dialect defined quote character(s)
 //			QuotingCharacterDisposition quotingCharacterDisposition = QuotingCharacterDisposition.NONE;
 //			if ( "`".equals( token ) ) {
 //				state.quoted = !state.quoted;
 //				quotingCharacterDisposition = state.quoted
 //						? QuotingCharacterDisposition.OPEN
 //						: QuotingCharacterDisposition.CLOSE;
 //				// replace token with the appropriate dialect quoting char
 //				token = lcToken = ( quotingCharacterDisposition == QuotingCharacterDisposition.OPEN )
 //						? dialectOpenQuote
 //						: dialectCloseQuote;
 //			}
 //			else if ( "'".equals( token ) ) {
 //				state.quoted = !state.quoted;
 //				quotingCharacterDisposition = state.quoted
 //						? QuotingCharacterDisposition.OPEN
 //						: QuotingCharacterDisposition.CLOSE;
 //			}
 //			else if ( !state.quoted && dialectOpenQuote.equals( token ) ) {
 //				state.quoted = true;
 //				quotingCharacterDisposition = QuotingCharacterDisposition.OPEN;
 //			}
 //			else if ( state.quoted && dialectCloseQuote.equals( token ) ) {
 //				state.quoted = false;
 //				quotingCharacterDisposition = QuotingCharacterDisposition.CLOSE;
 //			}
 //
 //			if ( state.quoted ) {
 //				quotedBuffer.append( token );
 //				continue;
 //			}
 //
 //			// if we were previously processing quoted state and just encountered the close quote, then handle that
 //			// quoted text
 //			if ( quotingCharacterDisposition == QuotingCharacterDisposition.CLOSE ) {
 //				token = quotedBuffer.toString();
 //				quotedBuffer.setLength( 0 );
 //				result.append( placeholder ).append( '.' )
 //						.append( dialectOpenQuote ).append( token ).append( dialectCloseQuote );
 //				continue;
 //			}
 //
 //			// Special processing for ANSI SQL EXTRACT function
 //			if ( "extract".equals( lcToken ) && "(".equals( nextToken ) ) {
 //				final String field = extractUntil( tokens, "from" );
 //				final String source = renderWhereStringTemplate(
 //						extractUntil( tokens, ")" ),
 //						placeholder,
 //						dialect,
 //						functionRegistry
 //				);
 //				result.append( "extract(" ).append( field ).append( " from " ).append( source ).append( ')' );
 //
 //				hasMore = tokens.hasMoreTokens();
 //				nextToken = hasMore ? tokens.nextToken() : null;
 //
 //				continue;
 //			}
 //
 //			// Special processing for ANSI SQL TRIM function
 //			if ( "trim".equals( lcToken ) && "(".equals( nextToken ) ) {
 //				List<String> operands = new ArrayList<String>();
 //				StringBuilder builder = new StringBuilder();
 //
 //				boolean hasMoreOperands = true;
 //				String operandToken = tokens.nextToken();
 //				boolean quoted = false;
 //				while ( hasMoreOperands ) {
 //					final boolean isQuote = "'".equals( operandToken );
 //					if ( isQuote ) {
 //						quoted = !quoted;
 //						if ( !quoted ) {
 //							operands.add( builder.append( '\'' ).toString() );
 //							builder.setLength( 0 );
 //						}
 //						else {
 //							builder.append( '\'' );
 //						}
 //					}
 //					else if ( quoted ) {
 //						builder.append( operandToken );
 //					}
 //					else if ( operandToken.length() == 1 && Character.isWhitespace( operandToken.charAt( 0 ) ) ) {
 //						// do nothing
 //					}
 //					else {
 //						operands.add( operandToken );
 //					}
 //					operandToken = tokens.nextToken();
 //					hasMoreOperands = tokens.hasMoreTokens() && ! ")".equals( operandToken );
 //				}
 //
 //				TrimOperands trimOperands = new TrimOperands( operands );
 //				result.append( "trim(" );
 //				if ( trimOperands.trimSpec != null ) {
 //					result.append( trimOperands.trimSpec ).append( ' ' );
 //				}
 //				if ( trimOperands.trimChar != null ) {
 //					if ( trimOperands.trimChar.startsWith( "'" ) && trimOperands.trimChar.endsWith( "'" ) ) {
 //						result.append( trimOperands.trimChar );
 //					}
 //					else {
 //						result.append(
 //								renderWhereStringTemplate( trimOperands.trimSpec, placeholder, dialect, functionRegistry )
 //						);
 //					}
 //					result.append( ' ' );
 //				}
 //				if ( trimOperands.from != null ) {
 //					result.append( trimOperands.from ).append( ' ' );
 //				}
 //				else if ( trimOperands.trimSpec != null || trimOperands.trimChar != null ) {
 //					// I think ANSI SQL says that the 'from' is not optional if either trim-spec or trim-char are specified
 //					result.append( "from " );
 //				}
 //
 //				result.append( renderWhereStringTemplate( trimOperands.trimSource, placeholder, dialect, functionRegistry ) )
 //						.append( ')' );
 //
 //				hasMore = tokens.hasMoreTokens();
 //				nextToken = hasMore ? tokens.nextToken() : null;
 //
 //				continue;
 //			}
 //
 //
 //			// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 //
 //			if ( Character.isWhitespace( token.charAt( 0 ) ) ) {
 //				result.append( token );
 //			}
 //			else if ( state.beforeTable ) {
 //				result.append( token );
 //				state.beforeTable = false;
 //				state.afterFromTable = true;
 //			}
 //			else if ( state.afterFromTable ) {
 //				if ( !"as".equals(lcToken) ) {
 //					state.afterFromTable = false;
 //				}
 //				result.append(token);
 //			}
 //			else if ( isNamedParameter(token) ) {
 //				result.append(token);
 //			}
 //			else if ( isIdentifier(token, dialect)
 //					&& !isFunctionOrKeyword(lcToken, nextToken, dialect , functionRegistry) ) {
 //				result.append(placeholder)
 //						.append('.')
 //						.append( dialect.quote(token) );
 //			}
 //			else {
 //				if ( BEFORE_TABLE_KEYWORDS.contains(lcToken) ) {
 //					state.beforeTable = true;
 //					state.inFromClause = true;
 //				}
 //				else if ( state.inFromClause && ",".equals(lcToken) ) {
 //					state.beforeTable = true;
 //				}
 //				result.append(token);
 //			}
 //
 //			//Yuck:
 //			if ( state.inFromClause
 //					&& KEYWORDS.contains( lcToken ) //"as" is not in KEYWORDS
 //					&& !BEFORE_TABLE_KEYWORDS.contains( lcToken ) ) {
 //				state.inFromClause = false;
 //			}
 //		}
 //
 //		return result.toString();
 //	}
 //
 //	private static class ProcessingState {
 //		boolean quoted = false;
 //		boolean quotedIdentifier = false;
 //		boolean beforeTable = false;
 //		boolean inFromClause = false;
 //		boolean afterFromTable = false;
 //	}
 //
 //	private static enum QuotingCharacterDisposition { NONE, OPEN, CLOSE }
 
 	private static class TrimOperands {
 		private final String trimSpec;
 		private final String trimChar;
 		private final String from;
 		private final String trimSource;
 
 		private TrimOperands(List<String> operands) {
 			final int size = operands.size();
 			if ( size == 1 ) {
 				trimSpec = null;
 				trimChar = null;
 				from = null;
 				trimSource = operands.get(0);
 			}
 			else if ( size == 4 ) {
 				trimSpec = operands.get(0);
 				trimChar = operands.get(1);
 				from = operands.get(2);
 				trimSource = operands.get(3);
 			}
 			else {
 				if ( size < 1 || size > 4 ) {
 					throw new HibernateException( "Unexpected number of trim function operands : " + size );
 				}
 
 				// trim-source will always be the last operand
 				trimSource = operands.get( size - 1 );
 
 				// ANSI SQL says that more than one operand means that the FROM is required
 				if ( ! "from".equals( operands.get( size - 2 ) ) ) {
 					throw new HibernateException( "Expecting FROM, found : " + operands.get( size - 2 ) );
 				}
 				from = operands.get( size - 2 );
 
 				// trim-spec, if there is one will always be the first operand
 				if ( "leading".equalsIgnoreCase( operands.get(0) )
 						|| "trailing".equalsIgnoreCase( operands.get(0) )
 						|| "both".equalsIgnoreCase( operands.get(0) ) ) {
 					trimSpec = operands.get(0);
 					trimChar = null;
 				}
 				else {
 					trimSpec = null;
 					if ( size - 2 == 0 ) {
 						trimChar = null;
 					}
 					else {
 						trimChar = operands.get( 0 );
 					}
 				}
 			}
 		}
 	}
 
 	private static String extractUntil(StringTokenizer tokens, String delimiter) {
 		StringBuilder valueBuilder = new StringBuilder();
 		String token = tokens.nextToken();
 		while ( ! delimiter.equalsIgnoreCase( token ) ) {
 			valueBuilder.append( token );
 			token = tokens.nextToken();
 		}
 		return valueBuilder.toString().trim();
 	}
 
 	public static class NoOpColumnMapper implements ColumnMapper {
 		public static final NoOpColumnMapper INSTANCE = new NoOpColumnMapper();
 		public SqlValueReference[] map(String reference) {
 //			return new String[] { reference };
 			return null;
 		}
 	}
 
 	/**
 	 * Performs order-by template rendering without {@link ColumnMapper column mapping}.  An <tt>ORDER BY</tt> template
 	 * has all column references "qualified" with a placeholder identified by {@link Template#TEMPLATE}
 	 *
 	 * @param orderByFragment The order-by fragment to render.
 	 * @param dialect The SQL dialect being used.
 	 * @param functionRegistry The SQL function registry
 	 *
 	 * @return The rendered <tt>ORDER BY</tt> template.
 	 *
 	 * @deprecated Use {@link #translateOrderBy} instead
 	 */
 	@Deprecated
-    public static String renderOrderByStringTemplate(
+	public static String renderOrderByStringTemplate(
 			String orderByFragment,
 			Dialect dialect,
 			SQLFunctionRegistry functionRegistry) {
 		return renderOrderByStringTemplate(
 				orderByFragment,
 				NoOpColumnMapper.INSTANCE,
 				null,
 				dialect,
 				functionRegistry
 		);
 	}
 
 	public static String renderOrderByStringTemplate(
 			String orderByFragment,
 			final ColumnMapper columnMapper,
 			final SessionFactoryImplementor sessionFactory,
 			final Dialect dialect,
 			final SQLFunctionRegistry functionRegistry) {
 		return translateOrderBy(
 				orderByFragment,
 				columnMapper,
 				sessionFactory,
 				dialect,
 				functionRegistry
 		).injectAliases( LEGACY_ORDER_BY_ALIAS_RESOLVER );
 	}
 
 	public static OrderByAliasResolver LEGACY_ORDER_BY_ALIAS_RESOLVER = new OrderByAliasResolver() {
 		@Override
 		public String resolveTableAlias(String columnReference) {
 			return TEMPLATE;
 		}
 	};
 
 	/**
 	 * Performs order-by template rendering allowing {@link ColumnMapper column mapping}.  An <tt>ORDER BY</tt> template
 	 * has all column references "qualified" with a placeholder identified by {@link Template#TEMPLATE} which can later
 	 * be used to easily inject the SQL alias.
 	 *
 	 * @param orderByFragment The order-by fragment to render.
 	 * @param columnMapper The column mapping strategy to use.
 	 * @param sessionFactory The session factory.
 	 * @param dialect The SQL dialect being used.
 	 * @param functionRegistry The SQL function registry
 	 *
 	 * @return The rendered <tt>ORDER BY</tt> template.
 	 */
 	public static OrderByTranslation translateOrderBy(
 			String orderByFragment,
 			final ColumnMapper columnMapper,
 			final SessionFactoryImplementor sessionFactory,
 			final Dialect dialect,
 			final SQLFunctionRegistry functionRegistry) {
 		TranslationContext context = new TranslationContext() {
 			public SessionFactoryImplementor getSessionFactory() {
 				return sessionFactory;
 			}
 
 			public Dialect getDialect() {
 				return dialect;
 			}
 
 			public SQLFunctionRegistry getSqlFunctionRegistry() {
 				return functionRegistry;
 			}
 
 			public ColumnMapper getColumnMapper() {
 				return columnMapper;
 			}
 		};
 
 		return OrderByFragmentTranslator.translate( context, orderByFragment );
 	}
 
 	private static boolean isNamedParameter(String token) {
 		return token.startsWith(":");
 	}
 
 	private static boolean isFunctionOrKeyword(String lcToken, String nextToken, Dialect dialect, SQLFunctionRegistry functionRegistry) {
 		return "(".equals(nextToken) ||
 			KEYWORDS.contains(lcToken) ||
 			isFunction(lcToken, nextToken, functionRegistry ) ||
 			dialect.getKeywords().contains(lcToken) ||
 			FUNCTION_KEYWORDS.contains(lcToken);
 	}
 
 	private static boolean isFunction(String lcToken, String nextToken, SQLFunctionRegistry functionRegistry) {
 		// checking for "(" is currently redundant because it is checked before getting here;
 		// doing the check anyhow, in case that earlier check goes away;
 		if ( "(".equals( nextToken ) ) {
 			return true;
 		}
 		SQLFunction function = functionRegistry.findSQLFunction(lcToken);
 		if ( function == null ) {
 			// lcToken does not refer to a function
 			return false;
 		}
 		// if function.hasParenthesesIfNoArguments() is true, then assume
 		// lcToken is not a function (since it is not followed by '(')
 		return ! function.hasParenthesesIfNoArguments();
 	}
 
 	private static boolean isIdentifier(String token) {
 		return token.charAt(0)=='`' || ( //allow any identifier quoted with backtick
 			Character.isLetter( token.charAt(0) ) && //only recognizes identifiers beginning with a letter
 			token.indexOf('.') < 0
 		);
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentParser.java b/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentParser.java
index 701d11c547..fe05d8c303 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentParser.java
@@ -1,334 +1,333 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008 Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.sql.ordering.antlr;
 
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.Set;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.sql.Template;
 
 import org.jboss.logging.Logger;
 
 import antlr.CommonAST;
 import antlr.TokenStream;
 import antlr.collections.AST;
 
 /**
  * Extension of the Antlr-generated parser for the purpose of adding our custom parsing behavior
  * (semantic analysis, etc).
  *
  * @author Steve Ebersole
  */
 public class OrderByFragmentParser extends GeneratedOrderByFragmentParser {
-    private static final Logger LOG = Logger.getLogger(OrderByFragmentParser.class.getName());
+	private static final Logger LOG = Logger.getLogger( OrderByFragmentParser.class.getName() );
 
 	private final TranslationContext context;
 
 	private Set<String> columnReferences = new HashSet<String>();
 
 	public OrderByFragmentParser(TokenStream lexer, TranslationContext context) {
 		super( lexer );
 		super.setASTFactory( new Factory() );
 		this.context = context;
 	}
 
 	public Set<String> getColumnReferences() {
 		return columnReferences;
 	}
 
 	@Override
-    protected AST quotedIdentifier(AST ident) {
+	protected AST quotedIdentifier(AST ident) {
 		/*
 		 * Semantic action used during recognition of quoted identifiers (quoted column names)
 		 */
 		final String columnName = context.getDialect().quote( '`' + ident.getText() + '`' );
 		columnReferences.add( columnName );
 		final String marker = '{' + columnName + '}';
 		return getASTFactory().create( OrderByTemplateTokenTypes.IDENT, marker );
 	}
 
 	@Override
-    protected AST quotedString(AST ident) {
+	protected AST quotedString(AST ident) {
 		/*
 		 * Semantic action used during recognition of quoted strings (string literals)
 		 */
 		return getASTFactory().create( OrderByTemplateTokenTypes.IDENT, context.getDialect().quote( ident.getText() ) );
 	}
 
 	@Override
 	@SuppressWarnings("SimplifiableIfStatement")
 	protected boolean isFunctionName(AST ast) {
 		/*
 		 * Semantic predicate used to determine whether a given AST node represents a function call
 		 */
 
 		AST child = ast.getFirstChild();
 		// assume it is a function if it has parameters
 		if ( child != null && "{param list}".equals( child.getText() ) ) {
 			return true;
 		}
 
 		// otherwise, in order for this to be a function logically it has to be a function that does not
 		// have arguments.  So try to assert that using the registry of known functions
 		final SQLFunction function = context.getSqlFunctionRegistry().findSQLFunction( ast.getText() );
 		if ( function == null ) {
 			// no registered function, so we cannot know for certain
 			return false;
 		}
 		else {
 			// if function.hasParenthesesIfNoArguments() is true, then assume the node is not a function
-			return ! function.hasParenthesesIfNoArguments();
+			return !function.hasParenthesesIfNoArguments();
 		}
 	}
 
 	@SuppressWarnings("unchecked")
 	@Override
-    protected AST resolveFunction(AST ast) {
+	protected AST resolveFunction(AST ast) {
 		/*
 		 * Semantic action used during recognition of a *known* function
 		 */
 		AST child = ast.getFirstChild();
 		if ( child != null ) {
-			assert "{param list}".equals(  child.getText() );
+			assert "{param list}".equals( child.getText() );
 			child = child.getFirstChild();
 		}
 
 		final String functionName = ast.getText();
 		final SQLFunction function = context.getSqlFunctionRegistry().findSQLFunction( functionName );
 		if ( function == null ) {
 			String text = functionName;
 			if ( child != null ) {
 				text += '(';
 				while ( child != null ) {
 					text += resolveFunctionArgument( child );
 					child = child.getNextSibling();
 					if ( child != null ) {
 						text += ", ";
 					}
 				}
 				text += ')';
 			}
 			return getASTFactory().create( OrderByTemplateTokenTypes.IDENT, text );
 		}
 		else {
 			ArrayList expressions = new ArrayList();
 			while ( child != null ) {
 				expressions.add( resolveFunctionArgument( child ) );
 				child = child.getNextSibling();
 			}
 			final String text = function.render( null, expressions, context.getSessionFactory() );
 			return getASTFactory().create( OrderByTemplateTokenTypes.IDENT, text );
 		}
 	}
 
 	private String resolveFunctionArgument(AST argumentNode) {
 		final String nodeText = argumentNode.getText();
 		final String adjustedText;
 		if ( nodeText.contains( Template.TEMPLATE ) ) {
 			// we have a SQL order-by fragment
 			adjustedText = adjustTemplateReferences( nodeText );
 		}
 		else if ( nodeText.startsWith( "{" ) && nodeText.endsWith( "}" ) ) {
 			columnReferences.add( nodeText.substring( 1, nodeText.length() - 1 ) );
 			return nodeText;
 		}
 		else {
 			adjustedText = nodeText;
 			// because we did not process the node text, we need to attempt to find any column references
 			// contained in it.
 			// NOTE : uses regex for the time being; we should check the performance of this
 			Pattern pattern = Pattern.compile( "\\{(.*)\\}" );
 			Matcher matcher = pattern.matcher( adjustedText );
 			while ( matcher.find() ) {
 				columnReferences.add( matcher.group( 1 ) );
 			}
 		}
 		return adjustedText;
 	}
 
 	@Override
-    protected AST resolveIdent(AST ident) {
+	protected AST resolveIdent(AST ident) {
 		/*
 		 * Semantic action used during recognition of an identifier.  This identifier might be a column name, it might
 		 * be a property name.
 		 */
 		String text = ident.getText();
 		SqlValueReference[] sqlValueReferences;
 		try {
 			sqlValueReferences = context.getColumnMapper().map( text );
 		}
-		catch( Throwable t ) {
+		catch (Throwable t) {
 			sqlValueReferences = null;
 		}
 
 		if ( sqlValueReferences == null || sqlValueReferences.length == 0 ) {
 			return getASTFactory().create( OrderByTemplateTokenTypes.IDENT, makeColumnReference( text ) );
 		}
 		else if ( sqlValueReferences.length == 1 ) {
 			return processSqlValueReference( sqlValueReferences[0] );
 		}
 		else {
 			final AST root = getASTFactory().create( OrderByTemplateTokenTypes.IDENT_LIST, "{ident list}" );
 			for ( SqlValueReference sqlValueReference : sqlValueReferences ) {
 				root.addChild( processSqlValueReference( sqlValueReference ) );
 			}
 			return root;
 		}
 	}
 
 	private AST processSqlValueReference(SqlValueReference sqlValueReference) {
 		if ( ColumnReference.class.isInstance( sqlValueReference ) ) {
 			final String columnName = ( (ColumnReference) sqlValueReference ).getColumnName();
 			return getASTFactory().create( OrderByTemplateTokenTypes.IDENT, makeColumnReference( columnName ) );
 		}
 		else {
 			final String formulaFragment = ( (FormulaReference) sqlValueReference ).getFormulaFragment();
 			// formulas have already been "adjusted" for aliases by appending Template.TEMPLATE to places
 			// where we believe column references are.  Fixing that is beyond scope of this work.  But we need
 			// to re-adjust that to use the order-by expectation of wrapping the column names in curly
 			// braces (i.e., `{column_name}`).
 			final String adjustedText = adjustTemplateReferences( formulaFragment );
 			return getASTFactory().create( OrderByTemplateTokenTypes.IDENT, adjustedText );
 		}
 	}
 
 	private String makeColumnReference(String text) {
 		columnReferences.add( text );
 		return "{" + text + "}";
 	}
 
 	private static final int TEMPLATE_MARKER_LENGTH = Template.TEMPLATE.length();
 
 	private String adjustTemplateReferences(String template) {
 		int templateLength = template.length();
 		int startPos = template.indexOf( Template.TEMPLATE );
 		while ( startPos != -1 && startPos < templateLength ) {
 			int dotPos = startPos + TEMPLATE_MARKER_LENGTH;
 
 			// from here we need to seek the end of the qualified identifier
 			int pos = dotPos + 1;
 			while ( pos < templateLength && isValidIdentifierCharacter( template.charAt( pos ) ) ) {
 				pos++;
 			}
 
 			// At this point we know all 3 points in the template that are needed for replacement.
 			// Basically we will be replacing the whole match with the bit following the dot, but will wrap
 			// the replacement in curly braces.
 			final String columnReference = template.substring( dotPos + 1, pos );
 			final String replacement = "{" + columnReference + "}";
 			template = template.replace( template.substring( startPos, pos ), replacement );
 			columnReferences.add( columnReference );
 
 			// prep for the next seek
 			startPos = template.indexOf( Template.TEMPLATE, ( pos - TEMPLATE_MARKER_LENGTH ) + 1 );
 			templateLength = template.length();
 		}
 
 		return template;
 	}
 
 	private static boolean isValidIdentifierCharacter(char c) {
 		return Character.isLetter( c )
 				|| Character.isDigit( c )
 				|| '_' == c
 				|| '\"' == c;
 	}
 
 	@Override
-    protected AST postProcessSortSpecification(AST sortSpec) {
+	protected AST postProcessSortSpecification(AST sortSpec) {
 		assert SORT_SPEC == sortSpec.getType();
-		SortSpecification sortSpecification = ( SortSpecification ) sortSpec;
+		SortSpecification sortSpecification = (SortSpecification) sortSpec;
 		AST sortKey = sortSpecification.getSortKey();
 		if ( IDENT_LIST == sortKey.getFirstChild().getType() ) {
 			AST identList = sortKey.getFirstChild();
 			AST ident = identList.getFirstChild();
 			AST holder = new CommonAST();
 			do {
 				holder.addChild(
 						createSortSpecification(
 								ident,
 								sortSpecification.getCollation(),
 								sortSpecification.getOrdering()
 						)
 				);
 				ident = ident.getNextSibling();
 			} while ( ident != null );
 			sortSpec = holder.getFirstChild();
 		}
 		return sortSpec;
 	}
 
 	private SortSpecification createSortSpecification(
 			AST ident,
 			CollationSpecification collationSpecification,
 			OrderingSpecification orderingSpecification) {
 		AST sortSpecification = getASTFactory().create( SORT_SPEC, "{{sort specification}}" );
 		AST sortKey = getASTFactory().create( SORT_KEY, "{{sort key}}" );
 		AST newIdent = getASTFactory().create( ident.getType(), ident.getText() );
 		sortKey.setFirstChild( newIdent );
 		sortSpecification.setFirstChild( sortKey );
 		if ( collationSpecification != null ) {
 			sortSpecification.addChild( collationSpecification );
 		}
 		if ( orderingSpecification != null ) {
 			sortSpecification.addChild( orderingSpecification );
 		}
-		return ( SortSpecification ) sortSpecification;
+		return (SortSpecification) sortSpecification;
 	}
 
 
-
 	// trace logging ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private int traceDepth = 0;
 
 
 	@Override
 	public void traceIn(String ruleName) {
 		if ( inputState.guessing > 0 ) {
 			return;
 		}
-		String prefix = StringHelper.repeat( '-', (traceDepth++ * 2) ) + "-> ";
-		LOG.trace(prefix + ruleName);
+		String prefix = StringHelper.repeat( '-', ( traceDepth++ * 2 ) ) + "-> ";
+		LOG.trace( prefix + ruleName );
 	}
 
 	@Override
 	public void traceOut(String ruleName) {
 		if ( inputState.guessing > 0 ) {
 			return;
 		}
-		String prefix = "<-" + StringHelper.repeat( '-', (--traceDepth * 2) ) + " ";
-		LOG.trace(prefix + ruleName);
+		String prefix = "<-" + StringHelper.repeat( '-', ( --traceDepth * 2 ) ) + " ";
+		LOG.trace( prefix + ruleName );
 	}
 
 	@Override
 	protected void trace(String msg) {
 		LOG.trace( msg );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentRenderer.java b/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentRenderer.java
index 0580ad9a36..ecdbbf98ff 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentRenderer.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/ordering/antlr/OrderByFragmentRenderer.java
@@ -1,93 +1,96 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008 Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.sql.ordering.antlr;
 
 import org.hibernate.NullPrecedence;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.hql.internal.ast.util.ASTPrinter;
 import org.hibernate.internal.util.StringHelper;
 
 import org.jboss.logging.Logger;
 
 import antlr.collections.AST;
 
 /**
  * Extension of the Antlr-generated tree walker for rendering the parsed order-by tree back to String form.
  * {@link #out(antlr.collections.AST)} is the sole semantic action here and it is used to utilize our
  * split between text (tree debugging text) and "renderable text" (text to use during rendering).
  *
  * @author Steve Ebersole
  */
 public class OrderByFragmentRenderer extends GeneratedOrderByFragmentRenderer {
 
 	private static final Logger LOG = Logger.getLogger( OrderByFragmentRenderer.class.getName() );
 	private static final ASTPrinter printer = new ASTPrinter( GeneratedOrderByFragmentRendererTokenTypes.class );
 
 	private final SessionFactoryImplementor sessionFactory;
 
 	public OrderByFragmentRenderer(SessionFactoryImplementor sessionFactory) {
 		this.sessionFactory = sessionFactory;
 	}
 
 	@Override
-    protected void out(AST ast) {
-		out( ( ( Node ) ast ).getRenderableText() );
+	protected void out(AST ast) {
+		out( ( (Node) ast ).getRenderableText() );
 	}
 
 
 	// handle trace logging ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-    private int traceDepth = 0;
+	private int traceDepth = 0;
 
 	@Override
-    public void traceIn(String ruleName, AST tree) {
+	public void traceIn(String ruleName, AST tree) {
 		if ( inputState.guessing > 0 ) {
 			return;
 		}
-		String prefix = StringHelper.repeat( '-', (traceDepth++ * 2) ) + "-> ";
-		String traceText = ruleName + " (" + buildTraceNodeName(tree) + ")";
+		String prefix = StringHelper.repeat( '-', ( traceDepth++ * 2 ) ) + "-> ";
+		String traceText = ruleName + " (" + buildTraceNodeName( tree ) + ")";
 		LOG.trace( prefix + traceText );
 	}
 
 	private String buildTraceNodeName(AST tree) {
 		return tree == null
 				? "???"
 				: tree.getText() + " [" + printer.getTokenTypeName( tree.getType() ) + "]";
 	}
 
 	@Override
-    public void traceOut(String ruleName, AST tree) {
+	public void traceOut(String ruleName, AST tree) {
 		if ( inputState.guessing > 0 ) {
 			return;
 		}
-		String prefix = "<-" + StringHelper.repeat( '-', (--traceDepth * 2) ) + " ";
+		String prefix = "<-" + StringHelper.repeat( '-', ( --traceDepth * 2 ) ) + " ";
 		LOG.trace( prefix + ruleName );
 	}
 
 	@Override
 	protected String renderOrderByElement(String expression, String collation, String order, String nulls) {
-		final NullPrecedence nullPrecedence = NullPrecedence.parse( nulls, sessionFactory.getSettings().getDefaultNullPrecedence() );
+		final NullPrecedence nullPrecedence = NullPrecedence.parse(
+				nulls,
+				sessionFactory.getSessionFactoryOptions().getDefaultNullPrecedence()
+		);
 		return sessionFactory.getDialect().renderOrderByElement( expression, collation, order, nullPrecedence );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentNaturalIdCacheStatisticsImpl.java b/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentNaturalIdCacheStatisticsImpl.java
index b4e64ce055..b3a5149e41 100644
--- a/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentNaturalIdCacheStatisticsImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentNaturalIdCacheStatisticsImpl.java
@@ -1,201 +1,204 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.stat.internal;
 
 import java.util.HashMap;
-import java.util.Iterator;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicLong;
 import java.util.concurrent.locks.Lock;
 import java.util.concurrent.locks.ReadWriteLock;
 import java.util.concurrent.locks.ReentrantReadWriteLock;
 
 import org.hibernate.cache.spi.NaturalIdCacheKey;
 import org.hibernate.cache.spi.Region;
 import org.hibernate.stat.NaturalIdCacheStatistics;
 
 /**
  * NaturalId cache statistics of a specific region
  * 
  * @author Eric Dalquist
  */
 public class ConcurrentNaturalIdCacheStatisticsImpl extends CategorizedStatistics implements NaturalIdCacheStatistics {
 	private static final long serialVersionUID = 1L;
 	private final transient Region region;
 	private final AtomicLong hitCount = new AtomicLong();
 	private final AtomicLong missCount = new AtomicLong();
 	private final AtomicLong putCount = new AtomicLong();
 	private final AtomicLong executionCount = new AtomicLong();
 	private final AtomicLong executionMaxTime = new AtomicLong();
 	private final AtomicLong executionMinTime = new AtomicLong( Long.MAX_VALUE );
 	private final AtomicLong totalExecutionTime = new AtomicLong();
 
 	private final Lock readLock;
 	private final Lock writeLock;
 	{
 		final ReadWriteLock lock = new ReentrantReadWriteLock();
 		this.readLock = lock.readLock();
 		this.writeLock = lock.writeLock();
 	}
 
 	ConcurrentNaturalIdCacheStatisticsImpl(Region region) {
 		super( region.getName() );
 		this.region = region;
 	}
 
 	@Override
 	public long getHitCount() {
 		return this.hitCount.get();
 	}
 
 	@Override
 	public long getMissCount() {
 		return this.missCount.get();
 	}
 
 	@Override
 	public long getPutCount() {
 		return this.putCount.get();
 	}
 
 	/**
 	 * queries executed to the DB
 	 */
 	@Override
 	public long getExecutionCount() {
 		return this.executionCount.get();
 	}
 
 	/**
 	 * average time in ms taken by the excution of this query onto the DB
 	 */
 	@Override
 	public long getExecutionAvgTime() {
 		// We write lock here to be sure that we always calculate the average time
 		// with all updates from the executed applied: executionCount and totalExecutionTime
 		// both used in the calculation
 		this.writeLock.lock();
 		try {
 			long avgExecutionTime = 0;
 			if ( this.executionCount.get() > 0 ) {
 				avgExecutionTime = this.totalExecutionTime.get() / this.executionCount.get();
 			}
 			return avgExecutionTime;
 		}
 		finally {
 			this.writeLock.unlock();
 		}
 	}
 
 	/**
 	 * max time in ms taken by the excution of this query onto the DB
 	 */
 	@Override
 	public long getExecutionMaxTime() {
 		return this.executionMaxTime.get();
 	}
 
 	/**
 	 * min time in ms taken by the excution of this query onto the DB
 	 */
 	@Override
 	public long getExecutionMinTime() {
 		return this.executionMinTime.get();
 	}
 
 	@Override
 	public long getElementCountInMemory() {
 		return this.region.getElementCountInMemory();
 	}
 
 	@Override
 	public long getElementCountOnDisk() {
 		return this.region.getElementCountOnDisk();
 	}
 
 	@Override
 	public long getSizeInMemory() {
 		return this.region.getSizeInMemory();
 	}
 
 	@Override
+	@SuppressWarnings("unchecked")
 	public Map getEntries() {
 		final Map map = new HashMap();
-		final Iterator iter = this.region.toMap().entrySet().iterator();
-		while ( iter.hasNext() ) {
-			final Map.Entry me = (Map.Entry) iter.next();
+		for ( Object o : this.region.toMap().entrySet() ) {
+			final Map.Entry me = (Map.Entry) o;
 			map.put( ( (NaturalIdCacheKey) me.getKey() ).getNaturalIdValues(), me.getValue() );
 		}
 		return map;
 	}
 
 	@Override
 	public String toString() {
 		final StringBuilder buf = new StringBuilder()
 			.append( "NaturalIdCacheStatistics" )
 			.append( "[hitCount=" ).append( this.hitCount )
 			.append( ",missCount=" ).append( this.missCount )
 			.append( ",putCount=" ).append( this.putCount )
 			.append( ",executionCount=" ).append( this.executionCount )
 			.append( ",executionAvgTime=" ).append( this.getExecutionAvgTime() )
 			.append( ",executionMinTime=" ).append( this.executionMinTime )
 			.append( ",executionMaxTime=" ).append( this.executionMaxTime );
 		// not sure if this would ever be null but wanted to be careful
 		if ( this.region != null ) {
 			buf.append( ",elementCountInMemory=" ).append( this.getElementCountInMemory() )
 				.append( ",elementCountOnDisk=" ).append( this.getElementCountOnDisk() )
 				.append( ",sizeInMemory=" ).append( this.getSizeInMemory() );
 		}
 		buf.append( ']' );
 		return buf.toString();
 	}
 
 	void incrementHitCount() {
 		this.hitCount.getAndIncrement();
 	}
 
 	void incrementMissCount() {
 		this.missCount.getAndIncrement();
 	}
 
 	void incrementPutCount() {
 		this.putCount.getAndIncrement();
 	}
 
 	void queryExecuted(long time) {
 		// read lock is enough, concurrent updates are supported by the underlying type AtomicLong
 		// this only guards executed(long, long) to be called, when another thread is executing getExecutionAvgTime()
 		this.readLock.lock();
 		try {
 			// Less chances for a context switch
-			for ( long old = this.executionMinTime.get(); time < old && !this.executionMinTime.compareAndSet( old, time ); old = this.executionMinTime.get() ) {;}
-			for ( long old = this.executionMaxTime.get(); time > old && !this.executionMaxTime.compareAndSet( old, time ); old = this.executionMaxTime.get() ) {;}
+			//noinspection StatementWithEmptyBody
+			for ( long old = this.executionMinTime.get(); time < old && !this.executionMinTime.compareAndSet( old, time ); old = this.executionMinTime.get() ) {
+			}
+			//noinspection StatementWithEmptyBody
+			for ( long old = this.executionMaxTime.get(); time > old && !this.executionMaxTime.compareAndSet( old, time ); old = this.executionMaxTime.get() ) {
+			}
 			this.executionCount.getAndIncrement();
 			this.totalExecutionTime.addAndGet( time );
 		}
 		finally {
 			this.readLock.unlock();
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentStatisticsImpl.java b/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentStatisticsImpl.java
index f16dc1afa6..d2b410f029 100644
--- a/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentStatisticsImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentStatisticsImpl.java
@@ -1,908 +1,909 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.stat.internal;
 
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.atomic.AtomicLong;
 
 import org.hibernate.cache.spi.Region;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.service.Service;
 import org.hibernate.stat.CollectionStatistics;
 import org.hibernate.stat.EntityStatistics;
 import org.hibernate.stat.NaturalIdCacheStatistics;
 import org.hibernate.stat.QueryStatistics;
 import org.hibernate.stat.SecondLevelCacheStatistics;
 import org.hibernate.stat.spi.StatisticsImplementor;
 
-import org.jboss.logging.Logger;
+import static org.hibernate.internal.CoreLogging.messageLogger;
 
 /**
  * Implementation of {@link org.hibernate.stat.Statistics} based on the {@link java.util.concurrent} package.
  *
  * @author Alex Snaps
  */
 @SuppressWarnings({ "unchecked" })
 public class ConcurrentStatisticsImpl implements StatisticsImplementor, Service {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ConcurrentStatisticsImpl.class.getName());
+	private static final CoreMessageLogger LOG = messageLogger( ConcurrentStatisticsImpl.class );
 
 	private SessionFactoryImplementor sessionFactory;
 
 	private volatile boolean isStatisticsEnabled;
 	private volatile long startTime;
 	private AtomicLong sessionOpenCount = new AtomicLong();
 	private AtomicLong sessionCloseCount = new AtomicLong();
 	private AtomicLong flushCount = new AtomicLong();
 	private AtomicLong connectCount = new AtomicLong();
 
 	private AtomicLong prepareStatementCount = new AtomicLong();
 	private AtomicLong closeStatementCount = new AtomicLong();
 
 	private AtomicLong entityLoadCount = new AtomicLong();
 	private AtomicLong entityUpdateCount = new AtomicLong();
 	private AtomicLong entityInsertCount = new AtomicLong();
 	private AtomicLong entityDeleteCount = new AtomicLong();
 	private AtomicLong entityFetchCount = new AtomicLong();
 	private AtomicLong collectionLoadCount = new AtomicLong();
 	private AtomicLong collectionUpdateCount = new AtomicLong();
 	private AtomicLong collectionRemoveCount = new AtomicLong();
 	private AtomicLong collectionRecreateCount = new AtomicLong();
 	private AtomicLong collectionFetchCount = new AtomicLong();
 
 	private AtomicLong secondLevelCacheHitCount = new AtomicLong();
 	private AtomicLong secondLevelCacheMissCount = new AtomicLong();
 	private AtomicLong secondLevelCachePutCount = new AtomicLong();
 	
 	private AtomicLong naturalIdCacheHitCount = new AtomicLong();
 	private AtomicLong naturalIdCacheMissCount = new AtomicLong();
 	private AtomicLong naturalIdCachePutCount = new AtomicLong();
 	private AtomicLong naturalIdQueryExecutionCount = new AtomicLong();
 	private AtomicLong naturalIdQueryExecutionMaxTime = new AtomicLong();
 	private volatile String naturalIdQueryExecutionMaxTimeRegion;
 	
 	private AtomicLong queryExecutionCount = new AtomicLong();
 	private AtomicLong queryExecutionMaxTime = new AtomicLong();
 	private volatile String queryExecutionMaxTimeQueryString;
 	private AtomicLong queryCacheHitCount = new AtomicLong();
 	private AtomicLong queryCacheMissCount = new AtomicLong();
 	private AtomicLong queryCachePutCount = new AtomicLong();
 
 	private AtomicLong updateTimestampsCacheHitCount = new AtomicLong();
 	private AtomicLong updateTimestampsCacheMissCount = new AtomicLong();
 	private AtomicLong updateTimestampsCachePutCount = new AtomicLong();
 
 	private AtomicLong committedTransactionCount = new AtomicLong();
 	private AtomicLong transactionCount = new AtomicLong();
 
 	private AtomicLong optimisticFailureCount = new AtomicLong();
 
 	/**
 	 * natural id cache statistics per region
 	 */
 	private final ConcurrentMap naturalIdCacheStatistics = new ConcurrentHashMap();
 	/**
 	 * second level cache statistics per region
 	 */
 	private final ConcurrentMap secondLevelCacheStatistics = new ConcurrentHashMap();
 	/**
 	 * entity statistics per name
 	 */
 	private final ConcurrentMap entityStatistics = new ConcurrentHashMap();
 	/**
 	 * collection statistics per name
 	 */
 	private final ConcurrentMap collectionStatistics = new ConcurrentHashMap();
 	/**
 	 * entity statistics per query string (HQL or SQL)
 	 */
 	private final ConcurrentMap queryStatistics = new ConcurrentHashMap();
 
 	@SuppressWarnings({ "UnusedDeclaration" })
 	public ConcurrentStatisticsImpl() {
 		clear();
 	}
 
 	public ConcurrentStatisticsImpl(SessionFactoryImplementor sessionFactory) {
 		clear();
 		this.sessionFactory = sessionFactory;
 	}
 
 	/**
 	 * reset all statistics
 	 */
 	public void clear() {
 		secondLevelCacheHitCount.set( 0 );
 		secondLevelCacheMissCount.set( 0 );
 		secondLevelCachePutCount.set( 0 );
 		
 		naturalIdCacheHitCount.set( 0 );
 		naturalIdCacheMissCount.set( 0 );
 		naturalIdCachePutCount.set( 0 );
 		naturalIdQueryExecutionCount.set( 0 );
 		naturalIdQueryExecutionMaxTime.set( 0 );
 		naturalIdQueryExecutionMaxTimeRegion = null;
 
 		sessionCloseCount.set( 0 );
 		sessionOpenCount.set( 0 );
 		flushCount.set( 0 );
 		connectCount.set( 0 );
 
 		prepareStatementCount.set( 0 );
 		closeStatementCount.set( 0 );
 
 		entityDeleteCount.set( 0 );
 		entityInsertCount.set( 0 );
 		entityUpdateCount.set( 0 );
 		entityLoadCount.set( 0 );
 		entityFetchCount.set( 0 );
 
 		collectionRemoveCount.set( 0 );
 		collectionUpdateCount.set( 0 );
 		collectionRecreateCount.set( 0 );
 		collectionLoadCount.set( 0 );
 		collectionFetchCount.set( 0 );
 
 		queryExecutionCount.set( 0 );
 		queryCacheHitCount.set( 0 );
 		queryExecutionMaxTime.set( 0 );
 		queryExecutionMaxTimeQueryString = null;
 		queryCacheMissCount.set( 0 );
 		queryCachePutCount.set( 0 );
 
 		updateTimestampsCacheMissCount.set( 0 );
 		updateTimestampsCacheHitCount.set( 0 );
 		updateTimestampsCachePutCount.set( 0 );
 
 		transactionCount.set( 0 );
 		committedTransactionCount.set( 0 );
 
 		optimisticFailureCount.set( 0 );
 
 		secondLevelCacheStatistics.clear();
 		entityStatistics.clear();
 		collectionStatistics.clear();
 		queryStatistics.clear();
 		naturalIdCacheStatistics.clear();
 
 		startTime = System.currentTimeMillis();
 	}
 
 	public void openSession() {
 		sessionOpenCount.getAndIncrement();
 	}
 
 	public void closeSession() {
 		sessionCloseCount.getAndIncrement();
 	}
 
 	public void flush() {
 		flushCount.getAndIncrement();
 	}
 
 	public void connect() {
 		connectCount.getAndIncrement();
 	}
 
 	public void loadEntity(String entityName) {
 		entityLoadCount.getAndIncrement();
 		( (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName ) ).incrementLoadCount();
 	}
 
 	public void fetchEntity(String entityName) {
 		entityFetchCount.getAndIncrement();
 		( (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName ) ).incrementFetchCount();
 	}
 
 	/**
 	 * find entity statistics per name
 	 *
 	 * @param entityName entity name
 	 *
 	 * @return EntityStatistics object
 	 */
 	public EntityStatistics getEntityStatistics(String entityName) {
 		ConcurrentEntityStatisticsImpl es = (ConcurrentEntityStatisticsImpl) entityStatistics.get( entityName );
 		if ( es == null ) {
 			es = new ConcurrentEntityStatisticsImpl( entityName );
 			ConcurrentEntityStatisticsImpl previous;
 			if ( ( previous = (ConcurrentEntityStatisticsImpl) entityStatistics.putIfAbsent(
 					entityName, es
 			) ) != null ) {
 				es = previous;
 			}
 		}
 		return es;
 	}
 
 	public void updateEntity(String entityName) {
 		entityUpdateCount.getAndIncrement();
 		ConcurrentEntityStatisticsImpl es = (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName );
 		es.incrementUpdateCount();
 	}
 
 	public void insertEntity(String entityName) {
 		entityInsertCount.getAndIncrement();
 		ConcurrentEntityStatisticsImpl es = (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName );
 		es.incrementInsertCount();
 	}
 
 	public void deleteEntity(String entityName) {
 		entityDeleteCount.getAndIncrement();
 		ConcurrentEntityStatisticsImpl es = (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName );
 		es.incrementDeleteCount();
 	}
 
 	/**
 	 * Get collection statistics per role
 	 *
 	 * @param role collection role
 	 *
 	 * @return CollectionStatistics
 	 */
 	public CollectionStatistics getCollectionStatistics(String role) {
 		ConcurrentCollectionStatisticsImpl cs = (ConcurrentCollectionStatisticsImpl) collectionStatistics.get( role );
 		if ( cs == null ) {
 			cs = new ConcurrentCollectionStatisticsImpl( role );
 			ConcurrentCollectionStatisticsImpl previous;
 			if ( ( previous = (ConcurrentCollectionStatisticsImpl) collectionStatistics.putIfAbsent(
 					role, cs
 			) ) != null ) {
 				cs = previous;
 			}
 		}
 		return cs;
 	}
 
 	public void loadCollection(String role) {
 		collectionLoadCount.getAndIncrement();
 		( (ConcurrentCollectionStatisticsImpl) getCollectionStatistics( role ) ).incrementLoadCount();
 	}
 
 	public void fetchCollection(String role) {
 		collectionFetchCount.getAndIncrement();
 		( (ConcurrentCollectionStatisticsImpl) getCollectionStatistics( role ) ).incrementFetchCount();
 	}
 
 	public void updateCollection(String role) {
 		collectionUpdateCount.getAndIncrement();
 		( (ConcurrentCollectionStatisticsImpl) getCollectionStatistics( role ) ).incrementUpdateCount();
 	}
 
 	public void recreateCollection(String role) {
 		collectionRecreateCount.getAndIncrement();
 		( (ConcurrentCollectionStatisticsImpl) getCollectionStatistics( role ) ).incrementRecreateCount();
 	}
 
 	public void removeCollection(String role) {
 		collectionRemoveCount.getAndIncrement();
 		( (ConcurrentCollectionStatisticsImpl) getCollectionStatistics( role ) ).incrementRemoveCount();
 	}
 	
 
 	@Override
 	public NaturalIdCacheStatistics getNaturalIdCacheStatistics(String regionName) {
 		ConcurrentNaturalIdCacheStatisticsImpl nics =
 				(ConcurrentNaturalIdCacheStatisticsImpl) naturalIdCacheStatistics.get( regionName );
 		
 		if ( nics == null ) {
 			if ( sessionFactory == null ) {
 				return null;
 			}
 			Region region = sessionFactory.getNaturalIdCacheRegion( regionName );
 			if ( region == null ) {
 				return null;
 			}
 			nics = new ConcurrentNaturalIdCacheStatisticsImpl( region );
 			ConcurrentNaturalIdCacheStatisticsImpl previous;
 			if ( ( previous = (ConcurrentNaturalIdCacheStatisticsImpl) naturalIdCacheStatistics.putIfAbsent(
 					regionName, nics
 			) ) != null ) {
 				nics = previous;
 			}
 		}
 		return nics;
 	}
 
 	/**
 	 * Second level cache statistics per region
 	 *
 	 * @param regionName region name
 	 *
 	 * @return SecondLevelCacheStatistics
 	 */
 	public SecondLevelCacheStatistics getSecondLevelCacheStatistics(String regionName) {
 		ConcurrentSecondLevelCacheStatisticsImpl slcs
 				= (ConcurrentSecondLevelCacheStatisticsImpl) secondLevelCacheStatistics.get( regionName );
 		if ( slcs == null ) {
 			if ( sessionFactory == null ) {
 				return null;
 			}
 			Region region = sessionFactory.getSecondLevelCacheRegion( regionName );
 			if ( region == null ) {
 				return null;
 			}
 			slcs = new ConcurrentSecondLevelCacheStatisticsImpl( region );
 			ConcurrentSecondLevelCacheStatisticsImpl previous;
 			if ( ( previous = (ConcurrentSecondLevelCacheStatisticsImpl) secondLevelCacheStatistics.putIfAbsent(
 					regionName, slcs
 			) ) != null ) {
 				slcs = previous;
 			}
 		}
 		return slcs;
 	}
 
 	public void secondLevelCachePut(String regionName) {
 		secondLevelCachePutCount.getAndIncrement();
 		( (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics( regionName ) ).incrementPutCount();
 	}
 
 	public void secondLevelCacheHit(String regionName) {
 		secondLevelCacheHitCount.getAndIncrement();
 		( (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics( regionName ) ).incrementHitCount();
 	}
 
 	public void secondLevelCacheMiss(String regionName) {
 		secondLevelCacheMissCount.getAndIncrement();
 		( (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics( regionName ) ).incrementMissCount();
 	}
 	
 	@Override
 	public void naturalIdCachePut(String regionName) {
 		naturalIdCachePutCount.getAndIncrement();
 		( (ConcurrentNaturalIdCacheStatisticsImpl) getNaturalIdCacheStatistics( regionName ) ).incrementPutCount();
 	}
 
 	@Override
 	public void naturalIdCacheHit(String regionName) {
 		naturalIdCacheHitCount.getAndIncrement();
 		( (ConcurrentNaturalIdCacheStatisticsImpl) getNaturalIdCacheStatistics( regionName ) ).incrementHitCount();
 	}
 
 	@Override
 	public void naturalIdCacheMiss(String regionName) {
 		naturalIdCacheMissCount.getAndIncrement();
 		( (ConcurrentNaturalIdCacheStatisticsImpl) getNaturalIdCacheStatistics( regionName ) ).incrementMissCount();
 	}
 	
 	@Override
 	public void naturalIdQueryExecuted(String regionName, long time) {
 		naturalIdQueryExecutionCount.getAndIncrement();
-		boolean isLongestQuery = false;
+		boolean isLongestQuery;
+		//noinspection StatementWithEmptyBody
 		for ( long old = naturalIdQueryExecutionMaxTime.get();
 			  ( isLongestQuery = time > old ) && ( !naturalIdQueryExecutionMaxTime.compareAndSet( old, time ) );
 			  old = naturalIdQueryExecutionMaxTime.get() ) {
 			// nothing to do here given the odd loop structure...
 		}
 		if ( isLongestQuery && regionName != null ) {
 			naturalIdQueryExecutionMaxTimeRegion = regionName;
 		}
 		if ( regionName != null ) {
 			( (ConcurrentNaturalIdCacheStatisticsImpl) getNaturalIdCacheStatistics( regionName ) ).queryExecuted( time );
 		}
 	}
 
 	@Override
 	public void queryExecuted(String hql, int rows, long time) {
         LOG.hql(hql, time, (long) rows );
 		queryExecutionCount.getAndIncrement();
-		boolean isLongestQuery = false;
+		boolean isLongestQuery;
+		//noinspection StatementWithEmptyBody
 		for ( long old = queryExecutionMaxTime.get();
 			  ( isLongestQuery = time > old ) && ( !queryExecutionMaxTime.compareAndSet( old, time ) );
 			  old = queryExecutionMaxTime.get() ) {
 			// nothing to do here given the odd loop structure...
 		}
 		if ( isLongestQuery ) {
 			queryExecutionMaxTimeQueryString = hql;
 		}
 		if ( hql != null ) {
 			ConcurrentQueryStatisticsImpl qs = (ConcurrentQueryStatisticsImpl) getQueryStatistics( hql );
 			qs.executed( rows, time );
 		}
 	}
 	@Override
 	public void queryCacheHit(String hql, String regionName) {
 		queryCacheHitCount.getAndIncrement();
 		if ( hql != null ) {
 			ConcurrentQueryStatisticsImpl qs = (ConcurrentQueryStatisticsImpl) getQueryStatistics( hql );
 			qs.incrementCacheHitCount();
 		}
 		ConcurrentSecondLevelCacheStatisticsImpl slcs = (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics(
 				regionName
 		);
 		slcs.incrementHitCount();
 	}
 	@Override
 	public void queryCacheMiss(String hql, String regionName) {
 		queryCacheMissCount.getAndIncrement();
 		if ( hql != null ) {
 			ConcurrentQueryStatisticsImpl qs = (ConcurrentQueryStatisticsImpl) getQueryStatistics( hql );
 			qs.incrementCacheMissCount();
 		}
 		ConcurrentSecondLevelCacheStatisticsImpl slcs = (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics(
 				regionName
 		);
 		slcs.incrementMissCount();
 	}
 	@Override
 	public void queryCachePut(String hql, String regionName) {
 		queryCachePutCount.getAndIncrement();
 		if ( hql != null ) {
 			ConcurrentQueryStatisticsImpl qs = (ConcurrentQueryStatisticsImpl) getQueryStatistics( hql );
 			qs.incrementCachePutCount();
 		}
 		ConcurrentSecondLevelCacheStatisticsImpl slcs = (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics(
 				regionName
 		);
 		slcs.incrementPutCount();
 	}
 
 	@Override
 	public void updateTimestampsCacheHit() {
 		updateTimestampsCacheHitCount.getAndIncrement();
 	}
 
 	@Override
 	public void updateTimestampsCacheMiss() {
 		updateTimestampsCacheMissCount.getAndIncrement();
 	}
 
 	@Override
 	public void updateTimestampsCachePut() {
 		updateTimestampsCachePutCount.getAndIncrement();
 	}
 
 	/**
 	 * Query statistics from query string (HQL or SQL)
 	 *
 	 * @param queryString query string
 	 *
 	 * @return QueryStatistics
 	 */
 	@Override
 	public QueryStatistics getQueryStatistics(String queryString) {
 		ConcurrentQueryStatisticsImpl qs = (ConcurrentQueryStatisticsImpl) queryStatistics.get( queryString );
 		if ( qs == null ) {
 			qs = new ConcurrentQueryStatisticsImpl( queryString );
 			ConcurrentQueryStatisticsImpl previous;
 			if ( ( previous = (ConcurrentQueryStatisticsImpl) queryStatistics.putIfAbsent(
 					queryString, qs
 			) ) != null ) {
 				qs = previous;
 			}
 		}
 		return qs;
 	}
 
 	/**
 	 * @return entity deletion count
 	 */
 	@Override
 	public long getEntityDeleteCount() {
 		return entityDeleteCount.get();
 	}
 
 	/**
 	 * @return entity insertion count
 	 */
 	@Override
 	public long getEntityInsertCount() {
 		return entityInsertCount.get();
 	}
 
 	/**
 	 * @return entity load (from DB)
 	 */
 	@Override
 	public long getEntityLoadCount() {
 		return entityLoadCount.get();
 	}
 
 	/**
 	 * @return entity fetch (from DB)
 	 */
 	@Override
 	public long getEntityFetchCount() {
 		return entityFetchCount.get();
 	}
 
 	/**
 	 * @return entity update
 	 */
 	@Override
 	public long getEntityUpdateCount() {
 		return entityUpdateCount.get();
 	}
 	@Override
 	public long getQueryExecutionCount() {
 		return queryExecutionCount.get();
 	}
 	@Override
 	public long getQueryCacheHitCount() {
 		return queryCacheHitCount.get();
 	}
 	@Override
 	public long getQueryCacheMissCount() {
 		return queryCacheMissCount.get();
 	}
 	@Override
 	public long getQueryCachePutCount() {
 		return queryCachePutCount.get();
 	}
 	@Override
 	public long getUpdateTimestampsCacheHitCount() {
 		return updateTimestampsCacheHitCount.get();
 	}
 	@Override
 	public long getUpdateTimestampsCacheMissCount() {
 		return updateTimestampsCacheMissCount.get();
 	}
 	@Override
 	public long getUpdateTimestampsCachePutCount() {
 		return updateTimestampsCachePutCount.get();
 	}
 
 	/**
 	 * @return flush
 	 */
 	@Override
 	public long getFlushCount() {
 		return flushCount.get();
 	}
 
 	/**
 	 * @return session connect
 	 */
 	@Override
 	public long getConnectCount() {
 		return connectCount.get();
 	}
 
 	/**
 	 * @return second level cache hit
 	 */
 	@Override
 	public long getSecondLevelCacheHitCount() {
 		return secondLevelCacheHitCount.get();
 	}
 
 	/**
 	 * @return second level cache miss
 	 */
 	@Override
 	public long getSecondLevelCacheMissCount() {
 		return secondLevelCacheMissCount.get();
 	}
 
 	/**
 	 * @return second level cache put
 	 */
 	@Override
 	public long getSecondLevelCachePutCount() {
 		return secondLevelCachePutCount.get();
 	}
 
 	@Override
 	public long getNaturalIdQueryExecutionCount() {
 		return naturalIdQueryExecutionCount.get();
 	}
 
 	@Override
 	public long getNaturalIdQueryExecutionMaxTime() {
 		return naturalIdQueryExecutionMaxTime.get();
 	}
 	
 	@Override
 	public String getNaturalIdQueryExecutionMaxTimeRegion() {
 		return naturalIdQueryExecutionMaxTimeRegion;
 	}
 	
 	@Override
 	public long getNaturalIdCacheHitCount() {
 		return naturalIdCacheHitCount.get();
 	}
 
 	@Override
 	public long getNaturalIdCacheMissCount() {
 		return naturalIdCacheMissCount.get();
 	}
 
 	@Override
 	public long getNaturalIdCachePutCount() {
 		return naturalIdCachePutCount.get();
 	}
 
 	/**
 	 * @return session closing
 	 */
 	@Override
 	public long getSessionCloseCount() {
 		return sessionCloseCount.get();
 	}
 
 	/**
 	 * @return session opening
 	 */
 	@Override
 	public long getSessionOpenCount() {
 		return sessionOpenCount.get();
 	}
 
 	/**
 	 * @return collection loading (from DB)
 	 */
 	@Override
 	public long getCollectionLoadCount() {
 		return collectionLoadCount.get();
 	}
 
 	/**
 	 * @return collection fetching (from DB)
 	 */
 	@Override
 	public long getCollectionFetchCount() {
 		return collectionFetchCount.get();
 	}
 
 	/**
 	 * @return collection update
 	 */
 	@Override
 	public long getCollectionUpdateCount() {
 		return collectionUpdateCount.get();
 	}
 
 	/**
 	 * @return collection removal
 	 *         FIXME: even if isInverse="true"?
 	 */
 	@Override
 	public long getCollectionRemoveCount() {
 		return collectionRemoveCount.get();
 	}
 
 	/**
 	 * @return collection recreation
 	 */
 	@Override
 	public long getCollectionRecreateCount() {
 		return collectionRecreateCount.get();
 	}
 
 	/**
 	 * @return start time in ms (JVM standards {@link System#currentTimeMillis()})
 	 */
 	@Override
 	public long getStartTime() {
 		return startTime;
 	}
 
 	/**
 	 * log in info level the main statistics
 	 */
 	@Override
 	public void logSummary() {
 		LOG.loggingStatistics();
 		LOG.startTime( startTime );
 		LOG.sessionsOpened( sessionOpenCount.get() );
 		LOG.sessionsClosed( sessionCloseCount.get() );
 		LOG.transactions( transactionCount.get() );
 		LOG.successfulTransactions( committedTransactionCount.get() );
 		LOG.optimisticLockFailures( optimisticFailureCount.get() );
 		LOG.flushes( flushCount.get() );
 		LOG.connectionsObtained( connectCount.get() );
 		LOG.statementsPrepared( prepareStatementCount.get() );
 		LOG.statementsClosed( closeStatementCount.get() );
 		LOG.secondLevelCachePuts( secondLevelCachePutCount.get() );
 		LOG.secondLevelCacheHits( secondLevelCacheHitCount.get() );
 		LOG.secondLevelCacheMisses( secondLevelCacheMissCount.get() );
 		LOG.entitiesLoaded( entityLoadCount.get() );
 		LOG.entitiesUpdated( entityUpdateCount.get() );
 		LOG.entitiesInserted( entityInsertCount.get() );
 		LOG.entitiesDeleted( entityDeleteCount.get() );
 		LOG.entitiesFetched( entityFetchCount.get() );
 		LOG.collectionsLoaded( collectionLoadCount.get() );
 		LOG.collectionsUpdated( collectionUpdateCount.get() );
 		LOG.collectionsRemoved( collectionRemoveCount.get() );
 		LOG.collectionsRecreated( collectionRecreateCount.get() );
 		LOG.collectionsFetched( collectionFetchCount.get() );
 		LOG.naturalIdCachePuts( naturalIdCachePutCount.get() );
 		LOG.naturalIdCacheHits( naturalIdCacheHitCount.get() );
 		LOG.naturalIdCacheMisses( naturalIdCacheMissCount.get() );
 		LOG.naturalIdMaxQueryTime( naturalIdQueryExecutionMaxTime.get() );
 		LOG.naturalIdQueriesExecuted( naturalIdQueryExecutionCount.get() );
 		LOG.queriesExecuted( queryExecutionCount.get() );
 		LOG.queryCachePuts( queryCachePutCount.get() );
 		LOG.timestampCachePuts( updateTimestampsCachePutCount.get() );
 		LOG.timestampCacheHits( updateTimestampsCacheHitCount.get() );
 		LOG.timestampCacheMisses( updateTimestampsCacheMissCount.get() );
 		LOG.queryCacheHits( queryCacheHitCount.get() );
 		LOG.queryCacheMisses( queryCacheMissCount.get() );
 		LOG.maxQueryTime( queryExecutionMaxTime.get() );
 	}
 
 	/**
 	 * Are statistics logged
 	 */
 	@Override
 	public boolean isStatisticsEnabled() {
 		return isStatisticsEnabled;
 	}
 
 	/**
 	 * Enable statistics logs (this is a dynamic parameter)
 	 */
 	@Override
 	public void setStatisticsEnabled(boolean b) {
 		isStatisticsEnabled = b;
 	}
 
 	/**
 	 * @return Returns the max query execution time,
 	 *         for all queries
 	 */
 	@Override
 	public long getQueryExecutionMaxTime() {
 		return queryExecutionMaxTime.get();
 	}
 
 	/**
 	 * Get all executed query strings
 	 */
 	@Override
 	public String[] getQueries() {
 		return ArrayHelper.toStringArray( queryStatistics.keySet() );
 	}
 
 	/**
 	 * Get the names of all entities
 	 */
 	@Override
 	public String[] getEntityNames() {
 		if ( sessionFactory == null ) {
 			return ArrayHelper.toStringArray( entityStatistics.keySet() );
 		}
 		else {
 			return ArrayHelper.toStringArray( sessionFactory.getAllClassMetadata().keySet() );
 		}
 	}
 
 	/**
 	 * Get the names of all collection roles
 	 */
 	@Override
 	public String[] getCollectionRoleNames() {
 		if ( sessionFactory == null ) {
 			return ArrayHelper.toStringArray( collectionStatistics.keySet() );
 		}
 		else {
 			return ArrayHelper.toStringArray( sessionFactory.getAllCollectionMetadata().keySet() );
 		}
 	}
 
 	/**
 	 * Get all second-level cache region names
 	 */
 	@Override
 	public String[] getSecondLevelCacheRegionNames() {
 		if ( sessionFactory == null ) {
 			return ArrayHelper.toStringArray( secondLevelCacheStatistics.keySet() );
 		}
 		else {
 			return ArrayHelper.toStringArray( sessionFactory.getAllSecondLevelCacheRegions().keySet() );
 		}
 	}
 	@Override
 	public void endTransaction(boolean success) {
 		transactionCount.getAndIncrement();
 		if ( success ) {
 			committedTransactionCount.getAndIncrement();
 		}
 	}
 	@Override
 	public long getSuccessfulTransactionCount() {
 		return committedTransactionCount.get();
 	}
 	@Override
 	public long getTransactionCount() {
 		return transactionCount.get();
 	}
 	@Override
 	public void closeStatement() {
 		closeStatementCount.getAndIncrement();
 	}
 	@Override
 	public void prepareStatement() {
 		prepareStatementCount.getAndIncrement();
 	}
 	@Override
 	public long getCloseStatementCount() {
 		return closeStatementCount.get();
 	}
 	@Override
 	public long getPrepareStatementCount() {
 		return prepareStatementCount.get();
 	}
 	@Override
 	public void optimisticFailure(String entityName) {
 		optimisticFailureCount.getAndIncrement();
 		( (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName ) ).incrementOptimisticFailureCount();
 	}
 	@Override
 	public long getOptimisticFailureCount() {
 		return optimisticFailureCount.get();
 	}
 
 	@Override
     public String toString() {
 		return new StringBuilder()
 				.append( "Statistics[" )
 				.append( "start time=" ).append( startTime )
 				.append( ",sessions opened=" ).append( sessionOpenCount )
 				.append( ",sessions closed=" ).append( sessionCloseCount )
 				.append( ",transactions=" ).append( transactionCount )
 				.append( ",successful transactions=" ).append( committedTransactionCount )
 				.append( ",optimistic lock failures=" ).append( optimisticFailureCount )
 				.append( ",flushes=" ).append( flushCount )
 				.append( ",connections obtained=" ).append( connectCount )
 				.append( ",statements prepared=" ).append( prepareStatementCount )
 				.append( ",statements closed=" ).append( closeStatementCount )
 				.append( ",second level cache puts=" ).append( secondLevelCachePutCount )
 				.append( ",second level cache hits=" ).append( secondLevelCacheHitCount )
 				.append( ",second level cache misses=" ).append( secondLevelCacheMissCount )
 				.append( ",entities loaded=" ).append( entityLoadCount )
 				.append( ",entities updated=" ).append( entityUpdateCount )
 				.append( ",entities inserted=" ).append( entityInsertCount )
 				.append( ",entities deleted=" ).append( entityDeleteCount )
 				.append( ",entities fetched=" ).append( entityFetchCount )
 				.append( ",collections loaded=" ).append( collectionLoadCount )
 				.append( ",collections updated=" ).append( collectionUpdateCount )
 				.append( ",collections removed=" ).append( collectionRemoveCount )
 				.append( ",collections recreated=" ).append( collectionRecreateCount )
 				.append( ",collections fetched=" ).append( collectionFetchCount )
 				.append( ",naturalId queries executed to database=" ).append( naturalIdQueryExecutionCount )
 				.append( ",naturalId cache puts=" ).append( naturalIdCachePutCount )
 				.append( ",naturalId cache hits=" ).append( naturalIdCacheHitCount )
 				.append( ",naturalId cache misses=" ).append( naturalIdCacheMissCount )
 				.append( ",naturalId max query time=" ).append( naturalIdQueryExecutionMaxTime )
 				.append( ",queries executed to database=" ).append( queryExecutionCount )
 				.append( ",query cache puts=" ).append( queryCachePutCount )
 				.append( ",query cache hits=" ).append( queryCacheHitCount )
 				.append( ",query cache misses=" ).append( queryCacheMissCount )
 				.append(",update timestamps cache puts=").append(updateTimestampsCachePutCount)
 				.append(",update timestamps cache hits=").append(updateTimestampsCacheHitCount)
 				.append(",update timestamps cache misses=").append(updateTimestampsCacheMissCount)
 				.append( ",max query time=" ).append( queryExecutionMaxTime )
 				.append( ']' )
 				.toString();
 	}
 	@Override
 	public String getQueryExecutionMaxTimeQueryString() {
 		return queryExecutionMaxTimeQueryString;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/ImportSqlCommandExtractorInitiator.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/ImportSqlCommandExtractorInitiator.java
index 6bb8c4736a..0e28c26faa 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/ImportSqlCommandExtractorInitiator.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/ImportSqlCommandExtractorInitiator.java
@@ -1,48 +1,49 @@
 package org.hibernate.tool.hbm2ddl;
 
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.boot.registry.StandardServiceInitiator;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.cfg.Environment;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 
 /**
  * Instantiates and configures an appropriate {@link ImportSqlCommandExtractor}. By default
  * {@link SingleLineSqlCommandExtractor} is used.
  *
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public class ImportSqlCommandExtractorInitiator implements StandardServiceInitiator<ImportSqlCommandExtractor> {
 	public static final ImportSqlCommandExtractorInitiator INSTANCE = new ImportSqlCommandExtractorInitiator();
 	public static final ImportSqlCommandExtractor DEFAULT_EXTRACTOR = new SingleLineSqlCommandExtractor();
 
 	@Override
 	public ImportSqlCommandExtractor initiateService(Map configurationValues, ServiceRegistryImplementor registry) {
 		String extractorClassName = (String) configurationValues.get( Environment.HBM2DDL_IMPORT_FILES_SQL_EXTRACTOR );
 		if ( StringHelper.isEmpty( extractorClassName ) ) {
 			return DEFAULT_EXTRACTOR;
 		}
 		final ClassLoaderService classLoaderService = registry.getService( ClassLoaderService.class );
 		return instantiateExplicitCommandExtractor( extractorClassName, classLoaderService );
 	}
 
-	private ImportSqlCommandExtractor instantiateExplicitCommandExtractor(String extractorClassName,
-																		  ClassLoaderService classLoaderService) {
+	private ImportSqlCommandExtractor instantiateExplicitCommandExtractor(
+			String extractorClassName,
+			ClassLoaderService classLoaderService) {
 		try {
 			return (ImportSqlCommandExtractor) classLoaderService.classForName( extractorClassName ).newInstance();
 		}
-		catch ( Exception e ) {
+		catch (Exception e) {
 			throw new HibernateException(
 					"Could not instantiate import sql command extractor [" + extractorClassName + "]", e
 			);
 		}
 	}
 
 	@Override
 	public Class<ImportSqlCommandExtractor> getServiceInitiated() {
 		return ImportSqlCommandExtractor.class;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExport.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExport.java
index acc93ca3f0..063195065c 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExport.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExport.java
@@ -1,747 +1,760 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.io.BufferedReader;
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.io.Reader;
 import java.sql.Connection;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.boot.MetadataBuilder;
 import org.hibernate.boot.MetadataSources;
 import org.hibernate.boot.model.naming.ImplicitNamingStrategy;
 import org.hibernate.boot.model.naming.PhysicalNamingStrategy;
 import org.hibernate.boot.registry.BootstrapServiceRegistry;
 import org.hibernate.boot.registry.BootstrapServiceRegistryBuilder;
 import org.hibernate.boot.registry.StandardServiceRegistry;
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.boot.registry.selector.spi.StrategySelector;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.engine.config.spi.ConfigurationService;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.jdbc.internal.FormatStyle;
 import org.hibernate.engine.jdbc.internal.Formatter;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.log.DeprecationLogger;
 import org.hibernate.internal.util.ConfigHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.tool.schema.spi.SchemaManagementTool;
 
 /**
  * Commandline tool to export table schema to the database. This class may also be called from inside an application.
  *
  * @author Daniel Bradby
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class SchemaExport {
-    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( SchemaExport.class );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( SchemaExport.class );
 
 	private static final String DEFAULT_IMPORT_FILE = "/import.sql";
 
 	public static enum Type {
 		CREATE,
 		DROP,
 		NONE,
 		BOTH;
 
 		public boolean doCreate() {
 			return this == BOTH || this == CREATE;
 		}
 
 		public boolean doDrop() {
 			return this == BOTH || this == DROP;
 		}
 	}
 
 	private final ConnectionHelper connectionHelper;
 	private final SqlStatementLogger sqlStatementLogger;
 	private final SqlExceptionHelper sqlExceptionHelper;
 	private final String[] dropSQL;
 	private final String[] createSQL;
 	private final String importFiles;
 
 	private final List<Exception> exceptions = new ArrayList<Exception>();
 
 	private Formatter formatter;
 	private ImportSqlCommandExtractor importSqlCommandExtractor = ImportSqlCommandExtractorInitiator.DEFAULT_EXTRACTOR;
 
 	private String outputFile;
 	private String delimiter;
 	private boolean haltOnError;
 
 	/**
 	 * Builds a SchemaExport object.
 	 *
 	 * @param metadata The metadata object holding the mapping info to be exported
 	 */
 	public SchemaExport(MetadataImplementor metadata) {
 		this( metadata.getMetadataBuildingOptions().getServiceRegistry(), metadata );
 	}
 
 	/**
 	 * Builds a SchemaExport object.
 	 *
 	 * @param metadata The metadata object holding the mapping info to be exported
 	 */
 	public SchemaExport(MetadataImplementor metadata, boolean exportSchemas) {
 		this( metadata.getMetadataBuildingOptions().getServiceRegistry(), metadata, exportSchemas );
 	}
 
 	/**
 	 * Builds a SchemaExport object.
 	 *
 	 * @param serviceRegistry The registry of services available for use.  Should, at a minimum, contain
 	 * the JdbcServices service.
 	 * @param metadata The metadata object holding the mapping info to be exported
 	 */
 	public SchemaExport(ServiceRegistry serviceRegistry, MetadataImplementor metadata) {
 		this(
 				new SuppliedConnectionProviderConnectionHelper(
 						serviceRegistry.getService( ConnectionProvider.class )
 				),
 				serviceRegistry,
 				metadata,
 				false
 		);
 	}
 
 	/**
 	 * Builds a SchemaExport object.
 	 *
 	 * @param serviceRegistry The registry of services available for use.  Should, at a minimum, contain
 	 * the JdbcServices service.
 	 * @param metadata The metadata object holding the mapping info to be exported
 	 */
 	public SchemaExport(ServiceRegistry serviceRegistry, MetadataImplementor metadata, boolean exportSchemas) {
 		this(
 				new SuppliedConnectionProviderConnectionHelper(
 						serviceRegistry.getService( ConnectionProvider.class )
 				),
 				serviceRegistry,
 				metadata,
 				exportSchemas
 		);
 	}
 
 	private SchemaExport(
 			ConnectionHelper connectionHelper,
 			ServiceRegistry serviceRegistry,
 			MetadataImplementor metadata,
 			boolean exportSchemas) {
 		this.connectionHelper = connectionHelper;
 		this.sqlStatementLogger = serviceRegistry.getService( JdbcServices.class ).getSqlStatementLogger();
 		this.formatter = ( sqlStatementLogger.isFormat() ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
 		this.sqlExceptionHelper = serviceRegistry.getService( JdbcEnvironment.class ).getSqlExceptionHelper();
 
 		this.importFiles = ConfigurationHelper.getString(
 				AvailableSettings.HBM2DDL_IMPORT_FILES,
 				serviceRegistry.getService( ConfigurationService.class ).getSettings(),
 				DEFAULT_IMPORT_FILE
 		);
 
 		// uses the schema management tool service to generate the create/drop scripts
 		// longer term this class should instead just leverage the tool for its execution phase.
 		// That is part of the larger task to consolidate Hibernate and JPA schema management
 
 		SchemaManagementTool schemaManagementTool = serviceRegistry.getService( SchemaManagementTool.class );
 		final List<String> commands = new ArrayList<String>();
 		final org.hibernate.tool.schema.spi.Target target = new org.hibernate.tool.schema.spi.Target() {
 			@Override
 			public boolean acceptsImportScriptActions() {
 				return false;
 			}
 
 			@Override
 			public void prepare() {
 				commands.clear();
 			}
 
 			@Override
 			public void accept(String command) {
 				commands.add( command );
 			}
 
 			@Override
 			public void release() {
 			}
 		};
 
 		final Map settings = serviceRegistry.getService( ConfigurationService.class ).getSettings();
 
 		schemaManagementTool.getSchemaDropper( settings ).doDrop( metadata, exportSchemas, target );
 		this.dropSQL = commands.toArray( new String[commands.size()] );
 
 		schemaManagementTool.getSchemaCreator( settings ).doCreation( metadata, exportSchemas, target );
 		this.createSQL = commands.toArray( new String[commands.size()] );
 	}
 
 	/**
 	 * Intended for testing use
 	 *
 	 * @param connectionHelper Access to the JDBC Connection
 	 * @param metadata The metadata object holding the mapping info to be exported
 	 */
 	public SchemaExport(
 			ConnectionHelper connectionHelper,
 			MetadataImplementor metadata) {
 		this(
 				connectionHelper,
 				metadata.getMetadataBuildingOptions().getServiceRegistry(),
 				metadata,
 				false
 		);
 	}
 
 	/**
 	 * Create a SchemaExport for the given Metadata, using the supplied connection for connectivity.
 	 *
 	 * @param metadata The metadata object holding the mapping info to be exported
 	 * @param connection The JDBC connection to use.
+	 *
 	 * @throws HibernateException Indicates problem preparing for schema export.
 	 */
 	public SchemaExport(MetadataImplementor metadata, Connection connection) throws HibernateException {
 		this( new SuppliedConnectionHelper( connection ), metadata );
 	}
 
 	/**
 	 * @deprecated Use one of the forms accepting {@link MetadataImplementor}, rather
 	 * than {@link Configuration}, instead.
 	 */
 	@Deprecated
 	public SchemaExport(ServiceRegistry serviceRegistry, Configuration configuration) {
 		throw new UnsupportedOperationException(
 				"Attempt to use unsupported SchemaExport constructor accepting org.hibernate.cfg.Configuration; " +
 						"one of the forms accepting org.hibernate.boot.spi.MetadataImplementor should be used instead"
 		);
 	}
 
 	/**
 	 * @deprecated Use one of the forms accepting {@link MetadataImplementor}, rather
 	 * than {@link Configuration}, instead.
 	 */
 	@Deprecated
 	public SchemaExport(Configuration configuration) {
 		throw new UnsupportedOperationException(
 				"Attempt to use unsupported SchemaExport constructor accepting org.hibernate.cfg.Configuration; " +
 						"one of the forms accepting org.hibernate.boot.spi.MetadataImplementor should be used instead"
 		);
 	}
 
 	/**
 	 * @deprecated Use one of the forms accepting {@link MetadataImplementor}, rather
 	 * than {@link Configuration}, instead.
 	 */
 	@Deprecated
 	public SchemaExport(Configuration configuration, Connection connection) throws HibernateException {
 		throw new UnsupportedOperationException(
 				"Attempt to use unsupported SchemaExport constructor accepting org.hibernate.cfg.Configuration; " +
 						"one of the forms accepting org.hibernate.boot.spi.MetadataImplementor should be used instead"
 		);
 	}
 
 	public SchemaExport(
 			ConnectionHelper connectionHelper,
 			String[] dropSql,
 			String[] createSql) {
 		this.connectionHelper = connectionHelper;
 		this.dropSQL = dropSql;
 		this.createSQL = createSql;
 		this.importFiles = "";
 		this.sqlStatementLogger = new SqlStatementLogger( false, true );
 		this.sqlExceptionHelper = new SqlExceptionHelper();
 		this.formatter = FormatStyle.DDL.getFormatter();
 	}
 
 	/**
 	 * For generating a export script file, this is the file which will be written.
 	 *
 	 * @param filename The name of the file to which to write the export script.
+	 *
 	 * @return this
 	 */
 	public SchemaExport setOutputFile(String filename) {
 		outputFile = filename;
 		return this;
 	}
 
 	/**
 	 * Set the end of statement delimiter
 	 *
 	 * @param delimiter The delimiter
+	 *
 	 * @return this
 	 */
 	public SchemaExport setDelimiter(String delimiter) {
 		this.delimiter = delimiter;
 		return this;
 	}
 
 	/**
 	 * Should we format the sql strings?
 	 *
 	 * @param format Should we format SQL strings
+	 *
 	 * @return this
 	 */
 	public SchemaExport setFormat(boolean format) {
 		this.formatter = ( format ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
 		return this;
 	}
 
 	/**
 	 * Set <i>import.sql</i> command extractor. By default {@link SingleLineSqlCommandExtractor} is used.
 	 *
 	 * @param importSqlCommandExtractor <i>import.sql</i> command extractor.
+	 *
 	 * @return this
 	 */
 	public SchemaExport setImportSqlCommandExtractor(ImportSqlCommandExtractor importSqlCommandExtractor) {
 		this.importSqlCommandExtractor = importSqlCommandExtractor;
 		return this;
 	}
 
 	/**
 	 * Should we stop once an error occurs?
 	 *
 	 * @param haltOnError True if export should stop after error.
+	 *
 	 * @return this
 	 */
 	public SchemaExport setHaltOnError(boolean haltOnError) {
 		this.haltOnError = haltOnError;
 		return this;
 	}
 
 	/**
 	 * Run the schema creation script; drop script is automatically
 	 * executed before running the creation script.
 	 *
 	 * @param script print the DDL to the console
 	 * @param export export the script to the database
 	 */
 	public void create(boolean script, boolean export) {
 		create( Target.interpret( script, export ) );
 	}
 
 	/**
 	 * Run the schema creation script; drop script is automatically
 	 * executed before running the creation script.
 	 *
 	 * @param output the target of the script.
 	 */
 	public void create(Target output) {
 		// need to drop tables before creating so need to specify Type.BOTH
 		execute( output, Type.BOTH );
 	}
 
 	/**
 	 * Run the drop schema script.
 	 *
 	 * @param script print the DDL to the console
 	 * @param export export the script to the database
 	 */
 	public void drop(boolean script, boolean export) {
 		drop( Target.interpret( script, export ) );
 	}
 
 	public void drop(Target output) {
 		execute( output, Type.DROP );
 	}
 
 	public void execute(boolean script, boolean export, boolean justDrop, boolean justCreate) {
 		execute( Target.interpret( script, export ), interpretType( justDrop, justCreate ) );
 	}
 
 	private Type interpretType(boolean justDrop, boolean justCreate) {
 		if ( justDrop ) {
 			return Type.DROP;
 		}
 		else if ( justCreate ) {
 			return Type.CREATE;
 		}
 		else {
 			return Type.BOTH;
 		}
 	}
 
 	public void execute(Target output, Type type) {
-		if ( (outputFile == null && output == Target.NONE) || type == SchemaExport.Type.NONE ) {
+		if ( ( outputFile == null && output == Target.NONE ) || type == SchemaExport.Type.NONE ) {
 			return;
 		}
 		exceptions.clear();
 
 		LOG.runningHbm2ddlSchemaExport();
 
 		final List<NamedReader> importFileReaders = new ArrayList<NamedReader>();
-		for ( String currentFile : importFiles.split(",") ) {
+		for ( String currentFile : importFiles.split( "," ) ) {
 			try {
 				final String resourceName = currentFile.trim();
 				InputStream stream = ConfigHelper.getResourceAsStream( resourceName );
 				importFileReaders.add( new NamedReader( resourceName, stream ) );
 			}
-			catch ( HibernateException e ) {
-				LOG.debugf("Import file not found: %s", currentFile);
+			catch (HibernateException e) {
+				LOG.debugf( "Import file not found: %s", currentFile );
 			}
 		}
 
 		final List<Exporter> exporters = new ArrayList<Exporter>();
 		try {
 			// prepare exporters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 			if ( output.doScript() ) {
 				exporters.add( new ScriptExporter() );
 			}
 			if ( outputFile != null ) {
 				exporters.add( new FileExporter( outputFile ) );
 			}
 			if ( output.doExport() ) {
 				exporters.add( new DatabaseExporter( connectionHelper, sqlExceptionHelper ) );
 			}
 
 			// perform exporters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 			if ( type.doDrop() ) {
 				perform( dropSQL, exporters );
 			}
 			if ( type.doCreate() ) {
 				perform( createSQL, exporters );
-				if ( ! importFileReaders.isEmpty() ) {
+				if ( !importFileReaders.isEmpty() ) {
 					for ( NamedReader namedReader : importFileReaders ) {
 						importScript( namedReader, exporters );
 					}
 				}
 			}
 		}
 		catch (Exception e) {
 			exceptions.add( e );
 			LOG.schemaExportUnsuccessful( e );
 		}
 		finally {
 			// release exporters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 			for ( Exporter exporter : exporters ) {
 				try {
 					exporter.release();
 				}
 				catch (Exception ignore) {
 				}
 			}
 
 			// release the named readers from import scripts
 			for ( NamedReader namedReader : importFileReaders ) {
 				try {
 					namedReader.getReader().close();
 				}
 				catch (Exception ignore) {
 				}
 			}
-            LOG.schemaExportComplete();
+			LOG.schemaExportComplete();
 		}
 	}
 
 	private void perform(String[] sqlCommands, List<Exporter> exporters) {
 		for ( String sqlCommand : sqlCommands ) {
 			String formatted = formatter.format( sqlCommand );
-	        if ( delimiter != null ) {
+			if ( delimiter != null ) {
 				formatted += delimiter;
 			}
 			sqlStatementLogger.logStatement( sqlCommand, formatter );
 			for ( Exporter exporter : exporters ) {
 				try {
 					exporter.export( formatted );
 				}
 				catch (Exception e) {
 					if ( haltOnError ) {
 						throw new HibernateException( "Error during DDL export", e );
 					}
 					exceptions.add( e );
 					LOG.unsuccessfulCreate( sqlCommand );
 					LOG.error( e.getMessage() );
 				}
 			}
 		}
 	}
 
 	private void importScript(NamedReader namedReader, List<Exporter> exporters) throws Exception {
 		BufferedReader reader = new BufferedReader( namedReader.getReader() );
 		String[] statements = importSqlCommandExtractor.extractCommands( reader );
-		if (statements != null) {
+		if ( statements != null ) {
 			for ( String statement : statements ) {
 				if ( statement != null ) {
 					String trimmedSql = statement.trim();
-					if ( trimmedSql.endsWith( ";" )) {
+					if ( trimmedSql.endsWith( ";" ) ) {
 						trimmedSql = trimmedSql.substring( 0, statement.length() - 1 );
 					}
 					if ( !StringHelper.isEmpty( trimmedSql ) ) {
 						try {
 							for ( Exporter exporter : exporters ) {
 								if ( exporter.acceptsImportScripts() ) {
 									exporter.export( trimmedSql );
 								}
 							}
 						}
-						catch ( Exception e ) {
-						  	if (haltOnError) {
-						  		throw new ImportScriptException( "Error during statement execution (file: '"
-						  				+ namedReader.getName() + "'): " + trimmedSql, e );
+						catch (Exception e) {
+							if ( haltOnError ) {
+								throw new ImportScriptException(
+										"Error during statement execution (file: '"
+												+ namedReader.getName() + "'): " + trimmedSql, e
+								);
 							}
-						  	exceptions.add(e);
-						  	LOG.unsuccessful(trimmedSql);
-						  	LOG.error(e.getMessage());
+							exceptions.add( e );
+							LOG.unsuccessful( trimmedSql );
+							LOG.error( e.getMessage() );
 						}
 					}
 				}
 			}
 		}
 	}
 
 	private static class NamedReader {
 		private final Reader reader;
 		private final String name;
 
 		public NamedReader(String name, InputStream stream) {
 			this.name = name;
 			this.reader = new InputStreamReader( stream );
 		}
 
 		public Reader getReader() {
 			return reader;
 		}
 
 		public String getName() {
 			return name;
 		}
 	}
 
 	public static void main(String[] args) {
 		try {
 			final CommandLineArgs commandLineArgs = CommandLineArgs.parseCommandLineArgs( args );
 			StandardServiceRegistry serviceRegistry = buildStandardServiceRegistry( commandLineArgs );
 			try {
 				final MetadataImplementor metadata = buildMetadata( commandLineArgs, serviceRegistry );
 
 				SchemaExport schemaExport = new SchemaExport( serviceRegistry, metadata, commandLineArgs.exportSchemas )
 						.setHaltOnError( commandLineArgs.halt )
 						.setOutputFile( commandLineArgs.outputFile )
 						.setDelimiter( commandLineArgs.delimiter )
 						.setImportSqlCommandExtractor( serviceRegistry.getService( ImportSqlCommandExtractor.class ) )
 						.setFormat( commandLineArgs.format );
-				schemaExport.execute( commandLineArgs.script, commandLineArgs.export, commandLineArgs.drop, commandLineArgs.create );
+				schemaExport.execute(
+						commandLineArgs.script,
+						commandLineArgs.export,
+						commandLineArgs.drop,
+						commandLineArgs.create
+				);
 			}
 			finally {
 				StandardServiceRegistryBuilder.destroy( serviceRegistry );
 			}
 		}
-		catch ( Exception e ) {
-            LOG.unableToCreateSchema( e );
+		catch (Exception e) {
+			LOG.unableToCreateSchema( e );
 			e.printStackTrace();
 		}
 	}
 
 	private static StandardServiceRegistry buildStandardServiceRegistry(CommandLineArgs commandLineArgs)
 			throws Exception {
 		final BootstrapServiceRegistry bsr = new BootstrapServiceRegistryBuilder().build();
 		final StandardServiceRegistryBuilder ssrBuilder = new StandardServiceRegistryBuilder( bsr );
 
 		if ( commandLineArgs.cfgXmlFile != null ) {
 			ssrBuilder.configure( commandLineArgs.cfgXmlFile );
 		}
 
 		Properties properties = new Properties();
 		if ( commandLineArgs.propertiesFile != null ) {
 			properties.load( new FileInputStream( commandLineArgs.propertiesFile ) );
 		}
 		ssrBuilder.applySettings( properties );
 
 		if ( commandLineArgs.importFile != null ) {
 			ssrBuilder.applySetting( AvailableSettings.HBM2DDL_IMPORT_FILES, commandLineArgs.importFile );
 		}
 
 		return ssrBuilder.build();
 	}
 
 	private static MetadataImplementor buildMetadata(
 			CommandLineArgs parsedArgs,
 			StandardServiceRegistry serviceRegistry) throws Exception {
 		final MetadataSources metadataSources = new MetadataSources( serviceRegistry );
 
 		for ( String filename : parsedArgs.hbmXmlFiles ) {
 			metadataSources.addFile( filename );
 		}
 
 		for ( String filename : parsedArgs.jarFiles ) {
 			metadataSources.addJar( new File( filename ) );
 		}
 
 
 		final MetadataBuilder metadataBuilder = metadataSources.getMetadataBuilder();
 		final StrategySelector strategySelector = serviceRegistry.getService( StrategySelector.class );
 		if ( parsedArgs.implicitNamingStrategyImplName != null ) {
 			metadataBuilder.applyImplicitNamingStrategy(
 					strategySelector.resolveStrategy(
 							ImplicitNamingStrategy.class,
 							parsedArgs.implicitNamingStrategyImplName
 					)
 			);
 		}
 		if ( parsedArgs.physicalNamingStrategyImplName != null ) {
 			metadataBuilder.applyPhysicalNamingStrategy(
 					strategySelector.resolveStrategy(
 							PhysicalNamingStrategy.class,
 							parsedArgs.physicalNamingStrategyImplName
 					)
 			);
 		}
 
 		return (MetadataImplementor) metadataBuilder.build();
 	}
 
 	/**
 	 * Intended for test usage only.  Builds a Metadata using the same algorithm  as
 	 * {@link #main}
 	 *
 	 * @param args The "command line args"
 	 *
 	 * @return The built Metadata
 	 *
 	 * @throws Exception Problems building the Metadata
 	 */
 	public static MetadataImplementor buildMetadataFromMainArgs(String[] args) throws Exception {
 		final CommandLineArgs commandLineArgs = CommandLineArgs.parseCommandLineArgs( args );
 		StandardServiceRegistry serviceRegistry = buildStandardServiceRegistry( commandLineArgs );
 		try {
 			return buildMetadata( commandLineArgs, serviceRegistry );
 		}
 		finally {
 			StandardServiceRegistryBuilder.destroy( serviceRegistry );
 		}
 	}
 
 	/**
 	 * Returns a List of all Exceptions which occured during the export.
 	 *
 	 * @return A List containig the Exceptions occured during the export
 	 */
 	public List getExceptions() {
 		return exceptions;
 	}
 
 	private static class CommandLineArgs {
 		boolean script = true;
 		boolean drop = false;
 		boolean create = false;
 		boolean halt = false;
 		boolean export = true;
 		boolean format = false;
 
 		boolean exportSchemas = false;
 
 		String delimiter = null;
 
 		String outputFile = null;
 		String importFile = DEFAULT_IMPORT_FILE;
 
 		String propertiesFile = null;
 		String cfgXmlFile = null;
 		String implicitNamingStrategyImplName = null;
 		String physicalNamingStrategyImplName = null;
 
 		List<String> hbmXmlFiles = new ArrayList<String>();
 		List<String> jarFiles = new ArrayList<String>();
 
 		public static CommandLineArgs parseCommandLineArgs(String[] args) {
 			CommandLineArgs parsedArgs = new CommandLineArgs();
 
 			for ( String arg : args ) {
 				if ( arg.startsWith( "--" ) ) {
 					if ( arg.equals( "--quiet" ) ) {
 						parsedArgs.script = false;
 					}
 					else if ( arg.equals( "--drop" ) ) {
 						parsedArgs.drop = true;
 					}
 					else if ( arg.equals( "--create" ) ) {
 						parsedArgs.create = true;
 					}
 					else if ( arg.equals( "--schemas" ) ) {
 						parsedArgs.exportSchemas = true;
 					}
 					else if ( arg.equals( "--haltonerror" ) ) {
 						parsedArgs.halt = true;
 					}
 					else if ( arg.equals( "--text" ) ) {
 						parsedArgs.export = false;
 					}
 					else if ( arg.startsWith( "--output=" ) ) {
 						parsedArgs.outputFile = arg.substring( 9 );
 					}
 					else if ( arg.startsWith( "--import=" ) ) {
 						parsedArgs.importFile = arg.substring( 9 );
 					}
 					else if ( arg.startsWith( "--properties=" ) ) {
 						parsedArgs.propertiesFile = arg.substring( 13 );
 					}
 					else if ( arg.equals( "--format" ) ) {
 						parsedArgs.format = true;
 					}
 					else if ( arg.startsWith( "--delimiter=" ) ) {
 						parsedArgs.delimiter = arg.substring( 12 );
 					}
 					else if ( arg.startsWith( "--config=" ) ) {
 						parsedArgs.cfgXmlFile = arg.substring( 9 );
 					}
 					else if ( arg.startsWith( "--naming=" ) ) {
 						DeprecationLogger.DEPRECATION_LOGGER.logDeprecatedNamingStrategyArgument();
 					}
 					else if ( arg.startsWith( "--implicit-naming=" ) ) {
 						parsedArgs.implicitNamingStrategyImplName = arg.substring( 18 );
 					}
 					else if ( arg.startsWith( "--physical-naming=" ) ) {
 						parsedArgs.physicalNamingStrategyImplName = arg.substring( 18 );
 					}
 				}
 				else {
 					if ( arg.endsWith( ".jar" ) ) {
 						parsedArgs.jarFiles.add( arg );
 					}
 					else {
 						parsedArgs.hbmXmlFiles.add( arg );
 					}
 				}
 			}
 
 			return parsedArgs;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExportTask.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExportTask.java
index d3efb9140a..c7d8a6df0d 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExportTask.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExportTask.java
@@ -1,281 +1,281 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.io.File;
 import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.util.LinkedList;
 import java.util.List;
 
 import org.hibernate.HibernateException;
 import org.hibernate.boot.MetadataBuilder;
 import org.hibernate.boot.MetadataSources;
 import org.hibernate.boot.model.naming.ImplicitNamingStrategy;
 import org.hibernate.boot.model.naming.PhysicalNamingStrategy;
 import org.hibernate.boot.registry.BootstrapServiceRegistry;
 import org.hibernate.boot.registry.BootstrapServiceRegistryBuilder;
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.boot.registry.internal.StandardServiceRegistryImpl;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.internal.log.DeprecationLogger;
 import org.hibernate.internal.util.collections.ArrayHelper;
 
 import org.apache.tools.ant.BuildException;
 import org.apache.tools.ant.DirectoryScanner;
 import org.apache.tools.ant.Project;
 import org.apache.tools.ant.taskdefs.MatchingTask;
 import org.apache.tools.ant.types.FileSet;
 
 /**
  * An Ant task for <tt>SchemaExport</tt>.
  *
  * <pre>
  * &lt;taskdef name="schemaexport"
  *     classname="org.hibernate.tool.hbm2ddl.SchemaExportTask"
  *     classpathref="class.path"/&gt;
  *
  * &lt;schemaexport
  *     properties="${build.classes.dir}/hibernate.properties"
  *     quiet="no"
  *     text="no"
  *     drop="no"
  *     delimiter=";"
  *     output="${build.dir}/schema-export.sql"&gt;
  *     &lt;fileset dir="${build.classes.dir}"&gt;
  *         &lt;include name="*.hbm.xml"/&gt;
  *     &lt;/fileset&gt;
  * &lt;/schemaexport&gt;
  * </pre>
  *
  * @see SchemaExport
  * @author Rong C Ou
  */
 public class SchemaExportTask extends MatchingTask {
 	private List<FileSet> fileSets = new LinkedList<FileSet>();
 	private File propertiesFile;
 	private File configurationFile;
 	private File outputFile;
 	private boolean quiet;
 	private boolean text;
 	private boolean drop;
 	private boolean create;
 	private boolean haltOnError;
 	private String delimiter;
 	private String implicitNamingStrategy;
 	private String physicalNamingStrategy;
 
 	@SuppressWarnings("UnusedDeclaration")
 	public void addFileset(FileSet set) {
 		fileSets.add(set);
 	}
 
 	/**
 	 * Set a properties file
 	 * @param propertiesFile the properties file name
 	 */
 	public void setProperties(File propertiesFile) {
 		if ( !propertiesFile.exists() ) {
 			throw new BuildException("Properties file: " + propertiesFile + " does not exist.");
 	}
 
 		log("Using properties file " + propertiesFile, Project.MSG_DEBUG);
 		this.propertiesFile = propertiesFile;
 	}
 
 	/**
 	 * Set a <literal>.cfg.xml</literal> file, which will be
 	 * loaded as a resource, from the classpath
 	 * @param configurationFile the path to the resource
 	 */
 	public void setConfig(File configurationFile) {
 		this.configurationFile = configurationFile;
 	}
 
 	/**
 	 * Enable "quiet" mode. The schema will not be
 	 * written to standard out.
 	 * @param quiet true to enable quiet mode
 	 */
 	@SuppressWarnings("UnusedDeclaration")
 	public void setQuiet(boolean quiet) {
 		this.quiet = quiet;
 	}
 
 	/**
 	 * Enable "text-only" mode. The schema will not
 	 * be exported to the database.
 	 * @param text true to enable text-only mode
 	 */
 	public void setText(boolean text) {
 		this.text = text;
 	}
 
 	/**
 	 * Enable "drop" mode. Database objects will be
 	 * dropped but not recreated.
 	 * @param drop true to enable drop mode
 	 */
 	public void setDrop(boolean drop) {
 		this.drop = drop;
 	}
 
 	/**
 	 * Enable "create" mode. Database objects will be
 	 * created but not first dropped.
 	 * @param create true to enable create mode
 	 */
 	public void setCreate(boolean create) {
 		this.create = create;
 	}
 
 	/**
 	 * Set the end of statement delimiter for the generated script
 	 * @param delimiter the delimiter
 	 */
 	@SuppressWarnings("UnusedDeclaration")
 	public void setDelimiter(String delimiter) {
 		this.delimiter = delimiter;
 	}
 
 	/**
 	 * Set the script output file
 	 * @param outputFile the file name
 	 */
 	public void setOutput(File outputFile) {
 		this.outputFile = outputFile;
 	}
 
 	/**
 	 * @deprecated Use {@link #setImplicitNamingStrategy} or {@link #setPhysicalNamingStrategy}
 	 * instead
 	 */
 	@Deprecated
 	public void setNamingStrategy(String namingStrategy) {
 		DeprecationLogger.DEPRECATION_LOGGER.logDeprecatedNamingStrategyAntArgument();
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	public void setImplicitNamingStrategy(String implicitNamingStrategy) {
 		this.implicitNamingStrategy = implicitNamingStrategy;
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	public void setPhysicalNamingStrategy(String physicalNamingStrategy) {
 		this.physicalNamingStrategy = physicalNamingStrategy;
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	public void setHaltonerror(boolean haltOnError) {
 		this.haltOnError = haltOnError;
 	}
 
 	/**
 	 * Execute the task
 	 */
 	@Override
-    public void execute() throws BuildException {
+	public void execute() throws BuildException {
 		try {
 			buildSchemaExport().execute( !quiet, !text, drop, create );
 		}
 		catch (HibernateException e) {
 			throw new BuildException("Schema text failed: " + e.getMessage(), e);
 		}
 		catch (FileNotFoundException e) {
 			throw new BuildException("File not found: " + e.getMessage(), e);
 		}
 		catch (IOException e) {
 			throw new BuildException("IOException : " + e.getMessage(), e);
 		}
 		catch (Exception e) {
 			throw new BuildException(e);
 		}
 	}
 
 	private String[] getFiles() {
 		List<String> files = new LinkedList<String>();
 		for ( FileSet fileSet : fileSets ) {
 			final DirectoryScanner ds = fileSet.getDirectoryScanner( getProject() );
 			final String[] dsFiles = ds.getIncludedFiles();
 			for ( String dsFileName : dsFiles ) {
 				File f = new File( dsFileName );
 				if ( !f.isFile() ) {
 					f = new File( ds.getBasedir(), dsFileName );
 				}
 
 				files.add( f.getAbsolutePath() );
 			}
 		}
 
 		return ArrayHelper.toStringArray(files);
 	}
 
 	private SchemaExport buildSchemaExport() throws Exception {
 		final BootstrapServiceRegistry bsr = new BootstrapServiceRegistryBuilder().build();
 
 		final MetadataSources metadataSources = new MetadataSources( bsr );
 		final StandardServiceRegistryBuilder ssrBuilder = new StandardServiceRegistryBuilder( bsr );
 
 		if ( configurationFile != null ) {
 			ssrBuilder.configure( configurationFile );
 		}
 		if ( propertiesFile != null ) {
 			ssrBuilder.loadProperties( propertiesFile );
 		}
 		ssrBuilder.applySettings( getProject().getProperties() );
 
 		for ( String fileName : getFiles() ) {
 			if ( fileName.endsWith(".jar") ) {
 				metadataSources.addJar( new File( fileName ) );
 			}
 			else {
 				metadataSources.addFile( fileName );
 			}
 		}
 
 
 		final StandardServiceRegistryImpl ssr = (StandardServiceRegistryImpl) ssrBuilder.build();
 		final MetadataBuilder metadataBuilder = metadataSources.getMetadataBuilder( ssr );
 
 		ClassLoaderService classLoaderService = bsr.getService( ClassLoaderService.class );
 		if ( implicitNamingStrategy != null ) {
 			metadataBuilder.applyImplicitNamingStrategy(
 					(ImplicitNamingStrategy) classLoaderService.classForName( implicitNamingStrategy ).newInstance()
 			);
 		}
 		if ( physicalNamingStrategy != null ) {
 			metadataBuilder.applyPhysicalNamingStrategy(
 					(PhysicalNamingStrategy) classLoaderService.classForName( physicalNamingStrategy ).newInstance()
 			);
 		}
 
 		return new SchemaExport( (MetadataImplementor) metadataBuilder.build() )
 				.setHaltOnError( haltOnError )
 				.setOutputFile( outputFile.getPath() )
 				.setDelimiter( delimiter );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdate.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdate.java
index e151207227..bc5e99c359 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdate.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdate.java
@@ -1,343 +1,343 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.io.File;
 import java.io.FileInputStream;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.boot.MetadataBuilder;
 import org.hibernate.boot.MetadataSources;
 import org.hibernate.boot.model.naming.ImplicitNamingStrategy;
 import org.hibernate.boot.model.naming.PhysicalNamingStrategy;
 import org.hibernate.boot.registry.BootstrapServiceRegistry;
 import org.hibernate.boot.registry.BootstrapServiceRegistryBuilder;
 import org.hibernate.boot.registry.StandardServiceRegistry;
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.boot.registry.selector.spi.StrategySelector;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.engine.config.spi.ConfigurationService;
 import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.log.DeprecationLogger;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.tool.schema.extract.internal.legacy.DatabaseInformationImpl;
 import org.hibernate.tool.schema.extract.spi.DatabaseInformation;
 import org.hibernate.tool.schema.internal.TargetDatabaseImpl;
 import org.hibernate.tool.schema.internal.TargetFileImpl;
 import org.hibernate.tool.schema.internal.TargetStdoutImpl;
 import org.hibernate.tool.schema.spi.SchemaManagementTool;
 import org.hibernate.tool.schema.spi.SchemaMigrator;
 
 /**
  * A commandline tool to update a database schema. May also be called from inside an application.
  *
  * @author Christoph Sturm
  * @author Steve Ebersole
  */
 public class SchemaUpdate {
-    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( SchemaUpdate.class );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( SchemaUpdate.class );
 
 	private final MetadataImplementor metadata;
 	private final ServiceRegistry serviceRegistry;
 
 	private final JdbcConnectionAccess jdbcConnectionAccess;
 	private final List<Exception> exceptions = new ArrayList<Exception>();
 	private String outputFile;
 
 	/**
 	 * Creates a SchemaUpdate object.  This form is intended for use from tooling
 	 *
 	 * @param metadata The metadata defining the schema as it should be after update
 	 *
 	 * @throws HibernateException
 	 */
 	public SchemaUpdate(MetadataImplementor metadata) {
 		this( metadata.getMetadataBuildingOptions().getServiceRegistry(), metadata );
 	}
 
 	/**
 	 * Creates a SchemaUpdate object.  This form is intended for use from
 	 * {@code hibernate.hbm2ddl.auto} handling, generally from within the SessionFactory
 	 * ctor.
 	 * <p/>
 	 * Note that the passed ServiceRegistry is expected to be of type
 	 * {@link org.hibernate.service.spi.SessionFactoryServiceRegistry}, although
 	 * any ServiceRegistry type will work as long as it has access to the
 	 * {@link org.hibernate.engine.jdbc.spi.JdbcServices} service.
 	 *
 	 * @param serviceRegistry The ServiceRegistry to use.
 	 * @param metadata The metadata defining the schema as it should be after update
 	 *
 	 * @throws HibernateException
 	 */
 	public SchemaUpdate(ServiceRegistry serviceRegistry, MetadataImplementor metadata) throws HibernateException {
 		this.metadata = metadata;
 		this.serviceRegistry = serviceRegistry;
 		this.jdbcConnectionAccess = serviceRegistry.getService( JdbcServices.class ).getBootstrapJdbcConnectionAccess();
 	}
 
 	/**
 	 * Execute the schema updates
 	 *
 	 * @param script print all DDL to the console
 	 */
 	public void execute(boolean script, boolean doUpdate) {
 		execute( Target.interpret( script, doUpdate ) );
 	}
-	
+
 	public void execute(Target target) {
-        LOG.runningHbm2ddlSchemaUpdate();
+		LOG.runningHbm2ddlSchemaUpdate();
 
 		exceptions.clear();
 
 		List<org.hibernate.tool.schema.spi.Target> toolTargets = buildToolTargets( target );
 
 		final ConfigurationService cfgService = serviceRegistry.getService( ConfigurationService.class );
 		final SchemaMigrator schemaMigrator = serviceRegistry.getService( SchemaManagementTool.class )
 				.getSchemaMigrator( cfgService.getSettings() );
 
 		final JdbcServices jdbcServices = serviceRegistry.getService( JdbcServices.class );
 		final DatabaseInformation databaseInformation;
 		try {
 			databaseInformation = new DatabaseInformationImpl(
 					serviceRegistry,
 					serviceRegistry.getService( JdbcEnvironment.class ),
 					jdbcConnectionAccess,
 					metadata.getDatabase().getDefaultSchema().getPhysicalName().getCatalog(),
 					metadata.getDatabase().getDefaultSchema().getPhysicalName().getSchema()
 			);
 		}
 		catch (SQLException e) {
 			throw jdbcServices.getSqlExceptionHelper().convert(
 					e,
 					"Error creating DatabaseInformation for schema migration"
 			);
 		}
 
 		schemaMigrator.doMigration( metadata, databaseInformation, true, toolTargets );
 	}
 
 	private List<org.hibernate.tool.schema.spi.Target> buildToolTargets(Target target) {
 		List<org.hibernate.tool.schema.spi.Target> toolTargets = new ArrayList<org.hibernate.tool.schema.spi.Target>();
 
 		if ( target.doScript() ) {
 			toolTargets.add( new TargetStdoutImpl() );
 		}
 
 		if ( target.doExport() ) {
 			toolTargets.add( new TargetDatabaseImpl( jdbcConnectionAccess ) );
 		}
 
 		if ( outputFile != null ) {
 			LOG.writingGeneratedSchemaToFile( outputFile );
 			toolTargets.add( new TargetFileImpl( outputFile ) );
 		}
 
 		return toolTargets;
 	}
 
 	/**
 	 * Returns a List of all Exceptions which occured during the export.
 	 *
 	 * @return A List containig the Exceptions occured during the export
 	 */
 	public List getExceptions() {
 		return exceptions;
 	}
 
 	public void setHaltOnError(boolean haltOnError) {
 	}
 
 	public void setFormat(boolean format) {
 	}
 
 	public void setOutputFile(String outputFile) {
 		this.outputFile = outputFile;
 	}
 
 	public void setDelimiter(String delimiter) {
 	}
 
 	public static void main(String[] args) {
 		try {
 			final CommandLineArgs parsedArgs = CommandLineArgs.parseCommandLineArgs( args );
 			final StandardServiceRegistry serviceRegistry = buildStandardServiceRegistry( parsedArgs );
 
 			try {
 				final MetadataImplementor metadata = buildMetadata( parsedArgs, serviceRegistry );
 
 				final SchemaUpdate schemaUpdate = new SchemaUpdate( metadata );
 				schemaUpdate.setOutputFile( parsedArgs.outFile );
 				schemaUpdate.execute( parsedArgs.script, parsedArgs.doUpdate );
 			}
 			finally {
 				StandardServiceRegistryBuilder.destroy( serviceRegistry );
 			}
 		}
-		catch ( Exception e ) {
-			LOG.unableToRunSchemaUpdate(e);
+		catch (Exception e) {
+			LOG.unableToRunSchemaUpdate( e );
 			e.printStackTrace();
 		}
 	}
 
 	private static StandardServiceRegistry buildStandardServiceRegistry(CommandLineArgs parsedArgs) throws Exception {
 		final BootstrapServiceRegistry bsr = new BootstrapServiceRegistryBuilder().build();
 		final StandardServiceRegistryBuilder ssrBuilder = new StandardServiceRegistryBuilder( bsr );
 
 		if ( parsedArgs.cfgXmlFile != null ) {
 			ssrBuilder.configure( parsedArgs.cfgXmlFile );
 		}
 
 		if ( parsedArgs.propertiesFile != null ) {
 			Properties props = new Properties();
 			props.load( new FileInputStream( parsedArgs.propertiesFile ) );
 			ssrBuilder.applySettings( props );
 		}
 
 		return ssrBuilder.build();
 	}
 
 	private static MetadataImplementor buildMetadata(CommandLineArgs parsedArgs, ServiceRegistry serviceRegistry)
 			throws Exception {
 		final MetadataSources metadataSources = new MetadataSources( serviceRegistry );
 
 		for ( String filename : parsedArgs.hbmXmlFiles ) {
 			metadataSources.addFile( filename );
 		}
 
 		for ( String filename : parsedArgs.jarFiles ) {
 			metadataSources.addJar( new File( filename ) );
 		}
 
 
 		final MetadataBuilder metadataBuilder = metadataSources.getMetadataBuilder();
 		final StrategySelector strategySelector = serviceRegistry.getService( StrategySelector.class );
 		if ( parsedArgs.implicitNamingStrategyImplName != null ) {
 			metadataBuilder.applyImplicitNamingStrategy(
 					strategySelector.resolveStrategy(
 							ImplicitNamingStrategy.class,
 							parsedArgs.implicitNamingStrategyImplName
 					)
 			);
 		}
 		if ( parsedArgs.physicalNamingStrategyImplName != null ) {
 			metadataBuilder.applyPhysicalNamingStrategy(
 					strategySelector.resolveStrategy(
 							PhysicalNamingStrategy.class,
 							parsedArgs.physicalNamingStrategyImplName
 					)
 			);
 		}
 
 		return (MetadataImplementor) metadataBuilder.build();
 	}
 
 	private static class CommandLineArgs {
 		boolean script = true;
 		// If true then execute db updates, otherwise just generate and display updates
 		boolean doUpdate = true;
 
 		String propertiesFile = null;
 		String cfgXmlFile = null;
 		String outFile = null;
 
 		String implicitNamingStrategyImplName = null;
 		String physicalNamingStrategyImplName = null;
 
 		List<String> hbmXmlFiles = new ArrayList<String>();
 		List<String> jarFiles = new ArrayList<String>();
 
 		public static CommandLineArgs parseCommandLineArgs(String[] args) {
 			final CommandLineArgs parsedArgs = new CommandLineArgs();
 
 			for ( String arg : args ) {
 				if ( arg.startsWith( "--" ) ) {
 					if ( arg.equals( "--quiet" ) ) {
 						parsedArgs.script = false;
 					}
 					else if ( arg.startsWith( "--properties=" ) ) {
 						parsedArgs.propertiesFile = arg.substring( 13 );
 					}
 					else if ( arg.startsWith( "--config=" ) ) {
 						parsedArgs.cfgXmlFile = arg.substring( 9 );
 					}
 					else if ( arg.startsWith( "--text" ) ) {
 						parsedArgs.doUpdate = false;
 					}
 					else if ( arg.startsWith( "--output=" ) ) {
 						parsedArgs.outFile = arg.substring( 9 );
 					}
 					else if ( arg.startsWith( "--naming=" ) ) {
 						DeprecationLogger.DEPRECATION_LOGGER.logDeprecatedNamingStrategyArgument();
 					}
 					else if ( arg.startsWith( "--implicit-naming=" ) ) {
 						parsedArgs.implicitNamingStrategyImplName = arg.substring( 18 );
 					}
 					else if ( arg.startsWith( "--physical-naming=" ) ) {
 						parsedArgs.physicalNamingStrategyImplName = arg.substring( 18 );
 					}
 				}
 				else {
 					if ( arg.endsWith( ".jar" ) ) {
 						parsedArgs.jarFiles.add( arg );
 					}
 					else {
 						parsedArgs.hbmXmlFiles.add( arg );
 					}
 				}
 			}
 
 			return parsedArgs;
 		}
 	}
 
 	/**
 	 * Intended for test usage only.  Builds a Metadata using the same algorithm  as
 	 * {@link #main}
 	 *
 	 * @param args The "command line args"
 	 *
 	 * @return The built Metadata
 	 *
 	 * @throws Exception Problems building the Metadata
 	 */
 	public static MetadataImplementor buildMetadataFromMainArgs(String[] args) throws Exception {
 		final CommandLineArgs commandLineArgs = CommandLineArgs.parseCommandLineArgs( args );
 		StandardServiceRegistry serviceRegistry = buildStandardServiceRegistry( commandLineArgs );
 		try {
 			return buildMetadata( commandLineArgs, serviceRegistry );
 		}
 		finally {
 			StandardServiceRegistryBuilder.destroy( serviceRegistry );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdateTask.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdateTask.java
index f1fbf50cd4..ebcdaed38d 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdateTask.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdateTask.java
@@ -1,292 +1,298 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.boot.MetadataBuilder;
 import org.hibernate.boot.MetadataSources;
 import org.hibernate.boot.model.naming.ImplicitNamingStrategy;
 import org.hibernate.boot.model.naming.PhysicalNamingStrategy;
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.internal.log.DeprecationLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 
 import org.apache.tools.ant.BuildException;
 import org.apache.tools.ant.DirectoryScanner;
 import org.apache.tools.ant.Project;
 import org.apache.tools.ant.taskdefs.MatchingTask;
 import org.apache.tools.ant.types.FileSet;
 
 /**
  * An Ant task for <tt>SchemaUpdate</tt>.
- *
+ * <p/>
  * <pre>
  * &lt;taskdef name="schemaupdate"
  *     classname="org.hibernate.tool.hbm2ddl.SchemaUpdateTask"
  *     classpathref="class.path"/&gt;
  *
  * &lt;schemaupdate
  *     properties="${build.classes.dir}/hibernate.properties"
  *     quiet="no"
  *     &lt;fileset dir="${build.classes.dir}"&gt;
  *         &lt;include name="*.hbm.xml"/&gt;
  *     &lt;/fileset&gt;
  * &lt;/schemaupdate&gt;
  * </pre>
  *
- * @see SchemaUpdate
  * @author Rong C Ou, Gavin King
+ * @see SchemaUpdate
  */
 public class SchemaUpdateTask extends MatchingTask {
 	private List<FileSet> fileSets = new LinkedList<FileSet>();
 	private File propertiesFile;
 	private File configurationFile;
 	private File outputFile;
 	private boolean quiet;
 	private boolean text = true;
 	private boolean haltOnError;
 	private String delimiter;
 
 	private String implicitNamingStrategy = null;
 	private String physicalNamingStrategy = null;
-	
+
 	@SuppressWarnings("UnusedDeclaration")
 	public void addFileset(FileSet fileSet) {
 		fileSets.add( fileSet );
 	}
 
 	/**
 	 * Set a properties file
 	 *
 	 * @param propertiesFile the properties file name
 	 */
 	@SuppressWarnings("UnusedDeclaration")
 	public void setProperties(File propertiesFile) {
 		if ( !propertiesFile.exists() ) {
-			throw new BuildException("Properties file: " + propertiesFile + " does not exist.");
+			throw new BuildException( "Properties file: " + propertiesFile + " does not exist." );
 		}
 
-		log("Using properties file " + propertiesFile, Project.MSG_DEBUG);
+		log( "Using properties file " + propertiesFile, Project.MSG_DEBUG );
 		this.propertiesFile = propertiesFile;
 	}
 
 	/**
 	 * Set a {@code cfg.xml} file
 	 *
 	 * @param configurationFile the file name
 	 */
 	@SuppressWarnings("UnusedDeclaration")
 	public void setConfig(File configurationFile) {
 		this.configurationFile = configurationFile;
 	}
 
 	/**
-     * Enable "text-only" mode. The schema will not be updated in the database.
+	 * Enable "text-only" mode. The schema will not be updated in the database.
 	 *
 	 * @param text true to enable text-only mode
-     */
+	 */
 	@SuppressWarnings("UnusedDeclaration")
-    public void setText(boolean text) {
-        this.text = text;
-    }
+	public void setText(boolean text) {
+		this.text = text;
+	}
 
 	/**
 	 * Enable "quiet" mode. The schema will not be written to standard out.
 	 *
 	 * @param quiet true to enable quiet mode
 	 */
 	@SuppressWarnings("UnusedDeclaration")
 	public void setQuiet(boolean quiet) {
 		this.quiet = quiet;
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	public void setNamingStrategy(String namingStrategy) {
 		DeprecationLogger.DEPRECATION_LOGGER.logDeprecatedNamingStrategyAntArgument();
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	public void setImplicitNamingStrategy(String implicitNamingStrategy) {
 		this.implicitNamingStrategy = implicitNamingStrategy;
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	public void setPhysicalNamingStrategy(String physicalNamingStrategy) {
 		this.physicalNamingStrategy = physicalNamingStrategy;
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	public File getOutputFile() {
 		return outputFile;
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	public void setOutputFile(File outputFile) {
 		this.outputFile = outputFile;
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	public boolean isHaltOnError() {
 		return haltOnError;
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	public void setHaltOnError(boolean haltOnError) {
 		this.haltOnError = haltOnError;
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	public String getDelimiter() {
 		return delimiter;
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	public void setDelimiter(String delimiter) {
 		this.delimiter = delimiter;
 	}
 
 	/**
 	 * Execute the task
 	 */
 	@Override
-    public void execute() throws BuildException {
-		log("Running Hibernate Core SchemaUpdate.");
-		log("This is an Ant task supporting only mapping files, if you want to use annotations see http://tools.hibernate.org.");
+	public void execute() throws BuildException {
+		log( "Running Hibernate Core SchemaUpdate." );
+		log( "This is an Ant task supporting only mapping files, if you want to use annotations see http://tools.hibernate.org." );
 
 		try {
 			final StandardServiceRegistryBuilder ssrBuilder = new StandardServiceRegistryBuilder();
 			configure( ssrBuilder );
 
 			final MetadataSources metadataSources = new MetadataSources( ssrBuilder.build() );
 			configure( metadataSources );
 
 			final MetadataBuilder metadataBuilder = metadataSources.getMetadataBuilder();
 			configure( metadataBuilder );
 
 			final MetadataImplementor metadata = (MetadataImplementor) metadataBuilder.build();
 
 			final SchemaUpdate su = new SchemaUpdate( metadata );
 			su.setOutputFile( outputFile.getPath() );
 			su.setDelimiter( delimiter );
 			su.setHaltOnError( haltOnError );
 			su.execute( !quiet, !text );
 		}
 		catch (HibernateException e) {
-			throw new BuildException("Schema text failed: " + e.getMessage(), e);
+			throw new BuildException( "Schema text failed: " + e.getMessage(), e );
 		}
 		catch (FileNotFoundException e) {
-			throw new BuildException("File not found: " + e.getMessage(), e);
+			throw new BuildException( "File not found: " + e.getMessage(), e );
 		}
 		catch (IOException e) {
-			throw new BuildException("IOException : " + e.getMessage(), e);
+			throw new BuildException( "IOException : " + e.getMessage(), e );
 		}
 		catch (BuildException e) {
 			throw e;
 		}
 		catch (Exception e) {
-			throw new BuildException(e);
+			throw new BuildException( e );
 		}
 	}
 
 	private void configure(StandardServiceRegistryBuilder registryBuilder) throws IOException {
 		if ( configurationFile != null ) {
 			registryBuilder.configure( configurationFile );
 		}
 
 		Properties properties = new Properties();
 		if ( propertiesFile == null ) {
 			properties.putAll( getProject().getProperties() );
 		}
 		else {
 			properties.load( new FileInputStream( propertiesFile ) );
 		}
 
 		registryBuilder.applySettings( properties );
 	}
 
 	private void configure(MetadataSources metadataSources) {
 		for ( String filename : collectFiles() ) {
-			if ( filename.endsWith(".jar") ) {
+			if ( filename.endsWith( ".jar" ) ) {
 				metadataSources.addJar( new File( filename ) );
 			}
 			else {
 				metadataSources.addFile( filename );
 			}
 		}
 	}
 
 	private String[] collectFiles() {
 		List<String> files = new LinkedList<String>();
 		for ( FileSet fileSet : fileSets ) {
 			final DirectoryScanner ds = fileSet.getDirectoryScanner( getProject() );
 			final String[] dsFiles = ds.getIncludedFiles();
 			for ( String dsFileName : dsFiles ) {
 				File f = new File( dsFileName );
 				if ( !f.isFile() ) {
 					f = new File( ds.getBasedir(), dsFileName );
 				}
 
 				files.add( f.getAbsolutePath() );
 			}
 		}
 		return ArrayHelper.toStringArray( files );
 	}
 
 	@SuppressWarnings("deprecation")
 	private void configure(MetadataBuilder metadataBuilder) {
 		if ( implicitNamingStrategy != null ) {
 			try {
 				metadataBuilder.applyImplicitNamingStrategy(
 						(ImplicitNamingStrategy) ReflectHelper.classForName( implicitNamingStrategy ).newInstance()
 				);
 			}
 			catch (Exception e) {
-				throw new BuildException( "Unable to instantiate specified ImplicitNamingStrategy [" + implicitNamingStrategy + "]", e );
+				throw new BuildException(
+						"Unable to instantiate specified ImplicitNamingStrategy [" + implicitNamingStrategy + "]",
+						e
+				);
 			}
 		}
 
 		if ( physicalNamingStrategy != null ) {
 			try {
 				metadataBuilder.applyPhysicalNamingStrategy(
 						(PhysicalNamingStrategy) ReflectHelper.classForName( physicalNamingStrategy ).newInstance()
 				);
 			}
 			catch (Exception e) {
-				throw new BuildException( "Unable to instantiate specified PhysicalNamingStrategy [" + physicalNamingStrategy + "]", e );
+				throw new BuildException(
+						"Unable to instantiate specified PhysicalNamingStrategy [" + physicalNamingStrategy + "]",
+						e
+				);
 			}
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidator.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidator.java
index b8a8ccb9a3..e1123de108 100755
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidator.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidator.java
@@ -1,242 +1,242 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.io.File;
 import java.io.FileInputStream;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Properties;
 
 import org.hibernate.boot.MetadataBuilder;
 import org.hibernate.boot.MetadataSources;
 import org.hibernate.boot.model.naming.ImplicitNamingStrategy;
 import org.hibernate.boot.model.naming.PhysicalNamingStrategy;
 import org.hibernate.boot.registry.BootstrapServiceRegistry;
 import org.hibernate.boot.registry.BootstrapServiceRegistryBuilder;
 import org.hibernate.boot.registry.StandardServiceRegistry;
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.boot.registry.selector.spi.StrategySelector;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.engine.config.spi.ConfigurationService;
 import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.log.DeprecationLogger;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.tool.schema.extract.internal.legacy.DatabaseInformationImpl;
 import org.hibernate.tool.schema.extract.spi.DatabaseInformation;
 import org.hibernate.tool.schema.spi.SchemaManagementTool;
 
 import org.jboss.logging.Logger;
 
 /**
  * A commandline tool to update a database schema. May also be called from
  * inside an application.
  *
  * @author Christoph Sturm
  */
 public class SchemaValidator {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			SchemaValidator.class.getName()
 	);
 
 	private final ServiceRegistry serviceRegistry;
 	private final MetadataImplementor metadata;
 	private final JdbcConnectionAccess jdbcConnectionAccess;
 
 	public SchemaValidator(MetadataImplementor metadata) {
 		this( metadata.getMetadataBuildingOptions().getServiceRegistry(), metadata );
 	}
 
 	public SchemaValidator(ServiceRegistry serviceRegistry, MetadataImplementor metadata) {
 		this.serviceRegistry = serviceRegistry;
 		this.metadata = metadata;
 		this.jdbcConnectionAccess = serviceRegistry.getService( JdbcServices.class ).getBootstrapJdbcConnectionAccess();
 	}
 
 	/**
 	 * Perform the validations.
 	 */
 	public void validate() {
 		LOG.runningSchemaValidator();
 
 		final ConfigurationService cfgService = serviceRegistry.getService( ConfigurationService.class );
 		final JdbcServices jdbcServices = serviceRegistry.getService( JdbcServices.class );
 		final DatabaseInformation databaseInformation;
 		try {
 			databaseInformation = new DatabaseInformationImpl(
 					serviceRegistry,
 					serviceRegistry.getService( JdbcEnvironment.class ),
 					jdbcConnectionAccess,
 					metadata.getDatabase().getDefaultSchema().getPhysicalName().getCatalog(),
 					metadata.getDatabase().getDefaultSchema().getPhysicalName().getSchema()
 			);
 		}
 		catch (SQLException e) {
 			throw jdbcServices.getSqlExceptionHelper().convert(
 					e,
 					"Error creating DatabaseInformation for schema validation"
 			);
 		}
 
 		serviceRegistry.getService( SchemaManagementTool.class ).getSchemaValidator( cfgService.getSettings() )
 				.doValidation( metadata, databaseInformation );
 	}
 
 	public static void main(String[] args) {
 		try {
 			final CommandLineArgs parsedArgs = CommandLineArgs.parseCommandLineArgs( args );
 			final StandardServiceRegistry serviceRegistry = buildStandardServiceRegistry( parsedArgs );
 
 			try {
 				final MetadataImplementor metadata = buildMetadata( parsedArgs, serviceRegistry );
 				new SchemaValidator( serviceRegistry, metadata ).validate();
 			}
 			finally {
 				StandardServiceRegistryBuilder.destroy( serviceRegistry );
 			}
 		}
 		catch (Exception e) {
 			LOG.unableToRunSchemaUpdate( e );
 			e.printStackTrace();
 		}
 	}
 
 	private static class CommandLineArgs {
 		String implicitNamingStrategy = null;
 		String physicalNamingStrategy = null;
 
 		String propertiesFile = null;
 		String cfgXmlFile = null;
 		List<String> hbmXmlFiles = new ArrayList<String>();
 		List<String> jarFiles = new ArrayList<String>();
 
 		public static CommandLineArgs parseCommandLineArgs(String[] args) {
 			final CommandLineArgs parsedArgs = new CommandLineArgs();
 
 			for ( String arg : args ) {
 				if ( arg.startsWith( "--" ) ) {
 					if ( arg.startsWith( "--properties=" ) ) {
 						parsedArgs.propertiesFile = arg.substring( 13 );
 					}
 					else if ( arg.startsWith( "--config=" ) ) {
 						parsedArgs.cfgXmlFile = arg.substring( 9 );
 					}
 					else if ( arg.startsWith( "--naming=" ) ) {
 						DeprecationLogger.DEPRECATION_LOGGER.logDeprecatedNamingStrategyArgument();
 					}
 					else if ( arg.startsWith( "--implicit-naming=" ) ) {
 						parsedArgs.implicitNamingStrategy = arg.substring( 18 );
 					}
 					else if ( arg.startsWith( "--physical-naming=" ) ) {
 						parsedArgs.physicalNamingStrategy = arg.substring( 18 );
 					}
 				}
 				else {
 					if ( arg.endsWith( ".jar" ) ) {
 						parsedArgs.jarFiles.add( arg );
 					}
 					else {
 						parsedArgs.hbmXmlFiles.add( arg );
 					}
 				}
 			}
 
 			return parsedArgs;
 		}
 	}
 
 	private static StandardServiceRegistry buildStandardServiceRegistry(CommandLineArgs parsedArgs) throws Exception {
 		final BootstrapServiceRegistry bsr = new BootstrapServiceRegistryBuilder().build();
 		final StandardServiceRegistryBuilder ssrBuilder = new StandardServiceRegistryBuilder( bsr );
 
 		if ( parsedArgs.cfgXmlFile != null ) {
 			ssrBuilder.configure( parsedArgs.cfgXmlFile );
 		}
 
 		if ( parsedArgs.propertiesFile != null ) {
 			Properties properties = new Properties();
 			properties.load( new FileInputStream( parsedArgs.propertiesFile ) );
 			ssrBuilder.applySettings( properties );
 		}
 
 		return ssrBuilder.build();
 	}
 
 	private static MetadataImplementor buildMetadata(
 			CommandLineArgs parsedArgs,
 			StandardServiceRegistry serviceRegistry) throws Exception {
 
 		final MetadataSources metadataSources = new MetadataSources(serviceRegistry);
 
 		for ( String filename : parsedArgs.hbmXmlFiles ) {
 			metadataSources.addFile( filename );
 		}
 
 		for ( String filename : parsedArgs.jarFiles ) {
 			metadataSources.addJar( new File( filename ) );
 		}
 
 		final MetadataBuilder metadataBuilder = metadataSources.getMetadataBuilder();
 		final StrategySelector strategySelector = serviceRegistry.getService( StrategySelector.class );
 		if ( parsedArgs.implicitNamingStrategy != null ) {
 			metadataBuilder.applyImplicitNamingStrategy(
 					strategySelector.resolveStrategy( ImplicitNamingStrategy.class, parsedArgs.implicitNamingStrategy )
 			);
 		}
 		if ( parsedArgs.physicalNamingStrategy != null ) {
 			metadataBuilder.applyPhysicalNamingStrategy(
 					strategySelector.resolveStrategy( PhysicalNamingStrategy.class, parsedArgs.physicalNamingStrategy )
 			);
 		}
 
 		return (MetadataImplementor) metadataBuilder.build();
 
 	}
 
 	/**
 	 * Intended for test usage only.  Builds a Metadata using the same algorithm  as
 	 * {@link #main}
 	 *
 	 * @param args The "command line args"
 	 *
 	 * @return The built Metadata
 	 *
 	 * @throws Exception Problems building the Metadata
 	 */
 	public static MetadataImplementor buildMetadataFromMainArgs(String[] args) throws Exception {
 		final CommandLineArgs commandLineArgs = CommandLineArgs.parseCommandLineArgs( args );
 		StandardServiceRegistry serviceRegistry = buildStandardServiceRegistry( commandLineArgs );
 		try {
 			return buildMetadata( commandLineArgs, serviceRegistry );
 		}
 		finally {
 			StandardServiceRegistryBuilder.destroy( serviceRegistry );
 		}
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidatorTask.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidatorTask.java
index aadda53256..26527c483f 100755
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidatorTask.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidatorTask.java
@@ -1,231 +1,231 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.boot.MetadataBuilder;
 import org.hibernate.boot.MetadataSources;
 import org.hibernate.boot.model.naming.ImplicitNamingStrategy;
 import org.hibernate.boot.model.naming.PhysicalNamingStrategy;
 import org.hibernate.boot.registry.StandardServiceRegistry;
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.boot.registry.selector.spi.StrategySelector;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.internal.log.DeprecationLogger;
 import org.hibernate.internal.util.collections.ArrayHelper;
 
 import org.apache.tools.ant.BuildException;
 import org.apache.tools.ant.DirectoryScanner;
 import org.apache.tools.ant.Project;
 import org.apache.tools.ant.taskdefs.MatchingTask;
 import org.apache.tools.ant.types.FileSet;
 
 /**
  * An Ant task for <tt>SchemaUpdate</tt>.
  *
  * <pre>
  * &lt;taskdef name="schemavalidator"
  *     classname="org.hibernate.tool.hbm2ddl.SchemaValidatorTask"
  *     classpathref="class.path"/&gt;
  *
  * &lt;schemaupdate
  *     properties="${build.classes.dir}/hibernate.properties"
  *     &lt;fileset dir="${build.classes.dir}"&gt;
  *         &lt;include name="*.hbm.xml"/&gt;
  *     &lt;/fileset&gt;
  * &lt;/schemaupdate&gt;
  * </pre>
  *
  * @see SchemaValidator
  * @author Gavin King
  */
 public class SchemaValidatorTask extends MatchingTask {
 	private List<FileSet> fileSets = new LinkedList<FileSet>();
 
 	private File propertiesFile;
 	private File configurationFile;
 
 	private String implicitNamingStrategy = null;
 	private String physicalNamingStrategy = null;
 
 
 	@SuppressWarnings("UnusedDeclaration")
 	public void addFileset(FileSet fileSet) {
 		fileSets.add( fileSet );
 	}
 
 	/**
 	 * Set a properties file
 	 * @param propertiesFile the properties file name
 	 */
 	public void setProperties(File propertiesFile) {
 		if ( !propertiesFile.exists() ) {
 			throw new BuildException("Properties file [" + propertiesFile + "] does not exist.");
 		}
 
 		log( "Using properties file " + propertiesFile, Project.MSG_DEBUG );
 		this.propertiesFile = propertiesFile;
 	}
 
 	/**
 	 * Set a <literal>.cfg.xml</literal> file
 	 * @param configurationFile the file name
 	 */
 	public void setConfig(File configurationFile) {
 		if ( !configurationFile.exists() ) {
 			throw new BuildException("Configuration file [" + configurationFile + "] does not exist.");
 		}
 
 		log( "Using configuration file " + propertiesFile, Project.MSG_DEBUG );
 		this.configurationFile = configurationFile;
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	public void setNamingStrategy(String namingStrategy) {
 		DeprecationLogger.DEPRECATION_LOGGER.logDeprecatedNamingStrategyAntArgument();
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	public void setImplicitNamingStrategy(String implicitNamingStrategy) {
 		this.implicitNamingStrategy = implicitNamingStrategy;
 	}
 
 	@SuppressWarnings("UnusedDeclaration")
 	public void setPhysicalNamingStrategy(String physicalNamingStrategy) {
 		this.physicalNamingStrategy = physicalNamingStrategy;
 	}
 
 	/**
 	 * Execute the task
 	 */
 	@Override
-    public void execute() throws BuildException {
+	public void execute() throws BuildException {
 		try {
 			final StandardServiceRegistryBuilder ssrBuilder = new StandardServiceRegistryBuilder();
 			configure( ssrBuilder );
 
 			final StandardServiceRegistry ssr = ssrBuilder.build();
 
 			try {
 				final MetadataSources metadataSources = new MetadataSources( ssrBuilder.build() );
 				configure( metadataSources );
 
 				final MetadataBuilder metadataBuilder = metadataSources.getMetadataBuilder();
 				configure( metadataBuilder, ssr );
 
 				final MetadataImplementor metadata = (MetadataImplementor) metadataBuilder.build();
 
 				new SchemaValidator( ssr, metadata ).validate();
 			}
 			finally {
 				StandardServiceRegistryBuilder.destroy( ssr );
 			}
 		}
 		catch (HibernateException e) {
 			throw new BuildException("Schema text failed: " + e.getMessage(), e);
 		}
 		catch (FileNotFoundException e) {
 			throw new BuildException("File not found: " + e.getMessage(), e);
 		}
 		catch (IOException e) {
 			throw new BuildException("IOException : " + e.getMessage(), e);
 		}
 		catch (BuildException e) {
 			throw e;
 		}
 		catch (Exception e) {
 			throw new BuildException(e);
 		}
 	}
 	private void configure(StandardServiceRegistryBuilder registryBuilder) throws IOException {
 		if ( configurationFile != null ) {
 			registryBuilder.configure( configurationFile );
 		}
 
 		Properties properties = new Properties();
 		if ( propertiesFile == null ) {
 			properties.putAll( getProject().getProperties() );
 		}
 		else {
 			properties.load( new FileInputStream( propertiesFile ) );
 		}
 
 		registryBuilder.applySettings( properties );
 	}
 
 	private void configure(MetadataSources metadataSources) {
 		for ( String filename : collectFiles() ) {
 			if ( filename.endsWith(".jar") ) {
 				metadataSources.addJar( new File( filename ) );
 			}
 			else {
 				metadataSources.addFile( filename );
 			}
 		}
 	}
 
 	private String[] collectFiles() {
 		List<String> files = new ArrayList<String>();
 
 		for ( Object fileSet : fileSets ) {
 			final FileSet fs = (FileSet) fileSet;
 			final DirectoryScanner ds = fs.getDirectoryScanner( getProject() );
 
 			for ( String dsFile : ds.getIncludedFiles() ) {
 				File f = new File( dsFile );
 				if ( !f.isFile() ) {
 					f = new File( ds.getBasedir(), dsFile );
 				}
 				files.add( f.getAbsolutePath() );
 			}
 		}
 
 		return ArrayHelper.toStringArray( files );
 	}
 
 	@SuppressWarnings("deprecation")
 	private void configure(MetadataBuilder metadataBuilder, StandardServiceRegistry serviceRegistry) {
 		final StrategySelector strategySelector = serviceRegistry.getService( StrategySelector.class );
 		if ( implicitNamingStrategy != null ) {
 			metadataBuilder.applyImplicitNamingStrategy(
 					strategySelector.resolveStrategy( ImplicitNamingStrategy.class, implicitNamingStrategy )
 			);
 		}
 		if ( physicalNamingStrategy != null ) {
 			metadataBuilder.applyPhysicalNamingStrategy(
 					strategySelector.resolveStrategy( PhysicalNamingStrategy.class, physicalNamingStrategy )
 			);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/TableMetadata.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/TableMetadata.java
index 6b8e37efb9..723e922fe2 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/TableMetadata.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/TableMetadata.java
@@ -1,210 +1,207 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tool.hbm2ddl;
 
-import org.hibernate.internal.CoreMessageLogger;
-import org.hibernate.mapping.ForeignKey;
-import org.jboss.logging.Logger;
-
 import java.sql.DatabaseMetaData;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.HashMap;
-import java.util.Iterator;
 import java.util.Locale;
 import java.util.Map;
 
+import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.mapping.ForeignKey;
+
+import static org.hibernate.internal.CoreLogging.messageLogger;
+
 /**
  * JDBC table metadata
  *
  * @author Christoph Sturm
  * @author Max Rydahl Andersen
  */
 public class TableMetadata {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, TableMetadata.class.getName());
+	private static final CoreMessageLogger LOG = messageLogger( TableMetadata.class );
 
 	private final String catalog;
 	private final String schema;
 	private final String name;
-	private final Map columns = new HashMap();
-	private final Map foreignKeys = new HashMap();
-	private final Map indexes = new HashMap();
+	private final Map<String, ColumnMetadata> columns = new HashMap<String, ColumnMetadata>();
+	private final Map<String,ForeignKeyMetadata> foreignKeys = new HashMap<String,ForeignKeyMetadata>();
+	private final Map<String, IndexMetadata> indexes = new HashMap<String, IndexMetadata>();
 
 	TableMetadata(ResultSet rs, DatabaseMetaData meta, boolean extras) throws SQLException {
-		catalog = rs.getString("TABLE_CAT");
-		schema = rs.getString("TABLE_SCHEM");
-		name = rs.getString("TABLE_NAME");
-		initColumns(meta);
-		if (extras) {
-			initForeignKeys(meta);
-			initIndexes(meta);
+		catalog = rs.getString( "TABLE_CAT" );
+		schema = rs.getString( "TABLE_SCHEM" );
+		name = rs.getString( "TABLE_NAME" );
+		initColumns( meta );
+		if ( extras ) {
+			initForeignKeys( meta );
+			initIndexes( meta );
 		}
-		String cat = catalog==null ? "" : catalog + '.';
-		String schem = schema==null ? "" : schema + '.';
-        LOG.tableFound( cat + schem + name );
-        LOG.columns( columns.keySet() );
-		if (extras) {
-            LOG.foreignKeys( foreignKeys.keySet() );
-            LOG.indexes( indexes.keySet() );
+		String cat = catalog == null ? "" : catalog + '.';
+		String schem = schema == null ? "" : schema + '.';
+		LOG.tableFound( cat + schem + name );
+		LOG.columns( columns.keySet() );
+		if ( extras ) {
+			LOG.foreignKeys( foreignKeys.keySet() );
+			LOG.indexes( indexes.keySet() );
 		}
 	}
 
 	public String getName() {
 		return name;
 	}
 
 	public String getCatalog() {
 		return catalog;
 	}
 
 	public String getSchema() {
 		return schema;
 	}
 
 	@Override
-    public String toString() {
+	public String toString() {
 		return "TableMetadata(" + name + ')';
 	}
 
 	public ColumnMetadata getColumnMetadata(String columnName) {
-		return (ColumnMetadata) columns.get( columnName.toLowerCase(Locale.ROOT) );
+		return columns.get( columnName.toLowerCase( Locale.ROOT ) );
 	}
 
 	public ForeignKeyMetadata getForeignKeyMetadata(String keyName) {
-		return (ForeignKeyMetadata) foreignKeys.get( keyName.toLowerCase(Locale.ROOT) );
+		return foreignKeys.get( keyName.toLowerCase( Locale.ROOT ) );
 	}
 
 	public ForeignKeyMetadata getForeignKeyMetadata(ForeignKey fk) {
-		Iterator it = foreignKeys.values().iterator();
-		while ( it.hasNext() ) {
-			ForeignKeyMetadata existingFk = ( ForeignKeyMetadata ) it.next();
+		for ( ForeignKeyMetadata existingFk : foreignKeys.values() ) {
 			if ( existingFk.matches( fk ) ) {
 				return existingFk;
 			}
 		}
 		return null;
 	}
 
 	public IndexMetadata getIndexMetadata(String indexName) {
-		return (IndexMetadata) indexes.get( indexName.toLowerCase(Locale.ROOT) );
+		return indexes.get( indexName.toLowerCase( Locale.ROOT ) );
 	}
 
 	private void addForeignKey(ResultSet rs) throws SQLException {
-		String fk = rs.getString("FK_NAME");
+		String fk = rs.getString( "FK_NAME" );
 
-		if (fk == null) {
+		if ( fk == null ) {
 			return;
 		}
 
-		ForeignKeyMetadata info = getForeignKeyMetadata(fk);
-		if (info == null) {
-			info = new ForeignKeyMetadata(rs);
-			foreignKeys.put( info.getName().toLowerCase(Locale.ROOT), info );
+		ForeignKeyMetadata info = getForeignKeyMetadata( fk );
+		if ( info == null ) {
+			info = new ForeignKeyMetadata( rs );
+			foreignKeys.put( info.getName().toLowerCase( Locale.ROOT ), info );
 		}
 
 		info.addReference( rs );
 	}
 
 	private void addIndex(ResultSet rs) throws SQLException {
-		String index = rs.getString("INDEX_NAME");
+		String index = rs.getString( "INDEX_NAME" );
 
-		if (index == null) {
+		if ( index == null ) {
 			return;
 		}
 
-		IndexMetadata info = getIndexMetadata(index);
-		if (info == null) {
-			info = new IndexMetadata(rs);
-			indexes.put( info.getName().toLowerCase(Locale.ROOT), info );
+		IndexMetadata info = getIndexMetadata( index );
+		if ( info == null ) {
+			info = new IndexMetadata( rs );
+			indexes.put( info.getName().toLowerCase( Locale.ROOT ), info );
 		}
 
-		info.addColumn( getColumnMetadata( rs.getString("COLUMN_NAME") ) );
+		info.addColumn( getColumnMetadata( rs.getString( "COLUMN_NAME" ) ) );
 	}
 
 	public void addColumn(ResultSet rs) throws SQLException {
-		String column = rs.getString("COLUMN_NAME");
+		String column = rs.getString( "COLUMN_NAME" );
 
-		if (column==null) {
+		if ( column == null ) {
 			return;
 		}
 
-		if ( getColumnMetadata(column) == null ) {
-			ColumnMetadata info = new ColumnMetadata(rs);
-			columns.put( info.getName().toLowerCase(Locale.ROOT), info );
+		if ( getColumnMetadata( column ) == null ) {
+			ColumnMetadata info = new ColumnMetadata( rs );
+			columns.put( info.getName().toLowerCase( Locale.ROOT ), info );
 		}
 	}
 
 	private void initForeignKeys(DatabaseMetaData meta) throws SQLException {
 		ResultSet rs = null;
 
 		try {
-			rs = meta.getImportedKeys(catalog, schema, name);
+			rs = meta.getImportedKeys( catalog, schema, name );
 			while ( rs.next() ) {
-				addForeignKey(rs);
+				addForeignKey( rs );
 			}
 		}
 		finally {
-			if (rs != null) {
+			if ( rs != null ) {
 				rs.close();
 			}
 		}
 	}
 
 	private void initIndexes(DatabaseMetaData meta) throws SQLException {
 		ResultSet rs = null;
 
 		try {
-			rs = meta.getIndexInfo(catalog, schema, name, false, true);
+			rs = meta.getIndexInfo( catalog, schema, name, false, true );
 
 			while ( rs.next() ) {
-				if ( rs.getShort("TYPE") == DatabaseMetaData.tableIndexStatistic ) {
+				if ( rs.getShort( "TYPE" ) == DatabaseMetaData.tableIndexStatistic ) {
 					continue;
 				}
-				addIndex(rs);
+				addIndex( rs );
 			}
 		}
 		finally {
-			if (rs != null) {
+			if ( rs != null ) {
 				rs.close();
 			}
 		}
 	}
 
 	private void initColumns(DatabaseMetaData meta) throws SQLException {
 		ResultSet rs = null;
 
 		try {
-			rs = meta.getColumns(catalog, schema, name, "%");
+			rs = meta.getColumns( catalog, schema, name, "%" );
 			while ( rs.next() ) {
-				addColumn(rs);
+				addColumn( rs );
 			}
 		}
-		finally  {
-			if (rs != null) {
+		finally {
+			if ( rs != null ) {
 				rs.close();
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/instrument/BasicInstrumentationTask.java b/hibernate-core/src/main/java/org/hibernate/tool/instrument/BasicInstrumentationTask.java
index 1174eb1137..e7d5b05f7b 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/instrument/BasicInstrumentationTask.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/instrument/BasicInstrumentationTask.java
@@ -1,137 +1,137 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tool.instrument;
 
 import java.io.File;
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
 
 import org.hibernate.bytecode.buildtime.spi.Instrumenter;
 import org.hibernate.bytecode.buildtime.spi.Logger;
 
 import org.apache.tools.ant.BuildException;
 import org.apache.tools.ant.DirectoryScanner;
 import org.apache.tools.ant.Project;
 import org.apache.tools.ant.Task;
 import org.apache.tools.ant.types.FileSet;
 
 /**
  * Super class for all Hibernate instrumentation tasks.  Provides the basic templating of how instrumentation
  * should occur; subclasses simply plug in to that process appropriately for the given bytecode provider.
  *
  * @author Steve Ebersole
  */
 public abstract class BasicInstrumentationTask extends Task implements Instrumenter.Options {
 
 	private final LoggerBridge logger = new LoggerBridge();
 
 	private List filesets = new ArrayList();
 	private boolean extended;
 
 	// deprecated option...
 	private boolean verbose;
 
 	public void addFileset(FileSet set) {
 		this.filesets.add( set );
 	}
 
 	protected final Iterator filesets() {
 		return filesets.iterator();
 	}
 
 	public boolean isExtended() {
 		return extended;
 	}
 
 	public void setExtended(boolean extended) {
 		this.extended = extended;
 	}
 
 	public boolean isVerbose() {
 		return verbose;
 	}
 
 	public void setVerbose(boolean verbose) {
 		this.verbose = verbose;
 	}
 
 	public final boolean performExtendedInstrumentation() {
 		return isExtended();
 	}
 
 	protected abstract Instrumenter buildInstrumenter(Logger logger, Instrumenter.Options options);
 
 	@Override
-    public void execute() throws BuildException {
+	public void execute() throws BuildException {
 		try {
 			buildInstrumenter( logger, this )
 					.execute( collectSpecifiedFiles() );
 		}
 		catch ( Throwable t ) {
 			throw new BuildException( t );
 		}
 	}
 
 	private Set collectSpecifiedFiles() {
 		HashSet files = new HashSet();
 		Project project = getProject();
 		Iterator filesets = filesets();
 		while ( filesets.hasNext() ) {
 			FileSet fs = ( FileSet ) filesets.next();
 			DirectoryScanner ds = fs.getDirectoryScanner( project );
 			String[] includedFiles = ds.getIncludedFiles();
 			File d = fs.getDir( project );
 			for ( int i = 0; i < includedFiles.length; ++i ) {
 				files.add( new File( d, includedFiles[i] ) );
 			}
 		}
 		return files;
 	}
 
 	protected class LoggerBridge implements Logger {
 		public void trace(String message) {
 			log( message, Project.MSG_VERBOSE );
 		}
 
 		public void debug(String message) {
 			log( message, Project.MSG_DEBUG );
 		}
 
 		public void info(String message) {
 			log( message, Project.MSG_INFO );
 		}
 
 		public void warn(String message) {
 			log( message, Project.MSG_WARN );
 		}
 
 		public void error(String message) {
 			log( message, Project.MSG_ERR );
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/instrument/javassist/InstrumentTask.java b/hibernate-core/src/main/java/org/hibernate/tool/instrument/javassist/InstrumentTask.java
index 80ca85c9fb..396028bca4 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/instrument/javassist/InstrumentTask.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/instrument/javassist/InstrumentTask.java
@@ -1,71 +1,71 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tool.instrument.javassist;
 
 import org.hibernate.bytecode.buildtime.internal.JavassistInstrumenter;
 import org.hibernate.bytecode.buildtime.spi.Instrumenter;
 import org.hibernate.bytecode.buildtime.spi.Logger;
 import org.hibernate.tool.instrument.BasicInstrumentationTask;
 
 /**
  * An Ant task for instrumenting persistent classes in order to enable
  * field-level interception using Javassist.
  * <p/>
  * In order to use this task, typically you would define a a taskdef
  * similiar to:<pre>
  * <taskdef name="instrument" classname="org.hibernate.tool.instrument.javassist.InstrumentTask">
  *     <classpath refid="lib.class.path"/>
  * </taskdef>
  * </pre>
  * where <tt>lib.class.path</tt> is an ANT path reference containing all the
  * required Hibernate and Javassist libraries.
  * <p/>
  * And then use it like:<pre>
  * <instrument verbose="true">
  *     <fileset dir="${testclasses.dir}/org/hibernate/test">
  *         <include name="yadda/yadda/**"/>
  *         ...
  *     </fileset>
  * </instrument>
  * </pre>
  * where the nested ANT fileset includes the class you would like to have
  * instrumented.
  * <p/>
  * Optionally you can chose to enable "Extended Instrumentation" if desired
  * by specifying the extended attriubute on the task:<pre>
  * <instrument verbose="true" extended="true">
  *     ...
  * </instrument>
  * </pre>
  * See the Hibernate manual regarding this option.
  *
  * @author Muga Nishizawa
  * @author Steve Ebersole
  */
 public class InstrumentTask extends BasicInstrumentationTask {
 	@Override
-    protected Instrumenter buildInstrumenter(Logger logger, Instrumenter.Options options) {
+	protected Instrumenter buildInstrumenter(Logger logger, Instrumenter.Options options) {
 		return new JavassistInstrumenter( logger, options );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/transform/DistinctResultTransformer.java b/hibernate-core/src/main/java/org/hibernate/transform/DistinctResultTransformer.java
index 85eaba3fbd..ff77dbd193 100644
--- a/hibernate-core/src/main/java/org/hibernate/transform/DistinctResultTransformer.java
+++ b/hibernate-core/src/main/java/org/hibernate/transform/DistinctResultTransformer.java
@@ -1,111 +1,102 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.transform;
 
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 
 import org.hibernate.internal.CoreMessageLogger;
 
-import org.jboss.logging.Logger;
+import static org.hibernate.internal.CoreLogging.messageLogger;
 
 /**
  * Distinctions the result tuples in the final result based on the defined
  * equality of the tuples.
  * <p/>
  * Since this transformer is stateless, all instances would be considered equal.
  * So for optimization purposes we limit it to a single, singleton {@link #INSTANCE instance}.
  *
  * @author Steve Ebersole
  */
 public class DistinctResultTransformer extends BasicTransformerAdapter {
-
 	public static final DistinctResultTransformer INSTANCE = new DistinctResultTransformer();
 
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
-                                                                       DistinctResultTransformer.class.getName());
+	private static final CoreMessageLogger LOG = messageLogger( DistinctResultTransformer.class );
 
 	/**
 	 * Helper class to handle distincting
 	 */
 	private static final class Identity {
 		final Object entity;
 
 		private Identity(Object entity) {
 			this.entity = entity;
 		}
 
-		/**
-		 * {@inheritDoc}
-		 */
 		@Override
-        public boolean equals(Object other) {
+		public boolean equals(Object other) {
 			return Identity.class.isInstance( other )
-					&& this.entity == ( ( Identity ) other ).entity;
+					&& this.entity == ( (Identity) other ).entity;
 		}
 
-		/**
-		 * {@inheritDoc}
-		 */
 		@Override
-        public int hashCode() {
+		public int hashCode() {
 			return System.identityHashCode( entity );
 		}
 	}
 
 	/**
 	 * Disallow instantiation of DistinctResultTransformer.
 	 */
 	private DistinctResultTransformer() {
 	}
 
 	/**
 	 * Uniquely distinct each tuple row here.
 	 */
 	@Override
-    public List transformList(List list) {
-		List result = new ArrayList( list.size() );
-		Set distinct = new HashSet();
-		for ( int i = 0; i < list.size(); i++ ) {
-			Object entity = list.get( i );
+	public List transformList(List list) {
+		List<Object> result = new ArrayList<Object>( list.size() );
+		Set<Identity> distinct = new HashSet<Identity>();
+		for ( Object entity : list ) {
 			if ( distinct.add( new Identity( entity ) ) ) {
 				result.add( entity );
 			}
 		}
 		LOG.debugf( "Transformed: %s rows to: %s distinct results", list.size(), result.size() );
 		return result;
 	}
 
 	/**
 	 * Serialization hook for ensuring singleton uniqueing.
 	 *
 	 * @return The singleton instance : {@link #INSTANCE}
 	 */
 	private Object readResolve() {
 		return INSTANCE;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/transform/RootEntityResultTransformer.java b/hibernate-core/src/main/java/org/hibernate/transform/RootEntityResultTransformer.java
index 261f797265..a950ce8711 100644
--- a/hibernate-core/src/main/java/org/hibernate/transform/RootEntityResultTransformer.java
+++ b/hibernate-core/src/main/java/org/hibernate/transform/RootEntityResultTransformer.java
@@ -1,83 +1,83 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.transform;
 
 import org.hibernate.internal.util.collections.ArrayHelper;
 
 /**
  * {@link ResultTransformer} implementation which limits the result tuple
  * to only the "root entity".
  * <p/>
  * Since this transformer is stateless, all instances would be considered equal.
  * So for optimization purposes we limit it to a single, singleton {@link #INSTANCE instance}.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public final class RootEntityResultTransformer extends BasicTransformerAdapter implements TupleSubsetResultTransformer {
 
 	public static final RootEntityResultTransformer INSTANCE = new RootEntityResultTransformer();
 
 	/**
 	 * Disallow instantiation of RootEntityResultTransformer.
 	 */
 	private RootEntityResultTransformer() {
 	}
 
 	/**
 	 * Return just the root entity from the row tuple.
 	 */
 	@Override
-    public Object transformTuple(Object[] tuple, String[] aliases) {
+	public Object transformTuple(Object[] tuple, String[] aliases) {
 		return tuple[ tuple.length-1 ];
 	}
 
 	@Override
 	public boolean isTransformedValueATupleElement(String[] aliases, int tupleLength) {
 		return true;
 	}
 
 	@Override
 	public boolean[] includeInTransform(String[] aliases, int tupleLength) {
 		boolean[] includeInTransform;
 		if ( tupleLength == 1 ) {
 			includeInTransform = ArrayHelper.TRUE;
 		}
 		else {
 			includeInTransform = new boolean[tupleLength];
 			includeInTransform[ tupleLength - 1 ] = true;
 		}
 		return includeInTransform;
 	}
 
 	/**
 	 * Serialization hook for ensuring singleton uniqueing.
 	 *
 	 * @return The singleton instance : {@link #INSTANCE}
 	 */
 	private Object readResolve() {
 		return INSTANCE;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/transform/ToListResultTransformer.java b/hibernate-core/src/main/java/org/hibernate/transform/ToListResultTransformer.java
index 129f4d8587..0fd21fa3f6 100644
--- a/hibernate-core/src/main/java/org/hibernate/transform/ToListResultTransformer.java
+++ b/hibernate-core/src/main/java/org/hibernate/transform/ToListResultTransformer.java
@@ -1,56 +1,54 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.transform;
 
 import java.util.Arrays;
-import java.util.List;
 
 /**
- * Tranforms each result row from a tuple into a {@link List}, such that what
- * you end up with is a {@link List} of {@link List Lists}.
+ * Tranforms each result row from a tuple into a {@link java.util.List} whose elements are each tuple value
  */
 public class ToListResultTransformer extends BasicTransformerAdapter {
 	public static final ToListResultTransformer INSTANCE = new ToListResultTransformer();
 
 	/**
 	 * Disallow instantiation of ToListResultTransformer.
 	 */
 	private ToListResultTransformer() {
 	}
 	
 	@Override
 	public Object transformTuple(Object[] tuple, String[] aliases) {
 		return Arrays.asList( tuple );
 	}
 
 	/**
 	 * Serialization hook for ensuring singleton uniqueing.
 	 *
 	 * @return The singleton instance : {@link #INSTANCE}
 	 */
 	private Object readResolve() {
 		return INSTANCE;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/AnnotationValueGeneration.java b/hibernate-core/src/main/java/org/hibernate/tuple/AnnotationValueGeneration.java
index aac9fd4f9f..18170e8092 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/AnnotationValueGeneration.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/AnnotationValueGeneration.java
@@ -1,51 +1,50 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple;
 
 import java.lang.annotation.Annotation;
 
-import org.hibernate.HibernateException;
 
 /**
  * A {@link ValueGeneration} based on a custom Java generator annotation type.
  *
  * @param <A> The generator annotation type supported by an implementation
  *
  * @author Gunnar Morling
  */
 public interface AnnotationValueGeneration<A extends Annotation> extends ValueGeneration {
 
 	/**
 	 * Initializes this generation strategy for the given annotation instance.
 	 *
 	 * @param annotation an instance of the strategy's annotation type. Typically implementations will retrieve the
 	 * annotation's attribute values and store them in fields.
 	 * @param propertyType the type of the property annotated with the generator annotation. Implementations may use
 	 * the type to determine the right {@link ValueGenerator} to be applied.
 	 *
-	 * @throws HibernateException in case an error occurred during initialization, e.g. if an implementation can't
-	 * create a value for the given property type.
+	 * @throws org.hibernate.HibernateException in case an error occurred during initialization, e.g. if
+	 * an implementation can't create a value for the given property type.
 	 */
 	void initialize(A annotation, Class<?> propertyType);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/ElementWrapper.java b/hibernate-core/src/main/java/org/hibernate/tuple/ElementWrapper.java
index 258e1755c8..dd120f9aa9 100755
--- a/hibernate-core/src/main/java/org/hibernate/tuple/ElementWrapper.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/ElementWrapper.java
@@ -1,591 +1,591 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.tuple;
 import java.io.IOException;
 import java.io.Serializable;
 import java.io.Writer;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.dom4j.Attribute;
 import org.dom4j.Branch;
 import org.dom4j.CDATA;
 import org.dom4j.Comment;
 import org.dom4j.Document;
 import org.dom4j.Element;
 import org.dom4j.Entity;
 import org.dom4j.InvalidXPathException;
 import org.dom4j.Namespace;
 import org.dom4j.Node;
 import org.dom4j.ProcessingInstruction;
 import org.dom4j.QName;
 import org.dom4j.Text;
 import org.dom4j.Visitor;
 import org.dom4j.XPath;
 
 /**
  * Wraps dom4j elements, allowing them to exist in a 
  * non-hierarchical structure.
  *
  * @author Gavin King
  */
 public class ElementWrapper implements Element, Serializable {
 
 	private Element element;
 	private Element parent;
 	
 	public Element getElement() {
 		return element;
 	}
 
 	public ElementWrapper(Element element) {
 		this.element = element;
 	}
 
 	public QName getQName() {
 		return element.getQName();
 	}
 
 	public QName getQName(String s) {
 		return element.getQName( s );
 	}
 
 	public void setQName(QName qName) {
 		element.setQName( qName );
 	}
 
 	public Namespace getNamespace() {
 		return element.getNamespace();
 	}
 
 	public Namespace getNamespaceForPrefix(String s) {
 		return element.getNamespaceForPrefix( s );
 	}
 
 	public Namespace getNamespaceForURI(String s) {
 		return element.getNamespaceForURI( s );
 	}
 
 	public List getNamespacesForURI(String s) {
 		return element.getNamespacesForURI( s );
 	}
 
 	public String getNamespacePrefix() {
 		return element.getNamespacePrefix();
 	}
 
 	public String getNamespaceURI() {
 		return element.getNamespaceURI();
 	}
 
 	public String getQualifiedName() {
 		return element.getQualifiedName();
 	}
 
 	public List additionalNamespaces() {
 		return element.additionalNamespaces();
 	}
 
 	public List declaredNamespaces() {
 		return element.declaredNamespaces();
 	}
 
 	public Element addAttribute(String attrName, String text) {
 		return element.addAttribute( attrName, text );
 	}
 
 	public Element addAttribute(QName attrName, String text) {
 		return element.addAttribute( attrName, text );
 	}
 
 	public Element addComment(String text) {
 		return element.addComment( text );
 	}
 
 	public Element addCDATA(String text) {
 		return element.addCDATA( text );
 	}
 
 	public Element addEntity(String name, String text) {
 		return element.addEntity( name, text );
 	}
 
 	public Element addNamespace(String prefix, String uri) {
 		return element.addNamespace( prefix, uri );
 	}
 
 	public Element addProcessingInstruction(String target, String text) {
 		return element.addProcessingInstruction( target, text );
 	}
 
 	public Element addProcessingInstruction(String target, Map data) {
 		return element.addProcessingInstruction( target, data );
 	}
 
 	public Element addText(String text) {
 		return element.addText( text );
 	}
 
 	public void add(Attribute attribute) {
 		element.add( attribute );
 	}
 
 	public void add(CDATA cdata) {
 		element.add( cdata );
 	}
 
 	public void add(Entity entity) {
 		element.add( entity );
 	}
 
 	public void add(Text text) {
 		element.add( text );
 	}
 
 	public void add(Namespace namespace) {
 		element.add( namespace );
 	}
 
 	public boolean remove(Attribute attribute) {
 		return element.remove( attribute );
 	}
 
 	public boolean remove(CDATA cdata) {
 		return element.remove( cdata );
 	}
 
 	public boolean remove(Entity entity) {
 		return element.remove( entity );
 	}
 
 	public boolean remove(Namespace namespace) {
 		return element.remove( namespace );
 	}
 
 	public boolean remove(Text text) {
 		return element.remove( text );
 	}
 
 	public boolean supportsParent() {
 		return element.supportsParent();
 	}
 
 	public Element getParent() {
 		return parent==null ? element.getParent() : parent;
 	}
 
 	public void setParent(Element parent) {
 		element.setParent( parent );
 		this.parent = parent;
 	}
 
 	public Document getDocument() {
 		return element.getDocument();
 	}
 
 	public void setDocument(Document document) {
 		element.setDocument( document );
 	}
 
 	public boolean isReadOnly() {
 		return element.isReadOnly();
 	}
 
 	public boolean hasContent() {
 		return element.hasContent();
 	}
 
 	public String getName() {
 		return element.getName();
 	}
 
 	public void setName(String name) {
 		element.setName( name );
 	}
 
 	public String getText() {
 		return element.getText();
 	}
 
 	public void setText(String text) {
 		element.setText( text );
 	}
 
 	public String getTextTrim() {
 		return element.getTextTrim();
 	}
 
 	public String getStringValue() {
 		return element.getStringValue();
 	}
 
 	public String getPath() {
 		return element.getPath();
 	}
 
 	public String getPath(Element element) {
 		return element.getPath( element );
 	}
 
 	public String getUniquePath() {
 		return element.getUniquePath();
 	}
 
 	public String getUniquePath(Element element) {
 		return element.getUniquePath( element );
 	}
 
 	public String asXML() {
 		return element.asXML();
 	}
 
 	public void write(Writer writer) throws IOException {
 		element.write( writer );
 	}
 
 	public short getNodeType() {
 		return element.getNodeType();
 	}
 
 	public String getNodeTypeName() {
 		return element.getNodeTypeName();
 	}
 
 	public Node detach() {
 		if (parent!=null) {
 			parent.remove(this);
 			parent = null;
 		}
 		return element.detach();
 	}
 
 	public List selectNodes(String xpath) {
 		return element.selectNodes( xpath );
 	}
 
 	public Object selectObject(String xpath) {
 		return element.selectObject( xpath );
 	}
 
 	public List selectNodes(String xpath, String comparison) {
 		return element.selectNodes( xpath, comparison );
 	}
 
 	public List selectNodes(String xpath, String comparison, boolean removeDups) {
 		return element.selectNodes( xpath, comparison, removeDups );
 	}
 
 	public Node selectSingleNode(String xpath) {
-        return element.selectSingleNode( xpath );
+		return element.selectSingleNode( xpath );
 	}
 
 	public String valueOf(String xpath) {
 		return element.valueOf( xpath );
 	}
 
 	public Number numberValueOf(String xpath) {
 		return element.numberValueOf( xpath );
 	}
 
 	public boolean matches(String xpath) {
 		return element.matches( xpath );
 	}
 
 	public XPath createXPath(String xpath) throws InvalidXPathException {
 		return element.createXPath( xpath );
 	}
 
 	public Node asXPathResult(Element element) {
 		return element.asXPathResult( element );
 	}
 
 	public void accept(Visitor visitor) {
 		element.accept( visitor );
 	}
 
 	public Object clone() {
 		return element.clone();
 	}
 
 	public Object getData() {
 		return element.getData();
 	}
 
 	public void setData(Object data) {
 		element.setData( data );
 	}
 
 	public List attributes() {
 		return element.attributes();
 	}
 
 	public void setAttributes(List list) {
 		element.setAttributes( list );
 	}
 
 	public int attributeCount() {
 		return element.attributeCount();
 	}
 
 	public Iterator attributeIterator() {
 		return element.attributeIterator();
 	}
 
 	public Attribute attribute(int i) {
 		return element.attribute( i );
 	}
 
 	public Attribute attribute(String name) {
 		return element.attribute( name );
 	}
 
 	public Attribute attribute(QName qName) {
 		return element.attribute( qName );
 	}
 
 	public String attributeValue(String name) {
 		return element.attributeValue( name );
 	}
 
 	public String attributeValue(String name, String defaultValue) {
 		return element.attributeValue( name, defaultValue );
 	}
 
 	public String attributeValue(QName qName) {
 		return element.attributeValue( qName );
 	}
 
 	public String attributeValue(QName qName, String defaultValue) {
 		return element.attributeValue( qName, defaultValue );
 	}
 
 	public void setAttributeValue(String name, String value) {
 		element.setAttributeValue( name, value );
 	}
 
 	public void setAttributeValue(QName qName, String value) {
 		element.setAttributeValue( qName, value );
 	}
 
 	public Element element(String name) {
 		return element.element( name );
 	}
 
 	public Element element(QName qName) {
 		return element.element( qName );
 	}
 
 	public List elements() {
 		return element.elements();
 	}
 
 	public List elements(String name) {
 		return element.elements( name );
 	}
 
 	public List elements(QName qName) {
 		return element.elements( qName );
 	}
 
 	public Iterator elementIterator() {
 		return element.elementIterator();
 	}
 
 	public Iterator elementIterator(String name) {
 		return element.elementIterator( name );
 
 	}
 
 	public Iterator elementIterator(QName qName) {
 		return element.elementIterator( qName );
 	}
 
 	public boolean isRootElement() {
 		return element.isRootElement();
 	}
 
 	public boolean hasMixedContent() {
 		return element.hasMixedContent();
 	}
 
 	public boolean isTextOnly() {
 		return element.isTextOnly();
 	}
 
 	public void appendAttributes(Element element) {
 		element.appendAttributes( element );
 	}
 
 	public Element createCopy() {
 		return element.createCopy();
 	}
 
 	public Element createCopy(String name) {
 		return element.createCopy( name );
 	}
 
 	public Element createCopy(QName qName) {
 		return element.createCopy( qName );
 	}
 
 	public String elementText(String name) {
 		return element.elementText( name );
 	}
 
 	public String elementText(QName qName) {
 		return element.elementText( qName );
 	}
 
 	public String elementTextTrim(String name) {
 		return element.elementTextTrim( name );
 	}
 
 	public String elementTextTrim(QName qName) {
 		return element.elementTextTrim( qName );
 	}
 
 	public Node getXPathResult(int i) {
 		return element.getXPathResult( i );
 	}
 
 	public Node node(int i) {
 		return element.node( i );
 	}
 
 	public int indexOf(Node node) {
 		return element.indexOf( node );
 	}
 
 	public int nodeCount() {
 		return element.nodeCount();
 	}
 
 	public Element elementByID(String id) {
 		return element.elementByID( id );
 	}
 
 	public List content() {
 		return element.content();
 	}
 
 	public Iterator nodeIterator() {
 		return element.nodeIterator();
 	}
 
 	public void setContent(List list) {
 		element.setContent( list );
 	}
 
 	public void appendContent(Branch branch) {
 		element.appendContent( branch );
 	}
 
 	public void clearContent() {
 		element.clearContent();
 	}
 
 	public List processingInstructions() {
 		return element.processingInstructions();
 	}
 
 	public List processingInstructions(String name) {
 		return element.processingInstructions( name );
 	}
 
 	public ProcessingInstruction processingInstruction(String name) {
 		return element.processingInstruction( name );
 	}
 
 	public void setProcessingInstructions(List list) {
 		element.setProcessingInstructions( list );
 	}
 
 	public Element addElement(String name) {
 		return element.addElement( name );
 	}
 
 	public Element addElement(QName qName) {
 		return element.addElement( qName );
 	}
 
 	public Element addElement(String name, String text) {
 		return element.addElement( name, text );
 
 	}
 
 	public boolean removeProcessingInstruction(String name) {
 		return element.removeProcessingInstruction( name );
 	}
 
 	public void add(Node node) {
 		element.add( node );
 	}
 
 	public void add(Comment comment) {
 		element.add( comment );
 	}
 
 	public void add(Element element) {
 		element.add( element );
 	}
 
 	public void add(ProcessingInstruction processingInstruction) {
 		element.add( processingInstruction );
 	}
 
 	public boolean remove(Node node) {
 		return element.remove( node );
 	}
 
 	public boolean remove(Comment comment) {
 		return element.remove( comment );
 	}
 
 	public boolean remove(Element element) {
 		return element.remove( element );
 	}
 
 	public boolean remove(ProcessingInstruction processingInstruction) {
 		return element.remove( processingInstruction );
 	}
 
 	public void normalize() {
 		element.normalize();
 	}
 	
 	public boolean equals(Object other) {
 		return element.equals(other);
 	}
 	
 	public int hashCode() {
 		return element.hashCode();
 	}
 	
 	public String toString() {
 		return element.toString();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/IdentifierProperty.java b/hibernate-core/src/main/java/org/hibernate/tuple/IdentifierProperty.java
index 54ad0ad32d..7aa774515c 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/IdentifierProperty.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/IdentifierProperty.java
@@ -1,133 +1,132 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple;
 
 import org.hibernate.engine.spi.IdentifierValue;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.PostInsertIdentifierGenerator;
 import org.hibernate.type.Type;
 
 /**
  * Represents a defined entity identifier property within the Hibernate
  * runtime-metamodel.
  *
  * @author Steve Ebersole
  */
 public class IdentifierProperty extends AbstractAttribute implements IdentifierAttribute {
-
 	private boolean virtual;
 	private boolean embedded;
 	private IdentifierValue unsavedValue;
 	private IdentifierGenerator identifierGenerator;
 	private boolean identifierAssignedByInsert;
 	private boolean hasIdentifierMapper;
 
 	/**
 	 * Construct a non-virtual identifier property.
 	 *
 	 * @param name The name of the property representing the identifier within
 	 * its owning entity.
 	 * @param node The node name to use for XML-based representation of this
 	 * property.
 	 * @param type The Hibernate Type for the identifier property.
 	 * @param embedded Is this an embedded identifier.
 	 * @param unsavedValue The value which, if found as the value on the identifier
 	 * property, represents new (i.e., un-saved) instances of the owning entity.
 	 * @param identifierGenerator The generator to use for id value generation.
 	 */
 	public IdentifierProperty(
 			String name,
 			String node,
 			Type type,
 			boolean embedded,
 			IdentifierValue unsavedValue,
 			IdentifierGenerator identifierGenerator) {
 		super( name, type );
 		this.virtual = false;
 		this.embedded = embedded;
 		this.hasIdentifierMapper = false;
 		this.unsavedValue = unsavedValue;
 		this.identifierGenerator = identifierGenerator;
 		this.identifierAssignedByInsert = identifierGenerator instanceof PostInsertIdentifierGenerator;
 	}
 
 	/**
 	 * Construct a virtual IdentifierProperty.
 	 *
 	 * @param type The Hibernate Type for the identifier property.
 	 * @param embedded Is this an embedded identifier.
 	 * @param unsavedValue The value which, if found as the value on the identifier
 	 * property, represents new (i.e., un-saved) instances of the owning entity.
 	 * @param identifierGenerator The generator to use for id value generation.
 	 */
 	public IdentifierProperty(
-	        Type type,
-	        boolean embedded,
+			Type type,
+			boolean embedded,
 			boolean hasIdentifierMapper,
 			IdentifierValue unsavedValue,
-	        IdentifierGenerator identifierGenerator) {
+			IdentifierGenerator identifierGenerator) {
 		super( null, type );
 		this.virtual = true;
 		this.embedded = embedded;
 		this.hasIdentifierMapper = hasIdentifierMapper;
 		this.unsavedValue = unsavedValue;
 		this.identifierGenerator = identifierGenerator;
 		this.identifierAssignedByInsert = identifierGenerator instanceof PostInsertIdentifierGenerator;
 	}
 
 	@Override
 	public boolean isVirtual() {
 		return virtual;
 	}
 
 	@Override
 	public boolean isEmbedded() {
 		return embedded;
 	}
 
 	@Override
 	public IdentifierValue getUnsavedValue() {
 		return unsavedValue;
 	}
 
 	@Override
 	public IdentifierGenerator getIdentifierGenerator() {
 		return identifierGenerator;
 	}
 
 	@Override
 	public boolean isIdentifierAssignedByInsert() {
 		return identifierAssignedByInsert;
 	}
 
 	@Override
 	public boolean hasIdentifierMapper() {
 		return hasIdentifierMapper;
 	}
 
 	@Override
 	public String toString() {
 		return "IdentifierAttribute(" + getName() + ")";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/Property.java b/hibernate-core/src/main/java/org/hibernate/tuple/Property.java
index 3e2732ee7c..f083f8c04f 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/Property.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/Property.java
@@ -1,38 +1,40 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple;
 
 /**
  * Defines the basic contract of a Property within the runtime metamodel.
  *
  * @author Steve Ebersole
+ *
+ * @deprecated Use the direct {@link Attribute} hierarchy
  */
 @Deprecated
 public interface Property extends Attribute {
 	/**
 	 * @deprecated DOM4j entity mode is no longer supported
 	 */
 	@Deprecated
 	public String getNode();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/PropertyFactory.java b/hibernate-core/src/main/java/org/hibernate/tuple/PropertyFactory.java
index 95bd6e631e..bf3c9d1d65 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/PropertyFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/PropertyFactory.java
@@ -1,331 +1,334 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple;
 
 import java.lang.reflect.Constructor;
 
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
 import org.hibernate.engine.internal.UnsavedValueFactory;
 import org.hibernate.engine.spi.IdentifierValue;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.VersionValue;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.mapping.KeyValue;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.property.Getter;
 import org.hibernate.property.PropertyAccessor;
 import org.hibernate.property.PropertyAccessorFactory;
 import org.hibernate.tuple.entity.EntityBasedAssociationAttribute;
 import org.hibernate.tuple.entity.EntityBasedBasicAttribute;
 import org.hibernate.tuple.entity.EntityBasedCompositionAttribute;
 import org.hibernate.tuple.entity.VersionProperty;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 
 /**
  * Responsible for generation of runtime metamodel {@link Property} representations.
  * Makes distinction between identifier, version, and other (standard) properties.
  *
  * @author Steve Ebersole
  */
 public final class PropertyFactory {
 	private PropertyFactory() {
 	}
 
 	/**
 	 * Generates the attribute representation of the identifier for a given entity mapping.
 	 *
 	 * @param mappedEntity The mapping definition of the entity.
 	 * @param generator The identifier value generator to use for this identifier.
+	 *
 	 * @return The appropriate IdentifierProperty definition.
 	 */
 	public static IdentifierProperty buildIdentifierAttribute(
 			PersistentClass mappedEntity,
 			IdentifierGenerator generator) {
 		String mappedUnsavedValue = mappedEntity.getIdentifier().getNullValue();
 		Type type = mappedEntity.getIdentifier().getType();
 		Property property = mappedEntity.getIdentifierProperty();
-		
+
 		IdentifierValue unsavedValue = UnsavedValueFactory.getUnsavedIdentifierValue(
 				mappedUnsavedValue,
 				getGetter( property ),
 				type,
-				getConstructor(mappedEntity)
-			);
+				getConstructor( mappedEntity )
+		);
 
 		if ( property == null ) {
 			// this is a virtual id property...
 			return new IdentifierProperty(
-			        type,
+					type,
 					mappedEntity.hasEmbeddedIdentifier(),
 					mappedEntity.hasIdentifierMapper(),
 					unsavedValue,
 					generator
-				);
+			);
 		}
 		else {
 			return new IdentifierProperty(
 					property.getName(),
 					property.getNodeName(),
 					type,
 					mappedEntity.hasEmbeddedIdentifier(),
 					unsavedValue,
 					generator
-				);
+			);
 		}
 	}
 
 	/**
 	 * Generates a VersionProperty representation for an entity mapping given its
 	 * version mapping Property.
 	 *
 	 * @param property The version mapping Property.
 	 * @param lazyAvailable Is property lazy loading currently available.
+	 *
 	 * @return The appropriate VersionProperty definition.
 	 */
 	public static VersionProperty buildVersionProperty(
 			EntityPersister persister,
 			SessionFactoryImplementor sessionFactory,
 			int attributeNumber,
 			Property property,
 			boolean lazyAvailable) {
 		String mappedUnsavedValue = ( (KeyValue) property.getValue() ).getNullValue();
-		
+
 		VersionValue unsavedValue = UnsavedValueFactory.getUnsavedVersionValue(
 				mappedUnsavedValue,
 				getGetter( property ),
 				(VersionType) property.getType(),
 				getConstructor( property.getPersistentClass() )
 		);
 
 		boolean lazy = lazyAvailable && property.isLazy();
 
 		return new VersionProperty(
 				persister,
 				sessionFactory,
 				attributeNumber,
-		        property.getName(),
-		        property.getValue().getType(),
+				property.getName(),
+				property.getValue().getType(),
 				new BaselineAttributeInformation.Builder()
 						.setLazy( lazy )
 						.setInsertable( property.isInsertable() )
 						.setUpdateable( property.isUpdateable() )
 						.setValueGenerationStrategy( property.getValueGenerationStrategy() )
 						.setNullable( property.isOptional() )
 						.setDirtyCheckable( property.isUpdateable() && !lazy )
 						.setVersionable( property.isOptimisticLocked() )
 						.setCascadeStyle( property.getCascadeStyle() )
 						.createInformation(),
-		        unsavedValue
-			);
+				unsavedValue
+		);
 	}
 
 	public static enum NonIdentifierAttributeNature {
 		BASIC,
 		COMPOSITE,
 		ANY,
 		ENTITY,
 		COLLECTION
 	}
 
 	/**
 	 * Generate a non-identifier (and non-version) attribute based on the given mapped property from the given entity
 	 *
 	 * @param property The mapped property.
 	 * @param lazyAvailable Is property lazy loading currently available.
+	 *
 	 * @return The appropriate NonIdentifierProperty definition.
 	 */
 	public static NonIdentifierAttribute buildEntityBasedAttribute(
 			EntityPersister persister,
 			SessionFactoryImplementor sessionFactory,
 			int attributeNumber,
 			Property property,
 			boolean lazyAvailable) {
 		final Type type = property.getValue().getType();
 
 		final NonIdentifierAttributeNature nature = decode( type );
 
 		// we need to dirty check collections, since they can cause an owner
 		// version number increment
-		
+
 		// we need to dirty check many-to-ones with not-found="ignore" in order 
 		// to update the cache (not the database), since in this case a null
 		// entity reference can lose information
-		
-		boolean alwaysDirtyCheck = type.isAssociationType() && 
-				( (AssociationType) type ).isAlwaysDirtyChecked(); 
+
+		boolean alwaysDirtyCheck = type.isAssociationType() &&
+				( (AssociationType) type ).isAlwaysDirtyChecked();
 
 		switch ( nature ) {
 			case BASIC: {
 				return new EntityBasedBasicAttribute(
 						persister,
 						sessionFactory,
 						attributeNumber,
 						property.getName(),
 						type,
 						new BaselineAttributeInformation.Builder()
 								.setLazy( lazyAvailable && property.isLazy() )
 								.setInsertable( property.isInsertable() )
 								.setUpdateable( property.isUpdateable() )
 								.setValueGenerationStrategy( property.getValueGenerationStrategy() )
 								.setNullable( property.isOptional() )
 								.setDirtyCheckable( alwaysDirtyCheck || property.isUpdateable() )
 								.setVersionable( property.isOptimisticLocked() )
 								.setCascadeStyle( property.getCascadeStyle() )
 								.setFetchMode( property.getValue().getFetchMode() )
 								.createInformation()
 				);
 			}
 			case COMPOSITE: {
 				return new EntityBasedCompositionAttribute(
 						persister,
 						sessionFactory,
 						attributeNumber,
 						property.getName(),
 						(CompositeType) type,
 						new BaselineAttributeInformation.Builder()
 								.setLazy( lazyAvailable && property.isLazy() )
 								.setInsertable( property.isInsertable() )
 								.setUpdateable( property.isUpdateable() )
 								.setValueGenerationStrategy( property.getValueGenerationStrategy() )
 								.setNullable( property.isOptional() )
 								.setDirtyCheckable( alwaysDirtyCheck || property.isUpdateable() )
 								.setVersionable( property.isOptimisticLocked() )
 								.setCascadeStyle( property.getCascadeStyle() )
 								.setFetchMode( property.getValue().getFetchMode() )
 								.createInformation()
 				);
 			}
 			case ENTITY:
 			case ANY:
 			case COLLECTION: {
 				return new EntityBasedAssociationAttribute(
 						persister,
 						sessionFactory,
 						attributeNumber,
 						property.getName(),
 						(AssociationType) type,
 						new BaselineAttributeInformation.Builder()
 								.setLazy( lazyAvailable && property.isLazy() )
 								.setInsertable( property.isInsertable() )
 								.setUpdateable( property.isUpdateable() )
 								.setValueGenerationStrategy( property.getValueGenerationStrategy() )
 								.setNullable( property.isOptional() )
 								.setDirtyCheckable( alwaysDirtyCheck || property.isUpdateable() )
 								.setVersionable( property.isOptimisticLocked() )
 								.setCascadeStyle( property.getCascadeStyle() )
 								.setFetchMode( property.getValue().getFetchMode() )
 								.createInformation()
 				);
 			}
 			default: {
 				throw new HibernateException( "Internal error" );
 			}
 		}
 	}
 
 	private static NonIdentifierAttributeNature decode(Type type) {
 		if ( type.isAssociationType() ) {
 			AssociationType associationType = (AssociationType) type;
 
 			if ( type.isComponentType() ) {
 				// an any type is both an association and a composite...
 				return NonIdentifierAttributeNature.ANY;
 			}
 
 			return type.isCollectionType()
 					? NonIdentifierAttributeNature.COLLECTION
 					: NonIdentifierAttributeNature.ENTITY;
 		}
 		else {
 			if ( type.isComponentType() ) {
 				return NonIdentifierAttributeNature.COMPOSITE;
 			}
 
 			return NonIdentifierAttributeNature.BASIC;
 		}
 	}
 
 	/**
 	 * @deprecated See mainly {@link #buildEntityBasedAttribute}
 	 */
 	@Deprecated
 	public static StandardProperty buildStandardProperty(Property property, boolean lazyAvailable) {
 		final Type type = property.getValue().getType();
 
 		// we need to dirty check collections, since they can cause an owner
 		// version number increment
 
 		// we need to dirty check many-to-ones with not-found="ignore" in order
 		// to update the cache (not the database), since in this case a null
 		// entity reference can lose information
 
 		boolean alwaysDirtyCheck = type.isAssociationType() &&
 				( (AssociationType) type ).isAlwaysDirtyChecked();
 
 		return new StandardProperty(
 				property.getName(),
 				type,
 				lazyAvailable && property.isLazy(),
 				property.isInsertable(),
 				property.isUpdateable(),
 				property.getValueGenerationStrategy(),
 				property.isOptional(),
 				alwaysDirtyCheck || property.isUpdateable(),
 				property.isOptimisticLocked(),
 				property.getCascadeStyle(),
 				property.getValue().getFetchMode()
 		);
 	}
 
 
 	private static Constructor getConstructor(PersistentClass persistentClass) {
 		if ( persistentClass == null || !persistentClass.hasPojoRepresentation() ) {
 			return null;
 		}
 
 		try {
 			return ReflectHelper.getDefaultConstructor( persistentClass.getMappedClass() );
 		}
-		catch( Throwable t ) {
+		catch (Throwable t) {
 			return null;
 		}
 	}
 
 	private static Getter getGetter(Property mappingProperty) {
 		if ( mappingProperty == null || !mappingProperty.getPersistentClass().hasPojoRepresentation() ) {
 			return null;
 		}
 
 		PropertyAccessor pa = PropertyAccessorFactory.getPropertyAccessor( mappingProperty, EntityMode.POJO );
 		return pa.getGetter( mappingProperty.getPersistentClass().getMappedClass(), mappingProperty.getName() );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/entity/AbstractEntityTuplizer.java b/hibernate-core/src/main/java/org/hibernate/tuple/entity/AbstractEntityTuplizer.java
index c05ffb7832..e9c668d022 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/entity/AbstractEntityTuplizer.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/entity/AbstractEntityTuplizer.java
@@ -1,710 +1,729 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple.entity;
 
 import java.io.Serializable;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.bytecode.instrumentation.spi.LazyPropertyInitializer;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.event.service.spi.EventListenerRegistry;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.event.spi.EventType;
 import org.hibernate.event.spi.PersistEvent;
 import org.hibernate.event.spi.PersistEventListener;
 import org.hibernate.id.Assigned;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.property.Getter;
 import org.hibernate.property.Setter;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.ProxyFactory;
 import org.hibernate.tuple.Instantiator;
 import org.hibernate.tuple.NonIdentifierAttribute;
 import org.hibernate.type.ComponentType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
-import org.jboss.logging.Logger;
+import static org.hibernate.internal.CoreLogging.messageLogger;
 
 
 /**
  * Support for tuplizers relating to entities.
  *
  * @author Steve Ebersole
  * @author Gavin King
  */
 public abstract class AbstractEntityTuplizer implements EntityTuplizer {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(
-			CoreMessageLogger.class,
-			AbstractEntityTuplizer.class.getName()
-	);
+	private static final CoreMessageLogger LOG = messageLogger( AbstractEntityTuplizer.class );
 
 	//TODO: currently keeps Getters and Setters (instead of PropertyAccessors) because of the way getGetter() and getSetter() are implemented currently; yuck!
 
 	private final EntityMetamodel entityMetamodel;
 
 	private final Getter idGetter;
 	private final Setter idSetter;
 
 	protected final Getter[] getters;
 	protected final Setter[] setters;
 	protected final int propertySpan;
 	protected final boolean hasCustomAccessors;
 	private final Instantiator instantiator;
 	private final ProxyFactory proxyFactory;
 	private final CompositeType identifierMapperType;
 
 	public Type getIdentifierMapperType() {
 		return identifierMapperType;
 	}
 
 	/**
 	 * Build an appropriate Getter for the given property.
 	 *
 	 * @param mappedProperty The property to be accessed via the built Getter.
 	 * @param mappedEntity The entity information regarding the mapped entity owning this property.
+	 *
 	 * @return An appropriate Getter instance.
 	 */
 	protected abstract Getter buildPropertyGetter(Property mappedProperty, PersistentClass mappedEntity);
 
 	/**
 	 * Build an appropriate Setter for the given property.
 	 *
 	 * @param mappedProperty The property to be accessed via the built Setter.
 	 * @param mappedEntity The entity information regarding the mapped entity owning this property.
+	 *
 	 * @return An appropriate Setter instance.
 	 */
 	protected abstract Setter buildPropertySetter(Property mappedProperty, PersistentClass mappedEntity);
 
 	/**
 	 * Build an appropriate Instantiator for the given mapped entity.
 	 *
 	 * @param mappingInfo The mapping information regarding the mapped entity.
+	 *
 	 * @return An appropriate Instantiator instance.
 	 */
 	protected abstract Instantiator buildInstantiator(PersistentClass mappingInfo);
 
 	/**
 	 * Build an appropriate ProxyFactory for the given mapped entity.
 	 *
 	 * @param mappingInfo The mapping information regarding the mapped entity.
 	 * @param idGetter The constructed Getter relating to the entity's id property.
 	 * @param idSetter The constructed Setter relating to the entity's id property.
+	 *
 	 * @return An appropriate ProxyFactory instance.
 	 */
 	protected abstract ProxyFactory buildProxyFactory(PersistentClass mappingInfo, Getter idGetter, Setter idSetter);
 
 	/**
 	 * Constructs a new AbstractEntityTuplizer instance.
 	 *
 	 * @param entityMetamodel The "interpreted" information relating to the mapped entity.
 	 * @param mappingInfo The parsed "raw" mapping data relating to the given entity.
 	 */
 	public AbstractEntityTuplizer(EntityMetamodel entityMetamodel, PersistentClass mappingInfo) {
 		this.entityMetamodel = entityMetamodel;
 
 		if ( !entityMetamodel.getIdentifierProperty().isVirtual() ) {
 			idGetter = buildPropertyGetter( mappingInfo.getIdentifierProperty(), mappingInfo );
 			idSetter = buildPropertySetter( mappingInfo.getIdentifierProperty(), mappingInfo );
 		}
 		else {
 			idGetter = null;
 			idSetter = null;
 		}
 
 		propertySpan = entityMetamodel.getPropertySpan();
 
-        getters = new Getter[propertySpan];
+		getters = new Getter[propertySpan];
 		setters = new Setter[propertySpan];
 
 		Iterator itr = mappingInfo.getPropertyClosureIterator();
-		boolean foundCustomAccessor=false;
-		int i=0;
+		boolean foundCustomAccessor = false;
+		int i = 0;
 		while ( itr.hasNext() ) {
 			//TODO: redesign how PropertyAccessors are acquired...
 			Property property = (Property) itr.next();
-			getters[i] = buildPropertyGetter(property, mappingInfo);
-			setters[i] = buildPropertySetter(property, mappingInfo);
+			getters[i] = buildPropertyGetter( property, mappingInfo );
+			setters[i] = buildPropertySetter( property, mappingInfo );
 			if ( !property.isBasicPropertyAccessor() ) {
 				foundCustomAccessor = true;
 			}
 			i++;
 		}
 		hasCustomAccessors = foundCustomAccessor;
 
-        instantiator = buildInstantiator( mappingInfo );
+		instantiator = buildInstantiator( mappingInfo );
 
 		if ( entityMetamodel.isLazy() ) {
 			proxyFactory = buildProxyFactory( mappingInfo, idGetter, idSetter );
-			if (proxyFactory == null) {
+			if ( proxyFactory == null ) {
 				entityMetamodel.setLazy( false );
 			}
 		}
 		else {
 			proxyFactory = null;
 		}
 
 		Component mapper = mappingInfo.getIdentifierMapper();
 		if ( mapper == null ) {
 			identifierMapperType = null;
 			mappedIdentifierValueMarshaller = null;
 		}
 		else {
 			identifierMapperType = (CompositeType) mapper.getType();
 			mappedIdentifierValueMarshaller = buildMappedIdentifierValueMarshaller(
 					(ComponentType) entityMetamodel.getIdentifierProperty().getType(),
 					(ComponentType) identifierMapperType
 			);
 		}
 	}
 
-	/** Retreives the defined entity-name for the tuplized entity.
+	/**
+	 * Retreives the defined entity-name for the tuplized entity.
 	 *
 	 * @return The entity-name.
 	 */
 	protected String getEntityName() {
 		return entityMetamodel.getName();
 	}
 
 	/**
 	 * Retrieves the defined entity-names for any subclasses defined for this
 	 * entity.
 	 *
 	 * @return Any subclass entity-names.
 	 */
 	protected Set getSubclassEntityNames() {
 		return entityMetamodel.getSubclassEntityNames();
 	}
 
 	@Override
 	public Serializable getIdentifier(Object entity) throws HibernateException {
 		return getIdentifier( entity, null );
 	}
 
 	@Override
 	public Serializable getIdentifier(Object entity, SessionImplementor session) {
 		final Object id;
 		if ( entityMetamodel.getIdentifierProperty().isEmbedded() ) {
 			id = entity;
 		}
 		else if ( HibernateProxy.class.isInstance( entity ) ) {
 			id = ( (HibernateProxy) entity ).getHibernateLazyInitializer().getIdentifier();
 		}
 		else {
 			if ( idGetter == null ) {
-				if (identifierMapperType==null) {
+				if ( identifierMapperType == null ) {
 					throw new HibernateException( "The class has no identifier property: " + getEntityName() );
 				}
 				else {
 					id = mappedIdentifierValueMarshaller.getIdentifier( entity, getEntityMode(), session );
 				}
 			}
 			else {
-                id = idGetter.get( entity );
-            }
-        }
+				id = idGetter.get( entity );
+			}
+		}
 
 		try {
 			return (Serializable) id;
 		}
-		catch ( ClassCastException cce ) {
+		catch (ClassCastException cce) {
 			StringBuilder msg = new StringBuilder( "Identifier classes must be serializable. " );
 			if ( id != null ) {
 				msg.append( id.getClass().getName() ).append( " is not serializable. " );
 			}
 			if ( cce.getMessage() != null ) {
 				msg.append( cce.getMessage() );
 			}
 			throw new ClassCastException( msg.toString() );
 		}
 	}
 
 	@Override
 	public void setIdentifier(Object entity, Serializable id) throws HibernateException {
 		// 99% of the time the session is not needed.  Its only needed for certain brain-dead
 		// interpretations of JPA 2 "derived identity" support
 		setIdentifier( entity, id, null );
 	}
 
 	@Override
 	public void setIdentifier(Object entity, Serializable id, SessionImplementor session) {
 		if ( entityMetamodel.getIdentifierProperty().isEmbedded() ) {
 			if ( entity != id ) {
 				CompositeType copier = (CompositeType) entityMetamodel.getIdentifierProperty().getType();
 				copier.setPropertyValues( entity, copier.getPropertyValues( id, getEntityMode() ), getEntityMode() );
 			}
 		}
 		else if ( idSetter != null ) {
 			idSetter.set( entity, id, getFactory() );
 		}
 		else if ( identifierMapperType != null ) {
 			mappedIdentifierValueMarshaller.setIdentifier( entity, id, getEntityMode(), session );
 		}
 	}
 
 	private static interface MappedIdentifierValueMarshaller {
 		public Object getIdentifier(Object entity, EntityMode entityMode, SessionImplementor session);
+
 		public void setIdentifier(Object entity, Serializable id, EntityMode entityMode, SessionImplementor session);
 	}
 
 	private final MappedIdentifierValueMarshaller mappedIdentifierValueMarshaller;
 
 	private static MappedIdentifierValueMarshaller buildMappedIdentifierValueMarshaller(
 			ComponentType mappedIdClassComponentType,
 			ComponentType virtualIdComponent) {
 		// so basically at this point we know we have a "mapped" composite identifier
 		// which is an awful way to say that the identifier is represented differently
 		// in the entity and in the identifier value.  The incoming value should
 		// be an instance of the mapped identifier class (@IdClass) while the incoming entity
 		// should be an instance of the entity class as defined by metamodel.
 		//
 		// However, even within that we have 2 potential scenarios:
 		//		1) @IdClass types and entity @Id property types match
 		//			- return a NormalMappedIdentifierValueMarshaller
 		//		2) They do not match
 		//			- return a IncrediblySillyJpaMapsIdMappedIdentifierValueMarshaller
 		boolean wereAllEquivalent = true;
 		// the sizes being off is a much bigger problem that should have been caught already...
 		for ( int i = 0; i < virtualIdComponent.getSubtypes().length; i++ ) {
 			if ( virtualIdComponent.getSubtypes()[i].isEntityType()
-					&& ! mappedIdClassComponentType.getSubtypes()[i].isEntityType() ) {
+					&& !mappedIdClassComponentType.getSubtypes()[i].isEntityType() ) {
 				wereAllEquivalent = false;
 				break;
 			}
 		}
 
 		return wereAllEquivalent
 				? new NormalMappedIdentifierValueMarshaller( virtualIdComponent, mappedIdClassComponentType )
-				: new IncrediblySillyJpaMapsIdMappedIdentifierValueMarshaller( virtualIdComponent, mappedIdClassComponentType );
+				: new IncrediblySillyJpaMapsIdMappedIdentifierValueMarshaller(
+				virtualIdComponent,
+				mappedIdClassComponentType
+		);
 	}
 
 	private static class NormalMappedIdentifierValueMarshaller implements MappedIdentifierValueMarshaller {
 		private final ComponentType virtualIdComponent;
 		private final ComponentType mappedIdentifierType;
 
-		private NormalMappedIdentifierValueMarshaller(ComponentType virtualIdComponent, ComponentType mappedIdentifierType) {
+		private NormalMappedIdentifierValueMarshaller(
+				ComponentType virtualIdComponent,
+				ComponentType mappedIdentifierType) {
 			this.virtualIdComponent = virtualIdComponent;
 			this.mappedIdentifierType = mappedIdentifierType;
 		}
 
 		@Override
 		public Object getIdentifier(Object entity, EntityMode entityMode, SessionImplementor session) {
 			Object id = mappedIdentifierType.instantiate( entityMode );
 			final Object[] propertyValues = virtualIdComponent.getPropertyValues( entity, entityMode );
 			mappedIdentifierType.setPropertyValues( id, propertyValues, entityMode );
 			return id;
 		}
 
 		@Override
 		public void setIdentifier(Object entity, Serializable id, EntityMode entityMode, SessionImplementor session) {
 			virtualIdComponent.setPropertyValues(
 					entity,
 					mappedIdentifierType.getPropertyValues( id, session ),
 					entityMode
 			);
 		}
 	}
 
-	private static class IncrediblySillyJpaMapsIdMappedIdentifierValueMarshaller implements MappedIdentifierValueMarshaller {
+	private static class IncrediblySillyJpaMapsIdMappedIdentifierValueMarshaller
+			implements MappedIdentifierValueMarshaller {
 		private final ComponentType virtualIdComponent;
 		private final ComponentType mappedIdentifierType;
 
-		private IncrediblySillyJpaMapsIdMappedIdentifierValueMarshaller(ComponentType virtualIdComponent, ComponentType mappedIdentifierType) {
+		private IncrediblySillyJpaMapsIdMappedIdentifierValueMarshaller(
+				ComponentType virtualIdComponent,
+				ComponentType mappedIdentifierType) {
 			this.virtualIdComponent = virtualIdComponent;
 			this.mappedIdentifierType = mappedIdentifierType;
 		}
 
 		@Override
 		public Object getIdentifier(Object entity, EntityMode entityMode, SessionImplementor session) {
 			final Object id = mappedIdentifierType.instantiate( entityMode );
 			final Object[] propertyValues = virtualIdComponent.getPropertyValues( entity, entityMode );
 			final Type[] subTypes = virtualIdComponent.getSubtypes();
 			final Type[] copierSubTypes = mappedIdentifierType.getSubtypes();
 			final Iterable<PersistEventListener> persistEventListeners = persistEventListeners( session );
 			final PersistenceContext persistenceContext = session.getPersistenceContext();
 			final int length = subTypes.length;
-			for ( int i = 0 ; i < length; i++ ) {
+			for ( int i = 0; i < length; i++ ) {
 				if ( propertyValues[i] == null ) {
 					throw new HibernateException( "No part of a composite identifier may be null" );
 				}
 				//JPA 2 @MapsId + @IdClass points to the pk of the entity
-				if ( subTypes[i].isAssociationType() && ! copierSubTypes[i].isAssociationType() ) {
+				if ( subTypes[i].isAssociationType() && !copierSubTypes[i].isAssociationType() ) {
 					// we need a session to handle this use case
 					if ( session == null ) {
 						throw new AssertionError(
 								"Deprecated version of getIdentifier (no session) was used but session was required"
 						);
 					}
 					final Object subId;
 					if ( HibernateProxy.class.isInstance( propertyValues[i] ) ) {
 						subId = ( (HibernateProxy) propertyValues[i] ).getHibernateLazyInitializer().getIdentifier();
 					}
 					else {
 						EntityEntry pcEntry = session.getPersistenceContext().getEntry( propertyValues[i] );
 						if ( pcEntry != null ) {
 							subId = pcEntry.getId();
 						}
 						else {
 							LOG.debug( "Performing implicit derived identity cascade" );
-							final PersistEvent event = new PersistEvent( null, propertyValues[i], (EventSource) session );
+							final PersistEvent event = new PersistEvent(
+									null,
+									propertyValues[i],
+									(EventSource) session
+							);
 							for ( PersistEventListener listener : persistEventListeners ) {
 								listener.onPersist( event );
 							}
 							pcEntry = persistenceContext.getEntry( propertyValues[i] );
 							if ( pcEntry == null || pcEntry.getId() == null ) {
 								throw new HibernateException( "Unable to process implicit derived identity cascade" );
 							}
 							else {
 								subId = pcEntry.getId();
 							}
 						}
 					}
 					propertyValues[i] = subId;
 				}
 			}
 			mappedIdentifierType.setPropertyValues( id, propertyValues, entityMode );
 			return id;
 		}
 
 		@Override
 		public void setIdentifier(Object entity, Serializable id, EntityMode entityMode, SessionImplementor session) {
 			final Object[] extractedValues = mappedIdentifierType.getPropertyValues( id, entityMode );
-			final Object[] injectionValues = new Object[ extractedValues.length ];
+			final Object[] injectionValues = new Object[extractedValues.length];
 			final PersistenceContext persistenceContext = session.getPersistenceContext();
 			for ( int i = 0; i < virtualIdComponent.getSubtypes().length; i++ ) {
 				final Type virtualPropertyType = virtualIdComponent.getSubtypes()[i];
 				final Type idClassPropertyType = mappedIdentifierType.getSubtypes()[i];
-				if ( virtualPropertyType.isEntityType() && ! idClassPropertyType.isEntityType() ) {
+				if ( virtualPropertyType.isEntityType() && !idClassPropertyType.isEntityType() ) {
 					if ( session == null ) {
 						throw new AssertionError(
 								"Deprecated version of getIdentifier (no session) was used but session was required"
 						);
 					}
 					final String associatedEntityName = ( (EntityType) virtualPropertyType ).getAssociatedEntityName();
 					final EntityKey entityKey = session.generateEntityKey(
 							(Serializable) extractedValues[i],
 							session.getFactory().getEntityPersister( associatedEntityName )
 					);
 					// it is conceivable there is a proxy, so check that first
 					Object association = persistenceContext.getProxy( entityKey );
 					if ( association == null ) {
 						// otherwise look for an initialized version
 						association = persistenceContext.getEntity( entityKey );
 					}
 					injectionValues[i] = association;
 				}
 				else {
 					injectionValues[i] = extractedValues[i];
 				}
 			}
 			virtualIdComponent.setPropertyValues( entity, injectionValues, entityMode );
 		}
 	}
 
 	private static Iterable<PersistEventListener> persistEventListeners(SessionImplementor session) {
 		return session
 				.getFactory()
 				.getServiceRegistry()
 				.getService( EventListenerRegistry.class )
 				.getEventListenerGroup( EventType.PERSIST )
 				.listeners();
 	}
 
 	@Override
 	public void resetIdentifier(Object entity, Serializable currentId, Object currentVersion) {
 		// 99% of the time the session is not needed.  Its only needed for certain brain-dead
 		// interpretations of JPA 2 "derived identity" support
 		resetIdentifier( entity, currentId, currentVersion, null );
 	}
 
 	@Override
 	public void resetIdentifier(
 			Object entity,
 			Serializable currentId,
 			Object currentVersion,
 			SessionImplementor session) {
+		//noinspection StatementWithEmptyBody
 		if ( entityMetamodel.getIdentifierProperty().getIdentifierGenerator() instanceof Assigned ) {
 		}
 		else {
 			//reset the id
 			Serializable result = entityMetamodel.getIdentifierProperty()
 					.getUnsavedValue()
 					.getDefaultValue( currentId );
 			setIdentifier( entity, result, session );
 			//reset the version
 			VersionProperty versionProperty = entityMetamodel.getVersionProperty();
 			if ( entityMetamodel.isVersioned() ) {
 				setPropertyValue(
-				        entity,
-				        entityMetamodel.getVersionPropertyIndex(),
+						entity,
+						entityMetamodel.getVersionPropertyIndex(),
 						versionProperty.getUnsavedValue().getDefaultValue( currentVersion )
 				);
 			}
 		}
 	}
 
 	@Override
 	public Object getVersion(Object entity) throws HibernateException {
-		if ( !entityMetamodel.isVersioned() ) return null;
-		return getters[ entityMetamodel.getVersionPropertyIndex() ].get( entity );
+		if ( !entityMetamodel.isVersioned() ) {
+			return null;
+		}
+		return getters[entityMetamodel.getVersionPropertyIndex()].get( entity );
 	}
 
 	protected boolean shouldGetAllProperties(Object entity) {
 		return !hasUninitializedLazyProperties( entity );
 	}
 
 	@Override
 	public Object[] getPropertyValues(Object entity) throws HibernateException {
 		boolean getAll = shouldGetAllProperties( entity );
 		final int span = entityMetamodel.getPropertySpan();
 		final Object[] result = new Object[span];
 
 		for ( int j = 0; j < span; j++ ) {
 			NonIdentifierAttribute property = entityMetamodel.getProperties()[j];
 			if ( getAll || !property.isLazy() ) {
 				result[j] = getters[j].get( entity );
 			}
 			else {
 				result[j] = LazyPropertyInitializer.UNFETCHED_PROPERTY;
 			}
 		}
 		return result;
 	}
 
 	@Override
 	public Object[] getPropertyValuesToInsert(Object entity, Map mergeMap, SessionImplementor session)
 			throws HibernateException {
 		final int span = entityMetamodel.getPropertySpan();
 		final Object[] result = new Object[span];
 
 		for ( int j = 0; j < span; j++ ) {
 			result[j] = getters[j].getForInsert( entity, mergeMap, session );
 		}
 		return result;
 	}
 
 	@Override
 	public Object getPropertyValue(Object entity, int i) throws HibernateException {
 		return getters[i].get( entity );
 	}
 
 	@Override
 	public Object getPropertyValue(Object entity, String propertyPath) throws HibernateException {
-		int loc = propertyPath.indexOf('.');
+		int loc = propertyPath.indexOf( '.' );
 		String basePropertyName = loc > 0
 				? propertyPath.substring( 0, loc )
 				: propertyPath;
 		//final int index = entityMetamodel.getPropertyIndexOrNull( basePropertyName );
 		Integer index = entityMetamodel.getPropertyIndexOrNull( basePropertyName );
-		if (index == null) {
+		if ( index == null ) {
 			propertyPath = PropertyPath.IDENTIFIER_MAPPER_PROPERTY + "." + propertyPath;
-			loc = propertyPath.indexOf('.');
+			loc = propertyPath.indexOf( '.' );
 			basePropertyName = loc > 0
-				? propertyPath.substring( 0, loc )
-				: propertyPath;
+					? propertyPath.substring( 0, loc )
+					: propertyPath;
 		}
 		index = entityMetamodel.getPropertyIndexOrNull( basePropertyName );
 		final Object baseValue = getPropertyValue( entity, index );
 		if ( loc > 0 ) {
 			if ( baseValue == null ) {
 				return null;
 			}
 			return getComponentValue(
 					(ComponentType) entityMetamodel.getPropertyTypes()[index],
 					baseValue,
-					propertyPath.substring(loc+1)
+					propertyPath.substring( loc + 1 )
 			);
 		}
 		else {
 			return baseValue;
 		}
 	}
 
 	/**
 	 * Extract a component property value.
 	 *
 	 * @param type The component property types.
 	 * @param component The component instance itself.
 	 * @param propertyPath The property path for the property to be extracted.
+	 *
 	 * @return The property value extracted.
 	 */
 	protected Object getComponentValue(ComponentType type, Object component, String propertyPath) {
 		final int loc = propertyPath.indexOf( '.' );
 		final String basePropertyName = loc > 0
 				? propertyPath.substring( 0, loc )
 				: propertyPath;
 		final int index = findSubPropertyIndex( type, basePropertyName );
 		final Object baseValue = type.getPropertyValue( component, index );
 		if ( loc > 0 ) {
 			if ( baseValue == null ) {
 				return null;
 			}
 			return getComponentValue(
 					(ComponentType) type.getSubtypes()[index],
 					baseValue,
-					propertyPath.substring(loc+1)
+					propertyPath.substring( loc + 1 )
 			);
 		}
 		else {
 			return baseValue;
 		}
 
 	}
 
 	private int findSubPropertyIndex(ComponentType type, String subPropertyName) {
 		final String[] propertyNames = type.getPropertyNames();
-		for ( int index = 0; index<propertyNames.length; index++ ) {
+		for ( int index = 0; index < propertyNames.length; index++ ) {
 			if ( subPropertyName.equals( propertyNames[index] ) ) {
 				return index;
 			}
 		}
 		throw new MappingException( "component property not found: " + subPropertyName );
 	}
 
 	@Override
 	public void setPropertyValues(Object entity, Object[] values) throws HibernateException {
 		boolean setAll = !entityMetamodel.hasLazyProperties();
 
 		for ( int j = 0; j < entityMetamodel.getPropertySpan(); j++ ) {
 			if ( setAll || values[j] != LazyPropertyInitializer.UNFETCHED_PROPERTY ) {
 				setters[j].set( entity, values[j], getFactory() );
 			}
 		}
 	}
 
 	@Override
 	public void setPropertyValue(Object entity, int i, Object value) throws HibernateException {
 		setters[i].set( entity, value, getFactory() );
 	}
 
 	@Override
 	public void setPropertyValue(Object entity, String propertyName, Object value) throws HibernateException {
-		setters[ entityMetamodel.getPropertyIndex( propertyName ) ].set( entity, value, getFactory() );
+		setters[entityMetamodel.getPropertyIndex( propertyName )].set( entity, value, getFactory() );
 	}
 
 	@Override
 	public final Object instantiate(Serializable id) throws HibernateException {
 		// 99% of the time the session is not needed.  Its only needed for certain brain-dead
 		// interpretations of JPA 2 "derived identity" support
 		return instantiate( id, null );
 	}
 
 	@Override
 	public final Object instantiate(Serializable id, SessionImplementor session) {
 		Object result = getInstantiator().instantiate( id );
 		if ( id != null ) {
 			setIdentifier( result, id, session );
 		}
 		return result;
 	}
 
 	@Override
 	public final Object instantiate() throws HibernateException {
 		return instantiate( null, null );
 	}
 
 	@Override
-	public void afterInitialize(Object entity, boolean lazyPropertiesAreUnfetched, SessionImplementor session) {}
+	public void afterInitialize(Object entity, boolean lazyPropertiesAreUnfetched, SessionImplementor session) {
+	}
 
 	@Override
 	public boolean hasUninitializedLazyProperties(Object entity) {
 		// the default is to simply not lazy fetch properties for now...
 		return false;
 	}
 
 	@Override
 	public final boolean isInstance(Object object) {
-        return getInstantiator().isInstance( object );
+		return getInstantiator().isInstance( object );
 	}
 
 	@Override
 	public boolean hasProxy() {
 		return entityMetamodel.isLazy();
 	}
 
 	@Override
 	public final Object createProxy(Serializable id, SessionImplementor session)
-	throws HibernateException {
+			throws HibernateException {
 		return getProxyFactory().getProxy( id, session );
 	}
 
 	@Override
 	public boolean isLifecycleImplementor() {
 		return false;
 	}
 
 	protected final EntityMetamodel getEntityMetamodel() {
 		return entityMetamodel;
 	}
 
 	protected final SessionFactoryImplementor getFactory() {
 		return entityMetamodel.getSessionFactory();
 	}
 
 	protected final Instantiator getInstantiator() {
 		return instantiator;
 	}
 
 	protected final ProxyFactory getProxyFactory() {
 		return proxyFactory;
 	}
 
 	@Override
-    public String toString() {
+	public String toString() {
 		return getClass().getName() + '(' + getEntityMetamodel().getName() + ')';
 	}
 
 	@Override
 	public Getter getIdentifierGetter() {
 		return idGetter;
 	}
 
 	@Override
 	public Getter getVersionGetter() {
 		if ( getEntityMetamodel().isVersioned() ) {
 			return getGetter( getEntityMetamodel().getVersionPropertyIndex() );
 		}
 		return null;
 	}
 
 	@Override
 	public Getter getGetter(int i) {
 		return getters[i];
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/entity/DynamicMapEntityTuplizer.java b/hibernate-core/src/main/java/org/hibernate/tuple/entity/DynamicMapEntityTuplizer.java
index 7433c5ba4d..d126ecfc93 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/entity/DynamicMapEntityTuplizer.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/entity/DynamicMapEntityTuplizer.java
@@ -1,163 +1,163 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple.entity;
 
 import java.util.Map;
 
 import org.hibernate.EntityMode;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.property.Getter;
 import org.hibernate.property.PropertyAccessor;
 import org.hibernate.property.PropertyAccessorFactory;
 import org.hibernate.property.Setter;
 import org.hibernate.proxy.ProxyFactory;
 import org.hibernate.proxy.map.MapProxyFactory;
 import org.hibernate.tuple.DynamicMapInstantiator;
 import org.hibernate.tuple.Instantiator;
 
 /**
  * An {@link EntityTuplizer} specific to the dynamic-map entity mode.
  *
  * @author Steve Ebersole
  * @author Gavin King
  */
 public class DynamicMapEntityTuplizer extends AbstractEntityTuplizer {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( DynamicMapEntityTuplizer.class );
 
 	DynamicMapEntityTuplizer(EntityMetamodel entityMetamodel, PersistentClass mappedEntity) {
-		super(entityMetamodel, mappedEntity);
+		super( entityMetamodel, mappedEntity );
 	}
 
 	@Override
 	public EntityMode getEntityMode() {
 		return EntityMode.MAP;
 	}
 
 	private PropertyAccessor buildPropertyAccessor(Property mappedProperty) {
 		if ( mappedProperty.isBackRef() ) {
-			return mappedProperty.getPropertyAccessor(null);
+			return mappedProperty.getPropertyAccessor( null );
 		}
 		else {
 			return PropertyAccessorFactory.getDynamicMapPropertyAccessor();
 		}
 	}
 
 	@Override
-    protected Getter buildPropertyGetter(Property mappedProperty, PersistentClass mappedEntity) {
-		return buildPropertyAccessor(mappedProperty).getGetter( null, mappedProperty.getName() );
+	protected Getter buildPropertyGetter(Property mappedProperty, PersistentClass mappedEntity) {
+		return buildPropertyAccessor( mappedProperty ).getGetter( null, mappedProperty.getName() );
 	}
 
 	@Override
-    protected Setter buildPropertySetter(Property mappedProperty, PersistentClass mappedEntity) {
-		return buildPropertyAccessor(mappedProperty).getSetter( null, mappedProperty.getName() );
+	protected Setter buildPropertySetter(Property mappedProperty, PersistentClass mappedEntity) {
+		return buildPropertyAccessor( mappedProperty ).getSetter( null, mappedProperty.getName() );
 	}
 
 	@Override
-    protected Instantiator buildInstantiator(PersistentClass mappingInfo) {
-        return new DynamicMapInstantiator( mappingInfo );
+	protected Instantiator buildInstantiator(PersistentClass mappingInfo) {
+		return new DynamicMapInstantiator( mappingInfo );
 	}
 
 	@Override
-    protected ProxyFactory buildProxyFactory(PersistentClass mappingInfo, Getter idGetter, Setter idSetter) {
+	protected ProxyFactory buildProxyFactory(PersistentClass mappingInfo, Getter idGetter, Setter idSetter) {
 
 		ProxyFactory pf = new MapProxyFactory();
 		try {
 			//TODO: design new lifecycle for ProxyFactory
 			pf.postInstantiate(
 					getEntityName(),
 					null,
 					null,
 					null,
 					null,
 					null
 			);
 		}
-		catch ( HibernateException he ) {
+		catch (HibernateException he) {
 			LOG.unableToCreateProxyFactory( getEntityName(), he );
 			pf = null;
 		}
 		return pf;
 	}
 
 	@Override
 	public Class getMappedClass() {
 		return Map.class;
 	}
 
 	@Override
 	public Class getConcreteProxyClass() {
 		return Map.class;
 	}
 
 	@Override
 	public boolean isInstrumented() {
 		return false;
 	}
 
 	@Override
 	public EntityNameResolver[] getEntityNameResolvers() {
-		return new EntityNameResolver[] { BasicEntityNameResolver.INSTANCE };
+		return new EntityNameResolver[] {BasicEntityNameResolver.INSTANCE};
 	}
 
 	@Override
 	public String determineConcreteSubclassEntityName(Object entityInstance, SessionFactoryImplementor factory) {
-		return extractEmbeddedEntityName( ( Map ) entityInstance );
+		return extractEmbeddedEntityName( (Map) entityInstance );
 	}
 
 	public static String extractEmbeddedEntityName(Map entity) {
-		return ( String ) entity.get( DynamicMapInstantiator.KEY );
+		return (String) entity.get( DynamicMapInstantiator.KEY );
 	}
 
 	public static class BasicEntityNameResolver implements EntityNameResolver {
 		public static final BasicEntityNameResolver INSTANCE = new BasicEntityNameResolver();
 
 		@Override
 		public String resolveEntityName(Object entity) {
-			if ( ! Map.class.isInstance( entity ) ) {
+			if ( !Map.class.isInstance( entity ) ) {
 				return null;
 			}
-			final String entityName = extractEmbeddedEntityName( ( Map ) entity );
+			final String entityName = extractEmbeddedEntityName( (Map) entity );
 			if ( entityName == null ) {
 				throw new HibernateException( "Could not determine type of dynamic map entity" );
 			}
 			return entityName;
 		}
 
 		@Override
-        public boolean equals(Object obj) {
+		public boolean equals(Object obj) {
 			return getClass().equals( obj.getClass() );
 		}
 
 		@Override
-        public int hashCode() {
+		public int hashCode() {
 			return getClass().hashCode();
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityMetamodel.java b/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityMetamodel.java
index 3ecdb23b13..7232111505 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityMetamodel.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/entity/EntityMetamodel.java
@@ -1,1119 +1,1118 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple.entity;
 
 import java.io.Serializable;
 import java.util.ArrayList;
-import java.util.Arrays;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.bytecode.spi.EntityInstrumentationMetadata;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.NotYetImplementedException;
 import org.hibernate.engine.OptimisticLockStyle;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.CascadeStyles;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.ValueInclusion;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.persister.entity.AbstractEntityPersister;
 import org.hibernate.tuple.GenerationTiming;
 import org.hibernate.tuple.IdentifierProperty;
 import org.hibernate.tuple.InDatabaseValueGenerationStrategy;
 import org.hibernate.tuple.InMemoryValueGenerationStrategy;
 import org.hibernate.tuple.NonIdentifierAttribute;
 import org.hibernate.tuple.PropertyFactory;
 import org.hibernate.tuple.ValueGeneration;
 import org.hibernate.tuple.ValueGenerator;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * Centralizes metamodel information about an entity.
  *
  * @author Steve Ebersole
  */
 public class EntityMetamodel implements Serializable {
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, EntityMetamodel.class.getName());
 
 	private static final int NO_VERSION_INDX = -66;
 
 	private final SessionFactoryImplementor sessionFactory;
 	private final AbstractEntityPersister persister;
 
 	private final String name;
 	private final String rootName;
 	private final EntityType entityType;
 
 	private final IdentifierProperty identifierAttribute;
 	private final boolean versioned;
 
 	private final int propertySpan;
 	private final int versionPropertyIndex;
 	private final NonIdentifierAttribute[] properties;
 	// temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	private final String[] propertyNames;
 	private final Type[] propertyTypes;
 	private final boolean[] propertyLaziness;
 	private final boolean[] propertyUpdateability;
 	private final boolean[] nonlazyPropertyUpdateability;
 	private final boolean[] propertyCheckability;
 	private final boolean[] propertyInsertability;
 	private final boolean[] propertyNullability;
 	private final boolean[] propertyVersionability;
 	private final CascadeStyle[] cascadeStyles;
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	// value generations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	private final boolean hasPreInsertGeneratedValues;
 	private final boolean hasPreUpdateGeneratedValues;
 	private final boolean hasInsertGeneratedValues;
 	private final boolean hasUpdateGeneratedValues;
 
 	private final InMemoryValueGenerationStrategy[] inMemoryValueGenerationStrategies;
 	private final InDatabaseValueGenerationStrategy[] inDatabaseValueGenerationStrategies;
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private final Map<String, Integer> propertyIndexes = new HashMap<String, Integer>();
 	private final boolean hasCollections;
 	private final boolean hasMutableProperties;
 	private final boolean hasLazyProperties;
 	private final boolean hasNonIdentifierPropertyNamedId;
 
 	private final int[] naturalIdPropertyNumbers;
 	private final boolean hasImmutableNaturalId;
 	private final boolean hasCacheableNaturalId;
 
 	private boolean lazy; //not final because proxy factory creation can fail
 	private final boolean hasCascades;
 	private final boolean mutable;
 	private final boolean isAbstract;
 	private final boolean selectBeforeUpdate;
 	private final boolean dynamicUpdate;
 	private final boolean dynamicInsert;
 	private final OptimisticLockStyle optimisticLockStyle;
 
 	private final boolean polymorphic;
 	private final String superclass;  // superclass entity-name
 	private final boolean explicitPolymorphism;
 	private final boolean inherited;
 	private final boolean hasSubclasses;
 	private final Set subclassEntityNames = new HashSet();
 	private final Map entityNameByInheritenceClassMap = new HashMap();
 
 	private final EntityMode entityMode;
 	private final EntityTuplizer entityTuplizer;
 	private final EntityInstrumentationMetadata instrumentationMetadata;
 
 	public EntityMetamodel(
 			PersistentClass persistentClass,
 			AbstractEntityPersister persister,
 			SessionFactoryImplementor sessionFactory) {
 		this.sessionFactory = sessionFactory;
 		this.persister = persister;
 
 		name = persistentClass.getEntityName();
 		rootName = persistentClass.getRootClass().getEntityName();
 		entityType = sessionFactory.getTypeResolver().getTypeFactory().manyToOne( name );
 
 		identifierAttribute = PropertyFactory.buildIdentifierAttribute(
 				persistentClass,
 				sessionFactory.getIdentifierGenerator( rootName )
 		);
 
 		versioned = persistentClass.isVersioned();
 
 		instrumentationMetadata = persistentClass.hasPojoRepresentation()
 				? Environment.getBytecodeProvider().getEntityInstrumentationMetadata( persistentClass.getMappedClass() )
 				: new NonPojoInstrumentationMetadata( persistentClass.getEntityName() );
 
 		boolean hasLazy = false;
 
 		propertySpan = persistentClass.getPropertyClosureSpan();
 		properties = new NonIdentifierAttribute[propertySpan];
 		List<Integer> naturalIdNumbers = new ArrayList<Integer>();
 		// temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		propertyNames = new String[propertySpan];
 		propertyTypes = new Type[propertySpan];
 		propertyUpdateability = new boolean[propertySpan];
 		propertyInsertability = new boolean[propertySpan];
 		nonlazyPropertyUpdateability = new boolean[propertySpan];
 		propertyCheckability = new boolean[propertySpan];
 		propertyNullability = new boolean[propertySpan];
 		propertyVersionability = new boolean[propertySpan];
 		propertyLaziness = new boolean[propertySpan];
 		cascadeStyles = new CascadeStyle[propertySpan];
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		// generated value strategies ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		this.inMemoryValueGenerationStrategies = new InMemoryValueGenerationStrategy[propertySpan];
 		this.inDatabaseValueGenerationStrategies = new InDatabaseValueGenerationStrategy[propertySpan];
 
 		boolean foundPreInsertGeneratedValues = false;
 		boolean foundPreUpdateGeneratedValues = false;
 		boolean foundPostInsertGeneratedValues = false;
 		boolean foundPostUpdateGeneratedValues = false;
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		Iterator iter = persistentClass.getPropertyClosureIterator();
 		int i = 0;
 		int tempVersionProperty = NO_VERSION_INDX;
 		boolean foundCascade = false;
 		boolean foundCollection = false;
 		boolean foundMutable = false;
 		boolean foundNonIdentifierPropertyNamedId = false;
 		boolean foundInsertGeneratedValue = false;
 		boolean foundUpdateGeneratedValue = false;
 		boolean foundUpdateableNaturalIdProperty = false;
 
 		while ( iter.hasNext() ) {
 			Property prop = ( Property ) iter.next();
 
 			if ( prop == persistentClass.getVersion() ) {
 				tempVersionProperty = i;
 				properties[i] = PropertyFactory.buildVersionProperty(
 						persister,
 						sessionFactory,
 						i,
 						prop,
 						instrumentationMetadata.isInstrumented()
 				);
 			}
 			else {
 				properties[i] = PropertyFactory.buildEntityBasedAttribute(
 						persister,
 						sessionFactory,
 						i,
 						prop,
 						instrumentationMetadata.isInstrumented()
 				);
 			}
 
 			if ( prop.isNaturalIdentifier() ) {
 				naturalIdNumbers.add( i );
 				if ( prop.isUpdateable() ) {
 					foundUpdateableNaturalIdProperty = true;
 				}
 			}
 
 			if ( "id".equals( prop.getName() ) ) {
 				foundNonIdentifierPropertyNamedId = true;
 			}
 
 			// temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 			boolean lazy = prop.isLazy() && instrumentationMetadata.isInstrumented();
 			if ( lazy ) {
 				hasLazy = true;
 			}
 			propertyLaziness[i] = lazy;
 
 			propertyNames[i] = properties[i].getName();
 			propertyTypes[i] = properties[i].getType();
 			propertyNullability[i] = properties[i].isNullable();
 			propertyUpdateability[i] = properties[i].isUpdateable();
 			propertyInsertability[i] = properties[i].isInsertable();
 			propertyVersionability[i] = properties[i].isVersionable();
 			nonlazyPropertyUpdateability[i] = properties[i].isUpdateable() && !lazy;
 			propertyCheckability[i] = propertyUpdateability[i] ||
 					( propertyTypes[i].isAssociationType() && ( (AssociationType) propertyTypes[i] ).isAlwaysDirtyChecked() );
 
 			cascadeStyles[i] = properties[i].getCascadeStyle();
 			// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 			// generated value strategies ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 			GenerationStrategyPair pair = buildGenerationStrategyPair( sessionFactory, prop );
 			inMemoryValueGenerationStrategies[i] = pair.getInMemoryStrategy();
 			inDatabaseValueGenerationStrategies[i] = pair.getInDatabaseStrategy();
 
 			if ( pair.getInMemoryStrategy() != null ) {
 				final GenerationTiming timing = pair.getInMemoryStrategy().getGenerationTiming();
 				if ( timing != GenerationTiming.NEVER ) {
 					final ValueGenerator generator = pair.getInMemoryStrategy().getValueGenerator();
 					if ( generator != null ) {
 						// we have some level of generation indicated
 						if ( timing == GenerationTiming.INSERT ) {
 							foundPreInsertGeneratedValues = true;
 						}
 						else if ( timing == GenerationTiming.ALWAYS ) {
 							foundPreInsertGeneratedValues = true;
 							foundPreUpdateGeneratedValues = true;
 						}
 					}
 				}
 			}
 			if (  pair.getInDatabaseStrategy() != null ) {
 				final GenerationTiming timing =  pair.getInDatabaseStrategy().getGenerationTiming();
 				if ( timing == GenerationTiming.INSERT ) {
 					foundPostInsertGeneratedValues = true;
 				}
 				else if ( timing == GenerationTiming.ALWAYS ) {
 					foundPostInsertGeneratedValues = true;
 					foundPostUpdateGeneratedValues = true;
 				}
 			}
 			// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 			if ( properties[i].isLazy() ) {
 				hasLazy = true;
 			}
 
 			if ( properties[i].getCascadeStyle() != CascadeStyles.NONE ) {
 				foundCascade = true;
 			}
 
 			if ( indicatesCollection( properties[i].getType() ) ) {
 				foundCollection = true;
 			}
 
 			if ( propertyTypes[i].isMutable() && propertyCheckability[i] ) {
 				foundMutable = true;
 			}
 
 			mapPropertyToIndex(prop, i);
 			i++;
 		}
 
 		if (naturalIdNumbers.size()==0) {
 			naturalIdPropertyNumbers = null;
 			hasImmutableNaturalId = false;
 			hasCacheableNaturalId = false;
 		}
 		else {
 			naturalIdPropertyNumbers = ArrayHelper.toIntArray(naturalIdNumbers);
 			hasImmutableNaturalId = !foundUpdateableNaturalIdProperty;
 			hasCacheableNaturalId = persistentClass.getNaturalIdCacheRegionName() != null;
 		}
 
 		this.hasPreInsertGeneratedValues = foundPreInsertGeneratedValues;
 		this.hasPreUpdateGeneratedValues = foundPreUpdateGeneratedValues;
 		this.hasInsertGeneratedValues = foundPostInsertGeneratedValues;
 		this.hasUpdateGeneratedValues = foundPostUpdateGeneratedValues;
 
 		hasCascades = foundCascade;
 		hasNonIdentifierPropertyNamedId = foundNonIdentifierPropertyNamedId;
 		versionPropertyIndex = tempVersionProperty;
 		hasLazyProperties = hasLazy;
         if (hasLazyProperties) {
 			LOG.lazyPropertyFetchingAvailable(name);
 		}
 
 		lazy = persistentClass.isLazy() && (
 				// TODO: this disables laziness even in non-pojo entity modes:
 				!persistentClass.hasPojoRepresentation() ||
 				!ReflectHelper.isFinalClass( persistentClass.getProxyInterface() )
 		);
 		mutable = persistentClass.isMutable();
 		if ( persistentClass.isAbstract() == null ) {
 			// legacy behavior (with no abstract attribute specified)
 			isAbstract = persistentClass.hasPojoRepresentation() &&
-			             ReflectHelper.isAbstractClass( persistentClass.getMappedClass() );
+					ReflectHelper.isAbstractClass( persistentClass.getMappedClass() );
 		}
 		else {
 			isAbstract = persistentClass.isAbstract().booleanValue();
 			if ( !isAbstract && persistentClass.hasPojoRepresentation() &&
-			     ReflectHelper.isAbstractClass( persistentClass.getMappedClass() ) ) {
-                LOG.entityMappedAsNonAbstract(name);
+					ReflectHelper.isAbstractClass( persistentClass.getMappedClass() ) ) {
+				LOG.entityMappedAsNonAbstract(name);
 			}
 		}
 		selectBeforeUpdate = persistentClass.hasSelectBeforeUpdate();
 		dynamicUpdate = persistentClass.useDynamicUpdate();
 		dynamicInsert = persistentClass.useDynamicInsert();
 
 		polymorphic = persistentClass.isPolymorphic();
 		explicitPolymorphism = persistentClass.isExplicitPolymorphism();
 		inherited = persistentClass.isInherited();
 		superclass = inherited ?
 				persistentClass.getSuperclass().getEntityName() :
 				null;
 		hasSubclasses = persistentClass.hasSubclasses();
 
 		optimisticLockStyle = persistentClass.getOptimisticLockStyle();
 		final boolean isAllOrDirty =
 				optimisticLockStyle == OptimisticLockStyle.ALL
 						|| optimisticLockStyle == OptimisticLockStyle.DIRTY;
 		if ( isAllOrDirty && !dynamicUpdate ) {
 			throw new MappingException( "optimistic-lock=all|dirty requires dynamic-update=\"true\": " + name );
 		}
 		if ( versionPropertyIndex != NO_VERSION_INDX && isAllOrDirty ) {
 			throw new MappingException( "version and optimistic-lock=all|dirty are not a valid combination : " + name );
 		}
 
 		hasCollections = foundCollection;
 		hasMutableProperties = foundMutable;
 
 		iter = persistentClass.getSubclassIterator();
 		while ( iter.hasNext() ) {
 			subclassEntityNames.add( ( (PersistentClass) iter.next() ).getEntityName() );
 		}
 		subclassEntityNames.add( name );
 
 		if ( persistentClass.hasPojoRepresentation() ) {
 			entityNameByInheritenceClassMap.put( persistentClass.getMappedClass(), persistentClass.getEntityName() );
 			iter = persistentClass.getSubclassIterator();
 			while ( iter.hasNext() ) {
 				final PersistentClass pc = ( PersistentClass ) iter.next();
 				entityNameByInheritenceClassMap.put( pc.getMappedClass(), pc.getEntityName() );
 			}
 		}
 
 		entityMode = persistentClass.hasPojoRepresentation() ? EntityMode.POJO : EntityMode.MAP;
 		final EntityTuplizerFactory entityTuplizerFactory = sessionFactory.getSettings().getEntityTuplizerFactory();
 		final String tuplizerClassName = persistentClass.getTuplizerImplClassName( entityMode );
 		if ( tuplizerClassName == null ) {
 			entityTuplizer = entityTuplizerFactory.constructDefaultTuplizer( entityMode, this, persistentClass );
 		}
 		else {
 			entityTuplizer = entityTuplizerFactory.constructTuplizer( tuplizerClassName, this, persistentClass );
 		}
 	}
 
 	private static GenerationStrategyPair buildGenerationStrategyPair(
 			final SessionFactoryImplementor sessionFactory,
 			final Property mappingProperty) {
 		final ValueGeneration valueGeneration = mappingProperty.getValueGenerationStrategy();
 		if ( valueGeneration != null && valueGeneration.getGenerationTiming() != GenerationTiming.NEVER ) {
 			// the property is generated in full. build the generation strategy pair.
 			if ( valueGeneration.getValueGenerator() != null ) {
 				// in-memory generation
 				return new GenerationStrategyPair(
 						FullInMemoryValueGenerationStrategy.create( valueGeneration )
 				);
 			}
 			else {
 				// in-db generation
 				return new GenerationStrategyPair(
 						create(
 								sessionFactory,
 								mappingProperty,
 								valueGeneration
 						)
 				);
 			}
 		}
 		else if ( mappingProperty.getValue() instanceof Component ) {
 			final CompositeGenerationStrategyPairBuilder builder = new CompositeGenerationStrategyPairBuilder( mappingProperty );
 			interpretPartialCompositeValueGeneration( sessionFactory, (Component) mappingProperty.getValue(), builder );
 			return builder.buildPair();
 		}
 
 		return NO_GEN_PAIR;
 	}
 
 	private static final GenerationStrategyPair NO_GEN_PAIR = new GenerationStrategyPair();
 
 	private static void interpretPartialCompositeValueGeneration(
 			SessionFactoryImplementor sessionFactory,
 			Component composite,
 			CompositeGenerationStrategyPairBuilder builder) {
 		Iterator subProperties = composite.getPropertyIterator();
 		while ( subProperties.hasNext() ) {
 			final Property subProperty = (Property) subProperties.next();
 			builder.addPair( buildGenerationStrategyPair( sessionFactory, subProperty ) );
 		}
 	}
 
 	public static InDatabaseValueGenerationStrategyImpl create(
 			SessionFactoryImplementor sessionFactoryImplementor,
 			Property mappingProperty,
 			ValueGeneration valueGeneration) {
 		final int numberOfMappedColumns = mappingProperty.getType().getColumnSpan( sessionFactoryImplementor );
 		if ( numberOfMappedColumns == 1 ) {
 			return new InDatabaseValueGenerationStrategyImpl(
 					valueGeneration.getGenerationTiming(),
 					valueGeneration.referenceColumnInSql(),
 					new String[] { valueGeneration.getDatabaseGeneratedReferencedColumnValue() }
 
 			);
 		}
 		else {
 			if ( valueGeneration.getDatabaseGeneratedReferencedColumnValue() != null ) {
 				LOG.debugf(
 						"Value generator specified column value in reference to multi-column attribute [%s -> %s]; ignoring",
 						mappingProperty.getPersistentClass(),
 						mappingProperty.getName()
 				);
 			}
 			return new InDatabaseValueGenerationStrategyImpl(
 					valueGeneration.getGenerationTiming(),
 					valueGeneration.referenceColumnInSql(),
 					new String[numberOfMappedColumns]
 			);
 		}
 	}
 
 	public static class GenerationStrategyPair {
 		private final InMemoryValueGenerationStrategy inMemoryStrategy;
 		private final InDatabaseValueGenerationStrategy inDatabaseStrategy;
 
 		public GenerationStrategyPair() {
 			this( NoInMemoryValueGenerationStrategy.INSTANCE, NoInDatabaseValueGenerationStrategy.INSTANCE );
 		}
 
 		public GenerationStrategyPair(FullInMemoryValueGenerationStrategy inMemoryStrategy) {
 			this( inMemoryStrategy, NoInDatabaseValueGenerationStrategy.INSTANCE );
 		}
 
 		public GenerationStrategyPair(InDatabaseValueGenerationStrategyImpl inDatabaseStrategy) {
 			this( NoInMemoryValueGenerationStrategy.INSTANCE, inDatabaseStrategy );
 		}
 
 		public GenerationStrategyPair(
 				InMemoryValueGenerationStrategy inMemoryStrategy,
 				InDatabaseValueGenerationStrategy inDatabaseStrategy) {
 			// perform some normalization.  Also check that only one (if any) strategy is specified
 			if ( inMemoryStrategy == null ) {
 				inMemoryStrategy = NoInMemoryValueGenerationStrategy.INSTANCE;
 			}
 			if ( inDatabaseStrategy == null ) {
 				inDatabaseStrategy = NoInDatabaseValueGenerationStrategy.INSTANCE;
 			}
 
 			if ( inMemoryStrategy.getGenerationTiming() != GenerationTiming.NEVER
 					&& inDatabaseStrategy.getGenerationTiming() != GenerationTiming.NEVER ) {
 				throw new ValueGenerationStrategyException(
 						"in-memory and in-database value generation are mutually exclusive"
 				);
 			}
 
 			this.inMemoryStrategy = inMemoryStrategy;
 			this.inDatabaseStrategy = inDatabaseStrategy;
 		}
 
 		public InMemoryValueGenerationStrategy getInMemoryStrategy() {
 			return inMemoryStrategy;
 		}
 
 		public InDatabaseValueGenerationStrategy getInDatabaseStrategy() {
 			return inDatabaseStrategy;
 		}
 	}
 
 	public static class ValueGenerationStrategyException extends HibernateException {
 		public ValueGenerationStrategyException(String message) {
 			super( message );
 		}
 
 		public ValueGenerationStrategyException(String message, Throwable cause) {
 			super( message, cause );
 		}
 	}
 
 	private static class CompositeGenerationStrategyPairBuilder {
 		private final Property mappingProperty;
 
 		private boolean hadInMemoryGeneration;
 		private boolean hadInDatabaseGeneration;
 
 		private List<InMemoryValueGenerationStrategy> inMemoryStrategies;
 		private List<InDatabaseValueGenerationStrategy> inDatabaseStrategies;
 
 		public CompositeGenerationStrategyPairBuilder(Property mappingProperty) {
 			this.mappingProperty = mappingProperty;
 		}
 
 		public void addPair(GenerationStrategyPair generationStrategyPair) {
 			add( generationStrategyPair.getInMemoryStrategy() );
 			add( generationStrategyPair.getInDatabaseStrategy() );
 		}
 
 		private void add(InMemoryValueGenerationStrategy inMemoryStrategy) {
 			if ( inMemoryStrategies == null ) {
 				inMemoryStrategies = new ArrayList<InMemoryValueGenerationStrategy>();
 			}
 			inMemoryStrategies.add( inMemoryStrategy );
 
 			if ( inMemoryStrategy.getGenerationTiming() != GenerationTiming.NEVER ) {
 				hadInMemoryGeneration = true;
 			}
 		}
 
 		private void add(InDatabaseValueGenerationStrategy inDatabaseStrategy) {
 			if ( inDatabaseStrategies == null ) {
 				inDatabaseStrategies = new ArrayList<InDatabaseValueGenerationStrategy>();
 			}
 			inDatabaseStrategies.add( inDatabaseStrategy );
 
 			if ( inDatabaseStrategy.getGenerationTiming() != GenerationTiming.NEVER ) {
 				hadInDatabaseGeneration = true;
 			}
 		}
 
 		public GenerationStrategyPair buildPair() {
 			if ( hadInMemoryGeneration && hadInDatabaseGeneration ) {
 				throw new ValueGenerationStrategyException(
 						"Composite attribute [" + mappingProperty.getName() + "] contained both in-memory"
 								+ " and in-database value generation"
 				);
 			}
 			else if ( hadInMemoryGeneration ) {
 				throw new NotYetImplementedException( "Still need to wire in composite in-memory value generation" );
 
 			}
 			else if ( hadInDatabaseGeneration ) {
 				final Component composite = (Component) mappingProperty.getValue();
 
 				// we need the numbers to match up so we can properly handle 'referenced sql column values'
 				if ( inDatabaseStrategies.size() != composite.getPropertySpan() ) {
 					throw new ValueGenerationStrategyException(
 							"Internal error : mismatch between number of collected in-db generation strategies" +
 									" and number of attributes for composite attribute : " + mappingProperty.getName()
 					);
 				}
 
 				// the base-line values for the aggregated InDatabaseValueGenerationStrategy we will build here.
 				GenerationTiming timing = GenerationTiming.INSERT;
 				boolean referenceColumns = false;
 				String[] columnValues = new String[ composite.getColumnSpan() ];
 
 				// start building the aggregate values
 				int propertyIndex = -1;
 				int columnIndex = 0;
 				Iterator subProperties = composite.getPropertyIterator();
 				while ( subProperties.hasNext() ) {
 					propertyIndex++;
 					final Property subProperty = (Property) subProperties.next();
 					final InDatabaseValueGenerationStrategy subStrategy = inDatabaseStrategies.get( propertyIndex );
 
 					if ( subStrategy.getGenerationTiming() == GenerationTiming.ALWAYS ) {
 						// override the base-line to the more often "ALWAYS"...
 						timing = GenerationTiming.ALWAYS;
 
 					}
 					if ( subStrategy.referenceColumnsInSql() ) {
 						// override base-line value
 						referenceColumns = true;
 					}
 					if ( subStrategy.getReferencedColumnValues() != null ) {
 						if ( subStrategy.getReferencedColumnValues().length != subProperty.getColumnSpan() ) {
 							throw new ValueGenerationStrategyException(
 									"Internal error : mismatch between number of collected 'referenced column values'" +
 											" and number of columns for composite attribute : " + mappingProperty.getName() +
 											'.' + subProperty.getName()
 							);
 						}
 						System.arraycopy(
 								subStrategy.getReferencedColumnValues(),
 								0,
 								columnValues,
 								columnIndex,
 								subProperty.getColumnSpan()
 						);
 					}
 				}
 
 				// then use the aggregated values to build the InDatabaseValueGenerationStrategy
 				return new GenerationStrategyPair(
 						new InDatabaseValueGenerationStrategyImpl( timing, referenceColumns, columnValues )
 				);
 			}
 			else {
 				return NO_GEN_PAIR;
 			}
 		}
 	}
 
 	private static class NoInMemoryValueGenerationStrategy implements InMemoryValueGenerationStrategy {
 		/**
 		 * Singleton access
 		 */
 		public static final NoInMemoryValueGenerationStrategy INSTANCE = new NoInMemoryValueGenerationStrategy();
 
 		@Override
 		public GenerationTiming getGenerationTiming() {
 			return GenerationTiming.NEVER;
 		}
 
 		@Override
 		public ValueGenerator getValueGenerator() {
 			return null;
 		}
 	}
 
 	private static class FullInMemoryValueGenerationStrategy implements InMemoryValueGenerationStrategy {
 		private final GenerationTiming timing;
 		private final ValueGenerator generator;
 
 		private FullInMemoryValueGenerationStrategy(GenerationTiming timing, ValueGenerator generator) {
 			this.timing = timing;
 			this.generator = generator;
 		}
 
 		public static FullInMemoryValueGenerationStrategy create(ValueGeneration valueGeneration) {
 			return new FullInMemoryValueGenerationStrategy(
 					valueGeneration.getGenerationTiming(),
 					valueGeneration.getValueGenerator()
 			);
 		}
 
 		@Override
 		public GenerationTiming getGenerationTiming() {
 			return timing;
 		}
 
 		@Override
 		public ValueGenerator getValueGenerator() {
 			return generator;
 		}
 	}
 
 	private static class NoInDatabaseValueGenerationStrategy implements InDatabaseValueGenerationStrategy {
 		/**
 		 * Singleton access
 		 */
 		public static final NoInDatabaseValueGenerationStrategy INSTANCE = new NoInDatabaseValueGenerationStrategy();
 
 		@Override
 		public GenerationTiming getGenerationTiming() {
 			return GenerationTiming.NEVER;
 		}
 
 		@Override
 		public boolean referenceColumnsInSql() {
 			return true;
 		}
 
 		@Override
 		public String[] getReferencedColumnValues() {
 			return null;
 		}
 	}
 
 	private static class InDatabaseValueGenerationStrategyImpl implements InDatabaseValueGenerationStrategy {
 		private final GenerationTiming timing;
 		private final boolean referenceColumnInSql;
 		private final String[] referencedColumnValues;
 
 		private InDatabaseValueGenerationStrategyImpl(
 				GenerationTiming timing,
 				boolean referenceColumnInSql,
 				String[] referencedColumnValues) {
 			this.timing = timing;
 			this.referenceColumnInSql = referenceColumnInSql;
 			this.referencedColumnValues = referencedColumnValues;
 		}
 
 		@Override
 		public GenerationTiming getGenerationTiming() {
 			return timing;
 		}
 
 		@Override
 		public boolean referenceColumnsInSql() {
 			return referenceColumnInSql;
 		}
 
 		@Override
 		public String[] getReferencedColumnValues() {
 			return referencedColumnValues;
 		}
 	}
 
 	private ValueInclusion determineInsertValueGenerationType(Property mappingProperty, NonIdentifierAttribute runtimeProperty) {
 		if ( isInsertGenerated( runtimeProperty ) ) {
 			return ValueInclusion.FULL;
 		}
 		else if ( mappingProperty.getValue() instanceof Component ) {
 			if ( hasPartialInsertComponentGeneration( ( Component ) mappingProperty.getValue() ) ) {
 				return ValueInclusion.PARTIAL;
 			}
 		}
 		return ValueInclusion.NONE;
 	}
 
 	private boolean isInsertGenerated(NonIdentifierAttribute property) {
 		return property.getValueGenerationStrategy() != null
 				&& property.getValueGenerationStrategy().getGenerationTiming() != GenerationTiming.NEVER;
 	}
 
 	private boolean isInsertGenerated(Property property) {
 		return property.getValueGenerationStrategy() != null
 				&& property.getValueGenerationStrategy().getGenerationTiming() != GenerationTiming.NEVER;
 	}
 
 	private boolean hasPartialInsertComponentGeneration(Component component) {
 		Iterator subProperties = component.getPropertyIterator();
 		while ( subProperties.hasNext() ) {
 			final Property prop = ( Property ) subProperties.next();
 			if ( isInsertGenerated( prop ) ) {
 				return true;
 			}
 			else if ( prop.getValue() instanceof Component ) {
 				if ( hasPartialInsertComponentGeneration( (Component) prop.getValue() ) ) {
 					return true;
 				}
 			}
 		}
 		return false;
 	}
 
 	private ValueInclusion determineUpdateValueGenerationType(Property mappingProperty, NonIdentifierAttribute runtimeProperty) {
 		if ( isUpdateGenerated( runtimeProperty ) ) {
 			return ValueInclusion.FULL;
 		}
 		else if ( mappingProperty.getValue() instanceof Component ) {
 			if ( hasPartialUpdateComponentGeneration( ( Component ) mappingProperty.getValue() ) ) {
 				return ValueInclusion.PARTIAL;
 			}
 		}
 		return ValueInclusion.NONE;
 	}
 
 	private static boolean isUpdateGenerated(Property property) {
 		return property.getValueGenerationStrategy() != null
 				&& property.getValueGenerationStrategy().getGenerationTiming() == GenerationTiming.ALWAYS;
 	}
 
 	private static boolean isUpdateGenerated(NonIdentifierAttribute property) {
 		return property.getValueGenerationStrategy() != null
 				&& property.getValueGenerationStrategy().getGenerationTiming() == GenerationTiming.ALWAYS;
 	}
 
 	private boolean hasPartialUpdateComponentGeneration(Component component) {
 		Iterator subProperties = component.getPropertyIterator();
 		while ( subProperties.hasNext() ) {
 			Property prop = (Property) subProperties.next();
 			if ( isUpdateGenerated( prop ) ) {
 				return true;
 			}
 			else if ( prop.getValue() instanceof Component ) {
 				if ( hasPartialUpdateComponentGeneration( ( Component ) prop.getValue() ) ) {
 					return true;
 				}
 			}
 		}
 		return false;
 	}
 
 	private void mapPropertyToIndex(Property prop, int i) {
 		propertyIndexes.put( prop.getName(), i );
 		if ( prop.getValue() instanceof Component ) {
 			Iterator iter = ( (Component) prop.getValue() ).getPropertyIterator();
 			while ( iter.hasNext() ) {
 				Property subprop = (Property) iter.next();
 				propertyIndexes.put(
 						prop.getName() + '.' + subprop.getName(),
 						i
 					);
 			}
 		}
 	}
 
 	public EntityTuplizer getTuplizer() {
 		return entityTuplizer;
 	}
 
 	public boolean isNaturalIdentifierInsertGenerated() {
 		// the intention is for this call to replace the usage of the old ValueInclusion stuff (as exposed from
 		// persister) in SelectGenerator to determine if it is safe to use the natural identifier to find the
 		// insert-generated identifier.  That wont work if the natural-id is also insert-generated.
 		//
 		// Assumptions:
 		//		* That code checks that there is a natural identifier before making this call, so we assume the same here
 		// 		* That code assumes a non-composite natural-id, so we assume the same here
 		final InDatabaseValueGenerationStrategy strategy = inDatabaseValueGenerationStrategies[ naturalIdPropertyNumbers[0] ];
 		return strategy != null && strategy.getGenerationTiming() != GenerationTiming.NEVER;
 	}
 
 	public boolean isVersionGenerated() {
 		final InDatabaseValueGenerationStrategy strategy = inDatabaseValueGenerationStrategies[ versionPropertyIndex ];
 		return strategy != null && strategy.getGenerationTiming() != GenerationTiming.NEVER;
 	}
 
 	public int[] getNaturalIdentifierProperties() {
 		return naturalIdPropertyNumbers;
 	}
 
 	public boolean hasNaturalIdentifier() {
 		return naturalIdPropertyNumbers!=null;
 	}
 	
 	public boolean isNaturalIdentifierCached() {
 		return hasNaturalIdentifier() && hasCacheableNaturalId;
 	}
 
 	public boolean hasImmutableNaturalId() {
 		return hasImmutableNaturalId;
 	}
 
 	public Set getSubclassEntityNames() {
 		return subclassEntityNames;
 	}
 
 	private boolean indicatesCollection(Type type) {
 		if ( type.isCollectionType() ) {
 			return true;
 		}
 		else if ( type.isComponentType() ) {
 			Type[] subtypes = ( (CompositeType) type ).getSubtypes();
 			for ( int i = 0; i < subtypes.length; i++ ) {
 				if ( indicatesCollection( subtypes[i] ) ) {
 					return true;
 				}
 			}
 		}
 		return false;
 	}
 
 	public SessionFactoryImplementor getSessionFactory() {
 		return sessionFactory;
 	}
 
 	public String getName() {
 		return name;
 	}
 
 	public String getRootName() {
 		return rootName;
 	}
 
 	public EntityType getEntityType() {
 		return entityType;
 	}
 
 	public IdentifierProperty getIdentifierProperty() {
 		return identifierAttribute;
 	}
 
 	public int getPropertySpan() {
 		return propertySpan;
 	}
 
 	public int getVersionPropertyIndex() {
 		return versionPropertyIndex;
 	}
 
 	public VersionProperty getVersionProperty() {
 		if ( NO_VERSION_INDX == versionPropertyIndex ) {
 			return null;
 		}
 		else {
 			return ( VersionProperty ) properties[ versionPropertyIndex ];
 		}
 	}
 
 	public NonIdentifierAttribute[] getProperties() {
 		return properties;
 	}
 
 	public int getPropertyIndex(String propertyName) {
 		Integer index = getPropertyIndexOrNull(propertyName);
 		if ( index == null ) {
 			throw new HibernateException("Unable to resolve property: " + propertyName);
 		}
 		return index;
 	}
 
 	public Integer getPropertyIndexOrNull(String propertyName) {
 		return propertyIndexes.get( propertyName );
 	}
 
 	public boolean hasCollections() {
 		return hasCollections;
 	}
 
 	public boolean hasMutableProperties() {
 		return hasMutableProperties;
 	}
 
 	public boolean hasNonIdentifierPropertyNamedId() {
 		return hasNonIdentifierPropertyNamedId;
 	}
 
 	public boolean hasLazyProperties() {
 		return hasLazyProperties;
 	}
 
 	public boolean hasCascades() {
 		return hasCascades;
 	}
 
 	public boolean isMutable() {
 		return mutable;
 	}
 
 	public boolean isSelectBeforeUpdate() {
 		return selectBeforeUpdate;
 	}
 
 	public boolean isDynamicUpdate() {
 		return dynamicUpdate;
 	}
 
 	public boolean isDynamicInsert() {
 		return dynamicInsert;
 	}
 
 	public OptimisticLockStyle getOptimisticLockStyle() {
 		return optimisticLockStyle;
 	}
 
 	public boolean isPolymorphic() {
 		return polymorphic;
 	}
 
 	public String getSuperclass() {
 		return superclass;
 	}
 
 	public boolean isExplicitPolymorphism() {
 		return explicitPolymorphism;
 	}
 
 	public boolean isInherited() {
 		return inherited;
 	}
 
 	public boolean hasSubclasses() {
 		return hasSubclasses;
 	}
 
 	public boolean isLazy() {
 		return lazy;
 	}
 
 	public void setLazy(boolean lazy) {
 		this.lazy = lazy;
 	}
 
 	public boolean isVersioned() {
 		return versioned;
 	}
 
 	public boolean isAbstract() {
 		return isAbstract;
 	}
 
 	/**
 	 * Return the entity-name mapped to the given class within our inheritance hierarchy, if any.
 	 *
 	 * @param inheritenceClass The class for which to resolve the entity-name.
 	 * @return The mapped entity-name, or null if no such mapping was found.
 	 */
 	public String findEntityNameByEntityClass(Class inheritenceClass) {
 		return ( String ) entityNameByInheritenceClassMap.get( inheritenceClass );
 	}
 
 	@Override
-    public String toString() {
+	public String toString() {
 		return "EntityMetamodel(" + name + ':' + ArrayHelper.toString(properties) + ')';
 	}
 
 	// temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	public String[] getPropertyNames() {
 		return propertyNames;
 	}
 
 	public Type[] getPropertyTypes() {
 		return propertyTypes;
 	}
 
 	public boolean[] getPropertyLaziness() {
 		return propertyLaziness;
 	}
 
 	public boolean[] getPropertyUpdateability() {
 		return propertyUpdateability;
 	}
 
 	public boolean[] getPropertyCheckability() {
 		return propertyCheckability;
 	}
 
 	public boolean[] getNonlazyPropertyUpdateability() {
 		return nonlazyPropertyUpdateability;
 	}
 
 	public boolean[] getPropertyInsertability() {
 		return propertyInsertability;
 	}
 
 	public boolean[] getPropertyNullability() {
 		return propertyNullability;
 	}
 
 	public boolean[] getPropertyVersionability() {
 		return propertyVersionability;
 	}
 
 	public CascadeStyle[] getCascadeStyles() {
 		return cascadeStyles;
 	}
 
 	public boolean hasPreInsertGeneratedValues() {
 		return hasPreInsertGeneratedValues;
 	}
 
 	public boolean hasPreUpdateGeneratedValues() {
 		return hasPreUpdateGeneratedValues;
 	}
 
 	public boolean hasInsertGeneratedValues() {
 		return hasInsertGeneratedValues;
 	}
 
 	public boolean hasUpdateGeneratedValues() {
 		return hasUpdateGeneratedValues;
 	}
 
 	public InMemoryValueGenerationStrategy[] getInMemoryValueGenerationStrategies() {
 		return inMemoryValueGenerationStrategies;
 	}
 
 	public InDatabaseValueGenerationStrategy[] getInDatabaseValueGenerationStrategies() {
 		return inDatabaseValueGenerationStrategies;
 	}
 
 	public EntityMode getEntityMode() {
 		return entityMode;
 	}
 
 	/**
 	 * Whether or not this class can be lazy (ie intercepted)
 	 */
 	public boolean isInstrumented() {
 		return instrumentationMetadata.isInstrumented();
 	}
 
 	public EntityInstrumentationMetadata getInstrumentationMetadata() {
 		return instrumentationMetadata;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/entity/PojoEntityTuplizer.java b/hibernate-core/src/main/java/org/hibernate/tuple/entity/PojoEntityTuplizer.java
index 4d4aed4bd4..32cfb7daed 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/entity/PojoEntityTuplizer.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/entity/PojoEntityTuplizer.java
@@ -1,340 +1,349 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple.entity;
 
 import java.lang.reflect.Method;
 import java.lang.reflect.Modifier;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.EntityMode;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.bytecode.instrumentation.internal.FieldInterceptionHelper;
 import org.hibernate.bytecode.instrumentation.spi.FieldInterceptor;
 import org.hibernate.bytecode.spi.ReflectionOptimizer;
 import org.hibernate.cfg.Environment;
 import org.hibernate.classic.Lifecycle;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Subclass;
 import org.hibernate.property.Getter;
 import org.hibernate.property.Setter;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.ProxyFactory;
 import org.hibernate.tuple.Instantiator;
 import org.hibernate.tuple.PojoInstantiator;
 import org.hibernate.type.CompositeType;
 
 /**
  * An {@link EntityTuplizer} specific to the pojo entity mode.
  *
  * @author Steve Ebersole
  * @author Gavin King
  */
 public class PojoEntityTuplizer extends AbstractEntityTuplizer {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( PojoEntityTuplizer.class );
 
 	private final Class mappedClass;
 	private final Class proxyInterface;
 	private final boolean lifecycleImplementor;
-	private final Set lazyPropertyNames = new HashSet();
+	private final Set<String> lazyPropertyNames = new HashSet<String>();
 	private final ReflectionOptimizer optimizer;
 	private final boolean isInstrumented;
 
 	public PojoEntityTuplizer(EntityMetamodel entityMetamodel, PersistentClass mappedEntity) {
 		super( entityMetamodel, mappedEntity );
 		this.mappedClass = mappedEntity.getMappedClass();
 		this.proxyInterface = mappedEntity.getProxyInterface();
 		this.lifecycleImplementor = Lifecycle.class.isAssignableFrom( mappedClass );
 		this.isInstrumented = entityMetamodel.isInstrumented();
 
 		Iterator iter = mappedEntity.getPropertyClosureIterator();
 		while ( iter.hasNext() ) {
 			Property property = (Property) iter.next();
 			if ( property.isLazy() ) {
 				lazyPropertyNames.add( property.getName() );
 			}
 		}
 
 		String[] getterNames = new String[propertySpan];
 		String[] setterNames = new String[propertySpan];
 		Class[] propTypes = new Class[propertySpan];
 		for ( int i = 0; i < propertySpan; i++ ) {
 			getterNames[i] = getters[i].getMethodName();
 			setterNames[i] = setters[i].getMethodName();
 			propTypes[i] = getters[i].getReturnType();
 		}
 
 		if ( hasCustomAccessors || !Environment.useReflectionOptimizer() ) {
 			optimizer = null;
 		}
 		else {
 			// todo : YUCK!!!
-			optimizer = Environment.getBytecodeProvider().getReflectionOptimizer( mappedClass, getterNames, setterNames, propTypes );
+			optimizer = Environment.getBytecodeProvider().getReflectionOptimizer(
+					mappedClass,
+					getterNames,
+					setterNames,
+					propTypes
+			);
 //			optimizer = getFactory().getSettings().getBytecodeProvider().getReflectionOptimizer(
 //					mappedClass, getterNames, setterNames, propTypes
 //			);
 		}
 	}
 
 	@Override
-    protected ProxyFactory buildProxyFactory(PersistentClass persistentClass, Getter idGetter, Setter idSetter) {
+	protected ProxyFactory buildProxyFactory(PersistentClass persistentClass, Getter idGetter, Setter idSetter) {
 		// determine the id getter and setter methods from the proxy interface (if any)
-        // determine all interfaces needed by the resulting proxy
+		// determine all interfaces needed by the resulting proxy
 		
 		/*
 		 * We need to preserve the order of the interfaces they were put into the set, since javassist will choose the
 		 * first one's class-loader to construct the proxy class with. This is also the reason why HibernateProxy.class
 		 * should be the last one in the order (on JBossAS7 its class-loader will be org.hibernate module's class-
 		 * loader, which will not see the classes inside deployed apps.  See HHH-3078
 		 */
 		Set<Class> proxyInterfaces = new java.util.LinkedHashSet<Class>();
 
 		Class mappedClass = persistentClass.getMappedClass();
 		Class proxyInterface = persistentClass.getProxyInterface();
 
-		if ( proxyInterface!=null && !mappedClass.equals( proxyInterface ) ) {
+		if ( proxyInterface != null && !mappedClass.equals( proxyInterface ) ) {
 			if ( !proxyInterface.isInterface() ) {
 				throw new MappingException(
 						"proxy must be either an interface, or the class itself: " + getEntityName()
 				);
 			}
 			proxyInterfaces.add( proxyInterface );
 		}
 
 		if ( mappedClass.isInterface() ) {
 			proxyInterfaces.add( mappedClass );
 		}
 
-		Iterator subclasses = persistentClass.getSubclassIterator();
+		Iterator<Subclass> subclasses = persistentClass.getSubclassIterator();
 		while ( subclasses.hasNext() ) {
-			final Subclass subclass = ( Subclass ) subclasses.next();
+			final Subclass subclass = subclasses.next();
 			final Class subclassProxy = subclass.getProxyInterface();
 			final Class subclassClass = subclass.getMappedClass();
-			if ( subclassProxy!=null && !subclassClass.equals( subclassProxy ) ) {
+			if ( subclassProxy != null && !subclassClass.equals( subclassProxy ) ) {
 				if ( !subclassProxy.isInterface() ) {
 					throw new MappingException(
 							"proxy must be either an interface, or the class itself: " + subclass.getEntityName()
 					);
 				}
 				proxyInterfaces.add( subclassProxy );
 			}
 		}
 
 		proxyInterfaces.add( HibernateProxy.class );
 
 		Iterator properties = persistentClass.getPropertyIterator();
 		Class clazz = persistentClass.getMappedClass();
 		while ( properties.hasNext() ) {
 			Property property = (Property) properties.next();
-			Method method = property.getGetter(clazz).getMethod();
+			Method method = property.getGetter( clazz ).getMethod();
 			if ( method != null && Modifier.isFinal( method.getModifiers() ) ) {
-                LOG.gettersOfLazyClassesCannotBeFinal(persistentClass.getEntityName(), property.getName());
+				LOG.gettersOfLazyClassesCannotBeFinal( persistentClass.getEntityName(), property.getName() );
 			}
-			method = property.getSetter(clazz).getMethod();
-            if ( method != null && Modifier.isFinal( method.getModifiers() ) ) {
-                LOG.settersOfLazyClassesCannotBeFinal(persistentClass.getEntityName(), property.getName());
+			method = property.getSetter( clazz ).getMethod();
+			if ( method != null && Modifier.isFinal( method.getModifiers() ) ) {
+				LOG.settersOfLazyClassesCannotBeFinal( persistentClass.getEntityName(), property.getName() );
 			}
 		}
 
-		Method idGetterMethod = idGetter==null ? null : idGetter.getMethod();
-		Method idSetterMethod = idSetter==null ? null : idSetter.getMethod();
+		Method idGetterMethod = idGetter == null ? null : idGetter.getMethod();
+		Method idSetterMethod = idSetter == null ? null : idSetter.getMethod();
 
-		Method proxyGetIdentifierMethod = idGetterMethod==null || proxyInterface==null ?
+		Method proxyGetIdentifierMethod = idGetterMethod == null || proxyInterface == null ?
 				null :
-		        ReflectHelper.getMethod(proxyInterface, idGetterMethod);
-		Method proxySetIdentifierMethod = idSetterMethod==null || proxyInterface==null  ?
+				ReflectHelper.getMethod( proxyInterface, idGetterMethod );
+		Method proxySetIdentifierMethod = idSetterMethod == null || proxyInterface == null ?
 				null :
-		        ReflectHelper.getMethod(proxyInterface, idSetterMethod);
+				ReflectHelper.getMethod( proxyInterface, idSetterMethod );
 
 		ProxyFactory pf = buildProxyFactoryInternal( persistentClass, idGetter, idSetter );
 		try {
 			pf.postInstantiate(
 					getEntityName(),
 					mappedClass,
 					proxyInterfaces,
 					proxyGetIdentifierMethod,
 					proxySetIdentifierMethod,
 					persistentClass.hasEmbeddedIdentifier() ?
-			                (CompositeType) persistentClass.getIdentifier().getType() :
-			                null
+							(CompositeType) persistentClass.getIdentifier().getType() :
+							null
 			);
 		}
-		catch ( HibernateException he ) {
-            LOG.unableToCreateProxyFactory(getEntityName(), he);
+		catch (HibernateException he) {
+			LOG.unableToCreateProxyFactory( getEntityName(), he );
 			pf = null;
 		}
 		return pf;
 	}
 
-	protected ProxyFactory buildProxyFactoryInternal(PersistentClass persistentClass, Getter idGetter, Setter idSetter) {
+	protected ProxyFactory buildProxyFactoryInternal(
+			PersistentClass persistentClass,
+			Getter idGetter,
+			Setter idSetter) {
 		// TODO : YUCK!!!  fix after HHH-1907 is complete
 		return Environment.getBytecodeProvider().getProxyFactoryFactory().buildProxyFactory();
 //		return getFactory().getSettings().getBytecodeProvider().getProxyFactoryFactory().buildProxyFactory();
 	}
 
 	@Override
-    protected Instantiator buildInstantiator(PersistentClass persistentClass) {
+	protected Instantiator buildInstantiator(PersistentClass persistentClass) {
 		if ( optimizer == null ) {
 			return new PojoInstantiator( persistentClass, null );
 		}
 		else {
 			return new PojoInstantiator( persistentClass, optimizer.getInstantiationOptimizer() );
 		}
 	}
 
 	@Override
-    public void setPropertyValues(Object entity, Object[] values) throws HibernateException {
+	public void setPropertyValues(Object entity, Object[] values) throws HibernateException {
 		if ( !getEntityMetamodel().hasLazyProperties() && optimizer != null && optimizer.getAccessOptimizer() != null ) {
 			setPropertyValuesWithOptimizer( entity, values );
 		}
 		else {
 			super.setPropertyValues( entity, values );
 		}
 	}
 
 	@Override
-    public Object[] getPropertyValues(Object entity) throws HibernateException {
+	public Object[] getPropertyValues(Object entity) throws HibernateException {
 		if ( shouldGetAllProperties( entity ) && optimizer != null && optimizer.getAccessOptimizer() != null ) {
 			return getPropertyValuesWithOptimizer( entity );
 		}
 		else {
 			return super.getPropertyValues( entity );
 		}
 	}
 
 	@Override
-    public Object[] getPropertyValuesToInsert(Object entity, Map mergeMap, SessionImplementor session) throws HibernateException {
+	public Object[] getPropertyValuesToInsert(Object entity, Map mergeMap, SessionImplementor session)
+			throws HibernateException {
 		if ( shouldGetAllProperties( entity ) && optimizer != null && optimizer.getAccessOptimizer() != null ) {
 			return getPropertyValuesWithOptimizer( entity );
 		}
 		else {
 			return super.getPropertyValuesToInsert( entity, mergeMap, session );
 		}
 	}
 
 	protected void setPropertyValuesWithOptimizer(Object object, Object[] values) {
 		optimizer.getAccessOptimizer().setPropertyValues( object, values );
 	}
 
 	protected Object[] getPropertyValuesWithOptimizer(Object object) {
 		return optimizer.getAccessOptimizer().getPropertyValues( object );
 	}
 
 	@Override
 	public EntityMode getEntityMode() {
 		return EntityMode.POJO;
 	}
 
 	@Override
 	public Class getMappedClass() {
 		return mappedClass;
 	}
 
 	@Override
-    public boolean isLifecycleImplementor() {
+	public boolean isLifecycleImplementor() {
 		return lifecycleImplementor;
 	}
 
 	@Override
-    protected Getter buildPropertyGetter(Property mappedProperty, PersistentClass mappedEntity) {
+	protected Getter buildPropertyGetter(Property mappedProperty, PersistentClass mappedEntity) {
 		return mappedProperty.getGetter( mappedEntity.getMappedClass() );
 	}
 
 	@Override
-    protected Setter buildPropertySetter(Property mappedProperty, PersistentClass mappedEntity) {
+	protected Setter buildPropertySetter(Property mappedProperty, PersistentClass mappedEntity) {
 		return mappedProperty.getSetter( mappedEntity.getMappedClass() );
 	}
 
 	@Override
 	public Class getConcreteProxyClass() {
 		return proxyInterface;
 	}
 
-    //TODO: need to make the majority of this functionality into a top-level support class for custom impl support
+	//TODO: need to make the majority of this functionality into a top-level support class for custom impl support
 
 	@Override
-    public void afterInitialize(Object entity, boolean lazyPropertiesAreUnfetched, SessionImplementor session) {
+	public void afterInitialize(Object entity, boolean lazyPropertiesAreUnfetched, SessionImplementor session) {
 		if ( isInstrumented() ) {
-			Set lazyProps = lazyPropertiesAreUnfetched && getEntityMetamodel().hasLazyProperties() ?
+			Set<String> lazyProps = lazyPropertiesAreUnfetched && getEntityMetamodel().hasLazyProperties() ?
 					lazyPropertyNames : null;
 			//TODO: if we support multiple fetch groups, we would need
 			//      to clone the set of lazy properties!
 			FieldInterceptionHelper.injectFieldInterceptor( entity, getEntityName(), lazyProps, session );
 
-            //also clear the fields that are marked as dirty in the dirtyness tracker
-            if(entity instanceof org.hibernate.engine.spi.SelfDirtinessTracker) {
-                ((org.hibernate.engine.spi.SelfDirtinessTracker) entity).$$_hibernate_clearDirtyAttributes();
-            }
+			//also clear the fields that are marked as dirty in the dirtyness tracker
+			if ( entity instanceof org.hibernate.engine.spi.SelfDirtinessTracker ) {
+				( (org.hibernate.engine.spi.SelfDirtinessTracker) entity ).$$_hibernate_clearDirtyAttributes();
+			}
 		}
 	}
 
 	@Override
-    public boolean hasUninitializedLazyProperties(Object entity) {
+	public boolean hasUninitializedLazyProperties(Object entity) {
 		if ( getEntityMetamodel().hasLazyProperties() ) {
 			FieldInterceptor callback = FieldInterceptionHelper.extractFieldInterceptor( entity );
 			return callback != null && !callback.isInitialized();
 		}
 		else {
 			return false;
 		}
 	}
 
 	@Override
 	public boolean isInstrumented() {
 		return isInstrumented;
 	}
 
 	@Override
 	public String determineConcreteSubclassEntityName(Object entityInstance, SessionFactoryImplementor factory) {
 		final Class concreteEntityClass = entityInstance.getClass();
 		if ( concreteEntityClass == getMappedClass() ) {
 			return getEntityName();
 		}
 		else {
 			String entityName = getEntityMetamodel().findEntityNameByEntityClass( concreteEntityClass );
 			if ( entityName == null ) {
 				throw new HibernateException(
 						"Unable to resolve entity name from Class [" + concreteEntityClass.getName() + "]"
 								+ " expected instance/subclass of [" + getEntityName() + "]"
 				);
 			}
 			return entityName;
 		}
 	}
 
 	@Override
 	public EntityNameResolver[] getEntityNameResolvers() {
 		return null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/entity/VersionProperty.java b/hibernate-core/src/main/java/org/hibernate/tuple/entity/VersionProperty.java
index 51a8e67d4e..086f9e03ff 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/entity/VersionProperty.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/entity/VersionProperty.java
@@ -1,70 +1,70 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple.entity;
 
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.VersionValue;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.tuple.AbstractNonIdentifierAttribute;
 import org.hibernate.tuple.BaselineAttributeInformation;
 import org.hibernate.type.Type;
 
 /**
  * Represents a version property within the Hibernate runtime-metamodel.
  *
  * @author Steve Ebersole
  */
 public class VersionProperty extends AbstractNonIdentifierAttribute {
-
-    private final VersionValue unsavedValue;
+	private final VersionValue unsavedValue;
 
 	/**
 	 * Constructs VersionProperty instances.
 	 *
 	 * @param source Reference back to the source of this attribute (the persister)
 	 * @param sessionFactory The session factory this is part of.
 	 * @param attributeNumber The attribute number within thje
 	 * @param attributeName The name by which the property can be referenced within
 	 * its owner.
 	 * @param attributeType The Hibernate Type of this property.
 	 * @param attributeInformation The basic attribute information.
 	 * @param unsavedValue The value which, if found as the value of
 	 * this (i.e., the version) property, represents new (i.e., un-saved)
 	 * instances of the owning entity.
 	 */
 	public VersionProperty(
 			EntityPersister source,
 			SessionFactoryImplementor sessionFactory,
 			int attributeNumber,
 			String attributeName,
 			Type attributeType,
-			BaselineAttributeInformation attributeInformation, VersionValue unsavedValue) {
+			BaselineAttributeInformation attributeInformation,
+			VersionValue unsavedValue) {
 		super( source, sessionFactory, attributeNumber, attributeName, attributeType, attributeInformation );
 		this.unsavedValue = unsavedValue;
 	}
 
-    public VersionValue getUnsavedValue() {
-        return unsavedValue;
-    }
+	public VersionValue getUnsavedValue() {
+		return unsavedValue;
+	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/AbstractStandardBasicType.java b/hibernate-core/src/main/java/org/hibernate/type/AbstractStandardBasicType.java
index 88624d31f1..58a763bbad 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/AbstractStandardBasicType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/AbstractStandardBasicType.java
@@ -1,404 +1,403 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Map;
 
 import org.hibernate.Hibernate;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.jdbc.LobCreator;
 import org.hibernate.engine.jdbc.Size;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.type.descriptor.WrapperOptions;
 import org.hibernate.type.descriptor.java.JavaTypeDescriptor;
 import org.hibernate.type.descriptor.java.MutabilityPlan;
 import org.hibernate.type.descriptor.sql.SqlTypeDescriptor;
 
 import org.dom4j.Node;
 
 /**
  * Convenience base class for {@link BasicType} implementations
  *
  * @author Steve Ebersole
  * @author Brett Meyer
  */
 public abstract class AbstractStandardBasicType<T>
 		implements BasicType, StringRepresentableType<T>, ProcedureParameterExtractionAware<T> {
 
 	private static final Size DEFAULT_SIZE = new Size( 19, 2, 255, Size.LobMultiplier.NONE ); // to match legacy behavior
 	private final Size dictatedSize = new Size();
 
 	// Don't use final here.  Need to initialize after-the-fact
 	// by DynamicParameterizedTypes.
 	private SqlTypeDescriptor sqlTypeDescriptor;
 	private JavaTypeDescriptor<T> javaTypeDescriptor;
 	// sqlTypes need always to be in sync with sqlTypeDescriptor
 	private int[] sqlTypes;
 
 	public AbstractStandardBasicType(SqlTypeDescriptor sqlTypeDescriptor, JavaTypeDescriptor<T> javaTypeDescriptor) {
 		this.sqlTypeDescriptor = sqlTypeDescriptor;
 		this.sqlTypes = new int[] { sqlTypeDescriptor.getSqlType() };
 		this.javaTypeDescriptor = javaTypeDescriptor;
 	}
 
 	public T fromString(String string) {
 		return javaTypeDescriptor.fromString( string );
 	}
 
 	public String toString(T value) {
 		return javaTypeDescriptor.toString( value );
 	}
 
 	public T fromStringValue(String xml) throws HibernateException {
 		return fromString( xml );
 	}
 
 	protected MutabilityPlan<T> getMutabilityPlan() {
 		return javaTypeDescriptor.getMutabilityPlan();
 	}
 
 	protected T getReplacement(T original, T target, SessionImplementor session) {
 		if ( !isMutable() ) {
 			return original;
 		}
 		else if ( isEqual( original, target ) ) {
 			return original;
 		}
 		else {
 			return deepCopy( original );
 		}
 	}
 
 	public boolean[] toColumnNullness(Object value, Mapping mapping) {
 		return value == null ? ArrayHelper.FALSE : ArrayHelper.TRUE;
 	}
 
 	public String[] getRegistrationKeys() {
 		return registerUnderJavaType()
 				? new String[] { getName(), javaTypeDescriptor.getJavaTypeClass().getName() }
 				: new String[] { getName() };
 	}
 
 	protected boolean registerUnderJavaType() {
 		return false;
 	}
 
 	protected static Size getDefaultSize() {
 		return DEFAULT_SIZE;
 	}
 
 	protected Size getDictatedSize() {
 		return dictatedSize;
 	}
 	
 	// final implementations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public final JavaTypeDescriptor<T> getJavaTypeDescriptor() {
 		return javaTypeDescriptor;
 	}
 	
 	public final void setJavaTypeDescriptor( JavaTypeDescriptor<T> javaTypeDescriptor ) {
 		this.javaTypeDescriptor = javaTypeDescriptor;
 	}
 
 	public final SqlTypeDescriptor getSqlTypeDescriptor() {
 		return sqlTypeDescriptor;
 	}
 
 	public final void setSqlTypeDescriptor( SqlTypeDescriptor sqlTypeDescriptor ) {
 		this.sqlTypeDescriptor = sqlTypeDescriptor;
 		this.sqlTypes = new int[] { sqlTypeDescriptor.getSqlType() };
 	}
 
 	public final Class getReturnedClass() {
 		return javaTypeDescriptor.getJavaTypeClass();
 	}
 
 	public final int getColumnSpan(Mapping mapping) throws MappingException {
 		return 1;
 	}
 
 	public final int[] sqlTypes(Mapping mapping) throws MappingException {
 		return sqlTypes;
 	}
 
 	@Override
 	public Size[] dictatedSizes(Mapping mapping) throws MappingException {
 		return new Size[] { getDictatedSize() };
 	}
 
 	@Override
 	public Size[] defaultSizes(Mapping mapping) throws MappingException {
 		return new Size[] { getDefaultSize() };
 	}
 
 	public final boolean isAssociationType() {
 		return false;
 	}
 
 	public final boolean isCollectionType() {
 		return false;
 	}
 
 	public final boolean isComponentType() {
 		return false;
 	}
 
 	public final boolean isEntityType() {
 		return false;
 	}
 
 	public final boolean isAnyType() {
 		return false;
 	}
 
 	public final boolean isXMLElement() {
 		return false;
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final boolean isSame(Object x, Object y) {
 		return isEqual( x, y );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final boolean isEqual(Object x, Object y, SessionFactoryImplementor factory) {
 		return isEqual( x, y );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final boolean isEqual(Object one, Object another) {
 		return javaTypeDescriptor.areEqual( (T) one, (T) another );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final int getHashCode(Object x) {
 		return javaTypeDescriptor.extractHashCode( (T) x );
 	}
 
 	public final int getHashCode(Object x, SessionFactoryImplementor factory) {
 		return getHashCode( x );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final int compare(Object x, Object y) {
 		return javaTypeDescriptor.getComparator().compare( (T) x, (T) y );
 	}
 
 	public final boolean isDirty(Object old, Object current, SessionImplementor session) {
 		return isDirty( old, current );
 	}
 
 	public final boolean isDirty(Object old, Object current, boolean[] checkable, SessionImplementor session) {
 		return checkable[0] && isDirty( old, current );
 	}
 
 	protected final boolean isDirty(Object old, Object current) {
 		return !isSame( old, current );
 	}
 
 	public final boolean isModified(
 			Object oldHydratedState,
 			Object currentState,
 			boolean[] checkable,
 			SessionImplementor session) {
 		return isDirty( oldHydratedState, currentState );
 	}
 
 	public final Object nullSafeGet(
 			ResultSet rs,
 			String[] names,
 			SessionImplementor session,
 			Object owner) throws SQLException {
 		return nullSafeGet( rs, names[0], session );
 	}
 
 	public final Object nullSafeGet(ResultSet rs, String name, SessionImplementor session, Object owner)
 			throws SQLException {
 		return nullSafeGet( rs, name, session );
 	}
 
 	public final T nullSafeGet(ResultSet rs, String name, final SessionImplementor session) throws SQLException {
 		final WrapperOptions options = getOptions(session);
 		return nullSafeGet( rs, name, options );
 	}
 
 	protected final T nullSafeGet(ResultSet rs, String name, WrapperOptions options) throws SQLException {
 		return remapSqlTypeDescriptor( options ).getExtractor( javaTypeDescriptor ).extract( rs, name, options );
 	}
 
 	public Object get(ResultSet rs, String name, SessionImplementor session) throws HibernateException, SQLException {
 		return nullSafeGet( rs, name, session );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final void nullSafeSet(
 			PreparedStatement st,
 			Object value,
 			int index,
 			final SessionImplementor session) throws SQLException {
 		final WrapperOptions options = getOptions(session);
 		nullSafeSet( st, value, index, options );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	protected final void nullSafeSet(PreparedStatement st, Object value, int index, WrapperOptions options) throws SQLException {
 		remapSqlTypeDescriptor( options ).getBinder( javaTypeDescriptor ).bind( st, ( T ) value, index, options );
 	}
 
 	protected SqlTypeDescriptor remapSqlTypeDescriptor(WrapperOptions options) {
 		return options.remapSqlTypeDescriptor( sqlTypeDescriptor );
 	}
 
 	public void set(PreparedStatement st, T value, int index, SessionImplementor session) throws HibernateException, SQLException {
 		nullSafeSet( st, value, index, session );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final String toLoggableString(Object value, SessionFactoryImplementor factory) {
 		return javaTypeDescriptor.extractLoggableRepresentation( (T) value );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final void setToXMLNode(Node node, Object value, SessionFactoryImplementor factory) {
 		node.setText( toString( (T) value ) );
 	}
 
 	public final Object fromXMLNode(Node xml, Mapping factory) {
 		return fromString( xml.getText() );
 	}
 
 	public final boolean isMutable() {
 		return getMutabilityPlan().isMutable();
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final Object deepCopy(Object value, SessionFactoryImplementor factory) {
 		return deepCopy( (T) value );
 	}
 
 	protected final T deepCopy(T value) {
 		return getMutabilityPlan().deepCopy( value );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final Serializable disassemble(Object value, SessionImplementor session, Object owner) throws HibernateException {
 		return getMutabilityPlan().disassemble( (T) value );
 	}
 
 	public final Object assemble(Serializable cached, SessionImplementor session, Object owner) throws HibernateException {
 		return getMutabilityPlan().assemble( cached );
 	}
 
 	public final void beforeAssemble(Serializable cached, SessionImplementor session) {
 	}
 
 	public final Object hydrate(ResultSet rs, String[] names, SessionImplementor session, Object owner)
 			throws HibernateException, SQLException {
 		return nullSafeGet(rs, names, session, owner);
 	}
 
 	public final Object resolve(Object value, SessionImplementor session, Object owner) throws HibernateException {
 		return value;
 	}
 
 	public final Object semiResolve(Object value, SessionImplementor session, Object owner) throws HibernateException {
 		return value;
 	}
 
 	public final Type getSemiResolvedType(SessionFactoryImplementor factory) {
 		return this;
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public final Object replace(Object original, Object target, SessionImplementor session, Object owner, Map copyCache) {
 		return getReplacement( (T) original, (T) target, session );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public Object replace(
 			Object original,
 			Object target,
 			SessionImplementor session,
 			Object owner,
 			Map copyCache,
 			ForeignKeyDirection foreignKeyDirection) {
 		return ForeignKeyDirection.FROM_PARENT == foreignKeyDirection
 				? getReplacement( (T) original, (T) target, session )
 				: target;
 	}
 
 	@Override
 	public boolean canDoExtraction() {
 		return true;
 	}
 
 	@Override
 	public T extract(CallableStatement statement, int startIndex, final SessionImplementor session) throws SQLException {
 		final WrapperOptions options = getOptions(session);
 		return remapSqlTypeDescriptor( options ).getExtractor( javaTypeDescriptor ).extract(
 				statement,
 				startIndex,
 				options
 		);
 	}
 
 	@Override
 	public T extract(CallableStatement statement, String[] paramNames, final SessionImplementor session) throws SQLException {
 		final WrapperOptions options = getOptions(session);
 		return remapSqlTypeDescriptor( options ).getExtractor( javaTypeDescriptor ).extract( statement, paramNames, options );
 	}
 	
 	// TODO : have SessionImplementor extend WrapperOptions
 	private WrapperOptions getOptions(final SessionImplementor session) {
 		return new WrapperOptions() {
 			public boolean useStreamForLobBinding() {
 				return Environment.useStreamsForBinary()
 						|| session.getFactory().getDialect().useInputStreamToInsertBlob();
 			}
 
 			public LobCreator getLobCreator() {
 				return Hibernate.getLobCreator( session );
 			}
 
 			public SqlTypeDescriptor remapSqlTypeDescriptor(SqlTypeDescriptor sqlTypeDescriptor) {
 				final SqlTypeDescriptor remapped = sqlTypeDescriptor.canBeRemapped()
 						? session.getFactory().getDialect().remapSqlTypeDescriptor( sqlTypeDescriptor )
 						: sqlTypeDescriptor;
 				return remapped == null ? sqlTypeDescriptor : remapped;
 			}
 		};
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/BasicTypeRegistry.java b/hibernate-core/src/main/java/org/hibernate/type/BasicTypeRegistry.java
index 1ffafd539b..e302631c1c 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/BasicTypeRegistry.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/BasicTypeRegistry.java
@@ -1,174 +1,170 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
+
 import org.hibernate.HibernateException;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.usertype.CompositeUserType;
 import org.hibernate.usertype.UserType;
-import org.jboss.logging.Logger;
-
-import java.io.Serializable;
-import java.util.Map;
-import java.util.concurrent.ConcurrentHashMap;
 
 /**
  * A registry of {@link BasicType} instances
  *
  * @author Steve Ebersole
  */
 public class BasicTypeRegistry implements Serializable {
-    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( BasicTypeRegistry.class );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( BasicTypeRegistry.class );
 
 	// TODO : analyze these sizing params; unfortunately this seems to be the only way to give a "concurrencyLevel"
-	private Map<String,BasicType> registry = new ConcurrentHashMap<String, BasicType>( 100, .75f, 1 );
+	private Map<String, BasicType> registry = new ConcurrentHashMap<String, BasicType>( 100, .75f, 1 );
 	private boolean locked;
 
 	public BasicTypeRegistry() {
 		register( BooleanType.INSTANCE );
 		register( NumericBooleanType.INSTANCE );
 		register( TrueFalseType.INSTANCE );
 		register( YesNoType.INSTANCE );
 
 		register( ByteType.INSTANCE );
 		register( CharacterType.INSTANCE );
 		register( ShortType.INSTANCE );
 		register( IntegerType.INSTANCE );
 		register( LongType.INSTANCE );
 		register( FloatType.INSTANCE );
 		register( DoubleType.INSTANCE );
 		register( BigDecimalType.INSTANCE );
 		register( BigIntegerType.INSTANCE );
 
 		register( StringType.INSTANCE );
 		register( StringNVarcharType.INSTANCE );
 		register( CharacterNCharType.INSTANCE );
 		register( UrlType.INSTANCE );
 
 		register( DateType.INSTANCE );
 		register( TimeType.INSTANCE );
 		register( TimestampType.INSTANCE );
 		register( DbTimestampType.INSTANCE );
 		register( CalendarType.INSTANCE );
 		register( CalendarDateType.INSTANCE );
 
 		register( LocaleType.INSTANCE );
 		register( CurrencyType.INSTANCE );
 		register( TimeZoneType.INSTANCE );
 		register( ClassType.INSTANCE );
 		register( UUIDBinaryType.INSTANCE );
 		register( UUIDCharType.INSTANCE );
 
 		register( BinaryType.INSTANCE );
 		register( WrapperBinaryType.INSTANCE );
 		register( ImageType.INSTANCE );
 		register( CharArrayType.INSTANCE );
 		register( CharacterArrayType.INSTANCE );
 		register( TextType.INSTANCE );
 		register( NTextType.INSTANCE );
 		register( BlobType.INSTANCE );
 		register( MaterializedBlobType.INSTANCE );
 		register( ClobType.INSTANCE );
 		register( NClobType.INSTANCE );
 		register( MaterializedClobType.INSTANCE );
 		register( MaterializedNClobType.INSTANCE );
 		register( SerializableType.INSTANCE );
 
 		register( ObjectType.INSTANCE );
 
 		//noinspection unchecked
 		register( new AdaptedImmutableType( DateType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( TimeType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( TimestampType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( DbTimestampType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( CalendarType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( CalendarDateType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( BinaryType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( SerializableType.INSTANCE ) );
 	}
 
 	/**
 	 * Constructor version used during shallow copy
 	 *
 	 * @param registeredTypes The type map to copy over
 	 */
-	@SuppressWarnings({ "UnusedDeclaration" })
+	@SuppressWarnings({"UnusedDeclaration"})
 	private BasicTypeRegistry(Map<String, BasicType> registeredTypes) {
 		registry.putAll( registeredTypes );
 		locked = true;
 	}
 
 	public void register(BasicType type) {
 		if ( locked ) {
 			throw new HibernateException( "Can not alter TypeRegistry at this time" );
 		}
 
 		if ( type == null ) {
 			throw new HibernateException( "Type to register cannot be null" );
 		}
 
 		if ( type.getRegistrationKeys() == null || type.getRegistrationKeys().length == 0 ) {
 			LOG.typeDefinedNoRegistrationKeys( type );
 		}
 
 		for ( String key : type.getRegistrationKeys() ) {
 			// be safe...
-            if (key == null) {
+			if ( key == null ) {
 				continue;
 			}
-            LOG.debugf("Adding type registration %s -> %s", key, type);
+			LOG.debugf( "Adding type registration %s -> %s", key, type );
 			final Type old = registry.put( key, type );
-            if (old != null && old != type) {
-				LOG.typeRegistrationOverridesPrevious(key, old);
+			if ( old != null && old != type ) {
+				LOG.typeRegistrationOverridesPrevious( key, old );
 			}
 		}
 	}
 
 	public void register(UserType type, String[] keys) {
 		register( new CustomType( type, keys ) );
 	}
 
 	public void register(CompositeUserType type, String[] keys) {
 		register( new CompositeCustomType( type, keys ) );
 	}
 
 	public BasicType getRegisteredType(String key) {
 		return registry.get( key );
 	}
 
 	public BasicTypeRegistry shallowCopy() {
 		return new BasicTypeRegistry( this.registry );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/BigDecimalType.java b/hibernate-core/src/main/java/org/hibernate/type/BigDecimalType.java
index 4b9e08c27b..e8d6b84d5f 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/BigDecimalType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/BigDecimalType.java
@@ -1,54 +1,53 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.math.BigDecimal;
-import java.sql.Types;
 
 import org.hibernate.type.descriptor.java.BigDecimalTypeDescriptor;
 import org.hibernate.type.descriptor.sql.NumericTypeDescriptor;
 
 /**
- * A type that maps between a {@link Types#NUMERIC NUMERIC} and {@link BigDecimal}.
+ * A type that maps between a {@link java.sql.Types#NUMERIC NUMERIC} and {@link BigDecimal}.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class BigDecimalType extends AbstractSingleColumnStandardBasicType<BigDecimal> {
 	public static final BigDecimalType INSTANCE = new BigDecimalType();
 
 	public BigDecimalType() {
 		super( NumericTypeDescriptor.INSTANCE, BigDecimalTypeDescriptor.INSTANCE );
 	}
 
 	@Override
 	public String getName() {
 		return "big_decimal";
 	}
 
 	@Override
 	protected boolean registerUnderJavaType() {
 		return true;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/BigIntegerType.java b/hibernate-core/src/main/java/org/hibernate/type/BigIntegerType.java
index b869c18e46..7bd2b81be4 100755
--- a/hibernate-core/src/main/java/org/hibernate/type/BigIntegerType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/BigIntegerType.java
@@ -1,68 +1,67 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.math.BigInteger;
-import java.sql.Types;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.type.descriptor.java.BigIntegerTypeDescriptor;
 import org.hibernate.type.descriptor.sql.BigIntTypeDescriptor;
 
 /**
- * A type that maps between a {@link Types#NUMERIC NUMERIC} and {@link BigInteger}.
+ * A type that maps between a {@link java.sql.Types#NUMERIC NUMERIC} and {@link BigInteger}.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class BigIntegerType
 		extends AbstractSingleColumnStandardBasicType<BigInteger>
 		implements DiscriminatorType<BigInteger> {
 
 	public static final BigIntegerType INSTANCE = new BigIntegerType();
 
 	public BigIntegerType() {
 		super( BigIntTypeDescriptor.INSTANCE, BigIntegerTypeDescriptor.INSTANCE );
 	}
 
 	@Override
 	public String getName() {
 		return "big_integer";
 	}
 
 	@Override
 	protected boolean registerUnderJavaType() {
 		return true;
 	}
 
 	@Override
 	public String objectToSQLString(BigInteger value, Dialect dialect) {
 		return BigIntegerTypeDescriptor.INSTANCE.toString( value );
 	}
 
 	@Override
 	public BigInteger stringToObject(String string) {
 		return BigIntegerTypeDescriptor.INSTANCE.fromString( string );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/ComponentType.java b/hibernate-core/src/main/java/org/hibernate/type/ComponentType.java
index ae7beaa20b..7c15d873e0 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/ComponentType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/ComponentType.java
@@ -1,816 +1,855 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.lang.reflect.Method;
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.EntityMode;
 import org.hibernate.FetchMode;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.PropertyNotFoundException;
+import org.hibernate.engine.jdbc.Size;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
-import org.hibernate.engine.jdbc.Size;
 import org.hibernate.tuple.StandardProperty;
 import org.hibernate.tuple.component.ComponentMetamodel;
 import org.hibernate.tuple.component.ComponentTuplizer;
 
 import org.dom4j.Element;
 import org.dom4j.Node;
 
 /**
  * Handles "component" mappings
  *
  * @author Gavin King
  */
 public class ComponentType extends AbstractType implements CompositeType, ProcedureParameterExtractionAware {
 
 	private final TypeFactory.TypeScope typeScope;
 	private final String[] propertyNames;
 	private final Type[] propertyTypes;
 	private final boolean[] propertyNullability;
 	protected final int propertySpan;
 	private final CascadeStyle[] cascade;
 	private final FetchMode[] joinedFetch;
 	private final boolean isKey;
 	private boolean hasNotNullProperty;
 
 	protected final EntityMode entityMode;
 	protected final ComponentTuplizer componentTuplizer;
 
 	public ComponentType(TypeFactory.TypeScope typeScope, ComponentMetamodel metamodel) {
 		this.typeScope = typeScope;
 		// for now, just "re-flatten" the metamodel since this is temporary stuff anyway (HHH-1907)
 		this.isKey = metamodel.isKey();
 		this.propertySpan = metamodel.getPropertySpan();
-		this.propertyNames = new String[ propertySpan ];
-		this.propertyTypes = new Type[ propertySpan ];
-		this.propertyNullability = new boolean[ propertySpan ];
-		this.cascade = new CascadeStyle[ propertySpan ];
-		this.joinedFetch = new FetchMode[ propertySpan ];
+		this.propertyNames = new String[propertySpan];
+		this.propertyTypes = new Type[propertySpan];
+		this.propertyNullability = new boolean[propertySpan];
+		this.cascade = new CascadeStyle[propertySpan];
+		this.joinedFetch = new FetchMode[propertySpan];
 
 		for ( int i = 0; i < propertySpan; i++ ) {
 			StandardProperty prop = metamodel.getProperty( i );
 			this.propertyNames[i] = prop.getName();
 			this.propertyTypes[i] = prop.getType();
 			this.propertyNullability[i] = prop.isNullable();
 			this.cascade[i] = prop.getCascadeStyle();
 			this.joinedFetch[i] = prop.getFetchMode();
-			if (!prop.isNullable()) {
+			if ( !prop.isNullable() ) {
 				hasNotNullProperty = true;
 			}
 		}
 
 		this.entityMode = metamodel.getEntityMode();
 		this.componentTuplizer = metamodel.getComponentTuplizer();
 	}
 
 	public boolean isKey() {
 		return isKey;
 	}
 
 	public EntityMode getEntityMode() {
 		return entityMode;
 	}
 
 	public ComponentTuplizer getComponentTuplizer() {
 		return componentTuplizer;
 	}
+
 	@Override
 	public int getColumnSpan(Mapping mapping) throws MappingException {
 		int span = 0;
 		for ( int i = 0; i < propertySpan; i++ ) {
 			span += propertyTypes[i].getColumnSpan( mapping );
 		}
 		return span;
 	}
+
 	@Override
 	public int[] sqlTypes(Mapping mapping) throws MappingException {
 		//Not called at runtime so doesn't matter if its slow :)
 		int[] sqlTypes = new int[getColumnSpan( mapping )];
 		int n = 0;
 		for ( int i = 0; i < propertySpan; i++ ) {
 			int[] subtypes = propertyTypes[i].sqlTypes( mapping );
 			for ( int subtype : subtypes ) {
 				sqlTypes[n++] = subtype;
 			}
 		}
 		return sqlTypes;
 	}
 
 	@Override
 	public Size[] dictatedSizes(Mapping mapping) throws MappingException {
 		//Not called at runtime so doesn't matter if its slow :)
-		final Size[] sizes = new Size[ getColumnSpan( mapping ) ];
+		final Size[] sizes = new Size[getColumnSpan( mapping )];
 		int soFar = 0;
 		for ( Type propertyType : propertyTypes ) {
 			final Size[] propertySizes = propertyType.dictatedSizes( mapping );
 			System.arraycopy( propertySizes, 0, sizes, soFar, propertySizes.length );
 			soFar += propertySizes.length;
 		}
 		return sizes;
 	}
 
 	@Override
 	public Size[] defaultSizes(Mapping mapping) throws MappingException {
 		//Not called at runtime so doesn't matter if its slow :)
-		final Size[] sizes = new Size[ getColumnSpan( mapping ) ];
+		final Size[] sizes = new Size[getColumnSpan( mapping )];
 		int soFar = 0;
 		for ( Type propertyType : propertyTypes ) {
 			final Size[] propertySizes = propertyType.defaultSizes( mapping );
 			System.arraycopy( propertySizes, 0, sizes, soFar, propertySizes.length );
 			soFar += propertySizes.length;
 		}
 		return sizes;
 	}
 
 
 	@Override
-    public final boolean isComponentType() {
+	public final boolean isComponentType() {
 		return true;
 	}
 
 	public Class getReturnedClass() {
 		return componentTuplizer.getMappedClass();
 	}
 
 	@Override
-    public boolean isSame(Object x, Object y) throws HibernateException {
+	public boolean isSame(Object x, Object y) throws HibernateException {
 		if ( x == y ) {
 			return true;
 		}
 		if ( x == null || y == null ) {
 			return false;
 		}
 		Object[] xvalues = getPropertyValues( x, entityMode );
 		Object[] yvalues = getPropertyValues( y, entityMode );
 		for ( int i = 0; i < propertySpan; i++ ) {
 			if ( !propertyTypes[i].isSame( xvalues[i], yvalues[i] ) ) {
 				return false;
 			}
 		}
 		return true;
 	}
 
 	@Override
 	public boolean isEqual(final Object x, final Object y) throws HibernateException {
 		if ( x == y ) {
 			return true;
 		}
 		if ( x == null || y == null ) {
 			return false;
 		}
 		for ( int i = 0; i < propertySpan; i++ ) {
 			if ( !propertyTypes[i].isEqual( getPropertyValue( x, i ), getPropertyValue( y, i ) ) ) {
 				return false;
 			}
 		}
 		return true;
 	}
 
 	@Override
-	public boolean isEqual(final Object x, final Object y, final SessionFactoryImplementor factory) throws HibernateException {
+	public boolean isEqual(final Object x, final Object y, final SessionFactoryImplementor factory)
+			throws HibernateException {
 		if ( x == y ) {
 			return true;
 		}
 		if ( x == null || y == null ) {
 			return false;
 		}
 		for ( int i = 0; i < propertySpan; i++ ) {
 			if ( !propertyTypes[i].isEqual( getPropertyValue( x, i ), getPropertyValue( y, i ), factory ) ) {
 				return false;
 			}
 		}
 		return true;
 	}
 
 	@Override
 	public int compare(final Object x, final Object y) {
 		if ( x == y ) {
 			return 0;
 		}
 		for ( int i = 0; i < propertySpan; i++ ) {
 			int propertyCompare = propertyTypes[i].compare( getPropertyValue( x, i ), getPropertyValue( y, i ) );
 			if ( propertyCompare != 0 ) {
 				return propertyCompare;
 			}
 		}
 		return 0;
 	}
 
 	public boolean isMethodOf(Method method) {
 		return false;
 	}
 
 	@Override
 	public int getHashCode(final Object x) {
 		int result = 17;
 		for ( int i = 0; i < propertySpan; i++ ) {
 			Object y = getPropertyValue( x, i );
 			result *= 37;
 			if ( y != null ) {
 				result += propertyTypes[i].getHashCode( y );
 			}
 		}
 		return result;
 	}
 
 	@Override
 	public int getHashCode(final Object x, final SessionFactoryImplementor factory) {
 		int result = 17;
 		for ( int i = 0; i < propertySpan; i++ ) {
 			Object y = getPropertyValue( x, i );
 			result *= 37;
 			if ( y != null ) {
 				result += propertyTypes[i].getHashCode( y, factory );
 			}
 		}
 		return result;
 	}
 
 	@Override
 	public boolean isDirty(final Object x, final Object y, final SessionImplementor session) throws HibernateException {
 		if ( x == y ) {
 			return false;
 		}
 		if ( x == null || y == null ) {
 			return true;
 		}
 		for ( int i = 0; i < propertySpan; i++ ) {
 			if ( propertyTypes[i].isDirty( getPropertyValue( x, i ), getPropertyValue( y, i ), session ) ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
-	public boolean isDirty(final Object x, final Object y, final boolean[] checkable, final SessionImplementor session) throws HibernateException {
+	public boolean isDirty(final Object x, final Object y, final boolean[] checkable, final SessionImplementor session)
+			throws HibernateException {
 		if ( x == y ) {
 			return false;
 		}
 		if ( x == null || y == null ) {
 			return true;
 		}
 		int loc = 0;
 		for ( int i = 0; i < propertySpan; i++ ) {
 			int len = propertyTypes[i].getColumnSpan( session.getFactory() );
 			if ( len <= 1 ) {
 				final boolean dirty = ( len == 0 || checkable[loc] ) &&
-				                      propertyTypes[i].isDirty( getPropertyValue( x, i ), getPropertyValue( y, i ), session );
+						propertyTypes[i].isDirty( getPropertyValue( x, i ), getPropertyValue( y, i ), session );
 				if ( dirty ) {
 					return true;
 				}
 			}
 			else {
 				boolean[] subcheckable = new boolean[len];
 				System.arraycopy( checkable, loc, subcheckable, 0, len );
-				final boolean dirty = propertyTypes[i].isDirty( getPropertyValue( x, i ), getPropertyValue( y, i ), subcheckable, session );
+				final boolean dirty = propertyTypes[i].isDirty(
+						getPropertyValue( x, i ),
+						getPropertyValue( y, i ),
+						subcheckable,
+						session
+				);
 				if ( dirty ) {
 					return true;
 				}
 			}
 			loc += len;
 		}
 		return false;
 	}
 
 	@Override
-	public boolean isModified(final Object old, final Object current, final boolean[] checkable, final SessionImplementor session) throws HibernateException {
+	public boolean isModified(
+			final Object old,
+			final Object current,
+			final boolean[] checkable,
+			final SessionImplementor session) throws HibernateException {
 		if ( current == null ) {
 			return old != null;
 		}
 		if ( old == null ) {
 			return true;
 		}
-		Object[] oldValues = ( Object[] ) old;
+		Object[] oldValues = (Object[]) old;
 		int loc = 0;
 		for ( int i = 0; i < propertySpan; i++ ) {
 			int len = propertyTypes[i].getColumnSpan( session.getFactory() );
 			boolean[] subcheckable = new boolean[len];
 			System.arraycopy( checkable, loc, subcheckable, 0, len );
 			if ( propertyTypes[i].isModified( oldValues[i], getPropertyValue( current, i ), subcheckable, session ) ) {
 				return true;
 			}
 			loc += len;
 		}
 		return false;
 
 	}
+
 	@Override
 	public Object nullSafeGet(ResultSet rs, String[] names, SessionImplementor session, Object owner)
 			throws HibernateException, SQLException {
 		return resolve( hydrate( rs, names, session, owner ), session, owner );
 	}
+
 	@Override
 	public void nullSafeSet(PreparedStatement st, Object value, int begin, SessionImplementor session)
 			throws HibernateException, SQLException {
 
 		Object[] subvalues = nullSafeGetValues( value, entityMode );
 
 		for ( int i = 0; i < propertySpan; i++ ) {
 			propertyTypes[i].nullSafeSet( st, subvalues[i], begin, session );
 			begin += propertyTypes[i].getColumnSpan( session.getFactory() );
 		}
 	}
+
 	@Override
 	public void nullSafeSet(
 			PreparedStatement st,
 			Object value,
 			int begin,
 			boolean[] settable,
 			SessionImplementor session)
 			throws HibernateException, SQLException {
 
 		Object[] subvalues = nullSafeGetValues( value, entityMode );
 
 		int loc = 0;
 		for ( int i = 0; i < propertySpan; i++ ) {
 			int len = propertyTypes[i].getColumnSpan( session.getFactory() );
+			//noinspection StatementWithEmptyBody
 			if ( len == 0 ) {
 				//noop
 			}
 			else if ( len == 1 ) {
 				if ( settable[loc] ) {
 					propertyTypes[i].nullSafeSet( st, subvalues[i], begin, session );
 					begin++;
 				}
 			}
 			else {
 				boolean[] subsettable = new boolean[len];
 				System.arraycopy( settable, loc, subsettable, 0, len );
 				propertyTypes[i].nullSafeSet( st, subvalues[i], begin, subsettable, session );
 				begin += ArrayHelper.countTrue( subsettable );
 			}
 			loc += len;
 		}
 	}
 
 	private Object[] nullSafeGetValues(Object value, EntityMode entityMode) throws HibernateException {
 		if ( value == null ) {
 			return new Object[propertySpan];
 		}
 		else {
 			return getPropertyValues( value, entityMode );
 		}
 	}
+
 	@Override
 	public Object nullSafeGet(ResultSet rs, String name, SessionImplementor session, Object owner)
 			throws HibernateException, SQLException {
 
 		return nullSafeGet( rs, new String[] {name}, session, owner );
 	}
+
 	@Override
 	public Object getPropertyValue(Object component, int i, SessionImplementor session)
 			throws HibernateException {
 		return getPropertyValue( component, i );
 	}
+
 	public Object getPropertyValue(Object component, int i, EntityMode entityMode)
 			throws HibernateException {
 		return getPropertyValue( component, i );
 	}
 
 	public Object getPropertyValue(Object component, int i)
 			throws HibernateException {
 		if ( component instanceof Object[] ) {
 			// A few calls to hashCode pass the property values already in an
 			// Object[] (ex: QueryKey hash codes for cached queries).
 			// It's easiest to just check for the condition here prior to
 			// trying reflection.
-			return (( Object[] ) component)[i];
-		} else {
+			return ( (Object[]) component )[i];
+		}
+		else {
 			return componentTuplizer.getPropertyValue( component, i );
 		}
 	}
 
 	@Override
 	public Object[] getPropertyValues(Object component, SessionImplementor session)
 			throws HibernateException {
 		return getPropertyValues( component, entityMode );
 	}
+
 	@Override
 	public Object[] getPropertyValues(Object component, EntityMode entityMode)
 			throws HibernateException {
 		if ( component instanceof Object[] ) {
 			// A few calls to hashCode pass the property values already in an 
 			// Object[] (ex: QueryKey hash codes for cached queries).
 			// It's easiest to just check for the condition here prior to
 			// trying reflection.
-			return ( Object[] ) component;
-		} else {
+			return (Object[]) component;
+		}
+		else {
 			return componentTuplizer.getPropertyValues( component );
 		}
 	}
+
 	@Override
 	public void setPropertyValues(Object component, Object[] values, EntityMode entityMode)
 			throws HibernateException {
 		componentTuplizer.setPropertyValues( component, values );
 	}
+
 	@Override
 	public Type[] getSubtypes() {
 		return propertyTypes;
 	}
+
 	@Override
 	public String getName() {
 		return "component" + ArrayHelper.toString( propertyNames );
 	}
+
 	@Override
 	public String toLoggableString(Object value, SessionFactoryImplementor factory)
 			throws HibernateException {
 		if ( value == null ) {
 			return "null";
 		}
 
 		if ( entityMode == null ) {
 			throw new ClassCastException( value.getClass().getName() );
 		}
-		Map<String,String> result = new HashMap<String, String>();
+		Map<String, String> result = new HashMap<String, String>();
 		Object[] values = getPropertyValues( value, entityMode );
 		for ( int i = 0; i < propertyTypes.length; i++ ) {
 			result.put( propertyNames[i], propertyTypes[i].toLoggableString( values[i], factory ) );
 		}
 		return StringHelper.unqualify( getName() ) + result.toString();
 	}
+
 	@Override
 	public String[] getPropertyNames() {
 		return propertyNames;
 	}
+
 	@Override
 	public Object deepCopy(Object component, SessionFactoryImplementor factory)
 			throws HibernateException {
 		if ( component == null ) {
 			return null;
 		}
 
 		Object[] values = getPropertyValues( component, entityMode );
 		for ( int i = 0; i < propertySpan; i++ ) {
 			values[i] = propertyTypes[i].deepCopy( values[i], factory );
 		}
 
 		Object result = instantiate( entityMode );
 		setPropertyValues( result, values, entityMode );
 
 		//not absolutely necessary, but helps for some
 		//equals()/hashCode() implementations
 		if ( componentTuplizer.hasParentProperty() ) {
 			componentTuplizer.setParent( result, componentTuplizer.getParent( component ), factory );
 		}
 
 		return result;
 	}
+
 	@Override
 	public Object replace(
 			Object original,
 			Object target,
 			SessionImplementor session,
 			Object owner,
 			Map copyCache)
 			throws HibernateException {
 
 		if ( original == null ) {
 			return null;
 		}
 		//if ( original == target ) return target;
 
 		final Object result = target == null
 				? instantiate( owner, session )
 				: target;
 
 		Object[] values = TypeHelper.replace(
 				getPropertyValues( original, entityMode ),
 				getPropertyValues( result, entityMode ),
 				propertyTypes,
 				session,
 				owner,
 				copyCache
 		);
 
 		setPropertyValues( result, values, entityMode );
 		return result;
 	}
 
 	@Override
-    public Object replace(
+	public Object replace(
 			Object original,
 			Object target,
 			SessionImplementor session,
 			Object owner,
 			Map copyCache,
 			ForeignKeyDirection foreignKeyDirection)
 			throws HibernateException {
 
 		if ( original == null ) {
 			return null;
 		}
 		//if ( original == target ) return target;
 
 		final Object result = target == null ?
 				instantiate( owner, session ) :
 				target;
 
 		Object[] values = TypeHelper.replace(
 				getPropertyValues( original, entityMode ),
 				getPropertyValues( result, entityMode ),
 				propertyTypes,
 				session,
 				owner,
 				copyCache,
 				foreignKeyDirection
 		);
 
 		setPropertyValues( result, values, entityMode );
 		return result;
 	}
 
 	/**
 	 * This method does not populate the component parent
 	 */
 	public Object instantiate(EntityMode entityMode) throws HibernateException {
 		return componentTuplizer.instantiate();
 	}
 
 	public Object instantiate(Object parent, SessionImplementor session)
 			throws HibernateException {
 
 		Object result = instantiate( entityMode );
 
 		if ( componentTuplizer.hasParentProperty() && parent != null ) {
 			componentTuplizer.setParent(
 					result,
 					session.getPersistenceContext().proxyFor( parent ),
 					session.getFactory()
 			);
 		}
 
 		return result;
 	}
+
 	@Override
 	public CascadeStyle getCascadeStyle(int i) {
 		return cascade[i];
 	}
+
 	@Override
 	public boolean isMutable() {
 		return true;
 	}
 
 	@Override
-    public Serializable disassemble(Object value, SessionImplementor session, Object owner)
+	public Serializable disassemble(Object value, SessionImplementor session, Object owner)
 			throws HibernateException {
 
 		if ( value == null ) {
 			return null;
 		}
 		else {
 			Object[] values = getPropertyValues( value, entityMode );
 			for ( int i = 0; i < propertyTypes.length; i++ ) {
 				values[i] = propertyTypes[i].disassemble( values[i], session, owner );
 			}
 			return values;
 		}
 	}
 
 	@Override
-    public Object assemble(Serializable object, SessionImplementor session, Object owner)
+	public Object assemble(Serializable object, SessionImplementor session, Object owner)
 			throws HibernateException {
 
 		if ( object == null ) {
 			return null;
 		}
 		else {
-			Object[] values = ( Object[] ) object;
+			Object[] values = (Object[]) object;
 			Object[] assembled = new Object[values.length];
 			for ( int i = 0; i < propertyTypes.length; i++ ) {
-				assembled[i] = propertyTypes[i].assemble( ( Serializable ) values[i], session, owner );
+				assembled[i] = propertyTypes[i].assemble( (Serializable) values[i], session, owner );
 			}
 			Object result = instantiate( owner, session );
 			setPropertyValues( result, assembled, entityMode );
 			return result;
 		}
 	}
+
 	@Override
 	public FetchMode getFetchMode(int i) {
 		return joinedFetch[i];
 	}
 
 	@Override
-    public Object hydrate(
+	public Object hydrate(
 			final ResultSet rs,
 			final String[] names,
 			final SessionImplementor session,
 			final Object owner)
 			throws HibernateException, SQLException {
 
 		int begin = 0;
 		boolean notNull = false;
 		Object[] values = new Object[propertySpan];
 		for ( int i = 0; i < propertySpan; i++ ) {
 			int length = propertyTypes[i].getColumnSpan( session.getFactory() );
 			String[] range = ArrayHelper.slice( names, begin, length ); //cache this
 			Object val = propertyTypes[i].hydrate( rs, range, session, owner );
 			if ( val == null ) {
 				if ( isKey ) {
 					return null; //different nullability rules for pk/fk
 				}
 			}
 			else {
 				notNull = true;
 			}
 			values[i] = val;
 			begin += length;
 		}
 
 		return notNull ? values : null;
 	}
 
 	@Override
-    public Object resolve(Object value, SessionImplementor session, Object owner)
+	public Object resolve(Object value, SessionImplementor session, Object owner)
 			throws HibernateException {
 
 		if ( value != null ) {
 			Object result = instantiate( owner, session );
-			Object[] values = ( Object[] ) value;
+			Object[] values = (Object[]) value;
 			Object[] resolvedValues = new Object[values.length]; //only really need new array during semiresolve!
 			for ( int i = 0; i < values.length; i++ ) {
 				resolvedValues[i] = propertyTypes[i].resolve( values[i], session, owner );
 			}
 			setPropertyValues( result, resolvedValues, entityMode );
 			return result;
 		}
 		else {
 			return null;
 		}
 	}
 
 	@Override
-    public Object semiResolve(Object value, SessionImplementor session, Object owner)
+	public Object semiResolve(Object value, SessionImplementor session, Object owner)
 			throws HibernateException {
 		//note that this implementation is kinda broken
 		//for components with many-to-one associations
 		return resolve( value, session, owner );
 	}
+
 	@Override
 	public boolean[] getPropertyNullability() {
 		return propertyNullability;
 	}
 
 	@Override
-    public boolean isXMLElement() {
+	public boolean isXMLElement() {
 		return true;
 	}
+
 	@Override
 	public Object fromXMLNode(Node xml, Mapping factory) throws HibernateException {
 		return xml;
 	}
+
 	@Override
 	public void setToXMLNode(Node node, Object value, SessionFactoryImplementor factory) throws HibernateException {
-		replaceNode( node, ( Element ) value );
+		replaceNode( node, (Element) value );
 	}
+
 	@Override
 	public boolean[] toColumnNullness(Object value, Mapping mapping) {
-		boolean[] result = new boolean[ getColumnSpan( mapping ) ];
+		boolean[] result = new boolean[getColumnSpan( mapping )];
 		if ( value == null ) {
 			return result;
 		}
 		Object[] values = getPropertyValues( value, EntityMode.POJO ); //TODO!!!!!!!
 		int loc = 0;
 		for ( int i = 0; i < propertyTypes.length; i++ ) {
 			boolean[] propertyNullness = propertyTypes[i].toColumnNullness( values[i], mapping );
 			System.arraycopy( propertyNullness, 0, result, loc, propertyNullness.length );
 			loc += propertyNullness.length;
 		}
 		return result;
 	}
+
 	@Override
 	public boolean isEmbedded() {
 		return false;
 	}
 
 	public int getPropertyIndex(String name) {
 		String[] names = getPropertyNames();
 		for ( int i = 0, max = names.length; i < max; i++ ) {
 			if ( names[i].equals( name ) ) {
 				return i;
 			}
 		}
 		throw new PropertyNotFoundException(
 				"Unable to locate property named " + name + " on " + getReturnedClass().getName()
 		);
 	}
 
 	private Boolean canDoExtraction;
 
 	@Override
 	public boolean canDoExtraction() {
 		if ( canDoExtraction == null ) {
 			canDoExtraction = determineIfProcedureParamExtractionCanBePerformed();
 		}
 		return canDoExtraction;
 	}
 
 	private boolean determineIfProcedureParamExtractionCanBePerformed() {
 		for ( Type propertyType : propertyTypes ) {
-			if ( ! ProcedureParameterExtractionAware.class.isInstance( propertyType ) ) {
+			if ( !ProcedureParameterExtractionAware.class.isInstance( propertyType ) ) {
 				return false;
 			}
-			if ( ! ( (ProcedureParameterExtractionAware) propertyType ).canDoExtraction() ) {
+			if ( !( (ProcedureParameterExtractionAware) propertyType ).canDoExtraction() ) {
 				return false;
 			}
 		}
 		return true;
 	}
 
 	@Override
 	public Object extract(CallableStatement statement, int startIndex, SessionImplementor session) throws SQLException {
 		Object[] values = new Object[propertySpan];
 
 		int currentIndex = startIndex;
 		boolean notNull = false;
 		for ( int i = 0; i < propertySpan; i++ ) {
 			// we know this cast is safe from canDoExtraction
 			final ProcedureParameterExtractionAware propertyType = (ProcedureParameterExtractionAware) propertyTypes[i];
 			final Object value = propertyType.extract( statement, currentIndex, session );
 			if ( value == null ) {
 				if ( isKey ) {
 					return null; //different nullability rules for pk/fk
 				}
 			}
 			else {
 				notNull = true;
 			}
 			values[i] = value;
 			currentIndex += propertyType.getColumnSpan( session.getFactory() );
 		}
 
-		if ( ! notNull ) {
+		if ( !notNull ) {
 			values = null;
 		}
 
 		return resolve( values, session, null );
 	}
 
 	@Override
-	public Object extract(CallableStatement statement, String[] paramNames, SessionImplementor session) throws SQLException {
+	public Object extract(CallableStatement statement, String[] paramNames, SessionImplementor session)
+			throws SQLException {
 		// for this form to work all sub-property spans must be one (1)...
 
 		Object[] values = new Object[propertySpan];
 
 		int indx = 0;
 		boolean notNull = false;
 		for ( String paramName : paramNames ) {
 			// we know this cast is safe from canDoExtraction
 			final ProcedureParameterExtractionAware propertyType = (ProcedureParameterExtractionAware) propertyTypes[indx];
-			final Object value = propertyType.extract( statement, new String[] { paramName }, session );
+			final Object value = propertyType.extract( statement, new String[] {paramName}, session );
 			if ( value == null ) {
 				if ( isKey ) {
 					return null; //different nullability rules for pk/fk
 				}
 			}
 			else {
 				notNull = true;
 			}
 			values[indx] = value;
 		}
 
-		if ( ! notNull ) {
+		if ( !notNull ) {
 			values = null;
 		}
 
 		return resolve( values, session, null );
 	}
-	
+
 	public boolean hasNotNullProperty() {
 		return hasNotNullProperty;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/EmbeddedComponentType.java b/hibernate-core/src/main/java/org/hibernate/type/EmbeddedComponentType.java
index 4453edb86d..1ed8181273 100755
--- a/hibernate-core/src/main/java/org/hibernate/type/EmbeddedComponentType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/EmbeddedComponentType.java
@@ -1,57 +1,57 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.lang.reflect.Method;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.tuple.component.ComponentMetamodel;
 
 /**
  * @author Gavin King
  */
 public class EmbeddedComponentType extends ComponentType {
 	public EmbeddedComponentType(TypeFactory.TypeScope typeScope, ComponentMetamodel metamodel) {
 		super( typeScope, metamodel );
 	}
 
 	public boolean isEmbedded() {
 		return true;
 	}
 
 	public boolean isMethodOf(Method method) {
 		return componentTuplizer.isMethodOf( method );
 	}
 
 	public Object instantiate(Object parent, SessionImplementor session) throws HibernateException {
-		final boolean useParent = parent!=null &&
-		                          //TODO: Yuck! This is not quite good enough, it's a quick
-		                          //hack around the problem of having a to-one association
-		                          //that refers to an embedded component:
-		                          super.getReturnedClass().isInstance(parent);
+		final boolean useParent = parent != null &&
+				//TODO: Yuck! This is not quite good enough, it's a quick
+				//hack around the problem of having a to-one association
+				//that refers to an embedded component:
+				super.getReturnedClass().isInstance( parent );
 
-		return useParent ? parent : super.instantiate(parent, session);
+		return useParent ? parent : super.instantiate( parent, session );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/EntityType.java b/hibernate-core/src/main/java/org/hibernate/type/EntityType.java
index 147b67f674..08eaede684 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/EntityType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/EntityType.java
@@ -1,772 +1,797 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.engine.internal.ForeignKeys;
 import org.hibernate.engine.spi.EntityUniqueKey;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.entity.UniqueKeyLoadable;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.tuple.ElementWrapper;
 
 import org.dom4j.Element;
 import org.dom4j.Node;
 
 /**
  * Base for types which map associations to persistent entities.
  *
  * @author Gavin King
  */
 public abstract class EntityType extends AbstractType implements AssociationType {
 
 	private final TypeFactory.TypeScope scope;
 	private final String associatedEntityName;
 	protected final String uniqueKeyPropertyName;
 	protected final boolean isEmbeddedInXML;
 	private final boolean eager;
 	private final boolean unwrapProxy;
 	private final boolean referenceToPrimaryKey;
 
 	/**
 	 * Cached because of performance
+	 *
 	 * @see #getIdentifierType(SessionImplementor)
 	 * @see #getIdentifierType(Mapping)
 	 */
 	private transient volatile Type associatedIdentifierType;
 
 	/**
 	 * Cached because of performance
+	 *
 	 * @see #getAssociatedEntityPersister
 	 */
 	private transient volatile EntityPersister associatedEntityPersister;
 
 	private transient Class returnedClass;
 
 	/**
 	 * Constructs the requested entity type mapping.
 	 *
 	 * @param scope The type scope
 	 * @param entityName The name of the associated entity.
 	 * @param uniqueKeyPropertyName The property-ref name, or null if we
 	 * reference the PK of the associated entity.
 	 * @param eager Is eager fetching enabled.
 	 * @param isEmbeddedInXML Should values of this mapping be embedded in XML modes?
 	 * @param unwrapProxy Is unwrapping of proxies allowed for this association; unwrapping
 	 * says to return the "implementation target" of lazy prooxies; typically only possible
 	 * with lazy="no-proxy".
 	 *
 	 * @deprecated Use {@link #EntityType(org.hibernate.type.TypeFactory.TypeScope, String, boolean, String, boolean, boolean)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	protected EntityType(
 			TypeFactory.TypeScope scope,
 			String entityName,
 			String uniqueKeyPropertyName,
 			boolean eager,
 			boolean isEmbeddedInXML,
 			boolean unwrapProxy) {
 		this( scope, entityName, uniqueKeyPropertyName == null, uniqueKeyPropertyName, eager, unwrapProxy );
 	}
 
 	/**
 	 * Constructs the requested entity type mapping.
 	 *
 	 * @param scope The type scope
 	 * @param entityName The name of the associated entity.
 	 * @param uniqueKeyPropertyName The property-ref name, or null if we
 	 * reference the PK of the associated entity.
 	 * @param eager Is eager fetching enabled.
 	 * @param unwrapProxy Is unwrapping of proxies allowed for this association; unwrapping
 	 * says to return the "implementation target" of lazy prooxies; typically only possible
 	 * with lazy="no-proxy".
-	 * 
+	 *
 	 * @deprecated Use {@link #EntityType(org.hibernate.type.TypeFactory.TypeScope, String, boolean, String, boolean, boolean)} instead.
 	 */
 	@Deprecated
 	protected EntityType(
 			TypeFactory.TypeScope scope,
 			String entityName,
 			String uniqueKeyPropertyName,
 			boolean eager,
 			boolean unwrapProxy) {
 		this( scope, entityName, uniqueKeyPropertyName == null, uniqueKeyPropertyName, eager, unwrapProxy );
 	}
 
 	/**
 	 * Constructs the requested entity type mapping.
 	 *
 	 * @param scope The type scope
 	 * @param entityName The name of the associated entity.
 	 * @param referenceToPrimaryKey True if association references a primary key.
 	 * @param uniqueKeyPropertyName The property-ref name, or null if we
 	 * reference the PK of the associated entity.
 	 * @param eager Is eager fetching enabled.
 	 * @param unwrapProxy Is unwrapping of proxies allowed for this association; unwrapping
 	 * says to return the "implementation target" of lazy prooxies; typically only possible
 	 * with lazy="no-proxy".
 	 */
 	protected EntityType(
 			TypeFactory.TypeScope scope,
 			String entityName,
 			boolean referenceToPrimaryKey,
 			String uniqueKeyPropertyName,
 			boolean eager,
 			boolean unwrapProxy) {
 		this.scope = scope;
 		this.associatedEntityName = entityName;
 		this.uniqueKeyPropertyName = uniqueKeyPropertyName;
 		this.isEmbeddedInXML = true;
 		this.eager = eager;
 		this.unwrapProxy = unwrapProxy;
 		this.referenceToPrimaryKey = referenceToPrimaryKey;
 	}
 
 	protected TypeFactory.TypeScope scope() {
 		return scope;
 	}
 
 	/**
 	 * An entity type is a type of association type
 	 *
 	 * @return True.
 	 */
 	@Override
 	public boolean isAssociationType() {
 		return true;
 	}
 
 	/**
 	 * Explicitly, an entity type is an entity type ;)
 	 *
 	 * @return True.
 	 */
 	@Override
 	public final boolean isEntityType() {
 		return true;
 	}
 
 	@Override
 	public boolean isMutable() {
 		return false;
 	}
 
 	/**
 	 * Generates a string representation of this type.
 	 *
 	 * @return string rep
 	 */
 	@Override
 	public String toString() {
 		return getClass().getName() + '(' + getAssociatedEntityName() + ')';
 	}
 
 	/**
 	 * For entity types, the name correlates to the associated entity name.
 	 */
 	@Override
 	public String getName() {
 		return associatedEntityName;
 	}
 
 	/**
 	 * Does this association foreign key reference the primary key of the other table?
 	 * Otherwise, it references a property-ref.
 	 *
 	 * @return True if this association reference the PK of the associated entity.
 	 */
 	public boolean isReferenceToPrimaryKey() {
 		return referenceToPrimaryKey;
 	}
 
 	@Override
 	public String getRHSUniqueKeyPropertyName() {
 		// Return null if this type references a PK.  This is important for
 		// associations' use of mappedBy referring to a derived ID.
 		return referenceToPrimaryKey ? null : uniqueKeyPropertyName;
 	}
 
 	@Override
 	public String getLHSPropertyName() {
 		return null;
 	}
 
 	public String getPropertyName() {
 		return null;
 	}
 
 	/**
 	 * The name of the associated entity.
 	 *
 	 * @return The associated entity name.
 	 */
 	public final String getAssociatedEntityName() {
 		return associatedEntityName;
 	}
 
 	/**
 	 * The name of the associated entity.
 	 *
 	 * @param factory The session factory, for resolution.
+	 *
 	 * @return The associated entity name.
 	 */
 	@Override
 	public String getAssociatedEntityName(SessionFactoryImplementor factory) {
 		return getAssociatedEntityName();
 	}
 
 	/**
 	 * Retrieves the {@link Joinable} defining the associated entity.
 	 *
 	 * @param factory The session factory.
+	 *
 	 * @return The associated joinable
+	 *
 	 * @throws MappingException Generally indicates an invalid entity name.
 	 */
 	@Override
 	public Joinable getAssociatedJoinable(SessionFactoryImplementor factory) throws MappingException {
-		return ( Joinable ) getAssociatedEntityPersister( factory );
+		return (Joinable) getAssociatedEntityPersister( factory );
 	}
 
 	/**
 	 * This returns the wrong class for an entity with a proxy, or for a named
 	 * entity.  Theoretically it should return the proxy class, but it doesn't.
 	 * <p/>
 	 * The problem here is that we do not necessarily have a ref to the associated
 	 * entity persister (nor to the session factory, to look it up) which is really
 	 * needed to "do the right thing" here...
 	 *
 	 * @return The entiyt class.
 	 */
 	@Override
 	public final Class getReturnedClass() {
 		if ( returnedClass == null ) {
 			returnedClass = determineAssociatedEntityClass();
 		}
 		return returnedClass;
 	}
 
-    private Class determineAssociatedEntityClass() {
-        final String entityName = getAssociatedEntityName();
-        try {
-            return ReflectHelper.classForName(entityName);
-        }
-        catch ( ClassNotFoundException cnfe ) {
-            return this.scope.resolveFactory().getEntityPersister(entityName).
-                getEntityTuplizer().getMappedClass();
-        }
-    }
+	private Class determineAssociatedEntityClass() {
+		final String entityName = getAssociatedEntityName();
+		try {
+			return ReflectHelper.classForName( entityName );
+		}
+		catch (ClassNotFoundException cnfe) {
+			return this.scope.resolveFactory().getEntityPersister( entityName ).
+					getEntityTuplizer().getMappedClass();
+		}
+	}
 
 	@Override
 	public Object nullSafeGet(ResultSet rs, String name, SessionImplementor session, Object owner)
 			throws HibernateException, SQLException {
 		return nullSafeGet( rs, new String[] {name}, session, owner );
 	}
 
 	@Override
 	public final Object nullSafeGet(
 			ResultSet rs,
 			String[] names,
 			SessionImplementor session,
 			Object owner) throws HibernateException, SQLException {
-		return resolve( hydrate(rs, names, session, owner), session, owner );
+		return resolve( hydrate( rs, names, session, owner ), session, owner );
 	}
 
 	/**
 	 * Two entities are considered the same when their instances are the same.
 	 *
-	 *
 	 * @param x One entity instance
 	 * @param y Another entity instance
+	 *
 	 * @return True if x == y; false otherwise.
 	 */
 	@Override
 	public final boolean isSame(Object x, Object y) {
 		return x == y;
 	}
 
 	@Override
 	public int compare(Object x, Object y) {
 		return 0; //TODO: entities CAN be compared, by PK, fix this! -> only if/when we can extract the id values....
 	}
 
 	@Override
 	public Object deepCopy(Object value, SessionFactoryImplementor factory) {
 		return value; //special case ... this is the leaf of the containment graph, even though not immutable
 	}
 
 	@Override
 	public Object replace(
 			Object original,
 			Object target,
 			SessionImplementor session,
 			Object owner,
 			Map copyCache) throws HibernateException {
 		if ( original == null ) {
 			return null;
 		}
-		Object cached = copyCache.get(original);
+		Object cached = copyCache.get( original );
 		if ( cached != null ) {
 			return cached;
 		}
 		else {
 			if ( original == target ) {
 				return target;
 			}
-			if ( session.getContextEntityIdentifier( original ) == null  &&
+			if ( session.getContextEntityIdentifier( original ) == null &&
 					ForeignKeys.isTransient( associatedEntityName, original, Boolean.FALSE, session ) ) {
 				final Object copy = session.getEntityPersister( associatedEntityName, original )
 						.instantiate( null, session );
 				copyCache.put( original, copy );
 				return copy;
 			}
 			else {
 				Object id = getIdentifier( original, session );
 				if ( id == null ) {
-					throw new AssertionFailure("non-transient entity has a null id: " + original.getClass().getName());
+					throw new AssertionFailure(
+							"non-transient entity has a null id: " + original.getClass()
+									.getName()
+					);
 				}
 				id = getIdentifierOrUniqueKeyType( session.getFactory() )
-						.replace(id, null, session, owner, copyCache);
+						.replace( id, null, session, owner, copyCache );
 				return resolve( id, session, owner );
 			}
 		}
 	}
 
 	@Override
 	public int getHashCode(Object x, SessionFactoryImplementor factory) {
 		EntityPersister persister = getAssociatedEntityPersister( factory );
 		if ( !persister.canExtractIdOutOfEntity() ) {
 			return super.getHashCode( x );
 		}
 
 		final Serializable id;
-		if (x instanceof HibernateProxy) {
+		if ( x instanceof HibernateProxy ) {
 			id = ( (HibernateProxy) x ).getHibernateLazyInitializer().getIdentifier();
 		}
 		else {
 			final Class mappedClass = persister.getMappedClass();
 			if ( mappedClass.isAssignableFrom( x.getClass() ) ) {
 				id = persister.getIdentifier( x );
 			}
 			else {
 				id = (Serializable) x;
 			}
 		}
 		return persister.getIdentifierType().getHashCode( id, factory );
 	}
 
 	@Override
 	public boolean isEqual(Object x, Object y, SessionFactoryImplementor factory) {
 		// associations (many-to-one and one-to-one) can be null...
 		if ( x == null || y == null ) {
 			return x == y;
 		}
 
 		EntityPersister persister = getAssociatedEntityPersister( factory );
 		if ( !persister.canExtractIdOutOfEntity() ) {
-			return super.isEqual(x, y );
+			return super.isEqual( x, y );
 		}
 
 		final Class mappedClass = persister.getMappedClass();
 		Serializable xid;
-		if (x instanceof HibernateProxy) {
+		if ( x instanceof HibernateProxy ) {
 			xid = ( (HibernateProxy) x ).getHibernateLazyInitializer()
 					.getIdentifier();
 		}
 		else {
 			if ( mappedClass.isAssignableFrom( x.getClass() ) ) {
 				xid = persister.getIdentifier( x );
 			}
 			else {
 				//JPA 2 case where @IdClass contains the id and not the associated entity
 				xid = (Serializable) x;
 			}
 		}
 
 		Serializable yid;
-		if (y instanceof HibernateProxy) {
+		if ( y instanceof HibernateProxy ) {
 			yid = ( (HibernateProxy) y ).getHibernateLazyInitializer()
 					.getIdentifier();
 		}
 		else {
 			if ( mappedClass.isAssignableFrom( y.getClass() ) ) {
 				yid = persister.getIdentifier( y );
 			}
 			else {
 				//JPA 2 case where @IdClass contains the id and not the associated entity
 				yid = (Serializable) y;
 			}
 		}
 
 		return persister.getIdentifierType()
-				.isEqual(xid, yid, factory);
+				.isEqual( xid, yid, factory );
 	}
 
 	@Override
 	public boolean isEmbeddedInXML() {
 		return isEmbeddedInXML;
 	}
 
 	@Override
 	public boolean isXMLElement() {
 		return isEmbeddedInXML;
 	}
 
 	@Override
 	public Object fromXMLNode(Node xml, Mapping factory) throws HibernateException {
 		if ( !isEmbeddedInXML ) {
-			return getIdentifierType(factory).fromXMLNode(xml, factory);
+			return getIdentifierType( factory ).fromXMLNode( xml, factory );
 		}
 		else {
 			return xml;
 		}
 	}
 
 	@Override
 	public void setToXMLNode(Node node, Object value, SessionFactoryImplementor factory) throws HibernateException {
 		if ( !isEmbeddedInXML ) {
-			getIdentifierType(factory).setToXMLNode(node, value, factory);
+			getIdentifierType( factory ).setToXMLNode( node, value, factory );
 		}
 		else {
 			Element elt = (Element) value;
-			replaceNode( node, new ElementWrapper(elt) );
+			replaceNode( node, new ElementWrapper( elt ) );
 		}
 	}
 
 	@Override
 	public String getOnCondition(String alias, SessionFactoryImplementor factory, Map enabledFilters) {
 		return getOnCondition( alias, factory, enabledFilters, null );
 	}
 
 	@Override
 	public String getOnCondition(
 			String alias,
 			SessionFactoryImplementor factory,
 			Map enabledFilters,
 			Set<String> treatAsDeclarations) {
 		if ( isReferenceToPrimaryKey() && ( treatAsDeclarations == null || treatAsDeclarations.isEmpty() ) ) {
 			return "";
 		}
 		else {
 			return getAssociatedJoinable( factory ).filterFragment( alias, enabledFilters, treatAsDeclarations );
 		}
 	}
 
 	/**
 	 * Resolve an identifier or unique key value
 	 */
 	@Override
 	public Object resolve(Object value, SessionImplementor session, Object owner) throws HibernateException {
 		if ( isNotEmbedded( session ) ) {
 			return value;
 		}
 
 		if ( value != null && !isNull( owner, session ) ) {
 			if ( isReferenceToPrimaryKey() ) {
 				return resolveIdentifier( (Serializable) value, session );
 			}
 			else if ( uniqueKeyPropertyName != null ) {
 				return loadByUniqueKey( getAssociatedEntityName(), uniqueKeyPropertyName, value, session );
 			}
 		}
-		
+
 		return null;
 	}
 
 	@Override
 	public Type getSemiResolvedType(SessionFactoryImplementor factory) {
 		return getAssociatedEntityPersister( factory ).getIdentifierType();
 	}
 
 	protected EntityPersister getAssociatedEntityPersister(final SessionFactoryImplementor factory) {
 		final EntityPersister persister = associatedEntityPersister;
 		//The following branch implements a simple lazy-initialization, but rather than the canonical
 		//form it returns the local variable to avoid a second volatile read: associatedEntityPersister
 		//needs to be volatile as the initialization might happen by a different thread than the readers.
 		if ( persister == null ) {
 			associatedEntityPersister = factory.getEntityPersister( getAssociatedEntityName() );
 			return associatedEntityPersister;
 		}
 		else {
 			return persister;
 		}
 	}
 
 	protected final Object getIdentifier(Object value, SessionImplementor session) throws HibernateException {
-		if ( isNotEmbedded(session) ) {
+		if ( isNotEmbedded( session ) ) {
 			return value;
 		}
 
 		if ( isReferenceToPrimaryKey() || uniqueKeyPropertyName == null ) {
-			return ForeignKeys.getEntityIdentifierIfNotUnsaved( getAssociatedEntityName(), value, session ); //tolerates nulls
+			return ForeignKeys.getEntityIdentifierIfNotUnsaved(
+					getAssociatedEntityName(),
+					value,
+					session
+			); //tolerates nulls
 		}
 		else if ( value == null ) {
 			return null;
 		}
 		else {
 			EntityPersister entityPersister = getAssociatedEntityPersister( session.getFactory() );
 			Object propertyValue = entityPersister.getPropertyValue( value, uniqueKeyPropertyName );
 			// We now have the value of the property-ref we reference.  However,
 			// we need to dig a little deeper, as that property might also be
 			// an entity type, in which case we need to resolve its identitifier
 			Type type = entityPersister.getPropertyType( uniqueKeyPropertyName );
 			if ( type.isEntityType() ) {
-				propertyValue = ( ( EntityType ) type ).getIdentifier( propertyValue, session );
+				propertyValue = ( (EntityType) type ).getIdentifier( propertyValue, session );
 			}
 
 			return propertyValue;
 		}
 	}
 
 	/**
 	 * @deprecated To be removed in 5.  Removed as part of removing the notion of DOM entity-mode.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	protected boolean isNotEmbedded(SessionImplementor session) {
 //		return !isEmbeddedInXML;
 		return false;
 	}
 
 	/**
 	 * Generate a loggable representation of an instance of the value mapped by this type.
 	 *
 	 * @param value The instance to be logged.
 	 * @param factory The session factory.
+	 *
 	 * @return The loggable string.
+	 *
 	 * @throws HibernateException Generally some form of resolution problem.
 	 */
 	@Override
 	public String toLoggableString(Object value, SessionFactoryImplementor factory) {
 		if ( value == null ) {
 			return "null";
 		}
-		
+
 		EntityPersister persister = getAssociatedEntityPersister( factory );
 		StringBuilder result = new StringBuilder().append( associatedEntityName );
 
 		if ( persister.hasIdentifierProperty() ) {
 			final EntityMode entityMode = persister.getEntityMode();
 			final Serializable id;
 			if ( entityMode == null ) {
 				if ( isEmbeddedInXML ) {
 					throw new ClassCastException( value.getClass().getName() );
 				}
-				id = ( Serializable ) value;
-			} else if ( value instanceof HibernateProxy ) {
-				HibernateProxy proxy = ( HibernateProxy ) value;
+				id = (Serializable) value;
+			}
+			else if ( value instanceof HibernateProxy ) {
+				HibernateProxy proxy = (HibernateProxy) value;
 				id = proxy.getHibernateLazyInitializer().getIdentifier();
 			}
 			else {
 				id = persister.getIdentifier( value );
 			}
-			
+
 			result.append( '#' )
-				.append( persister.getIdentifierType().toLoggableString( id, factory ) );
+					.append( persister.getIdentifierType().toLoggableString( id, factory ) );
 		}
-		
+
 		return result.toString();
 	}
 
 	/**
 	 * Is the association modeled here defined as a 1-1 in the database (physical model)?
 	 *
 	 * @return True if a 1-1 in the database; false otherwise.
 	 */
 	public abstract boolean isOneToOne();
 
 	/**
 	 * Is the association modeled here a 1-1 according to the logical moidel?
 	 *
 	 * @return True if a 1-1 in the logical model; false otherwise.
 	 */
 	public boolean isLogicalOneToOne() {
 		return isOneToOne();
 	}
 
 	/**
 	 * Convenience method to locate the identifier type of the associated entity.
 	 *
 	 * @param factory The mappings...
+	 *
 	 * @return The identifier type
 	 */
 	Type getIdentifierType(final Mapping factory) {
 		final Type type = associatedIdentifierType;
 		//The following branch implements a simple lazy-initialization, but rather than the canonical
 		//form it returns the local variable to avoid a second volatile read: associatedIdentifierType
 		//needs to be volatile as the initialization might happen by a different thread than the readers.
 		if ( type == null ) {
 			associatedIdentifierType = factory.getIdentifierType( getAssociatedEntityName() );
 			return associatedIdentifierType;
 		}
 		else {
 			return type;
 		}
 	}
 
 	/**
 	 * Convenience method to locate the identifier type of the associated entity.
 	 *
 	 * @param session The originating session
+	 *
 	 * @return The identifier type
 	 */
 	Type getIdentifierType(final SessionImplementor session) {
 		final Type type = associatedIdentifierType;
 		if ( type == null ) {
 			associatedIdentifierType = getIdentifierType( session.getFactory() );
 			return associatedIdentifierType;
 		}
 		else {
 			return type;
 		}
 	}
 
 	/**
 	 * Determine the type of either (1) the identifier if we reference the
 	 * associated entity's PK or (2) the unique key to which we refer (i.e.
 	 * the property-ref).
 	 *
 	 * @param factory The mappings...
+	 *
 	 * @return The appropriate type.
+	 *
 	 * @throws MappingException Generally, if unable to resolve the associated entity name
 	 * or unique key property name.
 	 */
 	public final Type getIdentifierOrUniqueKeyType(Mapping factory) throws MappingException {
 		if ( isReferenceToPrimaryKey() || uniqueKeyPropertyName == null ) {
-			return getIdentifierType(factory);
+			return getIdentifierType( factory );
 		}
 		else {
 			Type type = factory.getReferencedPropertyType( getAssociatedEntityName(), uniqueKeyPropertyName );
 			if ( type.isEntityType() ) {
-				type = ( ( EntityType ) type).getIdentifierOrUniqueKeyType( factory );
+				type = ( (EntityType) type ).getIdentifierOrUniqueKeyType( factory );
 			}
 			return type;
 		}
 	}
 
 	/**
 	 * The name of the property on the associated entity to which our FK
 	 * refers
 	 *
 	 * @param factory The mappings...
+	 *
 	 * @return The appropriate property name.
+	 *
 	 * @throws MappingException Generally, if unable to resolve the associated entity name
 	 */
 	public final String getIdentifierOrUniqueKeyPropertyName(Mapping factory)
-	throws MappingException {
+			throws MappingException {
 		if ( isReferenceToPrimaryKey() || uniqueKeyPropertyName == null ) {
 			return factory.getIdentifierPropertyName( getAssociatedEntityName() );
 		}
 		else {
 			return uniqueKeyPropertyName;
 		}
 	}
-	
+
 	protected abstract boolean isNullable();
 
 	/**
 	 * Resolve an identifier via a load.
 	 *
 	 * @param id The entity id to resolve
 	 * @param session The orginating session.
+	 *
 	 * @return The resolved identifier (i.e., loaded entity).
+	 *
 	 * @throws org.hibernate.HibernateException Indicates problems performing the load.
 	 */
 	protected final Object resolveIdentifier(Serializable id, SessionImplementor session) throws HibernateException {
 		boolean isProxyUnwrapEnabled = unwrapProxy &&
 				getAssociatedEntityPersister( session.getFactory() )
 						.isInstrumented();
 
 		Object proxyOrEntity = session.internalLoad(
 				getAssociatedEntityName(),
 				id,
 				eager,
 				isNullable() && !isProxyUnwrapEnabled
 		);
 
 		if ( proxyOrEntity instanceof HibernateProxy ) {
-			( ( HibernateProxy ) proxyOrEntity ).getHibernateLazyInitializer()
+			( (HibernateProxy) proxyOrEntity ).getHibernateLazyInitializer()
 					.setUnwrap( isProxyUnwrapEnabled );
 		}
 
 		return proxyOrEntity;
 	}
 
 	protected boolean isNull(Object owner, SessionImplementor session) {
 		return false;
 	}
 
 	/**
 	 * Load an instance by a unique key that is not the primary key.
 	 *
 	 * @param entityName The name of the entity to load
 	 * @param uniqueKeyPropertyName The name of the property defining the uniqie key.
 	 * @param key The unique key property value.
 	 * @param session The originating session.
+	 *
 	 * @return The loaded entity
+	 *
 	 * @throws HibernateException generally indicates problems performing the load.
 	 */
 	public Object loadByUniqueKey(
-			String entityName, 
-			String uniqueKeyPropertyName, 
-			Object key, 
+			String entityName,
+			String uniqueKeyPropertyName,
+			Object key,
 			SessionImplementor session) throws HibernateException {
 		final SessionFactoryImplementor factory = session.getFactory();
-		UniqueKeyLoadable persister = ( UniqueKeyLoadable ) factory.getEntityPersister( entityName );
+		UniqueKeyLoadable persister = (UniqueKeyLoadable) factory.getEntityPersister( entityName );
 
 		//TODO: implement caching?! proxies?!
 
 		EntityUniqueKey euk = new EntityUniqueKey(
-				entityName, 
-				uniqueKeyPropertyName, 
-				key, 
+				entityName,
+				uniqueKeyPropertyName,
+				key,
 				getIdentifierOrUniqueKeyType( factory ),
 				persister.getEntityMode(),
 				session.getFactory()
 		);
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		Object result = persistenceContext.getEntity( euk );
 		if ( result == null ) {
 			result = persister.loadByUniqueKey( uniqueKeyPropertyName, key, session );
 		}
 		return result == null ? null : persistenceContext.proxyFor( result );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/EnumType.java b/hibernate-core/src/main/java/org/hibernate/type/EnumType.java
index b6b494b682..f08507c630 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/EnumType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/EnumType.java
@@ -1,521 +1,522 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.lang.annotation.Annotation;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 import java.util.Properties;
 import javax.persistence.Enumerated;
 import javax.persistence.MapKeyEnumerated;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.usertype.DynamicParameterizedType;
 import org.hibernate.usertype.EnhancedUserType;
 import org.hibernate.usertype.LoggableUserType;
 
 import org.jboss.logging.Logger;
 
 /**
  * Value type mapper for enumerations.
  *
  * Generally speaking, the proper configuration is picked up from the annotations associated with the mapped attribute.
  *
  * There are a few configuration parameters understood by this type mapper:<ul>
  *     <li>
  *         <strong>enumClass</strong> - Names the enumeration class.
  *     </li>
  *     <li>
  *         <strong>useNamed</strong> - Should enum be mapped via name.  Default is to map as ordinal.  Used when
  *         annotations are not used (otherwise {@link javax.persistence.EnumType} is used).
  *     </li>
  *     <li>
  *         <strong>type</strong> - Identifies the JDBC type (via type code) to be used for the column.
  *     </li>
  * </ul>
  *
  * @author Emmanuel Bernard
  * @author Hardy Ferentschik
  * @author Steve Ebersole
  */
 @SuppressWarnings("unchecked")
 public class EnumType implements EnhancedUserType, DynamicParameterizedType,LoggableUserType, Serializable {
-    private static final Logger LOG = Logger.getLogger( EnumType.class.getName() );
+	private static final Logger LOG = CoreLogging.logger( EnumType.class );
 
 	public static final String ENUM = "enumClass";
 	public static final String NAMED = "useNamed";
 	public static final String TYPE = "type";
 
 	private Class<? extends Enum> enumClass;
 	private EnumValueMapper enumValueMapper;
 	private int sqlType = Types.INTEGER;  // before any guessing
 
 	@Override
 	public int[] sqlTypes() {
 		return new int[] { sqlType };
 	}
 
 	@Override
 	public Class<? extends Enum> returnedClass() {
 		return enumClass;
 	}
 
 	@Override
 	public boolean equals(Object x, Object y) throws HibernateException {
 		return x == y;
 	}
 
 	@Override
 	public int hashCode(Object x) throws HibernateException {
 		return x == null ? 0 : x.hashCode();
 	}
 
 	@Override
 	public Object nullSafeGet(ResultSet rs, String[] names, SessionImplementor session, Object owner) throws SQLException {
 		if ( enumValueMapper == null ) {
 			resolveEnumValueMapper( rs,  names[0] );
 		}
 		return enumValueMapper.getValue( rs, names );
 	}
 
 	private void resolveEnumValueMapper(ResultSet rs, String name) {
 		if ( enumValueMapper == null ) {
 			try {
 				resolveEnumValueMapper( rs.getMetaData().getColumnType( rs.findColumn( name ) ) );
 			}
 			catch (Exception e) {
 				// because some drivers do not implement this
 				LOG.debugf(
 						"JDBC driver threw exception calling java.sql.ResultSetMetaData.getColumnType; " +
 								"using fallback determination [%s] : %s",
 						enumClass.getName(),
 						e.getMessage()
 				);
 				// peek at the result value to guess type (this is legacy behavior)
 				try {
 					Object value = rs.getObject( name );
 					if ( Number.class.isInstance( value ) ) {
 						treatAsOrdinal();
 					}
 					else {
 						treatAsNamed();
 					}
 				}
 				catch (SQLException ignore) {
 					treatAsOrdinal();
 				}
 			}
 		}
 	}
 
 	private void resolveEnumValueMapper(int columnType) {
 		// fallback for cases where not enough parameter/parameterization information was passed in
 		if ( isOrdinal( columnType ) ) {
 			treatAsOrdinal();
 		}
 		else {
 			treatAsNamed();
 		}
 	}
 
 	@Override
 	public void nullSafeSet(PreparedStatement st, Object value, int index, SessionImplementor session) throws HibernateException, SQLException {
 		if ( enumValueMapper == null ) {
 			resolveEnumValueMapper( st, index );
 		}
 		enumValueMapper.setValue( st, (Enum) value, index );
 	}
 
 	private void resolveEnumValueMapper(PreparedStatement st, int index) {
 		if ( enumValueMapper == null ) {
 			try {
 				resolveEnumValueMapper( st.getParameterMetaData().getParameterType( index ) );
 			}
 			catch (Exception e) {
 				// because some drivers do not implement this
 				LOG.debugf(
 						"JDBC driver threw exception calling java.sql.ParameterMetaData#getParameterType; " +
 								"falling back to ordinal-based enum mapping [%s] : %s",
 						enumClass.getName(),
 						e.getMessage()
 				);
 				// Originally, this was simply treatAsOrdinal().  But, for DBs that do not implement the above, enums
 				// were treated as ordinal even when the *.hbm.xml explicitly define the type sqlCode.  By default,
 				// this is essentially the same anyway, since sqlType is defaulted to Integer.
 				resolveEnumValueMapper( sqlType );
 			}
 		}
 	}
 
 	@Override
 	public Object deepCopy(Object value) throws HibernateException {
 		return value;
 	}
 
 	@Override
 	public boolean isMutable() {
 		return false;
 	}
 
 	@Override
 	public Serializable disassemble(Object value) throws HibernateException {
 		return ( Serializable ) value;
 	}
 
 	@Override
 	public Object assemble(Serializable cached, Object owner) throws HibernateException {
 		return cached;
 	}
 
 	@Override
 	public Object replace(Object original, Object target, Object owner) throws HibernateException {
 		return original;
 	}
 
 	@Override
 	public void setParameterValues(Properties parameters) {
 		final ParameterType reader = (ParameterType) parameters.get( PARAMETER_TYPE );
 
 		// IMPL NOTE : be protective about not setting enumValueMapper (i.e. calling treatAsNamed/treatAsOrdinal)
 		// in cases where we do not have enough information.  In such cases we do additional checks
 		// as part of nullSafeGet/nullSafeSet to query against the JDBC metadata to make the determination.
 
 		if ( reader != null ) {
 			enumClass = reader.getReturnedClass().asSubclass( Enum.class );
 
 			final boolean isOrdinal;
 			final javax.persistence.EnumType enumType = getEnumType( reader );
 			if ( enumType == null ) {
 				isOrdinal = true;
 			}
 			else if ( javax.persistence.EnumType.ORDINAL.equals( enumType ) ) {
 				isOrdinal = true;
 			}
 			else if ( javax.persistence.EnumType.STRING.equals( enumType ) ) {
 				isOrdinal = false;
 			}
 			else {
 				throw new AssertionFailure( "Unknown EnumType: " + enumType );
 			}
 
 			if ( isOrdinal ) {
 				treatAsOrdinal();
 			}
 			else {
 				treatAsNamed();
 			}
 			sqlType = enumValueMapper.getSqlType();
 		}
 		else {
 			String enumClassName = (String) parameters.get( ENUM );
 			try {
 				enumClass = ReflectHelper.classForName( enumClassName, this.getClass() ).asSubclass( Enum.class );
 			}
 			catch ( ClassNotFoundException exception ) {
 				throw new HibernateException( "Enum class not found", exception );
 			}
 
 			final Object useNamedSetting = parameters.get( NAMED );
 			if ( useNamedSetting != null ) {
 				final boolean useNamed = ConfigurationHelper.getBoolean( NAMED, parameters );
 				if ( useNamed ) {
 					treatAsNamed();
 				}
 				else {
 					treatAsOrdinal();
 				}
 				sqlType = enumValueMapper.getSqlType();
 			}
 		}
 
 		final String type = (String) parameters.get( TYPE );
 		if ( type != null ) {
 			sqlType = Integer.decode( type );
 		}
 	}
 
 	private void treatAsOrdinal() {
 		if ( enumValueMapper == null || ! OrdinalEnumValueMapper.class.isInstance( enumValueMapper ) ) {
 			enumValueMapper = new OrdinalEnumValueMapper();
 			sqlType = enumValueMapper.getSqlType();
 		}
 	}
 
 	private void treatAsNamed() {
 		if ( enumValueMapper == null || ! NamedEnumValueMapper.class.isInstance( enumValueMapper ) ) {
 			enumValueMapper = new NamedEnumValueMapper();
 			sqlType = enumValueMapper.getSqlType();
 		}
 	}
 
 	private javax.persistence.EnumType getEnumType(ParameterType reader) {
 		javax.persistence.EnumType enumType = null;
 		if ( reader.isPrimaryKey() ) {
 			MapKeyEnumerated enumAnn = getAnnotation( reader.getAnnotationsMethod(), MapKeyEnumerated.class );
 			if ( enumAnn != null ) {
 				enumType = enumAnn.value();
 			}
 		}
 		else {
 			Enumerated enumAnn = getAnnotation( reader.getAnnotationsMethod(), Enumerated.class );
 			if ( enumAnn != null ) {
 				enumType = enumAnn.value();
 			}
 		}
 		return enumType;
 	}
 
 	private <T extends Annotation> T getAnnotation(Annotation[] annotations, Class<T> anClass) {
 		for ( Annotation annotation : annotations ) {
 			if ( anClass.isInstance( annotation ) ) {
 				return (T) annotation;
 			}
 		}
 		return null;
 	}
 
 	@Override
 	public String objectToSQLString(Object value) {
 		return enumValueMapper.objectToSQLString( (Enum) value );
 	}
 
 	@Override
 	public String toXMLString(Object value) {
 		return enumValueMapper.toXMLString( (Enum) value );
 	}
 
 	@Override
 	public Object fromXMLString(String xmlValue) {
 		return enumValueMapper.fromXMLString( xmlValue );
 	}
 
 	@Override
 	public String toLoggableString(Object value, SessionFactoryImplementor factory) {
 		if ( enumValueMapper != null ) {
 			return enumValueMapper.toXMLString( (Enum) value );
 		}
 		return value.toString();
 	}
 
 	private static interface EnumValueMapper extends Serializable {
 		public int getSqlType();
 		public Enum getValue(ResultSet rs, String[] names) throws SQLException;
 		public void setValue(PreparedStatement st, Enum value, int index) throws SQLException;
 
 		public String objectToSQLString(Enum value);
 		public String toXMLString(Enum value);
 		public Enum fromXMLString(String xml);
 	}
 
 	public abstract class EnumValueMapperSupport implements EnumValueMapper {
 		protected abstract Object extractJdbcValue(Enum value);
 
 		@Override
 		public void setValue(PreparedStatement st, Enum value, int index) throws SQLException {
 			final Object jdbcValue = value == null ? null : extractJdbcValue( value );
 
 			final boolean traceEnabled = LOG.isTraceEnabled();
 			if ( jdbcValue == null ) {
 				if ( traceEnabled ) {
 					LOG.trace(String.format("Binding null to parameter: [%s]", index));
 				}
 				st.setNull( index, getSqlType() );
 				return;
 			}
 
 			if ( traceEnabled ) {
 				LOG.trace(String.format("Binding [%s] to parameter: [%s]", jdbcValue, index));
 			}
 			st.setObject( index, jdbcValue, EnumType.this.sqlType );
 		}
 	}
 
 	private class OrdinalEnumValueMapper extends EnumValueMapperSupport implements EnumValueMapper, Serializable {
 		private transient Enum[] enumsByOrdinal;
 
 		@Override
 		public int getSqlType() {
 			return Types.INTEGER;
 		}
 
 		@Override
 		public Enum getValue(ResultSet rs, String[] names) throws SQLException {
 			final int ordinal = rs.getInt( names[0] );
 			final boolean traceEnabled = LOG.isTraceEnabled();
 			if ( rs.wasNull() ) {
 				if ( traceEnabled ) {
 					LOG.trace(String.format("Returning null as column [%s]", names[0]));
 				}
 				return null;
 			}
 
 			final Enum enumValue = fromOrdinal( ordinal );
 			if ( traceEnabled ) {
 				LOG.trace(String.format("Returning [%s] as column [%s]", enumValue, names[0]));
 			}
 			return enumValue;
 		}
 
 		private Enum fromOrdinal(int ordinal) {
 			final Enum[] enumsByOrdinal = enumsByOrdinal();
 			if ( ordinal < 0 || ordinal >= enumsByOrdinal.length ) {
 				throw new IllegalArgumentException(
 						String.format(
 								"Unknown ordinal value [%s] for enum class [%s]",
 								ordinal,
 								enumClass.getName()
 						)
 				);
 			}
 			return enumsByOrdinal[ordinal];
 
 		}
 
 		private Enum[] enumsByOrdinal() {
 			if ( enumsByOrdinal == null ) {
 				enumsByOrdinal = enumClass.getEnumConstants();
 				if ( enumsByOrdinal == null ) {
 					throw new HibernateException( "Failed to init enum values" );
 				}
 			}
 			return enumsByOrdinal;
 		}
 
 		@Override
 		public String objectToSQLString(Enum value) {
 			return toXMLString( value );
 		}
 
 		@Override
 		public String toXMLString(Enum value) {
 			return Integer.toString( value.ordinal() );
 		}
 
 		@Override
 		public Enum fromXMLString(String xml) {
 			return fromOrdinal( Integer.parseInt( xml ) );
 		}
 
 		@Override
 		protected Object extractJdbcValue(Enum value) {
 			return value.ordinal();
 		}
 	}
 
 	private class NamedEnumValueMapper extends EnumValueMapperSupport implements EnumValueMapper, Serializable {
 		@Override
 		public int getSqlType() {
 			return Types.VARCHAR;
 		}
 
 		@Override
 		public Enum getValue(ResultSet rs, String[] names) throws SQLException {
 			final String value = rs.getString( names[0] );
 
 			final boolean traceEnabled = LOG.isTraceEnabled();
 			if ( rs.wasNull() ) {
 				if ( traceEnabled ) {
 					LOG.trace(String.format("Returning null as column [%s]", names[0]));
 				}
 				return null;
 			}
 
 			final Enum enumValue = fromName( value );
 			if ( traceEnabled ) {
 				LOG.trace(String.format("Returning [%s] as column [%s]", enumValue, names[0]));
 			}
 			return enumValue;
 		}
 
 		private Enum fromName(String name) {
 			try {
-			    if(name == null) {
-			        return null;
-			    }
+				if (name == null) {
+					return null;
+				}
 				return Enum.valueOf( enumClass, name.trim() );
 			}
 			catch ( IllegalArgumentException iae ) {
 				throw new IllegalArgumentException(
 						String.format(
 								"Unknown name value [%s] for enum class [%s]",
 								name,
 								enumClass.getName()
 						)
 				);
 			}
 		}
 
 		@Override
 		public String objectToSQLString(Enum value) {
 			return '\'' + toXMLString( value ) + '\'';
 		}
 
 		@Override
 		public String toXMLString(Enum value) {
 			return value.name();
 		}
 
 		@Override
 		public Enum fromXMLString(String xml) {
 			return fromName( xml );
 		}
 
 		@Override
 		protected Object extractJdbcValue(Enum value) {
 			return value.name();
 		}
 	}
 
 	public boolean isOrdinal() {
 		return isOrdinal( sqlType );
 	}
 
 	private boolean isOrdinal(int paramType) {
 		switch ( paramType ) {
 			case Types.INTEGER:
 			case Types.NUMERIC:
 			case Types.SMALLINT:
 			case Types.TINYINT:
 			case Types.BIGINT:
 			case Types.DECIMAL: //for Oracle Driver
 			case Types.DOUBLE:  //for Oracle Driver
 			case Types.FLOAT:   //for Oracle Driver
 				return true;
 			case Types.CHAR:
 			case Types.LONGVARCHAR:
 			case Types.VARCHAR:
 				return false;
 			default:
 				throw new HibernateException( "Unable to persist an Enum in a column of SQL Type: " + paramType );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/SerializableToBlobType.java b/hibernate-core/src/main/java/org/hibernate/type/SerializableToBlobType.java
index cab5c265c2..c9e334a89c 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/SerializableToBlobType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/SerializableToBlobType.java
@@ -1,71 +1,73 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.util.Properties;
 
 import org.hibernate.MappingException;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.type.descriptor.java.SerializableTypeDescriptor;
 import org.hibernate.type.descriptor.sql.BlobTypeDescriptor;
 import org.hibernate.usertype.DynamicParameterizedType;
 
 /**
  * @author Brett Meyer
  */
 public class SerializableToBlobType<T extends Serializable> extends AbstractSingleColumnStandardBasicType<T> implements DynamicParameterizedType {
 	
 	public static final String CLASS_NAME = "classname";
 	
 	private static final long serialVersionUID = 1L;
 
 	public SerializableToBlobType() {
 		super( BlobTypeDescriptor.DEFAULT, new SerializableTypeDescriptor( Serializable.class ) );
 	}
 
 	@Override
 	public String getName() {
 		return getClass().getName();
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public void setParameterValues(Properties parameters) {
 		ParameterType reader = (ParameterType) parameters.get( PARAMETER_TYPE );
 		if ( reader != null ) {
 			setJavaTypeDescriptor( new SerializableTypeDescriptor<T>( reader.getReturnedClass() ) );
-		} else {
+		}
+		else {
 			String className = parameters.getProperty( CLASS_NAME );
 			if ( className == null ) {
 				throw new MappingException( "No class name defined for type: " + SerializableToBlobType.class.getName() );
 			}
 			try {
 				setJavaTypeDescriptor( new SerializableTypeDescriptor<T>( ReflectHelper.classForName( className ) ) );
-			} catch ( ClassNotFoundException e ) {
+			}
+			catch ( ClassNotFoundException e ) {
 				throw new MappingException( "Unable to load class from " + CLASS_NAME + " parameter", e );
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/SetType.java b/hibernate-core/src/main/java/org/hibernate/type/SetType.java
index e1b6bd3242..d21c028ce1 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/SetType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/SetType.java
@@ -1,67 +1,67 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.util.HashSet;
 
 import org.hibernate.collection.internal.PersistentSet;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.persister.collection.CollectionPersister;
 
 public class SetType extends CollectionType {
 
 	/**
 	 * @deprecated Use {@link #SetType(org.hibernate.type.TypeFactory.TypeScope, String, String)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public SetType(TypeFactory.TypeScope typeScope, String role, String propertyRef, boolean isEmbeddedInXML) {
 		super( typeScope, role, propertyRef, isEmbeddedInXML );
 	}
 
 	public SetType(TypeFactory.TypeScope typeScope, String role, String propertyRef) {
 		super( typeScope, role, propertyRef );
 	}
 
 	public PersistentCollection instantiate(SessionImplementor session, CollectionPersister persister, Serializable key) {
 		return new PersistentSet(session);
 	}
 
 	public Class getReturnedClass() {
 		return java.util.Set.class;
 	}
 
 	public PersistentCollection wrap(SessionImplementor session, Object collection) {
 		return new PersistentSet( session, (java.util.Set) collection );
 	}
 
 	public Object instantiate(int anticipatedSize) {
 		return anticipatedSize <= 0
-		       ? new HashSet()
-		       : new HashSet( anticipatedSize + (int)( anticipatedSize * .75f ), .75f );
+				? new HashSet()
+				: new HashSet( anticipatedSize + (int)( anticipatedSize * .75f ), .75f );
 	}
 	
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/TypeFactory.java b/hibernate-core/src/main/java/org/hibernate/type/TypeFactory.java
index d69c37d52b..675a3e582b 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/TypeFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/TypeFactory.java
@@ -1,532 +1,502 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.util.Comparator;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.classic.Lifecycle;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.tuple.component.ComponentMetamodel;
 import org.hibernate.usertype.CompositeUserType;
 import org.hibernate.usertype.ParameterizedType;
 import org.hibernate.usertype.UserType;
 
-import org.jboss.logging.Logger;
+import static org.hibernate.internal.CoreLogging.messageLogger;
 
 /**
  * Used internally to build instances of {@link Type}, specifically it builds instances of
- *
- *
+ * <p/>
+ * <p/>
  * Used internally to obtain instances of <tt>Type</tt>. Applications should use static methods
  * and constants on <tt>org.hibernate.Hibernate</tt>.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
-@SuppressWarnings({ "unchecked" })
+@SuppressWarnings({"unchecked"})
 public final class TypeFactory implements Serializable {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, TypeFactory.class.getName());
+	private static final CoreMessageLogger LOG = messageLogger( TypeFactory.class );
 
 	private final TypeScopeImpl typeScope = new TypeScopeImpl();
 
 	public static interface TypeScope extends Serializable {
 		public SessionFactoryImplementor resolveFactory();
 	}
 
 	private static class TypeScopeImpl implements TypeFactory.TypeScope {
 		private SessionFactoryImplementor factory;
 
 		public void injectSessionFactory(SessionFactoryImplementor factory) {
 			if ( this.factory != null ) {
 				LOG.scopingTypesToSessionFactoryAfterAlreadyScoped( this.factory, factory );
 			}
 			else {
 				LOG.tracev( "Scoping types to session factory {0}", factory );
 			}
 			this.factory = factory;
 		}
 
 		public SessionFactoryImplementor resolveFactory() {
 			if ( factory == null ) {
 				throw new HibernateException( "SessionFactory for type scoping not yet known" );
 			}
 			return factory;
 		}
 	}
 
 	public void injectSessionFactory(SessionFactoryImplementor factory) {
 		typeScope.injectSessionFactory( factory );
 	}
 
 	public SessionFactoryImplementor resolveSessionFactory() {
 		return typeScope.resolveFactory();
 	}
 
 	public Type byClass(Class clazz, Properties parameters) {
 		if ( Type.class.isAssignableFrom( clazz ) ) {
 			return type( clazz, parameters );
 		}
 
 		if ( CompositeUserType.class.isAssignableFrom( clazz ) ) {
 			return customComponent( clazz, parameters );
 		}
 
 		if ( UserType.class.isAssignableFrom( clazz ) ) {
 			return custom( clazz, parameters );
 		}
 
 		if ( Lifecycle.class.isAssignableFrom( clazz ) ) {
 			// not really a many-to-one association *necessarily*
 			return manyToOne( clazz.getName() );
 		}
 
 		if ( Serializable.class.isAssignableFrom( clazz ) ) {
 			return serializable( clazz );
 		}
 
 		return null;
 	}
 
 	public Type type(Class<Type> typeClass, Properties parameters) {
 		try {
 			Type type = typeClass.newInstance();
 			injectParameters( type, parameters );
 			return type;
 		}
 		catch (Exception e) {
 			throw new MappingException( "Could not instantiate Type: " + typeClass.getName(), e );
 		}
 	}
 
 	// todo : can a Properties be wrapped in unmodifiable in any way?
 	private final static Properties EMPTY_PROPERTIES = new Properties();
 
 	public static void injectParameters(Object type, Properties parameters) {
 		if ( ParameterizedType.class.isInstance( type ) ) {
 			if ( parameters == null ) {
 				( (ParameterizedType) type ).setParameterValues( EMPTY_PROPERTIES );
 			}
 			else {
-				( (ParameterizedType) type ).setParameterValues(parameters);
+				( (ParameterizedType) type ).setParameterValues( parameters );
 			}
 		}
-		else if ( parameters!=null && !parameters.isEmpty() ) {
+		else if ( parameters != null && !parameters.isEmpty() ) {
 			throw new MappingException( "type is not parameterized: " + type.getClass().getName() );
 		}
 	}
 
 	public CompositeCustomType customComponent(Class<CompositeUserType> typeClass, Properties parameters) {
 		return customComponent( typeClass, parameters, typeScope );
 	}
 
 	/**
 	 * @deprecated Only for use temporary use by {@link org.hibernate.Hibernate}
 	 */
 	@Deprecated
-    @SuppressWarnings({ "JavaDoc" })
-	public static CompositeCustomType customComponent(Class<CompositeUserType> typeClass, Properties parameters, TypeScope scope) {
+	@SuppressWarnings({"JavaDoc"})
+	public static CompositeCustomType customComponent(
+			Class<CompositeUserType> typeClass,
+			Properties parameters,
+			TypeScope scope) {
 		try {
 			CompositeUserType userType = typeClass.newInstance();
 			injectParameters( userType, parameters );
 			return new CompositeCustomType( userType );
 		}
-		catch ( Exception e ) {
+		catch (Exception e) {
 			throw new MappingException( "Unable to instantiate custom type: " + typeClass.getName(), e );
 		}
 	}
 
 	/**
 	 * @deprecated Use {@link #customCollection(String, java.util.Properties, String, String)}
 	 * instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType customCollection(
 			String typeName,
 			Properties typeParameters,
 			String role,
 			String propertyRef,
 			boolean embedded) {
 		Class typeClass;
 		try {
 			typeClass = ReflectHelper.classForName( typeName );
 		}
-		catch ( ClassNotFoundException cnfe ) {
+		catch (ClassNotFoundException cnfe) {
 			throw new MappingException( "user collection type class not found: " + typeName, cnfe );
 		}
 		CustomCollectionType result = new CustomCollectionType( typeScope, typeClass, role, propertyRef, embedded );
 		if ( typeParameters != null ) {
 			injectParameters( result.getUserType(), typeParameters );
 		}
 		return result;
 	}
 
 	public CollectionType customCollection(
 			String typeName,
 			Properties typeParameters,
 			String role,
 			String propertyRef) {
 		Class typeClass;
 		try {
 			typeClass = ReflectHelper.classForName( typeName );
 		}
-		catch ( ClassNotFoundException cnfe ) {
+		catch (ClassNotFoundException cnfe) {
 			throw new MappingException( "user collection type class not found: " + typeName, cnfe );
 		}
 		CustomCollectionType result = new CustomCollectionType( typeScope, typeClass, role, propertyRef );
 		if ( typeParameters != null ) {
 			injectParameters( result.getUserType(), typeParameters );
 		}
 		return result;
 	}
 
 	public CustomType custom(Class<UserType> typeClass, Properties parameters) {
 		return custom( typeClass, parameters, typeScope );
 	}
 
 	/**
 	 * @deprecated Only for use temporary use by {@link org.hibernate.Hibernate}
 	 */
 	@Deprecated
-    public static CustomType custom(Class<UserType> typeClass, Properties parameters, TypeScope scope) {
+	public static CustomType custom(Class<UserType> typeClass, Properties parameters, TypeScope scope) {
 		try {
 			UserType userType = typeClass.newInstance();
 			injectParameters( userType, parameters );
 			return new CustomType( userType );
 		}
-		catch ( Exception e ) {
+		catch (Exception e) {
 			throw new MappingException( "Unable to instantiate custom type: " + typeClass.getName(), e );
 		}
 	}
 
 	/**
 	 * Build a {@link SerializableType} from the given {@link Serializable} class.
 	 *
 	 * @param serializableClass The {@link Serializable} class.
 	 * @param <T> The actual class type (extends Serializable)
 	 *
 	 * @return The built {@link SerializableType}
 	 */
 	public static <T extends Serializable> SerializableType<T> serializable(Class<T> serializableClass) {
 		return new SerializableType<T>( serializableClass );
 	}
 
 
 	// one-to-one type builders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-	/**
-	 * @deprecated Use {@link #oneToOne(String, ForeignKeyDirection, String, boolean, boolean, String, String, boolean)} instead.
-	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
-	 */
-	@Deprecated
-	public EntityType oneToOne(
-			String persistentClass,
-			ForeignKeyDirection foreignKeyType,
-			String uniqueKeyPropertyName,
-			boolean lazy,
-			boolean unwrapProxy,
-			boolean isEmbeddedInXML,
-			String entityName,
-			String propertyName) {
-		return oneToOne( persistentClass, foreignKeyType, uniqueKeyPropertyName == null, uniqueKeyPropertyName, lazy, unwrapProxy, entityName,
-				propertyName );
-	}
-
-	/**
-	 * @deprecated Use {@link #oneToOne(String, ForeignKeyDirection, String, boolean, boolean, String, String, boolean)} instead.
-	 */
-	@Deprecated
-	public EntityType oneToOne(
-			String persistentClass,
-			ForeignKeyDirection foreignKeyType,
-			String uniqueKeyPropertyName,
-			boolean lazy,
-			boolean unwrapProxy,
-			String entityName,
-			String propertyName) {
-		return oneToOne( persistentClass, foreignKeyType, uniqueKeyPropertyName == null, uniqueKeyPropertyName, lazy, unwrapProxy, entityName,
-				propertyName );
-	}
-
 	public EntityType oneToOne(
 			String persistentClass,
 			ForeignKeyDirection foreignKeyType,
 			boolean referenceToPrimaryKey,
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			String entityName,
 			String propertyName) {
-		return new OneToOneType( typeScope, persistentClass, foreignKeyType, referenceToPrimaryKey,
-				uniqueKeyPropertyName, lazy, unwrapProxy, entityName, propertyName );
-	}
-	
-	/**
-	 * @deprecated Use {@link #specialOneToOne(String, ForeignKeyDirection, String, boolean, boolean, String, String, boolean)} instead.
-	 */
-	@Deprecated
-	public EntityType specialOneToOne(
-			String persistentClass,
-			ForeignKeyDirection foreignKeyType,
-			String uniqueKeyPropertyName,
-			boolean lazy,
-			boolean unwrapProxy,
-			String entityName,
-			String propertyName) {
-		return specialOneToOne( persistentClass, foreignKeyType, uniqueKeyPropertyName == null, uniqueKeyPropertyName, lazy, unwrapProxy,
-				entityName, propertyName );
+		return new OneToOneType(
+				typeScope, persistentClass, foreignKeyType, referenceToPrimaryKey,
+				uniqueKeyPropertyName, lazy, unwrapProxy, entityName, propertyName
+		);
 	}
 
 	public EntityType specialOneToOne(
 			String persistentClass,
 			ForeignKeyDirection foreignKeyType,
 			boolean referenceToPrimaryKey,
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			String entityName,
 			String propertyName) {
-		return new SpecialOneToOneType( typeScope, persistentClass, foreignKeyType, referenceToPrimaryKey,
-				uniqueKeyPropertyName, lazy, unwrapProxy, entityName, propertyName );
+		return new SpecialOneToOneType(
+				typeScope, persistentClass, foreignKeyType, referenceToPrimaryKey,
+				uniqueKeyPropertyName, lazy, unwrapProxy, entityName, propertyName
+		);
 	}
 
 
 	// many-to-one type builders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public EntityType manyToOne(String persistentClass) {
 		return new ManyToOneType( typeScope, persistentClass );
 	}
 
 	public EntityType manyToOne(String persistentClass, boolean lazy) {
 		return new ManyToOneType( typeScope, persistentClass, lazy );
 	}
 
 	/**
 	 * @deprecated Use {@link #manyToOne(String, boolean, String, boolean, boolean, boolean, boolean)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public EntityType manyToOne(
 			String persistentClass,
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			boolean isEmbeddedInXML,
 			boolean ignoreNotFound,
 			boolean isLogicalOneToOne) {
-		return manyToOne( persistentClass, uniqueKeyPropertyName == null, uniqueKeyPropertyName, lazy, unwrapProxy, ignoreNotFound,
-				isLogicalOneToOne );
+		return manyToOne(
+				persistentClass,
+				uniqueKeyPropertyName == null,
+				uniqueKeyPropertyName,
+				lazy,
+				unwrapProxy,
+				ignoreNotFound,
+				isLogicalOneToOne
+		);
 	}
 
 	/**
 	 * @deprecated Use {@link #manyToOne(String, boolean, String, boolean, boolean, boolean, boolean)} instead.
 	 */
 	@Deprecated
 	public EntityType manyToOne(
 			String persistentClass,
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			boolean ignoreNotFound,
 			boolean isLogicalOneToOne) {
-		return manyToOne( persistentClass, uniqueKeyPropertyName == null, uniqueKeyPropertyName, lazy, unwrapProxy, ignoreNotFound,
-				isLogicalOneToOne );
+		return manyToOne(
+				persistentClass,
+				uniqueKeyPropertyName == null,
+				uniqueKeyPropertyName,
+				lazy,
+				unwrapProxy,
+				ignoreNotFound,
+				isLogicalOneToOne
+		);
 	}
 
 	public EntityType manyToOne(
 			String persistentClass,
 			boolean referenceToPrimaryKey,
 			String uniqueKeyPropertyName,
 			boolean lazy,
 			boolean unwrapProxy,
 			boolean ignoreNotFound,
 			boolean isLogicalOneToOne) {
 		return new ManyToOneType(
 				typeScope,
 				persistentClass,
 				referenceToPrimaryKey,
 				uniqueKeyPropertyName,
 				lazy,
 				unwrapProxy,
 				ignoreNotFound,
 				isLogicalOneToOne
 		);
 	}
 
 	// collection type builders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * @deprecated Use {@link #array(String, String, Class)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType array(String role, String propertyRef, boolean embedded, Class elementClass) {
 		return new ArrayType( typeScope, role, propertyRef, elementClass, embedded );
 	}
 
 	public CollectionType array(String role, String propertyRef, Class elementClass) {
 		return new ArrayType( typeScope, role, propertyRef, elementClass );
 	}
 
 	/**
 	 * @deprecated Use {@link #list(String, String)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType list(String role, String propertyRef, boolean embedded) {
 		return new ListType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType list(String role, String propertyRef) {
 		return new ListType( typeScope, role, propertyRef );
 	}
 
 	/**
 	 * @deprecated Use {@link #bag(String, String)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType bag(String role, String propertyRef, boolean embedded) {
 		return new BagType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType bag(String role, String propertyRef) {
 		return new BagType( typeScope, role, propertyRef );
 	}
 
 	/**
 	 * @deprecated Use {@link #idbag(String, String)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType idbag(String role, String propertyRef, boolean embedded) {
 		return new IdentifierBagType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType idbag(String role, String propertyRef) {
 		return new IdentifierBagType( typeScope, role, propertyRef );
 	}
 
 	/**
 	 * @deprecated Use {@link #map(String, String)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType map(String role, String propertyRef, boolean embedded) {
 		return new MapType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType map(String role, String propertyRef) {
 		return new MapType( typeScope, role, propertyRef );
 	}
 
 	/**
 	 * @deprecated Use {@link #orderedMap(String, String)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType orderedMap(String role, String propertyRef, boolean embedded) {
 		return new OrderedMapType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType orderedMap(String role, String propertyRef) {
 		return new OrderedMapType( typeScope, role, propertyRef );
 	}
 
 	/**
 	 * @deprecated Use {@link #sortedMap(String, String, java.util.Comparator)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType sortedMap(String role, String propertyRef, boolean embedded, Comparator comparator) {
 		return new SortedMapType( typeScope, role, propertyRef, comparator, embedded );
 	}
 
 	public CollectionType sortedMap(String role, String propertyRef, Comparator comparator) {
 		return new SortedMapType( typeScope, role, propertyRef, comparator );
 	}
 
 	/**
 	 * @deprecated Use {@link #set(String, String)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType set(String role, String propertyRef, boolean embedded) {
 		return new SetType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType set(String role, String propertyRef) {
 		return new SetType( typeScope, role, propertyRef );
 	}
 
 	/**
 	 * @deprecated Use {@link #orderedSet(String, String)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType orderedSet(String role, String propertyRef, boolean embedded) {
 		return new OrderedSetType( typeScope, role, propertyRef, embedded );
 	}
 
 	public CollectionType orderedSet(String role, String propertyRef) {
 		return new OrderedSetType( typeScope, role, propertyRef );
 	}
 
 	/**
 	 * @deprecated Use {@link #sortedSet(String, String, java.util.Comparator)} instead.
 	 * See Jira issue: <a href="https://hibernate.onjira.com/browse/HHH-7771">HHH-7771</a>
 	 */
 	@Deprecated
 	public CollectionType sortedSet(String role, String propertyRef, boolean embedded, Comparator comparator) {
 		return new SortedSetType( typeScope, role, propertyRef, comparator, embedded );
 	}
 
 	public CollectionType sortedSet(String role, String propertyRef, Comparator comparator) {
 		return new SortedSetType( typeScope, role, propertyRef, comparator );
 	}
 
 	// component type builders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public ComponentType component(ComponentMetamodel metamodel) {
 		return new ComponentType( typeScope, metamodel );
 	}
 
 	public EmbeddedComponentType embeddedComponent(ComponentMetamodel metamodel) {
 		return new EmbeddedComponentType( typeScope, metamodel );
 	}
 
 
 	// any type builder ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public Type any(Type metaType, Type identifierType) {
 		return new AnyType( typeScope, metaType, identifierType );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/TypeResolver.java b/hibernate-core/src/main/java/org/hibernate/type/TypeResolver.java
index ba47fe1e79..0ddb72c21a 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/TypeResolver.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/TypeResolver.java
@@ -1,138 +1,137 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.util.Properties;
 
 import org.hibernate.MappingException;
-import org.hibernate.classic.Lifecycle;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.usertype.CompositeUserType;
 import org.hibernate.usertype.UserType;
 
 /**
  * Acts as the contract for getting types and as the mediator between {@link BasicTypeRegistry} and {@link TypeFactory}.
  *
  * @author Steve Ebersole
  */
 public class TypeResolver implements Serializable {
 	private final BasicTypeRegistry basicTypeRegistry;
 	private final TypeFactory typeFactory;
 
 	public TypeResolver() {
 		this(  new BasicTypeRegistry(), new TypeFactory() );
 	}
 
 	public TypeResolver(BasicTypeRegistry basicTypeRegistry, TypeFactory typeFactory) {
 		this.basicTypeRegistry = basicTypeRegistry;
 		this.typeFactory = typeFactory;
 	}
 
 	public TypeResolver scope(SessionFactoryImplementor factory) {
 		typeFactory.injectSessionFactory( factory );
 		return new TypeResolver( basicTypeRegistry.shallowCopy(), typeFactory );
 	}
 
 	public void registerTypeOverride(BasicType type) {
 		basicTypeRegistry.register( type );
 	}
 
 	public void registerTypeOverride(UserType type, String[] keys) {
 		basicTypeRegistry.register( type, keys );
 	}
 
 	public void registerTypeOverride(CompositeUserType type, String[] keys) {
 		basicTypeRegistry.register( type, keys );
 	}
 
 	public TypeFactory getTypeFactory() {
 		return typeFactory;
 	}
 
 	/**
 	 * Locate a Hibernate {@linkplain BasicType basic type} given (one of) its registration names.
 	 *
 	 * @param name The registration name
 	 *
 	 * @return The registered type
 	 */
 	public BasicType basic(String name) {
 		return basicTypeRegistry.getRegisteredType( name );
 	}
 
 	/**
 	 * See {@link #heuristicType(String, Properties)}
 	 *
 	 * @param typeName The name (see heuristic algorithm discussion on {@link #heuristicType(String, Properties)}).
 	 *
 	 * @return The deduced type; may be null.
 	 *
 	 * @throws MappingException Can be thrown from {@link #heuristicType(String, Properties)}
 	 */
 	public Type heuristicType(String typeName) throws MappingException {
 		return heuristicType( typeName, null );
 	}
 
 	/**
 	 * Uses heuristics to deduce the proper {@link Type} given a string naming the type or Java class.
 	 * <p/>
 	 * The search goes as follows:<ol>
 	 * 	<li>search for a basic type with 'typeName' as a registration key</li>
 	 * 	<li>
 	 * 		look for 'typeName' as a class name and<ol>
 	 *			<li>if it names a {@link Type} implementor, return an instance</li>
 	 *			<li>if it names a {@link CompositeUserType} or a {@link UserType}, return an instance of class wrapped intot the appropriate {@link Type} adapter</li>
-	 * 			<li>if it implements {@link Lifecycle}, return the corresponding entity type</li>
+	 * 			<li>if it implements {@link org.hibernate.classic.Lifecycle}, return the corresponding entity type</li>
 	 * 			<li>if it implements {@link Serializable}, return the corresponding serializable type</li>
 	 * 		</ol>
 	 * 	</li>
 	 * </ol>
 	 *
 	 * @param typeName The name (see heuristic algorithm above).
 	 * @param parameters Any parameters for the type.  Only applied if built!
 	 *
 	 * @return The deduced type; may be null.
 	 *
 	 * @throws MappingException Indicates a problem attempting to resolve 'typeName' as a {@link Class}
 	 */
 	public Type heuristicType(String typeName, Properties parameters) throws MappingException {
 		Type type = basic( typeName );
 		if ( type != null ) {
 			return type;
 		}
 
 		try {
 			Class typeClass = ReflectHelper.classForName( typeName );
 			if ( typeClass != null ) {
 				return typeFactory.byClass( typeClass, parameters );
 			}
 		}
 		catch ( ClassNotFoundException ignore ) {
 		}
 
 		return null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/descriptor/JdbcTypeNameMapper.java b/hibernate-core/src/main/java/org/hibernate/type/descriptor/JdbcTypeNameMapper.java
index df43463944..1a85d00743 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/descriptor/JdbcTypeNameMapper.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/descriptor/JdbcTypeNameMapper.java
@@ -1,110 +1,111 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type.descriptor;
 
 import java.lang.reflect.Field;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
-import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 
+import static org.hibernate.internal.CoreLogging.messageLogger;
+
 /**
  * (Badly named) helper for dealing with standard JDBC types as defined by {@link java.sql.Types}
  *
  * @author Steve Ebersole
  */
 public final class JdbcTypeNameMapper {
-    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( JdbcTypeNameMapper.class );
+	private static final CoreMessageLogger LOG = messageLogger( JdbcTypeNameMapper.class );
 
 	private static Map<Integer,String> JDBC_TYPE_MAP = buildJdbcTypeMap();
 
 	private static Map<Integer, String> buildJdbcTypeMap() {
 		HashMap<Integer, String> map = new HashMap<Integer, String>();
 		Field[] fields = java.sql.Types.class.getFields();
 		if ( fields == null ) {
 			throw new HibernateException( "Unexpected problem extracting JDBC type mapping codes from java.sql.Types" );
 		}
 		for ( Field field : fields ) {
 			try {
 				final int code = field.getInt( null );
 				String old = map.put( code, field.getName() );
-                if ( old != null ) {
+				if ( old != null ) {
 					LOG.JavaSqlTypesMappedSameCodeMultipleTimes( code, old, field.getName() );
 				}
 			}
 			catch ( IllegalAccessException e ) {
 				throw new HibernateException( "Unable to access JDBC type mapping [" + field.getName() + "]", e );
 			}
 		}
 		return Collections.unmodifiableMap( map );
 	}
 
 	/**
 	 * Determine whether the given JDBC type code represents a standard JDBC type ("standard" being those defined on
 	 * {@link java.sql.Types}).
 	 *
 	 * NOTE : {@link java.sql.Types#OTHER} is also "filtered out" as being non-standard.
 	 *
 	 * @param typeCode The JDBC type code to check
 	 *
 	 * @return {@code true} to indicate the type code is a standard type code; {@code false} otherwise.
 	 */
 	public static boolean isStandardTypeCode(int typeCode) {
 		return isStandardTypeCode( Integer.valueOf( typeCode ) );
 	}
 
 	/**
 	 * Same as call to {@link #isStandardTypeCode(int)}
 	 *
 	 * @see #isStandardTypeCode(int)
 	 */
 	public static boolean isStandardTypeCode(Integer typeCode) {
 		return JDBC_TYPE_MAP.containsKey( typeCode );
 	}
 
 	/**
 	 * Get the type name as in the static field names defined on {@link java.sql.Types}.  If a type code is not
 	 * recognized, it is reported as {@code UNKNOWN(?)} where '?' is replace with the given type code.
 	 *
 	 * Intended as useful for logging purposes...
 	 *
 	 * @param typeCode The type code to find the name for.
 	 *
 	 * @return The type name.
 	 */
 	public static String getTypeName(Integer typeCode) {
 		String name = JDBC_TYPE_MAP.get( typeCode );
 		if ( name == null ) {
 			return "UNKNOWN(" + typeCode + ")";
 		}
 		return name;
 	}
 
 	private JdbcTypeNameMapper() {
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/descriptor/converter/AttributeConverterSqlTypeDescriptorAdapter.java b/hibernate-core/src/main/java/org/hibernate/type/descriptor/converter/AttributeConverterSqlTypeDescriptorAdapter.java
index 058a2c8283..8bf2003ca6 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/descriptor/converter/AttributeConverterSqlTypeDescriptorAdapter.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/descriptor/converter/AttributeConverterSqlTypeDescriptorAdapter.java
@@ -1,155 +1,153 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type.descriptor.converter;
 
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import javax.persistence.AttributeConverter;
 import javax.persistence.PersistenceException;
 
 import org.hibernate.type.descriptor.ValueBinder;
 import org.hibernate.type.descriptor.ValueExtractor;
 import org.hibernate.type.descriptor.WrapperOptions;
 import org.hibernate.type.descriptor.java.JavaTypeDescriptor;
-import org.hibernate.type.descriptor.sql.BasicBinder;
-import org.hibernate.type.descriptor.sql.BasicExtractor;
 import org.hibernate.type.descriptor.sql.SqlTypeDescriptor;
 
 import org.jboss.logging.Logger;
 
 /**
  * Adapter for incorporating JPA {@link AttributeConverter} handling into the SqlTypeDescriptor contract.
  * <p/>
  * Essentially this is responsible for mapping to/from the intermediate database type representation.  Continuing the
  * {@code AttributeConverter<Integer,String>} example from
  * {@link org.hibernate.mapping.SimpleValue#buildAttributeConverterTypeAdapter()}, the "intermediate database type
  * representation" would be the String representation.  So on binding, we convert the incoming Integer to String;
  * on extraction we extract the value as String and convert to Integer.
  *
  * @author Steve Ebersole
  */
 public class AttributeConverterSqlTypeDescriptorAdapter implements SqlTypeDescriptor {
 	private static final Logger log = Logger.getLogger( AttributeConverterSqlTypeDescriptorAdapter.class );
 
 	private final AttributeConverter converter;
 	private final SqlTypeDescriptor delegate;
 	private final JavaTypeDescriptor intermediateJavaTypeDescriptor;
 
 	public AttributeConverterSqlTypeDescriptorAdapter(
 			AttributeConverter converter,
 			SqlTypeDescriptor delegate,
 			JavaTypeDescriptor intermediateJavaTypeDescriptor) {
 		this.converter = converter;
 		this.delegate = delegate;
 		this.intermediateJavaTypeDescriptor = intermediateJavaTypeDescriptor;
 	}
 
 	@Override
 	public int getSqlType() {
 		return delegate.getSqlType();
 	}
 
 	@Override
 	public boolean canBeRemapped() {
 		// todo : consider the ramifications of this.
 		// certainly we need to account for the remapping of the delegate sql-type, but is it really valid to
 		// allow remapping of the converter sql-type?
 		return delegate.canBeRemapped();
 	}
 
 
 	// Binding ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <X> ValueBinder<X> getBinder(JavaTypeDescriptor<X> javaTypeDescriptor) {
 		// Get the binder for the intermediate type representation
 		final ValueBinder realBinder = delegate.getBinder( intermediateJavaTypeDescriptor );
 
 		return new ValueBinder<X>() {
 			@Override
 			public void bind(PreparedStatement st, X value, int index, WrapperOptions options) throws SQLException {
 				final Object convertedValue;
 				try {
 					convertedValue = converter.convertToDatabaseColumn( value );
 				}
 				catch (PersistenceException pe) {
 					throw pe;
 				}
 				catch (RuntimeException re) {
 					throw new PersistenceException( "Error attempting to apply AttributeConverter", re );
 				}
 
 				log.debugf( "Converted value on binding : %s -> %s", value, convertedValue );
 				realBinder.bind( st, convertedValue, index, options );
 			}
 		};
 	}
 
 
 	// Extraction ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public <X> ValueExtractor<X> getExtractor(JavaTypeDescriptor<X> javaTypeDescriptor) {
 		// Get the extractor for the intermediate type representation
 		final ValueExtractor realExtractor = delegate.getExtractor( intermediateJavaTypeDescriptor );
 
 		return new ValueExtractor<X>() {
 			@Override
 			public X extract(ResultSet rs, String name, WrapperOptions options) throws SQLException {
 				return doConversion( realExtractor.extract( rs, name, options ) );
 			}
 
 			@Override
 			public X extract(CallableStatement statement, int index, WrapperOptions options) throws SQLException {
 				return doConversion( realExtractor.extract( statement, index, options ) );
 			}
 
 			@Override
 			public X extract(CallableStatement statement, String[] paramNames, WrapperOptions options) throws SQLException {
 				if ( paramNames.length > 1 ) {
 					throw new IllegalArgumentException( "Basic value extraction cannot handle multiple output parameters" );
 				}
 				return doConversion( realExtractor.extract( statement, paramNames, options ) );
 			}
 
 			@SuppressWarnings("unchecked")
 			private X doConversion(Object extractedValue) {
 				try {
 					X convertedValue = (X) converter.convertToEntityAttribute( extractedValue );
 					log.debugf( "Converted value on extraction: %s -> %s", extractedValue, convertedValue );
 					return convertedValue;
 				}
 				catch (PersistenceException pe) {
 					throw pe;
 				}
 				catch (RuntimeException re) {
 					throw new PersistenceException( "Error attempting to apply AttributeConverter", re );
 				}
 			}
 		};
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/descriptor/java/SerializableTypeDescriptor.java b/hibernate-core/src/main/java/org/hibernate/type/descriptor/java/SerializableTypeDescriptor.java
index 488e214c01..1b64e5b6e2 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/descriptor/java/SerializableTypeDescriptor.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/descriptor/java/SerializableTypeDescriptor.java
@@ -1,157 +1,157 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type.descriptor.java;
 
 import java.io.ByteArrayInputStream;
 import java.io.InputStream;
 import java.io.Serializable;
 import java.sql.Blob;
 import java.sql.SQLException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.jdbc.BinaryStream;
 import org.hibernate.engine.jdbc.internal.BinaryStreamImpl;
 import org.hibernate.internal.util.SerializationHelper;
 import org.hibernate.type.descriptor.WrapperOptions;
 
 /**
  * Descriptor for general {@link Serializable} handling.
  *
  * @author Steve Ebersole
  * @author Brett meyer
  */
 public class SerializableTypeDescriptor<T extends Serializable> extends AbstractTypeDescriptor<T> {
 
 	// unfortunately the param types cannot be the same so use something other than 'T' here to make that obvious
 	public static class SerializableMutabilityPlan<S extends Serializable> extends MutableMutabilityPlan<S> {
 		private final Class<S> type;
 
 		public static final SerializableMutabilityPlan<Serializable> INSTANCE
 				= new SerializableMutabilityPlan<Serializable>( Serializable.class );
 
 		public SerializableMutabilityPlan(Class<S> type) {
 			this.type = type;
 		}
 
 		@Override
-        @SuppressWarnings({ "unchecked" })
+		@SuppressWarnings({ "unchecked" })
 		public S deepCopyNotNull(S value) {
 			return (S) SerializationHelper.clone( value );
 		}
 
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public SerializableTypeDescriptor(Class<T> type) {
 		super(
 				type,
 				Serializable.class.equals( type )
 						? (MutabilityPlan<T>) SerializableMutabilityPlan.INSTANCE
 						: new SerializableMutabilityPlan<T>( type )
 		);
 	}
 
 	public String toString(T value) {
 		return PrimitiveByteArrayTypeDescriptor.INSTANCE.toString( toBytes( value ) );
 	}
 
 	public T fromString(String string) {
 		return fromBytes( PrimitiveByteArrayTypeDescriptor.INSTANCE.fromString( string ) );
 	}
 
 	@Override
 	public boolean areEqual(T one, T another) {
 		if ( one == another ) {
 			return true;
 		}
 		if ( one == null || another == null ) {
 			return false;
 		}
 		return one.equals( another )
 				|| PrimitiveByteArrayTypeDescriptor.INSTANCE.areEqual( toBytes( one ), toBytes( another ) );
 	}
 
 	@Override
 	public int extractHashCode(T value) {
 		return PrimitiveByteArrayTypeDescriptor.INSTANCE.extractHashCode( toBytes( value ) );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public <X> X unwrap(T value, Class<X> type, WrapperOptions options) {
 		if ( value == null ) {
 			return null;
 		}
 		else if ( type.isInstance( value ) ) {
 			return (X) value;
 		}
 		else if ( byte[].class.isAssignableFrom( type ) ) {
 			return (X) toBytes( value );
 		}
 		else if ( InputStream.class.isAssignableFrom( type ) ) {
 			return (X) new ByteArrayInputStream( toBytes( value ) );
 		}
 		else if ( BinaryStream.class.isAssignableFrom( type ) ) {
 			return (X) new BinaryStreamImpl( toBytes( value ) );
 		}
 		else if ( Blob.class.isAssignableFrom( type )) {
 			return (X) options.getLobCreator().createBlob( toBytes(value) );
 		}
 		
 		throw unknownUnwrap( type );
 	}
 
 	@SuppressWarnings("unchecked")
 	public <X> T wrap(X value, WrapperOptions options) {
 		if ( value == null ) {
 			return null;
 		}
 		else if ( byte[].class.isInstance( value ) ) {
 			return fromBytes( (byte[]) value );
 		}
 		else if ( InputStream.class.isInstance( value ) ) {
 			return fromBytes( DataHelper.extractBytes( (InputStream) value ) );
 		}
 		else if ( Blob.class.isInstance( value )) {
 			try {
 				return fromBytes( DataHelper.extractBytes( ( (Blob) value ).getBinaryStream() ) );
 			}
 			catch ( SQLException e ) {
 				throw new HibernateException(e);
 			}
 		}
 		else if ( getJavaTypeClass().isInstance( value ) ) {
 			return (T) value;
 		}
 		throw unknownWrap( value.getClass() );
 	}
 
 	protected byte[] toBytes(T value) {
 		return SerializationHelper.serialize( value );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	protected T fromBytes(byte[] bytes) {
 		return (T) SerializationHelper.deserialize( bytes, getJavaTypeClass().getClassLoader() );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/BasicBinder.java b/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/BasicBinder.java
index 31e9cbe2cf..bc283cb842 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/BasicBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/BasicBinder.java
@@ -1,105 +1,106 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type.descriptor.sql;
 
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.type.descriptor.JdbcTypeNameMapper;
 import org.hibernate.type.descriptor.ValueBinder;
 import org.hibernate.type.descriptor.WrapperOptions;
 import org.hibernate.type.descriptor.java.JavaTypeDescriptor;
 
 import org.jboss.logging.Logger;
 
 /**
  * Convenience base implementation of {@link ValueBinder}
  *
  * @author Steve Ebersole
  */
 public abstract class BasicBinder<J> implements ValueBinder<J> {
-    private static final Logger log = CoreLogging.logger( BasicBinder.class );
+	private static final Logger log = CoreLogging.logger( BasicBinder.class );
 
-    private static final String BIND_MSG_TEMPLATE = "binding parameter [%s] as [%s] - [%s]";
-    private static final String NULL_BIND_MSG_TEMPLATE = "binding parameter [%s] as [%s] - [null]";
+	private static final String BIND_MSG_TEMPLATE = "binding parameter [%s] as [%s] - [%s]";
+	private static final String NULL_BIND_MSG_TEMPLATE = "binding parameter [%s] as [%s] - [null]";
 
 	private final JavaTypeDescriptor<J> javaDescriptor;
 	private final SqlTypeDescriptor sqlDescriptor;
 
 	public JavaTypeDescriptor<J> getJavaDescriptor() {
 		return javaDescriptor;
 	}
 
 	public SqlTypeDescriptor getSqlDescriptor() {
 		return sqlDescriptor;
 	}
 
 	public BasicBinder(JavaTypeDescriptor<J> javaDescriptor, SqlTypeDescriptor sqlDescriptor) {
 		this.javaDescriptor = javaDescriptor;
 		this.sqlDescriptor = sqlDescriptor;
 	}
 
 	@Override
 	public final void bind(PreparedStatement st, J value, int index, WrapperOptions options) throws SQLException {
-        final boolean traceEnabled = log.isTraceEnabled();
-        if ( value == null ) {
-            if ( traceEnabled ) {
-                log.trace(
+		final boolean traceEnabled = log.isTraceEnabled();
+		if ( value == null ) {
+			if ( traceEnabled ) {
+				log.trace(
 						String.format(
 								NULL_BIND_MSG_TEMPLATE,
 								index,
 								JdbcTypeNameMapper.getTypeName( getSqlDescriptor().getSqlType() )
 						)
 				);
-            }
-            st.setNull( index, sqlDescriptor.getSqlType() );
-        }
-        else {
-            if ( traceEnabled ) {
-                log.trace(
+			}
+			st.setNull( index, sqlDescriptor.getSqlType() );
+		}
+		else {
+			if ( traceEnabled ) {
+				log.trace(
 						String.format(
 								BIND_MSG_TEMPLATE,
 								index,
 								JdbcTypeNameMapper.getTypeName( sqlDescriptor.getSqlType() ),
 								getJavaDescriptor().extractLoggableRepresentation( value )
 						)
 				);
-            }
-            doBind( st, value, index, options );
-        }
+			}
+			doBind( st, value, index, options );
+		}
 	}
 
 	/**
 	 * Perform the binding.  Safe to assume that value is not null.
 	 *
 	 * @param st The prepared statement
 	 * @param value The value to bind (not null).
 	 * @param index The index at which to bind
 	 * @param options The binding options
 	 *
 	 * @throws SQLException Indicates a problem binding to the prepared statement.
 	 */
-	protected abstract void doBind(PreparedStatement st, J value, int index, WrapperOptions options) throws SQLException;
+	protected abstract void doBind(PreparedStatement st, J value, int index, WrapperOptions options)
+			throws SQLException;
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/ClobTypeDescriptor.java b/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/ClobTypeDescriptor.java
index fb0e98ae6a..6241ebbcb7 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/ClobTypeDescriptor.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/ClobTypeDescriptor.java
@@ -1,166 +1,175 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type.descriptor.sql;
 
 import java.sql.CallableStatement;
 import java.sql.Clob;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 
 import org.hibernate.engine.jdbc.CharacterStream;
 import org.hibernate.type.descriptor.ValueBinder;
 import org.hibernate.type.descriptor.ValueExtractor;
 import org.hibernate.type.descriptor.WrapperOptions;
 import org.hibernate.type.descriptor.java.JavaTypeDescriptor;
 
 /**
  * Descriptor for {@link Types#CLOB CLOB} handling.
  *
  * @author Steve Ebersole
  * @author Gail Badner
  */
 public abstract class ClobTypeDescriptor implements SqlTypeDescriptor {
 	@Override
 	public int getSqlType() {
 		return Types.CLOB;
 	}
 
 	@Override
 	public boolean canBeRemapped() {
 		return true;
 	}
 
 	@Override
 	public <X> ValueExtractor<X> getExtractor(final JavaTypeDescriptor<X> javaTypeDescriptor) {
 		return new BasicExtractor<X>( javaTypeDescriptor, this ) {
 			@Override
-            protected X doExtract(ResultSet rs, String name, WrapperOptions options) throws SQLException {
-                return javaTypeDescriptor.wrap( rs.getClob( name ), options );
-            }
+			protected X doExtract(ResultSet rs, String name, WrapperOptions options) throws SQLException {
+				return javaTypeDescriptor.wrap( rs.getClob( name ), options );
+			}
 
 			@Override
 			protected X doExtract(CallableStatement statement, int index, WrapperOptions options)
 					throws SQLException {
 				return javaTypeDescriptor.wrap( statement.getClob( index ), options );
 			}
 
 			@Override
 			protected X doExtract(CallableStatement statement, String name, WrapperOptions options)
 					throws SQLException {
 				return javaTypeDescriptor.wrap( statement.getClob( name ), options );
 			}
 		};
 	}
 
 	protected abstract <X> BasicBinder<X> getClobBinder(JavaTypeDescriptor<X> javaTypeDescriptor);
 
 	@Override
-    public <X> ValueBinder<X> getBinder(JavaTypeDescriptor<X> javaTypeDescriptor) {
+	public <X> ValueBinder<X> getBinder(JavaTypeDescriptor<X> javaTypeDescriptor) {
 		return getClobBinder( javaTypeDescriptor );
 	}
 
 
 	public static final ClobTypeDescriptor DEFAULT = new ClobTypeDescriptor() {
 		@Override
 		public <X> BasicBinder<X> getClobBinder(final JavaTypeDescriptor<X> javaTypeDescriptor) {
 			return new BasicBinder<X>( javaTypeDescriptor, this ) {
 				@Override
-				protected void doBind(PreparedStatement st, X value, int index, WrapperOptions options) throws SQLException {
+				protected void doBind(PreparedStatement st, X value, int index, WrapperOptions options)
+						throws SQLException {
 					if ( options.useStreamForLobBinding() ) {
 						STREAM_BINDING.getClobBinder( javaTypeDescriptor ).doBind( st, value, index, options );
 					}
 					else {
 						CLOB_BINDING.getClobBinder( javaTypeDescriptor ).doBind( st, value, index, options );
 					}
 				}
 			};
 		}
 	};
 
 	public static final ClobTypeDescriptor CLOB_BINDING = new ClobTypeDescriptor() {
 		@Override
 		public <X> BasicBinder<X> getClobBinder(final JavaTypeDescriptor<X> javaTypeDescriptor) {
 			return new BasicBinder<X>( javaTypeDescriptor, this ) {
 				@Override
 				protected void doBind(PreparedStatement st, X value, int index, WrapperOptions options)
 						throws SQLException {
 					st.setClob( index, javaTypeDescriptor.unwrap( value, Clob.class, options ) );
 				}
 			};
 		}
 	};
 
 	public static final ClobTypeDescriptor STREAM_BINDING = new ClobTypeDescriptor() {
 		@Override
 		public <X> BasicBinder<X> getClobBinder(final JavaTypeDescriptor<X> javaTypeDescriptor) {
 			return new BasicBinder<X>( javaTypeDescriptor, this ) {
 				@Override
 				protected void doBind(PreparedStatement st, X value, int index, WrapperOptions options)
 						throws SQLException {
-					final CharacterStream characterStream = javaTypeDescriptor.unwrap( value, CharacterStream.class, options );
+					final CharacterStream characterStream = javaTypeDescriptor.unwrap(
+							value,
+							CharacterStream.class,
+							options
+					);
 					st.setCharacterStream( index, characterStream.asReader(), characterStream.getLength() );
 				}
 			};
 		}
 	};
 
 	public static final ClobTypeDescriptor STREAM_BINDING_EXTRACTING = new ClobTypeDescriptor() {
 		@Override
 		public <X> BasicBinder<X> getClobBinder(final JavaTypeDescriptor<X> javaTypeDescriptor) {
 			return new BasicBinder<X>( javaTypeDescriptor, this ) {
 				@Override
 				protected void doBind(PreparedStatement st, X value, int index, WrapperOptions options)
 						throws SQLException {
-					final CharacterStream characterStream = javaTypeDescriptor.unwrap( value, CharacterStream.class, options );
+					final CharacterStream characterStream = javaTypeDescriptor.unwrap(
+							value,
+							CharacterStream.class,
+							options
+					);
 					st.setCharacterStream( index, characterStream.asReader(), characterStream.getLength() );
 				}
 			};
 		}
 
 		@Override
 		public <X> ValueExtractor<X> getExtractor(final JavaTypeDescriptor<X> javaTypeDescriptor) {
 			return new BasicExtractor<X>( javaTypeDescriptor, this ) {
 				@Override
 				protected X doExtract(ResultSet rs, String name, WrapperOptions options) throws SQLException {
 					return javaTypeDescriptor.wrap( rs.getCharacterStream( name ), options );
 				}
 
 				@Override
 				protected X doExtract(CallableStatement statement, int index, WrapperOptions options)
 						throws SQLException {
 					return javaTypeDescriptor.wrap( statement.getCharacterStream( index ), options );
 				}
 
 				@Override
 				protected X doExtract(CallableStatement statement, String name, WrapperOptions options)
 						throws SQLException {
 					return javaTypeDescriptor.wrap( statement.getCharacterStream( name ), options );
 				}
 			};
 		}
 	};
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/NClobTypeDescriptor.java b/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/NClobTypeDescriptor.java
index 8c287ce80e..9be3f2f4cb 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/NClobTypeDescriptor.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/NClobTypeDescriptor.java
@@ -1,129 +1,134 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type.descriptor.sql;
 
 import java.sql.CallableStatement;
 import java.sql.NClob;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 
 import org.hibernate.engine.jdbc.CharacterStream;
 import org.hibernate.type.descriptor.ValueBinder;
 import org.hibernate.type.descriptor.ValueExtractor;
 import org.hibernate.type.descriptor.WrapperOptions;
 import org.hibernate.type.descriptor.java.JavaTypeDescriptor;
 
 /**
  * Descriptor for {@link Types#NCLOB NCLOB} handling.
  *
  * @author Steve Ebersole
  * @author Gail Badner
  */
 public abstract class NClobTypeDescriptor implements SqlTypeDescriptor {
 	@Override
 	public int getSqlType() {
 		return Types.NCLOB;
 	}
 
 	@Override
 	public boolean canBeRemapped() {
 		return true;
 	}
 
 	@Override
 	public <X> ValueExtractor<X> getExtractor(final JavaTypeDescriptor<X> javaTypeDescriptor) {
 		return new BasicExtractor<X>( javaTypeDescriptor, this ) {
 			@Override
-            protected X doExtract(ResultSet rs, String name, WrapperOptions options) throws SQLException {
-                return javaTypeDescriptor.wrap( rs.getNClob( name ), options );
-            }
+			protected X doExtract(ResultSet rs, String name, WrapperOptions options) throws SQLException {
+				return javaTypeDescriptor.wrap( rs.getNClob( name ), options );
+			}
 
 			@Override
 			protected X doExtract(CallableStatement statement, int index, WrapperOptions options)
 					throws SQLException {
 				return javaTypeDescriptor.wrap( statement.getNClob( index ), options );
 			}
 
 			@Override
 			protected X doExtract(CallableStatement statement, String name, WrapperOptions options)
 					throws SQLException {
 				return javaTypeDescriptor.wrap( statement.getNClob( name ), options );
 			}
 		};
 	}
 
 	protected abstract <X> BasicBinder<X> getNClobBinder(JavaTypeDescriptor<X> javaTypeDescriptor);
 
 	@Override
-    public <X> ValueBinder<X> getBinder(JavaTypeDescriptor<X> javaTypeDescriptor) {
+	public <X> ValueBinder<X> getBinder(JavaTypeDescriptor<X> javaTypeDescriptor) {
 		return getNClobBinder( javaTypeDescriptor );
 	}
 
 
 	public static final NClobTypeDescriptor DEFAULT = new NClobTypeDescriptor() {
 		@Override
 		public <X> BasicBinder<X> getNClobBinder(final JavaTypeDescriptor<X> javaTypeDescriptor) {
 			return new BasicBinder<X>( javaTypeDescriptor, this ) {
 				@Override
-				protected void doBind(PreparedStatement st, X value, int index, WrapperOptions options) throws SQLException {
+				protected void doBind(PreparedStatement st, X value, int index, WrapperOptions options)
+						throws SQLException {
 					if ( options.useStreamForLobBinding() ) {
 						STREAM_BINDING.getNClobBinder( javaTypeDescriptor ).doBind( st, value, index, options );
 					}
 					else {
 						NCLOB_BINDING.getNClobBinder( javaTypeDescriptor ).doBind( st, value, index, options );
 					}
 				}
 			};
 		}
 	};
 
 	public static final NClobTypeDescriptor NCLOB_BINDING = new NClobTypeDescriptor() {
 		@Override
 		public <X> BasicBinder<X> getNClobBinder(final JavaTypeDescriptor<X> javaTypeDescriptor) {
 			return new BasicBinder<X>( javaTypeDescriptor, this ) {
 				@Override
 				protected void doBind(PreparedStatement st, X value, int index, WrapperOptions options)
 						throws SQLException {
 					st.setNClob( index, javaTypeDescriptor.unwrap( value, NClob.class, options ) );
 				}
 			};
 		}
 	};
 
 	public static final NClobTypeDescriptor STREAM_BINDING = new NClobTypeDescriptor() {
 		@Override
 		public <X> BasicBinder<X> getNClobBinder(final JavaTypeDescriptor<X> javaTypeDescriptor) {
 			return new BasicBinder<X>( javaTypeDescriptor, this ) {
 				@Override
 				protected void doBind(PreparedStatement st, X value, int index, WrapperOptions options)
 						throws SQLException {
-					final CharacterStream characterStream = javaTypeDescriptor.unwrap( value, CharacterStream.class, options );
+					final CharacterStream characterStream = javaTypeDescriptor.unwrap(
+							value,
+							CharacterStream.class,
+							options
+					);
 					st.setCharacterStream( index, characterStream.asReader(), characterStream.getLength() );
 				}
 			};
 		}
 	};
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/TimeTypeDescriptor.java b/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/TimeTypeDescriptor.java
index 9764d940e6..607304d313 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/TimeTypeDescriptor.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/TimeTypeDescriptor.java
@@ -1,96 +1,95 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type.descriptor.sql;
 
 import java.sql.CallableStatement;
-import java.sql.Date;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Time;
 import java.sql.Types;
 import java.util.Calendar;
 
 import org.hibernate.type.descriptor.ValueBinder;
 import org.hibernate.type.descriptor.ValueExtractor;
 import org.hibernate.type.descriptor.WrapperOptions;
 import org.hibernate.type.descriptor.java.JavaTypeDescriptor;
 
 /**
  * Descriptor for {@link Types#TIME TIME} handling.
  *
  * @author Steve Ebersole
  */
 public class TimeTypeDescriptor implements SqlTypeDescriptor {
 	public static final TimeTypeDescriptor INSTANCE = new TimeTypeDescriptor();
 
 	public TimeTypeDescriptor() {
 	}
 
 	@Override
 	public int getSqlType() {
 		return Types.TIME;
 	}
 
 	@Override
 	public boolean canBeRemapped() {
 		return true;
 	}
 
 	@Override
 	public <X> ValueBinder<X> getBinder(final JavaTypeDescriptor<X> javaTypeDescriptor) {
 		return new BasicBinder<X>( javaTypeDescriptor, this ) {
 			@Override
 			protected void doBind(PreparedStatement st, X value, int index, WrapperOptions options) throws SQLException {
 				final Time time = javaTypeDescriptor.unwrap( value, Time.class, options );
 				if ( value instanceof Calendar ) {
 					st.setTime( index, time, (Calendar) value );
 				}
 				else {
 					st.setTime( index, time );
 				}
 			}
 		};
 	}
 
 	@Override
 	public <X> ValueExtractor<X> getExtractor(final JavaTypeDescriptor<X> javaTypeDescriptor) {
 		return new BasicExtractor<X>( javaTypeDescriptor, this ) {
 			@Override
 			protected X doExtract(ResultSet rs, String name, WrapperOptions options) throws SQLException {
 				return javaTypeDescriptor.wrap( rs.getTime( name ), options );
 			}
 
 			@Override
 			protected X doExtract(CallableStatement statement, int index, WrapperOptions options) throws SQLException {
 				return javaTypeDescriptor.wrap( statement.getTime( index ), options );
 			}
 
 			@Override
 			protected X doExtract(CallableStatement statement, String name, WrapperOptions options) throws SQLException {
 				return javaTypeDescriptor.wrap( statement.getTime( name ), options );
 			}
 		};
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/internal/EntityManagerFactoryBuilderImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/internal/EntityManagerFactoryBuilderImpl.java
index eecb535270..3ae9b31483 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/internal/EntityManagerFactoryBuilderImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/internal/EntityManagerFactoryBuilderImpl.java
@@ -1,916 +1,913 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.boot.internal;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.StringTokenizer;
 import java.util.concurrent.ConcurrentHashMap;
 import javax.persistence.AttributeConverter;
 import javax.persistence.EntityManagerFactory;
 import javax.persistence.EntityNotFoundException;
 import javax.persistence.PersistenceException;
 import javax.persistence.spi.PersistenceUnitTransactionType;
 import javax.sql.DataSource;
 
 import org.hibernate.Interceptor;
 import org.hibernate.SessionFactory;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.boot.CacheRegionDefinition;
 import org.hibernate.boot.MetadataBuilder;
 import org.hibernate.boot.MetadataSources;
 import org.hibernate.boot.SessionFactoryBuilder;
 import org.hibernate.boot.archive.scan.internal.StandardScanOptions;
 import org.hibernate.boot.cfgxml.internal.ConfigLoader;
 import org.hibernate.boot.cfgxml.spi.LoadedConfig;
 import org.hibernate.boot.model.TypeContributor;
 import org.hibernate.boot.registry.BootstrapServiceRegistry;
 import org.hibernate.boot.registry.BootstrapServiceRegistryBuilder;
 import org.hibernate.boot.registry.StandardServiceRegistry;
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.boot.registry.selector.StrategyRegistrationProvider;
 import org.hibernate.boot.registry.selector.spi.StrategySelector;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.cfg.AttributeConverterDefinition;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.beanvalidation.BeanValidationIntegrator;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.id.factory.spi.MutableIdentifierGeneratorFactory;
 import org.hibernate.integrator.spi.Integrator;
 import org.hibernate.internal.log.DeprecationLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.jpa.AvailableSettings;
 import org.hibernate.jpa.boot.spi.EntityManagerFactoryBuilder;
 import org.hibernate.jpa.boot.spi.IntegratorProvider;
 import org.hibernate.jpa.boot.spi.PersistenceUnitDescriptor;
 import org.hibernate.jpa.boot.spi.StrategyRegistrationProviderList;
 import org.hibernate.jpa.boot.spi.TypeContributorList;
 import org.hibernate.jpa.event.spi.JpaIntegrator;
 import org.hibernate.jpa.internal.EntityManagerFactoryImpl;
 import org.hibernate.jpa.internal.EntityManagerMessageLogger;
 import org.hibernate.jpa.internal.schemagen.JpaSchemaGenerator;
 import org.hibernate.jpa.internal.util.LogHelper;
 import org.hibernate.jpa.internal.util.PersistenceUnitTransactionTypeHelper;
 import org.hibernate.jpa.spi.IdentifierGeneratorStrategyProvider;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.proxy.EntityNotFoundDelegate;
-import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorBuilderImpl;
 import org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorBuilderImpl;
+import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorBuilderImpl;
 import org.hibernate.secure.spi.GrantedPermission;
 import org.hibernate.secure.spi.JaccPermissionDeclarations;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 
 import org.jboss.jandex.Index;
-import org.jboss.logging.Logger;
 
 import static org.hibernate.cfg.AvailableSettings.JACC_CONTEXT_ID;
 import static org.hibernate.cfg.AvailableSettings.JACC_PREFIX;
 import static org.hibernate.cfg.AvailableSettings.SESSION_FACTORY_NAME;
 import static org.hibernate.jpa.AvailableSettings.CFG_FILE;
 import static org.hibernate.jpa.AvailableSettings.CLASS_CACHE_PREFIX;
 import static org.hibernate.jpa.AvailableSettings.COLLECTION_CACHE_PREFIX;
 import static org.hibernate.jpa.AvailableSettings.DISCARD_PC_ON_CLOSE;
 import static org.hibernate.jpa.AvailableSettings.PERSISTENCE_UNIT_NAME;
 import static org.hibernate.jpa.AvailableSettings.SHARED_CACHE_MODE;
 import static org.hibernate.jpa.AvailableSettings.VALIDATION_MODE;
+import static org.hibernate.jpa.internal.HEMLogging.messageLogger;
 
 /**
  * @author Steve Ebersole
  */
 public class EntityManagerFactoryBuilderImpl implements EntityManagerFactoryBuilder {
-    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(
-			EntityManagerMessageLogger.class,
-			EntityManagerFactoryBuilderImpl.class.getName()
-	);
+	private static final EntityManagerMessageLogger LOG = messageLogger( EntityManagerFactoryBuilderImpl.class );
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// New settings
 
 	/**
 	 * Names a {@link IntegratorProvider}
 	 */
 	public static final String INTEGRATOR_PROVIDER = "hibernate.integrator_provider";
 	
 	/**
 	 * Names a {@link StrategyRegistrationProviderList}
 	 */
 	public static final String STRATEGY_REGISTRATION_PROVIDERS = "hibernate.strategy_registration_provider";
 	
 	/**
 	 * Names a {@link TypeContributorList}
 	 */
 	public static final String TYPE_CONTRIBUTORS = "hibernate.type_contributors";
 
 	/**
 	 * Names a Jandex {@link Index} instance to use.
 	 */
 	public static final String JANDEX_INDEX = "hibernate.jandex_index";
 
 
 	private final PersistenceUnitDescriptor persistenceUnit;
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// things built in first phase, needed for second phase..
 	private final Map configurationValues;
 	private final StandardServiceRegistry standardServiceRegistry;
 	private final MetadataImplementor metadata;
 	private final SettingsImpl settings;
 
 	/**
 	 * Intended for internal testing only...
 	 */
 	public MetadataImplementor getMetadata() {
 		return metadata;
 	}
 
 	private static class JpaEntityNotFoundDelegate implements EntityNotFoundDelegate, Serializable {
 		/**
 		 * Singleton access
 		 */
 		public static final JpaEntityNotFoundDelegate INSTANCE = new JpaEntityNotFoundDelegate();
 
 		public void handleEntityNotFound(String entityName, Serializable id) {
 			throw new EntityNotFoundException( "Unable to find " + entityName  + " with id " + id );
 		}
 	}
 
 	public EntityManagerFactoryBuilderImpl(PersistenceUnitDescriptor persistenceUnit, Map integrationSettings) {
 		this( persistenceUnit, integrationSettings, null );
 	}
 
 	public EntityManagerFactoryBuilderImpl(
 			PersistenceUnitDescriptor persistenceUnit,
 			Map integrationSettings,
 			ClassLoader providedClassLoader ) {
 		
 		LogHelper.logPersistenceUnitInformation( persistenceUnit );
 
 		this.persistenceUnit = persistenceUnit;
 
 		if ( integrationSettings == null ) {
 			integrationSettings = Collections.emptyMap();
 		}
 
 		// Build the boot-strap service registry, which mainly handles class loader interactions
 		final BootstrapServiceRegistry bsr = buildBootstrapServiceRegistry( integrationSettings, providedClassLoader );
 
 		// merge configuration sources and build the "standard" service registry
 		final StandardServiceRegistryBuilder ssrBuilder = new StandardServiceRegistryBuilder( bsr );
 		final MergedSettings mergedSettings = mergeSettings( persistenceUnit, integrationSettings, ssrBuilder );
 		this.configurationValues = mergedSettings.getConfigurationValues();
 
 		// Build the "standard" service registry
 		ssrBuilder.applySettings( configurationValues );
 		this.settings = configure( ssrBuilder );
 		this.standardServiceRegistry = ssrBuilder.build();
 		configure( standardServiceRegistry, mergedSettings );
 
 		final MetadataSources metadataSources = new MetadataSources( bsr );
 		List<AttributeConverterDefinition> attributeConverterDefinitions = populate( metadataSources, mergedSettings, standardServiceRegistry );
 		final MetadataBuilder metamodelBuilder = metadataSources.getMetadataBuilder( standardServiceRegistry );
 		populate( metamodelBuilder, mergedSettings, standardServiceRegistry, attributeConverterDefinitions );
 		this.metadata = (MetadataImplementor) metamodelBuilder.build();
 
 		withValidatorFactory( configurationValues.get( AvailableSettings.VALIDATION_FACTORY ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// push back class transformation to the environment; for the time being this only has any effect in EE
 		// container situations, calling back into PersistenceUnitInfo#addClassTransformer
 		final boolean useClassTransformer = "true".equals( configurationValues.remove( AvailableSettings.USE_CLASS_ENHANCER ) );
 		if ( useClassTransformer ) {
 			persistenceUnit.pushClassTransformer( collectNamesOfClassesToEnhance( metadata ) );
 		}
 	}
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// temporary!
 	@SuppressWarnings("unchecked")
 	public Map getConfigurationValues() {
 		return Collections.unmodifiableMap( configurationValues );
 	}
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 
 	/**
 	 * Builds the {@link BootstrapServiceRegistry} used to eventually build the {@link org.hibernate.boot.registry.StandardServiceRegistryBuilder}; mainly
 	 * used here during instantiation to define class-loading behavior.
 	 *
 	 * @param integrationSettings Any integration settings passed by the EE container or SE application
 	 *
 	 * @return The built BootstrapServiceRegistry
 	 */
 	private BootstrapServiceRegistry buildBootstrapServiceRegistry(
 			Map integrationSettings,
 			ClassLoader providedClassLoader) {
 		final BootstrapServiceRegistryBuilder bsrBuilder = new BootstrapServiceRegistryBuilder();
 		bsrBuilder.applyIntegrator( new JpaIntegrator() );
 
 		final IntegratorProvider integratorProvider = (IntegratorProvider) integrationSettings.get( INTEGRATOR_PROVIDER );
 		if ( integratorProvider != null ) {
 			for ( Integrator integrator : integratorProvider.getIntegrators() ) {
 				bsrBuilder.applyIntegrator( integrator );
 			}
 		}
 		
 		final StrategyRegistrationProviderList strategyRegistrationProviderList
 				= (StrategyRegistrationProviderList) integrationSettings.get( STRATEGY_REGISTRATION_PROVIDERS );
 		if ( strategyRegistrationProviderList != null ) {
 			for ( StrategyRegistrationProvider strategyRegistrationProvider : strategyRegistrationProviderList
 					.getStrategyRegistrationProviders() ) {
 				bsrBuilder.withStrategySelectors( strategyRegistrationProvider );
 			}
 		}
 
 
 		// ClassLoaders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		if ( persistenceUnit.getClassLoader() != null ) {
 			bsrBuilder.applyClassLoader( persistenceUnit.getClassLoader() );
 		}
 
 		if ( providedClassLoader != null ) {
 			bsrBuilder.applyClassLoader( providedClassLoader );
 		}
 
 		final ClassLoader appClassLoader = (ClassLoader) integrationSettings.get( org.hibernate.cfg.AvailableSettings.APP_CLASSLOADER );
 		if ( appClassLoader != null ) {
 			LOG.debugf(
 					"Found use of deprecated `%s` setting; use `%s` instead.",
 					org.hibernate.cfg.AvailableSettings.APP_CLASSLOADER,
 					org.hibernate.cfg.AvailableSettings.CLASSLOADERS
 			);
 		}
 		final Object classLoadersSetting = integrationSettings.get( org.hibernate.cfg.AvailableSettings.CLASSLOADERS );
 		if ( classLoadersSetting != null ) {
 			if ( java.util.Collection.class.isInstance( classLoadersSetting ) ) {
 				for ( ClassLoader classLoader : (java.util.Collection<ClassLoader>) classLoadersSetting ) {
 					bsrBuilder.applyClassLoader( classLoader );
 				}
 			}
 			else if ( classLoadersSetting.getClass().isArray() ) {
 				for ( ClassLoader classLoader : (ClassLoader[]) classLoadersSetting ) {
 					bsrBuilder.applyClassLoader( classLoader );
 				}
 			}
 			else if ( ClassLoader.class.isInstance( classLoadersSetting ) ) {
 				bsrBuilder.applyClassLoader( (ClassLoader) classLoadersSetting );
 			}
 		}
 
 		return bsrBuilder.build();
 	}
 
 	@SuppressWarnings("unchecked")
 	private MergedSettings mergeSettings(
 			PersistenceUnitDescriptor persistenceUnit,
 			Map<?,?> integrationSettings,
 			StandardServiceRegistryBuilder ssrBuilder) {
 		final MergedSettings mergedSettings = new MergedSettings();
 
 		// first, apply persistence.xml-defined settings
 		if ( persistenceUnit.getProperties() != null ) {
 			mergedSettings.configurationValues.putAll( persistenceUnit.getProperties() );
 		}
 
 		mergedSettings.configurationValues.put( PERSISTENCE_UNIT_NAME, persistenceUnit.getName() );
 
 		final ConfigLoader configLoader = new ConfigLoader( ssrBuilder.getBootstrapServiceRegistry() );
 
 		// see if the persistence.xml settings named a Hibernate config file....
 		final String cfgXmlResourceName1 = (String) mergedSettings.configurationValues.remove( CFG_FILE );
 		if ( StringHelper.isNotEmpty( cfgXmlResourceName1 ) ) {
 			final LoadedConfig loadedCfg = configLoader.loadConfigXmlResource( cfgXmlResourceName1 );
 			processConfigXml( loadedCfg, mergedSettings, ssrBuilder );
 		}
 
 		// see if integration settings named a Hibernate config file....
 		final String cfgXmlResourceName2 = (String) integrationSettings.get( CFG_FILE );
 		if ( StringHelper.isNotEmpty( cfgXmlResourceName2 ) ) {
 			integrationSettings.remove( CFG_FILE );
 			final LoadedConfig loadedCfg = configLoader.loadConfigXmlResource( cfgXmlResourceName2 );
 			processConfigXml( loadedCfg, mergedSettings, ssrBuilder );
 		}
 
 		// finally, apply integration-supplied settings (per JPA spec, integration settings should override other sources)
 		for ( Map.Entry<?,?> entry : integrationSettings.entrySet() ) {
 			if ( entry.getKey() == null ) {
 				continue;
 			}
 
 			if ( entry.getValue() == null ) {
 				mergedSettings.configurationValues.remove( entry.getKey() );
 			}
 			else {
 				mergedSettings.configurationValues.put( entry.getKey(), entry.getValue() );
 			}
 		}
 
 		if ( !mergedSettings.configurationValues.containsKey( VALIDATION_MODE ) ) {
 			if ( persistenceUnit.getValidationMode() != null ) {
 				mergedSettings.configurationValues.put( VALIDATION_MODE, persistenceUnit.getValidationMode() );
 			}
 		}
 
 		if ( !mergedSettings.configurationValues.containsKey( SHARED_CACHE_MODE ) ) {
 			if ( persistenceUnit.getSharedCacheMode() != null ) {
 				mergedSettings.configurationValues.put( SHARED_CACHE_MODE, persistenceUnit.getSharedCacheMode() );
 			}
 		}
 
 		final String jaccContextId = (String) mergedSettings.configurationValues.get( JACC_CONTEXT_ID );
 
 		// here we are going to iterate the merged config settings looking for:
 		//		1) additional JACC permissions
 		//		2) additional cache region declarations
 		//
 		// we will also clean up an references with null entries
 		Iterator itr = mergedSettings.configurationValues.entrySet().iterator();
 		while ( itr.hasNext() ) {
 			final Map.Entry entry = (Map.Entry) itr.next();
 			if ( entry.getValue() == null ) {
 				// remove entries with null values
 				itr.remove();
 				break;
 			}
 
 			if ( String.class.isInstance( entry.getKey() ) && String.class.isInstance( entry.getValue() ) ) {
 				final String keyString = (String) entry.getKey();
 				final String valueString = (String) entry.getValue();
 
 				if ( keyString.startsWith( JACC_PREFIX ) ) {
 					if ( jaccContextId == null ) {
 						LOG.debug(
 								"Found JACC permission grant [%s] in properties, but no JACC context id was specified; ignoring"
 						);
 					}
 					else {
 						mergedSettings.getJaccPermissions( jaccContextId ).addPermissionDeclaration(
 								parseJaccConfigEntry( keyString, valueString )
 						);
 					}
 				}
 				else if ( keyString.startsWith( CLASS_CACHE_PREFIX ) ) {
 					mergedSettings.addCacheRegionDefinition(
 							parseCacheRegionDefinitionEntry(
 									keyString.substring( CLASS_CACHE_PREFIX.length() + 1 ),
 									valueString,
 									CacheRegionDefinition.CacheRegionType.ENTITY
 							)
 					);
 				}
 				else if ( keyString.startsWith( COLLECTION_CACHE_PREFIX ) ) {
 					mergedSettings.addCacheRegionDefinition(
 							parseCacheRegionDefinitionEntry(
 									keyString.substring( COLLECTION_CACHE_PREFIX.length() + 1 ),
 									(String) entry.getValue(),
 									CacheRegionDefinition.CacheRegionType.COLLECTION
 							)
 					);
 				}
 			}
 
 		}
 
 		return mergedSettings;
 	}
 
 	@SuppressWarnings("unchecked")
 	private void processConfigXml(
 			LoadedConfig loadedConfig,
 			MergedSettings mergedSettings,
 			StandardServiceRegistryBuilder ssrBuilder) {
 		if ( ! mergedSettings.configurationValues.containsKey( SESSION_FACTORY_NAME ) ) {
 			// there is not already a SF-name in the merged settings
 			final String sfName = loadedConfig.getSessionFactoryName();
 			if ( sfName != null ) {
 				// but the cfg.xml file we are processing named one..
 				mergedSettings.configurationValues.put( SESSION_FACTORY_NAME, sfName );
 			}
 		}
 
 		mergedSettings.configurationValues.putAll( loadedConfig.getConfigurationValues() );
 		ssrBuilder.configure( loadedConfig );
 	}
 
 	private GrantedPermission parseJaccConfigEntry(String keyString, String valueString) {
 		try {
 			final int roleStart = JACC_PREFIX.length() + 1;
 			final String role = keyString.substring( roleStart, keyString.indexOf( '.', roleStart ) );
 			final int classStart = roleStart + role.length() + 1;
 			final String clazz = keyString.substring( classStart, keyString.length() );
 			return new GrantedPermission( role, clazz, valueString );
 		}
 		catch ( IndexOutOfBoundsException e ) {
 			throw persistenceException( "Illegal usage of " + JACC_PREFIX + ": " + keyString );
 		}
 	}
 
 	private CacheRegionDefinition parseCacheRegionDefinitionEntry(String role, String value, CacheRegionDefinition.CacheRegionType cacheType) {
 		final StringTokenizer params = new StringTokenizer( value, ";, " );
 		if ( !params.hasMoreTokens() ) {
 			StringBuilder error = new StringBuilder( "Illegal usage of " );
 			if ( cacheType == CacheRegionDefinition.CacheRegionType.ENTITY ) {
 				error.append( CLASS_CACHE_PREFIX )
 						.append( ": " )
 						.append( CLASS_CACHE_PREFIX );
 			}
 			else {
 				error.append( COLLECTION_CACHE_PREFIX )
 						.append( ": " )
 						.append( COLLECTION_CACHE_PREFIX );
 			}
 			error.append( '.' )
 					.append( role )
 					.append( ' ' )
 					.append( value )
 					.append( ".  Was expecting configuration (usage[,region[,lazy]]), but found none" );
 			throw persistenceException( error.toString() );
 		}
 
 		String usage = params.nextToken();
 		String region = null;
 		if ( params.hasMoreTokens() ) {
 			region = params.nextToken();
 		}
 		boolean lazyProperty = true;
 		if ( cacheType == CacheRegionDefinition.CacheRegionType.ENTITY ) {
 			if ( params.hasMoreTokens() ) {
 				lazyProperty = "all".equalsIgnoreCase( params.nextToken() );
 			}
 		}
 		else {
 			lazyProperty = false;
 		}
 
 		return new CacheRegionDefinition( cacheType, role, usage, region, lazyProperty );
 	}
 
 	private SettingsImpl configure(StandardServiceRegistryBuilder ssrBuilder) {
 		final SettingsImpl settings = new SettingsImpl();
 
 		applyJdbcConnectionProperties( ssrBuilder );
 		applyTransactionProperties( ssrBuilder, settings );
 
 		// flush before completion validation
 		if ( "true".equals( configurationValues.get( Environment.FLUSH_BEFORE_COMPLETION ) ) ) {
 			ssrBuilder.applySetting( Environment.FLUSH_BEFORE_COMPLETION, "false" );
 			LOG.definingFlushBeforeCompletionIgnoredInHem( Environment.FLUSH_BEFORE_COMPLETION );
 		}
 
 		final Object value = configurationValues.get( DISCARD_PC_ON_CLOSE );
 		if ( value != null ) {
 			settings.setReleaseResourcesOnCloseEnabled( "true".equals( value ) );
 		}
 
 		final StrategySelector strategySelector = ssrBuilder.getBootstrapServiceRegistry().getService( StrategySelector.class );
 		final Object interceptorSetting = configurationValues.remove( AvailableSettings.SESSION_INTERCEPTOR );
 		if ( interceptorSetting != null ) {
 			settings.setSessionInterceptorClass(
 					loadSessionInterceptorClass( interceptorSetting, strategySelector )
 			);
 		}
 
 		return settings;
 	}
 
 	private void applyJdbcConnectionProperties(StandardServiceRegistryBuilder ssrBuilder) {
 		if ( dataSource != null ) {
 			ssrBuilder.applySetting( org.hibernate.cfg.AvailableSettings.DATASOURCE, dataSource );
 		}
 		else if ( persistenceUnit.getJtaDataSource() != null ) {
 			if ( ! ssrBuilder.getSettings().containsKey( org.hibernate.cfg.AvailableSettings.DATASOURCE ) ) {
 				ssrBuilder.applySetting( org.hibernate.cfg.AvailableSettings.DATASOURCE, persistenceUnit.getJtaDataSource() );
 				// HHH-8121 : make the PU-defined value available to EMF.getProperties()
 				configurationValues.put( AvailableSettings.JTA_DATASOURCE, persistenceUnit.getJtaDataSource() );
 			}
 		}
 		else if ( persistenceUnit.getNonJtaDataSource() != null ) {
 			if ( ! ssrBuilder.getSettings().containsKey( org.hibernate.cfg.AvailableSettings.DATASOURCE ) ) {
 				ssrBuilder.applySetting( org.hibernate.cfg.AvailableSettings.DATASOURCE, persistenceUnit.getNonJtaDataSource() );
 				// HHH-8121 : make the PU-defined value available to EMF.getProperties()
 				configurationValues.put( AvailableSettings.NON_JTA_DATASOURCE, persistenceUnit.getNonJtaDataSource() );
 			}
 		}
 		else {
 			final String driver = (String) configurationValues.get( AvailableSettings.JDBC_DRIVER );
 			if ( StringHelper.isNotEmpty( driver ) ) {
 				ssrBuilder.applySetting( org.hibernate.cfg.AvailableSettings.DRIVER, driver );
 			}
 			final String url = (String) configurationValues.get( AvailableSettings.JDBC_URL );
 			if ( StringHelper.isNotEmpty( url ) ) {
 				ssrBuilder.applySetting( org.hibernate.cfg.AvailableSettings.URL, url );
 			}
 			final String user = (String) configurationValues.get( AvailableSettings.JDBC_USER );
 			if ( StringHelper.isNotEmpty( user ) ) {
 				ssrBuilder.applySetting( org.hibernate.cfg.AvailableSettings.USER, user );
 			}
 			final String pass = (String) configurationValues.get( AvailableSettings.JDBC_PASSWORD );
 			if ( StringHelper.isNotEmpty( pass ) ) {
 				ssrBuilder.applySetting( org.hibernate.cfg.AvailableSettings.PASS, pass );
 			}
 		}
 	}
 
 	private void applyTransactionProperties(StandardServiceRegistryBuilder ssrBuilder, SettingsImpl settings) {
 		PersistenceUnitTransactionType txnType = PersistenceUnitTransactionTypeHelper.interpretTransactionType(
 				configurationValues.get( AvailableSettings.TRANSACTION_TYPE )
 		);
 		if ( txnType == null ) {
 			txnType = persistenceUnit.getTransactionType();
 		}
 		if ( txnType == null ) {
 			// is it more appropriate to have this be based on bootstrap entry point (EE vs SE)?
 			txnType = PersistenceUnitTransactionType.RESOURCE_LOCAL;
 		}
 		settings.setTransactionType( txnType );
 		boolean hasTxStrategy = configurationValues.containsKey( Environment.TRANSACTION_COORDINATOR_STRATEGY );
 		if ( hasTxStrategy ) {
 			LOG.overridingTransactionStrategyDangerous( Environment.TRANSACTION_COORDINATOR_STRATEGY );
 		}
 		else {
 			if ( txnType == PersistenceUnitTransactionType.JTA ) {
 				ssrBuilder.applySetting( Environment.TRANSACTION_COORDINATOR_STRATEGY, JtaTransactionCoordinatorBuilderImpl.class );
 			}
 			else if ( txnType == PersistenceUnitTransactionType.RESOURCE_LOCAL ) {
 				ssrBuilder.applySetting( Environment.TRANSACTION_COORDINATOR_STRATEGY, JdbcResourceLocalTransactionCoordinatorBuilderImpl.class );
 			}
 		}
 	}
 
 	@SuppressWarnings("unchecked")
 	private Class<? extends Interceptor> loadSessionInterceptorClass(Object value, StrategySelector strategySelector) {
 		if ( value == null ) {
 			return null;
 		}
 
 		return Class.class.isInstance( value )
 				? (Class<? extends Interceptor>) value
 				: strategySelector.selectStrategyImplementor( Interceptor.class, value.toString() );
 	}
 
 	private void configure(StandardServiceRegistry ssr, MergedSettings mergedSettings) {
 		final StrategySelector strategySelector = ssr.getService( StrategySelector.class );
 
 		// apply id generators
 		final Object idGeneratorStrategyProviderSetting = configurationValues.remove( AvailableSettings.IDENTIFIER_GENERATOR_STRATEGY_PROVIDER );
 		if ( idGeneratorStrategyProviderSetting != null ) {
 			final IdentifierGeneratorStrategyProvider idGeneratorStrategyProvider =
 					strategySelector.resolveStrategy( IdentifierGeneratorStrategyProvider.class, idGeneratorStrategyProviderSetting );
 			final MutableIdentifierGeneratorFactory identifierGeneratorFactory = ssr.getService( MutableIdentifierGeneratorFactory.class );
 			if ( identifierGeneratorFactory == null ) {
 				throw persistenceException(
 						"Application requested custom identifier generator strategies, " +
 								"but the MutableIdentifierGeneratorFactory could not be found"
 				);
 			}
 			for ( Map.Entry<String,Class<?>> entry : idGeneratorStrategyProvider.getStrategies().entrySet() ) {
 				identifierGeneratorFactory.register( entry.getKey(), entry.getValue() );
 			}
 		}
 	}
 
 	@SuppressWarnings("unchecked")
 	private List<AttributeConverterDefinition> populate(
 			MetadataSources metadataSources,
 			MergedSettings mergedSettings,
 			StandardServiceRegistry ssr) {
 //		final ClassLoaderService classLoaderService = ssr.getService( ClassLoaderService.class );
 //
 //		// todo : make sure MetadataSources/Metadata are capable of handling duplicate sources
 //
 //		// explicit persistence unit mapping files listings
 //		if ( persistenceUnit.getMappingFileNames() != null ) {
 //			for ( String name : persistenceUnit.getMappingFileNames() ) {
 //				metadataSources.addResource( name );
 //			}
 //		}
 //
 //		// explicit persistence unit managed class listings
 //		//		IMPL NOTE : managed-classes can contain class or package names!!!
 //		if ( persistenceUnit.getManagedClassNames() != null ) {
 //			for ( String managedClassName : persistenceUnit.getManagedClassNames() ) {
 //				// try it as a class name first...
 //				final String classFileName = managedClassName.replace( '.', '/' ) + ".class";
 //				final URL classFileUrl = classLoaderService.locateResource( classFileName );
 //				if ( classFileUrl != null ) {
 //					// it is a class
 //					metadataSources.addAnnotatedClassName( managedClassName );
 //					continue;
 //				}
 //
 //				// otherwise, try it as a package name
 //				final String packageInfoFileName = managedClassName.replace( '.', '/' ) + "/package-info.class";
 //				final URL packageInfoFileUrl = classLoaderService.locateResource( packageInfoFileName );
 //				if ( packageInfoFileUrl != null ) {
 //					// it is a package
 //					metadataSources.addPackage( managedClassName );
 //					continue;
 //				}
 //
 //				LOG.debugf(
 //						"Unable to resolve class [%s] named in persistence unit [%s]",
 //						managedClassName,
 //						persistenceUnit.getName()
 //				);
 //			}
 //		}
 
 		List<AttributeConverterDefinition> attributeConverterDefinitions = null;
 
 		// add any explicit Class references passed in
 		final List<Class> loadedAnnotatedClasses = (List<Class>) configurationValues.remove( AvailableSettings.LOADED_CLASSES );
 		if ( loadedAnnotatedClasses != null ) {
 			for ( Class cls : loadedAnnotatedClasses ) {
 				if ( AttributeConverter.class.isAssignableFrom( cls ) ) {
 					if ( attributeConverterDefinitions == null ) {
 						attributeConverterDefinitions = new ArrayList<AttributeConverterDefinition>();
 					}
 					attributeConverterDefinitions.add( AttributeConverterDefinition.from( (Class<? extends AttributeConverter>) cls ) );
 				}
 				else {
 					metadataSources.addAnnotatedClass( cls );
 				}
 			}
 		}
 
 		// add any explicit hbm.xml references passed in
 		final String explicitHbmXmls = (String) configurationValues.remove( AvailableSettings.HBXML_FILES );
 		if ( explicitHbmXmls != null ) {
 			for ( String hbmXml : StringHelper.split( ", ", explicitHbmXmls ) ) {
 				metadataSources.addResource( hbmXml );
 			}
 		}
 
 		// add any explicit orm.xml references passed in
 		final List<String> explicitOrmXmlList = (List<String>) configurationValues.remove( AvailableSettings.XML_FILE_NAMES );
 		if ( explicitOrmXmlList != null ) {
 			for ( String ormXml : explicitOrmXmlList ) {
 				metadataSources.addResource( ormXml );
 			}
 		}
 
 		return attributeConverterDefinitions;
 	}
 
 	private void populate(
 			MetadataBuilder metamodelBuilder,
 			MergedSettings mergedSettings,
 			StandardServiceRegistry ssr,
 			List<AttributeConverterDefinition> attributeConverterDefinitions) {
 		if ( persistenceUnit.getTempClassLoader() != null ) {
 			metamodelBuilder.applyTempClassLoader( persistenceUnit.getTempClassLoader() );
 		}
 
 		metamodelBuilder.applyScanEnvironment( new StandardJpaScanEnvironmentImpl( persistenceUnit ) );
 		metamodelBuilder.applyScanOptions(
 				new StandardScanOptions(
 						(String) configurationValues.get( org.hibernate.cfg.AvailableSettings.SCANNER_DISCOVERY ),
 						persistenceUnit.isExcludeUnlistedClasses()
 				)
 		);
 
 		if ( mergedSettings.cacheRegionDefinitions != null ) {
 			for ( CacheRegionDefinition localCacheRegionDefinition : mergedSettings.cacheRegionDefinitions ) {
 				metamodelBuilder.applyCacheRegionDefinition( localCacheRegionDefinition );
 			}
 		}
 
 		final Object namingStrategySetting = configurationValues.remove( AvailableSettings.NAMING_STRATEGY );
 		if ( namingStrategySetting != null ) {
 			DeprecationLogger.DEPRECATION_LOGGER.logDeprecatedNamingStrategySetting(
 					AvailableSettings.NAMING_STRATEGY,
 					org.hibernate.cfg.AvailableSettings.IMPLICIT_NAMING_STRATEGY,
 					org.hibernate.cfg.AvailableSettings.PHYSICAL_NAMING_STRATEGY
 			);
 		}
 
 		final TypeContributorList typeContributorList = (TypeContributorList) configurationValues.remove(
 				TYPE_CONTRIBUTORS
 		);
 		if ( typeContributorList != null ) {
 			for ( TypeContributor typeContributor : typeContributorList.getTypeContributors() ) {
 				metamodelBuilder.applyTypes( typeContributor );
 			}
 		}
 
 		if ( attributeConverterDefinitions != null ) {
 			for ( AttributeConverterDefinition attributeConverterDefinition : attributeConverterDefinitions ) {
 				metamodelBuilder.applyAttributeConverter( attributeConverterDefinition );
 			}
 		}
 	}
 
 	private List<String> collectNamesOfClassesToEnhance(MetadataImplementor metadata) {
 		final List<String> entityClassNames = new ArrayList<String>();
 		for ( PersistentClass persistentClass : metadata.getEntityBindings() ) {
 			if ( persistentClass.getClassName() != null ) {
 				entityClassNames.add( persistentClass.getClassName() );
 			}
 		}
 		return entityClassNames;
 	}
 
 
 
 
 	// Phase 2 concerns ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private Object validatorFactory;
 	private Object cdiBeanManager;
 	private DataSource dataSource;
 
 	@Override
 	public EntityManagerFactoryBuilder withValidatorFactory(Object validatorFactory) {
 		this.validatorFactory = validatorFactory;
 
 		if ( validatorFactory != null ) {
 			BeanValidationIntegrator.validateFactory( validatorFactory );
 		}
 		return this;
 	}
 
 	@Override
 	public EntityManagerFactoryBuilder withDataSource(DataSource dataSource) {
 		this.dataSource = dataSource;
 
 		return this;
 	}
 
 	@Override
 	public void cancel() {
 		// todo : close the bootstrap registry (not critical, but nice to do)
 	}
 
 	@Override
 	public void generateSchema() {
 		// This seems overkill, but building the SF is necessary to get the Integrators to kick in.
 		// Metamodel will clean this up...
 		try {
 			SessionFactoryBuilder sfBuilder = metadata.getSessionFactoryBuilder();
 			populate( sfBuilder, standardServiceRegistry );
 			sfBuilder.build();
 
 			JpaSchemaGenerator.performGeneration( metadata, configurationValues, standardServiceRegistry );
 		}
 		catch (Exception e) {
 			throw persistenceException( "Unable to build Hibernate SessionFactory", e );
 		}
 
 
 		// release this builder
 		cancel();
 	}
 
 	@SuppressWarnings("unchecked")
 	public EntityManagerFactory build() {
 		SessionFactoryBuilder sfBuilder = metadata.getSessionFactoryBuilder();
 		populate( sfBuilder, standardServiceRegistry );
 
 		SessionFactoryImplementor sessionFactory;
 		try {
 			sessionFactory = (SessionFactoryImplementor) sfBuilder.build();
 		}
 		catch (Exception e) {
 			throw persistenceException( "Unable to build Hibernate SessionFactory", e );
 		}
 
 		JpaSchemaGenerator.performGeneration( metadata, configurationValues, standardServiceRegistry );
 
 		return new EntityManagerFactoryImpl(
 				persistenceUnit.getName(),
 				sessionFactory,
 				metadata,
 				settings,
 				configurationValues
 		);
 	}
 
 	private void populate(SessionFactoryBuilder sfBuilder, StandardServiceRegistry ssr) {
 		final StrategySelector strategySelector = ssr.getService( StrategySelector.class );
 
 		// Locate and apply the requested SessionFactory-level interceptor (if one)
 		final Object sessionFactoryInterceptorSetting = configurationValues.remove( AvailableSettings.INTERCEPTOR );
 		if ( sessionFactoryInterceptorSetting != null ) {
 			final Interceptor sessionFactoryInterceptor =
 					strategySelector.resolveStrategy( Interceptor.class, sessionFactoryInterceptorSetting );
 			sfBuilder.applyInterceptor( sessionFactoryInterceptor );
 		}
 
 		// Locate and apply any requested SessionFactoryObserver
 		final Object sessionFactoryObserverSetting = configurationValues.remove( AvailableSettings.SESSION_FACTORY_OBSERVER );
 		if ( sessionFactoryObserverSetting != null ) {
 			final SessionFactoryObserver suppliedSessionFactoryObserver =
 					strategySelector.resolveStrategy( SessionFactoryObserver.class, sessionFactoryObserverSetting );
 			sfBuilder.addSessionFactoryObservers( suppliedSessionFactoryObserver );
 		}
 
 		sfBuilder.addSessionFactoryObservers( ServiceRegistryCloser.INSTANCE );
 
 		sfBuilder.applyEntityNotFoundDelegate( JpaEntityNotFoundDelegate.INSTANCE );
 
 		if ( this.validatorFactory != null ) {
 			sfBuilder.applyValidatorFactory( validatorFactory );
 		}
 		if ( this.cdiBeanManager != null ) {
 			sfBuilder.applyBeanManager( cdiBeanManager );
 		}
 	}
 
 
 	public static class ServiceRegistryCloser implements SessionFactoryObserver {
 		/**
 		 * Singleton access
 		 */
 		public static final ServiceRegistryCloser INSTANCE = new ServiceRegistryCloser();
 
 		@Override
 		public void sessionFactoryCreated(SessionFactory sessionFactory) {
 			// nothing to do
 		}
 
 		@Override
 		public void sessionFactoryClosed(SessionFactory sessionFactory) {
 			SessionFactoryImplementor sfi = ( (SessionFactoryImplementor) sessionFactory );
 			sfi.getServiceRegistry().destroy();
 			ServiceRegistry basicRegistry = sfi.getServiceRegistry().getParentServiceRegistry();
 			( (ServiceRegistryImplementor) basicRegistry ).destroy();
 		}
 	}
 
 	private PersistenceException persistenceException(String message) {
 		return persistenceException( message, null );
 	}
 
 	private PersistenceException persistenceException(String message, Exception cause) {
 		return new PersistenceException(
 				getExceptionHeader() + message,
 				cause
 		);
 	}
 
 	private String getExceptionHeader() {
 		return "[PersistenceUnit: " + persistenceUnit.getName() + "] ";
 	}
 
 	public static class MergedSettings {
 		private final Map configurationValues = new ConcurrentHashMap( 16, 0.75f, 1 );
 
 		private Map<String, JaccPermissionDeclarations> jaccPermissionsByContextId;
 		private List<CacheRegionDefinition> cacheRegionDefinitions;
 
 		public MergedSettings() {
 		}
 
 		public Map getConfigurationValues() {
 			return configurationValues;
 		}
 
 		public JaccPermissionDeclarations getJaccPermissions(String jaccContextId) {
 			if ( jaccPermissionsByContextId == null ) {
 				jaccPermissionsByContextId = new HashMap<String, JaccPermissionDeclarations>();
 			}
 
 			JaccPermissionDeclarations jaccPermissions = jaccPermissionsByContextId.get( jaccContextId );
 			if ( jaccPermissions == null ) {
 				jaccPermissions = new JaccPermissionDeclarations( jaccContextId );
 				jaccPermissionsByContextId.put( jaccContextId, jaccPermissions );
 			}
 			return jaccPermissions;
 		}
 
 		public void addCacheRegionDefinition(CacheRegionDefinition cacheRegionDefinition) {
 			if ( this.cacheRegionDefinitions == null ) {
 				this.cacheRegionDefinitions = new ArrayList<CacheRegionDefinition>();
 			}
 			this.cacheRegionDefinitions.add( cacheRegionDefinition );
 		}
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/internal/PersistenceXmlParser.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/internal/PersistenceXmlParser.java
index 348f2593a7..ac75b1f81f 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/internal/PersistenceXmlParser.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/internal/PersistenceXmlParser.java
@@ -1,488 +1,485 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.boot.internal;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.net.URL;
 import java.net.URLConnection;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 import javax.persistence.PersistenceException;
 import javax.persistence.spi.PersistenceUnitTransactionType;
 import javax.xml.XMLConstants;
 import javax.xml.parsers.DocumentBuilder;
 import javax.xml.parsers.DocumentBuilderFactory;
 import javax.xml.parsers.ParserConfigurationException;
 import javax.xml.transform.dom.DOMSource;
 import javax.xml.transform.stream.StreamSource;
 import javax.xml.validation.Schema;
 import javax.xml.validation.SchemaFactory;
 import javax.xml.validation.Validator;
 
+import org.hibernate.boot.archive.internal.ArchiveHelper;
 import org.hibernate.boot.registry.classloading.internal.ClassLoaderServiceImpl;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.internal.util.StringHelper;
+import org.hibernate.internal.util.xml.XsdException;
 import org.hibernate.jpa.AvailableSettings;
-import org.hibernate.boot.archive.internal.ArchiveHelper;
 import org.hibernate.jpa.internal.EntityManagerMessageLogger;
 import org.hibernate.jpa.internal.util.ConfigurationHelper;
-import org.hibernate.internal.util.xml.XsdException;
-
-import org.jboss.logging.Logger;
 
 import org.w3c.dom.Document;
 import org.w3c.dom.Element;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
 import org.xml.sax.ErrorHandler;
 import org.xml.sax.InputSource;
 import org.xml.sax.SAXException;
 import org.xml.sax.SAXParseException;
 
+import static org.hibernate.jpa.internal.HEMLogging.messageLogger;
+
 /**
  * Used by Hibernate to parse {@code persistence.xml} files in SE environments.
  *
  * @author Steve Ebersole
  */
 public class PersistenceXmlParser {
-    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(
-			EntityManagerMessageLogger.class,
-			PersistenceXmlParser.class.getName()
-	);
+    private static final EntityManagerMessageLogger LOG = messageLogger( PersistenceXmlParser.class );
 
 	private final ClassLoaderService classLoaderService;
 	private final PersistenceUnitTransactionType defaultTransactionType;
 
 	public static List<ParsedPersistenceXmlDescriptor> locatePersistenceUnits(Map integration) {
 		final PersistenceXmlParser parser = new PersistenceXmlParser(
 				ClassLoaderServiceImpl.fromConfigSettings( integration ),
 				PersistenceUnitTransactionType.RESOURCE_LOCAL
 		);
 
 		return parser.doResolve( integration );
 	}
 
 
 	public PersistenceXmlParser(ClassLoaderService classLoaderService, PersistenceUnitTransactionType defaultTransactionType) {
 		this.classLoaderService = classLoaderService;
 		this.defaultTransactionType = defaultTransactionType;
 	}
 
 	public List<ParsedPersistenceXmlDescriptor> doResolve(Map integration) {
 		final List<ParsedPersistenceXmlDescriptor> persistenceUnits = new ArrayList<ParsedPersistenceXmlDescriptor>();
 
 		final List<URL> xmlUrls = classLoaderService.locateResources( "META-INF/persistence.xml" );
 		if ( xmlUrls.isEmpty() ) {
 			LOG.unableToFindPersistenceXmlInClasspath();
 		}
 		else {
 			for ( URL xmlUrl : xmlUrls ) {
 				persistenceUnits.addAll( parsePersistenceXml( xmlUrl, integration ) );
 			}
 		}
 
 		return persistenceUnits;
 	}
 
 	private List<ParsedPersistenceXmlDescriptor> parsePersistenceXml(URL xmlUrl, Map integration) {
 		LOG.tracef( "Attempting to parse persistence.xml file : %s", xmlUrl.toExternalForm() );
 
 		final Document doc = loadUrl( xmlUrl );
 		final Element top = doc.getDocumentElement();
 
 		final List<ParsedPersistenceXmlDescriptor> persistenceUnits = new ArrayList<ParsedPersistenceXmlDescriptor>();
 
 		final NodeList children = top.getChildNodes();
 		for ( int i = 0; i < children.getLength() ; i++ ) {
 			if ( children.item( i ).getNodeType() == Node.ELEMENT_NODE ) {
 				final Element element = (Element) children.item( i );
 				final String tag = element.getTagName();
 				if ( tag.equals( "persistence-unit" ) ) {
 					final URL puRootUrl = ArchiveHelper.getJarURLFromURLEntry( xmlUrl, "/META-INF/persistence.xml" );
 					ParsedPersistenceXmlDescriptor persistenceUnit = new ParsedPersistenceXmlDescriptor( puRootUrl );
 					bindPersistenceUnit( persistenceUnit, element );
 
 					// per JPA spec, any settings passed in to PersistenceProvider bootstrap methods should override
 					// values found in persistence.xml
 					if ( integration.containsKey( AvailableSettings.PROVIDER ) ) {
 						persistenceUnit.setProviderClassName( (String) integration.get( AvailableSettings.PROVIDER ) );
 					}
 					if ( integration.containsKey( AvailableSettings.TRANSACTION_TYPE ) ) {
 						String transactionType = (String) integration.get( AvailableSettings.TRANSACTION_TYPE );
 						persistenceUnit.setTransactionType( parseTransactionType( transactionType ) );
 					}
 					if ( integration.containsKey( AvailableSettings.JTA_DATASOURCE ) ) {
 						persistenceUnit.setJtaDataSource( integration.get( AvailableSettings.JTA_DATASOURCE ) );
 					}
 					if ( integration.containsKey( AvailableSettings.NON_JTA_DATASOURCE ) ) {
 						persistenceUnit.setNonJtaDataSource( integration.get( AvailableSettings.NON_JTA_DATASOURCE ) );
 					}
 
 					decodeTransactionType( persistenceUnit );
 
 					Properties properties = persistenceUnit.getProperties();
 					ConfigurationHelper.overrideProperties( properties, integration );
 
 					persistenceUnits.add( persistenceUnit );
 				}
 			}
 		}
 		return persistenceUnits;
 	}
 
 	private void decodeTransactionType(ParsedPersistenceXmlDescriptor persistenceUnit) {
 		// if transaction type is set already
 		// 		use that value
 		// else
 		//		if JTA DS
 		//			use JTA
 		//		else if NOT JTA DS
 		//			use RESOURCE_LOCAL
 		//		else
 		//			use defaultTransactionType
 		if ( persistenceUnit.getTransactionType() != null ) {
 			return;
 		}
 
 		if ( persistenceUnit.getJtaDataSource() != null ) {
 			persistenceUnit.setTransactionType( PersistenceUnitTransactionType.JTA );
 		}
 		else if ( persistenceUnit.getNonJtaDataSource() != null ) {
 			persistenceUnit.setTransactionType( PersistenceUnitTransactionType.RESOURCE_LOCAL );
 		}
 		else {
 			persistenceUnit.setTransactionType( defaultTransactionType );
 		}
 	}
 
 	private void bindPersistenceUnit(ParsedPersistenceXmlDescriptor persistenceUnit, Element persistenceUnitElement) {
 		final String name = persistenceUnitElement.getAttribute( "name" );
 		if ( StringHelper.isNotEmpty( name ) ) {
-            LOG.tracef( "Persistence unit name from persistence.xml : %s", name );
+			LOG.tracef( "Persistence unit name from persistence.xml : %s", name );
 			persistenceUnit.setName( name );
 		}
 
 		final PersistenceUnitTransactionType transactionType = parseTransactionType(
 				persistenceUnitElement.getAttribute( "transaction-type" )
 		);
 		if ( transactionType != null ) {
 			persistenceUnit.setTransactionType( transactionType );
 		}
 
 
 		NodeList children = persistenceUnitElement.getChildNodes();
 		for ( int i = 0; i < children.getLength() ; i++ ) {
 			if ( children.item( i ).getNodeType() == Node.ELEMENT_NODE ) {
 				Element element = (Element) children.item( i );
 				String tag = element.getTagName();
 				if ( tag.equals( "non-jta-data-source" ) ) {
 					persistenceUnit.setNonJtaDataSource( extractContent( element ) );
 				}
 				else if ( tag.equals( "jta-data-source" ) ) {
 					persistenceUnit.setJtaDataSource( extractContent( element ) );
 				}
 				else if ( tag.equals( "provider" ) ) {
 					persistenceUnit.setProviderClassName( extractContent( element ) );
 				}
 				else if ( tag.equals( "class" ) ) {
 					persistenceUnit.addClasses( extractContent( element ) );
 				}
 				else if ( tag.equals( "mapping-file" ) ) {
 					persistenceUnit.addMappingFiles( extractContent( element ) );
 				}
 				else if ( tag.equals( "jar-file" ) ) {
 					persistenceUnit.addJarFileUrl( ArchiveHelper.getURLFromPath( extractContent( element ) ) );
 				}
 				else if ( tag.equals( "exclude-unlisted-classes" ) ) {
 					persistenceUnit.setExcludeUnlistedClasses( extractBooleanContent(element, true) );
 				}
 				else if ( tag.equals( "delimited-identifiers" ) ) {
 					persistenceUnit.setUseQuotedIdentifiers( true );
 				}
 				else if ( tag.equals( "validation-mode" ) ) {
 					persistenceUnit.setValidationMode( extractContent( element ) );
 				}
 				else if ( tag.equals( "shared-cache-mode" ) ) {
 					persistenceUnit.setSharedCacheMode( extractContent( element ) );
 				}
 				else if ( tag.equals( "properties" ) ) {
 					NodeList props = element.getChildNodes();
 					for ( int j = 0; j < props.getLength() ; j++ ) {
 						if ( props.item( j ).getNodeType() == Node.ELEMENT_NODE ) {
 							Element propElement = (Element) props.item( j );
 							if ( !"property".equals( propElement.getTagName() ) ) {
 								continue;
 							}
 							String propName = propElement.getAttribute( "name" ).trim();
 							String propValue = propElement.getAttribute( "value" ).trim();
 							if ( StringHelper.isEmpty( propValue ) ) {
 								//fall back to the natural (Hibernate) way of description
 								propValue = extractContent( propElement, "" );
 							}
 							persistenceUnit.getProperties().put( propName, propValue );
 						}
 					}
 				}
 			}
 		}
 	}
 
 	private static String extractContent(Element element) {
 		return extractContent( element, null );
 	}
 
 	private static String extractContent(Element element, String defaultStr) {
 		if ( element == null ) {
 			return defaultStr;
 		}
 
 		NodeList children = element.getChildNodes();
 		StringBuilder result = new StringBuilder("");
 		for ( int i = 0; i < children.getLength() ; i++ ) {
 			if ( children.item( i ).getNodeType() == Node.TEXT_NODE ||
 					children.item( i ).getNodeType() == Node.CDATA_SECTION_NODE ) {
 				result.append( children.item( i ).getNodeValue() );
 			}
 		}
 		return result.toString().trim();
 	}
 
 	private static boolean extractBooleanContent(Element element, boolean defaultBool) {
 		String content = extractContent( element );
 		if (content != null && content.length() > 0) {
 			return Boolean.valueOf(content);
 		}
 		return defaultBool;
 	}
 
 	private static PersistenceUnitTransactionType parseTransactionType(String value) {
 		if ( StringHelper.isEmpty( value ) ) {
 			return null;
 		}
 		else if ( value.equalsIgnoreCase( "JTA" ) ) {
 			return PersistenceUnitTransactionType.JTA;
 		}
 		else if ( value.equalsIgnoreCase( "RESOURCE_LOCAL" ) ) {
 			return PersistenceUnitTransactionType.RESOURCE_LOCAL;
 		}
 		else {
 			throw new PersistenceException( "Unknown persistence unit transaction type : " + value );
 		}
 	}
 
 	private Document loadUrl(URL xmlUrl) {
 		final String resourceName = xmlUrl.toExternalForm();
 		try {
 			URLConnection conn = xmlUrl.openConnection();
 			conn.setUseCaches( false ); //avoid JAR locking on Windows and Tomcat
 			try {
 				InputStream inputStream = conn.getInputStream();
 				try {
 					final InputSource inputSource = new InputSource( inputStream );
 					try {
 						DocumentBuilder documentBuilder = documentBuilderFactory().newDocumentBuilder();
 						try {
 							Document document = documentBuilder.parse( inputSource );
 							validate( document );
 							return document;
 						}
 						catch (SAXException e) {
 							throw new PersistenceException( "Unexpected error parsing [" + resourceName + "]", e );
 						}
 						catch (IOException e) {
 							throw new PersistenceException( "Unexpected error parsing [" + resourceName + "]", e );
 						}
 					}
 					catch (ParserConfigurationException e) {
 						throw new PersistenceException( "Unable to generate javax.xml.parsers.DocumentBuilder instance", e );
 					}
 				}
 				finally {
 					try {
 						inputStream.close();
 					}
 					catch (Exception ignored) {
 					}
 				}
 			}
 			catch (IOException e) {
 				throw new PersistenceException( "Unable to obtain input stream from [" + resourceName + "]", e );
 			}
 		}
 		catch (IOException e) {
 			throw new PersistenceException( "Unable to access [" + resourceName + "]", e );
 		}
 	}
 
 	private void validate(Document document) {
 		// todo : add ability to disable validation...
 
 		final Validator validator;
 		final String version = document.getDocumentElement().getAttribute( "version" );
 		if ( "2.1".equals( version ) ) {
 			validator = v21Schema().newValidator();
 		}
 		else if ( "2.0".equals( version ) ) {
 			validator = v2Schema().newValidator();
 		}
 		else if ( "1.0".equals(  version ) ) {
 			validator = v1Schema().newValidator();
 		}
 		else {
 			throw new PersistenceException( "Unrecognized persistence.xml version [" + version + "]" );
 		}
 
 		List<SAXException> errors = new ArrayList<SAXException>();
 		validator.setErrorHandler( new ErrorHandlerImpl( errors ) );
 		try {
 			validator.validate( new DOMSource( document ) );
 		}
 		catch (SAXException e) {
 			errors.add( e );
 		}
 		catch (IOException e) {
 			throw new PersistenceException( "Unable to validate persistence.xml", e );
 		}
 
 		if ( errors.size() != 0 ) {
 			//report all errors in the exception
 			StringBuilder errorMessage = new StringBuilder( );
 			for ( SAXException error : errors ) {
 				errorMessage.append( extractInfo( error ) ).append( '\n' );
 			}
 			throw new PersistenceException( "Invalid persistence.xml.\n" + errorMessage.toString() );
 		}
 	}
 
 	private DocumentBuilderFactory documentBuilderFactory;
 
 	private DocumentBuilderFactory documentBuilderFactory() {
 		if ( documentBuilderFactory == null ) {
 			documentBuilderFactory = buildDocumentBuilderFactory();
 		}
 		return documentBuilderFactory;
 	}
 
 	private DocumentBuilderFactory buildDocumentBuilderFactory() {
 		DocumentBuilderFactory documentBuilderFactory = DocumentBuilderFactory.newInstance();
 		documentBuilderFactory.setNamespaceAware( true );
 		return documentBuilderFactory;
 	}
 
 	private Schema v21Schema;
 
 	private Schema v21Schema() {
 		if ( v21Schema == null ) {
 			v21Schema = resolveLocalSchema( "org/hibernate/jpa/persistence_2_1.xsd" );
 		}
 		return v21Schema;
 	}
 
 	private Schema v2Schema;
 
 	private Schema v2Schema() {
 		if ( v2Schema == null ) {
 			v2Schema = resolveLocalSchema( "org/hibernate/jpa/persistence_2_0.xsd" );
 		}
 		return v2Schema;
 	}
 
 	private Schema v1Schema;
 
 	private Schema v1Schema() {
 		if ( v1Schema == null ) {
 			v1Schema = resolveLocalSchema( "org/hibernate/jpa/persistence_1_0.xsd" );
 		}
 		return v1Schema;
 	}
 
 
 	private Schema resolveLocalSchema(String schemaName) {
 		// These XSD resources should be available on the Hibernate ClassLoader
 		final URL url = classLoaderService.locateResource( schemaName );
 		if ( url == null ) {
 			throw new XsdException( "Unable to locate schema [" + schemaName + "] via classpath", schemaName );
 		}
 		try {
 			InputStream schemaStream = url.openStream();
 			try {
 				StreamSource source = new StreamSource( url.openStream() );
 				SchemaFactory schemaFactory = SchemaFactory.newInstance( XMLConstants.W3C_XML_SCHEMA_NS_URI );
 				return schemaFactory.newSchema( source );
 			}
 			catch ( SAXException e ) {
 				throw new XsdException( "Unable to load schema [" + schemaName + "]", e, schemaName );
 			}
 			catch ( IOException e ) {
 				throw new XsdException( "Unable to load schema [" + schemaName + "]", e, schemaName );
 			}
 			finally {
 				try {
 					schemaStream.close();
 				}
 				catch ( IOException e ) {
 					LOG.debugf( "Problem closing schema stream [%s]", e.toString() );
 				}
 			}
 		}
 		catch ( IOException e ) {
 			throw new XsdException( "Stream error handling schema url [" + url.toExternalForm() + "]", schemaName );
 		}
 	}
 
 
 	public static class ErrorHandlerImpl implements ErrorHandler {
 		private List<SAXException> errors;
 
 		ErrorHandlerImpl(List<SAXException> errors) {
 			this.errors = errors;
 		}
 
 		public void error(SAXParseException error) {
 			errors.add( error );
 		}
 
 		public void fatalError(SAXParseException error) {
 			errors.add( error );
 		}
 
 		public void warning(SAXParseException warn) {
 			LOG.trace( extractInfo( warn ) );
 		}
 	}
 
 	private static String extractInfo(SAXException error) {
 		if ( error instanceof SAXParseException ) {
 			return "Error parsing XML [line : " + ( (SAXParseException) error ).getLineNumber()
 					+ ", column : " + ( (SAXParseException) error ).getColumnNumber()
 					+ "] : " + error.getMessage();
 		}
 		else {
 			return "Error parsing XML : " + error.getMessage();
 		}
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/CriteriaQueryImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/CriteriaQueryImpl.java
index b8045cfe5e..c7aa010031 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/CriteriaQueryImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/CriteriaQueryImpl.java
@@ -1,405 +1,405 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.criteria;
 
 import java.io.Serializable;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import javax.persistence.Query;
 import javax.persistence.Tuple;
 import javax.persistence.criteria.CriteriaQuery;
 import javax.persistence.criteria.Expression;
 import javax.persistence.criteria.Order;
 import javax.persistence.criteria.ParameterExpression;
 import javax.persistence.criteria.Predicate;
 import javax.persistence.criteria.Root;
 import javax.persistence.criteria.Selection;
 import javax.persistence.criteria.Subquery;
 import javax.persistence.metamodel.EntityType;
 
 import org.hibernate.jpa.criteria.compile.CompilableCriteria;
 import org.hibernate.jpa.criteria.compile.CriteriaInterpretation;
 import org.hibernate.jpa.criteria.compile.CriteriaQueryTypeQueryAdapter;
 import org.hibernate.jpa.criteria.compile.ImplicitParameterBinding;
 import org.hibernate.jpa.criteria.compile.InterpretedParameterMetadata;
 import org.hibernate.jpa.criteria.compile.RenderingContext;
 import org.hibernate.jpa.internal.QueryImpl;
 import org.hibernate.jpa.spi.HibernateEntityManagerImplementor;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * The Hibernate implementation of the JPA {@link CriteriaQuery} contract.  Mostly a set of delegation to its
  * internal {@link QueryStructure}.
  *
  * @author Steve Ebersole
  */
 public class CriteriaQueryImpl<T> extends AbstractNode implements CriteriaQuery<T>, CompilableCriteria, Serializable {
 	private static final Logger log = Logger.getLogger( CriteriaQueryImpl.class );
 
 	private final Class<T> returnType;
 
 	private final QueryStructure<T> queryStructure;
 	private List<Order> orderSpecs = Collections.emptyList();
 
 
 	public CriteriaQueryImpl(
 			CriteriaBuilderImpl criteriaBuilder,
 			Class<T> returnType) {
 		super( criteriaBuilder );
 		this.returnType = returnType;
 		this.queryStructure = new QueryStructure<T>( this, criteriaBuilder );
 	}
 
 	@Override
 	public Class<T> getResultType() {
 		return returnType;
 	}
 
 
 	// SELECTION ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public CriteriaQuery<T> distinct(boolean applyDistinction) {
 		queryStructure.setDistinct( applyDistinction );
 		return this;
 	}
 
 	@Override
 	public boolean isDistinct() {
 		return queryStructure.isDistinct();
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public Selection<T> getSelection() {
 		return ( Selection<T> ) queryStructure.getSelection();
 	}
 
 	public void applySelection(Selection<? extends T> selection) {
 		queryStructure.setSelection( selection );
 	}
 
 	@Override
 	public CriteriaQuery<T> select(Selection<? extends T> selection) {
 		applySelection( selection );
 		return this;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public CriteriaQuery<T> multiselect(Selection<?>... selections) {
 		return multiselect( Arrays.asList( selections ) );
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public CriteriaQuery<T> multiselect(List<Selection<?>> selections) {
 		final Selection<? extends T> selection;
 
 		if ( Tuple.class.isAssignableFrom( getResultType() ) ) {
 			selection = ( Selection<? extends T> ) criteriaBuilder().tuple( selections );
 		}
 		else if ( getResultType().isArray() ) {
 			selection = ( Selection<? extends T> )  criteriaBuilder().array(
 					( Class<? extends Object[]> ) getResultType(),
 					selections
 			);
 		}
 		else if ( Object.class.equals( getResultType() ) ) {
 			switch ( selections.size() ) {
 				case 0: {
 					throw new IllegalArgumentException(
 							"empty selections passed to criteria query typed as Object"
 					);
 				}
 				case 1: {
 					selection = ( Selection<? extends T> ) selections.get( 0 );
 					break;
 				}
 				default: {
 					selection = ( Selection<? extends T> ) criteriaBuilder().array( selections );
 				}
 			}
 		}
 		else {
 			selection = criteriaBuilder().construct( getResultType(), selections );
 		}
 		applySelection( selection );
 		return this;
 	}
 
 
 	// ROOTS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public Set<Root<?>> getRoots() {
 		return queryStructure.getRoots();
 	}
 
 	@Override
 	public <X> Root<X> from(EntityType<X> entityType) {
 		return queryStructure.from( entityType );
 	}
 
 	@Override
 	public <X> Root<X> from(Class<X> entityClass) {
 		return queryStructure.from( entityClass );
 	}
 
 
 	// RESTRICTION ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public Predicate getRestriction() {
 		return queryStructure.getRestriction();
 	}
 
 	@Override
 	public CriteriaQuery<T> where(Expression<Boolean> expression) {
 		queryStructure.setRestriction( criteriaBuilder().wrap( expression ) );
 		return this;
 	}
 
 	@Override
 	public CriteriaQuery<T> where(Predicate... predicates) {
 		// TODO : assuming this should be a conjuntion, but the spec does not say specifically...
 		queryStructure.setRestriction( criteriaBuilder().and( predicates ) );
 		return this;
 	}
 
 
 	// GROUPING ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public List<Expression<?>> getGroupList() {
 		return queryStructure.getGroupings();
 	}
 
 	@Override
 	public CriteriaQuery<T> groupBy(Expression<?>... groupings) {
 		queryStructure.setGroupings( groupings );
 		return this;
 	}
 
 	@Override
 	public CriteriaQuery<T> groupBy(List<Expression<?>> groupings) {
 		queryStructure.setGroupings( groupings );
 		return this;
 	}
 
 	@Override
 	public Predicate getGroupRestriction() {
 		return queryStructure.getHaving();
 	}
 
 	@Override
 	public CriteriaQuery<T> having(Expression<Boolean> expression) {
 		queryStructure.setHaving( criteriaBuilder().wrap( expression ) );
 		return this;
 	}
 
 	@Override
 	public CriteriaQuery<T> having(Predicate... predicates) {
 		queryStructure.setHaving( criteriaBuilder().and( predicates ) );
 		return this;
 	}
 
 
 	// ORDERING ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public List<Order> getOrderList() {
 		return orderSpecs;
 	}
 
 	@Override
 	public CriteriaQuery<T> orderBy(Order... orders) {
 		if ( orders != null && orders.length > 0 ) {
 			orderSpecs = Arrays.asList( orders );
 		}
 		else {
 			orderSpecs = Collections.emptyList();
 		}
 		return this;
 	}
 
 	@Override
 	public CriteriaQuery<T> orderBy(List<Order> orders) {
 		orderSpecs = orders;
 		return this;
 	}
 
 	@Override
 	public Set<ParameterExpression<?>> getParameters() {
 		return queryStructure.getParameters();
 	}
 
 	@Override
 	public <U> Subquery<U> subquery(Class<U> subqueryType) {
 		return queryStructure.subquery( subqueryType );
 	}
 
 	@Override
 	public void validate() {
 		// getRoots() is explicitly supposed to return empty if none defined, no need to check for null
 		if ( getRoots().isEmpty() ) {
 			throw new IllegalStateException( "No criteria query roots were specified" );
 		}
 
 		// if there is not an explicit selection, there is an *implicit* selection of the root entity provided only
 		// a single query root was defined.
 		if ( getSelection() == null && !hasImplicitSelection() ) {
 			throw new IllegalStateException( "No explicit selection and an implicit one could not be determined" );
 		}
 	}
 
 	/**
 	 * If no explicit selection was defined, we have a condition called an implicit selection if the query specified
 	 * a single {@link Root} and the java type of that {@link Root root's} model is the same as this criteria's
 	 * {@link #getResultType() result type}.
 	 *
 	 * @return True if there is an explicit selection; false otherwise.
 	 */
 	private boolean hasImplicitSelection() {
 		if ( getRoots().size() != 1 ) {
 			return false;
 		}
 
 		Root root = getRoots().iterator().next();
-        Class<?> javaType = root.getModel().getJavaType();
-        if ( javaType != null && javaType != returnType ) {
+		Class<?> javaType = root.getModel().getJavaType();
+		if ( javaType != null && javaType != returnType ) {
 			return false;
 		}
 
 		// if we get here, the query defined no selection but defined a single root of the same type as the
 		// criteria query return, so we use that as the implicit selection
 		//
 		// todo : should we put an implicit marker in the selection to this fact to make later processing easier?
 		return true;
 	}
 
 	@Override
 	public CriteriaInterpretation interpret(RenderingContext renderingContext) {
 		final StringBuilder jpaqlBuffer = new StringBuilder();
 
 		queryStructure.render( jpaqlBuffer, renderingContext );
 
 		if ( ! getOrderList().isEmpty() ) {
 			jpaqlBuffer.append( " order by " );
 			String sep = "";
 			for ( Order orderSpec : getOrderList() ) {
 				jpaqlBuffer.append( sep )
 						.append( ( ( Renderable ) orderSpec.getExpression() ).render( renderingContext ) )
 						.append( orderSpec.isAscending() ? " asc" : " desc" );
 				sep = ", ";
 			}
 		}
 
 		final String jpaqlString = jpaqlBuffer.toString();
 
 		log.debugf( "Rendered criteria query -> %s", jpaqlString );
 
 		return new CriteriaInterpretation() {
 			@Override
 			@SuppressWarnings("unchecked")
 			public Query buildCompiledQuery(HibernateEntityManagerImplementor entityManager, final InterpretedParameterMetadata parameterMetadata) {
 
 				final Map<String,Class> implicitParameterTypes = extractTypeMap( parameterMetadata.implicitParameterBindings() );
 
 				QueryImpl jpaqlQuery = entityManager.createQuery(
 						jpaqlString,
 						getResultType(),
 						getSelection(),
 						new HibernateEntityManagerImplementor.QueryOptions() {
 							@Override
 							public List<ValueHandlerFactory.ValueHandler> getValueHandlers() {
 								SelectionImplementor selection = (SelectionImplementor) queryStructure.getSelection();
 								return selection == null
 										? null
 										: selection.getValueHandlers();
 							}
 
 							@Override
 							public Map<String, Class> getNamedParameterExplicitTypes() {
 								return implicitParameterTypes;
 							}
 
 							@Override
 							public ResultMetadataValidator getResultMetadataValidator() {
 								return new HibernateEntityManagerImplementor.QueryOptions.ResultMetadataValidator() {
 									@Override
 									public void validate(Type[] returnTypes) {
 										SelectionImplementor selection = (SelectionImplementor) queryStructure.getSelection();
 										if ( selection != null ) {
 											if ( selection.isCompoundSelection() ) {
 												if ( returnTypes.length != selection.getCompoundSelectionItems().size() ) {
 													throw new IllegalStateException(
 															"Number of return values [" + returnTypes.length +
 																	"] did not match expected [" +
 																	selection.getCompoundSelectionItems().size() + "]"
 													);
 												}
 											}
 											else {
 												if ( returnTypes.length > 1 ) {
 													throw new IllegalStateException(
 															"Number of return values [" + returnTypes.length +
 																	"] did not match expected [1]"
 													);
 												}
 											}
 										}
 									}
 								};
 							}
 						}
 				);
 
 				for ( ImplicitParameterBinding implicitParameterBinding : parameterMetadata.implicitParameterBindings() ) {
 					implicitParameterBinding.bind( jpaqlQuery );
 				}
 
 				return new CriteriaQueryTypeQueryAdapter(
 						entityManager,
 						jpaqlQuery,
 						parameterMetadata.explicitParameterInfoMap()
 				);
 			}
 
 			private Map<String, Class> extractTypeMap(List<ImplicitParameterBinding> implicitParameterBindings) {
 				final HashMap<String,Class> map = new HashMap<String, Class>();
 				for ( ImplicitParameterBinding implicitParameter : implicitParameterBindings ) {
 					map.put( implicitParameter.getParameterName(), implicitParameter.getJavaType() );
 				}
 				return map;
 			}
 		};
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/ExpressionImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/ExpressionImpl.java
index a04a167eff..0411cfb131 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/ExpressionImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/ExpressionImpl.java
@@ -1,135 +1,135 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.criteria.expression;
 
 import java.io.Serializable;
 import java.math.BigDecimal;
 import java.math.BigInteger;
 import java.util.Collection;
 import javax.persistence.criteria.Expression;
 import javax.persistence.criteria.Predicate;
 
 import org.hibernate.jpa.criteria.CriteriaBuilderImpl;
 import org.hibernate.jpa.criteria.ExpressionImplementor;
 import org.hibernate.jpa.criteria.expression.function.CastFunction;
 
 /**
  * Models an expression in the criteria query language.
  *
  * @author Steve Ebersole
  */
 public abstract class ExpressionImpl<T>
 		extends SelectionImpl<T>
 		implements ExpressionImplementor<T>, Serializable {
 	public ExpressionImpl(CriteriaBuilderImpl criteriaBuilder, Class<T> javaType) {
 		super( criteriaBuilder, javaType );
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public <X> Expression<X> as(Class<X> type) {
 		return type.equals( getJavaType() )
 				? (Expression<X>) this
 				: new CastFunction<X, T>( criteriaBuilder(), type, this );
 	}
 
 	@Override
 	public Predicate isNull() {
 		return criteriaBuilder().isNull( this );
 	}
 
 	@Override
 	public Predicate isNotNull() {
 		return criteriaBuilder().isNotNull( this );
 	}
 
 	@Override
-    public Predicate in(Object... values) {
+	public Predicate in(Object... values) {
 		return criteriaBuilder().in( this, values );
 	}
 
 	@Override
 	public Predicate in(Expression<?>... values) {
 		return criteriaBuilder().in( this, values );
 	}
 
 	@Override
 	public Predicate in(Collection<?> values) {
 		return criteriaBuilder().in( this, values.toArray() );
 	}
 
 	@Override
 	public Predicate in(Expression<Collection<?>> values) {
 		return criteriaBuilder().in( this, values );
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public ExpressionImplementor<Long> asLong() {
 		resetJavaType( Long.class );
 		return (ExpressionImplementor<Long>) this;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public ExpressionImplementor<Integer> asInteger() {
 		resetJavaType( Integer.class );
 		return (ExpressionImplementor<Integer>) this;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public ExpressionImplementor<Float> asFloat() {
 		resetJavaType( Float.class );
 		return (ExpressionImplementor<Float>) this;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public ExpressionImplementor<Double> asDouble() {
 		resetJavaType( Double.class );
 		return (ExpressionImplementor<Double>) this;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public ExpressionImplementor<BigDecimal> asBigDecimal() {
 		resetJavaType( BigDecimal.class );
 		return (ExpressionImplementor<BigDecimal>) this;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public ExpressionImplementor<BigInteger> asBigInteger() {
 		resetJavaType( BigInteger.class );
 		return (ExpressionImplementor<BigInteger>) this;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public ExpressionImplementor<String> asString() {
 		resetJavaType( String.class );
 		return (ExpressionImplementor<String>) this;
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/function/AggregationFunction.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/function/AggregationFunction.java
index 2a1ddb4845..aae932ccfa 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/function/AggregationFunction.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/function/AggregationFunction.java
@@ -1,227 +1,227 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.criteria.expression.function;
 
 import java.io.Serializable;
 import java.util.List;
 import javax.persistence.criteria.Expression;
 import javax.persistence.criteria.Root;
 
 import org.hibernate.jpa.criteria.CriteriaBuilderImpl;
 import org.hibernate.jpa.criteria.compile.RenderingContext;
 import org.hibernate.jpa.criteria.expression.LiteralExpression;
 
 /**
  * Models SQL aggregation functions (<tt>MIN</tt>, <tt>MAX</tt>, <tt>COUNT</tt>, etc).
  *
  * @author Steve Ebersole
  */
 public class AggregationFunction<T>
 		extends ParameterizedFunctionExpression<T>
 		implements Serializable {
 
 	/**
 	 * Constructs an aggregation function with a single literal argument.
 	 *
 	 * @param criteriaBuilder The query builder instance.
 	 * @param returnType The function return type.
 	 * @param functionName The name of the function.
 	 * @param argument The literal argument
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public AggregationFunction(
 			CriteriaBuilderImpl criteriaBuilder,
 			Class<T> returnType,
 			String functionName,
 			Object argument) {
 		this( criteriaBuilder, returnType, functionName, new LiteralExpression( criteriaBuilder, argument ) );
 	}
 
 	/**
 	 * Constructs an aggregation function with a single literal argument.
 	 *
 	 * @param criteriaBuilder The query builder instance.
 	 * @param returnType The function return type.
 	 * @param functionName The name of the function.
 	 * @param argument The argument
 	 */
 	public AggregationFunction(
 			CriteriaBuilderImpl criteriaBuilder,
 			Class<T> returnType,
 			String functionName,
 			Expression<?> argument) {
 		super( criteriaBuilder, returnType, functionName, argument );
 	}
 
 	@Override
 	public boolean isAggregation() {
 		return true;
 	}
 
 	@Override
 	protected boolean isStandardJpaFunction() {
 		return true;
 	}
 
 	/**
 	 * Implementation of a <tt>COUNT</tt> function providing convenience in construction.
 	 * <p/>
 	 * Parameterized as {@link Long} because thats what JPA states
 	 * that the return from <tt>COUNT</tt> should be.
 	 */
 	public static class COUNT extends AggregationFunction<Long> {
 		public static final String NAME = "count";
 
 		private final boolean distinct;
 
 		public COUNT(CriteriaBuilderImpl criteriaBuilder, Expression<?> expression, boolean distinct) {
 			super( criteriaBuilder, Long.class, NAME , expression );
 			this.distinct = distinct;
 		}
 
 		@Override
 		protected void renderArguments(StringBuilder buffer, RenderingContext renderingContext) {
 			if ( isDistinct() ) {
 				buffer.append("distinct ");
 			}
 			else {
 	            // If function specifies a single non-distinct entity with ID, its alias would normally be rendered, which ends up
 	            // converting to the column(s) associated with the entity's ID in the rendered SQL.  However, some DBs don't support
 	            // the multiple columns that would end up here for entities with composite IDs.  So, since we modify the query to
 	            // instead specify star since that's functionally equivalent and supported by all DBs.
-			    List<Expression<?>> argExprs = getArgumentExpressions();
-			    if (argExprs.size() == 1) {
-        	        Expression argExpr = argExprs.get(0);
-        	        if (argExpr instanceof Root<?>) {
-        	            Root<?> root = (Root<?>)argExpr;
-        	            if (!root.getModel().hasSingleIdAttribute()) {
-        	                buffer.append('*');
-        	                return;
-        	            }
-        	        }
-			    }
+				List<Expression<?>> argExprs = getArgumentExpressions();
+				if (argExprs.size() == 1) {
+					Expression argExpr = argExprs.get(0);
+					if (argExpr instanceof Root<?>) {
+						Root<?> root = (Root<?>)argExpr;
+						if (!root.getModel().hasSingleIdAttribute()) {
+							buffer.append('*');
+							return;
+						}
+					}
+				}
 			}
-            super.renderArguments(buffer, renderingContext);
+			super.renderArguments(buffer, renderingContext);
 		}
 
 		public boolean isDistinct() {
 			return distinct;
 		}
 
 	}
 
 	/**
      * Implementation of a <tt>AVG</tt> function providing convenience in construction.
      * <p/>
      * Parameterized as {@link Double} because thats what JPA states that the return from <tt>AVG</tt> should be.
 	 */
 	public static class AVG extends AggregationFunction<Double> {
 		public static final String NAME = "avg";
 
 		public AVG(CriteriaBuilderImpl criteriaBuilder, Expression<? extends Number> expression) {
 			super( criteriaBuilder, Double.class, NAME, expression );
 		}
 	}
 
 	/**
 	 * Implementation of a <tt>SUM</tt> function providing convenience in construction.
 	 * <p/>
 	 * Parameterized as {@link Number N extends Number} because thats what JPA states
 	 * that the return from <tt>SUM</tt> should be.
 	 */
 	public static class SUM<N extends Number> extends AggregationFunction<N> {
 		public static final String NAME = "sum";
 
 		@SuppressWarnings({ "unchecked" })
 		public SUM(CriteriaBuilderImpl criteriaBuilder, Expression<N> expression) {
 			super( criteriaBuilder, (Class<N>)expression.getJavaType(), NAME , expression);
 			// force the use of a ValueHandler
 			resetJavaType( expression.getJavaType() );
 		}
 
 		public SUM(CriteriaBuilderImpl criteriaBuilder, Expression<? extends Number> expression, Class<N> returnType) {
 			super( criteriaBuilder, returnType, NAME , expression);
 			// force the use of a ValueHandler
 			resetJavaType( returnType );
 		}
 	}
 
 	/**
 	 * Implementation of a <tt>MIN</tt> function providing convenience in construction.
 	 * <p/>
 	 * Parameterized as {@link Number N extends Number} because thats what JPA states
 	 * that the return from <tt>MIN</tt> should be.
 	 */
 	public static class MIN<N extends Number> extends AggregationFunction<N> {
 		public static final String NAME = "min";
 
 		@SuppressWarnings({ "unchecked" })
 		public MIN(CriteriaBuilderImpl criteriaBuilder, Expression<N> expression) {
 			super( criteriaBuilder, ( Class<N> ) expression.getJavaType(), NAME , expression);
 		}
 	}
 
 	/**
 	 * Implementation of a <tt>MAX</tt> function providing convenience in construction.
 	 * <p/>
 	 * Parameterized as {@link Number N extends Number} because thats what JPA states
 	 * that the return from <tt>MAX</tt> should be.
 	 */
 	public static class MAX<N extends Number> extends AggregationFunction<N> {
 		public static final String NAME = "max";
 
 		@SuppressWarnings({ "unchecked" })
 		public MAX(CriteriaBuilderImpl criteriaBuilder, Expression<N> expression) {
 			super( criteriaBuilder, ( Class<N> ) expression.getJavaType(), NAME , expression);
 		}
 	}
 
 	/**
 	 * Models  the <tt>MIN</tt> function in terms of non-numeric expressions.
 	 *
 	 * @see MIN
 	 */
 	public static class LEAST<X extends Comparable<X>> extends AggregationFunction<X> {
 		public static final String NAME = "min";
 
 		@SuppressWarnings({ "unchecked" })
 		public LEAST(CriteriaBuilderImpl criteriaBuilder, Expression<X> expression) {
 			super( criteriaBuilder, ( Class<X> ) expression.getJavaType(), NAME , expression);
 		}
 	}
 
 	/**
 	 * Models  the <tt>MAX</tt> function in terms of non-numeric expressions.
 	 *
 	 * @see MAX
 	 */
 	public static class GREATEST<X extends Comparable<X>> extends AggregationFunction<X> {
 		public static final String NAME = "max";
 
 		@SuppressWarnings({ "unchecked" })
 		public GREATEST(CriteriaBuilderImpl criteriaBuilder, Expression<X> expression) {
 			super( criteriaBuilder, ( Class<X> ) expression.getJavaType(), NAME , expression);
 		}
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/function/TrimFunction.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/function/TrimFunction.java
index 489c23feaf..ed80399032 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/function/TrimFunction.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/function/TrimFunction.java
@@ -1,143 +1,144 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.criteria.expression.function;
 
 import java.io.Serializable;
 import javax.persistence.criteria.CriteriaBuilder.Trimspec;
 import javax.persistence.criteria.Expression;
 
 import org.hibernate.jpa.criteria.CriteriaBuilderImpl;
 import org.hibernate.jpa.criteria.ParameterRegistry;
 import org.hibernate.jpa.criteria.Renderable;
 import org.hibernate.jpa.criteria.compile.RenderingContext;
 import org.hibernate.jpa.criteria.expression.LiteralExpression;
 
 /**
  * Models the ANSI SQL <tt>TRIM</tt> function.
  *
  * @author Steve Ebersole
  * @author Brett Meyer
  */
 public class TrimFunction
 		extends BasicFunctionExpression<String>
 		implements Serializable {
 	public static final String NAME = "trim";
 	public static final Trimspec DEFAULT_TRIMSPEC = Trimspec.BOTH;
 	public static final char DEFAULT_TRIM_CHAR = ' ';
 
 	private final Trimspec trimspec;
 	private final Expression<Character> trimCharacter;
 	private final Expression<String> trimSource;
 
 	public TrimFunction(
 			CriteriaBuilderImpl criteriaBuilder,
 			Trimspec trimspec,
 			Expression<Character> trimCharacter,
 			Expression<String> trimSource) {
 		super( criteriaBuilder, String.class, NAME );
 		this.trimspec = trimspec;
 		this.trimCharacter = trimCharacter;
 		this.trimSource = trimSource;
 	}
 
 	public TrimFunction(
 			CriteriaBuilderImpl criteriaBuilder,
 			Trimspec trimspec,
 			char trimCharacter,
 			Expression<String> trimSource) {
 		super( criteriaBuilder, String.class, NAME );
 		this.trimspec = trimspec;
 		this.trimCharacter = new LiteralExpression<Character>( criteriaBuilder, trimCharacter );
 		this.trimSource = trimSource;
 	}
 
 	public TrimFunction(
 			CriteriaBuilderImpl criteriaBuilder,
 			Expression<String> trimSource) {
 		this( criteriaBuilder, DEFAULT_TRIMSPEC, DEFAULT_TRIM_CHAR, trimSource );
 	}
 
 	public TrimFunction(
 			CriteriaBuilderImpl criteriaBuilder,
 			Expression<Character> trimCharacter,
 			Expression<String> trimSource) {
 		this( criteriaBuilder, DEFAULT_TRIMSPEC, trimCharacter, trimSource );
 	}
 
 	public TrimFunction(
 			CriteriaBuilderImpl criteriaBuilder,
 			char trimCharacter,
 			Expression<String> trimSource) {
 		this( criteriaBuilder, DEFAULT_TRIMSPEC, trimCharacter, trimSource );
 	}
 
 	public TrimFunction(
 			CriteriaBuilderImpl criteriaBuilder,
 			Trimspec trimspec,
 			Expression<String> trimSource) {
 		this( criteriaBuilder, trimspec, DEFAULT_TRIM_CHAR, trimSource );
 	}
 
 	public Expression<Character> getTrimCharacter() {
 		return trimCharacter;
 	}
 
 	public Expression<String> getTrimSource() {
 		return trimSource;
 	}
 
 	public Trimspec getTrimspec() {
 		return trimspec;
 	}
 
 	@Override
 	public void registerParameters(ParameterRegistry registry) {
 		Helper.possibleParameter( getTrimCharacter(), registry );
 		Helper.possibleParameter( getTrimSource(), registry );
 	}
 
 	@Override
 	public String render(RenderingContext renderingContext) {
 		String renderedTrimChar;
 		if ( trimCharacter.getClass().isAssignableFrom( 
 				LiteralExpression.class ) ) {
 			// If the character is a literal, treat it as one.  A few dialects
 			// do not support parameters as trim() arguments.
 			renderedTrimChar = ( ( LiteralExpression<Character> ) 
 					trimCharacter ).getLiteral().toString();
-		} else {
+		}
+		else {
 			renderedTrimChar = ( (Renderable) trimCharacter ).render( 
 					renderingContext );
 		}
 		return new StringBuilder()
 				.append( "trim(" )
 				.append( trimspec.name() )
 				.append( ' ' )
 				.append( renderedTrimChar )
 				.append( " from " )
 				.append( ( (Renderable) trimSource ).render( renderingContext ) )
 				.append( ')' )
 				.toString();
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/path/AbstractFromImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/path/AbstractFromImpl.java
index 6dce4681c1..bc6dff2e6e 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/path/AbstractFromImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/path/AbstractFromImpl.java
@@ -1,611 +1,614 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, 2012 Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.criteria.path;
 
 import java.io.Serializable;
 import java.util.Collections;
 import java.util.LinkedHashSet;
 import java.util.Set;
 import javax.persistence.criteria.CollectionJoin;
 import javax.persistence.criteria.Fetch;
 import javax.persistence.criteria.From;
 import javax.persistence.criteria.Join;
 import javax.persistence.criteria.JoinType;
 import javax.persistence.criteria.ListJoin;
 import javax.persistence.criteria.MapJoin;
 import javax.persistence.criteria.SetJoin;
 import javax.persistence.metamodel.Attribute;
 import javax.persistence.metamodel.CollectionAttribute;
 import javax.persistence.metamodel.ListAttribute;
 import javax.persistence.metamodel.ManagedType;
 import javax.persistence.metamodel.MapAttribute;
 import javax.persistence.metamodel.PluralAttribute;
 import javax.persistence.metamodel.SetAttribute;
 import javax.persistence.metamodel.SingularAttribute;
 import javax.persistence.metamodel.Type;
 
 import org.hibernate.jpa.criteria.BasicPathUsageException;
 import org.hibernate.jpa.criteria.CollectionJoinImplementor;
 import org.hibernate.jpa.criteria.CriteriaBuilderImpl;
 import org.hibernate.jpa.criteria.CriteriaSubqueryImpl;
 import org.hibernate.jpa.criteria.FromImplementor;
 import org.hibernate.jpa.criteria.JoinImplementor;
 import org.hibernate.jpa.criteria.ListJoinImplementor;
 import org.hibernate.jpa.criteria.MapJoinImplementor;
 import org.hibernate.jpa.criteria.PathSource;
 import org.hibernate.jpa.criteria.SetJoinImplementor;
 import org.hibernate.jpa.criteria.compile.RenderingContext;
 
 /**
  * Convenience base class for various {@link javax.persistence.criteria.From} implementations.
  *
  * @author Steve Ebersole
  */
-public abstract class AbstractFromImpl<Z,X>
+public abstract class AbstractFromImpl<Z, X>
 		extends AbstractPathImpl<X>
-		implements From<Z,X>, FromImplementor<Z,X>, Serializable {
+		implements From<Z, X>, FromImplementor<Z, X>, Serializable {
 
 	public static final JoinType DEFAULT_JOIN_TYPE = JoinType.INNER;
 
-    private Set<Join<X, ?>> joins;
-    private Set<Fetch<X, ?>> fetches;
+	private Set<Join<X, ?>> joins;
+	private Set<Fetch<X, ?>> fetches;
 
 	public AbstractFromImpl(CriteriaBuilderImpl criteriaBuilder, Class<X> javaType) {
 		this( criteriaBuilder, javaType, null );
 	}
 
 	public AbstractFromImpl(CriteriaBuilderImpl criteriaBuilder, Class<X> javaType, PathSource pathSource) {
 		super( criteriaBuilder, javaType, pathSource );
 	}
 
 	@Override
-	@SuppressWarnings({ "unchecked" })
+	@SuppressWarnings({"unchecked"})
 	public PathSource<Z> getPathSource() {
 		return super.getPathSource();
 	}
 
 	@Override
 	public String getPathIdentifier() {
 		return getAlias();
 	}
 
 	@Override
 	protected boolean canBeDereferenced() {
 		return true;
 	}
 
 	@Override
 	public void prepareAlias(RenderingContext renderingContext) {
 		if ( getAlias() == null ) {
 			if ( isCorrelated() ) {
 				setAlias( getCorrelationParent().getAlias() );
 			}
 			else {
 				setAlias( renderingContext.generateAlias() );
 			}
 		}
 	}
 
 	@Override
 	public String renderProjection(RenderingContext renderingContext) {
 		prepareAlias( renderingContext );
 		return getAlias();
 	}
 
 	@Override
 	public String render(RenderingContext renderingContext) {
 		return renderProjection( renderingContext );
 	}
 
 	@Override
 	public Attribute<?, ?> getAttribute() {
 		return null;
 	}
 
 	public From<?, Z> getParent() {
 		return null;
 	}
 
 	@Override
-	@SuppressWarnings({ "unchecked" })
+	@SuppressWarnings({"unchecked"})
 	protected Attribute<X, ?> locateAttributeInternal(String name) {
 		return (Attribute<X, ?>) locateManagedType().getAttribute( name );
 	}
 
-	@SuppressWarnings({ "unchecked" })
+	@SuppressWarnings({"unchecked"})
 	protected ManagedType<? super X> locateManagedType() {
 		// by default, this should be the model
 		return (ManagedType<? super X>) getModel();
 	}
 
 
 	// CORRELATION ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	// IMPL NOTE : another means from handling correlations is to create a series of
 	//		specialized From implementations that represent the correlation roots.  While
 	//		that may be cleaner code-wise, it is certainly means creating a lot of "extra"
 	//		classes since we'd need one for each Subquery#correlate method
 
-	private FromImplementor<Z,X> correlationParent;
+	private FromImplementor<Z, X> correlationParent;
 
 	private JoinScope<X> joinScope = new BasicJoinScope();
 
 	/**
 	 * Helper contract used to define who/what keeps track of joins and fetches made from this <tt>FROM</tt>.
 	 */
 	public static interface JoinScope<X> extends Serializable {
 		public void addJoin(Join<X, ?> join);
-		public void addFetch(Fetch<X,?> fetch);
+
+		public void addFetch(Fetch<X, ?> fetch);
 	}
 
 	protected class BasicJoinScope implements JoinScope<X> {
 		@Override
 		public void addJoin(Join<X, ?> join) {
 			if ( joins == null ) {
-				joins = new LinkedHashSet<Join<X,?>>();
+				joins = new LinkedHashSet<Join<X, ?>>();
 			}
 			joins.add( join );
 		}
 
 		@Override
 		public void addFetch(Fetch<X, ?> fetch) {
 			if ( fetches == null ) {
-				fetches = new LinkedHashSet<Fetch<X,?>>();
+				fetches = new LinkedHashSet<Fetch<X, ?>>();
 			}
 			fetches.add( fetch );
 		}
 	}
 
 	protected class CorrelationJoinScope implements JoinScope<X> {
 		@Override
 		public void addJoin(Join<X, ?> join) {
 			if ( joins == null ) {
-				joins = new LinkedHashSet<Join<X,?>>();
+				joins = new LinkedHashSet<Join<X, ?>>();
 			}
 			joins.add( join );
 		}
 
 		@Override
 		public void addFetch(Fetch<X, ?> fetch) {
 			throw new UnsupportedOperationException( "Cannot define fetch from a subquery correlation" );
 		}
 	}
 
 	@Override
 	public boolean isCorrelated() {
 		return correlationParent != null;
 	}
 
 	@Override
-	public FromImplementor<Z,X> getCorrelationParent() {
+	public FromImplementor<Z, X> getCorrelationParent() {
 		if ( correlationParent == null ) {
 			throw new IllegalStateException(
 					String.format(
 							"Criteria query From node [%s] is not part of a subquery correlation",
 							getPathIdentifier()
 					)
 			);
 		}
 		return correlationParent;
 	}
 
 	@Override
-	@SuppressWarnings({ "unchecked" })
+	@SuppressWarnings({"unchecked"})
 	public FromImplementor<Z, X> correlateTo(CriteriaSubqueryImpl subquery) {
 		final FromImplementor<Z, X> correlationDelegate = createCorrelationDelegate();
 		correlationDelegate.prepareCorrelationDelegate( this );
 		return correlationDelegate;
 	}
 
 	protected abstract FromImplementor<Z, X> createCorrelationDelegate();
 
 	@Override
 	public void prepareCorrelationDelegate(FromImplementor<Z, X> parent) {
 		this.joinScope = new CorrelationJoinScope();
 		this.correlationParent = parent;
 	}
 
 	@Override
 	public String getAlias() {
 		return isCorrelated() ? getCorrelationParent().getAlias() : super.getAlias();
 	}
 
 	// JOINS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	protected abstract boolean canBeJoinSource();
 
 	protected RuntimeException illegalJoin() {
 		return new IllegalArgumentException(
 				"Collection of values [" + getPathIdentifier() + "] cannot be source of a join"
 		);
 	}
 
 	@Override
-	@SuppressWarnings({ "unchecked" })
+	@SuppressWarnings({"unchecked"})
 	public Set<Join<X, ?>> getJoins() {
 		return joins == null
 				? Collections.EMPTY_SET
 				: joins;
 	}
 
 	@Override
 	public <Y> Join<X, Y> join(SingularAttribute<? super X, Y> singularAttribute) {
 		return join( singularAttribute, DEFAULT_JOIN_TYPE );
 	}
 
 	@Override
 	public <Y> Join<X, Y> join(SingularAttribute<? super X, Y> attribute, JoinType jt) {
-		if ( ! canBeJoinSource() ) {
+		if ( !canBeJoinSource() ) {
 			throw illegalJoin();
 		}
 
 		Join<X, Y> join = constructJoin( attribute, jt );
 		joinScope.addJoin( join );
 		return join;
 	}
 
 	private <Y> JoinImplementor<X, Y> constructJoin(SingularAttribute<? super X, Y> attribute, JoinType jt) {
 		if ( Type.PersistenceType.BASIC.equals( attribute.getType().getPersistenceType() ) ) {
 			throw new BasicPathUsageException( "Cannot join to attribute of basic type", attribute );
-        }
+		}
 
 		// TODO : runtime check that the attribute in fact belongs to this From's model/bindable
 
 		if ( jt.equals( JoinType.RIGHT ) ) {
 			throw new UnsupportedOperationException( "RIGHT JOIN not supported" );
 		}
 
 		final Class<Y> attributeType = attribute.getBindableJavaType();
-		return new SingularAttributeJoin<X,Y>(
+		return new SingularAttributeJoin<X, Y>(
 				criteriaBuilder(),
 				attributeType,
 				this,
 				attribute,
 				jt
 		);
 	}
 
 	@Override
 	public <Y> CollectionJoin<X, Y> join(CollectionAttribute<? super X, Y> collection) {
 		return join( collection, DEFAULT_JOIN_TYPE );
 	}
 
 	@Override
 	public <Y> CollectionJoin<X, Y> join(CollectionAttribute<? super X, Y> collection, JoinType jt) {
-		if ( ! canBeJoinSource() ) {
+		if ( !canBeJoinSource() ) {
 			throw illegalJoin();
 		}
 
 		final CollectionJoin<X, Y> join = constructJoin( collection, jt );
 		joinScope.addJoin( join );
 		return join;
 	}
 
-	private <Y> CollectionJoinImplementor<X, Y> constructJoin(CollectionAttribute<? super X, Y> collection, JoinType jt) {
+	private <Y> CollectionJoinImplementor<X, Y> constructJoin(
+			CollectionAttribute<? super X, Y> collection,
+			JoinType jt) {
 		if ( jt.equals( JoinType.RIGHT ) ) {
 			throw new UnsupportedOperationException( "RIGHT JOIN not supported" );
 		}
 
 		// TODO : runtime check that the attribute in fact belongs to this From's model/bindable
 
 		final Class<Y> attributeType = collection.getBindableJavaType();
 		return new CollectionAttributeJoin<X, Y>(
 				criteriaBuilder(),
 				attributeType,
 				this,
 				collection,
 				jt
 		);
 	}
 
 	@Override
 	public <Y> SetJoin<X, Y> join(SetAttribute<? super X, Y> set) {
 		return join( set, DEFAULT_JOIN_TYPE );
 	}
 
 	@Override
 	public <Y> SetJoin<X, Y> join(SetAttribute<? super X, Y> set, JoinType jt) {
-		if ( ! canBeJoinSource() ) {
+		if ( !canBeJoinSource() ) {
 			throw illegalJoin();
 		}
 
 		final SetJoin<X, Y> join = constructJoin( set, jt );
 		joinScope.addJoin( join );
 		return join;
 	}
 
 	private <Y> SetJoinImplementor<X, Y> constructJoin(SetAttribute<? super X, Y> set, JoinType jt) {
 		if ( jt.equals( JoinType.RIGHT ) ) {
 			throw new UnsupportedOperationException( "RIGHT JOIN not supported" );
 		}
 
 		// TODO : runtime check that the attribute in fact belongs to this From's model/bindable
 
 		final Class<Y> attributeType = set.getBindableJavaType();
-		return new SetAttributeJoin<X,Y>( criteriaBuilder(), attributeType, this, set, jt );
+		return new SetAttributeJoin<X, Y>( criteriaBuilder(), attributeType, this, set, jt );
 	}
 
 	@Override
 	public <Y> ListJoin<X, Y> join(ListAttribute<? super X, Y> list) {
 		return join( list, DEFAULT_JOIN_TYPE );
 	}
 
 	@Override
 	public <Y> ListJoin<X, Y> join(ListAttribute<? super X, Y> list, JoinType jt) {
-		if ( ! canBeJoinSource() ) {
+		if ( !canBeJoinSource() ) {
 			throw illegalJoin();
 		}
 
 		final ListJoin<X, Y> join = constructJoin( list, jt );
 		joinScope.addJoin( join );
 		return join;
 	}
 
-	private  <Y> ListJoinImplementor<X, Y> constructJoin(ListAttribute<? super X, Y> list, JoinType jt) {
+	private <Y> ListJoinImplementor<X, Y> constructJoin(ListAttribute<? super X, Y> list, JoinType jt) {
 		if ( jt.equals( JoinType.RIGHT ) ) {
 			throw new UnsupportedOperationException( "RIGHT JOIN not supported" );
 		}
 
 		// TODO : runtime check that the attribute in fact belongs to this From's model/bindable
 
 		final Class<Y> attributeType = list.getBindableJavaType();
-		return new ListAttributeJoin<X,Y>( criteriaBuilder(), attributeType, this, list, jt );
+		return new ListAttributeJoin<X, Y>( criteriaBuilder(), attributeType, this, list, jt );
 	}
 
 	@Override
 	public <K, V> MapJoin<X, K, V> join(MapAttribute<? super X, K, V> map) {
 		return join( map, DEFAULT_JOIN_TYPE );
 	}
 
 	@Override
 	public <K, V> MapJoin<X, K, V> join(MapAttribute<? super X, K, V> map, JoinType jt) {
-		if ( ! canBeJoinSource() ) {
+		if ( !canBeJoinSource() ) {
 			throw illegalJoin();
 		}
 
 		final MapJoin<X, K, V> join = constructJoin( map, jt );
 		joinScope.addJoin( join );
 		return join;
 	}
 
 	private <K, V> MapJoinImplementor<X, K, V> constructJoin(MapAttribute<? super X, K, V> map, JoinType jt) {
 		if ( jt.equals( JoinType.RIGHT ) ) {
 			throw new UnsupportedOperationException( "RIGHT JOIN not supported" );
 		}
 
 		// TODO : runtime check that the attribute in fact belongs to this From's model/bindable
 
 		final Class<V> attributeType = map.getBindableJavaType();
 		return new MapAttributeJoin<X, K, V>( criteriaBuilder(), attributeType, this, map, jt );
 	}
 
 	@Override
-	public <X,Y> Join<X, Y> join(String attributeName) {
+	public <X, Y> Join<X, Y> join(String attributeName) {
 		return join( attributeName, DEFAULT_JOIN_TYPE );
 	}
 
 	@Override
-	@SuppressWarnings({ "unchecked" })
-	public <X,Y> Join<X, Y> join(String attributeName, JoinType jt) {
-		if ( ! canBeJoinSource() ) {
+	@SuppressWarnings({"unchecked"})
+	public <X, Y> Join<X, Y> join(String attributeName, JoinType jt) {
+		if ( !canBeJoinSource() ) {
 			throw illegalJoin();
 		}
 
 		if ( jt.equals( JoinType.RIGHT ) ) {
 			throw new UnsupportedOperationException( "RIGHT JOIN not supported" );
 		}
 
-		final Attribute<X,?> attribute = (Attribute<X, ?>) locateAttribute( attributeName );
+		final Attribute<X, ?> attribute = (Attribute<X, ?>) locateAttribute( attributeName );
 		if ( attribute.isCollection() ) {
-			final PluralAttribute pluralAttribute = ( PluralAttribute ) attribute;
+			final PluralAttribute pluralAttribute = (PluralAttribute) attribute;
 			if ( PluralAttribute.CollectionType.COLLECTION.equals( pluralAttribute.getCollectionType() ) ) {
-				return (Join<X,Y>) join( (CollectionAttribute) attribute, jt );
+				return (Join<X, Y>) join( (CollectionAttribute) attribute, jt );
 			}
 			else if ( PluralAttribute.CollectionType.LIST.equals( pluralAttribute.getCollectionType() ) ) {
-				return (Join<X,Y>) join( (ListAttribute) attribute, jt );
+				return (Join<X, Y>) join( (ListAttribute) attribute, jt );
 			}
 			else if ( PluralAttribute.CollectionType.SET.equals( pluralAttribute.getCollectionType() ) ) {
-				return (Join<X,Y>) join( (SetAttribute) attribute, jt );
+				return (Join<X, Y>) join( (SetAttribute) attribute, jt );
 			}
 			else {
-				return (Join<X,Y>) join( (MapAttribute) attribute, jt );
+				return (Join<X, Y>) join( (MapAttribute) attribute, jt );
 			}
 		}
 		else {
-			return (Join<X,Y>) join( (SingularAttribute)attribute, jt );
+			return (Join<X, Y>) join( (SingularAttribute) attribute, jt );
 		}
 	}
 
 	@Override
-	public <X,Y> CollectionJoin<X, Y> joinCollection(String attributeName) {
+	public <X, Y> CollectionJoin<X, Y> joinCollection(String attributeName) {
 		return joinCollection( attributeName, DEFAULT_JOIN_TYPE );
 	}
 
 	@Override
-	@SuppressWarnings({ "unchecked" })
-	public <X,Y> CollectionJoin<X, Y> joinCollection(String attributeName, JoinType jt) {
-		final Attribute<X,?> attribute = (Attribute<X, ?>) locateAttribute( attributeName );
-		if ( ! attribute.isCollection() ) {
-            throw new IllegalArgumentException( "Requested attribute was not a collection" );
+	@SuppressWarnings({"unchecked"})
+	public <X, Y> CollectionJoin<X, Y> joinCollection(String attributeName, JoinType jt) {
+		final Attribute<X, ?> attribute = (Attribute<X, ?>) locateAttribute( attributeName );
+		if ( !attribute.isCollection() ) {
+			throw new IllegalArgumentException( "Requested attribute was not a collection" );
 		}
 
-		final PluralAttribute pluralAttribute = ( PluralAttribute ) attribute;
-		if ( ! PluralAttribute.CollectionType.COLLECTION.equals( pluralAttribute.getCollectionType() ) ) {
-            throw new IllegalArgumentException( "Requested attribute was not a collection" );
+		final PluralAttribute pluralAttribute = (PluralAttribute) attribute;
+		if ( !PluralAttribute.CollectionType.COLLECTION.equals( pluralAttribute.getCollectionType() ) ) {
+			throw new IllegalArgumentException( "Requested attribute was not a collection" );
 		}
 
-		return (CollectionJoin<X,Y>) join( (CollectionAttribute) attribute, jt );
+		return (CollectionJoin<X, Y>) join( (CollectionAttribute) attribute, jt );
 	}
 
 	@Override
-	public <X,Y> SetJoin<X, Y> joinSet(String attributeName) {
+	public <X, Y> SetJoin<X, Y> joinSet(String attributeName) {
 		return joinSet( attributeName, DEFAULT_JOIN_TYPE );
 	}
 
 	@Override
-	@SuppressWarnings({ "unchecked" })
-	public <X,Y> SetJoin<X, Y> joinSet(String attributeName, JoinType jt) {
-		final Attribute<X,?> attribute = (Attribute<X, ?>) locateAttribute( attributeName );
-		if ( ! attribute.isCollection() ) {
-            throw new IllegalArgumentException( "Requested attribute was not a set" );
+	@SuppressWarnings({"unchecked"})
+	public <X, Y> SetJoin<X, Y> joinSet(String attributeName, JoinType jt) {
+		final Attribute<X, ?> attribute = (Attribute<X, ?>) locateAttribute( attributeName );
+		if ( !attribute.isCollection() ) {
+			throw new IllegalArgumentException( "Requested attribute was not a set" );
 		}
 
-		final PluralAttribute pluralAttribute = ( PluralAttribute ) attribute;
-		if ( ! PluralAttribute.CollectionType.SET.equals( pluralAttribute.getCollectionType() ) ) {
-            throw new IllegalArgumentException( "Requested attribute was not a set" );
+		final PluralAttribute pluralAttribute = (PluralAttribute) attribute;
+		if ( !PluralAttribute.CollectionType.SET.equals( pluralAttribute.getCollectionType() ) ) {
+			throw new IllegalArgumentException( "Requested attribute was not a set" );
 		}
 
-		return (SetJoin<X,Y>) join( (SetAttribute) attribute, jt );
+		return (SetJoin<X, Y>) join( (SetAttribute) attribute, jt );
 	}
 
 	@Override
-	public <X,Y> ListJoin<X, Y> joinList(String attributeName) {
+	public <X, Y> ListJoin<X, Y> joinList(String attributeName) {
 		return joinList( attributeName, DEFAULT_JOIN_TYPE );
 	}
 
 	@Override
-	@SuppressWarnings({ "unchecked" })
-	public <X,Y> ListJoin<X, Y> joinList(String attributeName, JoinType jt) {
-		final Attribute<X,?> attribute = (Attribute<X, ?>) locateAttribute( attributeName );
-		if ( ! attribute.isCollection() ) {
-            throw new IllegalArgumentException( "Requested attribute was not a list" );
+	@SuppressWarnings({"unchecked"})
+	public <X, Y> ListJoin<X, Y> joinList(String attributeName, JoinType jt) {
+		final Attribute<X, ?> attribute = (Attribute<X, ?>) locateAttribute( attributeName );
+		if ( !attribute.isCollection() ) {
+			throw new IllegalArgumentException( "Requested attribute was not a list" );
 		}
 
-		final PluralAttribute pluralAttribute = ( PluralAttribute ) attribute;
-		if ( ! PluralAttribute.CollectionType.LIST.equals( pluralAttribute.getCollectionType() ) ) {
-            throw new IllegalArgumentException( "Requested attribute was not a list" );
+		final PluralAttribute pluralAttribute = (PluralAttribute) attribute;
+		if ( !PluralAttribute.CollectionType.LIST.equals( pluralAttribute.getCollectionType() ) ) {
+			throw new IllegalArgumentException( "Requested attribute was not a list" );
 		}
 
-		return (ListJoin<X,Y>) join( (ListAttribute) attribute, jt );
+		return (ListJoin<X, Y>) join( (ListAttribute) attribute, jt );
 	}
 
 	@Override
 	public <X, K, V> MapJoin<X, K, V> joinMap(String attributeName) {
 		return joinMap( attributeName, DEFAULT_JOIN_TYPE );
 	}
 
 	@Override
-	@SuppressWarnings({ "unchecked" })
+	@SuppressWarnings({"unchecked"})
 	public <X, K, V> MapJoin<X, K, V> joinMap(String attributeName, JoinType jt) {
-		final Attribute<X,?> attribute = (Attribute<X, ?>) locateAttribute( attributeName );
-		if ( ! attribute.isCollection() ) {
-            throw new IllegalArgumentException( "Requested attribute was not a map" );
+		final Attribute<X, ?> attribute = (Attribute<X, ?>) locateAttribute( attributeName );
+		if ( !attribute.isCollection() ) {
+			throw new IllegalArgumentException( "Requested attribute was not a map" );
 		}
 
-		final PluralAttribute pluralAttribute = ( PluralAttribute ) attribute;
-		if ( ! PluralAttribute.CollectionType.MAP.equals( pluralAttribute.getCollectionType() ) ) {
-            throw new IllegalArgumentException( "Requested attribute was not a map" );
+		final PluralAttribute pluralAttribute = (PluralAttribute) attribute;
+		if ( !PluralAttribute.CollectionType.MAP.equals( pluralAttribute.getCollectionType() ) ) {
+			throw new IllegalArgumentException( "Requested attribute was not a map" );
 		}
 
-		return (MapJoin<X,K,V>) join( (MapAttribute) attribute, jt );
+		return (MapJoin<X, K, V>) join( (MapAttribute) attribute, jt );
 	}
 
 
 	// FETCHES ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	protected boolean canBeFetchSource() {
 		// the conditions should be the same...
 		return canBeJoinSource();
 	}
 
 	protected RuntimeException illegalFetch() {
 		return new IllegalArgumentException(
 				"Collection of values [" + getPathIdentifier() + "] cannot be source of a fetch"
 		);
 	}
 
 	@Override
-	@SuppressWarnings({ "unchecked" })
+	@SuppressWarnings({"unchecked"})
 	public Set<Fetch<X, ?>> getFetches() {
 		return fetches == null
 				? Collections.EMPTY_SET
 				: fetches;
 	}
 
 	@Override
 	public <Y> Fetch<X, Y> fetch(SingularAttribute<? super X, Y> singularAttribute) {
 		return fetch( singularAttribute, DEFAULT_JOIN_TYPE );
 	}
 
 	@Override
 	public <Y> Fetch<X, Y> fetch(SingularAttribute<? super X, Y> attribute, JoinType jt) {
-		if ( ! canBeFetchSource() ) {
+		if ( !canBeFetchSource() ) {
 			throw illegalFetch();
 		}
 
 		Fetch<X, Y> fetch = constructJoin( attribute, jt );
 		joinScope.addFetch( fetch );
 		return fetch;
 	}
 
 	@Override
 	public <Y> Fetch<X, Y> fetch(PluralAttribute<? super X, ?, Y> pluralAttribute) {
 		return fetch( pluralAttribute, DEFAULT_JOIN_TYPE );
 	}
 
 	@Override
 	public <Y> Fetch<X, Y> fetch(PluralAttribute<? super X, ?, Y> pluralAttribute, JoinType jt) {
-		if ( ! canBeFetchSource() ) {
+		if ( !canBeFetchSource() ) {
 			throw illegalFetch();
 		}
 
 		final Fetch<X, Y> fetch;
 		// TODO : combine Fetch and Join hierarchies (JoinImplementor extends Join,Fetch???)
 		if ( PluralAttribute.CollectionType.COLLECTION.equals( pluralAttribute.getCollectionType() ) ) {
-			fetch = constructJoin( (CollectionAttribute<X,Y>) pluralAttribute, jt );
+			fetch = constructJoin( (CollectionAttribute<X, Y>) pluralAttribute, jt );
 		}
 		else if ( PluralAttribute.CollectionType.LIST.equals( pluralAttribute.getCollectionType() ) ) {
-			fetch = constructJoin( (ListAttribute<X,Y>) pluralAttribute, jt );
+			fetch = constructJoin( (ListAttribute<X, Y>) pluralAttribute, jt );
 		}
 		else if ( PluralAttribute.CollectionType.SET.equals( pluralAttribute.getCollectionType() ) ) {
-			fetch = constructJoin( (SetAttribute<X,Y>) pluralAttribute, jt );
+			fetch = constructJoin( (SetAttribute<X, Y>) pluralAttribute, jt );
 		}
 		else {
-			fetch = constructJoin( (MapAttribute<X,?,Y>) pluralAttribute, jt );
+			fetch = constructJoin( (MapAttribute<X, ?, Y>) pluralAttribute, jt );
 		}
 		joinScope.addFetch( fetch );
 		return fetch;
 	}
 
 	@Override
-	public <X,Y> Fetch<X, Y> fetch(String attributeName) {
+	public <X, Y> Fetch<X, Y> fetch(String attributeName) {
 		return fetch( attributeName, DEFAULT_JOIN_TYPE );
 	}
 
 	@Override
-	@SuppressWarnings({ "unchecked" })
-	public <X,Y> Fetch<X, Y> fetch(String attributeName, JoinType jt) {
-		if ( ! canBeFetchSource() ) {
+	@SuppressWarnings({"unchecked"})
+	public <X, Y> Fetch<X, Y> fetch(String attributeName, JoinType jt) {
+		if ( !canBeFetchSource() ) {
 			throw illegalFetch();
 		}
 
-		Attribute<X,?> attribute = (Attribute<X, ?>) locateAttribute( attributeName );
+		Attribute<X, ?> attribute = (Attribute<X, ?>) locateAttribute( attributeName );
 		if ( attribute.isCollection() ) {
 			return (Fetch<X, Y>) fetch( (PluralAttribute) attribute, jt );
 		}
 		else {
 			return (Fetch<X, Y>) fetch( (SingularAttribute) attribute, jt );
 		}
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/path/AbstractPathImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/path/AbstractPathImpl.java
index 79057ce3e7..c5b5674c35 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/path/AbstractPathImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/path/AbstractPathImpl.java
@@ -1,272 +1,272 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.criteria.path;
 
 import java.io.Serializable;
 import java.util.Collection;
 import java.util.HashMap;
 import java.util.Map;
 import javax.persistence.criteria.Expression;
 import javax.persistence.criteria.Path;
 import javax.persistence.metamodel.Attribute;
 import javax.persistence.metamodel.MapAttribute;
 import javax.persistence.metamodel.PluralAttribute;
 import javax.persistence.metamodel.SingularAttribute;
 
 import org.hibernate.jpa.criteria.CriteriaBuilderImpl;
 import org.hibernate.jpa.criteria.ParameterRegistry;
 import org.hibernate.jpa.criteria.PathImplementor;
 import org.hibernate.jpa.criteria.PathSource;
 import org.hibernate.jpa.criteria.compile.RenderingContext;
 import org.hibernate.jpa.criteria.expression.ExpressionImpl;
 import org.hibernate.jpa.criteria.expression.PathTypeExpression;
 
 /**
  * Convenience base class for various {@link Path} implementations.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractPathImpl<X>
 		extends ExpressionImpl<X>
 		implements Path<X>, PathImplementor<X>, Serializable {
 
 	private final PathSource pathSource;
 	private final Expression<Class<? extends X>> typeExpression;
 	private Map<String,Path> attributePathRegistry;
 
 	/**
 	 * Constructs a basic path instance.
 	 *
 	 * @param criteriaBuilder The criteria builder
 	 * @param javaType The java type of this path
 	 * @param pathSource The source (or origin) from which this path originates
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public AbstractPathImpl(
 			CriteriaBuilderImpl criteriaBuilder,
 			Class<X> javaType,
 			PathSource pathSource) {
 		super( criteriaBuilder, javaType );
 		this.pathSource = pathSource;
 		this.typeExpression =  new PathTypeExpression( criteriaBuilder(), getJavaType(), this );
 	}
 
 	public PathSource getPathSource() {
 		return pathSource;
 	}
 
 	@Override
-    public PathSource<?> getParentPath() {
-        return getPathSource();
-    }
+	public PathSource<?> getParentPath() {
+		return getPathSource();
+	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public Expression<Class<? extends X>> type() {
 		return typeExpression;
 	}
 
 	@Override
 	public String getPathIdentifier() {
 		return getPathSource().getPathIdentifier() + "." + getAttribute().getName();
 	}
 
 	protected abstract boolean canBeDereferenced();
 
 	protected final RuntimeException illegalDereference() {
 		return new IllegalStateException(
 				String.format(
 						"Illegal attempt to dereference path source [%s] of basic type",
 						getPathIdentifier()
 				)
 		);
 //		String message = "Illegal attempt to dereference path source [";
 //		if ( source != null ) {
 //			message += " [" + getPathIdentifier() + "]";
 //		}
 //		return new IllegalArgumentException(message);
 	}
 
 	protected final RuntimeException unknownAttribute(String attributeName) {
 		String message = "Unable to resolve attribute [" + attributeName + "] against path";
 		PathSource<?> source = getPathSource();
 		if ( source != null ) {
 			message += " [" + source.getPathIdentifier() + "]";
 		}
 		return new IllegalArgumentException(message);
 	}
 
 	protected final Path resolveCachedAttributePath(String attributeName) {
 		return attributePathRegistry == null
 				? null
 				: attributePathRegistry.get( attributeName );
 	}
 
 	protected final void registerAttributePath(String attributeName, Path path) {
 		if ( attributePathRegistry == null ) {
 			attributePathRegistry = new HashMap<String,Path>();
 		}
 		attributePathRegistry.put( attributeName, path );
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public <Y> Path<Y> get(SingularAttribute<? super X, Y> attribute) {
 		if ( ! canBeDereferenced() ) {
 			throw illegalDereference();
 		}
 
 		SingularAttributePath<Y> path = (SingularAttributePath<Y>) resolveCachedAttributePath( attribute.getName() );
 		if ( path == null ) {
 			path = new SingularAttributePath<Y>(
 					criteriaBuilder(),
 					attribute.getJavaType(),
 					getPathSourceForSubPaths(),
 					attribute
 			);
 			registerAttributePath( attribute.getName(), path );
 		}
 		return path;
 	}
 
 	protected PathSource getPathSourceForSubPaths() {
 		return this;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public <E, C extends Collection<E>> Expression<C> get(PluralAttribute<X, C, E> attribute) {
 		if ( ! canBeDereferenced() ) {
 			throw illegalDereference();
 		}
 
 		PluralAttributePath<C> path = (PluralAttributePath<C>) resolveCachedAttributePath( attribute.getName() );
 		if ( path == null ) {
 			path = new PluralAttributePath<C>( criteriaBuilder(), this, attribute );
 			registerAttributePath( attribute.getName(), path );
 		}
 		return path;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public <K, V, M extends Map<K, V>> Expression<M> get(MapAttribute<X, K, V> attribute) {
 		if ( ! canBeDereferenced() ) {
 			throw illegalDereference();
 		}
 
 		PluralAttributePath path = (PluralAttributePath) resolveCachedAttributePath( attribute.getName() );
 		if ( path == null ) {
 			path = new PluralAttributePath( criteriaBuilder(), this, attribute );
 			registerAttributePath( attribute.getName(), path );
 		}
 		return path;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public <Y> Path<Y> get(String attributeName) {
 		if ( ! canBeDereferenced() ) {
 			throw illegalDereference();
 		}
 
 		final Attribute attribute = locateAttribute( attributeName );
 
 		if ( attribute.isCollection() ) {
 			final PluralAttribute<X,Y,?> pluralAttribute = (PluralAttribute<X,Y,?>) attribute;
 			if ( PluralAttribute.CollectionType.MAP.equals( pluralAttribute.getCollectionType() ) ) {
 				return (PluralAttributePath<Y>) this.<Object,Object,Map<Object, Object>>get( (MapAttribute) pluralAttribute );
 			}
 			else {
 				return (PluralAttributePath<Y>) this.get( (PluralAttribute) pluralAttribute );
 			}
 		}
 		else {
 			return get( (SingularAttribute<X,Y>) attribute );
 		}
 	}
 
 	/**
 	 * Get the attribute by name from the underlying model.  This allows subclasses to
 	 * define exactly how the attribute is derived.
 	 *
 	 * @param attributeName The name of the attribute to locate
 	 *
 	 * @return The attribute; should never return null.
 	 *
 	 * @throws IllegalArgumentException If no such attribute exists
 	 */
 	protected  final Attribute locateAttribute(String attributeName) {
 		final Attribute attribute = locateAttributeInternal( attributeName );
 		if ( attribute == null ) {
 			throw unknownAttribute( attributeName );
 		}
 		return attribute;
 	}
 
 	/**
 	 * Get the attribute by name from the underlying model.  This allows subclasses to
 	 * define exactly how the attribute is derived.  Called from {@link #locateAttribute}
 	 * which also applies nullness checking for proper error reporting.
 	 *
 	 * @param attributeName The name of the attribute to locate
 	 *
 	 * @return The attribute; may be null.
 	 *
 	 * @throws IllegalArgumentException If no such attribute exists
 	 */
 	protected abstract Attribute locateAttributeInternal(String attributeName);
 
 	@Override
 	public void registerParameters(ParameterRegistry registry) {
 		// none to register
 	}
 
 	@Override
 	public void prepareAlias(RenderingContext renderingContext) {
 		// Make sure we delegate up to our source (eventually up to the path root) to
 		// prepare the path properly.
 		PathSource<?> source = getPathSource();
 		if ( source != null ) {
 			source.prepareAlias( renderingContext );
 		}
 	}
 
 	@Override
 	public String render(RenderingContext renderingContext) {
 		PathSource<?> source = getPathSource();
 		if ( source != null ) {
 			source.prepareAlias( renderingContext );
 			return source.getPathIdentifier() + "." + getAttribute().getName();
 		}
 		else {
 			return getAttribute().getName();
 		}
 	}
 
 	@Override
 	public String renderProjection(RenderingContext renderingContext) {
 		return render( renderingContext );
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/path/MapKeyHelpers.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/path/MapKeyHelpers.java
index 88a6009e9f..3b93fa5021 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/path/MapKeyHelpers.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/path/MapKeyHelpers.java
@@ -1,312 +1,309 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.criteria.path;
 
 import java.io.Serializable;
 import java.lang.reflect.Member;
 import java.util.Map;
-import javax.persistence.criteria.Join;
-import javax.persistence.criteria.MapJoin;
-import javax.persistence.criteria.Path;
 import javax.persistence.metamodel.Attribute;
 import javax.persistence.metamodel.Bindable;
 import javax.persistence.metamodel.ManagedType;
 import javax.persistence.metamodel.MapAttribute;
 import javax.persistence.metamodel.SingularAttribute;
 import javax.persistence.metamodel.Type;
 
-import org.hibernate.jpa.criteria.compile.RenderingContext;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.jpa.criteria.CriteriaBuilderImpl;
-import org.hibernate.jpa.criteria.PathSource;
 import org.hibernate.jpa.criteria.MapJoinImplementor;
 import org.hibernate.jpa.criteria.PathImplementor;
+import org.hibernate.jpa.criteria.PathSource;
+import org.hibernate.jpa.criteria.compile.RenderingContext;
 import org.hibernate.persister.collection.CollectionPersister;
 
 /**
- * {@link MapJoin#key} poses a number of implementation difficulties in terms of the type signatures
- * amongst the {@link Path}, {@link Join} and {@link Attribute} reference at play.  The implementations found here
- * provide that bridge.
+ * {@link javax.persistence.criteria.MapJoin#key} poses a number of implementation difficulties in terms of the
+ * type signatures amongst the {@link javax.persistence.criteria.Path}, {@link javax.persistence.criteria.Join} and
+ * {@link Attribute}.  The implementations found here provide that bridge.
  *
  * @author Steve Ebersole
  */
 public class MapKeyHelpers {
 
 	/**
-	 * Models a path to a map key.  This is the actual return used from {@link MapJoin#key}
+	 * Models a path to a map key.  This is the actual return used from {@link javax.persistence.criteria.MapJoin#key}
 	 *
 	 * @param <K> The type of the map key.
 	 */
 	public static class MapKeyPath<K>
 			extends AbstractPathImpl<K>
 			implements PathImplementor<K>, Serializable {
 
 		private final MapKeyAttribute<K> mapKeyAttribute;
 
 		public MapKeyPath(
 				CriteriaBuilderImpl criteriaBuilder,
 				MapKeySource<K,?> source,
 				MapKeyAttribute<K> mapKeyAttribute) {
 			super( criteriaBuilder, mapKeyAttribute.getJavaType(), source );
 			this.mapKeyAttribute = mapKeyAttribute;
 		}
 
 		@Override
 		public MapKeySource getPathSource() {
 			return (MapKeySource) super.getPathSource();
 		}
 
 		public MapKeyAttribute<K> getAttribute() {
 			return mapKeyAttribute;
 		}
 
 		private boolean isBasicTypeKey() {
 			return Attribute.PersistentAttributeType.BASIC ==
 					mapKeyAttribute.getPersistentAttributeType();
 		}
 
 		@Override
 		protected boolean canBeDereferenced() {
 			return ! isBasicTypeKey();
 		}
 
 		@Override
 		protected Attribute locateAttributeInternal(String attributeName) {
 			if ( ! canBeDereferenced() ) {
 				throw new IllegalArgumentException(
 						"Map key [" + getPathSource().getPathIdentifier() + "] cannot be dereferenced"
 				);
 			}
 			throw new UnsupportedOperationException( "Not yet supported!" );
 		}
 
 		public Bindable<K> getModel() {
 			return mapKeyAttribute;
 		}
 
 		@Override
 		@SuppressWarnings("unchecked")
 		public <T extends K> MapKeyPath<T> treatAs(Class<T> treatAsType) {
 			// todo : if key is an entity, this is probably not enough
 			return (MapKeyPath<T>) this;
 		}
 
 		@Override
 		public String render(RenderingContext renderingContext) {
 			PathSource<?> source = getPathSource();
 			String name;
 			if ( source != null ) {
 				source.prepareAlias( renderingContext );
 				name = source.getPathIdentifier();
 			}
 			else {
 				name = getAttribute().getName();
 			}
 			return "key(" + name + ")";
 		}
 	}
 
 	/**
-	 * Defines a {@link Path} for the map which can then be used to represent the source of the
+	 * Defines a path for the map which can then be used to represent the source of the
 	 * map key "attribute".
 	 *
 	 * @param <K> The map key type
 	 * @param <V> The map value type
 	 */
 	public static class MapKeySource<K,V>
 			extends AbstractPathImpl<Map<K, V>>
 			implements PathImplementor<Map<K, V>>, Serializable {
 
 		private final MapAttribute<?,K,V> mapAttribute;
 		private final MapJoinImplementor<?,K,V> mapJoin;
 
 		public MapKeySource(
 				CriteriaBuilderImpl criteriaBuilder,
 				Class<Map<K, V>> javaType,
 				MapJoinImplementor<?,K,V> mapJoin,
 				MapAttribute<?,K,V> attribute) {
 			super( criteriaBuilder, javaType, null );
 			this.mapJoin = mapJoin;
 			this.mapAttribute = attribute;
 		}
 
 		public MapAttribute<?,K,V> getAttribute() {
 			return mapAttribute;
 		}
 
 		@SuppressWarnings({ "unchecked" })
 		public Bindable<Map<K, V>> getModel() {
 			// TODO : ok???  the attribute is in fact bindable, but its type signature is different
 			return (Bindable<Map<K, V>>) mapAttribute;
 		}
 
 		@Override
 		public PathImplementor<?> getParentPath() {
 			return (PathImplementor<?>) mapJoin.getParentPath();
 		}
 
 		@Override
 		protected boolean canBeDereferenced() {
 			return false;
 		}
 
 		@Override
 		protected Attribute locateAttributeInternal(String attributeName) {
 			throw new IllegalArgumentException( "Map [" + mapJoin.getPathIdentifier() + "] cannot be dereferenced" );
 		}
 
 		@Override
 		public <T extends Map<K, V>> PathImplementor<T> treatAs(Class<T> treatAsType) {
 			throw new UnsupportedOperationException();
 		}
 
 		@Override
 		public String getPathIdentifier() {
 			return mapJoin.getPathIdentifier();
 		}
 
 	}
 
 	/**
 	 * Disallow instantiation
 	 */
 	private MapKeyHelpers() {
 	}
 
 	/**
 	 * Defines an {@link javax.persistence.metamodel.Attribute} modelling of a map-key.
 	 *
 	 * @param <K> The type of the map key
 	 */
 	public static class MapKeyAttribute<K>
 			implements SingularAttribute<Map<K,?>,K>, Bindable<K>, Serializable {
 		private final MapAttribute<?,K,?> attribute;
 		private final CollectionPersister mapPersister;
 		private final org.hibernate.type.Type mapKeyType;
 		private final Type<K> jpaType;
 		private final BindableType jpaBindableType;
 		private final Class<K> jpaBinableJavaType;
 		private final PersistentAttributeType persistentAttributeType;
 
 		public MapKeyAttribute(CriteriaBuilderImpl criteriaBuilder, MapAttribute<?, K, ?> attribute) {
 			this.attribute = attribute;
 			this.jpaType = attribute.getKeyType();
 			this.jpaBinableJavaType = attribute.getKeyJavaType();
 			this.jpaBindableType = Type.PersistenceType
 					.ENTITY.equals( jpaType.getPersistenceType() )
 					? BindableType.ENTITY_TYPE
 					: BindableType.SINGULAR_ATTRIBUTE;
 
 			String guessedRoleName = determineRole( attribute );
 			SessionFactoryImplementor sfi = criteriaBuilder.getEntityManagerFactory().getSessionFactory();
 			mapPersister = sfi.getCollectionPersister( guessedRoleName );
 			if ( mapPersister == null ) {
 				throw new IllegalStateException( "Could not locate collection persister [" + guessedRoleName + "]" );
 			}
 			mapKeyType = mapPersister.getIndexType();
 			if ( mapKeyType == null ) {
 				throw new IllegalStateException( "Could not determine map-key type [" + guessedRoleName + "]" );
 			}
 
 			this.persistentAttributeType = mapKeyType.isEntityType()
 					? PersistentAttributeType.MANY_TO_ONE
 					: mapKeyType.isComponentType()
 							? PersistentAttributeType.EMBEDDED
 							: PersistentAttributeType.BASIC;
 		}
 
 		private String determineRole(MapAttribute<?,K,?> attribute) {
 			return attribute.getDeclaringType().getJavaType().getName() +
 					'.' + attribute.getName();
 		}
 
 		@Override
 		public String getName() {
 			// TODO : ???
 			return "map-key";
 		}
 
 		@Override
 		public PersistentAttributeType getPersistentAttributeType() {
 			return persistentAttributeType;
 		}
 
 		@Override
 		public ManagedType<Map<K, ?>> getDeclaringType() {
 			// TODO : ???
 			return null;
 		}
 
 		@Override
 		public Class<K> getJavaType() {
 			return attribute.getKeyJavaType();
 		}
 
 		@Override
 		public Member getJavaMember() {
 			// TODO : ???
 			return null;
 		}
 
 		@Override
 		public boolean isAssociation() {
 			return mapKeyType.isEntityType();
 		}
 
 		@Override
 		public boolean isCollection() {
 			return false;
 		}
 
 		@Override
 		public boolean isId() {
 			return false;
 		}
 
 		@Override
 		public boolean isVersion() {
 			return false;
 		}
 
 		@Override
 		public boolean isOptional() {
 			return false;
 		}
 
 		@Override
 		public Type<K> getType() {
 			return jpaType;
 		}
 
 		@Override
 		public BindableType getBindableType() {
 			return jpaBindableType;
 		}
 
 		@Override
 		public Class<K> getBindableJavaType() {
 			return jpaBinableJavaType;
 		}
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/predicate/BooleanExpressionPredicate.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/predicate/BooleanExpressionPredicate.java
index 58ba2d3d8d..e070fa8d68 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/predicate/BooleanExpressionPredicate.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/predicate/BooleanExpressionPredicate.java
@@ -1,68 +1,67 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.criteria.predicate;
 
 import java.io.Serializable;
 import javax.persistence.criteria.Expression;
-import javax.persistence.criteria.Predicate;
 
 import org.hibernate.jpa.criteria.CriteriaBuilderImpl;
 import org.hibernate.jpa.criteria.ParameterRegistry;
 import org.hibernate.jpa.criteria.Renderable;
 import org.hibernate.jpa.criteria.compile.RenderingContext;
 
 /**
- * Defines a {@link Predicate} used to wrap an {@link Expression Expression&lt;Boolean&gt;}.
+ * Defines a {@link javax.persistence.criteria.Predicate} used to wrap an {@link Expression Expression&lt;Boolean&gt;}.
  * 
  * @author Steve Ebersole
  */
 public class BooleanExpressionPredicate
 		extends AbstractSimplePredicate
 		implements Serializable {
 	private final Expression<Boolean> expression;
 
 	public BooleanExpressionPredicate(CriteriaBuilderImpl criteriaBuilder, Expression<Boolean> expression) {
 		super( criteriaBuilder );
 		this.expression = expression;
 	}
 
 	/**
 	 * Get the boolean expression defining the predicate.
 	 * 
 	 * @return The underlying boolean expression.
 	 */
 	public Expression<Boolean> getExpression() {
 		return expression;
 	}
 
 	@Override
 	public void registerParameters(ParameterRegistry registry) {
 		Helper.possibleParameter(expression, registry);
 	}
 
 	@Override
 	public String render(boolean isNegated, RenderingContext renderingContext) {
 		return ( (Renderable) getExpression() ).render( renderingContext );
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/predicate/InPredicate.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/predicate/InPredicate.java
index dfef1b544f..370ad563ac 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/predicate/InPredicate.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/predicate/InPredicate.java
@@ -1,213 +1,213 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.criteria.predicate;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.List;
 import javax.persistence.criteria.Expression;
 import javax.persistence.criteria.Subquery;
 
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.jpa.criteria.CriteriaBuilderImpl;
 import org.hibernate.jpa.criteria.ParameterRegistry;
 import org.hibernate.jpa.criteria.Renderable;
 import org.hibernate.jpa.criteria.ValueHandlerFactory;
 import org.hibernate.jpa.criteria.compile.RenderingContext;
 import org.hibernate.jpa.criteria.expression.LiteralExpression;
 import org.hibernate.jpa.criteria.expression.ParameterExpressionImpl;
 import org.hibernate.type.Type;
 
 /**
  * Models an <tt>[NOT] IN</tt> restriction
  *
  * @author Steve Ebersole
  */
 public class InPredicate<T>
 		extends AbstractSimplePredicate
 		implements CriteriaBuilderImpl.In<T>, Serializable {
 	private final Expression<? extends T> expression;
 	private final List<Expression<? extends T>> values;
 
 	/**
 	 * Constructs an <tt>IN</tt> predicate against a given expression with an empty list of values.
 	 *
 	 * @param criteriaBuilder The query builder from which this originates.
 	 * @param expression The expression.
 	 */
 	public InPredicate(
 			CriteriaBuilderImpl criteriaBuilder,
 			Expression<? extends T> expression) {
 		this( criteriaBuilder, expression, new ArrayList<Expression<? extends T>>() );
 	}
 
 	/**
 	 * Constructs an <tt>IN</tt> predicate against a given expression with the given list of expression values.
 	 *
 	 * @param criteriaBuilder The query builder from which this originates.
 	 * @param expression The expression.
 	 * @param values The value list.
 	 */
 	public InPredicate(
 			CriteriaBuilderImpl criteriaBuilder,
 			Expression<? extends T> expression,
 			Expression<? extends T>... values) {
 		this( criteriaBuilder, expression, Arrays.asList( values ) );
 	}
 
 	/**
 	 * Constructs an <tt>IN</tt> predicate against a given expression with the given list of expression values.
 	 *
 	 * @param criteriaBuilder The query builder from which this originates.
 	 * @param expression The expression.
 	 * @param values The value list.
 	 */
 	public InPredicate(
 			CriteriaBuilderImpl criteriaBuilder,
 			Expression<? extends T> expression,
 			List<Expression<? extends T>> values) {
 		super( criteriaBuilder );
 		this.expression = expression;
 		this.values = values;
 	}
 
 	/**
 	 * Constructs an <tt>IN</tt> predicate against a given expression with the given given literal value list.
 	 *
 	 * @param criteriaBuilder The query builder from which this originates.
 	 * @param expression The expression.
 	 * @param values The value list.
 	 */
 	public InPredicate(
 			CriteriaBuilderImpl criteriaBuilder,
 			Expression<? extends T> expression,
 			T... values) {
 		this( criteriaBuilder, expression, Arrays.asList( values ) );
 	}
 
 	/**
 	 * Constructs an <tt>IN</tt> predicate against a given expression with the given literal value list.
 	 *
 	 * @param criteriaBuilder The query builder from which this originates.
 	 * @param expression The expression.
 	 * @param values The value list.
 	 */
 	public InPredicate(
 			CriteriaBuilderImpl criteriaBuilder,
 			Expression<? extends T> expression,
 			Collection<T> values) {
 		super( criteriaBuilder );
 		this.expression = expression;
 		this.values = new ArrayList<Expression<? extends T>>( values.size() );
-        final Class<? extends T> javaType = expression.getJavaType();
-        ValueHandlerFactory.ValueHandler<? extends T> valueHandler = javaType != null && ValueHandlerFactory.isNumeric(javaType)
-            ? ValueHandlerFactory.determineAppropriateHandler((Class<? extends T>) javaType)
+		final Class<? extends T> javaType = expression.getJavaType();
+		ValueHandlerFactory.ValueHandler<? extends T> valueHandler = javaType != null && ValueHandlerFactory.isNumeric(javaType)
+				? ValueHandlerFactory.determineAppropriateHandler((Class<? extends T>) javaType)
 				: new ValueHandlerFactory.NoOpValueHandler<T>();
 		for ( T value : values ) {
 			this.values.add(
 					new LiteralExpression<T>( criteriaBuilder, valueHandler.convert( value ) )
 			);
 		}
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public Expression<T> getExpression() {
 		return ( Expression<T> ) expression;
 	}
 
 	public Expression<? extends T> getExpressionInternal() {
 		return expression;
 	}
 
 	public List<Expression<? extends T>> getValues() {
 		return values;
 	}
 
 	@Override
 	public InPredicate<T> value(T value) {
 		return value( new LiteralExpression<T>( criteriaBuilder(), value ) );
 	}
 
 	@Override
 	public InPredicate<T> value(Expression<? extends T> value) {
 		values.add( value );
 		return this;
 	}
 
 	@Override
 	public void registerParameters(ParameterRegistry registry) {
 		Helper.possibleParameter( getExpressionInternal(), registry );
 		for ( Expression value : getValues() ) {
 			Helper.possibleParameter(value, registry);
 		}
 	}
 
 	@Override
 	public String render(boolean isNegated, RenderingContext renderingContext) {
 		final StringBuilder buffer = new StringBuilder();
 		final Expression exp = getExpression();
 		if ( ParameterExpressionImpl.class.isInstance( exp ) ) {
 			// technically we only need to CAST (afaik) if expression and all values are parameters.
 			// but checking for that condition could take long time on a lon value list
 			final ParameterExpressionImpl parameterExpression = (ParameterExpressionImpl) exp;
 			final SessionFactoryImplementor sfi = criteriaBuilder().getEntityManagerFactory().unwrap( SessionFactoryImplementor.class );
 			final Type mappingType = sfi.getTypeResolver().heuristicType( parameterExpression.getParameterType().getName() );
 			buffer.append( "cast(" )
 					.append( parameterExpression.render( renderingContext ) )
 					.append( " as " )
 					.append( mappingType.getName() )
 					.append( ")" );
 		}
 		else {
 			buffer.append( ( (Renderable) getExpression() ).render( renderingContext ) );
 		}
 
 		if ( isNegated ) {
 			buffer.append( " not" );
 		}
 		buffer.append( " in " );
 
 		// subquery expressions are already wrapped in parenthesis, so we only need to
 		// render the parenthesis here if the values represent an explicit value list
 		boolean isInSubqueryPredicate = getValues().size() == 1
 				&& Subquery.class.isInstance( getValues().get( 0 ) );
 		if ( isInSubqueryPredicate ) {
 			buffer.append( ( (Renderable) getValues().get(0) ).render( renderingContext ) );
 		}
 		else {
 			buffer.append( '(' );
 			String sep = "";
 			for ( Expression value : getValues() ) {
 				buffer.append( sep )
 						.append( ( (Renderable) value ).render( renderingContext ) );
 				sep = ", ";
 			}
 			buffer.append( ')' );
 		}
 		return buffer.toString();
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/core/JpaPostUpdateEventListener.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/core/JpaPostUpdateEventListener.java
index b25f9795cb..43b08b5a6f 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/core/JpaPostUpdateEventListener.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/core/JpaPostUpdateEventListener.java
@@ -1,108 +1,105 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.event.internal.core;
 
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.Status;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.event.spi.PostCollectionRecreateEvent;
 import org.hibernate.event.spi.PostCollectionRecreateEventListener;
 import org.hibernate.event.spi.PostCollectionRemoveEvent;
 import org.hibernate.event.spi.PostCollectionRemoveEventListener;
 import org.hibernate.event.spi.PostCollectionUpdateEvent;
 import org.hibernate.event.spi.PostCollectionUpdateEventListener;
 import org.hibernate.event.spi.PostUpdateEvent;
 import org.hibernate.event.spi.PostUpdateEventListener;
 import org.hibernate.jpa.event.internal.jpa.CallbackRegistryConsumer;
 import org.hibernate.jpa.event.spi.jpa.CallbackRegistry;
 import org.hibernate.persister.entity.EntityPersister;
 
 /**
  * Implementation of the post update listeners.
  * 
  * @author <a href="mailto:kabir.khan@jboss.org">Kabir Khan</a>
  */
 @SuppressWarnings("serial")
 public class JpaPostUpdateEventListener
-		implements PostUpdateEventListener,
-				   CallbackRegistryConsumer,
-				   PostCollectionRecreateEventListener,
-				   PostCollectionRemoveEventListener,
-				   PostCollectionUpdateEventListener {
+		implements PostUpdateEventListener, CallbackRegistryConsumer, PostCollectionRecreateEventListener,
+				PostCollectionRemoveEventListener, PostCollectionUpdateEventListener {
 	private CallbackRegistry callbackRegistry;
 
 	@Override
 	public void injectCallbackRegistry(CallbackRegistry callbackRegistry) {
 		this.callbackRegistry = callbackRegistry;
 	}
 
 	public JpaPostUpdateEventListener() {
 		super();
 	}
 
 	public JpaPostUpdateEventListener(CallbackRegistry callbackRegistry) {
 		this.callbackRegistry = callbackRegistry;
 	}
 
 	@Override
 	public void onPostUpdate(PostUpdateEvent event) {
 		Object entity = event.getEntity();
 		EventSource eventSource = event.getSession();
 		handlePostUpdate(entity, eventSource);
 	}
 
 	private void handlePostUpdate(Object entity, EventSource source) {
 		EntityEntry entry = (EntityEntry) source.getPersistenceContext().getEntry( entity );
 		// mimic the preUpdate filter
 		if ( Status.DELETED != entry.getStatus()) {
 			callbackRegistry.postUpdate(entity);
 		}
 	}
 
 	@Override
 	public boolean requiresPostCommitHanding(EntityPersister persister) {
 		return callbackRegistry.hasPostUpdateCallbacks( persister.getMappedClass() );
 	}
 
 	@Override
 	public void onPostRecreateCollection(PostCollectionRecreateEvent event) {
 		Object entity = event.getCollection().getOwner();
 		EventSource eventSource = event.getSession();
 		handlePostUpdate(entity, eventSource);
 	}
 
 	@Override
 	public void onPostRemoveCollection(PostCollectionRemoveEvent event) {
 		Object entity = event.getCollection().getOwner();
 		EventSource eventSource = event.getSession();
 		handlePostUpdate(entity, eventSource);		
 	}
 
 	@Override
 	public void onPostUpdateCollection(PostCollectionUpdateEvent event) {
 		Object entity = event.getCollection().getOwner();
 		EventSource eventSource = event.getSession();
 		handlePostUpdate(entity, eventSource);		
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/jpa/LegacyCallbackProcessor.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/jpa/LegacyCallbackProcessor.java
index 7cb98f3d53..621e4dcfc3 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/jpa/LegacyCallbackProcessor.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/jpa/LegacyCallbackProcessor.java
@@ -1,244 +1,245 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.event.internal.jpa;
 
+import java.lang.annotation.Annotation;
+import java.lang.annotation.ElementType;
+import java.lang.annotation.Target;
+import java.lang.reflect.Method;
+import java.util.ArrayList;
+import java.util.List;
+import javax.persistence.Entity;
+import javax.persistence.EntityListeners;
+import javax.persistence.ExcludeDefaultListeners;
+import javax.persistence.ExcludeSuperclassListeners;
+import javax.persistence.MappedSuperclass;
+import javax.persistence.PersistenceException;
+
 import org.hibernate.MappingException;
 import org.hibernate.annotations.common.reflection.ClassLoadingException;
 import org.hibernate.annotations.common.reflection.ReflectionManager;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.annotations.common.reflection.XMethod;
 import org.hibernate.jpa.event.spi.jpa.Callback;
 import org.hibernate.jpa.event.spi.jpa.ListenerFactory;
-import org.jboss.logging.Logger;
 
-import javax.persistence.Entity;
-import javax.persistence.EntityListeners;
-import javax.persistence.ExcludeDefaultListeners;
-import javax.persistence.ExcludeSuperclassListeners;
-import javax.persistence.MappedSuperclass;
-import javax.persistence.PersistenceException;
-import java.lang.annotation.Annotation;
-import java.lang.annotation.ElementType;
-import java.lang.annotation.Target;
-import java.lang.reflect.Method;
-import java.util.ArrayList;
-import java.util.List;
+import org.jboss.logging.Logger;
 
 /**
  * @author <a href="mailto:kabir.khan@jboss.org">Kabir Khan</a>
  * @author Steve Ebersole
  */
 public class LegacyCallbackProcessor implements CallbackProcessor {
 	private static final Logger log = Logger.getLogger( LegacyCallbackProcessor.class );
 
 	private final ListenerFactory jpaListenerFactory;
 	private final ReflectionManager reflectionManager;
 
 	public LegacyCallbackProcessor(ListenerFactory jpaListenerFactory, ReflectionManager reflectionManager) {
 		this.jpaListenerFactory = jpaListenerFactory;
 		this.reflectionManager = reflectionManager;
 	}
 
 	@Override
 	public void processCallbacksForEntity(Object entityObject, CallbackRegistryImpl callbackRegistry) {
 		final String entityClassName = (String) entityObject;
 		try {
 			final XClass entityXClass = reflectionManager.classForName( entityClassName );
 			final Class entityClass = reflectionManager.toClass( entityXClass );
 			for ( Class annotationClass : CALLBACK_ANNOTATION_CLASSES ) {
 				final Callback[] callbacks = resolveCallbacks( entityXClass, annotationClass, reflectionManager );
 				callbackRegistry.addEntityCallbacks( entityClass, annotationClass, callbacks );
 			}
 		}
 		catch (ClassLoadingException e) {
 			throw new MappingException( "entity class not found: " + entityClassName, e );
 		}
 	}
 
 	public Callback[] resolveCallbacks(XClass beanClass, Class annotation, ReflectionManager reflectionManager) {
 		List<Callback> callbacks = new ArrayList<Callback>();
 		List<String> callbacksMethodNames = new ArrayList<String>(); //used to track overridden methods
 		List<Class> orderedListeners = new ArrayList<Class>();
 		XClass currentClazz = beanClass;
 		boolean stopListeners = false;
 		boolean stopDefaultListeners = false;
 		do {
 			Callback callback = null;
 			List<XMethod> methods = currentClazz.getDeclaredMethods();
-			final int size = methods.size();
-			for ( int i = 0; i < size ; i++ ) {
-				final XMethod xMethod = methods.get( i );
+			for ( final XMethod xMethod : methods ) {
 				if ( xMethod.isAnnotationPresent( annotation ) ) {
 					Method method = reflectionManager.toMethod( xMethod );
 					final String methodName = method.getName();
-					if ( ! callbacksMethodNames.contains( methodName ) ) {
+					if ( !callbacksMethodNames.contains( methodName ) ) {
 						//overridden method, remove the superclass overridden method
 						if ( callback == null ) {
 							callback = new EntityCallback( method );
 							Class returnType = method.getReturnType();
 							Class[] args = method.getParameterTypes();
 							if ( returnType != Void.TYPE || args.length != 0 ) {
 								throw new RuntimeException(
 										"Callback methods annotated on the bean class must return void and take no arguments: " + annotation
 												.getName() + " - " + xMethod
 								);
 							}
-							method.setAccessible(true);
-							log.debugf("Adding %s as %s callback for entity %s",
-									   methodName,
-									   annotation.getSimpleName(),
-									   beanClass.getName());
+							method.setAccessible( true );
+							log.debugf(
+									"Adding %s as %s callback for entity %s",
+									methodName,
+									annotation.getSimpleName(),
+									beanClass.getName()
+							);
 							callbacks.add( 0, callback ); //superclass first
 							callbacksMethodNames.add( 0, methodName );
 						}
 						else {
 							throw new PersistenceException(
 									"You can only annotate one callback method with "
 											+ annotation.getName() + " in bean class: " + beanClass.getName()
 							);
 						}
 					}
 				}
 			}
 			if ( !stopListeners ) {
 				getListeners( currentClazz, orderedListeners );
 				stopListeners = currentClazz.isAnnotationPresent( ExcludeSuperclassListeners.class );
 				stopDefaultListeners = currentClazz.isAnnotationPresent( ExcludeDefaultListeners.class );
 			}
 
 			do {
 				currentClazz = currentClazz.getSuperclass();
 			}
 			while ( currentClazz != null
-					&& ! ( currentClazz.isAnnotationPresent( Entity.class )
+					&& !( currentClazz.isAnnotationPresent( Entity.class )
 					|| currentClazz.isAnnotationPresent( MappedSuperclass.class ) )
 					);
 		}
 		while ( currentClazz != null );
 
 		//handle default listeners
-		if ( ! stopDefaultListeners ) {
+		if ( !stopDefaultListeners ) {
 			List<Class> defaultListeners = (List<Class>) reflectionManager.getDefaults().get( EntityListeners.class );
 
 			if ( defaultListeners != null ) {
 				int defaultListenerSize = defaultListeners.size();
-				for ( int i = defaultListenerSize - 1; i >= 0 ; i-- ) {
+				for ( int i = defaultListenerSize - 1; i >= 0; i-- ) {
 					orderedListeners.add( defaultListeners.get( i ) );
 				}
 			}
 		}
 
 		for ( Class listener : orderedListeners ) {
 			Callback callback = null;
 			if ( listener != null ) {
 				XClass xListener = reflectionManager.toXClass( listener );
 				callbacksMethodNames = new ArrayList<String>();
 				List<XMethod> methods = xListener.getDeclaredMethods();
-				final int size = methods.size();
-				for ( int i = 0; i < size ; i++ ) {
-					final XMethod xMethod = methods.get( i );
+				for ( final XMethod xMethod : methods ) {
 					if ( xMethod.isAnnotationPresent( annotation ) ) {
 						final Method method = reflectionManager.toMethod( xMethod );
 						final String methodName = method.getName();
-						if ( ! callbacksMethodNames.contains( methodName ) ) {
+						if ( !callbacksMethodNames.contains( methodName ) ) {
 							//overridden method, remove the superclass overridden method
 							if ( callback == null ) {
 								callback = new ListenerCallback( jpaListenerFactory.buildListener( listener ), method );
 
 								Class returnType = method.getReturnType();
 								Class[] args = method.getParameterTypes();
 								if ( returnType != Void.TYPE || args.length != 1 ) {
 									throw new PersistenceException(
 											"Callback methods annotated in a listener bean class must return void and take one argument: " + annotation
 													.getName() + " - " + method
 									);
 								}
-								if (!method.isAccessible()) {
-									method.setAccessible(true);
+								if ( !method.isAccessible() ) {
+									method.setAccessible( true );
 								}
-								log.debugf("Adding %s as %s callback for entity %s",
-										   methodName,
-										   annotation.getSimpleName(),
-										   beanClass.getName());
+								log.debugf(
+										"Adding %s as %s callback for entity %s",
+										methodName,
+										annotation.getSimpleName(),
+										beanClass.getName()
+								);
 								callbacks.add( 0, callback ); // listeners first
 							}
 							else {
 								throw new PersistenceException(
 										"You can only annotate one callback method with "
 												+ annotation.getName() + " in bean class: " + beanClass.getName() + " and callback listener: "
 												+ listener.getName()
 								);
 							}
 						}
 					}
 				}
 			}
 		}
-		return callbacks.toArray( new Callback[ callbacks.size() ] );
+		return callbacks.toArray( new Callback[callbacks.size()] );
 	}
 
 	private static boolean useAnnotationAnnotatedByListener;
 
 	static {
 		//check whether reading annotations of annotations is useful or not
 		useAnnotationAnnotatedByListener = false;
 		Target target = EntityListeners.class.getAnnotation( Target.class );
 		if ( target != null ) {
 			for ( ElementType type : target.value() ) {
 				if ( type.equals( ElementType.ANNOTATION_TYPE ) ) {
 					useAnnotationAnnotatedByListener = true;
 				}
 			}
 		}
 	}
 
 	private static void getListeners(XClass currentClazz, List<Class> orderedListeners) {
 		EntityListeners entityListeners = currentClazz.getAnnotation( EntityListeners.class );
 		if ( entityListeners != null ) {
 			Class[] classes = entityListeners.value();
 			int size = classes.length;
-			for ( int index = size - 1; index >= 0 ; index-- ) {
+			for ( int index = size - 1; index >= 0; index-- ) {
 				orderedListeners.add( classes[index] );
 			}
 		}
 		if ( useAnnotationAnnotatedByListener ) {
 			Annotation[] annotations = currentClazz.getAnnotations();
 			for ( Annotation annot : annotations ) {
 				entityListeners = annot.getClass().getAnnotation( EntityListeners.class );
 				if ( entityListeners != null ) {
 					Class[] classes = entityListeners.value();
 					int size = classes.length;
-					for ( int index = size - 1; index >= 0 ; index-- ) {
+					for ( int index = size - 1; index >= 0; index-- ) {
 						orderedListeners.add( classes[index] );
 					}
 				}
 			}
 		}
 	}
 
 	@Override
 	public void release() {
 		// nothing to do here
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/jpa/ListenerCallback.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/jpa/ListenerCallback.java
index ebabc25a42..afcf3d872a 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/jpa/ListenerCallback.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/jpa/ListenerCallback.java
@@ -1,70 +1,70 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.event.internal.jpa;
 
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Method;
 
 import org.hibernate.jpa.event.spi.jpa.Callback;
 
 /**
  * Represents a JPA callback using a dedicated listener
  *
  * @author <a href="mailto:kabir.khan@jboss.org">Kabir Khan</a>
  * @author Steve Ebersole
  */
 public class ListenerCallback implements Callback {
 	private final Method callbackMethod;
 	private final Object listenerInstance;
 
 	public ListenerCallback(Object listenerInstance, Method callbackMethod) {
 		this.listenerInstance = listenerInstance;
 		this.callbackMethod = callbackMethod;
 	}
 
 	@Override
-    public boolean performCallback(Object entity) {
+	public boolean performCallback(Object entity) {
 		try {
 			callbackMethod.invoke( listenerInstance, entity );
 			return true;
 		}
 		catch (InvocationTargetException e) {
 			//keep runtime exceptions as is
 			if ( e.getTargetException() instanceof RuntimeException ) {
 				throw (RuntimeException) e.getTargetException();
 			}
 			else {
 				throw new RuntimeException( e.getTargetException() );
 			}
 		}
 		catch (Exception e) {
 			throw new RuntimeException( e );
 		}
 	}
 
 	@Override
 	public boolean isActive() {
 		return true;
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/spi/JpaIntegrator.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/spi/JpaIntegrator.java
index 4a6036526f..e46be0d3eb 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/spi/JpaIntegrator.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/spi/JpaIntegrator.java
@@ -1,246 +1,253 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.event.spi;
 
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Method;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.annotations.common.reflection.ReflectionManager;
 import org.hibernate.boot.Metadata;
 import org.hibernate.boot.internal.MetadataImpl;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.engine.config.spi.ConfigurationService;
 import org.hibernate.engine.spi.CascadeStyles;
 import org.hibernate.engine.spi.CascadingAction;
 import org.hibernate.engine.spi.CascadingActions;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.event.service.spi.DuplicationStrategy;
 import org.hibernate.event.service.spi.EventListenerGroup;
 import org.hibernate.event.service.spi.EventListenerRegistry;
 import org.hibernate.event.spi.EventType;
 import org.hibernate.integrator.spi.Integrator;
 import org.hibernate.jpa.AvailableSettings;
 import org.hibernate.jpa.event.internal.core.HibernateEntityManagerEventListener;
 import org.hibernate.jpa.event.internal.core.JpaAutoFlushEventListener;
 import org.hibernate.jpa.event.internal.core.JpaDeleteEventListener;
 import org.hibernate.jpa.event.internal.core.JpaFlushEntityEventListener;
 import org.hibernate.jpa.event.internal.core.JpaFlushEventListener;
 import org.hibernate.jpa.event.internal.core.JpaMergeEventListener;
 import org.hibernate.jpa.event.internal.core.JpaPersistEventListener;
 import org.hibernate.jpa.event.internal.core.JpaPersistOnFlushEventListener;
 import org.hibernate.jpa.event.internal.core.JpaPostDeleteEventListener;
 import org.hibernate.jpa.event.internal.core.JpaPostInsertEventListener;
 import org.hibernate.jpa.event.internal.core.JpaPostLoadEventListener;
 import org.hibernate.jpa.event.internal.core.JpaPostUpdateEventListener;
 import org.hibernate.jpa.event.internal.core.JpaSaveEventListener;
 import org.hibernate.jpa.event.internal.core.JpaSaveOrUpdateEventListener;
 import org.hibernate.jpa.event.internal.jpa.CallbackProcessor;
 import org.hibernate.jpa.event.internal.jpa.CallbackRegistryConsumer;
 import org.hibernate.jpa.event.internal.jpa.CallbackRegistryImpl;
 import org.hibernate.jpa.event.internal.jpa.LegacyCallbackProcessor;
 import org.hibernate.jpa.event.internal.jpa.StandardListenerFactory;
 import org.hibernate.jpa.event.spi.jpa.ListenerFactory;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.spi.SessionFactoryServiceRegistry;
 
 /**
  * Hibernate EntityManager specific Integrator, performing JPA setup.
  *
  * @author Steve Ebersole
  */
 public class JpaIntegrator implements Integrator {
 	private ListenerFactory jpaListenerFactory;
 	private CallbackProcessor callbackProcessor;
 	private CallbackRegistryImpl callbackRegistry;
 
 	private static final DuplicationStrategy JPA_DUPLICATION_STRATEGY = new JPADuplicationStrategy();
 
 	/**
 	 * Perform integration.
 	 *
 	 * @param metadata The "compiled" representation of the mapping information
 	 * @param sessionFactory The session factory being created
 	 * @param serviceRegistry The session factory's service registry
 	 */
 	public void integrate(
 			Metadata metadata,
 			SessionFactoryImplementor sessionFactory,
 			SessionFactoryServiceRegistry serviceRegistry) {
 
 		// first, register the JPA-specific persist cascade style
 		CascadeStyles.registerCascadeStyle(
 				"persist",
-                new PersistCascadeStyle()
+				new PersistCascadeStyle()
 		);
 
 
 		// then prepare listeners
 		final EventListenerRegistry eventListenerRegistry = serviceRegistry.getService( EventListenerRegistry.class );
 
 		eventListenerRegistry.addDuplicationStrategy( JPA_DUPLICATION_STRATEGY );
 
 		// op listeners
 		eventListenerRegistry.setListeners( EventType.AUTO_FLUSH, JpaAutoFlushEventListener.INSTANCE );
 		eventListenerRegistry.setListeners( EventType.DELETE, new JpaDeleteEventListener() );
 		eventListenerRegistry.setListeners( EventType.FLUSH_ENTITY, new JpaFlushEntityEventListener() );
 		eventListenerRegistry.setListeners( EventType.FLUSH, JpaFlushEventListener.INSTANCE );
 		eventListenerRegistry.setListeners( EventType.MERGE, new JpaMergeEventListener() );
 		eventListenerRegistry.setListeners( EventType.PERSIST, new JpaPersistEventListener() );
 		eventListenerRegistry.setListeners( EventType.PERSIST_ONFLUSH, new JpaPersistOnFlushEventListener() );
 		eventListenerRegistry.setListeners( EventType.SAVE, new JpaSaveEventListener() );
 		eventListenerRegistry.setListeners( EventType.SAVE_UPDATE, new JpaSaveOrUpdateEventListener() );
 
 		// post op listeners
 		eventListenerRegistry.prependListeners( EventType.POST_DELETE, new JpaPostDeleteEventListener() );
 		eventListenerRegistry.prependListeners( EventType.POST_INSERT, new JpaPostInsertEventListener() );
 		eventListenerRegistry.prependListeners( EventType.POST_LOAD, new JpaPostLoadEventListener() );
 		eventListenerRegistry.prependListeners( EventType.POST_UPDATE, new JpaPostUpdateEventListener() );
 
 		final ConfigurationService cfgService = serviceRegistry.getService( ConfigurationService.class );
 
-		for ( Map.Entry entry : ( (Map<?,?>) cfgService.getSettings() ).entrySet() ) {
-			if ( ! String.class.isInstance( entry.getKey() ) ) {
+		for ( Map.Entry entry : ( (Map<?, ?>) cfgService.getSettings() ).entrySet() ) {
+			if ( !String.class.isInstance( entry.getKey() ) ) {
 				continue;
 			}
 			final String propertyName = (String) entry.getKey();
-			if ( ! propertyName.startsWith( AvailableSettings.EVENT_LISTENER_PREFIX ) ) {
+			if ( !propertyName.startsWith( AvailableSettings.EVENT_LISTENER_PREFIX ) ) {
 				continue;
 			}
 			final String eventTypeName = propertyName.substring( AvailableSettings.EVENT_LISTENER_PREFIX.length() + 1 );
 			final EventType eventType = EventType.resolveEventTypeByName( eventTypeName );
 			final EventListenerGroup eventListenerGroup = eventListenerRegistry.getEventListenerGroup( eventType );
 			for ( String listenerImpl : ( (String) entry.getValue() ).split( " ," ) ) {
 				eventListenerGroup.appendListener( instantiate( listenerImpl, serviceRegistry ) );
 			}
 		}
 
 		// handle JPA "entity listener classes"...
-		final ReflectionManager reflectionManager = ( (MetadataImpl) metadata ).getMetadataBuildingOptions().getReflectionManager();
+		final ReflectionManager reflectionManager = ( (MetadataImpl) metadata ).getMetadataBuildingOptions()
+				.getReflectionManager();
 
 		this.callbackRegistry = new CallbackRegistryImpl();
 		final Object beanManagerRef = sessionFactory.getSessionFactoryOptions().getBeanManagerReference();
 		this.jpaListenerFactory = beanManagerRef == null
 				? new StandardListenerFactory()
 				: buildBeanManagerListenerFactory( beanManagerRef );
 		this.callbackProcessor = new LegacyCallbackProcessor( jpaListenerFactory, reflectionManager );
 
 		for ( PersistentClass persistentClass : metadata.getEntityBindings() ) {
 			if ( persistentClass.getClassName() == null ) {
 				// we can have non java class persisted by hibernate
 				continue;
 			}
 			callbackProcessor.processCallbacksForEntity( persistentClass.getClassName(), callbackRegistry );
 		}
 
 		for ( EventType eventType : EventType.values() ) {
 			final EventListenerGroup eventListenerGroup = eventListenerRegistry.getEventListenerGroup( eventType );
 			for ( Object listener : eventListenerGroup.listeners() ) {
 				if ( CallbackRegistryConsumer.class.isInstance( listener ) ) {
 					( (CallbackRegistryConsumer) listener ).injectCallbackRegistry( callbackRegistry );
 				}
 			}
 		}
 	}
 
 	private static final String CDI_LISTENER_FACTORY_CLASS = "org.hibernate.jpa.event.internal.jpa.BeanManagerListenerFactory";
 
 	private ListenerFactory buildBeanManagerListenerFactory(Object beanManagerRef) {
 		try {
 			// specifically using our classloader here...
 			final Class beanManagerListenerFactoryClass = getClass().getClassLoader()
 					.loadClass( CDI_LISTENER_FACTORY_CLASS );
 			final Method beanManagerListenerFactoryBuilderMethod = beanManagerListenerFactoryClass.getMethod(
 					"fromBeanManagerReference",
 					Object.class
 			);
 
 			try {
 				return (ListenerFactory) beanManagerListenerFactoryBuilderMethod.invoke( null, beanManagerRef );
 			}
 			catch (InvocationTargetException e) {
 				throw e.getTargetException();
 			}
 		}
 		catch (ClassNotFoundException e) {
-			throw new HibernateException( "Could not locate BeanManagerListenerFactory class to handle CDI extensions", e );
+			throw new HibernateException(
+					"Could not locate BeanManagerListenerFactory class to handle CDI extensions",
+					e
+			);
 		}
 		catch (HibernateException e) {
 			throw e;
 		}
 		catch (Throwable e) {
-			throw new HibernateException( "Could not access BeanManagerListenerFactory class to handle CDI extensions", e );
+			throw new HibernateException(
+					"Could not access BeanManagerListenerFactory class to handle CDI extensions",
+					e
+			);
 		}
 	}
 
 	@Override
 	public void disintegrate(SessionFactoryImplementor sessionFactory, SessionFactoryServiceRegistry serviceRegistry) {
 		if ( callbackRegistry != null ) {
 			callbackRegistry.release();
 		}
 		if ( callbackProcessor != null ) {
 			callbackProcessor.release();
 		}
 		if ( jpaListenerFactory != null ) {
 			jpaListenerFactory.release();
 		}
 	}
 
 	private Object instantiate(String listenerImpl, ServiceRegistryImplementor serviceRegistry) {
 		try {
 			return serviceRegistry.getService( ClassLoaderService.class ).classForName( listenerImpl ).newInstance();
 		}
 		catch (Exception e) {
 			throw new HibernateException( "Could not instantiate requested listener [" + listenerImpl + "]", e );
-        }
-    }
-
-    private static class PersistCascadeStyle extends CascadeStyles.BaseCascadeStyle {
-        @Override
-        public boolean doCascade(CascadingAction action) {
-            return action == JpaPersistEventListener.PERSIST_SKIPLAZY
-                    || action == CascadingActions.PERSIST_ON_FLUSH;
-        }
-
-        @Override
-        public String toString() {
-            return "STYLE_PERSIST_SKIPLAZY";
-        }
-    }
-
-    private static class JPADuplicationStrategy implements DuplicationStrategy {
-        @Override
-        public boolean areMatch(Object listener, Object original) {
-            return listener.getClass().equals( original.getClass() ) &&
-                    HibernateEntityManagerEventListener.class.isInstance( original );
-        }
-
-        @Override
-        public Action getAction() {
-            return Action.KEEP_ORIGINAL;
-        }
-    }
+		}
+	}
+
+	private static class PersistCascadeStyle extends CascadeStyles.BaseCascadeStyle {
+		@Override
+		public boolean doCascade(CascadingAction action) {
+			return action == JpaPersistEventListener.PERSIST_SKIPLAZY
+					|| action == CascadingActions.PERSIST_ON_FLUSH;
+		}
+
+		@Override
+		public String toString() {
+			return "STYLE_PERSIST_SKIPLAZY";
+		}
+	}
+
+	private static class JPADuplicationStrategy implements DuplicationStrategy {
+		@Override
+		public boolean areMatch(Object listener, Object original) {
+			return listener.getClass().equals( original.getClass() ) &&
+					HibernateEntityManagerEventListener.class.isInstance( original );
+		}
+
+		@Override
+		public Action getAction() {
+			return Action.KEEP_ORIGINAL;
+		}
+	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/graph/internal/EntityGraphImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/graph/internal/EntityGraphImpl.java
index 7de1737e0d..ce07b24b20 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/graph/internal/EntityGraphImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/graph/internal/EntityGraphImpl.java
@@ -1,172 +1,172 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.graph.internal;
 
 import java.util.List;
 import javax.persistence.AttributeNode;
 import javax.persistence.EntityGraph;
 import javax.persistence.Subgraph;
 import javax.persistence.metamodel.Attribute;
 import javax.persistence.metamodel.EntityType;
 import javax.persistence.metamodel.IdentifiableType;
 
 import org.hibernate.cfg.NotYetImplementedException;
 import org.hibernate.graph.spi.GraphNodeImplementor;
 import org.hibernate.jpa.internal.EntityManagerFactoryImpl;
 
 /**
  * The Hibernate implementation of the JPA EntityGraph contract.
  *
  * @author Steve Ebersole
  */
 public class EntityGraphImpl<T> extends AbstractGraphNode<T> implements EntityGraph<T>, GraphNodeImplementor {
 	private final String name;
 	private final EntityType<T> entityType;
 
 	public EntityGraphImpl(String name, EntityType<T> entityType, EntityManagerFactoryImpl entityManagerFactory) {
 		super( entityManagerFactory, true );
 		this.name = name;
 		this.entityType = entityType;
 	}
 
 	public EntityGraphImpl<T> makeImmutableCopy(String name) {
 		return new EntityGraphImpl<T>( name, this, false );
 	}
 
 	public EntityGraphImpl<T> makeMutableCopy() {
 		return new EntityGraphImpl<T>( name, this, true );
 	}
 
 	private EntityGraphImpl(String name, EntityGraphImpl<T> original, boolean mutable) {
 		super( original, mutable );
 		this.name = name;
 		this.entityType = original.entityType;
 	}
 
 	public EntityType<T> getEntityType() {
 		return entityType;
 	}
 
 	@Override
 	public String getName() {
 		return name;
 	}
 
 	@Override
 	public void addAttributeNodes(String... attributeNames) {
 		super.addAttributeNodes( attributeNames );
 	}
 
 	@Override
 	public void addAttributeNodes(Attribute<T, ?>... attributes) {
 		super.addAttributeNodes( attributes );
 	}
 
 	@Override
 	public <X> SubgraphImpl<X> addSubgraph(Attribute<T, X> attribute) {
 		return super.addSubgraph( attribute );
 	}
 
 	@Override
 	public <X> SubgraphImpl<? extends X> addSubgraph(Attribute<T, X> attribute, Class<? extends X> type) {
 		return super.addSubgraph( attribute, type );
 	}
 
 	@Override
 	public <X> SubgraphImpl<X> addSubgraph(String attributeName) {
 		return super.addSubgraph( attributeName );
 	}
 
 	@Override
 	public <X> SubgraphImpl<X> addSubgraph(String attributeName, Class<X> type) {
 		return super.addSubgraph( attributeName, type );
 	}
 
 	@Override
 	public <X> SubgraphImpl<X> addKeySubgraph(Attribute<T, X> attribute) {
 		return super.addKeySubgraph( attribute );
 	}
 
 	@Override
 	public <X> SubgraphImpl<? extends X> addKeySubgraph(Attribute<T, X> attribute, Class<? extends X> type) {
 		return super.addKeySubgraph( attribute, type );
 	}
 
 	@Override
 	public <X> SubgraphImpl<X> addKeySubgraph(String attributeName) {
 		return super.addKeySubgraph( attributeName );
 	}
 
 	@Override
 	public <X> SubgraphImpl<X> addKeySubgraph(String attributeName, Class<X> type) {
 		return super.addKeySubgraph( attributeName, type );
 	}
 
 	@Override
 	public <T1 extends Object> Subgraph<? extends T1> addSubclassSubgraph(Class<? extends T1> type) {
 		// todo : implement
 		throw new NotYetImplementedException();
 	}
 
 	@Override
 	public List<AttributeNode<?>> getAttributeNodes() {
 		return super.attributeNodes();
 	}
 
 	@Override
 	protected Attribute<T,?> resolveAttribute(String attributeName) {
-        final Attribute attribute = entityType.getAttribute( attributeName );
+		final Attribute attribute = entityType.getAttribute( attributeName );
 		if ( attribute == null ) {
 			throw new IllegalArgumentException(
 					String.format(
 							"Given attribute name [%s] is not an attribute on this entity [%s]",
 							attributeName,
 							entityType.getName()
 					)
 			);
 		}
 		return attribute;
 	}
 
 	@SuppressWarnings("unchecked")
 	public boolean appliesTo(String entityName) {
 		return appliesTo( getFactory().getEntityTypeByName( entityName ) );
 	}
 
 	public boolean appliesTo(EntityType<? super T> entityType) {
 		if ( this.entityType.equals( entityType ) ) {
 			return true;
 		}
 
 		IdentifiableType superType = entityType.getSupertype();
 		while ( superType != null ) {
 			if ( superType.equals( entityType ) ) {
 				return true;
 			}
 			superType = superType.getSupertype();
 		}
 
 		return false;
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/EntityManagerImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/EntityManagerImpl.java
index 734cfa6da9..61ea58e245 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/EntityManagerImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/EntityManagerImpl.java
@@ -1,285 +1,286 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009, 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.internal;
 
 import java.util.List;
 import java.util.Map;
 import javax.persistence.EntityGraph;
 import javax.persistence.PersistenceContextType;
 import javax.persistence.PersistenceException;
 import javax.persistence.SynchronizationType;
 import javax.persistence.spi.PersistenceUnitTransactionType;
 import javax.transaction.SystemException;
 
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.Session;
 import org.hibernate.annotations.common.util.ReflectHelper;
 import org.hibernate.ejb.AbstractEntityManagerImpl;
 import org.hibernate.engine.spi.SessionBuilderImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.SessionOwner;
 import org.hibernate.internal.SessionImpl;
 import org.hibernate.jpa.AvailableSettings;
 import org.hibernate.jpa.graph.internal.EntityGraphImpl;
 import org.hibernate.resource.transaction.backend.jta.internal.synchronization.AfterCompletionAction;
 import org.hibernate.resource.transaction.backend.jta.internal.synchronization.ExceptionMapper;
 import org.hibernate.resource.transaction.backend.jta.internal.synchronization.ManagedFlushChecker;
 
+import static org.hibernate.jpa.internal.HEMLogging.messageLogger;
+
 /**
  * Hibernate implementation of {@link javax.persistence.EntityManager}.
  *
  * @author Gavin King
  */
 public class EntityManagerImpl extends AbstractEntityManagerImpl implements SessionOwner {
-
-    public static final EntityManagerMessageLogger LOG = HEMLogging.messageLogger( EntityManagerImpl.class.getName() );
+	public static final EntityManagerMessageLogger LOG = messageLogger( EntityManagerImpl.class.getName() );
 
 	protected Session session;
 	protected boolean open;
 	protected boolean discardOnClose;
 	private Class sessionInterceptorClass;
 
 	public EntityManagerImpl(
 			EntityManagerFactoryImpl entityManagerFactory,
 			PersistenceContextType pcType,
 			SynchronizationType synchronizationType,
 			PersistenceUnitTransactionType transactionType,
 			boolean discardOnClose,
 			Class sessionInterceptorClass,
 			Map properties) {
 		super( entityManagerFactory, pcType, synchronizationType, transactionType, properties );
 		this.open = true;
 		this.discardOnClose = discardOnClose;
 		Object localSessionInterceptor = null;
 		if (properties != null) {
 			localSessionInterceptor = properties.get( AvailableSettings.SESSION_INTERCEPTOR );
 		}
 		if ( localSessionInterceptor != null ) {
 			if (localSessionInterceptor instanceof Class) {
 				sessionInterceptorClass = (Class) localSessionInterceptor;
 			}
 			else if (localSessionInterceptor instanceof String) {
 				try {
 					sessionInterceptorClass =
 							ReflectHelper.classForName( (String) localSessionInterceptor, EntityManagerImpl.class );
 				}
 				catch (ClassNotFoundException e) {
 					throw new PersistenceException("Unable to instanciate interceptor: " + localSessionInterceptor, e);
 				}
 			}
 			else {
 				throw new PersistenceException("Unable to instanciate interceptor: " + localSessionInterceptor);
 			}
 		}
 		this.sessionInterceptorClass = sessionInterceptorClass;
 		postInit();
 	}
 
 	@Override
 	protected void checkOpen() {
 		checkOpen( true );
 	}
 
 	@Override
 	public void checkOpen(boolean markForRollbackIfClosed) {
 		if( ! isOpen() ) {
 			if ( markForRollbackIfClosed ) {
 				markForRollbackOnly();
 			}
 			throw new IllegalStateException( "EntityManager is closed" );
 		}
 	}
 
 	@Override
-    public Session getSession() {
+	public Session getSession() {
 		checkOpen();
 		return internalGetSession();
 	}
 
 	@Override
-    protected Session getRawSession() {
+	protected Session getRawSession() {
 		return internalGetSession();
 	}
 
 	@Override
 	protected Session internalGetSession() {
 		if ( session == null ) {
 			SessionBuilderImplementor sessionBuilder = internalGetEntityManagerFactory().getSessionFactory().withOptions();
 			sessionBuilder.owner( this );
 			if (sessionInterceptorClass != null) {
 				try {
 					Interceptor interceptor = (Interceptor) sessionInterceptorClass.newInstance();
 					sessionBuilder.interceptor( interceptor );
 				}
 				catch (InstantiationException e) {
 					throw new PersistenceException("Unable to instantiate session interceptor: " + sessionInterceptorClass, e);
 				}
 				catch (IllegalAccessException e) {
 					throw new PersistenceException("Unable to instantiate session interceptor: " + sessionInterceptorClass, e);
 				}
 				catch (ClassCastException e) {
 					throw new PersistenceException("Session interceptor does not implement Interceptor: " + sessionInterceptorClass, e);
 				}
 			}
 			sessionBuilder.autoJoinTransactions( getTransactionType() != PersistenceUnitTransactionType.JTA );
 			session = sessionBuilder.openSession();
 		}
 		return session;
 	}
 
 	public void close() {
 		checkEntityManagerFactory();
 		checkOpen();
 
 		if ( discardOnClose || !isTransactionInProgress() ) {
 			//close right now
 			if ( session != null ) {
 				session.close();
 			}
 		}
 		// Otherwise, session auto-close will be enabled by shouldAutoCloseSession().
 		open = false;
 	}
 
 	public boolean isOpen() {
 		//adjustFlushMode(); //don't adjust, can't be done on closed EM
 		checkEntityManagerFactory();
 		try {
 			if ( open ) {
 				internalGetSession().isOpen(); //to force enlistment in tx
 			}
 			return open;
 		}
 		catch (HibernateException he) {
 			throwPersistenceException( he );
 			return false;
 		}
 	}
 
 	@Override
 	public <T> EntityGraph<T> createEntityGraph(Class<T> rootType) {
 		checkOpen();
 		return new EntityGraphImpl<T>( null, getMetamodel().entity( rootType ), getEntityManagerFactory() );
 	}
 
 	@Override
 	public EntityGraph<?> createEntityGraph(String graphName) {
 		checkOpen();
 		final EntityGraphImpl named = getEntityManagerFactory().findEntityGraphByName( graphName );
 		if ( named == null ) {
 			return null;
 		}
 		return named.makeMutableCopy();
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public EntityGraph<?> getEntityGraph(String graphName) {
 		checkOpen();
 		final EntityGraphImpl named = getEntityManagerFactory().findEntityGraphByName( graphName );
 		if ( named == null ) {
 			throw new IllegalArgumentException( "Could not locate EntityGraph with given name : " + graphName );
 		}
 		return named;
 	}
 
 	@Override
 	public <T> List<EntityGraph<? super T>> getEntityGraphs(Class<T> entityClass) {
 		checkOpen();
 		return getEntityManagerFactory().findEntityGraphsByType( entityClass );
 	}
 
 	@Override
 	public boolean shouldAutoCloseSession() {
 		return !isOpen();
 	}
 
 	@Override
 	public ExceptionMapper getExceptionMapper() {
 		return new CallbackExceptionMapperImpl();
 	}
 
 	@Override
 	public AfterCompletionAction getAfterCompletionAction() {
 		return new AfterCompletionActionImpl();
 	}
 
 	@Override
 	public ManagedFlushChecker getManagedFlushChecker() {
 		return new ManagedFlushCheckerImpl();
 	}
 
 	private void checkEntityManagerFactory() {
 		if ( ! internalGetEntityManagerFactory().isOpen() ) {
 			open = false;
 		}
 	}
 
 	private class CallbackExceptionMapperImpl implements ExceptionMapper {
 		@Override
 		public RuntimeException mapStatusCheckFailure(String message, SystemException systemException) {
 			throw new PersistenceException( message, systemException );
 		}
 
 		@Override
 		public RuntimeException mapManagedFlushFailure(String message, RuntimeException failure) {
 			if ( HibernateException.class.isInstance( failure ) ) {
 				throw convert( failure );
 			}
 			if ( PersistenceException.class.isInstance( failure ) ) {
 				throw failure;
 			}
 			throw new PersistenceException( message, failure );
 		}
 	}
 
 	private class AfterCompletionActionImpl implements AfterCompletionAction {
 
 		@Override
 		public void doAction( boolean successful) {
 			if ( ((SessionImplementor)EntityManagerImpl.this.session).isClosed()) {
 				LOG.trace( "Session was closed; nothing to do" );
 				return;
 			}
 
 			if ( !successful && EntityManagerImpl.this.getTransactionType() == PersistenceUnitTransactionType.JTA ) {
 				((Session) session).clear();
 			}
 		}
 	}
 
 	private class ManagedFlushCheckerImpl implements ManagedFlushChecker {
 		@Override
 		public boolean shouldDoManagedFlush(SessionImpl session) {
 			return !session.isClosed()
 					&& !isManualFlushMode( session.getFlushMode() );
 		}
 	}
 
 	private boolean isManualFlushMode(FlushMode mode){
 		return FlushMode.MANUAL == mode;
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/EntityManagerMessageLogger.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/EntityManagerMessageLogger.java
index 07399e245f..6f2a01dc6b 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/EntityManagerMessageLogger.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/EntityManagerMessageLogger.java
@@ -1,134 +1,139 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.internal;
 
 import java.net.URISyntaxException;
 import java.net.URL;
 
 import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.annotations.Cause;
 import org.jboss.logging.annotations.LogMessage;
 import org.jboss.logging.annotations.Message;
 import org.jboss.logging.annotations.MessageLogger;
 
 import static org.jboss.logging.Logger.Level.DEBUG;
 import static org.jboss.logging.Logger.Level.ERROR;
 import static org.jboss.logging.Logger.Level.INFO;
 import static org.jboss.logging.Logger.Level.WARN;
 
 /**
  * The jboss-logging {@link MessageLogger} for the hibernate-entitymanager module.  It reserves message ids ranging from
  * 15001 to 20000 inclusively.
  * <p/>
  * New messages must be added after the last message defined to ensure message codes are unique.
  */
-@MessageLogger( projectCode = "HHH" )
+@MessageLogger(projectCode = "HHH")
 public interface EntityManagerMessageLogger extends CoreMessageLogger {
 
-    @LogMessage( level = INFO )
-    @Message( value = "Bound Ejb3Configuration to JNDI name: %s", id = 15001 )
-    void boundEjb3ConfigurationToJndiName( String name );
-
-    @LogMessage( level = INFO )
-    @Message( value = "Ejb3Configuration name: %s", id = 15002 )
-    void ejb3ConfigurationName( String name );
-
-    @LogMessage( level = INFO )
-    @Message( value = "An Ejb3Configuration was renamed from name: %s", id = 15003 )
-    void ejb3ConfigurationRenamedFromName( String name );
-
-    @LogMessage( level = INFO )
-    @Message( value = "An Ejb3Configuration was unbound from name: %s", id = 15004 )
-    void ejb3ConfigurationUnboundFromName( String name );
-
-    @LogMessage( level = WARN )
-    @Message( value = "Exploded jar file does not exist (ignored): %s", id = 15005 )
-    void explodedJarDoesNotExist( URL jarUrl );
-
-    @LogMessage( level = WARN )
-    @Message( value = "Exploded jar file not a directory (ignored): %s", id = 15006 )
-    void explodedJarNotDirectory( URL jarUrl );
-
-    @LogMessage( level = ERROR )
-    @Message( value = "Illegal argument on static metamodel field injection : %s#%s; expected type :  %s; encountered type : %s", id = 15007 )
-    void illegalArgumentOnStaticMetamodelFieldInjection( String name,
-                                                         String name2,
-                                                         String name3,
-                                                         String name4 );
-
-    @LogMessage( level = ERROR )
-    @Message( value = "Malformed URL: %s", id = 15008 )
-    void malformedUrl( URL jarUrl,
-                       @Cause URISyntaxException e );
-
-    @LogMessage( level = WARN )
-    @Message( value = "Malformed URL: %s", id = 15009 )
-    void malformedUrlWarning( URL jarUrl,
-                              @Cause URISyntaxException e );
-
-    @LogMessage( level = WARN )
-    @Message( value = "Unable to find file (ignored): %s", id = 15010 )
-    void unableToFindFile( URL jarUrl,
-                           @Cause Exception e );
-
-    @LogMessage( level = ERROR )
-    @Message( value = "Unable to locate static metamodel field : %s#%s", id = 15011 )
-    void unableToLocateStaticMetamodelField( String name,
-                                             String name2 );
-
-    @LogMessage( level = INFO )
-    @Message( value = "Using provided datasource", id = 15012 )
-    void usingProvidedDataSource();
-
-
-    @LogMessage( level = DEBUG )
-    @Message( value = "Returning null (as required by JPA spec) rather than throwing EntityNotFoundException, " +
-            "as the entity (type=%s, id=%s) does not exist", id = 15013 )
-    void ignoringEntityNotFound( String entityName, String identifier);
-
-	@LogMessage( level = WARN )
+	@LogMessage(level = INFO)
+	@Message(value = "Bound Ejb3Configuration to JNDI name: %s", id = 15001)
+	void boundEjb3ConfigurationToJndiName(String name);
+
+	@LogMessage(level = INFO)
+	@Message(value = "Ejb3Configuration name: %s", id = 15002)
+	void ejb3ConfigurationName(String name);
+
+	@LogMessage(level = INFO)
+	@Message(value = "An Ejb3Configuration was renamed from name: %s", id = 15003)
+	void ejb3ConfigurationRenamedFromName(String name);
+
+	@LogMessage(level = INFO)
+	@Message(value = "An Ejb3Configuration was unbound from name: %s", id = 15004)
+	void ejb3ConfigurationUnboundFromName(String name);
+
+	@LogMessage(level = WARN)
+	@Message(value = "Exploded jar file does not exist (ignored): %s", id = 15005)
+	void explodedJarDoesNotExist(URL jarUrl);
+
+	@LogMessage(level = WARN)
+	@Message(value = "Exploded jar file not a directory (ignored): %s", id = 15006)
+	void explodedJarNotDirectory(URL jarUrl);
+
+	@LogMessage(level = ERROR)
+	@Message(value = "Illegal argument on static metamodel field injection : %s#%s; expected type :  %s; encountered type : %s", id = 15007)
+	void illegalArgumentOnStaticMetamodelFieldInjection(
+			String name,
+			String name2,
+			String name3,
+			String name4);
+
+	@LogMessage(level = ERROR)
+	@Message(value = "Malformed URL: %s", id = 15008)
+	void malformedUrl(
+			URL jarUrl,
+			@Cause URISyntaxException e);
+
+	@LogMessage(level = WARN)
+	@Message(value = "Malformed URL: %s", id = 15009)
+	void malformedUrlWarning(
+			URL jarUrl,
+			@Cause URISyntaxException e);
+
+	@LogMessage(level = WARN)
+	@Message(value = "Unable to find file (ignored): %s", id = 15010)
+	void unableToFindFile(
+			URL jarUrl,
+			@Cause Exception e);
+
+	@LogMessage(level = ERROR)
+	@Message(value = "Unable to locate static metamodel field : %s#%s", id = 15011)
+	void unableToLocateStaticMetamodelField(
+			String name,
+			String name2);
+
+	@LogMessage(level = INFO)
+	@Message(value = "Using provided datasource", id = 15012)
+	void usingProvidedDataSource();
+
+
+	@LogMessage(level = DEBUG)
+	@Message(value = "Returning null (as required by JPA spec) rather than throwing EntityNotFoundException, " +
+			"as the entity (type=%s, id=%s) does not exist", id = 15013)
+	void ignoringEntityNotFound(String entityName, String identifier);
+
+	@LogMessage(level = WARN)
 	@Message(
 			value = "DEPRECATION - attempt to refer to JPA positional parameter [?%1$s] using String name [\"%1$s\"] " +
 					"rather than int position [%1$s] (generally in Query#setParameter, Query#getParameter or " +
 					"Query#getParameterValue calls).  Hibernate previously allowed such usage, but it is considered " +
 					"deprecated.",
 			id = 15014
 	)
 	void deprecatedJpaPositionalParameterAccess(Integer jpaPositionalParameter);
 
-	@LogMessage( level = INFO )
+	@LogMessage(level = INFO)
 	@Message(
 			id = 15015,
 			value = "Encountered a MappedSuperclass [%s] not used in any entity hierarchy"
 	)
 	void unusedMappedSuperclass(String name);
 
-	@LogMessage( level = WARN )
+	@LogMessage(level = WARN)
 	@Message(
 			id = 15016,
 			value = "Encountered a deprecated javax.persistence.spi.PersistenceProvider [%s]; use [%s] instead."
 	)
 	void deprecatedPersistenceProvider(String deprecated, String replacement);
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/QueryImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/QueryImpl.java
index 4ad57895cd..3aece339c3 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/QueryImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/QueryImpl.java
@@ -1,583 +1,587 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.internal;
 
 import java.util.Calendar;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.Date;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import javax.persistence.NoResultException;
 import javax.persistence.NonUniqueResultException;
 import javax.persistence.ParameterMode;
 import javax.persistence.PersistenceException;
 import javax.persistence.Query;
 import javax.persistence.TemporalType;
 import javax.persistence.TypedQuery;
 
 import org.hibernate.CacheMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.SQLQuery;
 import org.hibernate.TypeMismatchException;
 import org.hibernate.engine.query.spi.HQLQueryPlan;
 import org.hibernate.engine.query.spi.NamedParameterDescriptor;
 import org.hibernate.engine.query.spi.OrdinalParameterDescriptor;
 import org.hibernate.engine.query.spi.ParameterMetadata;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.hql.internal.QueryExecutionRequestException;
 import org.hibernate.internal.SQLQueryImpl;
 import org.hibernate.jpa.AvailableSettings;
 import org.hibernate.jpa.HibernateQuery;
 import org.hibernate.jpa.internal.util.ConfigurationHelper;
 import org.hibernate.jpa.internal.util.LockModeTypeHelper;
 import org.hibernate.jpa.spi.AbstractEntityManagerImpl;
 import org.hibernate.jpa.spi.AbstractQueryImpl;
 import org.hibernate.jpa.spi.ParameterBind;
 import org.hibernate.jpa.spi.ParameterRegistration;
 import org.hibernate.type.CompositeCustomType;
 import org.hibernate.type.Type;
 
-import org.jboss.logging.Logger;
-
 import static javax.persistence.TemporalType.DATE;
 import static javax.persistence.TemporalType.TIME;
 import static javax.persistence.TemporalType.TIMESTAMP;
+import static org.hibernate.jpa.internal.HEMLogging.messageLogger;
 
 /**
  * Hibernate implementation of both the {@link Query} and {@link TypedQuery} contracts.
  *
  * @author <a href="mailto:gavin@hibernate.org">Gavin King</a>
  * @author Emmanuel Bernard
  * @author Steve Ebersole
  */
-public class QueryImpl<X> extends AbstractQueryImpl<X> implements TypedQuery<X>, HibernateQuery, org.hibernate.ejb.HibernateQuery {
-
-    public static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class, QueryImpl.class.getName());
+public class QueryImpl<X> extends AbstractQueryImpl<X>
+		implements TypedQuery<X>, HibernateQuery, org.hibernate.ejb.HibernateQuery {
+	public static final EntityManagerMessageLogger LOG = messageLogger( QueryImpl.class );
 
 	private org.hibernate.Query query;
 
 	public QueryImpl(org.hibernate.Query query, AbstractEntityManagerImpl em) {
 		this( query, em, Collections.<String, Class>emptyMap() );
 	}
 
 	public QueryImpl(
 			org.hibernate.Query query,
 			AbstractEntityManagerImpl em,
-			Map<String,Class> namedParameterTypeRedefinitions) {
+			Map<String, Class> namedParameterTypeRedefinitions) {
 		super( em );
 		this.query = query;
 		extractParameterInfo( namedParameterTypeRedefinitions );
 	}
 
 	@Override
 	protected boolean isNativeSqlQuery() {
 		return SQLQuery.class.isInstance( query );
 	}
 
 	@Override
 	protected boolean isSelectQuery() {
 		if ( isNativeSqlQuery() ) {
 			throw new IllegalStateException( "Cannot tell if native SQL query is SELECT query" );
 		}
 
 		return org.hibernate.internal.QueryImpl.class.cast( query ).isSelect();
 	}
 
-	@SuppressWarnings({ "unchecked", "RedundantCast" })
-	private void extractParameterInfo(Map<String,Class> namedParameterTypeRedefinition) {
-		if ( ! org.hibernate.internal.AbstractQueryImpl.class.isInstance( query ) ) {
+	@SuppressWarnings({"unchecked", "RedundantCast"})
+	private void extractParameterInfo(Map<String, Class> namedParameterTypeRedefinition) {
+		if ( !org.hibernate.internal.AbstractQueryImpl.class.isInstance( query ) ) {
 			throw new IllegalStateException( "Unknown query type for parameter extraction" );
 		}
 
 		boolean hadJpaPositionalParameters = false;
 
-		final ParameterMetadata parameterMetadata = org.hibernate.internal.AbstractQueryImpl.class.cast( query ).getParameterMetadata();
+		final ParameterMetadata parameterMetadata = org.hibernate.internal.AbstractQueryImpl.class.cast( query )
+				.getParameterMetadata();
 
 		// extract named params
 		for ( String name : (Set<String>) parameterMetadata.getNamedParameterNames() ) {
 			final NamedParameterDescriptor descriptor = parameterMetadata.getNamedParameterDescriptor( name );
 			Class javaType = namedParameterTypeRedefinition.get( name );
 			if ( javaType != null && mightNeedRedefinition( javaType, descriptor.getExpectedType() ) ) {
 				descriptor.resetExpectedType(
 						sfi().getTypeResolver().heuristicType( javaType.getName() )
 				);
 			}
 			else if ( descriptor.getExpectedType() != null ) {
 				javaType = descriptor.getExpectedType().getReturnedClass();
 			}
 
 			if ( descriptor.isJpaStyle() ) {
 				hadJpaPositionalParameters = true;
 				final Integer position = Integer.valueOf( name );
 				registerParameter( new JpaPositionalParameterRegistrationImpl( this, query, position, javaType ) );
 			}
 			else {
 				registerParameter( new ParameterRegistrationImpl( this, query, name, javaType ) );
 			}
 		}
 
 		if ( hadJpaPositionalParameters ) {
 			if ( parameterMetadata.getOrdinalParameterCount() > 0 ) {
 				throw new IllegalArgumentException(
 						"Cannot mix JPA positional parameters and native Hibernate positional/ordinal parameters"
 				);
 			}
 		}
 
 		// extract Hibernate native positional parameters
 		for ( int i = 0, max = parameterMetadata.getOrdinalParameterCount(); i < max; i++ ) {
 			final OrdinalParameterDescriptor descriptor = parameterMetadata.getOrdinalParameterDescriptor( i + 1 );
-			Class javaType = descriptor.getExpectedType() == null ? null : descriptor.getExpectedType().getReturnedClass();
-			registerParameter( new ParameterRegistrationImpl( this, query, i+1, javaType ) );
+			Class javaType = descriptor.getExpectedType() == null ?
+					null :
+					descriptor.getExpectedType().getReturnedClass();
+			registerParameter( new ParameterRegistrationImpl( this, query, i + 1, javaType ) );
 		}
 	}
 
 	private SessionFactoryImplementor sfi() {
 		return (SessionFactoryImplementor) getEntityManager().getFactory().getSessionFactory();
 	}
 
 	private boolean mightNeedRedefinition(Class javaType, Type expectedType) {
 		// only redefine dates/times/timestamps that are not wrapped in a CompositeCustomType
 		if ( expectedType == null ) {
 			return java.util.Date.class.isAssignableFrom( javaType );
 		}
 		else {
 			return java.util.Date.class.isAssignableFrom( javaType )
 					&& !CompositeCustomType.class.isAssignableFrom( expectedType.getClass() );
 		}
 	}
 
 	private static class ParameterRegistrationImpl<T> implements ParameterRegistration<T> {
 		private final Query jpaQuery;
 		private final org.hibernate.Query nativeQuery;
 
 		private final String name;
 		private final Integer position;
 		private final Class<T> javaType;
 
 		private ParameterBind<T> bind;
 
 		protected ParameterRegistrationImpl(
 				Query jpaQuery,
 				org.hibernate.Query nativeQuery,
 				String name,
 				Class<T> javaType) {
 			this.jpaQuery = jpaQuery;
 			this.nativeQuery = nativeQuery;
 			this.name = name;
 			this.javaType = javaType;
 			this.position = null;
 		}
 
 		protected ParameterRegistrationImpl(
 				Query jpaQuery,
 				org.hibernate.Query nativeQuery,
 				Integer position,
 				Class<T> javaType) {
 			this.jpaQuery = jpaQuery;
 			this.nativeQuery = nativeQuery;
 			this.position = position;
 			this.javaType = javaType;
 			this.name = null;
 		}
 
 		@Override
 		public boolean isJpaPositionalParameter() {
 			return false;
 		}
 
 		@Override
 		public Query getQuery() {
 			return jpaQuery;
 		}
 
 		@Override
 		public String getName() {
 			return name;
 		}
 
 		@Override
 		public Integer getPosition() {
 			return position;
 		}
 
 		@Override
 		public Class<T> getParameterType() {
 			return javaType;
 		}
 
 		@Override
 		public ParameterMode getMode() {
 			// implicitly
 			return ParameterMode.IN;
 		}
 
 		@Override
 		public boolean isBindable() {
 			// again, implicitly
 			return true;
 		}
 
 		@Override
 		public void bindValue(T value) {
 			validateBinding( getParameterType(), value, null );
 
 			if ( name != null ) {
 				if ( value instanceof Collection ) {
 					nativeQuery.setParameterList( name, (Collection) value );
 				}
 				else {
 					nativeQuery.setParameter( name, value );
 				}
 			}
 			else {
 				nativeQuery.setParameter( position - 1, value );
 			}
 
 			bind = new ParameterBindImpl<T>( value, null );
 		}
 
 		@Override
 		public void bindValue(T value, TemporalType specifiedTemporalType) {
 			validateBinding( getParameterType(), value, specifiedTemporalType );
 
 			if ( Date.class.isInstance( value ) ) {
 				if ( name != null ) {
 					if ( specifiedTemporalType == DATE ) {
 						nativeQuery.setDate( name, (Date) value );
 					}
 					else if ( specifiedTemporalType == TIME ) {
 						nativeQuery.setTime( name, (Date) value );
 					}
 					else if ( specifiedTemporalType == TIMESTAMP ) {
 						nativeQuery.setTimestamp( name, (Date) value );
 					}
 				}
 				else {
 					if ( specifiedTemporalType == DATE ) {
 						nativeQuery.setDate( position - 1, (Date) value );
 					}
 					else if ( specifiedTemporalType == TIME ) {
 						nativeQuery.setTime( position - 1, (Date) value );
 					}
 					else if ( specifiedTemporalType == TIMESTAMP ) {
 						nativeQuery.setTimestamp( position - 1, (Date) value );
 					}
 				}
 			}
 			else if ( Calendar.class.isInstance( value ) ) {
 				if ( name != null ) {
 					if ( specifiedTemporalType == DATE ) {
 						nativeQuery.setCalendarDate( name, (Calendar) value );
 					}
 					else if ( specifiedTemporalType == TIME ) {
 						throw new IllegalArgumentException( "not yet implemented" );
 					}
 					else if ( specifiedTemporalType == TIMESTAMP ) {
 						nativeQuery.setCalendar( name, (Calendar) value );
 					}
 				}
 				else {
 					if ( specifiedTemporalType == DATE ) {
 						nativeQuery.setCalendarDate( position - 1, (Calendar) value );
 					}
 					else if ( specifiedTemporalType == TIME ) {
 						throw new IllegalArgumentException( "not yet implemented" );
 					}
 					else if ( specifiedTemporalType == TIMESTAMP ) {
 						nativeQuery.setCalendar( position - 1, (Calendar) value );
 					}
 				}
 			}
 			else {
 				throw new IllegalArgumentException(
 						"Unexpected type [" + value + "] passed with TemporalType; expecting Date or Calendar"
 				);
 			}
 
 			bind = new ParameterBindImpl<T>( value, specifiedTemporalType );
 		}
 
 		@Override
 		public ParameterBind<T> getBind() {
 			return bind;
 		}
 	}
 
 	/**
 	 * Specialized handling for JPA "positional parameters".
 	 *
 	 * @param <T> The parameter type type.
 	 */
 	public static class JpaPositionalParameterRegistrationImpl<T> extends ParameterRegistrationImpl<T> {
 		final Integer position;
 
 		protected JpaPositionalParameterRegistrationImpl(
 				Query jpaQuery,
 				org.hibernate.Query nativeQuery,
 				Integer position,
 				Class<T> javaType) {
 			super( jpaQuery, nativeQuery, position.toString(), javaType );
 			this.position = position;
 		}
 
 		@Override
 		public String getName() {
 			return null;
 		}
 
 		@Override
 		public Integer getPosition() {
 			return position;
 		}
 
 		@Override
 		public boolean isJpaPositionalParameter() {
 			return true;
 		}
 	}
 
 	public org.hibernate.Query getHibernateQuery() {
 		return query;
 	}
 
 	@Override
-    protected int internalExecuteUpdate() {
+	protected int internalExecuteUpdate() {
 		return query.executeUpdate();
 	}
 
 	@Override
-    protected void applyMaxResults(int maxResults) {
+	protected void applyMaxResults(int maxResults) {
 		query.setMaxResults( maxResults );
 	}
 
 	@Override
-    protected void applyFirstResult(int firstResult) {
+	protected void applyFirstResult(int firstResult) {
 		query.setFirstResult( firstResult );
 	}
 
 	@Override
-    protected boolean applyTimeoutHint(int timeout) {
+	protected boolean applyTimeoutHint(int timeout) {
 		query.setTimeout( timeout );
 		return true;
 	}
 
 	@Override
-    protected boolean applyCommentHint(String comment) {
+	protected boolean applyCommentHint(String comment) {
 		query.setComment( comment );
 		return true;
 	}
 
 	@Override
-    protected boolean applyFetchSizeHint(int fetchSize) {
+	protected boolean applyFetchSizeHint(int fetchSize) {
 		query.setFetchSize( fetchSize );
 		return true;
 	}
 
 	@Override
-    protected boolean applyCacheableHint(boolean isCacheable) {
+	protected boolean applyCacheableHint(boolean isCacheable) {
 		query.setCacheable( isCacheable );
 		return true;
 	}
 
 	@Override
-    protected boolean applyCacheRegionHint(String regionName) {
+	protected boolean applyCacheRegionHint(String regionName) {
 		query.setCacheRegion( regionName );
 		return true;
 	}
 
 	@Override
-    protected boolean applyReadOnlyHint(boolean isReadOnly) {
+	protected boolean applyReadOnlyHint(boolean isReadOnly) {
 		query.setReadOnly( isReadOnly );
 		return true;
 	}
 
 	@Override
-    protected boolean applyCacheModeHint(CacheMode cacheMode) {
+	protected boolean applyCacheModeHint(CacheMode cacheMode) {
 		query.setCacheMode( cacheMode );
 		return true;
 	}
 
 	@Override
-    protected boolean applyFlushModeHint(FlushMode flushMode) {
+	protected boolean applyFlushModeHint(FlushMode flushMode) {
 		query.setFlushMode( flushMode );
 		return true;
 	}
 
 	@Override
 	protected boolean canApplyAliasSpecificLockModeHints() {
 		return org.hibernate.internal.QueryImpl.class.isInstance( query ) || SQLQueryImpl.class.isInstance( query );
 	}
 
 	@Override
 	protected void applyAliasSpecificLockModeHint(String alias, LockMode lockMode) {
 		query.getLockOptions().setAliasSpecificLockMode( alias, lockMode );
 	}
 
 	@Override
-	@SuppressWarnings({ "unchecked", "RedundantCast" })
+	@SuppressWarnings({"unchecked", "RedundantCast"})
 	public List<X> getResultList() {
 		getEntityManager().checkOpen( true );
 		checkTransaction();
 		beforeQuery();
 		try {
 			return list();
 		}
 		catch (QueryExecutionRequestException he) {
-			throw new IllegalStateException(he);
+			throw new IllegalStateException( he );
 		}
-		catch( TypeMismatchException e ) {
-			throw new IllegalArgumentException(e);
+		catch (TypeMismatchException e) {
+			throw new IllegalArgumentException( e );
 		}
 		catch (HibernateException he) {
 			throw getEntityManager().convert( he );
 		}
 	}
 
 	/**
 	 * For JPA native SQL queries, we may need to perform a flush before executing the query.
 	 */
 	private void beforeQuery() {
 		final org.hibernate.Query query = getHibernateQuery();
-		if ( ! SQLQuery.class.isInstance( query ) ) {
+		if ( !SQLQuery.class.isInstance( query ) ) {
 			// this need only exists for native SQL queries, not JPQL or Criteria queries (both of which do
 			// partial auto flushing already).
 			return;
 		}
 
 		final SQLQuery sqlQuery = (SQLQuery) query;
-		if ( sqlQuery.getSynchronizedQuerySpaces() != null && ! sqlQuery.getSynchronizedQuerySpaces().isEmpty() ) {
+		if ( sqlQuery.getSynchronizedQuerySpaces() != null && !sqlQuery.getSynchronizedQuerySpaces().isEmpty() ) {
 			// The application defined query spaces on the Hibernate native SQLQuery which means the query will already
 			// perform a partial flush according to the defined query spaces, no need to do a full flush.
 			return;
 		}
 
 		// otherwise we need to flush.  the query itself is not required to execute in a transaction; if there is
 		// no transaction, the flush would throw a TransactionRequiredException which would potentially break existing
 		// apps, so we only do the flush if a transaction is in progress.
 		if ( getEntityManager().isTransactionInProgress() ) {
 			getEntityManager().flush();
 		}
 	}
 
 	@Override
-	@SuppressWarnings({ "unchecked", "RedundantCast" })
+	@SuppressWarnings({"unchecked", "RedundantCast"})
 	public X getSingleResult() {
 		getEntityManager().checkOpen( true );
 		checkTransaction();
 		beforeQuery();
 		try {
 			final List<X> result = list();
 
 			if ( result.size() == 0 ) {
 				NoResultException nre = new NoResultException( "No entity found for query" );
 				getEntityManager().handlePersistenceException( nre );
 				throw nre;
 			}
 			else if ( result.size() > 1 ) {
-				final Set<X> uniqueResult = new HashSet<X>(result);
+				final Set<X> uniqueResult = new HashSet<X>( result );
 				if ( uniqueResult.size() > 1 ) {
-					NonUniqueResultException nure = new NonUniqueResultException( "result returns more than one elements" );
+					NonUniqueResultException nure = new NonUniqueResultException(
+							"result returns more than one elements"
+					);
 					getEntityManager().handlePersistenceException( nure );
 					throw nure;
 				}
 				else {
 					return uniqueResult.iterator().next();
 				}
 			}
 			else {
 				return result.get( 0 );
 			}
 		}
 		catch (QueryExecutionRequestException he) {
-			throw new IllegalStateException(he);
+			throw new IllegalStateException( he );
 		}
-		catch( TypeMismatchException e ) {
-			throw new IllegalArgumentException(e);
+		catch (TypeMismatchException e) {
+			throw new IllegalArgumentException( e );
 		}
 		catch (HibernateException he) {
 			throw getEntityManager().convert( he );
 		}
 	}
 
 	@Override
-	@SuppressWarnings({ "unchecked" })
+	@SuppressWarnings({"unchecked"})
 	public <T> T unwrap(Class<T> tClass) {
 		if ( org.hibernate.Query.class.isAssignableFrom( tClass ) ) {
 			return (T) query;
 		}
 		if ( QueryImpl.class.isAssignableFrom( tClass ) ) {
 			return (T) this;
 		}
 		if ( HibernateQuery.class.isAssignableFrom( tClass ) ) {
 			return (T) this;
 		}
 
 		throw new PersistenceException(
 				String.format(
 						"Unsure how to unwrap %s impl [%s] as requested type [%s]",
 						Query.class.getSimpleName(),
 						this.getClass().getName(),
 						tClass.getName()
 				)
 		);
 	}
 
 	@Override
 	protected void internalApplyLockMode(javax.persistence.LockModeType lockModeType) {
 		query.getLockOptions().setLockMode( LockModeTypeHelper.getLockMode( lockModeType ) );
 		if ( getHints() != null && getHints().containsKey( AvailableSettings.LOCK_TIMEOUT ) ) {
 			applyLockTimeoutHint( ConfigurationHelper.getInteger( getHints().get( AvailableSettings.LOCK_TIMEOUT ) ) );
 		}
 	}
 
 	@Override
 	protected boolean applyLockTimeoutHint(int timeout) {
 		query.getLockOptions().setTimeOut( timeout );
 		return true;
 	}
 
 	private List<X> list() {
-		if (getEntityGraphQueryHint() != null) {
+		if ( getEntityGraphQueryHint() != null ) {
 			SessionImplementor sessionImpl = (SessionImplementor) getEntityManager().getSession();
 			HQLQueryPlan entityGraphQueryPlan = new HQLQueryPlan(
 					getHibernateQuery().getQueryString(),
 					false,
 					sessionImpl.getLoadQueryInfluencers().getEnabledFilters(),
 					sessionImpl.getFactory(),
 					getEntityGraphQueryHint()
 			);
 			// Safe to assume QueryImpl at this point.
 			unwrap( org.hibernate.internal.QueryImpl.class ).setQueryPlan( entityGraphQueryPlan );
 		}
 		return query.list();
 	}
 
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/metamodel/AbstractType.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/metamodel/AbstractType.java
index 84cb83723b..8c7fc8b0ab 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/metamodel/AbstractType.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/metamodel/AbstractType.java
@@ -1,79 +1,79 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.internal.metamodel;
 
 import java.io.Serializable;
 import javax.persistence.metamodel.Type;
 
 /**
  * Defines commonality for the JPA {@link Type} hierarchy of interfaces.
  *
  * @author Steve Ebersole
  * @author Brad Koehn
  */
 public abstract class AbstractType<X> implements Type<X>, Serializable {
-    private final Class<X> javaType;
-    private final String typeName;
+	private final Class<X> javaType;
+	private final String typeName;
 
 	/**
 	 * Instantiates the type based on the given Java type.
 	 *
 	 * @param javaType The Java type of the JPA model type.
 	 */
-    protected AbstractType(Class<X> javaType) {
+	protected AbstractType(Class<X> javaType) {
 		this( javaType, javaType != null ? javaType.getName() : null );
-    }
+	}
 
 	/**
 	 * Instantiates the type based on the given Java type.
 	 *
 	 * @param javaType
 	 * @param typeName
 	 */
 	protected AbstractType(Class<X> javaType, String typeName) {
 		this.javaType = javaType;
 		this.typeName = typeName == null ? "unknown" : typeName;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 * <p/>
 	 * IMPL NOTE : The Hibernate version may return {@code null} here in the case of either dynamic models or
 	 * entity classes mapped multiple times using entity-name.  In these cases, the {@link #getTypeName()} value
 	 * should be used.
 	 */
 	@Override
-    public Class<X> getJavaType() {
-        return javaType;
-    }
+	public Class<X> getJavaType() {
+		return javaType;
+	}
 
 	/**
 	 * Obtains the type name.  See notes on {@link #getJavaType()} for details
 	 *
 	 * @return The type name
 	 */
-    public String getTypeName() {
-        return typeName;
-    }
+	public String getTypeName() {
+		return typeName;
+	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/metamodel/MetadataContext.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/metamodel/MetadataContext.java
index eb0e2c59e4..f64e4b33e5 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/metamodel/MetadataContext.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/metamodel/MetadataContext.java
@@ -1,504 +1,514 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.internal.metamodel;
 
 import java.lang.reflect.Field;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import javax.persistence.metamodel.Attribute;
 import javax.persistence.metamodel.IdentifiableType;
 import javax.persistence.metamodel.MappedSuperclassType;
 import javax.persistence.metamodel.SingularAttribute;
 
 import org.hibernate.annotations.common.AssertionFailure;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.jpa.internal.EntityManagerMessageLogger;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.KeyValue;
 import org.hibernate.mapping.MappedSuperclass;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 
-import org.jboss.logging.Logger;
+import static org.hibernate.jpa.internal.HEMLogging.messageLogger;
 
 /**
  * Defines a context for storing information during the building of the {@link MetamodelImpl}.
  * <p/>
  * This contextual information includes data needing to be processed in a second pass as well as
  * cross-references into the built metamodel classes.
  * <p/>
  * At the end of the day, clients are interested in the {@link #getEntityTypeMap} and {@link #getEmbeddableTypeMap}
  * results, which represent all the registered {@linkplain #registerEntityType entities} and
- *  {@linkplain #registerEmbeddedableType embeddables} respectively.
+ * {@linkplain #registerEmbeddedableType embeddables} respectively.
  *
  * @author Steve Ebersole
  * @author Emmanuel Bernard
  */
 class MetadataContext {
-
-    private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class,
-                                                                           MetadataContext.class.getName());
+	private static final EntityManagerMessageLogger LOG = messageLogger( MetadataContext.class );
 
 	private final SessionFactoryImplementor sessionFactory;
 	private Set<MappedSuperclass> knownMappedSuperclasses;
 	private final boolean ignoreUnsupported;
 	private final AttributeFactory attributeFactory = new AttributeFactory( this );
 
-	private Map<Class<?>,EntityTypeImpl<?>> entityTypes
+	private Map<Class<?>, EntityTypeImpl<?>> entityTypes
 			= new HashMap<Class<?>, EntityTypeImpl<?>>();
-	private Map<String,EntityTypeImpl<?>> entityTypesByEntityName
+	private Map<String, EntityTypeImpl<?>> entityTypesByEntityName
 			= new HashMap<String, EntityTypeImpl<?>>();
-	private Map<PersistentClass,EntityTypeImpl<?>> entityTypesByPersistentClass
-			= new HashMap<PersistentClass,EntityTypeImpl<?>>();
+	private Map<PersistentClass, EntityTypeImpl<?>> entityTypesByPersistentClass
+			= new HashMap<PersistentClass, EntityTypeImpl<?>>();
 	private Map<Class<?>, EmbeddableTypeImpl<?>> embeddables
 			= new HashMap<Class<?>, EmbeddableTypeImpl<?>>();
 	private Map<MappedSuperclass, MappedSuperclassTypeImpl<?>> mappedSuperclassByMappedSuperclassMapping
-			= new HashMap<MappedSuperclass,MappedSuperclassTypeImpl<?>>();
+			= new HashMap<MappedSuperclass, MappedSuperclassTypeImpl<?>>();
 	//this list contains MappedSuperclass and EntityTypes ordered by superclass first
 	private List<Object> orderedMappings = new ArrayList<Object>();
 	/**
 	 * Stack of PersistentClass being process. Last in the list is the highest in the stack.
-	 *
 	 */
 	private List<PersistentClass> stackOfPersistentClassesBeingProcessed
 			= new ArrayList<PersistentClass>();
 	private Map<MappedSuperclassTypeImpl<?>, PersistentClass> mappedSuperClassTypeToPersistentClass
 			= new HashMap<MappedSuperclassTypeImpl<?>, PersistentClass>();
 
 	public MetadataContext(
 			SessionFactoryImplementor sessionFactory,
 			Set<MappedSuperclass> mappedSuperclasses,
 			boolean ignoreUnsupported) {
 		this.sessionFactory = sessionFactory;
 		this.knownMappedSuperclasses = mappedSuperclasses;
 		this.ignoreUnsupported = ignoreUnsupported;
 	}
 
 	/*package*/ SessionFactoryImplementor getSessionFactory() {
 		return sessionFactory;
 	}
 
-    /*package*/ boolean isIgnoreUnsupported() {
-        return ignoreUnsupported;
-    }
+	/*package*/ boolean isIgnoreUnsupported() {
+		return ignoreUnsupported;
+	}
 
-    /**
+	/**
 	 * Retrieves the {@linkplain Class java type} to {@link EntityTypeImpl} map.
 	 *
 	 * @return The {@linkplain Class java type} to {@link EntityTypeImpl} map.
 	 */
 	public Map<Class<?>, EntityTypeImpl<?>> getEntityTypeMap() {
 		return Collections.unmodifiableMap( entityTypes );
 	}
 
 	public Map<Class<?>, EmbeddableTypeImpl<?>> getEmbeddableTypeMap() {
 		return Collections.unmodifiableMap( embeddables );
 	}
 
-	public Map<Class<?>,MappedSuperclassType<?>> getMappedSuperclassTypeMap() {
+	public Map<Class<?>, MappedSuperclassType<?>> getMappedSuperclassTypeMap() {
 		// we need to actually build this map...
-		final Map<Class<?>,MappedSuperclassType<?>> mappedSuperClassTypeMap = CollectionHelper.mapOfSize(
+		final Map<Class<?>, MappedSuperclassType<?>> mappedSuperClassTypeMap = CollectionHelper.mapOfSize(
 				mappedSuperclassByMappedSuperclassMapping.size()
 		);
 
 		for ( MappedSuperclassTypeImpl mappedSuperclassType : mappedSuperclassByMappedSuperclassMapping.values() ) {
 			mappedSuperClassTypeMap.put(
 					mappedSuperclassType.getJavaType(),
 					mappedSuperclassType
 			);
 		}
 
 		return mappedSuperClassTypeMap;
 	}
 
 	/*package*/ void registerEntityType(PersistentClass persistentClass, EntityTypeImpl<?> entityType) {
 		entityTypes.put( entityType.getBindableJavaType(), entityType );
 		entityTypesByEntityName.put( persistentClass.getEntityName(), entityType );
 		entityTypesByPersistentClass.put( persistentClass, entityType );
 		orderedMappings.add( persistentClass );
 	}
 
 	/*package*/ void registerEmbeddedableType(EmbeddableTypeImpl<?> embeddableType) {
 		embeddables.put( embeddableType.getJavaType(), embeddableType );
 	}
 
 	/*package*/ void registerMappedSuperclassType(
 			MappedSuperclass mappedSuperclass,
 			MappedSuperclassTypeImpl<?> mappedSuperclassType) {
 		mappedSuperclassByMappedSuperclassMapping.put( mappedSuperclass, mappedSuperclassType );
 		orderedMappings.add( mappedSuperclass );
 		mappedSuperClassTypeToPersistentClass.put( mappedSuperclassType, getEntityWorkedOn() );
 
 		knownMappedSuperclasses.remove( mappedSuperclass );
 	}
 
 	/**
 	 * Given a Hibernate {@link PersistentClass}, locate the corresponding JPA {@link org.hibernate.type.EntityType}
 	 * implementation.  May retur null if the given {@link PersistentClass} has not yet been processed.
 	 *
 	 * @param persistentClass The Hibernate (config time) metamodel instance representing an entity.
+	 *
 	 * @return Tne corresponding JPA {@link org.hibernate.type.EntityType}, or null if not yet processed.
 	 */
 	public EntityTypeImpl<?> locateEntityType(PersistentClass persistentClass) {
 		return entityTypesByPersistentClass.get( persistentClass );
 	}
 
 	/**
 	 * Given a Java {@link Class}, locate the corresponding JPA {@link org.hibernate.type.EntityType}.  May
 	 * return null which could means that no such mapping exists at least at this time.
 	 *
 	 * @param javaType The java class.
+	 *
 	 * @return The corresponding JPA {@link org.hibernate.type.EntityType}, or null.
 	 */
 	public EntityTypeImpl<?> locateEntityType(Class<?> javaType) {
 		return entityTypes.get( javaType );
 	}
 
 	/**
 	 * Given an entity-name, locate the corresponding JPA {@link org.hibernate.type.EntityType}.  May
 	 * return null which could means that no such mapping exists at least at this time.
 	 *
 	 * @param entityName The entity-name.
+	 *
 	 * @return The corresponding JPA {@link org.hibernate.type.EntityType}, or null.
 	 */
 	public EntityTypeImpl<?> locateEntityType(String entityName) {
 		return entityTypesByEntityName.get( entityName );
 	}
 
-    public Map<String, EntityTypeImpl<?>> getEntityTypesByEntityName() {
-        return Collections.unmodifiableMap( entityTypesByEntityName );
-    }
+	public Map<String, EntityTypeImpl<?>> getEntityTypesByEntityName() {
+		return Collections.unmodifiableMap( entityTypesByEntityName );
+	}
 
-    @SuppressWarnings({ "unchecked" })
+	@SuppressWarnings({"unchecked"})
 	public void wrapUp() {
-        LOG.trace("Wrapping up metadata context...");
+		LOG.trace( "Wrapping up metadata context..." );
 
 		//we need to process types from superclasses to subclasses
-		for (Object mapping : orderedMappings) {
+		for ( Object mapping : orderedMappings ) {
 			if ( PersistentClass.class.isAssignableFrom( mapping.getClass() ) ) {
-				@SuppressWarnings( "unchecked" )
+				@SuppressWarnings("unchecked")
 				final PersistentClass safeMapping = (PersistentClass) mapping;
-                LOG.trace("Starting entity [" + safeMapping.getEntityName() + "]");
+				LOG.trace( "Starting entity [" + safeMapping.getEntityName() + "]" );
 				try {
 					final EntityTypeImpl<?> jpa2Mapping = entityTypesByPersistentClass.get( safeMapping );
 					applyIdMetadata( safeMapping, jpa2Mapping );
 					applyVersionAttribute( safeMapping, jpa2Mapping );
 					Iterator<Property> properties = safeMapping.getDeclaredPropertyIterator();
 					while ( properties.hasNext() ) {
 						final Property property = properties.next();
 						if ( property.getValue() == safeMapping.getIdentifierMapper() ) {
 							// property represents special handling for id-class mappings but we have already
 							// accounted for the embedded property mappings in #applyIdMetadata &&
 							// #buildIdClassAttributes
 							continue;
 						}
 						if ( safeMapping.isVersioned() && property == safeMapping.getVersion() ) {
 							// skip the version property, it was already handled previously.
 							continue;
 						}
 						final Attribute attribute = attributeFactory.buildAttribute( jpa2Mapping, property );
 						if ( attribute != null ) {
 							jpa2Mapping.getBuilder().addAttribute( attribute );
 						}
 					}
 					jpa2Mapping.lock();
 					populateStaticMetamodel( jpa2Mapping );
 				}
 				finally {
-                    LOG.trace("Completed entity [" + safeMapping.getEntityName() + "]");
+					LOG.trace( "Completed entity [" + safeMapping.getEntityName() + "]" );
 				}
 			}
 			else if ( MappedSuperclass.class.isAssignableFrom( mapping.getClass() ) ) {
-				@SuppressWarnings( "unchecked" )
+				@SuppressWarnings("unchecked")
 				final MappedSuperclass safeMapping = (MappedSuperclass) mapping;
-                LOG.trace("Starting mapped superclass [" + safeMapping.getMappedClass().getName() + "]");
+				LOG.trace( "Starting mapped superclass [" + safeMapping.getMappedClass().getName() + "]" );
 				try {
 					final MappedSuperclassTypeImpl<?> jpa2Mapping = mappedSuperclassByMappedSuperclassMapping.get(
 							safeMapping
 					);
 					applyIdMetadata( safeMapping, jpa2Mapping );
 					applyVersionAttribute( safeMapping, jpa2Mapping );
 					Iterator<Property> properties = safeMapping.getDeclaredPropertyIterator();
 					while ( properties.hasNext() ) {
 						final Property property = properties.next();
 						if ( safeMapping.isVersioned() && property == safeMapping.getVersion() ) {
 							// skip the version property, it was already handled previously.
 							continue;
 						}
 						final Attribute attribute = attributeFactory.buildAttribute( jpa2Mapping, property );
 						if ( attribute != null ) {
 							jpa2Mapping.getBuilder().addAttribute( attribute );
 						}
 					}
 					jpa2Mapping.lock();
 					populateStaticMetamodel( jpa2Mapping );
 				}
 				finally {
-                    LOG.trace("Completed mapped superclass [" + safeMapping.getMappedClass().getName() + "]");
+					LOG.trace( "Completed mapped superclass [" + safeMapping.getMappedClass().getName() + "]" );
 				}
 			}
 			else {
 				throw new AssertionFailure( "Unexpected mapping type: " + mapping.getClass() );
 			}
 		}
 
 		for ( EmbeddableTypeImpl embeddable : embeddables.values() ) {
 			populateStaticMetamodel( embeddable );
 		}
 	}
 
 
 	private <X> void applyIdMetadata(PersistentClass persistentClass, EntityTypeImpl<X> jpaEntityType) {
 		if ( persistentClass.hasIdentifierProperty() ) {
 			final Property declaredIdentifierProperty = persistentClass.getDeclaredIdentifierProperty();
-			if (declaredIdentifierProperty != null) {
+			if ( declaredIdentifierProperty != null ) {
 				jpaEntityType.getBuilder().applyIdAttribute(
 						attributeFactory.buildIdAttribute( jpaEntityType, declaredIdentifierProperty )
 				);
 			}
 		}
 		else if ( persistentClass.hasIdentifierMapper() ) {
-			@SuppressWarnings( "unchecked")
+			@SuppressWarnings("unchecked")
 			Iterator<Property> propertyIterator = persistentClass.getIdentifierMapper().getPropertyIterator();
 			Set<SingularAttribute<? super X, ?>> attributes = buildIdClassAttributes( jpaEntityType, propertyIterator );
 			jpaEntityType.getBuilder().applyIdClassAttributes( attributes );
 		}
 		else {
 			final KeyValue value = persistentClass.getIdentifier();
-			if (value instanceof Component ) {
-				final Component component = ( Component ) value;
+			if ( value instanceof Component ) {
+				final Component component = (Component) value;
 				if ( component.getPropertySpan() > 1 ) {
 					//FIXME we are an Hibernate embedded id (ie not type)
 				}
 				else {
 					//FIXME take care of declared vs non declared property
 					jpaEntityType.getBuilder().applyIdAttribute(
-						attributeFactory.buildIdAttribute(
-								jpaEntityType,
-								(Property) component.getPropertyIterator().next() )
+							attributeFactory.buildIdAttribute(
+									jpaEntityType,
+									(Property) component.getPropertyIterator().next()
+							)
 					);
 				}
 			}
 		}
 	}
 
 	private <X> void applyIdMetadata(MappedSuperclass mappingType, MappedSuperclassTypeImpl<X> jpaMappingType) {
 		if ( mappingType.hasIdentifierProperty() ) {
 			final Property declaredIdentifierProperty = mappingType.getDeclaredIdentifierProperty();
-			if (declaredIdentifierProperty != null) {
+			if ( declaredIdentifierProperty != null ) {
 				jpaMappingType.getBuilder().applyIdAttribute(
 						attributeFactory.buildIdAttribute( jpaMappingType, declaredIdentifierProperty )
 				);
 			}
 		}
 		//an MappedSuperclass can have no identifier if the id is set below in the hierarchy
-		else if ( mappingType.getIdentifierMapper() != null ){
-			@SuppressWarnings( "unchecked")
+		else if ( mappingType.getIdentifierMapper() != null ) {
+			@SuppressWarnings("unchecked")
 			Iterator<Property> propertyIterator = mappingType.getIdentifierMapper().getPropertyIterator();
-			Set<SingularAttribute<? super X, ?>> attributes = buildIdClassAttributes( jpaMappingType, propertyIterator );
+			Set<SingularAttribute<? super X, ?>> attributes = buildIdClassAttributes(
+					jpaMappingType,
+					propertyIterator
+			);
 			jpaMappingType.getBuilder().applyIdClassAttributes( attributes );
 		}
 	}
 
 	private <X> void applyVersionAttribute(PersistentClass persistentClass, EntityTypeImpl<X> jpaEntityType) {
 		final Property declaredVersion = persistentClass.getDeclaredVersion();
-		if (declaredVersion != null) {
+		if ( declaredVersion != null ) {
 			jpaEntityType.getBuilder().applyVersionAttribute(
 					attributeFactory.buildVersionAttribute( jpaEntityType, declaredVersion )
 			);
 		}
 	}
 
 	private <X> void applyVersionAttribute(MappedSuperclass mappingType, MappedSuperclassTypeImpl<X> jpaMappingType) {
 		final Property declaredVersion = mappingType.getDeclaredVersion();
 		if ( declaredVersion != null ) {
 			jpaMappingType.getBuilder().applyVersionAttribute(
 					attributeFactory.buildVersionAttribute( jpaMappingType, declaredVersion )
 			);
 		}
 	}
 
 	private <X> Set<SingularAttribute<? super X, ?>> buildIdClassAttributes(
 			AbstractIdentifiableType<X> ownerType,
 			Iterator<Property> propertyIterator) {
-		LOG.trace("Building old-school composite identifier [" + ownerType.getJavaType().getName() + "]");
-		Set<SingularAttribute<? super X, ?>> attributes	= new HashSet<SingularAttribute<? super X, ?>>();
+		LOG.trace( "Building old-school composite identifier [" + ownerType.getJavaType().getName() + "]" );
+		Set<SingularAttribute<? super X, ?>> attributes = new HashSet<SingularAttribute<? super X, ?>>();
 		while ( propertyIterator.hasNext() ) {
 			attributes.add( attributeFactory.buildIdAttribute( ownerType, propertyIterator.next() ) );
 		}
 		return attributes;
 	}
 
 	private <X> void populateStaticMetamodel(AbstractManagedType<X> managedType) {
 		final Class<X> managedTypeClass = managedType.getJavaType();
 		if ( managedTypeClass == null ) {
 			// should indicate MAP entity mode, skip...
 			return;
 		}
 		final String metamodelClassName = managedTypeClass.getName() + "_";
 		try {
 			final Class metamodelClass = Class.forName( metamodelClassName, true, managedTypeClass.getClassLoader() );
 			// we found the class; so populate it...
 			registerAttributes( metamodelClass, managedType );
 		}
-		catch ( ClassNotFoundException ignore ) {
+		catch (ClassNotFoundException ignore) {
 			// nothing to do...
 		}
 
 		// todo : this does not account for @MappeSuperclass, mainly because this is not being tracked in our
 		// internal metamodel as populated from the annotatios properly
 		AbstractManagedType<? super X> superType = managedType.getSupertype();
 		if ( superType != null ) {
 			populateStaticMetamodel( superType );
 		}
 	}
 
 	private final Set<Class> processedMetamodelClasses = new HashSet<Class>();
 
 	private <X> void registerAttributes(Class metamodelClass, AbstractManagedType<X> managedType) {
-		if ( ! processedMetamodelClasses.add( metamodelClass ) ) {
+		if ( !processedMetamodelClasses.add( metamodelClass ) ) {
 			return;
 		}
 
 		// push the attributes on to the metamodel class...
 		for ( Attribute<X, ?> attribute : managedType.getDeclaredAttributes() ) {
 			registerAttribute( metamodelClass, attribute );
 		}
 
 		if ( IdentifiableType.class.isInstance( managedType ) ) {
-			final AbstractIdentifiableType<X> entityType = ( AbstractIdentifiableType<X> ) managedType;
+			final AbstractIdentifiableType<X> entityType = (AbstractIdentifiableType<X>) managedType;
 
 			// handle version
 			if ( entityType.hasDeclaredVersionAttribute() ) {
 				registerAttribute( metamodelClass, entityType.getDeclaredVersion() );
 			}
 
 			// handle id-class mappings specially
 			if ( entityType.hasIdClass() ) {
 				final Set<SingularAttribute<? super X, ?>> attributes = entityType.getIdClassAttributesSafely();
 				if ( attributes != null ) {
 					for ( SingularAttribute<? super X, ?> attribute : attributes ) {
 						registerAttribute( metamodelClass, attribute );
 					}
 				}
 			}
 		}
 	}
 
 	private <X> void registerAttribute(Class metamodelClass, Attribute<X, ?> attribute) {
 		final String name = attribute.getName();
 		try {
 			// there is a shortcoming in the existing Hibernate code in terms of the way MappedSuperclass
 			// support was bolted on which comes to bear right here when the attribute is an embeddable type
 			// defined on a MappedSuperclass.  We do not have the correct information to determine the
 			// appropriate attribute declarer in such cases and so the incoming metamodelClass most likely
 			// does not represent the declarer in such cases.
 			//
 			// As a result, in the case of embeddable classes we simply use getField rather than get
 			// getDeclaredField
 			final Field field = attribute.getPersistentAttributeType() == Attribute.PersistentAttributeType.EMBEDDED
 					? metamodelClass.getField( name )
 					: metamodelClass.getDeclaredField( name );
 			try {
 				// should be public anyway, but to be sure...
 				field.setAccessible( true );
 				field.set( null, attribute );
 			}
-			catch ( IllegalAccessException e ) {
+			catch (IllegalAccessException e) {
 				// todo : exception type?
 				throw new AssertionFailure(
 						"Unable to inject static metamodel attribute : " + metamodelClass.getName() + '#' + name,
 						e
 				);
 			}
-			catch ( IllegalArgumentException e ) {
+			catch (IllegalArgumentException e) {
 				// most likely a mismatch in the type we are injecting and the defined field; this represents a
 				// mismatch in how the annotation processor interpretted the attribute and how our metamodel
 				// and/or annotation binder did.
 
 //              This is particularly the case as arrays are nto handled propery by the StaticMetamodel generator
 
 //				throw new AssertionFailure(
 //						"Illegal argument on static metamodel field injection : " + metamodelClass.getName() + '#' + name
 //								+ "; expected type :  " + attribute.getClass().getName()
 //								+ "; encountered type : " + field.getType().getName()
 //				);
-                LOG.illegalArgumentOnStaticMetamodelFieldInjection(metamodelClass.getName(),
-                                                                   name,
-                                                                   attribute.getClass().getName(),
-                                                                   field.getType().getName());
+				LOG.illegalArgumentOnStaticMetamodelFieldInjection(
+						metamodelClass.getName(),
+						name,
+						attribute.getClass().getName(),
+						field.getType().getName()
+				);
 			}
 		}
-		catch ( NoSuchFieldException e ) {
-            LOG.unableToLocateStaticMetamodelField(metamodelClass.getName(), name);
+		catch (NoSuchFieldException e) {
+			LOG.unableToLocateStaticMetamodelField( metamodelClass.getName(), name );
 //			throw new AssertionFailure(
 //					"Unable to locate static metamodel field : " + metamodelClass.getName() + '#' + name
 //			);
 		}
 	}
 
 	public MappedSuperclassTypeImpl<?> locateMappedSuperclassType(MappedSuperclass mappedSuperclass) {
-		return mappedSuperclassByMappedSuperclassMapping.get(mappedSuperclass);
+		return mappedSuperclassByMappedSuperclassMapping.get( mappedSuperclass );
 	}
 
 	public void pushEntityWorkedOn(PersistentClass persistentClass) {
-		stackOfPersistentClassesBeingProcessed.add(persistentClass);
+		stackOfPersistentClassesBeingProcessed.add( persistentClass );
 	}
 
 	public void popEntityWorkedOn(PersistentClass persistentClass) {
 		final PersistentClass stackTop = stackOfPersistentClassesBeingProcessed.remove(
 				stackOfPersistentClassesBeingProcessed.size() - 1
 		);
-		if (stackTop != persistentClass) {
-			throw new AssertionFailure( "Inconsistent popping: "
-				+ persistentClass.getEntityName() + " instead of " + stackTop.getEntityName() );
+		if ( stackTop != persistentClass ) {
+			throw new AssertionFailure(
+					"Inconsistent popping: "
+							+ persistentClass.getEntityName() + " instead of " + stackTop.getEntityName()
+			);
 		}
 	}
 
 	private PersistentClass getEntityWorkedOn() {
 		return stackOfPersistentClassesBeingProcessed.get(
-					stackOfPersistentClassesBeingProcessed.size() - 1
-			);
+				stackOfPersistentClassesBeingProcessed.size() - 1
+		);
 	}
 
 	public PersistentClass getPersistentClassHostingProperties(MappedSuperclassTypeImpl<?> mappedSuperclassType) {
 		final PersistentClass persistentClass = mappedSuperClassTypeToPersistentClass.get( mappedSuperclassType );
-		if (persistentClass == null) {
-			throw new AssertionFailure( "Could not find PersistentClass for MappedSuperclassType: "
-					+ mappedSuperclassType.getJavaType() );
+		if ( persistentClass == null ) {
+			throw new AssertionFailure(
+					"Could not find PersistentClass for MappedSuperclassType: "
+							+ mappedSuperclassType.getJavaType()
+			);
 		}
 		return persistentClass;
 	}
 
 	public Set<MappedSuperclass> getUnusedMappedSuperclasses() {
 		return new HashSet<MappedSuperclass>( knownMappedSuperclasses );
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/metamodel/MetamodelImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/metamodel/MetamodelImpl.java
index f5bc46a1fe..19ffbf7941 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/metamodel/MetamodelImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/metamodel/MetamodelImpl.java
@@ -1,259 +1,265 @@
 /*
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.internal.metamodel;
 
 import java.io.Serializable;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Set;
 import javax.persistence.metamodel.EmbeddableType;
 import javax.persistence.metamodel.EntityType;
 import javax.persistence.metamodel.ManagedType;
 import javax.persistence.metamodel.MappedSuperclassType;
 import javax.persistence.metamodel.Metamodel;
 
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.jpa.internal.EntityManagerMessageLogger;
 import org.hibernate.jpa.internal.HEMLogging;
 import org.hibernate.mapping.MappedSuperclass;
 import org.hibernate.mapping.PersistentClass;
 
 /**
  * Hibernate implementation of the JPA {@link Metamodel} contract.
  *
  * @author Steve Ebersole
  * @author Emmanuel Bernard
  */
 public class MetamodelImpl implements Metamodel, Serializable {
 	private static final EntityManagerMessageLogger log = HEMLogging.messageLogger( MetamodelImpl.class );
 
-	private final Map<Class<?>,EntityTypeImpl<?>> entities;
+	private final Map<Class<?>, EntityTypeImpl<?>> entities;
 	private final Map<Class<?>, EmbeddableTypeImpl<?>> embeddables;
 	private final Map<Class<?>, MappedSuperclassType<?>> mappedSuperclassTypeMap;
-    private final Map<String, EntityTypeImpl<?>> entityTypesByEntityName;
+	private final Map<String, EntityTypeImpl<?>> entityTypesByEntityName;
 
-    /**
-   	 * Build the metamodel using the information from the collection of Hibernate
-   	 * {@link PersistentClass} models as well as the Hibernate {@link org.hibernate.SessionFactory}.
-   	 *
-   	 * @param persistentClasses Iterator over the Hibernate (config-time) metamodel
-   	 * @param sessionFactory The Hibernate session factory.
-   	 * @return The built metamodel
-	 * 
-	 * @deprecated use {@link #buildMetamodel(Iterator,Set,SessionFactoryImplementor,boolean)} instead
-   	 */
+	/**
+	 * Build the metamodel using the information from the collection of Hibernate
+	 * {@link PersistentClass} models as well as the Hibernate {@link org.hibernate.SessionFactory}.
+	 *
+	 * @param persistentClasses Iterator over the Hibernate (config-time) metamodel
+	 * @param sessionFactory The Hibernate session factory.
+	 *
+	 * @return The built metamodel
+	 *
+	 * @deprecated use {@link #buildMetamodel(Iterator, Set, SessionFactoryImplementor, boolean)} instead
+	 */
 	@Deprecated
-   	public static MetamodelImpl buildMetamodel(
-   			Iterator<PersistentClass> persistentClasses,
-   			SessionFactoryImplementor sessionFactory) {
-        return buildMetamodel( persistentClasses, Collections.<MappedSuperclass>emptySet(), sessionFactory, false );
-   	}
+	public static MetamodelImpl buildMetamodel(
+			Iterator<PersistentClass> persistentClasses,
+			SessionFactoryImplementor sessionFactory) {
+		return buildMetamodel( persistentClasses, Collections.<MappedSuperclass>emptySet(), sessionFactory, false );
+	}
 
 	/**
 	 * Build the metamodel using the information from the collection of Hibernate
 	 * {@link PersistentClass} models as well as the Hibernate {@link org.hibernate.SessionFactory}.
 	 *
 	 * @param persistentClasses Iterator over the Hibernate (config-time) metamodel
 	 * @param mappedSuperclasses All known MappedSuperclasses
 	 * @param sessionFactory The Hibernate session factory.
-     * @param ignoreUnsupported ignore unsupported/unknown annotations (like @Any)
+	 * @param ignoreUnsupported ignore unsupported/unknown annotations (like @Any)
 	 *
 	 * @return The built metamodel
 	 */
 	public static MetamodelImpl buildMetamodel(
 			Iterator<PersistentClass> persistentClasses,
 			Set<MappedSuperclass> mappedSuperclasses,
 			SessionFactoryImplementor sessionFactory,
-            boolean ignoreUnsupported) {
+			boolean ignoreUnsupported) {
 		MetadataContext context = new MetadataContext( sessionFactory, mappedSuperclasses, ignoreUnsupported );
 		while ( persistentClasses.hasNext() ) {
 			PersistentClass pc = persistentClasses.next();
 			locateOrBuildEntityType( pc, context );
 		}
 		handleUnusedMappedSuperclasses( context );
 		context.wrapUp();
-		return new MetamodelImpl( context.getEntityTypeMap(), context.getEmbeddableTypeMap(), context.getMappedSuperclassTypeMap(), context.getEntityTypesByEntityName() );
+		return new MetamodelImpl(
+				context.getEntityTypeMap(),
+				context.getEmbeddableTypeMap(),
+				context.getMappedSuperclassTypeMap(),
+				context.getEntityTypesByEntityName()
+		);
 	}
 
 	private static void handleUnusedMappedSuperclasses(MetadataContext context) {
 		final Set<MappedSuperclass> unusedMappedSuperclasses = context.getUnusedMappedSuperclasses();
 		if ( !unusedMappedSuperclasses.isEmpty() ) {
 			for ( MappedSuperclass mappedSuperclass : unusedMappedSuperclasses ) {
 				log.unusedMappedSuperclass( mappedSuperclass.getMappedClass().getName() );
 				locateOrBuildMappedsuperclassType( mappedSuperclass, context );
 			}
 		}
 	}
 
 	private static EntityTypeImpl<?> locateOrBuildEntityType(PersistentClass persistentClass, MetadataContext context) {
 		EntityTypeImpl<?> entityType = context.locateEntityType( persistentClass );
 		if ( entityType == null ) {
 			entityType = buildEntityType( persistentClass, context );
 		}
 		return entityType;
 	}
 
 	//TODO remove / reduce @SW scope
-	@SuppressWarnings( "unchecked" )
+	@SuppressWarnings("unchecked")
 	private static EntityTypeImpl<?> buildEntityType(PersistentClass persistentClass, MetadataContext context) {
 		final Class javaType = persistentClass.getMappedClass();
-		context.pushEntityWorkedOn(persistentClass);
+		context.pushEntityWorkedOn( persistentClass );
 		final MappedSuperclass superMappedSuperclass = persistentClass.getSuperMappedSuperclass();
 		AbstractIdentifiableType<?> superType = superMappedSuperclass == null
 				? null
 				: locateOrBuildMappedsuperclassType( superMappedSuperclass, context );
 		//no mappedSuperclass, check for a super entity
-		if (superType == null) {
+		if ( superType == null ) {
 			final PersistentClass superPersistentClass = persistentClass.getSuperclass();
 			superType = superPersistentClass == null
 					? null
 					: locateOrBuildEntityType( superPersistentClass, context );
 		}
 		EntityTypeImpl entityType = new EntityTypeImpl(
 				javaType,
 				superType,
 				persistentClass
 		);
 
-        context.registerEntityType( persistentClass, entityType );
-		context.popEntityWorkedOn(persistentClass);
+		context.registerEntityType( persistentClass, entityType );
+		context.popEntityWorkedOn( persistentClass );
 		return entityType;
 	}
-	
+
 	private static MappedSuperclassTypeImpl<?> locateOrBuildMappedsuperclassType(
 			MappedSuperclass mappedSuperclass, MetadataContext context) {
 		MappedSuperclassTypeImpl<?> mappedSuperclassType = context.locateMappedSuperclassType( mappedSuperclass );
 		if ( mappedSuperclassType == null ) {
-			mappedSuperclassType = buildMappedSuperclassType(mappedSuperclass, context);
+			mappedSuperclassType = buildMappedSuperclassType( mappedSuperclass, context );
 		}
 		return mappedSuperclassType;
 	}
 
 	//TODO remove / reduce @SW scope
-	@SuppressWarnings( "unchecked" )
+	@SuppressWarnings("unchecked")
 	private static MappedSuperclassTypeImpl<?> buildMappedSuperclassType(
 			MappedSuperclass mappedSuperclass,
 			MetadataContext context) {
 		final MappedSuperclass superMappedSuperclass = mappedSuperclass.getSuperMappedSuperclass();
 		AbstractIdentifiableType<?> superType = superMappedSuperclass == null
 				? null
 				: locateOrBuildMappedsuperclassType( superMappedSuperclass, context );
 		//no mappedSuperclass, check for a super entity
-		if (superType == null) {
+		if ( superType == null ) {
 			final PersistentClass superPersistentClass = mappedSuperclass.getSuperPersistentClass();
 			superType = superPersistentClass == null
 					? null
 					: locateOrBuildEntityType( superPersistentClass, context );
 		}
 		final Class javaType = mappedSuperclass.getMappedClass();
 		MappedSuperclassTypeImpl mappedSuperclassType = new MappedSuperclassTypeImpl(
 				javaType,
 				mappedSuperclass,
 				superType
 		);
 		context.registerMappedSuperclassType( mappedSuperclass, mappedSuperclassType );
 		return mappedSuperclassType;
 	}
 
 	/**
 	 * Instantiate the metamodel.
 	 *
 	 * @param entities The entity mappings.
 	 * @param embeddables The embeddable (component) mappings.
 	 * @param mappedSuperclassTypeMap The {@link javax.persistence.MappedSuperclass} mappings
 	 */
 	private MetamodelImpl(
 			Map<Class<?>, EntityTypeImpl<?>> entities,
 			Map<Class<?>, EmbeddableTypeImpl<?>> embeddables,
-            Map<Class<?>, MappedSuperclassType<?>> mappedSuperclassTypeMap,
-            Map<String, EntityTypeImpl<?>> entityTypesByEntityName) {
+			Map<Class<?>, MappedSuperclassType<?>> mappedSuperclassTypeMap,
+			Map<String, EntityTypeImpl<?>> entityTypesByEntityName) {
 		this.entities = entities;
 		this.embeddables = embeddables;
 		this.mappedSuperclassTypeMap = mappedSuperclassTypeMap;
-        this.entityTypesByEntityName = entityTypesByEntityName;
+		this.entityTypesByEntityName = entityTypesByEntityName;
 	}
 
 	@Override
-	@SuppressWarnings({ "unchecked" })
+	@SuppressWarnings({"unchecked"})
 	public <X> EntityType<X> entity(Class<X> cls) {
 		final EntityType<?> entityType = entities.get( cls );
 		if ( entityType == null ) {
 			throw new IllegalArgumentException( "Not an entity: " + cls );
 		}
 		return (EntityType<X>) entityType;
 	}
 
 	@Override
-	@SuppressWarnings({ "unchecked" })
+	@SuppressWarnings({"unchecked"})
 	public <X> ManagedType<X> managedType(Class<X> cls) {
 		ManagedType<?> type = entities.get( cls );
 		if ( type == null ) {
 			type = mappedSuperclassTypeMap.get( cls );
 		}
 		if ( type == null ) {
 			type = embeddables.get( cls );
 		}
 		if ( type == null ) {
 			throw new IllegalArgumentException( "Not an managed type: " + cls );
 		}
 		return (ManagedType<X>) type;
 	}
 
 	@Override
-	@SuppressWarnings({ "unchecked" })
+	@SuppressWarnings({"unchecked"})
 	public <X> EmbeddableType<X> embeddable(Class<X> cls) {
 		final EmbeddableType<?> embeddableType = embeddables.get( cls );
 		if ( embeddableType == null ) {
 			throw new IllegalArgumentException( "Not an embeddable: " + cls );
 		}
 		return (EmbeddableType<X>) embeddableType;
 	}
 
 	@Override
 	public Set<ManagedType<?>> getManagedTypes() {
 		final int setSize = CollectionHelper.determineProperSizing(
 				entities.size() + mappedSuperclassTypeMap.size() + embeddables.size()
 		);
 		final Set<ManagedType<?>> managedTypes = new HashSet<ManagedType<?>>( setSize );
 		managedTypes.addAll( entities.values() );
 		managedTypes.addAll( mappedSuperclassTypeMap.values() );
 		managedTypes.addAll( embeddables.values() );
 		return managedTypes;
 	}
 
 	@Override
 	public Set<EntityType<?>> getEntities() {
 		return new HashSet<EntityType<?>>( entityTypesByEntityName.values() );
 	}
 
 	@Override
 	public Set<EmbeddableType<?>> getEmbeddables() {
 		return new HashSet<EmbeddableType<?>>( embeddables.values() );
 	}
 
 	public EntityTypeImpl getEntityTypeByName(String entityName) {
 		return entityTypesByEntityName.get( entityName );
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/AbstractEntityManagerImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/AbstractEntityManagerImpl.java
index 0abfcc0be7..331db5d851 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/AbstractEntityManagerImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/AbstractEntityManagerImpl.java
@@ -1,1794 +1,1780 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.spi;
 
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import javax.persistence.CacheRetrieveMode;
 import javax.persistence.CacheStoreMode;
 import javax.persistence.EntityExistsException;
 import javax.persistence.EntityGraph;
 import javax.persistence.EntityManager;
 import javax.persistence.EntityNotFoundException;
 import javax.persistence.EntityTransaction;
 import javax.persistence.FlushModeType;
 import javax.persistence.LockModeType;
 import javax.persistence.LockTimeoutException;
 import javax.persistence.NoResultException;
 import javax.persistence.NonUniqueResultException;
 import javax.persistence.OptimisticLockException;
 import javax.persistence.PersistenceContextType;
 import javax.persistence.PersistenceException;
 import javax.persistence.PessimisticLockException;
 import javax.persistence.PessimisticLockScope;
 import javax.persistence.Query;
 import javax.persistence.QueryTimeoutException;
 import javax.persistence.StoredProcedureQuery;
 import javax.persistence.SynchronizationType;
 import javax.persistence.TransactionRequiredException;
 import javax.persistence.Tuple;
 import javax.persistence.TupleElement;
 import javax.persistence.TypedQuery;
 import javax.persistence.criteria.CriteriaBuilder;
 import javax.persistence.criteria.CriteriaDelete;
 import javax.persistence.criteria.CriteriaQuery;
 import javax.persistence.criteria.CriteriaUpdate;
 import javax.persistence.criteria.Selection;
 import javax.persistence.metamodel.Metamodel;
 import javax.persistence.spi.PersistenceUnitTransactionType;
 import javax.transaction.Status;
 import javax.transaction.SystemException;
 import javax.transaction.TransactionManager;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.CacheMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.ObjectDeletedException;
 import org.hibernate.ObjectNotFoundException;
 import org.hibernate.QueryException;
 import org.hibernate.SQLQuery;
 import org.hibernate.Session;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.StaleStateException;
 import org.hibernate.TransactionException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.TypeMismatchException;
 import org.hibernate.UnresolvableObjectException;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.boot.registry.classloading.spi.ClassLoadingException;
 import org.hibernate.dialect.lock.LockingStrategyException;
 import org.hibernate.dialect.lock.OptimisticEntityLockException;
 import org.hibernate.dialect.lock.PessimisticEntityLockException;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.query.spi.HQLQueryPlan;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryConstructorReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryRootReturn;
 import org.hibernate.engine.spi.NamedQueryDefinition;
 import org.hibernate.engine.spi.NamedSQLQueryDefinition;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.jpa.AvailableSettings;
 import org.hibernate.jpa.HibernateEntityManagerFactory;
 import org.hibernate.jpa.QueryHints;
 import org.hibernate.jpa.criteria.ValueHandlerFactory;
 import org.hibernate.jpa.criteria.compile.CompilableCriteria;
 import org.hibernate.jpa.criteria.compile.CriteriaCompiler;
 import org.hibernate.jpa.criteria.expression.CompoundSelectionImpl;
 import org.hibernate.jpa.internal.EntityManagerFactoryImpl;
 import org.hibernate.jpa.internal.EntityManagerMessageLogger;
-import org.hibernate.jpa.internal.HEMLogging;
 import org.hibernate.jpa.internal.QueryImpl;
 import org.hibernate.jpa.internal.StoredProcedureQueryImpl;
 import org.hibernate.jpa.internal.TransactionImpl;
 import org.hibernate.jpa.internal.util.CacheModeHelper;
 import org.hibernate.jpa.internal.util.ConfigurationHelper;
 import org.hibernate.jpa.internal.util.LockModeTypeHelper;
 import org.hibernate.procedure.ProcedureCallMemento;
 import org.hibernate.procedure.UnknownSqlResultSetMappingException;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.resource.transaction.TransactionCoordinator;
 import org.hibernate.transform.BasicTransformerAdapter;
 import org.hibernate.type.Type;
 
+import static org.hibernate.jpa.internal.HEMLogging.messageLogger;
+
 /**
  * @author <a href="mailto:gavin@hibernate.org">Gavin King</a>
  * @author Emmanuel Bernard
  * @author Steve Ebersole
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public abstract class AbstractEntityManagerImpl implements HibernateEntityManagerImplementor, Serializable {
 	private static final long serialVersionUID = 78818181L;
 
-    private static final EntityManagerMessageLogger LOG = HEMLogging.messageLogger( AbstractEntityManagerImpl.class );
+	private static final EntityManagerMessageLogger LOG = messageLogger( AbstractEntityManagerImpl.class );
 
 	private static final List<String> ENTITY_MANAGER_SPECIFIC_PROPERTIES = new ArrayList<String>();
 
 	static {
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.LOCK_SCOPE );
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.LOCK_TIMEOUT );
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.FLUSH_MODE );
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE );
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.SHARED_CACHE_STORE_MODE );
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( QueryHints.SPEC_HINT_TIMEOUT );
 	}
 
 	private EntityManagerFactoryImpl entityManagerFactory;
 	protected transient TransactionImpl tx = new TransactionImpl( this );
 	private SynchronizationType synchronizationType;
 	private PersistenceUnitTransactionType transactionType;
 	private Map<String, Object> properties;
 	private LockOptions lockOptions;
 
 	protected AbstractEntityManagerImpl(
 			EntityManagerFactoryImpl entityManagerFactory,
 			PersistenceContextType type,  // TODO:  remove as no longer used
 			SynchronizationType synchronizationType,
 			PersistenceUnitTransactionType transactionType,
 			Map properties) {
 		this.entityManagerFactory = entityManagerFactory;
 		this.synchronizationType = synchronizationType;
 		this.transactionType = transactionType;
 
 		this.lockOptions = new LockOptions();
 		this.properties = new HashMap<String, Object>();
 		for ( String key : ENTITY_MANAGER_SPECIFIC_PROPERTIES ) {
 			if ( entityManagerFactory.getProperties().containsKey( key ) ) {
 				this.properties.put( key, entityManagerFactory.getProperties().get( key ) );
 			}
 			if ( properties != null && properties.containsKey( key ) ) {
 				this.properties.put( key, properties.get( key ) );
 			}
 		}
 	}
 
-//	protected PersistenceUnitTransactionType transactionType() {
-//		return transactionType;
-//	}
-//
-//	protected SynchronizationType synchronizationType() {
-//		return synchronizationType;
-//	}
-//
-//	public boolean shouldAutoJoinTransactions() {
-//		// the Session should auto join only if using non-JTA transactions or if the synchronization type
-//		// was specified as SYNCHRONIZED
-//		return transactionType != PersistenceUnitTransactionType.JTA
-//				|| synchronizationType == SynchronizationType.SYNCHRONIZED;
-//	}
-
 	public PersistenceUnitTransactionType getTransactionType() {
 		return transactionType;
 	}
 
 	protected void postInit() {
 		//register in Sync if needed
 		if ( transactionType == PersistenceUnitTransactionType.JTA
 				&& synchronizationType == SynchronizationType.SYNCHRONIZED ) {
 			joinTransaction( false );
 		}
 
 		setDefaultProperties();
 		applyProperties();
 	}
 
 	private void applyProperties() {
 		getSession().setFlushMode( ConfigurationHelper.getFlushMode( properties.get( AvailableSettings.FLUSH_MODE ) ) );
 		setLockOptions( this.properties, this.lockOptions );
 		getSession().setCacheMode(
 				CacheModeHelper.interpretCacheMode(
 						currentCacheStoreMode(),
 						currentCacheRetrieveMode()
 				)
 		);
 	}
 
 	private Query applyProperties(Query query) {
 		if ( lockOptions.getLockMode() != LockMode.NONE ) {
 			query.setLockMode( getLockMode(lockOptions.getLockMode()));
 		}
 		Object queryTimeout;
 		if ( (queryTimeout = getProperties().get(QueryHints.SPEC_HINT_TIMEOUT)) != null ) {
 			query.setHint( QueryHints.SPEC_HINT_TIMEOUT, queryTimeout );
 		}
 		Object lockTimeout;
 		if( (lockTimeout = getProperties().get( AvailableSettings.LOCK_TIMEOUT ))!=null){
 			query.setHint( AvailableSettings.LOCK_TIMEOUT, lockTimeout );
 		}
 		return query;
 	}
 
 	private CacheRetrieveMode currentCacheRetrieveMode() {
 		return determineCacheRetrieveMode( properties );
 	}
 
 	private CacheRetrieveMode determineCacheRetrieveMode(Map<String, Object> settings) {
 		return ( CacheRetrieveMode ) settings.get( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE );
 	}
 
 	private CacheStoreMode currentCacheStoreMode() {
 		return determineCacheStoreMode( properties );
 	}
 
 	private CacheStoreMode determineCacheStoreMode(Map<String, Object> settings) {
 		return ( CacheStoreMode ) settings.get( AvailableSettings.SHARED_CACHE_STORE_MODE );
 	}
 
 	private void setLockOptions(Map<String, Object> props, LockOptions options) {
 		Object lockScope = props.get( AvailableSettings.LOCK_SCOPE );
 		if ( lockScope instanceof String && PessimisticLockScope.valueOf( ( String ) lockScope ) == PessimisticLockScope.EXTENDED ) {
 			options.setScope( true );
 		}
 		else if ( lockScope instanceof PessimisticLockScope ) {
 			boolean extended = PessimisticLockScope.EXTENDED.equals( lockScope );
 			options.setScope( extended );
 		}
 		else if ( lockScope != null ) {
 			throw new PersistenceException( "Unable to parse " + AvailableSettings.LOCK_SCOPE + ": " + lockScope );
 		}
 
 		Object lockTimeout = props.get( AvailableSettings.LOCK_TIMEOUT );
 		int timeout = 0;
 		boolean timeoutSet = false;
 		if ( lockTimeout instanceof String ) {
 			timeout = Integer.parseInt( ( String ) lockTimeout );
 			timeoutSet = true;
 		}
 		else if ( lockTimeout instanceof Number ) {
 			timeout = ( (Number) lockTimeout ).intValue();
 			timeoutSet = true;
 		}
 		else if ( lockTimeout != null ) {
 			throw new PersistenceException( "Unable to parse " + AvailableSettings.LOCK_TIMEOUT + ": " + lockTimeout );
 		}
 		if ( timeoutSet ) {
-            if ( timeout == LockOptions.SKIP_LOCKED ) {
-                options.setTimeOut( LockOptions.SKIP_LOCKED );
-            }
+			if ( timeout == LockOptions.SKIP_LOCKED ) {
+				options.setTimeOut( LockOptions.SKIP_LOCKED );
+			}
 			else if ( timeout < 0 ) {
 				options.setTimeOut( LockOptions.WAIT_FOREVER );
 			}
 			else if ( timeout == 0 ) {
 				options.setTimeOut( LockOptions.NO_WAIT );
 			}
 			else {
 				options.setTimeOut( timeout );
 			}
 		}
 	}
 
 	/**
 	 * Sets the default property values for the properties the entity manager supports and which are not already explicitly
 	 * set.
 	 */
 	private void setDefaultProperties() {
 		if ( properties.get( AvailableSettings.FLUSH_MODE ) == null ) {
 			properties.put( AvailableSettings.FLUSH_MODE, getSession().getFlushMode().toString() );
 		}
 		if ( properties.get( AvailableSettings.LOCK_SCOPE ) == null ) {
 			this.properties.put( AvailableSettings.LOCK_SCOPE, PessimisticLockScope.EXTENDED.name() );
 		}
 		if ( properties.get( AvailableSettings.LOCK_TIMEOUT ) == null ) {
 			properties.put( AvailableSettings.LOCK_TIMEOUT, LockOptions.WAIT_FOREVER );
 		}
 		if ( properties.get( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE ) == null ) {
 			properties.put( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE, CacheModeHelper.DEFAULT_RETRIEVE_MODE );
 		}
 		if ( properties.get( AvailableSettings.SHARED_CACHE_STORE_MODE ) == null ) {
 			properties.put( AvailableSettings.SHARED_CACHE_STORE_MODE, CacheModeHelper.DEFAULT_STORE_MODE );
 		}
 	}
 
 	@Override
 	public Query createQuery(String jpaqlString) {
 		checkOpen();
 		try {
 			return applyProperties( new QueryImpl<Object>( internalGetSession().createQuery( jpaqlString ), this ) );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	protected abstract void checkOpen();
 
 	@Override
 	public <T> TypedQuery<T> createQuery(String jpaqlString, Class<T> resultClass) {
 		checkOpen();
 		try {
 			// do the translation
 			org.hibernate.Query hqlQuery = internalGetSession().createQuery( jpaqlString );
 
 			resultClassChecking( resultClass, hqlQuery );
 
 			// finally, build/return the query instance
 			return new QueryImpl<T>( hqlQuery, this );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	protected void resultClassChecking(Class resultClass, org.hibernate.Query hqlQuery) {
 		// make sure the query is a select -> HHH-7192
 		final SessionImplementor session = unwrap( SessionImplementor.class );
 		final HQLQueryPlan queryPlan = session.getFactory().getQueryPlanCache().getHQLQueryPlan(
 				hqlQuery.getQueryString(),
 				false,
 				session.getLoadQueryInfluencers().getEnabledFilters()
 		);
 		if ( queryPlan.getTranslators()[0].isManipulationStatement() ) {
 			throw new IllegalArgumentException( "Update/delete queries cannot be typed" );
 		}
 
 		// do some return type validation checking
 		if ( Object[].class.equals( resultClass ) ) {
 			// no validation needed
 		}
 		else if ( Tuple.class.equals( resultClass ) ) {
 			TupleBuilderTransformer tupleTransformer = new TupleBuilderTransformer( hqlQuery );
 			hqlQuery.setResultTransformer( tupleTransformer  );
 		}
 		else {
 			final Class dynamicInstantiationClass = queryPlan.getDynamicInstantiationResultType();
 			if ( dynamicInstantiationClass != null ) {
 				if ( ! resultClass.isAssignableFrom( dynamicInstantiationClass ) ) {
 					throw new IllegalArgumentException(
 							"Mismatch in requested result type [" + resultClass.getName() +
 									"] and actual result type [" + dynamicInstantiationClass.getName() + "]"
 					);
 				}
 			}
 			else if ( hqlQuery.getReturnTypes().length == 1 ) {
 				// if we have only a single return expression, its java type should match with the requested type
 				if ( !resultClass.isAssignableFrom( hqlQuery.getReturnTypes()[0].getReturnedClass() ) ) {
 					throw new IllegalArgumentException(
 							"Type specified for TypedQuery [" +
 									resultClass.getName() +
 									"] is incompatible with query return type [" +
 									hqlQuery.getReturnTypes()[0].getReturnedClass() + "]"
 					);
 				}
 			}
 			else {
 				throw new IllegalArgumentException(
 						"Cannot create TypedQuery for query with more than one return using requested result type [" +
 								resultClass.getName() + "]"
 				);
 			}
 		}
 	}
 
 	public static class TupleBuilderTransformer extends BasicTransformerAdapter {
 		private List<TupleElement<?>> tupleElements;
 		private Map<String,HqlTupleElementImpl> tupleElementsByAlias;
 
 		public TupleBuilderTransformer(org.hibernate.Query hqlQuery) {
 			final Type[] resultTypes = hqlQuery.getReturnTypes();
 			final int tupleSize = resultTypes.length;
 
 			this.tupleElements = CollectionHelper.arrayList( tupleSize );
 
 			final String[] aliases = hqlQuery.getReturnAliases();
 			final boolean hasAliases = aliases != null && aliases.length > 0;
 			this.tupleElementsByAlias = hasAliases
 					? CollectionHelper.<String, HqlTupleElementImpl>mapOfSize( tupleSize )
 					: Collections.<String, HqlTupleElementImpl>emptyMap();
 
 			for ( int i = 0; i < tupleSize; i++ ) {
 				final HqlTupleElementImpl tupleElement = new HqlTupleElementImpl(
 						i,
 						aliases == null ? null : aliases[i],
 						resultTypes[i]
 				);
 				tupleElements.add( tupleElement );
 				if ( hasAliases ) {
 					final String alias = aliases[i];
 					if ( alias != null ) {
 						tupleElementsByAlias.put( alias, tupleElement );
 					}
 				}
 			}
 		}
 
 		@Override
 		public Object transformTuple(Object[] tuple, String[] aliases) {
 			if ( tuple.length != tupleElements.size() ) {
 				throw new IllegalArgumentException(
 						"Size mismatch between tuple result [" + tuple.length + "] and expected tuple elements [" +
 								tupleElements.size() + "]"
 				);
 			}
 			return new HqlTupleImpl( tuple );
 		}
 
 		public static class HqlTupleElementImpl<X> implements TupleElement<X> {
 			private final int position;
 			private final String alias;
 			private final Type hibernateType;
 
 			public HqlTupleElementImpl(int position, String alias, Type hibernateType) {
 				this.position = position;
 				this.alias = alias;
 				this.hibernateType = hibernateType;
 			}
 
 			@Override
 			public Class getJavaType() {
 				return hibernateType.getReturnedClass();
 			}
 
 			@Override
 			public String getAlias() {
 				return alias;
 			}
 
 			public int getPosition() {
 				return position;
 			}
 
 			public Type getHibernateType() {
 				return hibernateType;
 			}
 		}
 
 		public class HqlTupleImpl implements Tuple {
 			private Object[] tuple;
 
 			public HqlTupleImpl(Object[] tuple) {
 				this.tuple = tuple;
 			}
 
 			@Override
 			public <X> X get(String alias, Class<X> type) {
 				final Object untyped = get( alias );
 				if ( untyped != null ) {
 					if ( ! type.isInstance( untyped ) ) {
 						throw new IllegalArgumentException(
 								String.format(
 										"Requested tuple value [alias=%s, value=%s] cannot be assigned to requested type [%s]",
 										alias,
 										untyped,
 										type.getName()
 								)
 						);
 					}
 				}
 				return (X) untyped;
 			}
 
 			@Override
 			public Object get(String alias) {
 				HqlTupleElementImpl tupleElement = tupleElementsByAlias.get( alias );
 				if ( tupleElement == null ) {
 					throw new IllegalArgumentException( "Unknown alias [" + alias + "]" );
 				}
 				return tuple[ tupleElement.getPosition() ];
 			}
 
 			@Override
 			public <X> X get(int i, Class<X> type) {
 				final Object result = get( i );
 				if ( result != null && ! type.isInstance( result ) ) {
 					throw new IllegalArgumentException(
 							String.format(
 									"Requested tuple value [index=%s, realType=%s] cannot be assigned to requested type [%s]",
 									i,
 									result.getClass().getName(),
 									type.getName()
 							)
 					);
 				}
 				return ( X ) result;
 			}
 
 			@Override
 			public Object get(int i) {
 				if ( i < 0 ) {
 					throw new IllegalArgumentException( "requested tuple index must be greater than zero" );
 				}
 				if ( i > tuple.length ) {
 					throw new IllegalArgumentException( "requested tuple index exceeds actual tuple size" );
 				}
 				return tuple[i];
 			}
 
 			@Override
 			public Object[] toArray() {
 				// todo : make a copy?
 				return tuple;
 			}
 
 			@Override
 			public List<TupleElement<?>> getElements() {
 				return tupleElements;
 			}
 
 			@Override
 			public <X> X get(TupleElement<X> tupleElement) {
 				if ( HqlTupleElementImpl.class.isInstance( tupleElement ) ) {
 					return get( ( (HqlTupleElementImpl) tupleElement ).getPosition(), tupleElement.getJavaType() );
 				}
 				else {
 					return get( tupleElement.getAlias(), tupleElement.getJavaType() );
 				}
 			}
 		}
 	}
 
 	@Override
 	public <T> QueryImpl<T> createQuery(
 			String jpaqlString,
 			Class<T> resultClass,
 			Selection selection,
 			QueryOptions queryOptions) {
 		try {
 			org.hibernate.Query hqlQuery = internalGetSession().createQuery( jpaqlString );
 
 			if ( queryOptions.getValueHandlers() == null ) {
 				if ( queryOptions.getResultMetadataValidator() != null ) {
 					queryOptions.getResultMetadataValidator().validate( hqlQuery.getReturnTypes() );
 				}
 			}
 
 			// determine if we need a result transformer
 			List tupleElements = Tuple.class.equals( resultClass )
 					? ( ( CompoundSelectionImpl<Tuple> ) selection ).getCompoundSelectionItems()
 					: null;
 			if ( queryOptions.getValueHandlers() != null || tupleElements != null ) {
 				hqlQuery.setResultTransformer(
 						new CriteriaQueryTransformer( queryOptions.getValueHandlers(), tupleElements )
 				);
 			}
 			return new QueryImpl<T>( hqlQuery, this, queryOptions.getNamedParameterExplicitTypes() );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	private static class CriteriaQueryTransformer extends BasicTransformerAdapter {
 		private final List<ValueHandlerFactory.ValueHandler> valueHandlers;
 		private final List tupleElements;
 
 		private CriteriaQueryTransformer(List<ValueHandlerFactory.ValueHandler> valueHandlers, List tupleElements) {
 			// todo : should these 2 sizes match *always*?
 			this.valueHandlers = valueHandlers;
 			this.tupleElements = tupleElements;
 		}
 
 		@Override
 		public Object transformTuple(Object[] tuple, String[] aliases) {
 			final Object[] valueHandlerResult;
 			if ( valueHandlers == null ) {
 				valueHandlerResult = tuple;
 			}
 			else {
 				valueHandlerResult = new Object[tuple.length];
 				for ( int i = 0; i < tuple.length; i++ ) {
 					ValueHandlerFactory.ValueHandler valueHandler = valueHandlers.get( i );
 					valueHandlerResult[i] = valueHandler == null
 							? tuple[i]
 							: valueHandler.convert( tuple[i] );
 				}
 			}
 
 			return tupleElements == null
 					? valueHandlerResult.length == 1 ? valueHandlerResult[0] : valueHandlerResult
 					: new TupleImpl( tuple );
 
 		}
 
 		private class TupleImpl implements Tuple {
 			private final Object[] tuples;
 
 			private TupleImpl(Object[] tuples) {
 				if ( tuples.length != tupleElements.size() ) {
 					throw new IllegalArgumentException(
 							"Size mismatch between tuple result [" + tuples.length
 									+ "] and expected tuple elements [" + tupleElements.size() + "]"
 					);
 				}
 				this.tuples = tuples;
 			}
 
 			public <X> X get(TupleElement<X> tupleElement) {
 				int index = tupleElements.indexOf( tupleElement );
 				if ( index < 0 ) {
 					throw new IllegalArgumentException(
 							"Requested tuple element did not correspond to element in the result tuple"
 					);
 				}
 				// index should be "in range" by nature of size check in ctor
 				return ( X ) tuples[index];
 			}
 
 			public Object get(String alias) {
 				int index = -1;
 				if ( alias != null ) {
 					alias = alias.trim();
 					if ( alias.length() > 0 ) {
 						int i = 0;
 						for ( TupleElement selection : ( List<TupleElement> ) tupleElements ) {
 							if ( alias.equals( selection.getAlias() ) ) {
 								index = i;
 								break;
 							}
 							i++;
 						}
 					}
 				}
 				if ( index < 0 ) {
 					throw new IllegalArgumentException(
 							"Given alias [" + alias + "] did not correspond to an element in the result tuple"
 					);
 				}
 				// index should be "in range" by nature of size check in ctor
 				return tuples[index];
 			}
 
 			public <X> X get(String alias, Class<X> type) {
 				final Object untyped = get( alias );
 				if ( untyped != null ) {
 					if ( ! type.isInstance( untyped ) ) {
 						throw new IllegalArgumentException(
 								String.format(
 										"Requested tuple value [alias=%s, value=%s] cannot be assigned to requested type [%s]",
 										alias,
 										untyped,
 										type.getName()
 								)
 						);
 					}
 				}
 				return (X) untyped;
 			}
 
 			public Object get(int i) {
 				if ( i >= tuples.length ) {
 					throw new IllegalArgumentException(
 							"Given index [" + i + "] was outside the range of result tuple size [" + tuples.length + "] "
 					);
 				}
 				return tuples[i];
 			}
 
 			public <X> X get(int i, Class<X> type) {
 				final Object result = get( i );
 				if ( result != null && ! type.isInstance( result ) ) {
 					throw new IllegalArgumentException(
 							String.format(
 									"Requested tuple value [index=%s, realType=%s] cannot be assigned to requested type [%s]",
 									i,
 									result.getClass().getName(),
 									type.getName()
 							)
 					);
 				}
 				return ( X ) result;
 			}
 
 			public Object[] toArray() {
 				return tuples;
 			}
 
 			public List<TupleElement<?>> getElements() {
 				return tupleElements;
 			}
 		}
 	}
 
 	private CriteriaCompiler criteriaCompiler;
 
 	protected CriteriaCompiler criteriaCompiler() {
 		if ( criteriaCompiler == null ) {
 			criteriaCompiler = new CriteriaCompiler( this );
 		}
 		return criteriaCompiler;
 	}
 
 	@Override
 	public <T> TypedQuery<T> createQuery(CriteriaQuery<T> criteriaQuery) {
 		checkOpen();
 		try {
 			return (TypedQuery<T>) criteriaCompiler().compile( (CompilableCriteria) criteriaQuery );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public Query createQuery(CriteriaUpdate criteriaUpdate) {
 		checkOpen();
 		try {
 			return criteriaCompiler().compile( (CompilableCriteria) criteriaUpdate );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public Query createQuery(CriteriaDelete criteriaDelete) {
 		checkOpen();
 		try {
 			return criteriaCompiler().compile( (CompilableCriteria) criteriaDelete );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public Query createNamedQuery(String name) {
 		return buildQueryFromName( name, null );
 	}
 
 	private QueryImpl buildQueryFromName(String name, Class resultType) {
 		checkOpen();
 
 		// we can't just call Session#getNamedQuery because we need to apply stored setting at the JPA Query
 		// level too
 
 		final SessionFactoryImplementor sfi = entityManagerFactory.getSessionFactory();
 
 		final NamedQueryDefinition jpqlDefinition = sfi.getNamedQueryRepository().getNamedQueryDefinition( name );
 		if ( jpqlDefinition != null ) {
 			return createNamedJpqlQuery( jpqlDefinition, resultType );
 		}
 
 		final NamedSQLQueryDefinition nativeQueryDefinition = sfi.getNamedQueryRepository().getNamedSQLQueryDefinition(	name );
 		if ( nativeQueryDefinition != null ) {
 			return createNamedSqlQuery( nativeQueryDefinition, resultType );
 		}
 
 		throw convert( new IllegalArgumentException( "No query defined for that name [" + name + "]" ) );
 	}
 
 	protected QueryImpl createNamedJpqlQuery(NamedQueryDefinition namedQueryDefinition, Class resultType) {
 		final org.hibernate.Query hibQuery = ( (SessionImplementor) internalGetSession() ).createQuery( namedQueryDefinition );
 		if ( resultType != null ) {
 			resultClassChecking( resultType, hibQuery );
 		}
 
 		return wrapAsJpaQuery( namedQueryDefinition, hibQuery );
 	}
 
 	protected QueryImpl wrapAsJpaQuery(NamedQueryDefinition namedQueryDefinition, org.hibernate.Query hibQuery) {
 		try {
 			final QueryImpl jpaQuery = new QueryImpl( hibQuery, this );
 			applySavedSettings( namedQueryDefinition, jpaQuery );
 			return jpaQuery;
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	protected void applySavedSettings(NamedQueryDefinition namedQueryDefinition, QueryImpl jpaQuery) {
 		if ( namedQueryDefinition.isCacheable() ) {
 			jpaQuery.setHint( QueryHints.HINT_CACHEABLE, true );
 			if ( namedQueryDefinition.getCacheRegion() != null ) {
 				jpaQuery.setHint( QueryHints.HINT_CACHE_REGION, namedQueryDefinition.getCacheRegion() );
 			}
 		}
 
 		if ( namedQueryDefinition.getCacheMode() != null ) {
 			jpaQuery.setHint( QueryHints.HINT_CACHE_MODE, namedQueryDefinition.getCacheMode() );
 		}
 
 		if ( namedQueryDefinition.isReadOnly() ) {
 			jpaQuery.setHint( QueryHints.HINT_READONLY, true );
 		}
 
 		if ( namedQueryDefinition.getTimeout() != null ) {
 			jpaQuery.setHint( QueryHints.SPEC_HINT_TIMEOUT, namedQueryDefinition.getTimeout() * 1000 );
 		}
 
 		if ( namedQueryDefinition.getFetchSize() != null ) {
 			jpaQuery.setHint( QueryHints.HINT_FETCH_SIZE, namedQueryDefinition.getFetchSize() );
 		}
 
 		if ( namedQueryDefinition.getComment() != null ) {
 			jpaQuery.setHint( QueryHints.HINT_COMMENT, namedQueryDefinition.getComment() );
 		}
 
 		if ( namedQueryDefinition.getFirstResult() != null ) {
 			jpaQuery.setFirstResult( namedQueryDefinition.getFirstResult() );
 		}
 
 		if ( namedQueryDefinition.getMaxResults() != null ) {
 			jpaQuery.setMaxResults( namedQueryDefinition.getMaxResults() );
 		}
 
 		if ( namedQueryDefinition.getLockOptions() != null ) {
 			if ( namedQueryDefinition.getLockOptions().getLockMode() != null ) {
 				jpaQuery.setLockMode(
 						LockModeTypeHelper.getLockModeType( namedQueryDefinition.getLockOptions().getLockMode() )
 				);
 			}
 		}
 
 		if ( namedQueryDefinition.getFlushMode() != null ) {
 			if ( namedQueryDefinition.getFlushMode() == FlushMode.COMMIT ) {
 				jpaQuery.setFlushMode( FlushModeType.COMMIT );
 			}
 			else {
 				jpaQuery.setFlushMode( FlushModeType.AUTO );
 			}
 		}
 	}
 
 	protected QueryImpl createNamedSqlQuery(NamedSQLQueryDefinition namedQueryDefinition, Class resultType) {
 		if ( resultType != null ) {
 			resultClassChecking( resultType, namedQueryDefinition );
 		}
 		return wrapAsJpaQuery(
 				namedQueryDefinition,
 				( (SessionImplementor) internalGetSession() ).createSQLQuery( namedQueryDefinition )
 		);
 	}
 
 	protected void resultClassChecking(Class resultType, NamedSQLQueryDefinition namedQueryDefinition) {
 		final SessionFactoryImplementor sfi = entityManagerFactory.getSessionFactory();
 
 		final NativeSQLQueryReturn[] queryReturns;
 		if ( namedQueryDefinition.getQueryReturns() != null ) {
 			queryReturns = namedQueryDefinition.getQueryReturns();
 		}
 		else if ( namedQueryDefinition.getResultSetRef() != null ) {
 			final ResultSetMappingDefinition rsMapping = sfi.getResultSetMapping( namedQueryDefinition.getResultSetRef() );
 			queryReturns = rsMapping.getQueryReturns();
 		}
 		else {
 			throw new AssertionFailure( "Unsupported named query model. Please report the bug in Hibernate EntityManager");
 		}
 
 		if ( queryReturns.length > 1 ) {
 			throw new IllegalArgumentException( "Cannot create TypedQuery for query with more than one return" );
 		}
 
 		final NativeSQLQueryReturn nativeSQLQueryReturn = queryReturns[0];
 
 		if ( nativeSQLQueryReturn instanceof NativeSQLQueryRootReturn ) {
 			final Class<?> actualReturnedClass;
 			final String entityClassName = ( (NativeSQLQueryRootReturn) nativeSQLQueryReturn ).getReturnEntityName();
 			try {
 				actualReturnedClass = sfi.getServiceRegistry().getService( ClassLoaderService.class ).classForName( entityClassName );
 			}
 			catch ( ClassLoadingException e ) {
 				throw new AssertionFailure(
 						"Unable to load class [" + entityClassName + "] declared on named native query [" +
 								namedQueryDefinition.getName() + "]"
 				);
 			}
 			if ( !resultType.isAssignableFrom( actualReturnedClass ) ) {
 				throw buildIncompatibleException( resultType, actualReturnedClass );
 			}
 		}
 		else if ( nativeSQLQueryReturn instanceof NativeSQLQueryConstructorReturn ) {
 			final NativeSQLQueryConstructorReturn ctorRtn = (NativeSQLQueryConstructorReturn) nativeSQLQueryReturn;
 			if ( !resultType.isAssignableFrom( ctorRtn.getTargetClass() ) ) {
 				throw buildIncompatibleException( resultType, ctorRtn.getTargetClass() );
 			}
 		}
 		else {
 			//TODO support other NativeSQLQueryReturn type. For now let it go.
 		}
 	}
 
 	@Override
 	public <T> TypedQuery<T> createNamedQuery(String name, Class<T> resultClass) {
 		return buildQueryFromName( name, resultClass );
 	}
 
 	private IllegalArgumentException buildIncompatibleException(Class<?> resultClass, Class<?> actualResultClass) {
 		return new IllegalArgumentException(
 				"Type specified for TypedQuery [" + resultClass.getName() +
 						"] is incompatible with query return type [" + actualResultClass + "]"
 		);
 	}
 
 	@Override
 	public Query createNativeQuery(String sqlString) {
 		checkOpen();
 		try {
 			SQLQuery q = internalGetSession().createSQLQuery( sqlString );
 			return new QueryImpl( q, this );
 		}
 		catch ( RuntimeException he ) {
 			throw convert( he );
 		}
 	}
 
 	@Override
 	public Query createNativeQuery(String sqlString, Class resultClass) {
 		checkOpen();
 		try {
 			SQLQuery q = internalGetSession().createSQLQuery( sqlString );
 			q.addEntity( "alias1", resultClass.getName(), LockMode.READ );
 			return new QueryImpl( q, this );
 		}
 		catch ( RuntimeException he ) {
 			throw convert( he );
 		}
 	}
 
 	@Override
 	public Query createNativeQuery(String sqlString, String resultSetMapping) {
 		checkOpen();
 		try {
 			final SQLQuery q = internalGetSession().createSQLQuery( sqlString );
 			q.setResultSetMapping( resultSetMapping );
 			return new QueryImpl( q, this );
 		}
 		catch ( RuntimeException he ) {
 			throw convert( he );
 		}
 	}
 
 	@Override
 	public StoredProcedureQuery createNamedStoredProcedureQuery(String name) {
 		checkOpen();
 		try {
 			final ProcedureCallMemento memento = ( (SessionImplementor) internalGetSession() ).getFactory()
 					.getNamedQueryRepository().getNamedProcedureCallMemento( name );
 			if ( memento == null ) {
 				throw new IllegalArgumentException( "No @NamedStoredProcedureQuery was found with that name : " + name );
 			}
 			final StoredProcedureQueryImpl jpaImpl = new StoredProcedureQueryImpl( memento, this );
 			// apply hints
 			if ( memento.getHintsMap() != null ) {
 				for ( Map.Entry<String,Object> hintEntry : memento.getHintsMap().entrySet() ) {
 					jpaImpl.setHint( hintEntry.getKey(), hintEntry.getValue() );
 				}
 			}
 			return jpaImpl;
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public StoredProcedureQuery createStoredProcedureQuery(String procedureName) {
 		checkOpen();
 		try {
 			return new StoredProcedureQueryImpl(
 					internalGetSession().createStoredProcedureCall( procedureName ),
 					this
 			);
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public StoredProcedureQuery createStoredProcedureQuery(String procedureName, Class... resultClasses) {
 		checkOpen();
 		try {
 			return new StoredProcedureQueryImpl(
 					internalGetSession().createStoredProcedureCall( procedureName, resultClasses ),
 					this
 			);
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public StoredProcedureQuery createStoredProcedureQuery(String procedureName, String... resultSetMappings) {
 		checkOpen();
 		try {
 			try {
 				return new StoredProcedureQueryImpl(
 						internalGetSession().createStoredProcedureCall( procedureName, resultSetMappings ),
 						this
 				);
 			}
 			catch (UnknownSqlResultSetMappingException unknownResultSetMapping) {
 				throw new IllegalArgumentException( unknownResultSetMapping.getMessage(), unknownResultSetMapping );
 			}
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <T> T getReference(Class<T> entityClass, Object primaryKey) {
 		checkOpen();
 		try {
 			return ( T ) internalGetSession().load( entityClass, ( Serializable ) primaryKey );
 		}
 		catch ( MappingException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( TypeMismatchException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( ClassCastException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <A> A find(Class<A> entityClass, Object primaryKey) {
 		checkOpen();
 		return find( entityClass, primaryKey, null, null );
 	}
 
 	@Override
 	public <T> T find(Class<T> entityClass, Object primaryKey, Map<String, Object> properties) {
 		checkOpen();
 		return find( entityClass, primaryKey, null, properties );
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <A> A find(Class<A> entityClass, Object primaryKey, LockModeType lockModeType) {
 		checkOpen();
 		return find( entityClass, primaryKey, lockModeType, null );
 	}
 
 	@Override
 	public <A> A find(Class<A> entityClass, Object primaryKey, LockModeType lockModeType, Map<String, Object> properties) {
 		checkOpen();
 		Session session = internalGetSession();
 		CacheMode previousCacheMode = session.getCacheMode();
 		CacheMode cacheMode = determineAppropriateLocalCacheMode( properties );
 		LockOptions lockOptions = null;
 		try {
 			if ( properties != null && !properties.isEmpty() ) {
 				( (SessionImplementor) session ).getLoadQueryInfluencers()
 						.setFetchGraph( (EntityGraph) properties.get( QueryHints.HINT_FETCHGRAPH ) );
 				( (SessionImplementor) session ).getLoadQueryInfluencers()
 						.setLoadGraph( (EntityGraph) properties.get( QueryHints.HINT_LOADGRAPH ) );
 			}
 			session.setCacheMode( cacheMode );
 			if ( lockModeType != null ) {
 				lockOptions = getLockRequest( lockModeType, properties );
 				if ( !LockModeType.NONE.equals( lockModeType) ) {
 					checkTransactionNeeded();
 				}
 				return ( A ) session.get(
 						entityClass, ( Serializable ) primaryKey, 
 						lockOptions
 				);
 			}
 			else {
 				return ( A ) session.get( entityClass, ( Serializable ) primaryKey );
 			}
 		}
 		catch ( EntityNotFoundException ignored ) {
 			// DefaultLoadEventListener.returnNarrowedProxy may throw ENFE (see HHH-7861 for details),
 			// which find() should not throw.  Find() should return null if the entity was not found.
 			if ( LOG.isDebugEnabled() ) {
 				String entityName = entityClass != null ? entityClass.getName(): null;
 				String identifierValue = primaryKey != null ? primaryKey.toString() : null ;
 				LOG.ignoringEntityNotFound( entityName, identifierValue );
 			}
 			return null;
 		}
 		catch ( ObjectDeletedException e ) {
 			//the spec is silent about people doing remove() find() on the same PC
 			return null;
 		}
 		catch ( ObjectNotFoundException e ) {
 			//should not happen on the entity itself with get
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch ( MappingException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( TypeMismatchException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( ClassCastException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e, lockOptions );
 		}
 		finally {
 			session.setCacheMode( previousCacheMode );
 			( (SessionImplementor) session ).getLoadQueryInfluencers().setFetchGraph( null );
 			( (SessionImplementor) session ).getLoadQueryInfluencers().setLoadGraph( null );
 
 		}
 	}
 
 	public CacheMode determineAppropriateLocalCacheMode(Map<String, Object> localProperties) {
 		CacheRetrieveMode retrieveMode = null;
 		CacheStoreMode storeMode = null;
 		if ( localProperties != null ) {
 			retrieveMode = determineCacheRetrieveMode( localProperties );
 			storeMode = determineCacheStoreMode( localProperties );
 		}
 		if ( retrieveMode == null ) {
 			// use the EM setting
 			retrieveMode = determineCacheRetrieveMode( this.properties );
 		}
 		if ( storeMode == null ) {
 			// use the EM setting
 			storeMode = determineCacheStoreMode( this.properties );
 		}
 		return CacheModeHelper.interpretCacheMode( storeMode, retrieveMode );
 	}
 
 	private void checkTransactionNeeded() {
 		if ( !isTransactionInProgress() ) {
 			throw new TransactionRequiredException(
 					"no transaction is in progress"
 			);
 		}
 	}
 
 	@Override
 	public void persist(Object entity) {
 		checkOpen();
 		try {
 			internalGetSession().persist( entity );
 		}
 		catch ( MappingException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage() ) ) ;
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <A> A merge(A entity) {
 		checkOpen();
 		try {
 			return ( A ) internalGetSession().merge( entity );
 		}
 		catch ( ObjectDeletedException sse ) {
 			throw convert( new IllegalArgumentException( sse ) );
 		}
 		catch ( MappingException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( RuntimeException e ) {
 			//including HibernateException
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public void remove(Object entity) {
 		checkOpen();
 		try {
 			internalGetSession().delete( entity );
 		}
 		catch ( MappingException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( RuntimeException e ) {
 			//including HibernateException
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public void refresh(Object entity) {
 		refresh( entity, null, null );
 	}
 
 	@Override
 	public void refresh(Object entity, Map<String, Object> properties) {
 		refresh( entity, null, properties );
 	}
 
 	@Override
 	public void refresh(Object entity, LockModeType lockModeType) {
 		refresh( entity, lockModeType, null );
 	}
 
 	@Override
 	public void refresh(Object entity, LockModeType lockModeType, Map<String, Object> properties) {
 		checkOpen();
 
 		final Session session = internalGetSession();
 		final CacheMode previousCacheMode = session.getCacheMode();
 		final CacheMode localCacheMode = determineAppropriateLocalCacheMode( properties );
 		LockOptions lockOptions = null;
 		try {
 			session.setCacheMode( localCacheMode );
 			if ( !session.contains( entity ) ) {
 				throw convert ( new IllegalArgumentException( "Entity not managed" ) );
 			}
 			if ( lockModeType != null ) {
 				if ( !LockModeType.NONE.equals( lockModeType) ) {
 					checkTransactionNeeded();
 				}
 
 				lockOptions = getLockRequest( lockModeType, properties );
 				session.refresh( entity, lockOptions );
 			}
 			else {
 				session.refresh( entity );
 			}
 		}
 		catch (MappingException e) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch (RuntimeException e) {
 			throw convert( e, lockOptions );
 		}
 		finally {
 			session.setCacheMode( previousCacheMode );
 		}
 	}
 
 	@Override
 	public boolean contains(Object entity) {
 		checkOpen();
 
 		try {
 			if ( entity != null
 					&& !( entity instanceof HibernateProxy )
 					&& internalGetSession().getSessionFactory().getClassMetadata( entity.getClass() ) == null ) {
 				throw convert( new IllegalArgumentException( "Not an entity:" + entity.getClass() ) );
 			}
 			return internalGetSession().contains( entity );
 		}
 		catch (MappingException e) {
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch (RuntimeException e) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public LockModeType getLockMode(Object entity) {
 		checkOpen();
 
 		if ( !isTransactionInProgress() ) {
 			throw new TransactionRequiredException( "Call to EntityManager#getLockMode should occur within transaction according to spec" );
 		}
 
 		if ( !contains( entity ) ) {
 			throw convert( new IllegalArgumentException( "entity not in the persistence context" ) );
 		}
 
 		return getLockModeType( internalGetSession().getCurrentLockMode( entity ) );
 	}
 
 	@Override
 	public void setProperty(String s, Object o) {
 		checkOpen();
 
 		if ( ENTITY_MANAGER_SPECIFIC_PROPERTIES.contains( s ) ) {
 			properties.put( s, o );
 			applyProperties();
-        }
+		}
 		else {
 			LOG.debugf("Trying to set a property which is not supported on entity manager level");
 		}
 	}
 
 	@Override
 	public Map<String, Object> getProperties() {
 		return Collections.unmodifiableMap( properties );
 	}
 
 	@Override
 	public void flush() {
 		checkOpen();
 		checkTransactionNeeded();
 
 		try {
 			internalGetSession().flush();
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	/**
 	 * return a Session
 	 *
 	 * @throws IllegalStateException if the entity manager is closed
 	 */
 	public abstract Session getSession();
 
 	/**
 	 * Return a Session (even if the entity manager is closed).
 	 *
 	 * @return A session.
 	 * @deprecated Deprecated in favor of {@link #getRawSession()}
 	 */
 	@Deprecated
 	protected abstract Session getRawSession();
 
 	/**
 	 * Return a Session without any validation checks.
 	 *
 	 * @return A session.
 	 */
 	protected abstract Session internalGetSession();
 
 	@Override
 	public EntityTransaction getTransaction() {
 		if ( transactionType == PersistenceUnitTransactionType.JTA ) {
 			throw new IllegalStateException( "A JTA EntityManager cannot use getTransaction()" );
 		}
 		return tx;
 	}
 
 	@Override
 	public EntityManagerFactoryImpl getEntityManagerFactory() {
 		checkOpen();
 		return internalGetEntityManagerFactory();
 	}
 
 	protected EntityManagerFactoryImpl internalGetEntityManagerFactory() {
 		return entityManagerFactory;
 	}
 
 	@Override
 	public HibernateEntityManagerFactory getFactory() {
 		return entityManagerFactory;
 	}
 
 	@Override
 	public CriteriaBuilder getCriteriaBuilder() {
 
 		checkOpen();
 		return getEntityManagerFactory().getCriteriaBuilder();
 	}
 
 	@Override
 	public Metamodel getMetamodel() {
 		checkOpen();
 		return getEntityManagerFactory().getMetamodel();
 	}
 
 	@Override
 	public void setFlushMode(FlushModeType flushModeType) {
 		checkOpen();
 		if ( flushModeType == FlushModeType.AUTO ) {
 			internalGetSession().setFlushMode( FlushMode.AUTO );
 		}
 		else if ( flushModeType == FlushModeType.COMMIT ) {
 			internalGetSession().setFlushMode( FlushMode.COMMIT );
 		}
 		else {
 			throw new AssertionFailure( "Unknown FlushModeType: " + flushModeType );
 		}
 	}
 
 	@Override
 	public void clear() {
 		checkOpen();
 		try {
 			internalGetSession().clear();
 		}
 		catch (RuntimeException e) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public void detach(Object entity) {
 		checkOpen();
 		try {
 			internalGetSession().evict( entity );
 		}
 		catch (RuntimeException e) {
 			throw convert( e );
 		}
 	}
 
 	/**
 	 * Hibernate can be set in various flush modes that are unknown to
 	 * JPA 2.0. This method can then return null.
 	 * If it returns null, do em.unwrap(Session.class).getFlushMode() to get the
 	 * Hibernate flush mode
 	 */
 	@Override
 	public FlushModeType getFlushMode() {
 		checkOpen();
 
 		FlushMode mode = internalGetSession().getFlushMode();
 		if ( mode == FlushMode.AUTO ) {
 			return FlushModeType.AUTO;
 		}
 		else if ( mode == FlushMode.COMMIT ) {
 			return FlushModeType.COMMIT;
 		}
 		else {
 			// otherwise this is an unknown mode for EJB3
 			return null;
 		}
 	}
 
 	public void lock(Object entity, LockModeType lockMode) {
 		lock( entity, lockMode, null );
 	}
 
 	public void lock(Object entity, LockModeType lockModeType, Map<String, Object> properties) {
 		checkOpen();
 		checkTransactionNeeded();
 
 		LockOptions lockOptions = null;
 
 		try {
 			if ( !contains( entity ) ) {
 				throw new IllegalArgumentException( "entity not in the persistence context" );
 			}
 			lockOptions = getLockRequest( lockModeType, properties );
 			internalGetSession().buildLockRequest( lockOptions ).lock( entity );
 		}
 		catch (RuntimeException e) {
 			throw convert( e, lockOptions );
 		}
 	}
 
 	public LockOptions getLockRequest(LockModeType lockModeType, Map<String, Object> properties) {
 		LockOptions lockOptions = new LockOptions();
 		LockOptions.copy( this.lockOptions, lockOptions );
 		lockOptions.setLockMode( getLockMode( lockModeType ) );
 		if ( properties != null ) {
 			setLockOptions( properties, lockOptions );
 		}
 		return lockOptions;
 	}
 
 	@SuppressWarnings("deprecation")
 	private static LockModeType getLockModeType(LockMode lockMode) {
 		//TODO check that if we have UPGRADE_NOWAIT we have a timeout of zero?
 		return LockModeTypeHelper.getLockModeType( lockMode );
 	}
 
 
 	private static LockMode getLockMode(LockModeType lockMode) {
 		return LockModeTypeHelper.getLockMode( lockMode );
 	}
 
 	public boolean isTransactionInProgress() {
 		return ( ( SessionImplementor ) internalGetSession() ).isTransactionInProgress();
 	}
 
 	private SessionFactoryImplementor sfi() {
 		return (SessionFactoryImplementor) internalGetSession().getSessionFactory();
 	}
 
 	@Override
 	public <T> T unwrap(Class<T> clazz) {
 		checkOpen();
 
 		if ( Session.class.isAssignableFrom( clazz ) ) {
 			return ( T ) internalGetSession();
 		}
 		if ( SessionImplementor.class.isAssignableFrom( clazz ) ) {
 			return ( T ) internalGetSession();
 		}
 		if ( EntityManager.class.isAssignableFrom( clazz ) ) {
 			return ( T ) this;
 		}
 		throw new PersistenceException( "Hibernate cannot unwrap " + clazz );
 	}
 
 	@Override
 	public void markForRollbackOnly() {
-        LOG.debugf("Mark transaction for rollback");
+		LOG.debugf("Mark transaction for rollback");
 		if ( tx.isActive() ) {
 			tx.setRollbackOnly();
 		}
 		else {
 			//no explicit use of the tx. boundaries methods
 			if ( PersistenceUnitTransactionType.JTA == transactionType ) {
 				TransactionManager transactionManager = sfi().getServiceRegistry().getService( JtaPlatform.class ).retrieveTransactionManager();
 				if ( transactionManager == null ) {
 					throw new PersistenceException(
 							"Using a JTA persistence context wo setting hibernate.transaction.jta.platform"
 					);
 				}
 				try {
 					if ( transactionManager.getStatus() != Status.STATUS_NO_TRANSACTION ) {
 						transactionManager.setRollbackOnly();
 					}
 				}
 				catch (SystemException e) {
 					throw new PersistenceException( "Unable to set the JTA transaction as RollbackOnly", e );
 				}
 			}
 		}
 	}
 
 	@Override
 	public boolean isJoinedToTransaction() {
 		checkOpen();
 
 		final SessionImplementor session = (SessionImplementor) internalGetSession();
 		return isOpen() && session.getTransactionCoordinator().isJoined();
 	}
 
 	@Override
 	public void joinTransaction() {
 		checkOpen();
 		joinTransaction( true );
 	}
 
 	private void joinTransaction(boolean explicitRequest) {
 		if ( transactionType != PersistenceUnitTransactionType.JTA ) {
 			if ( explicitRequest ) {
 				LOG.callingJoinTransactionOnNonJtaEntityManager();
 			}
 			return;
 		}
 
 		try {
 			final TransactionCoordinator transactionCoordinator = ((SessionImplementor) internalGetSession()).getTransactionCoordinator();
 			transactionCoordinator.explicitJoin();
 		}
 		catch (HibernateException he) {
 			throw convert( he );
 		}
 	}
 
 	/**
 	 * returns the underlying session
 	 */
 	public Object getDelegate() {
 		checkOpen();
 		return internalGetSession();
 	}
 
 	private void writeObject(ObjectOutputStream oos) throws IOException {
 		oos.defaultWriteObject();
 	}
 
 	private void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException {
 		ois.defaultReadObject();
 		tx = new TransactionImpl( this );
 	}
 
 	@Override
 	public void handlePersistenceException(PersistenceException e) {
 		if ( e instanceof NoResultException ) {
 			return;
 		}
 		if ( e instanceof NonUniqueResultException ) {
 			return;
 		}
 		if ( e instanceof LockTimeoutException ) {
 			return;
 		}
 		if ( e instanceof QueryTimeoutException ) {
 			return;
 		}
 
 		try {
 			markForRollbackOnly();
 		}
 		catch ( Exception ne ) {
 			//we do not want the subsequent exception to swallow the original one
-            LOG.unableToMarkForRollbackOnPersistenceException(ne);
+			LOG.unableToMarkForRollbackOnPersistenceException(ne);
 		}
 	}
 
 	@Override
 	public void throwPersistenceException(PersistenceException e) {
 		handlePersistenceException( e );
 		throw e;
 	}
 
 	@Override
 	public RuntimeException convert(HibernateException e) {
 		//FIXME should we remove all calls to this method and use convert(RuntimeException) ?
 		return convert( e, null );
 	}
 
 	public RuntimeException convert(RuntimeException e) {
 		RuntimeException result = e;
 		if ( e instanceof HibernateException ) {
 			result = convert( (HibernateException) e );
 		}
 		else {
 			markForRollbackOnly();
 		}
 		return result;
 	}
 
 	public RuntimeException convert(RuntimeException e, LockOptions lockOptions) {
 		RuntimeException result = e;
 		if ( e instanceof HibernateException ) {
 			result = convert( (HibernateException) e , lockOptions );
 		}
 		else {
 			markForRollbackOnly();
 		}
 		return result;
 	}
 
 	@Override
 	public RuntimeException convert(HibernateException e, LockOptions lockOptions) {
 		Throwable cause = e;
 		if(e instanceof TransactionException){
 			cause = e.getCause();
 		}
 		if ( cause instanceof StaleStateException ) {
 			final PersistenceException converted = wrapStaleStateException( (StaleStateException) cause );
 			handlePersistenceException( converted );
 			return converted;
 		}
 		else if ( cause instanceof LockingStrategyException ) {
 			final PersistenceException converted = wrapLockException( (HibernateException) cause, lockOptions );
 			handlePersistenceException( converted );
 			return converted;
 		}
 		else if ( cause instanceof org.hibernate.exception.LockTimeoutException ) {
 			final PersistenceException converted = wrapLockException( (HibernateException) cause, lockOptions );
 			handlePersistenceException( converted );
 			return converted;
 		}
 		else if ( cause instanceof org.hibernate.PessimisticLockException ) {
 			final PersistenceException converted = wrapLockException( (HibernateException) cause, lockOptions );
 			handlePersistenceException( converted );
 			return converted;
 		}
 		else if ( cause instanceof org.hibernate.QueryTimeoutException ) {
 			final QueryTimeoutException converted = new QueryTimeoutException( cause.getMessage(), cause );
 			handlePersistenceException( converted );
 			return converted;
 		}
 		else if ( cause instanceof ObjectNotFoundException ) {
 			final EntityNotFoundException converted = new EntityNotFoundException( cause.getMessage() );
 			handlePersistenceException( converted );
 			return converted;
 		}
 		else if ( cause instanceof org.hibernate.NonUniqueObjectException ) {
 			final EntityExistsException converted = new EntityExistsException( cause.getMessage() );
 			handlePersistenceException( converted );
 			return converted;
-        }
+		}
 		else if ( cause instanceof org.hibernate.NonUniqueResultException ) {
 			final NonUniqueResultException converted = new NonUniqueResultException( cause.getMessage() );
 			handlePersistenceException( converted );
 			return converted;
 		}
 		else if ( cause instanceof UnresolvableObjectException ) {
 			final EntityNotFoundException converted = new EntityNotFoundException( cause.getMessage() );
 			handlePersistenceException( converted );
 			return converted;
 		}
 		else if ( cause instanceof QueryException ) {
 			return new IllegalArgumentException( cause );
 		}
 		else if ( cause instanceof TransientObjectException ) {
 			try {
 				markForRollbackOnly();
 			}
 			catch ( Exception ne ) {
 				//we do not want the subsequent exception to swallow the original one
 				LOG.unableToMarkForRollbackOnTransientObjectException( ne );
 			}
 			return new IllegalStateException( e ); //Spec 3.2.3 Synchronization rules
 		}
 		else {
 			final PersistenceException converted = new PersistenceException( cause );
 			handlePersistenceException( converted );
 			return converted;
 		}
 	}
 
 	@Override
 	public void throwPersistenceException(HibernateException e) {
 		throw convert( e );
 	}
 
 	@Override
 	public PersistenceException wrapStaleStateException(StaleStateException e) {
 		PersistenceException pe;
 		if ( e instanceof StaleObjectStateException ) {
 			final StaleObjectStateException sose = (StaleObjectStateException) e;
 			final Serializable identifier = sose.getIdentifier();
 			if ( identifier != null ) {
 				try {
 					final Object entity = internalGetSession().load( sose.getEntityName(), identifier );
 					if ( entity instanceof Serializable ) {
 						//avoid some user errors regarding boundary crossing
 						pe = new OptimisticLockException( e.getMessage(), e, entity );
 					}
 					else {
 						pe = new OptimisticLockException( e.getMessage(), e );
 					}
 				}
 				catch ( EntityNotFoundException enfe ) {
 					pe = new OptimisticLockException( e.getMessage(), e );
 				}
 			}
 			else {
 				pe = new OptimisticLockException( e.getMessage(), e );
 			}
 		}
 		else {
 			pe = new OptimisticLockException( e.getMessage(), e );
 		}
 		return pe;
 	}
 
 	public PersistenceException wrapLockException(HibernateException e, LockOptions lockOptions) {
 		final PersistenceException pe;
 		if ( e instanceof OptimisticEntityLockException ) {
 			final OptimisticEntityLockException lockException = (OptimisticEntityLockException) e;
 			pe = new OptimisticLockException( lockException.getMessage(), lockException, lockException.getEntity() );
 		}
 		else if ( e instanceof org.hibernate.exception.LockTimeoutException ) {
 			pe = new LockTimeoutException( e.getMessage(), e, null );
 		}
 		else if ( e instanceof PessimisticEntityLockException ) {
 			final PessimisticEntityLockException lockException = (PessimisticEntityLockException) e;
 			if ( lockOptions != null && lockOptions.getTimeOut() > -1 ) {
 				// assume lock timeout occurred if a timeout or NO WAIT was specified
 				pe = new LockTimeoutException( lockException.getMessage(), lockException, lockException.getEntity() );
 			}
 			else {
 				pe = new PessimisticLockException( lockException.getMessage(), lockException, lockException.getEntity() );
 			}
 		}
 		else if ( e instanceof org.hibernate.PessimisticLockException ) {
 			final org.hibernate.PessimisticLockException jdbcLockException = (org.hibernate.PessimisticLockException) e;
 			if ( lockOptions != null && lockOptions.getTimeOut() > -1 ) {
 				// assume lock timeout occurred if a timeout or NO WAIT was specified
 				pe = new LockTimeoutException( jdbcLockException.getMessage(), jdbcLockException, null );
 			}
 			else {
 				pe = new PessimisticLockException( jdbcLockException.getMessage(), jdbcLockException, null );
 			}
 		}
 		else {
 			pe = new OptimisticLockException( e );
 		}
 		return pe;
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/boot/internal/AdditionalJaxbMappingProducerImpl.java b/hibernate-envers/src/main/java/org/hibernate/envers/boot/internal/AdditionalJaxbMappingProducerImpl.java
index 10eaffdb4e..42d6ccb8d2 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/boot/internal/AdditionalJaxbMappingProducerImpl.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/boot/internal/AdditionalJaxbMappingProducerImpl.java
@@ -1,144 +1,141 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.boot.internal;
 
 import java.io.BufferedInputStream;
 import java.io.ByteArrayInputStream;
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.io.PrintWriter;
 import java.io.Writer;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
-import javax.xml.transform.dom.DOMSource;
 
 import org.hibernate.HibernateException;
-import org.hibernate.boot.archive.internal.ByteArrayInputStreamAccess;
 import org.hibernate.boot.jaxb.Origin;
 import org.hibernate.boot.jaxb.SourceType;
 import org.hibernate.boot.jaxb.hbm.spi.JaxbHbmHibernateMapping;
 import org.hibernate.boot.jaxb.internal.MappingBinder;
 import org.hibernate.boot.jaxb.spi.Binding;
 import org.hibernate.boot.model.source.internal.hbm.MappingDocument;
 import org.hibernate.boot.spi.AdditionalJaxbMappingProducer;
 import org.hibernate.boot.spi.MetadataBuildingContext;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.envers.configuration.internal.MappingCollector;
 import org.hibernate.service.ServiceRegistry;
 
 import org.jboss.jandex.IndexView;
 import org.jboss.logging.Logger;
 
+import org.dom4j.Document;
 import org.dom4j.DocumentException;
-import org.dom4j.io.DOMWriter;
 import org.dom4j.io.OutputFormat;
 import org.dom4j.io.XMLWriter;
-import org.dom4j.Document;
 
 /**
  * @author Steve Ebersole
  */
 public class AdditionalJaxbMappingProducerImpl implements AdditionalJaxbMappingProducer {
 	private static final Logger log = Logger.getLogger( AdditionalJaxbMappingProducerImpl.class );
 
 	@Override
 	public Collection<MappingDocument> produceAdditionalMappings(
 			final MetadataImplementor metadata,
 			IndexView jandexIndex,
 			final MappingBinder mappingBinder,
 			final MetadataBuildingContext buildingContext) {
 		final ServiceRegistry serviceRegistry = metadata.getMetadataBuildingOptions().getServiceRegistry();
 		final EnversService enversService = serviceRegistry.getService( EnversService.class );
 
 		if ( !enversService.isEnabled() ) {
 			// short-circuit if envers integration has been disabled.
 			return Collections.emptyList();
 		}
 
 		final ArrayList<MappingDocument> additionalMappingDocuments = new ArrayList<MappingDocument>();
 
 		// atm we do not have distinct origin info for envers
 		final Origin origin = new Origin( SourceType.OTHER, "envers" );
 //		final DOMWriter writer = new DOMWriter();
 
 		final MappingCollector mappingCollector = new MappingCollector() {
 			@Override
 			public void addDocument(Document document) throws DocumentException {
 				dump( document );
 
 				// while the commented-out code here is more efficient (well, understanding that
 				// this whole process is un-efficient)  it leads to un-decipherable messages when
 				// we get mapping mapping errors from envers output.
 //				final DOMSource domSource = new DOMSource( writer.write( document ) );
 //				domSource.setSystemId( "envers" );
 //				final Binding jaxbBinding = mappingBinder.bind( domSource, origin );
 
 				// this form at least allows us to get better error messages
 				final ByteArrayOutputStream baos = new ByteArrayOutputStream();
 				final Writer w = new PrintWriter( baos );
 				try {
 					final XMLWriter xw = new XMLWriter( w, new OutputFormat( " ", true ) );
 					xw.write( document );
 					w.flush();
 				}
 				catch (IOException e) {
 					throw new HibernateException( "Unable to bind Envers-generated XML", e );
 				}
 
 				ByteArrayInputStream bais = new ByteArrayInputStream( baos.toByteArray() );
 				BufferedInputStream bis = new BufferedInputStream( bais );
 				final Binding jaxbBinding = mappingBinder.bind( bis, origin );
 
 				final JaxbHbmHibernateMapping jaxbRoot = (JaxbHbmHibernateMapping) jaxbBinding.getRoot();
 				additionalMappingDocuments.add( new MappingDocument( jaxbRoot, origin, buildingContext ) );
 			}
 		};
 
 		enversService.initialize( metadata, mappingCollector );
 
 		return additionalMappingDocuments;
 	}
 
 	private static void dump(Document document) {
 		if ( !log.isTraceEnabled() ) {
 			return;
 		}
 
 		final ByteArrayOutputStream baos = new ByteArrayOutputStream();
 		final Writer w = new PrintWriter( baos );
 
 		try {
 			final XMLWriter xw = new XMLWriter( w, new OutputFormat( " ", true ) );
 			xw.write( document );
 			w.flush();
 		}
 		catch (IOException e1) {
 			e1.printStackTrace();
 		}
 
 		log.tracef( "Envers-generate entity mapping -----------------------------\n%s", baos.toString() );
 		log.trace( "------------------------------------------------------------" );
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/RevisionInfoConfiguration.java b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/RevisionInfoConfiguration.java
index bfe6e52668..79a28d4be8 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/RevisionInfoConfiguration.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/RevisionInfoConfiguration.java
@@ -1,458 +1,460 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.configuration.internal;
 
-import org.dom4j.Document;
-import org.dom4j.Element;
+import java.util.Date;
+import java.util.Set;
+import javax.persistence.Column;
+
 import org.hibernate.MappingException;
 import org.hibernate.annotations.common.reflection.ClassLoadingException;
 import org.hibernate.annotations.common.reflection.ReflectionManager;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.annotations.common.reflection.XProperty;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.envers.Audited;
 import org.hibernate.envers.DefaultRevisionEntity;
 import org.hibernate.envers.DefaultTrackingModifiedEntitiesRevisionEntity;
 import org.hibernate.envers.ModifiedEntityNames;
 import org.hibernate.envers.RevisionEntity;
 import org.hibernate.envers.RevisionListener;
 import org.hibernate.envers.RevisionNumber;
 import org.hibernate.envers.RevisionTimestamp;
 import org.hibernate.envers.configuration.internal.metadata.AuditTableData;
 import org.hibernate.envers.configuration.internal.metadata.MetadataTools;
 import org.hibernate.envers.enhanced.SequenceIdRevisionEntity;
 import org.hibernate.envers.enhanced.SequenceIdTrackingModifiedEntitiesRevisionEntity;
 import org.hibernate.envers.internal.entities.PropertyData;
 import org.hibernate.envers.internal.revisioninfo.DefaultRevisionInfoGenerator;
 import org.hibernate.envers.internal.revisioninfo.DefaultTrackingModifiedEntitiesRevisionInfoGenerator;
 import org.hibernate.envers.internal.revisioninfo.ModifiedEntityNamesReader;
 import org.hibernate.envers.internal.revisioninfo.RevisionInfoGenerator;
 import org.hibernate.envers.internal.revisioninfo.RevisionInfoNumberReader;
 import org.hibernate.envers.internal.revisioninfo.RevisionInfoQueryCreator;
 import org.hibernate.envers.internal.tools.MutableBoolean;
 import org.hibernate.internal.util.xml.XMLHelper;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.type.LongType;
 import org.hibernate.type.Type;
 
-import javax.persistence.Column;
-import java.util.Date;
-import java.util.Set;
+import org.dom4j.Document;
+import org.dom4j.Element;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public class RevisionInfoConfiguration {
 	private String revisionInfoEntityName;
 	private PropertyData revisionInfoIdData;
 	private PropertyData revisionInfoTimestampData;
 	private PropertyData modifiedEntityNamesData;
 	private Type revisionInfoTimestampType;
 	private GlobalConfiguration globalCfg;
 
 	private String revisionPropType;
 	private String revisionPropSqlType;
 
 	public RevisionInfoConfiguration(GlobalConfiguration globalCfg) {
 		this.globalCfg = globalCfg;
 		if ( globalCfg.isUseRevisionEntityWithNativeId() ) {
 			revisionInfoEntityName = "org.hibernate.envers.DefaultRevisionEntity";
 		}
 		else {
 			revisionInfoEntityName = "org.hibernate.envers.enhanced.SequenceIdRevisionEntity";
 		}
 		revisionInfoIdData = new PropertyData( "id", "id", "field", null );
 		revisionInfoTimestampData = new PropertyData( "timestamp", "timestamp", "field", null );
 		modifiedEntityNamesData = new PropertyData( "modifiedEntityNames", "modifiedEntityNames", "field", null );
 		revisionInfoTimestampType = new LongType();
 
 		revisionPropType = "integer";
 	}
 
 	private Document generateDefaultRevisionInfoXmlMapping() {
 		final Document document = XMLHelper.getDocumentFactory().createDocument();
 
 		final Element classMapping = MetadataTools.createEntity(
 				document,
 				new AuditTableData( null, null, globalCfg.getDefaultSchemaName(), globalCfg.getDefaultCatalogName() ),
 				null,
 				null
 		);
 
 		classMapping.addAttribute( "name", revisionInfoEntityName );
 		classMapping.addAttribute( "table", "REVINFO" );
 
 		final Element idProperty = MetadataTools.addNativelyGeneratedId(
 				classMapping,
 				revisionInfoIdData.getName(),
 				revisionPropType,
 				globalCfg.isUseRevisionEntityWithNativeId()
 		);
 		MetadataTools.addColumn( idProperty, "REV", null, null, null, null, null, null, false );
 
 		final Element timestampProperty = MetadataTools.addProperty(
 				classMapping,
 				revisionInfoTimestampData.getName(),
 				revisionInfoTimestampType.getName(),
 				true,
 				false
 		);
 		MetadataTools.addColumn( timestampProperty, "REVTSTMP", null, null, null, null, null, null, false );
 
 		if ( globalCfg.isTrackEntitiesChangedInRevision() ) {
 			generateEntityNamesTrackingTableMapping(
 					classMapping,
 					"modifiedEntityNames",
 					globalCfg.getDefaultSchemaName(),
 					globalCfg.getDefaultCatalogName(),
 					"REVCHANGES",
 					"REV",
 					"ENTITYNAME",
 					"string"
 			);
 		}
 
 		return document;
 	}
 
 	/**
 	 * Generates mapping that represents a set of primitive types.<br />
 	 * <code>
 	 * &lt;set name="propertyName" table="joinTableName" schema="joinTableSchema" catalog="joinTableCatalog"
 	 * &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cascade="persist, delete" lazy="false" fetch="join"&gt;<br />
 	 * &nbsp;&nbsp;&nbsp;&lt;key column="joinTablePrimaryKeyColumnName" /&gt;<br />
 	 * &nbsp;&nbsp;&nbsp;&lt;element type="joinTableValueColumnType"&gt;<br />
 	 * &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;column name="joinTableValueColumnName" /&gt;<br />
 	 * &nbsp;&nbsp;&nbsp;&lt;/element&gt;<br />
 	 * &lt;/set&gt;
 	 * </code>
 	 */
 	private void generateEntityNamesTrackingTableMapping(
 			Element classMapping,
 			String propertyName,
 			String joinTableSchema,
 			String joinTableCatalog,
 			String joinTableName,
 			String joinTablePrimaryKeyColumnName,
 			String joinTableValueColumnName,
 			String joinTableValueColumnType) {
 		final Element set = classMapping.addElement( "set" );
 		set.addAttribute( "name", propertyName );
 		set.addAttribute( "table", joinTableName );
 		set.addAttribute( "schema", joinTableSchema );
 		set.addAttribute( "catalog", joinTableCatalog );
 		set.addAttribute( "cascade", "persist, delete" );
 		set.addAttribute( "fetch", "join" );
 		set.addAttribute( "lazy", "false" );
 		final Element key = set.addElement( "key" );
 		key.addAttribute( "column", joinTablePrimaryKeyColumnName );
 		final Element element = set.addElement( "element" );
 		element.addAttribute( "type", joinTableValueColumnType );
 		final Element column = element.addElement( "column" );
 		column.addAttribute( "name", joinTableValueColumnName );
 	}
 
 	private Element generateRevisionInfoRelationMapping() {
 		final Document document = XMLHelper.getDocumentFactory().createDocument();
 		final Element revRelMapping = document.addElement( "key-many-to-one" );
 		revRelMapping.addAttribute( "type", revisionPropType );
 		revRelMapping.addAttribute( "class", revisionInfoEntityName );
 
 		if ( revisionPropSqlType != null ) {
 			// Putting a fake name to make Hibernate happy. It will be replaced later anyway.
 			MetadataTools.addColumn( revRelMapping, "*", null, null, null, revisionPropSqlType, null, null, false );
 		}
 
 		return revRelMapping;
 	}
 
 	private void searchForRevisionInfoCfgInProperties(
 			XClass clazz,
 			ReflectionManager reflectionManager,
 			MutableBoolean revisionNumberFound,
 			MutableBoolean revisionTimestampFound,
 			MutableBoolean modifiedEntityNamesFound,
 			String accessType) {
 		for ( XProperty property : clazz.getDeclaredProperties( accessType ) ) {
 			final RevisionNumber revisionNumber = property.getAnnotation( RevisionNumber.class );
 			final RevisionTimestamp revisionTimestamp = property.getAnnotation( RevisionTimestamp.class );
 			final ModifiedEntityNames modifiedEntityNames = property.getAnnotation( ModifiedEntityNames.class );
 
 			if ( revisionNumber != null ) {
 				if ( revisionNumberFound.isSet() ) {
 					throw new MappingException( "Only one property may be annotated with @RevisionNumber!" );
 				}
 
 				final XClass revisionNumberClass = property.getType();
 				if ( reflectionManager.equals( revisionNumberClass, Integer.class ) ||
 						reflectionManager.equals( revisionNumberClass, Integer.TYPE ) ) {
 					revisionInfoIdData = new PropertyData( property.getName(), property.getName(), accessType, null );
 					revisionNumberFound.set();
 				}
 				else if ( reflectionManager.equals( revisionNumberClass, Long.class ) ||
 						reflectionManager.equals( revisionNumberClass, Long.TYPE ) ) {
 					revisionInfoIdData = new PropertyData( property.getName(), property.getName(), accessType, null );
 					revisionNumberFound.set();
 
 					// The default is integer
 					revisionPropType = "long";
 				}
 				else {
 					throw new MappingException(
 							"The field annotated with @RevisionNumber must be of type " +
 									"int, Integer, long or Long"
 					);
 				}
 
 				// Getting the @Column definition of the revision number property, to later use that info to
 				// generate the same mapping for the relation from an audit table's revision number to the
 				// revision entity revision number.
 				final Column revisionPropColumn = property.getAnnotation( Column.class );
 				if ( revisionPropColumn != null ) {
 					revisionPropSqlType = revisionPropColumn.columnDefinition();
 				}
 			}
 
 			if ( revisionTimestamp != null ) {
 				if ( revisionTimestampFound.isSet() ) {
 					throw new MappingException( "Only one property may be annotated with @RevisionTimestamp!" );
 				}
 
 				final XClass revisionTimestampClass = property.getType();
 				if ( reflectionManager.equals( revisionTimestampClass, Long.class ) ||
 						reflectionManager.equals( revisionTimestampClass, Long.TYPE ) ||
 						reflectionManager.equals( revisionTimestampClass, Date.class ) ||
 						reflectionManager.equals( revisionTimestampClass, java.sql.Date.class ) ) {
 					revisionInfoTimestampData = new PropertyData(
 							property.getName(),
 							property.getName(),
 							accessType,
 							null
 					);
 					revisionTimestampFound.set();
 				}
 				else {
 					throw new MappingException(
 							"The field annotated with @RevisionTimestamp must be of type " +
 									"long, Long, java.util.Date or java.sql.Date"
 					);
 				}
 			}
 
 			if ( modifiedEntityNames != null ) {
 				if ( modifiedEntityNamesFound.isSet() ) {
 					throw new MappingException( "Only one property may be annotated with @ModifiedEntityNames!" );
 				}
 				final XClass modifiedEntityNamesClass = property.getType();
 				if ( reflectionManager.equals( modifiedEntityNamesClass, Set.class ) &&
 						reflectionManager.equals( property.getElementClass(), String.class ) ) {
 					modifiedEntityNamesData = new PropertyData(
 							property.getName(),
 							property.getName(),
 							accessType,
 							null
 					);
 					modifiedEntityNamesFound.set();
 				}
 				else {
 					throw new MappingException(
 							"The field annotated with @ModifiedEntityNames must be of Set<String> type."
 					);
 				}
 			}
 		}
 	}
 
 	private void searchForRevisionInfoCfg(
 			XClass clazz, ReflectionManager reflectionManager,
 			MutableBoolean revisionNumberFound, MutableBoolean revisionTimestampFound,
 			MutableBoolean modifiedEntityNamesFound) {
 		final XClass superclazz = clazz.getSuperclass();
 		if ( !"java.lang.Object".equals( superclazz.getName() ) ) {
 			searchForRevisionInfoCfg(
 					superclazz,
 					reflectionManager,
 					revisionNumberFound,
 					revisionTimestampFound,
 					modifiedEntityNamesFound
 			);
 		}
 
 		searchForRevisionInfoCfgInProperties(
 				clazz, reflectionManager, revisionNumberFound, revisionTimestampFound,
 				modifiedEntityNamesFound, "field"
 		);
 		searchForRevisionInfoCfgInProperties(
 				clazz, reflectionManager, revisionNumberFound, revisionTimestampFound,
 				modifiedEntityNamesFound, "property"
 		);
 	}
 
 	public RevisionInfoConfigurationResult configure(MetadataImplementor metadata, ReflectionManager reflectionManager) {
 		boolean revisionEntityFound = false;
 		RevisionInfoGenerator revisionInfoGenerator = null;
 		Class<?> revisionInfoClass = null;
 
 		for ( PersistentClass persistentClass : metadata.getEntityBindings() ) {
 			// Ensure we're in POJO, not dynamic model, mapping.
 			if (persistentClass.getClassName() != null) {
 				XClass clazz;
 				try {
 					clazz = reflectionManager.classForName( persistentClass.getClassName() );
 				}
 				catch (ClassLoadingException e) {
 					throw new MappingException( e );
 				}
 
 				final RevisionEntity revisionEntity = clazz.getAnnotation( RevisionEntity.class );
 				if ( revisionEntity != null ) {
 					if (revisionEntityFound) {
 						throw new MappingException("Only one entity may be annotated with @RevisionEntity!");
 					}
 
 					// Checking if custom revision entity isn't audited
 					if (clazz.getAnnotation(Audited.class) != null) {
 						throw new MappingException("An entity annotated with @RevisionEntity cannot be audited!");
 					}
 
 					revisionEntityFound = true;
 
 					final MutableBoolean revisionNumberFound = new MutableBoolean();
 					final MutableBoolean revisionTimestampFound = new MutableBoolean();
 					final MutableBoolean modifiedEntityNamesFound = new MutableBoolean();
 
 					searchForRevisionInfoCfg(
 							clazz,
 							reflectionManager,
 							revisionNumberFound,
 							revisionTimestampFound,
 							modifiedEntityNamesFound
 					);
 
 					if (!revisionNumberFound.isSet()) {
 						throw new MappingException(
 								"An entity annotated with @RevisionEntity must have a field annotated " +
 										"with @RevisionNumber!"
 						);
 					}
 
 					if (!revisionTimestampFound.isSet()) {
 						throw new MappingException(
 								"An entity annotated with @RevisionEntity must have a field annotated " +
 										"with @RevisionTimestamp!"
 						);
 					}
 
 					revisionInfoEntityName = persistentClass.getEntityName();
 					revisionInfoClass = persistentClass.getMappedClass();
 					final Class<? extends RevisionListener> revisionListenerClass = getRevisionListenerClass(revisionEntity.value());
 					revisionInfoTimestampType = persistentClass.getProperty(revisionInfoTimestampData.getName()).getType();
 					if (globalCfg.isTrackEntitiesChangedInRevision()
 							|| (globalCfg.isUseRevisionEntityWithNativeId() && DefaultTrackingModifiedEntitiesRevisionEntity.class
 							.isAssignableFrom(revisionInfoClass))
 							|| (!globalCfg.isUseRevisionEntityWithNativeId() && SequenceIdTrackingModifiedEntitiesRevisionEntity.class
 							.isAssignableFrom(revisionInfoClass))
 							|| modifiedEntityNamesFound.isSet()) {
 						// If tracking modified entities parameter is enabled, custom revision info entity is a subtype
 						// of DefaultTrackingModifiedEntitiesRevisionEntity class, or @ModifiedEntityNames annotation is used.
 						revisionInfoGenerator = new DefaultTrackingModifiedEntitiesRevisionInfoGenerator(
 								revisionInfoEntityName,
 								revisionInfoClass, revisionListenerClass, revisionInfoTimestampData, isTimestampAsDate(),
 								modifiedEntityNamesData
 						);
 						globalCfg.setTrackEntitiesChangedInRevision(true);
-					} else {
+					}
+					else {
 						revisionInfoGenerator = new DefaultRevisionInfoGenerator(
 								revisionInfoEntityName, revisionInfoClass,
 								revisionListenerClass, revisionInfoTimestampData, isTimestampAsDate()
 						);
 					}
 				}
 			}
 		}
 
 		// In case of a custom revision info generator, the mapping will be null.
 		Document revisionInfoXmlMapping = null;
 
 		final Class<? extends RevisionListener> revisionListenerClass = getRevisionListenerClass( RevisionListener.class );
 
 		if ( revisionInfoGenerator == null ) {
 			if ( globalCfg.isTrackEntitiesChangedInRevision() ) {
 				revisionInfoClass = globalCfg.isUseRevisionEntityWithNativeId() ?
 						DefaultTrackingModifiedEntitiesRevisionEntity.class
 						:
 						SequenceIdTrackingModifiedEntitiesRevisionEntity.class;
 				revisionInfoEntityName = revisionInfoClass.getName();
 				revisionInfoGenerator = new DefaultTrackingModifiedEntitiesRevisionInfoGenerator(
 						revisionInfoEntityName, revisionInfoClass,
 						revisionListenerClass, revisionInfoTimestampData, isTimestampAsDate(), modifiedEntityNamesData
 				);
 			}
 			else {
 				revisionInfoClass = globalCfg.isUseRevisionEntityWithNativeId() ? DefaultRevisionEntity.class
 						: SequenceIdRevisionEntity.class;
 				revisionInfoGenerator = new DefaultRevisionInfoGenerator(
 						revisionInfoEntityName, revisionInfoClass,
 						revisionListenerClass, revisionInfoTimestampData, isTimestampAsDate()
 				);
 			}
 			revisionInfoXmlMapping = generateDefaultRevisionInfoXmlMapping();
 		}
 
 		return new RevisionInfoConfigurationResult(
 				revisionInfoGenerator, revisionInfoXmlMapping,
 				new RevisionInfoQueryCreator(
 						revisionInfoEntityName, revisionInfoIdData.getName(),
 						revisionInfoTimestampData.getName(), isTimestampAsDate()
 				),
 				generateRevisionInfoRelationMapping(),
 				new RevisionInfoNumberReader( revisionInfoClass, revisionInfoIdData ),
 				globalCfg.isTrackEntitiesChangedInRevision() ? new ModifiedEntityNamesReader(
 						revisionInfoClass,
 						modifiedEntityNamesData
 				)
 						: null,
 				revisionInfoEntityName, revisionInfoClass, revisionInfoTimestampData
 		);
 	}
 
 	private boolean isTimestampAsDate() {
 		final String typename = revisionInfoTimestampType.getName();
 		return "date".equals( typename ) || "time".equals( typename ) || "timestamp".equals( typename );
 	}
 
 	/**
 	 * @param defaultListener Revision listener that shall be applied if {@code org.hibernate.envers.revision_listener}
 	 * parameter has not been set.
 	 *
 	 * @return Revision listener.
 	 */
 	private Class<? extends RevisionListener> getRevisionListenerClass(Class<? extends RevisionListener> defaultListener) {
 		if ( globalCfg.getRevisionListenerClass() != null ) {
 			return globalCfg.getRevisionListenerClass();
 		}
 		return defaultListener;
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/AuditMetadataGenerator.java b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/AuditMetadataGenerator.java
index 1e561a0c7a..048b9670a8 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/AuditMetadataGenerator.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/AuditMetadataGenerator.java
@@ -1,796 +1,796 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.configuration.internal.metadata;
 
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 
 import org.hibernate.MappingException;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.envers.RelationTargetAuditMode;
 import org.hibernate.envers.configuration.internal.AuditEntitiesConfiguration;
 import org.hibernate.envers.configuration.internal.GlobalConfiguration;
 import org.hibernate.envers.configuration.internal.metadata.reader.ClassAuditingData;
 import org.hibernate.envers.configuration.internal.metadata.reader.PropertyAuditingData;
 import org.hibernate.envers.internal.EnversMessageLogger;
 import org.hibernate.envers.internal.entities.EntityConfiguration;
 import org.hibernate.envers.internal.entities.IdMappingData;
 import org.hibernate.envers.internal.entities.mapper.CompositeMapperBuilder;
 import org.hibernate.envers.internal.entities.mapper.ExtendedPropertyMapper;
 import org.hibernate.envers.internal.entities.mapper.MultiPropertyMapper;
 import org.hibernate.envers.internal.entities.mapper.SubclassPropertyMapper;
 import org.hibernate.envers.internal.tools.StringTools;
 import org.hibernate.envers.internal.tools.Triple;
 import org.hibernate.envers.strategy.AuditStrategy;
 import org.hibernate.envers.strategy.ValidityAuditStrategy;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.OneToOne;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Table;
 import org.hibernate.mapping.Value;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.ComponentType;
 import org.hibernate.type.ManyToOneType;
 import org.hibernate.type.OneToOneType;
 import org.hibernate.type.TimestampType;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 import org.dom4j.Element;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  * @author Sebastian Komander
  * @author Tomasz Bech
  * @author Stephanie Pau at Markit Group Plc
  * @author Hern&aacute;n Chanfreau
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  * @author Michal Skowronek (mskowr at o2 dot pl)
  */
 public final class AuditMetadataGenerator {
 	private static final EnversMessageLogger LOG = Logger.getMessageLogger(
 			EnversMessageLogger.class,
 			AuditMetadataGenerator.class.getName()
 	);
 
 	private final MetadataImplementor metadata;
 	private final ServiceRegistry serviceRegistry;
 	private final GlobalConfiguration globalCfg;
 	private final AuditEntitiesConfiguration verEntCfg;
 	private final AuditStrategy auditStrategy;
 	private final Element revisionInfoRelationMapping;
 
 	private final ClassLoaderService classLoaderService;
 
 	/*
 	 * Generators for different kinds of property values/types.
 	 */
 	private final BasicMetadataGenerator basicMetadataGenerator;
 	private final ComponentMetadataGenerator componentMetadataGenerator;
 	private final IdMetadataGenerator idMetadataGenerator;
 	private final ToOneRelationMetadataGenerator toOneRelationMetadataGenerator;
 
 	/*
 	 * Here information about already generated mappings will be accumulated.
 	 */
 	private final Map<String, EntityConfiguration> entitiesConfigurations;
 	private final Map<String, EntityConfiguration> notAuditedEntitiesConfigurations;
 
 	private final AuditEntityNameRegister auditEntityNameRegister;
 
 	// Map entity name -> (join descriptor -> element describing the "versioned" join)
 	private final Map<String, Map<Join, Element>> entitiesJoins;
 
 	public AuditMetadataGenerator(
 			MetadataImplementor metadata,
 			ServiceRegistry serviceRegistry,
 			GlobalConfiguration globalCfg,
 			AuditEntitiesConfiguration verEntCfg,
 			AuditStrategy auditStrategy,
 			Element revisionInfoRelationMapping,
 			AuditEntityNameRegister auditEntityNameRegister) {
 		this.metadata = metadata;
 		this.serviceRegistry = serviceRegistry;
 		this.globalCfg = globalCfg;
 		this.verEntCfg = verEntCfg;
 		this.auditStrategy = auditStrategy;
 		this.revisionInfoRelationMapping = revisionInfoRelationMapping;
 
 		this.basicMetadataGenerator = new BasicMetadataGenerator();
 		this.componentMetadataGenerator = new ComponentMetadataGenerator( this );
 		this.idMetadataGenerator = new IdMetadataGenerator( this );
 		this.toOneRelationMetadataGenerator = new ToOneRelationMetadataGenerator( this );
 
 		this.auditEntityNameRegister = auditEntityNameRegister;
 
 		entitiesConfigurations = new HashMap<String, EntityConfiguration>();
 		notAuditedEntitiesConfigurations = new HashMap<String, EntityConfiguration>();
 		entitiesJoins = new HashMap<String, Map<Join, Element>>();
 
 		classLoaderService = serviceRegistry.getService( ClassLoaderService.class );
 	}
 
 	public MetadataImplementor getMetadata() {
 		return metadata;
 	}
 
 	public ServiceRegistry getServiceRegistry() {
 		return serviceRegistry;
 	}
 
 	public ClassLoaderService getClassLoaderService() {
 		return classLoaderService;
 	}
 
 	/**
 	 * Clones the revision info relation mapping, so that it can be added to other mappings. Also, the name of
 	 * the property and the column are set properly.
 	 *
 	 * @return A revision info mapping, which can be added to other mappings (has no parent).
 	 */
 	private Element cloneAndSetupRevisionInfoRelationMapping() {
 		final Element revMapping = (Element) revisionInfoRelationMapping.clone();
 		revMapping.addAttribute( "name", verEntCfg.getRevisionFieldName() );
 		if ( globalCfg.isCascadeDeleteRevision() ) {
 			revMapping.addAttribute( "on-delete", "cascade" );
-	    }
+		}
 
 		MetadataTools.addOrModifyColumn( revMapping, verEntCfg.getRevisionFieldName() );
 
 		return revMapping;
 	}
 
 	void addRevisionInfoRelation(Element anyMapping) {
 		anyMapping.add( cloneAndSetupRevisionInfoRelationMapping() );
 	}
 
 	void addRevisionType(Element anyMapping, Element anyMappingEnd) {
 		addRevisionType( anyMapping, anyMappingEnd, false );
 	}
 
 	void addRevisionType(Element anyMapping, Element anyMappingEnd, boolean isKey) {
 		final Element revTypeProperty = MetadataTools.addProperty(
 				anyMapping,
 				verEntCfg.getRevisionTypePropName(),
 				verEntCfg.getRevisionTypePropType(),
 				true,
 				isKey
 		);
 		revTypeProperty.addAttribute( "type", "org.hibernate.envers.internal.entities.RevisionTypeType" );
 
 		// Adding the end revision, if appropriate
 		addEndRevision( anyMappingEnd );
 	}
 
 	private void addEndRevision(Element anyMapping) {
 		// Add the end-revision field, if the appropriate strategy is used.
 		if ( auditStrategy instanceof ValidityAuditStrategy ) {
 			final Element endRevMapping = (Element) revisionInfoRelationMapping.clone();
 			endRevMapping.setName( "many-to-one" );
 			endRevMapping.addAttribute( "name", verEntCfg.getRevisionEndFieldName() );
 			MetadataTools.addOrModifyColumn( endRevMapping, verEntCfg.getRevisionEndFieldName() );
 
 			anyMapping.add( endRevMapping );
 
 			if ( verEntCfg.isRevisionEndTimestampEnabled() ) {
 				// add a column for the timestamp of the end revision
 				final String revisionInfoTimestampSqlType = TimestampType.INSTANCE.getName();
 				final Element timestampProperty = MetadataTools.addProperty(
 						anyMapping,
 						verEntCfg.getRevisionEndTimestampFieldName(),
 						revisionInfoTimestampSqlType,
 						true,
 						true,
 						false
 				);
 				MetadataTools.addColumn(
 						timestampProperty,
 						verEntCfg.getRevisionEndTimestampFieldName(),
 						null,
 						null,
 						null,
 						null,
 						null,
 						null
 				);
 			}
 		}
 	}
 
 	private void addValueInFirstPass(
 			Element parent,
 			Value value,
 			CompositeMapperBuilder currentMapper,
 			String entityName,
 			EntityXmlMappingData xmlMappingData,
 			PropertyAuditingData propertyAuditingData,
 			boolean insertable,
 			boolean processModifiedFlag) {
 		final Type type = value.getType();
 		final boolean isBasic = basicMetadataGenerator.addBasic(
 				parent,
 				propertyAuditingData,
 				value,
 				currentMapper,
 				insertable,
 				false
 		);
 
 		if ( isBasic ) {
 			// The property was mapped by the basic generator.
 		}
 		else if ( type instanceof ComponentType ) {
 			componentMetadataGenerator.addComponent(
 					parent, propertyAuditingData, value, currentMapper,
 					entityName, xmlMappingData, true
 			);
 		}
 		else {
 			if ( !processedInSecondPass( type ) ) {
 				// If we got here in the first pass, it means the basic mapper didn't map it, and none of the
 				// above branches either.
 				throwUnsupportedTypeException( type, entityName, propertyAuditingData.getName() );
 			}
 			return;
 		}
 		addModifiedFlagIfNeeded( parent, propertyAuditingData, processModifiedFlag );
 	}
 
 	private boolean processedInSecondPass(Type type) {
 		return type instanceof ComponentType || type instanceof ManyToOneType ||
 				type instanceof OneToOneType || type instanceof CollectionType;
 	}
 
 	private void addValueInSecondPass(
 			Element parent,
 			Value value,
 			CompositeMapperBuilder currentMapper,
 			String entityName,
 			EntityXmlMappingData xmlMappingData,
 			PropertyAuditingData propertyAuditingData,
 			boolean insertable,
 			boolean processModifiedFlag) {
 		final Type type = value.getType();
 
 		if ( type instanceof ComponentType ) {
 			componentMetadataGenerator.addComponent(
 					parent,
 					propertyAuditingData,
 					value,
 					currentMapper,
 					entityName,
 					xmlMappingData,
 					false
 			);
 			// mod flag field has been already generated in first pass
 			return;
 		}
 		else if ( type instanceof ManyToOneType ) {
 			toOneRelationMetadataGenerator.addToOne(
 					parent,
 					propertyAuditingData,
 					value,
 					currentMapper,
 					entityName,
 					insertable
 			);
 		}
 		else if ( type instanceof OneToOneType ) {
 			final OneToOne oneToOne = (OneToOne) value;
 			if ( oneToOne.getReferencedPropertyName() != null ) {
 				toOneRelationMetadataGenerator.addOneToOneNotOwning(
 						propertyAuditingData,
 						value,
 						currentMapper,
 						entityName
 				);
 			}
 			else {
 				// @OneToOne relation marked with @PrimaryKeyJoinColumn
 				toOneRelationMetadataGenerator.addOneToOnePrimaryKeyJoinColumn(
 						propertyAuditingData,
 						value,
 						currentMapper,
 						entityName,
 						insertable
 				);
 			}
 		}
 		else if ( type instanceof CollectionType ) {
 			final CollectionMetadataGenerator collectionMetadataGenerator = new CollectionMetadataGenerator(
 					this,
 					(Collection) value,
 					currentMapper,
 					entityName,
 					xmlMappingData,
 					propertyAuditingData
 			);
 			collectionMetadataGenerator.addCollection();
 		}
 		else {
 			return;
 		}
 		addModifiedFlagIfNeeded( parent, propertyAuditingData, processModifiedFlag );
 	}
 
 	private void addModifiedFlagIfNeeded(
 			Element parent,
 			PropertyAuditingData propertyAuditingData,
 			boolean processModifiedFlag) {
 		if ( processModifiedFlag && propertyAuditingData.isUsingModifiedFlag() ) {
 			MetadataTools.addModifiedFlagProperty(
 					parent,
 					propertyAuditingData.getName(),
 					globalCfg.getModifiedFlagSuffix(),
 					propertyAuditingData.getModifiedFlagName()
 			);
 		}
 	}
 
 	void addValue(
 			Element parent, Value value, CompositeMapperBuilder currentMapper, String entityName,
 			EntityXmlMappingData xmlMappingData, PropertyAuditingData propertyAuditingData,
 			boolean insertable, boolean firstPass, boolean processModifiedFlag) {
 		if ( firstPass ) {
 			addValueInFirstPass(
 					parent, value, currentMapper, entityName,
 					xmlMappingData, propertyAuditingData, insertable, processModifiedFlag
 			);
 		}
 		else {
 			addValueInSecondPass(
 					parent, value, currentMapper, entityName,
 					xmlMappingData, propertyAuditingData, insertable, processModifiedFlag
 			);
 		}
 	}
 
 	private void addProperties(
 			Element parent,
 			Iterator<Property> properties,
 			CompositeMapperBuilder currentMapper,
 			ClassAuditingData auditingData,
 			String entityName,
 			EntityXmlMappingData xmlMappingData,
 			boolean firstPass) {
 		while ( properties.hasNext() ) {
 			final Property property = properties.next();
 			final String propertyName = property.getName();
 			final PropertyAuditingData propertyAuditingData = auditingData.getPropertyAuditingData( propertyName );
 			if ( propertyAuditingData != null ) {
 				addValue(
 						parent,
 						property.getValue(),
 						currentMapper,
 						entityName,
 						xmlMappingData,
 						propertyAuditingData,
 						property.isInsertable(),
 						firstPass,
 						true
 				);
 			}
 		}
 	}
 
 	private boolean checkPropertiesAudited(Iterator<Property> properties, ClassAuditingData auditingData) {
 		while ( properties.hasNext() ) {
 			final Property property = properties.next();
 			final String propertyName = property.getName();
 			final PropertyAuditingData propertyAuditingData = auditingData.getPropertyAuditingData( propertyName );
 			if ( propertyAuditingData == null ) {
 				return false;
 			}
 		}
 
 		return true;
 	}
 
 	protected String getSchema(String schemaFromAnnotation, Table table) {
 		// Get the schema from the annotation ...
 		String schema = schemaFromAnnotation;
 		// ... if empty, try using the default ...
 		if ( StringTools.isEmpty( schema ) ) {
 			schema = globalCfg.getDefaultSchemaName();
 
 			// ... if still empty, use the same as the normal table.
 			if ( StringTools.isEmpty( schema ) ) {
 				schema = table.getSchema();
 			}
 		}
 
 		return schema;
 	}
 
 	protected String getCatalog(String catalogFromAnnotation, Table table) {
 		// Get the catalog from the annotation ...
 		String catalog = catalogFromAnnotation;
 		// ... if empty, try using the default ...
 		if ( StringTools.isEmpty( catalog ) ) {
 			catalog = globalCfg.getDefaultCatalogName();
 
 			// ... if still empty, use the same as the normal table.
 			if ( StringTools.isEmpty( catalog ) ) {
 				catalog = table.getCatalog();
 			}
 		}
 
 		return catalog;
 	}
 
 	@SuppressWarnings({"unchecked"})
 	private void createJoins(PersistentClass pc, Element parent, ClassAuditingData auditingData) {
 		final Iterator<Join> joins = pc.getJoinIterator();
 		final Map<Join, Element> joinElements = new HashMap<Join, Element>();
 		entitiesJoins.put( pc.getEntityName(), joinElements );
 
 		while ( joins.hasNext() ) {
 			Join join = joins.next();
 
 			// Checking if all of the join properties are audited
 			if ( !checkPropertiesAudited( join.getPropertyIterator(), auditingData ) ) {
 				continue;
 			}
 
 			// Determining the table name. If there is no entry in the dictionary, just constructing the table name
 			// as if it was an entity (by appending/prepending configured strings).
 			final String originalTableName = join.getTable().getName();
 			String auditTableName = auditingData.getSecondaryTableDictionary().get( originalTableName );
 			if ( auditTableName == null ) {
 				auditTableName = verEntCfg.getAuditEntityName( originalTableName );
 			}
 
 			final String schema = getSchema( auditingData.getAuditTable().schema(), join.getTable() );
 			final String catalog = getCatalog( auditingData.getAuditTable().catalog(), join.getTable() );
 
 			final Element joinElement = MetadataTools.createJoin( parent, auditTableName, schema, catalog );
 			joinElements.put( join, joinElement );
 
 			final Element joinKey = joinElement.addElement( "key" );
 			MetadataTools.addColumns( joinKey, join.getKey().getColumnIterator() );
 			MetadataTools.addColumn( joinKey, verEntCfg.getRevisionFieldName(), null, null, null, null, null, null );
 		}
 	}
 
 	@SuppressWarnings({"unchecked"})
 	private void addJoins(
 			PersistentClass pc,
 			CompositeMapperBuilder currentMapper,
 			ClassAuditingData auditingData,
 			String entityName,
 			EntityXmlMappingData xmlMappingData,
 			boolean firstPass) {
 		final Iterator<Join> joins = pc.getJoinIterator();
 
 		while ( joins.hasNext() ) {
 			final Join join = joins.next();
 			final Element joinElement = entitiesJoins.get( entityName ).get( join );
 
 			if ( joinElement != null ) {
 				addProperties(
 						joinElement,
 						join.getPropertyIterator(),
 						currentMapper,
 						auditingData,
 						entityName,
 						xmlMappingData,
 						firstPass
 				);
 			}
 		}
 	}
 
 	@SuppressWarnings({"unchecked"})
 	private Triple<Element, ExtendedPropertyMapper, String> generateMappingData(
 			PersistentClass pc, EntityXmlMappingData xmlMappingData, AuditTableData auditTableData,
 			IdMappingData idMapper) {
 		final Element classMapping = MetadataTools.createEntity(
 				xmlMappingData.getMainXmlMapping(),
 				auditTableData,
 				pc.getDiscriminatorValue(),
 				pc.isAbstract()
 		);
 		final ExtendedPropertyMapper propertyMapper = new MultiPropertyMapper();
 
 		// Checking if there is a discriminator column
 		if ( pc.getDiscriminator() != null ) {
 			final Element discriminatorElement = classMapping.addElement( "discriminator" );
 			// Database column or SQL formula allowed to distinguish entity types
 			MetadataTools.addColumnsOrFormulas( discriminatorElement, pc.getDiscriminator().getColumnIterator() );
 			discriminatorElement.addAttribute( "type", pc.getDiscriminator().getType().getName() );
 		}
 
 		// Adding the id mapping
 		classMapping.add( (Element) idMapper.getXmlMapping().clone() );
 
 		// Adding the "revision type" property
 		addRevisionType( classMapping, classMapping );
 
 		return Triple.make( classMapping, propertyMapper, null );
 	}
 
 	private Triple<Element, ExtendedPropertyMapper, String> generateInheritanceMappingData(
 			PersistentClass pc, EntityXmlMappingData xmlMappingData, AuditTableData auditTableData,
 			String inheritanceMappingType) {
 		final String extendsEntityName = verEntCfg.getAuditEntityName( pc.getSuperclass().getEntityName() );
 		final Element classMapping = MetadataTools.createSubclassEntity(
 				xmlMappingData.getMainXmlMapping(),
 				inheritanceMappingType,
 				auditTableData,
 				extendsEntityName,
 				pc.getDiscriminatorValue(),
 				pc.isAbstract()
 		);
 
 		// The id and revision type is already mapped in the parent
 
 		// Getting the property mapper of the parent - when mapping properties, they need to be included
 		final String parentEntityName = pc.getSuperclass().getEntityName();
 
 		final EntityConfiguration parentConfiguration = entitiesConfigurations.get( parentEntityName );
 		if ( parentConfiguration == null ) {
 			throw new MappingException(
 					"Entity '" + pc.getEntityName() + "' is audited, but its superclass: '" +
 							parentEntityName + "' is not."
 			);
 		}
 
 		final ExtendedPropertyMapper parentPropertyMapper = parentConfiguration.getPropertyMapper();
 		final ExtendedPropertyMapper propertyMapper = new SubclassPropertyMapper(
 				new MultiPropertyMapper(),
 				parentPropertyMapper
 		);
 
 		return Triple.make( classMapping, propertyMapper, parentEntityName );
 	}
 
 	@SuppressWarnings({"unchecked"})
 	public void generateFirstPass(
 			PersistentClass pc,
 			ClassAuditingData auditingData,
 			EntityXmlMappingData xmlMappingData,
 			boolean isAudited) {
 		final String schema = getSchema( auditingData.getAuditTable().schema(), pc.getTable() );
 		final String catalog = getCatalog( auditingData.getAuditTable().catalog(), pc.getTable() );
 
 		if ( !isAudited ) {
 			final String entityName = pc.getEntityName();
 			final IdMappingData idMapper = idMetadataGenerator.addId( pc, false );
 
 			if ( idMapper == null ) {
 				// Unsupported id mapping, e.g. key-many-to-one. If the entity is used in auditing, an exception
 				// will be thrown later on.
 				LOG.debugf(
 						"Unable to create auditing id mapping for entity %s, because of an unsupported Hibernate id mapping (e.g. key-many-to-one)",
 						entityName
 				);
 				return;
 			}
 
 			final ExtendedPropertyMapper propertyMapper = null;
 			final String parentEntityName = null;
 			final EntityConfiguration entityCfg = new EntityConfiguration(
 					entityName,
 					pc.getClassName(),
 					idMapper,
 					propertyMapper,
 					parentEntityName
 			);
 			notAuditedEntitiesConfigurations.put( entityName, entityCfg );
 			return;
 		}
 
 		final String entityName = pc.getEntityName();
 		LOG.debugf( "Generating first-pass auditing mapping for entity %s", entityName );
 
 		final String auditEntityName = verEntCfg.getAuditEntityName( entityName );
 		final String auditTableName = verEntCfg.getAuditTableName( entityName, pc.getTable().getName() );
 
 		// Registering the audit entity name, now that it is known
 		auditEntityNameRegister.register( auditEntityName );
 
 		final AuditTableData auditTableData = new AuditTableData( auditEntityName, auditTableName, schema, catalog );
 
 		// Generating a mapping for the id
 		final IdMappingData idMapper = idMetadataGenerator.addId( pc, true );
 
 		final InheritanceType inheritanceType = InheritanceType.get( pc );
 
 		// These properties will be read from the mapping data
 		final Element classMapping;
 		final ExtendedPropertyMapper propertyMapper;
 		final String parentEntityName;
 
 		final Triple<Element, ExtendedPropertyMapper, String> mappingData;
 
 		// Reading the mapping data depending on inheritance type (if any)
 		switch ( inheritanceType ) {
 			case NONE:
 				mappingData = generateMappingData( pc, xmlMappingData, auditTableData, idMapper );
 				break;
 
 			case SINGLE:
 				mappingData = generateInheritanceMappingData( pc, xmlMappingData, auditTableData, "subclass" );
 				break;
 
 			case JOINED:
 				mappingData = generateInheritanceMappingData( pc, xmlMappingData, auditTableData, "joined-subclass" );
 
 				// Adding the "key" element with all id columns...
 				final Element keyMapping = mappingData.getFirst().addElement( "key" );
 				MetadataTools.addColumns( keyMapping, pc.getTable().getPrimaryKey().columnIterator() );
 
 				// ... and the revision number column, read from the revision info relation mapping.
 				keyMapping.add( (Element) cloneAndSetupRevisionInfoRelationMapping().element( "column" ).clone() );
 				break;
 
 			case TABLE_PER_CLASS:
 				mappingData = generateInheritanceMappingData( pc, xmlMappingData, auditTableData, "union-subclass" );
 				break;
 
 			default:
 				throw new AssertionError( "Impossible enum value." );
 		}
 
 		classMapping = mappingData.getFirst();
 		propertyMapper = mappingData.getSecond();
 		parentEntityName = mappingData.getThird();
 
 		xmlMappingData.setClassMapping( classMapping );
 
 		// Mapping unjoined properties
 		addProperties(
 				classMapping, pc.getUnjoinedPropertyIterator(), propertyMapper,
 				auditingData, pc.getEntityName(), xmlMappingData,
 				true
 		);
 
 		// Creating and mapping joins (first pass)
 		createJoins( pc, classMapping, auditingData );
 		addJoins( pc, propertyMapper, auditingData, pc.getEntityName(), xmlMappingData, true );
 
 		// Storing the generated configuration
 		final EntityConfiguration entityCfg = new EntityConfiguration(
 				auditEntityName,
 				pc.getClassName(),
 				idMapper,
 				propertyMapper,
 				parentEntityName
 		);
 		entitiesConfigurations.put( pc.getEntityName(), entityCfg );
 	}
 
 	@SuppressWarnings({"unchecked"})
 	public void generateSecondPass(
 			PersistentClass pc,
 			ClassAuditingData auditingData,
 			EntityXmlMappingData xmlMappingData) {
 		final String entityName = pc.getEntityName();
 		LOG.debugf( "Generating second-pass auditing mapping for entity %s", entityName );
 
 		final CompositeMapperBuilder propertyMapper = entitiesConfigurations.get( entityName ).getPropertyMapper();
 
 		// Mapping unjoined properties
 		final Element parent = xmlMappingData.getClassMapping();
 
 		addProperties(
 				parent,
 				pc.getUnjoinedPropertyIterator(),
 				propertyMapper,
 				auditingData,
 				entityName,
 				xmlMappingData,
 				false
 		);
 
 		// Mapping joins (second pass)
 		addJoins( pc, propertyMapper, auditingData, entityName, xmlMappingData, false );
 	}
 
 	public Map<String, EntityConfiguration> getEntitiesConfigurations() {
 		return entitiesConfigurations;
 	}
 
 	// Getters for generators and configuration
 
 	BasicMetadataGenerator getBasicMetadataGenerator() {
 		return basicMetadataGenerator;
 	}
 
 	GlobalConfiguration getGlobalCfg() {
 		return globalCfg;
 	}
 
 	AuditEntitiesConfiguration getVerEntCfg() {
 		return verEntCfg;
 	}
 
 	AuditStrategy getAuditStrategy() {
 		return auditStrategy;
 	}
 
 	AuditEntityNameRegister getAuditEntityNameRegister() {
 		return auditEntityNameRegister;
 	}
 
 	void throwUnsupportedTypeException(Type type, String entityName, String propertyName) {
 		final String message = "Type not supported for auditing: " + type.getClass().getName() +
 				", on entity " + entityName + ", property '" + propertyName + "'.";
 
 		throw new MappingException( message );
 	}
 
 	/**
 	 * Reads the id mapping data of a referenced entity.
 	 *
 	 * @param entityName Name of the entity which is the source of the relation.
 	 * @param referencedEntityName Name of the entity which is the target of the relation.
 	 * @param propertyAuditingData Auditing data of the property that is the source of the relation.
 	 * @param allowNotAuditedTarget Are not-audited target entities allowed.
 	 *
 	 * @return The id mapping data of the related entity.
 	 *
 	 * @throws MappingException If a relation from an audited to a non-audited entity is detected, which is not
 	 * mapped using {@link RelationTargetAuditMode#NOT_AUDITED}.
 	 */
 	IdMappingData getReferencedIdMappingData(
 			String entityName, String referencedEntityName,
 			PropertyAuditingData propertyAuditingData,
 			boolean allowNotAuditedTarget) {
 		EntityConfiguration configuration = getEntitiesConfigurations().get( referencedEntityName );
 		if ( configuration == null ) {
 			final RelationTargetAuditMode relationTargetAuditMode = propertyAuditingData.getRelationTargetAuditMode();
 			configuration = getNotAuditedEntitiesConfigurations().get( referencedEntityName );
 
 			if ( configuration == null || !allowNotAuditedTarget || !RelationTargetAuditMode.NOT_AUDITED.equals(
 					relationTargetAuditMode
 			) ) {
 				throw new MappingException(
 						"An audited relation from " + entityName + "."
 								+ propertyAuditingData.getName() + " to a not audited entity " + referencedEntityName + "!"
 								+ (allowNotAuditedTarget ?
 								" Such mapping is possible, but has to be explicitly defined using @Audited(targetAuditMode = NOT_AUDITED)." :
 								"")
 				);
 			}
 		}
 
 		return configuration.getIdMappingData();
 	}
 
 	/**
 	 * Get the notAuditedEntitiesConfigurations property.
 	 *
 	 * @return the notAuditedEntitiesConfigurations property value
 	 */
 	public Map<String, EntityConfiguration> getNotAuditedEntitiesConfigurations() {
 		return notAuditedEntitiesConfigurations;
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/ComponentMetadataGenerator.java b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/ComponentMetadataGenerator.java
index 5e2f7fd063..a37be1cac0 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/ComponentMetadataGenerator.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/ComponentMetadataGenerator.java
@@ -1,97 +1,98 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.configuration.internal.metadata;
 
 import java.util.Iterator;
 import java.util.Map;
 
 import org.hibernate.envers.configuration.internal.metadata.reader.ComponentAuditingData;
 import org.hibernate.envers.configuration.internal.metadata.reader.PropertyAuditingData;
 import org.hibernate.envers.internal.entities.mapper.CompositeMapperBuilder;
 import org.hibernate.envers.internal.tools.ReflectionTools;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Value;
 
 import org.dom4j.Element;
 
 /**
  * Generates metadata for components.
  *
  * @author Adam Warski (adam at warski dot org)
  * @author Lukasz Zuchowski (author at zuchos dot com)
  */
 public final class ComponentMetadataGenerator {
-    private final AuditMetadataGenerator mainGenerator;
+	private final AuditMetadataGenerator mainGenerator;
 
-    ComponentMetadataGenerator(AuditMetadataGenerator auditMetadataGenerator) {
-        mainGenerator = auditMetadataGenerator;
-    }
+	ComponentMetadataGenerator(AuditMetadataGenerator auditMetadataGenerator) {
+		mainGenerator = auditMetadataGenerator;
+	}
 
-    @SuppressWarnings({"unchecked"})
-    public void addComponent(
-            Element parent, PropertyAuditingData propertyAuditingData,
-            Value value, CompositeMapperBuilder mapper, String entityName,
-            EntityXmlMappingData xmlMappingData, boolean firstPass) {
-        final Component propComponent = (Component) value;
+	@SuppressWarnings({"unchecked"})
+	public void addComponent(
+			Element parent, PropertyAuditingData propertyAuditingData,
+			Value value, CompositeMapperBuilder mapper, String entityName,
+			EntityXmlMappingData xmlMappingData, boolean firstPass) {
+		final Component propComponent = (Component) value;
 
-        final Class componentClass;
-        if (propComponent.isDynamic()) {
-            componentClass = ReflectionTools.loadClass(
-                    Map.class.getCanonicalName(),
-                    mainGenerator.getClassLoaderService()
-            );
+		final Class componentClass;
+		if ( propComponent.isDynamic() ) {
+			componentClass = ReflectionTools.loadClass(
+					Map.class.getCanonicalName(),
+					mainGenerator.getClassLoaderService()
+			);
 
-        } else {
-            componentClass = ReflectionTools.loadClass(
-                    propComponent.getComponentClassName(),
-                    mainGenerator.getClassLoaderService()
-            );
-        }
-        final CompositeMapperBuilder componentMapper = mapper.addComponent(
-                propertyAuditingData.getPropertyData(),
-                componentClass
-        );
+		}
+		else {
+			componentClass = ReflectionTools.loadClass(
+					propComponent.getComponentClassName(),
+					mainGenerator.getClassLoaderService()
+			);
+		}
+		final CompositeMapperBuilder componentMapper = mapper.addComponent(
+				propertyAuditingData.getPropertyData(),
+				componentClass
+		);
 
-        // The property auditing data must be for a component.
-        final ComponentAuditingData componentAuditingData = (ComponentAuditingData) propertyAuditingData;
+		// The property auditing data must be for a component.
+		final ComponentAuditingData componentAuditingData = (ComponentAuditingData) propertyAuditingData;
 
-        // Adding all properties of the component
-        final Iterator<Property> properties = (Iterator<Property>) propComponent.getPropertyIterator();
-        while (properties.hasNext()) {
-            final Property property = properties.next();
+		// Adding all properties of the component
+		final Iterator<Property> properties = (Iterator<Property>) propComponent.getPropertyIterator();
+		while ( properties.hasNext() ) {
+			final Property property = properties.next();
 
-            final PropertyAuditingData componentPropertyAuditingData =
-                    componentAuditingData.getPropertyAuditingData(property.getName());
+			final PropertyAuditingData componentPropertyAuditingData =
+					componentAuditingData.getPropertyAuditingData( property.getName() );
 
-            // Checking if that property is audited
-            if (componentPropertyAuditingData != null) {
-                mainGenerator.addValue(
-                        parent, property.getValue(), componentMapper, entityName, xmlMappingData,
-                        componentPropertyAuditingData, property.isInsertable(), firstPass, false
-                );
-            }
-        }
-    }
+			// Checking if that property is audited
+			if ( componentPropertyAuditingData != null ) {
+				mainGenerator.addValue(
+						parent, property.getValue(), componentMapper, entityName, xmlMappingData,
+						componentPropertyAuditingData, property.isInsertable(), firstPass, false
+				);
+			}
+		}
+	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/reader/AuditedPropertiesReader.java b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/reader/AuditedPropertiesReader.java
index 911d4529b2..a7323211d6 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/reader/AuditedPropertiesReader.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/reader/AuditedPropertiesReader.java
@@ -1,772 +1,773 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.configuration.internal.metadata.reader;
 
+import java.lang.annotation.Annotation;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import javax.persistence.JoinColumn;
+import javax.persistence.MapKey;
+import javax.persistence.OneToMany;
+import javax.persistence.Version;
+
 import org.hibernate.MappingException;
 import org.hibernate.annotations.common.reflection.ClassLoadingException;
 import org.hibernate.annotations.common.reflection.ReflectionManager;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.annotations.common.reflection.XProperty;
 import org.hibernate.cfg.AccessType;
 import org.hibernate.envers.AuditJoinTable;
 import org.hibernate.envers.AuditMappedBy;
 import org.hibernate.envers.AuditOverride;
 import org.hibernate.envers.AuditOverrides;
 import org.hibernate.envers.Audited;
 import org.hibernate.envers.ModificationStore;
 import org.hibernate.envers.NotAudited;
 import org.hibernate.envers.RelationTargetAuditMode;
 import org.hibernate.envers.configuration.internal.GlobalConfiguration;
 import org.hibernate.envers.configuration.internal.metadata.MetadataTools;
 import org.hibernate.envers.internal.tools.MappingTools;
 import org.hibernate.envers.internal.tools.ReflectionTools;
 import org.hibernate.envers.internal.tools.StringTools;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Value;
 
-import javax.persistence.JoinColumn;
-import javax.persistence.MapKey;
-import javax.persistence.OneToMany;
-import javax.persistence.Version;
-import java.lang.annotation.Annotation;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-
 import static org.hibernate.envers.internal.tools.Tools.newHashMap;
 import static org.hibernate.envers.internal.tools.Tools.newHashSet;
 
 /**
  * Reads persistent properties form a {@link PersistentPropertiesSource} and adds the ones that are audited to a
  * {@link AuditedPropertiesHolder}, filling all the auditing data.
  *
  * @author Adam Warski (adam at warski dot org)
  * @author Erik-Berndt Scheper
  * @author Hern&aacut;n Chanfreau
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  * @author Michal Skowronek (mskowr at o2 dot pl)
  * @author Lukasz Zuchowski (author at zuchos dot com)
  */
 public class AuditedPropertiesReader {
 	protected final ModificationStore defaultStore;
 	private final PersistentPropertiesSource persistentPropertiesSource;
 	private final AuditedPropertiesHolder auditedPropertiesHolder;
 	private final GlobalConfiguration globalCfg;
 	private final ReflectionManager reflectionManager;
 	private final String propertyNamePrefix;
 
 	private final Set<String> propertyAccessedPersistentProperties;
 	private final Set<String> fieldAccessedPersistentProperties;
 	// Mapping class field to corresponding <properties> element.
 	private final Map<String, String> propertiesGroupMapping;
 
 	private final Set<XProperty> overriddenAuditedProperties;
 	private final Set<XProperty> overriddenNotAuditedProperties;
 
 	private final Set<XClass> overriddenAuditedClasses;
 	private final Set<XClass> overriddenNotAuditedClasses;
 
 	public AuditedPropertiesReader(
 			ModificationStore defaultStore,
 			PersistentPropertiesSource persistentPropertiesSource,
 			AuditedPropertiesHolder auditedPropertiesHolder,
 			GlobalConfiguration globalCfg,
 			ReflectionManager reflectionManager,
 			String propertyNamePrefix) {
 		this.defaultStore = defaultStore;
 		this.persistentPropertiesSource = persistentPropertiesSource;
 		this.auditedPropertiesHolder = auditedPropertiesHolder;
 		this.globalCfg = globalCfg;
 		this.reflectionManager = reflectionManager;
 		this.propertyNamePrefix = propertyNamePrefix;
 
 		propertyAccessedPersistentProperties = newHashSet();
 		fieldAccessedPersistentProperties = newHashSet();
 		propertiesGroupMapping = newHashMap();
 
 		overriddenAuditedProperties = newHashSet();
 		overriddenNotAuditedProperties = newHashSet();
 
 		overriddenAuditedClasses = newHashSet();
 		overriddenNotAuditedClasses = newHashSet();
 	}
 
 	public void read() {
 		// First reading the access types for the persistent properties.
 		readPersistentPropertiesAccess();
 
 		if ( persistentPropertiesSource instanceof DynamicComponentSource ) {
 			addPropertiesFromDynamicComponent( (DynamicComponentSource) persistentPropertiesSource );
 		}
 		else {
 			// Retrieve classes and properties that are explicitly marked for auditing process by any superclass
 			// of currently mapped entity or itself.
 			final XClass clazz = persistentPropertiesSource.getXClass();
 			readAuditOverrides( clazz );
 
 			// Adding all properties from the given class.
 			addPropertiesFromClass( clazz );
 		}
 	}
 
 	/**
 	 * Recursively constructs sets of audited and not audited properties and classes which behavior has been overridden
 	 * using {@link AuditOverride} annotation.
 	 *
 	 * @param clazz Class that is being processed. Currently mapped entity shall be passed during first invocation.
 	 */
 	private void readAuditOverrides(XClass clazz) {
 		/* TODO: Code to remove with @Audited.auditParents - start. */
 		final Audited allClassAudited = clazz.getAnnotation( Audited.class );
 		if ( allClassAudited != null && allClassAudited.auditParents().length > 0 ) {
 			for ( Class c : allClassAudited.auditParents() ) {
 				final XClass parentClass = reflectionManager.toXClass( c );
 				checkSuperclass( clazz, parentClass );
 				if ( !overriddenNotAuditedClasses.contains( parentClass ) ) {
 					// If the class has not been marked as not audited by the subclass.
 					overriddenAuditedClasses.add( parentClass );
 				}
 			}
 		}
 		/* TODO: Code to remove with @Audited.auditParents - finish. */
 		final List<AuditOverride> auditOverrides = computeAuditOverrides( clazz );
 		for ( AuditOverride auditOverride : auditOverrides ) {
 			if ( auditOverride.forClass() != void.class ) {
 				final XClass overrideClass = reflectionManager.toXClass( auditOverride.forClass() );
 				checkSuperclass( clazz, overrideClass );
 				final String propertyName = auditOverride.name();
 				if ( !StringTools.isEmpty( propertyName ) ) {
 					// Override @Audited annotation on property level.
 					final XProperty property = getProperty( overrideClass, propertyName );
 					if ( auditOverride.isAudited() ) {
 						if ( !overriddenNotAuditedProperties.contains( property ) ) {
 							// If the property has not been marked as not audited by the subclass.
 							overriddenAuditedProperties.add( property );
 						}
 					}
 					else {
 						if ( !overriddenAuditedProperties.contains( property ) ) {
 							// If the property has not been marked as audited by the subclass.
 							overriddenNotAuditedProperties.add( property );
 						}
 					}
 				}
 				else {
 					// Override @Audited annotation on class level.
 					if ( auditOverride.isAudited() ) {
 						if ( !overriddenNotAuditedClasses.contains( overrideClass ) ) {
 							// If the class has not been marked as not audited by the subclass.
 							overriddenAuditedClasses.add( overrideClass );
 						}
 					}
 					else {
 						if ( !overriddenAuditedClasses.contains( overrideClass ) ) {
 							// If the class has not been marked as audited by the subclass.
 							overriddenNotAuditedClasses.add( overrideClass );
 						}
 					}
 				}
 			}
 		}
 		final XClass superclass = clazz.getSuperclass();
 		if ( !clazz.isInterface() && !Object.class.getName().equals( superclass.getName() ) ) {
 			readAuditOverrides( superclass );
 		}
 	}
 
 	/**
 	 * @param clazz Source class.
 	 *
 	 * @return List of @AuditOverride annotations applied at class level.
 	 */
 	private List<AuditOverride> computeAuditOverrides(XClass clazz) {
 		final AuditOverrides auditOverrides = clazz.getAnnotation( AuditOverrides.class );
 		final AuditOverride auditOverride = clazz.getAnnotation( AuditOverride.class );
 		if ( auditOverrides == null && auditOverride != null ) {
 			return Arrays.asList( auditOverride );
 		}
 		else if ( auditOverrides != null && auditOverride == null ) {
 			return Arrays.asList( auditOverrides.value() );
 		}
 		else if ( auditOverrides != null && auditOverride != null ) {
 			throw new MappingException(
 					"@AuditOverrides annotation should encapsulate all @AuditOverride declarations. " +
 							"Please revise Envers annotations applied to class " + clazz.getName() + "."
 			);
 		}
 		return Collections.emptyList();
 	}
 
 	/**
 	 * Checks whether one class is assignable from another. If not {@link MappingException} is thrown.
 	 *
 	 * @param child Subclass.
 	 * @param parent Superclass.
 	 */
 	private void checkSuperclass(XClass child, XClass parent) {
 		if ( !parent.isAssignableFrom( child ) ) {
 			throw new MappingException(
 					"Class " + parent.getName() + " is not assignable from " + child.getName() + ". " +
 							"Please revise Envers annotations applied to " + child.getName() + " type."
 			);
 		}
 	}
 
 	/**
 	 * Checks whether class contains property with a given name. If not {@link MappingException} is thrown.
 	 *
 	 * @param clazz Class.
 	 * @param propertyName Property name.
 	 *
 	 * @return Property object.
 	 */
 	private XProperty getProperty(XClass clazz, String propertyName) {
 		final XProperty property = ReflectionTools.getProperty( clazz, propertyName );
 		if ( property == null ) {
 			throw new MappingException(
 					"Property '" + propertyName + "' not found in class " + clazz.getName() + ". " +
 							"Please revise Envers annotations applied to class " + persistentPropertiesSource.getXClass() + "."
 			);
 		}
 		return property;
 	}
 
 	private void readPersistentPropertiesAccess() {
 		final Iterator<Property> propertyIter = persistentPropertiesSource.getPropertyIterator();
 		while ( propertyIter.hasNext() ) {
 			final Property property = propertyIter.next();
 			addPersistentProperty( property );
 			if ( "embedded".equals( property.getPropertyAccessorName() )
 					&& property.getName().equals( property.getNodeName() ) ) {
 				// If property name equals node name and embedded accessor type is used, processing component
 				// has been defined with <properties> tag. See HHH-6636 JIRA issue.
 				createPropertiesGroupMapping( property );
 			}
 		}
 	}
 
 	private void addPersistentProperty(Property property) {
 		if ( "field".equals( property.getPropertyAccessorName() ) ) {
 			fieldAccessedPersistentProperties.add( property.getName() );
 		}
 		else {
 			propertyAccessedPersistentProperties.add( property.getName() );
 		}
 	}
 
 	@SuppressWarnings("unchecked")
 	private void createPropertiesGroupMapping(Property property) {
 		final Component component = (Component) property.getValue();
 		final Iterator<Property> componentProperties = component.getPropertyIterator();
 		while ( componentProperties.hasNext() ) {
 			final Property componentProperty = componentProperties.next();
 			propertiesGroupMapping.put( componentProperty.getName(), component.getNodeName() );
 		}
 	}
 
 	/**
 	 * @param clazz Class which properties are currently being added.
 	 *
 	 * @return {@link Audited} annotation of specified class. If processed type hasn't been explicitly marked, method
 	 *         checks whether given class exists in {@link AuditedPropertiesReader#overriddenAuditedClasses} collection.
 	 *         In case of success, {@link Audited} configuration of currently mapped entity is returned, otherwise
 	 *         {@code null}. If processed type exists in {@link AuditedPropertiesReader#overriddenNotAuditedClasses}
 	 *         collection, the result is also {@code null}.
 	 */
 	private Audited computeAuditConfiguration(XClass clazz) {
 		Audited allClassAudited = clazz.getAnnotation( Audited.class );
 		// If processed class is not explicitly marked with @Audited annotation, check whether auditing is
 		// forced by any of its child entities configuration (@AuditedOverride.forClass).
 		if ( allClassAudited == null && overriddenAuditedClasses.contains( clazz ) ) {
 			// Declared audited parent copies @Audited.modStore and @Audited.targetAuditMode configuration from
 			// currently mapped entity.
 			allClassAudited = persistentPropertiesSource.getXClass().getAnnotation( Audited.class );
 			if ( allClassAudited == null ) {
 				// If parent class declares @Audited on the field/property level.
 				allClassAudited = DEFAULT_AUDITED;
 			}
 		}
 		else if ( allClassAudited != null && overriddenNotAuditedClasses.contains( clazz ) ) {
 			return null;
 		}
 		return allClassAudited;
 	}
 
 	private void addPropertiesFromDynamicComponent(DynamicComponentSource dynamicComponentSource) {
 		Audited audited = computeAuditConfiguration( dynamicComponentSource.getXClass() );
 		if ( !fieldAccessedPersistentProperties.isEmpty() ) {
 			throw new MappingException(
 					"Audited dynamic component cannot have properties with access=\"field\" for properties: " + fieldAccessedPersistentProperties + ". \n Change properties access=\"property\", to make it work)"
 			);
 		}
 		for ( String property : propertyAccessedPersistentProperties ) {
 			String accessType = AccessType.PROPERTY.getType();
 			if ( !auditedPropertiesHolder.contains( property ) ) {
 				final Value propertyValue = persistentPropertiesSource.getProperty( property ).getValue();
 				if ( propertyValue instanceof Component ) {
 					this.addFromComponentProperty(
 							new DynamicProperty( dynamicComponentSource, property ),
 							accessType,
 							(Component) propertyValue,
 							audited
 					);
 				}
 				else {
 					this.addFromNotComponentProperty(
 							new DynamicProperty( dynamicComponentSource, property ),
 							accessType,
 							audited
 					);
 				}
 			}
 		}
 	}
 
 	/**
 	 * Recursively adds all audited properties of entity class and its superclasses.
 	 *
 	 * @param clazz Currently processed class.
 	 */
 	private void addPropertiesFromClass(XClass clazz) {
 		final Audited allClassAudited = computeAuditConfiguration( clazz );
 
 		//look in the class
 		addFromProperties(
 				clazz.getDeclaredProperties( "field" ),
 				"field",
 				fieldAccessedPersistentProperties,
 				allClassAudited
 		);
 		addFromProperties(
 				clazz.getDeclaredProperties( "property" ),
 				"property",
 				propertyAccessedPersistentProperties,
 				allClassAudited
 		);
 
 		if ( allClassAudited != null || !auditedPropertiesHolder.isEmpty() ) {
 			final XClass superclazz = clazz.getSuperclass();
 			if ( !clazz.isInterface() && !"java.lang.Object".equals( superclazz.getName() ) ) {
 				addPropertiesFromClass( superclazz );
 			}
 		}
 	}
 
 	private void addFromProperties(
 			Iterable<XProperty> properties,
 			String accessType,
 			Set<String> persistentProperties,
 			Audited allClassAudited) {
 		for ( XProperty property : properties ) {
 			// If this is not a persistent property, with the same access type as currently checked,
 			// it's not audited as well.
 			// If the property was already defined by the subclass, is ignored by superclasses
 			if ( persistentProperties.contains( property.getName() )
 					&& !auditedPropertiesHolder.contains( property.getName() ) ) {
 				final Value propertyValue = persistentPropertiesSource.getProperty( property.getName() ).getValue();
 				if ( propertyValue instanceof Component ) {
 					this.addFromComponentProperty( property, accessType, (Component) propertyValue, allClassAudited );
 				}
 				else {
 					this.addFromNotComponentProperty( property, accessType, allClassAudited );
 				}
 			}
 			else if ( propertiesGroupMapping.containsKey( property.getName() ) ) {
 				// Retrieve embedded component name based on class field.
 				final String embeddedName = propertiesGroupMapping.get( property.getName() );
 				if ( !auditedPropertiesHolder.contains( embeddedName ) ) {
 					// Manage properties mapped within <properties> tag.
 					final Value propertyValue = persistentPropertiesSource.getProperty( embeddedName ).getValue();
 					this.addFromPropertiesGroup(
 							embeddedName,
 							property,
 							accessType,
 							(Component) propertyValue,
 							allClassAudited
 					);
 				}
 			}
 		}
 	}
 
 	private void addFromPropertiesGroup(
 			String embeddedName,
 			XProperty property,
 			String accessType,
 			Component propertyValue,
 			Audited allClassAudited) {
 		final ComponentAuditingData componentData = new ComponentAuditingData();
 		final boolean isAudited = fillPropertyData( property, componentData, accessType, allClassAudited );
 		if ( isAudited ) {
 			// EntityPersister.getPropertyNames() returns name of embedded component instead of class field.
 			componentData.setName( embeddedName );
 			// Marking component properties as placed directly in class (not inside another component).
 			componentData.setBeanName( null );
 
 			final PersistentPropertiesSource componentPropertiesSource = new ComponentPropertiesSource(
 					reflectionManager,
 					propertyValue
 			);
 			final AuditedPropertiesReader audPropReader = new AuditedPropertiesReader(
 					ModificationStore.FULL, componentPropertiesSource, componentData, globalCfg, reflectionManager,
 					propertyNamePrefix + MappingTools.createComponentPrefix( embeddedName )
 			);
 			audPropReader.read();
 
 			auditedPropertiesHolder.addPropertyAuditingData( embeddedName, componentData );
 		}
 	}
 
 	private void addFromComponentProperty(
 			XProperty property,
 			String accessType,
 			Component propertyValue,
 			Audited allClassAudited) {
 		final ComponentAuditingData componentData = new ComponentAuditingData();
 		final boolean isAudited = fillPropertyData( property, componentData, accessType, allClassAudited );
 
 		final PersistentPropertiesSource componentPropertiesSource;
 		if ( propertyValue.isDynamic() ) {
 			componentPropertiesSource = new DynamicComponentSource( reflectionManager, propertyValue, property );
 		}
 		else {
 			componentPropertiesSource = new ComponentPropertiesSource( reflectionManager, propertyValue );
 		}
 
 		final ComponentAuditedPropertiesReader audPropReader = new ComponentAuditedPropertiesReader(
 				ModificationStore.FULL,
 				componentPropertiesSource,
 				componentData,
 				globalCfg,
 				reflectionManager,
 				propertyNamePrefix + MappingTools.createComponentPrefix( property.getName() )
 		);
 		audPropReader.read();
 
 		if ( isAudited ) {
 			// Now we know that the property is audited
 			auditedPropertiesHolder.addPropertyAuditingData( property.getName(), componentData );
 		}
 	}
 
 	private void addFromNotComponentProperty(XProperty property, String accessType, Audited allClassAudited) {
 		final PropertyAuditingData propertyData = new PropertyAuditingData();
 		final boolean isAudited = fillPropertyData( property, propertyData, accessType, allClassAudited );
 
 		if ( isAudited ) {
 			// Now we know that the property is audited
 			auditedPropertiesHolder.addPropertyAuditingData( property.getName(), propertyData );
 		}
 	}
 
 
 	/**
 	 * Checks if a property is audited and if yes, fills all of its data.
 	 *
 	 * @param property Property to check.
 	 * @param propertyData Property data, on which to set this property's modification store.
 	 * @param accessType Access type for the property.
 	 *
 	 * @return False if this property is not audited.
 	 */
 	private boolean fillPropertyData(
 			XProperty property,
 			PropertyAuditingData propertyData,
 			String accessType,
 			Audited allClassAudited) {
 
 		// check if a property is declared as not audited to exclude it
 		// useful if a class is audited but some properties should be excluded
 		final NotAudited unVer = property.getAnnotation( NotAudited.class );
 		if ( ( unVer != null
 				&& !overriddenAuditedProperties.contains( property ) )
 				|| overriddenNotAuditedProperties.contains( property ) ) {
 			return false;
 		}
 		else {
 			// if the optimistic locking field has to be unversioned and the current property
 			// is the optimistic locking field, don't audit it
 			if ( globalCfg.isDoNotAuditOptimisticLockingField() ) {
 				final Version jpaVer = property.getAnnotation( Version.class );
 				if ( jpaVer != null ) {
 					return false;
 				}
 			}
 		}
 
 		final String propertyName = propertyNamePrefix + property.getName();
 		if ( !this.checkAudited( property, propertyData,propertyName, allClassAudited, globalCfg.getModifiedFlagSuffix() ) ) {
 			return false;
 		}
 
 		propertyData.setName( propertyName );
 		propertyData.setBeanName( property.getName() );
 		propertyData.setAccessType( accessType );
 
 		addPropertyJoinTables( property, propertyData );
 		addPropertyAuditingOverrides( property, propertyData );
 		if ( !processPropertyAuditingOverrides( property, propertyData ) ) {
 			// not audited due to AuditOverride annotation
 			return false;
 		}
 		addPropertyMapKey( property, propertyData );
 		setPropertyAuditMappedBy( property, propertyData );
 		setPropertyRelationMappedBy( property, propertyData );
 
 		return true;
 	}
 
 
 	protected boolean checkAudited(
 			XProperty property,
 			PropertyAuditingData propertyData, String propertyName,
 			Audited allClassAudited, String modifiedFlagSuffix) {
 		// Checking if this property is explicitly audited or if all properties are.
 		Audited aud = ( property.isAnnotationPresent( Audited.class ) )
 				? property.getAnnotation( Audited.class )
 				: allClassAudited;
 		if ( aud == null
 				&& overriddenAuditedProperties.contains( property )
 				&& !overriddenNotAuditedProperties.contains( property ) ) {
 			// Assigning @Audited defaults. If anyone needs to customize those values in the future,
 			// appropriate fields shall be added to @AuditOverride annotation.
 			aud = DEFAULT_AUDITED;
 		}
 		if ( aud != null ) {
 			propertyData.setStore( aud.modStore() );
 			propertyData.setRelationTargetAuditMode( aud.targetAuditMode() );
 			propertyData.setUsingModifiedFlag( checkUsingModifiedFlag( aud ) );
 			if(aud.modifiedColumnName() != null && !"".equals(aud.modifiedColumnName())) {
 				propertyData.setModifiedFlagName(aud.modifiedColumnName());
-			} else {
+			}
+			else {
 				propertyData.setModifiedFlagName(
 						MetadataTools.getModifiedFlagPropertyName(propertyName, modifiedFlagSuffix)
 				);
 			}
 			return true;
 		}
 		else {
 			return false;
 		}
 	}
 
 	protected boolean checkUsingModifiedFlag(Audited aud) {
 		return globalCfg.hasSettingForUsingModifiedFlag() ?
 				globalCfg.isGlobalWithModifiedFlag() : aud.withModifiedFlag();
 	}
 
 	private void setPropertyRelationMappedBy(XProperty property, PropertyAuditingData propertyData) {
 		final OneToMany oneToMany = property.getAnnotation( OneToMany.class );
 		if ( oneToMany != null && !"".equals( oneToMany.mappedBy() ) ) {
 			propertyData.setRelationMappedBy( oneToMany.mappedBy() );
 		}
 	}
 
 	private void setPropertyAuditMappedBy(XProperty property, PropertyAuditingData propertyData) {
 		final AuditMappedBy auditMappedBy = property.getAnnotation( AuditMappedBy.class );
 		if ( auditMappedBy != null ) {
 			propertyData.setAuditMappedBy( auditMappedBy.mappedBy() );
 			if ( !"".equals( auditMappedBy.positionMappedBy() ) ) {
 				propertyData.setPositionMappedBy( auditMappedBy.positionMappedBy() );
 			}
 		}
 	}
 
 	private void addPropertyMapKey(XProperty property, PropertyAuditingData propertyData) {
 		final MapKey mapKey = property.getAnnotation( MapKey.class );
 		if ( mapKey != null ) {
 			propertyData.setMapKey( mapKey.name() );
 		}
 	}
 
 	private void addPropertyJoinTables(XProperty property, PropertyAuditingData propertyData) {
 		// first set the join table based on the AuditJoinTable annotation
 		final AuditJoinTable joinTable = property.getAnnotation( AuditJoinTable.class );
 		if ( joinTable != null ) {
 			propertyData.setJoinTable( joinTable );
 		}
 		else {
 			propertyData.setJoinTable( DEFAULT_AUDIT_JOIN_TABLE );
 		}
 	}
 
 	/**
 	 * Add the {@link AuditOverride} annotations.
 	 *
 	 * @param property the property being processed
 	 * @param propertyData the Envers auditing data for this property
 	 */
 	private void addPropertyAuditingOverrides(XProperty property, PropertyAuditingData propertyData) {
 		final AuditOverride annotationOverride = property.getAnnotation( AuditOverride.class );
 		if ( annotationOverride != null ) {
 			propertyData.addAuditingOverride( annotationOverride );
 		}
 		final AuditOverrides annotationOverrides = property.getAnnotation( AuditOverrides.class );
 		if ( annotationOverrides != null ) {
 			propertyData.addAuditingOverrides( annotationOverrides );
 		}
 	}
 
 	/**
 	 * Process the {@link AuditOverride} annotations for this property.
 	 *
 	 * @param property the property for which the {@link AuditOverride}
 	 * annotations are being processed
 	 * @param propertyData the Envers auditing data for this property
 	 *
 	 * @return {@code false} if isAudited() of the override annotation was set to
 	 */
 	private boolean processPropertyAuditingOverrides(XProperty property, PropertyAuditingData propertyData) {
 		// if this property is part of a component, process all override annotations
 		if ( this.auditedPropertiesHolder instanceof ComponentAuditingData ) {
 			final List<AuditOverride> overrides = ( (ComponentAuditingData) this.auditedPropertiesHolder ).getAuditingOverrides();
 			for ( AuditOverride override : overrides ) {
 				if ( property.getName().equals( override.name() ) ) {
 					// the override applies to this property
 					if ( !override.isAudited() ) {
 						return false;
 					}
 					else {
 						if ( override.auditJoinTable() != null ) {
 							propertyData.setJoinTable( override.auditJoinTable() );
 						}
 					}
 				}
 			}
 
 		}
 		return true;
 	}
 
 	private static final Audited DEFAULT_AUDITED = new Audited() {
 		@Override
 		public ModificationStore modStore() {
 			return ModificationStore.FULL;
 		}
 
 		@Override
 		public RelationTargetAuditMode targetAuditMode() {
 			return RelationTargetAuditMode.AUDITED;
 		}
 
 		@Override
 		public Class[] auditParents() {
 			return new Class[0];
 		}
 
 		@Override
 		public boolean withModifiedFlag() {
 			return false;
 		}
 
 		@Override
 		public String modifiedColumnName() {
 			return "";
 		}
 
 		@Override
 		public Class<? extends Annotation> annotationType() {
 			return this.getClass();
 		}
 	};
 
 	private static final AuditJoinTable DEFAULT_AUDIT_JOIN_TABLE = new AuditJoinTable() {
 		@Override
 		public String name() {
 			return "";
 		}
 
 		@Override
 		public String schema() {
 			return "";
 		}
 
 		@Override
 		public String catalog() {
 			return "";
 		}
 
 		@Override
 		public JoinColumn[] inverseJoinColumns() {
 			return new JoinColumn[0];
 		}
 
 		@Override
 		public Class<? extends Annotation> annotationType() {
 			return this.getClass();
 		}
 	};
 
 	public static class ComponentPropertiesSource implements PersistentPropertiesSource {
 		private final XClass xclass;
 		private final Component component;
 
 		protected ComponentPropertiesSource(XClass xClazz, Component component) {
 			this.xclass = xClazz;
 			this.component = component;
 		}
 
 		public ComponentPropertiesSource(ReflectionManager reflectionManager, Component component) {
 			try {
 				this.xclass = reflectionManager.classForName( component.getComponentClassName() );
 			}
 			catch ( ClassLoadingException e ) {
 				throw new MappingException( e );
 			}
 
 			this.component = component;
 		}
 
 		@Override
 		@SuppressWarnings({ "unchecked" })
 		public Iterator<Property> getPropertyIterator() {
 			return component.getPropertyIterator();
 		}
 
 		@Override
 		public Property getProperty(String propertyName) {
 			return component.getProperty( propertyName );
 		}
 
 		@Override
 		public XClass getXClass() {
 			return xclass;
 		}
 	}
 
 	public static class DynamicComponentSource extends ComponentPropertiesSource {
 
 		private XProperty baseProperty;
 
 		public DynamicComponentSource(ReflectionManager reflectionManager, Component component, XProperty baseProperty) {
 			super( reflectionManager.toXClass( Map.class ), component );
 			this.baseProperty = baseProperty;
 		}
 	}
 
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/reader/ComponentAuditedPropertiesReader.java b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/reader/ComponentAuditedPropertiesReader.java
index b4768f8aab..270bb1cefd 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/reader/ComponentAuditedPropertiesReader.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/reader/ComponentAuditedPropertiesReader.java
@@ -1,78 +1,79 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.configuration.internal.metadata.reader;
 
 import org.hibernate.annotations.common.reflection.ReflectionManager;
 import org.hibernate.annotations.common.reflection.XProperty;
 import org.hibernate.envers.Audited;
 import org.hibernate.envers.ModificationStore;
 import org.hibernate.envers.configuration.internal.GlobalConfiguration;
 import org.hibernate.envers.configuration.internal.metadata.MetadataTools;
 
 /**
  * Reads the audited properties for components.
  *
  * @author Hern&aacut;n Chanfreau
  * @author Michal Skowronek (mskowr at o2 dot pl)
  */
 public class ComponentAuditedPropertiesReader extends AuditedPropertiesReader {
 
 	public ComponentAuditedPropertiesReader(
 			ModificationStore defaultStore,
 			PersistentPropertiesSource persistentPropertiesSource,
 			AuditedPropertiesHolder auditedPropertiesHolder,
 			GlobalConfiguration globalCfg, ReflectionManager reflectionManager,
 			String propertyNamePrefix) {
 		super(
 				defaultStore, persistentPropertiesSource, auditedPropertiesHolder,
 				globalCfg, reflectionManager, propertyNamePrefix
 		);
 	}
 
 	@Override
 	protected boolean checkAudited(
 			XProperty property,
 			PropertyAuditingData propertyData, String propertyName,
 			Audited allClassAudited, String modifiedFlagSuffix) {
 		// Checking if this property is explicitly audited or if all properties are.
 		final Audited aud = property.getAnnotation( Audited.class );
 		if ( aud != null ) {
 			propertyData.setStore( aud.modStore() );
 			propertyData.setRelationTargetAuditMode( aud.targetAuditMode() );
 			propertyData.setUsingModifiedFlag( checkUsingModifiedFlag( aud ) );
 			if(aud.modifiedColumnName() != null && !"".equals(aud.modifiedColumnName())) {
 				propertyData.setModifiedFlagName(aud.modifiedColumnName());
-			} else {
+			}
+			else {
 				propertyData.setModifiedFlagName(
 						MetadataTools.getModifiedFlagPropertyName( propertyName, modifiedFlagSuffix )
 				);
 			}
 		}
 		else {
 			propertyData.setStore( ModificationStore.FULL );
 		}
 		return true;
 	}
 
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/EntityConfiguration.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/EntityConfiguration.java
index d734eb95f4..5c3b5f3b61 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/EntityConfiguration.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/EntityConfiguration.java
@@ -1,153 +1,169 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities;
 
 import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.envers.internal.entities.mapper.ExtendedPropertyMapper;
 import org.hibernate.envers.internal.entities.mapper.PropertyMapper;
 import org.hibernate.envers.internal.entities.mapper.id.IdMapper;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  * @author HernпїЅn Chanfreau
  */
 public class EntityConfiguration {
 	private String versionsEntityName;
 	/**
 	 * Holds the className for instantiation the configured entity
 	 */
 	private String entityClassName;
 	private IdMappingData idMappingData;
 	private ExtendedPropertyMapper propertyMapper;
 	// Maps from property name
 	private Map<String, RelationDescription> relations;
 	private String parentEntityName;
 
-	public EntityConfiguration(String versionsEntityName, String entityClassName, IdMappingData idMappingData,
-							   ExtendedPropertyMapper propertyMapper, String parentEntityName) {
+	public EntityConfiguration(
+			String versionsEntityName,
+			String entityClassName,
+			IdMappingData idMappingData,
+			ExtendedPropertyMapper propertyMapper,
+			String parentEntityName) {
 		this.versionsEntityName = versionsEntityName;
 		this.entityClassName = entityClassName;
 		this.idMappingData = idMappingData;
 		this.propertyMapper = propertyMapper;
 		this.parentEntityName = parentEntityName;
 
 		this.relations = new HashMap<String, RelationDescription>();
 	}
 
-	public void addToOneRelation(String fromPropertyName, String toEntityName, IdMapper idMapper, boolean insertable,
-								 boolean ignoreNotFound) {
+	public void addToOneRelation(
+			String fromPropertyName,
+			String toEntityName,
+			IdMapper idMapper,
+			boolean insertable,
+			boolean ignoreNotFound) {
 		relations.put(
 				fromPropertyName,
 				RelationDescription.toOne(
 						fromPropertyName, RelationType.TO_ONE, toEntityName, null, idMapper, null,
 						null, insertable, ignoreNotFound
 				)
 		);
 	}
 
-	public void addToOneNotOwningRelation(String fromPropertyName, String mappedByPropertyName,
-										  String toEntityName, IdMapper idMapper, boolean ignoreNotFound) {
+	public void addToOneNotOwningRelation(
+			String fromPropertyName,
+			String mappedByPropertyName,
+			String toEntityName,
+			IdMapper idMapper,
+			boolean ignoreNotFound) {
 		relations.put(
 				fromPropertyName,
 				RelationDescription.toOne(
 						fromPropertyName, RelationType.TO_ONE_NOT_OWNING, toEntityName, mappedByPropertyName,
 						idMapper, null, null, true, ignoreNotFound
 				)
 		);
 	}
 
-	public void addToManyNotOwningRelation(String fromPropertyName, String mappedByPropertyName, String toEntityName,
-										   IdMapper idMapper, PropertyMapper fakeBidirectionalRelationMapper,
-										   PropertyMapper fakeBidirectionalRelationIndexMapper) {
+	public void addToManyNotOwningRelation(
+			String fromPropertyName,
+			String mappedByPropertyName,
+			String toEntityName,
+			IdMapper idMapper,
+			PropertyMapper fakeBidirectionalRelationMapper,
+			PropertyMapper fakeBidirectionalRelationIndexMapper) {
 		relations.put(
 				fromPropertyName,
 				RelationDescription.toMany(
 						fromPropertyName, RelationType.TO_MANY_NOT_OWNING, toEntityName, mappedByPropertyName,
 						idMapper, fakeBidirectionalRelationMapper, fakeBidirectionalRelationIndexMapper, true
 				)
 		);
 	}
 
 	public void addToManyMiddleRelation(String fromPropertyName, String toEntityName) {
 		relations.put(
 				fromPropertyName,
 				RelationDescription.toMany(
 						fromPropertyName, RelationType.TO_MANY_MIDDLE, toEntityName, null, null, null, null, true
 				)
 		);
 	}
 
 	public void addToManyMiddleNotOwningRelation(String fromPropertyName, String mappedByPropertyName, String toEntityName) {
 		relations.put(
 				fromPropertyName,
 				RelationDescription.toMany(
 						fromPropertyName, RelationType.TO_MANY_MIDDLE_NOT_OWNING, toEntityName, mappedByPropertyName,
 						null, null, null, true
 				)
 		);
 	}
 
 	public boolean isRelation(String propertyName) {
 		return relations.get( propertyName ) != null;
 	}
 
 	public RelationDescription getRelationDescription(String propertyName) {
 		return relations.get( propertyName );
 	}
 
 	public IdMappingData getIdMappingData() {
 		return idMappingData;
 	}
 
 	public IdMapper getIdMapper() {
 		return idMappingData.getIdMapper();
 	}
 
 	public ExtendedPropertyMapper getPropertyMapper() {
 		return propertyMapper;
 	}
 
 	public String getParentEntityName() {
 		return parentEntityName;
 	}
 
 	/**
 	 * @return the className for the configured entity
 	 */
 	public String getEntityClassName() {
 		return entityClassName;
 	}
 
 	// For use by EntitiesConfigurations
 
 	String getVersionsEntityName() {
 		return versionsEntityName;
 	}
 
 	Iterable<RelationDescription> getRelationsIterator() {
 		return relations.values();
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/RelationDescription.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/RelationDescription.java
index 691dbad671..fdc2f5c332 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/RelationDescription.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/RelationDescription.java
@@ -1,126 +1,145 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities;
 
 import org.hibernate.envers.internal.entities.mapper.PropertyMapper;
 import org.hibernate.envers.internal.entities.mapper.id.IdMapper;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  */
 public class RelationDescription {
 	private final String fromPropertyName;
 	private final RelationType relationType;
 	private final String toEntityName;
 	private final String mappedByPropertyName;
 	private final boolean ignoreNotFound;
 	private final IdMapper idMapper;
 	private final PropertyMapper fakeBidirectionalRelationMapper;
 	private final PropertyMapper fakeBidirectionalRelationIndexMapper;
 	private final boolean insertable;
 	private boolean bidirectional;
 
-	public static RelationDescription toOne(String fromPropertyName, RelationType relationType, String toEntityName,
-											String mappedByPropertyName, IdMapper idMapper, PropertyMapper fakeBidirectionalRelationMapper,
-											PropertyMapper fakeBidirectionalRelationIndexMapper, boolean insertable,
-											boolean ignoreNotFound) {
+	public static RelationDescription toOne(
+			String fromPropertyName,
+			RelationType relationType,
+			String toEntityName,
+			String mappedByPropertyName,
+			IdMapper idMapper,
+			PropertyMapper fakeBidirectionalRelationMapper,
+			PropertyMapper fakeBidirectionalRelationIndexMapper,
+			boolean insertable,
+			boolean ignoreNotFound) {
 		return new RelationDescription(
-				fromPropertyName, relationType, toEntityName, mappedByPropertyName, idMapper, fakeBidirectionalRelationMapper,
-				fakeBidirectionalRelationIndexMapper, insertable, ignoreNotFound
+				fromPropertyName, relationType, toEntityName, mappedByPropertyName, idMapper,
+				fakeBidirectionalRelationMapper, fakeBidirectionalRelationIndexMapper, insertable, ignoreNotFound
 		);
 	}
 
-	public static RelationDescription toMany(String fromPropertyName, RelationType relationType, String toEntityName,
-											 String mappedByPropertyName, IdMapper idMapper, PropertyMapper fakeBidirectionalRelationMapper,
-											 PropertyMapper fakeBidirectionalRelationIndexMapper, boolean insertable) {
+	public static RelationDescription toMany(
+			String fromPropertyName,
+			RelationType relationType,
+			String toEntityName,
+			String mappedByPropertyName,
+			IdMapper idMapper,
+			PropertyMapper fakeBidirectionalRelationMapper,
+			PropertyMapper fakeBidirectionalRelationIndexMapper,
+			boolean insertable) {
 		// Envers populates collections by executing dedicated queries. Special handling of
 		// @NotFound(action = NotFoundAction.IGNORE) can be omitted in such case as exceptions
 		// (e.g. EntityNotFoundException, ObjectNotFoundException) are never thrown.
 		// Therefore assigning false to ignoreNotFound.
 		return new RelationDescription(
 				fromPropertyName, relationType, toEntityName, mappedByPropertyName, idMapper, fakeBidirectionalRelationMapper,
 				fakeBidirectionalRelationIndexMapper, insertable, false
 		);
 	}
 
-	private RelationDescription(String fromPropertyName, RelationType relationType, String toEntityName,
-								String mappedByPropertyName, IdMapper idMapper, PropertyMapper fakeBidirectionalRelationMapper,
-								PropertyMapper fakeBidirectionalRelationIndexMapper, boolean insertable, boolean ignoreNotFound) {
+	private RelationDescription(
+			String fromPropertyName,
+			RelationType relationType,
+			String toEntityName,
+			String mappedByPropertyName,
+			IdMapper idMapper,
+			PropertyMapper fakeBidirectionalRelationMapper,
+			PropertyMapper fakeBidirectionalRelationIndexMapper,
+			boolean insertable,
+			boolean ignoreNotFound) {
 		this.fromPropertyName = fromPropertyName;
 		this.relationType = relationType;
 		this.toEntityName = toEntityName;
 		this.mappedByPropertyName = mappedByPropertyName;
 		this.ignoreNotFound = ignoreNotFound;
 		this.idMapper = idMapper;
 		this.fakeBidirectionalRelationMapper = fakeBidirectionalRelationMapper;
 		this.fakeBidirectionalRelationIndexMapper = fakeBidirectionalRelationIndexMapper;
 		this.insertable = insertable;
 
 		this.bidirectional = false;
 	}
 
 	public String getFromPropertyName() {
 		return fromPropertyName;
 	}
 
 	public RelationType getRelationType() {
 		return relationType;
 	}
 
 	public String getToEntityName() {
 		return toEntityName;
 	}
 
 	public String getMappedByPropertyName() {
 		return mappedByPropertyName;
 	}
 
 	public boolean isIgnoreNotFound() {
 		return ignoreNotFound;
 	}
 
 	public IdMapper getIdMapper() {
 		return idMapper;
 	}
 
 	public PropertyMapper getFakeBidirectionalRelationMapper() {
 		return fakeBidirectionalRelationMapper;
 	}
 
 	public PropertyMapper getFakeBidirectionalRelationIndexMapper() {
 		return fakeBidirectionalRelationIndexMapper;
 	}
 
 	public boolean isInsertable() {
 		return insertable;
 	}
 
 	public boolean isBidirectional() {
 		return bidirectional;
 	}
 
 	void setBidirectional(boolean bidirectional) {
 		this.bidirectional = bidirectional;
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/OneToOneNotOwningMapper.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/OneToOneNotOwningMapper.java
index 0a0f43fdbf..a880d62802 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/OneToOneNotOwningMapper.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/OneToOneNotOwningMapper.java
@@ -1,62 +1,65 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities.mapper.relation;
 
 import java.io.Serializable;
-import javax.persistence.OneToOne;
 
 import org.hibernate.envers.internal.entities.PropertyData;
 import org.hibernate.envers.internal.reader.AuditReaderImplementor;
 import org.hibernate.envers.query.AuditEntity;
 
 /**
- * Property mapper for not owning side of {@link OneToOne} relation.
+ * Property mapper for not owning side of {@link javax.persistence.OneToOne} relation.
  *
  * @author Adam Warski (adam at warski dot org)
  * @author HernпїЅn Chanfreau
  * @author Michal Skowronek (mskowr at o2 dot pl)
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public class OneToOneNotOwningMapper extends AbstractOneToOneMapper {
 	private final String owningReferencePropertyName;
 
 	public OneToOneNotOwningMapper(
-			String notOwningEntityName, String owningEntityName, String owningReferencePropertyName,
+			String notOwningEntityName,
+			String owningEntityName,
+			String owningReferencePropertyName,
 			PropertyData propertyData) {
 		super( notOwningEntityName, owningEntityName, propertyData );
 		this.owningReferencePropertyName = owningReferencePropertyName;
 	}
 
 	@Override
 	protected Object queryForReferencedEntity(
-			AuditReaderImplementor versionsReader, EntityInfo referencedEntity,
-			Serializable primaryKey, Number revision) {
+			AuditReaderImplementor versionsReader,
+			EntityInfo referencedEntity,
+			Serializable primaryKey,
+			Number revision) {
 		return versionsReader.createQuery().forEntitiesAtRevision(
 				referencedEntity.getEntityClass(),
 				referencedEntity.getEntityName(), revision
 		)
 				.add( AuditEntity.relatedId( owningReferencePropertyName ).eq( primaryKey ) )
 				.getSingleResult();
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/revisioninfo/RevisionInfoGenerator.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/revisioninfo/RevisionInfoGenerator.java
index 30fa321d36..69f51effca 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/revisioninfo/RevisionInfoGenerator.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/revisioninfo/RevisionInfoGenerator.java
@@ -1,46 +1,45 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.revisioninfo;
 
 import java.io.Serializable;
 
 import org.hibernate.Session;
-import org.hibernate.envers.EntityTrackingRevisionListener;
 import org.hibernate.envers.RevisionType;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  */
 public interface RevisionInfoGenerator {
 	void saveRevisionData(Session session, Object revisionData);
 
 	Object generate();
 
 	/**
-	 * @see EntityTrackingRevisionListener#entityChanged(Class, String, Serializable, RevisionType, Object)
+	 * @see org.hibernate.envers.EntityTrackingRevisionListener#entityChanged(Class, String, Serializable, RevisionType, Object)
 	 */
 	void entityChanged(
 			Class entityClass, String entityName, Serializable entityId, RevisionType revisionType,
 			Object revisionEntity);
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/MapProxyTool.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/MapProxyTool.java
index 411d876cd5..774d9af349 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/MapProxyTool.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/MapProxyTool.java
@@ -1,160 +1,184 @@
 package org.hibernate.envers.internal.tools;
 
 import java.io.Serializable;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
 import java.util.Set;
 
 import javassist.CannotCompileException;
 import javassist.ClassPool;
 import javassist.CtClass;
 import javassist.CtConstructor;
 import javassist.CtField;
 import javassist.CtMethod;
 import javassist.CtNewConstructor;
 import javassist.NotFoundException;
 
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.boot.registry.classloading.spi.ClassLoadingException;
 import org.hibernate.envers.internal.entities.PropertyData;
 
 import static org.hibernate.envers.internal.tools.StringTools.capitalizeFirst;
 import static org.hibernate.envers.internal.tools.StringTools.getLastComponent;
 
 /**
  * @author Lukasz Zuchowski (author at zuchos dot com)
  */
 public final class MapProxyTool {
 	private MapProxyTool() {
 	}
 
 	/**
-     * @param className               Name of the class to construct (should be unique within class loader)
-     * @param map                instance that will be proxied by java bean
-     * @param propertyDatas      properties that should java bean declare
-     * @param classLoaderService
-     * @return new instance of proxy
-     * @author Lukasz Zuchowski (author at zuchos dot com)
-     * Creates instance of map proxy class. This proxy class will be a java bean with properties from <code>propertyDatas</code>.
-     * Instance will proxy calls to instance of the map passed as parameter.
-     */
-    public static Object newInstanceOfBeanProxyForMap(String className, Map<String, Object> map, Set<PropertyData> propertyDatas, ClassLoaderService classLoaderService) {
-        Map<String, Class<?>> properties = prepareProperties(propertyDatas);
-        return createNewInstance(map, classForName(className, properties, classLoaderService));
-    }
-
-    private static Object createNewInstance(Map<String, Object> map, Class aClass) {
-        try {
-            return aClass.getConstructor(Map.class).newInstance(map);
-        } catch (Exception e) {
-            throw new RuntimeException(e);
-        }
-    }
-
-    private static Map<String, Class<?>> prepareProperties(Set<PropertyData> propertyDatas) {
-        Map<String, Class<?>> properties = new HashMap<String, Class<?>>();
-        for (PropertyData propertyData : propertyDatas) {
-            properties.put(propertyData.getBeanName(), Object.class);
-        }
-        return properties;
-    }
-
-    private static Class loadClass(String className, ClassLoaderService classLoaderService) {
-        try {
-            return ReflectionTools.loadClass(className, classLoaderService);
-        } catch (ClassLoadingException e) {
-            return null;
-        }
-
-    }
-
-    /**
-     * Generates/loads proxy class for given name with properties for map.
-     * @param className name of the class that will be generated/loaded
-     * @param properties list of properties that should be exposed via java bean
-     * @param classLoaderService
-     * @return proxy class that wraps map into java bean
-     */
-    public static Class classForName(String className, Map<String,Class<?>> properties, ClassLoaderService classLoaderService) {
-        Class aClass = loadClass(className, classLoaderService);
-        if (aClass == null) {
-            aClass = generate(className, properties);
-        }
-        return aClass;
-    }
-
-    /**
-     * Protected for test only
-     */
-    protected static Class generate(String className, Map<String, Class<?>> properties) {
-        try {
-            ClassPool pool = ClassPool.getDefault();
-            CtClass cc = pool.makeClass(className);
-
-            cc.addInterface(resolveCtClass(Serializable.class));
-            cc.addField(new CtField(resolveCtClass(Map.class), "theMap", cc));
-            cc.addConstructor(generateConstructor(className, cc));
-
-            for (Entry<String, Class<?>> entry : properties.entrySet()) {
-
-                // add getter
-                cc.addMethod(generateGetter(cc, entry.getKey(), entry.getValue()));
-
-                // add setter
-                cc.addMethod(generateSetter(cc, entry.getKey(), entry.getValue()));
-            }
-            return cc.toClass();
-        } catch (Exception e) {
-            throw new RuntimeException(e);
-        }
-    }
-
-    private static CtConstructor generateConstructor(String className, CtClass cc) throws NotFoundException, CannotCompileException {
-        StringBuffer sb = new StringBuffer();
-        sb.append("public ").append(getLastComponent(className)).append("(").append(Map.class.getName()).append(" map)").append("{")
-                .append("this.theMap = map;").append("}");
-        System.out.println(sb);
-        return CtNewConstructor.make(sb.toString(), cc);
-    }
-
-    private static CtMethod generateGetter(CtClass declaringClass, String fieldName, Class fieldClass)
-            throws CannotCompileException {
-
-        String getterName = "get" + capitalizeFirst(fieldName);
-
-        StringBuilder sb = new StringBuilder();
-        sb.append("public ").append(fieldClass.getName()).append(" ")
-                .append(getterName).append("(){").append("return (").append(fieldClass.getName()).append(")this.theMap.get(\"")
-                .append(fieldName).append("\")").append(";").append("}");
-        return CtMethod.make(sb.toString(), declaringClass);
-    }
-
-    private static CtMethod generateSetter(CtClass declaringClass, String fieldName, Class fieldClass)
-            throws CannotCompileException {
-
-        String setterName = "set" + capitalizeFirst(fieldName);
-
-        StringBuilder sb = new StringBuilder();
-        sb.append("public void ").append(setterName).append("(")
-                .append(fieldClass.getName()).append(" ").append(fieldName)
-                .append(")").append("{").append("this.theMap.put(\"").append(fieldName)
-                .append("\",").append(fieldName).append(")").append(";").append("}");
-        return CtMethod.make(sb.toString(), declaringClass);
-    }
-
-    private static CtClass resolveCtClass(Class clazz) throws NotFoundException {
-        return resolveCtClass(clazz.getName());
-    }
-
-
-    private static CtClass resolveCtClass(String clazz) throws NotFoundException {
-        try {
-            ClassPool pool = ClassPool.getDefault();
-            return pool.get(clazz);
-        } catch (NotFoundException e) {
-            return null;
-        }
-    }
+	 * @param className Name of the class to construct (should be unique within class loader)
+	 * @param map instance that will be proxied by java bean
+	 * @param propertyDatas properties that should java bean declare
+	 * @param classLoaderService
+	 *
+	 * @return new instance of proxy
+	 *
+	 * @author Lukasz Zuchowski (author at zuchos dot com)
+	 * Creates instance of map proxy class. This proxy class will be a java bean with properties from <code>propertyDatas</code>.
+	 * Instance will proxy calls to instance of the map passed as parameter.
+	 */
+	public static Object newInstanceOfBeanProxyForMap(
+			String className,
+			Map<String, Object> map,
+			Set<PropertyData> propertyDatas,
+			ClassLoaderService classLoaderService) {
+		Map<String, Class<?>> properties = prepareProperties( propertyDatas );
+		return createNewInstance( map, classForName( className, properties, classLoaderService ) );
+	}
+
+	private static Object createNewInstance(Map<String, Object> map, Class aClass) {
+		try {
+			return aClass.getConstructor( Map.class ).newInstance( map );
+		}
+		catch (Exception e) {
+			throw new RuntimeException( e );
+		}
+	}
+
+	private static Map<String, Class<?>> prepareProperties(Set<PropertyData> propertyDatas) {
+		Map<String, Class<?>> properties = new HashMap<String, Class<?>>();
+		for ( PropertyData propertyData : propertyDatas ) {
+			properties.put( propertyData.getBeanName(), Object.class );
+		}
+		return properties;
+	}
+
+	private static Class loadClass(String className, ClassLoaderService classLoaderService) {
+		try {
+			return ReflectionTools.loadClass( className, classLoaderService );
+		}
+		catch (ClassLoadingException e) {
+			return null;
+		}
+
+	}
+
+	/**
+	 * Generates/loads proxy class for given name with properties for map.
+	 *
+	 * @param className name of the class that will be generated/loaded
+	 * @param properties list of properties that should be exposed via java bean
+	 * @param classLoaderService
+	 *
+	 * @return proxy class that wraps map into java bean
+	 */
+	public static Class classForName(
+			String className,
+			Map<String, Class<?>> properties,
+			ClassLoaderService classLoaderService) {
+		Class aClass = loadClass( className, classLoaderService );
+		if ( aClass == null ) {
+			aClass = generate( className, properties );
+		}
+		return aClass;
+	}
+
+	/**
+	 * Protected for test only
+	 */
+	protected static Class generate(String className, Map<String, Class<?>> properties) {
+		try {
+			ClassPool pool = ClassPool.getDefault();
+			CtClass cc = pool.makeClass( className );
+
+			cc.addInterface( resolveCtClass( Serializable.class ) );
+			cc.addField( new CtField( resolveCtClass( Map.class ), "theMap", cc ) );
+			cc.addConstructor( generateConstructor( className, cc ) );
+
+			for ( Entry<String, Class<?>> entry : properties.entrySet() ) {
+
+				// add getter
+				cc.addMethod( generateGetter( cc, entry.getKey(), entry.getValue() ) );
+
+				// add setter
+				cc.addMethod( generateSetter( cc, entry.getKey(), entry.getValue() ) );
+			}
+			return cc.toClass();
+		}
+		catch (Exception e) {
+			throw new RuntimeException( e );
+		}
+	}
+
+	private static CtConstructor generateConstructor(String className, CtClass cc)
+			throws NotFoundException, CannotCompileException {
+		StringBuffer sb = new StringBuffer();
+		sb.append( "public " )
+				.append( getLastComponent( className ) )
+				.append( "(" )
+				.append( Map.class.getName() )
+				.append( " map)" )
+				.append( "{" )
+				.append( "this.theMap = map;" )
+				.append( "}" );
+		System.out.println( sb );
+		return CtNewConstructor.make( sb.toString(), cc );
+	}
+
+	private static CtMethod generateGetter(CtClass declaringClass, String fieldName, Class fieldClass)
+			throws CannotCompileException {
+
+		String getterName = "get" + capitalizeFirst( fieldName );
+
+		StringBuilder sb = new StringBuilder();
+		sb.append( "public " ).append( fieldClass.getName() ).append( " " )
+				.append( getterName ).append( "(){" ).append( "return (" ).append( fieldClass.getName() ).append(
+				")this.theMap.get(\""
+		)
+				.append( fieldName ).append( "\")" ).append( ";" ).append( "}" );
+		return CtMethod.make( sb.toString(), declaringClass );
+	}
+
+	private static CtMethod generateSetter(CtClass declaringClass, String fieldName, Class fieldClass)
+			throws CannotCompileException {
+
+		String setterName = "set" + capitalizeFirst( fieldName );
+
+		StringBuilder sb = new StringBuilder();
+		sb.append( "public void " ).append( setterName ).append( "(" )
+				.append( fieldClass.getName() ).append( " " ).append( fieldName )
+				.append( ")" ).append( "{" ).append( "this.theMap.put(\"" ).append( fieldName )
+				.append( "\"," ).append( fieldName ).append( ")" ).append( ";" ).append( "}" );
+		return CtMethod.make( sb.toString(), declaringClass );
+	}
+
+	private static CtClass resolveCtClass(Class clazz) throws NotFoundException {
+		return resolveCtClass( clazz.getName() );
+	}
+
+
+	private static CtClass resolveCtClass(String clazz) throws NotFoundException {
+		try {
+			ClassPool pool = ClassPool.getDefault();
+			return pool.get( clazz );
+		}
+		catch (NotFoundException e) {
+			return null;
+		}
+	}
 
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/StringTools.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/StringTools.java
index 97ea076e4d..ce37721785 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/StringTools.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/StringTools.java
@@ -1,86 +1,90 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.tools;
 
 import java.util.Iterator;
 import java.util.Locale;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  * @author Lukasz Zuchowski (author at zuchos dot com)
  */
 public abstract class StringTools {
-    public static boolean isEmpty(String s) {
-        return s == null || "".equals(s);
-    }
+	public static boolean isEmpty(String s) {
+		return s == null || "".equals( s );
+	}
 
-    public static boolean isEmpty(Object o) {
-        return o == null || "".equals(o);
-    }
+	public static boolean isEmpty(Object o) {
+		return o == null || "".equals( o );
+	}
 
-    /**
-     * @param s String, from which to get the last component.
-     * @return The last component of the dot-separated string <code>s</code>. For example, for a string
-     *         "a.b.c", the result is "c".
-     */
-    public static String getLastComponent(String s) {
-        if (s == null) {
-            return null;
-        }
-        final int lastDot = s.lastIndexOf(".");
-        if (lastDot == -1) {
-            return s;
-        } else {
-            return s.substring(lastDot + 1);
-        }
-    }
+	/**
+	 * @param s String, from which to get the last component.
+	 *
+	 * @return The last component of the dot-separated string <code>s</code>. For example, for a string
+	 * "a.b.c", the result is "c".
+	 */
+	public static String getLastComponent(String s) {
+		if ( s == null ) {
+			return null;
+		}
+		final int lastDot = s.lastIndexOf( "." );
+		if ( lastDot == -1 ) {
+			return s;
+		}
+		else {
+			return s.substring( lastDot + 1 );
+		}
+	}
 
-    /**
-     * To the given string builder, appends all strings in the given iterator, separating them with the given
-     * separator. For example, for an interator "a" "b" "c" and separator ":" the output is "a:b:c".
-     *
-     * @param sb        String builder, to which to append.
-     * @param contents  Strings to be appended.
-     * @param separator Separator between subsequent content.
-     */
-    public static void append(StringBuilder sb, Iterator<String> contents, String separator) {
-        boolean isFirst = true;
-        while (contents.hasNext()) {
-            if (!isFirst) {
-                sb.append(separator);
-            }
-            sb.append(contents.next());
-            isFirst = false;
-        }
-    }
+	/**
+	 * To the given string builder, appends all strings in the given iterator, separating them with the given
+	 * separator. For example, for an interator "a" "b" "c" and separator ":" the output is "a:b:c".
+	 *
+	 * @param sb String builder, to which to append.
+	 * @param contents Strings to be appended.
+	 * @param separator Separator between subsequent content.
+	 */
+	public static void append(StringBuilder sb, Iterator<String> contents, String separator) {
+		boolean isFirst = true;
+		while ( contents.hasNext() ) {
+			if ( !isFirst ) {
+				sb.append( separator );
+			}
+			sb.append( contents.next() );
+			isFirst = false;
+		}
+	}
 
-    /**
-     * Capitalizes first letter of the string
-     * @param fieldName
-     * @return capitalized string
-     */
-    public static String capitalizeFirst(String fieldName) {
-        return fieldName.substring(0, 1).toUpperCase(Locale.ROOT) + fieldName.substring(1);
-    }
+	/**
+	 * Capitalizes first letter of the string
+	 *
+	 * @param fieldName
+	 *
+	 * @return capitalized string
+	 */
+	public static String capitalizeFirst(String fieldName) {
+		return fieldName.substring( 0, 1 ).toUpperCase( Locale.ROOT ) + fieldName.substring( 1 );
+	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/AuditEntity.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/AuditEntity.java
index 5b6e67dc7d..84aec0055a 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/AuditEntity.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/AuditEntity.java
@@ -1,134 +1,134 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query;
 
-import org.hibernate.criterion.Restrictions;
 import org.hibernate.envers.RevisionType;
 import org.hibernate.envers.query.criteria.AuditConjunction;
 import org.hibernate.envers.query.criteria.AuditCriterion;
 import org.hibernate.envers.query.criteria.AuditDisjunction;
 import org.hibernate.envers.query.criteria.AuditId;
 import org.hibernate.envers.query.criteria.AuditProperty;
 import org.hibernate.envers.query.criteria.AuditRelatedId;
 import org.hibernate.envers.query.criteria.internal.LogicalAuditExpression;
 import org.hibernate.envers.query.criteria.internal.NotAuditExpression;
 import org.hibernate.envers.query.internal.property.EntityPropertyName;
 import org.hibernate.envers.query.internal.property.RevisionNumberPropertyName;
 import org.hibernate.envers.query.internal.property.RevisionPropertyPropertyName;
 import org.hibernate.envers.query.internal.property.RevisionTypePropertyName;
 
 /**
  * TODO: ilike
  *
  * @author Adam Warski (adam at warski dot org)
- * @see Restrictions
+ *
+ * @see org.hibernate.criterion.Restrictions
  */
 @SuppressWarnings({"JavaDoc"})
 public class AuditEntity {
 	private AuditEntity() {
 	}
 
 	public static AuditId id() {
 		return new AuditId();
 	}
 
 	/**
 	 * Create restrictions, projections and specify order for a property of an audited entity.
 	 *
 	 * @param propertyName Name of the property.
 	 */
 	public static AuditProperty<Object> property(String propertyName) {
 		return new AuditProperty<Object>( new EntityPropertyName( propertyName ) );
 	}
 
 	/**
 	 * Create restrictions, projections and specify order for the revision number, corresponding to an
 	 * audited entity.
 	 */
 	public static AuditProperty<Number> revisionNumber() {
 		return new AuditProperty<Number>( new RevisionNumberPropertyName() );
 	}
 
 	/**
 	 * Create restrictions, projections and specify order for a property of the revision entity,
 	 * corresponding to an audited entity.
 	 *
 	 * @param propertyName Name of the property.
 	 */
 	public static AuditProperty<Object> revisionProperty(String propertyName) {
 		return new AuditProperty<Object>( new RevisionPropertyPropertyName( propertyName ) );
 	}
 
 	/**
 	 * Create restrictions, projections and specify order for the revision type, corresponding to an
 	 * audited entity.
 	 */
 	public static AuditProperty<RevisionType> revisionType() {
 		return new AuditProperty<RevisionType>( new RevisionTypePropertyName() );
 	}
 
 	/**
 	 * Create restrictions on an id of a related entity.
 	 *
 	 * @param propertyName Name of the property, which is the relation.
 	 */
 	public static AuditRelatedId relatedId(String propertyName) {
 		return new AuditRelatedId( new EntityPropertyName( propertyName ) );
 	}
 
 	/**
 	 * Return the conjuction of two criterions.
 	 */
 	public static AuditCriterion and(AuditCriterion lhs, AuditCriterion rhs) {
 		return new LogicalAuditExpression( lhs, rhs, "and" );
 	}
 
 	/**
 	 * Return the disjuction of two criterions.
 	 */
 	public static AuditCriterion or(AuditCriterion lhs, AuditCriterion rhs) {
 		return new LogicalAuditExpression( lhs, rhs, "or" );
 	}
 
 	/**
 	 * Return the negation of a criterion.
 	 */
 	public static AuditCriterion not(AuditCriterion expression) {
 		return new NotAuditExpression( expression );
 	}
 
 	/**
 	 * Group criterions together in a single conjunction (A and B and C...).
 	 */
 	public static AuditConjunction conjunction() {
 		return new AuditConjunction();
 	}
 
 	/**
 	 * Group criterions together in a single disjunction (A or B or C...).
 	 */
 	public static AuditDisjunction disjunction() {
 		return new AuditDisjunction();
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditId.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditId.java
index d3573055ed..9f82244519 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditId.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditId.java
@@ -1,75 +1,72 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query.criteria;
 
 import org.hibernate.envers.query.criteria.internal.IdentifierEqAuditExpression;
 import org.hibernate.envers.query.internal.property.EntityPropertyName;
-import org.hibernate.envers.query.internal.property.OriginalIdPropertyName;
 import org.hibernate.envers.query.internal.property.PropertyNameGetter;
-import org.hibernate.envers.query.projection.AuditProjection;
-import org.hibernate.envers.query.projection.internal.PropertyAuditProjection;
 
 /**
  * Create restrictions and projections for the id of an audited entity.
  *
  * @author Adam Warski (adam at warski dot org)
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 @SuppressWarnings({"JavaDoc"})
 public class AuditId<T> extends AuditProperty<T> {
 	public static final String IDENTIFIER_PLACEHOLDER = "$$id$$";
 	private static final PropertyNameGetter IDENTIFIER_PROPERTY_GETTER = new EntityPropertyName( IDENTIFIER_PLACEHOLDER );
 
 	public AuditId() {
 		super( IDENTIFIER_PROPERTY_GETTER );
 	}
 
 	/**
 	 * Apply an "equal" constraint
 	 */
 	@Override
 	public AuditCriterion eq(Object id) {
 		return new IdentifierEqAuditExpression( id, true );
 	}
 
 	/**
 	 * Apply a "not equal" constraint
 	 */
 	@Override
 	public AuditCriterion ne(Object id) {
 		return new IdentifierEqAuditExpression( id, false );
 	}
 
 	// Projections
 
 	@Override
 	public AuditCriterion hasChanged() {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public AuditCriterion hasNotChanged() {
 		throw new UnsupportedOperationException();
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditProperty.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditProperty.java
index 48106c1ecf..ea36f7a7bd 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditProperty.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditProperty.java
@@ -1,295 +1,295 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query.criteria;
 
 import java.util.Collection;
 
 import org.hibernate.criterion.MatchMode;
 import org.hibernate.envers.boot.internal.EnversService;
 import org.hibernate.envers.internal.tools.Triple;
 import org.hibernate.envers.query.criteria.internal.BetweenAuditExpression;
 import org.hibernate.envers.query.criteria.internal.IlikeAuditExpression;
 import org.hibernate.envers.query.criteria.internal.InAuditExpression;
 import org.hibernate.envers.query.criteria.internal.NotNullAuditExpression;
 import org.hibernate.envers.query.criteria.internal.NullAuditExpression;
 import org.hibernate.envers.query.criteria.internal.PropertyAuditExpression;
 import org.hibernate.envers.query.criteria.internal.SimpleAuditExpression;
 import org.hibernate.envers.query.internal.property.ModifiedFlagPropertyName;
 import org.hibernate.envers.query.internal.property.PropertyNameGetter;
 import org.hibernate.envers.query.order.AuditOrder;
 import org.hibernate.envers.query.order.internal.PropertyAuditOrder;
 import org.hibernate.envers.query.projection.AuditProjection;
 import org.hibernate.envers.query.projection.internal.PropertyAuditProjection;
 
 /**
  * Create restrictions, projections and specify order for a property of an audited entity.
  *
  * @author Adam Warski (adam at warski dot org)
  * @author Michal Skowronek (mskowr at o2 dot pl)
  */
 @SuppressWarnings({"JavaDoc"})
 public class AuditProperty<T> implements AuditProjection {
 	private final PropertyNameGetter propertyNameGetter;
 
 	public AuditProperty(PropertyNameGetter propertyNameGetter) {
 		this.propertyNameGetter = propertyNameGetter;
 	}
 
 	public AuditCriterion hasChanged() {
 		return new SimpleAuditExpression( new ModifiedFlagPropertyName( propertyNameGetter ), true, "=" );
 	}
 
 	public AuditCriterion hasNotChanged() {
 		return new SimpleAuditExpression( new ModifiedFlagPropertyName( propertyNameGetter ), false, "=" );
 	}
 
 	/**
 	 * Apply an "equal" constraint
 	 */
 	public AuditCriterion eq(T value) {
 		return new SimpleAuditExpression( propertyNameGetter, value, "=" );
 	}
 
 	/**
 	 * Apply a "not equal" constraint
 	 */
 	public AuditCriterion ne(T value) {
 		return new SimpleAuditExpression( propertyNameGetter, value, "<>" );
 	}
 
 	/**
 	 * Apply a "like" constraint
 	 */
 	public AuditCriterion like(T value) {
 		return new SimpleAuditExpression( propertyNameGetter, value, " like " );
 	}
 
 	/**
 	 * Apply a "like" constraint
 	 */
 	public AuditCriterion like(String value, MatchMode matchMode) {
 		return new SimpleAuditExpression( propertyNameGetter, matchMode.toMatchString( value ), " like " );
 	}
 
     /**
      *  Apply an "ilike" constraint
      */
-    public AuditCriterion ilike(T value) {
-        return new IlikeAuditExpression(propertyNameGetter, value.toString());
-    }
+	public AuditCriterion ilike(T value) {
+		return new IlikeAuditExpression(propertyNameGetter, value.toString());
+	}
 
     /**
      *  Apply an "ilike" constraint
      */
-    public AuditCriterion ilike(String value, MatchMode matchMode) {
-        return new IlikeAuditExpression( propertyNameGetter, matchMode.toMatchString( value ));
-    }
+	public AuditCriterion ilike(String value, MatchMode matchMode) {
+		return new IlikeAuditExpression( propertyNameGetter, matchMode.toMatchString( value ));
+	}
 
 	/**
 	 * Apply a "greater than" constraint
 	 */
 	public AuditCriterion gt(T value) {
 		return new SimpleAuditExpression( propertyNameGetter, value, ">" );
 	}
 
 	/**
 	 * Apply a "less than" constraint
 	 */
 	public AuditCriterion lt(T value) {
 		return new SimpleAuditExpression( propertyNameGetter, value, "<" );
 	}
 
 	/**
 	 * Apply a "less than or equal" constraint
 	 */
 	public AuditCriterion le(T value) {
 		return new SimpleAuditExpression( propertyNameGetter, value, "<=" );
 	}
 
 	/**
 	 * Apply a "greater than or equal" constraint
 	 */
 	public AuditCriterion ge(T value) {
 		return new SimpleAuditExpression( propertyNameGetter, value, ">=" );
 	}
 
 	/**
 	 * Apply a "between" constraint
 	 */
 	public AuditCriterion between(T lo, T hi) {
 		return new BetweenAuditExpression( propertyNameGetter, lo, hi );
 	}
 
 	/**
 	 * Apply an "in" constraint
 	 */
 	public AuditCriterion in(T[] values) {
 		return new InAuditExpression( propertyNameGetter, values );
 	}
 
 	/**
 	 * Apply an "in" constraint
 	 */
 	public AuditCriterion in(Collection values) {
 		return new InAuditExpression( propertyNameGetter, values.toArray() );
 	}
 
 	/**
 	 * Apply an "is null" constraint
 	 */
 	public AuditCriterion isNull() {
 		return new NullAuditExpression( propertyNameGetter );
 	}
 
 	/**
 	 * Apply an "equal" constraint to another property
 	 */
 	public AuditCriterion eqProperty(String otherPropertyName) {
 		return new PropertyAuditExpression( propertyNameGetter, otherPropertyName, "=" );
 	}
 
 	/**
 	 * Apply a "not equal" constraint to another property
 	 */
 	public AuditCriterion neProperty(String otherPropertyName) {
 		return new PropertyAuditExpression( propertyNameGetter, otherPropertyName, "<>" );
 	}
 
 	/**
 	 * Apply a "less than" constraint to another property
 	 */
 	public AuditCriterion ltProperty(String otherPropertyName) {
 		return new PropertyAuditExpression( propertyNameGetter, otherPropertyName, "<" );
 	}
 
 	/**
 	 * Apply a "less than or equal" constraint to another property
 	 */
 	public AuditCriterion leProperty(String otherPropertyName) {
 		return new PropertyAuditExpression( propertyNameGetter, otherPropertyName, "<=" );
 	}
 
 	/**
 	 * Apply a "greater than" constraint to another property
 	 */
 	public AuditCriterion gtProperty(String otherPropertyName) {
 		return new PropertyAuditExpression( propertyNameGetter, otherPropertyName, ">" );
 	}
 
 	/**
 	 * Apply a "greater than or equal" constraint to another property
 	 */
 	public AuditCriterion geProperty(String otherPropertyName) {
 		return new PropertyAuditExpression( propertyNameGetter, otherPropertyName, ">=" );
 	}
 
 	/**
 	 * Apply an "is not null" constraint to the another property
 	 */
 	public AuditCriterion isNotNull() {
 		return new NotNullAuditExpression( propertyNameGetter );
 	}
 
 	/**
 	 * Apply a "maximalize" constraint, with the ability to specify further constraints on the maximized
 	 * property
 	 */
 	public AggregatedAuditExpression maximize() {
 		return new AggregatedAuditExpression( propertyNameGetter, AggregatedAuditExpression.AggregatedMode.MAX );
 	}
 
 	/**
 	 * Apply a "minimize" constraint, with the ability to specify further constraints on the minimized
 	 * property
 	 */
 	public AggregatedAuditExpression minimize() {
 		return new AggregatedAuditExpression( propertyNameGetter, AggregatedAuditExpression.AggregatedMode.MIN );
 	}
 
 	// Projections
 
 	/**
 	 * Projection on the maximum value
 	 */
 	public AuditProjection max() {
 		return new PropertyAuditProjection( propertyNameGetter, "max", false );
 	}
 
 	/**
 	 * Projection on the minimum value
 	 */
 	public AuditProjection min() {
 		return new PropertyAuditProjection( propertyNameGetter, "min", false );
 	}
 
 	/**
 	 * Projection counting the values
 	 */
 	public AuditProjection count() {
 		return new PropertyAuditProjection( propertyNameGetter, "count", false );
 	}
 
 	/**
 	 * Projection counting distinct values
 	 */
 	public AuditProjection countDistinct() {
 		return new PropertyAuditProjection( propertyNameGetter, "count", true );
 	}
 
 	/**
 	 * Projection on distinct values
 	 */
 	public AuditProjection distinct() {
 		return new PropertyAuditProjection( propertyNameGetter, null, true );
 	}
 
 	/**
 	 * Projection using a custom function
 	 */
 	public AuditProjection function(String functionName) {
 		return new PropertyAuditProjection( propertyNameGetter, functionName, false );
 	}
 
 	// Projection on this property
 
 	public Triple<String, String, Boolean> getData(EnversService enversService) {
 		return Triple.make( null, propertyNameGetter.get( enversService ), false );
 	}
 
 	// Order
 
 	/**
 	 * Sort the results by the property in ascending order
 	 */
 	public AuditOrder asc() {
 		return new PropertyAuditOrder( propertyNameGetter, true );
 	}
 
 	/**
 	 * Sort the results by the property in descending order
 	 */
 	public AuditOrder desc() {
 		return new PropertyAuditOrder( propertyNameGetter, false );
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/strategy/AuditStrategy.java b/hibernate-envers/src/main/java/org/hibernate/envers/strategy/AuditStrategy.java
index 87e6f354e1..a9a2ef9068 100755
--- a/hibernate-envers/src/main/java/org/hibernate/envers/strategy/AuditStrategy.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/strategy/AuditStrategy.java
@@ -1,139 +1,137 @@
 package org.hibernate.envers.strategy;
 
 import java.io.Serializable;
 
 import org.hibernate.Session;
-import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.envers.boot.internal.EnversService;
 import org.hibernate.envers.configuration.internal.GlobalConfiguration;
-import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.envers.internal.entities.mapper.PersistentCollectionChangeData;
 import org.hibernate.envers.internal.entities.mapper.relation.MiddleComponentData;
 import org.hibernate.envers.internal.entities.mapper.relation.MiddleIdData;
 import org.hibernate.envers.internal.tools.query.Parameters;
 import org.hibernate.envers.internal.tools.query.QueryBuilder;
 
 /**
  * Behaviours of different audit strategy for populating audit data.
  *
  * @author Stephanie Pau
  * @author Adam Warski (adam at warski dot org)
  */
 public interface AuditStrategy {
 	/**
 	 * Perform the persistence of audited data for regular entities.
 	 *
 	 * @param session Session, which can be used to persist the data.
 	 * @param entityName Name of the entity, in which the audited change happens
 	 * @param enversService The EnversService
 	 * @param id Id of the entity.
 	 * @param data Audit data to persist
 	 * @param revision Current revision data
 	 */
 	void perform(
 			Session session,
 			String entityName,
 			EnversService enversService,
 			Serializable id,
 			Object data,
 			Object revision);
 
 	/**
 	 * Perform the persistence of audited data for collection ("middle") entities.
 	 *
 	 * @param session Session, which can be used to persist the data.
 	 * @param entityName Name of the entity, in which the audited change happens.
-	 * @param propertyName The name of the property holding the {@link PersistentCollection}.
+	 * @param propertyName The name of the property holding the persistent collection
 	 * @param enversService The EnversService
 	 * @param persistentCollectionChangeData Collection change data to be persisted.
 	 * @param revision Current revision data
 	 */
 	void performCollectionChange(
 			Session session,
 			String entityName,
 			String propertyName,
 			EnversService enversService,
 			PersistentCollectionChangeData persistentCollectionChangeData,
 			Object revision);
 
 
 	/**
 	 * Update the rootQueryBuilder with an extra WHERE clause to restrict the revision for a two-entity relation.
 	 * This WHERE clause depends on the AuditStrategy, as follows:
 	 * <ul>
 	 * <li>For {@link DefaultAuditStrategy} a subquery is created:
 	 * <p><code>e.revision = (SELECT max(...) ...)</code></p>
 	 * </li>
 	 * <li>for {@link ValidityAuditStrategy} the revision-end column is used:
 	 * <p><code>e.revision <= :revision and (e.endRevision > :revision or e.endRevision is null)</code></p>
 	 * </li>
 	 * </ul>
 	 *
 	 * @param globalCfg the {@link GlobalConfiguration}
 	 * @param rootQueryBuilder the {@link QueryBuilder} that will be updated
 	 * @param parameters root parameters to which restrictions shall be added
 	 * @param revisionProperty property of the revision column
 	 * @param revisionEndProperty property of the revisionEnd column (only used for {@link ValidityAuditStrategy})
 	 * @param addAlias {@code boolean} indicator if a left alias is needed
 	 * @param idData id-information for the two-entity relation (only used for {@link DefaultAuditStrategy})
 	 * @param revisionPropertyPath path of the revision property (only used for {@link ValidityAuditStrategy})
 	 * @param originalIdPropertyName name of the id property (only used for {@link ValidityAuditStrategy})
 	 * @param alias1 an alias used for subquery (only used for {@link ValidityAuditStrategy})
 	 * @param alias2 an alias used for subquery (only used for {@link ValidityAuditStrategy})
 	 * @param inclusive indicates whether revision number shall be treated as inclusive or exclusive
 	 */
 	void addEntityAtRevisionRestriction(
 			GlobalConfiguration globalCfg,
 			QueryBuilder rootQueryBuilder,
 			Parameters parameters,
 			String revisionProperty,
 			String revisionEndProperty,
 			boolean addAlias,
 			MiddleIdData idData,
 			String revisionPropertyPath,
 			String originalIdPropertyName,
 			String alias1,
 			String alias2,
 			boolean inclusive);
 
 	/**
 	 * Update the rootQueryBuilder with an extra WHERE clause to restrict the revision for a middle-entity
 	 * association. This WHERE clause depends on the AuditStrategy, as follows:
 	 * <ul>
 	 * <li>For {@link DefaultAuditStrategy} a subquery is created:
 	 * <p><code>e.revision = (SELECT max(...) ...)</code></p>
 	 * </li>
 	 * <li>for {@link ValidityAuditStrategy} the revision-end column is used:
 	 * <p><code>e.revision <= :revision and (e.endRevision > :revision or e.endRevision is null)</code></p>
 	 * </li>
 	 * </ul>
 	 *
 	 * @param rootQueryBuilder the {@link QueryBuilder} that will be updated
 	 * @param parameters root parameters to which restrictions shall be added
 	 * @param revisionProperty property of the revision column
 	 * @param revisionEndProperty property of the revisionEnd column (only used for {@link ValidityAuditStrategy})
 	 * @param addAlias {@code boolean} indicator if a left alias is needed
 	 * @param referencingIdData id-information for the middle-entity association (only used for {@link DefaultAuditStrategy})
 	 * @param versionsMiddleEntityName name of the middle-entity
 	 * @param eeOriginalIdPropertyPath name of the id property (only used for {@link ValidityAuditStrategy})
 	 * @param revisionPropertyPath path of the revision property (only used for {@link ValidityAuditStrategy})
 	 * @param originalIdPropertyName name of the id property (only used for {@link ValidityAuditStrategy})
 	 * @param alias1 an alias used for subqueries (only used for {@link DefaultAuditStrategy})
 	 * @param inclusive indicates whether revision number shall be treated as inclusive or exclusive
 	 * @param componentDatas information about the middle-entity relation
 	 */
 	void addAssociationAtRevisionRestriction(
 			QueryBuilder rootQueryBuilder,
 			Parameters parameters,
 			String revisionProperty,
 			String revisionEndProperty,
 			boolean addAlias,
 			MiddleIdData referencingIdData,
 			String versionsMiddleEntityName,
 			String eeOriginalIdPropertyPath,
 			String revisionPropertyPath,
 			String originalIdPropertyName,
 			String alias1,
 			boolean inclusive,
 			MiddleComponentData... componentDatas);
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/strategy/ValidityAuditStrategy.java b/hibernate-envers/src/main/java/org/hibernate/envers/strategy/ValidityAuditStrategy.java
index 8ef259ad1e..48d4146f88 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/strategy/ValidityAuditStrategy.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/strategy/ValidityAuditStrategy.java
@@ -1,369 +1,369 @@
 package org.hibernate.envers.strategy;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Date;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.LockOptions;
 import org.hibernate.Session;
 import org.hibernate.action.spi.BeforeTransactionCompletionProcess;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.envers.RevisionType;
 import org.hibernate.envers.boot.internal.EnversService;
 import org.hibernate.envers.configuration.internal.AuditEntitiesConfiguration;
 import org.hibernate.envers.configuration.internal.GlobalConfiguration;
 import org.hibernate.envers.internal.entities.mapper.PersistentCollectionChangeData;
 import org.hibernate.envers.internal.entities.mapper.relation.MiddleComponentData;
 import org.hibernate.envers.internal.entities.mapper.relation.MiddleIdData;
 import org.hibernate.envers.internal.synchronization.SessionCacheCleaner;
 import org.hibernate.envers.internal.tools.query.Parameters;
 import org.hibernate.envers.internal.tools.query.QueryBuilder;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.jdbc.ReturningWork;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.persister.entity.UnionSubclassEntityPersister;
 import org.hibernate.property.Getter;
 import org.hibernate.sql.Update;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.ComponentType;
 import org.hibernate.type.Type;
 
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.MIDDLE_ENTITY_ALIAS;
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.REVISION_PARAMETER;
 
 /**
  * Audit strategy which persists and retrieves audit information using a validity algorithm, based on the
  * start-revision and end-revision of a row in the audit tables.
  * <p>This algorithm works as follows:
  * <ul>
  * <li>For a <strong>new row</strong> that is persisted in an audit table, only the <strong>start-revision</strong> column of that row is set</li>
  * <li>At the same time the <strong>end-revision</strong> field of the <strong>previous</strong> audit row is set to this revision</li>
  * <li>Queries are retrieved using 'between start and end revision', instead of a subquery.</li>
  * </ul>
  * </p>
  * <p/>
  * <p>
  * This has a few important consequences that need to be judged against against each other:
  * <ul>
  * <li>Persisting audit information is a bit slower, because an extra row is updated</li>
  * <li>Retrieving audit information is a lot faster</li>
  * </ul>
  * </p>
  *
  * @author Stephanie Pau
  * @author Adam Warski (adam at warski dot org)
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public class ValidityAuditStrategy implements AuditStrategy {
 	/**
 	 * getter for the revision entity field annotated with @RevisionTimestamp
 	 */
 	private Getter revisionTimestampGetter = null;
 
 	private final SessionCacheCleaner sessionCacheCleaner;
 
 	public ValidityAuditStrategy() {
 		sessionCacheCleaner = new SessionCacheCleaner();
 	}
 
 	@Override
 	public void perform(
 			final Session session,
 			final String entityName,
 			final EnversService enversService,
 			final Serializable id,
 			final Object data,
 			final Object revision) {
 		final AuditEntitiesConfiguration audEntitiesCfg = enversService.getAuditEntitiesConfiguration();
 		final String auditedEntityName = audEntitiesCfg.getAuditEntityName( entityName );
 		final String revisionInfoEntityName = enversService.getAuditEntitiesConfiguration().getRevisionInfoEntityName();
 
 		// Save the audit data
 		session.save( auditedEntityName, data );
 
 		// Update the end date of the previous row.
 		//
 		// When application reuses identifiers of previously removed entities:
 		// The UPDATE statement will no-op if an entity with a given identifier has been
 		// inserted for the first time. But in case a deleted primary key value was
 		// reused, this guarantees correct strategy behavior: exactly one row with
 		// null end date exists for each identifier.
 		final boolean reuseEntityIdentifier = enversService.getGlobalConfiguration().isAllowIdentifierReuse();
 		if ( reuseEntityIdentifier || getRevisionType( enversService, data ) != RevisionType.ADD ) {
 			// Register transaction completion process to guarantee execution of UPDATE statement after INSERT.
 			( (EventSource) session ).getActionQueue().registerProcess( new BeforeTransactionCompletionProcess() {
 				@Override
 				public void doBeforeTransactionCompletion(final SessionImplementor sessionImplementor) {
 					final Queryable productionEntityQueryable = getQueryable( entityName, sessionImplementor );
 					final Queryable rootProductionEntityQueryable = getQueryable(
 							productionEntityQueryable.getRootEntityName(), sessionImplementor
 					);
 					final Queryable auditedEntityQueryable = getQueryable( auditedEntityName, sessionImplementor );
 					final Queryable rootAuditedEntityQueryable = getQueryable(
 							auditedEntityQueryable.getRootEntityName(), sessionImplementor
 					);
 
 					final String updateTableName;
 					if ( UnionSubclassEntityPersister.class.isInstance( rootProductionEntityQueryable ) ) {
 						// this is the condition causing all the problems in terms of the generated SQL UPDATE
 						// the problem being that we currently try to update the in-line view made up of the union query
 						//
 						// this is extremely hacky means to get the root table name for the union subclass style entities.
 						// hacky because it relies on internal behavior of UnionSubclassEntityPersister
 						// !!!!!! NOTICE - using subclass persister, not root !!!!!!
 						updateTableName = auditedEntityQueryable.getSubclassTableName( 0 );
 					}
 					else {
 						updateTableName = rootAuditedEntityQueryable.getTableName();
 					}
 
 					final Type revisionInfoIdType = sessionImplementor.getFactory().getEntityPersister( revisionInfoEntityName ).getIdentifierType();
 					final String revEndColumnName = rootAuditedEntityQueryable.toColumns( enversService.getAuditEntitiesConfiguration().getRevisionEndFieldName() )[0];
 
 					final boolean isRevisionEndTimestampEnabled = enversService.getAuditEntitiesConfiguration().isRevisionEndTimestampEnabled();
 
 					// update audit_ent set REVEND = ? [, REVEND_TSTMP = ?] where (prod_ent_id) = ? and REV <> ? and REVEND is null
 					final Update update = new Update( sessionImplementor.getFactory().getDialect() ).setTableName( updateTableName );
 					// set REVEND = ?
 					update.addColumn( revEndColumnName );
 					// set [, REVEND_TSTMP = ?]
 					if ( isRevisionEndTimestampEnabled ) {
 						update.addColumn(
 								rootAuditedEntityQueryable.toColumns( enversService.getAuditEntitiesConfiguration().getRevisionEndTimestampFieldName() )[0]
 						);
 					}
 
 					// where (prod_ent_id) = ?
 					update.addPrimaryKeyColumns( rootProductionEntityQueryable.getIdentifierColumnNames() );
 					// where REV <> ?
 					update.addWhereColumn(
 							rootAuditedEntityQueryable.toColumns( enversService.getAuditEntitiesConfiguration().getRevisionNumberPath() )[0], "<> ?"
 					);
 					// where REVEND is null
 					update.addWhereColumn( revEndColumnName, " is null" );
 
 					// Now lets execute the sql...
 					final String updateSql = update.toStatementString();
 
 					int rowCount = ( (Session) sessionImplementor ).doReturningWork(
 							new ReturningWork<Integer>() {
 								@Override
 								public Integer execute(Connection connection) throws SQLException {
 									PreparedStatement preparedStatement = sessionImplementor
 											.getJdbcCoordinator().getStatementPreparer().prepareStatement( updateSql );
 
 									try {
 										int index = 1;
 
 										// set REVEND = ?
 										final Number revisionNumber = enversService.getRevisionInfoNumberReader().getRevisionNumber(
 												revision
 										);
 										revisionInfoIdType.nullSafeSet(
 												preparedStatement, revisionNumber, index, sessionImplementor
 										);
 										index += revisionInfoIdType.getColumnSpan( sessionImplementor.getFactory() );
 
 										// set [, REVEND_TSTMP = ?]
 										if ( isRevisionEndTimestampEnabled ) {
 											final Object revEndTimestampObj = revisionTimestampGetter.get( revision );
 											final Date revisionEndTimestamp = convertRevEndTimestampToDate( revEndTimestampObj );
 											final Type revEndTsType = rootAuditedEntityQueryable.getPropertyType(
 													enversService.getAuditEntitiesConfiguration().getRevisionEndTimestampFieldName()
 											);
 											revEndTsType.nullSafeSet(
 													preparedStatement, revisionEndTimestamp, index, sessionImplementor
 											);
 											index += revEndTsType.getColumnSpan( sessionImplementor.getFactory() );
 										}
 
 										// where (prod_ent_id) = ?
 										final Type idType = rootProductionEntityQueryable.getIdentifierType();
 										idType.nullSafeSet( preparedStatement, id, index, sessionImplementor );
 										index += idType.getColumnSpan( sessionImplementor.getFactory() );
 
 										// where REV <> ?
 										final Type revType = rootAuditedEntityQueryable.getPropertyType(
 												enversService.getAuditEntitiesConfiguration().getRevisionNumberPath()
 										);
 										revType.nullSafeSet( preparedStatement, revisionNumber, index, sessionImplementor );
 
 										// where REVEND is null
 										// 		nothing to bind....
 
 										return sessionImplementor
 												.getJdbcCoordinator().getResultSetReturn().executeUpdate( preparedStatement );
 									}
 									finally {
 										sessionImplementor.getJdbcCoordinator().getResourceRegistry().release(
 												preparedStatement
 										);
 										sessionImplementor.getJdbcCoordinator().afterStatementExecution();
 									}
 								}
 							}
 					);
 
 					if ( rowCount != 1 && ( !reuseEntityIdentifier || ( getRevisionType( enversService, data ) != RevisionType.ADD ) ) ) {
 						throw new RuntimeException(
 								"Cannot update previous revision for entity " + auditedEntityName + " and id " + id
 						);
 					}
 				}
 			});
 		}
 		sessionCacheCleaner.scheduleAuditDataRemoval( session, data );
 	}
 
 	private Queryable getQueryable(String entityName, SessionImplementor sessionImplementor) {
 		return (Queryable) sessionImplementor.getFactory().getEntityPersister( entityName );
 	}
 
 	@Override
 	@SuppressWarnings({"unchecked"})
 	public void performCollectionChange(
 			Session session,
 			String entityName,
 			String propertyName,
 			EnversService enversService,
 			PersistentCollectionChangeData persistentCollectionChangeData, Object revision) {
 		final QueryBuilder qb = new QueryBuilder( persistentCollectionChangeData.getEntityName(), MIDDLE_ENTITY_ALIAS );
 
 		final String originalIdPropName = enversService.getAuditEntitiesConfiguration().getOriginalIdPropName();
 		final Map<String, Object> originalId = (Map<String, Object>) persistentCollectionChangeData.getData().get(
 				originalIdPropName
 		);
 		final String revisionFieldName = enversService.getAuditEntitiesConfiguration().getRevisionFieldName();
 		final String revisionTypePropName = enversService.getAuditEntitiesConfiguration().getRevisionTypePropName();
 
 		// Adding a parameter for each id component, except the rev number and type.
 		for ( Map.Entry<String, Object> originalIdEntry : originalId.entrySet() ) {
 			if ( !revisionFieldName.equals( originalIdEntry.getKey() ) && !revisionTypePropName.equals( originalIdEntry.getKey() ) ) {
 				qb.getRootParameters().addWhereWithParam(
 						originalIdPropName + "." + originalIdEntry.getKey(),
 						true, "=", originalIdEntry.getValue()
 				);
 			}
 		}
 
 		final SessionFactoryImplementor sessionFactory = ((SessionImplementor) session).getFactory();
 		final Type propertyType = sessionFactory.getEntityPersister( entityName ).getPropertyType( propertyName );
 		if ( propertyType.isCollectionType() ) {
 			CollectionType collectionPropertyType = (CollectionType) propertyType;
 			// Handling collection of components.
 			if ( collectionPropertyType.getElementType( sessionFactory ) instanceof ComponentType ) {
 				// Adding restrictions to compare data outside of primary key.
 				for ( Map.Entry<String, Object> dataEntry : persistentCollectionChangeData.getData().entrySet() ) {
 					if ( !originalIdPropName.equals( dataEntry.getKey() ) ) {
 						qb.getRootParameters().addWhereWithParam( dataEntry.getKey(), true, "=", dataEntry.getValue() );
 					}
 				}
 			}
 		}
 
 		addEndRevisionNullRestriction( enversService, qb.getRootParameters() );
 
 		final List<Object> l = qb.toQuery( session ).setLockOptions( LockOptions.UPGRADE ).list();
 
 		// Update the last revision if one exists.
 		// HHH-5967: with collections, the same element can be added and removed multiple times. So even if it's an
 		// ADD, we may need to update the last revision.
 		if ( l.size() > 0 ) {
 			updateLastRevision(
 					session, enversService, l, originalId, persistentCollectionChangeData.getEntityName(), revision
 			);
 		}
 
 		// Save the audit data
 		session.save( persistentCollectionChangeData.getEntityName(), persistentCollectionChangeData.getData() );
 		sessionCacheCleaner.scheduleAuditDataRemoval( session, persistentCollectionChangeData.getData() );
 	}
 
 	private void addEndRevisionNullRestriction(EnversService enversService, Parameters rootParameters) {
 		rootParameters.addWhere( enversService.getAuditEntitiesConfiguration().getRevisionEndFieldName(), true, "is", "null", false );
 	}
 
 	public void addEntityAtRevisionRestriction(
 			GlobalConfiguration globalCfg, QueryBuilder rootQueryBuilder,
 			Parameters parameters, String revisionProperty, String revisionEndProperty, boolean addAlias,
 			MiddleIdData idData, String revisionPropertyPath, String originalIdPropertyName,
 			String alias1, String alias2, boolean inclusive) {
 		addRevisionRestriction( parameters, revisionProperty, revisionEndProperty, addAlias, inclusive );
 	}
 
 	public void addAssociationAtRevisionRestriction(
 			QueryBuilder rootQueryBuilder, Parameters parameters, String revisionProperty,
 			String revisionEndProperty, boolean addAlias, MiddleIdData referencingIdData,
 			String versionsMiddleEntityName, String eeOriginalIdPropertyPath, String revisionPropertyPath,
 			String originalIdPropertyName, String alias1, boolean inclusive, MiddleComponentData... componentDatas) {
 		addRevisionRestriction( parameters, revisionProperty, revisionEndProperty, addAlias, inclusive );
 	}
 
 	public void setRevisionTimestampGetter(Getter revisionTimestampGetter) {
 		this.revisionTimestampGetter = revisionTimestampGetter;
 	}
 
 	private void addRevisionRestriction(
 			Parameters rootParameters, String revisionProperty, String revisionEndProperty,
 			boolean addAlias, boolean inclusive) {
 		// e.revision <= _revision and (e.endRevision > _revision or e.endRevision is null)
 		Parameters subParm = rootParameters.addSubParameters( "or" );
 		rootParameters.addWhereWithNamedParam( revisionProperty, addAlias, inclusive ? "<=" : "<", REVISION_PARAMETER );
 		subParm.addWhereWithNamedParam(
 				revisionEndProperty + ".id", addAlias, inclusive ? ">" : ">=", REVISION_PARAMETER
 		);
 		subParm.addWhere( revisionEndProperty, addAlias, "is", "null", false );
 	}
 
 	@SuppressWarnings({"unchecked"})
 	private RevisionType getRevisionType(EnversService enversService, Object data) {
 		return (RevisionType) ((Map<String, Object>) data).get( enversService.getAuditEntitiesConfiguration().getRevisionTypePropName() );
 	}
 
 	@SuppressWarnings({"unchecked"})
 	private void updateLastRevision(
 			Session session,
 			EnversService enversService,
 			List<Object> l,
 			Object id,
 			String auditedEntityName,
 			Object revision) {
 		// There should be one entry
 		if ( l.size() == 1 ) {
 			// Setting the end revision to be the current rev
 			Object previousData = l.get( 0 );
 			String revisionEndFieldName = enversService.getAuditEntitiesConfiguration().getRevisionEndFieldName();
 			((Map<String, Object>) previousData).put( revisionEndFieldName, revision );
 
 			if ( enversService.getAuditEntitiesConfiguration().isRevisionEndTimestampEnabled() ) {
 				// Determine the value of the revision property annotated with @RevisionTimestamp
 				String revEndTimestampFieldName = enversService.getAuditEntitiesConfiguration().getRevisionEndTimestampFieldName();
 				Object revEndTimestampObj = this.revisionTimestampGetter.get( revision );
 				Date revisionEndTimestamp = convertRevEndTimestampToDate( revEndTimestampObj );
 
 				// Setting the end revision timestamp
 				((Map<String, Object>) previousData).put( revEndTimestampFieldName, revisionEndTimestamp );
 			}
 
 			// Saving the previous version
 			session.save( auditedEntityName, previousData );
 			sessionCacheCleaner.scheduleAuditDataRemoval( session, previousData );
 		}
 		else {
 			throw new RuntimeException( "Cannot find previous revision for entity " + auditedEntityName + " and id " + id );
 		}
 	}
 
 	private Date convertRevEndTimestampToDate(Object revEndTimestampObj) {
 		// convert to a java.util.Date
 		if ( revEndTimestampObj instanceof Date ) {
 			return (Date) revEndTimestampObj;
 		}
 		return new Date( (Long) revEndTimestampObj );
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-hikaricp/src/main/java/org/hibernate/hikaricp/internal/HikariCPConnectionProvider.java b/hibernate-hikaricp/src/main/java/org/hibernate/hikaricp/internal/HikariCPConnectionProvider.java
index 3dab3ad002..1dfc8b81dc 100644
--- a/hibernate-hikaricp/src/main/java/org/hibernate/hikaricp/internal/HikariCPConnectionProvider.java
+++ b/hibernate-hikaricp/src/main/java/org/hibernate/hikaricp/internal/HikariCPConnectionProvider.java
@@ -1,136 +1,138 @@
 /* 
  * Hibernate, Relational Persistence for Idiomatic Java
  * 
  * JBoss, Home of Professional Open Source
  * Copyright 2014 Red Hat Inc. and/or its affiliates and other contributors
  * as indicated by the @authors tag. All rights reserved.
  * See the copyright.txt in the distribution for a
  * full listing of individual contributors.
  *
  * This copyrighted material is made available to anyone wishing to use,
  * modify, copy, or redistribute it subject to the terms and conditions
  * of the GNU Lesser General Public License, v. 2.1.
  * This program is distributed in the hope that it will be useful, but WITHOUT A
  * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
  * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
  * You should have received a copy of the GNU Lesser General Public License,
  * v.2.1 along with this distribution; if not, write to the Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
  * MA  02110-1301, USA.
  */
 
 package org.hibernate.hikaricp.internal;
 
-import com.zaxxer.hikari.HikariConfig;
-import com.zaxxer.hikari.HikariDataSource;
+import java.sql.Connection;
+import java.sql.SQLException;
+import java.util.Map;
+import javax.sql.DataSource;
+
 import org.hibernate.HibernateException;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.service.UnknownUnwrapTypeException;
 import org.hibernate.service.spi.Configurable;
 import org.hibernate.service.spi.Stoppable;
+
 import org.jboss.logging.Logger;
 
-import javax.sql.DataSource;
-import java.sql.Connection;
-import java.sql.SQLException;
-import java.util.Map;
+import com.zaxxer.hikari.HikariConfig;
+import com.zaxxer.hikari.HikariDataSource;
 
 /**
  * HikariCP Connection provider for Hibernate.
- * 
+ *
  * @author Brett Wooldridge
  * @author Luca Burgazzoli
  */
 public class HikariCPConnectionProvider implements ConnectionProvider, Configurable, Stoppable {
 
 	private static final long serialVersionUID = -9131625057941275711L;
 
 	private static final Logger LOGGER = Logger.getLogger( HikariCPConnectionProvider.class );
 
 	/**
 	 * HikariCP configuration.
 	 */
 	private HikariConfig hcfg = null;
 
 	/**
 	 * HikariCP data source.
 	 */
 	private HikariDataSource hds = null;
 
 	// *************************************************************************
 	// Configurable
 	// *************************************************************************
 
 	@SuppressWarnings("rawtypes")
 	@Override
 	public void configure(Map props) throws HibernateException {
 		try {
 			LOGGER.debug( "Configuring HikariCP" );
 
 			hcfg = HikariConfigurationUtil.loadConfiguration( props );
 			hds = new HikariDataSource( hcfg );
 
 		}
 		catch (Exception e) {
 			throw new HibernateException( e );
 		}
 
 		LOGGER.debug( "HikariCP Configured" );
 	}
 
 	// *************************************************************************
 	// ConnectionProvider
 	// *************************************************************************
 
 	@Override
 	public Connection getConnection() throws SQLException {
 		Connection conn = null;
 		if ( hds != null ) {
 			conn = hds.getConnection();
 		}
 
 		return conn;
 	}
 
 	@Override
 	public void closeConnection(Connection conn) throws SQLException {
 		conn.close();
 	}
 
 	@Override
 	public boolean supportsAggressiveRelease() {
 		return false;
 	}
 
 	@Override
 	@SuppressWarnings("rawtypes")
 	public boolean isUnwrappableAs(Class unwrapType) {
 		return ConnectionProvider.class.equals( unwrapType )
 				|| HikariCPConnectionProvider.class.isAssignableFrom( unwrapType )
-                || DataSource.class.isAssignableFrom( unwrapType );
+				|| DataSource.class.isAssignableFrom( unwrapType );
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <T> T unwrap(Class<T> unwrapType) {
-        if ( ConnectionProvider.class.equals( unwrapType ) ||
-                HikariCPConnectionProvider.class.isAssignableFrom( unwrapType ) ) {
-            return (T) this;
-        }
-        else if ( DataSource.class.isAssignableFrom( unwrapType ) ) {
-            return (T) hds;
-        }
-        else {
-            throw new UnknownUnwrapTypeException( unwrapType );
-        }
+		if ( ConnectionProvider.class.equals( unwrapType ) ||
+				HikariCPConnectionProvider.class.isAssignableFrom( unwrapType ) ) {
+			return (T) this;
+		}
+		else if ( DataSource.class.isAssignableFrom( unwrapType ) ) {
+			return (T) hds;
+		}
+		else {
+			throw new UnknownUnwrapTypeException( unwrapType );
+		}
 	}
 
 	// *************************************************************************
 	// Stoppable
 	// *************************************************************************
 
 	@Override
 	public void stop() {
 		hds.shutdown();
 	}
 }
diff --git a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/impl/BaseRegion.java b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/impl/BaseRegion.java
index 4e894ea076..14349e687e 100644
--- a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/impl/BaseRegion.java
+++ b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/impl/BaseRegion.java
@@ -1,284 +1,287 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cache.infinispan.impl;
 
 import java.util.Collections;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicReference;
 import javax.transaction.SystemException;
 import javax.transaction.Transaction;
 import javax.transaction.TransactionManager;
 
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.infinispan.util.Caches;
 import org.hibernate.cache.spi.Region;
 import org.hibernate.cache.spi.RegionFactory;
 
 import org.infinispan.AdvancedCache;
 import org.infinispan.context.Flag;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 /**
  * Support for Infinispan {@link Region}s. Handles common "utility" methods for an underlying named
  * Cache. In other words, this implementation doesn't actually read or write data. Subclasses are
  * expected to provide core cache interaction appropriate to the semantics needed.
  *
  * @author Chris Bredesen
  * @author Galder Zamarreño
  * @since 3.5
  */
 public abstract class BaseRegion implements Region {
 
 	private static final Log log = LogFactory.getLog( BaseRegion.class );
 	private Transaction currentTransaction;
 
 	private enum InvalidateState {
 		INVALID, CLEARING, VALID
 	}
 
 	private final String name;
 	private final AdvancedCache localAndSkipLoadCache;
 	private final TransactionManager tm;
 
 	private final Object invalidationMutex = new Object();
 	private final AtomicReference<InvalidateState> invalidateState =
 			new AtomicReference<InvalidateState>( InvalidateState.VALID );
 	private volatile Transaction invalidateTransaction;
 
 	private final RegionFactory factory;
 
 	protected final AdvancedCache cache;
 
    /**
     * Base region constructor.
     *
     * @param cache instance for the region
     * @param name of the region
     * @param factory for this region
     */
 	public BaseRegion(AdvancedCache cache, String name, RegionFactory factory) {
 		this.cache = cache;
 		this.name = name;
 		this.tm = cache.getTransactionManager();
 		this.factory = factory;
 		this.localAndSkipLoadCache = cache.withFlags(
 				Flag.CACHE_MODE_LOCAL, Flag.ZERO_LOCK_ACQUISITION_TIMEOUT,
 				Flag.SKIP_CACHE_LOAD
 		);
 	}
 
 	@Override
 	public String getName() {
 		return name;
 	}
 
 	@Override
 	public long getElementCountInMemory() {
 		if ( checkValid() ) {
 			return localAndSkipLoadCache.size();
 		}
 
 		return 0;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 * <p/>
 	 * Not supported; returns -1
 	 */
 	@Override
 	public long getElementCountOnDisk() {
 		return -1;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 * <p/>
 	 * Not supported; returns -1
 	 */
 	@Override
 	public long getSizeInMemory() {
 		return -1;
 	}
 
 	@Override
 	public int getTimeout() {
 		// 60 seconds
 		return 600;
 	}
 
 	@Override
 	public long nextTimestamp() {
 		return factory.nextTimestamp();
 	}
 
 	@Override
 	public Map toMap() {
 		if ( checkValid() ) {
 			return cache;
 		}
 
 		return Collections.EMPTY_MAP;
 	}
 
 	@Override
 	public void destroy() throws CacheException {
 		cache.stop();
 	}
 
 	@Override
 	public boolean contains(Object key) {
 		return checkValid() && cache.containsKey( key );
 	}
 
    /**
     * Checks if the region is valid for operations such as storing new data
     * in the region, or retrieving data from the region.
     *
     * @return true if the region is valid, false otherwise
     */
 	public boolean checkValid() {
 		boolean valid = isValid();
 		if ( !valid ) {
 			synchronized (invalidationMutex) {
 				if ( invalidateState.compareAndSet( InvalidateState.INVALID, InvalidateState.CLEARING ) ) {
 					try {
 						// Even if no transactions are running, a new transaction
 						// needs to be started to do clear the region
 						// (without forcing autoCommit cache configuration).
 						Transaction tx = getCurrentTransaction();
 						if ( tx != null ) {
 							log.tracef("Transaction, clearing one element at the time");
 							Caches.removeAll(localAndSkipLoadCache);
-						} else {
+						}
+						else {
 							log.tracef("Non-transactional, clear in one go");
 							localAndSkipLoadCache.clear();
 						}
 
 						log.tracef("Transition state from CLEARING to VALID");
 						invalidateState.compareAndSet(
 								InvalidateState.CLEARING, InvalidateState.VALID
 						);
 					}
 					catch ( Exception e ) {
 						if ( log.isTraceEnabled() ) {
 							log.trace("Could not invalidate region: ", e);
 						}
 					}
 				}
 			}
 			valid = isValid();
 		}
 
 		return valid;
 	}
 
 	protected boolean isValid() {
 		return invalidateState.get() == InvalidateState.VALID;
 	}
 
 	/**
 	 * Tell the TransactionManager to suspend any ongoing transaction.
 	 *
 	 * @return the transaction that was suspended, or <code>null</code> if
 	 *         there wasn't one
 	 */
 	public Transaction suspend() {
 		Transaction tx = null;
 		try {
 			if ( tm != null ) {
 				tx = tm.suspend();
 			}
 		}
 		catch (SystemException se) {
 			throw new CacheException( "Could not suspend transaction", se );
 		}
 		return tx;
 	}
 
 	/**
 	 * Tell the TransactionManager to resume the given transaction
 	 *
 	 * @param tx the transaction to suspend. May be <code>null</code>.
 	 */
 	public void resume(Transaction tx) {
 		try {
 			if ( tx != null ) {
 				tm.resume( tx );
 			}
 		}
 		catch (Exception e) {
 			throw new CacheException( "Could not resume transaction", e );
 		}
 	}
 
-   /**
-    * Invalidates the region.
-    */
-   public void invalidateRegion() {
+	/**
+	 * Invalidates the region.
+	 */
+	public void invalidateRegion() {
 		if (log.isTraceEnabled()) {
 			log.trace("Invalidate region: " + name);
 		}
 
 		Transaction tx = getCurrentTransaction();
 		if ( tx != null ) {
 			synchronized ( invalidationMutex ) {
 				invalidateTransaction = tx;
 				invalidateState.set( InvalidateState.INVALID );
 			}
-		} else {
+		}
+		else {
 			invalidateState.set( InvalidateState.INVALID );
 		}
 	}
 
 	public TransactionManager getTransactionManager() {
 		return tm;
 	}
 
 	// Used to satisfy TransactionalDataRegion.isTransactionAware in subclasses
 	@SuppressWarnings("unused")
 	public boolean isTransactionAware() {
 		return tm != null;
 	}
 
 	public AdvancedCache getCache() {
 		return cache;
 	}
 
 	public boolean isRegionInvalidatedInCurrentTx() {
 		Transaction tx = getCurrentTransaction();
 		return tx != null && tx.equals(invalidateTransaction);
 	}
 
 	private Transaction getCurrentTransaction() {
 		try {
 			// Transaction manager could be null
 			return tm != null ? tm.getTransaction() : null;
-		} catch (SystemException e) {
+		}
+		catch (SystemException e) {
 			throw new CacheException("Unable to get current transaction", e);
 		}
 	}
 
 }
diff --git a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/util/Caches.java b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/util/Caches.java
index aa609d99d2..ab01a08077 100644
--- a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/util/Caches.java
+++ b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/util/Caches.java
@@ -1,281 +1,282 @@
 /*
  * JBoss, Home of Professional Open Source
  * Copyright 2012 Red Hat Inc. and/or its affiliates and other
  * contributors as indicated by the @author tags. All rights reserved.
  * See the copyright.txt in the distribution for a full listing of
  * individual contributors.
  *
  * This is free software; you can redistribute it and/or modify it
  * under the terms of the GNU Lesser General Public License as
  * published by the Free Software Foundation; either version 2.1 of
  * the License, or (at your option) any later version.
  *
  * This software is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * Lesser General Public License for more details.
  *
  * You should have received a copy of the GNU Lesser General Public
  * License along with this software; if not, write to the Free
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
 package org.hibernate.cache.infinispan.util;
 
 import java.util.concurrent.Callable;
 import javax.transaction.Status;
 import javax.transaction.TransactionManager;
 
 import org.infinispan.AdvancedCache;
 import org.infinispan.commons.util.CloseableIterator;
 import org.infinispan.context.Flag;
 import org.infinispan.remoting.rpc.RpcManager;
 
 /**
  * Helper for dealing with Infinispan cache instances.
  *
  * @author Galder Zamarreño
  * @since 4.1
  */
 public class Caches {
 
 	private Caches() {
 		// Suppresses default constructor, ensuring non-instantiability.
 	}
 
    /**
     * Call an operation within a transaction. This method guarantees that the
     * right pattern is used to make sure that the transaction is always either
     * committed or rollback.
     *
     * @param cache instance whose transaction manager to use
     * @param c callable instance to run within a transaction
     * @param <T> type of callable return
     * @return returns whatever the callable returns
     * @throws Exception if any operation within the transaction fails
     */
 	public static <T> T withinTx(
 			AdvancedCache cache,
 			Callable<T> c) throws Exception {
 		// Retrieve transaction manager
 		return withinTx( cache.getTransactionManager(), c );
 	}
 
    /**
     * Call an operation within a transaction. This method guarantees that the
     * right pattern is used to make sure that the transaction is always either
     * committed or rollbacked.
     *
     * @param tm transaction manager
     * @param c callable instance to run within a transaction
     * @param <T> type of callable return
     * @return returns whatever the callable returns
     * @throws Exception if any operation within the transaction fails
     */
 	public static <T> T withinTx(
 			TransactionManager tm,
 			Callable<T> c) throws Exception {
 		if ( tm == null ) {
 			try {
 				return c.call();
 			}
 			catch (Exception e) {
 				throw e;
 			}
 		}
 		else {
 			tm.begin();
 			try {
 				return c.call();
 			}
 			catch (Exception e) {
 				tm.setRollbackOnly();
 				throw e;
 			}
 			finally {
 				if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 					tm.commit();
 				}
 				else {
 					tm.rollback();
 				}
 			}
 		}
 	}
 
    /**
     * Transform a given cache into a local cache
     *
     * @param cache to be transformed
     * @return a cache that operates only in local-mode
     */
 	public static AdvancedCache localCache(AdvancedCache cache) {
 		return cache.withFlags( Flag.CACHE_MODE_LOCAL );
 	}
 
    /**
     * Transform a given cache into a cache that ignores return values for
     * operations returning previous values, i.e. {@link AdvancedCache#put(Object, Object)}
     *
     * @param cache to be transformed
     * @return a cache that ignores return values
     */
 	public static AdvancedCache ignoreReturnValuesCache(AdvancedCache cache) {
 		return cache.withFlags( Flag.SKIP_CACHE_LOAD, Flag.SKIP_REMOTE_LOOKUP );
 	}
 
    /**
     * Transform a given cache into a cache that ignores return values for
     * operations returning previous values, i.e. {@link AdvancedCache#put(Object, Object)},
     * adding an extra flag.
     *
     * @param cache to be transformed
     * @param extraFlag to add to the returned cache
     * @return a cache that ignores return values
     */
 	public static AdvancedCache ignoreReturnValuesCache(
 			AdvancedCache cache, Flag extraFlag) {
 		return cache.withFlags(
 				Flag.SKIP_CACHE_LOAD, Flag.SKIP_REMOTE_LOOKUP, extraFlag
 		);
 	}
 
    /**
     * Transform a given cache into a cache that writes cache entries without
     * waiting for them to complete, adding an extra flag.
     *
     * @param cache to be transformed
     * @param extraFlag to add to the returned cache
     * @return a cache that writes asynchronously
     */
 	public static AdvancedCache asyncWriteCache(
 			AdvancedCache cache,
 			Flag extraFlag) {
 		return cache.withFlags(
 				Flag.SKIP_CACHE_LOAD,
 				Flag.SKIP_REMOTE_LOOKUP,
 				Flag.FORCE_ASYNCHRONOUS,
 				extraFlag
 		);
 	}
 
    /**
     * Transform a given cache into a cache that fails silently if cache writes fail.
     *
     * @param cache to be transformed
     * @return a cache that fails silently if cache writes fail
     */
 	public static AdvancedCache failSilentWriteCache(AdvancedCache cache) {
 		return cache.withFlags(
 				Flag.FAIL_SILENTLY,
 				Flag.ZERO_LOCK_ACQUISITION_TIMEOUT,
 				Flag.SKIP_CACHE_LOAD,
 				Flag.SKIP_REMOTE_LOOKUP
 		);
 	}
 
    /**
     * Transform a given cache into a cache that fails silently if
     * cache writes fail, adding an extra flag.
     *
     * @param cache to be transformed
     * @param extraFlag to be added to returned cache
     * @return a cache that fails silently if cache writes fail
     */
 	public static AdvancedCache failSilentWriteCache(
 			AdvancedCache cache,
 			Flag extraFlag) {
 		return cache.withFlags(
 				Flag.FAIL_SILENTLY,
 				Flag.ZERO_LOCK_ACQUISITION_TIMEOUT,
 				Flag.SKIP_CACHE_LOAD,
 				Flag.SKIP_REMOTE_LOOKUP,
 				extraFlag
 		);
 	}
 
    /**
     * Transform a given cache into a cache that fails silently if
     * cache reads fail.
     *
     * @param cache to be transformed
     * @return a cache that fails silently if cache reads fail
     */
 	public static AdvancedCache failSilentReadCache(AdvancedCache cache) {
 		return cache.withFlags(
 				Flag.FAIL_SILENTLY,
 				Flag.ZERO_LOCK_ACQUISITION_TIMEOUT
 		);
 	}
 
    /**
     * Broadcast an evict-all command with the given cache instance.
     *
     * @param cache instance used to broadcast command
     */
 	public static void broadcastEvictAll(AdvancedCache cache) {
 		final RpcManager rpcManager = cache.getRpcManager();
 		if ( rpcManager != null ) {
 			// Only broadcast evict all if it's clustered
 			final CacheCommandInitializer factory = cache.getComponentRegistry()
 					.getComponent( CacheCommandInitializer.class );
 			final boolean isSync = isSynchronousCache( cache );
 
 			final EvictAllCommand cmd = factory.buildEvictAllCommand( cache.getName() );
 			rpcManager.broadcastRpcCommand( cmd, isSync );
 		}
 	}
 
    /**
     * Indicates whether the given cache is configured with
     * {@link org.infinispan.configuration.cache.CacheMode#INVALIDATION_ASYNC} or
     * {@link org.infinispan.configuration.cache.CacheMode#INVALIDATION_SYNC}.
     *
     * @param cache to check for invalidation configuration
     * @return true if the cache is configured with invalidation, false otherwise
     */
 	public static boolean isInvalidationCache(AdvancedCache cache) {
 		return cache.getCacheConfiguration()
 				.clustering().cacheMode().isInvalidation();
 	}
 
    /**
     * Indicates whether the given cache is configured with
     * {@link org.infinispan.configuration.cache.CacheMode#REPL_SYNC},
     * {@link org.infinispan.configuration.cache.CacheMode#INVALIDATION_SYNC}, or
     * {@link org.infinispan.configuration.cache.CacheMode#DIST_SYNC}.
     *
     * @param cache to check for synchronous configuration
     * @return true if the cache is configured with synchronous mode, false otherwise
     */
 	public static boolean isSynchronousCache(AdvancedCache cache) {
 		return cache.getCacheConfiguration()
 				.clustering().cacheMode().isSynchronous();
 	}
 
    /**
     * Indicates whether the given cache is configured to cluster its contents.
     * A cache is considered to clustered if it's configured with any cache mode
     * except {@link org.infinispan.configuration.cache.CacheMode#LOCAL}
     *
     * @param cache to check whether it clusters its contents
     * @return true if the cache is configured with clustering, false otherwise
     */
 	public static boolean isClustered(AdvancedCache cache) {
 		return cache.getCacheConfiguration()
 				.clustering().cacheMode().isClustered();
 	}
 
 	public static void removeAll(AdvancedCache cache) {
 		CloseableIterator it = cache.keySet().iterator();
 		try {
 			while (it.hasNext()) {
 				it.next(); // Necessary to get next element
 				it.remove();
 			}
-		} finally {
+		}
+		finally {
 			it.close();
 		}
 	}
 
 }
diff --git a/hibernate-java8/src/main/java/org/hibernate/type/Java8DateTimeTypeContributor.java b/hibernate-java8/src/main/java/org/hibernate/type/Java8DateTimeTypeContributor.java
index f639183e82..b8ff66d902 100644
--- a/hibernate-java8/src/main/java/org/hibernate/type/Java8DateTimeTypeContributor.java
+++ b/hibernate-java8/src/main/java/org/hibernate/type/Java8DateTimeTypeContributor.java
@@ -1,50 +1,50 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import org.hibernate.boot.model.TypeContributions;
 import org.hibernate.boot.model.TypeContributor;
 import org.hibernate.service.ServiceRegistry;
 
 /**
  * TypeContributor for adding Java8 Date/Time specific Type implementations
  *
  * @author Steve Ebersole
  */
 public class Java8DateTimeTypeContributor implements TypeContributor {
 	@Override
 	public void contribute(TypeContributions typeContributions, ServiceRegistry serviceRegistry) {
 		typeContributions.contributeType( LocalDateTimeType.INSTANCE );
 		typeContributions.contributeType( LocalDateType.INSTANCE );
 		typeContributions.contributeType( LocalTimeType.INSTANCE );
 
 		typeContributions.contributeType( InstantType.INSTANCE );
 
 		typeContributions.contributeType( ZonedDateTimeType.INSTANCE );
 		typeContributions.contributeType( OffsetDateTimeType.INSTANCE );
 		typeContributions.contributeType( OffsetTimeType.INSTANCE );
 
 		typeContributions.contributeType( DurationType.INSTANCE );
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-java8/src/main/java/org/hibernate/type/OffsetDateTimeType.java b/hibernate-java8/src/main/java/org/hibernate/type/OffsetDateTimeType.java
index 1fecbbc092..b94b9210e3 100644
--- a/hibernate-java8/src/main/java/org/hibernate/type/OffsetDateTimeType.java
+++ b/hibernate-java8/src/main/java/org/hibernate/type/OffsetDateTimeType.java
@@ -1,86 +1,85 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.time.OffsetDateTime;
-import java.time.ZonedDateTime;
 import java.time.format.DateTimeFormatter;
 import java.util.Comparator;
 import java.util.Locale;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.compare.ComparableComparator;
 import org.hibernate.type.descriptor.java.OffsetDateTimeJavaDescriptor;
 import org.hibernate.type.descriptor.sql.TimestampTypeDescriptor;
 
 /**
  * @author Steve Ebersole
  */
 public class OffsetDateTimeType
 		extends AbstractSingleColumnStandardBasicType<OffsetDateTime>
 		implements VersionType<OffsetDateTime>, LiteralType<OffsetDateTime> {
 
 	/**
 	 * Singleton access
 	 */
 	public static final OffsetDateTimeType INSTANCE = new OffsetDateTimeType();
 
 	public static final DateTimeFormatter FORMATTER = DateTimeFormatter.ofPattern( "yyyy-MM-dd HH:mm:ss.S xxxxx", Locale.ENGLISH );
 
 	public OffsetDateTimeType() {
 		super( TimestampTypeDescriptor.INSTANCE, OffsetDateTimeJavaDescriptor.INSTANCE );
 	}
 
 	@Override
 	public String objectToSQLString(OffsetDateTime value, Dialect dialect) throws Exception {
 		return "{ts '" + FORMATTER.format( value ) + "'}";
 	}
 
 	@Override
 	public OffsetDateTime seed(SessionImplementor session) {
 		return OffsetDateTime.now();
 	}
 
 	@Override
 	public OffsetDateTime next(OffsetDateTime current, SessionImplementor session) {
 		return OffsetDateTime.now();
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public Comparator<OffsetDateTime> getComparator() {
 		return ComparableComparator.INSTANCE;
 	}
 
 	@Override
 	public String getName() {
 		return OffsetDateTime.class.getSimpleName();
 	}
 
 	@Override
 	protected boolean registerUnderJavaType() {
 		return true;
 	}
 }
diff --git a/hibernate-java8/src/main/java/org/hibernate/type/descriptor/java/OffsetDateTimeJavaDescriptor.java b/hibernate-java8/src/main/java/org/hibernate/type/descriptor/java/OffsetDateTimeJavaDescriptor.java
index 4c78ee334f..cd9ebd41f5 100644
--- a/hibernate-java8/src/main/java/org/hibernate/type/descriptor/java/OffsetDateTimeJavaDescriptor.java
+++ b/hibernate-java8/src/main/java/org/hibernate/type/descriptor/java/OffsetDateTimeJavaDescriptor.java
@@ -1,134 +1,132 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type.descriptor.java;
 
 import java.sql.Timestamp;
 import java.time.Instant;
 import java.time.OffsetDateTime;
 import java.time.ZoneId;
-import java.time.ZonedDateTime;
 import java.util.Calendar;
 import java.util.Date;
 import java.util.GregorianCalendar;
 
 import org.hibernate.type.OffsetDateTimeType;
-import org.hibernate.type.ZonedDateTimeType;
 import org.hibernate.type.descriptor.WrapperOptions;
 
 /**
  * Java type descriptor for the LocalDateTime type.
  *
  * @author Steve Ebersole
  */
 public class OffsetDateTimeJavaDescriptor extends AbstractTypeDescriptor<OffsetDateTime> {
 	/**
 	 * Singleton access
 	 */
 	public static final OffsetDateTimeJavaDescriptor INSTANCE = new OffsetDateTimeJavaDescriptor();
 
 	@SuppressWarnings("unchecked")
 	public OffsetDateTimeJavaDescriptor() {
 		super( OffsetDateTime.class, ImmutableMutabilityPlan.INSTANCE );
 	}
 
 	@Override
 	public String toString(OffsetDateTime value) {
 		return OffsetDateTimeType.FORMATTER.format( value );
 	}
 
 	@Override
 	public OffsetDateTime fromString(String string) {
 		return (OffsetDateTime) OffsetDateTimeType.FORMATTER.parse( string );
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <X> X unwrap(OffsetDateTime offsetDateTime, Class<X> type, WrapperOptions options) {
 		if ( offsetDateTime == null ) {
 			return null;
 		}
 
 		if ( OffsetDateTime.class.isAssignableFrom( type ) ) {
 			return (X) offsetDateTime;
 		}
 
 		if ( Calendar.class.isAssignableFrom( type ) ) {
 			return (X) GregorianCalendar.from( offsetDateTime.toZonedDateTime() );
 		}
 
 		if ( Timestamp.class.isAssignableFrom( type ) ) {
 			return (X) Timestamp.from( offsetDateTime.toInstant() );
 		}
 
 		if ( java.sql.Date.class.isAssignableFrom( type ) ) {
 			return (X) java.sql.Date.from( offsetDateTime.toInstant() );
 		}
 
 		if ( java.sql.Time.class.isAssignableFrom( type ) ) {
 			return (X) java.sql.Time.from( offsetDateTime.toInstant() );
 		}
 
 		if ( Date.class.isAssignableFrom( type ) ) {
 			return (X) Date.from( offsetDateTime.toInstant() );
 		}
 
 		if ( Long.class.isAssignableFrom( type ) ) {
 			return (X) Long.valueOf( offsetDateTime.toInstant().toEpochMilli() );
 		}
 
 		throw unknownUnwrap( type );
 	}
 
 	@Override
 	public <X> OffsetDateTime wrap(X value, WrapperOptions options) {
 		if ( value == null ) {
 			return null;
 		}
 
 		if ( OffsetDateTime.class.isInstance( value ) ) {
 			return (OffsetDateTime) value;
 		}
 
 		if ( Timestamp.class.isInstance( value ) ) {
 			final Timestamp ts = (Timestamp) value;
 			return OffsetDateTime.ofInstant( ts.toInstant(), ZoneId.systemDefault() );
 		}
 
 		if ( Date.class.isInstance( value ) ) {
 			final Date date = (Date) value;
 			return OffsetDateTime.ofInstant( date.toInstant(), ZoneId.systemDefault() );
 		}
 
 		if ( Long.class.isInstance( value ) ) {
 			return OffsetDateTime.ofInstant( Instant.ofEpochMilli( (Long) value ), ZoneId.systemDefault() );
 		}
 
 		if ( Calendar.class.isInstance( value ) ) {
 			final Calendar calendar = (Calendar) value;
 			return OffsetDateTime.ofInstant( calendar.toInstant(), calendar.getTimeZone().toZoneId() );
 		}
 
 		throw unknownWrap( value.getClass() );
 	}
 }
diff --git a/hibernate-java8/src/main/java/org/hibernate/type/descriptor/java/ZonedDateTimeJavaDescriptor.java b/hibernate-java8/src/main/java/org/hibernate/type/descriptor/java/ZonedDateTimeJavaDescriptor.java
index a2371ae7b5..8f67ff60c9 100644
--- a/hibernate-java8/src/main/java/org/hibernate/type/descriptor/java/ZonedDateTimeJavaDescriptor.java
+++ b/hibernate-java8/src/main/java/org/hibernate/type/descriptor/java/ZonedDateTimeJavaDescriptor.java
@@ -1,134 +1,132 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type.descriptor.java;
 
 import java.sql.Timestamp;
 import java.time.Instant;
 import java.time.ZoneId;
-import java.time.ZoneOffset;
 import java.time.ZonedDateTime;
 import java.util.Calendar;
 import java.util.Date;
 import java.util.GregorianCalendar;
 
-import org.hibernate.type.InstantType;
 import org.hibernate.type.ZonedDateTimeType;
 import org.hibernate.type.descriptor.WrapperOptions;
 
 /**
  * Java type descriptor for the LocalDateTime type.
  *
  * @author Steve Ebersole
  */
 public class ZonedDateTimeJavaDescriptor extends AbstractTypeDescriptor<ZonedDateTime> {
 	/**
 	 * Singleton access
 	 */
 	public static final ZonedDateTimeJavaDescriptor INSTANCE = new ZonedDateTimeJavaDescriptor();
 
 	@SuppressWarnings("unchecked")
 	public ZonedDateTimeJavaDescriptor() {
 		super( ZonedDateTime.class, ImmutableMutabilityPlan.INSTANCE );
 	}
 
 	@Override
 	public String toString(ZonedDateTime value) {
 		return ZonedDateTimeType.FORMATTER.format( value );
 	}
 
 	@Override
 	public ZonedDateTime fromString(String string) {
 		return (ZonedDateTime) ZonedDateTimeType.FORMATTER.parse( string );
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <X> X unwrap(ZonedDateTime zonedDateTime, Class<X> type, WrapperOptions options) {
 		if ( zonedDateTime == null ) {
 			return null;
 		}
 
 		if ( ZonedDateTime.class.isAssignableFrom( type ) ) {
 			return (X) zonedDateTime;
 		}
 
 		if ( Calendar.class.isAssignableFrom( type ) ) {
 			return (X) GregorianCalendar.from( zonedDateTime );
 		}
 
 		if ( Timestamp.class.isAssignableFrom( type ) ) {
 			return (X) Timestamp.from( zonedDateTime.toInstant() );
 		}
 
 		if ( java.sql.Date.class.isAssignableFrom( type ) ) {
 			return (X) java.sql.Date.from( zonedDateTime.toInstant() );
 		}
 
 		if ( java.sql.Time.class.isAssignableFrom( type ) ) {
 			return (X) java.sql.Time.from( zonedDateTime.toInstant() );
 		}
 
 		if ( Date.class.isAssignableFrom( type ) ) {
 			return (X) Date.from( zonedDateTime.toInstant() );
 		}
 
 		if ( Long.class.isAssignableFrom( type ) ) {
 			return (X) Long.valueOf( zonedDateTime.toInstant().toEpochMilli() );
 		}
 
 		throw unknownUnwrap( type );
 	}
 
 	@Override
 	public <X> ZonedDateTime wrap(X value, WrapperOptions options) {
 		if ( value == null ) {
 			return null;
 		}
 
 		if ( ZonedDateTime.class.isInstance( value ) ) {
 			return (ZonedDateTime) value;
 		}
 
 		if ( java.sql.Timestamp.class.isInstance( value ) ) {
 			final Timestamp ts = (Timestamp) value;
 			return ZonedDateTime.ofInstant( ts.toInstant(), ZoneId.systemDefault() );
 		}
 
 		if ( java.util.Date.class.isInstance( value ) ) {
 			final java.util.Date date = (java.util.Date) value;
 			return ZonedDateTime.ofInstant( date.toInstant(), ZoneId.systemDefault() );
 		}
 
 		if ( Long.class.isInstance( value ) ) {
 			return ZonedDateTime.ofInstant( Instant.ofEpochMilli( (Long) value ), ZoneId.systemDefault() );
 		}
 
 		if ( Calendar.class.isInstance( value ) ) {
 			final Calendar calendar = (Calendar) value;
 			return ZonedDateTime.ofInstant( calendar.toInstant(), calendar.getTimeZone().toZoneId() );
 		}
 
 		throw unknownWrap( value.getClass() );
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/AbstractReadWriteAccessStrategy.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/AbstractReadWriteAccessStrategy.java
index 966f920f79..498c832c56 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/AbstractReadWriteAccessStrategy.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/AbstractReadWriteAccessStrategy.java
@@ -1,346 +1,360 @@
 package org.hibernate.testing.cache;
 
 import java.io.Serializable;
 import java.util.Comparator;
 import java.util.UUID;
 import java.util.concurrent.atomic.AtomicLong;
 import java.util.concurrent.locks.ReentrantReadWriteLock;
 
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.access.SoftLock;
-import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.Logger;
 
 /**
  * @author Strong Liu
  */
 abstract class AbstractReadWriteAccessStrategy extends BaseRegionAccessStrategy {
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
-			CoreMessageLogger.class, AbstractReadWriteAccessStrategy.class.getName()
-	);
+	private static final Logger LOG = Logger.getLogger( AbstractReadWriteAccessStrategy.class.getName() );
+
 	private final UUID uuid = UUID.randomUUID();
 	private final AtomicLong nextLockId = new AtomicLong();
 	private ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock();
 	protected java.util.concurrent.locks.Lock readLock = reentrantReadWriteLock.readLock();
 	protected java.util.concurrent.locks.Lock writeLock = reentrantReadWriteLock.writeLock();
 
 	/**
 	 * Returns <code>null</code> if the item is not readable.  Locked items are not readable, nor are items created
 	 * after the start of this transaction.
 	 */
 	@Override
 	public final Object get(Object key, long txTimestamp) throws CacheException {
 		LOG.debugf( "getting key[%s] from region[%s]", key, getInternalRegion().getName() );
 		try {
 			readLock.lock();
 			Lockable item = (Lockable) getInternalRegion().get( key );
 
 			boolean readable = item != null && item.isReadable( txTimestamp );
 			if ( readable ) {
 				LOG.debugf( "hit key[%s] in region[%s]", key, getInternalRegion().getName() );
 				return item.getValue();
 			}
 			else {
 				if ( item == null ) {
-					LOG.debugf( "miss key[%s] in region[%s]", key, getInternalRegion().getName());
-				} else {
+					LOG.debugf( "miss key[%s] in region[%s]", key, getInternalRegion().getName() );
+				}
+				else {
 					LOG.debugf( "hit key[%s] in region[%s], but it is unreadable", key, getInternalRegion().getName() );
 				}
 				return null;
 			}
 		}
 		finally {
 			readLock.unlock();
 		}
 	}
 
 	abstract Comparator getVersionComparator();
 
 	/**
 	 * Returns <code>false</code> and fails to put the value if there is an existing un-writeable item mapped to this
 	 * key.
 	 */
 	@Override
-	public final boolean putFromLoad(Object key, Object value, long txTimestamp, Object version, boolean minimalPutOverride)
+	public final boolean putFromLoad(
+			Object key,
+			Object value,
+			long txTimestamp,
+			Object version,
+			boolean minimalPutOverride)
 			throws CacheException {
 		try {
 			LOG.debugf( "putting key[%s] -> value[%s] into region[%s]", key, value, getInternalRegion().getName() );
 			writeLock.lock();
 			Lockable item = (Lockable) getInternalRegion().get( key );
 			boolean writeable = item == null || item.isWriteable( txTimestamp, version, getVersionComparator() );
 			if ( writeable ) {
-				LOG.debugf( "putting key[%s] -> value[%s] into region[%s] success", key, value, getInternalRegion().getName() );
+				LOG.debugf(
+						"putting key[%s] -> value[%s] into region[%s] success",
+						key,
+						value,
+						getInternalRegion().getName()
+				);
 				getInternalRegion().put( key, new Item( value, version, getInternalRegion().nextTimestamp() ) );
 				return true;
 			}
 			else {
-				LOG.debugf( "putting key[%s] -> value[%s] into region[%s] fail due to it is unwriteable", key, value, getInternalRegion().getName() );
+				LOG.debugf(
+						"putting key[%s] -> value[%s] into region[%s] fail due to it is unwriteable",
+						key,
+						value,
+						getInternalRegion().getName()
+				);
 				return false;
 			}
 		}
 		finally {
 			writeLock.unlock();
 		}
 	}
 
 	/**
 	 * Soft-lock a cache item.
 	 */
 	@Override
 	public final SoftLock lockItem(Object key, Object version) throws CacheException {
 
 		try {
 			LOG.debugf( "locking key[%s] in region[%s]", key, getInternalRegion().getName() );
 			writeLock.lock();
 			Lockable item = (Lockable) getInternalRegion().get( key );
 			long timeout = getInternalRegion().nextTimestamp() + getInternalRegion().getTimeout();
 			final Lock lock = ( item == null ) ? new Lock( timeout, uuid, nextLockId(), version ) : item.lock(
 					timeout,
 					uuid,
 					nextLockId()
 			);
 			getInternalRegion().put( key, lock );
 			return lock;
 		}
 		finally {
 			writeLock.unlock();
 		}
 	}
 
 	/**
 	 * Soft-unlock a cache item.
 	 */
 	@Override
 	public final void unlockItem(Object key, SoftLock lock) throws CacheException {
 
 		try {
 			LOG.debugf( "unlocking key[%s] in region[%s]", key, getInternalRegion().getName() );
 			writeLock.lock();
 			Lockable item = (Lockable) getInternalRegion().get( key );
 
 			if ( ( item != null ) && item.isUnlockable( lock ) ) {
 				decrementLock( key, (Lock) item );
 			}
 			else {
 				handleLockExpiry( key, item );
 			}
 		}
 		finally {
 			writeLock.unlock();
 		}
 	}
 
 	private long nextLockId() {
 		return nextLockId.getAndIncrement();
 	}
 
 	/**
 	 * Unlock and re-put the given key, lock combination.
 	 */
 	protected void decrementLock(Object key, Lock lock) {
 		lock.unlock( getInternalRegion().nextTimestamp() );
 		getInternalRegion().put( key, lock );
 	}
 
 	/**
 	 * Handle the timeout of a previous lock mapped to this key
 	 */
 	protected void handleLockExpiry(Object key, Lockable lock) {
-		LOG.expired(key);
+		LOG.info( "Cached entry expired : " + key );
+
 		long ts = getInternalRegion().nextTimestamp() + getInternalRegion().getTimeout();
 		// create new lock that times out immediately
 		Lock newLock = new Lock( ts, uuid, nextLockId.getAndIncrement(), null );
 		newLock.unlock( ts );
 		getInternalRegion().put( key, newLock );
 	}
 
 	/**
 	 * Interface type implemented by all wrapper objects in the cache.
 	 */
-	protected static interface Lockable {
+	protected interface Lockable {
 
 		/**
 		 * Returns <code>true</code> if the enclosed value can be read by a transaction started at the given time.
 		 */
-		public boolean isReadable(long txTimestamp);
+		boolean isReadable(long txTimestamp);
 
 		/**
 		 * Returns <code>true</code> if the enclosed value can be replaced with one of the given version by a
 		 * transaction started at the given time.
 		 */
-		public boolean isWriteable(long txTimestamp, Object version, Comparator versionComparator);
+		boolean isWriteable(long txTimestamp, Object version, Comparator versionComparator);
 
 		/**
 		 * Returns the enclosed value.
 		 */
-		public Object getValue();
+		Object getValue();
 
 		/**
 		 * Returns <code>true</code> if the given lock can be unlocked using the given SoftLock instance as a handle.
 		 */
-		public boolean isUnlockable(SoftLock lock);
+		boolean isUnlockable(SoftLock lock);
 
 		/**
 		 * Locks this entry, stamping it with the UUID and lockId given, with the lock timeout occuring at the specified
 		 * time.  The returned Lock object can be used to unlock the entry in the future.
 		 */
-		public Lock lock(long timeout, UUID uuid, long lockId);
+		Lock lock(long timeout, UUID uuid, long lockId);
 	}
 
 	/**
 	 * Wrapper type representing unlocked items.
 	 */
 	protected final static class Item implements Serializable, Lockable {
 
 		private static final long serialVersionUID = 1L;
 		private final Object value;
 		private final Object version;
 		private final long timestamp;
 
 		/**
 		 * Creates an unlocked item wrapping the given value with a version and creation timestamp.
 		 */
 		Item(Object value, Object version, long timestamp) {
 			this.value = value;
 			this.version = version;
 			this.timestamp = timestamp;
 		}
 
 		@Override
 		public boolean isReadable(long txTimestamp) {
 			return txTimestamp > timestamp;
 		}
 
 		@Override
 		public boolean isWriteable(long txTimestamp, Object newVersion, Comparator versionComparator) {
 			return version != null && versionComparator.compare( version, newVersion ) < 0;
 		}
 
 		@Override
 		public Object getValue() {
 			return value;
 		}
 
 		@Override
 		public boolean isUnlockable(SoftLock lock) {
 			return false;
 		}
 
 		@Override
 		public Lock lock(long timeout, UUID uuid, long lockId) {
 			return new Lock( timeout, uuid, lockId, version );
 		}
 	}
 
 	/**
 	 * Wrapper type representing locked items.
 	 */
 	protected final static class Lock implements Serializable, Lockable, SoftLock {
 
 		private static final long serialVersionUID = 2L;
 
 		private final UUID sourceUuid;
 		private final long lockId;
 		private final Object version;
 
 		private long timeout;
 		private boolean concurrent;
 		private int multiplicity = 1;
 		private long unlockTimestamp;
 
 		/**
 		 * Creates a locked item with the given identifiers and object version.
 		 */
 		Lock(long timeout, UUID sourceUuid, long lockId, Object version) {
 			this.timeout = timeout;
 			this.lockId = lockId;
 			this.version = version;
 			this.sourceUuid = sourceUuid;
 		}
 
 		@Override
 		public boolean isReadable(long txTimestamp) {
 			return false;
 		}
 
 		@Override
 		public boolean isWriteable(long txTimestamp, Object newVersion, Comparator versionComparator) {
 			if ( txTimestamp > timeout ) {
 				// if timedout then allow write
 				return true;
 			}
 			if ( multiplicity > 0 ) {
 				// if still locked then disallow write
 				return false;
 			}
 			return version == null ? txTimestamp > unlockTimestamp : versionComparator.compare(
 					version,
 					newVersion
 			) < 0;
 		}
 
 		@Override
 		public Object getValue() {
 			return null;
 		}
 
 		@Override
 		public boolean isUnlockable(SoftLock lock) {
 			return equals( lock );
 		}
 
 		@Override
 		public boolean equals(Object o) {
 			if ( o == this ) {
 				return true;
 			}
 			else if ( o instanceof Lock ) {
 				return ( lockId == ( (Lock) o ).lockId ) && sourceUuid.equals( ( (Lock) o ).sourceUuid );
 			}
 			else {
 				return false;
 			}
 		}
 
 		@Override
 		public int hashCode() {
 			int hash = ( sourceUuid != null ? sourceUuid.hashCode() : 0 );
 			int temp = (int) lockId;
 			for ( int i = 1; i < Long.SIZE / Integer.SIZE; i++ ) {
 				temp ^= ( lockId >>> ( i * Integer.SIZE ) );
 			}
 			return hash + temp;
 		}
 
 		/**
 		 * Returns true if this Lock has been concurrently locked by more than one transaction.
 		 */
 		public boolean wasLockedConcurrently() {
 			return concurrent;
 		}
 
 		@Override
 		public Lock lock(long timeout, UUID uuid, long lockId) {
 			concurrent = true;
 			multiplicity++;
 			this.timeout = timeout;
 			return this;
 		}
 
 		/**
 		 * Unlocks this Lock, and timestamps the unlock event.
 		 */
 		public void unlock(long timestamp) {
 			if ( --multiplicity == 0 ) {
 				unlockTimestamp = timestamp;
 			}
 		}
 
 		@Override
 		public String toString() {
-			StringBuilder sb = new StringBuilder( "Lock Source-UUID:" + sourceUuid + " Lock-ID:" + lockId );
-			return sb.toString();
+			return "Lock Source-UUID:" + sourceUuid + " Lock-ID:" + lockId;
 		}
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseCollectionRegionAccessStrategy.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseCollectionRegionAccessStrategy.java
index 7e0702a3d8..360d5d85d1 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseCollectionRegionAccessStrategy.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseCollectionRegionAccessStrategy.java
@@ -1,51 +1,53 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.cache;
 
 import org.hibernate.cache.spi.CollectionRegion;
 import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 
 /**
  * @author Strong Liu
  */
 class BaseCollectionRegionAccessStrategy extends BaseRegionAccessStrategy implements CollectionRegionAccessStrategy {
 	private final CollectionRegionImpl region;
+
 	BaseCollectionRegionAccessStrategy(CollectionRegionImpl region) {
 		this.region = region;
 	}
+
 	@Override
 	protected BaseGeneralDataRegion getInternalRegion() {
 		return region;
 	}
 
 	@Override
 	protected boolean isDefaultMinimalPutOverride() {
 		return region.getSettings().isMinimalPutsEnabled();
 	}
 
 	@Override
 	public CollectionRegion getRegion() {
 		return region;
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseEntityRegionAccessStrategy.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseEntityRegionAccessStrategy.java
index 351a4a9e79..7144aab331 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseEntityRegionAccessStrategy.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseEntityRegionAccessStrategy.java
@@ -1,84 +1,78 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.cache;
 
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.EntityRegion;
 import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.spi.access.SoftLock;
-import org.hibernate.internal.CoreMessageLogger;
-
-import org.jboss.logging.Logger;
 
 /**
  * @author Strong Liu
  */
 class BaseEntityRegionAccessStrategy extends BaseRegionAccessStrategy implements EntityRegionAccessStrategy {
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
-			CoreMessageLogger.class, BaseEntityRegionAccessStrategy.class.getName()
-	);
 	private final EntityRegionImpl region;
 
 	BaseEntityRegionAccessStrategy(EntityRegionImpl region) {
 		this.region = region;
 	}
 
 
 	@Override
 	public EntityRegion getRegion() {
 		return region;
 	}
 
 	@Override
 	public boolean insert(Object key, Object value, Object version) throws CacheException {
 		return putFromLoad( key, value, 0, version );
 	}
 
 	@Override
 	public boolean afterInsert(Object key, Object value, Object version) throws CacheException {
 		return true;
 	}
 
 	@Override
 	public boolean update(Object key, Object value, Object currentVersion, Object previousVersion)
 			throws CacheException {
 		return false;
 	}
 
 	@Override
 	public boolean afterUpdate(Object key, Object value, Object currentVersion, Object previousVersion, SoftLock lock)
 			throws CacheException {
 		return false;
 	}
 
 	@Override
 	protected BaseGeneralDataRegion getInternalRegion() {
 		return region;
 	}
 
 	@Override
 	protected boolean isDefaultMinimalPutOverride() {
 		return region.getSettings().isMinimalPutsEnabled();
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseGeneralDataRegion.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseGeneralDataRegion.java
index cd6fc8519e..54a0202633 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseGeneralDataRegion.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseGeneralDataRegion.java
@@ -1,82 +1,79 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.cache;
 
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.GeneralDataRegion;
-import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.Logger;
 
 /**
  * @author Strong Liu
  */
 class BaseGeneralDataRegion extends BaseRegion implements GeneralDataRegion {
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
-			CoreMessageLogger.class, BaseGeneralDataRegion.class.getName()
-	);
+	private static final Logger LOG = Logger.getLogger( BaseGeneralDataRegion.class.getName() );
 
 	BaseGeneralDataRegion(String name) {
 		super( name );
 	}
 
 	@Override
 	public Object get(Object key) throws CacheException {
-		LOG.debugf( "Cache[%s] lookup : key[%s]",getName(), key );
+		LOG.debugf( "Cache[%s] lookup : key[%s]", getName(), key );
 		if ( key == null ) {
 			return null;
 		}
 		Object result = cache.get( key );
 		if ( result != null ) {
-			LOG.debugf( "Cache[%s] hit: %s",getName(), key );
+			LOG.debugf( "Cache[%s] hit: %s", getName(), key );
 		}
 		return result;
 	}
 
 	@Override
 	public void put(Object key, Object value) throws CacheException {
-		LOG.debugf( "Caching[%s] : [%s] -> [%s]",getName(), key, value );
+		LOG.debugf( "Caching[%s] : [%s] -> [%s]", getName(), key, value );
 		if ( key == null || value == null ) {
 			LOG.debug( "Key or Value is null" );
 			return;
 		}
 		cache.put( key, value );
 	}
 
 	@Override
 	public void evict(Object key) throws CacheException {
-		LOG.debugf( "Evicting[%s]: %s",getName(), key );
+		LOG.debugf( "Evicting[%s]: %s", getName(), key );
 		if ( key == null ) {
 			LOG.debug( "Key is null" );
 			return;
 		}
 		cache.remove( key );
 	}
 
 	@Override
 	public void evictAll() throws CacheException {
 		LOG.debugf( "evict cache[%s]", getName() );
 		cache.clear();
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseNaturalIdRegionAccessStrategy.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseNaturalIdRegionAccessStrategy.java
index 4a2e8a3353..aeffc8de9d 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseNaturalIdRegionAccessStrategy.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseNaturalIdRegionAccessStrategy.java
@@ -1,75 +1,75 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.cache;
 
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.NaturalIdRegion;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.cache.spi.access.SoftLock;
 
 /**
  * @author Eric Dalquist
  */
 class BaseNaturalIdRegionAccessStrategy extends BaseRegionAccessStrategy implements NaturalIdRegionAccessStrategy {
 	private final NaturalIdRegionImpl region;
 
 	@Override
 	protected BaseGeneralDataRegion getInternalRegion() {
 		return region;
 	}
 
 	@Override
 	protected boolean isDefaultMinimalPutOverride() {
 		return region.getSettings().isMinimalPutsEnabled();
 	}
 
 	@Override
 	public NaturalIdRegion getRegion() {
 		return region;
 	}
 
 	@Override
-	public boolean insert(Object key, Object value ) throws CacheException {
-		return putFromLoad( key, value, 0 , null );
+	public boolean insert(Object key, Object value) throws CacheException {
+		return putFromLoad( key, value, 0, null );
 	}
 
 	@Override
-	public boolean afterInsert(Object key, Object value ) throws CacheException {
+	public boolean afterInsert(Object key, Object value) throws CacheException {
 		return false;
 	}
 
 	@Override
-	public boolean update(Object key, Object value ) throws CacheException {
-		return putFromLoad( key, value, 0 , null );
+	public boolean update(Object key, Object value) throws CacheException {
+		return putFromLoad( key, value, 0, null );
 	}
 
 	@Override
 	public boolean afterUpdate(Object key, Object value, SoftLock lock) throws CacheException {
 		return false;
 	}
 
 	BaseNaturalIdRegionAccessStrategy(NaturalIdRegionImpl region) {
 		this.region = region;
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseRegionAccessStrategy.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseRegionAccessStrategy.java
index ba3a41c045..bb48089a49 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseRegionAccessStrategy.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/BaseRegionAccessStrategy.java
@@ -1,136 +1,135 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.cache;
 
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.access.RegionAccessStrategy;
 import org.hibernate.cache.spi.access.SoftLock;
-import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.Logger;
 
 /**
  * @author Strong Liu
  */
 abstract class BaseRegionAccessStrategy implements RegionAccessStrategy {
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
-			CoreMessageLogger.class, BaseRegionAccessStrategy.class.getName()
-	);
+	private static final Logger LOG = Logger.getLogger( BaseRegionAccessStrategy.class );
+
 
 	protected abstract BaseGeneralDataRegion getInternalRegion();
 
 	protected abstract boolean isDefaultMinimalPutOverride();
 
 	@Override
 	public Object get(Object key, long txTimestamp) throws CacheException {
 		return getInternalRegion().get( key );
 	}
 
 	@Override
 	public boolean putFromLoad(Object key, Object value, long txTimestamp, Object version) throws CacheException {
 		return putFromLoad( key, value, txTimestamp, version, isDefaultMinimalPutOverride() );
 	}
 
 	@Override
 	public boolean putFromLoad(Object key, Object value, long txTimestamp, Object version, boolean minimalPutOverride)
 			throws CacheException {
 
 		if ( key == null || value == null ) {
 			return false;
 		}
 		if ( minimalPutOverride && getInternalRegion().contains( key ) ) {
 			LOG.debugf( "Item already cached: %s", key );
 			return false;
 		}
 		LOG.debugf( "Caching: %s", key );
 		getInternalRegion().put( key, value );
 		return true;
 
 	}
 
 	/**
 	 * Region locks are not supported.
 	 *
 	 * @return <code>null</code>
 	 *
 	 * @see org.hibernate.cache.spi.access.EntityRegionAccessStrategy#lockRegion()
 	 * @see org.hibernate.cache.spi.access.CollectionRegionAccessStrategy#lockRegion()
 	 */
 	@Override
 	public SoftLock lockRegion() throws CacheException {
 		return null;
 	}
 
 	/**
 	 * Region locks are not supported - perform a cache clear as a precaution.
 	 *
 	 * @see org.hibernate.cache.spi.access.EntityRegionAccessStrategy#unlockRegion(org.hibernate.cache.spi.access.SoftLock)
 	 * @see org.hibernate.cache.spi.access.CollectionRegionAccessStrategy#unlockRegion(org.hibernate.cache.spi.access.SoftLock)
 	 */
 	@Override
 	public void unlockRegion(SoftLock lock) throws CacheException {
 		evictAll();
 	}
 
 	@Override
 	public SoftLock lockItem(Object key, Object version) throws CacheException {
 		return null;
 	}
 
 	@Override
 	public void unlockItem(Object key, SoftLock lock) throws CacheException {
 	}
 
 
 	/**
 	 * A no-op since this is an asynchronous cache access strategy.
 	 *
 	 * @see org.hibernate.cache.spi.access.EntityRegionAccessStrategy#remove(java.lang.Object)
 	 * @see org.hibernate.cache.spi.access.CollectionRegionAccessStrategy#remove(java.lang.Object)
 	 */
 	@Override
 	public void remove(Object key) throws CacheException {
 	}
-		/**
+
+	/**
 	 * Called to evict data from the entire region
 	 *
 	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
 	 * @see org.hibernate.cache.spi.access.EntityRegionAccessStrategy#removeAll()
 	 * @see org.hibernate.cache.spi.access.CollectionRegionAccessStrategy#removeAll()
 	 */
 	@Override
 	public void removeAll() throws CacheException {
 		evictAll();
 	}
 
 	@Override
 	public void evict(Object key) throws CacheException {
 		getInternalRegion().evict( key );
 	}
 
 	@Override
 	public void evictAll() throws CacheException {
 		getInternalRegion().evictAll();
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/CachingRegionFactory.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/CachingRegionFactory.java
index 4f8e0803e7..6fc2e46fc2 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/CachingRegionFactory.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/CachingRegionFactory.java
@@ -1,129 +1,131 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.cache;
 
 import java.util.Properties;
 
 import org.hibernate.boot.spi.SessionFactoryOptions;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.CacheDataDescription;
 import org.hibernate.cache.spi.CollectionRegion;
 import org.hibernate.cache.spi.EntityRegion;
 import org.hibernate.cache.spi.NaturalIdRegion;
 import org.hibernate.cache.spi.QueryResultsRegion;
 import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cache.spi.TimestampsRegion;
 import org.hibernate.cache.spi.access.AccessType;
-import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.Logger;
 
 /**
  * @author Strong Liu
  */
 public class CachingRegionFactory implements RegionFactory {
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
-			CoreMessageLogger.class, CachingRegionFactory.class.getName()
-	);
+	private static final Logger LOG = Logger.getLogger( CachingRegionFactory.class.getName() );
+
 	public static String DEFAULT_ACCESSTYPE = "DefaultAccessType";
 	private SessionFactoryOptions settings;
 	private Properties properties;
+
 	public CachingRegionFactory() {
 		LOG.warn( "CachingRegionFactory should be only used for testing." );
 	}
 
 	public CachingRegionFactory(Properties properties) {
 		//add here to avoid run into catch
 		LOG.warn( "CachingRegionFactory should be only used for testing." );
-		this.properties=properties; 
+		this.properties = properties;
 	}
 
 	@Override
 	public void start(SessionFactoryOptions settings, Properties properties) throws CacheException {
-		this.settings=settings;
-		this.properties=properties; 
+		this.settings = settings;
+		this.properties = properties;
 	}
 
 	@Override
 	public void stop() {
 	}
 
 	@Override
 	public boolean isMinimalPutsEnabledByDefault() {
 		return false;
 	}
 
 	@Override
 	public AccessType getDefaultAccessType() {
-		if (properties != null && properties.get(DEFAULT_ACCESSTYPE) != null) {
-			return AccessType.fromExternalName(properties.getProperty(DEFAULT_ACCESSTYPE));
+		if ( properties != null && properties.get( DEFAULT_ACCESSTYPE ) != null ) {
+			return AccessType.fromExternalName( properties.getProperty( DEFAULT_ACCESSTYPE ) );
 		}
 		return AccessType.READ_WRITE;
 	}
 
 	@Override
 	public long nextTimestamp() {
 		return Timestamper.next();
 	}
 
 	@Override
 	public EntityRegion buildEntityRegion(String regionName, Properties properties, CacheDataDescription metadata)
 			throws CacheException {
 		return new EntityRegionImpl( regionName, metadata, settings );
 	}
-	
+
 	@Override
-    public NaturalIdRegion buildNaturalIdRegion(String regionName, Properties properties, CacheDataDescription metadata)
-            throws CacheException {
-        return new NaturalIdRegionImpl( regionName, metadata, settings );
-    }
+	public NaturalIdRegion buildNaturalIdRegion(String regionName, Properties properties, CacheDataDescription metadata)
+			throws CacheException {
+		return new NaturalIdRegionImpl( regionName, metadata, settings );
+	}
 
-    @Override
-	public CollectionRegion buildCollectionRegion(String regionName, Properties properties, CacheDataDescription metadata)
+	@Override
+	public CollectionRegion buildCollectionRegion(
+			String regionName,
+			Properties properties,
+			CacheDataDescription metadata)
 			throws CacheException {
 		return new CollectionRegionImpl( regionName, metadata, settings );
 	}
 
 	@Override
 	public QueryResultsRegion buildQueryResultsRegion(String regionName, Properties properties) throws CacheException {
 		return new QueryResultsRegionImpl( regionName );
 	}
 
 	@Override
 	public TimestampsRegion buildTimestampsRegion(String regionName, Properties properties) throws CacheException {
 		return new TimestampsRegionImpl( regionName );
 	}
 
 	private static class QueryResultsRegionImpl extends BaseGeneralDataRegion implements QueryResultsRegion {
 		QueryResultsRegionImpl(String name) {
 			super( name );
 		}
 	}
 
 	private static class TimestampsRegionImpl extends BaseGeneralDataRegion implements TimestampsRegion {
 		TimestampsRegionImpl(String name) {
 			super( name );
 		}
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/CollectionRegionImpl.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/CollectionRegionImpl.java
index e34fa32960..37fc440790 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/CollectionRegionImpl.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/CollectionRegionImpl.java
@@ -1,76 +1,77 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.cache;
 
 import org.hibernate.boot.spi.SessionFactoryOptions;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.CacheDataDescription;
 import org.hibernate.cache.spi.CollectionRegion;
 import org.hibernate.cache.spi.access.AccessType;
 import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
-import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.Logger;
 
 /**
  * @author Strong Liu
  */
 class CollectionRegionImpl extends BaseTransactionalDataRegion implements CollectionRegion {
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
-			CoreMessageLogger.class, CollectionRegionImpl.class.getName()
-	);
+	private static final Logger LOG = Logger.getLogger( CollectionRegionImpl.class.getName() );
 
 	private final SessionFactoryOptions settings;
 
 	CollectionRegionImpl(String name, CacheDataDescription metadata, SessionFactoryOptions settings) {
 		super( name, metadata );
-		this.settings=settings;
+		this.settings = settings;
 	}
 
 	public SessionFactoryOptions getSettings() {
 		return settings;
 	}
 
 	@Override
 	public CollectionRegionAccessStrategy buildAccessStrategy(AccessType accessType) throws CacheException {
 		switch ( accessType ) {
-			case READ_ONLY:
+			case READ_ONLY: {
 				if ( getCacheDataDescription().isMutable() ) {
 					LOG.warnf( "read-only cache configured for mutable collection [ %s ]", getName() );
 				}
 				return new ReadOnlyCollectionRegionAccessStrategy( this );
-			case READ_WRITE:
-				 return new ReadWriteCollectionRegionAccessStrategy( this );
-			case NONSTRICT_READ_WRITE:
+			}
+			case READ_WRITE: {
+				return new ReadWriteCollectionRegionAccessStrategy( this );
+			}
+			case NONSTRICT_READ_WRITE: {
 				return new NonstrictReadWriteCollectionRegionAccessStrategy( this );
-			case TRANSACTIONAL:
+			}
+			case TRANSACTIONAL: {
 				return new TransactionalCollectionRegionAccessStrategy( this );
 //				throw new UnsupportedOperationException( "doesn't support this access strategy" );
-			default:
+			}
+			default: {
 				throw new IllegalArgumentException( "unrecognized access strategy type [" + accessType + "]" );
+			}
 		}
 	}
 
-
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/EntityRegionImpl.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/EntityRegionImpl.java
index c28db51ae8..777bc08823 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/EntityRegionImpl.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/EntityRegionImpl.java
@@ -1,78 +1,76 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.cache;
 
 import org.hibernate.boot.spi.SessionFactoryOptions;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.CacheDataDescription;
 import org.hibernate.cache.spi.EntityRegion;
 import org.hibernate.cache.spi.access.AccessType;
 import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
-import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.Logger;
 
 /**
  * @author Strong Liu
  */
 class EntityRegionImpl extends BaseTransactionalDataRegion implements EntityRegion {
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
-			CoreMessageLogger.class, EntityRegionImpl.class.getName()
-	);
+	private static final Logger LOG = Logger.getLogger( EntityRegionImpl.class );
+
 
 	private final SessionFactoryOptions settings;
 
 	EntityRegionImpl(String name, CacheDataDescription metadata, SessionFactoryOptions settings) {
 		super( name, metadata );
 		this.settings = settings;
 
 	}
 
 	public SessionFactoryOptions getSettings() {
 		return settings;
 	}
 
 	@Override
 	public EntityRegionAccessStrategy buildAccessStrategy(AccessType accessType) throws CacheException {
 		switch ( accessType ) {
 			case READ_ONLY:
 				if ( getCacheDataDescription().isMutable() ) {
 					LOG.warnf( "read-only cache configured for mutable entity [ %s ]", getName() );
 				}
 				return new ReadOnlyEntityRegionAccessStrategy( this );
 			case READ_WRITE:
 				return new ReadWriteEntityRegionAccessStrategy( this );
 			case NONSTRICT_READ_WRITE:
 				return new NonstrictReadWriteEntityRegionAccessStrategy( this );
 			case TRANSACTIONAL:
 //				throw new UnsupportedOperationException( "doesn't support this access strategy" );
 				return new TransactionalEntityRegionAccessStrategy( this );
 
 			default:
 				throw new IllegalArgumentException( "unrecognized access strategy type [" + accessType + "]" );
 		}
 
 	}
 
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/NaturalIdRegionImpl.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/NaturalIdRegionImpl.java
index c529aa7b83..f47ba128eb 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/NaturalIdRegionImpl.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/NaturalIdRegionImpl.java
@@ -1,76 +1,73 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.cache;
 
 import org.hibernate.boot.spi.SessionFactoryOptions;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.CacheDataDescription;
 import org.hibernate.cache.spi.NaturalIdRegion;
 import org.hibernate.cache.spi.access.AccessType;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
-import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.Logger;
 
 /**
  * @author Eric Dalquist
  */
 class NaturalIdRegionImpl extends BaseTransactionalDataRegion implements NaturalIdRegion {
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
-			CoreMessageLogger.class, NaturalIdRegionImpl.class.getName()
-	);
+	private static final Logger LOG = Logger.getLogger( NaturalIdRegionImpl.class.getName() );
 
 	private final SessionFactoryOptions settings;
 
 	NaturalIdRegionImpl(String name, CacheDataDescription metadata, SessionFactoryOptions settings) {
 		super( name, metadata );
-		this.settings=settings;
+		this.settings = settings;
 	}
 
 	public SessionFactoryOptions getSettings() {
 		return settings;
 	}
 
 	@Override
 	public NaturalIdRegionAccessStrategy buildAccessStrategy(AccessType accessType) throws CacheException {
 		switch ( accessType ) {
 			case READ_ONLY:
 				if ( getCacheDataDescription().isMutable() ) {
 					LOG.warnf( "read-only cache configured for mutable collection [ %s ]", getName() );
 				}
 				return new ReadOnlyNaturalIdRegionAccessStrategy( this );
 			case READ_WRITE:
-				 return new ReadWriteNaturalIdRegionAccessStrategy( this );
+				return new ReadWriteNaturalIdRegionAccessStrategy( this );
 			case NONSTRICT_READ_WRITE:
 				return new NonstrictReadWriteNaturalIdRegionAccessStrategy( this );
 			case TRANSACTIONAL:
 				return new TransactionalNaturalIdRegionAccessStrategy( this );
 //				throw new UnsupportedOperationException( "doesn't support this access strategy" );
 			default:
 				throw new IllegalArgumentException( "unrecognized access strategy type [" + accessType + "]" );
 		}
 	}
 
 
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/NonstrictReadWriteCollectionRegionAccessStrategy.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/NonstrictReadWriteCollectionRegionAccessStrategy.java
index bcafce7f34..51504a26de 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/NonstrictReadWriteCollectionRegionAccessStrategy.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/NonstrictReadWriteCollectionRegionAccessStrategy.java
@@ -1,45 +1,46 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.cache;
 
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.access.SoftLock;
 
 /**
  * @author Strong Liu
  */
 class NonstrictReadWriteCollectionRegionAccessStrategy extends BaseCollectionRegionAccessStrategy {
 	NonstrictReadWriteCollectionRegionAccessStrategy(CollectionRegionImpl region) {
 		super( region );
 	}
+
 	@Override
 	public void unlockItem(Object key, SoftLock lock) throws CacheException {
 		evict( key );
 	}
 
 	@Override
 	public void remove(Object key) throws CacheException {
 		evict( key );
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/NonstrictReadWriteNaturalIdRegionAccessStrategy.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/NonstrictReadWriteNaturalIdRegionAccessStrategy.java
index 3de694f7d6..f5c921bb7a 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/NonstrictReadWriteNaturalIdRegionAccessStrategy.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/NonstrictReadWriteNaturalIdRegionAccessStrategy.java
@@ -1,72 +1,62 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.cache;
 
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.access.SoftLock;
 
 /**
  * @author Eric Dalquist
  */
 class NonstrictReadWriteNaturalIdRegionAccessStrategy extends BaseNaturalIdRegionAccessStrategy {
 	NonstrictReadWriteNaturalIdRegionAccessStrategy(NaturalIdRegionImpl region) {
 		super( region );
 	}
+
 	@Override
 	public void unlockItem(Object key, SoftLock lock) throws CacheException {
 		evict( key );
 	}
 
 	@Override
 	public void remove(Object key) throws CacheException {
 		evict( key );
 	}
-	
-	/**
-	 * Returns <code>false</code> since this is an asynchronous cache access strategy.
-	 * @see org.hibernate.cache.ehcache.internal.strategy.NonStrictReadWriteEhcacheNaturalIdRegionAccessStrategy 
-	 */
+
 	@Override
-	public boolean insert(Object key, Object value ) throws CacheException {
+	public boolean insert(Object key, Object value) throws CacheException {
 		return false;
 	}
 
-	/**
-	 * Returns <code>false</code> since this is a non-strict read/write cache access strategy
-	 * @see org.hibernate.cache.ehcache.internal.strategy.NonStrictReadWriteEhcacheNaturalIdRegionAccessStrategy 
-	 */
 	@Override
-	public boolean afterInsert(Object key, Object value ) throws CacheException {
+	public boolean afterInsert(Object key, Object value) throws CacheException {
 		return false;
 	}
-	
-	/**
-	 * Removes the entry since this is a non-strict read/write cache strategy.
-	 * @see org.hibernate.cache.ehcache.internal.strategy.NonStrictReadWriteEhcacheNaturalIdRegionAccessStrategy 
-	 */
-	public boolean update(Object key, Object value ) throws CacheException {
+
+	@Override
+	public boolean update(Object key, Object value) throws CacheException {
 		remove( key );
 		return false;
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/ReadOnlyEntityRegionAccessStrategy.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/ReadOnlyEntityRegionAccessStrategy.java
index 9dc144d9a2..2bd83b0161 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/ReadOnlyEntityRegionAccessStrategy.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/ReadOnlyEntityRegionAccessStrategy.java
@@ -1,87 +1,86 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.cache;
 
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.access.SoftLock;
-import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.Logger;
 
 /**
  * @author Strong Liu
  */
 class ReadOnlyEntityRegionAccessStrategy extends BaseEntityRegionAccessStrategy {
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
-			CoreMessageLogger.class, ReadOnlyEntityRegionAccessStrategy.class.getName()
-	);
+	private static final Logger LOG = Logger.getLogger( ReadOnlyEntityRegionAccessStrategy.class );
+
 
 	ReadOnlyEntityRegionAccessStrategy(EntityRegionImpl region) {
 		super( region );
 	}
+
 	/**
 	 * This cache is asynchronous hence a no-op
 	 */
 	@Override
 	public boolean insert(Object key, Object value, Object version) throws CacheException {
 		return false; //wait until tx complete, see afterInsert().
 	}
 
 	@Override
 	public boolean afterInsert(Object key, Object value, Object version) throws CacheException {
 		getInternalRegion().put( key, value ); //save into cache since the tx is completed
 		return true;
 	}
 
 	@Override
 	public void unlockItem(Object key, SoftLock lock) throws CacheException {
 		evict( key );
 	}
 
 	/**
 	 * Throws UnsupportedOperationException since this cache is read-only
 	 *
 	 * @throws UnsupportedOperationException always
 	 */
 	@Override
 	public boolean update(Object key, Object value, Object currentVersion, Object previousVersion)
 			throws CacheException {
-		LOG.invalidEditOfReadOnlyItem( key );
+		LOG.info( "Illegal attempt to update item cached as read-only : " + key );
 		throw new UnsupportedOperationException( "Can't write to a readonly object" );
 	}
 
 	/**
 	 * Throws UnsupportedOperationException since this cache is read-only
 	 *
 	 * @throws UnsupportedOperationException always
 	 */
 	@Override
 	public boolean afterUpdate(Object key, Object value, Object currentVersion, Object previousVersion, SoftLock lock)
 			throws CacheException {
-		LOG.invalidEditOfReadOnlyItem( key );
+		LOG.info( "Illegal attempt to update item cached as read-only : " + key );
 		throw new UnsupportedOperationException( "Can't write to a readonly object" );
 	}
 
 
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/ReadOnlyNaturalIdRegionAccessStrategy.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/ReadOnlyNaturalIdRegionAccessStrategy.java
index fd16490e58..fa67b48ece 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/ReadOnlyNaturalIdRegionAccessStrategy.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/ReadOnlyNaturalIdRegionAccessStrategy.java
@@ -1,48 +1,41 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.cache;
 
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.access.SoftLock;
-import org.hibernate.internal.CoreMessageLogger;
-
-import org.jboss.logging.Logger;
 
 /**
  * @author Eric Dalquist
  */
 class ReadOnlyNaturalIdRegionAccessStrategy extends BaseNaturalIdRegionAccessStrategy {
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
-			CoreMessageLogger.class, ReadOnlyNaturalIdRegionAccessStrategy.class.getName()
-	);
-
 	ReadOnlyNaturalIdRegionAccessStrategy(NaturalIdRegionImpl region) {
 		super( region );
 	}
 
 	@Override
 	public void unlockItem(Object key, SoftLock lock) throws CacheException {
 		evict( key );
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/ReadWriteNaturalIdRegionAccessStrategy.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/ReadWriteNaturalIdRegionAccessStrategy.java
index c0908a0fd3..a1848a2d22 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/ReadWriteNaturalIdRegionAccessStrategy.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/ReadWriteNaturalIdRegionAccessStrategy.java
@@ -1,121 +1,121 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.cache;
 
 import java.util.Comparator;
 
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.NaturalIdRegion;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.cache.spi.access.SoftLock;
 
 /**
  * @author Eric Dalquist
  */
 class ReadWriteNaturalIdRegionAccessStrategy extends AbstractReadWriteAccessStrategy
 		implements NaturalIdRegionAccessStrategy {
 
 	private final NaturalIdRegionImpl region;
 
 	ReadWriteNaturalIdRegionAccessStrategy(NaturalIdRegionImpl region) {
 		this.region = region;
 	}
 
 	@Override
-	public boolean insert(Object key, Object value ) throws CacheException {
+	public boolean insert(Object key, Object value) throws CacheException {
 		return false;
 	}
 
 	@Override
-	public boolean update(Object key, Object value ) throws CacheException {
+	public boolean update(Object key, Object value) throws CacheException {
 		return false;
 	}
 
 	@Override
-	public boolean afterInsert(Object key, Object value ) throws CacheException {
+	public boolean afterInsert(Object key, Object value) throws CacheException {
 
 		try {
 			writeLock.lock();
 			Lockable item = (Lockable) region.get( key );
 			if ( item == null ) {
 				region.put( key, new Item( value, null, region.nextTimestamp() ) );
 				return true;
 			}
 			else {
 				return false;
 			}
 		}
 		finally {
 			writeLock.unlock();
 		}
 	}
 
 
 	@Override
 	public boolean afterUpdate(Object key, Object value, SoftLock lock) throws CacheException {
 		try {
 			writeLock.lock();
 			Lockable item = (Lockable) region.get( key );
 
 			if ( item != null && item.isUnlockable( lock ) ) {
 				Lock lockItem = (Lock) item;
 				if ( lockItem.wasLockedConcurrently() ) {
 					decrementLock( key, lockItem );
 					return false;
 				}
 				else {
 					region.put( key, new Item( value, null, region.nextTimestamp() ) );
 					return true;
 				}
 			}
 			else {
 				handleLockExpiry( key, item );
 				return false;
 			}
 		}
 		finally {
 			writeLock.unlock();
 		}
 	}
 
 	@Override
 	Comparator getVersionComparator() {
 		return region.getCacheDataDescription().getVersionComparator();
 	}
 
 	@Override
 	protected BaseGeneralDataRegion getInternalRegion() {
 		return region;
 	}
 
 	@Override
 	protected boolean isDefaultMinimalPutOverride() {
 		return region.getSettings().isMinimalPutsEnabled();
 	}
 
 	@Override
 	public NaturalIdRegion getRegion() {
 		return region;
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/Timestamper.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/Timestamper.java
index f409e03054..aaaae0e1f9 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/Timestamper.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/Timestamper.java
@@ -1,64 +1,64 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.cache;
 
 import java.util.concurrent.atomic.AtomicLong;
 
 /**
  * Generates increasing identifiers (in a single VM only). Not valid across multiple VMs.  Identifiers are not
  * necessarily strictly increasing, but usually are.
- *
+ * <p/>
  * Core while loop implemented by Alex Snaps - EHCache project - under ASL 2.0
  *
  * @author Hibernate team
  * @author Alex Snaps
  */
 public final class Timestamper {
 	private static final int BIN_DIGITS = 12;
 	public static final short ONE_MS = 1 << BIN_DIGITS;
 	private static final AtomicLong VALUE = new AtomicLong();
 
 	public static long next() {
 		while ( true ) {
 			long base = System.currentTimeMillis() << BIN_DIGITS;
 			long maxValue = base + ONE_MS - 1;
 
 			for ( long current = VALUE.get(), update = Math.max( base, current + 1 ); update < maxValue;
-				  current = VALUE.get(), update = Math.max( base, current + 1 ) ) {
+					current = VALUE.get(), update = Math.max( base, current + 1 ) ) {
 				if ( VALUE.compareAndSet( current, update ) ) {
 					return update;
 				}
 			}
 		}
 	}
 
 	private Timestamper() {
 	}
 }
 
 
 
 
 
 
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/TransactionalCollectionRegionAccessStrategy.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/TransactionalCollectionRegionAccessStrategy.java
index 31c4b538d0..4e56f31c3b 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/TransactionalCollectionRegionAccessStrategy.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/TransactionalCollectionRegionAccessStrategy.java
@@ -1,25 +1,18 @@
 package org.hibernate.testing.cache;
 
 import org.hibernate.cache.CacheException;
 
 /**
  * @author Strong Liu <stliu@hibernate.org>
  */
 class TransactionalCollectionRegionAccessStrategy extends BaseCollectionRegionAccessStrategy {
 	TransactionalCollectionRegionAccessStrategy(CollectionRegionImpl region) {
 		super( region );
 	}
 
-
-
-
-	/**
-	 * {@inheritDoc}
-	 */
 	@Override
 	public void remove(Object key) throws CacheException {
 		evict( key );
 	}
 
-
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/TransactionalEntityRegionAccessStrategy.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/TransactionalEntityRegionAccessStrategy.java
index 376b284360..088317d7d5 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/TransactionalEntityRegionAccessStrategy.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/TransactionalEntityRegionAccessStrategy.java
@@ -1,34 +1,35 @@
 package org.hibernate.testing.cache;
 
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.access.SoftLock;
 
 /**
  * @author Strong Liu <stliu@hibernate.org>
  */
 class TransactionalEntityRegionAccessStrategy extends BaseEntityRegionAccessStrategy {
 	TransactionalEntityRegionAccessStrategy(EntityRegionImpl region) {
 		super( region );
 	}
 
 	@Override
 	public boolean afterInsert(Object key, Object value, Object version) {
 		return false;
 	}
 
 	@Override
 	public boolean afterUpdate(Object key, Object value, Object currentVersion, Object previousVersion, SoftLock lock) {
 		return false;
 	}
 
 	@Override
 	public void remove(Object key) throws CacheException {
 		evict( key );
 	}
 
 	@Override
-	public boolean update(Object key, Object value, Object currentVersion,
-						  Object previousVersion) throws CacheException {
+	public boolean update(
+			Object key, Object value, Object currentVersion,
+			Object previousVersion) throws CacheException {
 		return insert( key, value, currentVersion );
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/cache/TransactionalNaturalIdRegionAccessStrategy.java b/hibernate-testing/src/main/java/org/hibernate/testing/cache/TransactionalNaturalIdRegionAccessStrategy.java
index 625941399d..7de8c47976 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/cache/TransactionalNaturalIdRegionAccessStrategy.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/cache/TransactionalNaturalIdRegionAccessStrategy.java
@@ -1,25 +1,18 @@
 package org.hibernate.testing.cache;
 
 import org.hibernate.cache.CacheException;
 
 /**
  * @author Eric Dalquist
  */
 class TransactionalNaturalIdRegionAccessStrategy extends BaseNaturalIdRegionAccessStrategy {
 	TransactionalNaturalIdRegionAccessStrategy(NaturalIdRegionImpl region) {
 		super( region );
 	}
 
-
-
-
-	/**
-	 * {@inheritDoc}
-	 */
 	@Override
 	public void remove(Object key) throws CacheException {
 		evict( key );
 	}
 
-
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/jta/JtaAwareConnectionProviderImpl.java b/hibernate-testing/src/main/java/org/hibernate/testing/jta/JtaAwareConnectionProviderImpl.java
index 28b18d7d40..e239eea5c0 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/jta/JtaAwareConnectionProviderImpl.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/jta/JtaAwareConnectionProviderImpl.java
@@ -1,269 +1,268 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.jta;
 
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
-import javax.sql.DataSource;
 import javax.transaction.SystemException;
 import javax.transaction.Transaction;
 import javax.transaction.xa.XAException;
 import javax.transaction.xa.XAResource;
 import javax.transaction.xa.Xid;
 
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.jdbc.connections.internal.ConnectionProviderInitiator;
 import org.hibernate.engine.jdbc.connections.internal.DriverManagerConnectionProviderImpl;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.service.spi.Configurable;
 import org.hibernate.service.spi.Stoppable;
 
 /**
- * A {@link DataSource} implementation intended for testing Hibernate/JTA interaction.  In that limited scope we
+ * A {@link ConnectionProvider} implementation intended for testing Hibernate/JTA interaction.  In that limited scope we
  * only ever have one single resource (the database connection) so we do not at all care about full-blown XA
  * semantics.  This class behaves accordingly.  This class also assumes usage of and access to JBossTS/Arjuna.
  *
  * @author Steve Ebersole
  * @author Jonathan Halliday
  */
 public class JtaAwareConnectionProviderImpl implements ConnectionProvider, Configurable, Stoppable {
 	private static final String CONNECTION_KEY = "_database_connection";
 
 	private DriverManagerConnectionProviderImpl delegate;
 
 	private List<Connection> nonEnlistedConnections = new ArrayList<Connection>();
 
 	@Override
 	public void configure(Map configurationValues) {
 		Properties connectionSettings = new Properties();
 		transferSetting( Environment.DRIVER, configurationValues, connectionSettings );
 		transferSetting( Environment.URL, configurationValues, connectionSettings );
 		transferSetting( Environment.USER, configurationValues, connectionSettings );
 		transferSetting( Environment.PASS, configurationValues, connectionSettings );
 		transferSetting( Environment.ISOLATION, configurationValues, connectionSettings );
 		Properties passThroughSettings = ConnectionProviderInitiator.getConnectionProperties( configurationValues );
 		if ( passThroughSettings != null ) {
 			for ( String setting : passThroughSettings.stringPropertyNames() ) {
 				transferSetting( Environment.CONNECTION_PREFIX + '.' + setting, configurationValues, connectionSettings );
 			}
 		}
 		connectionSettings.setProperty( Environment.AUTOCOMMIT, "false" );
 
 		delegate = new DriverManagerConnectionProviderImpl();
 		delegate.configure( connectionSettings );
 	}
 
 	@SuppressWarnings("unchecked")
 	private static void transferSetting(String settingName, Map source, Map target) {
 		Object value = source.get( settingName );
 		if ( value != null ) {
 			target.put( settingName, value );
 		}
 	}
 
 	@Override
 	public void stop() {
 		delegate.stop();
 	}
 
 	@Override
 	public Connection getConnection() throws SQLException {
 		Transaction currentTransaction = findCurrentTransaction();
 
 		try {
 			if ( currentTransaction == null ) {
 				// this block handles non enlisted connections ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 				Connection connection = delegate.getConnection();
 				nonEnlistedConnections.add( connection );
 				return connection;
 			}
 
 			// this portion handles enlisted connections ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 			Connection connection = (Connection) TestingJtaPlatformImpl.synchronizationRegistry().getResource(
 					CONNECTION_KEY
 			);
 			if ( connection == null ) {
 				connection = delegate.getConnection();
 				TestingJtaPlatformImpl.synchronizationRegistry().putResource( CONNECTION_KEY, connection );
 
 				XAResourceWrapper xaResourceWrapper = new XAResourceWrapper( this, connection );
 				currentTransaction.enlistResource( xaResourceWrapper );
 			}
 			return connection;
 		}
 		catch (SQLException e) {
 			throw e;
 		}
 		catch (Exception e) {
 			throw new SQLException(e);
 		}
 	}
 
 	@Override
 	public void closeConnection(Connection conn) throws SQLException {
 		if ( conn == null ) {
 			return;
 		}
 
 		if ( nonEnlistedConnections.contains( conn ) ) {
 			nonEnlistedConnections.remove( conn );
 			delegate.closeConnection( conn );
 		}
 		else {
 			// do nothing.  part of the enlistment contract here is that the XAResource wrapper
 			// takes that responsibility.
 		}
 	}
 
 	@Override
 	public boolean supportsAggressiveRelease() {
 		return true;
 	}
 
 	protected Transaction findCurrentTransaction() {
 		try {
 			return TestingJtaPlatformImpl.transactionManager().getTransaction();
 		}
 		catch (SystemException e) {
 			throw new IllegalStateException( "Could not locate current transaction" );
 		}
 	}
 
 	@Override
 	public boolean isUnwrappableAs(Class unwrapType) {
 		return delegate.isUnwrappableAs( unwrapType );
 	}
 
 	@Override
 	public <T> T unwrap(Class<T> unwrapType) {
 		return delegate.unwrap( unwrapType );
 	}
 
 	private void delist(Connection connection) {
 		// todo : verify the incoming connection is the currently enlisted one?
 		TestingJtaPlatformImpl.synchronizationRegistry().putResource( CONNECTION_KEY, null );
 		try {
 			delegate.closeConnection( connection );
 		}
 		catch (SQLException e) {
 			System.err.println( "!!!Error trying to close JDBC connection from delist callbacks!!!" );
 		}
 	}
 
 	public static class XAResourceWrapper implements XAResource {
 		private final JtaAwareConnectionProviderImpl pool;
 		private final Connection connection;
 		private int transactionTimeout;
 
 		public XAResourceWrapper(JtaAwareConnectionProviderImpl pool, Connection connection) {
 			this.pool = pool;
 			this.connection = connection;
 		}
 
 		@Override
 		public int prepare(Xid xid) throws XAException {
 			throw new RuntimeException("this should never be called");
 		}
 
 		@Override
 		public void commit(Xid xid, boolean onePhase) throws XAException {
 			if (!onePhase) {
 				throw new IllegalArgumentException( "must be one phase" );
 			}
 
 			try {
 				connection.commit();
 			}
 			catch(SQLException e) {
 				throw new XAException( e.toString() );
 			}
 			finally {
 				try {
 					pool.delist( connection );
 				}
 				catch (Exception ignore) {
 				}
 			}
 		}
 
 		@Override
 		public void rollback(Xid xid) throws XAException {
 
 			try {
 				connection.rollback();
 			}
 			catch(SQLException e) {
 				throw new XAException( e.toString() );
 			}
 			finally {
 				try {
 					pool.delist( connection );
 				}
 				catch (Exception ignore) {
 				}
 			}
 		}
 
 		@Override
 		public void end(Xid xid, int i) throws XAException {
 			// noop
 		}
 
 		@Override
 		public void start(Xid xid, int i) throws XAException {
 			// noop
 		}
 
 
 		@Override
 		public void forget(Xid xid) throws XAException {
 			// noop
 		}
 
 		@Override
 		public int getTransactionTimeout() throws XAException {
 			return transactionTimeout;
 		}
 
 		@Override
 		public boolean setTransactionTimeout(int i) throws XAException {
 			transactionTimeout = i;
 			return true;
 		}
 
 		@Override
 		public boolean isSameRM(XAResource xaResource) throws XAException {
 			return xaResource != null && xaResource == this;
 		}
 
 		@Override
 		public Xid[] recover(int i) throws XAException {
 			return new Xid[0];
 		}
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/BaseCoreFunctionalTestCase.java b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/BaseCoreFunctionalTestCase.java
index 94cf782720..81b4e0f6e3 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/BaseCoreFunctionalTestCase.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/BaseCoreFunctionalTestCase.java
@@ -1,459 +1,461 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.junit4;
 
 import java.io.InputStream;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 import javax.persistence.SharedCacheMode;
 
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.Session;
 import org.hibernate.boot.model.naming.ImplicitNamingStrategyLegacyJpaImpl;
 import org.hibernate.boot.registry.BootstrapServiceRegistry;
 import org.hibernate.boot.registry.BootstrapServiceRegistryBuilder;
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.boot.registry.internal.StandardServiceRegistryImpl;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.H2Dialect;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.jdbc.AbstractReturningWork;
 import org.hibernate.jdbc.Work;
 
 import org.hibernate.testing.AfterClassOnce;
 import org.hibernate.testing.BeforeClassOnce;
 import org.hibernate.testing.OnExpectedFailure;
 import org.hibernate.testing.OnFailure;
 import org.hibernate.testing.SkipLog;
 import org.hibernate.testing.cache.CachingRegionFactory;
 import org.junit.After;
 import org.junit.Before;
 
 import static org.junit.Assert.fail;
 
 /**
  * Applies functional testing logic for core Hibernate testing on top of {@link BaseUnitTestCase}
  *
  * @author Steve Ebersole
  */
 @SuppressWarnings( {"deprecation"} )
 public abstract class BaseCoreFunctionalTestCase extends BaseUnitTestCase {
 	public static final String VALIDATE_DATA_CLEANUP = "hibernate.test.validateDataCleanup";
 
 	public static final Dialect DIALECT = Dialect.getDialect();
 
 	private Configuration configuration;
 	private StandardServiceRegistryImpl serviceRegistry;
 	private SessionFactoryImplementor sessionFactory;
 
 	protected Session session;
 
 	protected static Dialect getDialect() {
 		return DIALECT;
 	}
 
 	protected Configuration configuration() {
 		return configuration;
 	}
 
 	protected StandardServiceRegistryImpl serviceRegistry() {
 		return serviceRegistry;
 	}
 
 	protected SessionFactoryImplementor sessionFactory() {
 		return sessionFactory;
 	}
 
 	protected Session openSession() throws HibernateException {
 		session = sessionFactory().openSession();
 		return session;
 	}
 
 	protected Session openSession(Interceptor interceptor) throws HibernateException {
 		session = sessionFactory().withOptions().interceptor( interceptor ).openSession();
 		return session;
 	}
 
 
 	// before/after test class ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@BeforeClassOnce
 	@SuppressWarnings( {"UnusedDeclaration"})
 	protected void buildSessionFactory() {
 		// for now, build the configuration to get all the property settings
 		configuration = constructAndConfigureConfiguration();
 		BootstrapServiceRegistry bootRegistry = buildBootstrapServiceRegistry();
 		serviceRegistry = buildServiceRegistry( bootRegistry, configuration );
 		// this is done here because Configuration does not currently support 4.0 xsd
 		afterConstructAndConfigureConfiguration( configuration );
 		sessionFactory = ( SessionFactoryImplementor ) configuration.buildSessionFactory( serviceRegistry );
 		afterSessionFactoryBuilt();
 	}
 
 	protected void rebuildSessionFactory() {
 		if ( sessionFactory == null ) {
 			return;
 		}
 		try {
 			sessionFactory.close();
 			sessionFactory = null;
 			configuration = null;
 			serviceRegistry.destroy();
 			serviceRegistry = null;
 		}
 		catch (Exception ignore) {
 		}
 
 		buildSessionFactory();
 	}
 
 	protected Configuration buildConfiguration() {
 		Configuration cfg = constructAndConfigureConfiguration();
 		afterConstructAndConfigureConfiguration( cfg );
 		return cfg;
 	}
 
 	protected Configuration constructAndConfigureConfiguration() {
 		Configuration cfg = constructConfiguration();
 		configure( cfg );
 		return cfg;
 	}
 
 	private void afterConstructAndConfigureConfiguration(Configuration cfg) {
 		addMappings( cfg );
 		applyCacheSettings( cfg );
 		afterConfigurationBuilt( cfg );
 	}
 
 	protected Configuration constructConfiguration() {
 		Configuration configuration = new Configuration();
 		configuration.setProperty( AvailableSettings.CACHE_REGION_FACTORY, CachingRegionFactory.class.getName() );
 		configuration.setProperty( AvailableSettings.USE_NEW_ID_GENERATOR_MAPPINGS, "true" );
 		if ( createSchema() ) {
 			configuration.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
 			final String secondSchemaName = createSecondSchema();
 			if ( StringHelper.isNotEmpty( secondSchemaName ) ) {
 				if ( !( getDialect() instanceof H2Dialect ) ) {
 					throw new UnsupportedOperationException( "Only H2 dialect supports creation of second schema." );
 				}
 				Helper.createH2Schema( secondSchemaName, configuration );
 			}
 		}
 		configuration.setImplicitNamingStrategy( ImplicitNamingStrategyLegacyJpaImpl.INSTANCE );
 		configuration.setProperty( Environment.DIALECT, getDialect().getClass().getName() );
 		return configuration;
 	}
 
 	protected void configure(Configuration configuration) {
 	}
 
 	protected void addMappings(Configuration configuration) {
 		String[] mappings = getMappings();
 		if ( mappings != null ) {
 			for ( String mapping : mappings ) {
 				configuration.addResource(
 						getBaseForMappings() + mapping,
 						getClass().getClassLoader()
 				);
 			}
 		}
 		Class<?>[] annotatedClasses = getAnnotatedClasses();
 		if ( annotatedClasses != null ) {
 			for ( Class<?> annotatedClass : annotatedClasses ) {
 				configuration.addAnnotatedClass( annotatedClass );
 			}
 		}
 		String[] annotatedPackages = getAnnotatedPackages();
 		if ( annotatedPackages != null ) {
 			for ( String annotatedPackage : annotatedPackages ) {
 				configuration.addPackage( annotatedPackage );
 			}
 		}
 		String[] xmlFiles = getXmlFiles();
 		if ( xmlFiles != null ) {
 			for ( String xmlFile : xmlFiles ) {
 				InputStream is = Thread.currentThread().getContextClassLoader().getResourceAsStream( xmlFile );
 				configuration.addInputStream( is );
 			}
 		}
 	}
 
 	protected static final String[] NO_MAPPINGS = new String[0];
 
 	protected String[] getMappings() {
 		return NO_MAPPINGS;
 	}
 
 	protected String getBaseForMappings() {
 		return "org/hibernate/test/";
 	}
 
 	protected static final Class<?>[] NO_CLASSES = new Class[0];
 
 	protected Class<?>[] getAnnotatedClasses() {
 		return NO_CLASSES;
 	}
 
 	protected String[] getAnnotatedPackages() {
 		return NO_MAPPINGS;
 	}
 
 	protected String[] getXmlFiles() {
 		// todo : rename to getOrmXmlFiles()
 		return NO_MAPPINGS;
 	}
 
 	protected void applyCacheSettings(Configuration configuration) {
 		if ( getCacheConcurrencyStrategy() != null ) {
 			configuration.setProperty( AvailableSettings.DEFAULT_CACHE_CONCURRENCY_STRATEGY, getCacheConcurrencyStrategy() );
 			configuration.setSharedCacheMode( SharedCacheMode.ALL );
 		}
 	}
 
 	protected String getCacheConcurrencyStrategy() {
 		return null;
 	}
 
 	protected void afterConfigurationBuilt(Configuration configuration) {
 	}
 
 	protected BootstrapServiceRegistry buildBootstrapServiceRegistry() {
 		final BootstrapServiceRegistryBuilder builder = new BootstrapServiceRegistryBuilder();
 		prepareBootstrapRegistryBuilder( builder );
 		return builder.build();
 	}
 
 	protected void prepareBootstrapRegistryBuilder(BootstrapServiceRegistryBuilder builder) {
 	}
 
 	protected StandardServiceRegistryImpl buildServiceRegistry(BootstrapServiceRegistry bootRegistry, Configuration configuration) {
 		Properties properties = new Properties();
 		properties.putAll( configuration.getProperties() );
 		Environment.verifyProperties( properties );
 		ConfigurationHelper.resolvePlaceHolders( properties );
 
 		StandardServiceRegistryBuilder cfgRegistryBuilder = configuration.getStandardServiceRegistryBuilder();
 
 		StandardServiceRegistryBuilder registryBuilder = new StandardServiceRegistryBuilder( bootRegistry, cfgRegistryBuilder.getAggregatedCfgXml() )
 				.applySettings( properties );
 
 		prepareBasicRegistryBuilder( registryBuilder );
 		return (StandardServiceRegistryImpl) registryBuilder.build();
 	}
 
 	protected void prepareBasicRegistryBuilder(StandardServiceRegistryBuilder serviceRegistryBuilder) {
 	}
 
 	protected void afterSessionFactoryBuilt() {
 	}
 
 	protected boolean createSchema() {
 		return true;
 	}
 
 	/**
 	 * Feature supported only by H2 dialect.
 	 * @return Provide not empty name to create second schema.
 	 */
 	protected String createSecondSchema() {
 		return null;
 	}
 
 	protected boolean rebuildSessionFactoryOnError() {
 		return true;
 	}
 
 	@AfterClassOnce
 	@SuppressWarnings( {"UnusedDeclaration"})
 	protected void releaseSessionFactory() {
 		if ( sessionFactory == null ) {
 			return;
 		}
 		sessionFactory.close();
 		sessionFactory = null;
 		configuration = null;
-        if ( serviceRegistry != null ) {
+		if ( serviceRegistry != null ) {
 			if ( serviceRegistry.isActive() ) {
 				try {
 					serviceRegistry.destroy();
 				}
 				catch (Exception ignore) {
 				}
 				fail( "StandardServiceRegistry was not closed down as expected" );
 			}
 		}
-        serviceRegistry=null;
+		serviceRegistry=null;
 	}
 
 	@OnFailure
 	@OnExpectedFailure
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public void onFailure() {
 		if ( rebuildSessionFactoryOnError() ) {
 			rebuildSessionFactory();
 		}
 	}
 
 
 	// before/after each test ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Before
 	public final void beforeTest() throws Exception {
 		prepareTest();
 	}
 
 	protected void prepareTest() throws Exception {
 	}
 
 	@After
 	public final void afterTest() throws Exception {
 		if ( isCleanupTestDataRequired() ) {
 			cleanupTestData();
 		}
 		cleanupTest();
 
 		cleanupSession();
 
 		assertAllDataRemoved();
 
 	}
 
 	protected void cleanupCache() {
 		if ( sessionFactory != null ) {
 			sessionFactory.getCache().evictAllRegions();
 		}
 	}
 	
-	protected boolean isCleanupTestDataRequired() { return false; }
+	protected boolean isCleanupTestDataRequired() {
+		return false;
+	}
 	
 	protected void cleanupTestData() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "delete from java.lang.Object" ).executeUpdate();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 
 	private void cleanupSession() {
 		if ( session != null && ! ( (SessionImplementor) session ).isClosed() ) {
 			if ( session.isConnected() ) {
 				session.doWork( new RollbackWork() );
 			}
 			session.close();
 		}
 		session = null;
 	}
 
 	public class RollbackWork implements Work {
 		public void execute(Connection connection) throws SQLException {
 			connection.rollback();
 		}
 	}
 
 	protected void cleanupTest() throws Exception {
 	}
 
 	@SuppressWarnings( {"UnnecessaryBoxing", "UnnecessaryUnboxing"})
 	protected void assertAllDataRemoved() {
 		if ( !createSchema() ) {
 			return; // no tables were created...
 		}
 		if ( !Boolean.getBoolean( VALIDATE_DATA_CLEANUP ) ) {
 			return;
 		}
 
 		Session tmpSession = sessionFactory.openSession();
 		try {
 			List list = tmpSession.createQuery( "select o from java.lang.Object o" ).list();
 
 			Map<String,Integer> items = new HashMap<String,Integer>();
 			if ( !list.isEmpty() ) {
 				for ( Object element : list ) {
 					Integer l = items.get( tmpSession.getEntityName( element ) );
 					if ( l == null ) {
 						l = 0;
 					}
 					l = l + 1 ;
 					items.put( tmpSession.getEntityName( element ), l );
 					System.out.println( "Data left: " + element );
 				}
 				fail( "Data is left in the database: " + items.toString() );
 			}
 		}
 		finally {
 			try {
 				tmpSession.close();
 			}
 			catch( Throwable t ) {
 				// intentionally empty
 			}
 		}
 	}
 
 	protected boolean readCommittedIsolationMaintained(String scenario) {
 		int isolation = java.sql.Connection.TRANSACTION_READ_UNCOMMITTED;
 		Session testSession = null;
 		try {
 			testSession = openSession();
 			isolation = testSession.doReturningWork(
 					new AbstractReturningWork<Integer>() {
 						@Override
 						public Integer execute(Connection connection) throws SQLException {
 							return connection.getTransactionIsolation();
 						}
 					}
 			);
 		}
 		catch( Throwable ignore ) {
 		}
 		finally {
 			if ( testSession != null ) {
 				try {
 					testSession.close();
 				}
 				catch( Throwable ignore ) {
 				}
 			}
 		}
 		if ( isolation < java.sql.Connection.TRANSACTION_READ_COMMITTED ) {
 			SkipLog.reportSkip( "environment does not support at least read committed isolation", scenario );
 			return false;
 		}
 		else {
 			return true;
 		}
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/BaseNonConfigCoreFunctionalTestCase.java b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/BaseNonConfigCoreFunctionalTestCase.java
index c4909b81e2..8a81065864 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/BaseNonConfigCoreFunctionalTestCase.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/BaseNonConfigCoreFunctionalTestCase.java
@@ -1,537 +1,539 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.junit4;
 
 import java.sql.Blob;
 import java.sql.Clob;
 import java.sql.Connection;
 import java.sql.NClob;
 import java.sql.SQLException;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.Session;
 import org.hibernate.boot.Metadata;
 import org.hibernate.boot.MetadataBuilder;
 import org.hibernate.boot.MetadataSources;
 import org.hibernate.boot.SessionFactoryBuilder;
 import org.hibernate.boot.model.naming.ImplicitNamingStrategyLegacyJpaImpl;
 import org.hibernate.boot.registry.BootstrapServiceRegistry;
 import org.hibernate.boot.registry.BootstrapServiceRegistryBuilder;
 import org.hibernate.boot.registry.StandardServiceRegistry;
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.H2Dialect;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.jdbc.Work;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.type.BlobType;
 import org.hibernate.type.ClobType;
 import org.hibernate.type.NClobType;
 
 import org.hibernate.testing.AfterClassOnce;
 import org.hibernate.testing.BeforeClassOnce;
 import org.hibernate.testing.OnExpectedFailure;
 import org.hibernate.testing.OnFailure;
 import org.hibernate.testing.cache.CachingRegionFactory;
 import org.junit.After;
 import org.junit.Before;
 
 import static org.junit.Assert.fail;
 
 /**
  * Applies functional testing logic for core Hibernate testing on top of {@link BaseUnitTestCase}.
  * Much like {@link org.hibernate.testing.junit4.BaseCoreFunctionalTestCase}, except that
  * this form uses the new bootstrapping APIs while BaseCoreFunctionalTestCase continues to
  * use (the neutered form of) Configuration.
  *
  * @author Steve Ebersole
  */
 public class BaseNonConfigCoreFunctionalTestCase extends BaseUnitTestCase {
 	public static final String VALIDATE_DATA_CLEANUP = "hibernate.test.validateDataCleanup";
 
 	private StandardServiceRegistry serviceRegistry;
 	private MetadataImplementor metadata;
 	private SessionFactoryImplementor sessionFactory;
 
 	private Session session;
 
 	protected Dialect getDialect() {
 		if ( serviceRegistry != null ) {
 			return serviceRegistry.getService( JdbcEnvironment.class ).getDialect();
 		}
 		else {
 			return BaseCoreFunctionalTestCase.getDialect();
 		}
 	}
 
 	protected StandardServiceRegistry serviceRegistry() {
 		return serviceRegistry;
 	}
 
 	protected MetadataImplementor metadata() {
 		return metadata;
 	}
 
 	protected SessionFactoryImplementor sessionFactory() {
 		return sessionFactory;
 	}
 
 	protected Session openSession() throws HibernateException {
 		session = sessionFactory().openSession();
 		return session;
 	}
 
 	protected Session openSession(Interceptor interceptor) throws HibernateException {
 		session = sessionFactory().withOptions().interceptor( interceptor ).openSession();
 		return session;
 	}
 
 	protected Session getSession() {
 		return session;
 	}
 
 	protected void rebuildSessionFactory() {
 		releaseResources();
 		buildResources();
 	}
 
 	protected void cleanupCache() {
 		if ( sessionFactory != null ) {
 			sessionFactory.getCache().evictAllRegions();
 		}
 	}
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// JUNIT hooks
 
 	@BeforeClassOnce
 	@SuppressWarnings( {"UnusedDeclaration"})
 	protected void startUp() {
 		buildResources();
 	}
 
 	protected void buildResources() {
 		final StandardServiceRegistryBuilder ssrb = constructStandardServiceRegistryBuilder();
 
 		serviceRegistry = ssrb.build();
 		afterStandardServiceRegistryBuilt( serviceRegistry );
 
 		final MetadataSources metadataSources = new MetadataSources( serviceRegistry );
 		applyMetadataSources( metadataSources );
 		afterMetadataSourcesApplied( metadataSources );
 
 		final MetadataBuilder metadataBuilder = metadataSources.getMetadataBuilder();
 		initialize( metadataBuilder );
 		configureMetadataBuilder( metadataBuilder );
 
 		metadata = (MetadataImplementor) metadataBuilder.build();
 		applyCacheSettings( metadata );
 		afterMetadataBuilt( metadata );
 
 		final SessionFactoryBuilder sfb = metadata.getSessionFactoryBuilder();
 		initialize( sfb, metadata );
 		configureSessionFactoryBuilder( sfb );
 
 		sessionFactory = (SessionFactoryImplementor) sfb.build();
 		afterSessionFactoryBuilt( sessionFactory );
 	}
 
 	protected final StandardServiceRegistryBuilder constructStandardServiceRegistryBuilder() {
 		final BootstrapServiceRegistryBuilder bsrb = new BootstrapServiceRegistryBuilder();
 		// by default we do not share the BootstrapServiceRegistry nor the StandardServiceRegistry,
 		// so we want the BootstrapServiceRegistry to be automatically closed when the
 		// StandardServiceRegistry is closed.
 		bsrb.enableAutoClose();
 		configureBootstrapServiceRegistryBuilder( bsrb );
 
 		final BootstrapServiceRegistry bsr = bsrb.build();
 		afterBootstrapServiceRegistryBuilt( bsr );
 
 		final Map settings = new HashMap();
 		addSettings( settings );
 
 		final StandardServiceRegistryBuilder ssrb = new StandardServiceRegistryBuilder( bsr );
 		initialize( ssrb );
 		ssrb.applySettings( settings );
 		configureStandardServiceRegistryBuilder( ssrb );
 		return ssrb;
 	}
 
 	protected void addSettings(Map settings) {
 	}
 
 	/**
 	 * Apply any desired config to the BootstrapServiceRegistryBuilder to be incorporated
 	 * into the built BootstrapServiceRegistry
 	 *
 	 * @param bsrb The BootstrapServiceRegistryBuilder
 	 */
 	@SuppressWarnings({"SpellCheckingInspection", "UnusedParameters"})
 	protected void configureBootstrapServiceRegistryBuilder(BootstrapServiceRegistryBuilder bsrb) {
 	}
 
 	/**
 	 * Hook to allow tests to use the BootstrapServiceRegistry if they wish
 	 *
 	 * @param bsr The BootstrapServiceRegistry
 	 */
 	@SuppressWarnings("UnusedParameters")
 	protected void afterBootstrapServiceRegistryBuilt(BootstrapServiceRegistry bsr) {
 	}
 
 	@SuppressWarnings("SpellCheckingInspection")
 	private void initialize(StandardServiceRegistryBuilder ssrb) {
 		final Dialect dialect = BaseCoreFunctionalTestCase.getDialect();
 
 		ssrb.applySetting( AvailableSettings.CACHE_REGION_FACTORY, CachingRegionFactory.class.getName() );
 		ssrb.applySetting( AvailableSettings.USE_NEW_ID_GENERATOR_MAPPINGS, "true" );
 		if ( createSchema() ) {
 			ssrb.applySetting( AvailableSettings.HBM2DDL_AUTO, "create-drop" );
 			final String secondSchemaName = createSecondSchema();
 			if ( StringHelper.isNotEmpty( secondSchemaName ) ) {
 				if ( !H2Dialect.class.isInstance( dialect ) ) {
 					// while it may be true that only H2 supports creation of a second schema via
 					// URL (no idea whether that is accurate), every db should support creation of schemas
 					// via DDL which SchemaExport can create for us.  See how this is used and
 					// whether that usage could not just leverage that capability
 					throw new UnsupportedOperationException( "Only H2 dialect supports creation of second schema." );
 				}
 				Helper.createH2Schema( secondSchemaName, ssrb.getSettings() );
 			}
 		}
 		ssrb.applySetting( AvailableSettings.DIALECT, dialect.getClass().getName() );
 	}
 
 	protected boolean createSchema() {
 		return true;
 	}
 
 	protected String createSecondSchema() {
 		// poorly named, yes, but to keep migration easy for existing BaseCoreFunctionalTestCase
 		// impls I kept the same name from there
 		return null;
 	}
 
 	/**
 	 * Apply any desired config to the StandardServiceRegistryBuilder to be incorporated
 	 * into the built StandardServiceRegistry
 	 *
 	 * @param ssrb The StandardServiceRegistryBuilder
 	 */
 	@SuppressWarnings({"SpellCheckingInspection", "UnusedParameters"})
 	protected void configureStandardServiceRegistryBuilder(StandardServiceRegistryBuilder ssrb) {
 	}
 
 	/**
 	 * Hook to allow tests to use the StandardServiceRegistry if they wish
 	 *
 	 * @param ssr The StandardServiceRegistry
 	 */
 	@SuppressWarnings("UnusedParameters")
 	protected void afterStandardServiceRegistryBuilt(StandardServiceRegistry ssr) {
 	}
 
 	protected void applyMetadataSources(MetadataSources metadataSources) {
 		for ( String mapping : getMappings() ) {
 			metadataSources.addResource( getBaseForMappings() + mapping );
 		}
 
 		for ( Class annotatedClass : getAnnotatedClasses() ) {
 			metadataSources.addAnnotatedClass( annotatedClass );
 		}
 
 		for ( String annotatedPackage : getAnnotatedPackages() ) {
 			metadataSources.addPackage( annotatedPackage );
 		}
 
 		for ( String ormXmlFile : getXmlFiles() ) {
 			metadataSources.addInputStream( Thread.currentThread().getContextClassLoader().getResourceAsStream( ormXmlFile ) );
 		}
 	}
 
 	protected static final String[] NO_MAPPINGS = new String[0];
 
 	protected String[] getMappings() {
 		return NO_MAPPINGS;
 	}
 
 	protected String getBaseForMappings() {
 		return "org/hibernate/test/";
 	}
 
 	protected static final Class[] NO_CLASSES = new Class[0];
 
 	protected Class[] getAnnotatedClasses() {
 		return NO_CLASSES;
 	}
 
 	protected String[] getAnnotatedPackages() {
 		return NO_MAPPINGS;
 	}
 
 	protected String[] getXmlFiles() {
 		return NO_MAPPINGS;
 	}
 
 	protected void afterMetadataSourcesApplied(MetadataSources metadataSources) {
 	}
 
 	private void initialize(MetadataBuilder metadataBuilder) {
 		metadataBuilder.enableNewIdentifierGeneratorSupport( true );
 		metadataBuilder.applyImplicitNamingStrategy( ImplicitNamingStrategyLegacyJpaImpl.INSTANCE );
 	}
 
 	protected void configureMetadataBuilder(MetadataBuilder metadataBuilder) {
 	}
 
 	protected boolean overrideCacheStrategy() {
 		return true;
 	}
 
 	protected String getCacheConcurrencyStrategy() {
 		return null;
 	}
 
 	protected final void applyCacheSettings(Metadata metadata) {
 		if ( !overrideCacheStrategy() ) {
 			return;
 		}
 
 		if ( getCacheConcurrencyStrategy() == null ) {
 			return;
 		}
 
 		for ( PersistentClass entityBinding : metadata.getEntityBindings() ) {
 			if ( entityBinding.isInherited() ) {
 				continue;
 			}
 
 			boolean hasLob = false;
 
 			final Iterator props = entityBinding.getPropertyClosureIterator();
 			while ( props.hasNext() ) {
 				final Property prop = (Property) props.next();
 				if ( prop.getValue().isSimpleValue() ) {
 					if ( isLob( ( (SimpleValue) prop.getValue() ).getTypeName() ) ) {
 						hasLob = true;
 						break;
 					}
 				}
 			}
 
 			if ( !hasLob ) {
 				( ( RootClass) entityBinding ).setCacheConcurrencyStrategy( getCacheConcurrencyStrategy() );
 			}
 		}
 
 		for ( Collection collectionBinding : metadata.getCollectionBindings() ) {
 			boolean isLob = false;
 
 			if ( collectionBinding.getElement().isSimpleValue() ) {
 				isLob = isLob( ( (SimpleValue) collectionBinding.getElement() ).getTypeName() );
 			}
 
 			if ( !isLob ) {
 				collectionBinding.setCacheConcurrencyStrategy( getCacheConcurrencyStrategy() );
 			}
 		}
 	}
 
 	private boolean isLob(String typeName) {
 		return "blob".equals( typeName )
 				|| "clob".equals( typeName )
 				|| "nclob".equals( typeName )
 				|| Blob.class.getName().equals( typeName )
 				|| Clob.class.getName().equals( typeName )
 				|| NClob.class.getName().equals( typeName )
 				|| BlobType.class.getName().equals( typeName )
 				|| ClobType.class.getName().equals( typeName )
 				|| NClobType.class.getName().equals( typeName );
 	}
 
 	protected void afterMetadataBuilt(Metadata metadata) {
 	}
 
 	private void initialize(SessionFactoryBuilder sfb, Metadata metadata) {
 		// todo : this is where we need to apply cache settings to be like BaseCoreFunctionalTestCase
 		//		it reads the class/collection mappings and creates corresponding
 		//		CacheRegionDescription references.
 		//
 		//		Ultimately I want those to go on MetadataBuilder, and in fact MetadataBuilder
 		//		already defines the needed method.  But for the [pattern used by the
 		//		tests we need this as part of SessionFactoryBuilder
 	}
 
 	protected void configureSessionFactoryBuilder(SessionFactoryBuilder sfb) {
 	}
 
 	protected void afterSessionFactoryBuilt(SessionFactoryImplementor sessionFactory) {
 	}
 
 	@AfterClassOnce
 	@SuppressWarnings( {"UnusedDeclaration"})
 	protected void shutDown() {
 		releaseResources();
 	}
 
 	protected void releaseResources() {
 		if ( sessionFactory != null ) {
 			try {
 				sessionFactory.close();
 			}
 			catch (Exception e) {
 				System.err.println( "Unable to release SessionFactory : " + e.getMessage() );
 				e.printStackTrace();
 			}
 		}
 		sessionFactory = null;
 
 		if ( serviceRegistry != null ) {
 			try {
 				StandardServiceRegistryBuilder.destroy( serviceRegistry );
 			}
 			catch (Exception e) {
 				System.err.println( "Unable to release StandardServiceRegistry : " + e.getMessage() );
 				e.printStackTrace();
 			}
 		}
 		serviceRegistry=null;
 	}
 
 	@OnFailure
 	@OnExpectedFailure
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public void onFailure() {
 		if ( rebuildSessionFactoryOnError() ) {
 			rebuildSessionFactory();
 		}
 	}
 
 	protected boolean rebuildSessionFactoryOnError() {
 		return true;
 	}
 
 	@Before
 	public final void beforeTest() throws Exception {
 		prepareTest();
 	}
 
 	protected void prepareTest() throws Exception {
 	}
 
 	@After
 	public final void afterTest() throws Exception {
 		if ( isCleanupTestDataRequired() ) {
 			cleanupTestData();
 		}
 		cleanupTest();
 
 		cleanupSession();
 
 		assertAllDataRemoved();
 
 	}
 
-	protected boolean isCleanupTestDataRequired() { return false; }
+	protected boolean isCleanupTestDataRequired() {
+		return false;
+	}
 
 	protected void cleanupTestData() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "delete from java.lang.Object" ).executeUpdate();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 
 	private void cleanupSession() {
 		if ( session != null && ! ( (SessionImplementor) session ).isClosed() ) {
 			if ( session.isConnected() ) {
 				session.doWork( new RollbackWork() );
 			}
 			session.close();
 		}
 		session = null;
 	}
 
 	public class RollbackWork implements Work {
 		public void execute(Connection connection) throws SQLException {
 			connection.rollback();
 		}
 	}
 
 	protected void cleanupTest() throws Exception {
 	}
 
 	@SuppressWarnings( {"UnnecessaryBoxing", "UnnecessaryUnboxing"})
 	protected void assertAllDataRemoved() {
 		if ( !createSchema() ) {
 			return; // no tables were created...
 		}
 		if ( !Boolean.getBoolean( VALIDATE_DATA_CLEANUP ) ) {
 			return;
 		}
 
 		Session tmpSession = sessionFactory.openSession();
 		try {
 			List list = tmpSession.createQuery( "select o from java.lang.Object o" ).list();
 
 			Map<String,Integer> items = new HashMap<String,Integer>();
 			if ( !list.isEmpty() ) {
 				for ( Object element : list ) {
 					Integer l = items.get( tmpSession.getEntityName( element ) );
 					if ( l == null ) {
 						l = 0;
 					}
 					l = l + 1 ;
 					items.put( tmpSession.getEntityName( element ), l );
 					System.out.println( "Data left: " + element );
 				}
 				fail( "Data is left in the database: " + items.toString() );
 			}
 		}
 		finally {
 			try {
 				tmpSession.close();
 			}
 			catch( Throwable t ) {
 				// intentionally empty
 			}
 		}
 	}
 
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/CallbackException.java b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/CallbackException.java
index 24fad231d0..74a3789e5b 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/CallbackException.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/CallbackException.java
@@ -1,49 +1,49 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.junit4;
 
 import java.lang.reflect.Method;
 
 /**
  * Indicates an exception while performing a callback on the test
  *
  * @author Steve Ebersole
  */
 public class CallbackException extends RuntimeException {
-    public CallbackException(Method method) {
-        this( Helper.extractMethodName( method ) );
-    }
+	public CallbackException(Method method) {
+		this( Helper.extractMethodName( method ) );
+	}
 
-    public CallbackException(String message) {
-        super( message );
-    }
+	public CallbackException(String message) {
+		super( message );
+	}
 
-    public CallbackException(Method method, Throwable cause) {
+	public CallbackException(Method method, Throwable cause) {
 		this( Helper.extractMethodName( method ), cause );
 	}
 
-    public CallbackException(String message, Throwable cause) {
-        super(message, cause);
-    }
+	public CallbackException(String message, Throwable cause) {
+		super( message, cause );
+	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/CustomRunner.java b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/CustomRunner.java
index fb286422cc..67da131dff 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/CustomRunner.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/CustomRunner.java
@@ -1,356 +1,375 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.junit4;
 
 import java.lang.annotation.Annotation;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Comparator;
 import java.util.List;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 
 import org.hibernate.testing.DialectCheck;
 import org.hibernate.testing.FailureExpected;
 import org.hibernate.testing.RequiresDialect;
 import org.hibernate.testing.RequiresDialectFeature;
 import org.hibernate.testing.RequiresDialects;
 import org.hibernate.testing.Skip;
 import org.hibernate.testing.SkipForDialect;
 import org.hibernate.testing.SkipForDialects;
 import org.junit.BeforeClass;
 import org.junit.Ignore;
 import org.junit.Test;
 import org.junit.runner.manipulation.NoTestsRemainException;
 import org.junit.runner.notification.RunNotifier;
 import org.junit.runners.BlockJUnit4ClassRunner;
 import org.junit.runners.model.FrameworkMethod;
 import org.junit.runners.model.InitializationError;
 import org.junit.runners.model.Statement;
 
 import org.jboss.logging.Logger;
 
 /**
  * The Hibernate-specific {@link org.junit.runner.Runner} implementation which layers {@link ExtendedFrameworkMethod}
  * support on top of the standard JUnit {@link FrameworkMethod} for extra information after checking to make sure the
  * test should be run.
  *
  * @author Steve Ebersole
  */
 public class CustomRunner extends BlockJUnit4ClassRunner {
 	private static final Logger log = Logger.getLogger( CustomRunner.class );
 
 	private TestClassMetadata testClassMetadata;
 
 	public CustomRunner(Class<?> clazz) throws InitializationError, NoTestsRemainException {
 		super( clazz );
 	}
 
 	@Override
 	protected void collectInitializationErrors(List<Throwable> errors) {
 		super.collectInitializationErrors( errors );
 		this.testClassMetadata = new TestClassMetadata( getTestClass().getJavaClass() );
 		testClassMetadata.validate( errors );
 	}
 
 	public TestClassMetadata getTestClassMetadata() {
 		return testClassMetadata;
 	}
 
-    private Boolean isAllTestsIgnored;
-
-    private boolean isAllTestsIgnored() {
-        if ( isAllTestsIgnored == null ) {
-            if ( computeTestMethods().isEmpty() ) {
-                isAllTestsIgnored = true;
-            }
-            else {
-                isAllTestsIgnored = true;
-                for ( FrameworkMethod method : computeTestMethods() ) {
-                    Ignore ignore = method.getAnnotation( Ignore.class );
-                    if ( ignore == null ) {
-                        isAllTestsIgnored = false;
-                        break;
-                    }
-                }
-            }
-        }
-        return isAllTestsIgnored;
-    }
-
-    @Override
-    protected Statement withBeforeClasses(Statement statement) {
-        if ( isAllTestsIgnored() ) {
-            return super.withBeforeClasses( statement );
-        }
-        return new BeforeClassCallbackHandler(
-                this,
-                super.withBeforeClasses( statement )
-        );
-    }
+	private Boolean isAllTestsIgnored;
+
+	private boolean isAllTestsIgnored() {
+		if ( isAllTestsIgnored == null ) {
+			if ( computeTestMethods().isEmpty() ) {
+				isAllTestsIgnored = true;
+			}
+			else {
+				isAllTestsIgnored = true;
+				for ( FrameworkMethod method : computeTestMethods() ) {
+					Ignore ignore = method.getAnnotation( Ignore.class );
+					if ( ignore == null ) {
+						isAllTestsIgnored = false;
+						break;
+					}
+				}
+			}
+		}
+		return isAllTestsIgnored;
+	}
+
+	@Override
+	protected Statement withBeforeClasses(Statement statement) {
+		if ( isAllTestsIgnored() ) {
+			return super.withBeforeClasses( statement );
+		}
+		return new BeforeClassCallbackHandler(
+				this,
+				super.withBeforeClasses( statement )
+		);
+	}
 
 	@Override
 	protected Statement withAfterClasses(Statement statement) {
-        if ( isAllTestsIgnored() ) {
-            return super.withAfterClasses( statement );
-        }
+		if ( isAllTestsIgnored() ) {
+			return super.withAfterClasses( statement );
+		}
 		return new AfterClassCallbackHandler(
 				this,
 				super.withAfterClasses( statement )
 		);
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @see org.junit.runners.ParentRunner#classBlock(org.junit.runner.notification.RunNotifier)
 	 */
 	@Override
-	protected Statement classBlock( RunNotifier notifier ) {
+	protected Statement classBlock(RunNotifier notifier) {
 		log.info( BeforeClass.class.getSimpleName() + ": " + getName() );
 
 		return super.classBlock( notifier );
 	}
 
 	@Override
 	protected Statement methodBlock(FrameworkMethod method) {
 		log.info( Test.class.getSimpleName() + ": " + method.getName() );
 
 		final Statement originalMethodBlock = super.methodBlock( method );
 		final ExtendedFrameworkMethod extendedFrameworkMethod = (ExtendedFrameworkMethod) method;
-		return new FailureExpectedHandler( originalMethodBlock, testClassMetadata, extendedFrameworkMethod, testInstance );
+		return new FailureExpectedHandler(
+				originalMethodBlock,
+				testClassMetadata,
+				extendedFrameworkMethod,
+				testInstance
+		);
 	}
 
 	private Object testInstance;
 
 	protected Object getTestInstance() throws Exception {
 		if ( testInstance == null ) {
 			testInstance = super.createTest();
 		}
 		return testInstance;
 	}
 
 	@Override
 	protected Object createTest() throws Exception {
 		return getTestInstance();
 	}
 
 	private List<FrameworkMethod> computedTestMethods;
 
 	@Override
 	protected List<FrameworkMethod> computeTestMethods() {
 		if ( computedTestMethods == null ) {
 			computedTestMethods = doComputation();
-			sortMethods(computedTestMethods);
+			sortMethods( computedTestMethods );
 		}
 		return computedTestMethods;
 	}
 
 	protected void sortMethods(List<FrameworkMethod> computedTestMethods) {
 		if ( CollectionHelper.isEmpty( computedTestMethods ) ) {
 			return;
 		}
-		Collections.sort( computedTestMethods, new Comparator<FrameworkMethod>() {
-			@Override
-			public int compare(FrameworkMethod o1, FrameworkMethod o2) {
-				return o1.getName().compareTo( o2.getName() );
-			}
-		} );
+		Collections.sort(
+				computedTestMethods, new Comparator<FrameworkMethod>() {
+					@Override
+					public int compare(FrameworkMethod o1, FrameworkMethod o2) {
+						return o1.getName().compareTo( o2.getName() );
+					}
+				}
+		);
 	}
 
 	protected List<FrameworkMethod> doComputation() {
-        // Next, get all the test methods as understood by JUnit
-        final List<FrameworkMethod> methods = super.computeTestMethods();
+		// Next, get all the test methods as understood by JUnit
+		final List<FrameworkMethod> methods = super.computeTestMethods();
 
-        // Now process that full list of test methods and build our custom result
-        final List<FrameworkMethod> result = new ArrayList<FrameworkMethod>();
+		// Now process that full list of test methods and build our custom result
+		final List<FrameworkMethod> result = new ArrayList<FrameworkMethod>();
 		final boolean doValidation = Boolean.getBoolean( Helper.VALIDATE_FAILURE_EXPECTED );
 		int testCount = 0;
 
 		Ignore virtualIgnore;
 
 		for ( FrameworkMethod frameworkMethod : methods ) {
 			// potentially ignore based on expected failure
-            final FailureExpected failureExpected = Helper.locateAnnotation( FailureExpected.class, frameworkMethod, getTestClass() );
+			final FailureExpected failureExpected = Helper.locateAnnotation(
+					FailureExpected.class,
+					frameworkMethod,
+					getTestClass()
+			);
 			if ( failureExpected != null && !doValidation ) {
 				virtualIgnore = new IgnoreImpl( Helper.extractIgnoreMessage( failureExpected, frameworkMethod ) );
 			}
 			else {
 				virtualIgnore = convertSkipToIgnore( frameworkMethod );
 			}
 
 			testCount++;
 			log.trace( "adding test " + Helper.extractTestName( frameworkMethod ) + " [#" + testCount + "]" );
 			result.add( new ExtendedFrameworkMethod( frameworkMethod, virtualIgnore, failureExpected ) );
 		}
 		return result;
 	}
 
-	@SuppressWarnings( {"ClassExplicitlyAnnotation"})
+	@SuppressWarnings({"ClassExplicitlyAnnotation"})
 	public static class IgnoreImpl implements Ignore {
 		private final String value;
 
 		public IgnoreImpl(String value) {
 			this.value = value;
 		}
 
 		@Override
 		public String value() {
 			return value;
 		}
 
 		@Override
 		public Class<? extends Annotation> annotationType() {
 			return Ignore.class;
 		}
 	}
 
 	private static Dialect dialect = determineDialect();
 
 	private static Dialect determineDialect() {
 		try {
 			return Dialect.getDialect();
 		}
-		catch( Exception e ) {
+		catch (Exception e) {
 			return new Dialect() {
 			};
 		}
 	}
 
 	protected Ignore convertSkipToIgnore(FrameworkMethod frameworkMethod) {
 		// @Skip
 		Skip skip = Helper.locateAnnotation( Skip.class, frameworkMethod, getTestClass() );
 		if ( skip != null ) {
 			if ( isMatch( skip.condition() ) ) {
 				return buildIgnore( skip );
 			}
 		}
 
 		// @SkipForDialects & @SkipForDialect
 		for ( SkipForDialect skipForDialectAnn : Helper.collectAnnotations(
 				SkipForDialect.class, SkipForDialects.class, frameworkMethod, getTestClass()
 		) ) {
 			for ( Class<? extends Dialect> dialectClass : skipForDialectAnn.value() ) {
 				if ( skipForDialectAnn.strictMatching() ) {
 					if ( dialectClass.equals( dialect.getClass() ) ) {
 						return buildIgnore( skipForDialectAnn );
 					}
 				}
 				else {
 					if ( dialectClass.isInstance( dialect ) ) {
 						return buildIgnore( skipForDialectAnn );
 					}
 				}
 			}
 		}
 
 		// @RequiresDialects & @RequiresDialect
 		for ( RequiresDialect requiresDialectAnn : Helper.collectAnnotations(
 				RequiresDialect.class, RequiresDialects.class, frameworkMethod, getTestClass()
 		) ) {
 			boolean foundMatch = false;
 			for ( Class<? extends Dialect> dialectClass : requiresDialectAnn.value() ) {
 				foundMatch = requiresDialectAnn.strictMatching()
 						? dialectClass.equals( dialect.getClass() )
 						: dialectClass.isInstance( dialect );
 				if ( foundMatch ) {
 					break;
 				}
 			}
 			if ( !foundMatch ) {
 				return buildIgnore( requiresDialectAnn );
 			}
 		}
 
 		// @RequiresDialectFeature
-		RequiresDialectFeature requiresDialectFeatureAnn = Helper.locateAnnotation( RequiresDialectFeature.class, frameworkMethod, getTestClass() );
+		RequiresDialectFeature requiresDialectFeatureAnn = Helper.locateAnnotation(
+				RequiresDialectFeature.class,
+				frameworkMethod,
+				getTestClass()
+		);
 		if ( requiresDialectFeatureAnn != null ) {
 			try {
 				boolean foundMatch = false;
 				for ( Class<? extends DialectCheck> checkClass : requiresDialectFeatureAnn.value() ) {
 					foundMatch = checkClass.newInstance().isMatch( dialect );
 					if ( !foundMatch ) {
 						return buildIgnore( requiresDialectFeatureAnn );
 					}
 				}
 			}
 			catch (RuntimeException e) {
 				throw e;
 			}
 			catch (Exception e) {
 				throw new RuntimeException( "Unable to instantiate DialectCheck", e );
 			}
 		}
 
 		return null;
 	}
 
 	private Ignore buildIgnore(Skip skip) {
 		return new IgnoreImpl( "@Skip : " + skip.message() );
 	}
 
 	private Ignore buildIgnore(SkipForDialect skip) {
 		return buildIgnore( "@SkipForDialect match", skip.comment(), skip.jiraKey() );
 	}
 
 	private Ignore buildIgnore(String reason, String comment, String jiraKey) {
 		StringBuilder buffer = new StringBuilder( reason );
 		if ( StringHelper.isNotEmpty( comment ) ) {
 			buffer.append( "; " ).append( comment );
 		}
 
 		if ( StringHelper.isNotEmpty( jiraKey ) ) {
 			buffer.append( " (" ).append( jiraKey ).append( ')' );
 		}
 
 		return new IgnoreImpl( buffer.toString() );
 	}
 
 	private Ignore buildIgnore(RequiresDialect requiresDialect) {
 		return buildIgnore( "@RequiresDialect non-match", requiresDialect.comment(), requiresDialect.jiraKey() );
 	}
 
 	private Ignore buildIgnore(RequiresDialectFeature requiresDialectFeature) {
-		return buildIgnore( "@RequiresDialectFeature non-match", requiresDialectFeature.comment(), requiresDialectFeature.jiraKey() );
+		return buildIgnore(
+				"@RequiresDialectFeature non-match",
+				requiresDialectFeature.comment(),
+				requiresDialectFeature.jiraKey()
+		);
 	}
 
 	private boolean isMatch(Class<? extends Skip.Matcher> condition) {
 		try {
 			Skip.Matcher matcher = condition.newInstance();
 			return matcher.isMatch();
 		}
 		catch (Exception e) {
 			throw new MatcherInstantiationException( condition, e );
 		}
 	}
 
 	private static class MatcherInstantiationException extends RuntimeException {
 		private MatcherInstantiationException(Class<? extends Skip.Matcher> matcherClass, Throwable cause) {
 			super( "Unable to instantiate specified Matcher [" + matcherClass.getName(), cause );
 		}
 	}
 
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/Helper.java b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/Helper.java
index c9cfb6bb66..d3bdc2b305 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/Helper.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/Helper.java
@@ -1,162 +1,165 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.junit4;
 
 import java.lang.annotation.Annotation;
 import java.lang.reflect.Method;
 import java.util.Arrays;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 
 import org.hibernate.testing.FailureExpected;
-import org.hibernate.testing.SkipForDialect;
-import org.hibernate.testing.SkipForDialects;
 import org.junit.runners.model.FrameworkMethod;
 import org.junit.runners.model.TestClass;
 
 /**
  * Centralized utility functionality
  *
  * @author Steve Ebersole
  */
 public final class Helper {
 	public static final String VALIDATE_FAILURE_EXPECTED = "hibernate.test.validatefailureexpected";
 
 	private Helper() {
 	}
 
 	/**
 	 * Standard string content checking.
 	 *
 	 * @param string The string to check
+	 *
 	 * @return Are its content empty or the reference null?
 	 */
 	public static boolean isNotEmpty(String string) {
 		return string != null && string.length() > 0;
 	}
 
 	/**
 	 * Extract a nice test name representation for display
 	 *
 	 * @param frameworkMethod The test method.
+	 *
 	 * @return The display representation
 	 */
 	public static String extractTestName(FrameworkMethod frameworkMethod) {
 		return frameworkMethod.getMethod().getDeclaringClass().getName() + '#' + frameworkMethod.getName();
 	}
 
 	/**
 	 * Extract a nice method name representation for display
 	 *
 	 * @param method The method.
+	 *
 	 * @return The display representation
 	 */
 	public static String extractMethodName(Method method) {
 		return method.getDeclaringClass().getName() + "#" + method.getName();
 	}
 
 	public static <T extends Annotation> T locateAnnotation(
 			Class<T> annotationClass,
 			FrameworkMethod frameworkMethod,
 			TestClass testClass) {
 		T annotation = frameworkMethod.getAnnotation( annotationClass );
 		if ( annotation == null ) {
 			annotation = testClass.getJavaClass().getAnnotation( annotationClass );
 		}
 		return annotation;
 	}
 
 	/**
-	 * @param singularAnnotationClass Singular annotation class (e.g. {@link SkipForDialect}).
-	 * @param pluralAnnotationClass Plural annotation class (e.g. {@link SkipForDialects}). Assuming that the only
-	 * 								declared method is an array of singular annotations.
+	 * @param singularAnnotationClass Singular annotation class (e.g. {@link org.hibernate.testing.SkipForDialect}).
+	 * @param pluralAnnotationClass Plural annotation class (e.g. {@link org.hibernate.testing.SkipForDialects}),
+	 * assuming that the only declared method is an array of singular annotations.
 	 * @param frameworkMethod Test method.
 	 * @param testClass Test class.
 	 * @param <S> Singular annotation type.
 	 * @param <P> Plural annotation type.
+	 *
 	 * @return Collection of all singular annotations or an empty list.
 	 */
 	@SuppressWarnings("unchecked")
-	public static <S extends Annotation, P extends Annotation> List<S> collectAnnotations(Class<S> singularAnnotationClass,
-																						  Class<P> pluralAnnotationClass,
-																						  FrameworkMethod frameworkMethod,
-																						  TestClass testClass) {
+	public static <S extends Annotation, P extends Annotation> List<S> collectAnnotations(
+			Class<S> singularAnnotationClass,
+			Class<P> pluralAnnotationClass,
+			FrameworkMethod frameworkMethod,
+			TestClass testClass) {
 		final List<S> collection = new LinkedList<S>();
 		final S singularAnn = Helper.locateAnnotation( singularAnnotationClass, frameworkMethod, testClass );
 		if ( singularAnn != null ) {
 			collection.add( singularAnn );
 		}
 		final P pluralAnn = Helper.locateAnnotation( pluralAnnotationClass, frameworkMethod, testClass );
 		if ( pluralAnn != null ) {
 			try {
-				collection.addAll( Arrays.asList( (S[]) pluralAnnotationClass.getDeclaredMethods()[0].invoke(pluralAnn) ) );
+				collection.addAll( Arrays.asList( (S[]) pluralAnnotationClass.getDeclaredMethods()[0].invoke( pluralAnn ) ) );
 			}
-			catch ( Exception e ) {
+			catch (Exception e) {
 				throw new RuntimeException( e );
 			}
 		}
 		return collection;
 	}
 
 	public static String extractMessage(FailureExpected failureExpected) {
 		StringBuilder buffer = new StringBuilder();
 		buffer.append( '(' ).append( failureExpected.jiraKey() ).append( ')' );
 		if ( isNotEmpty( failureExpected.message() ) ) {
 			buffer.append( " : " ).append( failureExpected.message() );
 		}
 		return buffer.toString();
 	}
 
 	public static String extractIgnoreMessage(FailureExpected failureExpected, FrameworkMethod frameworkMethod) {
 		return new StringBuilder( "Ignoring test [" )
 				.append( Helper.extractTestName( frameworkMethod ) )
 				.append( "] due to @FailureExpected - " )
 				.append( extractMessage( failureExpected ) )
 				.toString();
 	}
 
 	/**
 	 * @see #createH2Schema(String, Map)
 	 */
 	public static void createH2Schema(String schemaName, Configuration cfg) {
 		createH2Schema( schemaName, cfg.getProperties() );
 	}
 
 	/**
 	 * Create additional H2 schema.
 	 *
 	 * @param schemaName New schema name.
 	 * @param settings Current settings.
 	 */
 	public static void createH2Schema(String schemaName, Map settings) {
 		settings.put(
 				Environment.URL,
 				settings.get( Environment.URL ) + ";INIT=CREATE SCHEMA IF NOT EXISTS " + schemaName
 		);
 	}
 }
diff --git a/shared/config/checkstyle/checkstyle.xml b/shared/config/checkstyle/checkstyle.xml
index 5dd38fad5d..694d7794d2 100644
--- a/shared/config/checkstyle/checkstyle.xml
+++ b/shared/config/checkstyle/checkstyle.xml
@@ -1,231 +1,253 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <!--
   ~ Hibernate, Relational Persistence for Idiomatic Java
   ~
   ~ Copyright (c) 2013, Red Hat Inc. or third-party contributors as
   ~ indicated by the @author tags or express copyright attribution
   ~ statements applied by the authors.  All third-party contributions are
   ~ distributed under license by Red Hat Inc.
   ~
   ~ This copyrighted material is made available to anyone wishing to use, modify,
   ~ copy, or redistribute it subject to the terms and conditions of the GNU
   ~ Lesser General Public License, as published by the Free Software Foundation.
   ~
   ~ This program is distributed in the hope that it will be useful,
   ~ but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
   ~ or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
   ~ for more details.
   ~
   ~ You should have received a copy of the GNU Lesser General Public License
   ~ along with this distribution; if not, write to:
   ~ Free Software Foundation, Inc.
   ~ 51 Franklin Street, Fifth Floor
   ~ Boston, MA  02110-1301  USA
   -->
 <!DOCTYPE module PUBLIC "-//Puppy Crawl//DTD Check Configuration 1.1//EN" "http://www.puppycrawl.com/dtds/configuration_1_2.dtd">
 <module name="Checker">
 
-    <module name="SuppressionCommentFilter">
-        <property name="offCommentFormat" value="CHECKSTYLE:START_ALLOW_FINALIZER"/>
-        <property name="onCommentFormat" value="CHECKSTYLE:END_ALLOW_FINALIZER"/>
-        <property name="checkFormat" value="NoFinalizer"/>
-    </module>
-
     <!-- See http://checkstyle.sourceforge.net/checks.html for details of the various checks -->
 
     <module name="TreeWalker">
 
         <module name="FileContentsHolder"/>
 
         <!--
             High-priority warnings : fail the build...
         -->
         <module name="RegexpSinglelineJava">
             <property name="ignoreComments" value="true" />
             <property name="format" value="^\t* +\t*\S" />
             <property name="message" value="Line has leading space characters; indentation should be performed with tabs only." />
         </module>
 
         <module name="MissingDeprecated" />
 
         <module name="MissingOverride" />
 
         <module name="PackageAnnotation" />
 
         <module name="NeedBraces" />
 
         <module name="LeftCurly">
             <property name="option" value="eol" />
         </module>
 
         <module name="RightCurly">
             <property name="option" value="alone" />
         </module>
 
         <module name="EqualsHashCode" />
 
         <module name="StringLiteralEquality" />
 
         <module name="NoFinalizer" />
 
         <module name="OneStatementPerLine" />
 
-        <module name="AvoidStarImport" />
-
-        <module name="RedundantImport" />
-
-        <module name="UnusedImports" />
-
         <module name="UpperEll" />
 
+        <module name="IllegalImport">
+            <property name="illegalPkgs" value="java.awt, sun, org.slf4j"/>
+        </module>
 
 
         <!--
             Medium and low priority warnings : do not fail build
         -->
 
+        <module name="AvoidStarImport">
+            <property name="severity" value="warning" />
+        </module>
+
+        <module name="RedundantImport">
+            <property name="severity" value="warning" />
+        </module>
+
+        <module name="UnusedImports">
+            <property name="severity" value="warning" />
+        </module>
+
         <module name="AvoidNestedBlocks">
             <property name="allowInSwitchCase" value="true" />
             <property name="severity" value="warning" />
         </module>
 
         <module name="HideUtilityClassConstructor">
             <property name="severity" value="warning" />
         </module>
 
         <module name="MutableException">
             <property name="severity" value="warning" />
         </module>
 
         <module name="EmptyStatement">
             <property name="severity" value="warning" />
         </module>
 
         <module name="MissingSwitchDefault">
             <property name="severity" value="warning" />
         </module>
 
         <module name="DefaultComesLast">
             <property name="severity" value="warning" />
         </module>
 
         <module name="ModifiedControlVariable">
             <property name="severity" value="warning" />
         </module>
 
         <module name="SimplifyBooleanExpression">
             <property name="severity" value="warning" />
         </module>
 
         <module name="SimplifyBooleanReturn">
             <property name="severity" value="warning" />
         </module>
 
         <module name="ExplicitInitialization">
             <property name="severity" value="warning" />
         </module>
 
         <module name="FallThrough">
             <property name="severity" value="warning" />
         </module>
 
         <module name="ArrayTypeStyle">
             <property name="severity" value="warning" />
         </module>
 
         <module name="TrailingComment">
             <property name="severity" value="warning" />
         </module>
 
         <module name="ModifierOrder">
             <property name="severity" value="warning" />
         </module>
 
         <module name="AbstractClassName">
             <!-- we are just using this to make sure that classes matching the pattern (Abstract*) have the abstract modifier -->
             <property name="format" value="^Abstract.*$" />
             <property name="ignoreName" value="true" />
             <property name="severity" value="warning" />
         </module>
 
         <module name="ClassTypeParameterName">
             <property name="format" value="^[A-Z][A-Z0-9]*$" />
             <property name="severity" value="warning" />
         </module>
 
         <module name="ConstantName">
             <property name="format" value="^[A-Z](_?[A-Z0-9]+)*$|log" />
             <property name="severity" value="warning" />
         </module>
 
         <module name="LocalFinalVariableName">
             <property name="severity" value="warning" />
         </module>
 
         <module name="LocalVariableName">
             <property name="severity" value="warning" />
         </module>
 
         <module name="MemberName">
             <property name="severity" value="warning" />
         </module>
 
         <module name="MethodTypeParameterName">
             <property name="format" value="^[A-Z][A-Z0-9]*$" />
             <property name="severity" value="warning" />
         </module>
 
         <module name="PackageName">
             <property name="severity" value="warning" />
         </module>
 
         <module name="ParameterName">
             <property name="severity" value="warning" />
         </module>
 
         <module name="StaticVariableName">
             <property name="severity" value="warning" />
         </module>
 
         <module name="TypeName">
             <property name="severity" value="warning" />
         </module>
 
         <module name="AbbreviationAsWordInName">
             <property name="severity" value="warning" />
         </module>
 
         <module name="MethodParamPad">
             <property name="severity" value="warning" />
         </module>
 
         <module name="TypecastParenPad">
             <property name="severity" value="warning" />
         </module>
 
         <module name="ParenPad">
             <property name="tokens" value="CTOR_CALL, METHOD_CALL, SUPER_CTOR_CALL" />
             <property name="option" value="space" />
             <property name="severity" value="warning" />
         </module>
 
     </module>
 
     <module name="JavadocPackage">
         <property name="allowLegacy" value="true" />
         <property name="severity" value="warning" />
     </module>
 
     <module name="NewlineAtEndOfFile" />
 
     <!--
         Used to collect "todo" comments into a single location
     -->
     <module name="TreeWalker">
         <module name="TodoComment">
             <property name="format" value="[Tt][Oo][Dd][Oo]"/>
             <property name="severity" value="info" />
         </module>
     </module>
 
+
+    <!--
+        Source code comment-based suppressions
+    -->
+    <module name="SuppressionCommentFilter">
+        <!--
+            Allow a finalize() method within these comments.  DriverManagerConnectionProviderImpl e.g.
+            uses a finalizer to make sure we release all of its cached connections.
+        -->
+        <property name="offCommentFormat" value="CHECKSTYLE:START_ALLOW_FINALIZER"/>
+        <property name="onCommentFormat" value="CHECKSTYLE:END_ALLOW_FINALIZER"/>
+        <property name="checkFormat" value="NoFinalizer"/>
+    </module>
+
+    <module name="SuppressWithNearbyCommentFilter">
+        <property name="commentFormat" value="noinspection StatementWithEmptyBody"/>
+        <property name="checkFormat" value="EmptyStatement"/>
+        <property name="influenceFormat" value="1"/>
+    </module>
 </module>
diff --git a/tooling/metamodel-generator/src/main/java/org/hibernate/jpamodelgen/xml/JpaDescriptorParser.java b/tooling/metamodel-generator/src/main/java/org/hibernate/jpamodelgen/xml/JpaDescriptorParser.java
index bb9a99999e..666e96d4ab 100644
--- a/tooling/metamodel-generator/src/main/java/org/hibernate/jpamodelgen/xml/JpaDescriptorParser.java
+++ b/tooling/metamodel-generator/src/main/java/org/hibernate/jpamodelgen/xml/JpaDescriptorParser.java
@@ -1,480 +1,486 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat, Inc. and/or its affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat, Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpamodelgen.xml;
 
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.FileOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutput;
 import java.io.ObjectOutputStream;
 import java.net.URISyntaxException;
 import java.net.URL;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.List;
 import javax.lang.model.element.TypeElement;
 import javax.lang.model.util.Elements;
 import javax.tools.Diagnostic;
 import javax.xml.validation.Schema;
 
 import org.hibernate.jpamodelgen.Context;
 import org.hibernate.jpamodelgen.util.AccessType;
 import org.hibernate.jpamodelgen.util.AccessTypeInformation;
 import org.hibernate.jpamodelgen.util.FileTimeStampChecker;
 import org.hibernate.jpamodelgen.util.StringUtil;
 import org.hibernate.jpamodelgen.util.TypeUtils;
 import org.hibernate.jpamodelgen.util.xml.XmlParserHelper;
 import org.hibernate.jpamodelgen.util.xml.XmlParsingException;
 import org.hibernate.jpamodelgen.xml.jaxb.Entity;
 import org.hibernate.jpamodelgen.xml.jaxb.EntityMappings;
 import org.hibernate.jpamodelgen.xml.jaxb.Persistence;
 import org.hibernate.jpamodelgen.xml.jaxb.PersistenceUnitDefaults;
 import org.hibernate.jpamodelgen.xml.jaxb.PersistenceUnitMetadata;
 
 /**
  * Parser for JPA XML descriptors (persistence.xml and referenced mapping files).
  *
  * @author Hardy Ferentschik
  */
 public class JpaDescriptorParser {
 	private static final String DEFAULT_ORM_XML_LOCATION = "/META-INF/orm.xml";
 	private static final String SERIALIZATION_FILE_NAME = "Hibernate-Static-Metamodel-Generator.tmp";
 
 	private static final String PERSISTENCE_SCHEMA = "persistence_2_1.xsd";
 	private static final String ORM_SCHEMA = "orm_2_1.xsd";
 
 	private final Context context;
 	private final List<EntityMappings> entityMappings;
 	private final XmlParserHelper xmlParserHelper;
 
 	public JpaDescriptorParser(Context context) {
 		this.context = context;
 		this.entityMappings = new ArrayList<EntityMappings>();
 		this.xmlParserHelper = new XmlParserHelper( context );
 	}
 
 	public void parseXml() {
 		Collection<String> mappingFileNames = determineMappingFileNames();
 
 		if ( context.doLazyXmlParsing() && mappingFilesUnchanged( mappingFileNames ) ) {
 			return;
 		}
 
 		loadEntityMappings( mappingFileNames );
 		determineDefaultAccessTypeAndMetaCompleteness();
 		determineXmlAccessTypes();
 		if ( !context.isFullyXmlConfigured() ) {
 			// need to take annotations into consideration, since they can override xml settings
 			// we have to at least determine whether any of the xml configured entities is influenced by annotations
 			determineAnnotationAccessTypes();
 		}
 
 		for ( EntityMappings mappings : entityMappings ) {
 			String defaultPackageName = mappings.getPackage();
 			parseEntities( mappings.getEntity(), defaultPackageName );
 			parseEmbeddable( mappings.getEmbeddable(), defaultPackageName );
 			parseMappedSuperClass( mappings.getMappedSuperclass(), defaultPackageName );
 		}
 	}
 
 	private Collection<String> determineMappingFileNames() {
 		Collection<String> mappingFileNames = new ArrayList<String>();
 
 		Persistence persistence = getPersistence();
 		if ( persistence != null ) {
 			// get mapping file names from persistence.xml
 			List<Persistence.PersistenceUnit> persistenceUnits = persistence.getPersistenceUnit();
 			for ( Persistence.PersistenceUnit unit : persistenceUnits ) {
 				mappingFileNames.addAll( unit.getMappingFile() );
 			}
 		}
 
 		// /META-INF/orm.xml is implicit
 		mappingFileNames.add( DEFAULT_ORM_XML_LOCATION );
 
 		// not really part of the official spec, but the processor allows to specify mapping files directly as
 		// command line options
 		mappingFileNames.addAll( context.getOrmXmlFiles() );
 		return mappingFileNames;
 	}
 
 	private Persistence getPersistence() {
 		Persistence persistence = null;
 		String persistenceXmlLocation = context.getPersistenceXmlLocation();
 		InputStream stream = xmlParserHelper.getInputStreamForResource( persistenceXmlLocation );
 		if ( stream == null ) {
 			return null;
 		}
 
 		try {
 			Schema schema = xmlParserHelper.getSchema( PERSISTENCE_SCHEMA );
 			persistence = xmlParserHelper.getJaxbRoot( stream, Persistence.class, schema );
 		}
-		catch ( XmlParsingException e ) {
+		catch (XmlParsingException e) {
 			context.logMessage(
 					Diagnostic.Kind.WARNING, "Unable to parse persistence.xml: " + e.getMessage()
 			);
 		}
 
-        try {
-            stream.close();
-        } catch (IOException e) {
-            // eat it
-        }
+		try {
+			stream.close();
+		}
+		catch (IOException e) {
+			// eat it
+		}
 
 		return persistence;
 	}
 
 	private void loadEntityMappings(Collection<String> mappingFileNames) {
 		for ( String mappingFile : mappingFileNames ) {
 			InputStream stream = xmlParserHelper.getInputStreamForResource( mappingFile );
 			if ( stream == null ) {
 				continue;
 			}
 			EntityMappings mapping = null;
 			try {
 				Schema schema = xmlParserHelper.getSchema( ORM_SCHEMA );
 				mapping = xmlParserHelper.getJaxbRoot( stream, EntityMappings.class, schema );
 			}
-			catch ( XmlParsingException e ) {
+			catch (XmlParsingException e) {
 				context.logMessage(
 						Diagnostic.Kind.WARNING, "Unable to parse " + mappingFile + ": " + e.getMessage()
 				);
 			}
 			if ( mapping != null ) {
 				entityMappings.add( mapping );
 			}
 
-            try {
-                stream.close();
-            } catch (IOException e) {
-                // eat it
-            }
+			try {
+				stream.close();
+			}
+			catch (IOException e) {
+				// eat it
+			}
 		}
 	}
 
 	private boolean mappingFilesUnchanged(Collection<String> mappingFileNames) {
 		boolean mappingFilesUnchanged = false;
 		FileTimeStampChecker fileStampCheck = new FileTimeStampChecker();
 		for ( String mappingFile : mappingFileNames ) {
 			try {
 				URL url = this.getClass().getResource( mappingFile );
 				if ( url == null ) {
 					continue;
 				}
 				File file = new File( url.toURI() );
 				context.logMessage( Diagnostic.Kind.OTHER, "Check file  " + mappingFile );
 				if ( file.exists() ) {
 					fileStampCheck.add( mappingFile, file.lastModified() );
 				}
 			}
-			catch ( URISyntaxException e ) {
+			catch (URISyntaxException e) {
 				// in doubt return false
 				return false;
 			}
 		}
 
 		FileTimeStampChecker serializedTimeStampCheck = loadTimeStampCache();
 		if ( serializedTimeStampCheck.equals( fileStampCheck ) ) {
 			context.logMessage( Diagnostic.Kind.OTHER, "XML parsing will be skipped due to unchanged xml files" );
 			mappingFilesUnchanged = true;
 		}
 		else {
 			saveTimeStampCache( fileStampCheck );
 		}
 
 		return mappingFilesUnchanged;
 	}
 
 	private void saveTimeStampCache(FileTimeStampChecker fileStampCheck) {
 		try {
 			File file = getSerializationTmpFile();
 			ObjectOutput out = new ObjectOutputStream( new FileOutputStream( file ) );
 			out.writeObject( fileStampCheck );
 			out.close();
 			context.logMessage(
 					Diagnostic.Kind.OTHER, "Serialized " + fileStampCheck + " into " + file.getAbsolutePath()
 			);
 		}
-		catch ( IOException e ) {
+		catch (IOException e) {
 			// ignore - if the serialization failed we just have to keep parsing the xml
 			context.logMessage( Diagnostic.Kind.OTHER, "Error serializing  " + fileStampCheck );
 		}
 	}
 
 	private File getSerializationTmpFile() {
 		File tmpDir = new File( System.getProperty( "java.io.tmpdir" ) );
 		return new File( tmpDir, SERIALIZATION_FILE_NAME );
 	}
 
 	private FileTimeStampChecker loadTimeStampCache() {
 		FileTimeStampChecker serializedTimeStampCheck = new FileTimeStampChecker();
 		File file = null;
 		try {
 			file = getSerializationTmpFile();
 			if ( file.exists() ) {
 				ObjectInputStream in = new ObjectInputStream( new FileInputStream( file ) );
 				serializedTimeStampCheck = (FileTimeStampChecker) in.readObject();
 				in.close();
 			}
 		}
-		catch ( Exception e ) {
+		catch (Exception e) {
 			// ignore - if the de-serialization failed we just have to keep parsing the xml
 			context.logMessage( Diagnostic.Kind.OTHER, "Error de-serializing  " + file );
 		}
 		return serializedTimeStampCheck;
 	}
 
 	private void parseEntities(Collection<Entity> entities, String defaultPackageName) {
 		for ( Entity entity : entities ) {
 			String fqcn = StringUtil.determineFullyQualifiedClassName( defaultPackageName, entity.getClazz() );
 
 			if ( !xmlMappedTypeExists( fqcn ) ) {
 				context.logMessage(
 						Diagnostic.Kind.WARNING,
 						fqcn + " is mapped in xml, but class does not exist. Skipping meta model generation."
 				);
 				continue;
 			}
 
 			XmlMetaEntity metaEntity = new XmlMetaEntity(
 					entity, defaultPackageName, getXmlMappedType( fqcn ), context
 			);
 			if ( context.containsMetaEntity( fqcn ) ) {
 				context.logMessage(
 						Diagnostic.Kind.WARNING,
 						fqcn + " was already processed once. Skipping second occurrence."
 				);
 			}
 			context.addMetaEntity( fqcn, metaEntity );
 		}
 	}
 
-	private void parseEmbeddable(Collection<org.hibernate.jpamodelgen.xml.jaxb.Embeddable> embeddables, String defaultPackageName) {
+	private void parseEmbeddable(
+			Collection<org.hibernate.jpamodelgen.xml.jaxb.Embeddable> embeddables,
+			String defaultPackageName) {
 		for ( org.hibernate.jpamodelgen.xml.jaxb.Embeddable embeddable : embeddables ) {
 			String fqcn = StringUtil.determineFullyQualifiedClassName( defaultPackageName, embeddable.getClazz() );
 			// we have to extract the package name from the fqcn. Maybe the entity was setting a fqcn directly
 			String pkg = StringUtil.packageNameFromFqcn( fqcn );
 
 			if ( !xmlMappedTypeExists( fqcn ) ) {
 				context.logMessage(
 						Diagnostic.Kind.WARNING,
 						fqcn + " is mapped in xml, but class does not exist. Skipping meta model generation."
 				);
 				continue;
 			}
 
 			XmlMetaEntity metaEntity = new XmlMetaEntity( embeddable, pkg, getXmlMappedType( fqcn ), context );
 			if ( context.containsMetaEmbeddable( fqcn ) ) {
 				context.logMessage(
 						Diagnostic.Kind.WARNING,
 						fqcn + " was already processed once. Skipping second occurrence."
 				);
 			}
 			context.addMetaEmbeddable( fqcn, metaEntity );
 		}
 	}
 
-	private void parseMappedSuperClass(Collection<org.hibernate.jpamodelgen.xml.jaxb.MappedSuperclass> mappedSuperClasses, String defaultPackageName) {
+	private void parseMappedSuperClass(
+			Collection<org.hibernate.jpamodelgen.xml.jaxb.MappedSuperclass> mappedSuperClasses,
+			String defaultPackageName) {
 		for ( org.hibernate.jpamodelgen.xml.jaxb.MappedSuperclass mappedSuperClass : mappedSuperClasses ) {
 			String fqcn = StringUtil.determineFullyQualifiedClassName(
 					defaultPackageName, mappedSuperClass.getClazz()
 			);
 			// we have to extract the package name from the fqcn. Maybe the entity was setting a fqcn directly
 			String pkg = StringUtil.packageNameFromFqcn( fqcn );
 
 			if ( !xmlMappedTypeExists( fqcn ) ) {
 				context.logMessage(
 						Diagnostic.Kind.WARNING,
 						fqcn + " is mapped in xml, but class does not exist. Skipping meta model generation."
 				);
 				continue;
 			}
 
 			XmlMetaEntity metaEntity = new XmlMetaEntity(
 					mappedSuperClass, pkg, getXmlMappedType( fqcn ), context
 			);
 
 			if ( context.containsMetaEntity( fqcn ) ) {
 				context.logMessage(
 						Diagnostic.Kind.WARNING,
 						fqcn + " was already processed once. Skipping second occurrence."
 				);
 			}
 			context.addMetaEntity( fqcn, metaEntity );
 		}
 	}
 
 	private boolean xmlMappedTypeExists(String fullyQualifiedClassName) {
 		Elements utils = context.getElementUtils();
 		return utils.getTypeElement( fullyQualifiedClassName ) != null;
 	}
 
 	private TypeElement getXmlMappedType(String fullyQualifiedClassName) {
 		Elements utils = context.getElementUtils();
 		return utils.getTypeElement( fullyQualifiedClassName );
 	}
 
 	private AccessType determineEntityAccessType(EntityMappings mappings) {
 		AccessType accessType = context.getPersistenceUnitDefaultAccessType();
 		if ( mappings.getAccess() != null ) {
 			accessType = mapXmlAccessTypeToJpaAccessType( mappings.getAccess() );
 		}
 		return accessType;
 	}
 
 	private void determineXmlAccessTypes() {
 		for ( EntityMappings mappings : entityMappings ) {
 			String fqcn;
 			String packageName = mappings.getPackage();
 			AccessType defaultAccessType = determineEntityAccessType( mappings );
 
 			for ( Entity entity : mappings.getEntity() ) {
 				String name = entity.getClazz();
 				fqcn = StringUtil.determineFullyQualifiedClassName( packageName, name );
 				AccessType explicitAccessType = null;
 				org.hibernate.jpamodelgen.xml.jaxb.AccessType type = entity.getAccess();
 				if ( type != null ) {
 					explicitAccessType = mapXmlAccessTypeToJpaAccessType( type );
 				}
 				AccessTypeInformation accessInfo = new AccessTypeInformation(
 						fqcn, explicitAccessType, defaultAccessType
 				);
 				context.addAccessTypeInformation( fqcn, accessInfo );
 			}
 
 			for ( org.hibernate.jpamodelgen.xml.jaxb.MappedSuperclass mappedSuperClass : mappings.getMappedSuperclass() ) {
 				String name = mappedSuperClass.getClazz();
 				fqcn = StringUtil.determineFullyQualifiedClassName( packageName, name );
 				AccessType explicitAccessType = null;
 				org.hibernate.jpamodelgen.xml.jaxb.AccessType type = mappedSuperClass.getAccess();
 				if ( type != null ) {
 					explicitAccessType = mapXmlAccessTypeToJpaAccessType( type );
 				}
 				AccessTypeInformation accessInfo = new AccessTypeInformation(
 						fqcn, explicitAccessType, defaultAccessType
 				);
 				context.addAccessTypeInformation( fqcn, accessInfo );
 			}
 
 			for ( org.hibernate.jpamodelgen.xml.jaxb.Embeddable embeddable : mappings.getEmbeddable() ) {
 				String name = embeddable.getClazz();
 				fqcn = StringUtil.determineFullyQualifiedClassName( packageName, name );
 				AccessType explicitAccessType = null;
 				org.hibernate.jpamodelgen.xml.jaxb.AccessType type = embeddable.getAccess();
 				if ( type != null ) {
 					explicitAccessType = mapXmlAccessTypeToJpaAccessType( type );
 				}
 				AccessTypeInformation accessInfo = new AccessTypeInformation(
 						fqcn, explicitAccessType, defaultAccessType
 				);
 				context.addAccessTypeInformation( fqcn, accessInfo );
 			}
 		}
 	}
 
 	private void determineAnnotationAccessTypes() {
 		for ( EntityMappings mappings : entityMappings ) {
 			String fqcn;
 			String packageName = mappings.getPackage();
 
 			for ( Entity entity : mappings.getEntity() ) {
 				String name = entity.getClazz();
 				fqcn = StringUtil.determineFullyQualifiedClassName( packageName, name );
 				TypeElement element = context.getTypeElementForFullyQualifiedName( fqcn );
 				if ( element != null ) {
 					TypeUtils.determineAccessTypeForHierarchy( element, context );
 				}
 			}
 
 			for ( org.hibernate.jpamodelgen.xml.jaxb.MappedSuperclass mappedSuperClass : mappings.getMappedSuperclass() ) {
 				String name = mappedSuperClass.getClazz();
 				fqcn = StringUtil.determineFullyQualifiedClassName( packageName, name );
 				TypeElement element = context.getTypeElementForFullyQualifiedName( fqcn );
 				if ( element != null ) {
 					TypeUtils.determineAccessTypeForHierarchy( element, context );
 				}
 			}
 		}
 	}
 
 	/**
 	 * Determines the default access type as specified in the <i>persistence-unit-defaults</i> as well as whether the
 	 * xml configuration is complete and annotations should be ignored.
 	 * <p/>
 	 * Note, the spec says:
 	 * <ul>
 	 * <li>The persistence-unit-metadata element contains metadata for the entire persistence unit. It is
 	 * undefined if this element occurs in multiple mapping files within the same persistence unit.</li>
 	 * <li>If the xml-mapping-metadata-complete subelement is specified, the complete set of mapping
 	 * metadata for the persistence unit is contained in the XML mapping files for the persistence unit, and any
 	 * persistence annotations on the classes are ignored.</li>
 	 * <li>When the xml-mapping-metadata-complete element is specified, any metadata-complete attributes specified
 	 * within the entity, mapped-superclass, and embeddable elements are ignored.<li>
 	 * </ul>
 	 */
 	private void determineDefaultAccessTypeAndMetaCompleteness() {
 		for ( EntityMappings mappings : entityMappings ) {
 			PersistenceUnitMetadata meta = mappings.getPersistenceUnitMetadata();
 			if ( meta != null ) {
 				if ( meta.getXmlMappingMetadataComplete() != null ) {
 					context.mappingDocumentFullyXmlConfigured( true );
 				}
 				else {
 					context.mappingDocumentFullyXmlConfigured( false );
 				}
 
 				PersistenceUnitDefaults persistenceUnitDefaults = meta.getPersistenceUnitDefaults();
 				if ( persistenceUnitDefaults != null ) {
 					org.hibernate.jpamodelgen.xml.jaxb.AccessType xmlAccessType = persistenceUnitDefaults.getAccess();
 					if ( xmlAccessType != null ) {
 						context.setPersistenceUnitDefaultAccessType( mapXmlAccessTypeToJpaAccessType( xmlAccessType ) );
 					}
 				}
 			}
 			else {
 				context.mappingDocumentFullyXmlConfigured( false );
 			}
 		}
 	}
 
 	private AccessType mapXmlAccessTypeToJpaAccessType(org.hibernate.jpamodelgen.xml.jaxb.AccessType xmlAccessType) {
 		switch ( xmlAccessType ) {
 			case FIELD: {
 				return AccessType.FIELD;
 			}
 			case PROPERTY: {
 				return AccessType.PROPERTY;
 			}
 			default: {
 			}
 		}
 		return null;
 	}
 }
 
 
