diff --git a/hibernate-core/src/main/java/org/hibernate/Session.java b/hibernate-core/src/main/java/org/hibernate/Session.java
index 74a327666e..003c55764f 100644
--- a/hibernate-core/src/main/java/org/hibernate/Session.java
+++ b/hibernate-core/src/main/java/org/hibernate/Session.java
@@ -1,1075 +1,1075 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate;
 
 import java.io.Serializable;
 import java.sql.Connection;
 
 import org.hibernate.jdbc.Work;
 import org.hibernate.stat.SessionStatistics;
 
 /**
  * The main runtime interface between a Java application and Hibernate. This is the
  * central API class abstracting the notion of a persistence service.<br>
  * <br>
  * The lifecycle of a <tt>Session</tt> is bounded by the beginning and end of a logical
  * transaction. (Long transactions might span several database transactions.)<br>
  * <br>
  * The main function of the <tt>Session</tt> is to offer create, read and delete operations
  * for instances of mapped entity classes. Instances may exist in one of three states:<br>
  * <br>
  * <i>transient:</i> never persistent, not associated with any <tt>Session</tt><br>
  * <i>persistent:</i> associated with a unique <tt>Session</tt><br>
  * <i>detached:</i> previously persistent, not associated with any <tt>Session</tt><br>
  * <br>
  * Transient instances may be made persistent by calling <tt>save()</tt>,
  * <tt>persist()</tt> or <tt>saveOrUpdate()</tt>. Persistent instances may be made transient
  * by calling<tt> delete()</tt>. Any instance returned by a <tt>get()</tt> or
  * <tt>load()</tt> method is persistent. Detached instances may be made persistent
  * by calling <tt>update()</tt>, <tt>saveOrUpdate()</tt>, <tt>lock()</tt> or <tt>replicate()</tt>. 
  * The state of a transient or detached instance may also be made persistent as a new
  * persistent instance by calling <tt>merge()</tt>.<br>
  * <br>
  * <tt>save()</tt> and <tt>persist()</tt> result in an SQL <tt>INSERT</tt>, <tt>delete()</tt>
  * in an SQL <tt>DELETE</tt> and <tt>update()</tt> or <tt>merge()</tt> in an SQL <tt>UPDATE</tt>. 
  * Changes to <i>persistent</i> instances are detected at flush time and also result in an SQL
  * <tt>UPDATE</tt>. <tt>saveOrUpdate()</tt> and <tt>replicate()</tt> result in either an
  * <tt>INSERT</tt> or an <tt>UPDATE</tt>.<br>
  * <br>
  * It is not intended that implementors be threadsafe. Instead each thread/transaction
  * should obtain its own instance from a <tt>SessionFactory</tt>.<br>
  * <br>
  * A <tt>Session</tt> instance is serializable if its persistent classes are serializable.<br>
  * <br>
  * A typical transaction should use the following idiom:
  * <pre>
  * Session sess = factory.openSession();
  * Transaction tx;
  * try {
  *     tx = sess.beginTransaction();
  *     //do some work
  *     ...
  *     tx.commit();
  * }
  * catch (Exception e) {
  *     if (tx!=null) tx.rollback();
  *     throw e;
  * }
  * finally {
  *     sess.close();
  * }
  * </pre>
  * <br>
  * If the <tt>Session</tt> throws an exception, the transaction must be rolled back
  * and the session discarded. The internal state of the <tt>Session</tt> might not
  * be consistent with the database after the exception occurs.
  *
  * @see SessionFactory
  * @author Gavin King
  */
 public interface Session extends Serializable {
 
 	/**
 	 * Retrieve the entity mode in effect for this session.
 	 *
 	 * @return The entity mode for this session.
 	 */
 	public EntityMode getEntityMode();
 
 	/**
 	 * Starts a new Session with the given entity mode in effect. This secondary
 	 * Session inherits the connection, transaction, and other context
 	 * information from the primary Session. It doesn't need to be flushed
 	 * or closed by the developer.
 	 * 
 	 * @param entityMode The entity mode to use for the new session.
 	 * @return The new session
 	 */
 	public Session getSession(EntityMode entityMode);
 
 	/**
 	 * Force this session to flush. Must be called at the end of a
 	 * unit of work, before committing the transaction and closing the
 	 * session (depending on {@link #setFlushMode flush-mode},
 	 * {@link Transaction#commit()} calls this method).
 	 * <p/>
 	 * <i>Flushing</i> is the process of synchronizing the underlying persistent
 	 * store with persistable state held in memory.
 	 *
 	 * @throws HibernateException Indicates problems flushing the session or
 	 * talking to the database.
 	 */
 	public void flush() throws HibernateException;
 
 	/**
 	 * Set the flush mode for this session.
 	 * <p/>
 	 * The flush mode determines the points at which the session is flushed.
 	 * <i>Flushing</i> is the process of synchronizing the underlying persistent
 	 * store with persistable state held in memory.
 	 * <p/>
 	 * For a logically "read only" session, it is reasonable to set the session's
 	 * flush mode to {@link FlushMode#MANUAL} at the start of the session (in
 	 * order to achieve some extra performance).
 	 *
 	 * @param flushMode the new flush mode
 	 * @see FlushMode
 	 */
 	public void setFlushMode(FlushMode flushMode);
 
 	/**
 	 * Get the current flush mode for this session.
 	 *
 	 * @return The flush mode
 	 */
 	public FlushMode getFlushMode();
 
 	/**
 	 * Set the cache mode.
 	 * <p/>
 	 * Cache mode determines the manner in which this session can interact with
 	 * the second level cache.
 	 *
 	 * @param cacheMode The new cache mode.
 	 */
 	public void setCacheMode(CacheMode cacheMode);
 
 	/**
 	 * Get the current cache mode.
 	 *
 	 * @return The current cache mode.
 	 */
 	public CacheMode getCacheMode();
 
 	/**
 	 * Get the session factory which created this session.
 	 *
 	 * @return The session factory.
 	 * @see SessionFactory
 	 */
 	public SessionFactory getSessionFactory();
 
 	/**
 	 * Get the JDBC connection of this Session.<br>
 	 * <br>
 	 * If the session is using aggressive collection release (as in a
 	 * CMT environment), it is the application's responsibility to
 	 * close the connection returned by this call. Otherwise, the
 	 * application should not close the connection.
 	 *
 	 * @return the JDBC connection in use by the <tt>Session</tt>
 	 * @throws HibernateException if the <tt>Session</tt> is disconnected
 	 * @deprecated (scheduled for removal in 4.x).  Replacement depends on need; for doing direct JDBC stuff use
 	 * {@link #doWork}; for opening a 'temporary Session' use (TBD).
 	 */
 	public Connection connection() throws HibernateException;
 
 	/**
 	 * End the session by releasing the JDBC connection and cleaning up.  It is
 	 * not strictly necessary to close the session but you must at least
 	 * {@link #disconnect()} it.
 	 *
 	 * @return the connection provided by the application or null.
 	 * @throws HibernateException Indicates problems cleaning up.
 	 */
 	public Connection close() throws HibernateException;
 
 	/**
 	 * Cancel the execution of the current query.
 	 * <p/>
 	 * This is the sole method on session which may be safely called from
 	 * another thread.
 	 *
 	 * @throws HibernateException There was a problem canceling the query
 	 */
 	public void cancelQuery() throws HibernateException;
 
 	/**
 	 * Check if the session is still open.
 	 *
 	 * @return boolean
 	 */
 	public boolean isOpen();
 
 	/**
 	 * Check if the session is currently connected.
 	 *
 	 * @return boolean
 	 */
 	public boolean isConnected();
 
 	/**
 	 * Does this session contain any changes which must be synchronized with
 	 * the database?  In other words, would any DML operations be executed if
 	 * we flushed this session?
 	 *
 	 * @return True if the session contains pending changes; false otherwise.
 	 * @throws HibernateException could not perform dirtying checking
 	 */
 	public boolean isDirty() throws HibernateException;
 
 	/**
 	 * Will entities and proxies that are loaded into this session be made 
 	 * read-only by default?
 	 *
 	 * To determine the read-only/modifiable setting for a particular entity 
 	 * or proxy:
 	 * @see Session#isReadOnly(Object)
 	 *
 	 * @return true, loaded entities/proxies will be made read-only by default; 
 	 *         false, loaded entities/proxies will be made modifiable by default. 
 	 */
 	public boolean isDefaultReadOnly();
 
 	/**
 	 * Change the default for entities and proxies loaded into this session
 	 * from modifiable to read-only mode, or from modifiable to read-only mode.
 	 *
 	 * Read-only entities are not dirty-checked and snapshots of persistent
 	 * state are not maintained. Read-only entities can be modified, but
 	 * changes are not persisted.
 	 *
 	 * When a proxy is initialized, the loaded entity will have the same
 	 * read-only/modifiable setting as the uninitialized
 	 * proxy has, regardless of the session's current setting.
 	 *
 	 * To change the read-only/modifiable setting for a particular entity
 	 * or proxy that is already in this session:
 	 * @see Session#setReadOnly(Object,boolean)
 	 *
 	 * To override this session's read-only/modifiable setting for entities
 	 * and proxies loaded by a Query:
 	 * @see Query#setReadOnly(boolean)
 	 *
 	 * @param readOnly true, the default for loaded entities/proxies is read-only;
 	 *                 false, the default for loaded entities/proxies is modifiable
 	 */
 	public void setDefaultReadOnly(boolean readOnly);
 
 	/**
 	 * Return the identifier value of the given entity as associated with this
 	 * session.  An exception is thrown if the given entity instance is transient
 	 * or detached in relation to this session.
 	 *
 	 * @param object a persistent instance
 	 * @return the identifier
 	 * @throws TransientObjectException if the instance is transient or associated with
 	 * a different session
 	 */
 	public Serializable getIdentifier(Object object) throws HibernateException;
 
 	/**
 	 * Check if this instance is associated with this <tt>Session</tt>.
 	 *
 	 * @param object an instance of a persistent class
 	 * @return true if the given instance is associated with this <tt>Session</tt>
 	 */
 	public boolean contains(Object object);
 
 	/**
 	 * Remove this instance from the session cache. Changes to the instance will
 	 * not be synchronized with the database. This operation cascades to associated
 	 * instances if the association is mapped with <tt>cascade="evict"</tt>.
 	 *
 	 * @param object a persistent instance
 	 * @throws HibernateException
 	 */
 	public void evict(Object object) throws HibernateException;
 
 	/**
 	 * Return the persistent instance of the given entity class with the given identifier,
 	 * obtaining the specified lock mode, assuming the instance exists.
 	 *
 	 * @param theClass a persistent class
 	 * @param id a valid identifier of an existing persistent instance of the class
 	 * @param lockMode the lock level
 	 * @return the persistent instance or proxy
 	 * @throws HibernateException
 	 * @deprecated LockMode parameter should be replaced with LockOptions
 	 */
 	public Object load(Class theClass, Serializable id, LockMode lockMode) throws HibernateException;
 
 	/**
 	 * Return the persistent instance of the given entity class with the given identifier,
 	 * obtaining the specified lock mode, assuming the instance exists.
 	 *
 	 * @param theClass a persistent class
 	 * @param id a valid identifier of an existing persistent instance of the class
 	 * @param lockOptions contains the lock level
 	 * @return the persistent instance or proxy
 	 * @throws HibernateException
 	 */
 	public Object load(Class theClass, Serializable id, LockOptions lockOptions) throws HibernateException;
 
 	/**
 	 * Return the persistent instance of the given entity class with the given identifier,
 	 * obtaining the specified lock mode, assuming the instance exists.
 	 *
 	 * @param entityName a persistent class
 	 * @param id a valid identifier of an existing persistent instance of the class
 	 * @param lockMode the lock level
 	 * @return the persistent instance or proxy
 	 * @throws HibernateException
 	 * @deprecated LockMode parameter should be replaced with LockOptions
 	 */
 	public Object load(String entityName, Serializable id, LockMode lockMode) throws HibernateException;
 
 	/**
 	 * Return the persistent instance of the given entity class with the given identifier,
 	 * obtaining the specified lock mode, assuming the instance exists.
 	 *
 	 * @param entityName a persistent class
 	 * @param id a valid identifier of an existing persistent instance of the class
 	 * @param lockOptions contains the lock level
 	 * @return the persistent instance or proxy
 	 * @throws HibernateException
 	 */
 	public Object load(String entityName, Serializable id, LockOptions lockOptions) throws HibernateException;
 
 	/**
 	 * Return the persistent instance of the given entity class with the given identifier,
 	 * assuming that the instance exists. This method might return a proxied instance that
 	 * is initialized on-demand, when a non-identifier method is accessed.
 	 * <br><br>
 	 * You should not use this method to determine if an instance exists (use <tt>get()</tt>
 	 * instead). Use this only to retrieve an instance that you assume exists, where non-existence
 	 * would be an actual error.
 	 *
 	 * @param theClass a persistent class
 	 * @param id a valid identifier of an existing persistent instance of the class
 	 * @return the persistent instance or proxy
 	 * @throws HibernateException
 	 */
 	public Object load(Class theClass, Serializable id) throws HibernateException;
 
 	/**
 	 * Return the persistent instance of the given entity class with the given identifier,
 	 * assuming that the instance exists. This method might return a proxied instance that
 	 * is initialized on-demand, when a non-identifier method is accessed.
 	 * <br><br>
 	 * You should not use this method to determine if an instance exists (use <tt>get()</tt>
 	 * instead). Use this only to retrieve an instance that you assume exists, where non-existence
 	 * would be an actual error.
 	 *
 	 * @param entityName a persistent class
 	 * @param id a valid identifier of an existing persistent instance of the class
 	 * @return the persistent instance or proxy
 	 * @throws HibernateException
 	 */
 	public Object load(String entityName, Serializable id) throws HibernateException;
 
 	/**
 	 * Read the persistent state associated with the given identifier into the given transient
 	 * instance.
 	 *
 	 * @param object an "empty" instance of the persistent class
 	 * @param id a valid identifier of an existing persistent instance of the class
 	 * @throws HibernateException
 	 */
 	public void load(Object object, Serializable id) throws HibernateException;
 
 	/**
 	 * Persist the state of the given detached instance, reusing the current
 	 * identifier value.  This operation cascades to associated instances if
 	 * the association is mapped with <tt>cascade="replicate"</tt>.
 	 *
 	 * @param object a detached instance of a persistent class
 	 */
 	public void replicate(Object object, ReplicationMode replicationMode) throws HibernateException;
 
 	/**
 	 * Persist the state of the given detached instance, reusing the current
 	 * identifier value.  This operation cascades to associated instances if
 	 * the association is mapped with <tt>cascade="replicate"</tt>.
 	 *
 	 * @param object a detached instance of a persistent class
 	 */
 	public void replicate(String entityName, Object object, ReplicationMode replicationMode) throws HibernateException;
 
 	/**
 	 * Persist the given transient instance, first assigning a generated identifier. (Or
 	 * using the current value of the identifier property if the <tt>assigned</tt>
 	 * generator is used.) This operation cascades to associated instances if the
 	 * association is mapped with <tt>cascade="save-update"</tt>.
 	 *
 	 * @param object a transient instance of a persistent class
 	 * @return the generated identifier
 	 * @throws HibernateException
 	 */
 	public Serializable save(Object object) throws HibernateException;
 
 	/**
 	 * Persist the given transient instance, first assigning a generated identifier. (Or
 	 * using the current value of the identifier property if the <tt>assigned</tt>
 	 * generator is used.)  This operation cascades to associated instances if the
 	 * association is mapped with <tt>cascade="save-update"</tt>.
 	 *
 	 * @param object a transient instance of a persistent class
 	 * @return the generated identifier
 	 * @throws HibernateException
 	 */
 	public Serializable save(String entityName, Object object) throws HibernateException;
 
 	/**
 	 * Either {@link #save(Object)} or {@link #update(Object)} the given
 	 * instance, depending upon resolution of the unsaved-value checks (see the
 	 * manual for discussion of unsaved-value checking).
 	 * <p/>
 	 * This operation cascades to associated instances if the association is mapped
 	 * with <tt>cascade="save-update"</tt>.
 	 *
 	 * @see Session#save(java.lang.Object)
 	 * @see Session#update(Object object)
 	 * @param object a transient or detached instance containing new or updated state
 	 * @throws HibernateException
 	 */
 	public void saveOrUpdate(Object object) throws HibernateException;
 
 	/**
 	 * Either {@link #save(String, Object)} or {@link #update(String, Object)}
 	 * the given instance, depending upon resolution of the unsaved-value checks
 	 * (see the manual for discussion of unsaved-value checking).
 	 * <p/>
 	 * This operation cascades to associated instances if the association is mapped
 	 * with <tt>cascade="save-update"</tt>.
 	 *
 	 * @see Session#save(String,Object)
 	 * @see Session#update(String,Object)
 	 * @param object a transient or detached instance containing new or updated state
 	 * @throws HibernateException
 	 */
 	public void saveOrUpdate(String entityName, Object object) throws HibernateException;
 
 	/**
 	 * Update the persistent instance with the identifier of the given detached
 	 * instance. If there is a persistent instance with the same identifier,
 	 * an exception is thrown. This operation cascades to associated instances
 	 * if the association is mapped with <tt>cascade="save-update"</tt>.
 	 *
 	 * @param object a detached instance containing updated state
 	 * @throws HibernateException
 	 */
 	public void update(Object object) throws HibernateException;
 
 	/**
 	 * Update the persistent instance with the identifier of the given detached
 	 * instance. If there is a persistent instance with the same identifier,
 	 * an exception is thrown. This operation cascades to associated instances
 	 * if the association is mapped with <tt>cascade="save-update"</tt>.
 	 *
 	 * @param object a detached instance containing updated state
 	 * @throws HibernateException
 	 */
 	public void update(String entityName, Object object) throws HibernateException;
 
 	/**
 	 * Copy the state of the given object onto the persistent object with the same
 	 * identifier. If there is no persistent instance currently associated with
 	 * the session, it will be loaded. Return the persistent instance. If the
 	 * given instance is unsaved, save a copy of and return it as a newly persistent
 	 * instance. The given instance does not become associated with the session.
 	 * This operation cascades to associated instances if the association is mapped
 	 * with <tt>cascade="merge"</tt>.<br>
 	 * <br>
 	 * The semantics of this method are defined by JSR-220.
 	 *
 	 * @param object a detached instance with state to be copied
 	 * @return an updated persistent instance
 	 */
 	public Object merge(Object object) throws HibernateException;
 
 	/**
 	 * Copy the state of the given object onto the persistent object with the same
 	 * identifier. If there is no persistent instance currently associated with
 	 * the session, it will be loaded. Return the persistent instance. If the
 	 * given instance is unsaved, save a copy of and return it as a newly persistent
 	 * instance. The given instance does not become associated with the session.
 	 * This operation cascades to associated instances if the association is mapped
 	 * with <tt>cascade="merge"</tt>.<br>
 	 * <br>
 	 * The semantics of this method are defined by JSR-220.
 	 *
 	 * @param object a detached instance with state to be copied
 	 * @return an updated persistent instance
 	 */
 	public Object merge(String entityName, Object object) throws HibernateException;
 
 	/**
 	 * Make a transient instance persistent. This operation cascades to associated
 	 * instances if the association is mapped with <tt>cascade="persist"</tt>.<br>
 	 * <br>
 	 * The semantics of this method are defined by JSR-220.
 	 *
 	 * @param object a transient instance to be made persistent
 	 */
 	public void persist(Object object) throws HibernateException;
 	/**
 	 * Make a transient instance persistent. This operation cascades to associated
 	 * instances if the association is mapped with <tt>cascade="persist"</tt>.<br>
 	 * <br>
 	 * The semantics of this method are defined by JSR-220.
 	 *
 	 * @param object a transient instance to be made persistent
 	 */
 	public void persist(String entityName, Object object) throws HibernateException;
 
 	/**
 	 * Remove a persistent instance from the datastore. The argument may be
 	 * an instance associated with the receiving <tt>Session</tt> or a transient
 	 * instance with an identifier associated with existing persistent state.
 	 * This operation cascades to associated instances if the association is mapped
 	 * with <tt>cascade="delete"</tt>.
 	 *
 	 * @param object the instance to be removed
 	 * @throws HibernateException
 	 */
 	public void delete(Object object) throws HibernateException;
 
 	/**
 	 * Remove a persistent instance from the datastore. The <b>object</b> argument may be
 	 * an instance associated with the receiving <tt>Session</tt> or a transient
 	 * instance with an identifier associated with existing persistent state.
 	 * This operation cascades to associated instances if the association is mapped
 	 * with <tt>cascade="delete"</tt>.
 	 *
 	 * @param entityName The entity name for the instance to be removed.
 	 * @param object the instance to be removed
 	 * @throws HibernateException
 	 */
 	public void delete(String entityName, Object object) throws HibernateException;
 
 	/**
 	 * Obtain the specified lock level upon the given object. This may be used to
 	 * perform a version check (<tt>LockMode.READ</tt>), to upgrade to a pessimistic
 	 * lock (<tt>LockMode.PESSIMISTIC_WRITE</tt>), or to simply reassociate a transient instance
 	 * with a session (<tt>LockMode.NONE</tt>). This operation cascades to associated
 	 * instances if the association is mapped with <tt>cascade="lock"</tt>.
 	 *
 	 * @param object a persistent or transient instance
 	 * @param lockMode the lock level
 	 * @throws HibernateException
 	 * @deprecated instead call buildLockRequest(LockMode).lock(object)
 	 */
 	public void lock(Object object, LockMode lockMode) throws HibernateException;
 
 	/**
 	 * Obtain the specified lock level upon the given object. This may be used to
 	 * perform a version check (<tt>LockMode.OPTIMISTIC</tt>), to upgrade to a pessimistic
 	 * lock (<tt>LockMode.PESSIMISTIC_WRITE</tt>), or to simply reassociate a transient instance
 	 * with a session (<tt>LockMode.NONE</tt>). This operation cascades to associated
 	 * instances if the association is mapped with <tt>cascade="lock"</tt>.
 	 *
 	 * @param object a persistent or transient instance
 	 * @param lockMode the lock level
 	 * @throws HibernateException
 	 * @deprecated instead call buildLockRequest(LockMode).lock(entityName, object)
 	 */
 	public void lock(String entityName, Object object, LockMode lockMode) throws HibernateException;
 
 	/**
 	 * Build a LockRequest that specifies the LockMode, pessimistic lock timeout and lock scope.
 	 * timeout and scope is ignored for optimistic locking.  After building the LockRequest,
 	 * call LockRequest.lock to perform the requested locking. 
 	 *
 	 * Use: session.buildLockRequest().
 	 *      setLockMode(LockMode.PESSIMISTIC_WRITE).setTimeOut(1000 * 60).lock(entity);
 	 *
 	 * @param lockOptions contains the lock level
 	 * @return a lockRequest that can be used to lock the passed object.
 	 * @throws HibernateException
 	 */
 	public LockRequest buildLockRequest(LockOptions lockOptions);
 
 	/**
 	 * Re-read the state of the given instance from the underlying database. It is
 	 * inadvisable to use this to implement long-running sessions that span many
 	 * business tasks. This method is, however, useful in certain special circumstances.
 	 * For example
 	 * <ul>
 	 * <li>where a database trigger alters the object state upon insert or update
 	 * <li>after executing direct SQL (eg. a mass update) in the same session
 	 * <li>after inserting a <tt>Blob</tt> or <tt>Clob</tt>
 	 * </ul>
 	 *
 	 * @param object a persistent or detached instance
 	 * @throws HibernateException
 	 */
 	public void refresh(Object object) throws HibernateException;
 
 	/**
 	 * Re-read the state of the given instance from the underlying database, with
 	 * the given <tt>LockMode</tt>. It is inadvisable to use this to implement
 	 * long-running sessions that span many business tasks. This method is, however,
 	 * useful in certain special circumstances.
 	 *
 	 * @param object a persistent or detached instance
 	 * @param lockMode the lock mode to use
 	 * @throws HibernateException
 	 * @deprecated LockMode parameter should be replaced with LockOptions
 	 */
 	public void refresh(Object object, LockMode lockMode) throws HibernateException;
 
 	/**
 	 * Re-read the state of the given instance from the underlying database, with
 	 * the given <tt>LockMode</tt>. It is inadvisable to use this to implement
 	 * long-running sessions that span many business tasks. This method is, however,
 	 * useful in certain special circumstances.
 	 *
 	 * @param object a persistent or detached instance
 	 * @param lockOptions contains the lock mode to use
 	 * @throws HibernateException
 	 */
 	public void refresh(Object object, LockOptions lockOptions) throws HibernateException;
 
 	/**
 	 * Determine the current lock mode of the given object.
 	 *
 	 * @param object a persistent instance
 	 * @return the current lock mode
 	 * @throws HibernateException
 	 */
 	public LockMode getCurrentLockMode(Object object) throws HibernateException;
 
 	/**
 	 * Begin a unit of work and return the associated <tt>Transaction</tt> object.
 	 * If a new underlying transaction is required, begin the transaction. Otherwise
 	 * continue the new work in the context of the existing underlying transaction.
 	 * The class of the returned <tt>Transaction</tt> object is determined by the
 	 * property <tt>hibernate.transaction_factory</tt>.
 	 *
 	 * @return a Transaction instance
 	 * @throws HibernateException
 	 * @see Transaction
 	 */
 	public Transaction beginTransaction() throws HibernateException;
 
 	/**
 	 * Get the <tt>Transaction</tt> instance associated with this session.
 	 * The class of the returned <tt>Transaction</tt> object is determined by the
 	 * property <tt>hibernate.transaction_factory</tt>.
 	 *
 	 * @return a Transaction instance
 	 * @throws HibernateException
 	 * @see Transaction
 	 */
 	public Transaction getTransaction();
 
 	/**
 	 * Create a new <tt>Criteria</tt> instance, for the given entity class,
 	 * or a superclass of an entity class.
 	 *
 	 * @param persistentClass a class, which is persistent, or has persistent subclasses
 	 * @return Criteria
 	 */
 	public Criteria createCriteria(Class persistentClass);
 
 	/**
 	 * Create a new <tt>Criteria</tt> instance, for the given entity class,
 	 * or a superclass of an entity class, with the given alias.
 	 *
 	 * @param persistentClass a class, which is persistent, or has persistent subclasses
 	 * @return Criteria
 	 */
 	public Criteria createCriteria(Class persistentClass, String alias);
 
 	/**
 	 * Create a new <tt>Criteria</tt> instance, for the given entity name.
 	 *
 	 * @param entityName
 	 * @return Criteria
 	 */
 	public Criteria createCriteria(String entityName);
 
 	/**
 	 * Create a new <tt>Criteria</tt> instance, for the given entity name,
 	 * with the given alias.
 	 *
 	 * @param entityName
 	 * @return Criteria
 	 */
 	public Criteria createCriteria(String entityName, String alias);
 
 	/**
 	 * Create a new instance of <tt>Query</tt> for the given HQL query string.
 	 *
 	 * @param queryString a HQL query
 	 * @return Query
 	 * @throws HibernateException
 	 */
 	public Query createQuery(String queryString) throws HibernateException;
 
 	/**
 	 * Create a new instance of <tt>SQLQuery</tt> for the given SQL query string.
 	 *
 	 * @param queryString a SQL query
 	 * @return SQLQuery
 	 * @throws HibernateException
 	 */
 	public SQLQuery createSQLQuery(String queryString) throws HibernateException;
 
 	/**
 	 * Create a new instance of <tt>Query</tt> for the given collection and filter string.
 	 *
 	 * @param collection a persistent collection
 	 * @param queryString a Hibernate query
 	 * @return Query
 	 * @throws HibernateException
 	 */
 	public Query createFilter(Object collection, String queryString) throws HibernateException;
 
 	/**
 	 * Obtain an instance of <tt>Query</tt> for a named query string defined in the
 	 * mapping file.
 	 *
 	 * @param queryName the name of a query defined externally
 	 * @return Query
 	 * @throws HibernateException
 	 */
 	public Query getNamedQuery(String queryName) throws HibernateException;
 
 	/**
 	 * Completely clear the session. Evict all loaded instances and cancel all pending
 	 * saves, updates and deletions. Do not close open iterators or instances of
 	 * <tt>ScrollableResults</tt>.
 	 */
 	public void clear();
 
 	/**
 	 * Return the persistent instance of the given entity class with the given identifier,
 	 * or null if there is no such persistent instance. (If the instance is already associated
 	 * with the session, return that instance. This method never returns an uninitialized instance.)
 	 *
 	 * @param clazz a persistent class
 	 * @param id an identifier
 	 * @return a persistent instance or null
 	 * @throws HibernateException
 	 */
 	public Object get(Class clazz, Serializable id) throws HibernateException;
 
 	/**
 	 * Return the persistent instance of the given entity class with the given identifier,
 	 * or null if there is no such persistent instance. (If the instance is already associated
 	 * with the session, return that instance. This method never returns an uninitialized instance.)
 	 * Obtain the specified lock mode if the instance exists.
 	 *
 	 * @param clazz a persistent class
 	 * @param id an identifier
 	 * @param lockMode the lock mode
 	 * @return a persistent instance or null
 	 * @throws HibernateException
 	 * @deprecated LockMode parameter should be replaced with LockOptions
 	 */
 	public Object get(Class clazz, Serializable id, LockMode lockMode) throws HibernateException;
 
 	/**
 	 * Return the persistent instance of the given entity class with the given identifier,
 	 * or null if there is no such persistent instance. (If the instance is already associated
 	 * with the session, return that instance. This method never returns an uninitialized instance.)
 	 * Obtain the specified lock mode if the instance exists.
 	 *
 	 * @param clazz a persistent class
 	 * @param id an identifier
 	 * @param lockOptions the lock mode
 	 * @return a persistent instance or null
 	 * @throws HibernateException
 	 */
 	public Object get(Class clazz, Serializable id, LockOptions lockOptions) throws HibernateException;
 
 	/**
 	 * Return the persistent instance of the given named entity with the given identifier,
 	 * or null if there is no such persistent instance. (If the instance is already associated
 	 * with the session, return that instance. This method never returns an uninitialized instance.)
 	 *
 	 * @param entityName the entity name
 	 * @param id an identifier
 	 * @return a persistent instance or null
 	 * @throws HibernateException
 	 */
 	public Object get(String entityName, Serializable id) throws HibernateException;
 
 	/**
 	 * Return the persistent instance of the given entity class with the given identifier,
 	 * or null if there is no such persistent instance. (If the instance is already associated
 	 * with the session, return that instance. This method never returns an uninitialized instance.)
 	 * Obtain the specified lock mode if the instance exists.
 	 *
 	 * @param entityName the entity name
 	 * @param id an identifier
 	 * @param lockMode the lock mode
 	 * @return a persistent instance or null
 	 * @throws HibernateException
 	 * @deprecated LockMode parameter should be replaced with LockOptions
 	 */
 	public Object get(String entityName, Serializable id, LockMode lockMode) throws HibernateException;
 
 	/**
 	 * Return the persistent instance of the given entity class with the given identifier,
 	 * or null if there is no such persistent instance. (If the instance is already associated
 	 * with the session, return that instance. This method never returns an uninitialized instance.)
 	 * Obtain the specified lock mode if the instance exists.
 	 *
 	 * @param entityName the entity name
 	 * @param id an identifier
 	 * @param lockOptions contains the lock mode
 	 * @return a persistent instance or null
 	 * @throws HibernateException
 	 */
 	public Object get(String entityName, Serializable id, LockOptions lockOptions) throws HibernateException;
 
 	/**
 	 * Return the entity name for a persistent entity
 	 *   
 	 * @param object a persistent entity
 	 * @return the entity name
 	 * @throws HibernateException
 	 */
 	public String getEntityName(Object object) throws HibernateException;
 
 	/**
 	 * Enable the named filter for this current session.
 	 *
 	 * @param filterName The name of the filter to be enabled.
 	 * @return The Filter instance representing the enabled filter.
 	 */
 	public Filter enableFilter(String filterName);
 
 	/**
 	 * Retrieve a currently enabled filter by name.
 	 *
 	 * @param filterName The name of the filter to be retrieved.
 	 * @return The Filter instance representing the enabled filter.
 	 */
 	public Filter getEnabledFilter(String filterName);
 
 	/**
 	 * Disable the named filter for the current session.
 	 *
 	 * @param filterName The name of the filter to be disabled.
 	 */
 	public void disableFilter(String filterName);
 	
 	/**
 	 * Get the statistics for this session.
 	 */
 	public SessionStatistics getStatistics();
 
 	/**
 	 * Is the specified entity or proxy read-only?
 	 *
 	 * To get the default read-only/modifiable setting used for
 	 * entities and proxies that are loaded into the session:
 	 * @see org.hibernate.Session#isDefaultReadOnly()
 	 *
 	 * @param entityOrProxy, an entity or HibernateProxy
 	 * @return true, the entity or proxy is read-only;
 	 *         false, the entity or proxy is modifiable.
 	 */
 	public boolean isReadOnly(Object entityOrProxy);
 
 	/**
 	 * Set an unmodified persistent object to read-only mode, or a read-only
 	 * object to modifiable mode. In read-only mode, no snapshot is maintained,
 	 * the instance is never dirty checked, and changes are not persisted.
 	 *
 	 * If the entity or proxy already has the specified read-only/modifiable
 	 * setting, then this method does nothing.
 	 * 
 	 * To set the default read-only/modifiable setting used for
 	 * entities and proxies that are loaded into the session:
 	 * @see org.hibernate.Session#setDefaultReadOnly(boolean)
 	 *
 	 * To override this session's read-only/modifiable setting for entities
 	 * and proxies loaded by a Query:
 	 * @see Query#setReadOnly(boolean)
 	 * 
 	 * @param entityOrProxy, an entity or HibernateProxy
 	 * @param readOnly, if true, the entity or proxy is made read-only;
 	 *                  if false, the entity or proxy is made modifiable.
 	 */
 	public void setReadOnly(Object entityOrProxy, boolean readOnly);
 
 	/**
 	 * Controller for allowing users to perform JDBC related work using the Connection
 	 * managed by this Session.
 	 *
 	 * @param work The work to be performed.
 	 * @throws HibernateException Generally indicates wrapped {@link java.sql.SQLException}
 	 */
 	public void doWork(Work work) throws HibernateException;
 
 	/**
 	 * Disconnect the <tt>Session</tt> from the current JDBC connection. If
 	 * the connection was obtained by Hibernate close it and return it to
 	 * the connection pool; otherwise, return it to the application.
 	 * <p/>
 	 * This is used by applications which supply JDBC connections to Hibernate
 	 * and which require long-sessions (or long-conversations)
 	 * <p/>
 	 * Note that disconnect() called on a session where the connection was
 	 * retrieved by Hibernate through its configured
-	 * {@link org.hibernate.connection.ConnectionProvider} has no effect,
+	 * {@link org.hibernate.service.jdbc.connections.spi.ConnectionProvider} has no effect,
 	 * provided {@link ConnectionReleaseMode#ON_CLOSE} is not in effect.
 	 *
 	 * @return the application-supplied connection or <tt>null</tt>
 	 * @see #reconnect(Connection)
 	 * @see #reconnect()
 	 */
 	Connection disconnect() throws HibernateException;
 
 	/**
 	 * Obtain a new JDBC connection. This is used by applications which
 	 * require long transactions and do not supply connections to the
 	 * session.
 	 *
 	 * @see #disconnect()
 	 * @deprecated Manual reconnection is only needed in the case of
 	 * application-supplied connections, in which case the
 	 * {@link #reconnect(java.sql.Connection)} for should be used.
 	 */
 	void reconnect() throws HibernateException;
 
 	/**
 	 * Reconnect to the given JDBC connection. This is used by applications
 	 * which require long transactions and use application-supplied connections.
 	 *
 	 * @param connection a JDBC connection
 	 * @see #disconnect()
 	 */
 	void reconnect(Connection connection) throws HibernateException;
 
 	/**
 	 * Is a particular fetch profile enabled on this session?
 	 *
 	 * @param name The name of the profile to be checked.
 	 * @return True if fetch profile is enabled; false if not.
 	 * @throws UnknownProfileException Indicates that the given name does not
 	 * match any known profile names
 	 *
 	 * @see org.hibernate.engine.profile.FetchProfile for discussion of this feature
 	 */
 	public boolean isFetchProfileEnabled(String name) throws UnknownProfileException;
 
 	/**
 	 * Enable a particular fetch profile on this session.  No-op if requested
 	 * profile is already enabled.
 	 *
 	 * @param name The name of the fetch profile to be enabled.
 	 * @throws UnknownProfileException Indicates that the given name does not
 	 * match any known profile names
 	 *
 	 * @see org.hibernate.engine.profile.FetchProfile for discussion of this feature
 	 */
 	public void enableFetchProfile(String name) throws UnknownProfileException;
 
 	/**
 	 * Disable a particular fetch profile on this session.  No-op if requested
 	 * profile is already disabled.
 	 *
 	 * @param name The name of the fetch profile to be disabled.
 	 * @throws UnknownProfileException Indicates that the given name does not
 	 * match any known profile names
 	 *
 	 * @see org.hibernate.engine.profile.FetchProfile for discussion of this feature
 	 */
 	public void disableFetchProfile(String name) throws UnknownProfileException;
 
 	/**
 	 * Convenience access to the {@link TypeHelper} associated with this session's {@link SessionFactory}.
 	 * <p/>
 	 * Equivalent to calling {@link #getSessionFactory()}.{@link SessionFactory#getTypeHelper getTypeHelper()}
 	 *
 	 * @return The {@link TypeHelper} associated with this session's {@link SessionFactory}
 	 */
 	public TypeHelper getTypeHelper();
 
 	/**
 	 * Retrieve this session's helper/delegate for creating LOB instances.
 	 *
 	 * @return This session's LOB helper
 	 */
 	public LobHelper getLobHelper();
 
 	/**
 	 * Contains locking details (LockMode, Timeout and Scope).
 	 */
 	public interface LockRequest {
 		static final int PESSIMISTIC_NO_WAIT = 0;
 		static final int PESSIMISTIC_WAIT_FOREVER = -1;
 
 		/**
 		 * Get the lock mode.
 		 *
 		 * @return the lock mode.
 		 */
 		LockMode getLockMode();
 
 		/**
 		 * Specify the LockMode to be used.  The default is LockMode.none.
 		 *
 		 * @param lockMode
 		 *
 		 * @return this LockRequest instance for operation chaining.
 		 */
 		LockRequest setLockMode(LockMode lockMode);
 
 		/**
 		 * Get the timeout setting.
 		 *
 		 * @return timeout in milliseconds, -1 for indefinite wait and 0 for no wait.
 		 */
 		int getTimeOut();
 
 		/**
 		 * Specify the pessimistic lock timeout (check if your dialect supports this option).
 		 * The default pessimistic lock behavior is to wait forever for the lock.
 		 *
 		 * @param timeout is time in milliseconds to wait for lock.  -1 means wait forever and 0 means no wait.
 		 *
 		 * @return this LockRequest instance for operation chaining.
 		 */
 		LockRequest setTimeOut(int timeout);
 
 		/**
 		 * Check if locking is cascaded to owned collections and relationships.
 		 *
 		 * @return true if locking will be extended to owned collections and relationships.
 		 */
 		boolean getScope();
 
 		/**
 		 * Specify if LockMode should be cascaded to owned collections and relationships.
 		 * The association must be mapped with <tt>cascade="lock" for scope=true to work.
 		 *
 		 * @param scope
 		 *
 		 * @return
 		 */
 		LockRequest setScope(boolean scope);
 
 		void lock(String entityName, Object object) throws HibernateException;
 
 		public void lock(Object object) throws HibernateException;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/SessionFactory.java b/hibernate-core/src/main/java/org/hibernate/SessionFactory.java
index b8e22606fc..af193fc35e 100644
--- a/hibernate-core/src/main/java/org/hibernate/SessionFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/SessionFactory.java
@@ -1,396 +1,396 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.util.Map;
 import java.util.Set;
 
 import javax.naming.Referenceable;
 
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.metadata.CollectionMetadata;
 import org.hibernate.stat.Statistics;
 import org.hibernate.engine.FilterDefinition;
 
 /**
  * The main contract here is the creation of {@link Session} instances.  Usually
  * an application has a single {@link SessionFactory} instance and threads
  * servicing client requests obtain {@link Session} instances from this factory.
  * <p/>
  * The internal state of a {@link SessionFactory} is immutable.  Once it is created
  * this internal state is set.  This internal state includes all of the metadata
  * about Object/Relational Mapping.
  * <p/>
  * Implementors <strong>must</strong> be threadsafe.
  *
  * @see org.hibernate.cfg.Configuration
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public interface SessionFactory extends Referenceable, Serializable {
 	/**
 	 * Open a {@link Session}.
 	 * <p/>
 	 * JDBC {@link Connection connection(s} will be obtained from the
-	 * configured {@link org.hibernate.connection.ConnectionProvider} as needed
+	 * configured {@link org.hibernate.service.jdbc.connections.spi.ConnectionProvider} as needed
 	 * to perform requested work.
 	 *
 	 * @return The created session.
 	 *
 	 * @throws HibernateException Indicates a peroblem opening the session; pretty rare here.
 	 */
 	public org.hibernate.classic.Session openSession() throws HibernateException;
 
 	/**
 	 * Open a {@link Session}, utilizing the specified {@link Interceptor}.
 	 * <p/>
 	 * JDBC {@link Connection connection(s} will be obtained from the
-	 * configured {@link org.hibernate.connection.ConnectionProvider} as needed
+	 * configured {@link org.hibernate.service.jdbc.connections.spi.ConnectionProvider} as needed
 	 * to perform requested work.
 	 *
 	 * @param interceptor a session-scoped interceptor
 	 *
 	 * @return The created session.
 	 *
 	 * @throws HibernateException Indicates a peroblem opening the session; pretty rare here.
 	 */
 	public org.hibernate.classic.Session openSession(Interceptor interceptor) throws HibernateException;
 
 	/**
 	 * Open a {@link Session}, utilizing the specfied JDBC {@link Connection}.
 	 * <p>
 	 * Note that the second-level cache will be disabled if you supply a JDBC
 	 * connection. Hibernate will not be able to track any statements you might
 	 * have executed in the same transaction.  Consider implementing your own
-	 * {@link org.hibernate.connection.ConnectionProvider} instead as a highly
+	 * {@link org.hibernate.service.jdbc.connections.spi.ConnectionProvider} instead as a highly
 	 * recommended alternative.
 	 *
 	 * @param connection a connection provided by the application.
 	 *
 	 * @return The created session.
 	 */
 	public org.hibernate.classic.Session openSession(Connection connection);
 
 	/**
 	 * Open a {@link Session}, utilizing the specfied JDBC {@link Connection} and
 	 * specified {@link Interceptor}.
 	 * <p>
 	 * Note that the second-level cache will be disabled if you supply a JDBC
 	 * connection. Hibernate will not be able to track any statements you might
 	 * have executed in the same transaction.  Consider implementing your own
-	 * {@link org.hibernate.connection.ConnectionProvider} instead as a highly
+	 * {@link org.hibernate.service.jdbc.connections.spi.ConnectionProvider} instead as a highly
 	 * recommended alternative.
 	 *
 	 * @param connection a connection provided by the application.
 	 * @param interceptor a session-scoped interceptor
 	 *
 	 * @return The created session.
 	 */
 	public org.hibernate.classic.Session openSession(Connection connection, Interceptor interceptor);
 
 	/**
 	 * Obtains the current session.  The definition of what exactly "current"
 	 * means controlled by the {@link org.hibernate.context.CurrentSessionContext} impl configured
 	 * for use.
 	 * <p/>
 	 * Note that for backwards compatibility, if a {@link org.hibernate.context.CurrentSessionContext}
 	 * is not configured but a JTA {@link org.hibernate.transaction.TransactionManagerLookup}
 	 * is configured this will default to the {@link org.hibernate.context.JTASessionContext}
 	 * impl.
 	 *
 	 * @return The current session.
 	 *
 	 * @throws HibernateException Indicates an issue locating a suitable current session.
 	 */
 	public org.hibernate.classic.Session getCurrentSession() throws HibernateException;
 
 	/**
 	 * Open a new stateless session.
 	 *
 	 * @return The created stateless session.
 	 */
 	public StatelessSession openStatelessSession();
 
 	/**
 	 * Open a new stateless session, utilizing the specified JDBC
 	 * {@link Connection}.
 	 *
 	 * @param connection Connection provided by the application.
 	 *
 	 * @return The created stateless session.
 	 */
 	public StatelessSession openStatelessSession(Connection connection);
 
 	/**
 	 * Retrieve the {@link ClassMetadata} associated with the given entity class.
 	 *
 	 * @param entityClass The entity class
 	 *
 	 * @return The metadata associated with the given entity; may be null if no such
 	 * entity was mapped.
 	 *
 	 * @throws HibernateException Generally null is returned instead of throwing.
 	 */
 	public ClassMetadata getClassMetadata(Class entityClass);
 
 	/**
 	 * Retrieve the {@link ClassMetadata} associated with the given entity class.
 	 *
 	 * @param entityName The entity class
 	 *
 	 * @return The metadata associated with the given entity; may be null if no such
 	 * entity was mapped.
 	 *
 	 * @throws HibernateException Generally null is returned instead of throwing.
 	 * @since 3.0
 	 */
 	public ClassMetadata getClassMetadata(String entityName);
 
 	/**
 	 * Get the {@link CollectionMetadata} associated with the named collection role.
 	 *
 	 * @param roleName The collection role (in form [owning-entity-name].[collection-property-name]).
 	 *
 	 * @return The metadata associated with the given collection; may be null if no such
 	 * collection was mapped.
 	 *
 	 * @throws HibernateException Generally null is returned instead of throwing.
 	 */
 	public CollectionMetadata getCollectionMetadata(String roleName);
 
 	/**
 	 * Retrieve the {@link ClassMetadata} for all mapped entities.
 	 *
 	 * @return A map containing all {@link ClassMetadata} keyed by the
 	 * corresponding {@link String} entity-name.
 	 *
 	 * @throws HibernateException Generally empty map is returned instead of throwing.
 	 *
 	 * @since 3.0 changed key from {@link Class} to {@link String}.
 	 */
 	public Map<String,ClassMetadata> getAllClassMetadata();
 
 	/**
 	 * Get the {@link CollectionMetadata} for all mapped collections
 	 *
 	 * @return a map from <tt>String</tt> to <tt>CollectionMetadata</tt>
 	 *
 	 * @throws HibernateException Generally empty map is returned instead of throwing.
 	 */
 	public Map getAllCollectionMetadata();
 
 	/**
 	 * Retrieve the statistics fopr this factory.
 	 *
 	 * @return The statistics.
 	 */
 	public Statistics getStatistics();
 
 	/**
 	 * Destroy this <tt>SessionFactory</tt> and release all resources (caches,
 	 * connection pools, etc).
 	 * <p/>
 	 * It is the responsibility of the application to ensure that there are no
 	 * open {@link Session sessions} before calling this method as the impact
 	 * on those {@link Session sessions} is indeterminate.
 	 * <p/>
 	 * No-ops if already {@link #isClosed closed}.
 	 *
 	 * @throws HibernateException Indicates an issue closing the factory.
 	 */
 	public void close() throws HibernateException;
 
 	/**
 	 * Is this factory already closed?
 	 *
 	 * @return True if this factory is already closed; false otherwise.
 	 */
 	public boolean isClosed();
 
 	/**
 	 * Obtain direct access to the underlying cache regions.
 	 *
 	 * @return The direct cache access API.
 	 */
 	public Cache getCache();
 
 	/**
 	 * Evict all entries from the second-level cache. This method occurs outside
 	 * of any transaction; it performs an immediate "hard" remove, so does not respect
 	 * any transaction isolation semantics of the usage strategy. Use with care.
 	 *
 	 * @param persistentClass The entity class for which to evict data.
 	 *
 	 * @throws HibernateException Generally will mean that either that
 	 * 'persisttentClass' did not name a mapped entity or a problem
 	 * communicating with underlying cache impl.
 	 *
 	 * @deprecated Use {@link Cache#evictEntityRegion(Class)} accessed through
 	 * {@link #getCache()} instead.
 	 */
 	public void evict(Class persistentClass) throws HibernateException;
 
 	/**
 	 * Evict an entry from the second-level  cache. This method occurs outside
 	 * of any transaction; it performs an immediate "hard" remove, so does not respect
 	 * any transaction isolation semantics of the usage strategy. Use with care.
 	 *
 	 * @param persistentClass The entity class for which to evict data.
 	 * @param id The entity id
 	 *
 	 * @throws HibernateException Generally will mean that either that
 	 * 'persisttentClass' did not name a mapped entity or a problem
 	 * communicating with underlying cache impl.
 	 *
 	 * @deprecated Use {@link Cache#containsEntity(Class, Serializable)} accessed through
 	 * {@link #getCache()} instead.
 	 */
 	public void evict(Class persistentClass, Serializable id) throws HibernateException;
 
 	/**
 	 * Evict all entries from the second-level cache. This method occurs outside
 	 * of any transaction; it performs an immediate "hard" remove, so does not respect
 	 * any transaction isolation semantics of the usage strategy. Use with care.
 	 *
 	 * @param entityName The entity name for which to evict data.
 	 *
 	 * @throws HibernateException Generally will mean that either that
 	 * 'persisttentClass' did not name a mapped entity or a problem
 	 * communicating with underlying cache impl.
 	 *
 	 * @deprecated Use {@link Cache#evictEntityRegion(String)} accessed through
 	 * {@link #getCache()} instead.
 	 */
 	public void evictEntity(String entityName) throws HibernateException;
 
 	/**
 	 * Evict an entry from the second-level  cache. This method occurs outside
 	 * of any transaction; it performs an immediate "hard" remove, so does not respect
 	 * any transaction isolation semantics of the usage strategy. Use with care.
 	 *
 	 * @param entityName The entity name for which to evict data.
 	 * @param id The entity id
 	 *
 	 * @throws HibernateException Generally will mean that either that
 	 * 'persisttentClass' did not name a mapped entity or a problem
 	 * communicating with underlying cache impl.
 	 *
 	 * @deprecated Use {@link Cache#evictEntity(String,Serializable)} accessed through
 	 * {@link #getCache()} instead.
 	 */
 	public void evictEntity(String entityName, Serializable id) throws HibernateException;
 
 	/**
 	 * Evict all entries from the second-level cache. This method occurs outside
 	 * of any transaction; it performs an immediate "hard" remove, so does not respect
 	 * any transaction isolation semantics of the usage strategy. Use with care.
 	 *
 	 * @param roleName The name of the collection role whose regions should be evicted
 	 *
 	 * @throws HibernateException Generally will mean that either that
 	 * 'roleName' did not name a mapped collection or a problem
 	 * communicating with underlying cache impl.
 	 *
 	 * @deprecated Use {@link Cache#evictCollectionRegion(String)} accessed through
 	 * {@link #getCache()} instead.
 	 */
 	public void evictCollection(String roleName) throws HibernateException;
 
 	/**
 	 * Evict an entry from the second-level cache. This method occurs outside
 	 * of any transaction; it performs an immediate "hard" remove, so does not respect
 	 * any transaction isolation semantics of the usage strategy. Use with care.
 	 *
 	 * @param roleName The name of the collection role
 	 * @param id The id of the collection owner
 	 *
 	 * @throws HibernateException Generally will mean that either that
 	 * 'roleName' did not name a mapped collection or a problem
 	 * communicating with underlying cache impl.
 	 *
 	 * @deprecated Use {@link Cache#evictCollection(String,Serializable)} accessed through
 	 * {@link #getCache()} instead.
 	 */
 	public void evictCollection(String roleName, Serializable id) throws HibernateException;
 
 	/**
 	 * Evict any query result sets cached in the named query cache region.
 	 *
 	 * @param cacheRegion The named query cache region from which to evict.
 	 *
 	 * @throws HibernateException Since a not-found 'cacheRegion' simply no-ops,
 	 * this should indicate a problem communicating with underlying cache impl.
 	 *
 	 * @deprecated Use {@link Cache#evictQueryRegion(String)} accessed through
 	 * {@link #getCache()} instead.
 	 */
 	public void evictQueries(String cacheRegion) throws HibernateException;
 
 	/**
 	 * Evict any query result sets cached in the default query cache region.
 	 *
 	 * @throws HibernateException Indicate a problem communicating with
 	 * underlying cache impl.
 	 *
 	 * @deprecated Use {@link Cache#evictQueryRegions} accessed through
 	 * {@link #getCache()} instead.
 	 */
 	public void evictQueries() throws HibernateException;
 
 	/**
 	 * Obtain a set of the names of all filters defined on this SessionFactory.
 	 *
 	 * @return The set of filter names.
 	 */
 	public Set getDefinedFilterNames();
 
 	/**
 	 * Obtain the definition of a filter by name.
 	 *
 	 * @param filterName The name of the filter for which to obtain the definition.
 	 * @return The filter definition.
 	 * @throws HibernateException If no filter defined with the given name.
 	 */
 	public FilterDefinition getFilterDefinition(String filterName) throws HibernateException;
 
 	/**
 	 * Determine if this session factory contains a fetch profile definition
 	 * registered under the given name.
 	 *
 	 * @param name The name to check
 	 * @return True if there is such a fetch profile; false otherwise.
 	 */
 	public boolean containsFetchProfileDefinition(String name);
 
 	/**
 	 * Retrieve this factory's {@link TypeHelper}
 	 *
 	 * @return The factory's {@link TypeHelper}
 	 */
 	public TypeHelper getTypeHelper();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/AnnotationConfiguration.java b/hibernate-core/src/main/java/org/hibernate/cfg/AnnotationConfiguration.java
index e318381634..534c52e218 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/AnnotationConfiguration.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/AnnotationConfiguration.java
@@ -1,273 +1,269 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import java.io.File;
 import java.io.InputStream;
 import java.net.URL;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 import javax.persistence.Embeddable;
 import javax.persistence.Entity;
 import javax.persistence.MappedSuperclass;
 import javax.persistence.MapsId;
 
 import org.dom4j.Document;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import org.hibernate.AnnotationException;
 import org.hibernate.DuplicateMappingException;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.MappingException;
 import org.hibernate.annotations.AnyMetaDef;
 import org.hibernate.annotations.common.reflection.ReflectionManager;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.engine.NamedQueryDefinition;
 import org.hibernate.engine.NamedSQLQueryDefinition;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.mapping.IdGenerator;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Table;
 import org.hibernate.util.CollectionHelper;
 
 /**
  * Similar to the {@link Configuration} object but handles EJB3 and Hibernate
  * specific annotations as a metadata facility.
  *
  * @author Emmanuel Bernard
  * @author Hardy Ferentschik
  *
  * @deprecated All functionality has been moved to {@link Configuration}
  */
 @Deprecated
 public class AnnotationConfiguration extends Configuration {
 	private Logger log = LoggerFactory.getLogger( AnnotationConfiguration.class );
 
 	public AnnotationConfiguration() {
 		super();
 	}
 
-	public AnnotationConfiguration(SettingsFactory sf) {
-		super( sf );
-	}
-
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
 	public AnnotationConfiguration addAnnotatedClass(Class annotatedClass) throws MappingException {
 		return (AnnotationConfiguration) super.addAnnotatedClass( annotatedClass );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
 	public AnnotationConfiguration addPackage(String packageName) throws MappingException {
 		return (AnnotationConfiguration) super.addPackage( packageName );
 	}
 
 	public ExtendedMappings createExtendedMappings() {
 		return new ExtendedMappingsImpl();
 	}
 
 	@Override
 	public AnnotationConfiguration addFile(String xmlFile) throws MappingException {
 		super.addFile( xmlFile );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration addFile(File xmlFile) throws MappingException {
 		super.addFile( xmlFile );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration addCacheableFile(File xmlFile) throws MappingException {
 		super.addCacheableFile( xmlFile );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration addCacheableFile(String xmlFile) throws MappingException {
 		super.addCacheableFile( xmlFile );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration addXML(String xml) throws MappingException {
 		super.addXML( xml );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration addURL(URL url) throws MappingException {
 		super.addURL( url );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration addResource(String resourceName, ClassLoader classLoader) throws MappingException {
 		super.addResource( resourceName, classLoader );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration addDocument(org.w3c.dom.Document doc) throws MappingException {
 		super.addDocument( doc );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration addResource(String resourceName) throws MappingException {
 		super.addResource( resourceName );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration addClass(Class persistentClass) throws MappingException {
 		super.addClass( persistentClass );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration addJar(File jar) throws MappingException {
 		super.addJar( jar );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration addDirectory(File dir) throws MappingException {
 		super.addDirectory( dir );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration setInterceptor(Interceptor interceptor) {
 		super.setInterceptor( interceptor );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration setProperties(Properties properties) {
 		super.setProperties( properties );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration addProperties(Properties extraProperties) {
 		super.addProperties( extraProperties );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration mergeProperties(Properties properties) {
 		super.mergeProperties( properties );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration setProperty(String propertyName, String value) {
 		super.setProperty( propertyName, value );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration configure() throws HibernateException {
 		super.configure();
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration configure(String resource) throws HibernateException {
 		super.configure( resource );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration configure(URL url) throws HibernateException {
 		super.configure( url );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration configure(File configFile) throws HibernateException {
 		super.configure( configFile );
 		return this;
 	}
 
 	@Override
 	protected AnnotationConfiguration doConfigure(InputStream stream, String resourceName) throws HibernateException {
 		super.doConfigure( stream, resourceName );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration configure(org.w3c.dom.Document document) throws HibernateException {
 		super.configure( document );
 		return this;
 	}
 
 	@Override
 	protected AnnotationConfiguration doConfigure(Document doc) throws HibernateException {
 		super.doConfigure( doc );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration setCacheConcurrencyStrategy(String clazz, String concurrencyStrategy) {
 		super.setCacheConcurrencyStrategy( clazz, concurrencyStrategy );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration setCacheConcurrencyStrategy(String clazz, String concurrencyStrategy, String region) {
 		super.setCacheConcurrencyStrategy( clazz, concurrencyStrategy, region );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration setCollectionCacheConcurrencyStrategy(String collectionRole, String concurrencyStrategy)
 			throws MappingException {
 		super.setCollectionCacheConcurrencyStrategy( collectionRole, concurrencyStrategy );
 		return this;
 	}
 
 	@Override
 	public AnnotationConfiguration setNamingStrategy(NamingStrategy namingStrategy) {
 		super.setNamingStrategy( namingStrategy );
 		return this;
 	}
 
 	@Deprecated
 	protected class ExtendedMappingsImpl extends MappingsImpl implements ExtendedMappings {
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/Configuration.java b/hibernate-core/src/main/java/org/hibernate/cfg/Configuration.java
index ad86e8fb9f..d8051cd5e3 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/Configuration.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/Configuration.java
@@ -1,3833 +1,3837 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.FileNotFoundException;
 import java.io.FileOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.ObjectInputStream;
 import java.io.Serializable;
 import java.io.StringReader;
 import java.lang.reflect.Array;
 import java.lang.reflect.Constructor;
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Method;
 import java.net.URL;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.Enumeration;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.ListIterator;
 import java.util.Map;
 import java.util.Properties;
 import java.util.ResourceBundle;
 import java.util.Set;
 import java.util.StringTokenizer;
 import java.util.TreeMap;
 import java.util.jar.JarFile;
 import java.util.zip.ZipEntry;
 import javax.persistence.Embeddable;
 import javax.persistence.Entity;
 import javax.persistence.MapsId;
 
 import org.dom4j.Attribute;
 import org.dom4j.Document;
 import org.dom4j.DocumentException;
 import org.dom4j.Element;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.xml.sax.EntityResolver;
 import org.xml.sax.InputSource;
 
 import org.hibernate.AnnotationException;
 import org.hibernate.DuplicateMappingException;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.InvalidMappingException;
 import org.hibernate.MappingException;
 import org.hibernate.MappingNotFoundException;
 import org.hibernate.SessionFactory;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.annotations.AnyMetaDef;
 import org.hibernate.annotations.common.reflection.MetadataProvider;
 import org.hibernate.annotations.common.reflection.MetadataProviderInjector;
 import org.hibernate.annotations.common.reflection.ReflectionManager;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.annotations.common.reflection.java.JavaReflectionManager;
 import org.hibernate.cfg.annotations.reflection.JPAMetadataProvider;
 import org.hibernate.cfg.beanvalidation.BeanValidationActivator;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.MySQLDialect;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.engine.FilterDefinition;
 import org.hibernate.engine.Mapping;
 import org.hibernate.engine.NamedQueryDefinition;
 import org.hibernate.engine.NamedSQLQueryDefinition;
 import org.hibernate.engine.ResultSetMappingDefinition;
+import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.event.AutoFlushEventListener;
 import org.hibernate.event.DeleteEventListener;
 import org.hibernate.event.DirtyCheckEventListener;
 import org.hibernate.event.EventListeners;
 import org.hibernate.event.EvictEventListener;
 import org.hibernate.event.FlushEntityEventListener;
 import org.hibernate.event.FlushEventListener;
 import org.hibernate.event.InitializeCollectionEventListener;
 import org.hibernate.event.LoadEventListener;
 import org.hibernate.event.LockEventListener;
 import org.hibernate.event.MergeEventListener;
 import org.hibernate.event.PersistEventListener;
 import org.hibernate.event.PostCollectionRecreateEventListener;
 import org.hibernate.event.PostCollectionRemoveEventListener;
 import org.hibernate.event.PostCollectionUpdateEventListener;
 import org.hibernate.event.PostDeleteEventListener;
 import org.hibernate.event.PostInsertEventListener;
 import org.hibernate.event.PostLoadEventListener;
 import org.hibernate.event.PostUpdateEventListener;
 import org.hibernate.event.PreCollectionRecreateEventListener;
 import org.hibernate.event.PreCollectionRemoveEventListener;
 import org.hibernate.event.PreCollectionUpdateEventListener;
 import org.hibernate.event.PreDeleteEventListener;
 import org.hibernate.event.PreInsertEventListener;
 import org.hibernate.event.PreLoadEventListener;
 import org.hibernate.event.PreUpdateEventListener;
 import org.hibernate.event.RefreshEventListener;
 import org.hibernate.event.ReplicateEventListener;
 import org.hibernate.event.SaveOrUpdateEventListener;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.IdentifierGeneratorAggregator;
 import org.hibernate.id.PersistentIdentifierGenerator;
 import org.hibernate.id.factory.DefaultIdentifierGeneratorFactory;
 import org.hibernate.id.factory.IdentifierGeneratorFactory;
 import org.hibernate.impl.SessionFactoryImpl;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.mapping.AuxiliaryDatabaseObject;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.DenormalizedTable;
 import org.hibernate.mapping.FetchProfile;
 import org.hibernate.mapping.ForeignKey;
 import org.hibernate.mapping.IdGenerator;
 import org.hibernate.mapping.IdentifierCollection;
 import org.hibernate.mapping.Index;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.MappedSuperclass;
 import org.hibernate.mapping.MetadataSource;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.mapping.Table;
 import org.hibernate.mapping.TypeDef;
 import org.hibernate.mapping.UniqueKey;
 import org.hibernate.proxy.EntityNotFoundDelegate;
 import org.hibernate.secure.JACCConfiguration;
+import org.hibernate.service.spi.ServicesRegistry;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.tool.hbm2ddl.DatabaseMetadata;
 import org.hibernate.tool.hbm2ddl.IndexMetadata;
 import org.hibernate.tool.hbm2ddl.TableMetadata;
 import org.hibernate.tuple.entity.EntityTuplizerFactory;
 import org.hibernate.type.BasicType;
 import org.hibernate.type.SerializationException;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeResolver;
 import org.hibernate.usertype.CompositeUserType;
 import org.hibernate.usertype.UserType;
 import org.hibernate.util.ArrayHelper;
 import org.hibernate.util.CollectionHelper;
 import org.hibernate.util.ConfigHelper;
 import org.hibernate.util.JoinedIterator;
 import org.hibernate.util.ReflectHelper;
 import org.hibernate.util.SerializationHelper;
 import org.hibernate.util.StringHelper;
 import org.hibernate.util.XMLHelper;
 import org.hibernate.util.xml.MappingReader;
 import org.hibernate.util.xml.Origin;
 import org.hibernate.util.xml.OriginImpl;
 import org.hibernate.util.xml.XmlDocument;
 import org.hibernate.util.xml.XmlDocumentImpl;
 
 /**
  * An instance of <tt>Configuration</tt> allows the application
  * to specify properties and mapping documents to be used when
  * creating a <tt>SessionFactory</tt>. Usually an application will create
  * a single <tt>Configuration</tt>, build a single instance of
  * <tt>SessionFactory</tt> and then instantiate <tt>Session</tt>s in
  * threads servicing client requests. The <tt>Configuration</tt> is meant
  * only as an initialization-time object. <tt>SessionFactory</tt>s are
  * immutable and do not retain any association back to the
  * <tt>Configuration</tt>.<br>
  * <br>
  * A new <tt>Configuration</tt> will use the properties specified in
  * <tt>hibernate.properties</tt> by default.
  *
  * @author Gavin King
  * @see org.hibernate.SessionFactory
  */
 public class Configuration implements Serializable {
 	private static Logger log = LoggerFactory.getLogger( Configuration.class );
 
 	/**
 	 * Setting used to give the name of the default {@link org.hibernate.annotations.CacheConcurrencyStrategy}
 	 * to use when either {@link javax.persistence.Cacheable @Cacheable} or
 	 * {@link org.hibernate.annotations.Cache @Cache} is used.  {@link org.hibernate.annotations.Cache @Cache(strategy="..")} is used to override.
 	 */
 	public static final String DEFAULT_CACHE_CONCURRENCY_STRATEGY = "hibernate.cache.default_cache_concurrency_strategy";
 
 	/**
 	 * Setting which indicates whether or not the new {@link org.hibernate.id.IdentifierGenerator} are used
 	 * for AUTO, TABLE and SEQUENCE.
 	 * Default to false to keep backward compatibility.
 	 */
 	public static final String USE_NEW_ID_GENERATOR_MAPPINGS = "hibernate.id.new_generator_mappings";
 
 	public static final String ARTEFACT_PROCESSING_ORDER = "hibernate.mapping.precedence";
 
 	/**
 	 * Class name of the class needed to enable Search.
 	 */
 	private static final String SEARCH_STARTUP_CLASS = "org.hibernate.search.event.EventListenerRegister";
 
 	/**
 	 * Method to call to enable Search.
 	 */
 	private static final String SEARCH_STARTUP_METHOD = "enableHibernateSearch";
 
 	protected MetadataSourceQueue metadataSourceQueue;
 	private transient ReflectionManager reflectionManager;
 
 	protected Map<String, PersistentClass> classes;
 	protected Map<String, String> imports;
 	protected Map<String, Collection> collections;
 	protected Map<String, Table> tables;
 	protected List<AuxiliaryDatabaseObject> auxiliaryDatabaseObjects;
 
 	protected Map<String, NamedQueryDefinition> namedQueries;
 	protected Map<String, NamedSQLQueryDefinition> namedSqlQueries;
 	protected Map<String, ResultSetMappingDefinition> sqlResultSetMappings;
 
 	protected Map<String, TypeDef> typeDefs;
 	protected Map<String, FilterDefinition> filterDefinitions;
 	protected Map<String, FetchProfile> fetchProfiles;
 
 	protected Map tableNameBinding;
 	protected Map columnNameBindingPerTable;
 
 	protected List<SecondPass> secondPasses;
 	protected List<Mappings.PropertyReference> propertyReferences;
 	protected Map<ExtendsQueueEntry, ?> extendsQueue;
 
 	protected Map<String, SQLFunction> sqlFunctions;
 	private TypeResolver typeResolver = new TypeResolver();
 
 	private EntityTuplizerFactory entityTuplizerFactory;
 //	private ComponentTuplizerFactory componentTuplizerFactory; todo : HHH-3517 and HHH-1907
 
 	private Interceptor interceptor;
 	private Properties properties;
 	private EntityResolver entityResolver;
 	private EntityNotFoundDelegate entityNotFoundDelegate;
 
 	protected transient XMLHelper xmlHelper;
 	protected NamingStrategy namingStrategy;
 	private SessionFactoryObserver sessionFactoryObserver;
 
 	private EventListeners eventListeners;
 
 	protected final SettingsFactory settingsFactory;
 
 	private transient Mapping mapping = buildMapping();
 
 	private DefaultIdentifierGeneratorFactory identifierGeneratorFactory;
 
 	private Map<Class<?>, org.hibernate.mapping.MappedSuperclass> mappedSuperClasses;
 
 	private Map<String, IdGenerator> namedGenerators;
 	private Map<String, Map<String, Join>> joins;
 	private Map<String, AnnotatedClassType> classTypes;
 	private Set<String> defaultNamedQueryNames;
 	private Set<String> defaultNamedNativeQueryNames;
 	private Set<String> defaultSqlResultSetMappingNames;
 	private Set<String> defaultNamedGenerators;
 	private Map<String, Properties> generatorTables;
 	private Map<Table, List<UniqueConstraintHolder>> uniqueConstraintHoldersByTable;
 	private Map<String, String> mappedByResolver;
 	private Map<String, String> propertyRefResolver;
 	private Map<String, AnyMetaDef> anyMetaDefs;
 	private List<CacheHolder> caches;
 	private boolean inSecondPass = false;
 	private boolean isDefaultProcessed = false;
 	private boolean isValidatorNotPresentLogged;
 	private Map<XClass, Map<String, PropertyData>> propertiesAnnotatedWithMapsId;
 	private Map<XClass, Map<String, PropertyData>> propertiesAnnotatedWithIdAndToOne;
 	private boolean specjProprietarySyntaxEnabled;
 
 
 	protected Configuration(SettingsFactory settingsFactory) {
 		this.settingsFactory = settingsFactory;
 		reset();
 	}
 
 	public Configuration() {
 		this( new SettingsFactory() );
 	}
 
 	protected void reset() {
 		metadataSourceQueue = new MetadataSourceQueue();
 		createReflectionManager();
 
 		classes = new HashMap<String,PersistentClass>();
 		imports = new HashMap<String,String>();
 		collections = new HashMap<String,Collection>();
 		tables = new TreeMap<String,Table>();
 
 		namedQueries = new HashMap<String,NamedQueryDefinition>();
 		namedSqlQueries = new HashMap<String,NamedSQLQueryDefinition>();
 		sqlResultSetMappings = new HashMap<String, ResultSetMappingDefinition>();
 
 		typeDefs = new HashMap<String,TypeDef>();
 		filterDefinitions = new HashMap<String, FilterDefinition>();
 		fetchProfiles = new HashMap<String, FetchProfile>();
 		auxiliaryDatabaseObjects = new ArrayList<AuxiliaryDatabaseObject>();
 
 		tableNameBinding = new HashMap();
 		columnNameBindingPerTable = new HashMap();
 
 		secondPasses = new ArrayList<SecondPass>();
 		propertyReferences = new ArrayList<Mappings.PropertyReference>();
 		extendsQueue = new HashMap<ExtendsQueueEntry, String>();
 
 		xmlHelper = new XMLHelper();
 		interceptor = EmptyInterceptor.INSTANCE;
 		properties = Environment.getProperties();
 		entityResolver = XMLHelper.DEFAULT_DTD_RESOLVER;
 		eventListeners = new EventListeners();
 
 		sqlFunctions = new HashMap<String, SQLFunction>();
 
 		entityTuplizerFactory = new EntityTuplizerFactory();
 //		componentTuplizerFactory = new ComponentTuplizerFactory();
 
 		identifierGeneratorFactory = new DefaultIdentifierGeneratorFactory();
 
 		mappedSuperClasses = new HashMap<Class<?>, MappedSuperclass>();
 
 		metadataSourcePrecedence = Collections.emptyList();
 
 		namedGenerators = new HashMap<String, IdGenerator>();
 		joins = new HashMap<String, Map<String, Join>>();
 		classTypes = new HashMap<String, AnnotatedClassType>();
 		generatorTables = new HashMap<String, Properties>();
 		defaultNamedQueryNames = new HashSet<String>();
 		defaultNamedNativeQueryNames = new HashSet<String>();
 		defaultSqlResultSetMappingNames = new HashSet<String>();
 		defaultNamedGenerators = new HashSet<String>();
 		uniqueConstraintHoldersByTable = new HashMap<Table, List<UniqueConstraintHolder>>();
 		mappedByResolver = new HashMap<String, String>();
 		propertyRefResolver = new HashMap<String, String>();
 		caches = new ArrayList<CacheHolder>();
 		namingStrategy = EJB3NamingStrategy.INSTANCE;
 		setEntityResolver( new EJB3DTDEntityResolver() );
 		anyMetaDefs = new HashMap<String, AnyMetaDef>();
 		propertiesAnnotatedWithMapsId = new HashMap<XClass, Map<String, PropertyData>>();
 		propertiesAnnotatedWithIdAndToOne = new HashMap<XClass, Map<String, PropertyData>>();
 		specjProprietarySyntaxEnabled = System.getProperty( "hibernate.enable_specj_proprietary_syntax" ) != null;
 	}
 
 	public EntityTuplizerFactory getEntityTuplizerFactory() {
 		return entityTuplizerFactory;
 	}
 
 	public ReflectionManager getReflectionManager() {
 		return reflectionManager;
 	}
 
 //	public ComponentTuplizerFactory getComponentTuplizerFactory() {
 //		return componentTuplizerFactory;
 //	}
 
 	/**
 	 * Iterate the entity mappings
 	 *
 	 * @return Iterator of the entity mappings currently contained in the configuration.
 	 */
 	public Iterator<PersistentClass> getClassMappings() {
 		return classes.values().iterator();
 	}
 
 	/**
 	 * Iterate the collection mappings
 	 *
 	 * @return Iterator of the collection mappings currently contained in the configuration.
 	 */
 	public Iterator getCollectionMappings() {
 		return collections.values().iterator();
 	}
 
 	/**
 	 * Iterate the table mappings
 	 *
 	 * @return Iterator of the table mappings currently contained in the configuration.
 	 */
 	public Iterator<Table> getTableMappings() {
 		return tables.values().iterator();
 	}
 
 	/**
 	 * Iterate the mapped super class mappings
 	 * EXPERIMENTAL Consider this API as PRIVATE
 	 *
 	 * @return iterator over the MappedSuperclass mapping currently contained in the configuration.
 	 */
 	public Iterator<MappedSuperclass> getMappedSuperclassMappings() {
 		return mappedSuperClasses.values().iterator();
 	}
 
 	/**
 	 * Get the mapping for a particular entity
 	 *
 	 * @param entityName An entity name.
 	 * @return the entity mapping information
 	 */
 	public PersistentClass getClassMapping(String entityName) {
 		return classes.get( entityName );
 	}
 
 	/**
 	 * Get the mapping for a particular collection role
 	 *
 	 * @param role a collection role
 	 * @return The collection mapping information
 	 */
 	public Collection getCollectionMapping(String role) {
 		return collections.get( role );
 	}
 
 	/**
 	 * Set a custom entity resolver. This entity resolver must be
 	 * set before addXXX(misc) call.
 	 * Default value is {@link org.hibernate.util.DTDEntityResolver}
 	 *
 	 * @param entityResolver entity resolver to use
 	 */
 	public void setEntityResolver(EntityResolver entityResolver) {
 		this.entityResolver = entityResolver;
 	}
 
 	public EntityResolver getEntityResolver() {
 		return entityResolver;
 	}
 
 	/**
 	 * Retrieve the user-supplied delegate to handle non-existent entity
 	 * scenarios.  May be null.
 	 *
 	 * @return The user-supplied delegate
 	 */
 	public EntityNotFoundDelegate getEntityNotFoundDelegate() {
 		return entityNotFoundDelegate;
 	}
 
 	/**
 	 * Specify a user-supplied delegate to be used to handle scenarios where an entity could not be
 	 * located by specified id.  This is mainly intended for EJB3 implementations to be able to
 	 * control how proxy initialization errors should be handled...
 	 *
 	 * @param entityNotFoundDelegate The delegate to use
 	 */
 	public void setEntityNotFoundDelegate(EntityNotFoundDelegate entityNotFoundDelegate) {
 		this.entityNotFoundDelegate = entityNotFoundDelegate;
 	}
 
 	/**
 	 * Read mappings from a particular XML file
 	 *
 	 * @param xmlFile a path to a file
 	 * @return this (for method chaining purposes)
 	 * @throws org.hibernate.MappingException Indicates inability to locate or parse
 	 * the specified mapping file.
 	 * @see #addFile(java.io.File)
 	 */
 	public Configuration addFile(String xmlFile) throws MappingException {
 		return addFile( new File( xmlFile ) );
 	}
 
 	/**
 	 * Read mappings from a particular XML file
 	 *
 	 * @param xmlFile a path to a file
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates inability to locate the specified mapping file.  Historically this could
 	 * have indicated a problem parsing the XML document, but that is now delayed until after {@link #buildMappings}
 	 */
 	public Configuration addFile(final File xmlFile) throws MappingException {
 		log.info( "Reading mappings from file: " + xmlFile.getPath() );
 		final String name =  xmlFile.getAbsolutePath();
 		final InputSource inputSource;
 		try {
 			inputSource = new InputSource( new FileInputStream( xmlFile ) );
 		}
 		catch ( FileNotFoundException e ) {
 			throw new MappingNotFoundException( "file", xmlFile.toString() );
 		}
 		add( inputSource, "file", name );
 		return this;
 	}
 
 	private XmlDocument add(InputSource inputSource, String originType, String originName) {
 		return add( inputSource, new OriginImpl( originType, originName ) );
 	}
 
 	private XmlDocument add(InputSource inputSource, Origin origin) {
 		XmlDocument metadataXml = MappingReader.INSTANCE.readMappingDocument( entityResolver, inputSource, origin );
 		add( metadataXml );
 		return metadataXml;
 	}
 
 	public void add(XmlDocument metadataXml) {
 		if ( inSecondPass || !isOrmXml( metadataXml ) ) {
 			metadataSourceQueue.add( metadataXml );
 		}
 		else {
 			final MetadataProvider metadataProvider = ( (MetadataProviderInjector) reflectionManager ).getMetadataProvider();
 			JPAMetadataProvider jpaMetadataProvider = ( JPAMetadataProvider ) metadataProvider;
 			List<String> classNames = jpaMetadataProvider.getXMLContext().addDocument( metadataXml.getDocumentTree() );
 			for ( String className : classNames ) {
 				try {
 					metadataSourceQueue.add( reflectionManager.classForName( className, this.getClass() ) );
 				}
 				catch ( ClassNotFoundException e ) {
 					throw new AnnotationException( "Unable to load class defined in XML: " + className, e );
 				}
 			}
 		}
 	}
 
 	private static boolean isOrmXml(XmlDocument xmlDocument) {
 		return "entity-mappings".equals( xmlDocument.getDocumentTree().getRootElement().getName() );
 	}
 
 	/**
 	 * Add a cached mapping file.  A cached file is a serialized representation
 	 * of the DOM structure of a particular mapping.  It is saved from a previous
 	 * call as a file with the name <tt>xmlFile + ".bin"</tt> where xmlFile is
 	 * the name of the original mapping file.
 	 * </p>
 	 * If a cached <tt>xmlFile + ".bin"</tt> exists and is newer than
 	 * <tt>xmlFile</tt> the <tt>".bin"</tt> file will be read directly. Otherwise
 	 * xmlFile is read and then serialized to <tt>xmlFile + ".bin"</tt> for use
 	 * the next time.
 	 *
 	 * @param xmlFile The cacheable mapping file to be added.
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems reading the cached file or processing
 	 * the non-cached file.
 	 */
 	public Configuration addCacheableFile(File xmlFile) throws MappingException {
 		File cachedFile = determineCachedDomFile( xmlFile );
 
 		try {
 			return addCacheableFileStrictly( xmlFile );
 		}
 		catch ( SerializationException e ) {
 			log.warn( "Could not deserialize cache file: " + cachedFile.getPath() + " : " + e );
 		}
 		catch ( FileNotFoundException e ) {
 			log.warn( "I/O reported cached file could not be found : " + cachedFile.getPath() + " : " + e );
 		}
 
 		final String name = xmlFile.getAbsolutePath();
 		final InputSource inputSource;
 		try {
 			inputSource = new InputSource( new FileInputStream( xmlFile ) );
 		}
 		catch ( FileNotFoundException e ) {
 			throw new MappingNotFoundException( "file", xmlFile.toString() );
 		}
 
 		log.info( "Reading mappings from file: " + xmlFile );
 		XmlDocument metadataXml = add( inputSource, "file", name );
 
 		try {
 			log.debug( "Writing cache file for: " + xmlFile + " to: " + cachedFile );
 			SerializationHelper.serialize( ( Serializable ) metadataXml.getDocumentTree(), new FileOutputStream( cachedFile ) );
 		}
 		catch ( SerializationException e ) {
 			log.warn( "Could not write cached file: " + cachedFile, e );
 		}
 		catch ( FileNotFoundException e ) {
 			log.warn( "I/O reported error writing cached file : " + cachedFile.getPath(), e );
 		}
 
 		return this;
 	}
 
 	private File determineCachedDomFile(File xmlFile) {
 		return new File( xmlFile.getAbsolutePath() + ".bin" );
 	}
 
 	/**
 	 * <b>INTENDED FOR TESTSUITE USE ONLY!</b>
 	 * <p/>
 	 * Much like {@link #addCacheableFile(File)} except that here we will fail immediately if
 	 * the cache version cannot be found or used for whatever reason
 	 *
 	 * @param xmlFile The xml file, not the bin!
 	 *
 	 * @return The dom "deserialized" from the cached file.
 	 *
 	 * @throws SerializationException Indicates a problem deserializing the cached dom tree
 	 * @throws FileNotFoundException Indicates that the cached file was not found or was not usable.
 	 */
 	public Configuration addCacheableFileStrictly(File xmlFile) throws SerializationException, FileNotFoundException {
 		final File cachedFile = determineCachedDomFile( xmlFile );
 
 		final boolean useCachedFile = xmlFile.exists()
 				&& cachedFile.exists()
 				&& xmlFile.lastModified() < cachedFile.lastModified();
 
 		if ( ! useCachedFile ) {
 			throw new FileNotFoundException( "Cached file could not be found or could not be used" );
 		}
 
 		log.info( "Reading mappings from cache file: " + cachedFile );
 		Document document = ( Document ) SerializationHelper.deserialize( new FileInputStream( cachedFile ) );
 		add( new XmlDocumentImpl( document, "file", xmlFile.getAbsolutePath() ) );
 		return this;
 	}
 
 	/**
 	 * Add a cacheable mapping file.
 	 *
 	 * @param xmlFile The name of the file to be added.  This must be in a form
 	 * useable to simply construct a {@link java.io.File} instance.
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems reading the cached file or processing
 	 * the non-cached file.
 	 * @see #addCacheableFile(java.io.File)
 	 */
 	public Configuration addCacheableFile(String xmlFile) throws MappingException {
 		return addCacheableFile( new File( xmlFile ) );
 	}
 
 
 	/**
 	 * Read mappings from a <tt>String</tt>
 	 *
 	 * @param xml an XML string
 	 * @return this (for method chaining purposes)
 	 * @throws org.hibernate.MappingException Indicates problems parsing the
 	 * given XML string
 	 */
 	public Configuration addXML(String xml) throws MappingException {
 		if ( log.isDebugEnabled() ) {
 			log.debug( "Mapping XML:\n" + xml );
 		}
 		final InputSource inputSource = new InputSource( new StringReader( xml ) );
 		add( inputSource, "string", "XML String" );
 		return this;
 	}
 
 	/**
 	 * Read mappings from a <tt>URL</tt>
 	 *
 	 * @param url The url for the mapping document to be read.
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems reading the URL or processing
 	 * the mapping document.
 	 */
 	public Configuration addURL(URL url) throws MappingException {
 		final String urlExternalForm = url.toExternalForm();
 
 		if ( log.isDebugEnabled() ) {
 			log.debug( "Reading mapping document from URL : {}", urlExternalForm );
 		}
 
 		try {
 			add( url.openStream(), "URL", urlExternalForm );
 		}
 		catch ( IOException e ) {
 			throw new InvalidMappingException( "Unable to open url stream [" + urlExternalForm + "]", "URL", urlExternalForm, e );
 		}
 		return this;
 	}
 
 	private XmlDocument add(InputStream inputStream, final String type, final String name) {
 		final InputSource inputSource = new InputSource( inputStream );
 		try {
 			return add( inputSource, type, name );
 		}
 		finally {
 			try {
 				inputStream.close();
 			}
 			catch ( IOException ignore ) {
 				log.trace( "Was unable to close input stream" );
 			}
 		}
 	}
 
 	/**
 	 * Read mappings from a DOM <tt>Document</tt>
 	 *
 	 * @param doc The DOM document
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems reading the DOM or processing
 	 * the mapping document.
 	 */
 	public Configuration addDocument(org.w3c.dom.Document doc) throws MappingException {
 		if ( log.isDebugEnabled() ) {
 			log.debug( "Mapping document:\n" + doc );
 		}
 
 		final Document document = xmlHelper.createDOMReader().read( doc );
 		add( new XmlDocumentImpl( document, "unknown", null ) );
 
 		return this;
 	}
 
 	/**
 	 * Read mappings from an {@link java.io.InputStream}.
 	 *
 	 * @param xmlInputStream The input stream containing a DOM.
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems reading the stream, or
 	 * processing the contained mapping document.
 	 */
 	public Configuration addInputStream(InputStream xmlInputStream) throws MappingException {
 		add( xmlInputStream, "input stream", null );
 		return this;
 	}
 
 	/**
 	 * Read mappings as a application resource (i.e. classpath lookup).
 	 *
 	 * @param resourceName The resource name
 	 * @param classLoader The class loader to use.
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems locating the resource or
 	 * processing the contained mapping document.
 	 */
 	public Configuration addResource(String resourceName, ClassLoader classLoader) throws MappingException {
 		log.info( "Reading mappings from resource: " + resourceName );
 		InputStream resourceInputStream = classLoader.getResourceAsStream( resourceName );
 		if ( resourceInputStream == null ) {
 			throw new MappingNotFoundException( "resource", resourceName );
 		}
 		add( resourceInputStream, "resource", resourceName );
 		return this;
 	}
 
 	/**
 	 * Read mappings as a application resourceName (i.e. classpath lookup)
 	 * trying different class loaders.
 	 *
 	 * @param resourceName The resource name
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems locating the resource or
 	 * processing the contained mapping document.
 	 */
 	public Configuration addResource(String resourceName) throws MappingException {
 		log.info( "Reading mappings from resource : " + resourceName );
 		ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();
 		InputStream resourceInputStream = null;
 		if ( contextClassLoader != null ) {
 			resourceInputStream = contextClassLoader.getResourceAsStream( resourceName );
 		}
 		if ( resourceInputStream == null ) {
 			resourceInputStream = Environment.class.getClassLoader().getResourceAsStream( resourceName );
 		}
 		if ( resourceInputStream == null ) {
 			throw new MappingNotFoundException( "resource", resourceName );
 		}
 		add( resourceInputStream, "resource", resourceName );
 		return this;
 	}
 
 	/**
 	 * Read a mapping as an application resource using the convention that a class
 	 * named <tt>foo.bar.Foo</tt> is mapped by a file <tt>foo/bar/Foo.hbm.xml</tt>
 	 * which can be resolved as a classpath resource.
 	 *
 	 * @param persistentClass The mapped class
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems locating the resource or
 	 * processing the contained mapping document.
 	 */
 	public Configuration addClass(Class persistentClass) throws MappingException {
 		String mappingResourceName = persistentClass.getName().replace( '.', '/' ) + ".hbm.xml";
 		log.info( "Reading mappings from resource: " + mappingResourceName );
 		return addResource( mappingResourceName, persistentClass.getClassLoader() );
 	}
 
 	/**
 	 * Read metadata from the annotations associated with this class.
 	 *
 	 * @param annotatedClass The class containing annotations
 	 *
 	 * @return this (for method chaining)
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public Configuration addAnnotatedClass(Class annotatedClass) {
 		XClass xClass = reflectionManager.toXClass( annotatedClass );
 		metadataSourceQueue.add( xClass );
 		return this;
 	}
 
 	/**
 	 * Read package-level metadata.
 	 *
 	 * @param packageName java package name
 	 *
 	 * @return this (for method chaining)
 	 *
 	 * @throws MappingException in case there is an error in the mapping data
 	 */
 	public Configuration addPackage(String packageName) throws MappingException {
 		log.info( "Mapping package {}", packageName );
 		try {
 			AnnotationBinder.bindPackage( packageName, createMappings() );
 			return this;
 		}
 		catch ( MappingException me ) {
 			log.error( "Could not parse the package-level metadata [" + packageName + "]" );
 			throw me;
 		}
 	}
 
 	/**
 	 * Read all mappings from a jar file
 	 * <p/>
 	 * Assumes that any file named <tt>*.hbm.xml</tt> is a mapping document.
 	 *
 	 * @param jar a jar file
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems reading the jar file or
 	 * processing the contained mapping documents.
 	 */
 	public Configuration addJar(File jar) throws MappingException {
 		log.info( "Searching for mapping documents in jar: " + jar.getName() );
 		JarFile jarFile = null;
 		try {
 			try {
 				jarFile = new JarFile( jar );
 			}
 			catch (IOException ioe) {
 				throw new InvalidMappingException(
 						"Could not read mapping documents from jar: " + jar.getName(), "jar", jar.getName(),
 						ioe
 				);
 			}
 			Enumeration jarEntries = jarFile.entries();
 			while ( jarEntries.hasMoreElements() ) {
 				ZipEntry ze = (ZipEntry) jarEntries.nextElement();
 				if ( ze.getName().endsWith( ".hbm.xml" ) ) {
 					log.info( "Found mapping document in jar: " + ze.getName() );
 					try {
 						addInputStream( jarFile.getInputStream( ze ) );
 					}
 					catch (Exception e) {
 						throw new InvalidMappingException(
 								"Could not read mapping documents from jar: " + jar.getName(),
 								"jar",
 								jar.getName(),
 								e
 						);
 					}
 				}
 			}
 		}
 		finally {
 			try {
 				if ( jarFile != null ) {
 					jarFile.close();
 				}
 			}
 			catch (IOException ioe) {
 				log.error("could not close jar", ioe);
 			}
 		}
 
 		return this;
 	}
 
 	/**
 	 * Read all mapping documents from a directory tree.
 	 * <p/>
 	 * Assumes that any file named <tt>*.hbm.xml</tt> is a mapping document.
 	 *
 	 * @param dir The directory
 	 * @return this (for method chaining purposes)
 	 * @throws MappingException Indicates problems reading the jar file or
 	 * processing the contained mapping documents.
 	 */
 	public Configuration addDirectory(File dir) throws MappingException {
 		File[] files = dir.listFiles();
 		for ( File file : files ) {
 			if ( file.isDirectory() ) {
 				addDirectory( file );
 			}
 			else if ( file.getName().endsWith( ".hbm.xml" ) ) {
 				addFile( file );
 			}
 		}
 		return this;
 	}
 
 	/**
 	 * Create a new <tt>Mappings</tt> to add class and collection mappings to.
 	 *
 	 * @return The created mappings
 	 */
 	public Mappings createMappings() {
 		return new MappingsImpl();
 	}
 
 
 	@SuppressWarnings({ "unchecked" })
 	private Iterator<IdentifierGenerator> iterateGenerators(Dialect dialect) throws MappingException {
 
 		TreeMap generators = new TreeMap();
 		String defaultCatalog = properties.getProperty( Environment.DEFAULT_CATALOG );
 		String defaultSchema = properties.getProperty( Environment.DEFAULT_SCHEMA );
 
 		for ( PersistentClass pc : classes.values() ) {
 			if ( !pc.isInherited() ) {
 				IdentifierGenerator ig = pc.getIdentifier().createIdentifierGenerator(
 						getIdentifierGeneratorFactory(),
 						dialect,
 						defaultCatalog,
 						defaultSchema,
 						(RootClass) pc
 				);
 
 				if ( ig instanceof PersistentIdentifierGenerator ) {
 					generators.put( ( (PersistentIdentifierGenerator) ig ).generatorKey(), ig );
 				}
 				else if ( ig instanceof IdentifierGeneratorAggregator ) {
 					( (IdentifierGeneratorAggregator) ig ).registerPersistentGenerators( generators );
 				}
 			}
 		}
 
 		for ( Collection collection : collections.values() ) {
 			if ( collection.isIdentified() ) {
 				IdentifierGenerator ig = ( ( IdentifierCollection ) collection ).getIdentifier().createIdentifierGenerator(
 						getIdentifierGeneratorFactory(),
 						dialect,
 						defaultCatalog,
 						defaultSchema,
 						null
 				);
 
 				if ( ig instanceof PersistentIdentifierGenerator ) {
 					generators.put( ( (PersistentIdentifierGenerator) ig ).generatorKey(), ig );
 				}
 			}
 		}
 
 		return generators.values().iterator();
 	}
 
 	/**
 	 * Generate DDL for dropping tables
 	 *
 	 * @param dialect The dialect for which to generate the drop script
 
 	 * @return The sequence of DDL commands to drop the schema objects
 
 	 * @throws HibernateException Generally indicates a problem calling {@link #buildMappings()}
 
 	 * @see org.hibernate.tool.hbm2ddl.SchemaExport
 	 */
 	public String[] generateDropSchemaScript(Dialect dialect) throws HibernateException {
 		secondPassCompile();
 
 		String defaultCatalog = properties.getProperty( Environment.DEFAULT_CATALOG );
 		String defaultSchema = properties.getProperty( Environment.DEFAULT_SCHEMA );
 
 		ArrayList<String> script = new ArrayList<String>( 50 );
 
 		// drop them in reverse order in case db needs it done that way...
 		{
 			ListIterator itr = auxiliaryDatabaseObjects.listIterator( auxiliaryDatabaseObjects.size() );
 			while ( itr.hasPrevious() ) {
 				AuxiliaryDatabaseObject object = (AuxiliaryDatabaseObject) itr.previous();
 				if ( object.appliesToDialect( dialect ) ) {
 					script.add( object.sqlDropString( dialect, defaultCatalog, defaultSchema ) );
 				}
 			}
 		}
 
 		if ( dialect.dropConstraints() ) {
 			Iterator itr = getTableMappings();
 			while ( itr.hasNext() ) {
 				Table table = (Table) itr.next();
 				if ( table.isPhysicalTable() ) {
 					Iterator subItr = table.getForeignKeyIterator();
 					while ( subItr.hasNext() ) {
 						ForeignKey fk = (ForeignKey) subItr.next();
 						if ( fk.isPhysicalConstraint() ) {
 							script.add(
 									fk.sqlDropString(
 											dialect,
 											defaultCatalog,
 											defaultSchema
 										)
 								);
 						}
 					}
 				}
 			}
 		}
 
 
 		Iterator itr = getTableMappings();
 		while ( itr.hasNext() ) {
 
 			Table table = (Table) itr.next();
 			if ( table.isPhysicalTable() ) {
 
 				/*Iterator subIter = table.getIndexIterator();
 				while ( subIter.hasNext() ) {
 					Index index = (Index) subIter.next();
 					if ( !index.isForeignKey() || !dialect.hasImplicitIndexForForeignKey() ) {
 						script.add( index.sqlDropString(dialect) );
 					}
 				}*/
 
 				script.add(
 						table.sqlDropString(
 								dialect,
 								defaultCatalog,
 								defaultSchema
 							)
 					);
 
 			}
 
 		}
 
 		itr = iterateGenerators( dialect );
 		while ( itr.hasNext() ) {
 			String[] lines = ( (PersistentIdentifierGenerator) itr.next() ).sqlDropStrings( dialect );
 			script.addAll( Arrays.asList( lines ) );
 		}
 
 		return ArrayHelper.toStringArray( script );
 	}
 
 	/**
 	 * @param dialect The dialect for which to generate the creation script
 	 *
 	 * @return The sequence of DDL commands to create the schema objects
 	 *
 	 * @throws HibernateException Generally indicates a problem calling {@link #buildMappings()}
 	 *
 	 * @see org.hibernate.tool.hbm2ddl.SchemaExport
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public String[] generateSchemaCreationScript(Dialect dialect) throws HibernateException {
 		secondPassCompile();
 
 		ArrayList<String> script = new ArrayList<String>( 50 );
 		String defaultCatalog = properties.getProperty( Environment.DEFAULT_CATALOG );
 		String defaultSchema = properties.getProperty( Environment.DEFAULT_SCHEMA );
 
 		Iterator iter = getTableMappings();
 		while ( iter.hasNext() ) {
 			Table table = (Table) iter.next();
 			if ( table.isPhysicalTable() ) {
 				script.add(
 						table.sqlCreateString(
 								dialect,
 								mapping,
 								defaultCatalog,
 								defaultSchema
 							)
 					);
 				Iterator<String> comments = table.sqlCommentStrings( dialect, defaultCatalog, defaultSchema );
 				while ( comments.hasNext() ) {
 					script.add( comments.next() );
 				}
 			}
 		}
 
 		iter = getTableMappings();
 		while ( iter.hasNext() ) {
 			Table table = (Table) iter.next();
 			if ( table.isPhysicalTable() ) {
 
 				if ( !dialect.supportsUniqueConstraintInCreateAlterTable() ) {
 					Iterator subIter = table.getUniqueKeyIterator();
 					while ( subIter.hasNext() ) {
 						UniqueKey uk = (UniqueKey) subIter.next();
 						String constraintString = uk.sqlCreateString( dialect, mapping, defaultCatalog, defaultSchema );
 						if (constraintString != null) script.add( constraintString );
 					}
 				}
 
 
 				Iterator subIter = table.getIndexIterator();
 				while ( subIter.hasNext() ) {
 					Index index = (Index) subIter.next();
 					script.add(
 							index.sqlCreateString(
 									dialect,
 									mapping,
 									defaultCatalog,
 									defaultSchema
 								)
 						);
 				}
 
 				if ( dialect.hasAlterTable() ) {
 					subIter = table.getForeignKeyIterator();
 					while ( subIter.hasNext() ) {
 						ForeignKey fk = (ForeignKey) subIter.next();
 						if ( fk.isPhysicalConstraint() ) {
 							script.add(
 									fk.sqlCreateString(
 											dialect, mapping,
 											defaultCatalog,
 											defaultSchema
 										)
 								);
 						}
 					}
 				}
 
 			}
 		}
 
 		iter = iterateGenerators( dialect );
 		while ( iter.hasNext() ) {
 			String[] lines = ( (PersistentIdentifierGenerator) iter.next() ).sqlCreateStrings( dialect );
 			script.addAll( Arrays.asList( lines ) );
 		}
 
 		for ( AuxiliaryDatabaseObject auxiliaryDatabaseObject : auxiliaryDatabaseObjects ) {
 			if ( auxiliaryDatabaseObject.appliesToDialect( dialect ) ) {
 				script.add( auxiliaryDatabaseObject.sqlCreateString( dialect, mapping, defaultCatalog, defaultSchema ) );
 			}
 		}
 
 		return ArrayHelper.toStringArray( script );
 	}
 
 	/**
 	 * @param dialect The dialect for which to generate the creation script
 	 * @param databaseMetadata The database catalog information for the database to be updated; needed to work out what
 	 * should be created/altered
 	 *
 	 * @return The sequence of DDL commands to apply the schema objects
 	 *
 	 * @throws HibernateException Generally indicates a problem calling {@link #buildMappings()}
 	 *
 	 * @see org.hibernate.tool.hbm2ddl.SchemaExport
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public String[] generateSchemaUpdateScript(Dialect dialect, DatabaseMetadata databaseMetadata)
 			throws HibernateException {
 		secondPassCompile();
 
 		String defaultCatalog = properties.getProperty( Environment.DEFAULT_CATALOG );
 		String defaultSchema = properties.getProperty( Environment.DEFAULT_SCHEMA );
 
 		ArrayList<String> script = new ArrayList<String>( 50 );
 
 		Iterator iter = getTableMappings();
 		while ( iter.hasNext() ) {
 			Table table = (Table) iter.next();
 			if ( table.isPhysicalTable() ) {
 				
 				TableMetadata tableInfo = databaseMetadata.getTableMetadata(
 						table.getName(),
 						( table.getSchema() == null ) ? defaultSchema : table.getSchema(),
 						( table.getCatalog() == null ) ? defaultCatalog : table.getCatalog(),
 								table.isQuoted()
 
 					);
 				if ( tableInfo == null ) {
 					script.add(
 							table.sqlCreateString(
 									dialect,
 									mapping,
 									defaultCatalog,
 									defaultSchema
 								)
 						);
 				}
 				else {
 					Iterator<String> subiter = table.sqlAlterStrings(
 							dialect,
 							mapping,
 							tableInfo,
 							defaultCatalog,
 							defaultSchema
 						);
 					while ( subiter.hasNext() ) {
 						script.add( subiter.next() );
 					}
 				}
 
 				Iterator<String> comments = table.sqlCommentStrings( dialect, defaultCatalog, defaultSchema );
 				while ( comments.hasNext() ) {
 					script.add( comments.next() );
 				}
 
 			}
 		}
 
 		iter = getTableMappings();
 		while ( iter.hasNext() ) {
 			Table table = (Table) iter.next();
 			if ( table.isPhysicalTable() ) {
 
 				TableMetadata tableInfo = databaseMetadata.getTableMetadata(
 						table.getName(),
 						table.getSchema(),
 						table.getCatalog(),
 						table.isQuoted()
 					);
 
 				if ( dialect.hasAlterTable() ) {
 					Iterator subIter = table.getForeignKeyIterator();
 					while ( subIter.hasNext() ) {
 						ForeignKey fk = (ForeignKey) subIter.next();
 						if ( fk.isPhysicalConstraint() ) {
 							boolean create = tableInfo == null || (
 									tableInfo.getForeignKeyMetadata( fk ) == null && (
 											//Icky workaround for MySQL bug:
 											!( dialect instanceof MySQLDialect ) ||
 													tableInfo.getIndexMetadata( fk.getName() ) == null
 										)
 								);
 							if ( create ) {
 								script.add(
 										fk.sqlCreateString(
 												dialect,
 												mapping,
 												defaultCatalog,
 												defaultSchema
 											)
 									);
 							}
 						}
 					}
 				}
 
 				Iterator subIter = table.getIndexIterator();
 				while ( subIter.hasNext() ) {
 					final Index index = (Index) subIter.next();
 					// Skip if index already exists
 					if ( tableInfo != null && StringHelper.isNotEmpty( index.getName() ) ) {
 						final IndexMetadata meta = tableInfo.getIndexMetadata( index.getName() );
 						if ( meta != null ) {
 							continue;
 						}
 					}
 					script.add(
 							index.sqlCreateString(
 									dialect,
 									mapping,
 									defaultCatalog,
 									defaultSchema
 							)
 					);
 				}
 
 //broken, 'cos we don't generate these with names in SchemaExport
 //				subIter = table.getUniqueKeyIterator();
 //				while ( subIter.hasNext() ) {
 //					UniqueKey uk = (UniqueKey) subIter.next();
 //					if ( tableInfo==null || tableInfo.getIndexMetadata( uk.getFilterName() ) == null ) {
 //						script.add( uk.sqlCreateString(dialect, mapping) );
 //					}
 //				}
 			}
 		}
 
 		iter = iterateGenerators( dialect );
 		while ( iter.hasNext() ) {
 			PersistentIdentifierGenerator generator = (PersistentIdentifierGenerator) iter.next();
 			Object key = generator.generatorKey();
 			if ( !databaseMetadata.isSequence( key ) && !databaseMetadata.isTable( key ) ) {
 				String[] lines = generator.sqlCreateStrings( dialect );
 				script.addAll( Arrays.asList( lines ) );
 			}
 		}
 
 		return ArrayHelper.toStringArray( script );
 	}
 
 	public void validateSchema(Dialect dialect, DatabaseMetadata databaseMetadata)throws HibernateException {
 		secondPassCompile();
 
 		String defaultCatalog = properties.getProperty( Environment.DEFAULT_CATALOG );
 		String defaultSchema = properties.getProperty( Environment.DEFAULT_SCHEMA );
 		
 		Iterator iter = getTableMappings();
 		while ( iter.hasNext() ) {
 			Table table = (Table) iter.next();
 			if ( table.isPhysicalTable() ) {
 				
 
 				TableMetadata tableInfo = databaseMetadata.getTableMetadata(
 						table.getName(),
 						( table.getSchema() == null ) ? defaultSchema : table.getSchema(),
 						( table.getCatalog() == null ) ? defaultCatalog : table.getCatalog(),
 								table.isQuoted());
 				if ( tableInfo == null ) {
 					throw new HibernateException( "Missing table: " + table.getName() );
 				}
 				else {
 					table.validateColumns( dialect, mapping, tableInfo );
 				}
 
 			}
 		}
 
 		iter = iterateGenerators( dialect );
 		while ( iter.hasNext() ) {
 			PersistentIdentifierGenerator generator = (PersistentIdentifierGenerator) iter.next();
 			Object key = generator.generatorKey();
 			if ( !databaseMetadata.isSequence( key ) && !databaseMetadata.isTable( key ) ) {
 				throw new HibernateException( "Missing sequence or table: " + key );
 			}
 		}
 	}
 
 	private void validate() throws MappingException {
 		Iterator iter = classes.values().iterator();
 		while ( iter.hasNext() ) {
 			( (PersistentClass) iter.next() ).validate( mapping );
 		}
 		iter = collections.values().iterator();
 		while ( iter.hasNext() ) {
 			( (Collection) iter.next() ).validate( mapping );
 		}
 	}
 
 	/**
 	 * Call this to ensure the mappings are fully compiled/built. Usefull to ensure getting
 	 * access to all information in the metamodel when calling e.g. getClassMappings().
 	 */
 	public void buildMappings() {
 		secondPassCompile();
 	}
 
 	protected void secondPassCompile() throws MappingException {
 		log.trace( "Starting secondPassCompile() processing" );
 
 		//process default values first
 		{
 			if ( !isDefaultProcessed ) {
 				//use global delimiters if orm.xml declare it
 				final Object isDelimited = reflectionManager.getDefaults().get( "delimited-identifier" );
 				if ( isDelimited != null && isDelimited == Boolean.TRUE ) {
 					getProperties().put( Environment.GLOBALLY_QUOTED_IDENTIFIERS, "true" );
 				}
 
 				AnnotationBinder.bindDefaults( createMappings() );
 				isDefaultProcessed = true;
 			}
 		}
 
 		// process metadata queue
 		{
 			metadataSourceQueue.syncAnnotatedClasses();
 			metadataSourceQueue.processMetadata( determineMetadataSourcePrecedence() );
 		}
 
 		// process cache queue
 		{
 			for ( CacheHolder holder : caches ) {
 				if ( holder.isClass ) {
 					applyCacheConcurrencyStrategy( holder );
 				}
 				else {
 					applyCollectionCacheConcurrencyStrategy( holder );
 				}
 			}
 			caches.clear();
 		}
 
 		try {
 			inSecondPass = true;
 			processSecondPassesOfType( PkDrivenByDefaultMapsIdSecondPass.class );
 			processSecondPassesOfType( SetSimpleValueTypeSecondPass.class );
 			processSecondPassesOfType( CopyIdentifierComponentSecondPass.class );
 			processFkSecondPassInOrder();
 			processSecondPassesOfType( CreateKeySecondPass.class );
 			processSecondPassesOfType( SecondaryTableSecondPass.class );
 
 			originalSecondPassCompile();
 
 			inSecondPass = false;
 		}
 		catch ( RecoverableException e ) {
 			//the exception was not recoverable after all
 			throw ( RuntimeException ) e.getCause();
 		}
 
 		for ( Map.Entry<Table, List<UniqueConstraintHolder>> tableListEntry : uniqueConstraintHoldersByTable.entrySet() ) {
 			final Table table = tableListEntry.getKey();
 			final List<UniqueConstraintHolder> uniqueConstraints = tableListEntry.getValue();
 			int uniqueIndexPerTable = 0;
 			for ( UniqueConstraintHolder holder : uniqueConstraints ) {
 				uniqueIndexPerTable++;
 				final String keyName = StringHelper.isEmpty( holder.getName() )
 						? "key" + uniqueIndexPerTable
 						: holder.getName();
 				buildUniqueKeyFromColumnNames( table, keyName, holder.getColumns() );
 			}
 		}
 
 		applyConstraintsToDDL();
 	}
 
 	private void processSecondPassesOfType(Class<? extends SecondPass> type) {
 		Iterator iter = secondPasses.iterator();
 		while ( iter.hasNext() ) {
 			SecondPass sp = ( SecondPass ) iter.next();
 			//do the second pass of simple value types first and remove them
 			if ( type.isInstance( sp ) ) {
 				sp.doSecondPass( classes );
 				iter.remove();
 			}
 		}
 	}
 
 	/**
 	 * Processes FKSecondPass instances trying to resolve any
 	 * graph circularity (ie PK made of a many to one linking to
 	 * an entity having a PK made of a ManyToOne ...).
 	 */
 	private void processFkSecondPassInOrder() {
 		log.debug( "processing fk mappings (*ToOne and JoinedSubclass)" );
 		List<FkSecondPass> fkSecondPasses = getFKSecondPassesOnly();
 
 		if ( fkSecondPasses.size() == 0 ) {
 			return; // nothing to do here
 		}
 
 		// split FkSecondPass instances into primary key and non primary key FKs.
 		// While doing so build a map of class names to FkSecondPass instances depending on this class.
 		Map<String, Set<FkSecondPass>> isADependencyOf = new HashMap<String, Set<FkSecondPass>>();
 		List<FkSecondPass> endOfQueueFkSecondPasses = new ArrayList<FkSecondPass>( fkSecondPasses.size() );
 		for ( FkSecondPass sp : fkSecondPasses ) {
 			if ( sp.isInPrimaryKey() ) {
 				String referenceEntityName = sp.getReferencedEntityName();
 				PersistentClass classMapping = getClassMapping( referenceEntityName );
 				String dependentTable = classMapping.getTable().getQuotedName();
 				if ( !isADependencyOf.containsKey( dependentTable ) ) {
 					isADependencyOf.put( dependentTable, new HashSet<FkSecondPass>() );
 				}
 				isADependencyOf.get( dependentTable ).add( sp );
 			}
 			else {
 				endOfQueueFkSecondPasses.add( sp );
 			}
 		}
 
 		// using the isADependencyOf map we order the FkSecondPass recursively instances into the right order for processing
 		List<FkSecondPass> orderedFkSecondPasses = new ArrayList<FkSecondPass>( fkSecondPasses.size() );
 		for ( String tableName : isADependencyOf.keySet() ) {
 			buildRecursiveOrderedFkSecondPasses( orderedFkSecondPasses, isADependencyOf, tableName, tableName );
 		}
 
 		// process the ordered FkSecondPasses
 		for ( FkSecondPass sp : orderedFkSecondPasses ) {
 			sp.doSecondPass( classes );
 		}
 
 		processEndOfQueue( endOfQueueFkSecondPasses );
 	}
 
 	/**
 	 * @return Returns a list of all <code>secondPasses</code> instances which are a instance of
 	 *         <code>FkSecondPass</code>.
 	 */
 	private List<FkSecondPass> getFKSecondPassesOnly() {
 		Iterator iter = secondPasses.iterator();
 		List<FkSecondPass> fkSecondPasses = new ArrayList<FkSecondPass>( secondPasses.size() );
 		while ( iter.hasNext() ) {
 			SecondPass sp = ( SecondPass ) iter.next();
 			//do the second pass of fk before the others and remove them
 			if ( sp instanceof FkSecondPass ) {
 				fkSecondPasses.add( ( FkSecondPass ) sp );
 				iter.remove();
 			}
 		}
 		return fkSecondPasses;
 	}
 
 	/**
 	 * Recursively builds a list of FkSecondPass instances ready to be processed in this order.
 	 * Checking all dependencies recursively seems quite expensive, but the original code just relied
 	 * on some sort of table name sorting which failed in certain circumstances.
 	 * <p/>
 	 * See <tt>ANN-722</tt> and <tt>ANN-730</tt>
 	 *
 	 * @param orderedFkSecondPasses The list containing the <code>FkSecondPass<code> instances ready
 	 * for processing.
 	 * @param isADependencyOf Our lookup data structure to determine dependencies between tables
 	 * @param startTable Table name to start recursive algorithm.
 	 * @param currentTable The current table name used to check for 'new' dependencies.
 	 */
 	private void buildRecursiveOrderedFkSecondPasses(
 			List<FkSecondPass> orderedFkSecondPasses,
 			Map<String, Set<FkSecondPass>> isADependencyOf,
 			String startTable,
 			String currentTable) {
 
 		Set<FkSecondPass> dependencies = isADependencyOf.get( currentTable );
 
 		// bottom out
 		if ( dependencies == null || dependencies.size() == 0 ) {
 			return;
 		}
 
 		for ( FkSecondPass sp : dependencies ) {
 			String dependentTable = sp.getValue().getTable().getQuotedName();
 			if ( dependentTable.compareTo( startTable ) == 0 ) {
 				StringBuilder sb = new StringBuilder(
 						"Foreign key circularity dependency involving the following tables: "
 				);
 				throw new AnnotationException( sb.toString() );
 			}
 			buildRecursiveOrderedFkSecondPasses( orderedFkSecondPasses, isADependencyOf, startTable, dependentTable );
 			if ( !orderedFkSecondPasses.contains( sp ) ) {
 				orderedFkSecondPasses.add( 0, sp );
 			}
 		}
 	}
 
 	private void processEndOfQueue(List<FkSecondPass> endOfQueueFkSecondPasses) {
 		/*
 		 * If a second pass raises a recoverableException, queue it for next round
 		 * stop of no pass has to be processed or if the number of pass to processes
 		 * does not diminish between two rounds.
 		 * If some failing pass remain, raise the original exception
 		 */
 		boolean stopProcess = false;
 		RuntimeException originalException = null;
 		while ( !stopProcess ) {
 			List<FkSecondPass> failingSecondPasses = new ArrayList<FkSecondPass>();
 			Iterator<FkSecondPass> it = endOfQueueFkSecondPasses.listIterator();
 			while ( it.hasNext() ) {
 				final FkSecondPass pass = it.next();
 				try {
 					pass.doSecondPass( classes );
 				}
 				catch ( RecoverableException e ) {
 					failingSecondPasses.add( pass );
 					if ( originalException == null ) {
 						originalException = ( RuntimeException ) e.getCause();
 					}
 				}
 			}
 			stopProcess = failingSecondPasses.size() == 0 || failingSecondPasses.size() == endOfQueueFkSecondPasses.size();
 			endOfQueueFkSecondPasses = failingSecondPasses;
 		}
 		if ( endOfQueueFkSecondPasses.size() > 0 ) {
 			throw originalException;
 		}
 	}
 
 	private void buildUniqueKeyFromColumnNames(Table table, String keyName, String[] columnNames) {
 		keyName = normalizer.normalizeIdentifierQuoting( keyName );
 
 		UniqueKey uc;
 		int size = columnNames.length;
 		Column[] columns = new Column[size];
 		Set<Column> unbound = new HashSet<Column>();
 		Set<Column> unboundNoLogical = new HashSet<Column>();
 		for ( int index = 0; index < size; index++ ) {
 			final String logicalColumnName = normalizer.normalizeIdentifierQuoting( columnNames[index] );
 			try {
 				final String columnName = createMappings().getPhysicalColumnName( logicalColumnName, table );
 				columns[index] = new Column( columnName );
 				unbound.add( columns[index] );
 				//column equals and hashcode is based on column name
 			}
 			catch ( MappingException e ) {
 				unboundNoLogical.add( new Column( logicalColumnName ) );
 			}
 		}
 		for ( Column column : columns ) {
 			if ( table.containsColumn( column ) ) {
 				uc = table.getOrCreateUniqueKey( keyName );
 				uc.addColumn( table.getColumn( column ) );
 				unbound.remove( column );
 			}
 		}
 		if ( unbound.size() > 0 || unboundNoLogical.size() > 0 ) {
 			StringBuilder sb = new StringBuilder( "Unable to create unique key constraint (" );
 			for ( String columnName : columnNames ) {
 				sb.append( columnName ).append( ", " );
 			}
 			sb.setLength( sb.length() - 2 );
 			sb.append( ") on table " ).append( table.getName() ).append( ": " );
 			for ( Column column : unbound ) {
 				sb.append( column.getName() ).append( ", " );
 			}
 			for ( Column column : unboundNoLogical ) {
 				sb.append( column.getName() ).append( ", " );
 			}
 			sb.setLength( sb.length() - 2 );
 			sb.append( " not found" );
 			throw new AnnotationException( sb.toString() );
 		}
 	}
 
 	private void applyConstraintsToDDL() {
 		boolean applyOnDdl = getProperties().getProperty(
 				"hibernate.validator.apply_to_ddl",
 				"true"
 		)
 				.equalsIgnoreCase( "true" );
 
 		if ( !applyOnDdl ) {
 			return; // nothing to do in this case
 		}
 		applyHibernateValidatorLegacyConstraintsOnDDL();
 		applyBeanValidationConstraintsOnDDL();
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	private void applyHibernateValidatorLegacyConstraintsOnDDL() {
 		//TODO search for the method only once and cache it?
 		Constructor validatorCtr = null;
 		Method applyMethod = null;
 		try {
 			Class classValidator = ReflectHelper.classForName(
 					"org.hibernate.validator.ClassValidator", this.getClass()
 			);
 			Class messageInterpolator = ReflectHelper.classForName(
 					"org.hibernate.validator.MessageInterpolator", this.getClass()
 			);
 			validatorCtr = classValidator.getDeclaredConstructor(
 					Class.class, ResourceBundle.class, messageInterpolator, Map.class, ReflectionManager.class
 			);
 			applyMethod = classValidator.getMethod( "apply", PersistentClass.class );
 		}
 		catch ( ClassNotFoundException e ) {
 			if ( !isValidatorNotPresentLogged ) {
 				log.info( "Hibernate Validator not found: ignoring" );
 			}
 			isValidatorNotPresentLogged = true;
 		}
 		catch ( NoSuchMethodException e ) {
 			throw new AnnotationException( e );
 		}
 		if ( applyMethod != null ) {
 			for ( PersistentClass persistentClazz : classes.values() ) {
 				//integrate the validate framework
 				String className = persistentClazz.getClassName();
 				if ( StringHelper.isNotEmpty( className ) ) {
 					try {
 						Object validator = validatorCtr.newInstance(
 								ReflectHelper.classForName( className ), null, null, null, reflectionManager
 						);
 						applyMethod.invoke( validator, persistentClazz );
 					}
 					catch ( Exception e ) {
 						log.warn( "Unable to apply constraints on DDL for " + className, e );
 					}
 				}
 			}
 		}
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	private void applyBeanValidationConstraintsOnDDL() {
 		BeanValidationActivator.applyDDL( classes.values(), getProperties() );
 	}
 
 	private void originalSecondPassCompile() throws MappingException {
 		log.debug( "processing extends queue" );
 		processExtendsQueue();
 
 		log.debug( "processing collection mappings" );
 		Iterator itr = secondPasses.iterator();
 		while ( itr.hasNext() ) {
 			SecondPass sp = (SecondPass) itr.next();
 			if ( ! (sp instanceof QuerySecondPass) ) {
 				sp.doSecondPass( classes );
 				itr.remove();
 			}
 		}
 
 		log.debug( "processing native query and ResultSetMapping mappings" );
 		itr = secondPasses.iterator();
 		while ( itr.hasNext() ) {
 			SecondPass sp = (SecondPass) itr.next();
 			sp.doSecondPass( classes );
 			itr.remove();
 		}
 
 		log.debug( "processing association property references" );
 
 		itr = propertyReferences.iterator();
 		while ( itr.hasNext() ) {
 			Mappings.PropertyReference upr = (Mappings.PropertyReference) itr.next();
 
 			PersistentClass clazz = getClassMapping( upr.referencedClass );
 			if ( clazz == null ) {
 				throw new MappingException(
 						"property-ref to unmapped class: " +
 						upr.referencedClass
 					);
 			}
 
 			Property prop = clazz.getReferencedProperty( upr.propertyName );
 			if ( upr.unique ) {
 				( (SimpleValue) prop.getValue() ).setAlternateUniqueKey( true );
 			}
 		}
 
 		//TODO: Somehow add the newly created foreign keys to the internal collection
 
 		log.debug( "processing foreign key constraints" );
 
 		itr = getTableMappings();
 		Set done = new HashSet();
 		while ( itr.hasNext() ) {
 			secondPassCompileForeignKeys( (Table) itr.next(), done );
 		}
 
 	}
 
 	private int processExtendsQueue() {
 		log.debug( "processing extends queue" );
 		int added = 0;
 		ExtendsQueueEntry extendsQueueEntry = findPossibleExtends();
 		while ( extendsQueueEntry != null ) {
 			metadataSourceQueue.processHbmXml( extendsQueueEntry.getMetadataXml(), extendsQueueEntry.getEntityNames() );
 			extendsQueueEntry = findPossibleExtends();
 		}
 
 		if ( extendsQueue.size() > 0 ) {
 			Iterator iterator = extendsQueue.keySet().iterator();
 			StringBuffer buf = new StringBuffer( "Following super classes referenced in extends not found: " );
 			while ( iterator.hasNext() ) {
 				final ExtendsQueueEntry entry = ( ExtendsQueueEntry ) iterator.next();
 				buf.append( entry.getExplicitName() );
 				if ( entry.getMappingPackage() != null ) {
 					buf.append( "[" ).append( entry.getMappingPackage() ).append( "]" );
 				}
 				if ( iterator.hasNext() ) {
 					buf.append( "," );
 				}
 			}
 			throw new MappingException( buf.toString() );
 		}
 
 		return added;
 	}
 
 	protected ExtendsQueueEntry findPossibleExtends() {
 		Iterator<ExtendsQueueEntry> itr = extendsQueue.keySet().iterator();
 		while ( itr.hasNext() ) {
 			final ExtendsQueueEntry entry = itr.next();
 			boolean found = getClassMapping( entry.getExplicitName() ) != null
 					|| getClassMapping( HbmBinder.getClassName( entry.getExplicitName(), entry.getMappingPackage() ) ) != null;
 			if ( found ) {
 				itr.remove();
 				return entry;
 			}
 		}
 		return null;
 	}
 
 	protected void secondPassCompileForeignKeys(Table table, Set done) throws MappingException {
 		table.createForeignKeys();
 		Iterator iter = table.getForeignKeyIterator();
 		while ( iter.hasNext() ) {
 
 			ForeignKey fk = (ForeignKey) iter.next();
 			if ( !done.contains( fk ) ) {
 				done.add( fk );
 				final String referencedEntityName = fk.getReferencedEntityName();
 				if ( referencedEntityName == null ) {
 					throw new MappingException(
 							"An association from the table " +
 							fk.getTable().getName() +
 							" does not specify the referenced entity"
 						);
 				}
 				if ( log.isDebugEnabled() ) {
 					log.debug( "resolving reference to class: " + referencedEntityName );
 				}
 				PersistentClass referencedClass = classes.get( referencedEntityName );
 				if ( referencedClass == null ) {
 					throw new MappingException(
 							"An association from the table " +
 							fk.getTable().getName() +
 							" refers to an unmapped class: " +
 							referencedEntityName
 						);
 				}
 				if ( referencedClass.isJoinedSubclass() ) {
 					secondPassCompileForeignKeys( referencedClass.getSuperclass().getTable(), done );
 				}
 				fk.setReferencedTable( referencedClass.getTable() );
 				fk.alignColumns();
 			}
 		}
 	}
 
 	public Map<String, NamedQueryDefinition> getNamedQueries() {
 		return namedQueries;
 	}
 
 	/**
 	 * Create a {@link SessionFactory} using the properties and mappings in this configuration. The
 	 * {@link SessionFactory} will be immutable, so changes made to {@code this} {@link Configuration} after
 	 * building the {@link SessionFactory} will not affect it.
 	 *
 	 * @return The build {@link SessionFactory}
 	 *
 	 * @throws HibernateException usually indicates an invalid configuration or invalid mapping information
 	 */
-	public SessionFactory buildSessionFactory() throws HibernateException {
+	public SessionFactory buildSessionFactory(ServicesRegistry serviceRegistry) throws HibernateException {
 		log.debug( "Preparing to build session factory with filters : " + filterDefinitions );
 
 		secondPassCompile();
 		if ( ! metadataSourceQueue.isEmpty() ) {
 			log.warn( "mapping metadata cache was not completely processed" );
 		}
 
 		enableLegacyHibernateValidator();
 		enableBeanValidation();
 		enableHibernateSearch();
 
 		validate();
 		Environment.verifyProperties( properties );
 		Properties copy = new Properties();
 		copy.putAll( properties );
 		ConfigurationHelper.resolvePlaceHolders( copy );
-		Settings settings = buildSettings( copy );
+		Settings settings = buildSettings( copy, serviceRegistry.getService( JdbcServices.class ).getConnectionProvider() );
 
 		return new SessionFactoryImpl(
 				this,
 				mapping,
+				serviceRegistry,
 				settings,
 				getInitializedEventListeners(),
 				sessionFactoryObserver
 			);
 	}
 
 	private static final String LEGACY_VALIDATOR_EVENT_LISTENER = "org.hibernate.validator.event.ValidateEventListener";
 
 	private void enableLegacyHibernateValidator() {
 		//add validator events if the jar is available
 		boolean enableValidatorListeners = !"false".equalsIgnoreCase(
 				getProperty(
 						"hibernate.validator.autoregister_listeners"
 				)
 		);
 		Class validateEventListenerClass = null;
 		try {
 			validateEventListenerClass = ReflectHelper.classForName( LEGACY_VALIDATOR_EVENT_LISTENER, Configuration.class );
 		}
 		catch ( ClassNotFoundException e ) {
 			//validator is not present
 			log.debug( "Legacy Validator not present in classpath, ignoring event listener registration" );
 		}
 		if ( enableValidatorListeners && validateEventListenerClass != null ) {
 			//TODO so much duplication
 			Object validateEventListener;
 			try {
 				validateEventListener = validateEventListenerClass.newInstance();
 			}
 			catch ( Exception e ) {
 				throw new AnnotationException( "Unable to load Validator event listener", e );
 			}
 			{
 				boolean present = false;
 				PreInsertEventListener[] listeners = getEventListeners().getPreInsertEventListeners();
 				if ( listeners != null ) {
 					for ( Object eventListener : listeners ) {
 						//not isAssignableFrom since the user could subclass
 						present = present || validateEventListenerClass == eventListener.getClass();
 					}
 					if ( !present ) {
 						int length = listeners.length + 1;
 						PreInsertEventListener[] newListeners = new PreInsertEventListener[length];
 						System.arraycopy( listeners, 0, newListeners, 0, length - 1 );
 						newListeners[length - 1] = ( PreInsertEventListener ) validateEventListener;
 						getEventListeners().setPreInsertEventListeners( newListeners );
 					}
 				}
 				else {
 					getEventListeners().setPreInsertEventListeners(
 							new PreInsertEventListener[] { ( PreInsertEventListener ) validateEventListener }
 					);
 				}
 			}
 
 			//update event listener
 			{
 				boolean present = false;
 				PreUpdateEventListener[] listeners = getEventListeners().getPreUpdateEventListeners();
 				if ( listeners != null ) {
 					for ( Object eventListener : listeners ) {
 						//not isAssignableFrom since the user could subclass
 						present = present || validateEventListenerClass == eventListener.getClass();
 					}
 					if ( !present ) {
 						int length = listeners.length + 1;
 						PreUpdateEventListener[] newListeners = new PreUpdateEventListener[length];
 						System.arraycopy( listeners, 0, newListeners, 0, length - 1 );
 						newListeners[length - 1] = ( PreUpdateEventListener ) validateEventListener;
 						getEventListeners().setPreUpdateEventListeners( newListeners );
 					}
 				}
 				else {
 					getEventListeners().setPreUpdateEventListeners(
 							new PreUpdateEventListener[] { ( PreUpdateEventListener ) validateEventListener }
 					);
 				}
 			}
 		}
 	}
 
 	private void enableBeanValidation() {
 		BeanValidationActivator.activateBeanValidation( getEventListeners(), getProperties() );
 	}
 
 	private static final String SEARCH_EVENT_LISTENER_REGISTERER_CLASS = "org.hibernate.cfg.search.HibernateSearchEventListenerRegister";
 
 	/**
 	 * Tries to automatically register Hibernate Search event listeners by locating the
 	 * appropriate bootstrap class and calling the <code>enableHibernateSearch</code> method.
 	 */
 	private void enableHibernateSearch() {
 		// load the bootstrap class
 		Class searchStartupClass;
 		try {
 			searchStartupClass = ReflectHelper.classForName( SEARCH_STARTUP_CLASS, getClass() );
 		}
 		catch ( ClassNotFoundException e ) {
 			// TODO remove this together with SearchConfiguration after 3.1.0 release of Search
 			// try loading deprecated HibernateSearchEventListenerRegister
 			try {
 				searchStartupClass = ReflectHelper.classForName( SEARCH_EVENT_LISTENER_REGISTERER_CLASS, getClass() );
 			}
 			catch ( ClassNotFoundException cnfe ) {
 				log.debug( "Search not present in classpath, ignoring event listener registration." );
 				return;
 			}
 		}
 
 		// call the method for registering the listeners
 		try {
 			Object searchStartupInstance = searchStartupClass.newInstance();
 			Method enableSearchMethod = searchStartupClass.getDeclaredMethod(
 					SEARCH_STARTUP_METHOD,
 					EventListeners.class,
 					Properties.class
 			);
 			enableSearchMethod.invoke( searchStartupInstance, getEventListeners(), getProperties() );
 		}
 		catch ( InstantiationException e ) {
 			log.debug( "Unable to instantiate {}, ignoring event listener registration.", SEARCH_STARTUP_CLASS );
 		}
 		catch ( IllegalAccessException e ) {
 			log.debug( "Unable to instantiate {}, ignoring event listener registration.", SEARCH_STARTUP_CLASS );
 		}
 		catch ( NoSuchMethodException e ) {
 			log.debug( "Method enableHibernateSearch() not found in {}.", SEARCH_STARTUP_CLASS );
 		}
 		catch ( InvocationTargetException e ) {
 			log.debug( "Unable to execute {}, ignoring event listener registration.", SEARCH_STARTUP_METHOD );
 		}
 	}
 
 	private EventListeners getInitializedEventListeners() {
 		EventListeners result = (EventListeners) eventListeners.shallowCopy();
 		result.initializeListeners( this );
 		return result;
 	}
 
 	/**
 	 * Rterieve the configured {@link Interceptor}.
 	 *
 	 * @return The current {@link Interceptor}
 	 */
 	public Interceptor getInterceptor() {
 		return interceptor;
 	}
 
 	/**
 	 * Set the current {@link Interceptor}
 	 *
 	 * @param interceptor The {@link Interceptor} to use for the {@link #buildSessionFactory() built}
 	 * {@link SessionFactory}.
 	 *
 	 * @return this for method chaining
 	 */
 	public Configuration setInterceptor(Interceptor interceptor) {
 		this.interceptor = interceptor;
 		return this;
 	}
 
 	/**
 	 * Get all properties
 	 *
 	 * @return all properties
 	 */
 	public Properties getProperties() {
 		return properties;
 	}
 
 	/**
 	 * Get a property value by name
 	 *
 	 * @param propertyName The name of the property
 	 *
 	 * @return The value curently associated with that property name; may be null.
 	 */
 	public String getProperty(String propertyName) {
 		return properties.getProperty( propertyName );
 	}
 
 	/**
 	 * Specify a completely new set of properties
 	 *
 	 * @param properties The new set of properties
 	 *
 	 * @return this for method chaining
 	 */
 	public Configuration setProperties(Properties properties) {
 		this.properties = properties;
 		return this;
 	}
 
 	/**
 	 * Add the given properties to ours.
 	 *
 	 * @param extraProperties The properties to add.
 	 *
 	 * @return this for method chaining
 	 *
 	 */
 	public Configuration addProperties(Properties extraProperties) {
 		this.properties.putAll( extraProperties );
 		return this;
 	}
 
 	/**
 	 * Adds the incoming properties to the internal properties structure, as long as the internal structure does not
 	 * already contain an entry for the given key.
 	 *
 	 * @param properties The properties to merge
 	 *
 	 * @return this for ethod chaining
 	 */
 	public Configuration mergeProperties(Properties properties) {
 		for ( Map.Entry entry : properties.entrySet() ) {
 			if ( this.properties.containsKey( entry.getKey() ) ) {
 				continue;
 			}
 			this.properties.setProperty( (String) entry.getKey(), (String) entry.getValue() );
 		}
 		return this;
 	}
 
 	/**
 	 * Set a property value by name
 	 *
 	 * @param propertyName The name of the property to set
 	 * @param value The new property value
 	 *
 	 * @return this for method chaining
 	 */
 	public Configuration setProperty(String propertyName, String value) {
 		properties.setProperty( propertyName, value );
 		return this;
 	}
 
 	private void addProperties(Element parent) {
 		Iterator itr = parent.elementIterator( "property" );
 		while ( itr.hasNext() ) {
 			Element node = (Element) itr.next();
 			String name = node.attributeValue( "name" );
 			String value = node.getText().trim();
 			log.debug( name + "=" + value );
 			properties.setProperty( name, value );
 			if ( !name.startsWith( "hibernate" ) ) {
 				properties.setProperty( "hibernate." + name, value );
 			}
 		}
 		Environment.verifyProperties( properties );
 	}
 
 	/**
 	 * Use the mappings and properties specified in an application resource named <tt>hibernate.cfg.xml</tt>.
 	 *
 	 * @return this for method chaining
 	 *
 	 * @throws HibernateException Generally indicates we cannot find <tt>hibernate.cfg.xml</tt>
 	 *
 	 * @see #configure(String)
 	 */
 	public Configuration configure() throws HibernateException {
 		configure( "/hibernate.cfg.xml" );
 		return this;
 	}
 
 	/**
 	 * Use the mappings and properties specified in the given application resource. The format of the resource is
 	 * defined in <tt>hibernate-configuration-3.0.dtd</tt>.
 	 * <p/>
 	 * The resource is found via {@link #getConfigurationInputStream}
 	 *
 	 * @param resource The resource to use
 	 *
 	 * @return this for method chaining
 	 *
 	 * @throws HibernateException Generally indicates we cannot find the named resource
 	 *
 	 * @see #doConfigure(java.io.InputStream, String)
 	 */
 	public Configuration configure(String resource) throws HibernateException {
 		log.info( "configuring from resource: " + resource );
 		InputStream stream = getConfigurationInputStream( resource );
 		return doConfigure( stream, resource );
 	}
 
 	/**
 	 * Get the configuration file as an <tt>InputStream</tt>. Might be overridden
 	 * by subclasses to allow the configuration to be located by some arbitrary
 	 * mechanism.
 	 * <p/>
 	 * By default here we use classpath resource resolution
 	 *
 	 * @param resource The resource to locate
 	 *
 	 * @return The stream
 	 *
 	 * @throws HibernateException Generally indicates we cannot find the named resource
 	 */
 	protected InputStream getConfigurationInputStream(String resource) throws HibernateException {
 		log.info( "Configuration resource: " + resource );
 		return ConfigHelper.getResourceAsStream( resource );
 	}
 
 	/**
 	 * Use the mappings and properties specified in the given document. The format of the document is defined in
 	 * <tt>hibernate-configuration-3.0.dtd</tt>.
 	 *
 	 * @param url URL from which you wish to load the configuration
 	 *
 	 * @return this for method chaining
 	 *
 	 * @throws HibernateException Generally indicates a problem access the url
 	 *
 	 * @see #doConfigure(java.io.InputStream, String)
 	 */
 	public Configuration configure(URL url) throws HibernateException {
 		log.info( "configuring from url: " + url.toString() );
 		try {
 			return doConfigure( url.openStream(), url.toString() );
 		}
 		catch (IOException ioe) {
 			throw new HibernateException( "could not configure from URL: " + url, ioe );
 		}
 	}
 
 	/**
 	 * Use the mappings and properties specified in the given application file. The format of the file is defined in
 	 * <tt>hibernate-configuration-3.0.dtd</tt>.
 	 *
 	 * @param configFile File from which you wish to load the configuration
 	 *
 	 * @return this for method chaining
 	 *
 	 * @throws HibernateException Generally indicates a problem access the file
 	 *
 	 * @see #doConfigure(java.io.InputStream, String)
 	 */
 	public Configuration configure(File configFile) throws HibernateException {
 		log.info( "configuring from file: " + configFile.getName() );
 		try {
 			return doConfigure( new FileInputStream( configFile ), configFile.toString() );
 		}
 		catch (FileNotFoundException fnfe) {
 			throw new HibernateException( "could not find file: " + configFile, fnfe );
 		}
 	}
 
 	/**
 	 * Configure this configuration's state from the contents of the given input stream.  The expectation is that
 	 * the stream contents represent an XML document conforming to the Hibernate Configuration DTD.  See
 	 * {@link #doConfigure(Document)} for further details.
 	 *
 	 * @param stream The input stream from which to read
 	 * @param resourceName The name to use in warning/error messages
 	 *
 	 * @return this for method chaining
 	 *
 	 * @throws HibernateException Indicates a problem reading the stream contents.
 	 */
 	protected Configuration doConfigure(InputStream stream, String resourceName) throws HibernateException {
 		try {
 			List errors = new ArrayList();
 			Document document = xmlHelper.createSAXReader( resourceName, errors, entityResolver )
 					.read( new InputSource( stream ) );
 			if ( errors.size() != 0 ) {
 				throw new MappingException( "invalid configuration", (Throwable) errors.get( 0 ) );
 			}
 			doConfigure( document );
 		}
 		catch (DocumentException e) {
 			throw new HibernateException( "Could not parse configuration: " + resourceName, e );
 		}
 		finally {
 			try {
 				stream.close();
 			}
 			catch (IOException ioe) {
 				log.warn( "could not close input stream for: " + resourceName, ioe );
 			}
 		}
 		return this;
 	}
 
 	/**
 	 * Use the mappings and properties specified in the given XML document.
 	 * The format of the file is defined in
 	 * <tt>hibernate-configuration-3.0.dtd</tt>.
 	 *
 	 * @param document an XML document from which you wish to load the configuration
 	 * @return A configuration configured via the <tt>Document</tt>
 	 * @throws HibernateException if there is problem in accessing the file.
 	 */
 	public Configuration configure(org.w3c.dom.Document document) throws HibernateException {
 		log.info( "configuring from XML document" );
 		return doConfigure( xmlHelper.createDOMReader().read( document ) );
 	}
 
 	/**
 	 * Parse a dom4j document conforming to the Hibernate Configuration DTD (<tt>hibernate-configuration-3.0.dtd</tt>)
 	 * and use its information to configure this {@link Configuration}'s state
 	 *
 	 * @param doc The dom4j document
 	 *
 	 * @return this for method chaining
 	 *
 	 * @throws HibernateException Indicates a problem performing the configuration task
 	 */
 	protected Configuration doConfigure(Document doc) throws HibernateException {
 		Element sfNode = doc.getRootElement().element( "session-factory" );
 		String name = sfNode.attributeValue( "name" );
 		if ( name != null ) {
 			properties.setProperty( Environment.SESSION_FACTORY_NAME, name );
 		}
 		addProperties( sfNode );
 		parseSessionFactory( sfNode, name );
 
 		Element secNode = doc.getRootElement().element( "security" );
 		if ( secNode != null ) {
 			parseSecurity( secNode );
 		}
 
 		log.info( "Configured SessionFactory: " + name );
 		log.debug( "properties: " + properties );
 
 		return this;
 	}
 
 
 	private void parseSessionFactory(Element sfNode, String name) {
 		Iterator elements = sfNode.elementIterator();
 		while ( elements.hasNext() ) {
 			Element subelement = (Element) elements.next();
 			String subelementName = subelement.getName();
 			if ( "mapping".equals( subelementName ) ) {
 				parseMappingElement( subelement, name );
 			}
 			else if ( "class-cache".equals( subelementName ) ) {
 				String className = subelement.attributeValue( "class" );
 				Attribute regionNode = subelement.attribute( "region" );
 				final String region = ( regionNode == null ) ? className : regionNode.getValue();
 				boolean includeLazy = !"non-lazy".equals( subelement.attributeValue( "include" ) );
 				setCacheConcurrencyStrategy( className, subelement.attributeValue( "usage" ), region, includeLazy );
 			}
 			else if ( "collection-cache".equals( subelementName ) ) {
 				String role = subelement.attributeValue( "collection" );
 				Attribute regionNode = subelement.attribute( "region" );
 				final String region = ( regionNode == null ) ? role : regionNode.getValue();
 				setCollectionCacheConcurrencyStrategy( role, subelement.attributeValue( "usage" ), region );
 			}
 			else if ( "listener".equals( subelementName ) ) {
 				parseListener( subelement );
 			}
 			else if ( "event".equals( subelementName ) ) {
 				parseEvent( subelement );
 			}
 		}
 	}
 
 	private void parseMappingElement(Element mappingElement, String name) {
 		final Attribute resourceAttribute = mappingElement.attribute( "resource" );
 		final Attribute fileAttribute = mappingElement.attribute( "file" );
 		final Attribute jarAttribute = mappingElement.attribute( "jar" );
 		final Attribute packageAttribute = mappingElement.attribute( "package" );
 		final Attribute classAttribute = mappingElement.attribute( "class" );
 
 		if ( resourceAttribute != null ) {
 			final String resourceName = resourceAttribute.getValue();
 			log.debug( "session-factory config [{}] named resource [{}] for mapping", name, resourceName );
 			addResource( resourceName );
 		}
 		else if ( fileAttribute != null ) {
 			final String fileName = fileAttribute.getValue();
 			log.debug( "session-factory config [{}] named file [{}] for mapping", name, fileName );
 			addFile( fileName );
 		}
 		else if ( jarAttribute != null ) {
 			final String jarFileName = jarAttribute.getValue();
 			log.debug( "session-factory config [{}] named jar file [{}] for mapping", name, jarFileName );
 			addJar( new File( jarFileName ) );
 		}
 		else if ( packageAttribute != null ) {
 			final String packageName = packageAttribute.getValue();
 			log.debug( "session-factory config [{}] named package [{}] for mapping", name, packageName );
 			addPackage( packageName );
 		}
 		else if ( classAttribute != null ) {
 			final String className = classAttribute.getValue();
 			log.debug( "session-factory config [{}] named class [{}] for mapping", name, className );
 
 			try {
 				addAnnotatedClass( ReflectHelper.classForName( className ) );
 			}
 			catch ( Exception e ) {
 				throw new MappingException(
 						"Unable to load class [ " + className + "] declared in Hibernate configuration <mapping/> entry",
 						e
 				);
 			}
 		}
 		else {
 			throw new MappingException( "<mapping> element in configuration specifies no known attributes" );
 		}
 	}
 
 	private void parseSecurity(Element secNode) {
 		String contextId = secNode.attributeValue( "context" );
       setProperty(Environment.JACC_CONTEXTID, contextId);
 		log.info( "JACC contextID: " + contextId );
 		JACCConfiguration jcfg = new JACCConfiguration( contextId );
 		Iterator grantElements = secNode.elementIterator();
 		while ( grantElements.hasNext() ) {
 			Element grantElement = (Element) grantElements.next();
 			String elementName = grantElement.getName();
 			if ( "grant".equals( elementName ) ) {
 				jcfg.addPermission(
 						grantElement.attributeValue( "role" ),
 						grantElement.attributeValue( "entity-name" ),
 						grantElement.attributeValue( "actions" )
 					);
 			}
 		}
 	}
 
 	private void parseEvent(Element element) {
 		String type = element.attributeValue( "type" );
 		List listeners = element.elements();
 		String[] listenerClasses = new String[ listeners.size() ];
 		for ( int i = 0; i < listeners.size() ; i++ ) {
 			listenerClasses[i] = ( (Element) listeners.get( i ) ).attributeValue( "class" );
 		}
 		log.debug( "Event listeners: " + type + "=" + StringHelper.toString( listenerClasses ) );
 		setListeners( type, listenerClasses );
 	}
 
 	private void parseListener(Element element) {
 		String type = element.attributeValue( "type" );
 		if ( type == null ) {
 			throw new MappingException( "No type specified for listener" );
 		}
 		String impl = element.attributeValue( "class" );
 		log.debug( "Event listener: " + type + "=" + impl );
 		setListeners( type, new String[]{impl} );
 	}
 
 	public void setListener(String type, String listener) {
 		String[] listeners = null;
 		if ( listener != null ) {
 			listeners = (String[]) Array.newInstance( String.class, 1 );
 			listeners[0] = listener;
 		}
 		setListeners( type, listeners );
 	}
 
 	public void setListeners(String type, String[] listenerClasses) {
 		Object[] listeners = null;
 		if ( listenerClasses != null ) {
 			listeners = (Object[]) Array.newInstance( eventListeners.getListenerClassFor(type), listenerClasses.length );
 			for ( int i = 0; i < listeners.length ; i++ ) {
 				try {
 					listeners[i] = ReflectHelper.classForName( listenerClasses[i] ).newInstance();
 				}
 				catch (Exception e) {
 					throw new MappingException(
 							"Unable to instantiate specified event (" + type + ") listener class: " + listenerClasses[i],
 							e
 						);
 				}
 			}
 		}
 		setListeners( type, listeners );
 	}
 
 	public void setListener(String type, Object listener) {
 		Object[] listeners = null;
 		if ( listener != null ) {
 			listeners = (Object[]) Array.newInstance( eventListeners.getListenerClassFor(type), 1 );
 			listeners[0] = listener;
 		}
 		setListeners( type, listeners );
 	}
 
 	public void setListeners(String type, Object[] listeners) {
 		if ( "auto-flush".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setAutoFlushEventListeners( new AutoFlushEventListener[]{} );
 			}
 			else {
 				eventListeners.setAutoFlushEventListeners( (AutoFlushEventListener[]) listeners );
 			}
 		}
 		else if ( "merge".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setMergeEventListeners( new MergeEventListener[]{} );
 			}
 			else {
 				eventListeners.setMergeEventListeners( (MergeEventListener[]) listeners );
 			}
 		}
 		else if ( "create".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPersistEventListeners( new PersistEventListener[]{} );
 			}
 			else {
 				eventListeners.setPersistEventListeners( (PersistEventListener[]) listeners );
 			}
 		}
 		else if ( "create-onflush".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPersistOnFlushEventListeners( new PersistEventListener[]{} );
 			}
 			else {
 				eventListeners.setPersistOnFlushEventListeners( (PersistEventListener[]) listeners );
 			}
 		}
 		else if ( "delete".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setDeleteEventListeners( new DeleteEventListener[]{} );
 			}
 			else {
 				eventListeners.setDeleteEventListeners( (DeleteEventListener[]) listeners );
 			}
 		}
 		else if ( "dirty-check".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setDirtyCheckEventListeners( new DirtyCheckEventListener[]{} );
 			}
 			else {
 				eventListeners.setDirtyCheckEventListeners( (DirtyCheckEventListener[]) listeners );
 			}
 		}
 		else if ( "evict".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setEvictEventListeners( new EvictEventListener[]{} );
 			}
 			else {
 				eventListeners.setEvictEventListeners( (EvictEventListener[]) listeners );
 			}
 		}
 		else if ( "flush".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setFlushEventListeners( new FlushEventListener[]{} );
 			}
 			else {
 				eventListeners.setFlushEventListeners( (FlushEventListener[]) listeners );
 			}
 		}
 		else if ( "flush-entity".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setFlushEntityEventListeners( new FlushEntityEventListener[]{} );
 			}
 			else {
 				eventListeners.setFlushEntityEventListeners( (FlushEntityEventListener[]) listeners );
 			}
 		}
 		else if ( "load".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setLoadEventListeners( new LoadEventListener[]{} );
 			}
 			else {
 				eventListeners.setLoadEventListeners( (LoadEventListener[]) listeners );
 			}
 		}
 		else if ( "load-collection".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setInitializeCollectionEventListeners(
 						new InitializeCollectionEventListener[]{}
 					);
 			}
 			else {
 				eventListeners.setInitializeCollectionEventListeners(
 						(InitializeCollectionEventListener[]) listeners
 					);
 			}
 		}
 		else if ( "lock".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setLockEventListeners( new LockEventListener[]{} );
 			}
 			else {
 				eventListeners.setLockEventListeners( (LockEventListener[]) listeners );
 			}
 		}
 		else if ( "refresh".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setRefreshEventListeners( new RefreshEventListener[]{} );
 			}
 			else {
 				eventListeners.setRefreshEventListeners( (RefreshEventListener[]) listeners );
 			}
 		}
 		else if ( "replicate".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setReplicateEventListeners( new ReplicateEventListener[]{} );
 			}
 			else {
 				eventListeners.setReplicateEventListeners( (ReplicateEventListener[]) listeners );
 			}
 		}
 		else if ( "save-update".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setSaveOrUpdateEventListeners( new SaveOrUpdateEventListener[]{} );
 			}
 			else {
 				eventListeners.setSaveOrUpdateEventListeners( (SaveOrUpdateEventListener[]) listeners );
 			}
 		}
 		else if ( "save".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setSaveEventListeners( new SaveOrUpdateEventListener[]{} );
 			}
 			else {
 				eventListeners.setSaveEventListeners( (SaveOrUpdateEventListener[]) listeners );
 			}
 		}
 		else if ( "update".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setUpdateEventListeners( new SaveOrUpdateEventListener[]{} );
 			}
 			else {
 				eventListeners.setUpdateEventListeners( (SaveOrUpdateEventListener[]) listeners );
 			}
 		}
 		else if ( "pre-load".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPreLoadEventListeners( new PreLoadEventListener[]{} );
 			}
 			else {
 				eventListeners.setPreLoadEventListeners( (PreLoadEventListener[]) listeners );
 			}
 		}
 		else if ( "pre-update".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPreUpdateEventListeners( new PreUpdateEventListener[]{} );
 			}
 			else {
 				eventListeners.setPreUpdateEventListeners( (PreUpdateEventListener[]) listeners );
 			}
 		}
 		else if ( "pre-delete".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPreDeleteEventListeners( new PreDeleteEventListener[]{} );
 			}
 			else {
 				eventListeners.setPreDeleteEventListeners( (PreDeleteEventListener[]) listeners );
 			}
 		}
 		else if ( "pre-insert".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPreInsertEventListeners( new PreInsertEventListener[]{} );
 			}
 			else {
 				eventListeners.setPreInsertEventListeners( (PreInsertEventListener[]) listeners );
 			}
 		}
 		else if ( "pre-collection-recreate".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPreCollectionRecreateEventListeners( new PreCollectionRecreateEventListener[]{} );
 			}
 			else {
 				eventListeners.setPreCollectionRecreateEventListeners( (PreCollectionRecreateEventListener[]) listeners );
 			}
 		}
 		else if ( "pre-collection-remove".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPreCollectionRemoveEventListeners( new PreCollectionRemoveEventListener[]{} );
 			}
 			else {
 				eventListeners.setPreCollectionRemoveEventListeners( ( PreCollectionRemoveEventListener[]) listeners );
 			}
 		}
 		else if ( "pre-collection-update".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPreCollectionUpdateEventListeners( new PreCollectionUpdateEventListener[]{} );
 			}
 			else {
 				eventListeners.setPreCollectionUpdateEventListeners( ( PreCollectionUpdateEventListener[]) listeners );
 			}
 		}
 		else if ( "post-load".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPostLoadEventListeners( new PostLoadEventListener[]{} );
 			}
 			else {
 				eventListeners.setPostLoadEventListeners( (PostLoadEventListener[]) listeners );
 			}
 		}
 		else if ( "post-update".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPostUpdateEventListeners( new PostUpdateEventListener[]{} );
 			}
 			else {
 				eventListeners.setPostUpdateEventListeners( (PostUpdateEventListener[]) listeners );
 			}
 		}
 		else if ( "post-delete".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPostDeleteEventListeners( new PostDeleteEventListener[]{} );
 			}
 			else {
 				eventListeners.setPostDeleteEventListeners( (PostDeleteEventListener[]) listeners );
 			}
 		}
 		else if ( "post-insert".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPostInsertEventListeners( new PostInsertEventListener[]{} );
 			}
 			else {
 				eventListeners.setPostInsertEventListeners( (PostInsertEventListener[]) listeners );
 			}
 		}
 		else if ( "post-commit-update".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPostCommitUpdateEventListeners(
 						new PostUpdateEventListener[]{}
 					);
 			}
 			else {
 				eventListeners.setPostCommitUpdateEventListeners( (PostUpdateEventListener[]) listeners );
 			}
 		}
 		else if ( "post-commit-delete".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPostCommitDeleteEventListeners(
 						new PostDeleteEventListener[]{}
 					);
 			}
 			else {
 				eventListeners.setPostCommitDeleteEventListeners( (PostDeleteEventListener[]) listeners );
 			}
 		}
 		else if ( "post-commit-insert".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPostCommitInsertEventListeners(
 						new PostInsertEventListener[]{}
 				);
 			}
 			else {
 				eventListeners.setPostCommitInsertEventListeners( (PostInsertEventListener[]) listeners );
 			}
 		}
 		else if ( "post-collection-recreate".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPostCollectionRecreateEventListeners( new PostCollectionRecreateEventListener[]{} );
 			}
 			else {
 				eventListeners.setPostCollectionRecreateEventListeners( (PostCollectionRecreateEventListener[]) listeners );
 			}
 		}
 		else if ( "post-collection-remove".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPostCollectionRemoveEventListeners( new PostCollectionRemoveEventListener[]{} );
 			}
 			else {
 				eventListeners.setPostCollectionRemoveEventListeners( ( PostCollectionRemoveEventListener[]) listeners );
 			}
 		}
 		else if ( "post-collection-update".equals( type ) ) {
 			if ( listeners == null ) {
 				eventListeners.setPostCollectionUpdateEventListeners( new PostCollectionUpdateEventListener[]{} );
 			}
 			else {
 				eventListeners.setPostCollectionUpdateEventListeners( ( PostCollectionUpdateEventListener[]) listeners );
 			}
 		}
 		else {
 			throw new MappingException("Unrecognized listener type [" + type + "]");
 		}
 	}
 
 	public EventListeners getEventListeners() {
 		return eventListeners;
 	}
 
 	RootClass getRootClassMapping(String clazz) throws MappingException {
 		try {
 			return (RootClass) getClassMapping( clazz );
 		}
 		catch (ClassCastException cce) {
 			throw new MappingException( "You may only specify a cache for root <class> mappings" );
 		}
 	}
 
 	/**
 	 * Set up a cache for an entity class
 	 *
 	 * @param entityName The name of the entity to which we shoudl associate these cache settings
 	 * @param concurrencyStrategy The cache strategy to use
 	 *
 	 * @return this for method chaining
 	 */
 	public Configuration setCacheConcurrencyStrategy(String entityName, String concurrencyStrategy) {
 		setCacheConcurrencyStrategy( entityName, concurrencyStrategy, entityName );
 		return this;
 	}
 
 	/**
 	 * Set up a cache for an entity class, giving an explicit region name
 	 *
 	 * @param entityName The name of the entity to which we should associate these cache settings
 	 * @param concurrencyStrategy The cache strategy to use
 	 * @param region The name of the cache region to use
 	 *
 	 * @return this for method chaining
 	 */
 	public Configuration setCacheConcurrencyStrategy(String entityName, String concurrencyStrategy, String region) {
 		setCacheConcurrencyStrategy( entityName, concurrencyStrategy, region, true );
 		return this;
 	}
 
 	public void setCacheConcurrencyStrategy(
 			String entityName,
 			String concurrencyStrategy,
 			String region,
 			boolean cacheLazyProperty) throws MappingException {
 		caches.add( new CacheHolder( entityName, concurrencyStrategy, region, true, cacheLazyProperty ) );
 	}
 
 	private void applyCacheConcurrencyStrategy(CacheHolder holder) {
 		RootClass rootClass = getRootClassMapping( holder.role );
 		if ( rootClass == null ) {
 			throw new MappingException( "Cannot cache an unknown entity: " + holder.role );
 		}
 		rootClass.setCacheConcurrencyStrategy( holder.usage );
 		rootClass.setCacheRegionName( holder.region );
 		rootClass.setLazyPropertiesCacheable( holder.cacheLazy );
 	}
 
 	/**
 	 * Set up a cache for a collection role
 	 *
 	 * @param collectionRole The name of the collection to which we should associate these cache settings
 	 * @param concurrencyStrategy The cache strategy to use
 	 *
 	 * @return this for method chaining
 	 */
 	public Configuration setCollectionCacheConcurrencyStrategy(String collectionRole, String concurrencyStrategy) {
 		setCollectionCacheConcurrencyStrategy( collectionRole, concurrencyStrategy, collectionRole );
 		return this;
 	}
 
 	/**
 	 * Set up a cache for a collection role, giving an explicit region name
 	 *
 	 * @param collectionRole The name of the collection to which we should associate these cache settings
 	 * @param concurrencyStrategy The cache strategy to use
 	 * @param region The name of the cache region to use
 	 *
 	 * @return this for method chaining
 	 */
 	public void setCollectionCacheConcurrencyStrategy(String collectionRole, String concurrencyStrategy, String region) {
 		caches.add( new CacheHolder( collectionRole, concurrencyStrategy, region, false, false ) );
 	}
 
 	private void applyCollectionCacheConcurrencyStrategy(CacheHolder holder) {
 		Collection collection = getCollectionMapping( holder.role );
 		if ( collection == null ) {
 			throw new MappingException( "Cannot cache an unknown collection: " + holder.role );
 		}
 		collection.setCacheConcurrencyStrategy( holder.usage );
 		collection.setCacheRegionName( holder.region );
 	}
 
 	/**
 	 * Get the query language imports
 	 *
 	 * @return a mapping from "import" names to fully qualified class names
 	 */
 	public Map<String,String> getImports() {
 		return imports;
 	}
 
 	/**
 	 * Create an object-oriented view of the configuration properties
 	 *
 	 * @return The build settings
 	 */
-	public Settings buildSettings() {
+	public Settings buildSettings(ConnectionProvider connectionProvider) {
 		Properties clone = ( Properties ) properties.clone();
 		ConfigurationHelper.resolvePlaceHolders( clone );
-		return buildSettingsInternal( clone );
+		return buildSettingsInternal( clone, connectionProvider );
 	}
 
-	public Settings buildSettings(Properties props) throws HibernateException {
-		return buildSettingsInternal( props );
+	public Settings buildSettings(Properties props, ConnectionProvider connectionProvider) throws HibernateException {
+		return buildSettingsInternal( props, connectionProvider );
 	}
 
-	private Settings buildSettingsInternal(Properties props) {
-		final Settings settings = settingsFactory.buildSettings( props );
+	private Settings buildSettingsInternal(Properties props, ConnectionProvider connectionProvider) {
+		final Settings settings = settingsFactory.buildSettings( props, connectionProvider );
 		settings.setEntityTuplizerFactory( this.getEntityTuplizerFactory() );
 //		settings.setComponentTuplizerFactory( this.getComponentTuplizerFactory() );
 		return settings;
 	}
 
 	public Map getNamedSQLQueries() {
 		return namedSqlQueries;
 	}
 
 	public Map getSqlResultSetMappings() {
 		return sqlResultSetMappings;
 	}
 
 	public NamingStrategy getNamingStrategy() {
 		return namingStrategy;
 	}
 
 	/**
 	 * Set a custom naming strategy
 	 *
 	 * @param namingStrategy the NamingStrategy to set
 	 *
 	 * @return this for method chaining
 	 */
 	public Configuration setNamingStrategy(NamingStrategy namingStrategy) {
 		this.namingStrategy = namingStrategy;
 		return this;
 	}
 
 	/**
 	 * Retrieve the IdentifierGeneratorFactory in effect for this configuration.
 	 *
 	 * @return This configuration's IdentifierGeneratorFactory.
 	 */
 	public DefaultIdentifierGeneratorFactory getIdentifierGeneratorFactory() {
 		return identifierGeneratorFactory;
 	}
 
 	public Mapping buildMapping() {
 		return new Mapping() {
 			public IdentifierGeneratorFactory getIdentifierGeneratorFactory() {
 				return identifierGeneratorFactory;
 			}
 
 			/**
 			 * Returns the identifier type of a mapped class
 			 */
 			public Type getIdentifierType(String entityName) throws MappingException {
 				PersistentClass pc = classes.get( entityName );
 				if ( pc == null ) {
 					throw new MappingException( "persistent class not known: " + entityName );
 				}
 				return pc.getIdentifier().getType();
 			}
 
 			public String getIdentifierPropertyName(String entityName) throws MappingException {
 				final PersistentClass pc = classes.get( entityName );
 				if ( pc == null ) {
 					throw new MappingException( "persistent class not known: " + entityName );
 				}
 				if ( !pc.hasIdentifierProperty() ) {
 					return null;
 				}
 				return pc.getIdentifierProperty().getName();
 			}
 
 			public Type getReferencedPropertyType(String entityName, String propertyName) throws MappingException {
 				final PersistentClass pc = classes.get( entityName );
 				if ( pc == null ) {
 					throw new MappingException( "persistent class not known: " + entityName );
 				}
 				Property prop = pc.getReferencedProperty( propertyName );
 				if ( prop == null ) {
 					throw new MappingException(
 							"property not known: " +
 							entityName + '.' + propertyName
 						);
 				}
 				return prop.getType();
 			}
 		};
 	}
 
 	private void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException {
 		//we need  reflectionManager before reading the other components (MetadataSourceQueue in particular)
 		final MetadataProvider metadataProvider = (MetadataProvider) ois.readObject();
 		this.mapping = buildMapping();
 		xmlHelper = new XMLHelper();
 		createReflectionManager(metadataProvider);
 		ois.defaultReadObject();
 	}
 
 	private void writeObject(java.io.ObjectOutputStream out) throws IOException {
 		//We write MetadataProvider first as we need  reflectionManager before reading the other components
 		final MetadataProvider metadataProvider = ( ( MetadataProviderInjector ) reflectionManager ).getMetadataProvider();
 		out.writeObject( metadataProvider );
 		out.defaultWriteObject();
 	}
 
 	private void createReflectionManager() {
 		createReflectionManager( new JPAMetadataProvider() );
 	}
 
 	private void createReflectionManager(MetadataProvider metadataProvider) {
 		reflectionManager = new JavaReflectionManager();
 		( ( MetadataProviderInjector ) reflectionManager ).setMetadataProvider( metadataProvider );
 	}
 
 	public Map getFilterDefinitions() {
 		return filterDefinitions;
 	}
 
 	public void addFilterDefinition(FilterDefinition definition) {
 		filterDefinitions.put( definition.getFilterName(), definition );
 	}
 
 	public Iterator iterateFetchProfiles() {
 		return fetchProfiles.values().iterator();
 	}
 
 	public void addFetchProfile(FetchProfile fetchProfile) {
 		fetchProfiles.put( fetchProfile.getName(), fetchProfile );
 	}
 
 	public void addAuxiliaryDatabaseObject(AuxiliaryDatabaseObject object) {
 		auxiliaryDatabaseObjects.add( object );
 	}
 
 	public Map getSqlFunctions() {
 		return sqlFunctions;
 	}
 
 	public void addSqlFunction(String functionName, SQLFunction function) {
 		sqlFunctions.put( functionName, function );
 	}
 
 	public TypeResolver getTypeResolver() {
 		return typeResolver;
 	}
 
 	/**
 	 * Allows registration of a type into the type registry.  The phrase 'override' in the method name simply
 	 * reminds that registration *potentially* replaces a previously registered type .
 	 *
 	 * @param type The type to register.
 	 */
 	public void registerTypeOverride(BasicType type) {
 		getTypeResolver().registerTypeOverride( type );
 	}
 
 
 	public void registerTypeOverride(UserType type, String[] keys) {
 		getTypeResolver().registerTypeOverride( type, keys );
 	}
 
 	public void registerTypeOverride(CompositeUserType type, String[] keys) {
 		getTypeResolver().registerTypeOverride( type, keys );
 	}
 
 	public SessionFactoryObserver getSessionFactoryObserver() {
 		return sessionFactoryObserver;
 	}
 
 	public void setSessionFactoryObserver(SessionFactoryObserver sessionFactoryObserver) {
 		this.sessionFactoryObserver = sessionFactoryObserver;
 	}
 
 
 	// Mappings impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Internal implementation of the Mappings interface giving access to the Configuration's internal
 	 * <tt>metadata repository</tt> state ({@link Configuration#classes}, {@link Configuration#tables}, etc).
 	 */
 	protected class MappingsImpl implements ExtendedMappings, Serializable {
 
 		private String schemaName;
 
 		public String getSchemaName() {
 			return schemaName;
 		}
 
 		public void setSchemaName(String schemaName) {
 			this.schemaName = schemaName;
 		}
 
 
 		private String catalogName;
 
 		public String getCatalogName() {
 			return catalogName;
 		}
 
 		public void setCatalogName(String catalogName) {
 			this.catalogName = catalogName;
 		}
 
 
 		private String defaultPackage;
 
 		public String getDefaultPackage() {
 			return defaultPackage;
 		}
 
 		public void setDefaultPackage(String defaultPackage) {
 			this.defaultPackage = defaultPackage;
 		}
 
 
 		private boolean autoImport;
 
 		public boolean isAutoImport() {
 			return autoImport;
 		}
 
 		public void setAutoImport(boolean autoImport) {
 			this.autoImport = autoImport;
 		}
 
 
 		private boolean defaultLazy;
 
 		public boolean isDefaultLazy() {
 			return defaultLazy;
 		}
 
 		public void setDefaultLazy(boolean defaultLazy) {
 			this.defaultLazy = defaultLazy;
 		}
 
 
 		private String defaultCascade;
 
 		public String getDefaultCascade() {
 			return defaultCascade;
 		}
 
 		public void setDefaultCascade(String defaultCascade) {
 			this.defaultCascade = defaultCascade;
 		}
 
 
 		private String defaultAccess;
 
 		public String getDefaultAccess() {
 			return defaultAccess;
 		}
 
 		public void setDefaultAccess(String defaultAccess) {
 			this.defaultAccess = defaultAccess;
 		}
 
 
 		public NamingStrategy getNamingStrategy() {
 			return namingStrategy;
 		}
 
 		public void setNamingStrategy(NamingStrategy namingStrategy) {
 			Configuration.this.namingStrategy = namingStrategy;
 		}
 
 		public TypeResolver getTypeResolver() {
 			return typeResolver;
 		}
 
 		public Iterator<PersistentClass> iterateClasses() {
 			return classes.values().iterator();
 		}
 
 		public PersistentClass getClass(String entityName) {
 			return classes.get( entityName );
 		}
 
 		public PersistentClass locatePersistentClassByEntityName(String entityName) {
 			PersistentClass persistentClass = classes.get( entityName );
 			if ( persistentClass == null ) {
 				String actualEntityName = imports.get( entityName );
 				if ( StringHelper.isNotEmpty( actualEntityName ) ) {
 					persistentClass = classes.get( actualEntityName );
 				}
 			}
 			return persistentClass;
 		}
 
 		public void addClass(PersistentClass persistentClass) throws DuplicateMappingException {
 			Object old = classes.put( persistentClass.getEntityName(), persistentClass );
 			if ( old != null ) {
 				throw new DuplicateMappingException( "class/entity", persistentClass.getEntityName() );
 			}
 		}
 
 		public void addImport(String entityName, String rename) throws DuplicateMappingException {
 			String existing = imports.put( rename, entityName );
 			if ( existing != null ) {
 				if ( existing.equals( entityName ) ) {
 					log.info( "duplicate import: {} -> {}", entityName, rename );
 				}
 				else {
 					throw new DuplicateMappingException(
 							"duplicate import: " + rename + " refers to both " + entityName +
 									" and " + existing + " (try using auto-import=\"false\")",
 							"import",
 							rename
 					);
 				}
 			}
 		}
 
 		public Collection getCollection(String role) {
 			return collections.get( role );
 		}
 
 		public Iterator<Collection> iterateCollections() {
 			return collections.values().iterator();
 		}
 
 		public void addCollection(Collection collection) throws DuplicateMappingException {
 			Object old = collections.put( collection.getRole(), collection );
 			if ( old != null ) {
 				throw new DuplicateMappingException( "collection role", collection.getRole() );
 			}
 		}
 
 		public Table getTable(String schema, String catalog, String name) {
 			String key = Table.qualify(catalog, schema, name);
 			return tables.get(key);
 		}
 
 		public Iterator<Table> iterateTables() {
 			return tables.values().iterator();
 		}
 
 		public Table addTable(
 				String schema,
 				String catalog,
 				String name,
 				String subselect,
 				boolean isAbstract) {
 			name = getObjectNameNormalizer().normalizeIdentifierQuoting( name );
 			schema = getObjectNameNormalizer().normalizeIdentifierQuoting( schema );
 			catalog = getObjectNameNormalizer().normalizeIdentifierQuoting( catalog );
 
 			String key = subselect == null ? Table.qualify( catalog, schema, name ) : subselect;
 			Table table = tables.get( key );
 
 			if ( table == null ) {
 				table = new Table();
 				table.setAbstract( isAbstract );
 				table.setName( name );
 				table.setSchema( schema );
 				table.setCatalog( catalog );
 				table.setSubselect( subselect );
 				tables.put( key, table );
 			}
 			else {
 				if ( !isAbstract ) {
 					table.setAbstract( false );
 				}
 			}
 
 			return table;
 		}
 
 		public Table addDenormalizedTable(
 				String schema,
 				String catalog,
 				String name,
 				boolean isAbstract,
 				String subselect,
 				Table includedTable) throws DuplicateMappingException {
 			name = getObjectNameNormalizer().normalizeIdentifierQuoting( name );
 			schema = getObjectNameNormalizer().normalizeIdentifierQuoting( schema );
 			catalog = getObjectNameNormalizer().normalizeIdentifierQuoting( catalog );
 
 			String key = subselect == null ? Table.qualify(catalog, schema, name) : subselect;
 			if ( tables.containsKey( key ) ) {
 				throw new DuplicateMappingException( "table", name );
 			}
 
 			Table table = new DenormalizedTable( includedTable );
 			table.setAbstract( isAbstract );
 			table.setName( name );
 			table.setSchema( schema );
 			table.setCatalog( catalog );
 			table.setSubselect( subselect );
 
 			tables.put( key, table );
 			return table;
 		}
 
 		public NamedQueryDefinition getQuery(String name) {
 			return namedQueries.get( name );
 		}
 
 		public void addQuery(String name, NamedQueryDefinition query) throws DuplicateMappingException {
 			if ( !defaultNamedQueryNames.contains( name ) ) {
 				applyQuery( name, query );
 			}
 		}
 
 		private void applyQuery(String name, NamedQueryDefinition query) {
 			checkQueryName( name );
 			namedQueries.put( name.intern(), query );
 		}
 
 		private void checkQueryName(String name) throws DuplicateMappingException {
 			if ( namedQueries.containsKey( name ) || namedSqlQueries.containsKey( name ) ) {
 				throw new DuplicateMappingException( "query", name );
 			}
 		}
 
 		public void addDefaultQuery(String name, NamedQueryDefinition query) {
 			applyQuery( name, query );
 			defaultNamedQueryNames.add( name );
 		}
 
 		public NamedSQLQueryDefinition getSQLQuery(String name) {
 			return namedSqlQueries.get( name );
 		}
 
 		public void addSQLQuery(String name, NamedSQLQueryDefinition query) throws DuplicateMappingException {
 			if ( !defaultNamedNativeQueryNames.contains( name ) ) {
 				applySQLQuery( name, query );
 			}
 		}
 
 		private void applySQLQuery(String name, NamedSQLQueryDefinition query) throws DuplicateMappingException {
 			checkQueryName( name );
 			namedSqlQueries.put( name.intern(), query );
 		}
 
 		public void addDefaultSQLQuery(String name, NamedSQLQueryDefinition query) {
 			applySQLQuery( name, query );
 			defaultNamedNativeQueryNames.add( name );
 		}
 
 		public ResultSetMappingDefinition getResultSetMapping(String name) {
 			return sqlResultSetMappings.get(name);
 		}
 
 		public void addResultSetMapping(ResultSetMappingDefinition sqlResultSetMapping) throws DuplicateMappingException {
 			if ( !defaultSqlResultSetMappingNames.contains( sqlResultSetMapping.getName() ) ) {
 				applyResultSetMapping( sqlResultSetMapping );
 			}
 		}
 
 		public void applyResultSetMapping(ResultSetMappingDefinition sqlResultSetMapping) throws DuplicateMappingException {
 			Object old = sqlResultSetMappings.put( sqlResultSetMapping.getName(), sqlResultSetMapping );
 			if ( old != null ) {
 				throw new DuplicateMappingException( "resultSet",  sqlResultSetMapping.getName() );
 			}
 		}
 
 		public void addDefaultResultSetMapping(ResultSetMappingDefinition definition) {
 			final String name = definition.getName();
 			if ( !defaultSqlResultSetMappingNames.contains( name ) && getResultSetMapping( name ) != null ) {
 				removeResultSetMapping( name );
 			}
 			applyResultSetMapping( definition );
 			defaultSqlResultSetMappingNames.add( name );
 		}
 
 		protected void removeResultSetMapping(String name) {
 			sqlResultSetMappings.remove( name );
 		}
 
 		public TypeDef getTypeDef(String typeName) {
 			return typeDefs.get( typeName );
 		}
 
 		public void addTypeDef(String typeName, String typeClass, Properties paramMap) {
 			TypeDef def = new TypeDef( typeClass, paramMap );
 			typeDefs.put( typeName, def );
 			log.debug( "Added " + typeName + " with class " + typeClass );
 		}
 
 		public Map getFilterDefinitions() {
 			return filterDefinitions;
 		}
 
 		public FilterDefinition getFilterDefinition(String name) {
 			return filterDefinitions.get( name );
 		}
 
 		public void addFilterDefinition(FilterDefinition definition) {
 			filterDefinitions.put( definition.getFilterName(), definition );
 		}
 
 		public FetchProfile findOrCreateFetchProfile(String name, MetadataSource source) {
 			FetchProfile profile = fetchProfiles.get( name );
 			if ( profile == null ) {
 				profile = new FetchProfile( name, source );
 				fetchProfiles.put( name, profile );
 			}
 			return profile;
 		}
 
 		public Iterator<AuxiliaryDatabaseObject> iterateAuxliaryDatabaseObjects() {
 			return iterateAuxiliaryDatabaseObjects();
 		}
 
 		public Iterator<AuxiliaryDatabaseObject> iterateAuxiliaryDatabaseObjects() {
 			return auxiliaryDatabaseObjects.iterator();
 		}
 
 		public ListIterator<AuxiliaryDatabaseObject> iterateAuxliaryDatabaseObjectsInReverse() {
 			return iterateAuxiliaryDatabaseObjectsInReverse();
 		}
 
 		public ListIterator<AuxiliaryDatabaseObject> iterateAuxiliaryDatabaseObjectsInReverse() {
 			return auxiliaryDatabaseObjects.listIterator( auxiliaryDatabaseObjects.size() );
 		}
 
 		public void addAuxiliaryDatabaseObject(AuxiliaryDatabaseObject auxiliaryDatabaseObject) {
 			auxiliaryDatabaseObjects.add( auxiliaryDatabaseObject );
 		}
 
 		/**
 		 * Internal struct used to help track physical table names to logical table names.
 		 */
 		private class TableDescription implements Serializable {
 			final String logicalName;
 			final Table denormalizedSupertable;
 
 			TableDescription(String logicalName, Table denormalizedSupertable) {
 				this.logicalName = logicalName;
 				this.denormalizedSupertable = denormalizedSupertable;
 			}
 		}
 
 		public String getLogicalTableName(Table table) throws MappingException {
 			return getLogicalTableName( table.getQuotedSchema(), table.getCatalog(), table.getQuotedName() );
 		}
 
 		private String getLogicalTableName(String schema, String catalog, String physicalName) throws MappingException {
 			String key = buildTableNameKey( schema, catalog, physicalName );
 			TableDescription descriptor = (TableDescription) tableNameBinding.get( key );
 			if (descriptor == null) {
 				throw new MappingException( "Unable to find physical table: " + physicalName);
 			}
 			return descriptor.logicalName;
 		}
 
 		public void addTableBinding(
 				String schema,
 				String catalog,
 				String logicalName,
 				String physicalName,
 				Table denormalizedSuperTable) throws DuplicateMappingException {
 			String key = buildTableNameKey( schema, catalog, physicalName );
 			TableDescription tableDescription = new TableDescription( logicalName, denormalizedSuperTable );
 			TableDescription oldDescriptor = ( TableDescription ) tableNameBinding.put( key, tableDescription );
 			if ( oldDescriptor != null && ! oldDescriptor.logicalName.equals( logicalName ) ) {
 				//TODO possibly relax that
 				throw new DuplicateMappingException(
 						"Same physical table name [" + physicalName + "] references several logical table names: [" +
 								oldDescriptor.logicalName + "], [" + logicalName + ']',
 						"table",
 						physicalName
 				);
 			}
 		}
 
 		private String buildTableNameKey(String schema, String catalog, String finalName) {
 			StringBuffer keyBuilder = new StringBuffer();
 			if (schema != null) keyBuilder.append( schema );
 			keyBuilder.append( ".");
 			if (catalog != null) keyBuilder.append( catalog );
 			keyBuilder.append( ".");
 			keyBuilder.append( finalName );
 			return keyBuilder.toString();
 		}
 
 		/**
 		 * Internal struct used to maintain xref between physical and logical column
 		 * names for a table.  Mainly this is used to ensure that the defined
 		 * {@link NamingStrategy} is not creating duplicate column names.
 		 */
 		private class TableColumnNameBinding implements Serializable {
 			private final String tableName;
 			private Map/*<String, String>*/ logicalToPhysical = new HashMap();
 			private Map/*<String, String>*/ physicalToLogical = new HashMap();
 
 			private TableColumnNameBinding(String tableName) {
 				this.tableName = tableName;
 			}
 
 			public void addBinding(String logicalName, Column physicalColumn) {
 				bindLogicalToPhysical( logicalName, physicalColumn );
 				bindPhysicalToLogical( logicalName, physicalColumn );
 			}
 
 			private void bindLogicalToPhysical(String logicalName, Column physicalColumn) throws DuplicateMappingException {
 				final String logicalKey = logicalName.toLowerCase();
 				final String physicalName = physicalColumn.getQuotedName();
 				final String existingPhysicalName = ( String ) logicalToPhysical.put( logicalKey, physicalName );
 				if ( existingPhysicalName != null ) {
 					boolean areSamePhysicalColumn = physicalColumn.isQuoted()
 							? existingPhysicalName.equals( physicalName )
 							: existingPhysicalName.equalsIgnoreCase( physicalName );
 					if ( ! areSamePhysicalColumn ) {
 						throw new DuplicateMappingException(
 								" Table [" + tableName + "] contains logical column name [" + logicalName
 										+ "] referenced by multiple physical column names: [" + existingPhysicalName
 										+ "], [" + physicalName + "]",
 								"column-binding",
 								tableName + "." + logicalName
 						);
 					}
 				}
 			}
 
 			private void bindPhysicalToLogical(String logicalName, Column physicalColumn) throws DuplicateMappingException {
 				final String physicalName = physicalColumn.getQuotedName();
 				final String existingLogicalName = ( String ) physicalToLogical.put( physicalName, logicalName );
 				if ( existingLogicalName != null && ! existingLogicalName.equals( logicalName ) ) {
 					throw new DuplicateMappingException(
 							" Table [" + tableName + "] contains phyical column name [" + physicalName
 									+ "] represented by different logical column names: [" + existingLogicalName
 									+ "], [" + logicalName + "]",
 							"column-binding",
 							tableName + "." + physicalName
 					);
 				}
 			}
 		}
 
 		public void addColumnBinding(String logicalName, Column physicalColumn, Table table) throws DuplicateMappingException {
 			TableColumnNameBinding binding = ( TableColumnNameBinding ) columnNameBindingPerTable.get( table );
 			if ( binding == null ) {
 				binding = new TableColumnNameBinding( table.getName() );
 				columnNameBindingPerTable.put( table, binding );
 			}
 			binding.addBinding( logicalName, physicalColumn );
 		}
  
 		public String getPhysicalColumnName(String logicalName, Table table) throws MappingException {
 			logicalName = logicalName.toLowerCase();
 			String finalName = null;
 			Table currentTable = table;
 			do {
 				TableColumnNameBinding binding = ( TableColumnNameBinding ) columnNameBindingPerTable.get( currentTable );
 				if ( binding != null ) {
 					finalName = ( String ) binding.logicalToPhysical.get( logicalName );
 				}
 				String key = buildTableNameKey(
 						currentTable.getQuotedSchema(), currentTable.getCatalog(), currentTable.getQuotedName()
 				);
 				TableDescription description = ( TableDescription ) tableNameBinding.get( key );
 				if ( description != null ) {
 					currentTable = description.denormalizedSupertable;
 				}
 				else {
 					currentTable = null;
 				}
 			} while ( finalName == null && currentTable != null );
 
 			if ( finalName == null ) {
 				throw new MappingException(
 						"Unable to find column with logical name " + logicalName + " in table " + table.getName()
 				);
 			}
 			return finalName;
 		}
 
 		public String getLogicalColumnName(String physicalName, Table table) throws MappingException {
 			String logical = null;
 			Table currentTable = table;
 			TableDescription description = null;
 			do {
 				TableColumnNameBinding binding = ( TableColumnNameBinding ) columnNameBindingPerTable.get( currentTable );
 				if ( binding != null ) {
 					logical = ( String ) binding.physicalToLogical.get( physicalName );
 				}
 				String key = buildTableNameKey(
 						currentTable.getQuotedSchema(), currentTable.getCatalog(), currentTable.getQuotedName()
 				);
 				description = ( TableDescription ) tableNameBinding.get( key );
 				if ( description != null ) {
 					currentTable = description.denormalizedSupertable;
 				}
 				else {
 					currentTable = null;
 				}
 			}
 			while ( logical == null && currentTable != null && description != null );
 			if ( logical == null ) {
 				throw new MappingException(
 						"Unable to find logical column name from physical name "
 								+ physicalName + " in table " + table.getName()
 				);
 			}
 			return logical;
 		}
 
 		public void addSecondPass(SecondPass sp) {
 			addSecondPass( sp, false );
 		}
 
 		public void addSecondPass(SecondPass sp, boolean onTopOfTheQueue) {
 			if ( onTopOfTheQueue ) {
 				secondPasses.add( 0, sp );
 			}
 			else {
 				secondPasses.add( sp );
 			}
 		}
 
 		public void addPropertyReference(String referencedClass, String propertyName) {
 			propertyReferences.add( new PropertyReference( referencedClass, propertyName, false ) );
 		}
 
 		public void addUniquePropertyReference(String referencedClass, String propertyName) {
 			propertyReferences.add( new PropertyReference( referencedClass, propertyName, true ) );
 		}
 
 		public void addToExtendsQueue(ExtendsQueueEntry entry) {
 			extendsQueue.put( entry, null );
 		}
 
 		public DefaultIdentifierGeneratorFactory getIdentifierGeneratorFactory() {
 			return identifierGeneratorFactory;
 		}
 
 		public void addMappedSuperclass(Class type, MappedSuperclass mappedSuperclass) {
 			mappedSuperClasses.put( type, mappedSuperclass );
 		}
 
 		public MappedSuperclass getMappedSuperclass(Class type) {
 			return mappedSuperClasses.get( type );
 		}
 
 		public ObjectNameNormalizer getObjectNameNormalizer() {
 			return normalizer;
 		}
 
 		public Properties getConfigurationProperties() {
 			return properties;
 		}
 
 
 		private Boolean useNewGeneratorMappings;
 
 		public void addDefaultGenerator(IdGenerator generator) {
 			this.addGenerator( generator );
 			defaultNamedGenerators.add( generator.getName() );
 		}
 
 		public boolean isInSecondPass() {
 			return inSecondPass;
 		}
 
 		public PropertyData getPropertyAnnotatedWithMapsId(XClass entityType, String propertyName) {
 			final Map<String, PropertyData> map = propertiesAnnotatedWithMapsId.get( entityType );
 			return map == null ? null : map.get( propertyName );
 		}
 
 		public void addPropertyAnnotatedWithMapsId(XClass entityType, PropertyData property) {
 			Map<String, PropertyData> map = propertiesAnnotatedWithMapsId.get( entityType );
 			if ( map == null ) {
 				map = new HashMap<String, PropertyData>();
 				propertiesAnnotatedWithMapsId.put( entityType, map );
 			}
 			map.put( property.getProperty().getAnnotation( MapsId.class ).value(), property );
 		}
 
 		public boolean isSpecjProprietarySyntaxEnabled() {
 			return specjProprietarySyntaxEnabled;
 		}
 
 		public void addPropertyAnnotatedWithMapsIdSpecj(XClass entityType, PropertyData property, String mapsIdValue) {
 			Map<String, PropertyData> map = propertiesAnnotatedWithMapsId.get( entityType );
 			if ( map == null ) {
 				map = new HashMap<String, PropertyData>();
 				propertiesAnnotatedWithMapsId.put( entityType, map );
 			}
 			map.put( mapsIdValue, property );
 		}
 
 		public PropertyData getPropertyAnnotatedWithIdAndToOne(XClass entityType, String propertyName) {
 			final Map<String, PropertyData> map = propertiesAnnotatedWithIdAndToOne.get( entityType );
 			return map == null ? null : map.get( propertyName );
 		}
 
 		public void addToOneAndIdProperty(XClass entityType, PropertyData property) {
 			Map<String, PropertyData> map = propertiesAnnotatedWithIdAndToOne.get( entityType );
 			if ( map == null ) {
 				map = new HashMap<String, PropertyData>();
 				propertiesAnnotatedWithIdAndToOne.put( entityType, map );
 			}
 			map.put( property.getPropertyName(), property );
 		}
 
 		@SuppressWarnings({ "UnnecessaryUnboxing" })
 		public boolean useNewGeneratorMappings() {
 			if ( useNewGeneratorMappings == null ) {
 				final String booleanName = getConfigurationProperties().getProperty( USE_NEW_ID_GENERATOR_MAPPINGS );
 				useNewGeneratorMappings = Boolean.valueOf( booleanName );
 			}
 			return useNewGeneratorMappings.booleanValue();
 		}
 
 		public IdGenerator getGenerator(String name) {
 			return getGenerator( name, null );
 		}
 
 		public IdGenerator getGenerator(String name, Map<String, IdGenerator> localGenerators) {
 			if ( localGenerators != null ) {
 				IdGenerator result = localGenerators.get( name );
 				if ( result != null ) {
 					return result;
 				}
 			}
 			return namedGenerators.get( name );
 		}
 
 		public void addGenerator(IdGenerator generator) {
 			if ( !defaultNamedGenerators.contains( generator.getName() ) ) {
 				IdGenerator old = namedGenerators.put( generator.getName(), generator );
 				if ( old != null ) {
 					log.warn( "duplicate generator name {}", old.getName() );
 				}
 			}
 		}
 
 		public void addGeneratorTable(String name, Properties params) {
 			Object old = generatorTables.put( name, params );
 			if ( old != null ) {
 				log.warn( "duplicate generator table: {}", name );
 			}
 		}
 
 		public Properties getGeneratorTableProperties(String name, Map<String, Properties> localGeneratorTables) {
 			if ( localGeneratorTables != null ) {
 				Properties result = localGeneratorTables.get( name );
 				if ( result != null ) {
 					return result;
 				}
 			}
 			return generatorTables.get( name );
 		}
 
 		public Map<String, Join> getJoins(String entityName) {
 			return joins.get( entityName );
 		}
 
 		public void addJoins(PersistentClass persistentClass, Map<String, Join> joins) {
 			Object old = Configuration.this.joins.put( persistentClass.getEntityName(), joins );
 			if ( old != null ) {
 				log.warn( "duplicate joins for class: {}", persistentClass.getEntityName() );
 			}
 		}
 
 		public AnnotatedClassType getClassType(XClass clazz) {
 			AnnotatedClassType type = classTypes.get( clazz.getName() );
 			if ( type == null ) {
 				return addClassType( clazz );
 			}
 			else {
 				return type;
 			}
 		}
 
 		//FIXME should be private but is part of the ExtendedMapping contract
 
 		public AnnotatedClassType addClassType(XClass clazz) {
 			AnnotatedClassType type;
 			if ( clazz.isAnnotationPresent( Entity.class ) ) {
 				type = AnnotatedClassType.ENTITY;
 			}
 			else if ( clazz.isAnnotationPresent( Embeddable.class ) ) {
 				type = AnnotatedClassType.EMBEDDABLE;
 			}
 			else if ( clazz.isAnnotationPresent( javax.persistence.MappedSuperclass.class ) ) {
 				type = AnnotatedClassType.EMBEDDABLE_SUPERCLASS;
 			}
 			else {
 				type = AnnotatedClassType.NONE;
 			}
 			classTypes.put( clazz.getName(), type );
 			return type;
 		}
 
 		/**
 		 * {@inheritDoc}
 		 */
 		public Map<Table, List<String[]>> getTableUniqueConstraints() {
 			final Map<Table, List<String[]>> deprecatedStructure = new HashMap<Table, List<String[]>>(
 					CollectionHelper.determineProperSizing( getUniqueConstraintHoldersByTable() ),
 					CollectionHelper.LOAD_FACTOR
 			);
 			for ( Map.Entry<Table, List<UniqueConstraintHolder>> entry : getUniqueConstraintHoldersByTable().entrySet() ) {
 				List<String[]> columnsPerConstraint = new ArrayList<String[]>(
 						CollectionHelper.determineProperSizing( entry.getValue().size() )
 				);
 				deprecatedStructure.put( entry.getKey(), columnsPerConstraint );
 				for ( UniqueConstraintHolder holder : entry.getValue() ) {
 					columnsPerConstraint.add( holder.getColumns() );
 				}
 			}
 			return deprecatedStructure;
 		}
 
 		public Map<Table, List<UniqueConstraintHolder>> getUniqueConstraintHoldersByTable() {
 			return uniqueConstraintHoldersByTable;
 		}
 
 		@SuppressWarnings({ "unchecked" })
 		public void addUniqueConstraints(Table table, List uniqueConstraints) {
 			List<UniqueConstraintHolder> constraintHolders = new ArrayList<UniqueConstraintHolder>(
 					CollectionHelper.determineProperSizing( uniqueConstraints.size() )
 			);
 
 			int keyNameBase = determineCurrentNumberOfUniqueConstraintHolders( table );
 			for ( String[] columns : ( List<String[]> ) uniqueConstraints ) {
 				final String keyName = "key" + keyNameBase++;
 				constraintHolders.add(
 						new UniqueConstraintHolder().setName( keyName ).setColumns( columns )
 				);
 			}
 			addUniqueConstraintHolders( table, constraintHolders );
 		}
 
 		private int determineCurrentNumberOfUniqueConstraintHolders(Table table) {
 			List currentHolders = getUniqueConstraintHoldersByTable().get( table );
 			return currentHolders == null
 					? 0
 					: currentHolders.size();
 		}
 
 		public void addUniqueConstraintHolders(Table table, List<UniqueConstraintHolder> uniqueConstraintHolders) {
 			List<UniqueConstraintHolder> holderList = getUniqueConstraintHoldersByTable().get( table );
 			if ( holderList == null ) {
 				holderList = new ArrayList<UniqueConstraintHolder>();
 				getUniqueConstraintHoldersByTable().put( table, holderList );
 			}
 			holderList.addAll( uniqueConstraintHolders );
 		}
 
 		public void addMappedBy(String entityName, String propertyName, String inversePropertyName) {
 			mappedByResolver.put( entityName + "." + propertyName, inversePropertyName );
 		}
 
 		public String getFromMappedBy(String entityName, String propertyName) {
 			return mappedByResolver.get( entityName + "." + propertyName );
 		}
 
 		public void addPropertyReferencedAssociation(String entityName, String propertyName, String propertyRef) {
 			propertyRefResolver.put( entityName + "." + propertyName, propertyRef );
 		}
 
 		public String getPropertyReferencedAssociation(String entityName, String propertyName) {
 			return propertyRefResolver.get( entityName + "." + propertyName );
 		}
 
 		public ReflectionManager getReflectionManager() {
 			return reflectionManager;
 		}
 
 		public Map getClasses() {
 			return classes;
 		}
 
 		public void addAnyMetaDef(AnyMetaDef defAnn) throws AnnotationException {
 			if ( anyMetaDefs.containsKey( defAnn.name() ) ) {
 				throw new AnnotationException( "Two @AnyMetaDef with the same name defined: " + defAnn.name() );
 			}
 			anyMetaDefs.put( defAnn.name(), defAnn );
 		}
 
 		public AnyMetaDef getAnyMetaDef(String name) {
 			return anyMetaDefs.get( name );
 		}
 	}
 
 	final ObjectNameNormalizer normalizer = new ObjectNameNormalizerImpl();
 
 	final class ObjectNameNormalizerImpl extends ObjectNameNormalizer implements Serializable {
 		public boolean isUseQuotedIdentifiersGlobally() {
 			//Do not cache this value as we lazily set it in Hibernate Annotation (AnnotationConfiguration)
 			//TODO use a dedicated protected useQuotedIdentifier flag in Configuration (overriden by AnnotationConfiguration)
 			String setting = (String) properties.get( Environment.GLOBALLY_QUOTED_IDENTIFIERS );
 			return setting != null && Boolean.valueOf( setting ).booleanValue();
 		}
 
 		public NamingStrategy getNamingStrategy() {
 			return namingStrategy;
 		}
 	}
 
 	protected class MetadataSourceQueue implements Serializable {
 		private LinkedHashMap<XmlDocument, Set<String>> hbmMetadataToEntityNamesMap
 				= new LinkedHashMap<XmlDocument, Set<String>>();
 		private Map<String, XmlDocument> hbmMetadataByEntityNameXRef = new HashMap<String, XmlDocument>();
 
 		//XClass are not serializable by default
 		private transient List<XClass> annotatedClasses = new ArrayList<XClass>();
 		//only used during the secondPhaseCompile pass, hence does not need to be serialized
 		private transient Map<String, XClass> annotatedClassesByEntityNameMap = new HashMap<String, XClass>();
 
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/Environment.java b/hibernate-core/src/main/java/org/hibernate/cfg/Environment.java
index 562639cb50..89b456467c 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/Environment.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/Environment.java
@@ -1,825 +1,825 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.sql.Connection;
 import java.sql.Statement;
 import java.sql.Timestamp;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Properties;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import org.hibernate.HibernateException;
 import org.hibernate.Version;
 import org.hibernate.bytecode.BytecodeProvider;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.util.ConfigHelper;
 
 
 /**
  * Provides access to configuration info passed in <tt>Properties</tt> objects.
  * <br><br>
  * Hibernate has two property scopes:
  * <ul>
  * <li><b>Factory-level</b> properties may be passed to the <tt>SessionFactory</tt> when it
  * instantiated. Each instance might have different property values. If no
  * properties are specified, the factory calls <tt>Environment.getProperties()</tt>.
  * <li><b>System-level</b> properties are shared by all factory instances and are always
  * determined by the <tt>Environment</tt> properties.
  * </ul>
  * The only system-level properties are
  * <ul>
  * <li><tt>hibernate.jdbc.use_streams_for_binary</tt>
  * <li><tt>hibernate.cglib.use_reflection_optimizer</tt>
  * </ul>
  * <tt>Environment</tt> properties are populated by calling <tt>System.getProperties()</tt>
  * and then from a resource named <tt>/hibernate.properties</tt> if it exists. System
  * properties override properties specified in <tt>hibernate.properties</tt>.<br>
  * <br>
  * The <tt>SessionFactory</tt> is controlled by the following properties.
  * Properties may be either be <tt>System</tt> properties, properties
  * defined in a resource named <tt>/hibernate.properties</tt> or an instance of
  * <tt>java.util.Properties</tt> passed to
  * <tt>Configuration.buildSessionFactory()</tt><br>
  * <br>
  * <table>
  * <tr><td><b>property</b></td><td><b>meaning</b></td></tr>
  * <tr>
  *   <td><tt>hibernate.dialect</tt></td>
  *   <td>classname of <tt>org.hibernate.dialect.Dialect</tt> subclass</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.cache.provider_class</tt></td>
  *   <td>classname of <tt>org.hibernate.cache.CacheProvider</tt>
  *   subclass (if not specified EHCache is used)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.connection.provider_class</tt></td>
- *   <td>classname of <tt>org.hibernate.connection.ConnectionProvider</tt>
+ *   <td>classname of <tt>org.hibernate.service.jdbc.connections.spi.ConnectionProvider</tt>
  *   subclass (if not specified hueristics are used)</td>
  * </tr>
  * <tr><td><tt>hibernate.connection.username</tt></td><td>database username</td></tr>
  * <tr><td><tt>hibernate.connection.password</tt></td><td>database password</td></tr>
  * <tr>
  *   <td><tt>hibernate.connection.url</tt></td>
  *   <td>JDBC URL (when using <tt>java.sql.DriverManager</tt>)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.connection.driver_class</tt></td>
  *   <td>classname of JDBC driver</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.connection.isolation</tt></td>
  *   <td>JDBC transaction isolation level (only when using
  *     <tt>java.sql.DriverManager</tt>)
  *   </td>
  * </tr>
  *   <td><tt>hibernate.connection.pool_size</tt></td>
  *   <td>the maximum size of the connection pool (only when using
  *     <tt>java.sql.DriverManager</tt>)
  *   </td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.connection.datasource</tt></td>
  *   <td>databasource JNDI name (when using <tt>javax.sql.Datasource</tt>)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jndi.url</tt></td><td>JNDI <tt>InitialContext</tt> URL</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jndi.class</tt></td><td>JNDI <tt>InitialContext</tt> classname</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.max_fetch_depth</tt></td>
  *   <td>maximum depth of outer join fetching</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jdbc.batch_size</tt></td>
  *   <td>enable use of JDBC2 batch API for drivers which support it</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jdbc.fetch_size</tt></td>
  *   <td>set the JDBC fetch size</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jdbc.use_scrollable_resultset</tt></td>
  *   <td>enable use of JDBC2 scrollable resultsets (you only need this specify
  *   this property when using user supplied connections)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jdbc.use_getGeneratedKeys</tt></td>
  *   <td>enable use of JDBC3 PreparedStatement.getGeneratedKeys() to retrieve
  *   natively generated keys after insert. Requires JDBC3+ driver and JRE1.4+</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.hbm2ddl.auto</tt></td>
  *   <td>enable auto DDL export</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.default_schema</tt></td>
  *   <td>use given schema name for unqualified tables (always optional)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.default_catalog</tt></td>
  *   <td>use given catalog name for unqualified tables (always optional)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.session_factory_name</tt></td>
  *   <td>If set, the factory attempts to bind this name to itself in the
  *   JNDI context. This name is also used to support cross JVM <tt>
  *   Session</tt> (de)serialization.</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.transaction.manager_lookup_class</tt></td>
  *   <td>classname of <tt>org.hibernate.transaction.TransactionManagerLookup</tt>
  *   implementor</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.transaction.factory_class</tt></td>
  *   <td>the factory to use for instantiating <tt>Transaction</tt>s.
  *   (Defaults to <tt>JDBCTransactionFactory</tt>.)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.query.substitutions</tt></td><td>query language token substitutions</td>
  * </tr>
  * </table>
  *
  * @see org.hibernate.SessionFactory
  * @author Gavin King
  */
 public final class Environment {
 	/**
 	 * <tt>ConnectionProvider</tt> implementor to use when obtaining connections
 	 */
 	public static final String CONNECTION_PROVIDER ="hibernate.connection.provider_class";
 	/**
 	 * JDBC driver class
 	 */
 	public static final String DRIVER ="hibernate.connection.driver_class";
 	/**
 	 * JDBC transaction isolation level
 	 */
 	public static final String ISOLATION ="hibernate.connection.isolation";
 	/**
 	 * JDBC URL
 	 */
 	public static final String URL ="hibernate.connection.url";
 	/**
 	 * JDBC user
 	 */
 	public static final String USER ="hibernate.connection.username";
 	/**
 	 * JDBC password
 	 */
 	public static final String PASS ="hibernate.connection.password";
 	/**
 	 * JDBC autocommit mode
 	 */
 	public static final String AUTOCOMMIT ="hibernate.connection.autocommit";
 	/**
 	 * Maximum number of inactive connections for Hibernate's connection pool
 	 */
 	public static final String POOL_SIZE ="hibernate.connection.pool_size";
 	/**
 	 * <tt>java.sql.Datasource</tt> JNDI name
 	 */
 	public static final String DATASOURCE ="hibernate.connection.datasource";
 	/**
 	 * prefix for arbitrary JDBC connection properties
 	 */
 	public static final String CONNECTION_PREFIX = "hibernate.connection";
 
 	/**
 	 * JNDI initial context class, <tt>Context.INITIAL_CONTEXT_FACTORY</tt>
 	 */
 	public static final String JNDI_CLASS ="hibernate.jndi.class";
 	/**
 	 * JNDI provider URL, <tt>Context.PROVIDER_URL</tt>
 	 */
 	public static final String JNDI_URL ="hibernate.jndi.url";
 	/**
 	 * prefix for arbitrary JNDI <tt>InitialContext</tt> properties
 	 */
 	public static final String JNDI_PREFIX = "hibernate.jndi";
 	/**
 	 * JNDI name to bind to <tt>SessionFactory</tt>
 	 */
 	public static final String SESSION_FACTORY_NAME = "hibernate.session_factory_name";
 
 	/**
 	 * Hibernate SQL {@link org.hibernate.dialect.Dialect} class
 	 */
 	public static final String DIALECT ="hibernate.dialect";
 
 	/**
 	 * {@link org.hibernate.dialect.resolver.DialectResolver} classes to register with the
 	 * {@link org.hibernate.dialect.resolver.DialectFactory}
 	 */
 	public static final String DIALECT_RESOLVERS = "hibernate.dialect_resolvers";
 
 	/**
 	 * A default database schema (owner) name to use for unqualified tablenames
 	 */
 	public static final String DEFAULT_SCHEMA = "hibernate.default_schema";
 	/**
 	 * A default database catalog name to use for unqualified tablenames
 	 */
 	public static final String DEFAULT_CATALOG = "hibernate.default_catalog";
 
 	/**
 	 * Enable logging of generated SQL to the console
 	 */
 	public static final String SHOW_SQL ="hibernate.show_sql";
 	/**
 	 * Enable formatting of SQL logged to the console
 	 */
 	public static final String FORMAT_SQL ="hibernate.format_sql";
 	/**
 	 * Add comments to the generated SQL
 	 */
 	public static final String USE_SQL_COMMENTS ="hibernate.use_sql_comments";
 	/**
 	 * Maximum depth of outer join fetching
 	 */
 	public static final String MAX_FETCH_DEPTH = "hibernate.max_fetch_depth";
 	/**
 	 * The default batch size for batch fetching
 	 */
 	public static final String DEFAULT_BATCH_FETCH_SIZE = "hibernate.default_batch_fetch_size";
 	/**
 	 * Use <tt>java.io</tt> streams to read / write binary data from / to JDBC
 	 */
 	public static final String USE_STREAMS_FOR_BINARY = "hibernate.jdbc.use_streams_for_binary";
 	/**
 	 * Use JDBC scrollable <tt>ResultSet</tt>s. This property is only necessary when there is
 	 * no <tt>ConnectionProvider</tt>, ie. the user is supplying JDBC connections.
 	 */
 	public static final String USE_SCROLLABLE_RESULTSET = "hibernate.jdbc.use_scrollable_resultset";
 	/**
 	 * Tells the JDBC driver to attempt to retrieve row Id with the JDBC 3.0 PreparedStatement.getGeneratedKeys()
 	 * method. In general, performance will be better if this property is set to true and the underlying
 	 * JDBC driver supports getGeneratedKeys().
 	 */
 	public static final String USE_GET_GENERATED_KEYS = "hibernate.jdbc.use_get_generated_keys";
 	/**
 	 * Gives the JDBC driver a hint as to the number of rows that should be fetched from the database
 	 * when more rows are needed. If <tt>0</tt>, JDBC driver default settings will be used.
 	 */
 	public static final String STATEMENT_FETCH_SIZE = "hibernate.jdbc.fetch_size";
 	/**
 	 * Maximum JDBC batch size. A nonzero value enables batch updates.
 	 */
 	public static final String STATEMENT_BATCH_SIZE = "hibernate.jdbc.batch_size";
 	/**
 	 * Select a custom batcher.
 	 */
 	public static final String BATCH_STRATEGY = "hibernate.jdbc.factory_class";
 	/**
 	 * Should versioned data be included in batching?
 	 */
 	public static final String BATCH_VERSIONED_DATA = "hibernate.jdbc.batch_versioned_data";
 	/**
 	 * An XSLT resource used to generate "custom" XML
 	 */
 	public static final String OUTPUT_STYLESHEET ="hibernate.xml.output_stylesheet";
 
 	/**
 	 * Maximum size of C3P0 connection pool
 	 */
 	public static final String C3P0_MAX_SIZE = "hibernate.c3p0.max_size";
 	/**
 	 * Minimum size of C3P0 connection pool
 	 */
 	public static final String C3P0_MIN_SIZE = "hibernate.c3p0.min_size";
 
 	/**
 	 * Maximum idle time for C3P0 connection pool
 	 */
 	public static final String C3P0_TIMEOUT = "hibernate.c3p0.timeout";
 	/**
 	 * Maximum size of C3P0 statement cache
 	 */
 	public static final String C3P0_MAX_STATEMENTS = "hibernate.c3p0.max_statements";
 	/**
 	 * Number of connections acquired when pool is exhausted
 	 */
 	public static final String C3P0_ACQUIRE_INCREMENT = "hibernate.c3p0.acquire_increment";
 	/**
 	 * Idle time before a C3P0 pooled connection is validated
 	 */
 	public static final String C3P0_IDLE_TEST_PERIOD = "hibernate.c3p0.idle_test_period";
 
 	/**
 	 * Proxool/Hibernate property prefix
 	 */
 	public static final String PROXOOL_PREFIX = "hibernate.proxool";
 	/**
 	 * Proxool property to configure the Proxool Provider using an XML (<tt>/path/to/file.xml</tt>)
 	 */
 	public static final String PROXOOL_XML = "hibernate.proxool.xml";
 	/**
 	 * Proxool property to configure the Proxool Provider  using a properties file (<tt>/path/to/proxool.properties</tt>)
 	 */
 	public static final String PROXOOL_PROPERTIES = "hibernate.proxool.properties";
 	/**
 	 * Proxool property to configure the Proxool Provider from an already existing pool (<tt>true</tt> / <tt>false</tt>)
 	 */
 	public static final String PROXOOL_EXISTING_POOL = "hibernate.proxool.existing_pool";
 	/**
 	 * Proxool property with the Proxool pool alias to use
 	 * (Required for <tt>PROXOOL_EXISTING_POOL</tt>, <tt>PROXOOL_PROPERTIES</tt>, or
 	 * <tt>PROXOOL_XML</tt>)
 	 */
 	public static final String PROXOOL_POOL_ALIAS = "hibernate.proxool.pool_alias";
 
 	/**
 	 * Enable automatic session close at end of transaction
 	 */
 	public static final String AUTO_CLOSE_SESSION = "hibernate.transaction.auto_close_session";
 	/**
 	 * Enable automatic flush during the JTA <tt>beforeCompletion()</tt> callback
 	 */
 	public static final String FLUSH_BEFORE_COMPLETION = "hibernate.transaction.flush_before_completion";
 	/**
 	 * Specifies how Hibernate should release JDBC connections.
 	 */
 	public static final String RELEASE_CONNECTIONS = "hibernate.connection.release_mode";
 	/**
 	 * Context scoping impl for {@link org.hibernate.SessionFactory#getCurrentSession()} processing.
 	 */
 	public static final String CURRENT_SESSION_CONTEXT_CLASS = "hibernate.current_session_context_class";
 	/**
 	 * <tt>TransactionFactory</tt> implementor to use for creating <tt>Transaction</tt>s
 	 */
 	public static final String TRANSACTION_STRATEGY = "hibernate.transaction.factory_class";
 	/**
 	 * <tt>TransactionManagerLookup</tt> implementor to use for obtaining the <tt>TransactionManager</tt>
 	 */
 	public static final String TRANSACTION_MANAGER_STRATEGY = "hibernate.transaction.manager_lookup_class";
 	/**
 	 * JNDI name of JTA <tt>UserTransaction</tt> object
 	 */
 	public static final String USER_TRANSACTION = "jta.UserTransaction";
 
 	/**
 	 * The <tt>CacheProvider</tt> implementation class
 	 */
 	public static final String CACHE_PROVIDER = "hibernate.cache.provider_class";
 
 	/**
 	 * The {@link org.hibernate.cache.RegionFactory} implementation class
 	 */
 	public static final String CACHE_REGION_FACTORY = "hibernate.cache.region.factory_class";
 
 	/**
 	 * The <tt>CacheProvider</tt> implementation class
 	 */
 	public static final String CACHE_PROVIDER_CONFIG = "hibernate.cache.provider_configuration_file_resource_path";
 	/**
 	 * The <tt>CacheProvider</tt> JNDI namespace, if pre-bound to JNDI.
 	 */
 	public static final String CACHE_NAMESPACE = "hibernate.cache.jndi";
 	/**
 	 * Enable the query cache (disabled by default)
 	 */
 	public static final String USE_QUERY_CACHE = "hibernate.cache.use_query_cache";
 	/**
 	 * The <tt>QueryCacheFactory</tt> implementation class.
 	 */
 	public static final String QUERY_CACHE_FACTORY = "hibernate.cache.query_cache_factory";
 	/**
 	 * Enable the second-level cache (enabled by default)
 	 */
 	public static final String USE_SECOND_LEVEL_CACHE = "hibernate.cache.use_second_level_cache";
 	/**
 	 * Optimize the cache for minimal puts instead of minimal gets
 	 */
 	public static final String USE_MINIMAL_PUTS = "hibernate.cache.use_minimal_puts";
 	/**
 	 * The <tt>CacheProvider</tt> region name prefix
 	 */
 	public static final String CACHE_REGION_PREFIX = "hibernate.cache.region_prefix";
 	/**
 	 * Enable use of structured second-level cache entries
 	 */
 	public static final String USE_STRUCTURED_CACHE = "hibernate.cache.use_structured_entries";
 
 	/**
 	 * Enable statistics collection
 	 */
 	public static final String GENERATE_STATISTICS = "hibernate.generate_statistics";
 
 	public static final String USE_IDENTIFIER_ROLLBACK = "hibernate.use_identifier_rollback";
 
 	/**
 	 * Use bytecode libraries optimized property access
 	 */
 	public static final String USE_REFLECTION_OPTIMIZER = "hibernate.bytecode.use_reflection_optimizer";
 
 	/**
 	 * The classname of the HQL query parser factory
 	 */
 	public static final String QUERY_TRANSLATOR = "hibernate.query.factory_class";
 
 	/**
 	 * A comma-separated list of token substitutions to use when translating a Hibernate
 	 * query to SQL
 	 */
 	public static final String QUERY_SUBSTITUTIONS = "hibernate.query.substitutions";
 
 	/**
 	 * Should named queries be checked during startup (the default is enabled).
 	 * <p/>
 	 * Mainly intended for test environments.
 	 */
 	public static final String QUERY_STARTUP_CHECKING = "hibernate.query.startup_check";
 
 	/**
 	 * Auto export/update schema using hbm2ddl tool. Valid values are <tt>update</tt>,
 	 * <tt>create</tt>, <tt>create-drop</tt> and <tt>validate</tt>.
 	 */
 	public static final String HBM2DDL_AUTO = "hibernate.hbm2ddl.auto";
 
 	/**
 	 * Comma-separated names of the optional files containing SQL DML statements executed
 	 * during the SessionFactory creation.
 	 * File order matters, the statements of a give file are executed before the statements of the
 	 * following files.
 	 *
 	 * These statements are only executed if the schema is created ie if <tt>hibernate.hbm2ddl.auto</tt>
 	 * is set to <tt>create</tt> or <tt>create-drop</tt>.
 	 *
 	 * The default value is <tt>/import.sql</tt>
 	 */
 	public static final String HBM2DDL_IMPORT_FILES = "hibernate.hbm2ddl.import_files";
 
 	/**
 	 * The {@link org.hibernate.exception.SQLExceptionConverter} to use for converting SQLExceptions
 	 * to Hibernate's JDBCException hierarchy.  The default is to use the configured
 	 * {@link org.hibernate.dialect.Dialect}'s preferred SQLExceptionConverter.
 	 */
 	public static final String SQL_EXCEPTION_CONVERTER = "hibernate.jdbc.sql_exception_converter";
 
 	/**
 	 * Enable wrapping of JDBC result sets in order to speed up column name lookups for
 	 * broken JDBC drivers
 	 */
 	public static final String WRAP_RESULT_SETS = "hibernate.jdbc.wrap_result_sets";
 
 	/**
 	 * Enable ordering of update statements by primary key value
 	 */
 	public static final String ORDER_UPDATES = "hibernate.order_updates";
 
 	/**
 	 * Enable ordering of insert statements for the purpose of more efficient JDBC batching.
 	 */
 	public static final String ORDER_INSERTS = "hibernate.order_inserts";
 
 	/**
 	 * The EntityMode in which set the Session opened from the SessionFactory.
 	 */
     public static final String DEFAULT_ENTITY_MODE = "hibernate.default_entity_mode";
 
     /**
      * The jacc context id of the deployment
      */
     public static final String JACC_CONTEXTID = "hibernate.jacc_context_id";
 
 	/**
 	 * Should all database identifiers be quoted.
 	 */
 	public static final String GLOBALLY_QUOTED_IDENTIFIERS = "hibernate.globally_quoted_identifiers";
 
 	/**
 	 * Enable nullability checking.
 	 * Raises an exception if a property marked as not-null is null.
 	 * Default to false if Bean Validation is present in the classpath and Hibernate Annotations is used,
 	 * true otherwise.
 	 */
 	public static final String CHECK_NULLABILITY = "hibernate.check_nullability";
 
 
 	public static final String BYTECODE_PROVIDER = "hibernate.bytecode.provider";
 
 	public static final String JPAQL_STRICT_COMPLIANCE= "hibernate.query.jpaql_strict_compliance";
 
 	/**
 	 * When using pooled {@link org.hibernate.id.enhanced.Optimizer optimizers}, prefer interpreting the 
 	 * database value as the lower (lo) boundary.  The default is to interpret it as the high boundary.
 	 */
 	public static final String PREFER_POOLED_VALUES_LO = "hibernate.id.optimizer.pooled.prefer_lo";
 
 	/**
 	 * The maximum number of strong references maintained by {@link org.hibernate.util.SoftLimitMRUCache}. Default is 128.
 	 */
 	public static final String QUERY_PLAN_CACHE_MAX_STRONG_REFERENCES = "hibernate.query.plan_cache_max_strong_references";
 
 	/**
 	 * The maximum number of soft references maintained by {@link org.hibernate.util.SoftLimitMRUCache}. Default is 2048.
 	 */
 	public static final String QUERY_PLAN_CACHE_MAX_SOFT_REFERENCES = "hibernate.query.plan_cache_max_soft_references";
 
 	/**
 	 * Should we not use contextual LOB creation (aka based on {@link java.sql.Connection#createBlob()} et al).
 	 */
 	public static final String NON_CONTEXTUAL_LOB_CREATION = "hibernate.jdbc.lob.non_contextual_creation";
 
 
 	private static final BytecodeProvider BYTECODE_PROVIDER_INSTANCE;
 	private static final boolean ENABLE_BINARY_STREAMS;
 	private static final boolean ENABLE_REFLECTION_OPTIMIZER;
 	private static final boolean JVM_SUPPORTS_LINKED_HASH_COLLECTIONS;
 	private static final boolean JVM_HAS_TIMESTAMP_BUG;
 	private static final boolean JVM_HAS_JDK14_TIMESTAMP;
 	private static final boolean JVM_SUPPORTS_GET_GENERATED_KEYS;
 
 	private static final Properties GLOBAL_PROPERTIES;
 	private static final HashMap ISOLATION_LEVELS = new HashMap();
 	private static final Map OBSOLETE_PROPERTIES = new HashMap();
 	private static final Map RENAMED_PROPERTIES = new HashMap();
 
 	private static final Logger log = LoggerFactory.getLogger(Environment.class);
 
 	/**
 	 * Issues warnings to the user when any obsolete or renamed property names are used.
 	 *
 	 * @param props The specified properties.
 	 */
 	public static void verifyProperties(Properties props) {
 		Iterator iter = props.keySet().iterator();
 		Map propertiesToAdd = new HashMap();
 		while ( iter.hasNext() ) {
 			final Object propertyName = iter.next();
 			Object newPropertyName = OBSOLETE_PROPERTIES.get( propertyName );
 			if ( newPropertyName != null ) {
 				log.warn( "Usage of obsolete property: " + propertyName + " no longer supported, use: " + newPropertyName );
 			}
 			newPropertyName = RENAMED_PROPERTIES.get( propertyName );
 			if ( newPropertyName != null ) {
 				log.warn( "Property [" + propertyName + "] has been renamed to [" + newPropertyName + "]; update your properties appropriately" );
 				if ( ! props.containsKey( newPropertyName ) ) {
 					propertiesToAdd.put( newPropertyName, props.get( propertyName ) );
 				}
 			}
 		}
 		props.putAll(propertiesToAdd);
 	}
 
 	static {
 
 		log.info( "Hibernate " + Version.getVersionString() );
 
 		RENAMED_PROPERTIES.put( "hibernate.cglib.use_reflection_optimizer", USE_REFLECTION_OPTIMIZER );
 
 		ISOLATION_LEVELS.put( new Integer(Connection.TRANSACTION_NONE), "NONE" );
 		ISOLATION_LEVELS.put( new Integer(Connection.TRANSACTION_READ_UNCOMMITTED), "READ_UNCOMMITTED" );
 		ISOLATION_LEVELS.put( new Integer(Connection.TRANSACTION_READ_COMMITTED), "READ_COMMITTED" );
 		ISOLATION_LEVELS.put( new Integer(Connection.TRANSACTION_REPEATABLE_READ), "REPEATABLE_READ" );
 		ISOLATION_LEVELS.put( new Integer(Connection.TRANSACTION_SERIALIZABLE), "SERIALIZABLE" );
 
 		GLOBAL_PROPERTIES = new Properties();
 		//Set USE_REFLECTION_OPTIMIZER to false to fix HHH-227
 		GLOBAL_PROPERTIES.setProperty( USE_REFLECTION_OPTIMIZER, Boolean.FALSE.toString() );
 
 		try {
 			InputStream stream = ConfigHelper.getResourceAsStream("/hibernate.properties");
 			try {
 				GLOBAL_PROPERTIES.load(stream);
 				log.info( "loaded properties from resource hibernate.properties: " + ConfigurationHelper.maskOut(GLOBAL_PROPERTIES, PASS) );
 			}
 			catch (Exception e) {
 				log.error("problem loading properties from hibernate.properties");
 			}
 			finally {
 				try{
 					stream.close();
 				}
 				catch (IOException ioe){
 					log.error("could not close stream on hibernate.properties", ioe);
 				}
 			}
 		}
 		catch (HibernateException he) {
 			log.info("hibernate.properties not found");
 		}
 
 		try {
 			GLOBAL_PROPERTIES.putAll( System.getProperties() );
 		}
 		catch (SecurityException se) {
 			log.warn("could not copy system properties, system properties will be ignored");
 		}
 
 		verifyProperties(GLOBAL_PROPERTIES);
 
 		ENABLE_BINARY_STREAMS = ConfigurationHelper.getBoolean(USE_STREAMS_FOR_BINARY, GLOBAL_PROPERTIES);
 		ENABLE_REFLECTION_OPTIMIZER = ConfigurationHelper.getBoolean(USE_REFLECTION_OPTIMIZER, GLOBAL_PROPERTIES);
 
 		if (ENABLE_BINARY_STREAMS) {
 			log.info("using java.io streams to persist binary types");
 		}
 		if (ENABLE_REFLECTION_OPTIMIZER) {
 			log.info("using bytecode reflection optimizer");
 		}
 		BYTECODE_PROVIDER_INSTANCE = buildBytecodeProvider( GLOBAL_PROPERTIES );
 
 		boolean getGeneratedKeysSupport;
 		try {
 			Statement.class.getMethod("getGeneratedKeys", null);
 			getGeneratedKeysSupport = true;
 		}
 		catch (NoSuchMethodException nsme) {
 			getGeneratedKeysSupport = false;
 		}
 		JVM_SUPPORTS_GET_GENERATED_KEYS = getGeneratedKeysSupport;
 		if (!JVM_SUPPORTS_GET_GENERATED_KEYS) {
 			log.info("JVM does not support Statement.getGeneratedKeys()");
 		}
 
 		boolean linkedHashSupport;
 		try {
 			Class.forName("java.util.LinkedHashSet");
 			linkedHashSupport = true;
 		}
 		catch (ClassNotFoundException cnfe) {
 			linkedHashSupport = false;
 		}
 		JVM_SUPPORTS_LINKED_HASH_COLLECTIONS = linkedHashSupport;
 		if (!JVM_SUPPORTS_LINKED_HASH_COLLECTIONS) {
 			log.info("JVM does not support LinkedHasMap, LinkedHashSet - ordered maps and sets disabled");
 		}
 
 		long x = 123456789;
 		JVM_HAS_TIMESTAMP_BUG = new Timestamp(x).getTime() != x;
 		if (JVM_HAS_TIMESTAMP_BUG) {
 			log.info("using workaround for JVM bug in java.sql.Timestamp");
 		}
 
 		Timestamp t = new Timestamp(0);
 		t.setNanos(5 * 1000000);
 		JVM_HAS_JDK14_TIMESTAMP = t.getTime() == 5;
 		if (JVM_HAS_JDK14_TIMESTAMP) {
 			log.info("using JDK 1.4 java.sql.Timestamp handling");
 		}
 		else {
 			log.info("using pre JDK 1.4 java.sql.Timestamp handling");
 		}
 	}
 
 	public static BytecodeProvider getBytecodeProvider() {
 		return BYTECODE_PROVIDER_INSTANCE;
 	}
 
 	/**
 	 * Does this JVM's implementation of {@link java.sql.Timestamp} have a bug in which the following is true:<code>
 	 * new java.sql.Timestamp( x ).getTime() != x
 	 * </code>
 	 * <p/>
 	 * NOTE : IBM JDK 1.3.1 the only known JVM to exhibit this behavior.
 	 *
 	 * @return True if the JVM's {@link Timestamp} implementa
 	 */
 	public static boolean jvmHasTimestampBug() {
 		return JVM_HAS_TIMESTAMP_BUG;
 	}
 
 	/**
 	 * Does this JVM handle {@link java.sql.Timestamp} in the JDK 1.4 compliant way wrt to nano rolling>
 	 *
 	 * @return True if the JDK 1.4 (JDBC3) specification for {@link java.sql.Timestamp} nano rolling is adhered to.
 	 *
 	 * @deprecated Starting with 3.3 Hibernate requires JDK 1.4 or higher
 	 */
 	public static boolean jvmHasJDK14Timestamp() {
 		return JVM_HAS_JDK14_TIMESTAMP;
 	}
 
 	/**
 	 * Does this JVM support {@link java.util.LinkedHashSet} and {@link java.util.LinkedHashMap}?
 	 * <p/>
 	 * Note, this is true for JDK 1.4 and above; hence the deprecation.
 	 *
 	 * @return True if {@link java.util.LinkedHashSet} and {@link java.util.LinkedHashMap} are available.
 	 *
 	 * @deprecated Starting with 3.3 Hibernate requires JDK 1.4 or higher
 	 * @see java.util.LinkedHashSet
 	 * @see java.util.LinkedHashMap
 	 */
 	public static boolean jvmSupportsLinkedHashCollections() {
 		return JVM_SUPPORTS_LINKED_HASH_COLLECTIONS;
 	}
 
 	/**
 	 * Does this JDK/JVM define the JDBC {@link Statement} interface with a 'getGeneratedKeys' method?
 	 * <p/>
 	 * Note, this is true for JDK 1.4 and above; hence the deprecation.
 	 *
 	 * @return True if generated keys can be retrieved via Statement; false otherwise.
 	 *
 	 * @see Statement
 	 * @deprecated Starting with 3.3 Hibernate requires JDK 1.4 or higher
 	 */
 	public static boolean jvmSupportsGetGeneratedKeys() {
 		return JVM_SUPPORTS_GET_GENERATED_KEYS;
 	}
 
 	/**
 	 * Should we use streams to bind binary types to JDBC IN parameters?
 	 *
 	 * @return True if streams should be used for binary data handling; false otherwise.
 	 *
 	 * @see #USE_STREAMS_FOR_BINARY
 	 */
 	public static boolean useStreamsForBinary() {
 		return ENABLE_BINARY_STREAMS;
 	}
 
 	/**
 	 * Should we use reflection optimization?
 	 *
 	 * @return True if reflection optimization should be used; false otherwise.
 	 *
 	 * @see #USE_REFLECTION_OPTIMIZER
 	 * @see #getBytecodeProvider()
 	 * @see BytecodeProvider#getReflectionOptimizer
 	 */
 	public static boolean useReflectionOptimizer() {
 		return ENABLE_REFLECTION_OPTIMIZER;
 	}
 
 	/**
 	 * Disallow instantiation
 	 */
 	private Environment() {
 		throw new UnsupportedOperationException();
 	}
 
 	/**
 	 * Return <tt>System</tt> properties, extended by any properties specified
 	 * in <tt>hibernate.properties</tt>.
 	 * @return Properties
 	 */
 	public static Properties getProperties() {
 		Properties copy = new Properties();
 		copy.putAll(GLOBAL_PROPERTIES);
 		return copy;
 	}
 
 	/**
 	 * Get the name of a JDBC transaction isolation level
 	 *
 	 * @see java.sql.Connection
 	 * @param isolation as defined by <tt>java.sql.Connection</tt>
 	 * @return a human-readable name
 	 */
 	public static String isolationLevelToString(int isolation) {
 		return (String) ISOLATION_LEVELS.get( new Integer(isolation) );
 	}
 
 	public static BytecodeProvider buildBytecodeProvider(Properties properties) {
 		String provider = ConfigurationHelper.getString( BYTECODE_PROVIDER, properties, "javassist" );
 		log.info( "Bytecode provider name : " + provider );
 		return buildBytecodeProvider( provider );
 	}
 
 	private static BytecodeProvider buildBytecodeProvider(String providerName) {
 		if ( "javassist".equals( providerName ) ) {
 			return new org.hibernate.bytecode.javassist.BytecodeProviderImpl();
 		}
 		else if ( "cglib".equals( providerName ) ) {
 			return new org.hibernate.bytecode.cglib.BytecodeProviderImpl();
 		}
 
 		log.warn( "unrecognized bytecode provider [" + providerName + "], using javassist by default" );
 		return new org.hibernate.bytecode.javassist.BytecodeProviderImpl();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/Settings.java b/hibernate-core/src/main/java/org/hibernate/cfg/Settings.java
index dd252ce8d1..31bf6beba1 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/Settings.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/Settings.java
@@ -1,529 +1,525 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import java.util.Map;
 
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.EntityMode;
 import org.hibernate.cache.QueryCacheFactory;
 import org.hibernate.cache.RegionFactory;
-import org.hibernate.connection.ConnectionProvider;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.JdbcSupport;
 import org.hibernate.exception.SQLExceptionConverter;
 import org.hibernate.hql.QueryTranslatorFactory;
 import org.hibernate.jdbc.BatcherFactory;
 import org.hibernate.jdbc.util.SQLStatementLogger;
 import org.hibernate.transaction.TransactionFactory;
 import org.hibernate.transaction.TransactionManagerLookup;
 import org.hibernate.tuple.entity.EntityTuplizerFactory;
 
 /**
  * Settings that affect the behaviour of Hibernate at runtime.
  *
  * @author Gavin King
  */
 public final class Settings {
 
 //	private boolean showSql;
 //	private boolean formatSql;
 	private SQLStatementLogger sqlStatementLogger;
 	private Integer maximumFetchDepth;
 	private Map querySubstitutions;
 	private Dialect dialect;
 	private int jdbcBatchSize;
 	private int defaultBatchFetchSize;
 	private boolean scrollableResultSetsEnabled;
 	private boolean getGeneratedKeysEnabled;
 	private String defaultSchemaName;
 	private String defaultCatalogName;
 	private Integer jdbcFetchSize;
 	private String sessionFactoryName;
 	private boolean autoCreateSchema;
 	private boolean autoDropSchema;
 	private boolean autoUpdateSchema;
 	private boolean autoValidateSchema;
 	private boolean queryCacheEnabled;
 	private boolean structuredCacheEntriesEnabled;
 	private boolean secondLevelCacheEnabled;
 	private String cacheRegionPrefix;
 	private boolean minimalPutsEnabled;
 	private boolean commentsEnabled;
 	private boolean statisticsEnabled;
 	private boolean jdbcBatchVersionedData;
 	private boolean identifierRollbackEnabled;
 	private boolean flushBeforeCompletionEnabled;
 	private boolean autoCloseSessionEnabled;
 	private ConnectionReleaseMode connectionReleaseMode;
 	private RegionFactory regionFactory;
 	private QueryCacheFactory queryCacheFactory;
 	private ConnectionProvider connectionProvider;
 	private TransactionFactory transactionFactory;
 	private TransactionManagerLookup transactionManagerLookup;
 	private BatcherFactory batcherFactory;
 	private QueryTranslatorFactory queryTranslatorFactory;
 	private SQLExceptionConverter sqlExceptionConverter;
 	private boolean wrapResultSetsEnabled;
 	private boolean orderUpdatesEnabled;
 	private boolean orderInsertsEnabled;
 	private EntityMode defaultEntityMode;
 	private boolean dataDefinitionImplicitCommit;
 	private boolean dataDefinitionInTransactionSupported;
 	private boolean strictJPAQLCompliance;
 	private boolean namedQueryStartupCheckingEnabled;
 	private EntityTuplizerFactory entityTuplizerFactory;
 	private boolean checkNullability;
 //	private ComponentTuplizerFactory componentTuplizerFactory; todo : HHH-3517 and HHH-1907
 //	private BytecodeProvider bytecodeProvider;
 	private JdbcSupport jdbcSupport;
 	private String importFiles;
 
 	/**
 	 * Package protected constructor
 	 */
 	Settings() {
 	}
 
 	// public getters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 //	public boolean isShowSqlEnabled() {
 //		return showSql;
 //	}
 //
 //	public boolean isFormatSqlEnabled() {
 //		return formatSql;
 //	}
 
 	public String getImportFiles() {
 		return importFiles;
 	}
 
 	public void setImportFiles(String importFiles) {
 		this.importFiles = importFiles;
 	}
 
 	public SQLStatementLogger getSqlStatementLogger() {
 		return sqlStatementLogger;
 	}
 
 	public String getDefaultSchemaName() {
 		return defaultSchemaName;
 	}
 
 	public String getDefaultCatalogName() {
 		return defaultCatalogName;
 	}
 
 	public Dialect getDialect() {
 		return dialect;
 	}
 
 	public int getJdbcBatchSize() {
 		return jdbcBatchSize;
 	}
 
 	public int getDefaultBatchFetchSize() {
 		return defaultBatchFetchSize;
 	}
 
 	public Map getQuerySubstitutions() {
 		return querySubstitutions;
 	}
 
 	public boolean isIdentifierRollbackEnabled() {
 		return identifierRollbackEnabled;
 	}
 
 	public boolean isScrollableResultSetsEnabled() {
 		return scrollableResultSetsEnabled;
 	}
 
 	public boolean isGetGeneratedKeysEnabled() {
 		return getGeneratedKeysEnabled;
 	}
 
 	public boolean isMinimalPutsEnabled() {
 		return minimalPutsEnabled;
 	}
 
 	public Integer getJdbcFetchSize() {
 		return jdbcFetchSize;
 	}
 
-	public ConnectionProvider getConnectionProvider() {
-		return connectionProvider;
-	}
-
 	public TransactionFactory getTransactionFactory() {
 		return transactionFactory;
 	}
 
 	public String getSessionFactoryName() {
 		return sessionFactoryName;
 	}
 
 	public boolean isAutoCreateSchema() {
 		return autoCreateSchema;
 	}
 
 	public boolean isAutoDropSchema() {
 		return autoDropSchema;
 	}
 
 	public boolean isAutoUpdateSchema() {
 		return autoUpdateSchema;
 	}
 
 	public Integer getMaximumFetchDepth() {
 		return maximumFetchDepth;
 	}
 
 	public RegionFactory getRegionFactory() {
 		return regionFactory;
 	}
 
 	public TransactionManagerLookup getTransactionManagerLookup() {
 		return transactionManagerLookup;
 	}
 
 	public boolean isQueryCacheEnabled() {
 		return queryCacheEnabled;
 	}
 
 	public boolean isCommentsEnabled() {
 		return commentsEnabled;
 	}
 
 	public boolean isSecondLevelCacheEnabled() {
 		return secondLevelCacheEnabled;
 	}
 
 	public String getCacheRegionPrefix() {
 		return cacheRegionPrefix;
 	}
 
 	public QueryCacheFactory getQueryCacheFactory() {
 		return queryCacheFactory;
 	}
 
 	public boolean isStatisticsEnabled() {
 		return statisticsEnabled;
 	}
 
 	public boolean isJdbcBatchVersionedData() {
 		return jdbcBatchVersionedData;
 	}
 
 	public boolean isFlushBeforeCompletionEnabled() {
 		return flushBeforeCompletionEnabled;
 	}
 
 	public BatcherFactory getBatcherFactory() {
 		return batcherFactory;
 	}
 
 	public boolean isAutoCloseSessionEnabled() {
 		return autoCloseSessionEnabled;
 	}
 
 	public ConnectionReleaseMode getConnectionReleaseMode() {
 		return connectionReleaseMode;
 	}
 
 	public QueryTranslatorFactory getQueryTranslatorFactory() {
 		return queryTranslatorFactory;
 	}
 
 	public SQLExceptionConverter getSQLExceptionConverter() {
 		return sqlExceptionConverter;
 	}
 
 	public boolean isWrapResultSetsEnabled() {
 		return wrapResultSetsEnabled;
 	}
 
 	public boolean isOrderUpdatesEnabled() {
 		return orderUpdatesEnabled;
 	}
 
 	public boolean isOrderInsertsEnabled() {
 		return orderInsertsEnabled;
 	}
 
 	public boolean isStructuredCacheEntriesEnabled() {
 		return structuredCacheEntriesEnabled;
 	}
 
 	public EntityMode getDefaultEntityMode() {
 		return defaultEntityMode;
 	}
 
 	public boolean isAutoValidateSchema() {
 		return autoValidateSchema;
 	}
 
 	public boolean isDataDefinitionImplicitCommit() {
 		return dataDefinitionImplicitCommit;
 	}
 
 	public boolean isDataDefinitionInTransactionSupported() {
 		return dataDefinitionInTransactionSupported;
 	}
 
 	public boolean isStrictJPAQLCompliance() {
 		return strictJPAQLCompliance;
 	}
 
 	public boolean isNamedQueryStartupCheckingEnabled() {
 		return namedQueryStartupCheckingEnabled;
 	}
 
 	public EntityTuplizerFactory getEntityTuplizerFactory() {
 		return entityTuplizerFactory;
 	}
 
 //	public ComponentTuplizerFactory getComponentTuplizerFactory() {
 //		return componentTuplizerFactory;
 //	}
 
 	public JdbcSupport getJdbcSupport() {
 		return jdbcSupport;
 	}
 
 
 	// package protected setters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 //	void setShowSqlEnabled(boolean b) {
 //		showSql = b;
 //	}
 //
 //	void setFormatSqlEnabled(boolean b) {
 //		formatSql = b;
 //	}
 
 	void setSqlStatementLogger(SQLStatementLogger sqlStatementLogger) {
 		this.sqlStatementLogger = sqlStatementLogger;
 	}
 
 	void setDefaultSchemaName(String string) {
 		defaultSchemaName = string;
 	}
 
 	void setDefaultCatalogName(String string) {
 		defaultCatalogName = string;
 	}
 
 	void setDialect(Dialect dialect) {
 		this.dialect = dialect;
 	}
 
 	void setJdbcBatchSize(int i) {
 		jdbcBatchSize = i;
 	}
 
 	void setDefaultBatchFetchSize(int i) {
 		defaultBatchFetchSize = i;
 	}
 
 	void setQuerySubstitutions(Map map) {
 		querySubstitutions = map;
 	}
 
 	void setIdentifierRollbackEnabled(boolean b) {
 		identifierRollbackEnabled = b;
 	}
 
 	void setMinimalPutsEnabled(boolean b) {
 		minimalPutsEnabled = b;
 	}
 
 	void setScrollableResultSetsEnabled(boolean b) {
 		scrollableResultSetsEnabled = b;
 	}
 
 	void setGetGeneratedKeysEnabled(boolean b) {
 		getGeneratedKeysEnabled = b;
 	}
 
 	void setJdbcFetchSize(Integer integer) {
 		jdbcFetchSize = integer;
 	}
 
 	void setConnectionProvider(ConnectionProvider provider) {
 		connectionProvider = provider;
 	}
 
 	void setTransactionFactory(TransactionFactory factory) {
 		transactionFactory = factory;
 	}
 
 	void setSessionFactoryName(String string) {
 		sessionFactoryName = string;
 	}
 
 	void setAutoCreateSchema(boolean b) {
 		autoCreateSchema = b;
 	}
 
 	void setAutoDropSchema(boolean b) {
 		autoDropSchema = b;
 	}
 
 	void setAutoUpdateSchema(boolean b) {
 		autoUpdateSchema = b;
 	}
 
 	void setMaximumFetchDepth(Integer i) {
 		maximumFetchDepth = i;
 	}
 
 	void setRegionFactory(RegionFactory regionFactory) {
 		this.regionFactory = regionFactory;
 	}
 
 	void setTransactionManagerLookup(TransactionManagerLookup lookup) {
 		transactionManagerLookup = lookup;
 	}
 
 	void setQueryCacheEnabled(boolean b) {
 		queryCacheEnabled = b;
 	}
 
 	void setCommentsEnabled(boolean commentsEnabled) {
 		this.commentsEnabled = commentsEnabled;
 	}
 
 	void setSecondLevelCacheEnabled(boolean secondLevelCacheEnabled) {
 		this.secondLevelCacheEnabled = secondLevelCacheEnabled;
 	}
 
 	void setCacheRegionPrefix(String cacheRegionPrefix) {
 		this.cacheRegionPrefix = cacheRegionPrefix;
 	}
 
 	void setQueryCacheFactory(QueryCacheFactory queryCacheFactory) {
 		this.queryCacheFactory = queryCacheFactory;
 	}
 
 	void setStatisticsEnabled(boolean statisticsEnabled) {
 		this.statisticsEnabled = statisticsEnabled;
 	}
 
 	void setJdbcBatchVersionedData(boolean jdbcBatchVersionedData) {
 		this.jdbcBatchVersionedData = jdbcBatchVersionedData;
 	}
 
 	void setFlushBeforeCompletionEnabled(boolean flushBeforeCompletionEnabled) {
 		this.flushBeforeCompletionEnabled = flushBeforeCompletionEnabled;
 	}
 
 	void setBatcherFactory(BatcherFactory batcher) {
 		this.batcherFactory = batcher;
 	}
 
 	void setAutoCloseSessionEnabled(boolean autoCloseSessionEnabled) {
 		this.autoCloseSessionEnabled = autoCloseSessionEnabled;
 	}
 
 	void setConnectionReleaseMode(ConnectionReleaseMode connectionReleaseMode) {
 		this.connectionReleaseMode = connectionReleaseMode;
 	}
 
 	void setQueryTranslatorFactory(QueryTranslatorFactory queryTranslatorFactory) {
 		this.queryTranslatorFactory = queryTranslatorFactory;
 	}
 
 	void setSQLExceptionConverter(SQLExceptionConverter sqlExceptionConverter) {
 		this.sqlExceptionConverter = sqlExceptionConverter;
 	}
 
 	void setWrapResultSetsEnabled(boolean wrapResultSetsEnabled) {
 		this.wrapResultSetsEnabled = wrapResultSetsEnabled;
 	}
 
 	void setOrderUpdatesEnabled(boolean orderUpdatesEnabled) {
 		this.orderUpdatesEnabled = orderUpdatesEnabled;
 	}
 
 	void setOrderInsertsEnabled(boolean orderInsertsEnabled) {
 		this.orderInsertsEnabled = orderInsertsEnabled;
 	}
 
 	void setStructuredCacheEntriesEnabled(boolean structuredCacheEntriesEnabled) {
 		this.structuredCacheEntriesEnabled = structuredCacheEntriesEnabled;
 	}
 
 	void setDefaultEntityMode(EntityMode defaultEntityMode) {
 		this.defaultEntityMode = defaultEntityMode;
 	}
 
 	void setAutoValidateSchema(boolean autoValidateSchema) {
 		this.autoValidateSchema = autoValidateSchema;
 	}
 
 	void setDataDefinitionImplicitCommit(boolean dataDefinitionImplicitCommit) {
 		this.dataDefinitionImplicitCommit = dataDefinitionImplicitCommit;
 	}
 
 	void setDataDefinitionInTransactionSupported(boolean dataDefinitionInTransactionSupported) {
 		this.dataDefinitionInTransactionSupported = dataDefinitionInTransactionSupported;
 	}
 
 	void setStrictJPAQLCompliance(boolean strictJPAQLCompliance) {
 		this.strictJPAQLCompliance = strictJPAQLCompliance;
 	}
 
 	void setNamedQueryStartupCheckingEnabled(boolean namedQueryStartupCheckingEnabled) {
 		this.namedQueryStartupCheckingEnabled = namedQueryStartupCheckingEnabled;
 	}
 
 	void setEntityTuplizerFactory(EntityTuplizerFactory entityTuplizerFactory) {
 		this.entityTuplizerFactory = entityTuplizerFactory;
 	}
 
 	public boolean isCheckNullability() {
 		return checkNullability;
 	}
 
 	public void setCheckNullability(boolean checkNullability) {
 		this.checkNullability = checkNullability;
 	}
 
 	//	void setComponentTuplizerFactory(ComponentTuplizerFactory componentTuplizerFactory) {
 //		this.componentTuplizerFactory = componentTuplizerFactory;
 //	}
 
 	void setJdbcSupport(JdbcSupport jdbcSupport) {
 		this.jdbcSupport = jdbcSupport;
 	}
 
 	//	public BytecodeProvider getBytecodeProvider() {
 //		return bytecodeProvider;
 //	}
 //
 //	void setBytecodeProvider(BytecodeProvider bytecodeProvider) {
 //		this.bytecodeProvider = bytecodeProvider;
 //	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/SettingsFactory.java b/hibernate-core/src/main/java/org/hibernate/cfg/SettingsFactory.java
index 3401260bad..b6321e8b7b 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/SettingsFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/SettingsFactory.java
@@ -1,464 +1,456 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.DatabaseMetaData;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Map;
 import java.util.Properties;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
 import org.hibernate.engine.jdbc.JdbcSupport;
 import org.hibernate.bytecode.BytecodeProvider;
 import org.hibernate.cache.QueryCacheFactory;
 import org.hibernate.cache.RegionFactory;
 import org.hibernate.cache.impl.NoCachingRegionFactory;
 import org.hibernate.cache.impl.bridge.RegionFactoryCacheProviderBridge;
-import org.hibernate.connection.ConnectionProvider;
-import org.hibernate.connection.ConnectionProviderFactory;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.resolver.DialectFactory;
 import org.hibernate.exception.SQLExceptionConverter;
 import org.hibernate.exception.SQLExceptionConverterFactory;
 import org.hibernate.hql.QueryTranslatorFactory;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.jdbc.BatcherFactory;
 import org.hibernate.jdbc.BatchingBatcherFactory;
 import org.hibernate.jdbc.NonBatchingBatcherFactory;
 import org.hibernate.jdbc.util.SQLStatementLogger;
 import org.hibernate.transaction.TransactionFactory;
 import org.hibernate.transaction.TransactionFactoryFactory;
 import org.hibernate.transaction.TransactionManagerLookup;
 import org.hibernate.transaction.TransactionManagerLookupFactory;
 import org.hibernate.util.ReflectHelper;
 import org.hibernate.util.StringHelper;
 
 /**
  * Reads configuration properties and builds a {@link Settings} instance.
  *
  * @author Gavin King
  */
 public class SettingsFactory implements Serializable {
 	private static final Logger log = LoggerFactory.getLogger( SettingsFactory.class );
 	private static final long serialVersionUID = -1194386144994524825L;
 
 	public static final String DEF_CACHE_REG_FACTORY = NoCachingRegionFactory.class.getName();
 
 	protected SettingsFactory() {
 	}
 
-	public Settings buildSettings(Properties props) {
+	public Settings buildSettings(Properties props, ConnectionProvider connections) {
 		Settings settings = new Settings();
 
 		//SessionFactory name:
 
 		String sessionFactoryName = props.getProperty(Environment.SESSION_FACTORY_NAME);
 		settings.setSessionFactoryName(sessionFactoryName);
 
 		//JDBC and connection settings:
 
-		ConnectionProvider connections = createConnectionProvider(props);
-		settings.setConnectionProvider(connections);
-
 		//Interrogate JDBC metadata
 
 		boolean metaSupportsScrollable = false;
 		boolean metaSupportsGetGeneratedKeys = false;
 		boolean metaSupportsBatchUpdates = false;
 		boolean metaReportsDDLCausesTxnCommit = false;
 		boolean metaReportsDDLInTxnSupported = true;
 		Dialect dialect = null;
 
 		// 'hibernate.temp.use_jdbc_metadata_defaults' is a temporary magic value.
 		// The need for it is intended to be alleviated with future development, thus it is
 		// not defined as an Environment constant...
 		//
 		// it is used to control whether we should consult the JDBC metadata to determine
 		// certain Settings default values; it is useful to *not* do this when the database
 		// may not be available (mainly in tools usage).
 		boolean useJdbcMetadata = ConfigurationHelper.getBoolean( "hibernate.temp.use_jdbc_metadata_defaults", props, true );
 		if ( useJdbcMetadata ) {
 			try {
 				Connection conn = connections.getConnection();
 				try {
 					DatabaseMetaData meta = conn.getMetaData();
 					log.info( "Database ->\n" +
 							"       name : " + meta.getDatabaseProductName() + '\n' +
 							"    version : " +  meta.getDatabaseProductVersion() + '\n' +
 							"      major : " + meta.getDatabaseMajorVersion() + '\n' +
 							"      minor : " + meta.getDatabaseMinorVersion()
 					);
 					log.info( "Driver ->\n" +
 							"       name : " + meta.getDriverName() + '\n' +
 							"    version : " + meta.getDriverVersion() + '\n' +
 							"      major : " + meta.getDriverMajorVersion() + '\n' +
 							"      minor : " + meta.getDriverMinorVersion()
 					);
 
 					dialect = DialectFactory.buildDialect( props, conn );
 
 					metaSupportsScrollable = meta.supportsResultSetType( ResultSet.TYPE_SCROLL_INSENSITIVE );
 					metaSupportsBatchUpdates = meta.supportsBatchUpdates();
 					metaReportsDDLCausesTxnCommit = meta.dataDefinitionCausesTransactionCommit();
 					metaReportsDDLInTxnSupported = !meta.dataDefinitionIgnoredInTransactions();
 					metaSupportsGetGeneratedKeys = meta.supportsGetGeneratedKeys();
 				}
 				catch ( SQLException sqle ) {
 					log.warn( "Could not obtain connection metadata", sqle );
 				}
 				finally {
 					connections.closeConnection( conn );
 				}
 			}
 			catch ( SQLException sqle ) {
 				log.warn( "Could not obtain connection to query metadata", sqle );
 				dialect = DialectFactory.buildDialect( props );
 			}
 			catch ( UnsupportedOperationException uoe ) {
 				// user supplied JDBC connections
 				dialect = DialectFactory.buildDialect( props );
 			}
 		}
 		else {
 			dialect = DialectFactory.buildDialect( props );
 		}
 
 		settings.setDataDefinitionImplicitCommit( metaReportsDDLCausesTxnCommit );
 		settings.setDataDefinitionInTransactionSupported( metaReportsDDLInTxnSupported );
 		settings.setDialect( dialect );
 
 		//use dialect default properties
 		final Properties properties = new Properties();
 		properties.putAll( dialect.getDefaultProperties() );
 		properties.putAll( props );
 
 		settings.setJdbcSupport( new JdbcSupport( ! ConfigurationHelper.getBoolean( Environment.NON_CONTEXTUAL_LOB_CREATION, properties ) ) );
 
 		// Transaction settings:
 
 		TransactionFactory transactionFactory = createTransactionFactory(properties);
 		settings.setTransactionFactory(transactionFactory);
 		settings.setTransactionManagerLookup( createTransactionManagerLookup(properties) );
 
 		boolean flushBeforeCompletion = ConfigurationHelper.getBoolean(Environment.FLUSH_BEFORE_COMPLETION, properties);
 		log.info("Automatic flush during beforeCompletion(): " + enabledDisabled(flushBeforeCompletion) );
 		settings.setFlushBeforeCompletionEnabled(flushBeforeCompletion);
 
 		boolean autoCloseSession = ConfigurationHelper.getBoolean(Environment.AUTO_CLOSE_SESSION, properties);
 		log.info("Automatic session close at end of transaction: " + enabledDisabled(autoCloseSession) );
 		settings.setAutoCloseSessionEnabled(autoCloseSession);
 
 		//JDBC and connection settings:
 
 		int batchSize = ConfigurationHelper.getInt(Environment.STATEMENT_BATCH_SIZE, properties, 0);
 		if ( !metaSupportsBatchUpdates ) batchSize = 0;
 		if (batchSize>0) log.info("JDBC batch size: " + batchSize);
 		settings.setJdbcBatchSize(batchSize);
 		boolean jdbcBatchVersionedData = ConfigurationHelper.getBoolean(Environment.BATCH_VERSIONED_DATA, properties, false);
 		if (batchSize>0) log.info("JDBC batch updates for versioned data: " + enabledDisabled(jdbcBatchVersionedData) );
 		settings.setJdbcBatchVersionedData(jdbcBatchVersionedData);
 		settings.setBatcherFactory( createBatcherFactory(properties, batchSize) );
 
 		boolean useScrollableResultSets = ConfigurationHelper.getBoolean(Environment.USE_SCROLLABLE_RESULTSET, properties, metaSupportsScrollable);
 		log.info("Scrollable result sets: " + enabledDisabled(useScrollableResultSets) );
 		settings.setScrollableResultSetsEnabled(useScrollableResultSets);
 
 		boolean wrapResultSets = ConfigurationHelper.getBoolean(Environment.WRAP_RESULT_SETS, properties, false);
 		log.debug( "Wrap result sets: " + enabledDisabled(wrapResultSets) );
 		settings.setWrapResultSetsEnabled(wrapResultSets);
 
 		boolean useGetGeneratedKeys = ConfigurationHelper.getBoolean(Environment.USE_GET_GENERATED_KEYS, properties, metaSupportsGetGeneratedKeys);
 		log.info("JDBC3 getGeneratedKeys(): " + enabledDisabled(useGetGeneratedKeys) );
 		settings.setGetGeneratedKeysEnabled(useGetGeneratedKeys);
 
 		Integer statementFetchSize = ConfigurationHelper.getInteger(Environment.STATEMENT_FETCH_SIZE, properties);
 		if (statementFetchSize!=null) log.info("JDBC result set fetch size: " + statementFetchSize);
 		settings.setJdbcFetchSize(statementFetchSize);
 
 		String releaseModeName = ConfigurationHelper.getString( Environment.RELEASE_CONNECTIONS, properties, "auto" );
 		log.info( "Connection release mode: " + releaseModeName );
 		ConnectionReleaseMode releaseMode;
 		if ( "auto".equals(releaseModeName) ) {
 			releaseMode = transactionFactory.getDefaultReleaseMode();
 		}
 		else {
 			releaseMode = ConnectionReleaseMode.parse( releaseModeName );
 			if ( releaseMode == ConnectionReleaseMode.AFTER_STATEMENT && !connections.supportsAggressiveRelease() ) {
 				log.warn( "Overriding release mode as connection provider does not support 'after_statement'" );
 				releaseMode = ConnectionReleaseMode.AFTER_TRANSACTION;
 			}
 		}
 		settings.setConnectionReleaseMode( releaseMode );
 
 		//SQL Generation settings:
 
 		String defaultSchema = properties.getProperty(Environment.DEFAULT_SCHEMA);
 		String defaultCatalog = properties.getProperty(Environment.DEFAULT_CATALOG);
 		if (defaultSchema!=null) log.info("Default schema: " + defaultSchema);
 		if (defaultCatalog!=null) log.info("Default catalog: " + defaultCatalog);
 		settings.setDefaultSchemaName(defaultSchema);
 		settings.setDefaultCatalogName(defaultCatalog);
 
 		Integer maxFetchDepth = ConfigurationHelper.getInteger(Environment.MAX_FETCH_DEPTH, properties);
 		if (maxFetchDepth!=null) log.info("Maximum outer join fetch depth: " + maxFetchDepth);
 		settings.setMaximumFetchDepth(maxFetchDepth);
 		int batchFetchSize = ConfigurationHelper.getInt(Environment.DEFAULT_BATCH_FETCH_SIZE, properties, 1);
 		log.info("Default batch fetch size: " + batchFetchSize);
 		settings.setDefaultBatchFetchSize(batchFetchSize);
 
 		boolean comments = ConfigurationHelper.getBoolean(Environment.USE_SQL_COMMENTS, properties);
 		log.info( "Generate SQL with comments: " + enabledDisabled(comments) );
 		settings.setCommentsEnabled(comments);
 
 		boolean orderUpdates = ConfigurationHelper.getBoolean(Environment.ORDER_UPDATES, properties);
 		log.info( "Order SQL updates by primary key: " + enabledDisabled(orderUpdates) );
 		settings.setOrderUpdatesEnabled(orderUpdates);
 
 		boolean orderInserts = ConfigurationHelper.getBoolean(Environment.ORDER_INSERTS, properties);
 		log.info( "Order SQL inserts for batching: " + enabledDisabled( orderInserts ) );
 		settings.setOrderInsertsEnabled( orderInserts );
 
 		//Query parser settings:
 
 		settings.setQueryTranslatorFactory( createQueryTranslatorFactory(properties) );
 
 		Map querySubstitutions = ConfigurationHelper.toMap(Environment.QUERY_SUBSTITUTIONS, " ,=;:\n\t\r\f", properties);
 		log.info("Query language substitutions: " + querySubstitutions);
 		settings.setQuerySubstitutions(querySubstitutions);
 
 		boolean jpaqlCompliance = ConfigurationHelper.getBoolean( Environment.JPAQL_STRICT_COMPLIANCE, properties, false );
 		settings.setStrictJPAQLCompliance( jpaqlCompliance );
 		log.info( "JPA-QL strict compliance: " + enabledDisabled( jpaqlCompliance ) );
 
 		// Second-level / query cache:
 
 		boolean useSecondLevelCache = ConfigurationHelper.getBoolean(Environment.USE_SECOND_LEVEL_CACHE, properties, true);
 		log.info( "Second-level cache: " + enabledDisabled(useSecondLevelCache) );
 		settings.setSecondLevelCacheEnabled(useSecondLevelCache);
 
 		boolean useQueryCache = ConfigurationHelper.getBoolean(Environment.USE_QUERY_CACHE, properties);
 		log.info( "Query cache: " + enabledDisabled(useQueryCache) );
 		settings.setQueryCacheEnabled(useQueryCache);
 
 		// The cache provider is needed when we either have second-level cache enabled
 		// or query cache enabled.  Note that useSecondLevelCache is enabled by default
 		settings.setRegionFactory( createRegionFactory( properties, ( useSecondLevelCache || useQueryCache ) ) );
 
 		boolean useMinimalPuts = ConfigurationHelper.getBoolean(
 				Environment.USE_MINIMAL_PUTS, properties, settings.getRegionFactory().isMinimalPutsEnabledByDefault()
 		);
 		log.info( "Optimize cache for minimal puts: " + enabledDisabled(useMinimalPuts) );
 		settings.setMinimalPutsEnabled(useMinimalPuts);
 
 		String prefix = properties.getProperty(Environment.CACHE_REGION_PREFIX);
 		if ( StringHelper.isEmpty(prefix) ) prefix=null;
 		if (prefix!=null) log.info("Cache region prefix: "+ prefix);
 		settings.setCacheRegionPrefix(prefix);
 
 		boolean useStructuredCacheEntries = ConfigurationHelper.getBoolean(Environment.USE_STRUCTURED_CACHE, properties, false);
 		log.info( "Structured second-level cache entries: " + enabledDisabled(useStructuredCacheEntries) );
 		settings.setStructuredCacheEntriesEnabled(useStructuredCacheEntries);
 
 		if (useQueryCache) settings.setQueryCacheFactory( createQueryCacheFactory(properties) );
 
 		//SQL Exception converter:
 
 		SQLExceptionConverter sqlExceptionConverter;
 		try {
 			sqlExceptionConverter = SQLExceptionConverterFactory.buildSQLExceptionConverter( dialect, properties );
 		}
 		catch(HibernateException e) {
 			log.warn("Error building SQLExceptionConverter; using minimal converter");
 			sqlExceptionConverter = SQLExceptionConverterFactory.buildMinimalSQLExceptionConverter();
 		}
 		settings.setSQLExceptionConverter(sqlExceptionConverter);
 
 		//Statistics and logging:
 
 		boolean showSql = ConfigurationHelper.getBoolean(Environment.SHOW_SQL, properties);
 		if (showSql) log.info("Echoing all SQL to stdout");
 //		settings.setShowSqlEnabled(showSql);
 
 		boolean formatSql = ConfigurationHelper.getBoolean(Environment.FORMAT_SQL, properties);
 //		settings.setFormatSqlEnabled(formatSql);
 
 		settings.setSqlStatementLogger( new SQLStatementLogger( showSql, formatSql ) );
 
 		boolean useStatistics = ConfigurationHelper.getBoolean(Environment.GENERATE_STATISTICS, properties);
 		log.info( "Statistics: " + enabledDisabled(useStatistics) );
 		settings.setStatisticsEnabled(useStatistics);
 
 		boolean useIdentifierRollback = ConfigurationHelper.getBoolean(Environment.USE_IDENTIFIER_ROLLBACK, properties);
 		log.info( "Deleted entity synthetic identifier rollback: " + enabledDisabled(useIdentifierRollback) );
 		settings.setIdentifierRollbackEnabled(useIdentifierRollback);
 
 		//Schema export:
 
 		String autoSchemaExport = properties.getProperty(Environment.HBM2DDL_AUTO);
 		if ( "validate".equals(autoSchemaExport) ) settings.setAutoValidateSchema(true);
 		if ( "update".equals(autoSchemaExport) ) settings.setAutoUpdateSchema(true);
 		if ( "create".equals(autoSchemaExport) ) settings.setAutoCreateSchema(true);
 		if ( "create-drop".equals(autoSchemaExport) ) {
 			settings.setAutoCreateSchema(true);
 			settings.setAutoDropSchema(true);
 		}
 		settings.setImportFiles( properties.getProperty( Environment.HBM2DDL_IMPORT_FILES ) );
 
 		EntityMode defaultEntityMode = EntityMode.parse( properties.getProperty( Environment.DEFAULT_ENTITY_MODE ) );
 		log.info( "Default entity-mode: " + defaultEntityMode );
 		settings.setDefaultEntityMode( defaultEntityMode );
 
 		boolean namedQueryChecking = ConfigurationHelper.getBoolean( Environment.QUERY_STARTUP_CHECKING, properties, true );
 		log.info( "Named query checking : " + enabledDisabled( namedQueryChecking ) );
 		settings.setNamedQueryStartupCheckingEnabled( namedQueryChecking );
 
 		boolean checkNullability = ConfigurationHelper.getBoolean(Environment.CHECK_NULLABILITY, properties, true);
 		log.info( "Check Nullability in Core (should be disabled when Bean Validation is on): " + enabledDisabled(checkNullability) );
 		settings.setCheckNullability(checkNullability);
 
 
 //		String provider = properties.getProperty( Environment.BYTECODE_PROVIDER );
 //		log.info( "Bytecode provider name : " + provider );
 //		BytecodeProvider bytecodeProvider = buildBytecodeProvider( provider );
 //		settings.setBytecodeProvider( bytecodeProvider );
 
 		return settings;
 
 	}
 
 	protected BytecodeProvider buildBytecodeProvider(String providerName) {
 		if ( "javassist".equals( providerName ) ) {
 			return new org.hibernate.bytecode.javassist.BytecodeProviderImpl();
 		}
 		else if ( "cglib".equals( providerName ) ) {
 			return new org.hibernate.bytecode.cglib.BytecodeProviderImpl();
 		}
 		else {
 			log.debug( "using javassist as bytecode provider by default" );
 			return new org.hibernate.bytecode.javassist.BytecodeProviderImpl();
 		}
 	}
 
 	private static String enabledDisabled(boolean value) {
 		return value ? "enabled" : "disabled";
 	}
 
 	protected QueryCacheFactory createQueryCacheFactory(Properties properties) {
 		String queryCacheFactoryClassName = ConfigurationHelper.getString(
 				Environment.QUERY_CACHE_FACTORY, properties, "org.hibernate.cache.StandardQueryCacheFactory"
 		);
 		log.info("Query cache factory: " + queryCacheFactoryClassName);
 		try {
 			return (QueryCacheFactory) ReflectHelper.classForName(queryCacheFactoryClassName).newInstance();
 		}
 		catch (Exception cnfe) {
 			throw new HibernateException("could not instantiate QueryCacheFactory: " + queryCacheFactoryClassName, cnfe);
 		}
 	}
 
 	public static RegionFactory createRegionFactory(Properties properties, boolean cachingEnabled) {
 		String regionFactoryClassName = ConfigurationHelper.getString( Environment.CACHE_REGION_FACTORY, properties, null );
 		if ( regionFactoryClassName == null && cachingEnabled ) {
 			String providerClassName = ConfigurationHelper.getString( Environment.CACHE_PROVIDER, properties, null );
 			if ( providerClassName != null ) {
 				// legacy behavior, apply the bridge...
 				regionFactoryClassName = RegionFactoryCacheProviderBridge.class.getName();
 			}
 		}
 		if ( regionFactoryClassName == null ) {
 			regionFactoryClassName = DEF_CACHE_REG_FACTORY;
 		}
 		log.info( "Cache region factory : " + regionFactoryClassName );
 		try {
 			try {
 				return (RegionFactory) ReflectHelper.classForName( regionFactoryClassName )
 						.getConstructor( Properties.class )
 						.newInstance( properties );
 			}
 			catch ( NoSuchMethodException nsme ) {
 				// no constructor accepting Properties found, try no arg constructor
 				log.debug(
 						regionFactoryClassName + " did not provide constructor accepting java.util.Properties; " +
 								"attempting no-arg constructor."
 				);
 				return (RegionFactory) ReflectHelper.classForName( regionFactoryClassName ).newInstance();
 			}
 		}
 		catch ( Exception e ) {
 			throw new HibernateException( "could not instantiate RegionFactory [" + regionFactoryClassName + "]", e );
 		}
 	}
 
 	protected QueryTranslatorFactory createQueryTranslatorFactory(Properties properties) {
 		String className = ConfigurationHelper.getString(
 				Environment.QUERY_TRANSLATOR, properties, "org.hibernate.hql.ast.ASTQueryTranslatorFactory"
 		);
 		log.info("Query translator: " + className);
 		try {
 			return (QueryTranslatorFactory) ReflectHelper.classForName(className).newInstance();
 		}
 		catch (Exception cnfe) {
 			throw new HibernateException("could not instantiate QueryTranslatorFactory: " + className, cnfe);
 		}
 	}
 
 	protected BatcherFactory createBatcherFactory(Properties properties, int batchSize) {
 		String batcherClass = properties.getProperty(Environment.BATCH_STRATEGY);
 		if (batcherClass==null) {
 			return batchSize == 0
 					? new NonBatchingBatcherFactory()
 					: new BatchingBatcherFactory();
 		}
 		else {
 			log.info("Batcher factory: " + batcherClass);
 			try {
 				return (BatcherFactory) ReflectHelper.classForName(batcherClass).newInstance();
 			}
 			catch (Exception cnfe) {
 				throw new HibernateException("could not instantiate BatcherFactory: " + batcherClass, cnfe);
 			}
 		}
 	}
 
-	protected ConnectionProvider createConnectionProvider(Properties properties) {
-		return ConnectionProviderFactory.newConnectionProvider(properties);
-	}
-
 	protected TransactionFactory createTransactionFactory(Properties properties) {
 		return TransactionFactoryFactory.buildTransactionFactory(properties);
 	}
 
 	protected TransactionManagerLookup createTransactionManagerLookup(Properties properties) {
 		return TransactionManagerLookupFactory.getTransactionManagerLookup(properties);
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/connection/ConnectionProvider.java b/hibernate-core/src/main/java/org/hibernate/connection/ConnectionProvider.java
deleted file mode 100644
index e05b6ab2dc..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/connection/ConnectionProvider.java
+++ /dev/null
@@ -1,94 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.connection;
-import java.sql.Connection;
-import java.sql.SQLException;
-import java.util.Properties;
-
-import org.hibernate.HibernateException;
-
-/**
- * A strategy for obtaining JDBC connections.
- * <br><br>
- * Implementors might also implement connection pooling.<br>
- * <br>
- * The <tt>ConnectionProvider</tt> interface is not intended to be
- * exposed to the application. Instead it is used internally by
- * Hibernate to obtain connections.<br>
- * <br>
- * Implementors should provide a public default constructor.
- *
- * @see ConnectionProviderFactory
- * @author Gavin King
- */
-public interface ConnectionProvider {
-	/**
-	 * Initialize the connection provider from given properties.
-	 * @param props <tt>SessionFactory</tt> properties
-	 */
-	public void configure(Properties props) throws HibernateException;
-	/**
-	 * Grab a connection, with the autocommit mode specified by
-	 * <tt>hibernate.connection.autocommit</tt>.
-	 * @return a JDBC connection
-	 * @throws SQLException
-	 */
-	public Connection getConnection() throws SQLException;
-	/**
-	 * Dispose of a used connection.
-	 * @param conn a JDBC connection
-	 * @throws SQLException
-	 */
-	public void closeConnection(Connection conn) throws SQLException;
-
-	/**
-	 * Release all resources held by this provider. JavaDoc requires a second sentence.
-	 * @throws HibernateException
-	 */
-	public void close() throws HibernateException;
-
-	/**
-	 * Does this connection provider support aggressive release of JDBC
-	 * connections and re-acquistion of those connections (if need be) later?
-	 * <p/>
-	 * This is used in conjunction with {@link org.hibernate.cfg.Environment.RELEASE_CONNECTIONS}
-	 * to aggressively release JDBC connections.  However, the configured ConnectionProvider
-	 * must support re-acquisition of the same underlying connection for that semantic to work.
-	 * <p/>
-	 * Typically, this is only true in managed environments where a container
-	 * tracks connections by transaction or thread.
-	 *
-	 * Note that JTA semantic depends on the fact that the underlying connection provider does
-	 * support aggressive release.
-	 */
-	public boolean supportsAggressiveRelease();
-}
-
-
-
-
-
-
-
diff --git a/hibernate-core/src/main/java/org/hibernate/connection/ConnectionProviderFactory.java b/hibernate-core/src/main/java/org/hibernate/connection/ConnectionProviderFactory.java
deleted file mode 100644
index f2116bc230..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/connection/ConnectionProviderFactory.java
+++ /dev/null
@@ -1,235 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.connection;
-
-import java.beans.BeanInfo;
-import java.beans.IntrospectionException;
-import java.beans.Introspector;
-import java.beans.PropertyDescriptor;
-import java.lang.reflect.InvocationTargetException;
-import java.lang.reflect.Method;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.Map;
-import java.util.Properties;
-import java.util.Set;
-
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import org.hibernate.HibernateException;
-import org.hibernate.cfg.Environment;
-import org.hibernate.util.ReflectHelper;
-
-/**
- * Instantiates a connection provider given either <tt>System</tt> properties or
- * a <tt>java.util.Properties</tt> instance. The <tt>ConnectionProviderFactory</tt>
- * first attempts to find a name of a <tt>ConnectionProvider</tt> subclass in the
- * property <tt>hibernate.connection.provider_class</tt>. If missing, heuristics are used
- * to choose either <tt>DriverManagerConnectionProvider</tt>,
- * <tt>DatasourceConnectionProvider</tt>, <tt>C3P0ConnectionProvider</tt> or
- * <tt>DBCPConnectionProvider</tt>.
- *
- * @author Gavin King
- * @see ConnectionProvider
- */
-
-public final class ConnectionProviderFactory {
-
-	private static final Logger log = LoggerFactory.getLogger( ConnectionProviderFactory.class );
-
-	/**
-	 * Instantiate a <tt>ConnectionProvider</tt> using <tt>System</tt> properties.
-	 *
-	 * @return The created connection provider.
-	 *
-	 * @throws HibernateException
-	 */
-	public static ConnectionProvider newConnectionProvider() throws HibernateException {
-		return newConnectionProvider( Environment.getProperties() );
-	}
-
-	/**
-	 * Instantiate a <tt>ConnectionProvider</tt> using given properties.
-	 * Method newConnectionProvider.
-	 *
-	 * @param properties hibernate <tt>SessionFactory</tt> properties
-	 *
-	 * @return ConnectionProvider
-	 *
-	 * @throws HibernateException
-	 */
-	public static ConnectionProvider newConnectionProvider(Properties properties) throws HibernateException {
-		return newConnectionProvider( properties, null );
-	}
-
-	/**
-	 * Create a connection provider based on the given information.
-	 *
-	 * @param properties Properties being used to build the {@link org.hibernate.SessionFactory}.
-	 * @param connectionProviderInjectionData Something to be injected in the connection provided
-	 *
-	 * @return The created connection provider
-	 *
-	 * @throws HibernateException
-	 */
-	public static ConnectionProvider newConnectionProvider(Properties properties, Map connectionProviderInjectionData)
-			throws HibernateException {
-		ConnectionProvider connections;
-		String providerClass = properties.getProperty( Environment.CONNECTION_PROVIDER );
-		if ( providerClass != null ) {
-			connections = initializeConnectionProviderFromConfig( providerClass );
-		}
-		else if ( c3p0ConfigDefined( properties ) && c3p0ProviderPresent() ) {
-			connections = initializeConnectionProviderFromConfig("org.hibernate.connection.C3P0ConnectionProvider");
-		}
-		else if ( properties.getProperty( Environment.DATASOURCE ) != null ) {
-			connections = new DatasourceConnectionProvider();
-		}
-		else if ( properties.getProperty( Environment.URL ) != null ) {
-			connections = new DriverManagerConnectionProvider();
-		}
-		else {
-			connections = new UserSuppliedConnectionProvider();
-		}
-
-		if ( connectionProviderInjectionData != null && connectionProviderInjectionData.size() != 0 ) {
-			//inject the data
-			try {
-				BeanInfo info = Introspector.getBeanInfo( connections.getClass() );
-				PropertyDescriptor[] descritors = info.getPropertyDescriptors();
-				int size = descritors.length;
-				for ( int index = 0; index < size; index++ ) {
-					String propertyName = descritors[index].getName();
-					if ( connectionProviderInjectionData.containsKey( propertyName ) ) {
-						Method method = descritors[index].getWriteMethod();
-						method.invoke(
-								connections, new Object[] { connectionProviderInjectionData.get( propertyName ) }
-						);
-					}
-				}
-			}
-			catch ( IntrospectionException e ) {
-				throw new HibernateException( "Unable to inject objects into the connection provider", e );
-			}
-			catch ( IllegalAccessException e ) {
-				throw new HibernateException( "Unable to inject objects into the connection provider", e );
-			}
-			catch ( InvocationTargetException e ) {
-				throw new HibernateException( "Unable to inject objects into the connection provider", e );
-			}
-		}
-		connections.configure( properties );
-		return connections;
-	}
-
-	private static boolean c3p0ProviderPresent() {
-		try {
-			ReflectHelper.classForName( "org.hibernate.connection.C3P0ConnectionProvider" );
-		}
-		catch ( ClassNotFoundException e ) {
-			log.warn( "c3p0 properties is specificed, but could not find org.hibernate.connection.C3P0ConnectionProvider from the classpath, " +
-					"these properties are going to be ignored." );
-			return false;
-		}
-		return true;
-	}
-
-	private static boolean c3p0ConfigDefined(Properties properties) {
-		Iterator iter = properties.keySet().iterator();
-		while ( iter.hasNext() ) {
-			String property = (String) iter.next();
-			if ( property.startsWith( "hibernate.c3p0" ) ) {
-				return true;
-			}
-		}
-		return false;
-	}
-
-	private static ConnectionProvider initializeConnectionProviderFromConfig(String providerClass) {
-		ConnectionProvider connections;
-		try {
-			log.info( "Initializing connection provider: " + providerClass );
-			connections = (ConnectionProvider) ReflectHelper.classForName( providerClass ).newInstance();
-		}
-		catch ( Exception e ) {
-			log.error( "Could not instantiate connection provider", e );
-			throw new HibernateException( "Could not instantiate connection provider: " + providerClass );
-		}
-		return connections;
-	}
-
-	// cannot be instantiated
-
-	private ConnectionProviderFactory() {
-		throw new UnsupportedOperationException();
-	}
-
-	/**
-	 * Transform JDBC connection properties.
-	 *
-	 * Passed in the form <tt>hibernate.connection.*</tt> to the
-	 * format accepted by <tt>DriverManager</tt> by trimming the leading "<tt>hibernate.connection</tt>".
-	 */
-	public static Properties getConnectionProperties(Properties properties) {
-
-		Iterator iter = properties.keySet().iterator();
-		Properties result = new Properties();
-		while ( iter.hasNext() ) {
-			String prop = (String) iter.next();
-			if ( prop.startsWith( Environment.CONNECTION_PREFIX ) && !SPECIAL_PROPERTIES.contains( prop ) ) {
-				result.setProperty(
-						prop.substring( Environment.CONNECTION_PREFIX.length() + 1 ),
-						properties.getProperty( prop )
-				);
-			}
-		}
-		String userName = properties.getProperty( Environment.USER );
-		if ( userName != null ) {
-			result.setProperty( "user", userName );
-		}
-		return result;
-	}
-
-	private static final Set SPECIAL_PROPERTIES;
-
-	static {
-		SPECIAL_PROPERTIES = new HashSet();
-		SPECIAL_PROPERTIES.add( Environment.DATASOURCE );
-		SPECIAL_PROPERTIES.add( Environment.URL );
-		SPECIAL_PROPERTIES.add( Environment.CONNECTION_PROVIDER );
-		SPECIAL_PROPERTIES.add( Environment.POOL_SIZE );
-		SPECIAL_PROPERTIES.add( Environment.ISOLATION );
-		SPECIAL_PROPERTIES.add( Environment.DRIVER );
-		SPECIAL_PROPERTIES.add( Environment.USER );
-
-	}
-
-}
-
-
-
-
-
-
diff --git a/hibernate-core/src/main/java/org/hibernate/connection/DatasourceConnectionProvider.java b/hibernate-core/src/main/java/org/hibernate/connection/DatasourceConnectionProvider.java
deleted file mode 100644
index a10ab53489..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/connection/DatasourceConnectionProvider.java
+++ /dev/null
@@ -1,116 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.connection;
-
-import java.sql.Connection;
-import java.sql.SQLException;
-import java.util.Properties;
-
-import javax.sql.DataSource;
-
-import org.hibernate.HibernateException;
-import org.hibernate.cfg.Environment;
-import org.hibernate.internal.util.jndi.JndiHelper;
-
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * A connection provider that uses a <tt>DataSource</tt> registered with JNDI.
- * Hibernate will use this <tt>ConnectionProvider</tt> by default if the
- * property <tt>hibernate.connection.datasource</tt> is set.
- * @see ConnectionProvider
- * @author Gavin King
- */
-public class DatasourceConnectionProvider implements ConnectionProvider {
-	private DataSource ds;
-	private String user;
-	private String pass;
-
-	private static final Logger log = LoggerFactory.getLogger(DatasourceConnectionProvider.class);
-
-	public DataSource getDataSource() {
-		return ds;
-	}
-
-	public void setDataSource(DataSource ds) {
-		this.ds = ds;
-	}
-
-	public void configure(Properties props) throws HibernateException {
-
-		String jndiName = props.getProperty( Environment.DATASOURCE );
-		if ( jndiName == null ) {
-			String msg = "datasource JNDI name was not specified by property " + Environment.DATASOURCE;
-			log.error( msg );
-			throw new HibernateException( msg );
-		}
-
-		user = props.getProperty( Environment.USER );
-		pass = props.getProperty( Environment.PASS );
-
-		try {
-			ds = ( DataSource ) JndiHelper.getInitialContext( props ).lookup( jndiName );
-		}
-		catch ( Exception e ) {
-			log.error( "Could not find datasource: " + jndiName, e );
-			throw new HibernateException( "Could not find datasource", e );
-		}
-		if ( ds == null ) {
-			throw new HibernateException( "Could not find datasource: " + jndiName );
-		}
-		log.info( "Using datasource: " + jndiName );
-	}
-
-	public Connection getConnection() throws SQLException {
-		if (user != null || pass != null) {
-			return ds.getConnection(user, pass);
-		}
-		else {
-			return ds.getConnection();
-		}
-	}
-
-	public void closeConnection(Connection conn) throws SQLException {
-		conn.close();
-	}
-
-	public void close() {}
-
-	/**
-	 * @see ConnectionProvider#supportsAggressiveRelease()
-	 */
-	public boolean supportsAggressiveRelease() {
-		return true;
-	}
-
-}
-
-
-
-
-
-
-
diff --git a/hibernate-core/src/main/java/org/hibernate/connection/DriverManagerConnectionProvider.java b/hibernate-core/src/main/java/org/hibernate/connection/DriverManagerConnectionProvider.java
deleted file mode 100644
index 046d33d3a7..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/connection/DriverManagerConnectionProvider.java
+++ /dev/null
@@ -1,199 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.connection;
-
-import java.sql.Connection;
-import java.sql.DriverManager;
-import java.sql.SQLException;
-import java.util.ArrayList;
-import java.util.Iterator;
-import java.util.Properties;
-
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-import org.hibernate.HibernateException;
-import org.hibernate.cfg.Environment;
-import org.hibernate.internal.util.config.ConfigurationHelper;
-import org.hibernate.util.ReflectHelper;
-
-/**
- * A connection provider that uses <tt>java.sql.DriverManager</tt>. This provider
- * also implements a very rudimentary connection pool.
- * @see ConnectionProvider
- * @author Gavin King
- */
-public class DriverManagerConnectionProvider implements ConnectionProvider {
-
-	private String url;
-	private Properties connectionProps;
-	private Integer isolation;
-	private final ArrayList pool = new ArrayList();
-	private int poolSize;
-	private int checkedOut = 0;
-	private boolean autocommit;
-
-	private static final Logger log = LoggerFactory.getLogger(DriverManagerConnectionProvider.class);
-
-	public void configure(Properties props) throws HibernateException {
-
-		String driverClass = props.getProperty(Environment.DRIVER);
-
-		poolSize = ConfigurationHelper.getInt(Environment.POOL_SIZE, props, 20); //default pool size 20
-		log.info("Using Hibernate built-in connection pool (not for production use!)");
-		log.info("Hibernate connection pool size: " + poolSize);
-		
-		autocommit = ConfigurationHelper.getBoolean(Environment.AUTOCOMMIT, props);
-		log.info("autocommit mode: " + autocommit);
-
-		isolation = ConfigurationHelper.getInteger(Environment.ISOLATION, props);
-		if (isolation!=null)
-		log.info( "JDBC isolation level: " + Environment.isolationLevelToString( isolation.intValue() ) );
-
-		if (driverClass==null) {
-			log.warn("no JDBC Driver class was specified by property " + Environment.DRIVER);
-		}
-		else {
-			try {
-				// trying via forName() first to be as close to DriverManager's semantics
-				Class.forName(driverClass);
-			}
-			catch (ClassNotFoundException cnfe) {
-				try {
-					ReflectHelper.classForName(driverClass);
-				}
-				catch (ClassNotFoundException e) {
-					String msg = "JDBC Driver class not found: " + driverClass;
-					log.error( msg, e );
-					throw new HibernateException(msg, e);
-				}
-			}
-		}
-
-		url = props.getProperty( Environment.URL );
-		if ( url == null ) {
-			String msg = "JDBC URL was not specified by property " + Environment.URL;
-			log.error( msg );
-			throw new HibernateException( msg );
-		}
-
-		connectionProps = ConnectionProviderFactory.getConnectionProperties( props );
-
-		log.info( "using driver: " + driverClass + " at URL: " + url );
-		// if debug level is enabled, then log the password, otherwise mask it
-		if ( log.isDebugEnabled() ) {
-			log.info( "connection properties: " + connectionProps );
-		} 
-		else if ( log.isInfoEnabled() ) {
-			log.info( "connection properties: " + ConfigurationHelper.maskOut(connectionProps, "password") );
-		}
-
-	}
-
-	public Connection getConnection() throws SQLException {
-
-		if ( log.isTraceEnabled() ) log.trace( "total checked-out connections: " + checkedOut );
-
-		synchronized (pool) {
-			if ( !pool.isEmpty() ) {
-				int last = pool.size() - 1;
-				if ( log.isTraceEnabled() ) {
-					log.trace("using pooled JDBC connection, pool size: " + last);
-					checkedOut++;
-				}
-				Connection pooled = (Connection) pool.remove(last);
-				if (isolation!=null) pooled.setTransactionIsolation( isolation.intValue() );
-				if ( pooled.getAutoCommit()!=autocommit ) pooled.setAutoCommit(autocommit);
-				return pooled;
-			}
-		}
-
-		log.debug("opening new JDBC connection");
-		Connection conn = DriverManager.getConnection(url, connectionProps);
-		if (isolation!=null) conn.setTransactionIsolation( isolation.intValue() );
-		if ( conn.getAutoCommit()!=autocommit ) conn.setAutoCommit(autocommit);
-
-		if ( log.isDebugEnabled() ) {
-			log.debug( "created connection to: " + url + ", Isolation Level: " + conn.getTransactionIsolation() );
-		}
-		if ( log.isTraceEnabled() ) checkedOut++;
-
-		return conn;
-	}
-
-	public void closeConnection(Connection conn) throws SQLException {
-
-		if ( log.isDebugEnabled() ) checkedOut--;
-
-		synchronized (pool) {
-			int currentSize = pool.size();
-			if ( currentSize < poolSize ) {
-				if ( log.isTraceEnabled() ) log.trace("returning connection to pool, pool size: " + (currentSize + 1) );
-				pool.add(conn);
-				return;
-			}
-		}
-
-		log.debug("closing JDBC connection");
-
-		conn.close();
-
-	}
-
-	protected void finalize() {
-		close();
-	}
-
-	public void close() {
-
-		log.info("cleaning up connection pool: " + url);
-
-		Iterator iter = pool.iterator();
-		while ( iter.hasNext() ) {
-			try {
-				( (Connection) iter.next() ).close();
-			}
-			catch (SQLException sqle) {
-				log.warn("problem closing pooled connection", sqle);
-			}
-		}
-		pool.clear();
-
-	}
-
-	/**
-	 * @see ConnectionProvider#supportsAggressiveRelease()
-	 */
-	public boolean supportsAggressiveRelease() {
-		return false;
-	}
-
-}
-
-
-
-
-
-
-
diff --git a/hibernate-core/src/main/java/org/hibernate/connection/UserSuppliedConnectionProvider.java b/hibernate-core/src/main/java/org/hibernate/connection/UserSuppliedConnectionProvider.java
deleted file mode 100644
index b676676bf6..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/connection/UserSuppliedConnectionProvider.java
+++ /dev/null
@@ -1,80 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.connection;
-
-import java.sql.Connection;
-import java.util.Properties;
-
-import org.slf4j.LoggerFactory;
-import org.hibernate.HibernateException;
-
-/**
- * An implementation of the <literal>ConnectionProvider</literal> interface that
- * simply throws an exception when a connection is requested. This implementation
- * indicates that the user is expected to supply a JDBC connection.
- * @see ConnectionProvider
- * @author Gavin King
- */
-public class UserSuppliedConnectionProvider implements ConnectionProvider {
-
-	/**
-	 * @see org.hibernate.connection.ConnectionProvider#configure(Properties)
-	 */
-	public void configure(Properties props) throws HibernateException {
-		LoggerFactory.getLogger( UserSuppliedConnectionProvider.class )
-				.warn( "No connection properties specified - the user must supply JDBC connections" );
-	}
-
-	/**
-	 * @see org.hibernate.connection.ConnectionProvider#getConnection()
-	 */
-	public Connection getConnection() {
-		throw new UnsupportedOperationException("The user must supply a JDBC connection");
-	}
-
-	/**
-	 * @see org.hibernate.connection.ConnectionProvider#closeConnection(Connection)
-	 */
-	public void closeConnection(Connection conn) {
-		throw new UnsupportedOperationException("The user must supply a JDBC connection");
-	}
-
-	public void close() {
-	}
-
-	/**
-	 * @see ConnectionProvider#supportsAggressiveRelease()
-	 */
-	public boolean supportsAggressiveRelease() {
-		return false;
-	}
-
-}
-
-
-
-
-
-
diff --git a/hibernate-core/src/main/java/org/hibernate/connection/package.html b/hibernate-core/src/main/java/org/hibernate/connection/package.html
deleted file mode 100755
index ebe7d7f74d..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/connection/package.html
+++ /dev/null
@@ -1,38 +0,0 @@
-<!--
-  ~ Hibernate, Relational Persistence for Idiomatic Java
-  ~
-  ~ Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
-  ~ indicated by the @author tags or express copyright attribution
-  ~ statements applied by the authors.  All third-party contributions are
-  ~ distributed under license by Red Hat Middleware LLC.
-  ~
-  ~ This copyrighted material is made available to anyone wishing to use, modify,
-  ~ copy, or redistribute it subject to the terms and conditions of the GNU
-  ~ Lesser General Public License, as published by the Free Software Foundation.
-  ~
-  ~ This program is distributed in the hope that it will be useful,
-  ~ but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
-  ~ or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
-  ~ for more details.
-  ~
-  ~ You should have received a copy of the GNU Lesser General Public License
-  ~ along with this distribution; if not, write to:
-  ~ Free Software Foundation, Inc.
-  ~ 51 Franklin Street, Fifth Floor
-  ~ Boston, MA  02110-1301  USA
-  ~
-  -->
-
-<html>
-<head></head>
-<body>
-<p>
-	This package abstracts the mechanism for obtaining
-	a JDBC connection.
-</p>
-<p>
-	A concrete implementation of <tt>ConnectionProvider</tt> may be 
-	selected by specifying <tt>hibernate.connection.provider_class</tt>.
-</p>
-</body>
-</html>
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/SessionFactoryImplementor.java b/hibernate-core/src/main/java/org/hibernate/engine/SessionFactoryImplementor.java
index 23e2470918..026285a19c 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/SessionFactoryImplementor.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/SessionFactoryImplementor.java
@@ -1,247 +1,247 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.engine;
 
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import java.sql.Connection;
 
 import javax.transaction.TransactionManager;
 
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.MappingException;
 import org.hibernate.SessionFactory;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.proxy.EntityNotFoundDelegate;
 import org.hibernate.engine.query.QueryPlanCache;
 import org.hibernate.engine.profile.FetchProfile;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.cache.QueryCache;
 import org.hibernate.cache.UpdateTimestampsCache;
 import org.hibernate.cache.Region;
 import org.hibernate.cfg.Settings;
-import org.hibernate.connection.ConnectionProvider;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.exception.SQLExceptionConverter;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.stat.StatisticsImplementor;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeResolver;
 
 /**
  * Defines the internal contract between the <tt>SessionFactory</tt> and other parts of
  * Hibernate such as implementors of <tt>Type</tt>.
  *
  * @see org.hibernate.SessionFactory
  * @see org.hibernate.impl.SessionFactoryImpl
  * @author Gavin King
  */
 public interface SessionFactoryImplementor extends Mapping, SessionFactory {
 	/**
 	 * Retrieve the {@link Type} resolver associated with this factory.
 	 *
 	 * @return The type resolver
 	 */
 	public TypeResolver getTypeResolver();
 
 	/**
 	 * Get a copy of the Properties used to configure this session factory.
 	 *
 	 * @return The properties.
 	 */
 	public Properties getProperties();
 
 	/**
 	 * Get the persister for the named entity
 	 *
 	 * @param entityName The name of the entity for which to retrieve the persister.
 	 * @return The persister
 	 * @throws MappingException Indicates persister could not be found with that name.
 	 */
 	public EntityPersister getEntityPersister(String entityName) throws MappingException;
 
 	/**
 	 * Get the persister object for a collection role.
 	 *
 	 * @param role The role (name) of the collection for which to retrieve the
 	 * persister.
 	 * @return The persister
 	 * @throws MappingException Indicates persister could not be found with that role.
 	 */
 	public CollectionPersister getCollectionPersister(String role) throws MappingException;
 
 	/**
 	 * Get the SQL dialect.
 	 * <p/>
 	 * Shorthand for {@link #getSettings()}.{@link Settings#getDialect()}
 	 *
 	 * @return The dialect
 	 */
 	public Dialect getDialect();
 
 	/**
 	 * Get the factory scoped interceptor for this factory.
 	 *
 	 * @return The factory scope interceptor, or null if none.
 	 */
 	public Interceptor getInterceptor();
 
 	public QueryPlanCache getQueryPlanCache();
 
 	/**
 	 * Get the return types of a query
 	 */
 	public Type[] getReturnTypes(String queryString) throws HibernateException;
 
 	/**
 	 * Get the return aliases of a query
 	 */
 	public String[] getReturnAliases(String queryString) throws HibernateException;
 
 	/**
 	 * Get the connection provider
 	 */
 	public ConnectionProvider getConnectionProvider();
 	/**
 	 * Get the names of all persistent classes that implement/extend the given interface/class
 	 */
 	public String[] getImplementors(String className) throws MappingException;
 	/**
 	 * Get a class name, using query language imports
 	 */
 	public String getImportedClassName(String name);
 
 
 	/**
 	 * Get the JTA transaction manager
 	 */
 	public TransactionManager getTransactionManager();
 
 
 	/**
 	 * Get the default query cache
 	 */
 	public QueryCache getQueryCache();
 	/**
 	 * Get a particular named query cache, or the default cache
 	 * @param regionName the name of the cache region, or null for the default query cache
 	 * @return the existing cache, or a newly created cache if none by that region name
 	 */
 	public QueryCache getQueryCache(String regionName) throws HibernateException;
 	
 	/**
 	 * Get the cache of table update timestamps
 	 */
 	public UpdateTimestampsCache getUpdateTimestampsCache();
 	/**
 	 * Statistics SPI
 	 */
 	public StatisticsImplementor getStatisticsImplementor();
 	
 	public NamedQueryDefinition getNamedQuery(String queryName);
 	public NamedSQLQueryDefinition getNamedSQLQuery(String queryName);
 	public ResultSetMappingDefinition getResultSetMapping(String name);
 
 	/**
 	 * Get the identifier generator for the hierarchy
 	 */
 	public IdentifierGenerator getIdentifierGenerator(String rootEntityName);
 	
 	/**
 	 * Get a named second-level cache region
 	 *
 	 * @param regionName The name of the region to retrieve.
 	 * @return The region
 	 */
 	public Region getSecondLevelCacheRegion(String regionName);
 
 	/**
 	 * Get a map of all the second level cache regions currently maintained in
 	 * this session factory.  The map is structured with the region name as the
 	 * key and the {@link Region} instances as the values.
 	 *
 	 * @return The map of regions
 	 */
 	public Map getAllSecondLevelCacheRegions();
 	
 	/**
 	 * Retrieves the SQLExceptionConverter in effect for this SessionFactory.
 	 *
 	 * @return The SQLExceptionConverter for this SessionFactory.
 	 */
 	public SQLExceptionConverter getSQLExceptionConverter();
 
 	public Settings getSettings();
 
 	/**
 	 * Get a nontransactional "current" session for Hibernate EntityManager
 	 */
 	public org.hibernate.classic.Session openTemporarySession() throws HibernateException;
 
 	/**
 	 * Open a session conforming to the given parameters.  Used mainly by
 	 * {@link org.hibernate.context.JTASessionContext} for current session processing.
 	 *
 	 * @param connection The external jdbc connection to use, if one (i.e., optional).
 	 * @param flushBeforeCompletionEnabled Should the session be auto-flushed
 	 * prior to transaction completion?
 	 * @param autoCloseSessionEnabled Should the session be auto-closed after
 	 * transaction completion?
 	 * @param connectionReleaseMode The release mode for managed jdbc connections.
 	 * @return An appropriate session.
 	 * @throws HibernateException
 	 */
 	public org.hibernate.classic.Session openSession(
 			final Connection connection,
 			final boolean flushBeforeCompletionEnabled,
 			final boolean autoCloseSessionEnabled,
 			final ConnectionReleaseMode connectionReleaseMode) throws HibernateException;
 
 	/**
 	 * Retrieves a set of all the collection roles in which the given entity
 	 * is a participant, as either an index or an element.
 	 *
 	 * @param entityName The entity name for which to get the collection roles.
 	 * @return set of all the collection roles in which the given entityName participates.
 	 */
 	public Set<String> getCollectionRolesByEntityParticipant(String entityName);
 
 	public EntityNotFoundDelegate getEntityNotFoundDelegate();
 
 	public SQLFunctionRegistry getSqlFunctionRegistry();
 
 	/**
 	 * Retrieve fetch profile by name.
 	 *
 	 * @param name The name of the profile to retrieve.
 	 * @return The profile definition
 	 */
 	public FetchProfile getFetchProfile(String name);
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/impl/SessionFactoryImpl.java b/hibernate-core/src/main/java/org/hibernate/impl/SessionFactoryImpl.java
index fbda191f57..9baccd21ff 100644
--- a/hibernate-core/src/main/java/org/hibernate/impl/SessionFactoryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/impl/SessionFactoryImpl.java
@@ -1,1332 +1,1336 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.impl;
 
 import java.io.IOException;
 import java.io.InvalidObjectException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.ObjectStreamException;
 import java.io.Serializable;
 import java.sql.Connection;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashSet;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import javax.naming.NamingException;
 import javax.naming.Reference;
 import javax.naming.StringRefAddr;
 import javax.transaction.TransactionManager;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.Cache;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.EntityMode;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.MappingException;
 import org.hibernate.ObjectNotFoundException;
 import org.hibernate.QueryException;
 import org.hibernate.SessionFactory;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.StatelessSession;
 import org.hibernate.TypeHelper;
 import org.hibernate.cache.CacheKey;
 import org.hibernate.cache.CollectionRegion;
 import org.hibernate.cache.EntityRegion;
 import org.hibernate.cache.QueryCache;
 import org.hibernate.cache.Region;
 import org.hibernate.cache.UpdateTimestampsCache;
 import org.hibernate.cache.access.AccessType;
 import org.hibernate.cache.access.CollectionRegionAccessStrategy;
 import org.hibernate.cache.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.impl.CacheDataDescriptionImpl;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Settings;
-import org.hibernate.connection.ConnectionProvider;
+import org.hibernate.engine.jdbc.spi.JdbcServices;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.context.CurrentSessionContext;
 import org.hibernate.context.JTASessionContext;
 import org.hibernate.context.ManagedSessionContext;
 import org.hibernate.context.ThreadLocalSessionContext;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.engine.FilterDefinition;
 import org.hibernate.engine.Mapping;
 import org.hibernate.engine.NamedQueryDefinition;
 import org.hibernate.engine.NamedSQLQueryDefinition;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.profile.Association;
 import org.hibernate.engine.profile.Fetch;
 import org.hibernate.engine.profile.FetchProfile;
 import org.hibernate.engine.query.QueryPlanCache;
 import org.hibernate.engine.query.sql.NativeSQLQuerySpecification;
 import org.hibernate.event.EventListeners;
 import org.hibernate.exception.SQLExceptionConverter;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.UUIDGenerator;
 import org.hibernate.id.factory.IdentifierGeneratorFactory;
 import org.hibernate.jdbc.BatcherFactory;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.metadata.CollectionMetadata;
 import org.hibernate.persister.PersisterFactory;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.EntityNotFoundDelegate;
+import org.hibernate.service.spi.ServicesRegistry;
 import org.hibernate.stat.ConcurrentStatisticsImpl;
 import org.hibernate.stat.Statistics;
 import org.hibernate.stat.StatisticsImplementor;
 import org.hibernate.tool.hbm2ddl.SchemaExport;
 import org.hibernate.tool.hbm2ddl.SchemaUpdate;
 import org.hibernate.tool.hbm2ddl.SchemaValidator;
 import org.hibernate.transaction.TransactionFactory;
 import org.hibernate.tuple.entity.EntityTuplizer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeResolver;
 import org.hibernate.util.CollectionHelper;
 import org.hibernate.util.EmptyIterator;
 import org.hibernate.util.ReflectHelper;
 
 
 /**
  * Concrete implementation of the <tt>SessionFactory</tt> interface. Has the following
  * responsibilities
  * <ul>
  * <li>caches configuration settings (immutably)
  * <li>caches "compiled" mappings ie. <tt>EntityPersister</tt>s and
  *     <tt>CollectionPersister</tt>s (immutable)
  * <li>caches "compiled" queries (memory sensitive cache)
  * <li>manages <tt>PreparedStatement</tt>s
  * <li> delegates JDBC <tt>Connection</tt> management to the <tt>ConnectionProvider</tt>
  * <li>factory for instances of <tt>SessionImpl</tt>
  * </ul>
  * This class must appear immutable to clients, even if it does all kinds of caching
  * and pooling under the covers. It is crucial that the class is not only thread
  * safe, but also highly concurrent. Synchronization must be used extremely sparingly.
  *
- * @see org.hibernate.connection.ConnectionProvider
+ * @see org.hibernate.service.jdbc.connections.spi.ConnectionProvider
  * @see org.hibernate.classic.Session
  * @see org.hibernate.hql.QueryTranslator
  * @see org.hibernate.persister.entity.EntityPersister
  * @see org.hibernate.persister.collection.CollectionPersister
  * @author Gavin King
  */
 public final class SessionFactoryImpl implements SessionFactory, SessionFactoryImplementor {
 
 	private static final Logger log = LoggerFactory.getLogger(SessionFactoryImpl.class);
 	private static final IdentifierGenerator UUID_GENERATOR = UUIDGenerator.buildSessionFactoryUniqueIdentifierGenerator();
 
 	private final String name;
 	private final String uuid;
 
 	private final transient Map entityPersisters;
 	private final transient Map<String,ClassMetadata> classMetadata;
 	private final transient Map collectionPersisters;
 	private final transient Map collectionMetadata;
 	private final transient Map<String,Set<String>> collectionRolesByEntityParticipant;
 	private final transient Map identifierGenerators;
 	private final transient Map namedQueries;
 	private final transient Map namedSqlQueries;
 	private final transient Map sqlResultSetMappings;
 	private final transient Map filters;
 	private final transient Map fetchProfiles;
 	private final transient Map imports;
 	private final transient Interceptor interceptor;
+	private final transient ServicesRegistry serviceRegistry;
 	private final transient Settings settings;
 	private final transient Properties properties;
 	private transient SchemaExport schemaExport;
 	private final transient TransactionManager transactionManager;
 	private final transient QueryCache queryCache;
 	private final transient UpdateTimestampsCache updateTimestampsCache;
 	private final transient Map queryCaches;
 	private final transient Map allCacheRegions = new HashMap();
 	private final transient Statistics statistics;
 	private final transient EventListeners eventListeners;
 	private final transient CurrentSessionContext currentSessionContext;
 	private final transient EntityNotFoundDelegate entityNotFoundDelegate;
 	private final transient SQLFunctionRegistry sqlFunctionRegistry;
 	private final transient SessionFactoryObserver observer;
 	private final transient HashMap entityNameResolvers = new HashMap();
 	private final transient QueryPlanCache queryPlanCache;
 	private final transient Cache cacheAccess = new CacheImpl();
 	private transient boolean isClosed = false;
 	private final transient TypeResolver typeResolver;
 	private final transient TypeHelper typeHelper;
 
 	public SessionFactoryImpl(
 			Configuration cfg,
 	        Mapping mapping,
+			ServicesRegistry serviceRegistry,
 	        Settings settings,
 	        EventListeners listeners,
 			SessionFactoryObserver observer) throws HibernateException {
 		log.info("building session factory");
 
 		this.statistics = new ConcurrentStatisticsImpl( this );
 		getStatistics().setStatisticsEnabled( settings.isStatisticsEnabled() );
 		log.debug( "Statistics initialized [enabled={}]}", settings.isStatisticsEnabled() );
 
 		this.properties = new Properties();
 		this.properties.putAll( cfg.getProperties() );
 		this.interceptor = cfg.getInterceptor();
+		this.serviceRegistry = serviceRegistry;
 		this.settings = settings;
 		this.sqlFunctionRegistry = new SQLFunctionRegistry(settings.getDialect(), cfg.getSqlFunctions());
         this.eventListeners = listeners;
 		this.observer = observer != null ? observer : new SessionFactoryObserver() {
 			public void sessionFactoryCreated(SessionFactory factory) {
 			}
 			public void sessionFactoryClosed(SessionFactory factory) {
 			}
 		};
 
 		this.typeResolver = cfg.getTypeResolver().scope( this );
 		this.typeHelper = new TypeLocatorImpl( typeResolver );
 
 		this.filters = new HashMap();
 		this.filters.putAll( cfg.getFilterDefinitions() );
 
 		if ( log.isDebugEnabled() ) {
 			log.debug("Session factory constructed with filter configurations : " + filters);
 		}
 
 		if ( log.isDebugEnabled() ) {
 			log.debug(
 					"instantiating session factory with properties: " + properties
 			);
 		}
 
 		// Caches
 		settings.getRegionFactory().start( settings, properties );
 		this.queryPlanCache = new QueryPlanCache( this );
 
 		//Generators:
 
 		identifierGenerators = new HashMap();
 		Iterator classes = cfg.getClassMappings();
 		while ( classes.hasNext() ) {
 			PersistentClass model = (PersistentClass) classes.next();
 			if ( !model.isInherited() ) {
 				IdentifierGenerator generator = model.getIdentifier().createIdentifierGenerator(
 						cfg.getIdentifierGeneratorFactory(),
 						settings.getDialect(),
 				        settings.getDefaultCatalogName(),
 				        settings.getDefaultSchemaName(),
 				        (RootClass) model
 				);
 				identifierGenerators.put( model.getEntityName(), generator );
 			}
 		}
 
 
 		///////////////////////////////////////////////////////////////////////
 		// Prepare persisters and link them up with their cache
 		// region/access-strategy
 
 		final String cacheRegionPrefix = settings.getCacheRegionPrefix() == null ? "" : settings.getCacheRegionPrefix() + ".";
 
 		entityPersisters = new HashMap();
 		Map entityAccessStrategies = new HashMap();
 		Map<String,ClassMetadata> classMeta = new HashMap<String,ClassMetadata>();
 		classes = cfg.getClassMappings();
 		while ( classes.hasNext() ) {
 			final PersistentClass model = (PersistentClass) classes.next();
 			model.prepareTemporaryTables( mapping, settings.getDialect() );
 			final String cacheRegionName = cacheRegionPrefix + model.getRootClass().getCacheRegionName();
 			// cache region is defined by the root-class in the hierarchy...
 			EntityRegionAccessStrategy accessStrategy = ( EntityRegionAccessStrategy ) entityAccessStrategies.get( cacheRegionName );
 			if ( accessStrategy == null && settings.isSecondLevelCacheEnabled() ) {
 				final AccessType accessType = AccessType.parse( model.getCacheConcurrencyStrategy() );
 				if ( accessType != null ) {
 					log.trace( "Building cache for entity data [" + model.getEntityName() + "]" );
 					EntityRegion entityRegion = settings.getRegionFactory().buildEntityRegion( cacheRegionName, properties, CacheDataDescriptionImpl.decode( model ) );
 					accessStrategy = entityRegion.buildAccessStrategy( accessType );
 					entityAccessStrategies.put( cacheRegionName, accessStrategy );
 					allCacheRegions.put( cacheRegionName, entityRegion );
 				}
 			}
 			EntityPersister cp = PersisterFactory.createClassPersister( model, accessStrategy, this, mapping );
 			entityPersisters.put( model.getEntityName(), cp );
 			classMeta.put( model.getEntityName(), cp.getClassMetadata() );
 		}
 		this.classMetadata = Collections.unmodifiableMap(classMeta);
 
 		Map<String,Set<String>> tmpEntityToCollectionRoleMap = new HashMap<String,Set<String>>();
 		collectionPersisters = new HashMap();
 		Iterator collections = cfg.getCollectionMappings();
 		while ( collections.hasNext() ) {
 			Collection model = (Collection) collections.next();
 			final String cacheRegionName = cacheRegionPrefix + model.getCacheRegionName();
 			final AccessType accessType = AccessType.parse( model.getCacheConcurrencyStrategy() );
 			CollectionRegionAccessStrategy accessStrategy = null;
 			if ( accessType != null && settings.isSecondLevelCacheEnabled() ) {
 				log.trace( "Building cache for collection data [" + model.getRole() + "]" );
 				CollectionRegion collectionRegion = settings.getRegionFactory().buildCollectionRegion( cacheRegionName, properties, CacheDataDescriptionImpl.decode( model ) );
 				accessStrategy = collectionRegion.buildAccessStrategy( accessType );
 				entityAccessStrategies.put( cacheRegionName, accessStrategy );
 				allCacheRegions.put( cacheRegionName, collectionRegion );
 			}
 			CollectionPersister persister = PersisterFactory.createCollectionPersister( cfg, model, accessStrategy, this) ;
 			collectionPersisters.put( model.getRole(), persister.getCollectionMetadata() );
 			Type indexType = persister.getIndexType();
 			if ( indexType != null && indexType.isAssociationType() && !indexType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) indexType ).getAssociatedEntityName( this );
 				Set roles = ( Set ) tmpEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet();
 					tmpEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 			Type elementType = persister.getElementType();
 			if ( elementType.isAssociationType() && !elementType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) elementType ).getAssociatedEntityName( this );
 				Set roles = ( Set ) tmpEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet();
 					tmpEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 		}
 		collectionMetadata = Collections.unmodifiableMap(collectionPersisters);
 		Iterator itr = tmpEntityToCollectionRoleMap.entrySet().iterator();
 		while ( itr.hasNext() ) {
 			final Map.Entry entry = ( Map.Entry ) itr.next();
 			entry.setValue( Collections.unmodifiableSet( ( Set ) entry.getValue() ) );
 		}
 		collectionRolesByEntityParticipant = Collections.unmodifiableMap( tmpEntityToCollectionRoleMap );
 
 		//Named Queries:
 		namedQueries = new HashMap( cfg.getNamedQueries() );
 		namedSqlQueries = new HashMap( cfg.getNamedSQLQueries() );
 		sqlResultSetMappings = new HashMap( cfg.getSqlResultSetMappings() );
 		imports = new HashMap( cfg.getImports() );
 
 		// after *all* persisters and named queries are registered
 		Iterator iter = entityPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			final EntityPersister persister = ( ( EntityPersister ) iter.next() );
 			persister.postInstantiate();
 			registerEntityNameResolvers( persister );
 
 		}
 		iter = collectionPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			final CollectionPersister persister = ( ( CollectionPersister ) iter.next() );
 			persister.postInstantiate();
 		}
 
 		//JNDI + Serialization:
 
 		name = settings.getSessionFactoryName();
 		try {
 			uuid = (String) UUID_GENERATOR.generate(null, null);
 		}
 		catch (Exception e) {
 			throw new AssertionFailure("Could not generate UUID");
 		}
 		SessionFactoryObjectFactory.addInstance(uuid, name, this, properties);
 
 		log.debug("instantiated session factory");
 
 		if ( settings.isAutoCreateSchema() ) {
-			new SchemaExport( cfg, settings ).create( false, true );
+			new SchemaExport( getJdbcServices(), cfg ).create( false, true );
 		}
 		if ( settings.isAutoUpdateSchema() ) {
-			new SchemaUpdate( cfg, settings ).execute( false, true );
+			new SchemaUpdate( getJdbcServices(), cfg ).execute( false, true );
 		}
 		if ( settings.isAutoValidateSchema() ) {
-			new SchemaValidator( cfg, settings ).validate();
+			new SchemaValidator( getJdbcServices(), cfg ).validate();
 		}
 		if ( settings.isAutoDropSchema() ) {
-			schemaExport = new SchemaExport( cfg, settings );
+			schemaExport = new SchemaExport( getJdbcServices(), cfg );
 		}
 
 		if ( settings.getTransactionManagerLookup()!=null ) {
 			log.debug("obtaining JTA TransactionManager");
 			transactionManager = settings.getTransactionManagerLookup().getTransactionManager(properties);
 		}
 		else {
 			if ( settings.getTransactionFactory().isTransactionManagerRequired() ) {
 				throw new HibernateException("The chosen transaction strategy requires access to the JTA TransactionManager");
 			}
 			transactionManager = null;
 		}
 
 		currentSessionContext = buildCurrentSessionContext();
 
 		if ( settings.isQueryCacheEnabled() ) {
 			updateTimestampsCache = new UpdateTimestampsCache(settings, properties);
 			queryCache = settings.getQueryCacheFactory()
 			        .getQueryCache(null, updateTimestampsCache, settings, properties);
 			queryCaches = new HashMap();
 			allCacheRegions.put( updateTimestampsCache.getRegion().getName(), updateTimestampsCache.getRegion() );
 			allCacheRegions.put( queryCache.getRegion().getName(), queryCache.getRegion() );
 		}
 		else {
 			updateTimestampsCache = null;
 			queryCache = null;
 			queryCaches = null;
 		}
 
 		//checking for named queries
 		if ( settings.isNamedQueryStartupCheckingEnabled() ) {
 			Map errors = checkNamedQueries();
 			if ( !errors.isEmpty() ) {
 				Set keys = errors.keySet();
 				StringBuffer failingQueries = new StringBuffer( "Errors in named queries: " );
 				for ( Iterator iterator = keys.iterator() ; iterator.hasNext() ; ) {
 					String queryName = ( String ) iterator.next();
 					HibernateException e = ( HibernateException ) errors.get( queryName );
 					failingQueries.append( queryName );
 					if ( iterator.hasNext() ) {
 						failingQueries.append( ", " );
 					}
 					log.error( "Error in named query: " + queryName, e );
 				}
 				throw new HibernateException( failingQueries.toString() );
 			}
 		}
 
 		// EntityNotFoundDelegate
 		EntityNotFoundDelegate entityNotFoundDelegate = cfg.getEntityNotFoundDelegate();
 		if ( entityNotFoundDelegate == null ) {
 			entityNotFoundDelegate = new EntityNotFoundDelegate() {
 				public void handleEntityNotFound(String entityName, Serializable id) {
 					throw new ObjectNotFoundException( id, entityName );
 				}
 			};
 		}
 		this.entityNotFoundDelegate = entityNotFoundDelegate;
 
 		// this needs to happen after persisters are all ready to go...
 		this.fetchProfiles = new HashMap();
 		itr = cfg.iterateFetchProfiles();
 		while ( itr.hasNext() ) {
 			final org.hibernate.mapping.FetchProfile mappingProfile =
 					( org.hibernate.mapping.FetchProfile ) itr.next();
 			final FetchProfile fetchProfile = new FetchProfile( mappingProfile.getName() );
 			Iterator fetches = mappingProfile.getFetches().iterator();
 			while ( fetches.hasNext() ) {
 				final org.hibernate.mapping.FetchProfile.Fetch mappingFetch =
 						( org.hibernate.mapping.FetchProfile.Fetch ) fetches.next();
 				// resolve the persister owning the fetch
 				final String entityName = getImportedClassName( mappingFetch.getEntity() );
 				final EntityPersister owner = ( EntityPersister ) ( entityName == null ? null : entityPersisters.get( entityName ) );
 				if ( owner == null ) {
 					throw new HibernateException(
 							"Unable to resolve entity reference [" + mappingFetch.getEntity()
 									+ "] in fetch profile [" + fetchProfile.getName() + "]"
 					);
 				}
 
 				// validate the specified association fetch
 				Type associationType = owner.getPropertyType( mappingFetch.getAssociation() );
 				if ( associationType == null || !associationType.isAssociationType() ) {
 					throw new HibernateException( "Fetch profile [" + fetchProfile.getName() + "] specified an invalid association" );
 				}
 
 				// resolve the style
 				final Fetch.Style fetchStyle = Fetch.Style.parse( mappingFetch.getStyle() );
 
 				// then construct the fetch instance...
 				fetchProfile.addFetch( new Association( owner, mappingFetch.getAssociation() ), fetchStyle );
 				( ( Loadable ) owner ).registerAffectingFetchProfile( fetchProfile.getName() );
 			}
 			fetchProfiles.put( fetchProfile.getName(), fetchProfile );
 		}
 
 		this.observer.sessionFactoryCreated( this );
 	}
 
 	public Properties getProperties() {
 		return properties;
 	}
 
 	public IdentifierGeneratorFactory getIdentifierGeneratorFactory() {
 		return null;
 	}
 
 	public TypeResolver getTypeResolver() {
 		return typeResolver;
 	}
 
 	private void registerEntityNameResolvers(EntityPersister persister) {
 		if ( persister.getEntityMetamodel() == null || persister.getEntityMetamodel().getTuplizerMapping() == null ) {
 			return;
 		}
 		Iterator itr = persister.getEntityMetamodel().getTuplizerMapping().iterateTuplizers();
 		while ( itr.hasNext() ) {
 			final EntityTuplizer tuplizer = ( EntityTuplizer ) itr.next();
 			registerEntityNameResolvers( tuplizer );
 		}
 	}
 
 	private void registerEntityNameResolvers(EntityTuplizer tuplizer) {
 		EntityNameResolver[] resolvers = tuplizer.getEntityNameResolvers();
 		if ( resolvers == null ) {
 			return;
 		}
 
 		for ( int i = 0; i < resolvers.length; i++ ) {
 			registerEntityNameResolver( resolvers[i], tuplizer.getEntityMode() );
 		}
 	}
 
 	public void registerEntityNameResolver(EntityNameResolver resolver, EntityMode entityMode) {
 		LinkedHashSet resolversForMode = ( LinkedHashSet ) entityNameResolvers.get( entityMode );
 		if ( resolversForMode == null ) {
 			resolversForMode = new LinkedHashSet();
 			entityNameResolvers.put( entityMode, resolversForMode );
 		}
 		resolversForMode.add( resolver );
 	}
 
 	public Iterator iterateEntityNameResolvers(EntityMode entityMode) {
 		Set actualEntityNameResolvers = ( Set ) entityNameResolvers.get( entityMode );
 		return actualEntityNameResolvers == null
 				? EmptyIterator.INSTANCE
 				: actualEntityNameResolvers.iterator();
 	}
 
 	public QueryPlanCache getQueryPlanCache() {
 		return queryPlanCache;
 	}
 
 	private Map checkNamedQueries() throws HibernateException {
 		Map errors = new HashMap();
 
 		// Check named HQL queries
 		log.debug("Checking " + namedQueries.size() + " named HQL queries");
 		Iterator itr = namedQueries.entrySet().iterator();
 		while ( itr.hasNext() ) {
 			final Map.Entry entry = ( Map.Entry ) itr.next();
 			final String queryName = ( String ) entry.getKey();
 			final NamedQueryDefinition qd = ( NamedQueryDefinition ) entry.getValue();
 			// this will throw an error if there's something wrong.
 			try {
 				log.debug("Checking named query: " + queryName);
 				//TODO: BUG! this currently fails for named queries for non-POJO entities
 				queryPlanCache.getHQLQueryPlan( qd.getQueryString(), false, CollectionHelper.EMPTY_MAP );
 			}
 			catch ( QueryException e ) {
 				errors.put( queryName, e );
 			}
 			catch ( MappingException e ) {
 				errors.put( queryName, e );
 			}
 		}
 
 		log.debug("Checking " + namedSqlQueries.size() + " named SQL queries");
 		itr = namedSqlQueries.entrySet().iterator();
 		while ( itr.hasNext() ) {
 			final Map.Entry entry = ( Map.Entry ) itr.next();
 			final String queryName = ( String ) entry.getKey();
 			final NamedSQLQueryDefinition qd = ( NamedSQLQueryDefinition ) entry.getValue();
 			// this will throw an error if there's something wrong.
 			try {
 				log.debug("Checking named SQL query: " + queryName);
 				// TODO : would be really nice to cache the spec on the query-def so as to not have to re-calc the hash;
 				// currently not doable though because of the resultset-ref stuff...
 				NativeSQLQuerySpecification spec;
 				if ( qd.getResultSetRef() != null ) {
 					ResultSetMappingDefinition definition = ( ResultSetMappingDefinition ) sqlResultSetMappings.get( qd.getResultSetRef() );
 					if ( definition == null ) {
 						throw new MappingException( "Unable to find resultset-ref definition: " + qd.getResultSetRef() );
 					}
 					spec = new NativeSQLQuerySpecification(
 							qd.getQueryString(),
 					        definition.getQueryReturns(),
 					        qd.getQuerySpaces()
 					);
 				}
 				else {
 					spec =  new NativeSQLQuerySpecification(
 							qd.getQueryString(),
 					        qd.getQueryReturns(),
 					        qd.getQuerySpaces()
 					);
 				}
 				queryPlanCache.getNativeSQLQueryPlan( spec );
 			}
 			catch ( QueryException e ) {
 				errors.put( queryName, e );
 			}
 			catch ( MappingException e ) {
 				errors.put( queryName, e );
 			}
 		}
 
 		return errors;
 	}
 
 	public StatelessSession openStatelessSession() {
 		return new StatelessSessionImpl( null, this );
 	}
 
 	public StatelessSession openStatelessSession(Connection connection) {
 		return new StatelessSessionImpl( connection, this );
 	}
 
 	private SessionImpl openSession(
 		Connection connection,
 	    boolean autoClose,
 	    long timestamp,
 	    Interceptor sessionLocalInterceptor
 	) {
 		return new SessionImpl(
 		        connection,
 		        this,
 		        autoClose,
 		        timestamp,
 		        sessionLocalInterceptor == null ? interceptor : sessionLocalInterceptor,
 		        settings.getDefaultEntityMode(),
 		        settings.isFlushBeforeCompletionEnabled(),
 		        settings.isAutoCloseSessionEnabled(),
 		        settings.getConnectionReleaseMode()
 			);
 	}
 
 	public org.hibernate.classic.Session openSession(Connection connection, Interceptor sessionLocalInterceptor) {
 		return openSession(connection, false, Long.MIN_VALUE, sessionLocalInterceptor);
 	}
 
 	public org.hibernate.classic.Session openSession(Interceptor sessionLocalInterceptor)
 	throws HibernateException {
 		// note that this timestamp is not correct if the connection provider
 		// returns an older JDBC connection that was associated with a
 		// transaction that was already begun before openSession() was called
 		// (don't know any possible solution to this!)
 		long timestamp = settings.getRegionFactory().nextTimestamp();
 		return openSession( null, true, timestamp, sessionLocalInterceptor );
 	}
 
 	public org.hibernate.classic.Session openSession(Connection connection) {
 		return openSession(connection, interceptor); //prevents this session from adding things to cache
 	}
 
 	public org.hibernate.classic.Session openSession() throws HibernateException {
 		return openSession(interceptor);
 	}
 
 	public org.hibernate.classic.Session openTemporarySession() throws HibernateException {
 		return new SessionImpl(
 				null,
 		        this,
 		        true,
 		        settings.getRegionFactory().nextTimestamp(),
 		        interceptor,
 		        settings.getDefaultEntityMode(),
 		        false,
 		        false,
 		        ConnectionReleaseMode.AFTER_STATEMENT
 			);
 	}
 
 	public org.hibernate.classic.Session openSession(
 			final Connection connection,
 	        final boolean flushBeforeCompletionEnabled,
 	        final boolean autoCloseSessionEnabled,
 	        final ConnectionReleaseMode connectionReleaseMode) throws HibernateException {
 		return new SessionImpl(
 				connection,
 		        this,
 		        true,
 		        settings.getRegionFactory().nextTimestamp(),
 		        interceptor,
 		        settings.getDefaultEntityMode(),
 		        flushBeforeCompletionEnabled,
 		        autoCloseSessionEnabled,
 		        connectionReleaseMode
 			);
 	}
 
 	public org.hibernate.classic.Session getCurrentSession() throws HibernateException {
 		if ( currentSessionContext == null ) {
 			throw new HibernateException( "No CurrentSessionContext configured!" );
 		}
 		return currentSessionContext.currentSession();
 	}
 
 	public EntityPersister getEntityPersister(String entityName) throws MappingException {
 		EntityPersister result = (EntityPersister) entityPersisters.get(entityName);
 		if (result==null) {
 			throw new MappingException( "Unknown entity: " + entityName );
 		}
 		return result;
 	}
 
 	public CollectionPersister getCollectionPersister(String role) throws MappingException {
 		CollectionPersister result = (CollectionPersister) collectionPersisters.get(role);
 		if (result==null) {
 			throw new MappingException( "Unknown collection role: " + role );
 		}
 		return result;
 	}
 
 	public Settings getSettings() {
 		return settings;
 	}
 
 	public Dialect getDialect() {
 		return settings.getDialect();
 	}
 
 	public Interceptor getInterceptor()
 	{
 		return interceptor;
 	}
 
 	public TransactionFactory getTransactionFactory() {
 		return settings.getTransactionFactory();
 	}
 
 	public TransactionManager getTransactionManager() {
 		return transactionManager;
 	}
 
 	public SQLExceptionConverter getSQLExceptionConverter() {
 		return settings.getSQLExceptionConverter();
 	}
 
 	public Set<String> getCollectionRolesByEntityParticipant(String entityName) {
 		return collectionRolesByEntityParticipant.get( entityName );
 	}
 
 	// from javax.naming.Referenceable
 	public Reference getReference() throws NamingException {
 		log.debug("Returning a Reference to the SessionFactory");
 		return new Reference(
 			SessionFactoryImpl.class.getName(),
 		    new StringRefAddr("uuid", uuid),
 		    SessionFactoryObjectFactory.class.getName(),
 		    null
 		);
 	}
 
 	private Object readResolve() throws ObjectStreamException {
 		log.trace("Resolving serialized SessionFactory");
 		// look for the instance by uuid
 		Object result = SessionFactoryObjectFactory.getInstance(uuid);
 		if (result==null) {
 			// in case we were deserialized in a different JVM, look for an instance with the same name
 			// (alternatively we could do an actual JNDI lookup here....)
 			result = SessionFactoryObjectFactory.getNamedInstance(name);
 			if (result==null) {
 				throw new InvalidObjectException("Could not find a SessionFactory named: " + name);
 			}
 			else {
 				log.debug("resolved SessionFactory by name");
 			}
 		}
 		else {
 			log.debug("resolved SessionFactory by uid");
 		}
 		return result;
 	}
 
 	public NamedQueryDefinition getNamedQuery(String queryName) {
 		return (NamedQueryDefinition) namedQueries.get(queryName);
 	}
 
 	public NamedSQLQueryDefinition getNamedSQLQuery(String queryName) {
 		return (NamedSQLQueryDefinition) namedSqlQueries.get(queryName);
 	}
 
 	public ResultSetMappingDefinition getResultSetMapping(String resultSetName) {
 		return (ResultSetMappingDefinition) sqlResultSetMappings.get(resultSetName);
 	}
 
 	public Type getIdentifierType(String className) throws MappingException {
 		return getEntityPersister(className).getIdentifierType();
 	}
 	public String getIdentifierPropertyName(String className) throws MappingException {
 		return getEntityPersister(className).getIdentifierPropertyName();
 	}
 
 	private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException {
 		log.trace("deserializing");
 		in.defaultReadObject();
 		log.debug("deserialized: " + uuid);
 	}
 
 	private void writeObject(ObjectOutputStream out) throws IOException {
 		log.debug("serializing: " + uuid);
 		out.defaultWriteObject();
 		log.trace("serialized");
 	}
 
 	public Type[] getReturnTypes(String queryString) throws HibernateException {
 		return queryPlanCache.getHQLQueryPlan( queryString, false, CollectionHelper.EMPTY_MAP ).getReturnMetadata().getReturnTypes();
 	}
 
 	public String[] getReturnAliases(String queryString) throws HibernateException {
 		return queryPlanCache.getHQLQueryPlan( queryString, false, CollectionHelper.EMPTY_MAP ).getReturnMetadata().getReturnAliases();
 	}
 
 	public ClassMetadata getClassMetadata(Class persistentClass) throws HibernateException {
 		return getClassMetadata( persistentClass.getName() );
 	}
 
 	public CollectionMetadata getCollectionMetadata(String roleName) throws HibernateException {
 		return (CollectionMetadata) collectionMetadata.get(roleName);
 	}
 
 	public ClassMetadata getClassMetadata(String entityName) throws HibernateException {
 		return (ClassMetadata) classMetadata.get(entityName);
 	}
 
 	/**
 	 * Return the names of all persistent (mapped) classes that extend or implement the
 	 * given class or interface, accounting for implicit/explicit polymorphism settings
 	 * and excluding mapped subclasses/joined-subclasses of other classes in the result.
 	 */
 	public String[] getImplementors(String className) throws MappingException {
 
 		final Class clazz;
 		try {
 			clazz = ReflectHelper.classForName(className);
 		}
 		catch (ClassNotFoundException cnfe) {
 			return new String[] { className }; //for a dynamic-class
 		}
 
 		ArrayList results = new ArrayList();
 		Iterator iter = entityPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			//test this entity to see if we must query it
 			EntityPersister testPersister = (EntityPersister) iter.next();
 			if ( testPersister instanceof Queryable ) {
 				Queryable testQueryable = (Queryable) testPersister;
 				String testClassName = testQueryable.getEntityName();
 				boolean isMappedClass = className.equals(testClassName);
 				if ( testQueryable.isExplicitPolymorphism() ) {
 					if ( isMappedClass ) {
 						return new String[] {className}; //NOTE EARLY EXIT
 					}
 				}
 				else {
 					if (isMappedClass) {
 						results.add(testClassName);
 					}
 					else {
 						final Class mappedClass = testQueryable.getMappedClass( EntityMode.POJO );
 						if ( mappedClass!=null && clazz.isAssignableFrom( mappedClass ) ) {
 							final boolean assignableSuperclass;
 							if ( testQueryable.isInherited() ) {
 								Class mappedSuperclass = getEntityPersister( testQueryable.getMappedSuperclass() ).getMappedClass( EntityMode.POJO);
 								assignableSuperclass = clazz.isAssignableFrom(mappedSuperclass);
 							}
 							else {
 								assignableSuperclass = false;
 							}
 							if ( !assignableSuperclass ) {
 								results.add( testClassName );
 							}
 						}
 					}
 				}
 			}
 		}
 		return (String[]) results.toArray( new String[ results.size() ] );
 	}
 
 	public String getImportedClassName(String className) {
 		String result = (String) imports.get(className);
 		if (result==null) {
 			try {
 				ReflectHelper.classForName(className);
 				return className;
 			}
 			catch (ClassNotFoundException cnfe) {
 				return null;
 			}
 		}
 		else {
 			return result;
 		}
 	}
 
 	public Map<String,ClassMetadata> getAllClassMetadata() throws HibernateException {
 		return classMetadata;
 	}
 
 	public Map getAllCollectionMetadata() throws HibernateException {
 		return collectionMetadata;
 	}
 
 	public Type getReferencedPropertyType(String className, String propertyName)
 		throws MappingException {
 		return getEntityPersister(className).getPropertyType(propertyName);
 	}
 
+	private JdbcServices getJdbcServices() {
+		return serviceRegistry.getService( JdbcServices.class );
+	}
+
 	public ConnectionProvider getConnectionProvider() {
-		return settings.getConnectionProvider();
+		return serviceRegistry.getService( JdbcServices.class ).getConnectionProvider();
 	}
 
 	/**
 	 * Closes the session factory, releasing all held resources.
 	 *
 	 * <ol>
 	 * <li>cleans up used cache regions and "stops" the cache provider.
 	 * <li>close the JDBC connection
 	 * <li>remove the JNDI binding
 	 * </ol>
 	 *
 	 * Note: Be aware that the sessionfactory instance still can
 	 * be a "heavy" object memory wise after close() has been called.  Thus
 	 * it is important to not keep referencing the instance to let the garbage
 	 * collector release the memory.
 	 */
 	public void close() throws HibernateException {
 
 		if ( isClosed ) {
 			log.trace( "already closed" );
 			return;
 		}
 
 		log.info("closing");
 
 		isClosed = true;
 
 		Iterator iter = entityPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			EntityPersister p = (EntityPersister) iter.next();
 			if ( p.hasCache() ) {
 				p.getCacheAccessStrategy().getRegion().destroy();
 			}
 		}
 
 		iter = collectionPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			CollectionPersister p = (CollectionPersister) iter.next();
 			if ( p.hasCache() ) {
 				p.getCacheAccessStrategy().getRegion().destroy();
 			}
 		}
 
 		if ( settings.isQueryCacheEnabled() )  {
 			queryCache.destroy();
 
 			iter = queryCaches.values().iterator();
 			while ( iter.hasNext() ) {
 				QueryCache cache = (QueryCache) iter.next();
 				cache.destroy();
 			}
 			updateTimestampsCache.destroy();
 		}
 
 		settings.getRegionFactory().stop();
 
 		if ( settings.isAutoDropSchema() ) {
 			schemaExport.drop( false, true );
 		}
 
-		try {
-			settings.getConnectionProvider().close();
-		}
-		finally {
-			SessionFactoryObjectFactory.removeInstance(uuid, name, properties);
-		}
+		SessionFactoryObjectFactory.removeInstance(uuid, name, properties);
 
 		observer.sessionFactoryClosed( this );
 		eventListeners.destroyListeners();
 	}
 
 	private class CacheImpl implements Cache {
 		public boolean containsEntity(Class entityClass, Serializable identifier) {
 			return containsEntity( entityClass.getName(), identifier );
 		}
 
 		public boolean containsEntity(String entityName, Serializable identifier) {
 			EntityPersister p = getEntityPersister( entityName );
 			return p.hasCache() &&
 					p.getCacheAccessStrategy().getRegion().contains( buildCacheKey( identifier, p ) );
 		}
 
 		public void evictEntity(Class entityClass, Serializable identifier) {
 			evictEntity( entityClass.getName(), identifier );
 		}
 
 		public void evictEntity(String entityName, Serializable identifier) {
 			EntityPersister p = getEntityPersister( entityName );
 			if ( p.hasCache() ) {
 				if ( log.isDebugEnabled() ) {
 					log.debug( 
 							"evicting second-level cache: " +
 									MessageHelper.infoString( p, identifier, SessionFactoryImpl.this )
 					);
 				}
 				p.getCacheAccessStrategy().evict( buildCacheKey( identifier, p ) );
 			}
 		}
 
 		private CacheKey buildCacheKey(Serializable identifier, EntityPersister p) {
 			return new CacheKey(
 					identifier,
 					p.getIdentifierType(),
 					p.getRootEntityName(),
 					EntityMode.POJO,
 					SessionFactoryImpl.this
 			);
 		}
 
 		public void evictEntityRegion(Class entityClass) {
 			evictEntityRegion( entityClass.getName() );
 		}
 
 		public void evictEntityRegion(String entityName) {
 			EntityPersister p = getEntityPersister( entityName );
 			if ( p.hasCache() ) {
 				if ( log.isDebugEnabled() ) {
 					log.debug( "evicting second-level cache: " + p.getEntityName() );
 				}
 				p.getCacheAccessStrategy().evictAll();
 			}
 		}
 
 		public void evictEntityRegions() {
 			Iterator entityNames = entityPersisters.keySet().iterator();
 			while ( entityNames.hasNext() ) {
 				evictEntityRegion( ( String ) entityNames.next() );
 			}
 		}
 
 		public boolean containsCollection(String role, Serializable ownerIdentifier) {
 			CollectionPersister p = getCollectionPersister( role );
 			return p.hasCache() &&
 					p.getCacheAccessStrategy().getRegion().contains( buildCacheKey( ownerIdentifier, p ) );
 		}
 
 		public void evictCollection(String role, Serializable ownerIdentifier) {
 			CollectionPersister p = getCollectionPersister( role );
 			if ( p.hasCache() ) {
 				if ( log.isDebugEnabled() ) {
 					log.debug(
 							"evicting second-level cache: " +
 									MessageHelper.collectionInfoString(p, ownerIdentifier, SessionFactoryImpl.this)
 					);
 				}
 				CacheKey cacheKey = buildCacheKey( ownerIdentifier, p );
 				p.getCacheAccessStrategy().evict( cacheKey );
 			}
 		}
 
 		private CacheKey buildCacheKey(Serializable ownerIdentifier, CollectionPersister p) {
 			return new CacheKey(
 					ownerIdentifier,
 					p.getKeyType(),
 					p.getRole(),
 					EntityMode.POJO,
 					SessionFactoryImpl.this
 			);
 		}
 
 		public void evictCollectionRegion(String role) {
 			CollectionPersister p = getCollectionPersister( role );
 			if ( p.hasCache() ) {
 				if ( log.isDebugEnabled() ) {
 					log.debug( "evicting second-level cache: " + p.getRole() );
 				}
 				p.getCacheAccessStrategy().evictAll();
 			}
 		}
 
 		public void evictCollectionRegions() {
 			Iterator collectionRoles = collectionPersisters.keySet().iterator();
 			while ( collectionRoles.hasNext() ) {
 				evictCollectionRegion( ( String ) collectionRoles.next() );
 			}
 		}
 
 		public boolean containsQuery(String regionName) {
 			return queryCaches.get( regionName ) != null;
 		}
 
 		public void evictDefaultQueryRegion() {
 			if ( settings.isQueryCacheEnabled() ) {
 				queryCache.clear();
 			}
 		}
 
 		public void evictQueryRegion(String regionName) {
 			if ( regionName == null ) {
 				throw new NullPointerException(
 						"Region-name cannot be null (use Cache#evictDefaultQueryRegion to evict the default query cache)"
 				);
 			}
 			else {
 				synchronized ( allCacheRegions ) {
 					if ( settings.isQueryCacheEnabled() ) {
 						QueryCache namedQueryCache = ( QueryCache ) queryCaches.get( regionName );
 						if ( namedQueryCache != null ) {
 							namedQueryCache.clear();
 							// TODO : cleanup entries in queryCaches + allCacheRegions ?
 						}
 					}
 				}
 			}
 		}
 
 		public void evictQueryRegions() {
 			synchronized ( allCacheRegions ) {
 				Iterator regions = queryCaches.values().iterator();
 				while ( regions.hasNext() ) {
 					QueryCache cache = ( QueryCache ) regions.next();
 					cache.clear();
 					// TODO : cleanup entries in queryCaches + allCacheRegions ?
 				}
 			}
 		}
 	}
 
 	public Cache getCache() {
 		return cacheAccess;
 	}
 
 	public void evictEntity(String entityName, Serializable id) throws HibernateException {
 		getCache().evictEntity( entityName, id );
 	}
 
 	public void evictEntity(String entityName) throws HibernateException {
 		getCache().evictEntityRegion( entityName );
 	}
 
 	public void evict(Class persistentClass, Serializable id) throws HibernateException {
 		getCache().evictEntity( persistentClass, id );
 	}
 
 	public void evict(Class persistentClass) throws HibernateException {
 		getCache().evictEntityRegion( persistentClass );
 	}
 
 	public void evictCollection(String roleName, Serializable id) throws HibernateException {
 		getCache().evictCollection( roleName, id );
 	}
 
 	public void evictCollection(String roleName) throws HibernateException {
 		getCache().evictCollectionRegion( roleName );
 	}
 
 	public void evictQueries() throws HibernateException {
 		if ( settings.isQueryCacheEnabled() ) {
 			queryCache.clear();
 		}
 	}
 
 	public void evictQueries(String regionName) throws HibernateException {
 		getCache().evictQueryRegion( regionName );
 	}
 
 	public UpdateTimestampsCache getUpdateTimestampsCache() {
 		return updateTimestampsCache;
 	}
 
 	public QueryCache getQueryCache() {
 		return queryCache;
 	}
 
 	public QueryCache getQueryCache(String regionName) throws HibernateException {
 		if ( regionName == null ) {
 			return getQueryCache();
 		}
 
 		if ( !settings.isQueryCacheEnabled() ) {
 			return null;
 		}
 
 		synchronized ( allCacheRegions ) {
 			QueryCache currentQueryCache = ( QueryCache ) queryCaches.get( regionName );
 			if ( currentQueryCache == null ) {
 				currentQueryCache = settings.getQueryCacheFactory().getQueryCache( regionName, updateTimestampsCache, settings, properties );
 				queryCaches.put( regionName, currentQueryCache );
 				allCacheRegions.put( currentQueryCache.getRegion().getName(), currentQueryCache.getRegion() );
 			}
 			return currentQueryCache;
 		}
 	}
 
 	public Region getSecondLevelCacheRegion(String regionName) {
 		synchronized ( allCacheRegions ) {
 			return ( Region ) allCacheRegions.get( regionName );
 		}
 	}
 
 	public Map getAllSecondLevelCacheRegions() {
 		synchronized ( allCacheRegions ) {
 			return new HashMap( allCacheRegions );
 		}
 	}
 
 	public boolean isClosed() {
 		return isClosed;
 	}
 
 	public Statistics getStatistics() {
 		return statistics;
 	}
 
 	public StatisticsImplementor getStatisticsImplementor() {
 		return (StatisticsImplementor) statistics;
 	}
 
 	public FilterDefinition getFilterDefinition(String filterName) throws HibernateException {
 		FilterDefinition def = ( FilterDefinition ) filters.get( filterName );
 		if ( def == null ) {
 			throw new HibernateException( "No such filter configured [" + filterName + "]" );
 		}
 		return def;
 	}
 
 	public boolean containsFetchProfileDefinition(String name) {
 		return fetchProfiles.containsKey( name );
 	}
 
 	public Set getDefinedFilterNames() {
 		return filters.keySet();
 	}
 
 	public BatcherFactory getBatcherFactory() {
 		return settings.getBatcherFactory();
 	}
 
 	public IdentifierGenerator getIdentifierGenerator(String rootEntityName) {
 		return (IdentifierGenerator) identifierGenerators.get(rootEntityName);
 	}
 
 	private CurrentSessionContext buildCurrentSessionContext() {
 		String impl = properties.getProperty( Environment.CURRENT_SESSION_CONTEXT_CLASS );
 		// for backward-compatability
 		if ( impl == null && transactionManager != null ) {
 			impl = "jta";
 		}
 
 		if ( impl == null ) {
 			return null;
 		}
 		else if ( "jta".equals( impl ) ) {
 			if ( settings.getTransactionFactory().areCallbacksLocalToHibernateTransactions() ) {
 				log.warn( "JTASessionContext being used with JDBCTransactionFactory; auto-flush will not operate correctly with getCurrentSession()" );
 			}
 			return new JTASessionContext( this );
 		}
 		else if ( "thread".equals( impl ) ) {
 			return new ThreadLocalSessionContext( this );
 		}
 		else if ( "managed".equals( impl ) ) {
 			return new ManagedSessionContext( this );
 		}
 		else {
 			try {
 				Class implClass = ReflectHelper.classForName( impl );
 				return ( CurrentSessionContext ) implClass
 						.getConstructor( new Class[] { SessionFactoryImplementor.class } )
 						.newInstance( new Object[] { this } );
 			}
 			catch( Throwable t ) {
 				log.error( "Unable to construct current session context [" + impl + "]", t );
 				return null;
 			}
 		}
 	}
 
 	public EventListeners getEventListeners()
 	{
 		return eventListeners;
 	}
 
 	public EntityNotFoundDelegate getEntityNotFoundDelegate() {
 		return entityNotFoundDelegate;
 	}
 
 	public SQLFunctionRegistry getSqlFunctionRegistry() {
 		return sqlFunctionRegistry;
 	}
 
 	public FetchProfile getFetchProfile(String name) {
 		return ( FetchProfile ) fetchProfiles.get( name );
 	}
 
 	public TypeHelper getTypeHelper() {
 		return typeHelper;
 	}
 
 	/**
 	 * Custom serialization hook used during Session serialization.
 	 *
 	 * @param oos The stream to which to write the factory
 	 * @throws IOException Indicates problems writing out the serial data stream
 	 */
 	void serialize(ObjectOutputStream oos) throws IOException {
 		oos.writeUTF( uuid );
 		oos.writeBoolean( name != null );
 		if ( name != null ) {
 			oos.writeUTF( name );
 		}
 	}
 
 	/**
 	 * Custom deserialization hook used during Session deserialization.
 	 *
 	 * @param ois The stream from which to "read" the factory
 	 * @return The deserialized factory
 	 * @throws IOException indicates problems reading back serial data stream
 	 * @throws ClassNotFoundException indicates problems reading back serial data stream
 	 */
 	static SessionFactoryImpl deserialize(ObjectInputStream ois) throws IOException, ClassNotFoundException {
 		String uuid = ois.readUTF();
 		boolean isNamed = ois.readBoolean();
 		String name = null;
 		if ( isNamed ) {
 			name = ois.readUTF();
 		}
 		Object result = SessionFactoryObjectFactory.getInstance( uuid );
 		if ( result == null ) {
 			log.trace( "could not locate session factory by uuid [" + uuid + "] during session deserialization; trying name" );
 			if ( isNamed ) {
 				result = SessionFactoryObjectFactory.getNamedInstance( name );
 			}
 			if ( result == null ) {
 				throw new InvalidObjectException( "could not resolve session factory during session deserialization [uuid=" + uuid + ", name=" + name + "]" );
 			}
 		}
 		return ( SessionFactoryImpl ) result;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/jmx/HibernateService.java b/hibernate-core/src/main/java/org/hibernate/jmx/HibernateService.java
index efb936c83e..a4946c1398 100644
--- a/hibernate-core/src/main/java/org/hibernate/jmx/HibernateService.java
+++ b/hibernate-core/src/main/java/org/hibernate/jmx/HibernateService.java
@@ -1,168 +1,171 @@
 //$Id: HibernateService.java 6100 2005-03-17 10:48:03Z turin42 $
 package org.hibernate.jmx;
 
 import java.util.Properties;
 import java.util.Map;
 
 import javax.naming.InitialContext;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import org.hibernate.HibernateException;
 import org.hibernate.SessionFactory;
 import org.hibernate.cfg.Environment;
+import org.hibernate.cfg.internal.ServicesRegistryBootstrap;
+import org.hibernate.service.spi.ServicesRegistry;
 import org.hibernate.tool.hbm2ddl.SchemaExport;
 import org.hibernate.internal.util.jndi.JndiHelper;
 import org.hibernate.util.ExternalSessionFactoryConfig;
 
 
 /**
  * Implementation of <tt>HibernateServiceMBean</tt>. Creates a
  * <tt>SessionFactory</tt> and binds it to the specified JNDI name.<br>
  * <br>
  * All mapping documents are loaded as resources by the MBean.
  * @see HibernateServiceMBean
  * @see org.hibernate.SessionFactory
  * @author John Urberg, Gavin King
  */
 public class HibernateService extends ExternalSessionFactoryConfig implements HibernateServiceMBean {
 
 	private static final Logger log = LoggerFactory.getLogger(HibernateServiceMBean.class);
 
 	private String boundName;
 	private Properties properties = new Properties();
 
-
 	public void start() throws HibernateException {
 		boundName = getJndiName();
 		try {
 			buildSessionFactory();
 		}
 		catch (HibernateException he) {
 			log.info( "Could not build SessionFactory using the MBean classpath - will try again using client classpath: " + he.getMessage() );
 			log.debug("Error was", he);
 			new SessionFactoryStub(this);
 		}
 	}
 
 	public void stop() {
 		log.info("stopping service");
 		try {
 			InitialContext context = JndiHelper.getInitialContext( buildProperties() );
 			( (SessionFactory) context.lookup(boundName) ).close();
 			//context.unbind(boundName);
 		}
 		catch (Exception e) {
 			log.warn("exception while stopping service", e);
 		}
 	}
 	
 	SessionFactory buildSessionFactory() throws HibernateException {
 		log.info( "starting service at JNDI name: " + boundName );
 		log.info( "service properties: " + properties );
-		return buildConfiguration().buildSessionFactory();
+		return buildConfiguration().buildSessionFactory(
+				new ServicesRegistryBootstrap().initiateServicesRegistry( properties )
+		);
 	}
 
 	protected Map getExtraProperties() {
 		return properties;
 	}
 
 	public String getTransactionStrategy() {
 		return getProperty(Environment.TRANSACTION_STRATEGY);
 	}
 
 	public void setTransactionStrategy(String txnStrategy) {
 		setProperty(Environment.TRANSACTION_STRATEGY, txnStrategy);
 	}
 
 	public String getUserTransactionName() {
 		return getProperty(Environment.USER_TRANSACTION);
 	}
 
 	public void setUserTransactionName(String utName) {
 		setProperty(Environment.USER_TRANSACTION, utName);
 	}
 
 	public String getTransactionManagerLookupStrategy() {
 		return getProperty(Environment.TRANSACTION_MANAGER_STRATEGY);
 	}
 
 	public void setTransactionManagerLookupStrategy(String lkpStrategy) {
 		setProperty(Environment.TRANSACTION_MANAGER_STRATEGY, lkpStrategy);
 	}
 
 	public String getPropertyList() {
 		return buildProperties().toString();
 	}
 
 	public String getProperty(String property) {
 		return properties.getProperty(property);
 	}
 
 	public void setProperty(String property, String value) {
 		properties.setProperty(property, value);
 	}
 
 	public void dropSchema() {
 		new SchemaExport( buildConfiguration() ).drop(false, true);
 	}
 
 	public void createSchema() {
 		new SchemaExport( buildConfiguration() ).create(false, true);
 	}	public String getName() {
 		return getProperty(Environment.SESSION_FACTORY_NAME);
 	}
 
 	public String getDatasource() {
 		return getProperty(Environment.DATASOURCE);
 	}
 
 	public void setDatasource(String datasource) {
 		setProperty(Environment.DATASOURCE, datasource);
 	}
 
 	public String getJndiName() {
 		return getProperty(Environment.SESSION_FACTORY_NAME);
 	}
 
 	public void setJndiName(String jndiName) {
 		setProperty(Environment.SESSION_FACTORY_NAME, jndiName);
 	}
 
 	public String getUserName() {
 		return getProperty(Environment.USER);
 	}
 
 	public void setUserName(String userName) {
 		setProperty(Environment.USER, userName);
 	}
 
 	public String getPassword() {
 		return getProperty(Environment.PASS);
 	}
 
 	public void setPassword(String password) {
 		setProperty(Environment.PASS, password);
 	}
 
 	public void setFlushBeforeCompletionEnabled(String enabled) {
 		setProperty(Environment.FLUSH_BEFORE_COMPLETION, enabled);
 	}
 
 	public String getFlushBeforeCompletionEnabled() {
 		return getProperty(Environment.FLUSH_BEFORE_COMPLETION);
 	}
 
 	public void setAutoCloseSessionEnabled(String enabled) {
 		setProperty(Environment.AUTO_CLOSE_SESSION, enabled);
 	}
 
 	public String getAutoCloseSessionEnabled() {
 		return getProperty(Environment.AUTO_CLOSE_SESSION);
 	}
 
 	public Properties getProperties() {
 		return buildProperties();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/service/jdbc/connections/internal/ConnectionProviderInitiator.java b/hibernate-core/src/main/java/org/hibernate/service/jdbc/connections/internal/ConnectionProviderInitiator.java
index 38317d408a..3a33891dac 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/jdbc/connections/internal/ConnectionProviderInitiator.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/jdbc/connections/internal/ConnectionProviderInitiator.java
@@ -1,291 +1,291 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service.jdbc.connections.internal;
 
 import java.beans.BeanInfo;
 import java.beans.PropertyDescriptor;
 import java.lang.reflect.Method;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import org.hibernate.HibernateException;
 import org.hibernate.cfg.Environment;
 import org.hibernate.service.classloading.spi.ClassLoaderService;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.internal.util.beans.BeanInfoHelper;
 import org.hibernate.service.spi.ServicesRegistry;
 import org.hibernate.service.spi.ServiceInitiator;
 
 /**
  * Instantiates and configures an appropriate {@link ConnectionProvider}.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class ConnectionProviderInitiator implements ServiceInitiator<ConnectionProvider> {
 	public static final ConnectionProviderInitiator INSTANCE = new ConnectionProviderInitiator();
 
 	private static final Logger log = LoggerFactory.getLogger( ConnectionProviderInitiator.class );
 
 	public static final String C3P0_CONFIG_PREFIX = "hibernate.c3p0";
 	public static final String C3P0_PROVIDER_CLASS_NAME =
 			"org.hibernate.service.jdbc.connections.internal.C3P0ConnectionProvider";
 
 	public static final String PROXOOL_CONFIG_PREFIX = "hibernate.proxool";
 	public static final String PROXOOL_PROVIDER_CLASS_NAME =
 			"org.hibernate.service.jdbc.connections.internal.ProxoolConnectionProvider";
 
 	public static final String INJECTION_DATA = "hibernate.connection_provider.injection_data";
 	
 	// mapping from legacy connection provider name to actual
 	// connection provider that will be used
 	private static final Map<String,String> LEGACY_CONNECTION_PROVIDER_MAPPING;
 
 	static {
 		LEGACY_CONNECTION_PROVIDER_MAPPING = new HashMap<String,String>( 5 );
 		
 		LEGACY_CONNECTION_PROVIDER_MAPPING.put(
 				"org.hibernate.connection.DatasourceConnectionProvider",
 				DatasourceConnectionProviderImpl.class.getName()
 		);
 		LEGACY_CONNECTION_PROVIDER_MAPPING.put(
 				"org.hibernate.connection.DriverManagerConnectionProvider",
 				DriverManagerConnectionProviderImpl.class.getName()
 		);
 		LEGACY_CONNECTION_PROVIDER_MAPPING.put(
 				"org.hibernate.connection.UserSuppliedConnectionProvider",
 				UserSuppliedConnectionProviderImpl.class.getName()
 		);
 		LEGACY_CONNECTION_PROVIDER_MAPPING.put(
 				"org.hibernate.connection.C3P0ConnectionProvider",
 				C3P0_PROVIDER_CLASS_NAME 
 		);
 		LEGACY_CONNECTION_PROVIDER_MAPPING.put(
 				"org.hibernate.connection.ProxoolConnectionProvider",
 				PROXOOL_PROVIDER_CLASS_NAME
 		);
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public Class<ConnectionProvider> getServiceInitiated() {
 		return ConnectionProvider.class;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public ConnectionProvider initiateService(Map configurationValues, ServicesRegistry registry) {
 		final ClassLoaderService classLoaderService = registry.getService( ClassLoaderService.class );
 
 		ConnectionProvider connectionProvider = null;
 		String providerClassName = (String) getConfiguredConnectionProviderName( configurationValues );
 		if ( providerClassName != null ) {
 			connectionProvider = instantiateExplicitConnectionProvider( providerClassName, classLoaderService );
 		}
 		else if ( configurationValues.get( Environment.DATASOURCE ) != null ) {
 			connectionProvider = new DatasourceConnectionProviderImpl();
 		}
 
 		if ( connectionProvider == null ) {
 			if ( c3p0ConfigDefined( configurationValues ) && c3p0ProviderPresent( classLoaderService ) ) {
 				connectionProvider = instantiateExplicitConnectionProvider( C3P0_PROVIDER_CLASS_NAME,
 						classLoaderService
 				);
 			}
 		}
 
 		if ( connectionProvider == null ) {
 			if ( proxoolConfigDefined( configurationValues ) && proxoolProviderPresent( classLoaderService ) ) {
 				connectionProvider = instantiateExplicitConnectionProvider( PROXOOL_PROVIDER_CLASS_NAME,
 						classLoaderService
 				);
 			}
 		}
 
 		if ( connectionProvider == null ) {
 			if ( configurationValues.get( Environment.URL ) != null ) {
 				connectionProvider = new DriverManagerConnectionProviderImpl();
 			}
 		}
 
 		if ( connectionProvider == null ) {
 			log.warn( "No appropriate connection provider encountered, assuming application will be supplying connections" );
 			connectionProvider = new UserSuppliedConnectionProviderImpl();
 		}
 
 
 		final Map injectionData = (Map) configurationValues.get( INJECTION_DATA );
 		if ( injectionData != null && injectionData.size() > 0 ) {
 			final ConnectionProvider theConnectionProvider = connectionProvider;
 			new BeanInfoHelper( connectionProvider.getClass() ).applyToBeanInfo(
 					connectionProvider,
 					new BeanInfoHelper.BeanInfoDelegate() {
 						public void processBeanInfo(BeanInfo beanInfo) throws Exception {
 							PropertyDescriptor[] descritors = beanInfo.getPropertyDescriptors();
 							for ( int i = 0, size = descritors.length; i < size; i++ ) {
 								String propertyName = descritors[i].getName();
 								if ( injectionData.containsKey( propertyName ) ) {
 									Method method = descritors[i].getWriteMethod();
 									method.invoke(
 											theConnectionProvider,
 											injectionData.get( propertyName )
 									);
 								}
 							}
 						}
 					}
 			);
 		}
 
 		return connectionProvider;
 	}
 
 	private String getConfiguredConnectionProviderName( Map configurationValues ) {
 		String providerClassName = ( String ) configurationValues.get( Environment.CONNECTION_PROVIDER );
 		if ( LEGACY_CONNECTION_PROVIDER_MAPPING.containsKey( providerClassName ) ) {
 			String actualProviderClassName = LEGACY_CONNECTION_PROVIDER_MAPPING.get( providerClassName );
 			if ( log.isWarnEnabled() ) {
 				StringBuffer buf = new StringBuffer()
 						.append( providerClassName )
 						.append( " has been deprecated in favor of ")
 						.append( actualProviderClassName )
 						.append( "; that provider will be used instead." );
 				log.warn( buf.toString() );
 			}
 			providerClassName = actualProviderClassName;
 		}
 		return providerClassName;
 	}
 
 	private ConnectionProvider instantiateExplicitConnectionProvider(
 			String providerClassName,
 			ClassLoaderService classLoaderService) {
 		try {
 			log.info( "Instantiating explicit connection provider: " + providerClassName );
 			return (ConnectionProvider) classLoaderService.classForName( providerClassName ).newInstance();
 		}
 		catch ( Exception e ) {
 			throw new HibernateException( "Could not instantiate connection provider [" + providerClassName + "]", e );
 		}
 	}
 
 	private boolean c3p0ProviderPresent(ClassLoaderService classLoaderService) {
 		try {
 			classLoaderService.classForName( C3P0_PROVIDER_CLASS_NAME );
 		}
 		catch ( Exception e ) {
 			log.warn(
 					"c3p0 properties were encountered, but the " + C3P0_PROVIDER_CLASS_NAME +
 							" provider class was not found on the classpath; these properties are going to be ignored."
 			);
 			return false;
 		}
 		return true;
 	}
 
 	private static boolean c3p0ConfigDefined(Map configValues) {
 		for ( Object key : configValues.keySet() ) {
 			if ( String.class.isInstance( key )
 					&& ( (String) key ).startsWith( C3P0_CONFIG_PREFIX ) ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	private boolean proxoolProviderPresent(ClassLoaderService classLoaderService) {
 		try {
 			classLoaderService.classForName( PROXOOL_PROVIDER_CLASS_NAME );
 		}
 		catch ( Exception e ) {
 			log.warn(
 					"proxool properties were encountered, but the " + PROXOOL_PROVIDER_CLASS_NAME +
 							" provider class was not found on the classpath; these properties are going to be ignored."
 			);
 			return false;
 		}
 		return true;
 	}
 
 	private static boolean proxoolConfigDefined(Map configValues) {
 		for ( Object key : configValues.keySet() ) {
 			if ( String.class.isInstance( key )
 					&& ( (String) key ).startsWith( PROXOOL_CONFIG_PREFIX ) ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	/**
 	 * Transform JDBC connection properties.
 	 *
 	 * Passed in the form <tt>hibernate.connection.*</tt> to the
 	 * format accepted by <tt>DriverManager</tt> by trimming the leading "<tt>hibernate.connection</tt>".
 	 */
 	public static Properties getConnectionProperties(Map<?,?> properties) {
 		Properties result = new Properties();
 		for ( Map.Entry entry : properties.entrySet() ) {
-			if ( ! ( String.class.isInstance( entry.getKey() ) ) && String.class.isInstance( entry.getValue() ) ) {
+			if ( ! ( String.class.isInstance( entry.getKey() ) ) || ! String.class.isInstance( entry.getValue() ) ) {
 				continue;
 			}
 			final String key = (String) entry.getKey();
 			final String value = (String) entry.getValue();
 			if ( key.startsWith( Environment.CONNECTION_PREFIX ) ) {
 				if ( SPECIAL_PROPERTIES.contains( key ) ) {
 					if ( Environment.USER.equals( key ) ) {
 						result.setProperty( "user", value );
 					}
 				}
 				else {
 					final String passThruKey = key.substring( Environment.CONNECTION_PREFIX.length() + 1 );
 					result.setProperty( passThruKey, value );
 				}
 			}
 		}
 		return result;
 	}
 
 	private static final Set<String> SPECIAL_PROPERTIES;
 
 	static {
 		SPECIAL_PROPERTIES = new HashSet<String>();
 		SPECIAL_PROPERTIES.add( Environment.DATASOURCE );
 		SPECIAL_PROPERTIES.add( Environment.URL );
 		SPECIAL_PROPERTIES.add( Environment.CONNECTION_PROVIDER );
 		SPECIAL_PROPERTIES.add( Environment.POOL_SIZE );
 		SPECIAL_PROPERTIES.add( Environment.ISOLATION );
 		SPECIAL_PROPERTIES.add( Environment.DRIVER );
 		SPECIAL_PROPERTIES.add( Environment.USER );
 
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/stat/StatisticsImplementor.java b/hibernate-core/src/main/java/org/hibernate/stat/StatisticsImplementor.java
index 3fd65db8d7..a7de6b929a 100644
--- a/hibernate-core/src/main/java/org/hibernate/stat/StatisticsImplementor.java
+++ b/hibernate-core/src/main/java/org/hibernate/stat/StatisticsImplementor.java
@@ -1,204 +1,204 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.stat;
 
 /**
  * Statistics SPI for the Hibernate core.  This is essentially the "statistic collector" API, its the contract
  * called to collect various stats.
  * 
  * @author Emmanuel Bernard
  */
 public interface StatisticsImplementor {
 	/**
 	 * Callback about a session being opened.
 	 */
 	public void openSession();
 
 	/**
 	 * Callback about a session being closed.
 	 */
 	public void closeSession();
 
 	/**
 	 * Callback about a flush occurring
 	 */
 	public void flush();
 
 	/**
-	 * Callback about a connection being obtained from {@link org.hibernate.connection.ConnectionProvider}
+	 * Callback about a connection being obtained from {@link org.hibernate.service.jdbc.connections.spi.ConnectionProvider}
 	 */
 	public void connect();
 
 	/**
 	 * Callback about a statement being prepared.
 	 */
 	public void prepareStatement();
 
 	/**
 	 * Callback about a statement being closed.
 	 */
 	public void closeStatement();
 
 	/**
 	 * Callback about a transaction completing.
 	 *
 	 * @param success Was the transaction successful?
 	 */
 	public void endTransaction(boolean success);
 
 	/**
 	 * Callback about an entity being loaded.  This might indicate a proxy or a fully initialized entity, but in either
 	 * case it means without a separate SQL query being needed.
 	 *
 	 * @param entityName The name of the entity loaded.
 	 */
 	public void loadEntity(String entityName);
 
 	/**
 	 * Callback about an entity being fetched.  Unlike {@link #loadEntity} this indicates a separate query being
 	 * performed.
 	 *
 	 * @param entityName The name of the entity fetched.
 	 */
 	public void fetchEntity(String entityName);
 
 	/**
 	 * Callback about an entity being updated.
 	 *
 	 * @param entityName The name of the entity updated.
 	 */
 	public void updateEntity(String entityName);
 
 	/**
 	 * Callback about an entity being inserted
 	 *
 	 * @param entityName The name of the entity inserted
 	 */
 	public void insertEntity(String entityName);
 
 	/**
 	 * Callback about an entity being deleted.
 	 *
 	 * @param entityName The name of the entity deleted.
 	 */
 	public void deleteEntity(String entityName);
 
 	/**
 	 * Callback about an optimistic lock failure on an entity
 	 *
 	 * @param entityName The name of the entity.
 	 */
 	public void optimisticFailure(String entityName);
 
 	/**
 	 * Callback about a collection loading.  This might indicate a lazy collection or an initialized collection being
 	 * created, but in either case it means without a separate SQL query being needed.
 	 *
 	 * @param role The collection role.
 	 */
 	public void loadCollection(String role);
 
 	/**
 	 * Callback to indicate a collection being fetched.  Unlike {@link #loadCollection}, this indicates a separate
 	 * query was needed.
 	 *
 	 * @param role The collection role.
 	 */
 	public void fetchCollection(String role);
 
 	/**
 	 * Callback indicating a collection was updated.
 	 *
 	 * @param role The collection role.
 	 */
 	public void updateCollection(String role);
 
 	/**
 	 * Callback indicating a collection recreation (full deletion + full (re-)insertion).
 	 *
 	 * @param role The collection role.
 	 */
 	public void recreateCollection(String role);
 
 	/**
 	 * Callback indicating a collection removal.
 	 *
 	 * @param role The collection role.
 	 */
 	public void removeCollection(String role);
 
 	/**
 	 * Callback indicating a put into second level cache.
 	 *
 	 * @param regionName The name of the cache region
 	 */
 	public void secondLevelCachePut(String regionName);
 
 	/**
 	 * Callback indicating a get from second level cache resulted in a hit.
 	 *
 	 * @param regionName The name of the cache region
 	 */
 	public void secondLevelCacheHit(String regionName);
 
 	/**
 	 * Callback indicating a get from second level cache resulted in a miss.
 	 *
 	 * @param regionName The name of the cache region
 	 */
 	public void secondLevelCacheMiss(String regionName);
 
 	/**
 	 * Callback indicating a put into the query cache.
 	 *
 	 * @param hql The query
 	 * @param regionName The cache region
 	 */
 	public void queryCachePut(String hql, String regionName);
 
 	/**
 	 * Callback indicating a get from the query cache resulted in a hit.
 	 *
 	 * @param hql The query
 	 * @param regionName The name of the cache region
 	 */
 	public void queryCacheHit(String hql, String regionName);
 
 	/**
 	 * Callback indicating a get from the query cache resulted in a miss.
 	 *
 	 * @param hql The query
 	 * @param regionName The name of the cache region
 	 */
 	public void queryCacheMiss(String hql, String regionName);
 
 	/**
 	 * Callback indicating execution of a sql/hql query
 	 *
 	 * @param hql The query
 	 * @param rows Number of rows returned
 	 * @param time execution time
 	 */
 	public void queryExecuted(String hql, int rows, long time);
 }
\ No newline at end of file
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/ManagedProviderConnectionHelper.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/ManagedProviderConnectionHelper.java
index 87cc8d58e9..df8c354881 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/ManagedProviderConnectionHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/ManagedProviderConnectionHelper.java
@@ -1,75 +1,80 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.tool.hbm2ddl;
 
-import org.hibernate.connection.ConnectionProvider;
-import org.hibernate.connection.ConnectionProviderFactory;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
+import org.hibernate.service.spi.Stoppable;
 import org.hibernate.util.JDBCExceptionReporter;
 
 import java.util.Properties;
 import java.sql.Connection;
 import java.sql.SQLException;
 
 /**
  * A {@link ConnectionHelper} implementation based on an internally
  * built and managed {@link ConnectionProvider}.
  *
  * @author Steve Ebersole
  */
 class ManagedProviderConnectionHelper implements ConnectionHelper {
 	private Properties cfgProperties;
 	private ConnectionProvider connectionProvider;
 	private Connection connection;
 
 	public ManagedProviderConnectionHelper(Properties cfgProperties) {
 		this.cfgProperties = cfgProperties;
 	}
 
 	public void prepare(boolean needsAutoCommit) throws SQLException {
-		connectionProvider = ConnectionProviderFactory.newConnectionProvider( cfgProperties );
+		/* TEMP TEMP TEMP
+		connectionProvider = ConnectionProviderBuilder.buildConnectionProvider();
 		connection = connectionProvider.getConnection();
 		if ( needsAutoCommit && !connection.getAutoCommit() ) {
 			connection.commit();
 			connection.setAutoCommit( true );
 		}
+		*/
 	}
 
 	public Connection getConnection() throws SQLException {
 		return connection;
 	}
 
 	public void release() throws SQLException {
 		if ( connection != null ) {
 			try {
 				JDBCExceptionReporter.logAndClearWarnings( connection );
 				connectionProvider.closeConnection( connection );
 			}
 			finally {
-				connectionProvider.close();
+				if ( connectionProvider instanceof Stoppable ) {
+						( ( Stoppable ) connectionProvider ).stop();
+				}
+				connectionProvider = null;
 			}
 		}
 		connection = null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExport.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExport.java
index 6d7256b533..4916f13734 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExport.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExport.java
@@ -1,539 +1,542 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.io.BufferedReader;
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.FileWriter;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.io.Reader;
 import java.io.Writer;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.sql.SQLWarning;
 import java.sql.Statement;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Properties;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import org.hibernate.HibernateException;
 import org.hibernate.JDBCException;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.NamingStrategy;
-import org.hibernate.cfg.Settings;
 import org.hibernate.dialect.Dialect;
+import org.hibernate.engine.jdbc.spi.JdbcServices;
+import org.hibernate.engine.jdbc.spi.SQLStatementLogger;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.jdbc.util.FormatStyle;
 import org.hibernate.jdbc.util.Formatter;
-import org.hibernate.jdbc.util.SQLStatementLogger;
 import org.hibernate.util.ConfigHelper;
 import org.hibernate.util.JDBCExceptionReporter;
 import org.hibernate.util.ReflectHelper;
 
 /**
  * Commandline tool to export table schema to the database. This class may also be called from inside an application.
  *
  * @author Daniel Bradby
  * @author Gavin King
  */
 public class SchemaExport {
 
 	private static final Logger log = LoggerFactory.getLogger( SchemaExport.class );
 
 	private ConnectionHelper connectionHelper;
 	private String[] dropSQL;
 	private String[] createSQL;
 	private String outputFile = null;
 	private String importFiles;
 	private Dialect dialect;
 	private String delimiter;
 	private final List exceptions = new ArrayList();
 	private boolean haltOnError = false;
 	private Formatter formatter;
 	private SQLStatementLogger sqlStatementLogger;
 	private static final String DEFAULT_IMPORT_FILE = "/import.sql";
 
 	/**
 	 * Create a schema exporter for the given Configuration
 	 *
 	 * @param cfg The configuration from which to build a schema export.
 	 * @throws HibernateException Indicates problem preparing for schema export.
 	 */
 	public SchemaExport(Configuration cfg) throws HibernateException {
 		this( cfg, cfg.getProperties() );
 	}
 
 	/**
 	 * Create a schema exporter for the given Configuration and given settings
 	 *
 	 * @param cfg The configuration from which to build a schema export.
 	 * @param settings The 'parsed' settings.
 	 * @throws HibernateException Indicates problem preparing for schema export.
 	 */
-	public SchemaExport(Configuration cfg, Settings settings) throws HibernateException {
-		dialect = settings.getDialect();
-		connectionHelper = new SuppliedConnectionProviderConnectionHelper( settings.getConnectionProvider() );
+	public SchemaExport(JdbcServices jdbcServices, Configuration cfg) throws HibernateException {
+		dialect = jdbcServices.getDialect();
+		connectionHelper = new SuppliedConnectionProviderConnectionHelper( jdbcServices.getConnectionProvider() );
 		dropSQL = cfg.generateDropSchemaScript( dialect );
 		createSQL = cfg.generateSchemaCreationScript( dialect );
-		sqlStatementLogger = settings.getSqlStatementLogger();
-		formatter = ( sqlStatementLogger.isFormatSql() ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
-		importFiles = settings.getImportFiles() != null ? settings.getImportFiles() : DEFAULT_IMPORT_FILE;
+		sqlStatementLogger = jdbcServices.getSqlStatementLogger();
+		formatter = ( sqlStatementLogger.isFormat() ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
+		importFiles = ConfigurationHelper.getString(
+				Environment.HBM2DDL_IMPORT_FILES, cfg.getProperties(),
+				DEFAULT_IMPORT_FILE
+		);
 	}
 
 	/**
 	 * Create a schema exporter for the given Configuration, with the given
 	 * database connection properties.
 	 *
 	 * @param cfg The configuration from which to build a schema export.
 	 * @param properties The properties from which to configure connectivity etc.
 	 * @throws HibernateException Indicates problem preparing for schema export.
 	 *
 	 * @deprecated properties may be specified via the Configuration object
 	 */
 	public SchemaExport(Configuration cfg, Properties properties) throws HibernateException {
 		dialect = Dialect.getDialect( properties );
 
 		Properties props = new Properties();
 		props.putAll( dialect.getDefaultProperties() );
 		props.putAll( properties );
 
 		connectionHelper = new ManagedProviderConnectionHelper( props );
 		dropSQL = cfg.generateDropSchemaScript( dialect );
 		createSQL = cfg.generateSchemaCreationScript( dialect );
 
 		formatter = ( ConfigurationHelper.getBoolean( Environment.FORMAT_SQL, props ) ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
 
 		importFiles = ConfigurationHelper.getString( Environment.HBM2DDL_IMPORT_FILES, props, DEFAULT_IMPORT_FILE );
 	}
 
 	/**
 	 * Create a schema exporter for the given Configuration, using the supplied connection for connectivity.
 	 *
 	 * @param cfg The configuration to use.
 	 * @param connection The JDBC connection to use.
 	 * @throws HibernateException Indicates problem preparing for schema export.
 	 */
 	public SchemaExport(Configuration cfg, Connection connection) throws HibernateException {
 		this.connectionHelper = new SuppliedConnectionHelper( connection );
 		dialect = Dialect.getDialect( cfg.getProperties() );
 		dropSQL = cfg.generateDropSchemaScript( dialect );
 		createSQL = cfg.generateSchemaCreationScript( dialect );
 		formatter = ( ConfigurationHelper.getBoolean( Environment.FORMAT_SQL, cfg.getProperties() ) ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
 		importFiles = ConfigurationHelper.getString( Environment.HBM2DDL_IMPORT_FILES, cfg.getProperties(),
 				DEFAULT_IMPORT_FILE
 		);
 	}
 
 	/**
 	 * For generating a export script file, this is the file which will be written.
 	 *
 	 * @param filename The name of the file to which to write the export script.
 	 * @return this
 	 */
 	public SchemaExport setOutputFile(String filename) {
 		outputFile = filename;
 		return this;
 	}
 
 	/**
 	 * An import file, containing raw SQL statements to be executed.
 	 *
 	 * @param filename The import file name.
 	 * @return this
 	 * @deprecated use {@link org.hibernate.cfg.Environment.HBM2DDL_IMPORT_FILE}
 	 */
 	public SchemaExport setImportFile(String filename) {
 		importFiles = filename;
 		return this;
 	}
 
 	/**
 	 * Set the end of statement delimiter
 	 *
 	 * @param delimiter The delimiter
 	 * @return this
 	 */
 	public SchemaExport setDelimiter(String delimiter) {
 		this.delimiter = delimiter;
 		return this;
 	}
 
 	/**
 	 * Should we format the sql strings?
 	 *
 	 * @param format Should we format SQL strings
 	 * @return this
 	 */
 	public SchemaExport setFormat(boolean format) {
 		this.formatter = ( format ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
 		return this;
 	}
 
 	/**
 	 * Should we stop once an error occurs?
 	 *
 	 * @param haltOnError True if export should stop after error.
 	 * @return this
 	 */
 	public SchemaExport setHaltOnError(boolean haltOnError) {
 		this.haltOnError = haltOnError;
 		return this;
 	}
 
 	/**
 	 * Run the schema creation script.
 	 *
 	 * @param script print the DDL to the console
 	 * @param export export the script to the database
 	 */
 	public void create(boolean script, boolean export) {
 		execute( script, export, false, false );
 	}
 
 	/**
 	 * Run the drop schema script.
 	 *
 	 * @param script print the DDL to the console
 	 * @param export export the script to the database
 	 */
 	public void drop(boolean script, boolean export) {
 		execute( script, export, true, false );
 	}
 
 	public void execute(boolean script, boolean export, boolean justDrop, boolean justCreate) {
 
 		log.info( "Running hbm2ddl schema export" );
 
 		Connection connection = null;
 		Writer outputFileWriter = null;
 		List<NamedReader> importFileReaders = new ArrayList<NamedReader>();
 		Statement statement = null;
 
 		exceptions.clear();
 
 		try {
 
 			for ( String currentFile : importFiles.split(",") ) {
 				try {
 					final String resourceName = currentFile.trim();
 					InputStream stream = ConfigHelper.getResourceAsStream( resourceName );
 					importFileReaders.add( new NamedReader( resourceName, stream ) );
 				}
 				catch ( HibernateException e ) {
 					log.debug( "import file not found: " + currentFile );
 				}
 			}
 
 			if ( outputFile != null ) {
 				log.info( "writing generated schema to file: " + outputFile );
 				outputFileWriter = new FileWriter( outputFile );
 			}
 
 			if ( export ) {
 				log.info( "exporting generated schema to database" );
 				connectionHelper.prepare( true );
 				connection = connectionHelper.getConnection();
 				statement = connection.createStatement();
 			}
 
 			if ( !justCreate ) {
 				drop( script, export, outputFileWriter, statement );
 			}
 
 			if ( !justDrop ) {
 				create( script, export, outputFileWriter, statement );
 				if ( export && importFileReaders.size() > 0 ) {
 					for (NamedReader reader : importFileReaders) {
 						importScript( reader, statement );
 					}
 				}
 			}
 
 			log.info( "schema export complete" );
 
 		}
 
 		catch ( Exception e ) {
 			exceptions.add( e );
 			log.error( "schema export unsuccessful", e );
 		}
 
 		finally {
 
 			try {
 				if ( statement != null ) {
 					statement.close();
 				}
 				if ( connection != null ) {
 					connectionHelper.release();
 				}
 			}
 			catch ( Exception e ) {
 				exceptions.add( e );
 				log.error( "Could not close connection", e );
 			}
 
 			try {
 				if ( outputFileWriter != null ) {
 					outputFileWriter.close();
 				}
 			}
 			catch ( IOException ioe ) {
 				exceptions.add( ioe );
 				log.error( "Error closing output file: " + outputFile, ioe );
 			}
 				for (NamedReader reader : importFileReaders) {
 					try {
 						reader.getReader().close();
 					}
 					catch ( IOException ioe ) {
 						exceptions.add( ioe );
 						log.error( "Error closing imput files: " + reader.getName(), ioe );
 					}
 				}
 
 
 		}
 	}
 
 	private class NamedReader {
 		private final Reader reader;
 		private final String name;
 
 		public NamedReader(String name, InputStream stream) {
 			this.name = name;
 			this.reader = new InputStreamReader( stream );
 		}
 
 		public Reader getReader() {
 			return reader;
 		}
 
 		public String getName() {
 			return name;
 		}
 	}
 
 	private void importScript(NamedReader importFileReader, Statement statement)
 			throws IOException {
 		log.info( "Executing import script: " + importFileReader.getName() );
 		BufferedReader reader = new BufferedReader( importFileReader.getReader() );
 		long lineNo = 0;
 		for ( String sql = reader.readLine(); sql != null; sql = reader.readLine() ) {
 			try {
 				lineNo++;
 				String trimmedSql = sql.trim();
 				if ( trimmedSql.length() == 0 ||
 				     trimmedSql.startsWith( "--" ) ||
 				     trimmedSql.startsWith( "//" ) ||
 				     trimmedSql.startsWith( "/*" ) ) {
 					continue;
 				}
 				else {
 					if ( trimmedSql.endsWith( ";" ) ) {
 						trimmedSql = trimmedSql.substring( 0, trimmedSql.length() - 1 );
 					}
 					log.debug( trimmedSql );
 					statement.execute( trimmedSql );
 				}
 			}
 			catch ( SQLException e ) {
 				throw new JDBCException( "Error during import script execution at line " + lineNo, e );
 			}
 		}
 	}
 
 	private void create(boolean script, boolean export, Writer fileOutput, Statement statement)
 			throws IOException {
 		for ( int j = 0; j < createSQL.length; j++ ) {
 			try {
 				execute( script, export, fileOutput, statement, createSQL[j] );
 			}
 			catch ( SQLException e ) {
 				if ( haltOnError ) {
 					throw new JDBCException( "Error during DDL export", e );
 				}
 				exceptions.add( e );
 				log.error( "Unsuccessful: " + createSQL[j] );
 				log.error( e.getMessage() );
 			}
 		}
 	}
 
 	private void drop(boolean script, boolean export, Writer fileOutput, Statement statement)
 			throws IOException {
 		for ( int i = 0; i < dropSQL.length; i++ ) {
 			try {
 				execute( script, export, fileOutput, statement, dropSQL[i] );
 			}
 			catch ( SQLException e ) {
 				exceptions.add( e );
 				log.debug( "Unsuccessful: " + dropSQL[i] );
 				log.debug( e.getMessage() );
 			}
 		}
 	}
 
 	private void execute(boolean script, boolean export, Writer fileOutput, Statement statement, final String sql)
 			throws IOException, SQLException {
 		String formatted = formatter.format( sql );
 		if ( delimiter != null ) {
 			formatted += delimiter;
 		}
 		if ( script ) {
 			System.out.println( formatted );
 		}
 		log.debug( formatted );
 		if ( outputFile != null ) {
 			fileOutput.write( formatted + "\n" );
 		}
 		if ( export ) {
 
 			statement.executeUpdate( sql );
 			try {
 				SQLWarning warnings = statement.getWarnings();
 				if ( warnings != null) {
 					JDBCExceptionReporter.logAndClearWarnings( connectionHelper.getConnection() );
 				}
 			}
 			catch( SQLException sqle ) {
 				log.warn( "unable to log SQLWarnings : " + sqle );
 			}
 		}
 
 		
 	}
 
 	public static void main(String[] args) {
 		try {
 			Configuration cfg = new Configuration();
 
 			boolean script = true;
 			boolean drop = false;
 			boolean create = false;
 			boolean halt = false;
 			boolean export = true;
 			String outFile = null;
 			String importFile = DEFAULT_IMPORT_FILE;
 			String propFile = null;
 			boolean format = false;
 			String delim = null;
 
 			for ( int i = 0; i < args.length; i++ ) {
 				if ( args[i].startsWith( "--" ) ) {
 					if ( args[i].equals( "--quiet" ) ) {
 						script = false;
 					}
 					else if ( args[i].equals( "--drop" ) ) {
 						drop = true;
 					}
 					else if ( args[i].equals( "--create" ) ) {
 						create = true;
 					}
 					else if ( args[i].equals( "--haltonerror" ) ) {
 						halt = true;
 					}
 					else if ( args[i].equals( "--text" ) ) {
 						export = false;
 					}
 					else if ( args[i].startsWith( "--output=" ) ) {
 						outFile = args[i].substring( 9 );
 					}
 					else if ( args[i].startsWith( "--import=" ) ) {
 						importFile = args[i].substring( 9 );
 					}
 					else if ( args[i].startsWith( "--properties=" ) ) {
 						propFile = args[i].substring( 13 );
 					}
 					else if ( args[i].equals( "--format" ) ) {
 						format = true;
 					}
 					else if ( args[i].startsWith( "--delimiter=" ) ) {
 						delim = args[i].substring( 12 );
 					}
 					else if ( args[i].startsWith( "--config=" ) ) {
 						cfg.configure( args[i].substring( 9 ) );
 					}
 					else if ( args[i].startsWith( "--naming=" ) ) {
 						cfg.setNamingStrategy(
 								( NamingStrategy ) ReflectHelper.classForName( args[i].substring( 9 ) )
 										.newInstance()
 						);
 					}
 				}
 				else {
 					String filename = args[i];
 					if ( filename.endsWith( ".jar" ) ) {
 						cfg.addJar( new File( filename ) );
 					}
 					else {
 						cfg.addFile( filename );
 					}
 				}
 
 			}
 
 			if ( propFile != null ) {
 				Properties props = new Properties();
 				props.putAll( cfg.getProperties() );
 				props.load( new FileInputStream( propFile ) );
 				cfg.setProperties( props );
 			}
 
 			if (importFile != null) {
 				cfg.setProperty( Environment.HBM2DDL_IMPORT_FILES, importFile );
 			}
 			SchemaExport se = new SchemaExport( cfg )
 					.setHaltOnError( halt )
 					.setOutputFile( outFile )
 					.setDelimiter( delim );
 			if ( format ) {
 				se.setFormat( true );
 			}
 			se.execute( script, export, drop, create );
 
 		}
 		catch ( Exception e ) {
 			log.error( "Error creating schema ", e );
 			e.printStackTrace();
 		}
 	}
 
 	/**
 	 * Returns a List of all Exceptions which occured during the export.
 	 *
 	 * @return A List containig the Exceptions occured during the export
 	 */
 	public List getExceptions() {
 		return exceptions;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdate.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdate.java
index 07298c9947..09bf4db55c 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdate.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdate.java
@@ -1,273 +1,274 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.io.FileInputStream;
 import java.io.FileWriter;
 import java.io.Writer;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.JDBCException;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.cfg.Settings;
 import org.hibernate.dialect.Dialect;
+import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.jdbc.util.FormatStyle;
 import org.hibernate.jdbc.util.Formatter;
-import org.hibernate.jdbc.util.SQLStatementLogger;
+import org.hibernate.engine.jdbc.spi.SQLStatementLogger;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.util.ReflectHelper;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
  * A commandline tool to update a database schema. May also be called from
  * inside an application.
  *
  * @author Christoph Sturm
  */
 public class SchemaUpdate {
 
 	private static final Logger log = LoggerFactory.getLogger( SchemaUpdate.class );
 	private ConnectionHelper connectionHelper;
 	private Configuration configuration;
 	private Dialect dialect;
 	private List exceptions;
 	private boolean haltOnError = false;
 	private boolean format = true;
 	private String outputFile = null;
 	private String delimiter;
 	private Formatter formatter;
 	private SQLStatementLogger sqlStatementLogger;
 
 	public SchemaUpdate(Configuration cfg) throws HibernateException {
 		this( cfg, cfg.getProperties() );
 	}
 
 	public SchemaUpdate(Configuration cfg, Properties connectionProperties) throws HibernateException {
 		this.configuration = cfg;
 		dialect = Dialect.getDialect( connectionProperties );
 		Properties props = new Properties();
 		props.putAll( dialect.getDefaultProperties() );
 		props.putAll( connectionProperties );
 		connectionHelper = new ManagedProviderConnectionHelper( props );
 		exceptions = new ArrayList();
 		formatter = ( ConfigurationHelper.getBoolean( Environment.FORMAT_SQL, props ) ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
 	}
 
-	public SchemaUpdate(Configuration cfg, Settings settings) throws HibernateException {
+	public SchemaUpdate(JdbcServices jdbcServices, Configuration cfg) throws HibernateException {
 		this.configuration = cfg;
-		dialect = settings.getDialect();
+		dialect = jdbcServices.getDialect();
 		connectionHelper = new SuppliedConnectionProviderConnectionHelper(
-				settings.getConnectionProvider()
+				jdbcServices.getConnectionProvider()
 		);
 		exceptions = new ArrayList();
-		sqlStatementLogger = settings.getSqlStatementLogger();
-		formatter = ( sqlStatementLogger.isFormatSql() ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
+		sqlStatementLogger = jdbcServices.getSqlStatementLogger();
+		formatter = ( sqlStatementLogger.isFormat() ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
 	}
 
 	public static void main(String[] args) {
 		try {
 			Configuration cfg = new Configuration();
 
 			boolean script = true;
 			// If true then execute db updates, otherwise just generate and display updates
 			boolean doUpdate = true;
 			String propFile = null;
 
 			for ( int i = 0; i < args.length; i++ ) {
 				if ( args[i].startsWith( "--" ) ) {
 					if ( args[i].equals( "--quiet" ) ) {
 						script = false;
 					}
 					else if ( args[i].startsWith( "--properties=" ) ) {
 						propFile = args[i].substring( 13 );
 					}
 					else if ( args[i].startsWith( "--config=" ) ) {
 						cfg.configure( args[i].substring( 9 ) );
 					}
 					else if ( args[i].startsWith( "--text" ) ) {
 						doUpdate = false;
 					}
 					else if ( args[i].startsWith( "--naming=" ) ) {
 						cfg.setNamingStrategy(
 								( NamingStrategy ) ReflectHelper.classForName( args[i].substring( 9 ) ).newInstance()
 						);
 					}
 				}
 				else {
 					cfg.addFile( args[i] );
 				}
 
 			}
 
 			if ( propFile != null ) {
 				Properties props = new Properties();
 				props.putAll( cfg.getProperties() );
 				props.load( new FileInputStream( propFile ) );
 				cfg.setProperties( props );
 			}
 
 			new SchemaUpdate( cfg ).execute( script, doUpdate );
 		}
 		catch ( Exception e ) {
 			log.error( "Error running schema update", e );
 			e.printStackTrace();
 		}
 	}
 
 	/**
 	 * Execute the schema updates
 	 *
 	 * @param script print all DDL to the console
 	 */
 	public void execute(boolean script, boolean doUpdate) {
 
 		log.info( "Running hbm2ddl schema update" );
 
 		Connection connection = null;
 		Statement stmt = null;
 		Writer outputFileWriter = null;
 
 		exceptions.clear();
 
 		try {
 
 			DatabaseMetadata meta;
 			try {
 				log.info( "fetching database metadata" );
 				connectionHelper.prepare( true );
 				connection = connectionHelper.getConnection();
 				meta = new DatabaseMetadata( connection, dialect );
 				stmt = connection.createStatement();
 			}
 			catch ( SQLException sqle ) {
 				exceptions.add( sqle );
 				log.error( "could not get database metadata", sqle );
 				throw sqle;
 			}
 
 			log.info( "updating schema" );
 
 			
 			if ( outputFile != null ) {
 				log.info( "writing generated schema to file: " + outputFile );
 				outputFileWriter = new FileWriter( outputFile );
 			}
 			 
 			String[] createSQL = configuration.generateSchemaUpdateScript( dialect, meta );
 			for ( int j = 0; j < createSQL.length; j++ ) {
 
 				final String sql = createSQL[j];
 				String formatted = formatter.format( sql );
 				try {
 					if ( delimiter != null ) {
 						formatted += delimiter;
 					}
 					if ( script ) {
 						System.out.println( formatted );
 					}
 					if ( outputFile != null ) {
 						outputFileWriter.write( formatted + "\n" );
 					}
 					if ( doUpdate ) {
 						log.debug( sql );
 						stmt.executeUpdate( formatted );
 					}
 				}
 				catch ( SQLException e ) {
 					if ( haltOnError ) {
 						throw new JDBCException( "Error during DDL export", e );
 					}
 					exceptions.add( e );
 					log.error( "Unsuccessful: " + sql );
 					log.error( e.getMessage() );
 				}
 			}
 
 			log.info( "schema update complete" );
 
 		}
 		catch ( Exception e ) {
 			exceptions.add( e );
 			log.error( "could not complete schema update", e );
 		}
 		finally {
 
 			try {
 				if ( stmt != null ) {
 					stmt.close();
 				}
 				connectionHelper.release();
 			}
 			catch ( Exception e ) {
 				exceptions.add( e );
 				log.error( "Error closing connection", e );
 			}
 			try {
 				if( outputFileWriter != null ) {
 					outputFileWriter.close();
 				}
 			}
 			catch(Exception e) {
 				exceptions.add(e);
 				log.error( "Error closing connection", e );
 			}
 		}
 	}
 
 	/**
 	 * Returns a List of all Exceptions which occured during the export.
 	 *
 	 * @return A List containig the Exceptions occured during the export
 	 */
 	public List getExceptions() {
 		return exceptions;
 	}
 
 	public void setHaltOnError(boolean haltOnError) {
 		this.haltOnError = haltOnError;
 	}
 
 	public void setFormat(boolean format) {
 		this.formatter = ( format ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
 	}
 
 	public void setOutputFile(String outputFile) {
 		this.outputFile = outputFile;
 	}
 
 	public void setDelimiter(String delimiter) {
 		this.delimiter = delimiter;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidator.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidator.java
index a2711d434e..04f9985220 100755
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidator.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidator.java
@@ -1,157 +1,158 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.io.FileInputStream;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.Properties;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.hibernate.HibernateException;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.cfg.Settings;
 import org.hibernate.dialect.Dialect;
+import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.util.ReflectHelper;
 
 /**
  * A commandline tool to update a database schema. May also be called from
  * inside an application.
  *
  * @author Christoph Sturm
  */
 public class SchemaValidator {
 
 	private static final Logger log = LoggerFactory.getLogger( SchemaValidator.class );
 	private ConnectionHelper connectionHelper;
 	private Configuration configuration;
 	private Dialect dialect;
 
 	public SchemaValidator(Configuration cfg) throws HibernateException {
 		this( cfg, cfg.getProperties() );
 	}
 
 	public SchemaValidator(Configuration cfg, Properties connectionProperties) throws HibernateException {
 		this.configuration = cfg;
 		dialect = Dialect.getDialect( connectionProperties );
 		Properties props = new Properties();
 		props.putAll( dialect.getDefaultProperties() );
 		props.putAll( connectionProperties );
 		connectionHelper = new ManagedProviderConnectionHelper( props );
 	}
 
-	public SchemaValidator(Configuration cfg, Settings settings) throws HibernateException {
+	public SchemaValidator(JdbcServices jdbcServices, Configuration cfg ) throws HibernateException {
 		this.configuration = cfg;
-		dialect = settings.getDialect();
+		dialect = jdbcServices.getDialect();
 		connectionHelper = new SuppliedConnectionProviderConnectionHelper(
-				settings.getConnectionProvider()
+				jdbcServices.getConnectionProvider()
 		);
 	}
 
 	public static void main(String[] args) {
 		try {
 			Configuration cfg = new Configuration();
 
 			String propFile = null;
 
 			for ( int i = 0; i < args.length; i++ ) {
 				if ( args[i].startsWith( "--" ) ) {
 					if ( args[i].startsWith( "--properties=" ) ) {
 						propFile = args[i].substring( 13 );
 					}
 					else if ( args[i].startsWith( "--config=" ) ) {
 						cfg.configure( args[i].substring( 9 ) );
 					}
 					else if ( args[i].startsWith( "--naming=" ) ) {
 						cfg.setNamingStrategy(
 								( NamingStrategy ) ReflectHelper.classForName( args[i].substring( 9 ) ).newInstance()
 						);
 					}
 				}
 				else {
 					cfg.addFile( args[i] );
 				}
 
 			}
 
 			if ( propFile != null ) {
 				Properties props = new Properties();
 				props.putAll( cfg.getProperties() );
 				props.load( new FileInputStream( propFile ) );
 				cfg.setProperties( props );
 			}
 
 			new SchemaValidator( cfg ).validate();
 		}
 		catch ( Exception e ) {
 			log.error( "Error running schema update", e );
 			e.printStackTrace();
 		}
 	}
 
 	/**
 	 * Perform the validations.
 	 */
 	public void validate() {
 
 		log.info( "Running schema validator" );
 
 		Connection connection = null;
 
 		try {
 
 			DatabaseMetadata meta;
 			try {
 				log.info( "fetching database metadata" );
 				connectionHelper.prepare( false );
 				connection = connectionHelper.getConnection();
 				meta = new DatabaseMetadata( connection, dialect, false );
 			}
 			catch ( SQLException sqle ) {
 				log.error( "could not get database metadata", sqle );
 				throw sqle;
 			}
 
 			configuration.validateSchema( dialect, meta );
 
 		}
 		catch ( SQLException e ) {
 			log.error( "could not complete schema validation", e );
 		}
 		finally {
 
 			try {
 				connectionHelper.release();
 			}
 			catch ( Exception e ) {
 				log.error( "Error closing connection", e );
 			}
 
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SuppliedConnectionProviderConnectionHelper.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SuppliedConnectionProviderConnectionHelper.java
index 41fc7792be..903dace8f0 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SuppliedConnectionProviderConnectionHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SuppliedConnectionProviderConnectionHelper.java
@@ -1,79 +1,79 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.tool.hbm2ddl;
 
-import org.hibernate.connection.ConnectionProvider;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.util.JDBCExceptionReporter;
 
 import java.sql.Connection;
 import java.sql.SQLException;
 
 /**
  * A {@link ConnectionHelper} implementation based on a provided
  * {@link ConnectionProvider}.  Essentially, ensures that the connection
  * gets cleaned up, but that the provider itself remains usable since it
  * was externally provided to us.
  *
  * @author Steve Ebersole
  */
 class SuppliedConnectionProviderConnectionHelper implements ConnectionHelper {
 	private ConnectionProvider provider;
 	private Connection connection;
 	private boolean toggleAutoCommit;
 
 	public SuppliedConnectionProviderConnectionHelper(ConnectionProvider provider) {
 		this.provider = provider;
 	}
 
 	public void prepare(boolean needsAutoCommit) throws SQLException {
 		connection = provider.getConnection();
 		toggleAutoCommit = needsAutoCommit && !connection.getAutoCommit();
 		if ( toggleAutoCommit ) {
 			try {
 				connection.commit();
 			}
 			catch( Throwable ignore ) {
 				// might happen with a managed connection
 			}
 			connection.setAutoCommit( true );
 		}
 	}
 
 	public Connection getConnection() throws SQLException {
 		return connection;
 	}
 
 	public void release() throws SQLException {
 		// we only release the connection
 		if ( connection != null ) {
 			JDBCExceptionReporter.logAndClearWarnings( connection );
 			if ( toggleAutoCommit ) {
 				connection.setAutoCommit( false );
 			}
 			provider.closeConnection( connection );
 			connection = null;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/util/ExternalSessionFactoryConfig.java b/hibernate-core/src/main/java/org/hibernate/util/ExternalSessionFactoryConfig.java
index 6eb711e683..3db5f4e3e5 100644
--- a/hibernate-core/src/main/java/org/hibernate/util/ExternalSessionFactoryConfig.java
+++ b/hibernate-core/src/main/java/org/hibernate/util/ExternalSessionFactoryConfig.java
@@ -1,398 +1,400 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.util;
 
+import org.hibernate.SessionFactory;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
+import org.hibernate.cfg.internal.ServicesRegistryBootstrap;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 
 import java.util.Properties;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Set;
 import java.util.HashMap;
 import java.util.HashSet;
 
 /**
  * Defines support for various externally configurable SessionFactory(s), for
  * example, {@link org.hibernate.jmx.HibernateService JMX} or the JCA
  * adapter.
  *
  * @author Steve Ebersole
  */
 public abstract class ExternalSessionFactoryConfig {
 
 	private String mapResources;
 	private String dialect;
 	private String defaultSchema;
 	private String defaultCatalog;
 	private String maximumFetchDepth;
 	private String jdbcFetchSize;
 	private String jdbcBatchSize;
 	private String batchVersionedDataEnabled;
 	private String jdbcScrollableResultSetEnabled;
 	private String getGeneratedKeysEnabled;
 	private String streamsForBinaryEnabled;
 	private String reflectionOptimizationEnabled;
 	private String querySubstitutions;
 	private String showSqlEnabled;
 	private String commentsEnabled;
 	private String cacheProviderClass;
 	private String cacheProviderConfig;
 	private String cacheRegionPrefix;
 	private String secondLevelCacheEnabled;
 	private String minimalPutsEnabled;
 	private String queryCacheEnabled;
 
 	private Map additionalProperties;
 	private Set excludedPropertyNames = new HashSet();
 	private Map customListeners;
 
 
 	protected Set getExcludedPropertyNames() {
 		return excludedPropertyNames;
 	}
 
 	public final String getMapResources() {
 		return mapResources;
 	}
 
 	public final void setMapResources(String mapResources) {
 		this.mapResources = mapResources;
 	}
 
 	public void addMapResource(String mapResource) {
 		if ( mapResources==null || mapResources.length()==0 ) {
 			mapResources = mapResource.trim();
 		}
 		else {
 			mapResources += ", " + mapResource.trim();
 		}
 	}
 
 	public final String getDialect() {
 		return dialect;
 	}
 
 	public final void setDialect(String dialect) {
 		this.dialect = dialect;
 	}
 
 	public final String getDefaultSchema() {
 		return defaultSchema;
 	}
 
 	public final void setDefaultSchema(String defaultSchema) {
 		this.defaultSchema = defaultSchema;
 	}
 
 	public final String getDefaultCatalog() {
 		return defaultCatalog;
 	}
 
 	public final void setDefaultCatalog(String defaultCatalog) {
 		this.defaultCatalog = defaultCatalog;
 	}
 
 	public final String getMaximumFetchDepth() {
 		return maximumFetchDepth;
 	}
 
 	public final void setMaximumFetchDepth(String maximumFetchDepth) {
 		verifyInt( maximumFetchDepth );
 		this.maximumFetchDepth = maximumFetchDepth;
 	}
 
 	public final String getJdbcFetchSize() {
 		return jdbcFetchSize;
 	}
 
 	public final void setJdbcFetchSize(String jdbcFetchSize) {
 		verifyInt( jdbcFetchSize );
 		this.jdbcFetchSize = jdbcFetchSize;
 	}
 
 	public final String getJdbcBatchSize() {
 		return jdbcBatchSize;
 	}
 
 	public final void setJdbcBatchSize(String jdbcBatchSize) {
 		verifyInt( jdbcBatchSize );
 		this.jdbcBatchSize = jdbcBatchSize;
 	}
 
 	public final String getBatchVersionedDataEnabled() {
 		return batchVersionedDataEnabled;
 	}
 
 	public final void setBatchVersionedDataEnabled(String batchVersionedDataEnabled) {
 		this.batchVersionedDataEnabled = batchVersionedDataEnabled;
 	}
 
 	public final String getJdbcScrollableResultSetEnabled() {
 		return jdbcScrollableResultSetEnabled;
 	}
 
 	public final void setJdbcScrollableResultSetEnabled(String jdbcScrollableResultSetEnabled) {
 		this.jdbcScrollableResultSetEnabled = jdbcScrollableResultSetEnabled;
 	}
 
 	public final String getGetGeneratedKeysEnabled() {
 		return getGeneratedKeysEnabled;
 	}
 
 	public final void setGetGeneratedKeysEnabled(String getGeneratedKeysEnabled) {
 		this.getGeneratedKeysEnabled = getGeneratedKeysEnabled;
 	}
 
 	public final String getStreamsForBinaryEnabled() {
 		return streamsForBinaryEnabled;
 	}
 
 	public final void setStreamsForBinaryEnabled(String streamsForBinaryEnabled) {
 		this.streamsForBinaryEnabled = streamsForBinaryEnabled;
 	}
 
 	public final String getReflectionOptimizationEnabled() {
 		return reflectionOptimizationEnabled;
 	}
 
 	public final void setReflectionOptimizationEnabled(String reflectionOptimizationEnabled) {
 		this.reflectionOptimizationEnabled = reflectionOptimizationEnabled;
 	}
 
 	public final String getQuerySubstitutions() {
 		return querySubstitutions;
 	}
 
 	public final void setQuerySubstitutions(String querySubstitutions) {
 		this.querySubstitutions = querySubstitutions;
 	}
 
 	public final String getShowSqlEnabled() {
 		return showSqlEnabled;
 	}
 
 	public final void setShowSqlEnabled(String showSqlEnabled) {
 		this.showSqlEnabled = showSqlEnabled;
 	}
 
 	public final String getCommentsEnabled() {
 		return commentsEnabled;
 	}
 
 	public final void setCommentsEnabled(String commentsEnabled) {
 		this.commentsEnabled = commentsEnabled;
 	}
 
 	public final String getSecondLevelCacheEnabled() {
 		return secondLevelCacheEnabled;
 	}
 
 	public final void setSecondLevelCacheEnabled(String secondLevelCacheEnabled) {
 		this.secondLevelCacheEnabled = secondLevelCacheEnabled;
 	}
 
 	public final String getCacheProviderClass() {
 		return cacheProviderClass;
 	}
 
 	public final void setCacheProviderClass(String cacheProviderClass) {
 		this.cacheProviderClass = cacheProviderClass;
 	}
 
 	public String getCacheProviderConfig() {
 		return cacheProviderConfig;
 	}
 
 	public void setCacheProviderConfig(String cacheProviderConfig) {
 		this.cacheProviderConfig = cacheProviderConfig;
 	}
 
 	public final String getCacheRegionPrefix() {
 		return cacheRegionPrefix;
 	}
 
 	public final void setCacheRegionPrefix(String cacheRegionPrefix) {
 		this.cacheRegionPrefix = cacheRegionPrefix;
 	}
 
 	public final String getMinimalPutsEnabled() {
 		return minimalPutsEnabled;
 	}
 
 	public final void setMinimalPutsEnabled(String minimalPutsEnabled) {
 		this.minimalPutsEnabled = minimalPutsEnabled;
 	}
 
 	public final String getQueryCacheEnabled() {
 		return queryCacheEnabled;
 	}
 
 	public final void setQueryCacheEnabled(String queryCacheEnabled) {
 		this.queryCacheEnabled = queryCacheEnabled;
 	}
 
 	public final Map getCustomListeners() {
 		return customListeners;
 	}
 
 	public void setCustomListeners(Map customListeners) {
 		this.customListeners = customListeners;
 	}
 
 	public void setCustomListenersAsString(String customListenersString) {
 		// Note : expected in the syntax:
 		//      type=listenerClass
 		//          ({sep}type=listenerClass)*
 		// where {sep} is any whitespace or comma
 		if ( StringHelper.isNotEmpty( customListenersString) ) {
 			String[] listenerEntries = ConfigurationHelper.toStringArray( customListenersString, " ,\n\t\r\f" );
 			for ( int i = 0; i < listenerEntries.length; i++ ) {
 				final int keyValueSepPosition = listenerEntries[i].indexOf( '=' );
 				final String type = listenerEntries[i].substring( 0, keyValueSepPosition );
 				final String listenerClass = listenerEntries[i].substring( keyValueSepPosition + 1 );
 				setCustomListener( type, listenerClass );
 			}
 		}
 	}
 
 	public void setCustomListener(String type, String listenerClass) {
 		if ( customListeners == null ) {
 			customListeners = new HashMap();
 		}
 		customListeners.put( type, listenerClass );
 	}
 
 	public final void addAdditionalProperty(String name, String value) {
 		if ( !getExcludedPropertyNames().contains( name ) ) {
 			if ( additionalProperties == null ) {
 				additionalProperties = new HashMap();
 			}
 			additionalProperties.put( name, value );
 		}
 	}
 
 	protected final Configuration buildConfiguration() {
 
 		Configuration cfg = new Configuration().setProperties( buildProperties() );
 
 
 		String[] mappingFiles = ConfigurationHelper.toStringArray( mapResources, " ,\n\t\r\f" );
 		for ( int i = 0; i < mappingFiles.length; i++ ) {
 			cfg.addResource( mappingFiles[i] );
 		}
 
 		if ( customListeners != null && !customListeners.isEmpty() ) {
 			Iterator entries = customListeners.entrySet().iterator();
 			while ( entries.hasNext() ) {
 				final Map.Entry entry = ( Map.Entry ) entries.next();
 				final String type = ( String ) entry.getKey();
 				final Object value = entry.getValue();
 				if ( value != null ) {
 					if ( String.class.isAssignableFrom( value.getClass() ) ) {
 						// Its the listener class name
 						cfg.setListener( type, ( ( String ) value ) );
 					}
 					else {
 						// Its the listener instance (or better be)
 						cfg.setListener( type, value );
 					}
 				}
 			}
 		}
 
 		return cfg;
 	}
 
 	protected final Properties buildProperties() {
 		Properties props = new Properties();
 		setUnlessNull( props, Environment.DIALECT, dialect );
 		setUnlessNull( props, Environment.DEFAULT_SCHEMA, defaultSchema );
 		setUnlessNull( props, Environment.DEFAULT_CATALOG, defaultCatalog );
 		setUnlessNull( props, Environment.MAX_FETCH_DEPTH, maximumFetchDepth );
 		setUnlessNull( props, Environment.STATEMENT_FETCH_SIZE, jdbcFetchSize );
 		setUnlessNull( props, Environment.STATEMENT_BATCH_SIZE, jdbcBatchSize );
 		setUnlessNull( props, Environment.BATCH_VERSIONED_DATA, batchVersionedDataEnabled );
 		setUnlessNull( props, Environment.USE_SCROLLABLE_RESULTSET, jdbcScrollableResultSetEnabled );
 		setUnlessNull( props, Environment.USE_GET_GENERATED_KEYS, getGeneratedKeysEnabled );
 		setUnlessNull( props, Environment.USE_STREAMS_FOR_BINARY, streamsForBinaryEnabled );
 		setUnlessNull( props, Environment.USE_REFLECTION_OPTIMIZER, reflectionOptimizationEnabled );
 		setUnlessNull( props, Environment.QUERY_SUBSTITUTIONS, querySubstitutions );
 		setUnlessNull( props, Environment.SHOW_SQL, showSqlEnabled );
 		setUnlessNull( props, Environment.USE_SQL_COMMENTS, commentsEnabled );
 		setUnlessNull( props, Environment.CACHE_PROVIDER, cacheProviderClass );
 		setUnlessNull( props, Environment.CACHE_PROVIDER_CONFIG, cacheProviderConfig );
 		setUnlessNull( props, Environment.CACHE_REGION_PREFIX, cacheRegionPrefix );
 		setUnlessNull( props, Environment.USE_MINIMAL_PUTS, minimalPutsEnabled );
 		setUnlessNull( props, Environment.USE_SECOND_LEVEL_CACHE, secondLevelCacheEnabled );
 		setUnlessNull( props, Environment.USE_QUERY_CACHE, queryCacheEnabled );
 
 		Map extraProperties = getExtraProperties();
 		if ( extraProperties != null ) {
 			addAll( props, extraProperties );
 		}
 
 		if ( additionalProperties != null ) {
 			addAll( props, additionalProperties );
 		}
 
 		return props;
 	}
 
 	protected void addAll( Properties target, Map source ) {
 		Iterator itr = source.entrySet().iterator();
 		while ( itr.hasNext() ) {
 			final Map.Entry entry = ( Map.Entry ) itr.next();
 			final String propertyName = ( String ) entry.getKey();
 			final String propertyValue = ( String ) entry.getValue();
 			if ( propertyName != null && propertyValue != null ) {
 				// Make sure we don't override previous set values
 				if ( !target.keySet().contains( propertyName ) ) {
 					if ( !getExcludedPropertyNames().contains( propertyName) ) {
 						target.put( propertyName, propertyValue );
 					}
 				}
 			}
 		}
 	}
 
 	protected Map getExtraProperties() {
 		return null;
 	}
 
 	private void setUnlessNull(Properties props, String key, String value) {
 		if ( value != null ) {
 			props.setProperty( key, value );
 		}
 	}
 
 	private void verifyInt(String value)
 	{
 		if ( value != null ) {
 			Integer.parseInt( value );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/javadoc/package.html b/hibernate-core/src/main/javadoc/package.html
index 521ff379a9..19bd6c8223 100644
--- a/hibernate-core/src/main/javadoc/package.html
+++ b/hibernate-core/src/main/javadoc/package.html
@@ -1,54 +1,54 @@
 <body>
 
 <h2>Hibernate Core (native API) JavaDocs</h2>
 
 In addition to  {@link org.hibernate.SessionFactory} and {@link org.hibernate.Session}, applications using the
 Hibernate native API will often need to utilize the following interfaces:<ul>
     <li>{@link org.hibernate.cfg.Configuration}</li>
     <li>{@link org.hibernate.Hibernate}</li>
     <li>{@link org.hibernate.Transaction}</li>
     <li>{@link org.hibernate.Query}</li>
     <li>{@link org.hibernate.Criteria}</li>
     <li>{@link org.hibernate.criterion.Projection}</li>
     <li>{@link org.hibernate.criterion.Projections}</li>
     <li>{@link org.hibernate.criterion.Criterion}</li>
     <li>{@link org.hibernate.criterion.Restrictions}</li>
     <li>{@link org.hibernate.criterion.Order}</li>
     <li>{@link org.hibernate.criterion.Example}</li>
 </ul>
 These interfaces are fully intended to be exposed to application code.
 <hr/>
 
 <h3>Extensions</h3>
 Hibernate defines a number of interfaces that are completely intended to be extendable by application programmers and/or
 integrators.  Listed below is a (not necessarily exhaustive) list of the most commonly utilized extension points:<ul>
     <li>{@link org.hibernate.EntityNameResolver}</li>
     <li>{@link org.hibernate.Interceptor} / {@link org.hibernate.EmptyInterceptor}</li>
     <li>{@link org.hibernate.Transaction} / {@link org.hibernate.transaction.TransactionFactory}</li>
     <li>{@link org.hibernate.context.CurrentSessionContext}</li>
     <li>{@link org.hibernate.dialect.Dialect}</li>
     <li>{@link org.hibernate.dialect.resolver.DialectResolver}</li>
     <li>{@link org.hibernate.event event listener} interfaces</li>
     <li>{@link org.hibernate.id.IdentifierGenerator}</li>
     <li>{@link org.hibernate.tuple.entity.EntityTuplizer} / {@link org.hibernate.tuple.component.ComponentTuplizer}</li>
     <li>{@link org.hibernate.type.Type} / {@link org.hibernate.usertype}</li>
 </ul>
 Note that there is a large degree of crossover between the notion of extension points and that of an integration SPI (below).
 <hr/>
 
 <h3>Integration SPI</h3>
 Hibernate provides a number of SPIs intended to integrate itself with various third party frameworks or application code to provide
 additional capabilities.   The SPIs fall mainly into 2 categories:<ul>
     <li>Caching - {@link org.hibernate.cache.RegionFactory}</li>
-    <li>JDBC Connection management - {@link org.hibernate.connection.ConnectionProvider}
+    <li>JDBC Connection management - {@link org.hibernate.service.jdbc.connections.spi.ConnectionProvider}
 </ul>
 Certainly {@link org.hibernate.dialect.Dialect} could fit in here as well, though we chose to list it under extensions since application
 developers tend to provide extended dialects rather frequently for various reasons.
 <br/>
 Another SPI that is not yet exposed but is planned for such is the <em>bytecode provider</em> SPI.  See {@link org.hibernate.bytecode}
 for details.
 <hr/>
 
 Complete Hibernate documentation may be found online at <a href="http://docs.jboss.org/hibernate/">http://docs.jboss.org/hibernate/</a>.
 
 </body>
\ No newline at end of file
diff --git a/hibernate-core/src/test/java/org/hibernate/connection/PropertiesTest.java b/hibernate-core/src/test/java/org/hibernate/connection/PropertiesTest.java
index 60a2759c0b..9d7c6a7a31 100644
--- a/hibernate-core/src/test/java/org/hibernate/connection/PropertiesTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/connection/PropertiesTest.java
@@ -1,54 +1,56 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.connection;
 
 import java.util.Properties;
 
 import junit.framework.TestCase;
 
+import org.hibernate.service.jdbc.connections.internal.ConnectionProviderInitiator;
+
 /**
  * Undocumented
  *
  * @author kbow
  */
 
 public class PropertiesTest extends TestCase {
 	public void testProperties() throws Exception {
 		final Properties props = new Properties();
 
 		props.put("rpt.1.hibernate.dialect", "org.hibernate.dialect.DerbyDialect");
 		props.put("rpt.2.hibernate.connection.driver_class", "org.apache.derby.jdbc.ClientDriver");
 		props.put("rpt.3.hibernate.connection.url", "jdbc:derby://localhost:1527/db/reports.db");
 		props.put("rpt.4.hibernate.connection.username", "sa");
 		props.put("rpt.5.hibernate.connection.password_enc", "76f271db3661fd50082e68d4b953fbee");
 		props.put("rpt.6.hibernate.connection.password_enc", "76f271db3661fd50082e68d4b953fbee");
 		props.put("hibernate.connection.create", "true");
 
-		final Properties outputProps = ConnectionProviderFactory.getConnectionProperties(props);
+		final Properties outputProps = ConnectionProviderInitiator.getConnectionProperties( props );
 		assertEquals(1, outputProps.size());
 		assertEquals("true", outputProps.get("create"));
 	}
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/id/SequenceHiLoGeneratorNoIncrementTest.java b/hibernate-core/src/test/java/org/hibernate/id/SequenceHiLoGeneratorNoIncrementTest.java
index 60080ecd46..30da3a4d36 100644
--- a/hibernate-core/src/test/java/org/hibernate/id/SequenceHiLoGeneratorNoIncrementTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/id/SequenceHiLoGeneratorNoIncrementTest.java
@@ -1,164 +1,169 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Properties;
 
 import junit.framework.TestCase;
 
 import org.hibernate.Hibernate;
 import org.hibernate.Session;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.cfg.ObjectNameNormalizer;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.H2Dialect;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.impl.SessionImpl;
 import org.hibernate.jdbc.Work;
 import org.hibernate.mapping.SimpleAuxiliaryDatabaseObject;
 import org.hibernate.TestingDatabaseInfo;
-		
+import org.hibernate.test.common.ServiceRegistryHolder;
+
 /**
  * I went back to 3.3 source and grabbed the code/logic as it existed back then and crafted this
  * unit test so that we can make sure the value keep being generated in the expected manner
  *
  * @author Steve Ebersole
  */
 @SuppressWarnings({ "deprecation" })
 public class SequenceHiLoGeneratorNoIncrementTest extends TestCase {
 	private static final String TEST_SEQUENCE = "test_sequence";
 
 	private Configuration cfg;
+	ServiceRegistryHolder serviceRegistryHolder;
 	private SessionFactoryImplementor sessionFactory;
 	private SequenceHiLoGenerator generator;
 
 	@Override
 	protected void setUp() throws Exception {
 		super.setUp();
 
 		Properties properties = new Properties();
 		properties.setProperty( SequenceGenerator.SEQUENCE, TEST_SEQUENCE );
 		properties.setProperty( SequenceHiLoGenerator.MAX_LO, "0" ); // JPA allocationSize of 1
 		properties.put(
 				PersistentIdentifierGenerator.IDENTIFIER_NORMALIZER,
 				new ObjectNameNormalizer() {
 					@Override
 					protected boolean isUseQuotedIdentifiersGlobally() {
 						return false;
 					}
 
 					@Override
 					protected NamingStrategy getNamingStrategy() {
 						return cfg.getNamingStrategy();
 					}
 				}
 		);
 
 		Dialect dialect = new H2Dialect();
 
 		generator = new SequenceHiLoGenerator();
 		generator.configure( Hibernate.LONG, properties, dialect );
 
 		cfg = TestingDatabaseInfo.buildBaseConfiguration()
 				.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
 		cfg.addAuxiliaryDatabaseObject(
 				new SimpleAuxiliaryDatabaseObject(
 						generator.sqlCreateStrings( dialect )[0],
 						generator.sqlDropStrings( dialect )[0]
 				)
 		);
 
-		sessionFactory = (SessionFactoryImplementor) cfg.buildSessionFactory();
+		serviceRegistryHolder = new ServiceRegistryHolder( cfg.getProperties() );
+		sessionFactory = (SessionFactoryImplementor) cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 	}
 
 	@Override
 	protected void tearDown() throws Exception {
 		if ( sessionFactory != null ) {
 			sessionFactory.close();
 		}
-
+		if ( serviceRegistryHolder != null ) {
+			serviceRegistryHolder.destroy();
+		}
 		super.tearDown();
 	}
 
 	public void testHiLoAlgorithm() {
 		SessionImpl session = (SessionImpl) sessionFactory.openSession();
 		session.beginTransaction();
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// initially sequence should be uninitialized
 		assertEquals( 0L, extractSequenceValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// historically the hilo generators skipped the initial block of values;
 		// 		so the first generated id value is maxlo + 1, here be 4
 		Long generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 1L, generatedValue.longValue() );
 		// which should also perform the first read on the sequence which should set it to its "start with" value (1)
 		assertEquals( 1L, extractSequenceValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 2L, generatedValue.longValue() );
 		assertEquals( 2L, extractSequenceValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 3L, generatedValue.longValue() );
 		assertEquals( 3L, extractSequenceValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 4L, generatedValue.longValue() );
 		assertEquals( 4L, extractSequenceValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 5L, generatedValue.longValue() );
 		assertEquals( 5L, extractSequenceValue( session ) );
 
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	private long extractSequenceValue(Session session) {
 		class WorkImpl implements Work {
 			private long value;
 			public void execute(Connection connection) throws SQLException {
 				PreparedStatement query = connection.prepareStatement( "select currval('" + TEST_SEQUENCE + "');" );
 				ResultSet resultSet = query.executeQuery();
 				resultSet.next();
 				value = resultSet.getLong( 1 );
 			}
 		}
 		WorkImpl work = new WorkImpl();
 		session.doWork( work );
 		return work.value;
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/test/java/org/hibernate/id/SequenceHiLoGeneratorTest.java b/hibernate-core/src/test/java/org/hibernate/id/SequenceHiLoGeneratorTest.java
index 4dd89a75c9..e8f3385ac4 100644
--- a/hibernate-core/src/test/java/org/hibernate/id/SequenceHiLoGeneratorTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/id/SequenceHiLoGeneratorTest.java
@@ -1,167 +1,173 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Properties;
 
 import junit.framework.TestCase;
 
 import org.hibernate.Hibernate;
 import org.hibernate.Session;
 import org.hibernate.TestingDatabaseInfo;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.cfg.ObjectNameNormalizer;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.H2Dialect;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.impl.SessionImpl;
 import org.hibernate.jdbc.Work;
 import org.hibernate.mapping.SimpleAuxiliaryDatabaseObject;
+import org.hibernate.test.common.ServiceRegistryHolder;
 
 /**
  * I went back to 3.3 source and grabbed the code/logic as it existed back then and crafted this
  * unit test so that we can make sure the value keep being generated in the expected manner
  *
  * @author Steve Ebersole
  */
 @SuppressWarnings({ "deprecation" })
 public class SequenceHiLoGeneratorTest extends TestCase {
 	private static final String TEST_SEQUENCE = "test_sequence";
 
 	private Configuration cfg;
+	private ServiceRegistryHolder serviceRegistryHolder;
 	private SessionFactoryImplementor sessionFactory;
 	private SequenceHiLoGenerator generator;
 
 	@Override
 	protected void setUp() throws Exception {
 		super.setUp();
 
 		Properties properties = new Properties();
 		properties.setProperty( SequenceGenerator.SEQUENCE, TEST_SEQUENCE );
 		properties.setProperty( SequenceHiLoGenerator.MAX_LO, "3" );
 		properties.put(
 				PersistentIdentifierGenerator.IDENTIFIER_NORMALIZER,
 				new ObjectNameNormalizer() {
 					@Override
 					protected boolean isUseQuotedIdentifiersGlobally() {
 						return false;
 					}
 
 					@Override
 					protected NamingStrategy getNamingStrategy() {
 						return cfg.getNamingStrategy();
 					}
 				}
 		);
 
 		Dialect dialect = new H2Dialect();
 
 		generator = new SequenceHiLoGenerator();
 		generator.configure( Hibernate.LONG, properties, dialect );
 
 		cfg = TestingDatabaseInfo.buildBaseConfiguration()
 				.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
 		cfg.addAuxiliaryDatabaseObject(
 				new SimpleAuxiliaryDatabaseObject(
 						generator.sqlCreateStrings( dialect )[0],
 						generator.sqlDropStrings( dialect )[0]
 				)
 		);
+		serviceRegistryHolder = new ServiceRegistryHolder( cfg.getProperties() );
 
-		sessionFactory = (SessionFactoryImplementor) cfg.buildSessionFactory();
+		sessionFactory =
+				(SessionFactoryImplementor) cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 	}
 
 	@Override
 	protected void tearDown() throws Exception {
 		if ( sessionFactory != null ) {
 			sessionFactory.close();
 		}
-
+		if ( serviceRegistryHolder != null ) {
+			serviceRegistryHolder.destroy();
+		}
 		super.tearDown();
 	}
 
 	public void testHiLoAlgorithm() {
 		SessionImpl session = (SessionImpl) sessionFactory.openSession();
 		session.beginTransaction();
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// initially sequence should be uninitialized
 		assertEquals( 0L, extractSequenceValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// historically the hilo generators skipped the initial block of values;
 		// 		so the first generated id value is maxlo + 1, here be 4
 		Long generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 4L, generatedValue.longValue() );
 		// which should also perform the first read on the sequence which should set it to its "start with" value (1)
 		assertEquals( 1L, extractSequenceValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 5L, generatedValue.longValue() );
 		assertEquals( 1L, extractSequenceValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 6L, generatedValue.longValue() );
 		assertEquals( 1L, extractSequenceValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 7L, generatedValue.longValue() );
 		// unlike the newer strategies, the db value will not get update here.  It gets updated on the next invocation
 		// 	after a clock over
 		assertEquals( 1L, extractSequenceValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 8L, generatedValue.longValue() );
 		// this should force an increment in the sequence value
 		assertEquals( 2L, extractSequenceValue( session ) );
 
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	private long extractSequenceValue(Session session) {
 		class WorkImpl implements Work {
 			private long value;
 			public void execute(Connection connection) throws SQLException {
 				PreparedStatement query = connection.prepareStatement( "select currval('" + TEST_SEQUENCE + "');" );
 				ResultSet resultSet = query.executeQuery();
 				resultSet.next();
 				value = resultSet.getLong( 1 );
 			}
 		}
 		WorkImpl work = new WorkImpl();
 		session.doWork( work );
 		return work.value;
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/id/TableHiLoGeneratorTest.java b/hibernate-core/src/test/java/org/hibernate/id/TableHiLoGeneratorTest.java
index 7a18842231..64c79612e0 100644
--- a/hibernate-core/src/test/java/org/hibernate/id/TableHiLoGeneratorTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/id/TableHiLoGeneratorTest.java
@@ -1,170 +1,177 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Properties;
 
 import junit.framework.TestCase;
 
 import org.hibernate.Hibernate;
 import org.hibernate.Session;
 import org.hibernate.TestingDatabaseInfo;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.cfg.ObjectNameNormalizer;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.H2Dialect;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.impl.SessionImpl;
 import org.hibernate.jdbc.Work;
 import org.hibernate.mapping.SimpleAuxiliaryDatabaseObject;
+import org.hibernate.test.common.ServiceRegistryHolder;
 
 /**
  * I went back to 3.3 source and grabbed the code/logic as it existed back then and crafted this
  * unit test so that we can make sure the value keep being generated in the expected manner
  *
  * @author Steve Ebersole
  */
 @SuppressWarnings({ "deprecation" })
 public class TableHiLoGeneratorTest extends TestCase {
 	private static final String GEN_TABLE = "generator_table";
 	private static final String GEN_COLUMN = TableHiLoGenerator.DEFAULT_COLUMN_NAME;
 
 	private Configuration cfg;
+	private ServiceRegistryHolder serviceRegistryHolder;
 	private SessionFactoryImplementor sessionFactory;
 	private TableHiLoGenerator generator;
 
 	@Override
 	protected void setUp() throws Exception {
 		super.setUp();
 
 		Properties properties = new Properties();
 		properties.setProperty( TableHiLoGenerator.TABLE, GEN_TABLE );
 		properties.setProperty( TableHiLoGenerator.COLUMN, GEN_COLUMN );
 		properties.setProperty( TableHiLoGenerator.MAX_LO, "3" );
 		properties.put(
 				PersistentIdentifierGenerator.IDENTIFIER_NORMALIZER,
 				new ObjectNameNormalizer() {
 					@Override
 					protected boolean isUseQuotedIdentifiersGlobally() {
 						return false;
 					}
 
 					@Override
 					protected NamingStrategy getNamingStrategy() {
 						return cfg.getNamingStrategy();
 					}
 				}
 		);
 
 		Dialect dialect = new H2Dialect();
 
 		generator = new TableHiLoGenerator();
 		generator.configure( Hibernate.LONG, properties, dialect );
 
 		cfg = TestingDatabaseInfo.buildBaseConfiguration()
 				.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
 		cfg.addAuxiliaryDatabaseObject(
 				new SimpleAuxiliaryDatabaseObject(
 						generator.sqlCreateStrings( dialect )[0],
 						generator.sqlDropStrings( dialect )[0]
 				)
 		);
 
 		cfg.addAuxiliaryDatabaseObject(
 				new SimpleAuxiliaryDatabaseObject(
 						generator.sqlCreateStrings( dialect )[1],
 						null
 				)
 		);
 
-		sessionFactory = (SessionFactoryImplementor) cfg.buildSessionFactory();
+		serviceRegistryHolder = new ServiceRegistryHolder( cfg.getProperties() );
+		sessionFactory =
+				(SessionFactoryImplementor) cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 	}
 
 	@Override
 	protected void tearDown() throws Exception {
 		if ( sessionFactory != null ) {
 			sessionFactory.close();
 		}
+		if ( serviceRegistryHolder != null ) {
+			serviceRegistryHolder.destroy();
+		}
 
 		super.tearDown();
 	}
 
 	public void testHiLoAlgorithm() {
 		SessionImpl session = (SessionImpl) sessionFactory.openSession();
 		session.beginTransaction();
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// initially sequence should be uninitialized
 		assertEquals( 0L, extractInDatabaseValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		Long generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 1L, generatedValue.longValue() );
 		assertEquals( 1L, extractInDatabaseValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 2L, generatedValue.longValue() );
 		assertEquals( 1L, extractInDatabaseValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 3L, generatedValue.longValue() );
 		assertEquals( 1L, extractInDatabaseValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 4L, generatedValue.longValue() );
 		assertEquals( 2L, extractInDatabaseValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 5L, generatedValue.longValue() );
 		assertEquals( 2L, extractInDatabaseValue( session ) );
 
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	private long extractInDatabaseValue(Session session) {
 		class WorkImpl implements Work {
 			private long value;
 			public void execute(Connection connection) throws SQLException {
 				PreparedStatement query = connection.prepareStatement( "select " + GEN_COLUMN + " from " + GEN_TABLE );
 				ResultSet resultSet = query.executeQuery();
 				resultSet.next();
 				value = resultSet.getLong( 1 );
 			}
 		}
 		WorkImpl work = new WorkImpl();
 		session.doWork( work );
 		return work.value;
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/test/java/org/hibernate/subclassProxyInterface/SubclassProxyInterfaceTest.java b/hibernate-core/src/test/java/org/hibernate/subclassProxyInterface/SubclassProxyInterfaceTest.java
index fa0af592a6..df79682885 100644
--- a/hibernate-core/src/test/java/org/hibernate/subclassProxyInterface/SubclassProxyInterfaceTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/subclassProxyInterface/SubclassProxyInterfaceTest.java
@@ -1,44 +1,47 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.subclassProxyInterface;
 
 import junit.framework.TestCase;
 
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.H2Dialect;
+import org.hibernate.test.common.ServiceRegistryHolder;
 
 /**
  * TODO : javadoc
  *
  * @author Steve Ebersole
  */
 public class SubclassProxyInterfaceTest extends TestCase {
 	public void testSubclassProxyInterfaces() {
         final Configuration cfg = new Configuration()
 				.setProperty( Environment.DIALECT, H2Dialect.class.getName() );
 		cfg.addClass( Person.class );
-		cfg.buildSessionFactory().close();
+		ServiceRegistryHolder serviceRegistryHolder = new ServiceRegistryHolder( cfg.getProperties() );
+		cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() ).close();
+		serviceRegistryHolder.destroy();
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/ConfigurationTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/ConfigurationTest.java
index 2b10a83ad1..f836ef7660 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/ConfigurationTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/ConfigurationTest.java
@@ -1,144 +1,157 @@
 //$Id$
 package org.hibernate.test.annotations;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.Query;
 import org.hibernate.Session;
 import org.hibernate.SessionFactory;
 import org.hibernate.Transaction;
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
+import org.hibernate.test.common.ServiceRegistryHolder;
 
 /**
  * @author Emmanuel Bernard
  */
 public class ConfigurationTest extends junit.framework.TestCase {
+	private ServiceRegistryHolder serviceRegistryHolder;
+
+	protected void setUp() {
+		serviceRegistryHolder = new ServiceRegistryHolder( Environment.getProperties() );
+	}
+
+	protected void tearDown() {
+		if ( serviceRegistryHolder != null ) {
+			serviceRegistryHolder.destroy();
+		}
+	}
+
 	public void testDeclarativeMix() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		cfg.configure( "org/hibernate/test/annotations/hibernate.cfg.xml" );
 		cfg.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
-		SessionFactory sf = cfg.buildSessionFactory();
+		SessionFactory sf = cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 		assertNotNull( sf );
 		Session s = sf.openSession();
 		Transaction tx = s.beginTransaction();
 		Query q = s.createQuery( "from Boat" );
 		assertEquals( 0, q.list().size() );
 		q = s.createQuery( "from Plane" );
 		assertEquals( 0, q.list().size() );
 		tx.commit();
 		s.close();
 		sf.close();
 	}
 
 	public void testIgnoringHbm() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		cfg.configure( "org/hibernate/test/annotations/hibernate.cfg.xml" );
 		cfg.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
 		cfg.setProperty( AnnotationConfiguration.ARTEFACT_PROCESSING_ORDER, "class" );
-		SessionFactory sf = cfg.buildSessionFactory();
+		SessionFactory sf = cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 		assertNotNull( sf );
 		Session s = sf.openSession();
 		Transaction tx = s.beginTransaction();
 		Query q;
 		try {
 			s.createQuery( "from Boat" ).list();
 			fail( "Boat should not be mapped" );
 		}
 		catch (HibernateException e) {
 			//all good
 		}
 		q = s.createQuery( "from Plane" );
 		assertEquals( 0, q.list().size() );
 		tx.commit();
 		s.close();
 		sf.close();
 	}
 
 	public void testPrecedenceHbm() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		cfg.configure( "org/hibernate/test/annotations/hibernate.cfg.xml" );
 		cfg.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
 		cfg.addAnnotatedClass( Boat.class );
-		SessionFactory sf = cfg.buildSessionFactory();
+		SessionFactory sf = cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 		assertNotNull( sf );
 		Session s = sf.openSession();
 		s.getTransaction().begin();
 		Boat boat = new Boat();
 		boat.setSize( 12 );
 		boat.setWeight( 34 );
 		s.persist( boat );
 		s.getTransaction().commit();
 		s.clear();
 		Transaction tx = s.beginTransaction();
 		boat = (Boat) s.get( Boat.class, boat.getId() );
 		assertTrue( "Annotation has precedence", 34 != boat.getWeight() );
 		s.delete( boat );
 		//s.getTransaction().commit();
 		tx.commit();
 		s.close();
 		sf.close();
 	}
 
 	public void testPrecedenceAnnotation() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		cfg.configure( "org/hibernate/test/annotations/hibernate.cfg.xml" );
 		cfg.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
 		cfg.setProperty( AnnotationConfiguration.ARTEFACT_PROCESSING_ORDER, "class, hbm" );
 		cfg.addAnnotatedClass( Boat.class );
-		SessionFactory sf = cfg.buildSessionFactory();
+		SessionFactory sf = cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 		assertNotNull( sf );
 		Session s = sf.openSession();
 		s.getTransaction().begin();
 		Boat boat = new Boat();
 		boat.setSize( 12 );
 		boat.setWeight( 34 );
 		s.persist( boat );
 		s.getTransaction().commit();
 		s.clear();
 		Transaction tx = s.beginTransaction();
 		boat = (Boat) s.get( Boat.class, boat.getId() );
 		assertTrue( "Annotation has precedence", 34 == boat.getWeight() );
 		s.delete( boat );
 		tx.commit();
 		s.close();
 		sf.close();
 	}
 
 	public void testHbmWithSubclassExtends() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		cfg.configure( "org/hibernate/test/annotations/hibernate.cfg.xml" );
 		cfg.addClass( Ferry.class );
 		cfg.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
-		SessionFactory sf = cfg.buildSessionFactory();
+		SessionFactory sf = cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 		assertNotNull( sf );
 		Session s = sf.openSession();
 		Transaction tx = s.beginTransaction();
 		Query q = s.createQuery( "from Ferry" );
 		assertEquals( 0, q.list().size() );
 		q = s.createQuery( "from Plane" );
 		assertEquals( 0, q.list().size() );
 		tx.commit();
 		s.close();
 		sf.close();
 	}
 
 	public void testAnnReferencesHbm() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		cfg.configure( "org/hibernate/test/annotations/hibernate.cfg.xml" );
 		cfg.addAnnotatedClass( Port.class );
 		cfg.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
-		SessionFactory sf = cfg.buildSessionFactory();
+		SessionFactory sf = cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 		assertNotNull( sf );
 		Session s = sf.openSession();
 		Transaction tx = s.beginTransaction();
 		Query q = s.createQuery( "from Boat" );
 		assertEquals( 0, q.list().size() );
 		q = s.createQuery( "from Port" );
 		assertEquals( 0, q.list().size() );
 		tx.commit();
 		s.close();
 		sf.close();
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/SafeMappingTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/SafeMappingTest.java
index c691fc0f90..45ada004b1 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/SafeMappingTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/SafeMappingTest.java
@@ -1,25 +1,33 @@
 //$Id$
 package org.hibernate.test.annotations;
 
 import org.hibernate.AnnotationException;
 import org.hibernate.SessionFactory;
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.cfg.Environment;
+import org.hibernate.test.common.ServiceRegistryHolder;
 
 /**
  * @author Emmanuel Bernard
  */
 public class SafeMappingTest extends junit.framework.TestCase {
 	public void testDeclarativeMix() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		cfg.addAnnotatedClass( IncorrectEntity.class );
 		cfg.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
+		ServiceRegistryHolder serviceRegistryHolder = null;
 		try {
-			SessionFactory sf = cfg.buildSessionFactory();
+			serviceRegistryHolder = new ServiceRegistryHolder( cfg.getProperties() );
+			SessionFactory sf = cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 			fail( "Entity wo id should fail" );
 		}
 		catch (AnnotationException e) {
 			//success
 		}
+		finally {
+			if ( serviceRegistryHolder != null ) {
+				serviceRegistryHolder.destroy();
+			}
+		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/SecuredBindingTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/SecuredBindingTest.java
index f45537f4bf..88b071dac9 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/SecuredBindingTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/SecuredBindingTest.java
@@ -1,44 +1,52 @@
 //$Id$
 package org.hibernate.test.annotations;
 
 import java.util.Properties;
 
 import junit.framework.TestCase;
 import org.hibernate.HibernateException;
 import org.hibernate.SessionFactory;
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.cfg.Environment;
+import org.hibernate.test.common.ServiceRegistryHolder;
 
 /**
  * @author Emmanuel Bernard
  */
 public class SecuredBindingTest extends TestCase {
 
 	public SecuredBindingTest(String x) {
 		super( x );
 	}
 
 	public void testConfigurationMethods() throws Exception {
 		AnnotationConfiguration ac = new AnnotationConfiguration();
 		Properties p = new Properties();
 		p.put( Environment.DIALECT, "org.hibernate.dialect.HSQLDialect" );
 		p.put( "hibernate.connection.driver_class", "org.hsqldb.jdbcDrive" );
 		p.put( "hibernate.connection.url", "jdbc:hsqldb:." );
 		p.put( "hibernate.connection.username", "sa" );
 		p.put( "hibernate.connection.password", "" );
 		p.put( "hibernate.show_sql", "true" );
 		ac.setProperties( p );
 		ac.addAnnotatedClass( Plane.class );
 		SessionFactory sf;
+		ServiceRegistryHolder serviceRegistryHolder = null;
 		try {
-			sf = ac.buildSessionFactory();
+			serviceRegistryHolder = new ServiceRegistryHolder( p );
+			sf = ac.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 			fail( "Driver property overriding should work" );
 			sf.close();
 		}
 		catch (HibernateException he) {
 			//success
 		}
+		finally {
+			if ( serviceRegistryHolder != null ) {
+				serviceRegistryHolder.destroy();
+			}
+		}
 
 	}
 }
 
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/TestCase.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/TestCase.java
index f36b80fdca..72c38f9983 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/TestCase.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/TestCase.java
@@ -1,150 +1,152 @@
 //$Id$
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations;
 
 import java.io.InputStream;
 
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.Session;
 import org.hibernate.SessionFactory;
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.SessionFactoryImplementor;
+import org.hibernate.test.common.ServiceRegistryHolder;
 import org.hibernate.testing.junit.functional.annotations.HibernateTestCase;
 
 /**
  * A base class for all annotation tests.
  *
  * @author Emmnauel Bernand
  * @author Hardy Ferentschik
  */
 public abstract class TestCase extends HibernateTestCase {
 
 	protected static SessionFactory sessions;
 	private Session session;
 
 	public TestCase() {
 		super();
 	}
 
 	public TestCase(String name) {
 		super( name );
 	}
 
 	public Session openSession() throws HibernateException {
 		session = getSessions().openSession();
 		return session;
 	}
 
 	public Session openSession(Interceptor interceptor) throws HibernateException {
 		session = getSessions().openSession( interceptor );
 		return session;
 	}
 
 	protected SessionFactory getSessions() {
 		if ( sessions == null ) {
 			try {
 				buildConfiguration();
 			}
 			catch ( Exception e ) {
 				throw new HibernateException( e );
 			}
 		}
 		return sessions;
 	}
 
 	protected SessionFactoryImplementor sfi() {
 		return (SessionFactoryImplementor) getSessions();
 	}
 
 	@Override	
 	protected void buildConfiguration() throws Exception {
 		if ( sessions != null ) {
 			sessions.close();
 		}
 		try {
 			setCfg( new AnnotationConfiguration() );
 			// by default use the new id generator scheme...
 			cfg.setProperty( AnnotationConfiguration.USE_NEW_ID_GENERATOR_MAPPINGS, "true" );
 			configure( cfg );
 			if ( recreateSchema() ) {
 				cfg.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
 			}
 			for ( String aPackage : getAnnotatedPackages() ) {
 				( ( AnnotationConfiguration ) getCfg() ).addPackage( aPackage );
 			}
 			for ( Class<?> aClass : getAnnotatedClasses() ) {
 				( ( AnnotationConfiguration ) getCfg() ).addAnnotatedClass( aClass );
 			}
 			for ( String xmlFile : getXmlFiles() ) {
 				InputStream is = Thread.currentThread().getContextClassLoader().getResourceAsStream( xmlFile );
 				getCfg().addInputStream( is );
 			}
-			sessions = getCfg().buildSessionFactory();
+			sessions = getCfg().buildSessionFactory( getServiceRegistry() );
 		}
 		catch ( Exception e ) {
 			e.printStackTrace();
 			throw e;
 		}
 	}
 
 	@Override
 	protected void handleUnclosedResources() {
 		if ( session != null && session.isOpen() ) {
 			if ( session.isConnected() ) {
 				session.doWork( new RollbackWork() );
 			}
 			session.close();
 			session = null;
 			fail( "unclosed session" );
 		}
 		else {
 			session = null;
 		}
 	}
 
 	@Override
 	protected void closeResources() {
 		try {
 			if ( session != null && session.isOpen() ) {
 				if ( session.isConnected() ) {
 					session.doWork( new RollbackWork() );
 				}
 				session.close();
 			}
 		}
 		catch ( Exception ignore ) {
 		}
 		try {
 			if ( sessions != null ) {
 				sessions.close();
 				sessions = null;
 			}
 		}
 		catch ( Exception ignore ) {
 		}
+		super.closeResources();
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/access/jpa/AccessMappingTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/access/jpa/AccessMappingTest.java
index 9a8807274b..d26c4f37da 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/access/jpa/AccessMappingTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/access/jpa/AccessMappingTest.java
@@ -1,205 +1,219 @@
 //$Id$
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations.access.jpa;
 
 import junit.framework.TestCase;
 
 import org.hibernate.EntityMode;
 import org.hibernate.MappingException;
 import org.hibernate.cfg.AnnotationConfiguration;
+import org.hibernate.cfg.Environment;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.property.BasicPropertyAccessor;
 import org.hibernate.property.DirectPropertyAccessor;
+import org.hibernate.test.common.ServiceRegistryHolder;
 import org.hibernate.tuple.entity.EntityMetamodel;
 import org.hibernate.tuple.entity.PojoEntityTuplizer;
 
 
 /**
  * Tests verifying the correct behaviour for the usage of {@code @javax.persistence.Access}.
  *
  * @author Hardy Ferentschik
  */
 public class AccessMappingTest extends TestCase {
 
+	private ServiceRegistryHolder serviceRegistryHolder;
+
+	protected void setUp() {
+		serviceRegistryHolder = new ServiceRegistryHolder( Environment.getProperties() );
+	}
+
+	protected void tearDown() {
+		if ( serviceRegistryHolder != null ) {
+			serviceRegistryHolder.destroy();
+		}
+	}
+
 	public void testInconsistentAnnotationPlacement() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		cfg.addAnnotatedClass( Course1.class );
 		cfg.addAnnotatedClass( Student.class );
 		try {
-			cfg.buildSessionFactory();
+			cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 			fail( "@Id and @OneToMany are not placed consistently in test entities. SessionFactory creation should fail." );
 		}
 		catch ( MappingException e ) {
 			// success
 		}
 	}
 
 	public void testFieldAnnotationPlacement() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		Class<?> classUnderTest = Course6.class;
 		cfg.addAnnotatedClass( classUnderTest );
 		cfg.addAnnotatedClass( Student.class );
-		SessionFactoryImplementor factory = ( SessionFactoryImplementor ) cfg.buildSessionFactory();
+		SessionFactoryImplementor factory = ( SessionFactoryImplementor ) cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 		EntityMetamodel metaModel = factory.getEntityPersister( classUnderTest.getName() )
 				.getEntityMetamodel();
 		PojoEntityTuplizer tuplizer = ( PojoEntityTuplizer ) metaModel.getTuplizer( EntityMode.POJO );
 		assertTrue(
 				"Field access should be used.",
 				tuplizer.getIdentifierGetter() instanceof DirectPropertyAccessor.DirectGetter
 		);
 	}
 
 	public void testPropertyAnnotationPlacement() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		Class<?> classUnderTest = Course7.class;
 		cfg.addAnnotatedClass( classUnderTest );
 		cfg.addAnnotatedClass( Student.class );
-		SessionFactoryImplementor factory = ( SessionFactoryImplementor ) cfg.buildSessionFactory();
+		SessionFactoryImplementor factory = ( SessionFactoryImplementor ) cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 		EntityMetamodel metaModel = factory.getEntityPersister( classUnderTest.getName() )
 				.getEntityMetamodel();
 		PojoEntityTuplizer tuplizer = ( PojoEntityTuplizer ) metaModel.getTuplizer( EntityMode.POJO );
 		assertTrue(
 				"Property access should be used.",
 				tuplizer.getIdentifierGetter() instanceof BasicPropertyAccessor.BasicGetter
 		);
 	}
 
 	public void testExplicitPropertyAccessAnnotationsOnProperty() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		Class<?> classUnderTest = Course2.class;
 		cfg.addAnnotatedClass( classUnderTest );
 		cfg.addAnnotatedClass( Student.class );
-		SessionFactoryImplementor factory = ( SessionFactoryImplementor ) cfg.buildSessionFactory();
+		SessionFactoryImplementor factory = ( SessionFactoryImplementor ) cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 		EntityMetamodel metaModel = factory.getEntityPersister( classUnderTest.getName() )
 				.getEntityMetamodel();
 		PojoEntityTuplizer tuplizer = ( PojoEntityTuplizer ) metaModel.getTuplizer( EntityMode.POJO );
 		assertTrue(
 				"Property access should be used.",
 				tuplizer.getIdentifierGetter() instanceof BasicPropertyAccessor.BasicGetter
 		);
 	}
 
 	public void testExplicitPropertyAccessAnnotationsOnField() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		cfg.addAnnotatedClass( Course4.class );
 		cfg.addAnnotatedClass( Student.class );
 		try {
-			cfg.buildSessionFactory();
+			cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 			fail( "@Id and @OneToMany are not placed consistently in test entities. SessionFactory creation should fail." );
 		}
 		catch ( MappingException e ) {
 			// success
 		}
 	}
 
 	public void testExplicitPropertyAccessAnnotationsWithHibernateStyleOverride() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		Class<?> classUnderTest = Course3.class;
 		cfg.addAnnotatedClass( classUnderTest );
 		cfg.addAnnotatedClass( Student.class );
-		SessionFactoryImplementor factory = ( SessionFactoryImplementor ) cfg.buildSessionFactory();
+		SessionFactoryImplementor factory = ( SessionFactoryImplementor ) cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 		EntityMetamodel metaModel = factory.getEntityPersister( classUnderTest.getName() )
 				.getEntityMetamodel();
 		PojoEntityTuplizer tuplizer = ( PojoEntityTuplizer ) metaModel.getTuplizer( EntityMode.POJO );
 		assertTrue(
 				"Field access should be used.",
 				tuplizer.getIdentifierGetter() instanceof DirectPropertyAccessor.DirectGetter
 		);
 
 		assertTrue(
 				"Property access should be used.",
 				tuplizer.getGetter( 0 ) instanceof BasicPropertyAccessor.BasicGetter
 		);
 	}
 
 	public void testExplicitPropertyAccessAnnotationsWithJpaStyleOverride() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		Class<?> classUnderTest = Course5.class;
 		cfg.addAnnotatedClass( classUnderTest );
 		cfg.addAnnotatedClass( Student.class );
-		SessionFactoryImplementor factory = ( SessionFactoryImplementor ) cfg.buildSessionFactory();
+		SessionFactoryImplementor factory = ( SessionFactoryImplementor ) cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 		EntityMetamodel metaModel = factory.getEntityPersister( classUnderTest.getName() )
 				.getEntityMetamodel();
 		PojoEntityTuplizer tuplizer = ( PojoEntityTuplizer ) metaModel.getTuplizer( EntityMode.POJO );
 		assertTrue(
 				"Field access should be used.",
 				tuplizer.getIdentifierGetter() instanceof DirectPropertyAccessor.DirectGetter
 		);
 
 		assertTrue(
 				"Property access should be used.",
 				tuplizer.getGetter( 0 ) instanceof BasicPropertyAccessor.BasicGetter
 		);
 	}
 
 	public void testDefaultFieldAccessIsInherited() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		Class<?> classUnderTest = User.class;
 		cfg.addAnnotatedClass( classUnderTest );
 		cfg.addAnnotatedClass( Person.class );
 		cfg.addAnnotatedClass( Being.class );
-		SessionFactoryImplementor factory = ( SessionFactoryImplementor ) cfg.buildSessionFactory();
+		SessionFactoryImplementor factory = ( SessionFactoryImplementor ) cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 		EntityMetamodel metaModel = factory.getEntityPersister( classUnderTest.getName() )
 				.getEntityMetamodel();
 		PojoEntityTuplizer tuplizer = ( PojoEntityTuplizer ) metaModel.getTuplizer( EntityMode.POJO );
 		assertTrue(
 				"Field access should be used since the default access mode gets inherited",
 				tuplizer.getIdentifierGetter() instanceof DirectPropertyAccessor.DirectGetter
 		);
 	}
 
 	public void testDefaultPropertyAccessIsInherited() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		cfg.addAnnotatedClass( Horse.class );
 		cfg.addAnnotatedClass( Animal.class );
 
-		SessionFactoryImplementor factory = ( SessionFactoryImplementor ) cfg.buildSessionFactory();
+		SessionFactoryImplementor factory = ( SessionFactoryImplementor ) cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 		EntityMetamodel metaModel = factory.getEntityPersister( Animal.class.getName() )
 				.getEntityMetamodel();
 		PojoEntityTuplizer tuplizer = ( PojoEntityTuplizer ) metaModel.getTuplizer( EntityMode.POJO );
 		assertTrue(
 				"Property access should be used since explicity configured via @Access",
 				tuplizer.getIdentifierGetter() instanceof BasicPropertyAccessor.BasicGetter
 		);
 
 		metaModel = factory.getEntityPersister( Horse.class.getName() )
 				.getEntityMetamodel();
 		tuplizer = ( PojoEntityTuplizer ) metaModel.getTuplizer( EntityMode.POJO );
 		assertTrue(
 				"Property access should be used since the default access mode gets inherited",
 				tuplizer.getGetter( 0 ) instanceof BasicPropertyAccessor.BasicGetter
 		);
 	}
 
 	/**
 	 * HHH-5004
 	 */
 	public void testAccessOnClassAndId() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		cfg.addAnnotatedClass( Course8.class );
 		cfg.addAnnotatedClass( Student.class );
-		cfg.buildSessionFactory();
+		cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/access/xml/XmlAccessTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/access/xml/XmlAccessTest.java
index 2dfaa5522c..b36f503a52 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/access/xml/XmlAccessTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/access/xml/XmlAccessTest.java
@@ -1,195 +1,209 @@
 //$Id$
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations.access.xml;
 
 import java.io.InputStream;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
 import javax.persistence.AccessType;
 
 import junit.framework.TestCase;
 
 import org.hibernate.EntityMode;
 import org.hibernate.cfg.AnnotationConfiguration;
+import org.hibernate.cfg.Environment;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.property.BasicPropertyAccessor;
 import org.hibernate.property.DirectPropertyAccessor;
+import org.hibernate.test.common.ServiceRegistryHolder;
 import org.hibernate.tuple.entity.EntityMetamodel;
 import org.hibernate.tuple.entity.PojoEntityTuplizer;
 
 
 /**
  * Test verifying that it is possible to configure the access type via xml configuration.
  *
  * @author Hardy Ferentschik
  */
 public class XmlAccessTest extends TestCase {
 
+	private ServiceRegistryHolder serviceRegistryHolder;
+
+	protected void setUp() {
+		serviceRegistryHolder = new ServiceRegistryHolder( Environment.getProperties() );
+	}
+
+	protected void tearDown() {
+		if ( serviceRegistryHolder != null ) {
+			serviceRegistryHolder.destroy();
+		}
+	}
+
 	public void testAccessOnBasicXmlElement() throws Exception {
 		Class<?> classUnderTest = Tourist.class;
 		List<Class<?>> classes = new ArrayList<Class<?>>();
 		classes.add( classUnderTest );
 		List<String> configFiles = Collections.emptyList();
 		SessionFactoryImplementor factory = buildSessionFactory( classes, configFiles );
 
 		// without any xml configuration we have field access
 		assertAccessType( factory, classUnderTest, AccessType.FIELD );
 
 		// now with an additional xml configuration file changing the default access type for Tourist using basic
 		configFiles = new ArrayList<String>();
 		configFiles.add( "org/hibernate/test/annotations/access/xml/Tourist.xml" );
 		factory = buildSessionFactory( classes, configFiles );
 		assertAccessType( factory, classUnderTest, AccessType.PROPERTY );
 	}
 
 	public void testAccessOnPersistenceUnitDefaultsXmlElement() throws Exception {
 		Class<?> classUnderTest = Tourist.class;
 		List<Class<?>> classes = new ArrayList<Class<?>>();
 		classes.add( classUnderTest );
 		List<String> configFiles = Collections.emptyList();
 		SessionFactoryImplementor factory = buildSessionFactory( classes, configFiles );
 
 		// without any xml configuration we have field access
 		assertAccessType( factory, classUnderTest, AccessType.FIELD );
 
 		// now with an additional xml configuration file changing the default access type for Tourist using persitence unit defaults
 		configFiles = new ArrayList<String>();
 		configFiles.add( "org/hibernate/test/annotations/access/xml/Tourist2.xml" );
 		factory = buildSessionFactory( classes, configFiles );
 		assertAccessType( factory, classUnderTest, AccessType.PROPERTY );
 	}
 
 	public void testAccessOnEntityMappingsXmlElement() throws Exception {
 		Class<?> classUnderTest = Tourist.class;
 		List<Class<?>> classes = new ArrayList<Class<?>>();
 		classes.add( classUnderTest );
 		List<String> configFiles = Collections.emptyList();
 		SessionFactoryImplementor factory = buildSessionFactory( classes, configFiles );
 
 		// without any xml configuration we have field access
 		assertAccessType( factory, classUnderTest, AccessType.FIELD );
 
 		// now with an additional xml configuration file changing the default access type for Tourist using default in entity-mappings
 		configFiles = new ArrayList<String>();
 		configFiles.add( "org/hibernate/test/annotations/access/xml/Tourist3.xml" );
 		factory = buildSessionFactory( classes, configFiles );
 		assertAccessType( factory, classUnderTest, AccessType.PROPERTY );
 	}
 
 	public void testAccessOnEntityXmlElement() throws Exception {
 		Class<?> classUnderTest = Tourist.class;
 		List<Class<?>> classes = new ArrayList<Class<?>>();
 		classes.add( classUnderTest );
 		List<String> configFiles = Collections.emptyList();
 		SessionFactoryImplementor factory = buildSessionFactory( classes, configFiles );
 
 		// without any xml configuration we have field access
 		assertAccessType( factory, classUnderTest, AccessType.FIELD );
 
 		// now with an additional xml configuration file changing the default access type for Tourist using entity level config
 		configFiles = new ArrayList<String>();
 		configFiles.add( "org/hibernate/test/annotations/access/xml/Tourist4.xml" );
 		factory = buildSessionFactory( classes, configFiles );
 		assertAccessType( factory, classUnderTest, AccessType.PROPERTY );
 	}
 
 	public void testAccessOnMappedSuperClassXmlElement() throws Exception {
 		Class<?> classUnderTest = Waiter.class;
 		List<Class<?>> classes = new ArrayList<Class<?>>();
 		classes.add( classUnderTest );
 		classes.add( Crew.class );
 		List<String> configFiles = new ArrayList<String>();
 		configFiles.add( "org/hibernate/test/annotations/access/xml/Crew.xml" );
 		SessionFactoryImplementor factory = buildSessionFactory( classes, configFiles );
 		assertAccessType( factory, classUnderTest, AccessType.FIELD );
 	}
 
 	public void testAccessOnAssociationXmlElement() throws Exception {
 		Class<?> classUnderTest = RentalCar.class;
 		List<Class<?>> classes = new ArrayList<Class<?>>();
 		classes.add( classUnderTest );
 		classes.add( Driver.class );
 		List<String> configFiles = new ArrayList<String>();
 		configFiles.add( "org/hibernate/test/annotations/access/xml/RentalCar.xml" );
 		SessionFactoryImplementor factory = buildSessionFactory( classes, configFiles );
 		assertAccessType( factory, classUnderTest, AccessType.PROPERTY );
 	}
 
 	public void testAccessOnEmbeddedXmlElement() throws Exception {
 		Class<?> classUnderTest = Cook.class;
 		List<Class<?>> classes = new ArrayList<Class<?>>();
 		classes.add( classUnderTest );
 		classes.add( Knive.class );
 		List<String> configFiles = new ArrayList<String>();
 		configFiles.add( "org/hibernate/test/annotations/access/xml/Cook.xml" );
 		SessionFactoryImplementor factory = buildSessionFactory( classes, configFiles );
 		assertAccessType( factory, classUnderTest, AccessType.PROPERTY );
 	}
 
 	public void testAccessOnElementCollectionXmlElement() throws Exception {
 		Class<?> classUnderTest = Boy.class;
 		List<Class<?>> classes = new ArrayList<Class<?>>();
 		classes.add( classUnderTest );
 		List<String> configFiles = new ArrayList<String>();
 		configFiles.add( "org/hibernate/test/annotations/access/xml/Boy.xml" );
 		SessionFactoryImplementor factory = buildSessionFactory( classes, configFiles );
 		assertAccessType( factory, classUnderTest, AccessType.PROPERTY );
 	}
 
 	private SessionFactoryImplementor buildSessionFactory(List<Class<?>> classesUnderTest, List<String> configFiles) {
 		assert classesUnderTest != null;
 		assert configFiles != null;
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		for ( Class<?> clazz : classesUnderTest ) {
 			cfg.addAnnotatedClass( clazz );
 		}
 		for ( String configFile : configFiles ) {
 			InputStream is = Thread.currentThread().getContextClassLoader().getResourceAsStream( configFile );
 			cfg.addInputStream( is );
 		}
-		return ( SessionFactoryImplementor ) cfg.buildSessionFactory();
+		return ( SessionFactoryImplementor ) cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 	}
 
 	// uses the first getter of the tupelizer for the assertions
 
 	private void assertAccessType(SessionFactoryImplementor factory, Class<?> classUnderTest, AccessType accessType) {
 		EntityMetamodel metaModel = factory.getEntityPersister( classUnderTest.getName() )
 				.getEntityMetamodel();
 		PojoEntityTuplizer tuplizer = ( PojoEntityTuplizer ) metaModel.getTuplizer( EntityMode.POJO );
 		if ( AccessType.FIELD.equals( accessType ) ) {
 			assertTrue(
 					"Field access was expected.",
 					tuplizer.getGetter( 0 ) instanceof DirectPropertyAccessor.DirectGetter
 			);
 		}
 		else {
 			assertTrue(
 					"Property access was expected.",
 					tuplizer.getGetter( 0 ) instanceof BasicPropertyAccessor.BasicGetter
 			);
 		}
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/backquotes/BackquoteTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/backquotes/BackquoteTest.java
index 9fd2fae88a..fbb81ff83a 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/backquotes/BackquoteTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/backquotes/BackquoteTest.java
@@ -1,66 +1,81 @@
 //$Id$
 package org.hibernate.test.annotations.backquotes;
 
 import java.io.PrintWriter;
 import java.io.StringWriter;
 
 import junit.framework.TestCase;
 
 import org.hibernate.MappingException;
 import org.hibernate.cfg.AnnotationConfiguration;
+import org.hibernate.cfg.Environment;
+import org.hibernate.test.common.ServiceRegistryHolder;
+
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
  * Testcase for ANN-718 - @JoinTable / @JoinColumn fail when using backquotes in PK field name.
  * 
  * @author Hardy Ferentschik
  *
  */
 public class BackquoteTest extends TestCase {
 		
 	private Logger log = LoggerFactory.getLogger(BackquoteTest.class);	
 	
+	private ServiceRegistryHolder serviceRegistryHolder;
+
+	protected void setUp() {
+		serviceRegistryHolder = new ServiceRegistryHolder( Environment.getProperties() );
+	}
+
+	protected void tearDown() {
+		if ( serviceRegistryHolder != null ) {
+			serviceRegistryHolder.destroy();
+		}
+	}
+
 	public void testBackquotes() {
 		try {
 			AnnotationConfiguration config = new AnnotationConfiguration();
 			config.addAnnotatedClass(Bug.class);
 			config.addAnnotatedClass(Category.class);
-			config.buildSessionFactory();
+			config.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 		}
 		catch( Exception e ) {
 			StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
 			log.debug(writer.toString());
 			fail(e.getMessage());
 		}
 	}
 	
 	/** 
 	 *  HHH-4647 : Problems with @JoinColumn referencedColumnName and quoted column and table names
 	 *  
 	 *  An invalid referencedColumnName to an entity having a quoted table name results in an 
 	 *  infinite loop in o.h.c.Configuration$MappingsImpl#getPhysicalColumnName(). 
 	 *  The same issue exists with getLogicalColumnName()
 	 */
 	public void testInvalidReferenceToQuotedTableName() {
     	try {
     		AnnotationConfiguration config = new AnnotationConfiguration();
     		config.addAnnotatedClass(Printer.class);
     		config.addAnnotatedClass(PrinterCable.class);
-    		config.buildSessionFactory();
+    		config.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
     		fail("expected MappingException to be thrown");
     	}
     	//we WANT MappingException to be thrown
         catch( MappingException e ) { 
         	assertTrue("MappingException was thrown", true); 
         }
         catch(Exception e) {
         	StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
 			log.debug(writer.toString());
         	fail(e.getMessage());
         }
 	}
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/duplicatedgenerator/DuplicateTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/duplicatedgenerator/DuplicateTest.java
index 2a219aeb77..926b17c592 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/duplicatedgenerator/DuplicateTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/duplicatedgenerator/DuplicateTest.java
@@ -1,28 +1,36 @@
 //$Id$
 package org.hibernate.test.annotations.duplicatedgenerator;
 
 import junit.framework.TestCase;
 import org.hibernate.AnnotationException;
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.cfg.Environment;
+import org.hibernate.test.common.ServiceRegistryHolder;
 
 /**
  * @author Emmanuel Bernard
  */
 public class DuplicateTest extends TestCase {
 	public void testDuplicateEntityName() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		cfg.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
+		ServiceRegistryHolder serviceRegistryHolder = null;
 		try {
 			cfg.addAnnotatedClass( Flight.class );
 			cfg.addAnnotatedClass( org.hibernate.test.annotations.Flight.class );
 			cfg.addResource( "org/hibernate/test/annotations/orm.xml" );
 			cfg.addResource( "org/hibernate/test/annotations/duplicatedgenerator/orm.xml" );
-			cfg.buildSessionFactory();
+			serviceRegistryHolder = new ServiceRegistryHolder( cfg.getProperties() );
+			cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 			fail( "Should not be able to map the same entity name twice" );
 		}
 		catch (AnnotationException ae) {
 			//success
 		}
+		finally {
+			if ( serviceRegistryHolder != null ) {
+				serviceRegistryHolder.destroy();
+			}
+		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/entity/BasicHibernateAnnotationsTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/entity/BasicHibernateAnnotationsTest.java
index 11e705e964..3492e4df3b 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/entity/BasicHibernateAnnotationsTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/entity/BasicHibernateAnnotationsTest.java
@@ -1,717 +1,717 @@
 //$Id$
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009, Red Hat, Inc. and/or its affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat, Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations.entity;
 
 import java.math.BigDecimal;
 import java.util.Currency;
 import java.util.Date;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Set;
 
 import org.hibernate.AnnotationException;
 import org.hibernate.Hibernate;
 import org.hibernate.HibernateException;
 import org.hibernate.Query;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.test.annotations.TestCase;
 
 /**
  * @author Emmanuel Bernard
  */
 public class BasicHibernateAnnotationsTest extends TestCase {
 
 	public void testEntity() throws Exception {
 		if( !getDialect().supportsExpectedLobUsagePattern() ){
 			return;
 		}
 		Forest forest = new Forest();
 		forest.setName( "Fontainebleau" );
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.persist( forest );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		forest = (Forest) s.get( Forest.class, forest.getId() );
 		assertNotNull( forest );
 		forest.setName( "Fontainebleau" );
 		//should not execute SQL update
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		forest = (Forest) s.get( Forest.class, forest.getId() );
 		assertNotNull( forest );
 		forest.setLength( 23 );
 		//should execute dynamic SQL update
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		s.delete( s.get( Forest.class, forest.getId() ) );
 		tx.commit();
 		s.close();
 	}
 
 	public void testVersioning() throws Exception {
 		if( !getDialect().supportsExpectedLobUsagePattern() ){
 			return;
 		}
 		Forest forest = new Forest();
 		forest.setName( "Fontainebleau" );
 		forest.setLength( 33 );
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.persist( forest );
 		tx.commit();
 		s.close();
 
 		Session parallelSession = openSession();
 		Transaction parallelTx = parallelSession.beginTransaction();
 		s = openSession();
 		tx = s.beginTransaction();
 
 		forest = (Forest) parallelSession.get( Forest.class, forest.getId() );
 		Forest reloadedForest = (Forest) s.get( Forest.class, forest.getId() );
 		reloadedForest.setLength( 11 );
 		assertNotSame( forest, reloadedForest );
 		tx.commit();
 		s.close();
 
 		forest.setLength( 22 );
 		try {
 			parallelTx.commit();
 			fail( "All optimistic locking should have make it fail" );
 		}
 		catch (HibernateException e) {
 			if ( parallelTx != null ) parallelTx.rollback();
 		}
 		finally {
 			parallelSession.close();
 		}
 
 		s = openSession();
 		tx = s.beginTransaction();
 		s.delete( s.get( Forest.class, forest.getId() ) );
 		tx.commit();
 		s.close();
 
 	}
 
 	public void testPolymorphism() throws Exception {
 		if( !getDialect().supportsExpectedLobUsagePattern() ){
 			return;
 		}
 		Forest forest = new Forest();
 		forest.setName( "Fontainebleau" );
 		forest.setLength( 33 );
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.persist( forest );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		Query query = s.createQuery( "from java.lang.Object" );
 		assertEquals( 0, query.list().size() );
 		query = s.createQuery( "from Forest" );
 		assertTrue( 0 < query.list().size() );
 		tx.commit();
 		s.close();
 	}
 
 	public void testType() throws Exception {
 		if( !getDialect().supportsExpectedLobUsagePattern() ){
 			return;
 		}
 		Forest f = new Forest();
 		f.setName( "Broceliande" );
 		String description = "C'est une enorme foret enchantee ou vivais Merlin et toute la clique";
 		f.setLongDescription( description );
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.persist( f );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		f = (Forest) s.get( Forest.class, f.getId() );
 		assertNotNull( f );
 		assertEquals( description, f.getLongDescription() );
 		s.delete( f );
 		tx.commit();
 		s.close();
 
 	}
 
 	/*
 	 * Test import of TypeDefs from MappedSuperclass and 
 	 * Embedded classes.
 	 * The classes 'Name' and 'FormalLastName' both embed the same 
 	 * component 'LastName'. This is to verify that processing the 
 	 * typedef defined in the component TWICE does not create any 
 	 * issues.  
 	 * 
 	 */
 	public void testImportTypeDefinitions() throws Exception {
 		LastName lastName = new LastName();
 		lastName.setName("reddy");
 				
 		Name name = new Name();
 		name.setFirstName("SHARATH");
 		name.setLastName(lastName);
 		
 		FormalLastName formalName = new FormalLastName();
 		formalName.setLastName(lastName);
 		formalName.setDesignation("Mr");
 				
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.persist(name);
 		s.persist(formalName);
 		tx.commit();
 		s.close();
 		 
 		s = openSession();
 		tx = s.beginTransaction();
 		name = (Name) s.get( Name.class, name.getId() );
 		assertNotNull( name );
 		assertEquals( "sharath", name.getFirstName() );
 		assertEquals( "REDDY", name.getLastName().getName() );
 		
 		formalName = (FormalLastName) s.get(FormalLastName.class, formalName.getId());
 		assertEquals( "REDDY", formalName.getLastName().getName() );
 		
 		s.delete(name);
 		s.delete(formalName);
 		tx.commit();
 		s.close();
 	}
 
 	public void testNonLazy() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Forest f = new Forest();
 		Tree t = new Tree();
 		t.setName( "Basic one" );
 		s.persist( f );
 		s.persist( t );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		f = (Forest) s.load( Forest.class, f.getId() );
 		t = (Tree) s.load( Tree.class, t.getId() );
 		assertFalse( "Default should be lazy", Hibernate.isInitialized( f ) );
 		assertTrue( "Tree is not lazy", Hibernate.isInitialized( t ) );
 		tx.commit();
 		s.close();
 	}
 
 	public void testCache() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		ZipCode zc = new ZipCode();
 		zc.code = "92400";
 		s.persist( zc );
 		tx.commit();
 		s.close();
 		getSessions().getStatistics().clear();
 		getSessions().getStatistics().setStatisticsEnabled( true );
 		getSessions().evict( ZipCode.class );
 		s = openSession();
 		tx = s.beginTransaction();
 		s.get( ZipCode.class, zc.code );
 		assertEquals( 1, getSessions().getStatistics().getSecondLevelCachePutCount() );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		s.get( ZipCode.class, zc.code );
 		assertEquals( 1, getSessions().getStatistics().getSecondLevelCacheHitCount() );
 		tx.commit();
 		s.close();
 	}
 	 
 	
 	public void testFilterOnCollection() {
 		
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		
 		Topic topic = new Topic();
 		Narrative n1 = new Narrative();
 		n1.setState("published");
 		topic.addNarrative(n1);
 		
 		Narrative n2 = new Narrative();
 		n2.setState("draft");
 		topic.addNarrative(n2);
 		
 		s.persist(topic);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		topic = (Topic) s.load( Topic.class, topic.getId() );
 		
 		s.enableFilter("byState").setParameter("state", "published");
 		topic = (Topic) s.load( Topic.class, topic.getId() );
 		assertNotNull(topic); 
 		assertTrue(topic.getNarratives().size() == 1); 
 		assertEquals("published", topic.getNarratives().iterator().next().getState());
 		tx.commit();
 		s.close();
 		
 	} 
 
 	public void testCascadedDeleteOfChildEntitiesBug2() {
 		// Relationship is one SoccerTeam to many Players.
 		// Create a SoccerTeam (parent) and three Players (child).
 		// Verify that the count of Players is correct.
 		// Clear the SoccerTeam reference Players.
 		// The orphanRemoval should remove the Players automatically.
 		// @OneToMany(mappedBy="name", orphanRemoval=true)
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 
 		SoccerTeam team = new SoccerTeam();
 		int teamid = team.getId();
 		Player player1 = new Player();
 		player1.setName("Shalrie Joseph");
 		team.addPlayer(player1);
 
 		Player player2 = new Player();
 		player2.setName("Taylor Twellman");
 		team.addPlayer(player2);
 
 		Player player3 = new Player();
 		player3.setName("Steve Ralston");
 		team.addPlayer(player3);
 		s.persist(team);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		team = (SoccerTeam)s.merge(team);
 		int count = ( (Long) s.createQuery( "select count(*) from Player" ).iterate().next() ).intValue();
 		assertEquals("expected count of 3 but got = " + count, count, 3);
 
 		// clear references to players, this should orphan the players which should
 		// in turn trigger orphanRemoval logic.
 		team.getPlayers().clear();
 //		count = ( (Long) s.createQuery( "select count(*) from Player" ).iterate().next() ).intValue();
 //		assertEquals("expected count of 0 but got = " + count, count, 0);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		count = ( (Long) s.createQuery( "select count(*) from Player" ).iterate().next() ).intValue();
 		assertEquals("expected count of 0 but got = " + count, count, 0);
 		tx.commit();
 		s.close();
 	}
 
 	public void testCascadedDeleteOfChildOneToOne() {
 		// create two single player teams (for one versus one match of soccer)
 		// and associate teams with players via the special OneVOne methods.
 		// Clear the Team reference to players, which should orphan the teams.
 		// Orphaning the team should delete the team. 
 
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 
 		SoccerTeam team = new SoccerTeam();
 		team.setName("Shalrie's team");
 		Player player1 = new Player();
 		player1.setName("Shalrie Joseph");
 		team.setOneVonePlayer(player1);
 		player1.setOneVoneTeam(team);
 
 		s.persist(team);
 
 		SoccerTeam team2 = new SoccerTeam();
 		team2.setName("Taylor's team");
 		Player player2 = new Player();
 		player2.setName("Taylor Twellman");
 		team2.setOneVonePlayer(player2);
 		player2.setOneVoneTeam(team2);
 		s.persist(team2);
 		tx.commit();
 
 		tx = s.beginTransaction();
 		s.clear();
 		team2 = (SoccerTeam)s.load(team2.getClass(), team2.getId());
 		team = (SoccerTeam)s.load(team.getClass(), team.getId());
 		int count = ( (Long) s.createQuery( "select count(*) from Player" ).iterate().next() ).intValue();
 		assertEquals("expected count of 2 but got = " + count, count, 2);
 
 		// clear references to players, this should orphan the players which should
 		// in turn trigger orphanRemoval logic.
 		team.setOneVonePlayer(null);
 		team2.setOneVonePlayer(null);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		count = ( (Long) s.createQuery( "select count(*) from Player" ).iterate().next() ).intValue();
 		assertEquals("expected count of 0 but got = " + count, count, 0);
 		tx.commit();
 		s.close();
 	}
 
 	public void testFilter() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.createQuery( "delete Forest" ).executeUpdate();
 		Forest f1 = new Forest();
 		f1.setLength( 2 );
 		s.persist( f1 );
 		Forest f2 = new Forest();
 		f2.setLength( 20 );
 		s.persist( f2 );
 		Forest f3 = new Forest();
 		f3.setLength( 200 );
 		s.persist( f3 );
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		s.enableFilter( "betweenLength" ).setParameter( "minLength", 5 ).setParameter( "maxLength", 50 );
 		long count = ( (Long) s.createQuery( "select count(*) from Forest" ).iterate().next() ).intValue();
 		assertEquals( 1, count );
 		s.disableFilter( "betweenLength" );
 		s.enableFilter( "minLength" ).setParameter( "minLength", 5 );
 		count = ( (Long) s.createQuery( "select count(*) from Forest" ).iterate().next() ).longValue();
 		assertEquals( 2l, count );
 		s.disableFilter( "minLength" );
 		tx.rollback();
 		s.close();
 	}
 	  
 	/**
 	 * Tests the functionality of inheriting @Filter and @FilterDef annotations
 	 * defined on a parent MappedSuperclass(s)
 	 */
 	public void testInheritFiltersFromMappedSuperclass() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.createQuery( "delete Drill" ).executeUpdate();
 		Drill d1 = new PowerDrill();
 		d1.setName("HomeDrill1");
 		d1.setCategory("HomeImprovment");
 		s.persist( d1 );
 		Drill d2 = new PowerDrill();
 		d2.setName("HomeDrill2");
 		d2.setCategory("HomeImprovement");
 		s.persist(d2);
 		Drill d3 = new PowerDrill();
 		d3.setName("HighPowerDrill");
 		d3.setCategory("Industrial");
 		s.persist( d3 );
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		 
 		//We test every filter with 2 queries, the first on the base class of the 
 		//inheritance hierarchy (Drill), and the second on a subclass (PowerDrill)
 		s.enableFilter( "byName" ).setParameter( "name", "HomeDrill1");
 		long count = ( (Long) s.createQuery( "select count(*) from Drill" ).iterate().next() ).intValue();
 		assertEquals( 1, count );
 		count = ( (Long) s.createQuery( "select count(*) from PowerDrill" ).iterate().next() ).intValue();
 		assertEquals( 1, count );
 		s.disableFilter( "byName" );
 		
 		s.enableFilter( "byCategory" ).setParameter( "category", "Industrial" );
 		count = ( (Long) s.createQuery( "select count(*) from Drill" ).iterate().next() ).longValue();
 		assertEquals( 1, count );
 		count = ( (Long) s.createQuery( "select count(*) from PowerDrill" ).iterate().next() ).longValue();
 		assertEquals( 1, count );
 		s.disableFilter( "byCategory" );
 		
 		tx.rollback();
 		s.close();
 	}
 	
 	public void testParameterizedType() throws Exception {
 		if( !getDialect().supportsExpectedLobUsagePattern() ){
 			return;
 		}
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Forest f = new Forest();
 		f.setSmallText( "ThisIsASmallText" );
 		f.setBigText( "ThisIsABigText" );
 		s.persist( f );
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		Forest f2 = (Forest) s.get( Forest.class, f.getId() );
 		assertEquals( f.getSmallText().toLowerCase(), f2.getSmallText() );
 		assertEquals( f.getBigText().toUpperCase(), f2.getBigText() );
 		tx.commit();
 		s.close();
 	}
 
 	public void testSerialized() throws Exception {
 		if( !getDialect().supportsExpectedLobUsagePattern() ){
 			return;
 		}
 		Forest forest = new Forest();
 		forest.setName( "Shire" );
 		Country country = new Country();
 		country.setName( "Middle Earth" );
 		forest.setCountry( country );
 		Set<Country> near = new HashSet<Country>();
 		country = new Country();
 		country.setName("Mordor");
 		near.add(country);
 		country = new Country();
 		country.setName("Gondor");
 		near.add(country);
 		country = new Country();
 		country.setName("Eriador");
 		near.add(country);
 		forest.setNear(near);
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.persist( forest );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		forest = (Forest) s.get( Forest.class, forest.getId() );
 		assertNotNull( forest );
 		country = forest.getCountry();
 		assertNotNull( country );
 		assertEquals( country.getName(), forest.getCountry().getName() );
 		near = forest.getNear();
 		assertTrue("correct number of nearby countries", near.size() == 3);
 		for (Iterator iter = near.iterator(); iter.hasNext();) {
 			country = (Country)iter.next();
 			String name = country.getName();
 			assertTrue("found expected nearby country " + name,
 				(name.equals("Mordor") || name.equals("Gondor") || name.equals("Eriador")));
 		}
 		tx.commit();
 		s.close();
 	}
 
 	public void testCompositeType() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Ransom r = new Ransom();
 		r.setKidnapperName( "Se7en" );
 		r.setDate( new Date() );
 		MonetaryAmount amount = new MonetaryAmount(
 				new BigDecimal( 100000 ),
 				Currency.getInstance( "EUR" )
 		);
 		r.setAmount( amount );
 		s.persist( r );
 		tx.commit();
 		s.clear();
 		tx = s.beginTransaction();
 		r = (Ransom) s.get( Ransom.class, r.getId() );
 		assertNotNull( r );
 		assertNotNull( r.getAmount() );
 		assertTrue( 0 == new BigDecimal( 100000 ).compareTo( r.getAmount().getAmount() ) );
 		assertEquals( Currency.getInstance( "EUR" ), r.getAmount().getCurrency() );
 		tx.commit();
 		s.close();
 	}
 
 	public void testFormula() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		org.hibernate.test.annotations.entity.Flight airFrance = new Flight();
 		airFrance.setId( new Long( 747 ) );
 		airFrance.setMaxAltitude( 10000 );
 		s.persist( airFrance );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		airFrance = (Flight) s.get( Flight.class, airFrance.getId() );
 		assertNotNull( airFrance );
 		assertEquals( 10000000, airFrance.getMaxAltitudeInMilimeter() );
 		s.delete( airFrance );
 		tx.commit();
 		s.close();
 	}
 		
 	
 	public void testTypeDefNameAndDefaultForTypeAttributes() {
 		
 		ContactDetails contactDetails = new ContactDetails();
 		contactDetails.setLocalPhoneNumber(new PhoneNumber("999999"));
 		contactDetails.setOverseasPhoneNumber(
 				new OverseasPhoneNumber("041", "111111"));
 		
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		s.persist(contactDetails);
 		tx.commit();
 		s.close();
 		
 		s = openSession();
 		tx = s.beginTransaction();
 		contactDetails = 
 			(ContactDetails) s.get( ContactDetails.class, contactDetails.getId() );
 		assertNotNull( contactDetails );
 		assertEquals( "999999", contactDetails.getLocalPhoneNumber().getNumber() );
 		assertEquals( "041111111", contactDetails.getOverseasPhoneNumber().getNumber() );
 		s.delete(contactDetails);
 		tx.commit();
 		s.close();
 	
 	}
 	
 	public void testTypeDefWithoutNameAndDefaultForTypeAttributes() {
 		
 		try {
 			AnnotationConfiguration config = new AnnotationConfiguration();
 			config.addAnnotatedClass(LocalContactDetails.class);
-			config.buildSessionFactory();
+			config.buildSessionFactory( getServiceRegistry() );
 			fail("Did not throw expected exception");
 		}
 		catch( AnnotationException ex ) {
 			assertEquals(
 					"Either name or defaultForType (or both) attribute should be set in TypeDef having typeClass org.hibernate.test.annotations.entity.PhoneNumberType", 
 					ex.getMessage());
 		}	
 		
 	}
 
 	
 	/**
 	 * A custom type is used in the base class, but defined in the derived class. 
 	 * This would have caused an exception, because the base class is processed 
 	 * BEFORE the derived class, and the custom type is not yet defined. However, 
 	 * it works now because we are setting the typeName for SimpleValue in the second 
 	 * pass. 
 	 * 
 	 * 
 	 * @throws Exception
 	 */
 	public void testSetSimpleValueTypeNameInSecondPass() throws Exception {
 		Peugot derived = new Peugot();
 		derived.setName("sharath");
 		
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		s.persist(derived);
 		tx.commit();
 		s.close();
 		
 		s = openSession();
 		tx = s.beginTransaction();
 		derived = (Peugot) s.get( Peugot.class, derived.getId() );
 		assertNotNull( derived );
 		assertEquals( "SHARATH", derived.getName() );
 		s.delete(derived);
 		tx.commit();
 		s.close();
 	}
 	
 
 	public BasicHibernateAnnotationsTest(String x) {
 		super( x );
 	}
 
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[]{
 				Forest.class,
 				Tree.class,
 				Ransom.class,
 				ZipCode.class,
 				Flight.class,
 				Name.class,
 				FormalLastName.class,
 				Car.class,
 				Peugot.class,
 				ContactDetails.class,
 				Topic.class,
 				Narrative.class,
 				Drill.class,
 				PowerDrill.class,
 				SoccerTeam.class,
 				Player.class
 		};
 	}
 
 	protected String[] getAnnotatedPackages() {
 		return new String[]{
 				"org.hibernate.test.annotations.entity"
 		};
 	}
 
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/fetchprofile/FetchProfileTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/fetchprofile/FetchProfileTest.java
index b32b6118d5..9872013b99 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/fetchprofile/FetchProfileTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/fetchprofile/FetchProfileTest.java
@@ -1,158 +1,178 @@
 // $Id$
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.test.annotations.fetchprofile;
 
 import java.io.InputStream;
 
 import junit.framework.TestCase;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import org.hibernate.MappingException;
 import org.hibernate.cfg.AnnotationConfiguration;
+import org.hibernate.cfg.Environment;
 import org.hibernate.engine.SessionFactoryImplementor;
+import org.hibernate.test.common.ServiceRegistryHolder;
 
 /**
  * Test case for HHH-4812
  *
  * @author Hardy Ferentschik
  */
 public class FetchProfileTest extends TestCase {
 
 	private Logger log = LoggerFactory.getLogger( FetchProfileTest.class );
 
+	private ServiceRegistryHolder serviceRegistryHolder;
+
+	protected void setUp() {
+		serviceRegistryHolder = new ServiceRegistryHolder( Environment.getProperties() );
+	}
+
+	protected void tearDown() {
+		if ( serviceRegistryHolder != null ) {
+			serviceRegistryHolder.destroy();
+		}
+	}
+
 	public void testFetchProfileConfigured() {
 		AnnotationConfiguration config = new AnnotationConfiguration();
 		config.addAnnotatedClass( Customer.class );
 		config.addAnnotatedClass( Order.class );
 		config.addAnnotatedClass( SupportTickets.class );
 		config.addAnnotatedClass( Country.class );
-		SessionFactoryImplementor sessionImpl = ( SessionFactoryImplementor ) config.buildSessionFactory();
+		SessionFactoryImplementor sessionImpl = ( SessionFactoryImplementor ) config.buildSessionFactory(
+				serviceRegistryHolder.getServiceRegistry()
+		);
 
 		assertTrue(
 				"fetch profile not parsed properly",
 				sessionImpl.containsFetchProfileDefinition( "customer-with-orders" )
 		);
 		assertFalse(
 				"package info should not be parsed",
 				sessionImpl.containsFetchProfileDefinition( "package-profile-1" )
 		);
 	}
 
 	public void testWrongAssociationName() {
 		AnnotationConfiguration config = new AnnotationConfiguration();
 		config.addAnnotatedClass( Customer2.class );
 		config.addAnnotatedClass( Order.class );
 		config.addAnnotatedClass( Country.class );
 
 		try {
-			config.buildSessionFactory();
+			config.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 			fail();
 		}
 		catch ( MappingException e ) {
 			log.trace( "success" );
 		}
 	}
 
 	public void testWrongClass() {
 		AnnotationConfiguration config = new AnnotationConfiguration();
 		config.addAnnotatedClass( Customer3.class );
 		config.addAnnotatedClass( Order.class );
 		config.addAnnotatedClass( Country.class );
 
 		try {
-			config.buildSessionFactory();
+			config.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 			fail();
 		}
 		catch ( MappingException e ) {
 			log.trace( "success" );
 		}
 	}
 
 	public void testUnsupportedFetchMode() {
 		AnnotationConfiguration config = new AnnotationConfiguration();
 		config.addAnnotatedClass( Customer4.class );
 		config.addAnnotatedClass( Order.class );
 		config.addAnnotatedClass( Country.class );
 
 		try {
-			config.buildSessionFactory();
+			config.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 			fail();
 		}
 		catch ( MappingException e ) {
 			log.trace( "success" );
 		}
 	}
 
 	public void testXmlOverride() {
 		AnnotationConfiguration config = new AnnotationConfiguration();
 		config.addAnnotatedClass( Customer5.class );
 		config.addAnnotatedClass( Order.class );
 		config.addAnnotatedClass( Country.class );
 		InputStream is = Thread.currentThread()
 				.getContextClassLoader()
 				.getResourceAsStream( "org/hibernate/test/annotations/fetchprofile/mappings.hbm.xml" );
 		config.addInputStream( is );
-		SessionFactoryImplementor sessionImpl = ( SessionFactoryImplementor ) config.buildSessionFactory();
+		SessionFactoryImplementor sessionImpl = ( SessionFactoryImplementor ) config.buildSessionFactory(
+				serviceRegistryHolder.getServiceRegistry()
+		);
 
 		assertTrue(
 				"fetch profile not parsed properly",
 				sessionImpl.containsFetchProfileDefinition( "orders-profile" )
 		);
 
 		// now the same with no xml
 		config = new AnnotationConfiguration();
 		config.addAnnotatedClass( Customer5.class );
 		config.addAnnotatedClass( Order.class );
 		config.addAnnotatedClass( Country.class );
 		try {
-			config.buildSessionFactory();
+			config.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 			fail();
 		}
 		catch ( MappingException e ) {
 			log.trace( "success" );
 		}
 	}
 
 	public void testPackageConfiguredFetchProfile() {
 		AnnotationConfiguration config = new AnnotationConfiguration();
 		config.addAnnotatedClass( Customer.class );
 		config.addAnnotatedClass( Order.class );
 		config.addAnnotatedClass( SupportTickets.class );
 		config.addAnnotatedClass( Country.class );
 		config.addPackage( Customer.class.getPackage().getName() );
-		SessionFactoryImplementor sessionImpl = ( SessionFactoryImplementor ) config.buildSessionFactory();
+		SessionFactoryImplementor sessionImpl = ( SessionFactoryImplementor ) config.buildSessionFactory(
+				serviceRegistryHolder.getServiceRegistry()
+		);
 
 		assertTrue(
 				"fetch profile not parsed properly",
 				sessionImpl.containsFetchProfileDefinition( "package-profile-1" )
 		);
 		assertTrue(
 				"fetch profile not parsed properly",
 				sessionImpl.containsFetchProfileDefinition( "package-profile-2" )
 		);
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/fkcircularity/FkCircularityTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/fkcircularity/FkCircularityTest.java
index f5c6cbd368..91165f18b7 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/fkcircularity/FkCircularityTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/fkcircularity/FkCircularityTest.java
@@ -1,67 +1,82 @@
 // $Id$
 package org.hibernate.test.annotations.fkcircularity;
 
 import java.io.PrintWriter;
 import java.io.StringWriter;
 
 import junit.framework.TestCase;
 
 import org.hibernate.cfg.AnnotationConfiguration;
+import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.HSQLDialect;
 import org.hibernate.dialect.SQLServerDialect;
+import org.hibernate.test.common.ServiceRegistryHolder;
+
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
  * Test case for ANN-722 and ANN-730.
  * 
  * @author Hardy Ferentschik
  */
 public class FkCircularityTest extends TestCase {
 
 	private Logger log = LoggerFactory.getLogger(FkCircularityTest.class);
 
+	private ServiceRegistryHolder serviceRegistryHolder;
+
+	protected void setUp() {
+		serviceRegistryHolder = new ServiceRegistryHolder( Environment.getProperties() );
+	}
+
+	protected void tearDown() {
+		if ( serviceRegistryHolder != null ) {
+			serviceRegistryHolder.destroy();
+		}
+	}
+
 	public void testJoinedSublcassesInPK() {
 		try {
 			AnnotationConfiguration config = new AnnotationConfiguration();
 			config.addAnnotatedClass(A.class);
 			config.addAnnotatedClass(B.class);
 			config.addAnnotatedClass(C.class);
 			config.addAnnotatedClass(D.class);
-			config.buildSessionFactory();
+			config.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 			String[] schema = config
 					.generateSchemaCreationScript(new SQLServerDialect());
 			for (String s : schema) {
 				log.debug(s);
 			}
 			log.debug("success");
 		} catch (Exception e) {
 			StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
 			log.debug(writer.toString());
 			fail(e.getMessage());
 		}
 	}
 
 	public void testDeepJoinedSuclassesHierachy() {
 		try {
 			AnnotationConfiguration config = new AnnotationConfiguration();
 			config.addAnnotatedClass(ClassA.class);
 			config.addAnnotatedClass(ClassB.class);
 			config.addAnnotatedClass(ClassC.class);
 			config.addAnnotatedClass(ClassD.class);
-			config.buildSessionFactory();
+			config.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 			String[] schema = config
 					.generateSchemaCreationScript(new HSQLDialect());
 			for (String s : schema) {
 				log.debug(s);
 			}
 			log.debug("success");
 		} catch (Exception e) {
 			StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
 			log.debug(writer.toString());
 			fail(e.getMessage());
 		}
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/id/JoinColumnOverrideTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/id/JoinColumnOverrideTest.java
index 73b2f763c3..ef34357258 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/id/JoinColumnOverrideTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/id/JoinColumnOverrideTest.java
@@ -1,64 +1,64 @@
 //$Id$
 package org.hibernate.test.annotations.id;
 
 import java.io.PrintWriter;
 import java.io.StringWriter;
 
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.dialect.SQLServerDialect;
 import org.hibernate.test.annotations.TestCase;
 import org.hibernate.test.annotations.id.entities.Bunny;
 import org.hibernate.test.annotations.id.entities.PointyTooth;
 import org.hibernate.test.annotations.id.entities.TwinkleToes;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
  * Tests for JIRA issue ANN-748.
  * 
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public class JoinColumnOverrideTest extends TestCase {
 
 	private Logger log = LoggerFactory.getLogger(JoinColumnOverrideTest.class);
 	
 	public JoinColumnOverrideTest(String x) {
 		super(x);
 	}
 
 	public void testBlownPrecision() throws Exception {
 		
 		try {
 			AnnotationConfiguration config = new AnnotationConfiguration();
 			config.addAnnotatedClass(Bunny.class);
 			config.addAnnotatedClass(PointyTooth.class);
 			config.addAnnotatedClass(TwinkleToes.class);
-			config.buildSessionFactory();
+			config.buildSessionFactory( getServiceRegistry() );
 			String[] schema = config
 					.generateSchemaCreationScript(new SQLServerDialect());
 			for (String s : schema) {
 				log.debug(s);
 			}
 			String expectedSqlPointyTooth = "create table PointyTooth (id numeric(128,0) not null, " +
 					"bunny_id numeric(128,0) null, primary key (id))";
 			assertEquals("Wrong SQL", expectedSqlPointyTooth, schema[1]);
 			
 			String expectedSqlTwinkleToes = "create table TwinkleToes (id numeric(128,0) not null, " +
 			"bunny_id numeric(128,0) null, primary key (id))";
 			assertEquals("Wrong SQL", expectedSqlTwinkleToes, schema[2]);
 		} catch (Exception e) {
 			StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
 			log.debug(writer.toString());
 			fail(e.getMessage());
 		}		
 	}
 
 	/**
 	 * @see org.hibernate.test.annotations.TestCase#getAnnotatedClasses()
 	 */
 	protected Class[] getAnnotatedClasses() {
 		return new Class[] {};
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/id/sequences/JoinColumnOverrideTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/id/sequences/JoinColumnOverrideTest.java
index f4091c1d05..772107f8a2 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/id/sequences/JoinColumnOverrideTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/id/sequences/JoinColumnOverrideTest.java
@@ -1,64 +1,64 @@
 //$Id$
 package org.hibernate.test.annotations.id.sequences;
 
 import java.io.PrintWriter;
 import java.io.StringWriter;
 
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.dialect.SQLServerDialect;
 import org.hibernate.test.annotations.TestCase;
 import org.hibernate.test.annotations.id.sequences.entities.Bunny;
 import org.hibernate.test.annotations.id.sequences.entities.PointyTooth;
 import org.hibernate.test.annotations.id.sequences.entities.TwinkleToes;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
  * Tests for JIRA issue ANN-748.
  * 
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public class JoinColumnOverrideTest extends TestCase {
 
 	private Logger log = LoggerFactory.getLogger(JoinColumnOverrideTest.class);
 	
 	public JoinColumnOverrideTest(String x) {
 		super(x);
 	}
 
 	public void testBlownPrecision() throws Exception {
 		
 		try {
 			AnnotationConfiguration config = new AnnotationConfiguration();
 			config.addAnnotatedClass(Bunny.class);
 			config.addAnnotatedClass(PointyTooth.class);
 			config.addAnnotatedClass(TwinkleToes.class);
-			config.buildSessionFactory();
+			config.buildSessionFactory(  getServiceRegistry() );
 			String[] schema = config
 					.generateSchemaCreationScript(new SQLServerDialect());
 			for (String s : schema) {
 				log.debug(s);
 			}
 			String expectedSqlPointyTooth = "create table PointyTooth (id numeric(128,0) not null, " +
 					"bunny_id numeric(128,0) null, primary key (id))";
 			assertEquals("Wrong SQL", expectedSqlPointyTooth, schema[1]);
 			
 			String expectedSqlTwinkleToes = "create table TwinkleToes (id numeric(128,0) not null, " +
 			"bunny_id numeric(128,0) null, primary key (id))";
 			assertEquals("Wrong SQL", expectedSqlTwinkleToes, schema[2]);
 		} catch (Exception e) {
 			StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
 			log.debug(writer.toString());
 			fail(e.getMessage());
 		}		
 	}
 
 	/**
 	 * @see org.hibernate.test.annotations.TestCase#getAnnotatedClasses()
 	 */
 	protected Class[] getAnnotatedClasses() {
 		return new Class[] {};
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/immutable/ImmutableTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/immutable/ImmutableTest.java
index 6786d5cead..5f0d6a5f16 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/immutable/ImmutableTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/immutable/ImmutableTest.java
@@ -1,159 +1,159 @@
 //$Id$
 package org.hibernate.test.annotations.immutable;
 
 import java.util.ArrayList;
 import java.util.List;
 
 import org.hibernate.AnnotationException;
 import org.hibernate.HibernateException;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.test.annotations.TestCase;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
  * Tests for <code>Immutable</code> annotation.
  * 
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public class ImmutableTest extends TestCase {
 
 	private Logger log = LoggerFactory.getLogger(ImmutableTest.class);
 
 	public ImmutableTest(String x) {
 		super(x);
 	}
 
 	public void testImmutableEntity() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Country country = new Country();
 		country.setName("Germany");
 		s.persist(country);
 		tx.commit();
 		s.close();
 
 		// try changing the entity
 		s = openSession();
 		tx = s.beginTransaction();
 		Country germany = (Country) s.get(Country.class, country.getId());
 		assertNotNull(germany);
 		germany.setName("France");
 		assertEquals("Local name can be changed", "France", germany.getName());
 		s.save(germany);
 		tx.commit();
 		s.close();
 		
 		// retrieving the country again - it should be unmodified
 		s = openSession();
 		tx = s.beginTransaction();
 		germany = (Country) s.get(Country.class, country.getId());
 		assertNotNull(germany);
 		assertEquals("Name should not have changed", "Germany", germany.getName());
 		tx.commit();
 		s.close();
 		
 //		// try deletion
 //		s = openSession();
 //		tx = s.beginTransaction();
 //		s.delete(germany);
 //		tx.commit();
 //		s.close();
 //		
 //		s = openSession();
 //		tx = s.beginTransaction();
 //		germany = (Country) s.get(Country.class, country.getId());
 //		assertNotNull(germany);
 //		assertEquals("Name should not have changed", "Germany", germany.getName());
 //		s.close();
 	}
 	
 	public void testImmutableCollection() {
 		Country country = new Country();
 		country.setName("Germany");
 		List states = new ArrayList<State>();
 		State bayern = new State();
 		bayern.setName("Bayern");
 		State hessen = new State();
 		hessen.setName("Hessen");
 		State sachsen = new State();
 		sachsen.setName("Sachsen");
 		states.add(bayern);
 		states.add(hessen);
 		states.add(sachsen);
 		country.setStates(states);
 		
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		s.persist(country);
 		tx.commit();
 		s.close();
 		
 		s = openSession();
 		tx = s.beginTransaction();
 		Country germany = (Country) s.get(Country.class, country.getId());
 		assertNotNull(germany);
 		assertEquals("Wrong number of states", 3, germany.getStates().size());
 		
 		// try adding a state
 		State foobar = new State();
 		foobar.setName("foobar");
 		s.save(foobar);
 		germany.getStates().add(foobar);
 		try {
 			tx.commit();
 			fail();
 		} catch (HibernateException e) {
 			assertTrue(e.getMessage().contains("changed an immutable collection instance"));
 			log.debug("success");
 		}
 		s.close();
 		
 		s = openSession();
 		tx = s.beginTransaction();
 		germany = (Country) s.get(Country.class, country.getId());
 		assertNotNull(germany);
 		assertEquals("Wrong number of states", 3, germany.getStates().size());
 		
 		// try deleting a state
 		germany.getStates().remove(0);
 		try {
 			tx.commit();
 			fail();
 		} catch (HibernateException e) {
 			assertTrue(e.getMessage().contains("changed an immutable collection instance"));
 			log.debug("success");
 		}	
 		s.close();	
 		
 		s = openSession();
 		tx = s.beginTransaction();
 		germany = (Country) s.get(Country.class, country.getId());
 		assertNotNull(germany);
 		assertEquals("Wrong number of states", 3, germany.getStates().size());
 		tx.commit();
 		s.close();
 	}
 	
 	public void testMiscplacedImmutableAnnotation() {
 		try {
 			AnnotationConfiguration config = new AnnotationConfiguration();
 			config.addAnnotatedClass(Foobar.class);
-			config.buildSessionFactory();
+			config.buildSessionFactory( getServiceRegistry() );
 			fail();
 		} catch (AnnotationException ae) {
 			log.debug("succes");
 		}
 	}
 	
 	/**
 	 * @see org.hibernate.test.annotations.TestCase#getAnnotatedClasses()
 	 */
 	protected Class[] getAnnotatedClasses() {
 		return new Class[] { Country.class, State.class};
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/namingstrategy/NamingStrategyTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/namingstrategy/NamingStrategyTest.java
index 0b8ceac840..29c423dfeb 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/namingstrategy/NamingStrategyTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/namingstrategy/NamingStrategyTest.java
@@ -1,85 +1,100 @@
 // $Id$
 package org.hibernate.test.annotations.namingstrategy;
 
 import java.io.PrintWriter;
 import java.io.StringWriter;
 import java.util.Iterator;
 
 import junit.framework.TestCase;
 
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.cfg.EJB3NamingStrategy;
+import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Mappings;
 import org.hibernate.mapping.Table;
+import org.hibernate.test.common.ServiceRegistryHolder;
+
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
  * Test harness for ANN-716.
  * 
  * @author Hardy Ferentschik
  */
 public class NamingStrategyTest extends TestCase {
 	
 	private Logger log = LoggerFactory.getLogger(NamingStrategyTest.class);
 
+	private ServiceRegistryHolder serviceRegistryHolder;
+
+	protected void setUp() {
+		serviceRegistryHolder = new ServiceRegistryHolder( Environment.getProperties() );
+	}
+
+	protected void tearDown() {
+		if ( serviceRegistryHolder != null ) {
+			serviceRegistryHolder.destroy();
+		}
+	}
+
 	public void testWithCustomNamingStrategy() throws Exception {
 		try {
 			AnnotationConfiguration config = new AnnotationConfiguration();
 			config.setNamingStrategy(new DummyNamingStrategy());
 			config.addAnnotatedClass(Address.class);
 			config.addAnnotatedClass(Person.class);
-			config.buildSessionFactory();
+			config.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 		}
 		catch( Exception e ) {
 			StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
 			log.debug(writer.toString());
 			fail(e.getMessage());
 		}
 	}
 
 	public void testWithEJB3NamingStrategy() throws Exception {
 		try {
 			AnnotationConfiguration config = new AnnotationConfiguration();
 			config.setNamingStrategy(EJB3NamingStrategy.INSTANCE);
 			config.addAnnotatedClass(A.class);
 			config.addAnnotatedClass(AddressEntry.class);
-			config.buildSessionFactory();
+			config.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 			Mappings mappings = config.createMappings();
 			boolean foundIt = false;
 
 			for ( Iterator iter = mappings.iterateTables(); iter.hasNext();  ) {
 				Table table = (Table) iter.next();
 				log.info("testWithEJB3NamingStrategy table = " + table.getName());
 				if ( table.getName().equalsIgnoreCase("A_ADDRESS")) {
 					foundIt = true;
 				}
 				// make sure we use A_ADDRESS instead of AEC_address
 				assertFalse("got table name mapped to: AEC_address (should be A_ADDRESS) which violates JPA-2 spec section 11.1.8 ([OWNING_ENTITY_NAME]_[COLLECTION_ATTRIBUTE_NAME])",table.getName().equalsIgnoreCase("AEC_address"));
 			}
 			assertTrue("table not mapped to A_ADDRESS which violates JPA-2 spec section 11.1.8",foundIt);
 		}
 		catch( Exception e ) {
 			StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
 			log.debug(writer.toString());
 			fail(e.getMessage());
 		}
 	}
 
 	public void testWithoutCustomNamingStrategy() throws Exception {
 		try {
 			AnnotationConfiguration config = new AnnotationConfiguration();
 			config.addAnnotatedClass(Address.class);
 			config.addAnnotatedClass(Person.class);
-			config.buildSessionFactory();
+			config.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 		}
 		catch( Exception e ) {
 			StringWriter writer = new StringWriter();
 			e.printStackTrace(new PrintWriter(writer));
 			log.debug(writer.toString());
 			fail(e.getMessage());
 		}
 	}	
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/onetoone/OneToOneErrorTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/onetoone/OneToOneErrorTest.java
index 34f39bb40b..a630cceed4 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/onetoone/OneToOneErrorTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/onetoone/OneToOneErrorTest.java
@@ -1,26 +1,34 @@
 //$Id$
 package org.hibernate.test.annotations.onetoone;
 
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.SessionFactory;
 import org.hibernate.AnnotationException;
+import org.hibernate.test.common.ServiceRegistryHolder;
 
 /**
  * @author Emmanuel Bernard
  */
 public class OneToOneErrorTest extends junit.framework.TestCase {
 	public void testWrongOneToOne() throws Exception {
 		AnnotationConfiguration cfg = new AnnotationConfiguration();
 		cfg.addAnnotatedClass( Show.class )
 				.addAnnotatedClass( ShowDescription.class );
 		cfg.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
+		ServiceRegistryHolder serviceRegistryHolder = null;
 		try {
-			SessionFactory sf = cfg.buildSessionFactory();
+			serviceRegistryHolder = new ServiceRegistryHolder( Environment.getProperties() );
+			SessionFactory sf = cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 			fail( "Wrong mappedBy does not fail property" );
 		}
 		catch (AnnotationException e) {
 			//success
 		}
+		finally {
+			if ( serviceRegistryHolder != null ) {
+				serviceRegistryHolder.destroy();
+			}			
+		}
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/onetoone/primarykey/NullablePrimaryKeyTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/onetoone/primarykey/NullablePrimaryKeyTest.java
index da238e10df..692534beed 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/onetoone/primarykey/NullablePrimaryKeyTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/onetoone/primarykey/NullablePrimaryKeyTest.java
@@ -1,39 +1,50 @@
 //$Id: A320.java 14736 2008-06-04 14:23:42Z hardy.ferentschik $
 package org.hibernate.test.annotations.onetoone.primarykey;
 
 import junit.framework.TestCase;
 
 import org.hibernate.cfg.AnnotationConfiguration;
+import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.SQLServerDialect;
+import org.hibernate.test.common.ServiceRegistryHolder;
+
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
  * Test harness for ANN-742.
  * 
  * @author Hardy Ferentschik
  * 
  */
 public class NullablePrimaryKeyTest extends TestCase {
 
 	private Logger log = LoggerFactory.getLogger(NullablePrimaryKeyTest.class);
 
 	public void testGeneratedSql() {
+
+		ServiceRegistryHolder serviceRegistryHolder = null;
 		try {
 			AnnotationConfiguration config = new AnnotationConfiguration();
 			config.addAnnotatedClass(Address.class);
 			config.addAnnotatedClass(Person.class);
-			config.buildSessionFactory();
+			serviceRegistryHolder = new ServiceRegistryHolder( Environment.getProperties() );
+			config.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 			String[] schema = config
 					.generateSchemaCreationScript(new SQLServerDialect());
 			for (String s : schema) {
 				log.debug(s);
 			}
 			String expectedMappingTableSql = "create table personAddress (address_id numeric(19,0) null, " +
 					"person_id numeric(19,0) not null, primary key (person_id))";
 			assertEquals("Wrong SQL", expectedMappingTableSql, schema[2]);
 		} catch (Exception e) {
 			fail(e.getMessage());
 		}
+		finally {
+			if ( serviceRegistryHolder != null ) {
+				serviceRegistryHolder.destroy();
+			}
+		}		
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/cfg/ConfigurationSerializationTest.java b/hibernate-core/src/test/java/org/hibernate/test/cfg/ConfigurationSerializationTest.java
index 3315044324..f3a9932299 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/cfg/ConfigurationSerializationTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/cfg/ConfigurationSerializationTest.java
@@ -1,125 +1,138 @@
 /*
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA\
  */
 package org.hibernate.test.cfg;
 
 import javax.persistence.Entity;
 import javax.persistence.Id;
 
 import junit.framework.Test;
 import junit.framework.TestSuite;
 
+import org.hibernate.test.common.ServiceRegistryHolder;
 import org.hibernate.testing.junit.UnitTestCase;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.util.SerializationHelper;
 import org.hibernate.SessionFactory;
 
 /**
  * Copied over mostly from ConfigurationPerformanceTest
  *
  * @author Steve Ebersole
  * @author Max Andersen
  */
 public class ConfigurationSerializationTest extends UnitTestCase {
 	public ConfigurationSerializationTest(String string) {
 		super( string );
 	}
 
 	public static Test suite() {
 		return new TestSuite( ConfigurationSerializationTest.class );
 	}
 
 	private static final String[] FILES = new String[] {
 			"legacy/ABC.hbm.xml",
 			"legacy/ABCExtends.hbm.xml",
 			"legacy/Baz.hbm.xml",
 			"legacy/Blobber.hbm.xml",
 			"legacy/Broken.hbm.xml",
 			"legacy/Category.hbm.xml",
 			"legacy/Circular.hbm.xml",
 			"legacy/Commento.hbm.xml",
 			"legacy/ComponentNotNullMaster.hbm.xml",
 			"legacy/Componentizable.hbm.xml",
 			"legacy/Container.hbm.xml",
 			"legacy/Custom.hbm.xml",
 			"legacy/CustomSQL.hbm.xml",
 			"legacy/Eye.hbm.xml",
 			"legacy/Fee.hbm.xml",
 			"legacy/Fo.hbm.xml",
 			"legacy/FooBar.hbm.xml",
 			"legacy/Fum.hbm.xml",
 			"legacy/Fumm.hbm.xml",
 			"legacy/Glarch.hbm.xml",
 			"legacy/Holder.hbm.xml",
 			"legacy/IJ2.hbm.xml",
 			"legacy/Immutable.hbm.xml",
 			"legacy/Location.hbm.xml",
 			"legacy/Many.hbm.xml",
 			"legacy/Map.hbm.xml",
 			"legacy/Marelo.hbm.xml",
 			"legacy/MasterDetail.hbm.xml",
 			"legacy/Middle.hbm.xml",
 			"legacy/Multi.hbm.xml",
 			"legacy/MultiExtends.hbm.xml",
 			"legacy/Nameable.hbm.xml",
 			"legacy/One.hbm.xml",
 			"legacy/ParentChild.hbm.xml",
 			"legacy/Qux.hbm.xml",
 			"legacy/Simple.hbm.xml",
 			"legacy/SingleSeveral.hbm.xml",
 			"legacy/Stuff.hbm.xml",
 			"legacy/UpDown.hbm.xml",
 			"legacy/Vetoer.hbm.xml",
 			"legacy/WZ.hbm.xml",
 			"cfg/orm-serializable.xml"
 	};
 
 	public void testConfiguraionSerializability() {
 		Configuration cfg = new Configuration();
 		for ( String file : FILES ) {
 			cfg.addResource( "org/hibernate/test/" + file );
 		}
 
 		cfg.addAnnotatedClass( Serial.class );
 
 		byte[] bytes = SerializationHelper.serialize( cfg );
 		cfg = ( Configuration ) SerializationHelper.deserialize( bytes );
 
-		// try to build SF
-		SessionFactory factory = cfg.buildSessionFactory();
-		factory.close();
+		SessionFactory factory = null;
+		ServiceRegistryHolder serviceRegistryHolder = null;
+		try {
+			serviceRegistryHolder = new ServiceRegistryHolder( cfg.getProperties() );
+			// try to build SF
+			factory = cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry());
+		}
+		finally {
+			if ( factory != null ) {
+				factory.close();
+			}
+			if ( serviceRegistryHolder != null ) {
+				serviceRegistryHolder.destroy();
+			}
+		}
 	}
 
 	@Entity
 	public static class Serial {
 		private String id;
 		private String value;
 
 		@Id
 		public String getId() {
 			return id;
 		}
 
 		public void setId(String id) {
 			this.id = id;
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/common/ServiceRegistryHolder.java b/hibernate-core/src/test/java/org/hibernate/test/common/ServiceRegistryHolder.java
new file mode 100644
index 0000000000..c9850fc169
--- /dev/null
+++ b/hibernate-core/src/test/java/org/hibernate/test/common/ServiceRegistryHolder.java
@@ -0,0 +1,81 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.test.common;
+
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Properties;
+
+import org.hibernate.cfg.Environment;
+import org.hibernate.cfg.internal.ServicesRegistryBootstrap;
+import org.hibernate.engine.jdbc.internal.JdbcServicesImpl;
+import org.hibernate.engine.jdbc.spi.JdbcServices;
+import org.hibernate.internal.util.config.ConfigurationHelper;
+import org.hibernate.service.classloading.spi.ClassLoaderService;
+import org.hibernate.service.internal.ServicesRegistryImpl;
+import org.hibernate.service.jdbc.connections.internal.ConnectionProviderInitiator;
+import org.hibernate.service.spi.ServicesRegistry;
+
+/**
+ * @author Gail Badner
+ */
+public class ServiceRegistryHolder {
+	private final ServicesRegistryImpl serviceRegistry;
+	private final Properties properties;
+
+	public ServiceRegistryHolder(Map props) {
+		properties = new Properties();
+		properties.putAll( props );
+		Environment.verifyProperties( properties );
+		ConfigurationHelper.resolvePlaceHolders( properties );
+		serviceRegistry = new ServicesRegistryBootstrap().initiateServicesRegistry( properties );
+		properties.putAll( serviceRegistry.getService( JdbcServices.class ).getDialect().getDefaultProperties() );
+	}
+
+	public Properties getProperties() {
+		return properties;
+	}
+
+	public ServicesRegistry getServiceRegistry() {
+		return serviceRegistry;
+	}
+
+	public JdbcServices getJdbcServices() {
+		return serviceRegistry.getService( JdbcServices.class );
+	}
+
+	public JdbcServicesImpl getJdbcServicesImpl() {
+		return ( JdbcServicesImpl ) getJdbcServices();
+	}
+
+	public ClassLoaderService getClassLoaderService() {
+		return serviceRegistry.getService( ClassLoaderService.class );
+	}
+
+	public void destroy() {
+		if ( serviceRegistry != null ) {
+			serviceRegistry.destroy();
+		}
+	}
+}
diff --git a/hibernate-core/src/test/java/org/hibernate/test/connections/SuppliedConnectionTest.java b/hibernate-core/src/test/java/org/hibernate/test/connections/SuppliedConnectionTest.java
index a577c266e5..9bd7e49b12 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/connections/SuppliedConnectionTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/connections/SuppliedConnectionTest.java
@@ -1,121 +1,125 @@
 // $Id: SuppliedConnectionTest.java 11332 2007-03-22 17:34:55Z steve.ebersole@jboss.com $
 package org.hibernate.test.connections;
 
 import java.sql.Connection;
 import java.sql.ResultSet;
 
 import junit.framework.Test;
 
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.Session;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
-import org.hibernate.connection.ConnectionProvider;
-import org.hibernate.connection.ConnectionProviderFactory;
-import org.hibernate.connection.UserSuppliedConnectionProvider;
+import org.hibernate.service.jdbc.connections.internal.UserSuppliedConnectionProviderImpl;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
+import org.hibernate.service.spi.Stoppable;
+import org.hibernate.test.common.ConnectionProviderBuilder;
 import org.hibernate.testing.junit.functional.FunctionalTestClassTestSuite;
 import org.hibernate.tool.hbm2ddl.SchemaExport;
 
 /**
  * Implementation of SuppliedConnectionTest.
  *
  * @author Steve Ebersole
  */
 public class SuppliedConnectionTest extends ConnectionManagementTestCase {
 
-	private ConnectionProvider cp = ConnectionProviderFactory.newConnectionProvider();
+	private ConnectionProvider cp = ConnectionProviderBuilder.buildConnectionProvider();
 	private Connection connectionUnderTest;
 
 	public SuppliedConnectionTest(String name) {
 		super( name );
 	}
 
 	public static Test suite() {
 		return new FunctionalTestClassTestSuite( SuppliedConnectionTest.class );
 	}
 
 	protected Session getSessionUnderTest() throws Throwable {
 		connectionUnderTest = cp.getConnection();
 		return getSessions().openSession( connectionUnderTest );
 	}
 
 	protected void reconnect(Session session) {
 		session.reconnect( connectionUnderTest );
 	}
 
 	protected void done() throws Throwable {
 		cp.closeConnection( connectionUnderTest );
 	}
 
 	public void configure(Configuration cfg) {
 		super.configure( cfg );
 		cfg.setProperty( Environment.RELEASE_CONNECTIONS, ConnectionReleaseMode.ON_CLOSE.toString() );
-		cfg.setProperty( Environment.CONNECTION_PROVIDER, UserSuppliedConnectionProvider.class.getName() );
+		cfg.setProperty( Environment.CONNECTION_PROVIDER, UserSuppliedConnectionProviderImpl.class.getName() );
 		boolean supportsScroll = true;
 		Connection conn = null;
 		try {
 			conn = cp.getConnection();
 			supportsScroll = conn.getMetaData().supportsResultSetType(ResultSet.TYPE_SCROLL_INSENSITIVE);
 		}
 		catch( Throwable ignore ) {
 		}
 		finally {
 			if ( conn != null ) {
 				try {
 					conn.close();
 				}
 				catch( Throwable ignore ) {
 					// ignore it...
 				}
 			}
 		}
 		cfg.setProperty( Environment.USE_SCROLLABLE_RESULTSET, "" + supportsScroll );
 	}
 
 	public boolean createSchema() {
 		return false;
 	}
 
 	public boolean recreateSchemaAfterFailure() {
 		return false;
 	}
 
 	protected void prepareTest() throws Exception {
 		super.prepareTest();
 		Connection conn = cp.getConnection();
 		try {
 			new SchemaExport( getCfg(), conn ).create( false, true );
 		}
 		finally {
 			if ( conn != null ) {
 				try {
 					cp.closeConnection( conn );
 				}
 				catch( Throwable ignore ) {
 				}
 			}
 		}
 	}
 
 	protected void cleanupTest() throws Exception {
 		Connection conn = cp.getConnection();
 		try {
 			new SchemaExport( getCfg(), conn ).drop( false, true );
 		}
 		finally {
 			if ( conn != null ) {
 				try {
 					cp.closeConnection( conn );
 				}
 				catch( Throwable ignore ) {
 				}
 			}
 		}
 		try {
-			cp.close();
+			if ( cp instanceof Stoppable ) {
+					( ( Stoppable ) cp ).stop();
+			}
+			cp = null;
 		}
 		catch( Throwable ignore ) {
 		}
 		super.cleanupTest();
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/extendshbm/ExtendsTest.java b/hibernate-core/src/test/java/org/hibernate/test/extendshbm/ExtendsTest.java
index e1f1cdb94b..fa4c222168 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/extendshbm/ExtendsTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/extendshbm/ExtendsTest.java
@@ -1,193 +1,193 @@
 //$Id: ExtendsTest.java 10977 2006-12-12 23:28:04Z steve.ebersole@jboss.com $
 package org.hibernate.test.extendshbm;
 
 import junit.framework.Test;
 import junit.framework.TestSuite;
 
 import org.hibernate.HibernateException;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.testing.junit.UnitTestCase;
 
 /**
  * @author Gavin King
  */
 public class ExtendsTest extends UnitTestCase {
 
 	public ExtendsTest(String str) {
 		super( str );
 	}
 
 	public static Test suite() {
 		return new TestSuite( ExtendsTest.class );
 	}
 
 	private String getBaseForMappings() {
 		return "org/hibernate/test/";
 	}
 
 	public void testAllInOne() {
 		Configuration cfg = new Configuration();
 
 		cfg.addResource( getBaseForMappings() + "extendshbm/allinone.hbm.xml" );
 		cfg.buildMappings();
 		assertNotNull( cfg.getClassMapping( "org.hibernate.test.extendshbm.Customer" ) );
 		assertNotNull( cfg.getClassMapping( "org.hibernate.test.extendshbm.Person" ) );
 		assertNotNull( cfg.getClassMapping( "org.hibernate.test.extendshbm.Employee" ) );
 	}
 
 	public void testOutOfOrder() {
 		Configuration cfg = new Configuration();
 
 		try {
 			cfg.addResource( getBaseForMappings() + "extendshbm/Customer.hbm.xml" );
 			assertNull(
 					"cannot be in the configuration yet!",
 					cfg.getClassMapping( "org.hibernate.test.extendshbm.Customer" )
 			);
 			cfg.addResource( getBaseForMappings() + "extendshbm/Person.hbm.xml" );
 			cfg.addResource( getBaseForMappings() + "extendshbm/Employee.hbm.xml" );
 
-			cfg.buildSessionFactory();
+			cfg.buildSessionFactory( getServiceRegistry() );
 
 			assertNotNull( cfg.getClassMapping( "org.hibernate.test.extendshbm.Customer" ) );
 			assertNotNull( cfg.getClassMapping( "org.hibernate.test.extendshbm.Person" ) );
 			assertNotNull( cfg.getClassMapping( "org.hibernate.test.extendshbm.Employee" ) );
 
 		}
 		catch ( HibernateException e ) {
 			fail( "should not fail with exception! " + e );
 		}
 
 	}
 
 	public void testNwaitingForSuper() {
 		Configuration cfg = new Configuration();
 
 		try {
 			cfg.addResource( getBaseForMappings() + "extendshbm/Customer.hbm.xml" );
 			assertNull(
 					"cannot be in the configuration yet!",
 					cfg.getClassMapping( "org.hibernate.test.extendshbm.Customer" )
 			);
 			cfg.addResource( getBaseForMappings() + "extendshbm/Employee.hbm.xml" );
 			assertNull(
 					"cannot be in the configuration yet!",
 					cfg.getClassMapping( "org.hibernate.test.extendshbm.Employee" )
 			);
 			cfg.addResource( getBaseForMappings() + "extendshbm/Person.hbm.xml" );
 
 			cfg.buildMappings();
 
 			assertNotNull( cfg.getClassMapping( "org.hibernate.test.extendshbm.Person" ) );
 			assertNotNull( cfg.getClassMapping( "org.hibernate.test.extendshbm.Employee" ) );
 			assertNotNull( cfg.getClassMapping( "org.hibernate.test.extendshbm.Customer" ) );
 
 
 		}
 		catch ( HibernateException e ) {
 			e.printStackTrace();
 			fail( "should not fail with exception! " + e );
 
 		}
 
 	}
 
 	public void testMissingSuper() {
 		Configuration cfg = new Configuration();
 
 		try {
 			cfg.addResource( getBaseForMappings() + "extendshbm/Customer.hbm.xml" );
 			assertNull(
 					"cannot be in the configuration yet!",
 					cfg.getClassMapping( "org.hibernate.test.extendshbm.Customer" )
 			);
 			cfg.addResource( getBaseForMappings() + "extendshbm/Employee.hbm.xml" );
 
-			cfg.buildSessionFactory();
+			cfg.buildSessionFactory( getServiceRegistry() );
 
 			fail( "Should not be able to build sessionfactory without a Person" );
 		}
 		catch ( HibernateException e ) {
 
 		}
 
 	}
 
 	public void testAllSeparateInOne() {
 		Configuration cfg = new Configuration();
 
 		try {
 			cfg.addResource( getBaseForMappings() + "extendshbm/allseparateinone.hbm.xml" );
 
-			cfg.buildSessionFactory();
+			cfg.buildSessionFactory( getServiceRegistry() );
 
 			assertNotNull( cfg.getClassMapping( "org.hibernate.test.extendshbm.Customer" ) );
 			assertNotNull( cfg.getClassMapping( "org.hibernate.test.extendshbm.Person" ) );
 			assertNotNull( cfg.getClassMapping( "org.hibernate.test.extendshbm.Employee" ) );
 
 		}
 		catch ( HibernateException e ) {
 			fail( "should not fail with exception! " + e );
 		}
 
 	}
 
 	public void testJoinedSubclassAndEntityNamesOnly() {
 		Configuration cfg = new Configuration();
 
 		try {
 			cfg.addResource( getBaseForMappings() + "extendshbm/entitynames.hbm.xml" );
 
 			cfg.buildMappings();
 
 			assertNotNull( cfg.getClassMapping( "EntityHasName" ) );
 			assertNotNull( cfg.getClassMapping( "EntityCompany" ) );
 
 		}
 		catch ( HibernateException e ) {
 			e.printStackTrace();
 			fail( "should not fail with exception! " + e );
 
 		}
 	}
 
 	public void testEntityNamesWithPackage() {
 		Configuration cfg = new Configuration();
 		try {
 			cfg.addResource( getBaseForMappings() + "extendshbm/packageentitynames.hbm.xml" );
 
 			cfg.buildMappings();
 
 			assertNotNull( cfg.getClassMapping( "EntityHasName" ) );
 			assertNotNull( cfg.getClassMapping( "EntityCompany" ) );
 
 		}
 		catch ( HibernateException e ) {
 			e.printStackTrace();
 			fail( "should not fail with exception! " + e );
 
 		}
 	}
 
 
 	public void testUnionSubclass() {
 		Configuration cfg = new Configuration();
 
 		try {
 			cfg.addResource( getBaseForMappings() + "extendshbm/unionsubclass.hbm.xml" );
 
 			cfg.buildMappings();
 
 			assertNotNull( cfg.getClassMapping( "org.hibernate.test.extendshbm.Person" ) );
 			assertNotNull( cfg.getClassMapping( "org.hibernate.test.extendshbm.Customer" ) );
 
 		}
 		catch ( HibernateException e ) {
 			e.printStackTrace();
 			fail( "should not fail with exception! " + e );
 
 		}
 	}
 
 }
 
diff --git a/hibernate-core/src/test/java/org/hibernate/test/instrument/cases/AbstractExecutable.java b/hibernate-core/src/test/java/org/hibernate/test/instrument/cases/AbstractExecutable.java
index 87f006dd88..70a64e26fb 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/instrument/cases/AbstractExecutable.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/instrument/cases/AbstractExecutable.java
@@ -1,42 +1,48 @@
 package org.hibernate.test.instrument.cases;
 
 import org.hibernate.SessionFactory;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
+import org.hibernate.test.common.ServiceRegistryHolder;
 
 /**
  * @author Steve Ebersole
  */
 public abstract class AbstractExecutable implements Executable {
 
+	private ServiceRegistryHolder serviceRegistryHolder;
 	private SessionFactory factory;
 
 	public final void prepare() {
 		Configuration cfg = new Configuration().setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
 		String[] resources = getResources();
 		for ( int i = 0; i < resources.length; i++ ) {
 			cfg.addResource( resources[i] );
 		}
-		factory = cfg.buildSessionFactory();
+		serviceRegistryHolder = new ServiceRegistryHolder( cfg.getProperties() );
+		factory = cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 	}
 
 	public final void complete() {
 		try {
 			cleanup();
 		}
 		finally {
 			factory.close();
+			if ( serviceRegistryHolder != null ) {
+				serviceRegistryHolder.destroy();
+			}			
 		}
 	}
 
 	protected SessionFactory getFactory() {
 		return factory;
 	}
 
 	protected void cleanup() {
 	}
 
 	protected String[] getResources() {
 		return new String[] { "org/hibernate/test/instrument/domain/Documents.hbm.xml" };
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java b/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java
index 595081c4d9..c63b5391fa 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java
@@ -1,1059 +1,1058 @@
 //$Id: FooBarTest.java 10977 2006-12-12 23:28:04Z steve.ebersole@jboss.com $
 package org.hibernate.test.legacy;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.Time;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.Date;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Locale;
 import java.util.Set;
 import java.util.SortedSet;
 import java.util.TimeZone;
 import java.util.TreeMap;
 import java.util.TreeSet;
 
 import junit.framework.Test;
 import junit.textui.TestRunner;
 
 import org.hibernate.Criteria;
 import org.hibernate.FetchMode;
 import org.hibernate.FlushMode;
 import org.hibernate.Hibernate;
 import org.hibernate.HibernateException;
 import org.hibernate.LazyInitializationException;
 import org.hibernate.LockMode;
 import org.hibernate.ObjectNotFoundException;
 import org.hibernate.Query;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Transaction;
-import org.hibernate.cfg.Environment;
 import org.hibernate.classic.Session;
-import org.hibernate.connection.ConnectionProvider;
-import org.hibernate.connection.DriverManagerConnectionProvider;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.criterion.Example;
 import org.hibernate.criterion.MatchMode;
 import org.hibernate.criterion.Order;
 import org.hibernate.criterion.Restrictions;
 import org.hibernate.dialect.DB2Dialect;
 import org.hibernate.dialect.DerbyDialect;
 import org.hibernate.dialect.HSQLDialect;
 import org.hibernate.dialect.InterbaseDialect;
 import org.hibernate.dialect.MckoiDialect;
 import org.hibernate.dialect.MySQLDialect;
 import org.hibernate.dialect.Oracle8iDialect;
 import org.hibernate.dialect.PointbaseDialect;
 import org.hibernate.dialect.PostgreSQLDialect;
 import org.hibernate.dialect.SAPDBDialect;
 import org.hibernate.dialect.Sybase11Dialect;
 import org.hibernate.dialect.SybaseASE15Dialect;
 import org.hibernate.dialect.SybaseDialect;
 import org.hibernate.dialect.TimesTenDialect;
 import org.hibernate.engine.SessionFactoryImplementor;
+import org.hibernate.test.common.ConnectionProviderBuilder;
 import org.hibernate.testing.junit.functional.FunctionalTestClassTestSuite;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.util.JoinedIterator;
 import org.hibernate.util.SerializationHelper;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 
 public class FooBarTest extends LegacyTestCase {
 	private static final Logger log = LoggerFactory.getLogger( FooBarTest.class );
 
 	public FooBarTest(String arg) {
 		super(arg);
 	}
 
 	public String[] getMappings() {
 		return new String[] {
 			"legacy/FooBar.hbm.xml",
 			"legacy/Baz.hbm.xml",
 			"legacy/Qux.hbm.xml",
 			"legacy/Glarch.hbm.xml",
 			"legacy/Fum.hbm.xml",
 			"legacy/Fumm.hbm.xml",
 			"legacy/Fo.hbm.xml",
 			"legacy/One.hbm.xml",
 			"legacy/Many.hbm.xml",
 			"legacy/Immutable.hbm.xml",
 			"legacy/Fee.hbm.xml",
 			"legacy/Vetoer.hbm.xml",
 			"legacy/Holder.hbm.xml",
 			"legacy/Location.hbm.xml",
 			"legacy/Stuff.hbm.xml",
 			"legacy/Container.hbm.xml",
 			"legacy/Simple.hbm.xml",
 			"legacy/XY.hbm.xml"
 		};
 	}
 
 	public static Test suite() {
 		return new FunctionalTestClassTestSuite( FooBarTest.class );
 	}
 
 	public static void main(String[] args) throws Exception {
 		TestRunner.run( suite() );
 	}
 
 	public void testSaveOrUpdateCopyAny() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Bar bar = new Bar();
 		One one = new One();
 		bar.setObject(one);
 		s.save(bar);
 		GlarchProxy g = bar.getComponent().getGlarch();
 		bar.getComponent().setGlarch(null);
 		s.delete(g);
 		s.flush();
 		assertTrue( s.contains(one) );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Bar bar2 = (Bar) s.saveOrUpdateCopy(bar);
 		s.flush();
 		s.delete(bar2);
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testRefreshProxy() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Glarch g = new Glarch();
 		Serializable gid = s.save(g);
 		s.flush();
 		s.clear();
 		GlarchProxy gp = (GlarchProxy) s.load(Glarch.class, gid);
 		gp.getName(); //force init
 		s.refresh(gp);
 		s.delete(gp);
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testOnCascadeDelete() throws Exception {
 		if ( ! supportsCircularCascadeDelete() ) {
 			return;
 		}
 
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.subs = new ArrayList();
 		Baz sub = new Baz();
 		sub.superBaz = baz;
 		baz.subs.add(sub);
 		s.save(baz);
 		s.flush();
 		assertTrue( s.createQuery("from Baz").list().size()==2 );
 		s.getTransaction().commit();
 		s.beginTransaction();
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.beginTransaction();
 		assertTrue( s.createQuery("from Baz").list().size()==0 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testRemoveFromIdbag() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setByteBag( new ArrayList() );
 		byte[] bytes = { 12, 13 };
 		baz.getByteBag().add( new byte[] { 10, 45 } );
 		baz.getByteBag().add(bytes);
 		baz.getByteBag().add( new byte[] { 1, 11 } );
 		baz.getByteBag().add( new byte[] { 12 } );
 		s.save(baz);
 		s.flush();
 		baz.getByteBag().remove(bytes);
 		s.flush();
 		baz.getByteBag().add(bytes);
 		s.flush();
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testLoad() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Qux q = new Qux();
 		s.save(q);
 		BarProxy b = new Bar();
 		s.save(b);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		q = (Qux) s.load(Qux.class, q.getKey() );
 		b = (BarProxy) s.load( Foo.class, b.getKey() );
 		b.getKey();
 		assertFalse( Hibernate.isInitialized(b) );
 		b.getBarString();
 		assertTrue( Hibernate.isInitialized(b) );
 		BarProxy b2 = (BarProxy) s.load( Bar.class, b.getKey() );
 		Qux q2 = (Qux) s.load( Qux.class, q.getKey() );
 		assertTrue( "loaded same object", q==q2 );
 		assertTrue( "loaded same object", b==b2 );
 		assertTrue( Math.round( b.getFormula() ) == b.getInt()/2 );
 		s.delete(q2);
 		s.delete(b2);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testJoin() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		foo.setJoinedProp("foo");
 		s.save(foo);
 		s.flush();
 		foo.setJoinedProp("bar");
 		s.flush();
 		String fid = foo.getKey();
 		s.delete(foo);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Foo foo2 = new Foo();
 		foo2.setJoinedProp("foo");
 		s.save(foo2);
 		s.createQuery( "select foo.id from Foo foo where foo.joinedProp = 'foo'" ).list();
 		assertNull( s.get(Foo.class, fid) );
 		s.delete(foo2);
 		s.getTransaction().commit();
 		s.close();
 
 	}
 
 	public void testDereferenceLazyCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setFooSet( new HashSet() );
 		Foo foo = new Foo();
 		baz.getFooSet().add(foo);
 		s.save(foo);
 		s.save(baz);
 		foo.setBytes( "foobar".getBytes() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = (Foo) s.get( Foo.class, foo.getKey() );
 		assertTrue( Hibernate.isInitialized( foo.getBytes() ) );
 		assertTrue( foo.getBytes().length==6 );
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertTrue( baz.getFooSet().size()==1 );
 		s.getTransaction().commit();
 		s.close();
 
 		getSessions().evictCollection("org.hibernate.test.legacy.Baz.fooSet");
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertFalse( Hibernate.isInitialized( baz.getFooSet() ) );
 		baz.setFooSet(null);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = (Foo) s.get( Foo.class, foo.getKey() );
 		assertTrue( foo.getBytes().length==6 );
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertFalse( Hibernate.isInitialized( baz.getFooSet() ) );
 		assertTrue( baz.getFooSet().size()==0 );
 		s.delete(baz);
 		s.delete(foo);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testMoveLazyCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		Baz baz2 = new Baz();
 		baz.setFooSet( new HashSet() );
 		Foo foo = new Foo();
 		baz.getFooSet().add(foo);
 		s.save(foo);
 		s.save(baz);
 		s.save(baz2);
 		foo.setBytes( "foobar".getBytes() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = (Foo) s.get( Foo.class, foo.getKey() );
 		assertTrue( Hibernate.isInitialized( foo.getBytes() ) );
 		assertTrue( foo.getBytes().length==6 );
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertTrue( baz.getFooSet().size()==1 );
 		s.getTransaction().commit();
 		s.close();
 
 		getSessions().evictCollection("org.hibernate.test.legacy.Baz.fooSet");
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertFalse( Hibernate.isInitialized( baz.getFooSet() ) );
 		baz2 = (Baz) s.get( Baz.class, baz2.getCode() );
 		baz2.setFooSet( baz.getFooSet() );
 		baz.setFooSet(null);
 		assertFalse( Hibernate.isInitialized( baz2.getFooSet() ) );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = (Foo) s.get( Foo.class, foo.getKey() );
 		assertTrue( foo.getBytes().length==6 );
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		baz2 = (Baz) s.get( Baz.class, baz2.getCode() );
 		assertFalse( Hibernate.isInitialized( baz.getFooSet() ) );
 		assertTrue( baz.getFooSet().size()==0 );
 		assertTrue( Hibernate.isInitialized( baz2.getFooSet() ) ); //fooSet has batching enabled
 		assertTrue( baz2.getFooSet().size()==1 );
 		s.delete(baz);
 		s.delete(baz2);
 		s.delete(foo);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testCriteriaCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz bb = (Baz) s.createCriteria(Baz.class).uniqueResult();
 		assertTrue(bb==null);
 		Baz baz = new Baz();
 		s.save(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Baz b = (Baz) s.createCriteria(Baz.class).uniqueResult();
 		assertTrue( Hibernate.isInitialized( b.getTopGlarchez() ) );
 		assertTrue( b.getTopGlarchez().size()==0 );
 		s.delete(b);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testQuery() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		Foo foo2 = new Foo();
 		s.save(foo2);
 		foo.setFoo(foo2);
 
 		List list = s.createQuery( "from Foo foo inner join fetch foo.foo" ).list();
 		Foo foof = (Foo) list.get(0);
 		assertTrue( Hibernate.isInitialized( foof.getFoo() ) );
 
 		s.createQuery( "from Baz baz left outer join fetch baz.fooToGlarch" ).list();
 
 		list = s.createQuery( "select foo, bar from Foo foo left outer join foo.foo bar where foo = ?" )
 				.setParameter( 0, foo, Hibernate.entity(Foo.class) )
 				.list();
 		Object[] row1 = (Object[]) list.get(0);
 		assertTrue( row1[0]==foo && row1[1]==foo2 );
 
 		s.createQuery( "select foo.foo.foo.string from Foo foo where foo.foo = 'bar'" ).list();
 		s.createQuery( "select foo.foo.foo.foo.string from Foo foo where foo.foo = 'bar'" ).list();
 		s.createQuery( "select foo from Foo foo where foo.foo.foo = 'bar'" ).list();
 		s.createQuery( "select foo.foo.foo.foo.string from Foo foo where foo.foo.foo = 'bar'" ).list();
 		s.createQuery( "select foo.foo.foo.string from Foo foo where foo.foo.foo.foo.string = 'bar'" ).list();
 		if ( ! (getDialect() instanceof HSQLDialect) )
 			s.createQuery( "select foo.string from Foo foo where foo.foo.foo.foo = foo.foo.foo" ).list();
 		s.createQuery( "select foo.string from Foo foo where foo.foo.foo = 'bar' and foo.foo.foo.foo = 'baz'" ).list();
 		s.createQuery( "select foo.string from Foo foo where foo.foo.foo.foo.string = 'a' and foo.foo.string = 'b'" )
 				.list();
 
 		s.createQuery( "from Bar bar, foo in elements(bar.baz.fooArray)" ).list();
 
 		//s.find("from Baz as baz where baz.topComponents[baz].name = 'bazzz'");
 
 		if ( (getDialect() instanceof DB2Dialect) && !(getDialect() instanceof DerbyDialect) ) {
 			s.createQuery( "from Foo foo where lower( foo.foo.string ) = 'foo'" ).list();
 			s.createQuery( "from Foo foo where lower( (foo.foo.string || 'foo') || 'bar' ) = 'foo'" ).list();
 			s.createQuery( "from Foo foo where repeat( (foo.foo.string || 'foo') || 'bar', 2 ) = 'foo'" ).list();
 			s.createQuery(
 					"from Bar foo where foo.foo.integer is not null and repeat( (foo.foo.string || 'foo') || 'bar', (5+5)/2 ) = 'foo'"
 			).list();
 			s.createQuery(
 					"from Bar foo where foo.foo.integer is not null or repeat( (foo.foo.string || 'foo') || 'bar', (5+5)/2 ) = 'foo'"
 			).list();
 		}
 		if (getDialect() instanceof SybaseDialect) {
 			s.createQuery( "select baz from Baz as baz join baz.fooArray foo group by baz order by sum(foo.float)" )
 					.iterate();
 		}
 
 		s.createQuery( "from Foo as foo where foo.component.glarch.name is not null" ).list();
 		s.createQuery( "from Foo as foo left outer join foo.component.glarch as glarch where glarch.name = 'foo'" )
 				.list();
 
 		list = s.createQuery( "from Foo" ).list();
 		assertTrue( list.size()==2 && list.get(0) instanceof FooProxy );
 		list = s.createQuery( "from Foo foo left outer join foo.foo" ).list();
 		assertTrue( list.size()==2 && ( (Object[]) list.get(0) )[0] instanceof FooProxy );
 
 		s.createQuery("from Bar, Bar").list();
 		s.createQuery("from Foo, Bar").list();
 		s.createQuery( "from Baz baz left join baz.fooToGlarch, Bar bar join bar.foo" ).list();
 		s.createQuery( "from Baz baz left join baz.fooToGlarch join baz.fooSet" ).list();
 		s.createQuery( "from Baz baz left join baz.fooToGlarch join fetch baz.fooSet foo left join fetch foo.foo" )
 				.list();
 
 		list = s.createQuery(
 				"from Foo foo where foo.string='osama bin laden' and foo.boolean = true order by foo.string asc, foo.component.count desc"
 		).list();
 		assertTrue( "empty query", list.size()==0 );
 		Iterator iter = s.createQuery(
 				"from Foo foo where foo.string='osama bin laden' order by foo.string asc, foo.component.count desc"
 		).iterate();
 		assertTrue( "empty iterator", !iter.hasNext() );
 
 		list = s.createQuery( "select foo.foo from Foo foo" ).list();
 		assertTrue( "query", list.size()==1 );
 		assertTrue( "returned object", list.get(0)==foo.getFoo() );
 		foo.getFoo().setFoo(foo);
 		foo.setString("fizard");
 		//The following test is disabled for databases with no subselects...also for Interbase (not sure why).
 		if ( 
 				!(getDialect() instanceof MySQLDialect) && 
 				!(getDialect() instanceof HSQLDialect) && 
 				!(getDialect() instanceof MckoiDialect) && 
 				!(getDialect() instanceof SAPDBDialect) && 
 				!(getDialect() instanceof PointbaseDialect) &&
 				!(getDialect() instanceof DerbyDialect)
 		)  {
 			// && !db.equals("weblogic") {
 			if ( !( getDialect() instanceof InterbaseDialect ) ) {
 				list = s.createQuery( "from Foo foo where ? = some elements(foo.component.importantDates)" )
 						.setParameter( 0, new Date(), Hibernate.DATE )
 						.list();
 				assertTrue( "component query", list.size()==2 );
 			}
 			if( !( getDialect() instanceof TimesTenDialect)) {
 				list = s.createQuery( "from Foo foo where size(foo.component.importantDates) = 3" ).list(); //WAS: 4
 				assertTrue( "component query", list.size()==2 );
 				list = s.createQuery( "from Foo foo where 0 = size(foo.component.importantDates)" ).list();
 				assertTrue( "component query", list.size()==0 );
 			}
 			list = s.createQuery( "from Foo foo where exists elements(foo.component.importantDates)" ).list();
 			assertTrue( "component query", list.size()==2 );
 			s.createQuery( "from Foo foo where not exists (from Bar bar where bar.id = foo.id)" ).list();
 
 			s.createQuery(
 					"select foo.foo from Foo foo where foo = some(select x from Foo x where x.long > foo.foo.long)"
 			).list();
 			s.createQuery( "select foo.foo from Foo foo where foo = some(from Foo x where (x.long > foo.foo.long))" )
 					.list();
 			if ( !( getDialect() instanceof TimesTenDialect)) {
 				s.createQuery(
 						"select foo.foo from Foo foo where foo.long = some( select max(x.long) from Foo x where (x.long > foo.foo.long) group by x.foo )"
 				).list();
 			}
 			s.createQuery(
 					"from Foo foo where foo = some(select x from Foo x where x.long > foo.foo.long) and foo.foo.string='baz'"
 			).list();
 			s.createQuery(
 					"from Foo foo where foo.foo.string='baz' and foo = some(select x from Foo x where x.long > foo.foo.long)"
 			).list();
 			s.createQuery( "from Foo foo where foo = some(select x from Foo x where x.long > foo.foo.long)" ).list();
 
 			s.createQuery(
 					"select foo.string, foo.date, foo.foo.string, foo.id from Foo foo, Baz baz where foo in elements(baz.fooArray) and foo.string like 'foo'"
 			).iterate();
 		}
 		list = s.createQuery( "from Foo foo where foo.component.count is null order by foo.component.count" ).list();
 		assertTrue( "component query", list.size()==0 );
 		list = s.createQuery( "from Foo foo where foo.component.name='foo'" ).list();
 		assertTrue( "component query", list.size()==2 );
 		list = s.createQuery(
 				"select distinct foo.component.name, foo.component.name from Foo foo where foo.component.name='foo'"
 		).list();
 		assertTrue( "component query", list.size()==1 );
 		list = s.createQuery( "select distinct foo.component.name, foo.id from Foo foo where foo.component.name='foo'" )
 				.list();
 		assertTrue( "component query", list.size()==2 );
 		list = s.createQuery( "select foo.foo from Foo foo" ).list();
 		assertTrue( "query", list.size()==2 );
 		list = s.createQuery( "from Foo foo where foo.id=?" )
 				.setParameter( 0, foo.getKey(), Hibernate.STRING )
 				.list();
 		assertTrue( "id query", list.size()==1 );
 		list = s.createQuery( "from Foo foo where foo.key=?" )
 				.setParameter( 0, foo.getKey(), Hibernate.STRING )
 				.list();
 		assertTrue( "named id query", list.size()==1 );
 		assertTrue( "id query", list.get(0)==foo );
 		list = s.createQuery( "select foo.foo from Foo foo where foo.string='fizard'" ).list();
 		assertTrue( "query", list.size()==1 );
 		assertTrue( "returned object", list.get(0)==foo.getFoo() );
 		list = s.createQuery( "from Foo foo where foo.component.subcomponent.name='bar'" ).list();
 		assertTrue( "components of components", list.size()==2 );
 		list = s.createQuery( "select foo.foo from Foo foo where foo.foo.id=?" )
 				.setParameter( 0, foo.getFoo().getKey(), Hibernate.STRING )
 				.list();
 		assertTrue( "by id query", list.size()==1 );
 		assertTrue( "by id returned object", list.get(0)==foo.getFoo() );
 
 		s.createQuery( "from Foo foo where foo.foo = ?" ).setParameter( 0, foo.getFoo(), Hibernate.entity(Foo.class) ).list();
 
 		assertTrue( !s.createQuery( "from Bar bar where bar.string='a string' or bar.string='a string'" )
 				.iterate()
 				.hasNext() );
 
 		iter = s.createQuery( "select foo.component.name, elements(foo.component.importantDates) from Foo foo where foo.foo.id=?" )
 				.setParameter( 0, foo.getFoo().getKey(), Hibernate.STRING )
 				.iterate();
 		int i=0;
 		while ( iter.hasNext() ) {
 			i++;
 			Object[] row = (Object[]) iter.next();
 			assertTrue( row[0] instanceof String && ( row[1]==null || row[1] instanceof Date ) );
 		}
 		assertTrue(i==3); //WAS: 4
 		iter = s.createQuery( "select max( elements(foo.component.importantDates) ) from Foo foo group by foo.id" )
 				.iterate();
 		assertTrue( iter.next() instanceof Date );
 
 		list = s.createQuery(
 				"select foo.foo.foo.foo from Foo foo, Foo foo2 where"
 						+ " foo = foo2.foo and not not ( not foo.string='fizard' )"
 						+ " and foo2.string between 'a' and (foo.foo.string)"
 						+ ( ( getDialect() instanceof HSQLDialect || getDialect() instanceof InterbaseDialect || getDialect() instanceof TimesTenDialect ) ?
 						" and ( foo2.string in ( 'fiz', 'blah') or 1=1 )"
 						:
 						" and ( foo2.string in ( 'fiz', 'blah', foo.foo.string, foo.string, foo2.string ) )"
 				)
 		).list();
 		assertTrue( "complex query", list.size()==1 );
 		assertTrue( "returned object", list.get(0)==foo );
 		foo.setString("from BoogieDown  -tinsel town  =!@#$^&*())");
 		list = s.createQuery( "from Foo foo where foo.string='from BoogieDown  -tinsel town  =!@#$^&*())'" ).list();
 		assertTrue( "single quotes", list.size()==1 );
 		list = s.createQuery( "from Foo foo where not foo.string='foo''bar'" ).list();
 		assertTrue( "single quotes", list.size()==2 );
 		list = s.createQuery( "from Foo foo where foo.component.glarch.next is null" ).list();
 		assertTrue( "query association in component", list.size()==2 );
 		Bar bar = new Bar();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		bar.setBaz(baz);
 		baz.setManyToAny( new ArrayList() );
 		baz.getManyToAny().add(bar);
 		baz.getManyToAny().add(foo);
 		s.save(bar);
 		s.save(baz);
 		list = s.createQuery(
 				" from Bar bar where bar.baz.count=667 and bar.baz.count!=123 and not bar.baz.name='1-E-1'"
 		).list();
 		assertTrue( "query many-to-one", list.size()==1 );
 		list = s.createQuery( " from Bar i where i.baz.name='Bazza'" ).list();
 		assertTrue( "query many-to-one", list.size()==1 );
 
 		Iterator rs = s.createQuery( "select count(distinct foo.foo) from Foo foo" ).iterate();
 		assertTrue( "count", ( (Long) rs.next() ).longValue()==2 );
 		assertTrue( !rs.hasNext() );
 		rs = s.createQuery( "select count(foo.foo.boolean) from Foo foo" ).iterate();
 		assertTrue( "count", ( (Long) rs.next() ).longValue()==2 );
 		assertTrue( !rs.hasNext() );
 		rs = s.createQuery( "select count(*), foo.int from Foo foo group by foo.int" ).iterate();
 		assertTrue( "count(*) group by", ( (Object[]) rs.next() )[0].equals( new Long(3) ) );
 		assertTrue( !rs.hasNext() );
 		rs = s.createQuery( "select sum(foo.foo.int) from Foo foo" ).iterate();
 		assertTrue( "sum", ( (Long) rs.next() ).longValue()==4 );
 		assertTrue( !rs.hasNext() );
 		rs = s.createQuery( "select count(foo) from Foo foo where foo.id=?" )
 				.setParameter( 0, foo.getKey(), Hibernate.STRING )
 				.iterate();
 		assertTrue( "id query count", ( (Long) rs.next() ).longValue()==1 );
 		assertTrue( !rs.hasNext() );
 
 		s.createQuery( "from Foo foo where foo.boolean = ?" )
 				.setParameter( 0, new Boolean(true), Hibernate.BOOLEAN )
 				.list();
 
 		s.createQuery( "select new Foo(fo.x) from Fo fo" ).list();
 		s.createQuery( "select new Foo(fo.integer) from Foo fo" ).list();
 
 		list = s.createQuery("select new Foo(fo.x) from Foo fo")
 			//.setComment("projection test")
 			.setCacheable(true)
 			.list();
 		assertTrue(list.size()==3);
 		list = s.createQuery("select new Foo(fo.x) from Foo fo")
 			//.setComment("projection test 2")
 			.setCacheable(true)
 			.list();
 		assertTrue(list.size()==3);
 
 		rs = s.createQuery( "select new Foo(fo.x) from Foo fo" ).iterate();
 		assertTrue( "projection iterate (results)", rs.hasNext() );
 		assertTrue( "projection iterate (return check)", Foo.class.isAssignableFrom( rs.next().getClass() ) );
 
 		ScrollableResults sr = s.createQuery("select new Foo(fo.x) from Foo fo").scroll();
 		assertTrue( "projection scroll (results)", sr.next() );
 		assertTrue( "projection scroll (return check)", Foo.class.isAssignableFrom( sr.get(0).getClass() ) );
 
 		list = s.createQuery( "select foo.long, foo.component.name, foo, foo.foo from Foo foo" ).list();
 		rs = list.iterator();
 		int count=0;
 		while ( rs.hasNext() ) {
 			count++;
 			Object[] row = (Object[]) rs.next();
 			assertTrue( row[0] instanceof Long );
 			assertTrue( row[1] instanceof String );
 			assertTrue( row[2] instanceof Foo );
 			assertTrue( row[3] instanceof Foo );
 		}
 		assertTrue(count!=0);
 		list = s.createQuery( "select avg(foo.float), max(foo.component.name), count(distinct foo.id) from Foo foo" )
 				.list();
 		rs = list.iterator();
 		count=0;
 		while ( rs.hasNext() ) {
 			count++;
 			Object[] row = (Object[]) rs.next();
 			assertTrue( row[0] instanceof Double );
 			assertTrue( row[1] instanceof String );
 			assertTrue( row[2] instanceof Long );
 		}
 		assertTrue(count!=0);
 		list = s.createQuery( "select foo.long, foo.component, foo, foo.foo from Foo foo" ).list();
 		rs = list.iterator();
 		count=0;
 		while ( rs.hasNext() ) {
 			count++;
 			Object[] row = (Object[]) rs.next();
 			assertTrue( row[0] instanceof Long );
 			assertTrue( row[1] instanceof FooComponent );
 			assertTrue( row[2] instanceof Foo );
 			assertTrue( row[3] instanceof Foo );
 		}
 		assertTrue(count!=0);
 
 		s.save( new Holder("ice T") );
 		s.save( new Holder("ice cube") );
 
 		assertTrue( s.createQuery( "from java.lang.Object as o" ).list().size()==15 );
 		assertTrue( s.createQuery( "from Named" ).list().size()==7 );
 		assertTrue( s.createQuery( "from Named n where n.name is not null" ).list().size()==4 );
 		iter = s.createQuery( "from Named n" ).iterate();
 		while ( iter.hasNext() ) {
 			assertTrue( iter.next() instanceof Named );
 		}
 
 		s.save( new Holder("bar") );
 		iter = s.createQuery( "from Named n0, Named n1 where n0.name = n1.name" ).iterate();
 		int cnt = 0;
 		while ( iter.hasNext() ) {
 			Object[] row = (Object[]) iter.next();
 			if ( row[0]!=row[1] ) cnt++;
 		}
 		if ( !(getDialect() instanceof HSQLDialect) ) {
 			assertTrue(cnt==2);
 			assertTrue( s.createQuery( "from Named n0, Named n1 where n0.name = n1.name" ).list().size()==7 );
 		}
 
 		Query qu = s.createQuery("from Named n where n.name = :name");
 		qu.getReturnTypes();
 		qu.getNamedParameters();
 
 		iter = s.createQuery( "from java.lang.Object" ).iterate();
 		int c = 0;
 		while ( iter.hasNext() ) {
 			iter.next();
 			c++;
 		}
 		assertTrue(c==16);
 
 		s.createQuery( "select baz.code, min(baz.count) from Baz baz group by baz.code" ).iterate();
 
 		iter = s.createQuery( "selecT baz from Baz baz where baz.stringDateMap['foo'] is not null or baz.stringDateMap['bar'] = ?" )
 				.setParameter( 0, new Date(), Hibernate.DATE )
 				.iterate();
 		assertFalse( iter.hasNext() );
 		list = s.createQuery( "select baz from Baz baz where baz.stringDateMap['now'] is not null" ).list();
 		assertTrue( list.size()==1 );
 		list = s.createQuery(
 				"select baz from Baz baz where baz.stringDateMap['now'] is not null and baz.stringDateMap['big bang'] < baz.stringDateMap['now']"
 		).list();
 		assertTrue( list.size()==1 );
 		list = s.createQuery( "select index(date) from Baz baz join baz.stringDateMap date" ).list();
 		System.out.println(list);
 		assertTrue( list.size()==2 );
 
 		s.createQuery(
 				"from Foo foo where foo.integer not between 1 and 5 and foo.string not in ('cde', 'abc') and foo.string is not null and foo.integer<=3"
 		).list();
 
 		s.createQuery( "from Baz baz inner join baz.collectionComponent.nested.foos foo where foo.string is null" )
 				.list();
 		if ( !(getDialect() instanceof MySQLDialect) && !(getDialect() instanceof MckoiDialect) && !(getDialect() instanceof SAPDBDialect) && !(getDialect() instanceof PointbaseDialect) )  {
 			s.createQuery(
 					"from Baz baz inner join baz.fooSet where '1' in (from baz.fooSet foo where foo.string is not null)"
 			).list();
 			s.createQuery(
 					"from Baz baz where 'a' in elements(baz.collectionComponent.nested.foos) and 1.0 in elements(baz.collectionComponent.nested.floats)"
 			).list();
 			s.createQuery(
 					"from Baz baz where 'b' in elements(baz.collectionComponent.nested.foos) and 1.0 in elements(baz.collectionComponent.nested.floats)"
 			).list();
 		}
 
 		s.createQuery( "from Foo foo join foo.foo where foo.foo in ('1','2','3')" ).list();
 		if ( !(getDialect() instanceof HSQLDialect) )
 			s.createQuery( "from Foo foo left join foo.foo where foo.foo in ('1','2','3')" ).list();
 		s.createQuery( "select foo.foo from Foo foo where foo.foo in ('1','2','3')" ).list();
 		s.createQuery( "select foo.foo.string from Foo foo where foo.foo in ('1','2','3')" ).list();
 		s.createQuery( "select foo.foo.string from Foo foo where foo.foo.string in ('1','2','3')" ).list();
 		s.createQuery( "select foo.foo.long from Foo foo where foo.foo.string in ('1','2','3')" ).list();
 		s.createQuery( "select count(*) from Foo foo where foo.foo.string in ('1','2','3') or foo.foo.long in (1,2,3)" )
 				.list();
 		s.createQuery( "select count(*) from Foo foo where foo.foo.string in ('1','2','3') group by foo.foo.long" )
 				.list();
 
 		s.createQuery( "from Foo foo1 left join foo1.foo foo2 left join foo2.foo where foo1.string is not null" )
 				.list();
 		s.createQuery( "from Foo foo1 left join foo1.foo.foo where foo1.string is not null" ).list();
 		s.createQuery( "from Foo foo1 left join foo1.foo foo2 left join foo1.foo.foo foo3 where foo1.string is not null" )
 				.list();
 
 		s.createQuery( "select foo.formula from Foo foo where foo.formula > 0" ).list();
 
 		int len = s.createQuery( "from Foo as foo join foo.foo as foo2 where foo2.id >'a' or foo2.id <'a'" ).list().size();
 		assertTrue(len==2);
 
 		s.delete("from Holder");
 
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		baz = (Baz) s.createQuery("from Baz baz left outer join fetch baz.manyToAny").uniqueResult();
 		assertTrue( Hibernate.isInitialized( baz.getManyToAny() ) );
 		assertTrue( baz.getManyToAny().size()==2 );
 		BarProxy barp = (BarProxy) baz.getManyToAny().get(0);
 		s.createQuery( "from Baz baz join baz.manyToAny" ).list();
 		assertTrue( s.createQuery( "select baz from Baz baz join baz.manyToAny a where index(a) = 0" ).list().size()==1 );
 
 		FooProxy foop = (FooProxy) s.get( Foo.class, foo.getKey() );
 		assertTrue( foop == baz.getManyToAny().get(1) );
 
 		barp.setBaz(baz);
 		assertTrue(
 				s.createQuery( "select bar from Bar bar where bar.baz.stringDateMap['now'] is not null" ).list().size()==1 );
 		assertTrue(
 				s.createQuery(
 						"select bar from Bar bar join bar.baz b where b.stringDateMap['big bang'] < b.stringDateMap['now'] and b.stringDateMap['now'] is not null"
 				).list()
 						.size()==1 );
 		assertTrue(
 				s.createQuery(
 						"select bar from Bar bar where bar.baz.stringDateMap['big bang'] < bar.baz.stringDateMap['now'] and bar.baz.stringDateMap['now'] is not null"
 				).list()
 						.size()==1 );
 
 		list = s.createQuery( "select foo.string, foo.component, foo.id from Bar foo" ).list();
 		assertTrue ( ( (FooComponent) ( (Object[]) list.get(0) )[1] ).getName().equals("foo") );
 		list = s.createQuery( "select elements(baz.components) from Baz baz" ).list();
 		assertTrue( list.size()==2 );
 		list = s.createQuery( "select bc.name from Baz baz join baz.components bc" ).list();
 		assertTrue( list.size()==2 );
 		//list = s.find("select bc from Baz baz join baz.components bc");
 
 		s.createQuery("from Foo foo where foo.integer < 10 order by foo.string").setMaxResults(12).list();
 
 		s.delete(barp);
 		s.delete(baz);
 		s.delete( foop.getFoo() );
 		s.delete(foop);
 		txn.commit();
 		s.close();
 	}
 
 	public void testCascadeDeleteDetached() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		List list = new ArrayList();
 		list.add( new Fee() );
 		baz.setFees(list);
 		s.save(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		s.getTransaction().commit();
 		s.close();
 
 		assertFalse( Hibernate.isInitialized( baz.getFees() ) );
 
 		s = openSession();
 		s.beginTransaction();
 		s.delete(baz);
 		s.flush();
 		assertFalse( s.createQuery( "from Fee" ).iterate().hasNext() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = new Baz();
 		list = new ArrayList();
 		list.add( new Fee() );
 		list.add( new Fee() );
 		baz.setFees(list);
 		s.save(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		Hibernate.initialize( baz.getFees() );
 		s.getTransaction().commit();
 		s.close();
 
 		assertTrue( baz.getFees().size()==2 );
 
 		s = openSession();
 		s.beginTransaction();
 		s.delete(baz);
 		s.flush();
 		assertFalse( s.createQuery( "from Fee" ).iterate().hasNext() );
 		s.getTransaction().commit();
 		s.close();
 
 	}
 
 	public void testForeignKeys() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		Foo foo = new Foo();
 		List bag = new ArrayList();
 		bag.add(foo);
 		baz.setIdFooBag(bag);
 		baz.setFoo(foo);
 		s.save(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testNonlazyCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		s.save(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.createCriteria(Baz.class)
 			//.setComment("criteria test")
 			.setFetchMode( "stringDateMap", FetchMode.JOIN )
 			.uniqueResult();
 		assertTrue( Hibernate.isInitialized( baz.getFooToGlarch() ) );
 		assertTrue( Hibernate.isInitialized( baz.getFooComponentToFoo() ) );
 		assertTrue( !Hibernate.isInitialized( baz.getStringSet() ) );
 		assertTrue( Hibernate.isInitialized( baz.getStringDateMap() ) );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 
 	}
 
 	public void testReuseDeletedCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		s.flush();
 		s.delete(baz);
 		Baz baz2 = new Baz();
 		baz2.setStringArray( new String[] {"x-y-z"} );
 		s.save(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 		baz2.setStringSet( baz.getStringSet() );
 		baz2.setStringArray( baz.getStringArray() );
 		baz2.setFooArray( baz.getFooArray() );
 
 		s = openSession();
 		s.beginTransaction();
 		s.update(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		assertTrue( baz2.getStringArray().length==3 );
 		assertTrue( baz2.getStringSet().size()==3 );
 		s.delete(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 
 	}
 
 	public void testPropertyRef() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Holder h = new Holder();
 		h.setName("foo");
 		Holder h2 = new Holder();
 		h2.setName("bar");
 		h.setOtherHolder(h2);
 		Serializable hid = s.save(h);
 		Qux q = new Qux();
 		q.setHolder(h2);
 		Serializable qid = s.save(q);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		h = (Holder) s.load(Holder.class, hid);
 		assertEquals( h.getName(), "foo");
 		assertEquals( h.getOtherHolder().getName(), "bar");
 		Object[] res = (Object[]) s.createQuery( "from Holder h join h.otherHolder oh where h.otherHolder.name = 'bar'" )
 				.list()
 				.get(0);
 		assertTrue( res[0]==h );
 		q = (Qux) s.get(Qux.class, qid);
 		assertTrue( q.getHolder() == h.getOtherHolder() );
 		s.delete(h);
 		s.delete(q);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testQueryCollectionOfValues() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		Glarch g = new Glarch();
 		Serializable gid = s.save(g);
 
 		if ( !(getDialect() instanceof MySQLDialect) && !(getDialect() instanceof HSQLDialect) /*&& !(dialect instanceof MckoiDialect)*/ && !(getDialect() instanceof SAPDBDialect) && !(getDialect() instanceof PointbaseDialect) && !(getDialect() instanceof TimesTenDialect) ) {
 			s.createFilter( baz.getFooArray(), "where size(this.bytes) > 0" ).list();
 			s.createFilter( baz.getFooArray(), "where 0 in elements(this.bytes)" ).list();
 		}
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.createQuery( "from Baz baz join baz.fooSet foo join foo.foo.foo foo2 where foo2.string = 'foo'" ).list();
 		s.createQuery( "from Baz baz join baz.fooArray foo join foo.foo.foo foo2 where foo2.string = 'foo'" ).list();
 		s.createQuery( "from Baz baz join baz.stringDateMap date where index(date) = 'foo'" ).list();
 		s.createQuery( "from Baz baz join baz.topGlarchez g where index(g) = 'A'" ).list();
 		s.createQuery( "select index(g) from Baz baz join baz.topGlarchez g" ).list();
 
 		assertTrue( s.createQuery( "from Baz baz left join baz.stringSet" ).list().size()==3 );
 		baz = (Baz) s.createQuery( "from Baz baz join baz.stringSet str where str='foo'" ).list().get(0);
 		assertTrue( !Hibernate.isInitialized( baz.getStringSet() ) );
 		baz = (Baz) s.createQuery( "from Baz baz left join fetch baz.stringSet" ).list().get(0);
 		assertTrue( Hibernate.isInitialized( baz.getStringSet() ) );
 		assertTrue( s.createQuery( "from Baz baz join baz.stringSet string where string='foo'" ).list().size()==1 );
 		assertTrue( s.createQuery( "from Baz baz inner join baz.components comp where comp.name='foo'" ).list().size()==1 );
 		//List bss = s.find("select baz, ss from Baz baz inner join baz.stringSet ss");
 		s.createQuery( "from Glarch g inner join g.fooComponents comp where comp.fee is not null" ).list();
 		s.createQuery( "from Glarch g inner join g.fooComponents comp join comp.fee fee where fee.count > 0" ).list();
 		s.createQuery( "from Glarch g inner join g.fooComponents comp where comp.fee.count is not null" ).list();
 
 		s.delete(baz);
 		s.delete( s.get(Glarch.class, gid) );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testBatchLoad() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		SortedSet stringSet = new TreeSet();
 		stringSet.add("foo");
 		stringSet.add("bar");
 		Set fooSet = new HashSet();
 		for (int i=0; i<3; i++) {
 			Foo foo = new Foo();
 			s.save(foo);
 			fooSet.add(foo);
 		}
 		baz.setFooSet(fooSet);
 		baz.setStringSet(stringSet);
 		s.save(baz);
 		Baz baz2 = new Baz();
 		fooSet = new HashSet();
 		for (int i=0; i<2; i++) {
 			Foo foo = new Foo();
 			s.save(foo);
 			fooSet.add(foo);
 		}
 		baz2.setFooSet(fooSet);
 		s.save(baz2);
 		Baz baz3 = new Baz();
 		stringSet = new TreeSet();
 		stringSet.add("foo");
 		stringSet.add("baz");
 		baz3.setStringSet(stringSet);
 		s.save(baz3);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
@@ -3349,1511 +3348,1510 @@ public class FooBarTest extends LegacyTestCase {
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		iter = s.createQuery( "from Glarch g order by g.order asc" ).iterate();
 		while ( iter.hasNext() ) {
 			GlarchProxy g = (GlarchProxy) iter.next();
 			assertTrue( "not null", g!=null );
 			iter.remove();
 		}
 		txn.commit();
 		s.close();
 
 		//Same thing but using polymorphic class (no optimisation possible):
 		s = openSession();
 		txn = s.beginTransaction();
 		FooProxy flast = new Bar();
 		s.save(flast);
 		flast.setString( "foo0" );
 		for (int i=0; i<5; i++) {
 			FooProxy foo = new Bar();
 			s.save(foo);
 			flast.setFoo(foo);
 			flast = flast.getFoo();
 			flast.setString( "foo" + (i+1) );
 		}
 		iter = s.createQuery( "from Foo foo" ).iterate();
 		while ( iter.hasNext() ) {
 			iter.next();
 		}
 		list = s.createQuery( "from Foo foo" ).list();
 		assertTrue( "recursive find", list.size()==6 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		list = s.createQuery( "from Foo foo" ).list();
 		assertTrue( "recursive iter", list.size()==6 );
 		iter = list.iterator();
 		while ( iter.hasNext() ) {
 			assertTrue( "polymorphic recursive load", iter.next() instanceof BarProxy );
 		}
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		iter = s.createQuery( "from Foo foo order by foo.string asc" ).iterate();
 		while ( iter.hasNext() ) {
 			BarProxy bar = (BarProxy) iter.next();
 			assertTrue( "not null", bar!=null );
 			iter.remove();
 		}
 		txn.commit();
 		s.close();
 	}
 
 	public void testScrollableIterator() throws Exception {
 		// skip if not one of these named dialects
 		boolean match = getDialect() instanceof DB2Dialect
 				|| getDialect() instanceof SybaseDialect
 				|| getDialect() instanceof HSQLDialect
 				|| getDialect() instanceof Oracle8iDialect // 9i/10g too because of inheritence...
 				;
 		if ( ! match ) {
 			return;
 		}
 
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		s.save( new Foo() );
 		s.save( new Foo() );
 		s.save( new Foo() );
 		s.save( new Bar() );
 		Query query = s.createQuery("select f, f.integer from Foo f");
 		assertTrue( query.getReturnTypes().length==2 );
 		ScrollableResults iter = query.scroll();
 		assertTrue( iter.next() );
 		assertTrue( iter.scroll(1) );
 		FooProxy f2 = (FooProxy) iter.get()[0];
 		assertTrue( f2!=null );
 		assertTrue( iter.scroll(-1) );
 		Object f1 = iter.get(0);
 		iter.next();
 		assertTrue( f1!=null && iter.get(0)==f2 );
 		iter.getInteger(1);
 
 		assertTrue( !iter.scroll(100) );
 		assertTrue( iter.first() );
 		assertTrue( iter.scroll(3) );
 		Object f4 = iter.get(0);
 		assertTrue( f4!=null );
 		assertTrue( !iter.next() );
 		assertTrue( iter.first() );
 		assertTrue( iter.get(0)==f1 );
 		assertTrue( iter.last() );
 		assertTrue( iter.get(0)==f4 );
 		assertTrue( iter.previous() );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		query = s.createQuery("select f, f.integer from Foo f");
 		assertTrue( query.getReturnTypes().length==2 );
 		iter = query.scroll();
 		assertTrue( iter.next() );
 		assertTrue( iter.scroll(1) );
 		f2 = (FooProxy) iter.get()[0];
 		assertTrue( f2!=null );
 		assertTrue( f2.getString()!=null  && f2.getComponent().getImportantDates().length > 0 );
 		assertTrue( iter.scroll(-1) );
 		f1 = iter.get(0);
 		iter.next();
 		assertTrue( f1!=null && iter.get(0)==f2 );
 		iter.getInteger(1);
 
 		assertTrue( !iter.scroll(100) );
 		assertTrue( iter.first() );
 		assertTrue( iter.scroll(3) );
 		f4 = iter.get(0);
 		assertTrue( f4!=null );
 		assertTrue( !iter.next() );
 		assertTrue( iter.first() );
 		assertTrue( iter.get(0)==f1 );
 		assertTrue( iter.last() );
 		assertTrue( iter.get(0)==f4 );
 		assertTrue( iter.previous() );
 		assertTrue( s.delete("from Foo")==4 );
 		s.flush();
 		assertTrue( s.createQuery( "from java.lang.Object" ).list().size()==0 );
 		txn.commit();
 		s.close();
 	}
 
 	public void testMultiColumnQueries() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		Foo foo1 = new Foo();
 		s.save(foo1);
 		foo.setFoo(foo1);
 		List l = s.createQuery( "select parent, child from Foo parent, Foo child where parent.foo = child" ).list();
 		assertTrue( "multi-column find", l.size()==1 );
 
 		Iterator rs = s.createQuery(
 				"select count(distinct child.id), count(distinct parent.id) from Foo parent, Foo child where parent.foo = child"
 		).iterate();
 		Object[] row = (Object[]) rs.next();
 		assertTrue( "multi-column count", ( (Long) row[0] ).intValue()==1 );
 		assertTrue( "multi-column count", ( (Long) row[1] ).intValue()==1 );
 		assertTrue( !rs.hasNext() );
 
 		rs = s.createQuery( "select child.id, parent.id, child.long from Foo parent, Foo child where parent.foo = child" )
 				.iterate();
 		row = (Object[]) rs.next();
 		assertTrue( "multi-column id", row[0].equals( foo.getFoo().getKey() ) );
 		assertTrue( "multi-column id", row[1].equals( foo.getKey() ) );
 		assertTrue( "multi-column property", row[2].equals( foo.getFoo().getLong() ) );
 		assertTrue( !rs.hasNext() );
 
 		rs = s.createQuery(
 				"select child.id, parent.id, child.long, child, parent.foo from Foo parent, Foo child where parent.foo = child"
 		).iterate();
 		row = (Object[]) rs.next();
 		assertTrue(
 			foo.getFoo().getKey().equals( row[0] ) &&
 			foo.getKey().equals( row[1] ) &&
 			foo.getFoo().getLong().equals( row[2] ) &&
 			row[3] == foo.getFoo() &&
 			row[3]==row[4]
 		);
 		assertTrue( !rs.hasNext() );
 
 		row = (Object[]) l.get(0);
 		assertTrue( "multi-column find", row[0]==foo && row[1]==foo.getFoo() );
 		txn.commit();
 		s.close();
 		
 		s = openSession();
 		txn = s.beginTransaction();
 		Iterator iter = s.createQuery(
 				"select parent, child from Foo parent, Foo child where parent.foo = child and parent.string='a string'"
 		).iterate();
 		int deletions=0;
 		while ( iter.hasNext() ) {
 			Object[] pnc = (Object[]) iter.next();
 			s.delete( pnc[0] );
 			s.delete( pnc[1] );
 			deletions++;
 		}
 		assertTrue("multi-column iterate", deletions==1);
 		txn.commit();
 		s.close();
 	}
 
 	public void testDeleteTransient() throws Exception {
 		Fee fee = new Fee();
 		Fee fee2 = new Fee();
 		fee2.setAnotherFee(fee);
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		s.save(fee);
 		s.save(fee2);
 		s.flush();
 		fee.setCount(123);
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		s.delete(fee);
 		s.delete(fee2);
 		//foo.setAnotherFee(null);
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		assertTrue( s.createQuery( "from Fee fee" ).list().size()==0 );
 		tx.commit();
 		s.close();
 	}
 
 	public void testDeleteUpdatedTransient() throws Exception {
 		Fee fee = new Fee();
 		Fee fee2 = new Fee();
 		fee2.setAnotherFee(fee);
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		s.save(fee);
 		s.save(fee2);
 		s.flush();
 		fee.setCount(123);
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		s.update(fee);
 		//fee2.setAnotherFee(null);
 		s.update(fee2);
 		s.delete(fee);
 		s.delete(fee2);
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		assertTrue( s.createQuery( "from Fee fee" ).list().size()==0 );
 		tx.commit();
 		s.close();
 	}
 
 	public void testUpdateOrder() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Fee fee1 = new Fee();
 		s.save(fee1);
 		Fee fee2 = new Fee();
 		fee1.setFee(fee2);
 		fee2.setFee(fee1);
 		fee2.setFees( new HashSet() );
 		Fee fee3 = new Fee();
 		fee3.setFee(fee1);
 		fee3.setAnotherFee(fee2);
 		fee2.setAnotherFee(fee3);
 		s.save(fee3);
 		s.save(fee2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		fee1.setCount(10);
 		fee2.setCount(20);
 		fee3.setCount(30);
 		s.update(fee1);
 		s.update(fee2);
 		s.update(fee3);
 		s.flush();
 		s.delete(fee1);
 		s.delete(fee2);
 		s.delete(fee3);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		assertTrue( s.createQuery( "from Fee fee" ).list().size()==0 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testUpdateFromTransient() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Fee fee1 = new Fee();
 		s.save(fee1);
 		Fee fee2 = new Fee();
 		fee1.setFee(fee2);
 		fee2.setFee(fee1);
 		fee2.setFees( new HashSet() );
 		Fee fee3 = new Fee();
 		fee3.setFee(fee1);
 		fee3.setAnotherFee(fee2);
 		fee2.setAnotherFee(fee3);
 		s.save(fee3);
 		s.save(fee2);
 		s.getTransaction().commit();
 		s.close();
 
 		fee1.setFi("changed");
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee1);
 		s.getTransaction().commit();
 		s.close();
 
 		Qux q = new Qux("quxxy");
 		q.setTheKey(0);
 		fee1.setQux(q);
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee1);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		fee1 = (Fee) s.load( Fee.class, fee1.getKey() );
 		assertTrue( "updated from transient", fee1.getFi().equals("changed") );
 		assertTrue( "unsaved value", fee1.getQux()!=null );
 		s.delete( fee1.getQux() );
 		fee1.setQux(null);
 		s.getTransaction().commit();
 		s.close();
 
 		fee2.setFi("CHANGED");
 		fee2.getFees().add("an element");
 		fee1.setFi("changed again");
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee2);
 		s.update( fee1, fee1.getKey() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Fee fee = new Fee();
 		s.load( fee, fee2.getKey() );
 		fee1 = (Fee) s.load( Fee.class, fee1.getKey() );
 		assertTrue( "updated from transient", fee1.getFi().equals("changed again") );
 		assertTrue( "updated from transient", fee.getFi().equals("CHANGED") );
 		assertTrue( "updated collection", fee.getFees().contains("an element") );
 		s.getTransaction().commit();
 		s.close();
 
 		fee.getFees().clear();
 		fee.getFees().add("new element");
 		fee1.setFee(null);
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee);
 		s.saveOrUpdate(fee1);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.load( fee, fee.getKey() );
 		assertTrue( "update", fee.getAnotherFee()!=null );
 		assertTrue( "update", fee.getFee()!=null );
 		assertTrue( "update", fee.getAnotherFee().getFee()==fee.getFee() );
 		assertTrue( "updated collection", fee.getFees().contains("new element") );
 		assertTrue( "updated collection", !fee.getFees().contains("an element") );
 		s.getTransaction().commit();
 		s.close();
 
 		fee.setQux( new Qux("quxy") );
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee);
 		s.getTransaction().commit();
 		s.close();
 
 		fee.getQux().setStuff("xxx");
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.load( fee, fee.getKey() );
 		assertTrue( "cascade update", fee.getQux()!=null );
 		assertTrue( "cascade update", fee.getQux().getStuff().equals("xxx") );
 		assertTrue( "update", fee.getAnotherFee()!=null );
 		assertTrue( "update", fee.getFee()!=null );
 		assertTrue( "update", fee.getAnotherFee().getFee()==fee.getFee() );
 		fee.getAnotherFee().setAnotherFee(null);
 		s.delete(fee);
 		doDelete( s, "from Fee fee" );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		assertTrue( s.createQuery( "from Fee fee" ).list().size()==0 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testArraysOfTimes() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz() ;
 		s.save(baz);
 		baz.setDefaults();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz.getTimeArray()[2] = new Date(123);
 		baz.getTimeArray()[3] = new java.sql.Time(1234);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testComponents() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		Foo foo = new Foo();
 		foo.setComponent( new FooComponent("foo", 69, null, new FooComponent("bar", 96, null, null) ) );
 		s.save(foo);
 		foo.getComponent().setName("IFA");
 		txn.commit();
 		s.close();
 
 		foo.setComponent(null);
 
 		s = openSession();
 		txn = s.beginTransaction();
 		s.load( foo, foo.getKey() );
 		assertTrue(
 			"save components",
 			foo.getComponent().getName().equals("IFA") &&
 			foo.getComponent().getSubcomponent().getName().equals("bar")
 		);
 		assertTrue( "cascade save via component", foo.getComponent().getGlarch()!=null);
 		foo.getComponent().getSubcomponent().setName("baz");
 		txn.commit();
 		s.close();
 
 		foo.setComponent(null);
 
 		s = openSession();
 		txn = s.beginTransaction();
 		s.load( foo, foo.getKey() );
 		assertTrue(
 			"update components",
 			foo.getComponent().getName().equals("IFA") &&
 			foo.getComponent().getSubcomponent().getName().equals("baz")
 		);
 		s.delete(foo);
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		foo = new Foo();
 		s.save(foo);
 		foo.setCustom( new String[] { "one", "two" } );
 		assertTrue( s.createQuery( "from Foo foo where foo.custom.s1 = 'one'" ).list().get(0)==foo );
 		s.delete(foo);
 		txn.commit();
 		s.close();
 
 	}
 
 	public void testNoForeignKeyViolations() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Glarch g1 = new Glarch();
 		Glarch g2 = new Glarch();
 		g1.setNext(g2);
 		g2.setNext(g1);
 		s.save(g1);
 		s.save(g2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		List l = s.createQuery( "from Glarch g where g.next is not null" ).list();
 		s.delete( l.get(0) );
 		s.delete( l.get(1) );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testLazyCollections() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Qux q = new Qux();
 		s.save(q);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		q = (Qux) s.load( Qux.class, q.getKey() );
 		s.getTransaction().commit();
 		s.close();
 
 		System.out.println("Two exceptions are supposed to occur:");
 		boolean ok = false;
 		try {
 			q.getMoreFums().isEmpty();
 		}
 		catch (LazyInitializationException e) {
 			ok = true;
 		}
 		assertTrue( "lazy collection with one-to-many", ok );
 
 		ok = false;
 		try {
 			q.getFums().isEmpty();
 		}
 		catch (LazyInitializationException e) {
 			ok = true;
 		}
 		assertTrue( "lazy collection with many-to-many", ok );
 
 		s = openSession();
 		s.beginTransaction();
 		q = (Qux) s.load( Qux.class, q.getKey() );
 		s.delete(q);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testNewSessionLifecycle() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Serializable fid = null;
 		try {
 			Foo f = new Foo();
 			s.save(f);
 			fid = s.getIdentifier(f);
 			s.getTransaction().commit();
 		}
 		catch (Exception e) {
 			s.getTransaction().rollback();
 			throw e;
 		}
 		finally {
 			s.close();
 		}
 
 		s = openSession();
 		s.beginTransaction();
 		try {
 			Foo f = new Foo();
 			s.delete(f);
 			s.getTransaction().commit();
 		}
 		catch (Exception e) {
 			s.getTransaction().rollback();
 		}
 		finally {
 			s.close();
 		}
 
 		s = openSession();
 		s.beginTransaction();
 		try {
 			Foo f = (Foo) s.load(Foo.class, fid, LockMode.UPGRADE);
 			s.delete(f);
 			s.flush();
 			s.getTransaction().commit();
 		}
 		catch (Exception e) {
 			s.getTransaction().rollback();
 			throw e;
 		}
 		finally {
 			assertTrue( s.close()==null );
 		}
 	}
 
 	public void testDisconnect() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		Foo foo2 = new Foo();
 		s.save(foo);
 		s.save(foo2);
 		foo2.setFoo(foo);
 		s.getTransaction().commit();
 
 		s.disconnect();
 		s.reconnect();
 
 		s.beginTransaction();
 		s.delete(foo);
 		foo2.setFoo(null);
 		s.getTransaction().commit();
 
 		s.disconnect();
 		s.reconnect();
 
 		s.beginTransaction();
 		s.delete(foo2);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 
 
 	public void testOrderBy() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		List list = s.createQuery(
 				"select foo from Foo foo, Fee fee where foo.dependent = fee order by foo.string desc, foo.component.count asc, fee.id"
 		).list();
 		assertTrue( "order by", list.size()==1 );
 		Foo foo2 = new Foo();
 		s.save(foo2);
 		foo.setFoo(foo2);
 		list = s.createQuery(
 				"select foo.foo, foo.dependent from Foo foo order by foo.foo.string desc, foo.component.count asc, foo.dependent.id"
 		).list();
 		assertTrue( "order by", list.size()==1 );
 		list = s.createQuery( "select foo from Foo foo order by foo.dependent.id, foo.dependent.fi" ).list();
 		assertTrue( "order by", list.size()==2 );
 		s.delete(foo);
 		s.delete(foo2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Many manyB = new Many();
 		s.save(manyB);
 		One oneB = new One();
 		s.save(oneB);
 		oneB.setValue("b");
 		manyB.setOne(oneB);
 		Many manyA = new Many();
 		s.save(manyA);
 		One oneA = new One();
 		s.save(oneA);
 		oneA.setValue("a");
 		manyA.setOne(oneA);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		List results = s.createQuery( "SELECT one FROM " + One.class.getName() + " one ORDER BY one.value ASC" ).list();
 		assertEquals( 2, results.size() );
 		assertEquals( "'a' isn't first element", "a", ( (One) results.get(0) ).getValue() );
 		assertEquals( "'b' isn't second element", "b", ( (One) results.get(1) ).getValue() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		results = s.createQuery( "SELECT many.one FROM " + Many.class.getName() + " many ORDER BY many.one.value ASC, many.one.id" )
 				.list();
 		assertEquals( 2, results.size() );
 		assertEquals( 2, results.size() );
 		assertEquals( "'a' isn't first element", "a", ( (One) results.get(0) ).getValue() );
 		assertEquals( "'b' isn't second element", "b", ( (One) results.get(1) ).getValue() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		oneA = (One)s.load(One.class, oneA.getKey());
 		manyA = (Many)s.load(Many.class, manyA.getKey());
 		oneB = (One)s.load(One.class, oneB.getKey());
 		manyB = (Many)s.load(Many.class, manyB.getKey());
 		s.delete(manyA);
 		s.delete(oneA);
 		s.delete(manyB);
 		s.delete(oneB);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testManyToOne() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		One one = new One();
 		s.save(one);
 		one.setValue("yada");
 		Many many = new Many();
 		many.setOne(one);
 		s.save(many);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		one = (One) s.load( One.class, one.getKey() );
 		one.getManies().size();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		many = (Many) s.load( Many.class, many.getKey() );
 		assertTrue( "many-to-one assoc", many.getOne()!=null );
 		s.delete( many.getOne() );
 		s.delete(many);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testSaveDelete() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo f = new Foo();
 		s.save(f);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.delete( s.load( Foo.class, f.getKey() ) );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testProxyArray() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		GlarchProxy g = new Glarch();
 		Glarch g1 = new Glarch();
 		Glarch g2 = new Glarch();
 		g.setProxyArray( new GlarchProxy[] { g1, g2 } );
 		Glarch g3 = new Glarch();
 		s.save(g3);
 		g2.setProxyArray( new GlarchProxy[] {null, g3, g} );
 		Set set = new HashSet();
 		set.add(g1);
 		set.add(g2);
 		g.setProxySet(set);
 		s.save(g);
 		s.save(g1);
 		s.save(g2);
 		Serializable id = s.getIdentifier(g);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, id);
 		assertTrue( "array of proxies", g.getProxyArray().length==2 );
 		assertTrue( "array of proxies", g.getProxyArray()[0]!=null );
 		assertTrue("deferred load test",g.getProxyArray()[1].getProxyArray()[0]==null );
 		assertTrue("deferred load test",g.getProxyArray()[1].getProxyArray()[2]==g );
 		assertTrue( "set of proxies", g.getProxySet().size()==2 );
 		Iterator iter = s.createQuery( "from Glarch g" ).iterate();
 		while ( iter.hasNext() ) {
 			iter.next();
 			iter.remove();
 		}
 		s.getTransaction().commit();
 		s.disconnect();
 		SerializationHelper.deserialize( SerializationHelper.serialize(s) );
 		s.close();
 	}
 
 	public void testCache() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Immutable im = new Immutable();
 		s.save(im);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.load( im, im.getId() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.load( im, im.getId() );
 		assertEquals(
 				"cached object identity",
 				im,
 				s.createQuery( "from Immutable im where im = ?" ).setParameter( 0, im, Hibernate.entity(Immutable.class) ).uniqueResult()
 		);
 		s.connection().createStatement().executeUpdate("delete from immut");
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testFindLoad() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		FooProxy foo = new Foo();
 		s.save(foo);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = (FooProxy) s.createQuery( "from Foo foo" ).list().get(0);
 		FooProxy foo2 = (FooProxy) s.load( Foo.class, foo.getKey() );
 		assertTrue("find returns same object as load", foo==foo2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo2 = (FooProxy) s.load( Foo.class, foo.getKey() );
 		foo = (FooProxy) s.createQuery( "from Foo foo" ).list().get(0);
 		assertTrue("find returns same object as load", foo==foo2);
 		doDelete( s, "from Foo foo" );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testRefresh() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		s.flush();
 		s.connection().createStatement().executeUpdate("update "+getDialect().openQuote()+"foos"+getDialect().closeQuote()+" set long_ = -3");
 		s.refresh(foo);
 		assertTrue( foo.getLong().longValue()==-3l );
 		assertTrue( s.getCurrentLockMode(foo)==LockMode.READ );
 		s.refresh(foo, LockMode.UPGRADE);
 		if ( getDialect().supportsOuterJoinForUpdate() ) {
 			assertTrue( s.getCurrentLockMode(foo)==LockMode.UPGRADE );
 		}
 		s.delete(foo);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testAutoFlush() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		FooProxy foo = new Foo();
 		s.save(foo);
 		assertTrue( "autoflush create", s.createQuery( "from Foo foo" ).list().size()==1 );
 		foo.setChar( new Character('X') );
 		assertTrue( "autoflush update", s.createQuery( "from Foo foo where foo.char='X'" ).list().size()==1 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		foo = (FooProxy) s.load( Foo.class, foo.getKey() );
 		//s.update( new Foo(), foo.getKey() );
 		//assertTrue( s.find("from Foo foo where not foo.char='X'").size()==1, "autoflush update" );
 		if ( !(getDialect() instanceof MySQLDialect) && !(getDialect() instanceof HSQLDialect) && !(getDialect() instanceof PointbaseDialect) )  {
 			foo.setBytes( "osama".getBytes() );
 			assertTrue( "autoflush collection update",
 					s.createQuery( "from Foo foo where 111 in elements(foo.bytes)" ).list().size()==1 );
 			foo.getBytes()[0] = 69;
 			assertTrue( "autoflush collection update",
 					s.createQuery( "from Foo foo where 69 in elements(foo.bytes)" ).list()
 							.size()==1 );
 		}
 		s.delete(foo);
 		assertTrue( "autoflush delete", s.createQuery( "from Foo foo" ).list().size()==0 );
 		txn.commit();
 		s.close();
 	}
 
 	public void testVeto() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Vetoer v = new Vetoer();
 		s.save(v); Serializable id = s.save(v);
 		s.getTransaction().commit();
 		s.close();
 		s = openSession();
 		s.beginTransaction();
 		s.update(v, id);
 		s.update(v, id);
 		s.delete(v);
 		s.delete(v);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testSerializableType() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Vetoer v = new Vetoer();
 		v.setStrings( new String[] { "foo", "bar", "baz" } );
 		s.save(v); Serializable id = s.save(v);
 		v.getStrings()[1] = "osama";
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		v = (Vetoer) s.load(Vetoer.class, id);
 		assertTrue( "serializable type", v.getStrings()[1].equals("osama") );
 		s.delete(v); s.delete(v);
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testAutoFlushCollections() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		baz = (Baz) s.load(Baz.class, baz.getCode());
 		baz.getStringArray()[0] = "bark";
 		Iterator i = s.createQuery( "select elements(baz.stringArray) from Baz baz" ).iterate();
 		boolean found = false;
 		while ( i.hasNext() ) {
 			if ( "bark".equals( i.next() ) ) found = true;
 		}
 		assertTrue(found);
 		baz.setStringArray(null);
 		i = s.createQuery( "select distinct elements(baz.stringArray) from Baz baz" ).iterate();
 		assertTrue( !i.hasNext() );
 		baz.setStringArray( new String[] { "foo", "bar" } );
 		i = s.createQuery( "select elements(baz.stringArray) from Baz baz" ).iterate();
 		assertTrue( i.hasNext() );
 
 		Foo foo = new Foo();
 		s.save(foo);
 		s.flush();
 		baz.setFooArray( new Foo[] {foo} );
 
 		i = s.createQuery( "select foo from Baz baz join baz.fooArray foo" ).iterate();
 		found = false;
 		while ( i.hasNext() ) {
 			if ( foo==i.next() ) found = true;
 		}
 		assertTrue(found);
 
 		baz.getFooArray()[0] = null;
 		i = s.createQuery( "select foo from Baz baz join baz.fooArray foo" ).iterate();
 		assertTrue( !i.hasNext() );
 		baz.getFooArray()[0] = foo;
 		i = s.createQuery( "select elements(baz.fooArray) from Baz baz" ).iterate();
 		assertTrue( i.hasNext() );
 
 		if ( !(getDialect() instanceof MySQLDialect)
 				&& !(getDialect() instanceof HSQLDialect)
 				&& !(getDialect() instanceof InterbaseDialect)
 				&& !(getDialect() instanceof PointbaseDialect)
 				&& !(getDialect() instanceof SAPDBDialect) )  {
 			baz.getFooArray()[0] = null;
 			i = s.createQuery( "from Baz baz where ? in elements(baz.fooArray)" )
 					.setParameter( 0, foo, Hibernate.entity( Foo.class ) )
 					.iterate();
 			assertTrue( !i.hasNext() );
 			baz.getFooArray()[0] = foo;
 			i = s.createQuery( "select foo from Foo foo where foo in (select elt from Baz baz join baz.fooArray elt)" )
 					.iterate();
 			assertTrue( i.hasNext() );
 		}
 		s.delete(foo);
 		s.delete(baz);
 		tx.commit();
 		s.close();
 	}
 
 	public void testUserProvidedConnection() throws Exception {
-		ConnectionProvider dcp = new DriverManagerConnectionProvider();
-		dcp.configure( Environment.getProperties() );
+		ConnectionProvider dcp = ConnectionProviderBuilder.buildConnectionProvider();
 		Session s = getSessions().openSession( dcp.getConnection() );
 		Transaction tx = s.beginTransaction();
 		s.createQuery( "from Fo" ).list();
 		tx.commit();
 		Connection c = s.disconnect();
 		assertTrue( c!=null );
 		s.reconnect(c);
 		tx = s.beginTransaction();
 		s.createQuery( "from Fo" ).list();
 		tx.commit();
 		assertTrue( s.close()==c );
 		c.close();
 	}
 
 	public void testCachedCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		( (FooComponent) baz.getTopComponents().get(0) ).setCount(99);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		assertTrue( ( (FooComponent) baz.getTopComponents().get(0) ).getCount()==99 );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testComplicatedQuery() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		Foo foo = new Foo();
 		Serializable id = s.save(foo);
 		assertTrue(id!=null);
 		Qux q = new Qux("q");
 		foo.getDependent().setQux(q);
 		s.save(q);
 		q.getFoo().setString("foo2");
 		//s.flush();
 		//s.connection().commit();
 		assertTrue(
 				s.createQuery( "from Foo foo where foo.dependent.qux.foo.string = 'foo2'" ).iterate().hasNext()
 		);
 		s.delete(foo);
 		txn.commit();
 		s.close();
 	}
 
 	public void testLoadAfterDelete() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		Serializable id = s.save(foo);
 		s.flush();
 		s.delete(foo);
 		boolean err=false;
 		try {
 			s.load(Foo.class, id);
 		}
 		catch (ObjectNotFoundException ode) {
 			err=true;
 		}
 		assertTrue(err);
 		s.flush();
 		err=false;
 		try {
 			( (FooProxy) s.load(Foo.class, id) ).getBool();
 		}
 		catch (ObjectNotFoundException onfe) {
 			err=true;
 		}
 		assertTrue(err);
 		Fo fo = Fo.newFo();
 		id = new FumTest("").fumKey("abc"); //yuck!!
 		s.save(fo, id);
 		s.flush();
 		s.delete(fo);
 		err=false;
 		try {
 			s.load(Fo.class, id);
 		}
 		catch (ObjectNotFoundException ode) {
 			err=true;
 		}
 		assertTrue(err);
 		s.flush();
 		err=false;
 		try {
 			s.load(Fo.class, id);
 		}
 		catch (ObjectNotFoundException onfe) {
 			err=true;
 		}
 		assertTrue(err);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testObjectType() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		GlarchProxy g = new Glarch();
 		Foo foo = new Foo();
 		g.setAny(foo);
 		Serializable gid = s.save(g);
 		s.save(foo);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( g.getAny()!=null && g.getAny() instanceof FooProxy );
 		s.delete( g.getAny() );
 		s.delete(g);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 
 	public void testAny() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		One one = new One();
 		BarProxy foo = new Bar();
 		foo.setObject(one);
 		Serializable fid = s.save(foo);
 		Serializable oid = one.getKey();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		List results = s.createQuery( "from Bar bar where bar.object.id = ? and bar.object.class = ?" )
 				.setParameter( 0, oid, Hibernate.LONG )
 				.setParameter( 1, new Character('O'), Hibernate.CHARACTER )
 				.list();
 		assertEquals( 1, results.size() );
 		results = s.createQuery( "select one from One one, Bar bar where bar.object.id = one.id and bar.object.class = 'O'" )
 				.list();
 		assertEquals( 1, results.size() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = (BarProxy) s.load(Foo.class, fid);
 		assertTrue( foo.getObject()!=null && foo.getObject() instanceof One && s.getIdentifier( foo.getObject() ).equals(oid) );
 		//s.delete( foo.getObject() );
 		s.delete(foo);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testEmbeddedCompositeID() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Location l = new Location();
 		l.setCountryCode("AU");
 		l.setDescription("foo bar");
 		l.setLocale( Locale.getDefault() );
 		l.setStreetName("Brunswick Rd");
 		l.setStreetNumber(300);
 		l.setCity("Melbourne");
 		s.save(l);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.setFlushMode(FlushMode.MANUAL);
 		l = (Location) s.createQuery( "from Location l where l.countryCode = 'AU' and l.description='foo bar'" )
 				.list()
 				.get(0);
 		assertTrue( l.getCountryCode().equals("AU") );
 		assertTrue( l.getCity().equals("Melbourne") );
 		assertTrue( l.getLocale().equals( Locale.getDefault() ) );
 		assertTrue( s.createCriteria(Location.class).add( Restrictions.eq( "streetNumber", new Integer(300) ) ).list().size()==1 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		l.setDescription("sick're");
 		s.update(l);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		l = new Location();
 		l.setCountryCode("AU");
 		l.setDescription("foo bar");
 		l.setLocale(Locale.ENGLISH);
 		l.setStreetName("Brunswick Rd");
 		l.setStreetNumber(300);
 		l.setCity("Melbourne");
 		assertTrue( l==s.load(Location.class, l) );
 		assertTrue( l.getLocale().equals( Locale.getDefault() ) );
 		s.delete(l);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testAutosaveChildren() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Baz baz = new Baz();
 		Set bars = new HashSet();
 		baz.setCascadingBars(bars);
 		s.save(baz);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		baz.getCascadingBars().add( new Bar() );
 		baz.getCascadingBars().add( new Bar() );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		assertTrue( baz.getCascadingBars().size()==2 );
 		assertTrue( baz.getCascadingBars().iterator().next()!=null );
 		baz.getCascadingBars().clear(); //test all-delete-orphan;
 		s.flush();
 		assertTrue( s.createQuery( "from Bar bar" ).list().size()==0 );
 		s.delete(baz);
 		t.commit();
 		s.close();
 	}
 
 	public void testOrphanDelete() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Baz baz = new Baz();
 		Set bars = new HashSet();
 		baz.setCascadingBars(bars);
 		bars.add( new Bar() );
 		bars.add( new Bar() );
 		bars.add( new Bar() );
 		bars.add( new Bar() );
 		s.save(baz);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		bars = baz.getCascadingBars();
 		assertEquals( 4, bars.size() );
 		bars.remove( bars.iterator().next() );
 		assertEquals( 3, s.createQuery( "From Bar bar" ).list().size() );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		bars = baz.getCascadingBars();
 		assertEquals( 3, bars.size() );
 		bars.remove( bars.iterator().next() );
 		s.delete(baz);
 		bars.remove( bars.iterator().next() );
 		assertEquals( 0, s.createQuery( "From Bar bar" ).list().size() );
 		t.commit();
 		s.close();
 
 	}
 
 	public void testTransientOrphanDelete() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Baz baz = new Baz();
 		Set bars = new HashSet();
 		baz.setCascadingBars(bars);
 		bars.add( new Bar() );
 		bars.add( new Bar() );
 		bars.add( new Bar() );
 		List foos = new ArrayList();
 		foos.add( new Foo() );
 		foos.add( new Foo() );
 		baz.setFooBag(foos);
 		s.save(baz);
 		Iterator i = new JoinedIterator( new Iterator[] {foos.iterator(), bars.iterator()} );
 		while ( i.hasNext() ) {
 			FooComponent cmp = ( (Foo) i.next() ).getComponent();
 			s.delete( cmp.getGlarch() );
 			cmp.setGlarch(null);
 		}
 		t.commit();
 		s.close();
 
 		bars.remove( bars.iterator().next() );
 		foos.remove(1);
 		s = openSession();
 		t = s.beginTransaction();
 		s.update(baz);
 		assertEquals( 2, s.createQuery( "From Bar bar" ).list().size() );
 		assertEquals( 3, s.createQuery( "From Foo foo" ).list().size() );
 		t.commit();
 		s.close();
 
 		foos.remove(0);
 		s = openSession();
 		t = s.beginTransaction();
 		s.update(baz);
 		bars.remove( bars.iterator().next() );
 		assertEquals( 1, s.createQuery( "From Foo foo" ).list().size() );
 		s.delete(baz);
 		//s.flush();
 		assertEquals( 0, s.createQuery( "From Foo foo" ).list().size() );
 		t.commit();
 		s.close();
 
 	}
 
 	public void testProxiesInCollections() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		Bar bar = new Bar();
 		Bar bar2 = new Bar();
 		s.save(bar);
 		Serializable bar2id = s.save(bar2);
 		baz.setFooArray( new Foo[] { bar, bar2 } );
 		HashSet set = new HashSet();
 		bar = new Bar();
 		s.save(bar);
 		set.add(bar);
 		baz.setFooSet(set);
 		set = new HashSet();
 		set.add( new Bar() );
 		set.add( new Bar() );
 		baz.setCascadingBars(set);
 		ArrayList list = new ArrayList();
 		list.add( new Foo() );
 		baz.setFooBag(list);
 		Serializable id = s.save(baz);
 		Serializable bid = ( (Bar) baz.getCascadingBars().iterator().next() ).getKey();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		BarProxy barprox = (BarProxy) s.load(Bar.class, bid);
 		BarProxy bar2prox = (BarProxy) s.load(Bar.class, bar2id);
 		assertTrue(bar2prox instanceof HibernateProxy);
 		assertTrue(barprox instanceof HibernateProxy);
 		baz = (Baz) s.load(Baz.class, id);
 		Iterator i = baz.getCascadingBars().iterator();
 		BarProxy b1 = (BarProxy) i.next();
 		BarProxy b2 = (BarProxy) i.next();
 		assertTrue( ( b1==barprox && !(b2 instanceof HibernateProxy) ) || ( b2==barprox && !(b1 instanceof HibernateProxy) ) ); //one-to-many
 		assertTrue( baz.getFooArray()[0] instanceof HibernateProxy ); //many-to-many
 		assertTrue( baz.getFooArray()[1]==bar2prox );
 		if ( !isOuterJoinFetchingDisabled() ) assertTrue( !(baz.getFooBag().iterator().next() instanceof HibernateProxy) ); //many-to-many outer-join="true"
 		assertTrue( !(baz.getFooSet().iterator().next() instanceof HibernateProxy) ); //one-to-many
 		doDelete( s, "from Baz" );
 		doDelete( s, "from Foo" );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testPSCache() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		for ( int i=0; i<10; i++ ) s.save( new Foo() );
 		Query q = s.createQuery("from Foo");
 		q.setMaxResults(2);
 		q.setFirstResult(5);
 		assertTrue( q.list().size()==2 );
 		q = s.createQuery("from Foo");
 		assertTrue( q.list().size()==10 );
 		assertTrue( q.list().size()==10 );
 		q.setMaxResults(3);
 		q.setFirstResult(3);
 		assertTrue( q.list().size()==3 );
 		q = s.createQuery("from Foo");
 		assertTrue( q.list().size()==10 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		q = s.createQuery("from Foo");
 		assertTrue( q.list().size()==10 );
 		q.setMaxResults(5);
 		assertTrue( q.list().size()==5 );
 		doDelete( s, "from Foo" );
 		txn.commit();
 		s.close();
 
 	}
 
 	public void testForCertain() throws Exception {
 		Glarch g = new Glarch();
 		Glarch g2 = new Glarch();
 		List set = new ArrayList();
 		set.add("foo");
 		g2.setStrings(set);
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Serializable gid = (Serializable) s.save(g);
 		Serializable g2id = (Serializable) s.save(g2);
 		t.commit();
 		assertTrue( g.getVersion()==0 );
 		assertTrue( g2.getVersion()==0 );
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		g = (Glarch) s.get(Glarch.class, gid);
 		g2 = (Glarch) s.get(Glarch.class, g2id);
 		assertTrue( g2.getStrings().size()==1 );
 		s.delete(g);
 		s.delete(g2);
 		t.commit();
 		s.close();
 
 	}
 
 	public void testBagMultipleElements() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setBag( new ArrayList() );
 		baz.setByteBag( new ArrayList() );
 		s.save(baz);
 		baz.getBag().add("foo");
 		baz.getBag().add("bar");
 		baz.getByteBag().add( "foo".getBytes() );
 		baz.getByteBag().add( "bar".getBytes() );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		//put in cache
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertTrue( baz.getBag().size()==2 );
 		assertTrue( baz.getByteBag().size()==2 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertTrue( baz.getBag().size()==2 );
 		assertTrue( baz.getByteBag().size()==2 );
 		baz.getBag().remove("bar");
  		baz.getBag().add("foo");
  		baz.getByteBag().add( "bar".getBytes() );
 		t.commit();
 		s.close();
 
  		s = openSession();
  		t = s.beginTransaction();
  		baz = (Baz) s.get( Baz.class, baz.getCode() );
  		assertTrue( baz.getBag().size()==2 );
  		assertTrue( baz.getByteBag().size()==3 );
  		s.delete(baz);
  		t.commit();
  		s.close();
  	}
 
 	public void testWierdSession() throws Exception {
  		Session s = openSession();
  		Transaction t = s.beginTransaction();
  		Serializable id =  s.save( new Foo() );
  		t.commit();
  		s.close();
 
  		s = openSession();
  		s.setFlushMode(FlushMode.MANUAL);
 		t = s.beginTransaction();
 		Foo foo = (Foo) s.get(Foo.class, id);
 		t.commit();
 		s.disconnect();
 
 		s.reconnect();
 		t = s.beginTransaction();
 		s.flush();
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		foo = (Foo) s.get(Foo.class, id);
 		s.delete(foo);
 		t.commit();
 		s.close();
 	}
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/schemaupdate/MigrationTest.java b/hibernate-core/src/test/java/org/hibernate/test/schemaupdate/MigrationTest.java
index 0c3f58860b..808c7fe050 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/schemaupdate/MigrationTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/schemaupdate/MigrationTest.java
@@ -1,49 +1,49 @@
 package org.hibernate.test.schemaupdate;
 
 import junit.framework.Test;
 import junit.framework.TestSuite;
 
 import org.hibernate.cfg.Configuration;
 import org.hibernate.testing.junit.UnitTestCase;
 import org.hibernate.tool.hbm2ddl.SchemaExport;
 import org.hibernate.tool.hbm2ddl.SchemaUpdate;
 
 /**
  * @author Max Rydahl Andersen
  */
 public class MigrationTest extends UnitTestCase {
 
 	public MigrationTest(String str) {
 		super( str );
 	}
 
 	public static Test suite() {
 		return new TestSuite( MigrationTest.class );
 	}
 
 	public void testSimpleColumnAddition() {
 		String resource1 = "org/hibernate/test/schemaupdate/1_Version.hbm.xml";
 		String resource2 = "org/hibernate/test/schemaupdate/2_Version.hbm.xml";
 
 		Configuration v1cfg = new Configuration();
 		v1cfg.addResource( resource1 );
 		new SchemaExport( v1cfg ).execute( false, true, true, false );
 
-		SchemaUpdate v1schemaUpdate = new SchemaUpdate( v1cfg );
+		SchemaUpdate v1schemaUpdate = new SchemaUpdate( getJdbcServices(), v1cfg );
 		v1schemaUpdate.execute( true, true );
 
 		assertEquals( 0, v1schemaUpdate.getExceptions().size() );
 
 		Configuration v2cfg = new Configuration();
 		v2cfg.addResource( resource2 );
 
-		SchemaUpdate v2schemaUpdate = new SchemaUpdate( v2cfg );
+		SchemaUpdate v2schemaUpdate = new SchemaUpdate( getJdbcServices(), v2cfg );
 		v2schemaUpdate.execute( true, true );
 		assertEquals( 0, v2schemaUpdate.getExceptions().size() );
 		
-		new SchemaExport( v2cfg ).drop( false, true );
+		new SchemaExport( getJdbcServices(), v2cfg ).drop( false, true );
 
 	}
 
 }
 
diff --git a/hibernate-core/src/test/java/org/hibernate/test/stats/StatsTest.java b/hibernate-core/src/test/java/org/hibernate/test/stats/StatsTest.java
index 528b678628..6815c2f6ee 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/stats/StatsTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/stats/StatsTest.java
@@ -1,237 +1,237 @@
 //$Id: StatsTest.java 15731 2008-12-26 23:42:56Z gbadner $
 package org.hibernate.test.stats;
 
 import java.util.HashSet;
 import java.util.Iterator;
 
 import junit.framework.Test;
 
 import org.hibernate.FetchMode;
 import org.hibernate.Hibernate;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.SessionFactory;
 import org.hibernate.Transaction;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.testing.junit.functional.FunctionalTestCase;
 import org.hibernate.testing.junit.functional.FunctionalTestClassTestSuite;
 import org.hibernate.mapping.Collection;
 import org.hibernate.stat.QueryStatistics;
 import org.hibernate.stat.Statistics;
 
 /**
  * Show the difference between fetch and load
  *
  * @author Emmanuel Bernard
  */
 public class StatsTest extends FunctionalTestCase {
 
 	public StatsTest(String x) {
 		super(x);
 	}
 
 	public String[] getMappings() {
 		return new String[] { "stats/Continent.hbm.xml" };
 	}
 
 	public void configure(Configuration cfg) {
 		super.configure( cfg );
 		cfg.setProperty( Environment.GENERATE_STATISTICS, "true" );
 	}
 
 	public static Test suite() {
 		return new FunctionalTestClassTestSuite( StatsTest.class );
 	}
 
 	public void testCollectionFetchVsLoad() throws Exception {
 		Statistics stats = getSessions().getStatistics();
 		stats.clear();
 
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Continent europe = fillDb(s);
 		tx.commit();
 		s.clear();
 
 		tx = s.beginTransaction();
 		assertEquals(0, stats.getCollectionLoadCount() );
 		assertEquals(0,  stats.getCollectionFetchCount() );
 		Continent europe2 = (Continent) s.get( Continent.class, europe.getId() );
 		assertEquals("Lazy true: no collection should be loaded", 0, stats.getCollectionLoadCount() );
 		assertEquals( 0, stats.getCollectionFetchCount() );
 		europe2.getCountries().size();
 		assertEquals( 1, stats.getCollectionLoadCount() );
 		assertEquals("Explicit fetch of the collection state", 1, stats.getCollectionFetchCount() );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		stats.clear();
 		europe = fillDb(s);
 		tx.commit();
 		s.clear();
 		tx = s.beginTransaction();
 		assertEquals( 0, stats.getCollectionLoadCount() );
 		assertEquals( 0, stats.getCollectionFetchCount() );
 		europe2 = (Continent) s.createQuery(
 				"from " + Continent.class.getName() + " a join fetch a.countries where a.id = " + europe.getId()
 			).uniqueResult();
 		assertEquals( 1, stats.getCollectionLoadCount() );
 		assertEquals( "collection should be loaded in the same query as its parent", 0, stats.getCollectionFetchCount() );
 		tx.commit();
 		s.close();
 
 		Collection coll = getCfg().getCollectionMapping(Continent.class.getName() + ".countries");
 		coll.setFetchMode(FetchMode.JOIN);
 		coll.setLazy(false);
-		SessionFactory sf = getCfg().buildSessionFactory();
+		SessionFactory sf = getCfg().buildSessionFactory( getServiceRegistry() );
 		stats = sf.getStatistics();
 		stats.clear();
 		stats.setStatisticsEnabled(true);
 		s = sf.openSession();
 		tx = s.beginTransaction();
 		europe = fillDb(s);
 		tx.commit();
 		s.clear();
 		tx = s.beginTransaction();
 		assertEquals( 0, stats.getCollectionLoadCount() );
 		assertEquals( 0, stats.getCollectionFetchCount() );
 		europe2 = (Continent) s.get( Continent.class, europe.getId() );
 		assertEquals( 1, stats.getCollectionLoadCount() );
 		assertEquals( "Should do direct load, not indirect second load when lazy false and JOIN", 0, stats.getCollectionFetchCount() );
 		tx.commit();
 		s.close();
 		sf.close();
 
 		coll = getCfg().getCollectionMapping(Continent.class.getName() + ".countries");
 		coll.setFetchMode(FetchMode.SELECT);
 		coll.setLazy(false);
-		sf = getCfg().buildSessionFactory();
+		sf = getCfg().buildSessionFactory( getServiceRegistry() );
 		stats = sf.getStatistics();
 		stats.clear();
 		stats.setStatisticsEnabled(true);
 		s = sf.openSession();
 		tx = s.beginTransaction();
 		europe = fillDb(s);
 		tx.commit();
 		s.clear();
 		tx = s.beginTransaction();
 		assertEquals( 0, stats.getCollectionLoadCount() );
 		assertEquals( 0, stats.getCollectionFetchCount() );
 		europe2 = (Continent) s.get( Continent.class, europe.getId() );
 		assertEquals( 1, stats.getCollectionLoadCount() );
 		assertEquals( "Should do explicit collection load, not part of the first one", 1, stats.getCollectionFetchCount() );
 		Iterator countries = europe2.getCountries().iterator();
 		while ( countries.hasNext() ) {
 			s.delete( countries.next() );
 		}
 		cleanDb( s );
 		tx.commit();
 		s.close();
 	}
 
 	public void testQueryStatGathering() {
 		Statistics stats = getSessions().getStatistics();
 		stats.clear();
 
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		fillDb(s);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		final String continents = "from Continent";
 		int results = s.createQuery( continents ).list().size();
 		QueryStatistics continentStats = stats.getQueryStatistics( continents );
 		assertNotNull( "stats were null",  continentStats );
 		assertEquals( "unexpected execution count", 1, continentStats.getExecutionCount() );
 		assertEquals( "unexpected row count", results, continentStats.getExecutionRowCount() );
 		long maxTime = continentStats.getExecutionMaxTime();
 		assertEquals( maxTime, stats.getQueryExecutionMaxTime() );
 //		assertEquals( continents, stats.getQueryExecutionMaxTimeQueryString() );
 
 		Iterator itr = s.createQuery( continents ).iterate();
 		// iterate() should increment the execution count
 		assertEquals( "unexpected execution count", 2, continentStats.getExecutionCount() );
 		// but should not effect the cumulative row count
 		assertEquals( "unexpected row count", results, continentStats.getExecutionRowCount() );
 		Hibernate.close( itr );
 
 		ScrollableResults scrollableResults = s.createQuery( continents ).scroll();
 		// same deal with scroll()...
 		assertEquals( "unexpected execution count", 3, continentStats.getExecutionCount() );
 		assertEquals( "unexpected row count", results, continentStats.getExecutionRowCount() );
 		// scroll through data because SybaseASE15Dialect throws NullPointerException
 		// if data is not read before closing the ResultSet
 		while ( scrollableResults.next() ) {
 			// do nothing
 		}
 		scrollableResults.close();
 		tx.commit();
 		s.close();
 
 		// explicitly check that statistics for "split queries" get collected
 		// under the original query
 		stats.clear();
 		s = openSession();
 		tx = s.beginTransaction();
 		final String localities = "from Locality";
 		results = s.createQuery( localities ).list().size();
 		QueryStatistics localityStats = stats.getQueryStatistics( localities );
 		assertNotNull( "stats were null",  localityStats );
 		// ...one for each split query
 		assertEquals( "unexpected execution count", 2, localityStats.getExecutionCount() );
 		assertEquals( "unexpected row count", results, localityStats.getExecutionRowCount() );
 		maxTime = localityStats.getExecutionMaxTime();
 		assertEquals( maxTime, stats.getQueryExecutionMaxTime() );
 //		assertEquals( localities, stats.getQueryExecutionMaxTimeQueryString() );
 		tx.commit();
 		s.close();
 		assertFalse( s.isOpen() );
 
 		// native sql queries
 		stats.clear();
 		s = openSession();
 		tx = s.beginTransaction();
 		final String sql = "select id, name from Country";
 		results = s.createSQLQuery( sql ).addEntity( Country.class ).list().size();
 		QueryStatistics sqlStats = stats.getQueryStatistics( sql );
 		assertNotNull( "sql stats were null", sqlStats );
 		assertEquals( "unexpected execution count", 1, sqlStats.getExecutionCount() );
 		assertEquals( "unexpected row count", results, sqlStats.getExecutionRowCount() );
 		maxTime = sqlStats.getExecutionMaxTime();
 		assertEquals( maxTime, stats.getQueryExecutionMaxTime() );
 //		assertEquals( sql, stats.getQueryExecutionMaxTimeQueryString() );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		cleanDb( s );
 		tx.commit();
 		s.close();
 	}
 
 	private Continent fillDb(Session s) {
 		Continent europe = new Continent();
 		europe.setName("Europe");
 		Country france = new Country();
 		france.setName("France");
 		europe.setCountries( new HashSet() );
 		europe.getCountries().add(france);
 		s.persist(france);
 		s.persist(europe);
 		return europe;
 	}
 
 	private void cleanDb(Session s) {
 		s.createQuery( "delete Locality" ).executeUpdate();
 		s.createQuery( "delete Country" ).executeUpdate();
 		s.createQuery( "delete Continent" ).executeUpdate();
 	}
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/testing/junit/UnitTestCase.java b/hibernate-core/src/test/java/org/hibernate/testing/junit/UnitTestCase.java
index b500632d17..0726cc837a 100644
--- a/hibernate-core/src/test/java/org/hibernate/testing/junit/UnitTestCase.java
+++ b/hibernate-core/src/test/java/org/hibernate/testing/junit/UnitTestCase.java
@@ -1,161 +1,191 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.junit;
 
 import java.util.Enumeration;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Set;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import junit.framework.AssertionFailedError;
 import junit.framework.Test;
 import junit.framework.TestCase;
 import junit.framework.TestSuite;
 
+import org.hibernate.cfg.Environment;
+import org.hibernate.engine.jdbc.spi.JdbcServices;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
+import org.hibernate.service.spi.ServicesRegistry;
+import org.hibernate.test.common.ServiceRegistryHolder;
 
 /**
  * A basic JUnit {@link junit.framework.TestCase} subclass for
  * adding some Hibernate specific behavior and functionality.
  *
  * @author Steve Ebersole
  */
 public abstract class UnitTestCase extends junit.framework.TestCase {
 
 	private static final Logger log = LoggerFactory.getLogger( UnitTestCase.class );
 
+	private ServiceRegistryHolder serviceRegistryHolder;
+
 	public UnitTestCase(String string) {
 		super( string );
 	}
 
 	/**
 	 * runBare overridden in order to apply FailureExpected validations
 	 * as well as start/complete logging
 	 *
 	 * @throws Throwable
 	 */
 	public void runBare() throws Throwable {
 		final boolean doValidate = getName().endsWith( "FailureExpected" ) && Boolean.getBoolean( "hibernate.test.validatefailureexpected" );
 		try {
 			log.info( "Starting test [" + fullTestName() + "]" );
 			super.runBare();
 			if ( doValidate ) {
 				throw new FailureExpectedTestPassedException();
 			}
 		}
 		catch ( FailureExpectedTestPassedException t ) {
 			throw t;
 		}
 		catch( Throwable t ) {
 			if ( doValidate ) {
 				skipExpectedFailure( t );
 			}
 			else {
 				throw t;
 			}
 		}
 		finally {
 			log.info( "Completed test [" + fullTestName() + "]" );
 		}
 	}
 
+	@Override
+	protected void tearDown() throws Exception {
+		if ( serviceRegistryHolder != null ) {
+				serviceRegistryHolder.destroy();
+				serviceRegistryHolder = null;
+		}
+	}
+
+	protected ServicesRegistry getServiceRegistry() {
+		if ( serviceRegistryHolder == null ) {
+			serviceRegistryHolder = new ServiceRegistryHolder( Environment.getProperties() );
+		}
+		return serviceRegistryHolder.getServiceRegistry();
+ 	}
+
+	protected JdbcServices getJdbcServices() {
+		return getServiceRegistry().getService( JdbcServices.class );
+	}
+
+	protected ConnectionProvider getConnectionProvider() {
+		return getJdbcServices().getConnectionProvider();
+	}
+
 	private static class FailureExpectedTestPassedException extends Exception {
 		public FailureExpectedTestPassedException() {
 			super( "Test marked as FailureExpected, but did not fail!" );
 		}
 	}
 
 	protected void skipExpectedFailure(Throwable error) {
 		reportSkip( "ignoring *FailuredExpected methods", "Failed with: " + error.toString() );
 	}
 
 	// additional assertions ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public static void assertElementTypeAssignability(java.util.Collection collection, Class clazz) throws AssertionFailedError {
 		Iterator itr = collection.iterator();
 		while ( itr.hasNext() ) {
 			assertClassAssignability( itr.next().getClass(), clazz );
 		}
 	}
 
 	public static void assertClassAssignability(Class source, Class target) throws AssertionFailedError {
 		if ( !target.isAssignableFrom( source ) ) {
 			throw new AssertionFailedError(
 			        "Classes were not assignment-compatible : source<" + source.getName() +
 			        "> target<" + target.getName() + ">"
 			);
 		}
 	}
 
 
 	// test skipping ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public String fullTestName() {
 		return this.getClass().getName() + "#" + this.getName();
 	}
 
 	protected void reportSkip(String reason, String testDescription) {
 		SkipLog.LOG.warn( "*** skipping [" + fullTestName() + "] - " + testDescription + " : " + reason, new Exception()  );
 	}
 	
 	// testsuite utitities ---------------------------------------------------
 	
 	/**
 	 * Supports easy creation of TestSuites where a subclass' "FailureExpected"
 	 * version of a base test is included in the suite, while the base test
 	 * is excluded.  E.g. test class FooTestCase includes method testBar(), while test
 	 * class SubFooTestCase extends FooTestCase includes method testBarFailureExcluded().
 	 * Passing SubFooTestCase.class to this method will return a suite that
 	 * does not include testBar().
 	 */
 	public static TestSuite createFailureExpectedSuite(Class testClass) {
 	   
 	   TestSuite allTests = new TestSuite(testClass);
        Set failureExpected = new HashSet();
 	   Enumeration tests = allTests.tests();
 	   while (tests.hasMoreElements()) {
 	      Test t = (Test) tests.nextElement();
 	      if (t instanceof TestCase) {
 	         String name = ((TestCase) t).getName();
 	         if (name.endsWith("FailureExpected"))
 	            failureExpected.add(name);
 	      }	      
 	   }
 	   
 	   TestSuite result = new TestSuite();
        tests = allTests.tests();
        while (tests.hasMoreElements()) {
           Test t = (Test) tests.nextElement();
           if (t instanceof TestCase) {
              String name = ((TestCase) t).getName();
              if (!failureExpected.contains(name + "FailureExpected")) {
                 result.addTest(t);
              }
           }       
        }
 	   
 	   return result;
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/testing/junit/functional/ExecutionEnvironment.java b/hibernate-core/src/test/java/org/hibernate/testing/junit/functional/ExecutionEnvironment.java
index dc843ff239..32992cade3 100644
--- a/hibernate-core/src/test/java/org/hibernate/testing/junit/functional/ExecutionEnvironment.java
+++ b/hibernate-core/src/test/java/org/hibernate/testing/junit/functional/ExecutionEnvironment.java
@@ -1,186 +1,222 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.junit.functional;
 
+import java.util.HashMap;
 import java.util.Iterator;
 import java.sql.Blob;
 import java.sql.Clob;
+import java.util.Map;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Mappings;
 import org.hibernate.SessionFactory;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.mapping.Collection;
+import org.hibernate.service.jdbc.connections.internal.ConnectionProviderInitiator;
+import org.hibernate.service.spi.ServicesRegistry;
+import org.hibernate.test.common.ServiceRegistryHolder;
 
 /**
  * {@inheritDoc}
  *
  * @author Steve Ebersole
  */
 public class ExecutionEnvironment {
 
 	public static final Dialect DIALECT = Dialect.getDialect();
 
 	private final ExecutionEnvironment.Settings settings;
 
+	private Map conectionProviderInjectionProperties;
+	private ServiceRegistryHolder serviceRegistryHolder;
 	private Configuration configuration;
 	private SessionFactory sessionFactory;
 	private boolean allowRebuild;
 
 	public ExecutionEnvironment(ExecutionEnvironment.Settings settings) {
 		this.settings = settings;
 	}
 
 	public boolean isAllowRebuild() {
 		return allowRebuild;
 	}
 
 	public void setAllowRebuild(boolean allowRebuild) {
 		this.allowRebuild = allowRebuild;
 	}
 
 	public Dialect getDialect() {
 		return DIALECT;
 	}
 
 	public Configuration getConfiguration() {
 		return configuration;
 	}
 
+	public ServicesRegistry getServiceRegistry() {
+		return serviceRegistryHolder.getServiceRegistry();
+	}
+
 	public SessionFactory getSessionFactory() {
 		return sessionFactory;
 	}
 
-	public void initialize() {
+	public void initialize(Map conectionProviderInjectionProperties) {
 		if ( sessionFactory != null ) {
 			throw new IllegalStateException( "attempt to initialize already initialized ExecutionEnvironment" );
 		}
 		if ( ! settings.appliesTo( getDialect() ) ) {
 			return;
 		}
 
+		this.conectionProviderInjectionProperties = conectionProviderInjectionProperties;
 		Configuration configuration = new Configuration();
 		configuration.setProperty( Environment.CACHE_PROVIDER, "org.hibernate.cache.HashtableCacheProvider" );
 
 		settings.configure( configuration );
 
 		if ( settings.createSchema() ) {
 			configuration.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
 		}
 
 		// make sure we use the same dialect...
 		configuration.setProperty( Environment.DIALECT, getDialect().getClass().getName() );
 
 		applyMappings( configuration );
 		configuration.buildMappings();
 
 		applyCacheSettings( configuration );
 		settings.afterConfigurationBuilt( configuration.createMappings(), getDialect() );
 
-		SessionFactory sessionFactory = configuration.buildSessionFactory();
 		this.configuration = configuration;
-		this.sessionFactory = sessionFactory;
+
+		serviceRegistryHolder = new ServiceRegistryHolder( getServiceRegistryProperties() );
+		sessionFactory = configuration.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 
 		settings.afterSessionFactoryBuilt( ( SessionFactoryImplementor ) sessionFactory );
 	}
 
+	private Map getServiceRegistryProperties() {
+		Map serviceRegistryProperties = configuration.getProperties();
+		if ( conectionProviderInjectionProperties != null && conectionProviderInjectionProperties.size() > 0 ) {
+			serviceRegistryProperties = new HashMap(
+					configuration.getProperties().size() + conectionProviderInjectionProperties.size()
+			);
+			serviceRegistryProperties.putAll( configuration.getProperties() );
+			serviceRegistryProperties.put(
+					ConnectionProviderInitiator.INJECTION_DATA, conectionProviderInjectionProperties
+			);
+		}
+		return serviceRegistryProperties;
+	}
+
 	private void applyMappings(Configuration configuration) {
 		String[] mappings = settings.getMappings();
 		for ( String mapping : mappings ) {
 			configuration.addResource(
 					settings.getBaseForMappings() + mapping,
 					ExecutionEnvironment.class.getClassLoader()
 			);
 		}
 	}
 
 	private void applyCacheSettings(Configuration configuration) {
 		if ( settings.getCacheConcurrencyStrategy() != null ) {
 			Iterator iter = configuration.getClassMappings();
 			while ( iter.hasNext() ) {
 				PersistentClass clazz = (PersistentClass) iter.next();
 				Iterator props = clazz.getPropertyClosureIterator();
 				boolean hasLob = false;
 				while ( props.hasNext() ) {
 					Property prop = (Property) props.next();
 					if ( prop.getValue().isSimpleValue() ) {
 						String type = ( ( SimpleValue ) prop.getValue() ).getTypeName();
 						if ( "blob".equals(type) || "clob".equals(type) ) {
 							hasLob = true;
 						}
 						if ( Blob.class.getName().equals(type) || Clob.class.getName().equals(type) ) {
 							hasLob = true;
 						}
 					}
 				}
 				if ( !hasLob && !clazz.isInherited() && settings.overrideCacheStrategy() ) {
 					configuration.setCacheConcurrencyStrategy( clazz.getEntityName(), settings.getCacheConcurrencyStrategy() );
 				}
 			}
 			iter = configuration.getCollectionMappings();
 			while ( iter.hasNext() ) {
 				Collection coll = (Collection) iter.next();
 				configuration.setCollectionCacheConcurrencyStrategy( coll.getRole(), settings.getCacheConcurrencyStrategy() );
 			}
 		}
 	}
 
 	public void rebuild() {
 		if ( !allowRebuild ) {
 			return;
 		}
 		if ( sessionFactory != null ) {
 			sessionFactory.close();
 			sessionFactory = null;
 		}
-		sessionFactory = configuration.buildSessionFactory();
+		if ( serviceRegistryHolder != null ) {
+			serviceRegistryHolder.destroy();
+			serviceRegistryHolder = null;
+		}
+		serviceRegistryHolder = new ServiceRegistryHolder( getServiceRegistryProperties() );
+		sessionFactory = configuration.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
 		settings.afterSessionFactoryBuilt( ( SessionFactoryImplementor ) sessionFactory );
 	}
 
 	public void complete() {
 		if ( sessionFactory != null ) {
 			sessionFactory.close();
 			sessionFactory = null;
 		}
+		if ( serviceRegistryHolder != null ) {
+			serviceRegistryHolder.destroy();
+			serviceRegistryHolder = null;
+		}
 		configuration = null;
 	}
 
 	public static interface Settings {
 		public String[] getMappings();
 		public String getBaseForMappings();
 		public boolean createSchema();
 		public boolean recreateSchemaAfterFailure();
 		public void configure(Configuration cfg);
 		public boolean overrideCacheStrategy();
 		public String getCacheConcurrencyStrategy();
 		public void afterSessionFactoryBuilt(SessionFactoryImplementor sfi);
 		public void afterConfigurationBuilt(Mappings mappings, Dialect dialect);
 		public boolean appliesTo(Dialect dialect);
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/testing/junit/functional/FunctionalTestCase.java b/hibernate-core/src/test/java/org/hibernate/testing/junit/functional/FunctionalTestCase.java
index aa4ec014f3..da2d44e80d 100644
--- a/hibernate-core/src/test/java/org/hibernate/testing/junit/functional/FunctionalTestCase.java
+++ b/hibernate-core/src/test/java/org/hibernate/testing/junit/functional/FunctionalTestCase.java
@@ -1,544 +1,549 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.junit.functional;
 
+import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.sql.Connection;
 
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Mappings;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.DB2Dialect;
 import org.hibernate.dialect.DerbyDialect;
 import org.hibernate.SessionFactory;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.Session;
 import org.hibernate.testing.junit.UnitTestCase;
 import org.hibernate.engine.SessionFactoryImplementor;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
  * Most of the Hibernate test suite in fact is a series of functional tests, not
  * unit tests.  Here is a base class for these functional tests.
  *
  * @author Steve Ebersole
  */
 public abstract class FunctionalTestCase extends UnitTestCase implements ExecutionEnvironment.Settings {
 
 	private static final Logger log = LoggerFactory.getLogger( FunctionalTestCase.class );
 
 	private ExecutionEnvironment environment;
 	private boolean isEnvironmentLocallyManaged;
 
 	private org.hibernate.classic.Session session;
 
 	public FunctionalTestCase(String string) {
 		super( string );
 	}
 
 	public ExecutionEnvironment getEnvironment() {
 		return environment;
 	}
 
 	public void setEnvironment(ExecutionEnvironment environment) {
 		this.environment = environment;
 	}
 
 	protected void prepareTest() throws Exception {
 	}
 
 	protected void cleanupTest() throws Exception {
 	}
 
 	// JUnit hooks ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Override {@link junit.framework.TestCase#setUp()} to check if we need
 	 * to build a locally managed execution environment.
 	 *
 	 * @throws Exception
 	 */
 	protected final void setUp() throws Exception {
 		if ( environment == null ) {
 			log.info( "Building locally managed execution env" );
 			isEnvironmentLocallyManaged = true;
 			environment = new ExecutionEnvironment( this );
-			environment.initialize();
+			environment.initialize( getConnectionProviderInjectionProperties() );
 		}
 		prepareTest();
 	}
 
+	protected Map getConnectionProviderInjectionProperties() {
+		return Collections.EMPTY_MAP;
+	}
+
 	/**
 	 * Override {@link junit.framework.TestCase#tearDown()} to tear down
 	 * the execution environment if it is locally managed.
 	 *
 	 * @throws Exception
 	 */
 	protected final void tearDown() throws Exception {
 		cleanupTest();
 		if ( isEnvironmentLocallyManaged ) {
 			log.info( "Destroying locally managed execution env" );
 			environment.complete();
 			environment = null;
 		}
 	}
 
 	/**
 	 * runTest is overridden in order to apply session closure assertions.
 	 *
 	 * @throws Throwable
 	 */
 	protected void runTest() throws Throwable {
 		final boolean stats = sfi().getStatistics().isStatisticsEnabled();
 		try {
 			if ( stats ) {
 				sfi().getStatistics().clear();
 			}
 
 			super.runTest();
 
 			if ( stats ) {
 				sfi().getStatistics().logSummary();
 			}
 
 			if ( session != null && session.isOpen() ) {
 				if ( session.isConnected() ) {
 					session.connection().rollback();
 				}
 				session.close();
 				session = null;
 				fail( "unclosed session" );
 			}
 			else {
 				session = null;
 			}
 			assertAllDataRemoved();
 		}
 		catch ( Throwable e ) {
 			log.trace( "test run resulted in error; attempting to cleanup", e );
 			try {
 				if ( session != null && session.isOpen() ) {
 					if ( session.isConnected() ) {
 						session.connection().rollback();
 					}
 					session.close();
 				}
 			}
 			catch ( Exception ignore ) {
 			}
 			try {
 				if ( recreateSchemaAfterFailure() && environment != null ) {
 					environment.rebuild();
 				}
 			}
 			catch ( Exception ignore ) {
 			}
 			throw e;
 		}
 	}
 
 	protected void assertAllDataRemoved() {
 		if ( !createSchema() ) {
 			return; // no tables were created...
 		}
 		if ( !Boolean.getBoolean( "hibernate.test.validateDataCleanup" ) ) {
 			return;
 		}
 
 		Session tmpSession = getSessions().openSession();
 		try {
 			List list = tmpSession.createQuery( "select o from java.lang.Object o" ).list();
 
 			Map items = new HashMap();
 			if ( !list.isEmpty() ) {
 				for ( Iterator iter = list.iterator(); iter.hasNext(); ) {
 					Object element = iter.next();
 					Integer l = ( Integer ) items.get( tmpSession.getEntityName( element ) );
 					if ( l == null ) {
 						l = new Integer( 0 );
 					}
 					l = new Integer( l.intValue() + 1 );
 					items.put( tmpSession.getEntityName( element ), l );
 					System.out.println( "Data left: " + element );
 				}
 				fail( "Data is left in the database: " + items.toString() );
 			}
 		}
 		finally {
 			try {
 				tmpSession.close();
 			}
 			catch( Throwable t ) {
 				// intentionally empty
 			}
 		}
 	}
 
 	protected void skipExpectedFailure(Throwable error) {
 		super.skipExpectedFailure( error );
 		try {
 			if ( recreateSchemaAfterFailure() && environment != null ) {
 				environment.rebuild();
 			}
 		}
 		catch ( Exception ignore ) {
 		}
 	}
 
 	// ExecutionEnvironment.Settings implementation ~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public String getBaseForMappings() {
 		return "org/hibernate/test/";
 	}
 
 	public boolean createSchema() {
 		return true;
 	}
 
 	public boolean recreateSchemaAfterFailure() {
 		return true;
 	}
 
 	public void configure(Configuration cfg) {
 	}
 
 	public boolean overrideCacheStrategy() {
 		return true;
 	}
 
 	public String getCacheConcurrencyStrategy() {
 		return "nonstrict-read-write";
 	}
 
 	public void afterSessionFactoryBuilt(SessionFactoryImplementor sfi) {
 	}
 
 	public void afterConfigurationBuilt(Mappings mappings, Dialect dialect) {
 	}
 
 	/**
 	 * Intended to indicate that this test class as a whole is intended for
 	 * a dialect or series of dialects.  Skips here (appliesTo = false) therefore
 	 * simply indicate that the given tests target a particular feature of the
 	 * checked database and none of the tests on this class should be run for the
 	 * checked dialect.
 	 *
 	 * @param dialect The dialect to be checked.
 	 * @return False if the test class as a whole is specifically targetting
 	 * a dialect (or series of dialects) other than the indicated dialect
 	 * and the test should therefore be skipped in its entirety;
 	 * true otherwise.
 	 */
 	public boolean appliesTo(Dialect dialect) {
 		return true;
 	}
 
 
 	// methods for subclasses to access environment ~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Get the factory for this test environment.
 	 *
 	 * @return The factory.
 	 */
 	protected SessionFactory getSessions() {
 		return environment.getSessionFactory();
 	}
 
 	/**
 	 * Get the factory for this test environment, casted to {@link org.hibernate.engine.SessionFactoryImplementor}.
 	 * <p/>
 	 * Shorthand for ( {@link org.hibernate.engine.SessionFactoryImplementor} ) {@link #getSessions()}...
 	 *
 	 * @return The factory
 	 */
 	protected SessionFactoryImplementor sfi() {
 		return ( SessionFactoryImplementor ) getSessions();
 	}
 
 	protected Dialect getDialect() {
 		return ExecutionEnvironment.DIALECT;
 	}
 
 	protected Configuration getCfg() {
 		return environment.getConfiguration();
 	}
 
 	public org.hibernate.classic.Session openSession() throws HibernateException {
 		session = getSessions().openSession();
 		return session;
 	}
 
 	public org.hibernate.classic.Session openSession(Interceptor interceptor) throws HibernateException {
 		session = getSessions().openSession(interceptor);
 		return session;
 	}
 
 
 
 	/**
 	 * Do connections enforce SERIALIZABLE isolation...
 	 *
 	 * @return
 	 * @throws Exception
 	 */
 	protected boolean isSerializableIsolationEnforced() throws Exception {
 		Connection conn = null;
 		try {
 			conn = sfi().getConnectionProvider().getConnection();
 			return conn.getTransactionIsolation() >= Connection.TRANSACTION_SERIALIZABLE;
 		}
 		finally {
 			if ( conn != null ) {
 				try {
 					sfi().getConnectionProvider().closeConnection( conn );
 				}
 				catch ( Throwable ignore ) {
 					// ignore...
 				}
 			}
 		}
 	}
 
 	/**
 	 * Is connection at least read committed?
 	 * <p/>
 	 * Not, that this skip check relies on the JDBC driver reporting
 	 * the true isolation level correctly.  HSQLDB, for example, will
 	 * report whatever you specify as the isolation
 	 * (Connection.setTransationIsolation()), even though it only supports
 	 * read-uncommitted.
 	 *
 	 * @param scenario text description of the scenario being tested.
 	 * @return true if read-committed isolation is maintained.
 	 */
 	protected boolean readCommittedIsolationMaintained(String scenario) {
 		int isolation = java.sql.Connection.TRANSACTION_READ_UNCOMMITTED;
 		Session testSession = null;
 		try {
 			testSession = openSession();
 			isolation = testSession.connection().getTransactionIsolation();
 		}
 		catch( Throwable ignore ) {
 		}
 		finally {
 			if ( testSession != null ) {
 				try {
 					testSession.close();
 				}
 				catch( Throwable ignore ) {
 				}
 			}
 		}
 		if ( isolation < java.sql.Connection.TRANSACTION_READ_COMMITTED ) {
 			reportSkip( "environment does not support at least read committed isolation", scenario );
 			return false;
 		}
 		else {
 			return true;
 		}
 	}
 
 	/**
 	 * Does the db/dialect support using a column's physical name in the order-by clause
 	 * even after it has been aliased in the select clause.  This is not actually
 	 * required by the SQL spec, although virtually ever DB in the world supports this
 	 * (the most glaring omission here being IBM-variant DBs ala DB2 and Derby).
 	 *
 	 * @param testDescription description of the scenario being tested.
 	 * @return true if is allowed
 	 */
 	protected boolean allowsPhysicalColumnNameInOrderby(String testDescription) {
 		if ( DB2Dialect.class.isInstance( getDialect() ) ) {
 			// https://issues.apache.org/jira/browse/DERBY-1624
 			reportSkip( "Dialect does not support physical column name in order-by clause after it is aliased", testDescription );
 			return false;
 		}
 		return true;
 	}
 
 	/**
 	 * Does the db/dialect support using a column's physical name in the having clause
 	 * even after it has been aliased in the select/group-by clause.  This is not actually
 	 * required by the SQL spec, although virtually ever DB in the world supports this.
 	 *
 	 * @param testDescription description of the scenario being tested.
 	 * @return true if is allowed
 	 */
 	protected boolean allowsPhysicalColumnNameInHaving(String testDescription) {
 		// I only *know* of this being a limitation on Derby, although I highly suspect
 		// it is a limitation on any IBM/DB2 variant
 		if ( DerbyDialect.class.isInstance( getDialect() ) ) {
 			// https://issues.apache.org/jira/browse/DERBY-1624
 			reportSkip( "Dialect does not support physical column name in having clause after it is aliased", testDescription );
 			return false;
 		}
 		return true;
 	}
 
 	/**
 	 * Does the db/dialect support empty lists in the IN operator?
 	 * <p/>
 	 * For example, is "... a.b IN () ..." supported?
 	 *
 	 * @param testDescription description of the scenario being tested.
 	 * @return true if is allowed
 	 */
 	protected boolean dialectSupportsEmptyInList(String testDescription) {
 		if ( ! getDialect().supportsEmptyInList() ) {
 			reportSkip( "Dialect does not support SQL empty in list : x in ()", testDescription );
 			return false;
 		}
 		return true;
 	}
 
 	/**
 	 * Is the db/dialect sensitive in terms of string comparisons?
 	 * @param testDescription description of the scenario being tested.
 	 * @return true if sensitive
 	 */
 	protected boolean dialectIsCaseSensitive(String testDescription) {
 		if ( ! getDialect().areStringComparisonsCaseInsensitive() ) {
 			reportSkip( "Dialect is case sensitive. ", testDescription );
 			return true;
 		}
 		return false;
 	}
 
 	protected boolean supportsResultSetPositionQueryMethodsOnForwardOnlyCursor() {
 		if ( ! getDialect().supportsResultSetPositionQueryMethodsOnForwardOnlyCursor() ) {
 			reportSkip( "Driver does not support 'position query' methods on forward-only cursors", "query support" );
 			return false;
 		}
 		return true;
 	}
 
 	protected boolean supportsCircularCascadeDelete() {
 		if ( ! getDialect().supportsCircularCascadeDeleteConstraints() ) {
 			reportSkip( "db/dialect does not support 'circular' cascade delete constraints", "cascade delete constraint support" );
 			return false;
 		}
 		return true;
 	}
 
 	protected boolean supportsSubselectOnLeftSideIn() {
 		if ( ! getDialect().supportsSubselectAsInPredicateLHS() ) {
 			reportSkip( "Database does not support (<subselect>) in ( ... ) ", "query support" );
 			return false;
 		}
 		return true;
 	}
 
 	/**
 	 * Expected LOB usage pattern is such that I can perform an insert
 	 * via prepared statement with a parameter binding for a LOB value
 	 * without crazy casting to JDBC driver implementation-specific classes...
 	 * <p/>
 	 * Part of the trickiness here is the fact that this is largely
 	 * driver dependent.  For Oracle, which is notoriously bad with
 	 * LOB support in their drivers actually does a pretty good job with
 	 * LOB support as of the 10.2.x versions of their drivers...
 	 *
 	 * @return True if expected usage pattern is support; false otherwise.
 	 */
 	protected boolean supportsExpectedLobUsagePattern() {
 		if ( ! getDialect().supportsExpectedLobUsagePattern() ) {
 			reportSkip( "database/driver does not support expected LOB usage pattern", "LOB support" );
 			return false;
 		}
 		return true;
 	}
 
 	/**
 	 * Does the current dialect support propogating changes to LOB
 	 * values back to the database?  Talking about mutating the
 	 * underlying value as opposed to supplying a new
 	 * LOB instance...
 	 *
 	 * @return True if the changes are propogated back to the
 	 * database; false otherwise.
 	 */
 	protected boolean supportsLobValueChangePropogation() {
 		if ( ! getDialect().supportsLobValueChangePropogation() ) {
 			reportSkip( "database/driver does not support propogating LOB value change back to database", "LOB support" );
 			return false;
 		}
 		return true;
 	}
 
 	/**
 	 * Is it supported to materialize a LOB locator outside the transaction in
 	 * which it was created?
 	 * <p/>
 	 * Again, part of the trickiness here is the fact that this is largely
 	 * driver dependent.
 	 * <p/>
 	 * NOTE: all database I have tested which {@link #supportsExpectedLobUsagePattern()}
 	 * also support the ability to materialize a LOB outside the owning transaction...
 	 *
 	 * @return True if unbounded materialization is supported; false otherwise.
 	 */
 	protected boolean supportsUnboundedLobLocatorMaterialization() {
 		if ( !getDialect().supportsUnboundedLobLocatorMaterialization() ) {
 			reportSkip( "database/driver does not support materializing a LOB locator outside the 'owning' transaction", "LOB support" );
 			return false;
 		}
 		return true;
 	}
 
 	protected boolean supportsSubqueryOnMutatingTable() {
 		if ( !getDialect().supportsSubqueryOnMutatingTable() ) {
 			reportSkip( "database/driver does not support referencing mutating table in subquery", "bulk DML support" );
 			return false;
 		}
 		return true;
 	}
 
 	protected boolean dialectIs(Class dialectClass) {
 		return dialectClass.isInstance( getDialect() );
 	}
 
 	protected boolean dialectIsOneOf(Class[] dialectClasses) {
 		for ( int i = 0; i < dialectClasses.length; i++ ) {
 			if ( dialectClasses[i].isInstance( getDialect() ) ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	protected boolean dialectIsNot(Class dialectClass) {
 		return ! dialectIs( dialectClass );
 	}
 
 	protected boolean dialectIsNot(Class[] dialectClasses) {
 		return ! dialectIsOneOf( dialectClasses );
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/testing/junit/functional/FunctionalTestClassTestSuite.java b/hibernate-core/src/test/java/org/hibernate/testing/junit/functional/FunctionalTestClassTestSuite.java
index 3b2999082a..1796cf7203 100644
--- a/hibernate-core/src/test/java/org/hibernate/testing/junit/functional/FunctionalTestClassTestSuite.java
+++ b/hibernate-core/src/test/java/org/hibernate/testing/junit/functional/FunctionalTestClassTestSuite.java
@@ -1,144 +1,151 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.junit.functional;
 
+import java.util.Collections;
+import java.util.Map;
+
 import junit.framework.TestSuite;
 import junit.framework.Test;
 import junit.framework.TestResult;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
  * A specialized {@link junit.framework.TestSuite} implementation intended
  * for use as an aggregate for a single test class specifically for the purpose
  * of maintaing a single {@link org.hibernate.SessionFactory} for executings all
  * tests defined as part of the given functional test class.
  *
  * @author Steve Ebersole
  */
 public class FunctionalTestClassTestSuite extends TestSuite {
 
 	private static final Logger log = LoggerFactory.getLogger( FunctionalTestClassTestSuite.class );
 
 	private ExecutionEnvironment.Settings settings;
 	private ExecutionEnvironment environment;
 	private Throwable environmentSetupError;
 	private int testCount;
 	private int testPosition;
 
 	public FunctionalTestClassTestSuite(Class testClass, String name) {
 		super( testClass, name );
 	}
 
 	public FunctionalTestClassTestSuite(Class testClass) {
 		this( testClass, testClass.getName() );
 	}
 
 
 	public void addTest(Test test) {
 		log.trace( "adding test [" + test + "]" );
 		if ( settings == null ) {
 			if ( test instanceof ExecutionEnvironment.Settings ) {
 				settings = ( ExecutionEnvironment.Settings ) test;
 				// todo : we could also centralize the skipping of "database specific" tests here
 				// instead of duplicating this notion in AllTests and DatabaseSpecificFunctionalTestCase.
 				// as a test gets added, simply check to see if we should really add it via
 				// DatabaseSpecificFunctionalTestCase.appliesTo( ExecutionEnvironment.DIALECT )...
 			}
 		}
 		testCount++;
 		super.addTest( test );
 	}
 
 	public void run(TestResult testResult) {
 		if ( testCount == 0 ) {
 			// might be zero if database-specific...
 			return;
 		}
 		try {
 			log.info( "Starting test-suite [" + getName() + "]" );
 			setUp();
 			testPosition = 0;
 			super.run( testResult );
 		}
 		finally {
 			try {
 				tearDown();
 			}
 			catch( Throwable ignore ) {
 			}
 			log.info( "Completed test-suite [" + getName() + "]" );
 		}
 	}
 
 	public void runTest(Test test, TestResult testResult) {
 		testPosition++;
 		if ( environmentSetupError != null ) {
 			testResult.startTest( test );
 			testResult.addError( test, environmentSetupError );
 			testResult.endTest( test );
 			return;
 		}
 		if ( ! ( test instanceof FunctionalTestCase ) ) {
 			super.runTest( test, testResult );
 		}
 		else {
 			FunctionalTestCase functionalTest = ( ( FunctionalTestCase ) test );
 			try {
 				// disallow rebuilding the schema because this is the last test
 				// in this suite, thus it is about to get dropped immediately
 				// afterwards anyway...
 				environment.setAllowRebuild( testPosition < testCount );
 				functionalTest.setEnvironment( environment );
 				super.runTest( functionalTest, testResult );
 			}
 			finally {
 				functionalTest.setEnvironment( null );
 			}
 		}
 	}
 
 	protected void setUp() {
 		if ( settings == null ) {
 			return;
 		}
 		log.info( "Building aggregated execution environment" );
 		try {
 			environment = new ExecutionEnvironment( settings );
-			environment.initialize();
+			environment.initialize( getConnectionProviderInjectionProperties() );
 		}
 		catch( Throwable t ) {
 			environmentSetupError = t;
 		}
 	}
 
+	protected Map getConnectionProviderInjectionProperties() {
+		return Collections.EMPTY_MAP;
+	}
+
 	protected void tearDown() {
 		if ( environment != null ) {
 			log.info( "Destroying aggregated execution environment" );
 			environment.complete();
 			this.environment = null;
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/testing/junit/functional/annotations/HibernateTestCase.java b/hibernate-core/src/test/java/org/hibernate/testing/junit/functional/annotations/HibernateTestCase.java
index 34bee3d876..7e2fe5be78 100644
--- a/hibernate-core/src/test/java/org/hibernate/testing/junit/functional/annotations/HibernateTestCase.java
+++ b/hibernate-core/src/test/java/org/hibernate/testing/junit/functional/annotations/HibernateTestCase.java
@@ -1,334 +1,355 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 
 // $Id$
 
 package org.hibernate.testing.junit.functional.annotations;
 
 import java.lang.annotation.Annotation;
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Method;
 import java.lang.reflect.Modifier;
 import java.sql.Connection;
 import java.sql.SQLException;
 
 import junit.framework.TestCase;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import org.hibernate.cfg.Configuration;
+import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.Dialect;
+import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.jdbc.Work;
+import org.hibernate.service.spi.ServicesRegistry;
+import org.hibernate.test.common.ServiceRegistryHolder;
 import org.hibernate.testing.junit.DialectChecks;
 import org.hibernate.testing.junit.FailureExpected;
 import org.hibernate.testing.junit.RequiresDialect;
 import org.hibernate.testing.junit.RequiresDialectFeature;
 import org.hibernate.testing.junit.SkipForDialect;
 import org.hibernate.testing.junit.SkipLog;
 import org.hibernate.tool.hbm2ddl.SchemaExport;
 import org.hibernate.util.StringHelper;
 
 /**
  * A base class for all tests.
  *
  * @author Emmnauel Bernand
  * @author Hardy Ferentschik
  */
 public abstract class HibernateTestCase extends TestCase {
 
 	public static final Logger log = LoggerFactory.getLogger( HibernateTestCase.class );
 
 	protected static Configuration cfg;
 	private static Class<?> lastTestClass;
+	private ServiceRegistryHolder serviceRegistryHolder;
 
 	public HibernateTestCase() {
 		super();
 	}
 
 	public HibernateTestCase(String x) {
 		super( x );
 	}
 
 	@Override
 	public void runBare() throws Throwable {
 		Method runMethod = findTestMethod();
 
 		final Skip skip = determineSkipByDialect( Dialect.getDialect(), runMethod );
 		if ( skip != null ) {
 			reportSkip( skip );
 			return;
 		}
 
 		setUp();
 		try {
 			runTest();
 		}
 		finally {
 			tearDown();
 		}
 	}
 
 	@Override
 	protected void runTest() throws Throwable {
 		Method runMethod = findTestMethod();
 		FailureExpected failureExpected = locateAnnotation( FailureExpected.class, runMethod );
 		try {
 			super.runTest();
 			if ( failureExpected != null ) {
 				throw new FailureExpectedTestPassedException();
 			}
 		}
 		catch ( FailureExpectedTestPassedException t ) {
 			closeResources();
 			throw t;
 		}
 		catch ( Throwable t ) {
 			if ( t instanceof InvocationTargetException ) {
 				t = ( ( InvocationTargetException ) t ).getTargetException();
 			}
 			if ( t instanceof IllegalAccessException ) {
 				t.fillInStackTrace();
 			}
 			closeResources();
 			if ( failureExpected != null ) {
 				StringBuilder builder = new StringBuilder();
 				if ( StringHelper.isNotEmpty( failureExpected.message() ) ) {
 					builder.append( failureExpected.message() );
 				}
 				else {
 					builder.append( "ignoring @FailureExpected test" );
 				}
 				builder.append( " (" )
 						.append( failureExpected.jiraKey() )
 						.append( ")" );
 				SkipLog.LOG.warn( builder.toString(), t );
 			}
 			else {
 				throw t;
 			}
 		}
 	}
 
 	@Override
 	protected void setUp() throws Exception {
 		if ( cfg == null || lastTestClass != getClass() ) {
 			buildConfiguration();
 			lastTestClass = getClass();
 		}
 		else {
 			runSchemaGeneration();
 		}
 	}
 
 	@Override
 	protected void tearDown() throws Exception {
 		runSchemaDrop();
 		handleUnclosedResources();
 	}
 
+	protected ServicesRegistry getServiceRegistry() {
+		if ( serviceRegistryHolder == null ) {
+			serviceRegistryHolder = new ServiceRegistryHolder( Environment.getProperties() );
+		}
+		return serviceRegistryHolder.getServiceRegistry();
+ 	}
+
+	protected JdbcServices getJdbcServices() {
+		return getServiceRegistry().getService( JdbcServices.class );
+	}
+
 	protected static class Skip {
 		private final String reason;
 		private final String testDescription;
 
 		public Skip(String reason, String testDescription) {
 			this.reason = reason;
 			this.testDescription = testDescription;
 		}
 	}
 
 	protected final Skip determineSkipByDialect(Dialect dialect, Method runMethod) throws Exception {
 		// skips have precedence, so check them first
 		SkipForDialect skipForDialectAnn = locateAnnotation( SkipForDialect.class, runMethod );
 		if ( skipForDialectAnn != null ) {
 			for ( Class<? extends Dialect> dialectClass : skipForDialectAnn.value() ) {
 				if ( skipForDialectAnn.strictMatching() ) {
 					if ( dialectClass.equals( dialect.getClass() ) ) {
 						return buildSkip( dialect, skipForDialectAnn.comment(), skipForDialectAnn.jiraKey() );
 					}
 				}
 				else {
 					if ( dialectClass.isInstance( dialect ) ) {
 						return buildSkip( dialect, skipForDialectAnn.comment(), skipForDialectAnn.jiraKey() );
 					}
 				}
 			}
 		}
 
 		// then check against the requires
 		RequiresDialect requiresDialectAnn = locateAnnotation( RequiresDialect.class, runMethod );
 		if ( requiresDialectAnn != null ) {
 			for ( Class<? extends Dialect> dialectClass : requiresDialectAnn.value() ) {
 				if ( requiresDialectAnn.strictMatching() ) {
 					if ( !dialectClass.equals( dialect.getClass() ) ) {
 						return buildSkip( dialect, null, null );
 					}
 				}
 				else {
 					if ( !dialectClass.isInstance( dialect ) ) {
 						return buildSkip( dialect, requiresDialectAnn.comment(), requiresDialectAnn.jiraKey() );
 					}
 				}
 			}
 		}
 
 		// then check against a dialect feature
 		RequiresDialectFeature requiresDialectFeatureAnn = locateAnnotation( RequiresDialectFeature.class, runMethod );
 		if ( requiresDialectFeatureAnn != null ) {
 			Class<? extends DialectChecks> checkClass = requiresDialectFeatureAnn.value();
 			DialectChecks check = checkClass.newInstance();
 			boolean skip = !check.include( dialect );
 			if ( skip ) {
 				return buildSkip( dialect, requiresDialectFeatureAnn.comment(), requiresDialectFeatureAnn.jiraKey() );
 			}
 		}
 		return null;
 	}
 
 	protected <T extends Annotation> T locateAnnotation(Class<T> annotationClass, Method runMethod) {
 		T annotation = runMethod.getAnnotation( annotationClass );
 		if ( annotation == null ) {
 			annotation = getClass().getAnnotation( annotationClass );
 		}
 		if ( annotation == null ) {
 			annotation = runMethod.getDeclaringClass().getAnnotation( annotationClass );
 		}
 		return annotation;
 	}
 
 	protected Skip buildSkip(Dialect dialect, String comment, String jiraKey) {
 		StringBuilder buffer = new StringBuilder();
 		buffer.append( "skipping database-specific test [" );
 		buffer.append( fullTestName() );
 		buffer.append( "] for dialect [" );
 		buffer.append( dialect.getClass().getName() );
 		buffer.append( ']' );
 
 		if ( StringHelper.isNotEmpty( comment ) ) {
 			buffer.append( "; " ).append( comment );
 		}
 
 		if ( StringHelper.isNotEmpty( jiraKey ) ) {
 			buffer.append( " (" ).append( jiraKey ).append( ')' );
 		}
 
 		return new Skip( buffer.toString(), null );
 	}
 
 	public String fullTestName() {
 		return this.getClass().getName() + "#" + this.getName();
 	}
 
 	private Method findTestMethod() {
 		String fName = getName();
 		assertNotNull( fName );
 		Method runMethod = null;
 		try {
 			runMethod = getClass().getMethod( fName );
 		}
 		catch ( NoSuchMethodException e ) {
 			fail( "Method \"" + fName + "\" not found" );
 		}
 		if ( !Modifier.isPublic( runMethod.getModifiers() ) ) {
 			fail( "Method \"" + fName + "\" should be public" );
 		}
 		return runMethod;
 	}
 
 	protected abstract void buildConfiguration() throws Exception;
 
 	protected abstract Class<?>[] getAnnotatedClasses();
 
 	protected String[] getMappings() {
 		return new String[] { };
 	}
 
 	protected abstract void handleUnclosedResources();
 
-	protected abstract void closeResources();
+	protected void closeResources() {
+		if ( serviceRegistryHolder != null ) {
+			serviceRegistryHolder.destroy();
+			serviceRegistryHolder = null;
+		}
+	}
 
 	protected String[] getAnnotatedPackages() {
 		return new String[] { };
 	}
 
 	protected String[] getXmlFiles() {
 		return new String[] { };
 	}
 
 	protected Dialect getDialect() {
 		return Dialect.getDialect();
 	}
 
 	protected static void setCfg(Configuration cfg) {
 		HibernateTestCase.cfg = cfg;
 	}
 
 	protected static Configuration getCfg() {
 		return cfg;
 	}
 
 	protected void configure(Configuration cfg) {
 	}
 
 	protected boolean recreateSchema() {
 		return true;
 	}
 
 	protected void runSchemaGeneration() {
-		SchemaExport export = new SchemaExport( cfg );
+		SchemaExport export = new SchemaExport( getJdbcServices(), cfg );
 		export.create( true, true );
 	}
 
 	protected void runSchemaDrop() {
-		SchemaExport export = new SchemaExport( cfg );
+		SchemaExport export = new SchemaExport( getJdbcServices(), cfg );
 		export.drop( true, true );
 	}
 
 	private void reportSkip(Skip skip) {
 		reportSkip( skip.reason, skip.testDescription );
 	}
 
 	protected void reportSkip(String reason, String testDescription) {
 		StringBuilder builder = new StringBuilder();
 		builder.append( "*** skipping test [" );
 		builder.append( fullTestName() );
 		builder.append( "] - " );
 		builder.append( testDescription );
 		builder.append( " : " );
 		builder.append( reason );
 		SkipLog.LOG.warn( builder.toString() );
 	}
 
 	public class RollbackWork implements Work {
 
 		public void execute(Connection connection) throws SQLException {
 			connection.rollback();
 		}
 	}
 
 	private static class FailureExpectedTestPassedException extends Exception {
 		public FailureExpectedTestPassedException() {
 			super( "Test marked as @FailureExpected, but did not fail!" );
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/testing/tm/ConnectionProviderImpl.java b/hibernate-core/src/test/java/org/hibernate/testing/tm/ConnectionProviderImpl.java
index 9c73a197d0..3afb91af59 100644
--- a/hibernate-core/src/test/java/org/hibernate/testing/tm/ConnectionProviderImpl.java
+++ b/hibernate-core/src/test/java/org/hibernate/testing/tm/ConnectionProviderImpl.java
@@ -1,83 +1,86 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.tm;
 
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
-import org.hibernate.connection.ConnectionProvider;
-import org.hibernate.connection.ConnectionProviderFactory;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
+import org.hibernate.service.spi.Stoppable;
+import org.hibernate.test.common.ConnectionProviderBuilder;
 
 /**
  * A {@link ConnectionProvider} implementation adding JTA-style transactionality
  * around the returned connections using the {@link SimpleJtaTransactionManagerImpl}.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class ConnectionProviderImpl implements ConnectionProvider {
-	private static ConnectionProvider actualConnectionProvider = ConnectionProviderFactory.newConnectionProvider();
+	private static ConnectionProvider actualConnectionProvider = ConnectionProviderBuilder.buildConnectionProvider();
 
 	private boolean isTransactional;
 
 	public static ConnectionProvider getActualConnectionProvider() {
 		return actualConnectionProvider;
 	}
 
 	public void configure(Properties props) throws HibernateException {
 	}
 
 	public Connection getConnection() throws SQLException {
 		SimpleJtaTransactionImpl currentTransaction = SimpleJtaTransactionManagerImpl.getInstance().getCurrentTransaction();
 		if ( currentTransaction == null ) {
 			isTransactional = false;
 			return actualConnectionProvider.getConnection();
 		}
 		else {
 			isTransactional = true;
 			Connection connection = currentTransaction.getEnlistedConnection();
 			if ( connection == null ) {
 				connection = actualConnectionProvider.getConnection();
 				currentTransaction.enlistConnection( connection );
 			}
 			return connection;
 		}
 	}
 
 	public void closeConnection(Connection conn) throws SQLException {
 		if ( !isTransactional ) {
 			conn.close();
 		}
 	}
 
 	public void close() throws HibernateException {
-		actualConnectionProvider.close();
+		if ( actualConnectionProvider instanceof Stoppable ) {
+			( ( Stoppable ) actualConnectionProvider ).stop();
+		}
 	}
 
 	public boolean supportsAggressiveRelease() {
 		return true;
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/Ejb3Configuration.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/Ejb3Configuration.java
index 95dd417454..ca53cc4ec3 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/Ejb3Configuration.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/Ejb3Configuration.java
@@ -1,1637 +1,1641 @@
 // $Id$
 /*
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb;
 
 import java.io.BufferedInputStream;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.ObjectOutput;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.lang.annotation.Annotation;
 import java.net.URL;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.Enumeration;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import java.util.StringTokenizer;
 import javax.naming.BinaryRefAddr;
 import javax.naming.NamingException;
 import javax.naming.Reference;
 import javax.naming.Referenceable;
 import javax.persistence.Embeddable;
 import javax.persistence.Entity;
 import javax.persistence.EntityManagerFactory;
 import javax.persistence.EntityNotFoundException;
 import javax.persistence.MappedSuperclass;
 import javax.persistence.PersistenceException;
 import javax.persistence.spi.PersistenceUnitInfo;
 import javax.persistence.spi.PersistenceUnitTransactionType;
 import javax.sql.DataSource;
 
 import org.dom4j.Element;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.xml.sax.EntityResolver;
 import org.xml.sax.InputSource;
 
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.MappingException;
 import org.hibernate.MappingNotFoundException;
 import org.hibernate.SessionFactory;
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.cfg.Settings;
-import org.hibernate.cfg.SettingsFactory;
 import org.hibernate.cfg.annotations.reflection.XMLContext;
 import org.hibernate.ejb.connection.InjectedDataSourceConnectionProvider;
 import org.hibernate.ejb.instrument.InterceptFieldClassFileTransformer;
 import org.hibernate.ejb.packaging.JarVisitorFactory;
 import org.hibernate.ejb.packaging.NamedInputStream;
 import org.hibernate.ejb.packaging.NativeScanner;
 import org.hibernate.ejb.packaging.PersistenceMetadata;
 import org.hibernate.ejb.packaging.PersistenceXmlLoader;
 import org.hibernate.ejb.packaging.Scanner;
 import org.hibernate.ejb.transaction.JoinableCMTTransactionFactory;
 import org.hibernate.ejb.util.ConfigurationHelper;
 import org.hibernate.ejb.util.LogHelper;
 import org.hibernate.ejb.util.NamingHelper;
 import org.hibernate.engine.FilterDefinition;
 import org.hibernate.event.EventListeners;
 import org.hibernate.mapping.AuxiliaryDatabaseObject;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.proxy.EntityNotFoundDelegate;
 import org.hibernate.secure.JACCConfiguration;
+import org.hibernate.service.jdbc.connections.internal.ConnectionProviderInitiator;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
+import org.hibernate.service.spi.ServicesRegistry;
 import org.hibernate.transaction.JDBCTransactionFactory;
 import org.hibernate.util.CollectionHelper;
 import org.hibernate.util.ReflectHelper;
 import org.hibernate.util.StringHelper;
 import org.hibernate.util.xml.MappingReader;
 import org.hibernate.util.xml.OriginImpl;
 import org.hibernate.util.xml.XmlDocument;
 
 /**
  * Allow a fine tuned configuration of an EJB 3.0 EntityManagerFactory
  *
  * A Ejb3Configuration object is only guaranteed to create one EntityManagerFactory.
  * Multiple usage of #buildEntityManagerFactory() is not guaranteed.
  *
  * After #buildEntityManagerFactory() has been called, you no longer can change the configuration
  * state (no class adding, no property change etc)
  *
  * When serialized / deserialized or retrieved from the JNDI, you no longer can change the
  * configuration state (no class adding, no property change etc)
  *
  * Putting the configuration in the JNDI is an expensive operation that requires a partial
  * serialization
  *
  * @author Emmanuel Bernard
  */
 public class Ejb3Configuration implements Serializable, Referenceable {
 	private final Logger log = LoggerFactory.getLogger( Ejb3Configuration.class );
 	private static final String IMPLEMENTATION_NAME = HibernatePersistence.class.getName();
 	private static final String META_INF_ORM_XML = "META-INF/orm.xml";
 	private static final String PARSED_MAPPING_DOMS = "hibernate.internal.mapping_doms";
 
 	private static EntityNotFoundDelegate ejb3EntityNotFoundDelegate = new Ejb3EntityNotFoundDelegate();
 	private static Configuration DEFAULT_CONFIGURATION = new AnnotationConfiguration();
 
 	private static class Ejb3EntityNotFoundDelegate implements EntityNotFoundDelegate, Serializable {
 		public void handleEntityNotFound(String entityName, Serializable id) {
 			throw new EntityNotFoundException("Unable to find " + entityName  + " with id " + id);
 		}
 	}
 
 	static {
 		Version.touch();
 	}
 
 	private String persistenceUnitName;
 	private String cfgXmlResource;
 
 	private AnnotationConfiguration cfg;
-	private SettingsFactory settingsFactory;
+	private final Map connectionProviderInjectionData;
 	//made transient and not restored in deserialization on purpose, should no longer be called after restoration
 	private transient EventListenerConfigurator listenerConfigurator;
 	private PersistenceUnitTransactionType transactionType;
 	private boolean discardOnClose;
 	//made transient and not restored in deserialization on purpose, should no longer be called after restoration
 	private transient ClassLoader overridenClassLoader;
 	private boolean isConfigurationProcessed = false;
 
 
 	public Ejb3Configuration() {
-		settingsFactory = new InjectionSettingsFactory();
-		cfg = new AnnotationConfiguration( settingsFactory );
+		connectionProviderInjectionData = new HashMap();
+		cfg = new AnnotationConfiguration();
 		cfg.setEntityNotFoundDelegate( ejb3EntityNotFoundDelegate );
 		listenerConfigurator = new EventListenerConfigurator( this );
 	}
 
 	/**
 	 * Used to inject a datasource object as the connection provider.
 	 * If used, be sure to <b>not override</b> the hibernate.connection.provider_class
 	 * property
 	 */
 	@SuppressWarnings({ "JavaDoc", "unchecked" })
 	public void setDataSource(DataSource ds) {
 		if ( ds != null ) {
 			Map cpInjection = new HashMap();
 			cpInjection.put( "dataSource", ds );
-			( (InjectionSettingsFactory) settingsFactory ).setConnectionProviderInjectionData( cpInjection );
+			connectionProviderInjectionData.put( ConnectionProviderInitiator.INJECTION_DATA, cpInjection );
 			this.setProperty( Environment.CONNECTION_PROVIDER, InjectedDataSourceConnectionProvider.class.getName() );
 		}
 	}
 
 	/**
 	 * create a factory from a parsed persistence.xml
 	 * Especially the scanning of classes and additional jars is done already at this point.
 	 * <p/>
 	 * NOTE: public only for unit testing purposes; not a public API!
 	 *
 	 * @param metadata The information parsed from the persistence.xml
 	 * @param overridesIn Any explicitly passed config settings
 	 *
 	 * @return this
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public Ejb3Configuration configure(PersistenceMetadata metadata, Map overridesIn) {
 		log.debug( "Creating Factory: {}", metadata.getName() );
 
 		Map overrides = new HashMap();
 		if ( overridesIn != null ) {
 			overrides.putAll( overridesIn );
 		}
 
 		Map workingVars = new HashMap();
 		workingVars.put( AvailableSettings.PERSISTENCE_UNIT_NAME, metadata.getName() );
 		this.persistenceUnitName = metadata.getName();
 
 		if ( StringHelper.isNotEmpty( metadata.getJtaDatasource() ) ) {
 			this.setProperty( Environment.DATASOURCE, metadata.getJtaDatasource() );
 		}
 		else if ( StringHelper.isNotEmpty( metadata.getNonJtaDatasource() ) ) {
 			this.setProperty( Environment.DATASOURCE, metadata.getNonJtaDatasource() );
 		}
 		else {
 			final String driver = (String) metadata.getProps().get( AvailableSettings.JDBC_DRIVER );
 			if ( StringHelper.isNotEmpty( driver ) ) {
 				this.setProperty( Environment.DRIVER, driver );
 			}
 			final String url = (String) metadata.getProps().get( AvailableSettings.JDBC_URL );
 			if ( StringHelper.isNotEmpty( url ) ) {
 				this.setProperty( Environment.URL, url );
 			}
 			final String user = (String) metadata.getProps().get( AvailableSettings.JDBC_USER );
 			if ( StringHelper.isNotEmpty( user ) ) {
 				this.setProperty( Environment.USER, user );
 			}
 			final String pass = (String) metadata.getProps().get( AvailableSettings.JDBC_PASSWORD );
 			if ( StringHelper.isNotEmpty( pass ) ) {
 				this.setProperty( Environment.PASS, pass );
 			}
 		}
 		defineTransactionType( metadata.getTransactionType(), workingVars );
 		if ( metadata.getClasses().size() > 0 ) {
 			workingVars.put( AvailableSettings.CLASS_NAMES, metadata.getClasses() );
 		}
 		if ( metadata.getPackages().size() > 0 ) {
 			workingVars.put( AvailableSettings.PACKAGE_NAMES, metadata.getPackages() );
 		}
 		if ( metadata.getMappingFiles().size() > 0 ) {
 			workingVars.put( AvailableSettings.XML_FILE_NAMES, metadata.getMappingFiles() );
 		}
 		if ( metadata.getHbmfiles().size() > 0 ) {
 			workingVars.put( AvailableSettings.HBXML_FILES, metadata.getHbmfiles() );
 		}
 
 		Properties props = new Properties();
 		props.putAll( metadata.getProps() );
 
 		// validation factory
 		final Object validationFactory = overrides.get( AvailableSettings.VALIDATION_FACTORY );
 		if ( validationFactory != null ) {
 			props.put( AvailableSettings.VALIDATION_FACTORY, validationFactory );
 		}
 		overrides.remove( AvailableSettings.VALIDATION_FACTORY );
 
 		// validation-mode (overrides has precedence)
 		{
 			final Object integrationValue = overrides.get( AvailableSettings.VALIDATION_MODE );
 			if ( integrationValue != null ) {
 				props.put( AvailableSettings.VALIDATION_MODE, integrationValue.toString() );
 			}
 			else if ( metadata.getValidationMode() != null ) {
 				props.put( AvailableSettings.VALIDATION_MODE, metadata.getValidationMode() );
 			}
 			overrides.remove( AvailableSettings.VALIDATION_MODE );
 		}
 
 		// shared-cache-mode (overrides has precedence)
 		{
 			final Object integrationValue = overrides.get( AvailableSettings.SHARED_CACHE_MODE );
 			if ( integrationValue != null ) {
 				props.put( AvailableSettings.SHARED_CACHE_MODE, integrationValue.toString() );
 			}
 			else if ( metadata.getSharedCacheMode() != null ) {
 				props.put( AvailableSettings.SHARED_CACHE_MODE, metadata.getSharedCacheMode() );
 			}
 			overrides.remove( AvailableSettings.SHARED_CACHE_MODE );
 		}
 
 		for ( Map.Entry entry : (Set<Map.Entry>) overrides.entrySet() ) {
 			Object value = entry.getValue();
 			props.put( entry.getKey(), value == null ? "" :  value ); //alter null, not allowed in properties
 		}
 
 		configure( props, workingVars );
 		return this;
 	}
 
 	/**
 	 * Build the configuration from an entity manager name and given the
 	 * appropriate extra properties. Those properties override the one get through
 	 * the peristence.xml file.
 	 * If the persistence unit name is not found or does not match the Persistence Provider, null is returned
 	 *
 	 * This method is used in a non managed environment
 	 *
 	 * @param persistenceUnitName persistence unit name
 	 * @param integration properties passed to the persistence provider
 	 *
 	 * @return configured Ejb3Configuration or null if no persistence unit match
 	 *
 	 * @see HibernatePersistence#createEntityManagerFactory(String, java.util.Map)
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public Ejb3Configuration configure(String persistenceUnitName, Map integration) {
 		try {
 			log.debug( "Look up for persistence unit: {}", persistenceUnitName );
 			integration = integration == null ?
 					CollectionHelper.EMPTY_MAP :
 					Collections.unmodifiableMap( integration );
 			Enumeration<URL> xmls = Thread.currentThread()
 					.getContextClassLoader()
 					.getResources( "META-INF/persistence.xml" );
 			if ( ! xmls.hasMoreElements() ) {
 				log.info( "Could not find any META-INF/persistence.xml file in the classpath");
 			}
 			while ( xmls.hasMoreElements() ) {
 				URL url = xmls.nextElement();
 				log.trace( "Analysing persistence.xml: {}", url );
 				List<PersistenceMetadata> metadataFiles = PersistenceXmlLoader.deploy(
 						url,
 						integration,
 						cfg.getEntityResolver(),
 						PersistenceUnitTransactionType.RESOURCE_LOCAL );
 				for ( PersistenceMetadata metadata : metadataFiles ) {
 					log.trace( "{}", metadata );
 
 					if ( metadata.getProvider() == null || IMPLEMENTATION_NAME.equalsIgnoreCase(
 							metadata.getProvider()
 					) ) {
 						//correct provider
 
 						//lazy load the scanner to avoid unnecessary IOExceptions
 						Scanner scanner = null;
 						URL jarURL = null;
 						if ( metadata.getName() == null ) {
 							scanner = buildScanner( metadata.getProps(), integration );
 							jarURL = JarVisitorFactory.getJarURLFromURLEntry( url, "/META-INF/persistence.xml" );
 							metadata.setName( scanner.getUnqualifiedJarName(jarURL) );
 						}
 						if ( persistenceUnitName == null && xmls.hasMoreElements() ) {
 							throw new PersistenceException( "No name provided and several persistence units found" );
 						}
 						else if ( persistenceUnitName == null || metadata.getName().equals( persistenceUnitName ) ) {
 							if (scanner == null) {
 								scanner = buildScanner( metadata.getProps(), integration );
 								jarURL = JarVisitorFactory.getJarURLFromURLEntry( url, "/META-INF/persistence.xml" );
 							}
 							//scan main JAR
 							ScanningContext mainJarScanCtx = new ScanningContext()
 									.scanner( scanner )
 									.url( jarURL )
 									.explicitMappingFiles( metadata.getMappingFiles() )
 									.searchOrm( true );
 							setDetectedArtifactsOnScanningContext( mainJarScanCtx, metadata.getProps(), integration,
 																				metadata.getExcludeUnlistedClasses() );
 							addMetadataFromScan( mainJarScanCtx, metadata );
 
 							ScanningContext otherJarScanCtx = new ScanningContext()
 									.scanner( scanner )
 									.explicitMappingFiles( metadata.getMappingFiles() )
 									.searchOrm( true );
 							setDetectedArtifactsOnScanningContext( otherJarScanCtx, metadata.getProps(), integration,
 																				false );
 							for ( String jarFile : metadata.getJarFiles() ) {
 								otherJarScanCtx.url( JarVisitorFactory.getURLFromPath( jarFile ) );
 								addMetadataFromScan( otherJarScanCtx, metadata );
 							}
 							return configure( metadata, integration );
 						}
 					}
 				}
 			}
 			return null;
 		}
 		catch (Exception e) {
 			if ( e instanceof PersistenceException) {
 				throw (PersistenceException) e;
 			}
 			else {
 				throw new PersistenceException( getExceptionHeader() + "Unable to configure EntityManagerFactory", e );
 			}
 		}
 	}
 
 	private Scanner buildScanner(Properties properties, Map<?,?> integration) {
 		//read the String or Instance from the integration map first and use the properties as a backup.
 		Object scanner = integration.get( AvailableSettings.SCANNER );
 		if (scanner == null) {
 			scanner = properties.getProperty( AvailableSettings.SCANNER );
 		}
 		if (scanner != null) {
 			Class<?> scannerClass;
 			if ( scanner instanceof String ) {
 				try {
 					scannerClass = ReflectHelper.classForName( (String) scanner, this.getClass() );
 				}
 				catch ( ClassNotFoundException e ) {
 					throw new PersistenceException(  "Cannot find scanner class. " + AvailableSettings.SCANNER + "=" + scanner, e );
 				}
 			}
 			else if (scanner instanceof Class) {
 				scannerClass = (Class<? extends Scanner>) scanner;
 			}
 			else if (scanner instanceof Scanner) {
 				return (Scanner) scanner;
 			}
 			else {
 				throw new PersistenceException(  "Scanner class configuration error: unknown type on the property. " + AvailableSettings.SCANNER );
 			}
 			try {
 				return (Scanner) scannerClass.newInstance();
 			}
 			catch ( InstantiationException e ) {
 				throw new PersistenceException(  "Unable to load Scanner class: " + scannerClass, e );
 			}
 			catch ( IllegalAccessException e ) {
 				throw new PersistenceException(  "Unable to load Scanner class: " + scannerClass, e );
 			}
 		}
 		else {
 			return new NativeScanner();
 		}
 	}
 
 	private static class ScanningContext {
 		//boolean excludeUnlistedClasses;
 		private Scanner scanner;
 		private URL url;
 		private List<String> explicitMappingFiles;
 		private boolean detectClasses;
 		private boolean detectHbmFiles;
 		private boolean searchOrm;
 
 		public ScanningContext scanner(Scanner scanner) {
 			this.scanner = scanner;
 			return this;
 		}
 
 		public ScanningContext url(URL url) {
 			this.url = url;
 			return this;
 		}
 
 		public ScanningContext explicitMappingFiles(List<String> explicitMappingFiles) {
 			this.explicitMappingFiles = explicitMappingFiles;
 			return this;
 		}
 
 		public ScanningContext detectClasses(boolean detectClasses) {
 			this.detectClasses = detectClasses;
 			return this;
 		}
 
 		public ScanningContext detectHbmFiles(boolean detectHbmFiles) {
 			this.detectHbmFiles = detectHbmFiles;
 			return this;
 		}
 
 		public ScanningContext searchOrm(boolean searchOrm) {
 			this.searchOrm = searchOrm;
 			return this;
 		}
 	}
 
 	private static void addMetadataFromScan(ScanningContext scanningContext, PersistenceMetadata metadata) throws IOException {
 		List<String> classes = metadata.getClasses();
 		List<String> packages = metadata.getPackages();
 		List<NamedInputStream> hbmFiles = metadata.getHbmfiles();
 		List<String> mappingFiles = metadata.getMappingFiles();
 		addScannedEntries( scanningContext, classes, packages, hbmFiles, mappingFiles );
 	}
 
 	private static void addScannedEntries(ScanningContext scanningContext, List<String> classes, List<String> packages, List<NamedInputStream> hbmFiles, List<String> mappingFiles) throws IOException {
 		Scanner scanner = scanningContext.scanner;
 		if (scanningContext.detectClasses) {
 			Set<Class<? extends Annotation>> annotationsToExclude = new HashSet<Class<? extends Annotation>>(3);
 			annotationsToExclude.add( Entity.class );
 			annotationsToExclude.add( MappedSuperclass.class );
 			annotationsToExclude.add( Embeddable.class );
 			Set<Class<?>> matchingClasses = scanner.getClassesInJar( scanningContext.url, annotationsToExclude );
 			for (Class<?> clazz : matchingClasses) {
 				classes.add( clazz.getName() );
 			}
 
 			Set<Package> matchingPackages = scanner.getPackagesInJar( scanningContext.url, new HashSet<Class<? extends Annotation>>(0) );
 			for (Package pkg : matchingPackages) {
 				packages.add( pkg.getName() );
 			}
 		}
 		Set<String> patterns = new HashSet<String>();
 		if (scanningContext.searchOrm) {
 			patterns.add( META_INF_ORM_XML );
 		}
 		if (scanningContext.detectHbmFiles) {
 			patterns.add( "**/*.hbm.xml" );
 		}
 		if ( mappingFiles != null) patterns.addAll( mappingFiles );
 		if (patterns.size() !=0) {
 			Set<NamedInputStream> files = scanner.getFilesInJar( scanningContext.url, patterns );
 			for (NamedInputStream file : files) {
 				hbmFiles.add( file );
 				if (mappingFiles != null) mappingFiles.remove( file.getName() );
 			}
 		}
 	}
 
 	/**
 	 * Process configuration from a PersistenceUnitInfo object; typically called by the container
 	 * via {@link javax.persistence.spi.PersistenceProvider#createContainerEntityManagerFactory}.
 	 * In Hibernate EM, this correlates to {@link HibernatePersistence#createContainerEntityManagerFactory}
 	 *
 	 * @param info The persistence unit info passed in by the container (usually from processing a persistence.xml).
 	 * @param integration The map of integration properties from the container to configure the provider.
 	 *
 	 * @return The configured EJB3Configurartion object
 	 *
 	 * @see HibernatePersistence#createContainerEntityManagerFactory
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public Ejb3Configuration configure(PersistenceUnitInfo info, Map integration) {
 		if ( log.isDebugEnabled() ) {
 			log.debug( "Processing {}", LogHelper.logPersistenceUnitInfo( info ) );
 		}
 		else {
 			log.info( "Processing PersistenceUnitInfo [\n\tname: {}\n\t...]", info.getPersistenceUnitName() );
 		}
 
 		// Spec says the passed map may be null, so handle that to make further processing easier...
 		integration = integration != null ? Collections.unmodifiableMap( integration ) : CollectionHelper.EMPTY_MAP;
 
 		// See if we (Hibernate) are the persistence provider
 		String provider = (String) integration.get( AvailableSettings.PROVIDER );
 		if ( provider == null ) {
 			provider = info.getPersistenceProviderClassName();
 		}
 		if ( provider != null && ! provider.trim().startsWith( IMPLEMENTATION_NAME ) ) {
 			log.info( "Required a different provider: {}", provider );
 			return null;
 		}
 
 		// set the classloader, passed in by the container in info, to set as the TCCL so that
 		// Hibernate uses it to properly resolve class references.
 		if ( info.getClassLoader() == null ) {
 			throw new IllegalStateException(
 					"[PersistenceUnit: " + info.getPersistenceUnitName() == null ? "" : info.getPersistenceUnitName()
 							+ "] " + "PersistenceUnitInfo.getClassLoader() id null" );
 		}
 		Thread thread = Thread.currentThread();
 		ClassLoader contextClassLoader = thread.getContextClassLoader();
 		boolean sameClassLoader = info.getClassLoader().equals( contextClassLoader );
 		if ( ! sameClassLoader ) {
 			overridenClassLoader = info.getClassLoader();
 			thread.setContextClassLoader( overridenClassLoader );
 		}
 		else {
 			overridenClassLoader = null;
 		}
 
 		// Best I can tell, 'workingVars' is some form of additional configuration contract.
 		// But it does not correlate 1-1 to EMF/SF settings.  It really is like a set of de-typed
 		// additional configuration info.  I think it makes better sense to define this as an actual
 		// contract if that was in fact the intent; the code here is pretty confusing.
 		try {
 			Map workingVars = new HashMap();
 			workingVars.put( AvailableSettings.PERSISTENCE_UNIT_NAME, info.getPersistenceUnitName() );
 			this.persistenceUnitName = info.getPersistenceUnitName();
 			List<String> entities = new ArrayList<String>( 50 );
 			if ( info.getManagedClassNames() != null ) entities.addAll( info.getManagedClassNames() );
 			List<NamedInputStream> hbmFiles = new ArrayList<NamedInputStream>();
 			List<String> packages = new ArrayList<String>();
 			List<String> xmlFiles = new ArrayList<String>( 50 );
 			List<XmlDocument> xmlDocuments = new ArrayList<XmlDocument>( 50 );
 			if ( info.getMappingFileNames() != null ) {
 				xmlFiles.addAll( info.getMappingFileNames() );
 			}
 			//Should always be true if the container is not dump
 			boolean searchForORMFiles = ! xmlFiles.contains( META_INF_ORM_XML );
 
 			ScanningContext context = new ScanningContext();
 			final Properties copyOfProperties = (Properties) info.getProperties().clone();
 			ConfigurationHelper.overrideProperties( copyOfProperties, integration );
 			context.scanner( buildScanner( copyOfProperties, integration ) )
 					.searchOrm( searchForORMFiles )
 					.explicitMappingFiles( null ); //URLs provided by the container already
 
 			//context for other JARs
 			setDetectedArtifactsOnScanningContext(context, info.getProperties(), null, false );
 			for ( URL jar : info.getJarFileUrls() ) {
 				context.url(jar);
 				scanForClasses( context, packages, entities, hbmFiles );
 			}
 
 			//main jar
 			context.url( info.getPersistenceUnitRootUrl() );
 			setDetectedArtifactsOnScanningContext( context, info.getProperties(), null, info.excludeUnlistedClasses() );
 			scanForClasses( context, packages, entities, hbmFiles );
 
 			Properties properties = info.getProperties() != null ? info.getProperties() : new Properties();
 			ConfigurationHelper.overrideProperties( properties, integration );
 
 			//FIXME entities is used to enhance classes and to collect annotated entities this should not be mixed
 			//fill up entities with the on found in xml files
 			addXMLEntities( xmlFiles, info, entities, xmlDocuments );
 
 			//FIXME send the appropriate entites.
 			if ( "true".equalsIgnoreCase( properties.getProperty( AvailableSettings.USE_CLASS_ENHANCER ) ) ) {
 				info.addTransformer( new InterceptFieldClassFileTransformer( entities ) );
 			}
 
 			workingVars.put( AvailableSettings.CLASS_NAMES, entities );
 			workingVars.put( AvailableSettings.PACKAGE_NAMES, packages );
 			workingVars.put( AvailableSettings.XML_FILE_NAMES, xmlFiles );
 			workingVars.put( PARSED_MAPPING_DOMS, xmlDocuments );
 
 			if ( hbmFiles.size() > 0 ) {
 				workingVars.put( AvailableSettings.HBXML_FILES, hbmFiles );
 			}
 
 			// validation factory
 			final Object validationFactory = integration.get( AvailableSettings.VALIDATION_FACTORY );
 			if ( validationFactory != null ) {
 				properties.put( AvailableSettings.VALIDATION_FACTORY, validationFactory );
 			}
 
 			// validation-mode (integration has precedence)
 			{
 				final Object integrationValue = integration.get( AvailableSettings.VALIDATION_MODE );
 				if ( integrationValue != null ) {
 					properties.put( AvailableSettings.VALIDATION_MODE, integrationValue.toString() );
 				}
 				else if ( info.getValidationMode() != null ) {
 					properties.put( AvailableSettings.VALIDATION_MODE, info.getValidationMode().name() );
 				}
 			}
 
 			// shared-cache-mode (integration has precedence)
 			{
 				final Object integrationValue = integration.get( AvailableSettings.SHARED_CACHE_MODE );
 				if ( integrationValue != null ) {
 					properties.put( AvailableSettings.SHARED_CACHE_MODE, integrationValue.toString() );
 				}
 				else if ( info.getSharedCacheMode() != null ) {
 					properties.put( AvailableSettings.SHARED_CACHE_MODE, info.getSharedCacheMode().name() );
 				}
 			}
 
 			//datasources
 			Boolean isJTA = null;
 			boolean overridenDatasource = false;
 			if ( integration.containsKey( AvailableSettings.JTA_DATASOURCE ) ) {
 				String dataSource = (String) integration.get( AvailableSettings.JTA_DATASOURCE );
 				overridenDatasource = true;
 				properties.setProperty( Environment.DATASOURCE, dataSource );
 				isJTA = Boolean.TRUE;
 			}
 			if ( integration.containsKey( AvailableSettings.NON_JTA_DATASOURCE ) ) {
 				String dataSource = (String) integration.get( AvailableSettings.NON_JTA_DATASOURCE );
 				overridenDatasource = true;
 				properties.setProperty( Environment.DATASOURCE, dataSource );
 				if (isJTA == null) isJTA = Boolean.FALSE;
 			}
 
 			if ( ! overridenDatasource && ( info.getJtaDataSource() != null || info.getNonJtaDataSource() != null ) ) {
 				isJTA = info.getJtaDataSource() != null ? Boolean.TRUE : Boolean.FALSE;
 				this.setDataSource(
 						isJTA ? info.getJtaDataSource() : info.getNonJtaDataSource()
 				);
 				this.setProperty(
 						Environment.CONNECTION_PROVIDER, InjectedDataSourceConnectionProvider.class.getName()
 				);
 			}
 			/*
 			 * If explicit type => use it
 			 * If a JTA DS is used => JTA transaction,
 			 * if a non JTA DS is used => RESOURCe_LOCAL
 			 * if none, set to JavaEE default => JTA transaction
 			 */
 			PersistenceUnitTransactionType transactionType = info.getTransactionType();
 			if (transactionType == null) {
 				if (isJTA == Boolean.TRUE) {
 					transactionType = PersistenceUnitTransactionType.JTA;
 				}
 				else if ( isJTA == Boolean.FALSE ) {
 					transactionType = PersistenceUnitTransactionType.RESOURCE_LOCAL;
 				}
 				else {
 					transactionType = PersistenceUnitTransactionType.JTA;
 				}
 			}
 			defineTransactionType( transactionType, workingVars );
 			configure( properties, workingVars );
 		}
 		finally {
 			//After EMF, set the CCL back
 			if ( ! sameClassLoader ) {
 				thread.setContextClassLoader( contextClassLoader );
 			}
 		}
 		return this;
 	}
 
 	/**
 	 * Processes {@code xmlFiles} argument and populates:<ul>
 	 * <li>the {@code entities} list with encountered classnames</li>
 	 * <li>the {@code xmlDocuments} list with parsed/validated {@link XmlDocument} corrolary to each xml file</li>
 	 * </ul>
 	 *
 	 * @param xmlFiles The XML resource names; these will be resolved by classpath lookup and parsed/validated.
 	 * @param info The PUI
 	 * @param entities (output) The names of all encountered "mapped" classes
 	 * @param xmlDocuments (output) The list of {@link XmlDocument} instances of each entry in {@code xmlFiles}
 	 */
 	@SuppressWarnings({ "unchecked" })
 	private void addXMLEntities(
 			List<String> xmlFiles,
 			PersistenceUnitInfo info,
 			List<String> entities,
 			List<XmlDocument> xmlDocuments) {
 		//TODO handle inputstream related hbm files
 		ClassLoader classLoaderToUse = info.getNewTempClassLoader();
 		if ( classLoaderToUse == null ) {
 			log.warn(
 					"Persistence provider caller does not implement the EJB3 spec correctly." +
 							"PersistenceUnitInfo.getNewTempClassLoader() is null."
 			);
 			return;
 		}
 		for ( final String xmlFile : xmlFiles ) {
 			final InputStream fileInputStream = classLoaderToUse.getResourceAsStream( xmlFile );
 			if ( fileInputStream == null ) {
 				log.info( "Unable to resolve mapping file [{}]", xmlFile );
 				continue;
 			}
 			final InputSource inputSource = new InputSource( fileInputStream );
 
 			XmlDocument metadataXml = MappingReader.INSTANCE.readMappingDocument(
 					cfg.getEntityResolver(),
 					inputSource,
 					new OriginImpl( "persistence-unit-info", xmlFile )
 			);
 			xmlDocuments.add( metadataXml );
 			try {
 				final Element rootElement = metadataXml.getDocumentTree().getRootElement();
 				if ( rootElement != null && "entity-mappings".equals( rootElement.getName() ) ) {
 					Element element = rootElement.element( "package" );
 					String defaultPackage = element != null ? element.getTextTrim() : null;
 					List<Element> elements = rootElement.elements( "entity" );
 					for (Element subelement : elements ) {
 						String classname = XMLContext.buildSafeClassName( subelement.attributeValue( "class" ), defaultPackage );
 						if ( ! entities.contains( classname ) ) {
 							entities.add( classname );
 						}
 					}
 					elements = rootElement.elements( "mapped-superclass" );
 					for (Element subelement : elements ) {
 						String classname = XMLContext.buildSafeClassName( subelement.attributeValue( "class" ), defaultPackage );
 						if ( ! entities.contains( classname ) ) {
 							entities.add( classname );
 						}
 					}
 					elements = rootElement.elements( "embeddable" );
 					for (Element subelement : elements ) {
 						String classname = XMLContext.buildSafeClassName( subelement.attributeValue( "class" ), defaultPackage );
 						if ( ! entities.contains( classname ) ) {
 							entities.add( classname );
 						}
 					}
 				}
 				else if ( rootElement != null && "hibernate-mappings".equals( rootElement.getName() ) ) {
 					//FIXME include hbm xml entities to enhance them but entities is also used to collect annotated entities
 				}
 			}
 			finally {
 				try {
 					fileInputStream.close();
 				}
 				catch (IOException ioe) {
 					log.warn( "Could not close input stream", ioe );
 				}
 			}
 		}
 		xmlFiles.clear();
 	}
 
 	private void defineTransactionType(Object overridenTxType, Map workingVars) {
 		if ( overridenTxType == null ) {
 //			if ( transactionType == null ) {
 //				transactionType = PersistenceUnitTransactionType.JTA; //this is the default value
 //			}
 			//nothing to override
 		}
 		else if ( overridenTxType instanceof String ) {
 			transactionType = PersistenceXmlLoader.getTransactionType( (String) overridenTxType );
 		}
 		else if ( overridenTxType instanceof PersistenceUnitTransactionType ) {
 			transactionType = (PersistenceUnitTransactionType) overridenTxType;
 		}
 		else {
 			throw new PersistenceException( getExceptionHeader() +
 					AvailableSettings.TRANSACTION_TYPE + " of the wrong class type"
 							+ ": " + overridenTxType.getClass()
 			);
 		}
 
 	}
 
 	public Ejb3Configuration setProperty(String key, String value) {
 		cfg.setProperty( key, value );
 		return this;
 	}
 
 	/**
 	 * Set ScanningContext detectClasses and detectHbmFiles according to context
 	 */
 	private void setDetectedArtifactsOnScanningContext(ScanningContext context,
 													   Properties properties,
 													   Map overridenProperties,
 													   boolean excludeIfNotOverriden) {
 
 		boolean detectClasses = false;
 		boolean detectHbm = false;
 		String detectSetting = overridenProperties != null ?
 				(String) overridenProperties.get( AvailableSettings.AUTODETECTION ) :
 				null;
 		detectSetting = detectSetting == null ?
 				properties.getProperty( AvailableSettings.AUTODETECTION) :
 				detectSetting;
 		if ( detectSetting == null && excludeIfNotOverriden) {
 			//not overriden through HibernatePersistence.AUTODETECTION so we comply with the spec excludeUnlistedClasses
 			context.detectClasses( false ).detectHbmFiles( false );
 			return;
 		}
 
 		if ( detectSetting == null){
 			detectSetting = "class,hbm";
 		}
 		StringTokenizer st = new StringTokenizer( detectSetting, ", ", false );
 		while ( st.hasMoreElements() ) {
 			String element = (String) st.nextElement();
 			if ( "class".equalsIgnoreCase( element ) ) detectClasses = true;
 			if ( "hbm".equalsIgnoreCase( element ) ) detectHbm = true;
 		}
 		log.debug( "Detect class: {}; detect hbm: {}", detectClasses, detectHbm );
 		context.detectClasses( detectClasses ).detectHbmFiles( detectHbm );
 	}
 
 	private void scanForClasses(ScanningContext scanningContext, List<String> packages, List<String> entities, List<NamedInputStream> hbmFiles) {
 		if (scanningContext.url == null) {
 			log.error( "Container is providing a null PersistenceUnitRootUrl: discovery impossible");
 			return;
 		}
 		try {
 			addScannedEntries( scanningContext, entities, packages, hbmFiles, null );
 		}
 		catch (RuntimeException e) {
 			throw new RuntimeException( "error trying to scan <jar-file>: " + scanningContext.url.toString(), e );
 		}
 		catch( IOException e ) {
 			throw new RuntimeException( "Error while reading " + scanningContext.url.toString(), e );
 		}
 	}
 
 	/**
 	 * create a factory from a list of properties and
 	 * HibernatePersistence.CLASS_NAMES -> Collection<String> (use to list the classes from config files
 	 * HibernatePersistence.PACKAGE_NAMES -> Collection<String> (use to list the mappings from config files
 	 * HibernatePersistence.HBXML_FILES -> Collection<InputStream> (input streams of hbm files)
 	 * HibernatePersistence.LOADED_CLASSES -> Collection<Class> (list of loaded classes)
 	 * <p/>
 	 * <b>Used by JBoss AS only</b>
 	 * @deprecated use the Java Persistence API
 	 */
 	// This is used directly by JBoss so don't remove until further notice.  bill@jboss.org
 	public EntityManagerFactory createEntityManagerFactory(Map workingVars) {
 		Properties props = new Properties();
 		if ( workingVars != null ) {
 			props.putAll( workingVars );
 			//remove huge non String elements for a clean props
 			props.remove( AvailableSettings.CLASS_NAMES );
 			props.remove( AvailableSettings.PACKAGE_NAMES );
 			props.remove( AvailableSettings.HBXML_FILES );
 			props.remove( AvailableSettings.LOADED_CLASSES );
 		}
 		configure( props, workingVars );
 		return buildEntityManagerFactory();
 	}
 
 	/**
 	 * Process configuration and build an EntityManagerFactory <b>when</b> the configuration is ready
 	 * @deprecated
 	 */
 	public EntityManagerFactory createEntityManagerFactory() {
 		configure( cfg.getProperties(), new HashMap() );
 		return buildEntityManagerFactory();
 	}
 
 	public EntityManagerFactory buildEntityManagerFactory() {
 		Thread thread = null;
 		ClassLoader contextClassLoader = null;
 		if (overridenClassLoader != null) {
 			thread = Thread.currentThread();
 			contextClassLoader = thread.getContextClassLoader();
 			thread.setContextClassLoader( overridenClassLoader );
 		}
 		try {
 			configure( (Properties)null, null );
 			NamingHelper.bind(this);
 			return new EntityManagerFactoryImpl(
-					cfg.buildSessionFactory(),
 					transactionType,
 					discardOnClose,
 					getSessionInterceptorClass( cfg.getProperties() ),
-					cfg
+					cfg,
+					connectionProviderInjectionData
 			);
 		}
 		catch (HibernateException e) {
 			throw new PersistenceException( getExceptionHeader() + "Unable to build EntityManagerFactory", e );
 		}
 		finally {
 			if (thread != null) {
 				thread.setContextClassLoader( contextClassLoader );
 			}
 		}
 	}
 
 	private Class getSessionInterceptorClass(Properties properties) {
 		String sessionInterceptorClassname = (String) properties.get( AvailableSettings.SESSION_INTERCEPTOR );
 		if ( StringHelper.isNotEmpty( sessionInterceptorClassname ) ) {
 			try {
 				Class interceptorClass = ReflectHelper.classForName( sessionInterceptorClassname, Ejb3Configuration.class );
 				interceptorClass.newInstance();
 				return interceptorClass;
 			}
 			catch (ClassNotFoundException e) {
 				throw new PersistenceException( getExceptionHeader() + "Unable to load "
 						+ AvailableSettings.SESSION_INTERCEPTOR + ": " + sessionInterceptorClassname, e);
 			}
 			catch (IllegalAccessException e) {
 				throw new PersistenceException( getExceptionHeader() + "Unable to instanciate "
 						+ AvailableSettings.SESSION_INTERCEPTOR + ": " + sessionInterceptorClassname, e);
 			}
 			catch (InstantiationException e) {
 				throw new PersistenceException( getExceptionHeader() + "Unable to instanciate "
 						+ AvailableSettings.SESSION_INTERCEPTOR + ": " + sessionInterceptorClassname, e);
 			}
 		}
 		else {
 			return null;
 		}
 	}
 
 	public Reference getReference() throws NamingException {
 		log.debug("Returning a Reference to the Ejb3Configuration");
 		ByteArrayOutputStream stream = new ByteArrayOutputStream();
 		ObjectOutput out = null;
 		byte[] serialized;
 		try {
 			out = new ObjectOutputStream( stream );
 			out.writeObject( this );
 			out.close();
 			serialized = stream.toByteArray();
 			stream.close();
 		}
 		catch (IOException e) {
 			NamingException namingException = new NamingException( "Unable to serialize Ejb3Configuration" );
 			namingException.setRootCause( e );
 			throw namingException;
 		}
 
 		return new Reference(
 				Ejb3Configuration.class.getName(),
 				new BinaryRefAddr("object", serialized ),
 				Ejb3ConfigurationObjectFactory.class.getName(),
 				null
 		);
 	}
 
 	/**
 	 * Configures this configuration object from 2 distinctly different sources.
 	 *
 	 * @param properties These are the properties that came from the user, either via
 	 * a persistence.xml or explicitly passed in to one of our
 	 * {@link javax.persistence.spi.PersistenceProvider}/{@link HibernatePersistence} contracts.
 	 * @param workingVars Is collection of settings which need to be handled similarly
 	 * between the 2 main bootstrap methods, but where the values are determine very differently
 	 * by each bootstrap method.  todo eventually make this a contract (class/interface)
 	 *
 	 * @return The configured configuration
 	 *
 	 * @see HibernatePersistence
 	 */
 	private Ejb3Configuration configure(Properties properties, Map workingVars) {
 		//TODO check for people calling more than once this method (except buildEMF)
 		if (isConfigurationProcessed) return this;
 		isConfigurationProcessed = true;
 		Properties preparedProperties = prepareProperties( properties, workingVars );
 		if ( workingVars == null ) workingVars = CollectionHelper.EMPTY_MAP;
 
 		if ( preparedProperties.containsKey( AvailableSettings.CFG_FILE ) ) {
 			String cfgFileName = preparedProperties.getProperty( AvailableSettings.CFG_FILE );
 			cfg.configure( cfgFileName );
 		}
 
 		cfg.addProperties( preparedProperties ); //persistence.xml has priority over hibernate.cfg.xml
 
 		addClassesToSessionFactory( workingVars );
 
 		//processes specific properties
 		List<String> jaccKeys = new ArrayList<String>();
 
 
 		Interceptor defaultInterceptor = DEFAULT_CONFIGURATION.getInterceptor();
 		NamingStrategy defaultNamingStrategy = DEFAULT_CONFIGURATION.getNamingStrategy();
 
 		Iterator propertyIt = preparedProperties.keySet().iterator();
 		while ( propertyIt.hasNext() ) {
 			Object uncastObject = propertyIt.next();
 			//had to be safe
 			if ( uncastObject != null && uncastObject instanceof String ) {
 				String propertyKey = (String) uncastObject;
 				if ( propertyKey.startsWith( AvailableSettings.CLASS_CACHE_PREFIX ) ) {
 					setCacheStrategy( propertyKey, preparedProperties, true, workingVars );
 				}
 				else if ( propertyKey.startsWith( AvailableSettings.COLLECTION_CACHE_PREFIX ) ) {
 					setCacheStrategy( propertyKey, preparedProperties, false, workingVars );
 				}
 				else if ( propertyKey.startsWith( AvailableSettings.JACC_PREFIX )
 						&& ! ( propertyKey.equals( AvailableSettings.JACC_CONTEXT_ID )
 						|| propertyKey.equals( AvailableSettings.JACC_ENABLED ) ) ) {
 					jaccKeys.add( propertyKey );
 				}
 			}
 		}
 		if ( preparedProperties.containsKey( AvailableSettings.INTERCEPTOR )
 				&& ( cfg.getInterceptor() == null
 				|| cfg.getInterceptor().equals( defaultInterceptor ) ) ) {
 			//cfg.setInterceptor has precedence over configuration file
 			String interceptorName = preparedProperties.getProperty( AvailableSettings.INTERCEPTOR );
 			try {
 				Class interceptor = classForName( interceptorName );
 				cfg.setInterceptor( (Interceptor) interceptor.newInstance() );
 			}
 			catch (ClassNotFoundException e) {
 				throw new PersistenceException(
 						getExceptionHeader() + "Unable to find interceptor class: " + interceptorName, e
 				);
 			}
 			catch (IllegalAccessException e) {
 				throw new PersistenceException(
 						getExceptionHeader() + "Unable to access interceptor class: " + interceptorName, e
 				);
 			}
 			catch (InstantiationException e) {
 				throw new PersistenceException(
 						getExceptionHeader() + "Unable to instanciate interceptor class: " + interceptorName, e
 				);
 			}
 			catch (ClassCastException e) {
 				throw new PersistenceException(
 						getExceptionHeader() + "Interceptor class does not implement Interceptor interface: " + interceptorName, e
 				);
 			}
 		}
 		if ( preparedProperties.containsKey( AvailableSettings.NAMING_STRATEGY )
 				&& ( cfg.getNamingStrategy() == null
 				|| cfg.getNamingStrategy().equals( defaultNamingStrategy ) ) ) {
 			//cfg.setNamingStrategy has precedence over configuration file
 			String namingStrategyName = preparedProperties.getProperty( AvailableSettings.NAMING_STRATEGY );
 			try {
 				Class namingStragegy = classForName( namingStrategyName );
 				cfg.setNamingStrategy( (NamingStrategy) namingStragegy.newInstance() );
 			}
 			catch (ClassNotFoundException e) {
 				throw new PersistenceException(
 						getExceptionHeader() + "Unable to find naming strategy class: " + namingStrategyName, e
 				);
 			}
 			catch (IllegalAccessException e) {
 				throw new PersistenceException(
 						getExceptionHeader() + "Unable to access naming strategy class: " + namingStrategyName, e
 				);
 			}
 			catch (InstantiationException e) {
 				throw new PersistenceException(
 						getExceptionHeader() + "Unable to instanciate naming strategy class: " + namingStrategyName, e
 				);
 			}
 			catch (ClassCastException e) {
 				throw new PersistenceException(
 						getExceptionHeader() + "Naming strategyy class does not implement NmaingStrategy interface: " + namingStrategyName,
 						e
 				);
 			}
 		}
 
 		if ( jaccKeys.size() > 0 ) {
 			addSecurity( jaccKeys, preparedProperties, workingVars );
 		}
 
 		//initialize listeners
 		listenerConfigurator.setProperties( preparedProperties );
 		listenerConfigurator.configure();
 
 		//some spec compliance checking
 		//TODO centralize that?
 		if ( ! "true".equalsIgnoreCase( cfg.getProperty( Environment.AUTOCOMMIT ) ) ) {
 			log.warn( "{} = false break the EJB3 specification", Environment.AUTOCOMMIT );
 		}
 		discardOnClose = preparedProperties.getProperty( AvailableSettings.DISCARD_PC_ON_CLOSE )
 				.equals( "true" );
 		return this;
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	private void addClassesToSessionFactory(Map workingVars) {
 		if ( workingVars.containsKey( AvailableSettings.CLASS_NAMES ) ) {
 			Collection<String> classNames = (Collection<String>) workingVars.get(
 					AvailableSettings.CLASS_NAMES
 			);
 			addNamedAnnotatedClasses( this, classNames, workingVars );
 		}
 
 		if ( workingVars.containsKey( PARSED_MAPPING_DOMS ) ) {
 			Collection<XmlDocument> xmlDocuments = (Collection<XmlDocument>) workingVars.get( PARSED_MAPPING_DOMS );
 			for ( XmlDocument xmlDocument : xmlDocuments ) {
 				cfg.add( xmlDocument );
 			}
 		}
 
 		//TODO apparently only used for Tests, get rid of it?
 		if ( workingVars.containsKey( AvailableSettings.LOADED_CLASSES ) ) {
 			Collection<Class> classes = (Collection<Class>) workingVars.get( AvailableSettings.LOADED_CLASSES );
 			for ( Class clazz : classes ) {
 				cfg.addAnnotatedClass( clazz );
 			}
 		}
 		if ( workingVars.containsKey( AvailableSettings.PACKAGE_NAMES ) ) {
 			Collection<String> packages = (Collection<String>) workingVars.get(
 					AvailableSettings.PACKAGE_NAMES
 			);
 			for ( String pkg : packages ) {
 				cfg.addPackage( pkg );
 			}
 		}
 		if ( workingVars.containsKey( AvailableSettings.XML_FILE_NAMES ) ) {
 			Collection<String> xmlFiles = (Collection<String>) workingVars.get(
 					AvailableSettings.XML_FILE_NAMES
 			);
 			for ( String xmlFile : xmlFiles ) {
 				Boolean useMetaInf = null;
 				try {
 					if ( xmlFile.endsWith( META_INF_ORM_XML ) ) useMetaInf = true;
 					cfg.addResource( xmlFile );
 				}
 				catch( MappingNotFoundException e ) {
 					if ( ! xmlFile.endsWith( META_INF_ORM_XML ) ) {
 						throw new PersistenceException( getExceptionHeader()
 								+ "Unable to find XML mapping file in classpath: " + xmlFile);
 					}
 					else {
 						useMetaInf = false;
 						//swallow it, the META-INF/orm.xml is optional
 					}
 				}
 				catch( MappingException me ) {
 					throw new PersistenceException( getExceptionHeader()
 								+ "Error while reading JPA XML file: " + xmlFile, me);
 				}
 				if ( log.isInfoEnabled() ) {
 					if ( Boolean.TRUE.equals( useMetaInf ) ) {
 						log.info( "{} {} found", getExceptionHeader(), META_INF_ORM_XML);
 					}
 					else if (Boolean.FALSE.equals( useMetaInf ) ) {
 						log.info( "{} No {} found", getExceptionHeader(), META_INF_ORM_XML);
 					}
 				}
 			}
 		}
 		if ( workingVars.containsKey( AvailableSettings.HBXML_FILES ) ) {
 			Collection<NamedInputStream> hbmXmlFiles = (Collection<NamedInputStream>) workingVars.get(
 					AvailableSettings.HBXML_FILES
 			);
 			for ( NamedInputStream is : hbmXmlFiles ) {
 				try {
 					//addInputStream has the responsibility to close the stream
 					cfg.addInputStream( new BufferedInputStream( is.getStream() ) );
 				}
 				catch (MappingException me) {
 					//try our best to give the file name
 					if ( StringHelper.isEmpty( is.getName() ) ) {
 						throw me;
 					}
 					else {
 						throw new MappingException("Error while parsing file: " + is.getName(), me );
 					}
 				}
 			}
 		}
 	}
 
 	private String getExceptionHeader() {
 		if ( StringHelper.isNotEmpty( persistenceUnitName ) ) {
 			return "[PersistenceUnit: " + persistenceUnitName + "] ";
 		}
 		else {
 			return "";
 		}
 	}
 
 	private Properties prepareProperties(Properties properties, Map workingVars) {
 		Properties preparedProperties = new Properties();
 
 		//defaults different from Hibernate
 		preparedProperties.setProperty( Environment.RELEASE_CONNECTIONS, "auto" );
 		preparedProperties.setProperty( Environment.JPAQL_STRICT_COMPLIANCE, "true" );
 		//settings that always apply to a compliant EJB3
 		preparedProperties.setProperty( Environment.AUTOCOMMIT, "true" );
 		preparedProperties.setProperty( Environment.USE_IDENTIFIER_ROLLBACK, "false" );
 		preparedProperties.setProperty( Environment.FLUSH_BEFORE_COMPLETION, "false" );
 		preparedProperties.setProperty( AvailableSettings.DISCARD_PC_ON_CLOSE, "false" );
 		if (cfgXmlResource != null) {
 			preparedProperties.setProperty( AvailableSettings.CFG_FILE, cfgXmlResource );
 			cfgXmlResource = null;
 		}
 
 		//override the new defaults with the user defined ones
 		//copy programmatically defined properties
 		if ( cfg.getProperties() != null ) preparedProperties.putAll( cfg.getProperties() );
 		//copy them coping from configuration
 		if ( properties != null ) preparedProperties.putAll( properties );
 		//note we don't copy cfg.xml properties, since they have to be overriden
 
 		if (transactionType == null) {
 			//if it has not been set, the user use a programmatic way
 			transactionType = PersistenceUnitTransactionType.RESOURCE_LOCAL;
 		}
 		defineTransactionType(
 				preparedProperties.getProperty( AvailableSettings.TRANSACTION_TYPE ),
 				workingVars
 		);
 		boolean hasTxStrategy = StringHelper.isNotEmpty(
 				preparedProperties.getProperty( Environment.TRANSACTION_STRATEGY )
 		);
 		if ( ! hasTxStrategy && transactionType == PersistenceUnitTransactionType.JTA ) {
 			preparedProperties.setProperty(
 					Environment.TRANSACTION_STRATEGY, JoinableCMTTransactionFactory.class.getName()
 			);
 		}
 		else if ( ! hasTxStrategy && transactionType == PersistenceUnitTransactionType.RESOURCE_LOCAL ) {
 			preparedProperties.setProperty( Environment.TRANSACTION_STRATEGY, JDBCTransactionFactory.class.getName() );
 		}
 		if ( hasTxStrategy ) {
 			log.warn(
 					"Overriding {} is dangerous, this might break the EJB3 specification implementation",
 					Environment.TRANSACTION_STRATEGY
 			);
 		}
 		if ( preparedProperties.getProperty( Environment.FLUSH_BEFORE_COMPLETION ).equals( "true" ) ) {
 			preparedProperties.setProperty( Environment.FLUSH_BEFORE_COMPLETION, "false" );
 			log.warn( "Defining {}=true ignored in HEM", Environment.FLUSH_BEFORE_COMPLETION );
 		}
 		return preparedProperties;
 	}
 
 	private Class classForName(String className) throws ClassNotFoundException {
 		return ReflectHelper.classForName( className, this.getClass() );
 	}
 
 	private void setCacheStrategy(String propertyKey, Map properties, boolean isClass, Map workingVars) {
 		String role = propertyKey.substring(
 				( isClass ? AvailableSettings.CLASS_CACHE_PREFIX
 						.length() : AvailableSettings.COLLECTION_CACHE_PREFIX.length() )
 						+ 1
 		);
 		//dot size added
 		String value = (String) properties.get( propertyKey );
 		StringTokenizer params = new StringTokenizer( value, ";, " );
 		if ( !params.hasMoreTokens() ) {
 			StringBuilder error = new StringBuilder( "Illegal usage of " );
 			error.append(
 					isClass ? AvailableSettings.CLASS_CACHE_PREFIX : AvailableSettings.COLLECTION_CACHE_PREFIX
 			);
 			error.append( ": " ).append( propertyKey ).append( " " ).append( value );
 			throw new PersistenceException( getExceptionHeader() + error.toString() );
 		}
 		String usage = params.nextToken();
 		String region = null;
 		if ( params.hasMoreTokens() ) {
 			region = params.nextToken();
 		}
 		if ( isClass ) {
 			boolean lazyProperty = true;
 			if ( params.hasMoreTokens() ) {
 				lazyProperty = "all".equalsIgnoreCase( params.nextToken() );
 			}
 			cfg.setCacheConcurrencyStrategy( role, usage, region, lazyProperty );
 		}
 		else {
 			cfg.setCollectionCacheConcurrencyStrategy( role, usage, region );
 		}
 	}
 
 	private void addSecurity(List<String> keys, Map properties, Map workingVars) {
 		log.debug( "Adding security" );
 		if ( !properties.containsKey( AvailableSettings.JACC_CONTEXT_ID ) ) {
 			throw new PersistenceException( getExceptionHeader() +
 					"Entities have been configured for JACC, but "
 							+ AvailableSettings.JACC_CONTEXT_ID
 							+ " has not been set"
 			);
 		}
 		String contextId = (String) properties.get( AvailableSettings.JACC_CONTEXT_ID );
 		setProperty( Environment.JACC_CONTEXTID, contextId );
 
 		int roleStart = AvailableSettings.JACC_PREFIX.length() + 1;
 
 		for ( String key : keys ) {
 			JACCConfiguration jaccCfg = new JACCConfiguration( contextId );
 			try {
 				String role = key.substring( roleStart, key.indexOf( '.', roleStart ) );
 				int classStart = roleStart + role.length() + 1;
 				String clazz = key.substring( classStart, key.length() );
 				String actions = (String) properties.get( key );
 				jaccCfg.addPermission( role, clazz, actions );
 			}
 			catch (IndexOutOfBoundsException e) {
 				throw new PersistenceException( getExceptionHeader() +
 						"Illegal usage of " + AvailableSettings.JACC_PREFIX + ": " + key );
 			}
 		}
 	}
 
 	private void addNamedAnnotatedClasses(
 			Ejb3Configuration cfg, Collection<String> classNames, Map workingVars
 	) {
 		for ( String name : classNames ) {
 			try {
 				Class clazz = classForName( name );
 				cfg.addAnnotatedClass( clazz );
 			}
 			catch (ClassNotFoundException cnfe) {
 				Package pkg;
 				try {
 					pkg = classForName( name + ".package-info" ).getPackage();
 				}
 				catch (ClassNotFoundException e) {
 					pkg = null;
 				}
 				if ( pkg == null ) {
 					throw new PersistenceException( getExceptionHeader() +  "class or package not found", cnfe );
 				}
 				else {
 					cfg.addPackage( name );
 				}
 			}
 		}
 	}
 
-
-	public Settings buildSettings() throws HibernateException {
+	/*
+		TODO: not needed any more?
+	public Settings buildSettings(ConnectionProvider connectionProvider) throws HibernateException {
 		Thread thread = null;
 		ClassLoader contextClassLoader = null;
 		if (overridenClassLoader != null) {
 			thread = Thread.currentThread();
 			contextClassLoader = thread.getContextClassLoader();
 			thread.setContextClassLoader( overridenClassLoader );
 		}
 		try {
-			return settingsFactory.buildSettings( cfg.getProperties() );
+			return settingsFactory.buildSettings( cfg.getProperties(), connectionProvider );
 		}
 		finally {
 			if (thread != null) thread.setContextClassLoader( contextClassLoader );
 		}
 	}
+	*/
 
 	public Ejb3Configuration addProperties(Properties props) {
 		cfg.addProperties( props );
 		return this;
 	}
 
 	public Ejb3Configuration addAnnotatedClass(Class persistentClass) throws MappingException {
 		Thread thread = null;
 		ClassLoader contextClassLoader = null;
 		if (overridenClassLoader != null) {
 			thread = Thread.currentThread();
 			contextClassLoader = thread.getContextClassLoader();
 			thread.setContextClassLoader( overridenClassLoader );
 		}
 		try {
 			cfg.addAnnotatedClass( persistentClass );
 			return this;
 		}
 		finally {
 			if (thread != null) thread.setContextClassLoader( contextClassLoader );
 		}
 	}
 
 	public Ejb3Configuration configure(String resource) throws HibernateException {
 		//delay the call to configure to allow proper addition of all annotated classes (EJB-330)
 		if (cfgXmlResource != null)
 			throw new PersistenceException("configure(String) method already called for " + cfgXmlResource);
 		this.cfgXmlResource = resource;
 		return this;
 	}
 
 	public Ejb3Configuration addPackage(String packageName) throws MappingException {
 		Thread thread = null;
 		ClassLoader contextClassLoader = null;
 		if (overridenClassLoader != null) {
 			thread = Thread.currentThread();
 			contextClassLoader = thread.getContextClassLoader();
 			thread.setContextClassLoader( overridenClassLoader );
 		}
 		try {
 			cfg.addPackage( packageName );
 			return this;
 		}
 		finally {
 			if (thread != null) thread.setContextClassLoader( contextClassLoader );
 		}
 	}
 
 	public Ejb3Configuration addFile(String xmlFile) throws MappingException {
 		Thread thread = null;
 		ClassLoader contextClassLoader = null;
 		if (overridenClassLoader != null) {
 			thread = Thread.currentThread();
 			contextClassLoader = thread.getContextClassLoader();
 			thread.setContextClassLoader( overridenClassLoader );
 		}
 		try {
 			cfg.addFile( xmlFile );
 			return this;
 		}
 		finally {
 			if (thread != null) thread.setContextClassLoader( contextClassLoader );
 		}
 	}
 
 	public Ejb3Configuration addClass(Class persistentClass) throws MappingException {
 		Thread thread = null;
 		ClassLoader contextClassLoader = null;
 		if (overridenClassLoader != null) {
 			thread = Thread.currentThread();
 			contextClassLoader = thread.getContextClassLoader();
 			thread.setContextClassLoader( overridenClassLoader );
 		}
 		try {
 			cfg.addClass( persistentClass );
 			return this;
 		}
 		finally {
 			if (thread != null) thread.setContextClassLoader( contextClassLoader );
 		}
 	}
 
 	public Ejb3Configuration addFile(File xmlFile) throws MappingException {
 		Thread thread = null;
 		ClassLoader contextClassLoader = null;
 		if (overridenClassLoader != null) {
 			thread = Thread.currentThread();
 			contextClassLoader = thread.getContextClassLoader();
 			thread.setContextClassLoader( overridenClassLoader );
 		}
 		try {
 			cfg.addFile( xmlFile );
 			return this;
 		}
 		finally {
 			if (thread != null) thread.setContextClassLoader( contextClassLoader );
 		}
 	}
 
 	public void buildMappings() {
 		Thread thread = null;
 		ClassLoader contextClassLoader = null;
 		if (overridenClassLoader != null) {
 			thread = Thread.currentThread();
 			contextClassLoader = thread.getContextClassLoader();
 			thread.setContextClassLoader( overridenClassLoader );
 		}
 		try {
 			cfg.buildMappings();
 		}
 		finally {
 			if (thread != null) thread.setContextClassLoader( contextClassLoader );
 		}
 	}
 
 	public Iterator getClassMappings() {
 		Thread thread = null;
 		ClassLoader contextClassLoader = null;
 		if (overridenClassLoader != null) {
 			thread = Thread.currentThread();
 			contextClassLoader = thread.getContextClassLoader();
 			thread.setContextClassLoader( overridenClassLoader );
 		}
 		try {
 			return cfg.getClassMappings();
 		}
 		finally {
 			if (thread != null) thread.setContextClassLoader( contextClassLoader );
 		}
 	}
 
 	public EventListeners getEventListeners() {
 		return cfg.getEventListeners();
 	}
 
-	SessionFactory buildSessionFactory() throws HibernateException {
-		return cfg.buildSessionFactory();
+	SessionFactory buildSessionFactory(ServicesRegistry serviceRegistry) throws HibernateException {
+		return cfg.buildSessionFactory( serviceRegistry );
 	}
 
 	public Iterator getTableMappings() {
 		return cfg.getTableMappings();
 	}
 
 	public PersistentClass getClassMapping(String persistentClass) {
 		return cfg.getClassMapping( persistentClass );
 	}
 
 	public org.hibernate.mapping.Collection getCollectionMapping(String role) {
 		return cfg.getCollectionMapping( role );
 	}
 
 	public void setEntityResolver(EntityResolver entityResolver) {
 		cfg.setEntityResolver( entityResolver );
 	}
 
 	public Map getNamedQueries() {
 		return cfg.getNamedQueries();
 	}
 
 	public Interceptor getInterceptor() {
 		return cfg.getInterceptor();
 	}
 
 	public Properties getProperties() {
 		return cfg.getProperties();
 	}
 
 	public Ejb3Configuration setInterceptor(Interceptor interceptor) {
 		cfg.setInterceptor( interceptor );
 		return this;
 	}
 
 	public Ejb3Configuration setProperties(Properties properties) {
 		cfg.setProperties( properties );
 		return this;
 	}
 
 	public Map getFilterDefinitions() {
 		return cfg.getFilterDefinitions();
 	}
 
 	public void addFilterDefinition(FilterDefinition definition) {
 		cfg.addFilterDefinition( definition );
 	}
 
 	public void addAuxiliaryDatabaseObject(AuxiliaryDatabaseObject object) {
 		cfg.addAuxiliaryDatabaseObject( object );
 	}
 
 	public NamingStrategy getNamingStrategy() {
 		return cfg.getNamingStrategy();
 	}
 
 	public Ejb3Configuration setNamingStrategy(NamingStrategy namingStrategy) {
 		cfg.setNamingStrategy( namingStrategy );
 		return this;
 	}
 
 	public void setListeners(String type, String[] listenerClasses) {
 		cfg.setListeners( type, listenerClasses );
 	}
 
 	public void setListeners(String type, Object[] listeners) {
 		cfg.setListeners( type, listeners );
 	}
 
 	/**
 	 * This API is intended to give a read-only configuration.
 	 * It is sueful when working with SchemaExport or any Configuration based
 	 * tool.
 	 * DO NOT update configuration through it.
 	 */
 	public AnnotationConfiguration getHibernateConfiguration() {
 		//TODO make it really read only (maybe through proxying)
 		return cfg;
 	}
 
 	public Ejb3Configuration addInputStream(InputStream xmlInputStream) throws MappingException {
 		Thread thread = null;
 		ClassLoader contextClassLoader = null;
 		if (overridenClassLoader != null) {
 			thread = Thread.currentThread();
 			contextClassLoader = thread.getContextClassLoader();
 			thread.setContextClassLoader( overridenClassLoader );
 		}
 		try {
 			cfg.addInputStream( xmlInputStream );
 			return this;
 		}
 		finally {
 			if (thread != null) thread.setContextClassLoader( contextClassLoader );
 		}
 	}
 
 	public Ejb3Configuration addResource(String path) throws MappingException {
 		Thread thread = null;
 		ClassLoader contextClassLoader = null;
 		if (overridenClassLoader != null) {
 			thread = Thread.currentThread();
 			contextClassLoader = thread.getContextClassLoader();
 			thread.setContextClassLoader( overridenClassLoader );
 		}
 		try {
 			cfg.addResource( path );
 			return this;
 		}
 		finally {
 			if (thread != null) thread.setContextClassLoader( contextClassLoader );
 		}
 	}
 
 	public Ejb3Configuration addResource(String path, ClassLoader classLoader) throws MappingException {
 		cfg.addResource( path, classLoader );
 		return this;
 	}
 
 	private enum XML_SEARCH {
 		HBM,
 		ORM_XML,
 		BOTH,
 		NONE;
 
 		public static XML_SEARCH getType(boolean searchHbm, boolean searchOrm) {
 			return searchHbm ?
 					searchOrm ? XML_SEARCH.BOTH : XML_SEARCH.HBM :
 					searchOrm ? XML_SEARCH.ORM_XML : XML_SEARCH.NONE;
 		}
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/EntityManagerFactoryImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/EntityManagerFactoryImpl.java
index 3d096c8dab..ee1e4b6a71 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/EntityManagerFactoryImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/EntityManagerFactoryImpl.java
@@ -1,220 +1,235 @@
 /*
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb;
 
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import java.util.Iterator;
 import java.io.Serializable;
 import javax.persistence.EntityManager;
 import javax.persistence.PersistenceContextType;
 import javax.persistence.Cache;
 import javax.persistence.PersistenceUnitUtil;
 import javax.persistence.metamodel.Metamodel;
 import javax.persistence.criteria.CriteriaBuilder;
 import javax.persistence.spi.PersistenceUnitTransactionType;
 import javax.persistence.spi.LoadState;
 
 import org.hibernate.SessionFactory;
 import org.hibernate.Hibernate;
 import org.hibernate.HibernateException;
 import org.hibernate.EntityMode;
+import org.hibernate.cfg.internal.ServicesRegistryBootstrap;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.ejb.criteria.CriteriaBuilderImpl;
 import org.hibernate.ejb.metamodel.MetamodelImpl;
 import org.hibernate.ejb.util.PersistenceUtilHelper;
+import org.hibernate.service.internal.ServicesRegistryImpl;
+import org.hibernate.service.spi.ServicesRegistry;
 
 /**
  * Actual Hiberate implementation of {@link javax.persistence.EntityManagerFactory}.
  *
  * @author Gavin King
  * @author Emmanuel Bernard
  * @author Steve Ebersole
  */
 public class EntityManagerFactoryImpl implements HibernateEntityManagerFactory {
+	private final transient ServicesRegistryImpl serviceRegistry;
 	private final SessionFactory sessionFactory;
 	private final PersistenceUnitTransactionType transactionType;
 	private final boolean discardOnClose;
 	private final Class sessionInterceptorClass;
 	private final CriteriaBuilderImpl criteriaBuilder;
 	private final Metamodel metamodel;
 	private final HibernatePersistenceUnitUtil util;
 	private final Map<String,Object> properties;
+	private final Map connectionProviderInjectionData;
+
 	private final PersistenceUtilHelper.MetadataCache cache = new PersistenceUtilHelper.MetadataCache();
 
 	@SuppressWarnings( "unchecked" )
 	public EntityManagerFactoryImpl(
-			SessionFactory sessionFactory,
 			PersistenceUnitTransactionType transactionType,
 			boolean discardOnClose,
 			Class<?> sessionInterceptorClass,
-			Configuration cfg) {
-		this.sessionFactory = sessionFactory;
+			Configuration cfg,
+			Map connectionProviderInjectionData) {
+		// FIXME: Get rid of this temporary way of creating the service registry for EM
+		Map serviceRegistryProperties = new HashMap(
+				cfg.getProperties().size() + connectionProviderInjectionData.size()
+		);
+		serviceRegistryProperties.putAll( cfg.getProperties() );
+		serviceRegistryProperties.putAll( connectionProviderInjectionData );
+		this.serviceRegistry = new ServicesRegistryBootstrap().initiateServicesRegistry( serviceRegistryProperties );
+		this.sessionFactory = cfg.buildSessionFactory( serviceRegistry );
 		this.transactionType = transactionType;
 		this.discardOnClose = discardOnClose;
 		this.sessionInterceptorClass = sessionInterceptorClass;
 		final Iterator<PersistentClass> classes = cfg.getClassMappings();
 		//a safe guard till we are confident that metamodel is wll tested
 		if ( !"disabled".equalsIgnoreCase( cfg.getProperty( "hibernate.ejb.metamodel.generation" ) ) ) {
 			this.metamodel = MetamodelImpl.buildMetamodel( classes, ( SessionFactoryImplementor ) sessionFactory );
 		}
 		else {
 			this.metamodel = null;
 		}
 		this.criteriaBuilder = new CriteriaBuilderImpl( this );
 		this.util = new HibernatePersistenceUnitUtil( this );
 
 		HashMap<String,Object> props = new HashMap<String, Object>();
 		addAll( props, ( (SessionFactoryImplementor) sessionFactory ).getProperties() );
 		addAll( props, cfg.getProperties() );
 		this.properties = Collections.unmodifiableMap( props );
+		this.connectionProviderInjectionData = new HashMap();
 	}
 
 	private static void addAll(HashMap<String, Object> propertyMap, Properties properties) {
 		for ( Map.Entry entry : properties.entrySet() ) {
 			if ( String.class.isInstance( entry.getKey() ) ) {
 				propertyMap.put( (String)entry.getKey(), entry.getValue() );
 			}
 		}
 	}
 
 	public EntityManager createEntityManager() {
 		return createEntityManager( null );
 	}
 
 	public EntityManager createEntityManager(Map map) {
 		//TODO support discardOnClose, persistencecontexttype?, interceptor,
 		return new EntityManagerImpl(
 				this, PersistenceContextType.EXTENDED, transactionType,
 				discardOnClose, sessionInterceptorClass, map
 		);
 	}
 
 	public CriteriaBuilder getCriteriaBuilder() {
 		return criteriaBuilder;
 	}
 
 	public Metamodel getMetamodel() {
 		return metamodel;
 	}
 
 	public void close() {
 		sessionFactory.close();
+		serviceRegistry.destroy();
 	}
 
 	public Map<String, Object> getProperties() {
 		return properties;
 	}
 
 	public Cache getCache() {
 		// TODO : cache the cache reference?
 		if ( ! isOpen() ) {
 			throw new IllegalStateException("EntityManagerFactory is closed");
 		}
 		return new JPACache( sessionFactory );
 	}
 
 	public PersistenceUnitUtil getPersistenceUnitUtil() {
 		if ( ! isOpen() ) {
 			throw new IllegalStateException("EntityManagerFactory is closed");
 		}
 		return util;
 	}
 
 	public boolean isOpen() {
 		return ! sessionFactory.isClosed();
 	}
 
 	public SessionFactory getSessionFactory() {
 		return sessionFactory;
 	}
 
 	private static class JPACache implements Cache {
 		private SessionFactory sessionFactory;
 
 		private JPACache(SessionFactory sessionFactory) {
 			this.sessionFactory = sessionFactory;
 		}
 
 		public boolean contains(Class entityClass, Object identifier) {
 			return sessionFactory.getCache().containsEntity( entityClass, ( Serializable ) identifier );
 		}
 
 		public void evict(Class entityClass, Object identifier) {
 			sessionFactory.getCache().evictEntity( entityClass, ( Serializable ) identifier );
 		}
 
 		public void evict(Class entityClass) {
 			sessionFactory.getCache().evictEntityRegion( entityClass );
 		}
 
 		public void evictAll() {
 			sessionFactory.getCache().evictEntityRegions();
 // TODO : if we want to allow an optional clearing of all cache data, the additional calls would be:
 //			sessionFactory.getCache().evictCollectionRegions();
 //			sessionFactory.getCache().evictQueryRegions();
 		}
 	}
 
 	private static class HibernatePersistenceUnitUtil implements PersistenceUnitUtil, Serializable {
 		private final HibernateEntityManagerFactory emf;
 		private transient PersistenceUtilHelper.MetadataCache cache;
 
 		private HibernatePersistenceUnitUtil(EntityManagerFactoryImpl emf) {
 			this.emf = emf;
 			this.cache = emf.cache;
 		}
 
 		public boolean isLoaded(Object entity, String attributeName) {
 			LoadState state = PersistenceUtilHelper.isLoadedWithoutReference( entity, attributeName, cache );
 			if (state == LoadState.LOADED) {
 				return true;
 			}
 			else if (state == LoadState.NOT_LOADED ) {
 				return false;
 			}
 			else {
 				return PersistenceUtilHelper.isLoadedWithReference( entity, attributeName, cache ) != LoadState.NOT_LOADED;
 			}
 		}
 
 		public boolean isLoaded(Object entity) {
 			return PersistenceUtilHelper.isLoaded( entity ) != LoadState.NOT_LOADED;
 		}
 
 		public Object getIdentifier(Object entity) {
 			final Class entityClass = Hibernate.getClass( entity );
 			final ClassMetadata classMetadata = emf.getSessionFactory().getClassMetadata( entityClass );
 			if (classMetadata == null) {
 				throw new IllegalArgumentException( entityClass + " is not an entity" );
 			}
 			//TODO does that work for @IdClass?
 			return classMetadata.getIdentifier( entity, EntityMode.POJO );
 		}
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/HibernatePersistence.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/HibernatePersistence.java
index 63817d1085..7271e4dbd8 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/HibernatePersistence.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/HibernatePersistence.java
@@ -1,108 +1,110 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA\
  */
 package org.hibernate.ejb;
 
 import java.util.Map;
+import java.util.Properties;
 import javax.persistence.EntityManagerFactory;
 import javax.persistence.spi.LoadState;
 import javax.persistence.spi.PersistenceProvider;
 import javax.persistence.spi.PersistenceUnitInfo;
 import javax.persistence.spi.ProviderUtil;
 
+import org.hibernate.cfg.internal.ServicesRegistryBootstrap;
 import org.hibernate.ejb.util.PersistenceUtilHelper;
 
 /**
  * Hibernate EJB3 persistence provider implementation
  *
  * @author Gavin King
  */
 public class HibernatePersistence extends AvailableSettings implements PersistenceProvider {
 	private final PersistenceUtilHelper.MetadataCache cache = new PersistenceUtilHelper.MetadataCache();
 
 	/**
 	 * Get an entity manager factory by its entity manager name, using the specified
 	 * properties (they override any found in the peristence.xml file).
 	 * <p/>
 	 * This is the form used in JSE environments.
 	 *
 	 * @param persistenceUnitName entity manager name
 	 * @param properties The explicit property values
 	 *
 	 * @return initialized EntityManagerFactory
 	 */
 	public EntityManagerFactory createEntityManagerFactory(String persistenceUnitName, Map properties) {
 		Ejb3Configuration cfg = new Ejb3Configuration();
 		Ejb3Configuration configured = cfg.configure( persistenceUnitName, properties );
 		return configured != null ? configured.buildEntityManagerFactory() : null;
 	}
 
 	/**
 	 * Create an entity manager factory from the given persistence unit info, using the specified
 	 * properties (they override any on the PUI).
 	 * <p/>
 	 * This is the form used by the container in a JEE environment.
 	 *
 	 * @param info The persistence unit information
 	 * @param properties The explicit property values
 	 *
 	 * @return initialized EntityManagerFactory
 	 */
 	public EntityManagerFactory createContainerEntityManagerFactory(PersistenceUnitInfo info, Map properties) {
 		Ejb3Configuration cfg = new Ejb3Configuration();
 		Ejb3Configuration configured = cfg.configure( info, properties );
 		return configured != null ? configured.buildEntityManagerFactory() : null;
 	}
 
 	/**
 	 * create a factory from a canonical version
 	 * @deprecated
 	 */
 	public EntityManagerFactory createEntityManagerFactory(Map properties) {
 		// This is used directly by JBoss so don't remove until further notice.  bill@jboss.org
 		Ejb3Configuration cfg = new Ejb3Configuration();
 		return cfg.createEntityManagerFactory( properties );
 	}
 
 	private final ProviderUtil providerUtil = new ProviderUtil() {
 		public LoadState isLoadedWithoutReference(Object proxy, String property) {
 			return PersistenceUtilHelper.isLoadedWithoutReference( proxy, property, cache );
 		}
 
 		public LoadState isLoadedWithReference(Object proxy, String property) {
 			return PersistenceUtilHelper.isLoadedWithReference( proxy, property, cache );
 		}
 
 		public LoadState isLoaded(Object o) {
 			return PersistenceUtilHelper.isLoaded(o);
 		}
 	};
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public ProviderUtil getProviderUtil() {
 		return providerUtil;
 	}
 
 }
\ No newline at end of file
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/InjectionSettingsFactory.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/InjectionSettingsFactory.java
deleted file mode 100644
index 670f84de76..0000000000
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/InjectionSettingsFactory.java
+++ /dev/null
@@ -1,53 +0,0 @@
-/*
- * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-
-//$Id$
-package org.hibernate.ejb;
-
-import java.util.Map;
-import java.util.Properties;
-
-import org.hibernate.cfg.SettingsFactory;
-import org.hibernate.connection.ConnectionProvider;
-import org.hibernate.connection.ConnectionProviderFactory;
-
-/**
- * @author Emmanuel Bernard
- */
-public class InjectionSettingsFactory extends SettingsFactory {
-	private Map connectionProviderInjectionData;
-
-	/**
-	 * Map<String,Object> where the key represents the javabean property in witch
-	 * Object will be injected
-	 *
-	 * @param connectionProviderInjectionData
-	 *
-	 */
-	public void setConnectionProviderInjectionData(Map connectionProviderInjectionData) {
-		this.connectionProviderInjectionData = connectionProviderInjectionData;
-	}
-
-	protected ConnectionProvider createConnectionProvider(Properties properties) {
-		return ConnectionProviderFactory.newConnectionProvider( properties, connectionProviderInjectionData );
-	}
-}
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/connection/InjectedDataSourceConnectionProvider.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/connection/InjectedDataSourceConnectionProvider.java
index 3e4494bcb5..8bcb156daa 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/connection/InjectedDataSourceConnectionProvider.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/connection/InjectedDataSourceConnectionProvider.java
@@ -1,74 +1,75 @@
 /*
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.connection;
 
 import java.util.Properties;
 import java.sql.Connection;
 import java.sql.SQLException;
 import javax.sql.DataSource;
 
 import org.hibernate.HibernateException;
 import org.hibernate.cfg.Environment;
-import org.hibernate.connection.DatasourceConnectionProvider;
+import org.hibernate.service.jdbc.connections.internal.DatasourceConnectionProviderImpl;
+
 import org.slf4j.LoggerFactory;
 import org.slf4j.Logger;
 
 /**
- * A specialization of {@link DatasourceConnectionProvider} which uses the {@link DataSource} specified vi
+ * A specialization of {@link DatasourceConnectionProviderImpl} which uses the {@link DataSource} specified vi
  * {@link #setDataSource} rather than locating it from JNDI.
  * <p/>
  * NOTE : {@link #setDataSource} must be called prior to {@link #configure}.
  * <p/>
  * TODO : could not find where #setDataSource is actually called.  Can't this just be passed in to #configure???
  *
  * @author Emmanuel Bernard
  */
-public class InjectedDataSourceConnectionProvider extends DatasourceConnectionProvider {
+public class InjectedDataSourceConnectionProvider extends DatasourceConnectionProviderImpl {
 	private final Logger log = LoggerFactory.getLogger( InjectedDataSourceConnectionProvider.class );
 
 	private String user;
 	private String pass;
 
 	public void setDataSource(DataSource ds) {
 		super.setDataSource( ds );
 	}
 
 	public void configure(Properties props) throws HibernateException {
 		user = props.getProperty( Environment.USER );
 		pass = props.getProperty( Environment.PASS );
 
 		if ( getDataSource() == null ) {
 			throw new HibernateException( "No datasource provided" );
 		}
 		log.info( "Using provided datasource" );
 	}
 
 	@Override
 	public Connection getConnection() throws SQLException {
 		if (user != null || pass != null) {
 			return getDataSource().getConnection(user, pass);
 		}
 		else {
 			return getDataSource().getConnection();
 		}
 	}
 }
diff --git a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/TestCase.java b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/TestCase.java
index 1f80cfab52..fceafbe65b 100644
--- a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/TestCase.java
+++ b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/TestCase.java
@@ -1,229 +1,230 @@
 // $Id$
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.test;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Properties;
 import javax.persistence.EntityManager;
 import javax.persistence.EntityManagerFactory;
 import javax.persistence.Persistence;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.ejb.AvailableSettings;
 import org.hibernate.ejb.Ejb3Configuration;
 import org.hibernate.testing.junit.functional.annotations.HibernateTestCase;
 
 /**
  * A base class for all ejb tests.
  *
  * @author Emmanuel Bernard
  * @author Hardy Ferentschik
  */
 public abstract class TestCase extends HibernateTestCase {
 	private static final Logger log = LoggerFactory.getLogger( TestCase.class );
 
 	protected static EntityManagerFactory factory;
 	private EntityManager em;
 	private ArrayList isolatedEms = new ArrayList();
 
 
 	public TestCase() {
 		super();
 	}
 
 	public TestCase(String name) {
 		super( name );
 	}
 
 
 	public void tearDown() throws Exception {
 		super.tearDown();
 	}
 
 	@Override
 	protected void buildConfiguration() throws Exception {
 		Ejb3Configuration ejbconfig = new Ejb3Configuration();
 		TestCase.cfg = ejbconfig.getHibernateConfiguration();
 		if ( recreateSchema() ) {
 			cfg.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
 		}
 		cfg.setProperty( AnnotationConfiguration.USE_NEW_ID_GENERATOR_MAPPINGS, "true" );
 
 		for ( String mappingFile : getMappings() ) {
 			cfg.addResource( mappingFile );
 		}
 
 		factory = ejbconfig.createEntityManagerFactory( getConfig() );
 	}
 
 	private void cleanUnclosed(EntityManager em) {
 		if ( em == null ) {
 			return;
 		}
 		if ( em.getTransaction().isActive() ) {
 			em.getTransaction().rollback();
 			log.warn( "You left an open transaction! Fix your test case. For now, we are closing it for you." );
 		}
 		if ( em.isOpen() ) {
 			// as we open an EM before the test runs, it will still be open if the test uses a custom EM.
 			// or, the person may have forgotten to close. So, do not raise a "fail", but log the fact.
 			em.close();
 			log.warn( "The EntityManager is not closed. Closing it." );
 		}
 	}
 
 	protected void handleUnclosedResources() {
 		cleanUnclosed( this.em );
 		for ( Iterator iter = isolatedEms.iterator(); iter.hasNext(); ) {
 			cleanUnclosed( ( EntityManager ) iter.next() );
 		}
 
 		cfg = null;
 	}
 
 	protected void closeResources() {
 		if ( factory != null ) {
 			factory.close();
 		}
+		super.closeResources();
 	}
 
 	protected EntityManager getOrCreateEntityManager() {
 		if ( em == null || !em.isOpen() ) {
 			em = factory.createEntityManager();
 		}
 		return em;
 	}
 
 	protected EntityManager createIsolatedEntityManager() {
 		EntityManager isolatedEm = factory.createEntityManager();
 		isolatedEms.add( isolatedEm );
 		return isolatedEm;
 	}
 
 	protected EntityManager createIsolatedEntityManager(Map props) {
 		EntityManager isolatedEm = factory.createEntityManager(props);
 		isolatedEms.add( isolatedEm );
 		return isolatedEm;
 	}
 
 	/**
 	 * always reopen a new EM and clse the existing one
 	 */
 	protected EntityManager createEntityManager(Map properties) {
 		if ( em != null && em.isOpen() ) {
 			em.close();
 		}
 		em = factory.createEntityManager( properties );
 		return em;
 	}
 
 	public String[] getEjb3DD() {
 		return new String[] { };
 	}
 
 	public Map<Class, String> getCachedClasses() {
 		return new HashMap<Class, String>();
 	}
 
 	public Map<String, String> getCachedCollections() {
 		return new HashMap<String, String>();
 	}
 
 	public static Properties loadProperties() {
 		Properties props = new Properties();
 		InputStream stream = Persistence.class.getResourceAsStream( "/hibernate.properties" );
 		if ( stream != null ) {
 			try {
 				props.load( stream );
 			}
 			catch ( Exception e ) {
 				throw new RuntimeException( "could not load hibernate.properties" );
 			}
 			finally {
 				try {
 					stream.close();
 				}
 				catch ( IOException ioe ) {
 				}
 			}
 		}
 		props.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
 		return props;
 	}
 
 	public Map getConfig() {
 		Map<Object, Object> config = loadProperties();
 		ArrayList<Class> classes = new ArrayList<Class>();
 
 		classes.addAll( Arrays.asList( getAnnotatedClasses() ) );
 		config.put( AvailableSettings.LOADED_CLASSES, classes );
 		for ( Map.Entry<Class, String> entry : getCachedClasses().entrySet() ) {
 			config.put(
 					AvailableSettings.CLASS_CACHE_PREFIX + "." + entry.getKey().getName(),
 					entry.getValue()
 			);
 		}
 		for ( Map.Entry<String, String> entry : getCachedCollections().entrySet() ) {
 			config.put(
 					AvailableSettings.COLLECTION_CACHE_PREFIX + "." + entry.getKey(),
 					entry.getValue()
 			);
 		}
 		if ( getEjb3DD().length > 0 ) {
 			ArrayList<String> dds = new ArrayList<String>();
 			dds.addAll( Arrays.asList( getEjb3DD() ) );
 			config.put( AvailableSettings.XML_FILE_NAMES, dds );
 		}
 
 		addConfigOptions( config );
 		return config;
 	}
 
 	protected void addConfigOptions(Map options) {
 	}
 
 	@Override
 	public void runBare() throws Throwable {
 		if ( !appliesTo( Dialect.getDialect() ) ) {
 			return;
 		}
 		super.runBare();
 	}
 
 	public boolean appliesTo(Dialect dialect) {
 		return true;
 	}
 }
diff --git a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/metadata/MetadataTest.java b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/metadata/MetadataTest.java
index bb2cf6443e..c988686377 100644
--- a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/metadata/MetadataTest.java
+++ b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/metadata/MetadataTest.java
@@ -1,367 +1,367 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.test.metadata;
 
 import java.util.Set;
 import javax.persistence.EntityManagerFactory;
 import javax.persistence.metamodel.EntityType;
 import javax.persistence.metamodel.Bindable;
 import javax.persistence.metamodel.SingularAttribute;
 import javax.persistence.metamodel.Type;
 import javax.persistence.metamodel.Attribute;
 import javax.persistence.metamodel.EmbeddableType;
 import javax.persistence.metamodel.SetAttribute;
 import javax.persistence.metamodel.PluralAttribute;
 import javax.persistence.metamodel.MapAttribute;
 import javax.persistence.metamodel.ListAttribute;
 import javax.persistence.metamodel.MappedSuperclassType;
 import javax.persistence.metamodel.IdentifiableType;
 
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.ejb.metamodel.MetamodelImpl;
 import org.hibernate.ejb.test.TestCase;
 import org.hibernate.engine.SessionFactoryImplementor;
 
 /**
  * @author Emmanuel Bernard
  */
 public class MetadataTest extends TestCase {
 
 	public void testBaseOfService() throws Exception {
 		EntityManagerFactory emf = factory;
 		assertNotNull( emf.getMetamodel() );
 		final EntityType<Fridge> entityType = emf.getMetamodel().entity( Fridge.class );
 		assertNotNull( entityType );
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public void testBuildingMetamodelWithParameterizedCollection() {
 		AnnotationConfiguration cfg = new AnnotationConfiguration( );
 		configure( cfg );
 		cfg.addAnnotatedClass( WithGenericCollection.class );
 		cfg.buildMappings();
-		SessionFactoryImplementor sfi = (SessionFactoryImplementor) cfg.buildSessionFactory();
+		SessionFactoryImplementor sfi = (SessionFactoryImplementor) cfg.buildSessionFactory( getServiceRegistry() );
 		MetamodelImpl.buildMetamodel( cfg.getClassMappings(), sfi );
 	}
 
 	public void testLogicalManyToOne() throws Exception {
 		final EntityType<JoinedManyToOneOwner> entityType = factory.getMetamodel().entity( JoinedManyToOneOwner.class );
 		final SingularAttribute attr = entityType.getDeclaredSingularAttribute( "house" );
 		assertEquals( Attribute.PersistentAttributeType.MANY_TO_ONE, attr.getPersistentAttributeType() );
 		assertEquals( House.class, attr.getBindableJavaType() );
 		final EntityType<House> houseType = factory.getMetamodel().entity( House.class );
 		assertEquals( houseType.getBindableJavaType(), attr.getBindableJavaType() );
 	}
 
 	public void testEntity() throws Exception {
 		final EntityType<Fridge> fridgeType = factory.getMetamodel().entity( Fridge.class );
 		assertEquals( Fridge.class, fridgeType.getBindableJavaType() );
 		assertEquals( Bindable.BindableType.ENTITY_TYPE, fridgeType.getBindableType() );
 		SingularAttribute<Fridge,Integer> wrapped = fridgeType.getDeclaredSingularAttribute( "temperature", Integer.class );
 		assertNotNull( wrapped );
 		SingularAttribute<Fridge,Integer> primitive = fridgeType.getDeclaredSingularAttribute( "temperature", int.class );
 		assertNotNull( primitive );
 		assertNotNull( fridgeType.getDeclaredSingularAttribute( "temperature" ) );
 		assertNotNull( fridgeType.getDeclaredAttribute( "temperature" ) );
 		final SingularAttribute<Fridge, Long> id = fridgeType.getDeclaredId( Long.class );
 		assertNotNull( id );
 		assertTrue( id.isId() );
 		try {
 			fridgeType.getDeclaredId( java.util.Date.class );
 			fail( "expecting failure" );
 		}
 		catch ( IllegalArgumentException ignore ) {
 			// expected result
 		}
 		final SingularAttribute<? super Fridge, Long> id2 = fridgeType.getId( Long.class );
 		assertNotNull( id2 );
 
 		assertEquals( "Fridge", fridgeType.getName() );
 		assertEquals( Long.class, fridgeType.getIdType().getJavaType() );
 		assertTrue( fridgeType.hasSingleIdAttribute() );
 		assertFalse( fridgeType.hasVersionAttribute() );
 		assertEquals( Type.PersistenceType.ENTITY, fridgeType.getPersistenceType() );
 
 		assertEquals( 3, fridgeType.getDeclaredAttributes().size() );
 
 		final EntityType<House> houseType = factory.getMetamodel().entity( House.class );
 		assertEquals( "org.hibernate.ejb.test.metadata.House", houseType.getName() );
 		assertTrue( houseType.hasSingleIdAttribute() );
 		final SingularAttribute<House, House.Key> houseId = houseType.getDeclaredId( House.Key.class );
 		assertNotNull( houseId );
 		assertTrue( houseId.isId() );
 		assertEquals( Attribute.PersistentAttributeType.EMBEDDED, houseId.getPersistentAttributeType() );
 		
 		final EntityType<Person> personType = factory.getMetamodel().entity( Person.class );
 		assertEquals( "Homo", personType.getName() );
 		assertFalse( personType.hasSingleIdAttribute() );
 		final Set<SingularAttribute<? super Person,?>> ids = personType.getIdClassAttributes();
 		assertNotNull( ids );
 		assertEquals( 2, ids.size() );
 		for (SingularAttribute<? super Person,?> localId : ids) {
 			assertTrue( localId.isId() );
 		}
 
 		final EntityType<FoodItem> foodType = factory.getMetamodel().entity( FoodItem.class );
 		assertTrue( foodType.hasVersionAttribute() );
 		final SingularAttribute<? super FoodItem, Long> version = foodType.getVersion( Long.class );
 		assertNotNull( version );
 		assertTrue( version.isVersion() );
 		assertEquals( 3, foodType.getDeclaredAttributes().size() );
 
 	}
 
 	public void testBasic() throws Exception {
 		final EntityType<Fridge> entityType = factory.getMetamodel().entity( Fridge.class );
 		final SingularAttribute<? super Fridge,Integer> singularAttribute = entityType.getDeclaredSingularAttribute(
 				"temperature",
 				Integer.class
 		);
 //		assertEquals( Integer.class, singularAttribute.getBindableJavaType() );
 //		assertEquals( Integer.class, singularAttribute.getType().getJavaType() );
 		assertEquals( int.class, singularAttribute.getBindableJavaType() );
 		assertEquals( int.class, singularAttribute.getType().getJavaType() );
 		assertEquals( Bindable.BindableType.SINGULAR_ATTRIBUTE, singularAttribute.getBindableType() );
 		assertFalse( singularAttribute.isId() );
 		assertFalse( singularAttribute.isOptional() );
 		assertFalse( entityType.getDeclaredSingularAttribute( "brand", String.class ).isOptional() );
 		assertEquals( Type.PersistenceType.BASIC, singularAttribute.getType().getPersistenceType() );
 		final Attribute<? super Fridge, ?> attribute = entityType.getDeclaredAttribute( "temperature" );
 		assertNotNull( attribute );
 		assertEquals( "temperature", attribute.getName() );
 		assertEquals( Fridge.class, attribute.getDeclaringType().getJavaType() );
 		assertEquals( Attribute.PersistentAttributeType.BASIC, attribute.getPersistentAttributeType() );
 //		assertEquals( Integer.class, attribute.getJavaType() );
 		assertEquals( int.class, attribute.getJavaType() );
 		assertFalse( attribute.isAssociation() );
 		assertFalse( attribute.isCollection() );
 
 		boolean found = false;
 		for (Attribute<Fridge, ?> attr : entityType.getDeclaredAttributes() ) {
 			if ("temperature".equals( attr.getName() ) ) {
 				found = true;
 				break;
 			}
 		}
 		assertTrue( found );
 	}
 
 	public void testEmbeddable() throws Exception {
 		final EntityType<House> entityType = factory.getMetamodel().entity( House.class );
 		final SingularAttribute<? super House,Address> address = entityType.getDeclaredSingularAttribute(
 				"address",
 				Address.class
 		);
 		assertNotNull( address );
 		assertEquals( Attribute.PersistentAttributeType.EMBEDDED, address.getPersistentAttributeType() );
 		assertFalse( address.isCollection() );
 		assertFalse( address.isAssociation() );
 		final EmbeddableType<Address> addressType = (EmbeddableType<Address>) address.getType();
 		assertEquals( Type.PersistenceType.EMBEDDABLE, addressType.getPersistenceType() );
 		assertEquals( 3, addressType.getDeclaredAttributes().size() );
 		assertTrue( addressType.getDeclaredSingularAttribute( "address1" ).isOptional() );
 		assertFalse( addressType.getDeclaredSingularAttribute( "address2" ).isOptional() );
 
 		final EmbeddableType<Address> directType = factory.getMetamodel().embeddable( Address.class );
 		assertNotNull( directType );
 		assertEquals( Type.PersistenceType.EMBEDDABLE, directType.getPersistenceType() );
 	}
 
 	public void testCollection() throws Exception {
 		final EntityType<Garden> entiytype = factory.getMetamodel().entity( Garden.class );
 		final Set<PluralAttribute<? super Garden, ?, ?>> attributes = entiytype.getPluralAttributes();
 		assertEquals( 1, attributes.size() );
 		PluralAttribute<? super Garden, ?, ?> flowers = attributes.iterator().next();
 		assertTrue( flowers instanceof ListAttribute );
 	}
 
 	public void testElementCollection() throws Exception {
 		final EntityType<House> entityType = factory.getMetamodel().entity( House.class );
 		final SetAttribute<House,Room> rooms = entityType.getDeclaredSet( "rooms", Room.class );
 		assertNotNull( rooms );
 		assertTrue( rooms.isAssociation() );
 		assertTrue( rooms.isCollection() );
 		assertEquals( Attribute.PersistentAttributeType.ELEMENT_COLLECTION, rooms.getPersistentAttributeType() );
 		assertEquals( Room.class, rooms.getBindableJavaType() );
 		assertEquals( Bindable.BindableType.PLURAL_ATTRIBUTE, rooms.getBindableType() );
 		assertEquals( Set.class, rooms.getJavaType() );
 		assertEquals( PluralAttribute.CollectionType.SET, rooms.getCollectionType() );
 		assertEquals( 3, entityType.getDeclaredPluralAttributes().size() );
 		assertEquals( Type.PersistenceType.EMBEDDABLE, rooms.getElementType().getPersistenceType() );
 
 		final MapAttribute<House,String,Room> roomsByName = entityType.getDeclaredMap(
 				"roomsByName", String.class, Room.class
 		);
 		assertNotNull( roomsByName );
 		assertEquals( String.class, roomsByName.getKeyJavaType() );
 		assertEquals( Type.PersistenceType.BASIC, roomsByName.getKeyType().getPersistenceType() );
 		assertEquals( PluralAttribute.CollectionType.MAP, roomsByName.getCollectionType() );
 
 		final ListAttribute<House,Room> roomsBySize = entityType.getDeclaredList( "roomsBySize", Room.class );
 		assertNotNull( roomsBySize );
 		assertEquals( Type.PersistenceType.EMBEDDABLE, roomsBySize.getElementType().getPersistenceType() );
 		assertEquals( PluralAttribute.CollectionType.LIST, roomsBySize.getCollectionType() );
 	}
 
 	public void testHierarchy() {
 		final EntityType<Cat> cat = factory.getMetamodel().entity( Cat.class );
 		assertNotNull( cat );
 		assertEquals( 7, cat.getAttributes().size() );
 		assertEquals( 1, cat.getDeclaredAttributes().size() );
 		ensureProperMember(cat.getDeclaredAttributes());
 
 		assertTrue( cat.hasVersionAttribute() );
 		assertEquals( "version", cat.getVersion(Long.class).getName() );
 		verifyDeclaredVersionNotPresent( cat );
 		verifyDeclaredIdNotPresentAndIdPresent(cat);
 
 		assertEquals( Type.PersistenceType.MAPPED_SUPERCLASS, cat.getSupertype().getPersistenceType() );
 		MappedSuperclassType<Cattish> cattish = (MappedSuperclassType<Cattish>) cat.getSupertype();
 		assertEquals( 6, cattish.getAttributes().size() );
 		assertEquals( 1, cattish.getDeclaredAttributes().size() );
 		ensureProperMember(cattish.getDeclaredAttributes());
 
 		assertTrue( cattish.hasVersionAttribute() );
 		assertEquals( "version", cattish.getVersion(Long.class).getName() );
 		verifyDeclaredVersionNotPresent( cattish );
 		verifyDeclaredIdNotPresentAndIdPresent(cattish);
 
 		assertEquals( Type.PersistenceType.ENTITY, cattish.getSupertype().getPersistenceType() );
 		EntityType<Feline> feline = (EntityType<Feline>) cattish.getSupertype();
 		assertEquals( 5, feline.getAttributes().size() );
 		assertEquals( 1, feline.getDeclaredAttributes().size() );
 		ensureProperMember(feline.getDeclaredAttributes());
 
 		assertTrue( feline.hasVersionAttribute() );
 		assertEquals( "version", feline.getVersion(Long.class).getName() );
 		verifyDeclaredVersionNotPresent( feline );
 		verifyDeclaredIdNotPresentAndIdPresent(feline);
 
 		assertEquals( Type.PersistenceType.MAPPED_SUPERCLASS, feline.getSupertype().getPersistenceType() );
 		MappedSuperclassType<Animal> animal = (MappedSuperclassType<Animal>) feline.getSupertype();
 		assertEquals( 4, animal.getAttributes().size() );
 		assertEquals( 2, animal.getDeclaredAttributes().size() );
 		ensureProperMember(animal.getDeclaredAttributes());
 
 		assertTrue( animal.hasVersionAttribute() );
 		assertEquals( "version", animal.getVersion(Long.class).getName() );
 		verifyDeclaredVersionNotPresent( animal );
 		assertEquals( "id", animal.getId(Long.class).getName() );
 		final SingularAttribute<Animal, Long> id = animal.getDeclaredId( Long.class );
 		assertEquals( "id", id.getName() );
 		assertNotNull( id.getJavaMember() );
 
 		assertEquals( Type.PersistenceType.MAPPED_SUPERCLASS, animal.getSupertype().getPersistenceType() );
 		MappedSuperclassType<Thing> thing = (MappedSuperclassType<Thing>) animal.getSupertype();
 		assertEquals( 2, thing.getAttributes().size() );
 		assertEquals( 2, thing.getDeclaredAttributes().size() );
 		ensureProperMember(thing.getDeclaredAttributes());
 		final SingularAttribute<Thing, Double> weight = thing.getDeclaredSingularAttribute( "weight", Double.class );
 		assertEquals( Double.class, weight.getJavaType() );
 
 		assertEquals( "version", thing.getVersion(Long.class).getName() );
 		final SingularAttribute<Thing, Long> version = thing.getDeclaredVersion( Long.class );
 		assertEquals( "version", version.getName() );
 		assertNotNull( version.getJavaMember() );
 		assertNull( thing.getId( Long.class ) );
 
 		assertNull( thing.getSupertype() );
 	}
 
 	public void testBackrefAndGenerics() throws Exception {
 		final EntityType<Parent> parent = factory.getMetamodel().entity( Parent.class );
 		assertNotNull( parent );
 		final SetAttribute<? super Parent, ?> children = parent.getSet( "children" );
 		assertNotNull( children );
 		assertEquals( 1, parent.getPluralAttributes().size() );
 		assertEquals( 4, parent.getAttributes().size() );
 		final EntityType<Child> child = factory.getMetamodel().entity( Child.class );
 		assertNotNull( child );
 		assertEquals( 2, child.getAttributes().size() );
 		final SingularAttribute<? super Parent, Parent.Relatives> attribute = parent.getSingularAttribute(
 				"siblings", Parent.Relatives.class
 		);
 		final EmbeddableType<Parent.Relatives> siblings = (EmbeddableType<Parent.Relatives>) attribute.getType();
 		assertNotNull(siblings);
 		final SetAttribute<? super Parent.Relatives, ?> siblingsCollection = siblings.getSet( "siblings" );
 		assertNotNull( siblingsCollection );
 		final Type<?> collectionElement = siblingsCollection.getElementType();
 		assertNotNull( collectionElement );
 		assertEquals( collectionElement, child );
 	}
 
 	private void ensureProperMember(Set<?> attributes) {
 		//we do not update the set so we are safe
 		@SuppressWarnings( "unchecked" )
 		final Set<Attribute<?, ?>> safeAttributes = ( Set<Attribute<?, ?>> ) attributes;
 		for (Attribute<?,?> attribute : safeAttributes ) {
 			final String name = attribute.getJavaMember().getName();
 			assertNotNull( attribute.getJavaMember() );
 			assertTrue( name.toLowerCase().endsWith( attribute.getName().toLowerCase() ) );
 		}
 	}
 
 	private void verifyDeclaredIdNotPresentAndIdPresent(IdentifiableType<?> type) {
 		assertEquals( "id", type.getId(Long.class).getName() );
 		try {
 			type.getDeclaredId(Long.class);
 			fail("Should not have a declared id");
 		}
 		catch (IllegalArgumentException e) {
 			//success
 		}
 	}
 
 	private void verifyDeclaredVersionNotPresent(IdentifiableType<?> type) {
 		try {
 			type.getDeclaredVersion(Long.class);
 			fail("Should not have a declared version");
 		}
 		catch (IllegalArgumentException e) {
 			//success
 		}
 	}
 
 	//todo test plural
 
 	@Override
 	public Class[] getAnnotatedClasses() {
 		return new Class[]{
 				Fridge.class,
 				FoodItem.class,
 				Person.class,
 				House.class,
 				Dog.class,
 				Cat.class,
 				Cattish.class,
 				Feline.class,
 				Garden.class,
 				Flower.class,
 				JoinedManyToOneOwner.class,
 				Parent.class,
 				Child.class
 		};
 	}
 
 }
diff --git a/hibernate-envers/src/test/java/org/hibernate/envers/test/AbstractSessionTest.java b/hibernate-envers/src/test/java/org/hibernate/envers/test/AbstractSessionTest.java
index d8488b3fbe..6f3d205719 100644
--- a/hibernate-envers/src/test/java/org/hibernate/envers/test/AbstractSessionTest.java
+++ b/hibernate-envers/src/test/java/org/hibernate/envers/test/AbstractSessionTest.java
@@ -1,78 +1,91 @@
 package org.hibernate.envers.test;
 
 import java.io.File;
 import java.net.URISyntaxException;
 import java.net.URL;
 
 import org.hibernate.MappingException;
 import org.hibernate.Session;
 import org.hibernate.SessionFactory;
 import org.hibernate.cfg.AnnotationConfiguration;
 import org.hibernate.cfg.Configuration;
+import org.hibernate.cfg.Environment;
 import org.hibernate.envers.AuditReader;
 import org.hibernate.envers.AuditReaderFactory;
+import org.hibernate.test.common.ServiceRegistryHolder;
+
 import org.testng.annotations.*;
 
 /**
  * Base class for testing envers with Session.
  * 
  * @author Hernn Chanfreau
  *
  */
 public abstract class AbstractSessionTest {
 
 	protected Configuration config;
+	private ServiceRegistryHolder serviceRegistryHolder;
 	private SessionFactory sessionFactory;
 	private Session session ;
 	private AuditReader auditReader;
 	
 	
 	@BeforeClass
     @Parameters("auditStrategy")
     public void init(@Optional String auditStrategy) throws URISyntaxException {
         config = new AnnotationConfiguration();
         URL url = Thread.currentThread().getContextClassLoader().getResource("hibernate.test.session-cfg.xml");
         config.configure(new File(url.toURI()));
 
         if (auditStrategy != null && !"".equals(auditStrategy)) {
             config.setProperty("org.hibernate.envers.audit_strategy", auditStrategy);
         }
 
         this.initMappings();
 		
-		sessionFactory = config.buildSessionFactory();
+		serviceRegistryHolder = new ServiceRegistryHolder( Environment.getProperties() );
+		sessionFactory = config.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
     }
 	
 	protected abstract void initMappings() throws MappingException, URISyntaxException ;
 
 
 
 	private SessionFactory getSessionFactory(){
 		return sessionFactory;
     }
 
 
     @BeforeMethod
     public void newSessionFactory() {
       session = getSessionFactory().openSession();
       auditReader = AuditReaderFactory.get(session);
     }
 	
 	@AfterClass
 	public void closeSessionFactory() {
-	    sessionFactory.close();
+		try {
+	   		sessionFactory.close();
+		}
+		finally {
+			if ( serviceRegistryHolder != null ) {
+					serviceRegistryHolder.destroy();
+					serviceRegistryHolder = null;
+			}
+		}
 	}
 	
 	
 	protected Session getSession() {
 		return session;
 	}
 
 
 
 	protected AuditReader getAuditReader() {
 		return auditReader;
 	}
 
 }
 
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractEntityCollectionRegionTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractEntityCollectionRegionTestCase.java
index c196a1e9dc..d029b99e1a 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractEntityCollectionRegionTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractEntityCollectionRegionTestCase.java
@@ -1,109 +1,117 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan;
 
 import java.util.Properties;
 
 import org.hibernate.cache.CacheDataDescription;
 import org.hibernate.cache.RegionFactory;
 import org.hibernate.cache.TransactionalDataRegion;
 import org.hibernate.cache.access.AccessType;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 
 /**
  * Base class for tests of EntityRegion and CollectionRegion implementations.
  * 
  * @author Galder Zamarreo
  * @since 3.5
  */
 public abstract class AbstractEntityCollectionRegionTestCase extends AbstractRegionImplTestCase {
 
    /**
     * Create a new EntityCollectionRegionTestCaseBase.
     * 
     * @param name
     */
    public AbstractEntityCollectionRegionTestCase(String name) {
       super(name);
    }
 
    /**
     * Creates a Region backed by an PESSIMISTIC locking JBoss Cache, and then ensures that it
     * handles calls to buildAccessStrategy as expected when all the various {@link AccessType}s are
     * passed as arguments.
     */
    public void testSupportedAccessTypes() throws Exception {
       supportedAccessTypeTest();
    }
 
    private void supportedAccessTypeTest() throws Exception {
       Configuration cfg = CacheTestUtil.buildConfiguration("test", InfinispanRegionFactory.class, true, false);
       String entityCfg = "entity";
       cfg.setProperty(InfinispanRegionFactory.ENTITY_CACHE_RESOURCE_PROP, entityCfg);
-      InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(cfg, getCacheTestSupport());
+      InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
+			  getConnectionProvider(), cfg, getCacheTestSupport()
+	  );
       supportedAccessTypeTest(regionFactory, cfg.getProperties());
    }
 
    /**
     * Creates a Region using the given factory, and then ensure that it handles calls to
     * buildAccessStrategy as expected when all the various {@link AccessType}s are passed as
     * arguments.
     */
    protected abstract void supportedAccessTypeTest(RegionFactory regionFactory, Properties properties);
 
    /**
     * Test that the Region properly implements {@link TransactionalDataRegion#isTransactionAware()}.
     * 
     * @throws Exception
     */
    public void testIsTransactionAware() throws Exception {
       Configuration cfg = CacheTestUtil.buildConfiguration("test", InfinispanRegionFactory.class, true, false);
-      InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(cfg, getCacheTestSupport());
+      InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
+			  getConnectionProvider(), cfg, getCacheTestSupport()
+	  );
       TransactionalDataRegion region = (TransactionalDataRegion) createRegion(regionFactory, "test/test", cfg.getProperties(), getCacheDataDescription());
       assertTrue("Region is transaction-aware", region.isTransactionAware());
       CacheTestUtil.stopRegionFactory(regionFactory, getCacheTestSupport());
       cfg = CacheTestUtil.buildConfiguration("test", InfinispanRegionFactory.class, true, false);
       // Make it non-transactional
       cfg.getProperties().remove(Environment.TRANSACTION_MANAGER_STRATEGY);
-      regionFactory = CacheTestUtil.startRegionFactory(cfg, getCacheTestSupport());
+      regionFactory = CacheTestUtil.startRegionFactory(
+			  getConnectionProvider(), cfg, getCacheTestSupport()
+	  );
       region = (TransactionalDataRegion) createRegion(regionFactory, "test/test", cfg.getProperties(), getCacheDataDescription());
       assertFalse("Region is not transaction-aware", region.isTransactionAware());
       CacheTestUtil.stopRegionFactory(regionFactory, getCacheTestSupport());
    }
 
    public void testGetCacheDataDescription() throws Exception {
       Configuration cfg = CacheTestUtil.buildConfiguration("test", InfinispanRegionFactory.class, true, false);
-      InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(cfg, getCacheTestSupport());
+      InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
+			  getConnectionProvider(), cfg, getCacheTestSupport()
+	  );
       TransactionalDataRegion region = (TransactionalDataRegion) createRegion(regionFactory, "test/test", cfg.getProperties(), getCacheDataDescription());
       CacheDataDescription cdd = region.getCacheDataDescription();
       assertNotNull(cdd);
       CacheDataDescription expected = getCacheDataDescription();
       assertEquals(expected.isMutable(), cdd.isMutable());
       assertEquals(expected.isVersioned(), cdd.isVersioned());
       assertEquals(expected.getVersionComparator(), cdd.getVersionComparator());
    }
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractGeneralDataRegionTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractGeneralDataRegionTestCase.java
index 4d69d2887c..1cb2e9661f 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractGeneralDataRegionTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractGeneralDataRegionTestCase.java
@@ -1,194 +1,202 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan;
 
 import java.util.Set;
 
 import org.hibernate.cache.GeneralDataRegion;
 import org.hibernate.cache.QueryResultsRegion;
 import org.hibernate.cache.Region;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 import org.infinispan.transaction.tm.BatchModeTransactionManager;
 
 /**
  * Base class for tests of QueryResultsRegion and TimestampsRegion.
  * 
  * @author Galder Zamarreo
  * @since 3.5
  */
 public abstract class AbstractGeneralDataRegionTestCase extends AbstractRegionImplTestCase {
    protected static final String KEY = "Key";
 
    protected static final String VALUE1 = "value1";
    protected static final String VALUE2 = "value2";
 
    public AbstractGeneralDataRegionTestCase(String name) {
       super(name);
    }
 
    @Override
    protected void putInRegion(Region region, Object key, Object value) {
       ((GeneralDataRegion) region).put(key, value);
    }
 
    @Override
    protected void removeFromRegion(Region region, Object key) {
       ((GeneralDataRegion) region).evict(key);
    }
 
    /**
     * Test method for {@link QueryResultsRegion#evict(java.lang.Object)}.
     * 
     * FIXME add testing of the "immediately without regard for transaction isolation" bit in the
     * CollectionRegionAccessStrategy API.
     */
    public void testEvict() throws Exception {
       evictOrRemoveTest();
    }
 
    private void evictOrRemoveTest() throws Exception {
       Configuration cfg = createConfiguration();
-      InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(cfg, getCacheTestSupport());
+      InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
+			  getConnectionProvider(), cfg, getCacheTestSupport()
+	  );
       CacheAdapter localCache = getInfinispanCache(regionFactory);
       boolean invalidation = localCache.isClusteredInvalidation();
 
       // Sleep a bit to avoid concurrent FLUSH problem
       avoidConcurrentFlush();
 
       GeneralDataRegion localRegion = (GeneralDataRegion) createRegion(regionFactory,
                getStandardRegionName(REGION_PREFIX), cfg.getProperties(), null);
 
       cfg = createConfiguration();
-      regionFactory = CacheTestUtil.startRegionFactory(cfg, getCacheTestSupport());
+      regionFactory = CacheTestUtil.startRegionFactory(
+			  getConnectionProvider(), cfg, getCacheTestSupport()
+	  );
 
       GeneralDataRegion remoteRegion = (GeneralDataRegion) createRegion(regionFactory,
                getStandardRegionName(REGION_PREFIX), cfg.getProperties(), null);
 
       assertNull("local is clean", localRegion.get(KEY));
       assertNull("remote is clean", remoteRegion.get(KEY));
 
       localRegion.put(KEY, VALUE1);
       assertEquals(VALUE1, localRegion.get(KEY));
 
       // allow async propagation
       sleep(250);
       Object expected = invalidation ? null : VALUE1;
       assertEquals(expected, remoteRegion.get(KEY));
 
       localRegion.evict(KEY);
 
       // allow async propagation
       sleep(250);
       assertEquals(null, localRegion.get(KEY));
       assertEquals(null, remoteRegion.get(KEY));
    }
 
    protected abstract String getStandardRegionName(String regionPrefix);
 
    /**
     * Test method for {@link QueryResultsRegion#evictAll()}.
     * 
     * FIXME add testing of the "immediately without regard for transaction isolation" bit in the
     * CollectionRegionAccessStrategy API.
     */
    public void testEvictAll() throws Exception {
       evictOrRemoveAllTest("entity");
    }
 
    private void evictOrRemoveAllTest(String configName) throws Exception {
       Configuration cfg = createConfiguration();
-      InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(cfg, getCacheTestSupport());
+      InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
+			  getConnectionProvider(), cfg, getCacheTestSupport()
+	  );
       CacheAdapter localCache = getInfinispanCache(regionFactory);
 
       // Sleep a bit to avoid concurrent FLUSH problem
       avoidConcurrentFlush();
 
       GeneralDataRegion localRegion = (GeneralDataRegion) createRegion(regionFactory,
                getStandardRegionName(REGION_PREFIX), cfg.getProperties(), null);
 
       cfg = createConfiguration();
-      regionFactory = CacheTestUtil.startRegionFactory(cfg, getCacheTestSupport());
+      regionFactory = CacheTestUtil.startRegionFactory(
+			  getConnectionProvider(), cfg, getCacheTestSupport()
+	  );
       CacheAdapter remoteCache = getInfinispanCache(regionFactory);
 
       // Sleep a bit to avoid concurrent FLUSH problem
       avoidConcurrentFlush();
 
       GeneralDataRegion remoteRegion = (GeneralDataRegion) createRegion(regionFactory,
                getStandardRegionName(REGION_PREFIX), cfg.getProperties(), null);
 
       Set keys = localCache.keySet();
       assertEquals("No valid children in " + keys, 0, getValidKeyCount(keys));
 
       keys = remoteCache.keySet();
       assertEquals("No valid children in " + keys, 0, getValidKeyCount(keys));
 
       assertNull("local is clean", localRegion.get(KEY));
       assertNull("remote is clean", remoteRegion.get(KEY));
 
       localRegion.put(KEY, VALUE1);
       assertEquals(VALUE1, localRegion.get(KEY));
 
       // Allow async propagation
       sleep(250);
 
       remoteRegion.put(KEY, VALUE1);
       assertEquals(VALUE1, remoteRegion.get(KEY));
 
       // Allow async propagation
       sleep(250);
 
       localRegion.evictAll();
 
       // allow async propagation
       sleep(250);
       // This should re-establish the region root node in the optimistic case
       assertNull(localRegion.get(KEY));
       assertEquals("No valid children in " + keys, 0, getValidKeyCount(localCache.keySet()));
 
       // Re-establishing the region root on the local node doesn't
       // propagate it to other nodes. Do a get on the remote node to re-establish
       // This only adds a node in the case of optimistic locking
       assertEquals(null, remoteRegion.get(KEY));
       assertEquals("No valid children in " + keys, 0, getValidKeyCount(remoteCache.keySet()));
 
       assertEquals("local is clean", null, localRegion.get(KEY));
       assertEquals("remote is clean", null, remoteRegion.get(KEY));
    }
 
    protected Configuration createConfiguration() {
       Configuration cfg = CacheTestUtil.buildConfiguration("test", InfinispanRegionFactory.class, false, true);
       return cfg;
    }
 
    protected void rollback() {
       try {
          BatchModeTransactionManager.getInstance().rollback();
       } catch (Exception e) {
          log.error(e.getMessage(), e);
       }
    }
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractNonFunctionalTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractNonFunctionalTestCase.java
index acf3f93eee..84ffd1264b 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractNonFunctionalTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractNonFunctionalTestCase.java
@@ -1,111 +1,115 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan;
 
 import java.util.Set;
 
 import org.hibernate.cache.RegionFactory;
 import org.hibernate.cache.infinispan.util.CacheHelper;
+import org.hibernate.cfg.Environment;
+import org.hibernate.engine.jdbc.spi.JdbcServices;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
+import org.hibernate.service.spi.ServicesRegistry;
 import org.hibernate.testing.junit.UnitTestCase;
 import org.hibernate.test.cache.infinispan.util.CacheTestSupport;
 import org.infinispan.Cache;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
  * Base class for all non-functional tests of Infinispan integration.
  * 
  * @author Galder Zamarreo
  * @since 3.5
  */
 public abstract class AbstractNonFunctionalTestCase extends UnitTestCase {
 
     public static final String REGION_PREFIX = "test";
     
     private CacheTestSupport testSupport;
     protected final Logger log = LoggerFactory.getLogger(getClass());
     
     public AbstractNonFunctionalTestCase(String name) {
         super(name);
         testSupport = new CacheTestSupport(log);
     }
 
     @Override
     protected void setUp() throws Exception {
         super.setUp();
         
         testSupport.setUp();
     }
 
     @Override
     protected void tearDown() throws Exception {
         super.tearDown();
         
         testSupport.tearDown();
     }
 
     protected void registerCache(Cache cache) {
         testSupport.registerCache(cache);
     }
 
     protected void unregisterCache(Cache cache) {
         testSupport.unregisterCache(cache);
     }
 
     protected void registerFactory(RegionFactory factory) {
         testSupport.registerFactory(factory);
     }
 
     protected void unregisterFactory(RegionFactory factory) {
         testSupport.unregisterFactory(factory);
     }
 
     protected CacheTestSupport getCacheTestSupport() {
         return testSupport;
     }
 
     protected void sleep(long ms) {
         try {
             Thread.sleep(ms);
         }
         catch (InterruptedException e) {
             log.warn("Interrupted during sleep", e);
         }
     }
     
     protected void avoidConcurrentFlush() {
         testSupport.avoidConcurrentFlush();
     }
 
     protected int getValidKeyCount(Set keys) {
        int result = 0;
        for (Object key : keys) {
           if (!(CacheHelper.isEvictAllNotification(key))) {
              result++;
           }
        }
        return result;
    }
 
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractCollectionRegionAccessStrategyTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractCollectionRegionAccessStrategyTestCase.java
index 0c77292874..5b6c30ca7b 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractCollectionRegionAccessStrategyTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractCollectionRegionAccessStrategyTestCase.java
@@ -1,571 +1,589 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.collection;
 
 import java.util.concurrent.BrokenBarrierException;
 import java.util.concurrent.Callable;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.CyclicBarrier;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
 import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.locks.Lock;
 
 import junit.extensions.TestSetup;
 import junit.framework.AssertionFailedError;
 import junit.framework.Test;
 import junit.framework.TestSuite;
 
 import org.hibernate.cache.CacheDataDescription;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.CollectionRegion;
 import org.hibernate.cache.access.AccessType;
 import org.hibernate.cache.access.CollectionRegionAccessStrategy;
 import org.hibernate.cache.impl.CacheDataDescriptionImpl;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.access.PutFromLoadValidator;
 import org.hibernate.cache.infinispan.access.TransactionalAccessDelegate;
 import org.hibernate.cache.infinispan.collection.CollectionRegionImpl;
 import org.hibernate.cache.infinispan.impl.BaseRegion;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.cache.infinispan.util.CacheAdapterImpl;
 import org.hibernate.cache.infinispan.util.FlagAdapter;
 import org.hibernate.cfg.Configuration;
+import org.hibernate.cfg.Environment;
 import org.hibernate.test.cache.infinispan.AbstractNonFunctionalTestCase;
 import org.hibernate.test.cache.infinispan.functional.cluster.DualNodeJtaTransactionManagerImpl;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
+import org.hibernate.test.common.ServiceRegistryHolder;
 import org.hibernate.util.ComparableComparator;
 import org.infinispan.Cache;
 import org.infinispan.transaction.tm.BatchModeTransactionManager;
 
 import javax.transaction.TransactionManager;
 
 /**
  * Base class for tests of CollectionRegionAccessStrategy impls.
  * 
  * @author Galder Zamarreo
  * @since 3.5
  */
 public abstract class AbstractCollectionRegionAccessStrategyTestCase extends AbstractNonFunctionalTestCase {
 
    public static final String REGION_NAME = "test/com.foo.test";
    public static final String KEY_BASE = "KEY";
    public static final String VALUE1 = "VALUE1";
    public static final String VALUE2 = "VALUE2";
 
    protected static int testCount;
 
    protected static Configuration localCfg;
    protected static InfinispanRegionFactory localRegionFactory;
    protected CacheAdapter localCache;
    protected static Configuration remoteCfg;
    protected static InfinispanRegionFactory remoteRegionFactory;
    protected CacheAdapter remoteCache;
 
    protected CollectionRegion localCollectionRegion;
    protected CollectionRegionAccessStrategy localAccessStrategy;
 
    protected CollectionRegion remoteCollectionRegion;
    protected CollectionRegionAccessStrategy remoteAccessStrategy;
 
    protected boolean invalidation;
    protected boolean synchronous;
 
    protected Exception node1Exception;
    protected Exception node2Exception;
 
    protected AssertionFailedError node1Failure;
    protected AssertionFailedError node2Failure;
 
    public static Test getTestSetup(Class testClass, String configName) {
       TestSuite suite = new TestSuite(testClass);
       return new AccessStrategyTestSetup(suite, configName);
    }
 
    public static Test getTestSetup(Test test, String configName) {
       return new AccessStrategyTestSetup(test, configName);
    }
 
    /**
     * Create a new TransactionalAccessTestCase.
     * 
     * @param name
     */
    public AbstractCollectionRegionAccessStrategyTestCase(String name) {
       super(name);
    }
 
    protected abstract AccessType getAccessType();
 
    protected void setUp() throws Exception {
       super.setUp();
 
       // Sleep a bit to avoid concurrent FLUSH problem
       avoidConcurrentFlush();
 
       localCollectionRegion = localRegionFactory.buildCollectionRegion(REGION_NAME, localCfg.getProperties(),
                getCacheDataDescription());
       localCache = ((BaseRegion) localCollectionRegion).getCacheAdapter();
       localAccessStrategy = localCollectionRegion.buildAccessStrategy(getAccessType());
       invalidation = localCache.isClusteredInvalidation();
       synchronous = localCache.isSynchronous();
 
       // Sleep a bit to avoid concurrent FLUSH problem
       avoidConcurrentFlush();
 
       remoteCollectionRegion = remoteRegionFactory.buildCollectionRegion(REGION_NAME, remoteCfg.getProperties(),
                getCacheDataDescription());
       remoteCache = ((BaseRegion) remoteCollectionRegion).getCacheAdapter();
       remoteAccessStrategy = remoteCollectionRegion.buildAccessStrategy(getAccessType());
 
       node1Exception = null;
       node2Exception = null;
 
       node1Failure = null;
       node2Failure = null;
    }
 
    protected void tearDown() throws Exception {
 
       super.tearDown();
 
       try {
          localCache.withFlags(FlagAdapter.CACHE_MODE_LOCAL).clear();
       } catch (Exception e) {
          log.error("Problem purging local cache", e);
       }
 
       try {
          remoteCache.withFlags(FlagAdapter.CACHE_MODE_LOCAL).clear();
       } catch (Exception e) {
          log.error("Problem purging remote cache", e);
       }
 
       node1Exception = null;
       node2Exception = null;
 
       node1Failure = null;
       node2Failure = null;
    }
 
    protected static Configuration createConfiguration(String configName, String configResource) {
       Configuration cfg = CacheTestUtil.buildConfiguration(REGION_PREFIX, InfinispanRegionFactory.class, true, false);
       cfg.setProperty(InfinispanRegionFactory.ENTITY_CACHE_RESOURCE_PROP, configName);
       return cfg;
    }
 
    protected CacheDataDescription getCacheDataDescription() {
       return new CacheDataDescriptionImpl(true, true, ComparableComparator.INSTANCE);
    }
 
    protected boolean isUsingInvalidation() {
       return invalidation;
    }
 
    protected boolean isSynchronous() {
       return synchronous;
    }
 
    /**
     * This is just a setup test where we assert that the cache config is as we expected.
     */
    public abstract void testCacheConfiguration();
 
    /**
     * Test method for {@link CollectionRegionAccessStrategy#getRegion()}.
     */
    public void testGetRegion() {
       assertEquals("Correct region", localCollectionRegion, localAccessStrategy.getRegion());
    }
 
    public void testPutFromLoadRemoveDoesNotProduceStaleData() throws Exception {
       final CountDownLatch pferLatch = new CountDownLatch(1);
       final CountDownLatch removeLatch = new CountDownLatch(1);
       TransactionManager tm = DualNodeJtaTransactionManagerImpl.getInstance("test1234");
       PutFromLoadValidator validator = new PutFromLoadValidator(tm) {
          @Override
          public boolean acquirePutFromLoadLock(Object key) {
             boolean acquired = super.acquirePutFromLoadLock(key);
             try {
                removeLatch.countDown();
                pferLatch.await(2, TimeUnit.SECONDS);
             } catch (InterruptedException e) {
                log.debug("Interrupted");
                Thread.currentThread().interrupt();
             } catch (Exception e) {
                log.error("Error", e);
                throw new RuntimeException("Error", e);
             }
             return acquired;
          }
       };
       final TransactionalAccessDelegate delegate = new TransactionalAccessDelegate((CollectionRegionImpl) localCollectionRegion, validator);
 
       Callable<Void> pferCallable = new Callable<Void>() {
          public Void call() throws Exception {
             delegate.putFromLoad("k1", "v1", 0, null);
             return null;
          }
       };
 
       Callable<Void> removeCallable = new Callable<Void>() {
          public Void call() throws Exception {
             removeLatch.await();
             delegate.remove("k1");
             pferLatch.countDown();
             return null;
          }
       };
 
       ExecutorService executorService = Executors.newCachedThreadPool();
       Future<Void> pferFuture = executorService.submit(pferCallable);
       Future<Void> removeFuture = executorService.submit(removeCallable);
 
       pferFuture.get();
       removeFuture.get();
 
       assertFalse(localCache.containsKey("k1"));
    }
 
    /**
     * Test method for
     * {@link CollectionRegionAccessStrategy#putFromLoad(java.lang.Object, java.lang.Object, long, java.lang.Object)}
     * .
     */
    public void testPutFromLoad() throws Exception {
       putFromLoadTest(false);
    }
 
    /**
     * Test method for
     * {@link CollectionRegionAccessStrategy#putFromLoad(java.lang.Object, java.lang.Object, long, java.lang.Object, boolean)}
     * .
     */
    public void testPutFromLoadMinimal() throws Exception {
       putFromLoadTest(true);
    }
 
    /**
     * Simulate 2 nodes, both start, tx do a get, experience a cache miss, then 'read from db.' First
     * does a putFromLoad, then an evict (to represent a change). Second tries to do a putFromLoad
     * with stale data (i.e. it took longer to read from the db). Both commit their tx. Then both
     * start a new tx and get. First should see the updated data; second should either see the
     * updated data (isInvalidation()( == false) or null (isInvalidation() == true).
     * 
     * @param useMinimalAPI
     * @throws Exception
     */
    private void putFromLoadTest(final boolean useMinimalAPI) throws Exception {
 
       final String KEY = KEY_BASE + testCount++;
 
       final CountDownLatch writeLatch1 = new CountDownLatch(1);
       final CountDownLatch writeLatch2 = new CountDownLatch(1);
       final CountDownLatch completionLatch = new CountDownLatch(2);
 
       Thread node1 = new Thread() {
 
          public void run() {
 
             try {
                long txTimestamp = System.currentTimeMillis();
                BatchModeTransactionManager.getInstance().begin();
 
                assertEquals("node1 starts clean", null, localAccessStrategy.get(KEY, txTimestamp));
 
                writeLatch1.await();
 
                if (useMinimalAPI) {
                   localAccessStrategy.putFromLoad(KEY, VALUE2, txTimestamp, new Integer(2), true);
                } else {
                   localAccessStrategy.putFromLoad(KEY, VALUE2, txTimestamp, new Integer(2));
                }
 
                BatchModeTransactionManager.getInstance().commit();
             } catch (Exception e) {
                log.error("node1 caught exception", e);
                node1Exception = e;
                rollback();
             } catch (AssertionFailedError e) {
                node1Failure = e;
                rollback();
             } finally {
                // Let node2 write
                writeLatch2.countDown();
                completionLatch.countDown();
             }
          }
       };
 
       Thread node2 = new Thread() {
 
          public void run() {
 
             try {
                long txTimestamp = System.currentTimeMillis();
                BatchModeTransactionManager.getInstance().begin();
 
                assertNull("node2 starts clean", remoteAccessStrategy.get(KEY, txTimestamp));
 
                // Let node1 write
                writeLatch1.countDown();
                // Wait for node1 to finish
                writeLatch2.await();
 
                // Let the first PFER propagate
                sleep(200);
 
                if (useMinimalAPI) {
                   remoteAccessStrategy.putFromLoad(KEY, VALUE1, txTimestamp, new Integer(1), true);
                } else {
                   remoteAccessStrategy.putFromLoad(KEY, VALUE1, txTimestamp, new Integer(1));
                }
 
                BatchModeTransactionManager.getInstance().commit();
             } catch (Exception e) {
                log.error("node2 caught exception", e);
                node2Exception = e;
                rollback();
             } catch (AssertionFailedError e) {
                node2Failure = e;
                rollback();
             } finally {
                completionLatch.countDown();
             }
          }
       };
 
       node1.setDaemon(true);
       node2.setDaemon(true);
 
       node1.start();
       node2.start();
 
       assertTrue("Threads completed", completionLatch.await(2, TimeUnit.SECONDS));
 
       if (node1Failure != null)
          throw node1Failure;
       if (node2Failure != null)
          throw node2Failure;
 
       assertEquals("node1 saw no exceptions", null, node1Exception);
       assertEquals("node2 saw no exceptions", null, node2Exception);
 
       // let the final PFER propagate
       sleep(100);
 
       long txTimestamp = System.currentTimeMillis();
       String msg1 = "Correct node1 value";
       String msg2 = "Correct node2 value";
       Object expected1 = null;
       Object expected2 = null;
       if (isUsingInvalidation()) {
          // PFER does not generate any invalidation, so each node should
          // succeed. We count on database locking and Hibernate removing
          // the collection on any update to prevent the situation we have
          // here where the caches have inconsistent data
          expected1 = VALUE2;
          expected2 = VALUE1;
       } else {
          // the initial VALUE2 should prevent the node2 put
          expected1 = VALUE2;
          expected2 = VALUE2;
       }
 
       assertEquals(msg1, expected1, localAccessStrategy.get(KEY, txTimestamp));
       assertEquals(msg2, expected2, remoteAccessStrategy.get(KEY, txTimestamp));
    }
 
    /**
     * Test method for {@link CollectionRegionAccessStrategy#remove(java.lang.Object)}.
     */
    public void testRemove() {
       evictOrRemoveTest(false);
    }
 
    /**
     * Test method for {@link CollectionRegionAccessStrategy#removeAll()}.
     */
    public void testRemoveAll() {
       evictOrRemoveAllTest(false);
    }
 
    /**
     * Test method for {@link CollectionRegionAccessStrategy#evict(java.lang.Object)}.
     * 
     * FIXME add testing of the "immediately without regard for transaction isolation" bit in the
     * CollectionRegionAccessStrategy API.
     */
    public void testEvict() {
       evictOrRemoveTest(true);
    }
 
    /**
     * Test method for {@link CollectionRegionAccessStrategy#evictAll()}.
     * 
     * FIXME add testing of the "immediately without regard for transaction isolation" bit in the
     * CollectionRegionAccessStrategy API.
     */
    public void testEvictAll() {
       evictOrRemoveAllTest(true);
    }
 
    private void evictOrRemoveTest(boolean evict) {
 
       final String KEY = KEY_BASE + testCount++;
 
       assertNull("local is clean", localAccessStrategy.get(KEY, System.currentTimeMillis()));
       assertNull("remote is clean", remoteAccessStrategy.get(KEY, System.currentTimeMillis()));
 
       localAccessStrategy.putFromLoad(KEY, VALUE1, System.currentTimeMillis(), new Integer(1));
       assertEquals(VALUE1, localAccessStrategy.get(KEY, System.currentTimeMillis()));
       remoteAccessStrategy.putFromLoad(KEY, VALUE1, System.currentTimeMillis(), new Integer(1));
       assertEquals(VALUE1, remoteAccessStrategy.get(KEY, System.currentTimeMillis()));
 
       // Wait for async propagation
       sleep(250);
 
       if (evict)
          localAccessStrategy.evict(KEY);
       else
          localAccessStrategy.remove(KEY);
 
       assertEquals(null, localAccessStrategy.get(KEY, System.currentTimeMillis()));
 
       assertEquals(null, remoteAccessStrategy.get(KEY, System.currentTimeMillis()));
    }
 
    private void evictOrRemoveAllTest(boolean evict) {
 
       final String KEY = KEY_BASE + testCount++;
 
       assertEquals(0, getValidKeyCount(localCache.keySet()));
 
       assertEquals(0, getValidKeyCount(remoteCache.keySet()));
 
       assertNull("local is clean", localAccessStrategy.get(KEY, System.currentTimeMillis()));
       assertNull("remote is clean", remoteAccessStrategy.get(KEY, System.currentTimeMillis()));
 
       localAccessStrategy.putFromLoad(KEY, VALUE1, System.currentTimeMillis(), new Integer(1));
       assertEquals(VALUE1, localAccessStrategy.get(KEY, System.currentTimeMillis()));
       remoteAccessStrategy.putFromLoad(KEY, VALUE1, System.currentTimeMillis(), new Integer(1));
       assertEquals(VALUE1, remoteAccessStrategy.get(KEY, System.currentTimeMillis()));
 
       // Wait for async propagation
       sleep(250);
 
       if (evict)
          localAccessStrategy.evictAll();
       else
          localAccessStrategy.removeAll();
 
       // This should re-establish the region root node
       assertNull(localAccessStrategy.get(KEY, System.currentTimeMillis()));
 
       assertEquals(0, getValidKeyCount(localCache.keySet()));
 
       // Re-establishing the region root on the local node doesn't
       // propagate it to other nodes. Do a get on the remote node to re-establish
       assertEquals(null, remoteAccessStrategy.get(KEY, System.currentTimeMillis()));
 
       assertEquals(0, getValidKeyCount(remoteCache.keySet()));
 
       // Test whether the get above messes up the optimistic version
       remoteAccessStrategy.putFromLoad(KEY, VALUE1, System.currentTimeMillis(), new Integer(1));
       assertEquals(VALUE1, remoteAccessStrategy.get(KEY, System.currentTimeMillis()));
 
       assertEquals(1, getValidKeyCount(remoteCache.keySet()));
 
       // Wait for async propagation of the putFromLoad
       sleep(250);
 
       assertEquals("local is correct", (isUsingInvalidation() ? null : VALUE1), localAccessStrategy.get(KEY, System
                .currentTimeMillis()));
       assertEquals("remote is correct", VALUE1, remoteAccessStrategy.get(KEY, System.currentTimeMillis()));
    }
 
    private void rollback() {
       try {
          BatchModeTransactionManager.getInstance().rollback();
       } catch (Exception e) {
          log.error(e.getMessage(), e);
       }
 
    }
 
    private static class AccessStrategyTestSetup extends TestSetup {
 
       private static final String PREFER_IPV4STACK = "java.net.preferIPv4Stack";
 
       private final String configResource;
       private final String configName;
       private String preferIPv4Stack;
+      private ServiceRegistryHolder serviceRegistryHolder;
 
       public AccessStrategyTestSetup(Test test, String configName) {
          this(test, configName, null);
       }
 
       public AccessStrategyTestSetup(Test test, String configName, String configResource) {
          super(test);
          this.configName = configName;
          this.configResource = configResource;
       }
 
       @Override
       protected void setUp() throws Exception {
          super.setUp();
 
          // Try to ensure we use IPv4; otherwise cluster formation is very slow
          preferIPv4Stack = System.getProperty(PREFER_IPV4STACK);
          System.setProperty(PREFER_IPV4STACK, "true");
 
+         serviceRegistryHolder = new ServiceRegistryHolder( Environment.getProperties() );
+
          localCfg = createConfiguration(configName, configResource);
-         localRegionFactory = CacheTestUtil.startRegionFactory(localCfg);
+         localRegionFactory = CacheTestUtil.startRegionFactory(
+				 serviceRegistryHolder.getJdbcServicesImpl().getConnectionProvider(),
+				 localCfg
+		 );
 
          remoteCfg = createConfiguration(configName, configResource);
-         remoteRegionFactory = CacheTestUtil.startRegionFactory(remoteCfg);
+         remoteRegionFactory = CacheTestUtil.startRegionFactory(
+				 serviceRegistryHolder.getJdbcServicesImpl().getConnectionProvider(),
+				 remoteCfg
+		 );
       }
 
       @Override
       protected void tearDown() throws Exception {
          try {
             super.tearDown();
          } finally {
             if (preferIPv4Stack == null)
                System.clearProperty(PREFER_IPV4STACK);
             else
                System.setProperty(PREFER_IPV4STACK, preferIPv4Stack);
          }
 
-         if (localRegionFactory != null)
-            localRegionFactory.stop();
+		  try {
+            if (localRegionFactory != null)
+               localRegionFactory.stop();
 
-         if (remoteRegionFactory != null)
-            remoteRegionFactory.stop();
+            if (remoteRegionFactory != null)
+               remoteRegionFactory.stop();
+		  }
+		  finally {
+            if ( serviceRegistryHolder != null ) {
+               serviceRegistryHolder.destroy(); 
+            }
+		  }
       }
 
    }
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/TransactionalExtraAPITestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/TransactionalExtraAPITestCase.java
index e77ccd204b..755de34c89 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/TransactionalExtraAPITestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/TransactionalExtraAPITestCase.java
@@ -1,125 +1,127 @@
 /*
  * JBoss, Home of Professional Open Source.
  * Copyright 2009, Red Hat, Inc. and/or it's affiliates, and individual contributors
  * as indicated by the @author tags. See the copyright.txt file in the
  * distribution for a full listing of individual contributors.
  *
  * This is free software; you can redistribute it and/or modify it
  * under the terms of the GNU Lesser General Public License as
  * published by the Free Software Foundation; either version 2.1 of
  * the License, or (at your option) any later version.
  *
  * This software is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * Lesser General Public License for more details.
  *
  * You should have received a copy of the GNU Lesser General Public
  * License along with this software; if not, write to the Free
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
 package org.hibernate.test.cache.infinispan.collection;
 
 import org.hibernate.cache.CollectionRegion;
 import org.hibernate.cache.access.AccessType;
 import org.hibernate.cache.access.CollectionRegionAccessStrategy;
 import org.hibernate.cache.access.SoftLock;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.test.cache.infinispan.AbstractNonFunctionalTestCase;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 
 /**
  * TransactionalExtraAPITestCase.
  * 
  * @author Galder Zamarreo
  * @since 3.5
  */
 public class TransactionalExtraAPITestCase extends AbstractNonFunctionalTestCase {
 
    public static final String REGION_NAME = "test/com.foo.test";
    public static final String KEY = "KEY";
    public static final String VALUE1 = "VALUE1";
    public static final String VALUE2 = "VALUE2";
    
    private static CollectionRegionAccessStrategy localAccessStrategy;
    
    public TransactionalExtraAPITestCase(String name) {
       super(name);
    }
 
    protected void setUp() throws Exception {
        super.setUp();
        
        if (getCollectionAccessStrategy() == null) {
            Configuration cfg = createConfiguration();
-           InfinispanRegionFactory rf  = CacheTestUtil.startRegionFactory(cfg, getCacheTestSupport());
+           InfinispanRegionFactory rf  = CacheTestUtil.startRegionFactory(
+				   getConnectionProvider(), cfg, getCacheTestSupport()
+		   );
            
            // Sleep a bit to avoid concurrent FLUSH problem
            avoidConcurrentFlush();
            
            CollectionRegion localCollectionRegion = rf.buildCollectionRegion(REGION_NAME, cfg.getProperties(), null);
            setCollectionAccessStrategy(localCollectionRegion.buildAccessStrategy(getAccessType()));
        }
    }
 
    protected void tearDown() throws Exception {
        
        super.tearDown();
    }
    
    protected Configuration createConfiguration() {
        Configuration cfg = CacheTestUtil.buildConfiguration(REGION_PREFIX, InfinispanRegionFactory.class, true, false);
        cfg.setProperty(InfinispanRegionFactory.ENTITY_CACHE_RESOURCE_PROP, getCacheConfigName());
        return cfg;
    }
    
    protected String getCacheConfigName() {
        return "entity";
    }
    
    protected AccessType getAccessType() {
        return AccessType.TRANSACTIONAL;
    }
    
    protected CollectionRegionAccessStrategy getCollectionAccessStrategy() {
        return localAccessStrategy;
    }
    
    protected void setCollectionAccessStrategy(CollectionRegionAccessStrategy strategy) {
        localAccessStrategy = strategy;
    }
 
    /**
     * Test method for {@link TransactionalAccess#lockItem(java.lang.Object, java.lang.Object)}.
     */
    public void testLockItem() {
        assertNull(getCollectionAccessStrategy().lockItem(KEY, new Integer(1)));
    }
 
    /**
     * Test method for {@link TransactionalAccess#lockRegion()}.
     */
    public void testLockRegion() {
        assertNull(getCollectionAccessStrategy().lockRegion());
    }
 
    /**
     * Test method for {@link TransactionalAccess#unlockItem(java.lang.Object, org.hibernate.cache.access.SoftLock)}.
     */
    public void testUnlockItem() {
        getCollectionAccessStrategy().unlockItem(KEY, new MockSoftLock());
    }
 
    /**
     * Test method for {@link TransactionalAccess#unlockRegion(org.hibernate.cache.access.SoftLock)}.
     */
    public void testUnlockRegion() {
        getCollectionAccessStrategy().unlockItem(KEY, new MockSoftLock());
    }
    
    public static class MockSoftLock implements SoftLock {
        
    }
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractEntityRegionAccessStrategyTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractEntityRegionAccessStrategyTestCase.java
index b65ae2d767..be99245d70 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractEntityRegionAccessStrategyTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractEntityRegionAccessStrategyTestCase.java
@@ -1,681 +1,699 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.entity;
 
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 
 import junit.extensions.TestSetup;
 import junit.framework.AssertionFailedError;
 import junit.framework.Test;
 import junit.framework.TestSuite;
 
 import org.hibernate.cache.CacheDataDescription;
 import org.hibernate.cache.EntityRegion;
 import org.hibernate.cache.access.AccessType;
 import org.hibernate.cache.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.impl.CacheDataDescriptionImpl;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.impl.BaseRegion;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.cache.infinispan.util.FlagAdapter;
 import org.hibernate.cfg.Configuration;
+import org.hibernate.cfg.Environment;
 import org.hibernate.test.cache.infinispan.AbstractNonFunctionalTestCase;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
+import org.hibernate.test.common.ServiceRegistryHolder;
 import org.hibernate.util.ComparableComparator;
 import org.infinispan.transaction.tm.BatchModeTransactionManager;
 
 /**
  * Base class for tests of EntityRegionAccessStrategy impls.
  * 
  * @author Galder Zamarreo
  * @since 3.5
  */
 public abstract class AbstractEntityRegionAccessStrategyTestCase extends AbstractNonFunctionalTestCase {
 
    public static final String REGION_NAME = "test/com.foo.test";
    public static final String KEY_BASE = "KEY";
    public static final String VALUE1 = "VALUE1";
    public static final String VALUE2 = "VALUE2";
 
    protected static int testCount;
 
    protected static Configuration localCfg;
    protected static InfinispanRegionFactory localRegionFactory;
    protected CacheAdapter localCache;
    protected static Configuration remoteCfg;
    protected static InfinispanRegionFactory remoteRegionFactory;
    protected CacheAdapter remoteCache;
 
    protected boolean invalidation;
    protected boolean synchronous;
 
    protected EntityRegion localEntityRegion;
    protected EntityRegionAccessStrategy localAccessStrategy;
 
    protected EntityRegion remoteEntityRegion;
    protected EntityRegionAccessStrategy remoteAccessStrategy;
 
    protected Exception node1Exception;
    protected Exception node2Exception;
 
    protected AssertionFailedError node1Failure;
    protected AssertionFailedError node2Failure;
 
    public static Test getTestSetup(Class testClass, String configName) {
       TestSuite suite = new TestSuite(testClass);
       return new AccessStrategyTestSetup(suite, configName);
    }
 
    public static Test getTestSetup(Test test, String configName) {
       return new AccessStrategyTestSetup(test, configName);
    }
 
    /**
     * Create a new TransactionalAccessTestCase.
     * 
     * @param name
     */
    public AbstractEntityRegionAccessStrategyTestCase(String name) {
       super(name);
    }
 
    protected abstract AccessType getAccessType();
 
    protected void setUp() throws Exception {
       super.setUp();
 
       // Sleep a bit to avoid concurrent FLUSH problem
       avoidConcurrentFlush();
 
       localEntityRegion = localRegionFactory.buildEntityRegion(REGION_NAME, localCfg
                .getProperties(), getCacheDataDescription());
       localAccessStrategy = localEntityRegion.buildAccessStrategy(getAccessType());
 
       localCache = ((BaseRegion) localEntityRegion).getCacheAdapter();
 
       invalidation = localCache.isClusteredInvalidation();
       synchronous = localCache.isSynchronous();
 
       // Sleep a bit to avoid concurrent FLUSH problem
       avoidConcurrentFlush();
 
       remoteEntityRegion = remoteRegionFactory.buildEntityRegion(REGION_NAME, remoteCfg
                .getProperties(), getCacheDataDescription());
       remoteAccessStrategy = remoteEntityRegion.buildAccessStrategy(getAccessType());
 
       remoteCache = ((BaseRegion) remoteEntityRegion).getCacheAdapter();
 
       node1Exception = null;
       node2Exception = null;
 
       node1Failure = null;
       node2Failure = null;
    }
 
    protected void tearDown() throws Exception {
 
       super.tearDown();
 
       try {
          localCache.withFlags(FlagAdapter.CACHE_MODE_LOCAL).clear();
       } catch (Exception e) {
          log.error("Problem purging local cache", e);
       }
 
       try {
          remoteCache.withFlags(FlagAdapter.CACHE_MODE_LOCAL).clear();
       } catch (Exception e) {
          log.error("Problem purging remote cache", e);
       }
 
       node1Exception = null;
       node2Exception = null;
 
       node1Failure = null;
       node2Failure = null;
    }
 
    protected static Configuration createConfiguration(String configName) {
       Configuration cfg = CacheTestUtil.buildConfiguration(REGION_PREFIX, InfinispanRegionFactory.class, true, false);
       cfg.setProperty(InfinispanRegionFactory.ENTITY_CACHE_RESOURCE_PROP, configName);
       return cfg;
    }
 
    protected CacheDataDescription getCacheDataDescription() {
       return new CacheDataDescriptionImpl(true, true, ComparableComparator.INSTANCE);
    }
 
    protected boolean isUsingInvalidation() {
       return invalidation;
    }
 
    protected boolean isSynchronous() {
       return synchronous;
    }
 
    protected void assertThreadsRanCleanly() {
       if (node1Failure != null)
          throw node1Failure;
       if (node2Failure != null)
          throw node2Failure;
 
       if (node1Exception != null) {
          log.error("node1 saw an exception", node1Exception);
          assertEquals("node1 saw no exceptions", null, node1Exception);
       }
 
       if (node2Exception != null) {
          log.error("node2 saw an exception", node2Exception);
          assertEquals("node2 saw no exceptions", null, node2Exception);
       }
    }
 
    /**
     * This is just a setup test where we assert that the cache config is as we expected.
     */
    public abstract void testCacheConfiguration();
 
    /**
     * Test method for {@link TransactionalAccess#getRegion()}.
     */
    public void testGetRegion() {
       assertEquals("Correct region", localEntityRegion, localAccessStrategy.getRegion());
    }
 
    /**
     * Test method for
     * {@link TransactionalAccess#putFromLoad(java.lang.Object, java.lang.Object, long, java.lang.Object)}
     * .
     */
    public void testPutFromLoad() throws Exception {
       putFromLoadTest(false);
    }
 
    /**
     * Test method for
     * {@link TransactionalAccess#putFromLoad(java.lang.Object, java.lang.Object, long, java.lang.Object, boolean)}
     * .
     */
    public void testPutFromLoadMinimal() throws Exception {
       putFromLoadTest(true);
    }
 
    /**
     * Simulate 2 nodes, both start, tx do a get, experience a cache miss, then 'read from db.' First
     * does a putFromLoad, then an update. Second tries to do a putFromLoad with stale data (i.e. it
     * took longer to read from the db). Both commit their tx. Then both start a new tx and get.
     * First should see the updated data; second should either see the updated data (isInvalidation()
     * == false) or null (isInvalidation() == true).
     * 
     * @param useMinimalAPI
     * @throws Exception
     */
    private void putFromLoadTest(final boolean useMinimalAPI) throws Exception {
 
       final String KEY = KEY_BASE + testCount++;
 
       final CountDownLatch writeLatch1 = new CountDownLatch(1);
       final CountDownLatch writeLatch2 = new CountDownLatch(1);
       final CountDownLatch completionLatch = new CountDownLatch(2);
 
       Thread node1 = new Thread() {
 
          public void run() {
 
             try {
                long txTimestamp = System.currentTimeMillis();
                BatchModeTransactionManager.getInstance().begin();
 
                assertNull("node1 starts clean", localAccessStrategy.get(KEY, txTimestamp));
 
                writeLatch1.await();
 
                if (useMinimalAPI) {
                   localAccessStrategy.putFromLoad(KEY, VALUE1, txTimestamp, new Integer(1), true);
                } else {
                   localAccessStrategy.putFromLoad(KEY, VALUE1, txTimestamp, new Integer(1));
                }
 
                localAccessStrategy.update(KEY, VALUE2, new Integer(2), new Integer(1));
 
                BatchModeTransactionManager.getInstance().commit();
             } catch (Exception e) {
                log.error("node1 caught exception", e);
                node1Exception = e;
                rollback();
             } catch (AssertionFailedError e) {
                node1Failure = e;
                rollback();
             } finally {
                // Let node2 write
                writeLatch2.countDown();
                completionLatch.countDown();
             }
          }
       };
 
       Thread node2 = new Thread() {
 
          public void run() {
 
             try {
                long txTimestamp = System.currentTimeMillis();
                BatchModeTransactionManager.getInstance().begin();
 
                assertNull("node1 starts clean", remoteAccessStrategy.get(KEY, txTimestamp));
 
                // Let node1 write
                writeLatch1.countDown();
                // Wait for node1 to finish
                writeLatch2.await();
 
                if (useMinimalAPI) {
                   remoteAccessStrategy.putFromLoad(KEY, VALUE1, txTimestamp, new Integer(1), true);
                } else {
                   remoteAccessStrategy.putFromLoad(KEY, VALUE1, txTimestamp, new Integer(1));
                }
 
                BatchModeTransactionManager.getInstance().commit();
             } catch (Exception e) {
                log.error("node2 caught exception", e);
                node2Exception = e;
                rollback();
             } catch (AssertionFailedError e) {
                node2Failure = e;
                rollback();
             } finally {
                completionLatch.countDown();
             }
          }
       };
 
       node1.setDaemon(true);
       node2.setDaemon(true);
 
       node1.start();
       node2.start();
 
       assertTrue("Threads completed", completionLatch.await(2, TimeUnit.SECONDS));
 
       assertThreadsRanCleanly();
 
       long txTimestamp = System.currentTimeMillis();
       assertEquals("Correct node1 value", VALUE2, localAccessStrategy.get(KEY, txTimestamp));
 
       if (isUsingInvalidation()) {
          // no data version to prevent the PFER; we count on db locks preventing this
          assertEquals("Expected node2 value", VALUE1, remoteAccessStrategy.get(KEY, txTimestamp));
       } else {
          // The node1 update is replicated, preventing the node2 PFER
          assertEquals("Correct node2 value", VALUE2, remoteAccessStrategy.get(KEY, txTimestamp));
       }
    }
 
    /**
     * Test method for
     * {@link TransactionalAccess#insert(java.lang.Object, java.lang.Object, java.lang.Object)}.
     */
    public void testInsert() throws Exception {
 
       final String KEY = KEY_BASE + testCount++;
 
       final CountDownLatch readLatch = new CountDownLatch(1);
       final CountDownLatch commitLatch = new CountDownLatch(1);
       final CountDownLatch completionLatch = new CountDownLatch(2);
 
       Thread inserter = new Thread() {
 
          public void run() {
 
             try {
                long txTimestamp = System.currentTimeMillis();
                BatchModeTransactionManager.getInstance().begin();
 
                assertNull("Correct initial value", localAccessStrategy.get(KEY, txTimestamp));
 
                localAccessStrategy.insert(KEY, VALUE1, new Integer(1));
 
                readLatch.countDown();
                commitLatch.await();
 
                BatchModeTransactionManager.getInstance().commit();
             } catch (Exception e) {
                log.error("node1 caught exception", e);
                node1Exception = e;
                rollback();
             } catch (AssertionFailedError e) {
                node1Failure = e;
                rollback();
             } finally {
                completionLatch.countDown();
             }
          }
       };
 
       Thread reader = new Thread() {
 
          public void run() {
 
             try {
                long txTimestamp = System.currentTimeMillis();
                BatchModeTransactionManager.getInstance().begin();
 
                readLatch.await();
 //               Object expected = !isBlockingReads() ? null : VALUE1;
                Object expected = null;
 
                assertEquals("Correct initial value", expected, localAccessStrategy.get(KEY,
                         txTimestamp));
 
                BatchModeTransactionManager.getInstance().commit();
             } catch (Exception e) {
                log.error("node1 caught exception", e);
                node1Exception = e;
                rollback();
             } catch (AssertionFailedError e) {
                node1Failure = e;
                rollback();
             } finally {
                commitLatch.countDown();
                completionLatch.countDown();
             }
          }
       };
 
       inserter.setDaemon(true);
       reader.setDaemon(true);
       inserter.start();
       reader.start();
 
       assertTrue("Threads completed", completionLatch.await(1, TimeUnit.SECONDS));
 
       assertThreadsRanCleanly();
 
       long txTimestamp = System.currentTimeMillis();
       assertEquals("Correct node1 value", VALUE1, localAccessStrategy.get(KEY, txTimestamp));
       Object expected = isUsingInvalidation() ? null : VALUE1;
       assertEquals("Correct node2 value", expected, remoteAccessStrategy.get(KEY, txTimestamp));
    }
 
    /**
     * Test method for
     * {@link TransactionalAccess#update(java.lang.Object, java.lang.Object, java.lang.Object, java.lang.Object)}
     * .
     */
    public void testUpdate() throws Exception {
 
       final String KEY = KEY_BASE + testCount++;
 
       // Set up initial state
       localAccessStrategy.putFromLoad(KEY, VALUE1, System.currentTimeMillis(), new Integer(1));
       remoteAccessStrategy.putFromLoad(KEY, VALUE1, System.currentTimeMillis(), new Integer(1));
 
       // Let the async put propagate
       sleep(250);
 
       final CountDownLatch readLatch = new CountDownLatch(1);
       final CountDownLatch commitLatch = new CountDownLatch(1);
       final CountDownLatch completionLatch = new CountDownLatch(2);
 
       Thread updater = new Thread("testUpdate-updater") {
 
          public void run() {
             boolean readerUnlocked = false;
             try {
                long txTimestamp = System.currentTimeMillis();
                BatchModeTransactionManager.getInstance().begin();
                log.debug("Transaction began, get initial value");
                assertEquals("Correct initial value", VALUE1, localAccessStrategy.get(KEY, txTimestamp));
                log.debug("Now update value");
                localAccessStrategy.update(KEY, VALUE2, new Integer(2), new Integer(1));
                log.debug("Notify the read latch");
                readLatch.countDown();
                readerUnlocked = true;
                log.debug("Await commit");
                commitLatch.await();
                BatchModeTransactionManager.getInstance().commit();
             } catch (Exception e) {
                log.error("node1 caught exception", e);
                node1Exception = e;
                rollback();
             } catch (AssertionFailedError e) {
                node1Failure = e;
                rollback();
             } finally {
                if (!readerUnlocked) readLatch.countDown();
                log.debug("Completion latch countdown");
                completionLatch.countDown();
             }
          }
       };
 
       Thread reader = new Thread("testUpdate-reader") {
 
          public void run() {
             try {
                long txTimestamp = System.currentTimeMillis();
                BatchModeTransactionManager.getInstance().begin();
                log.debug("Transaction began, await read latch");
                readLatch.await();
                log.debug("Read latch acquired, verify local access strategy");
 
                // This won't block w/ mvc and will read the old value
                Object expected = VALUE1;
                assertEquals("Correct value", expected, localAccessStrategy.get(KEY, txTimestamp));
 
                BatchModeTransactionManager.getInstance().commit();
             } catch (Exception e) {
                log.error("node1 caught exception", e);
                node1Exception = e;
                rollback();
             } catch (AssertionFailedError e) {
                node1Failure = e;
                rollback();
             } finally {
                commitLatch.countDown();
                log.debug("Completion latch countdown");
                completionLatch.countDown();
             }
          }
       };
 
       updater.setDaemon(true);
       reader.setDaemon(true);
       updater.start();
       reader.start();
 
       // Should complete promptly
       assertTrue(completionLatch.await(2, TimeUnit.SECONDS));
 
       assertThreadsRanCleanly();
 
       long txTimestamp = System.currentTimeMillis();
       assertEquals("Correct node1 value", VALUE2, localAccessStrategy.get(KEY, txTimestamp));
       Object expected = isUsingInvalidation() ? null : VALUE2;
       assertEquals("Correct node2 value", expected, remoteAccessStrategy.get(KEY, txTimestamp));
    }
 
    /**
     * Test method for {@link TransactionalAccess#remove(java.lang.Object)}.
     */
    public void testRemove() {
       evictOrRemoveTest(false);
    }
 
    /**
     * Test method for {@link TransactionalAccess#removeAll()}.
     */
    public void testRemoveAll() {
       evictOrRemoveAllTest(false);
    }
 
    /**
     * Test method for {@link TransactionalAccess#evict(java.lang.Object)}.
     * 
     * FIXME add testing of the "immediately without regard for transaction isolation" bit in the
     * EntityRegionAccessStrategy API.
     */
    public void testEvict() {
       evictOrRemoveTest(true);
    }
 
    /**
     * Test method for {@link TransactionalAccess#evictAll()}.
     * 
     * FIXME add testing of the "immediately without regard for transaction isolation" bit in the
     * EntityRegionAccessStrategy API.
     */
    public void testEvictAll() {
       evictOrRemoveAllTest(true);
    }
 
    private void evictOrRemoveTest(boolean evict) {
       final String KEY = KEY_BASE + testCount++;
       assertEquals(0, getValidKeyCount(localCache.keySet()));
       assertEquals(0, getValidKeyCount(remoteCache.keySet()));
 
       assertNull("local is clean", localAccessStrategy.get(KEY, System.currentTimeMillis()));
       assertNull("remote is clean", remoteAccessStrategy.get(KEY, System.currentTimeMillis()));
 
       localAccessStrategy.putFromLoad(KEY, VALUE1, System.currentTimeMillis(), new Integer(1));
       assertEquals(VALUE1, localAccessStrategy.get(KEY, System.currentTimeMillis()));
       remoteAccessStrategy.putFromLoad(KEY, VALUE1, System.currentTimeMillis(), new Integer(1));
       assertEquals(VALUE1, remoteAccessStrategy.get(KEY, System.currentTimeMillis()));
 
       if (evict)
          localAccessStrategy.evict(KEY);
       else
          localAccessStrategy.remove(KEY);
 
       assertEquals(null, localAccessStrategy.get(KEY, System.currentTimeMillis()));
       assertEquals(0, getValidKeyCount(localCache.keySet()));
       assertEquals(null, remoteAccessStrategy.get(KEY, System.currentTimeMillis()));
       assertEquals(0, getValidKeyCount(remoteCache.keySet()));
    }
 
    private void evictOrRemoveAllTest(boolean evict) {
       final String KEY = KEY_BASE + testCount++;
       assertEquals(0, getValidKeyCount(localCache.keySet()));
       assertEquals(0, getValidKeyCount(remoteCache.keySet()));
       assertNull("local is clean", localAccessStrategy.get(KEY, System.currentTimeMillis()));
       assertNull("remote is clean", remoteAccessStrategy.get(KEY, System.currentTimeMillis()));
 
       localAccessStrategy.putFromLoad(KEY, VALUE1, System.currentTimeMillis(), new Integer(1));
       assertEquals(VALUE1, localAccessStrategy.get(KEY, System.currentTimeMillis()));
 
       // Wait for async propagation
       sleep(250);
 
       remoteAccessStrategy.putFromLoad(KEY, VALUE1, System.currentTimeMillis(), new Integer(1));
       assertEquals(VALUE1, remoteAccessStrategy.get(KEY, System.currentTimeMillis()));
 
       // Wait for async propagation
       sleep(250);
 
       if (evict) {
          log.debug("Call evict all locally");
          localAccessStrategy.evictAll();
       } else {
          localAccessStrategy.removeAll();
       }
 
       // This should re-establish the region root node in the optimistic case
       assertNull(localAccessStrategy.get(KEY, System.currentTimeMillis()));
       assertEquals(0, getValidKeyCount(localCache.keySet()));
 
       // Re-establishing the region root on the local node doesn't
       // propagate it to other nodes. Do a get on the remote node to re-establish
       assertEquals(null, remoteAccessStrategy.get(KEY, System.currentTimeMillis()));
       assertEquals(0, getValidKeyCount(remoteCache.keySet()));
 
       // Test whether the get above messes up the optimistic version
       remoteAccessStrategy.putFromLoad(KEY, VALUE1, System.currentTimeMillis(), new Integer(1));
       assertEquals(VALUE1, remoteAccessStrategy.get(KEY, System.currentTimeMillis()));
       assertEquals(1, getValidKeyCount(remoteCache.keySet()));
 
       // Wait for async propagation
       sleep(250);
 
       assertEquals("local is correct", (isUsingInvalidation() ? null : VALUE1), localAccessStrategy
                .get(KEY, System.currentTimeMillis()));
       assertEquals("remote is correct", VALUE1, remoteAccessStrategy.get(KEY, System
                .currentTimeMillis()));
    }
 
    protected void rollback() {
       try {
          BatchModeTransactionManager.getInstance().rollback();
       } catch (Exception e) {
          log.error(e.getMessage(), e);
       }
    }
 
    private static class AccessStrategyTestSetup extends TestSetup {
 
       private static final String PREFER_IPV4STACK = "java.net.preferIPv4Stack";
       private final String configName;
       private String preferIPv4Stack;
+      private ServiceRegistryHolder serviceRegistryHolder;
 
       public AccessStrategyTestSetup(Test test, String configName) {
          super(test);
          this.configName = configName;
       }
 
       @Override
       protected void setUp() throws Exception {
          try {
             super.tearDown();
          } finally {
             if (preferIPv4Stack == null)
                System.clearProperty(PREFER_IPV4STACK);
             else
                System.setProperty(PREFER_IPV4STACK, preferIPv4Stack);
          }
 
          // Try to ensure we use IPv4; otherwise cluster formation is very slow
          preferIPv4Stack = System.getProperty(PREFER_IPV4STACK);
          System.setProperty(PREFER_IPV4STACK, "true");
 
+		 serviceRegistryHolder = new ServiceRegistryHolder( Environment.getProperties() );
+
          localCfg = createConfiguration(configName);
-         localRegionFactory = CacheTestUtil.startRegionFactory(localCfg);
+         localRegionFactory = CacheTestUtil.startRegionFactory(
+				 serviceRegistryHolder.getJdbcServicesImpl().getConnectionProvider(),
+				 localCfg
+		 );
 
          remoteCfg = createConfiguration(configName);
-         remoteRegionFactory = CacheTestUtil.startRegionFactory(remoteCfg);
+         remoteRegionFactory = CacheTestUtil.startRegionFactory(
+				 serviceRegistryHolder.getJdbcServicesImpl().getConnectionProvider(),
+				 remoteCfg
+		 );
       }
 
       @Override
       protected void tearDown() throws Exception {
          super.tearDown();
 
-         if (localRegionFactory != null)
-            localRegionFactory.stop();
+		  try {
+            if (localRegionFactory != null)
+               localRegionFactory.stop();
 
-         if (remoteRegionFactory != null)
-            remoteRegionFactory.stop();
+            if (remoteRegionFactory != null)
+               remoteRegionFactory.stop();
+		  }
+		  finally {
+            if ( serviceRegistryHolder != null ) {
+               serviceRegistryHolder.destroy();
+            }
+		  }
       }
 
    }
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/TransactionalExtraAPITestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/TransactionalExtraAPITestCase.java
index 4996bca881..3079be28e5 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/TransactionalExtraAPITestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/TransactionalExtraAPITestCase.java
@@ -1,147 +1,149 @@
 /*
  * JBoss, Home of Professional Open Source.
  * Copyright 2009, Red Hat, Inc. and/or it's affiliates, and individual contributors
  * as indicated by the @author tags. See the copyright.txt file in the
  * distribution for a full listing of individual contributors.
  *
  * This is free software; you can redistribute it and/or modify it
  * under the terms of the GNU Lesser General Public License as
  * published by the Free Software Foundation; either version 2.1 of
  * the License, or (at your option) any later version.
  *
  * This software is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * Lesser General Public License for more details.
  *
  * You should have received a copy of the GNU Lesser General Public
  * License along with this software; if not, write to the Free
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
 package org.hibernate.test.cache.infinispan.entity;
 
 import org.hibernate.cache.EntityRegion;
 import org.hibernate.cache.access.AccessType;
 import org.hibernate.cache.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.access.SoftLock;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.test.cache.infinispan.AbstractNonFunctionalTestCase;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 
 /**
  * Tests for the "extra API" in EntityRegionAccessStrategy;.
  * <p>
  * By "extra API" we mean those methods that are superfluous to the 
  * function of the JBC integration, where the impl is a no-op or a static
  * false return value, UnsupportedOperationException, etc.
  * 
  * @author Galder Zamarreo
  * @since 3.5
  */
 public class TransactionalExtraAPITestCase extends AbstractNonFunctionalTestCase {
 
    public TransactionalExtraAPITestCase(String name) {
       super(name);
    }
    
    public static final String REGION_NAME = "test/com.foo.test";
    public static final String KEY = "KEY";
    public static final String VALUE1 = "VALUE1";
    public static final String VALUE2 = "VALUE2";
    
    private static EntityRegionAccessStrategy localAccessStrategy;
    
    private static boolean optimistic;
    
    protected void setUp() throws Exception {
        super.setUp();
        
        if (getEntityAccessStrategy() == null) {
            Configuration cfg = createConfiguration();
-           InfinispanRegionFactory rf  = CacheTestUtil.startRegionFactory(cfg, getCacheTestSupport());
+           InfinispanRegionFactory rf  = CacheTestUtil.startRegionFactory(
+				   getConnectionProvider(), cfg, getCacheTestSupport()
+		   );
            
            // Sleep a bit to avoid concurrent FLUSH problem
            avoidConcurrentFlush();
            
            EntityRegion localEntityRegion = rf.buildEntityRegion(REGION_NAME, cfg.getProperties(), null);
            setEntityRegionAccessStrategy(localEntityRegion.buildAccessStrategy(getAccessType()));
        }
    }
 
    protected void tearDown() throws Exception {
        
        super.tearDown();
    }
    
    protected Configuration createConfiguration() {
        Configuration cfg = CacheTestUtil.buildConfiguration(REGION_PREFIX, InfinispanRegionFactory.class, true, false);
        cfg.setProperty(InfinispanRegionFactory.ENTITY_CACHE_RESOURCE_PROP, getCacheConfigName());
        return cfg;
    }
    
    protected String getCacheConfigName() {
        return "entity";
    }
    
    protected AccessType getAccessType() {
        return AccessType.TRANSACTIONAL;
    }
    
    protected EntityRegionAccessStrategy getEntityAccessStrategy() {
        return localAccessStrategy;
    }
    
    protected void setEntityRegionAccessStrategy(EntityRegionAccessStrategy strategy) {
        localAccessStrategy = strategy;
    }
 
    /**
     * Test method for {@link TransactionalAccess#lockItem(java.lang.Object, java.lang.Object)}.
     */
    public void testLockItem() {
        assertNull(getEntityAccessStrategy().lockItem(KEY, new Integer(1)));
    }
 
    /**
     * Test method for {@link TransactionalAccess#lockRegion()}.
     */
    public void testLockRegion() {
        assertNull(getEntityAccessStrategy().lockRegion());
    }
 
    /**
     * Test method for {@link TransactionalAccess#unlockItem(java.lang.Object, org.hibernate.cache.access.SoftLock)}.
     */
    public void testUnlockItem() {
        getEntityAccessStrategy().unlockItem(KEY, new MockSoftLock());
    }
 
    /**
     * Test method for {@link TransactionalAccess#unlockRegion(org.hibernate.cache.access.SoftLock)}.
     */
    public void testUnlockRegion() {
        getEntityAccessStrategy().unlockItem(KEY, new MockSoftLock());
    }
 
    /**
     * Test method for {@link TransactionalAccess#afterInsert(java.lang.Object, java.lang.Object, java.lang.Object)}.
     */
    public void testAfterInsert() {
        assertFalse("afterInsert always returns false", getEntityAccessStrategy().afterInsert(KEY, VALUE1, new Integer(1)));
    }
 
    /**
     * Test method for {@link TransactionalAccess#afterUpdate(java.lang.Object, java.lang.Object, java.lang.Object, java.lang.Object, org.hibernate.cache.access.SoftLock)}.
     */
    public void testAfterUpdate() {
        assertFalse("afterInsert always returns false", getEntityAccessStrategy().afterUpdate(KEY, VALUE2, new Integer(1), new Integer(2), new MockSoftLock()));
    }
    
    public static class MockSoftLock implements SoftLock {
        
    }
 
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/ConcurrentWriteTest.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/ConcurrentWriteTest.java
index 2feceed6db..7b188b615d 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/ConcurrentWriteTest.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/ConcurrentWriteTest.java
@@ -1,514 +1,521 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.functional;
 
 import java.io.PrintWriter;
 import java.io.StringWriter;
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.HashSet;
 import java.util.List;
+import java.util.Map;
 import java.util.Random;
 import java.util.Set;
 import java.util.concurrent.Callable;
 import java.util.concurrent.CyclicBarrier;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
 import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 
 import javax.transaction.TransactionManager;
 
 import org.hibernate.FlushMode;
 import org.hibernate.Session;
 import org.hibernate.cache.RegionFactory;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cfg.Configuration;
-import org.hibernate.connection.ConnectionProvider;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.stat.SecondLevelCacheStatistics;
 import org.hibernate.test.cache.infinispan.functional.cluster.DualNodeTestCase;
 import org.hibernate.test.cache.infinispan.functional.cluster.DualNodeConnectionProviderImpl;
 import org.hibernate.test.cache.infinispan.functional.cluster.DualNodeJtaTransactionManagerImpl;
 import org.hibernate.test.cache.infinispan.functional.cluster.DualNodeTransactionManagerLookup;
 import org.hibernate.transaction.TransactionManagerLookup;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 /**
  * 
  * @author nikita_tovstoles@mba.berkeley.edu
  * @author Galder Zamarreo
  */
 public class ConcurrentWriteTest extends SingleNodeTestCase {
    private static final Log log = LogFactory.getLog(ConcurrentWriteTest.class);
    private static final boolean trace = log.isTraceEnabled();
    /**
     * when USER_COUNT==1, tests pass, when >4 tests fail
     */
    private static final int USER_COUNT = 5;
    private static final int ITERATION_COUNT = 150;
    private static final int THINK_TIME_MILLIS = 10;
    private static final long LAUNCH_INTERVAL_MILLIS = 10;
    private static final Random random = new Random();
 
    /**
     * kill switch used to stop all users when one fails
     */
    private static volatile boolean TERMINATE_ALL_USERS = false;
 
    /**
     * collection of IDs of all customers participating in this test
     */
    private Set<Integer> customerIDs = new HashSet<Integer>();
 
    private TransactionManager tm;
 
    public ConcurrentWriteTest(String x) {
       super(x);
    }
 
    @Override
    protected TransactionManager getTransactionManager() {
       return DualNodeJtaTransactionManagerImpl.getInstance(DualNodeTestCase.LOCAL);
    }
 
    @Override
    protected Class<? extends RegionFactory> getCacheRegionFactory() {
       return InfinispanRegionFactory.class;
    }
 
    @Override
    protected Class<? extends ConnectionProvider> getConnectionProviderClass() {
        return DualNodeConnectionProviderImpl.class;
    }
 
    @Override
    protected Class<? extends TransactionManagerLookup> getTransactionManagerLookupClass() {
        return DualNodeTransactionManagerLookup.class;
    }
 
    /**
     * test that DB can be queried
     * 
     * @throws java.lang.Exception
     */
    public void testPingDb() throws Exception {
       try {
          beginTx();
          getEnvironment().getSessionFactory().getCurrentSession().createQuery("from " + Customer.class.getName()).list();
       } catch (Exception e) {
          setRollbackOnlyTx(e);
 //         setRollbackOnly();
 //         fail("failed to query DB; exception=" + e);
       } finally {
          commitOrRollbackTx();
       }
    }
 
    @Override
    protected void prepareTest() throws Exception {
       super.prepareTest();
       TERMINATE_ALL_USERS = false;
    }
 
    @Override
    protected void cleanupTest() throws Exception {
       try {
          super.cleanupTest();
       } finally {
          cleanup();
          // DualNodeJtaTransactionManagerImpl.cleanupTransactions();
          // DualNodeJtaTransactionManagerImpl.cleanupTransactionManagers();
       }
    }
 
    @Override
    public void configure(Configuration cfg) {
       super.configure(cfg);
       cfg.setProperty(DualNodeTestCase.NODE_ID_PROP, DualNodeTestCase.LOCAL);
    }
 
    @Override
+   protected Map getConnectionProviderInjectionProperties() {
+      return Collections.singletonMap( DualNodeTestCase.NODE_ID_FIELD, DualNodeTestCase.LOCAL );
+   }
+
+   @Override
    protected boolean getUseQueryCache() {
       return true;
    }
 
    public void testSingleUser() throws Exception {
       // setup
       Customer customer = createCustomer(0);
       final Integer customerId = customer.getId();
       getCustomerIDs().add(customerId);
 
       assertNull("contact exists despite not being added", getFirstContact(customerId));
 
       // check that cache was hit
       SecondLevelCacheStatistics customerSlcs = getEnvironment().getSessionFactory()
                .getStatistics().getSecondLevelCacheStatistics(Customer.class.getName());
       assertEquals(customerSlcs.getPutCount(), 1);
       assertEquals(customerSlcs.getElementCountInMemory(), 1);
       assertEquals(customerSlcs.getEntries().size(), 1);
 
       SecondLevelCacheStatistics contactsCollectionSlcs = getEnvironment().getSessionFactory()
                .getStatistics().getSecondLevelCacheStatistics(Customer.class.getName() + ".contacts");
       assertEquals(1, contactsCollectionSlcs.getPutCount());
       assertEquals(1, contactsCollectionSlcs.getElementCountInMemory());
       assertEquals(1, contactsCollectionSlcs.getEntries().size());
 
       final Contact contact = addContact(customerId);
       assertNotNull("contact returned by addContact is null", contact);
       assertEquals("Customer.contacts cache was not invalidated after addContact", 0,
                contactsCollectionSlcs.getElementCountInMemory());
 
       assertNotNull("Contact missing after successful add call", getFirstContact(customerId));
 
       // read everyone's contacts
       readEveryonesFirstContact();
 
       removeContact(customerId);
       assertNull("contact still exists after successful remove call", getFirstContact(customerId));
 
    }
 
    /**
     * TODO: This will fail until ISPN-??? has been fixed.
     *
     * @throws Exception
     */
    public void testManyUsers() throws Throwable {
       try {
          // setup - create users
          for (int i = 0; i < USER_COUNT; i++) {
             Customer customer = createCustomer(0);
             getCustomerIDs().add(customer.getId());
          }
          assertEquals("failed to create enough Customers", USER_COUNT, getCustomerIDs().size());
 
          final ExecutorService executor = Executors.newFixedThreadPool(USER_COUNT);
 
          CyclicBarrier barrier = new CyclicBarrier(USER_COUNT + 1);
          List<Future<Void>> futures = new ArrayList<Future<Void>>(USER_COUNT);
          for (Integer customerId : getCustomerIDs()) {
             Future<Void> future = executor.submit(new UserRunner(customerId, barrier));
             futures.add(future);
             Thread.sleep(LAUNCH_INTERVAL_MILLIS); // rampup
          }
 //         barrier.await(); // wait for all threads to be ready
          barrier.await(45, TimeUnit.SECONDS); // wait for all threads to finish
          log.info("All threads finished, let's shutdown the executor and check whether any exceptions were reported");
          for (Future<Void> future : futures) future.get();
          log.info("All future gets checked");
       } catch (Throwable t) {
          log.error("Error running test", t);
          throw t;
       }
    }
 
    public void cleanup() throws Exception {
       getCustomerIDs().clear();
       String deleteContactHQL = "delete from Contact";
       String deleteCustomerHQL = "delete from Customer";
       beginTx();
       try {
          Session session = getEnvironment().getSessionFactory().getCurrentSession();
          session.createQuery(deleteContactHQL).setFlushMode(FlushMode.AUTO).executeUpdate();
          session.createQuery(deleteCustomerHQL).setFlushMode(FlushMode.AUTO).executeUpdate();
       } catch (Exception e) {
          setRollbackOnlyTx(e);
       } finally {
          commitOrRollbackTx();
       }
    }
 
    private Customer createCustomer(int nameSuffix) throws Exception {
       Customer customer = null;
       beginTx();
       try {
          customer = new Customer();
          customer.setName("customer_" + nameSuffix);
          customer.setContacts(new HashSet<Contact>());
          getEnvironment().getSessionFactory().getCurrentSession().persist(customer);
       } catch (Exception e) {
          setRollbackOnlyTx(e);
       } finally {
          commitOrRollbackTx();
       }
       return customer;
    }
 
    /**
     * read first contact of every Customer participating in this test. this forces concurrent cache
     * writes of Customer.contacts Collection cache node
     * 
     * @return who cares
     * @throws java.lang.Exception
     */
    private void readEveryonesFirstContact() throws Exception {
       beginTx();
       try {
          for (Integer customerId : getCustomerIDs()) {
             if (TERMINATE_ALL_USERS) {
                setRollbackOnlyTx();
                return;
             }
             Customer customer = (Customer) getEnvironment().getSessionFactory().getCurrentSession().load(Customer.class, customerId);
             Set<Contact> contacts = customer.getContacts();
             if (!contacts.isEmpty()) {
                contacts.iterator().next();
             }
          }
       } catch (Exception e) {
          setRollbackOnlyTx(e);
       } finally {
          commitOrRollbackTx();
       }
    }
 
    /**
     * -load existing Customer -get customer's contacts; return 1st one
     * 
     * @param customerId
     * @return first Contact or null if customer has none
     */
    private Contact getFirstContact(Integer customerId) throws Exception {
       assert customerId != null;
       Contact firstContact = null;
       beginTx();
       try {
          final Customer customer = (Customer) getEnvironment().getSessionFactory()
                   .getCurrentSession().load(Customer.class, customerId);
          Set<Contact> contacts = customer.getContacts();
          firstContact = contacts.isEmpty() ? null : contacts.iterator().next();
          if (TERMINATE_ALL_USERS)
             setRollbackOnlyTx();
       } catch (Exception e) {
          setRollbackOnlyTx(e);
       } finally {
          commitOrRollbackTx();
       }
       return firstContact;
    }
 
    /**
     * -load existing Customer -create a new Contact and add to customer's contacts
     * 
     * @param customerId
     * @return added Contact
     */
    private Contact addContact(Integer customerId) throws Exception {
       assert customerId != null;
       Contact contact = null;
       beginTx();
       try {
          final Customer customer = (Customer) getEnvironment().getSessionFactory()
                   .getCurrentSession().load(Customer.class, customerId);
          contact = new Contact();
          contact.setName("contact name");
          contact.setTlf("wtf is tlf?");
          contact.setCustomer(customer);
          customer.getContacts().add(contact);
          // assuming contact is persisted via cascade from customer
          if (TERMINATE_ALL_USERS)
             setRollbackOnlyTx();
       } catch (Exception e) {
          setRollbackOnlyTx(e);
       } finally {
          commitOrRollbackTx();
       }
       return contact;
    }
 
    /**
     * remove existing 'contact' from customer's list of contacts
     * 
     * @param customerId
     * @throws IllegalStateException
     *            if customer does not own a contact
     */
    private void removeContact(Integer customerId) throws Exception {
       assert customerId != null;
 
       beginTx();
       try {
          Customer customer = (Customer) getEnvironment().getSessionFactory().getCurrentSession()
                   .load(Customer.class, customerId);
          Set<Contact> contacts = customer.getContacts();
          if (contacts.size() != 1) {
             throw new IllegalStateException("can't remove contact: customer id=" + customerId
                      + " expected exactly 1 contact, " + "actual count=" + contacts.size());
          }
 
          Contact contact = contacts.iterator().next();
          contacts.remove(contact);
          contact.setCustomer(null);
 
          // explicitly delete Contact because hbm has no 'DELETE_ORPHAN' cascade?
          // getEnvironment().getSessionFactory().getCurrentSession().delete(contact); //appears to
          // not be needed
 
          // assuming contact is persisted via cascade from customer
 
          if (TERMINATE_ALL_USERS)
             setRollbackOnlyTx();
       } catch (Exception e) {
          setRollbackOnlyTx(e);
       } finally {
          commitOrRollbackTx();
       }
    }
 
    /**
     * @return the customerIDs
     */
    public Set<Integer> getCustomerIDs() {
       return customerIDs;
    }
 
    private String statusOfRunnersToString(Set<UserRunner> runners) {
       assert runners != null;
 
       StringBuilder sb = new StringBuilder("TEST CONFIG [userCount=" + USER_COUNT
                + ", iterationsPerUser=" + ITERATION_COUNT + ", thinkTimeMillis="
                + THINK_TIME_MILLIS + "] " + " STATE of UserRunners: ");
 
       for (UserRunner r : runners) {
          sb.append(r.toString() + System.getProperty("line.separator"));
       }
       return sb.toString();
    }
 
    class UserRunner implements Callable<Void> {
       private final CyclicBarrier barrier;
       final private Integer customerId;
       private int completedIterations = 0;
       private Throwable causeOfFailure;
 
       public UserRunner(Integer cId, CyclicBarrier barrier) {
          assert cId != null;
          this.customerId = cId;
          this.barrier = barrier;
       }
 
       private boolean contactExists() throws Exception {
          return getFirstContact(customerId) != null;
       }
 
       public Void call() throws Exception {
          // name this thread for easier log tracing
          Thread.currentThread().setName("UserRunnerThread-" + getCustomerId());
          log.info("Wait for all executions paths to be ready to perform calls");
          try {
 //            barrier.await();
             for (int i = 0; i < ITERATION_COUNT && !TERMINATE_ALL_USERS; i++) {
                contactExists();
                if (trace) log.trace("Add contact for customer " + customerId);
                addContact(customerId);
                if (trace) log.trace("Added contact");
                thinkRandomTime();
                contactExists();
                thinkRandomTime();
                if (trace) log.trace("Read all customers' first contact");
                // read everyone's contacts
                readEveryonesFirstContact();
                if (trace) log.trace("Read completed");
                thinkRandomTime();
                if (trace) log.trace("Remove contact of customer" + customerId);
                removeContact(customerId);
                if (trace) log.trace("Removed contact");
                contactExists();
                thinkRandomTime();
                ++completedIterations;
                if (log.isTraceEnabled()) log.trace("Iteration completed {0}", completedIterations);
             }
          } catch (Throwable t) {
             TERMINATE_ALL_USERS = true;
             log.error("Error", t);
             throw new Exception(t);
             // rollback current transaction if any
             // really should not happen since above methods all follow begin-commit-rollback pattern
             // try {
             // if
             // (DualNodeJtaTransactionManagerImpl.getInstance(DualNodeTestUtil.LOCAL).getTransaction()
             // != null) {
             // DualNodeJtaTransactionManagerImpl.getInstance(DualNodeTestUtil.LOCAL).rollback();
             // }
             // } catch (SystemException ex) {
             // throw new RuntimeException("failed to rollback tx", ex);
             // }
          } finally {
             log.info("Wait for all execution paths to finish");
             barrier.await();
          }
          return null;
       }
 
       public boolean isSuccess() {
          return ITERATION_COUNT == getCompletedIterations();
       }
 
       public int getCompletedIterations() {
          return completedIterations;
       }
 
       public Throwable getCauseOfFailure() {
          return causeOfFailure;
       }
 
       public Integer getCustomerId() {
          return customerId;
       }
 
       @Override
       public String toString() {
          return super.toString() + "[customerId=" + getCustomerId() + " iterationsCompleted="
                   + getCompletedIterations() + " completedAll=" + isSuccess() + " causeOfFailure="
                   + (this.causeOfFailure != null ? getStackTrace(causeOfFailure) : "") + "] ";
       }
    }
 
    public static String getStackTrace(Throwable throwable) {
       StringWriter sw = new StringWriter();
       PrintWriter pw = new PrintWriter(sw, true);
       throwable.printStackTrace(pw);
       return sw.getBuffer().toString();
    }
 
    /**
     * sleep between 0 and THINK_TIME_MILLIS.
     * 
     * @throws RuntimeException
     *            if sleep is interrupted or TERMINATE_ALL_USERS flag was set to true i n the
     *            meantime
     */
    private void thinkRandomTime() {
       try {
          Thread.sleep(random.nextInt(THINK_TIME_MILLIS));
       } catch (InterruptedException ex) {
          throw new RuntimeException("sleep interrupted", ex);
       }
 
       if (TERMINATE_ALL_USERS) {
          throw new RuntimeException("told to terminate (because a UserRunner had failed)");
       }
    }
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/JndiRegionFactoryTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/JndiRegionFactoryTestCase.java
index 7ea83aee06..274e526945 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/JndiRegionFactoryTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/JndiRegionFactoryTestCase.java
@@ -1,180 +1,180 @@
 package org.hibernate.test.cache.infinispan.functional;
 
 import org.hibernate.Session;
 import org.hibernate.cache.RegionFactory;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.JndiInfinispanRegionFactory;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Mappings;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.testing.junit.functional.ExecutionEnvironment;
 import org.hibernate.stat.Statistics;
 import org.infinispan.Cache;
 import org.infinispan.lifecycle.ComponentStatus;
 import org.infinispan.manager.DefaultCacheManager;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 import org.jboss.util.naming.NonSerializableFactory;
 import org.jnp.server.Main;
 import org.jnp.server.SingletonNamingServer;
 
 import javax.naming.Context;
 import javax.naming.InitialContext;
 import javax.naming.Name;
 import javax.naming.NameNotFoundException;
 import javax.naming.Reference;
 import javax.naming.StringRefAddr;
 import java.util.Properties;
 
 /**
  * // TODO: Document this
  *
  * @author Galder Zamarreo
  * @since // TODO
  */
 public class JndiRegionFactoryTestCase extends SingleNodeTestCase {
    private static final Log log = LogFactory.getLog(JndiRegionFactoryTestCase.class);
    private static final String JNDI_NAME = "java:CacheManager";
    private Main namingMain;
    private SingletonNamingServer namingServer;
    private Properties props;
    private boolean bindToJndi = true;
    private EmbeddedCacheManager manager;
 
    public JndiRegionFactoryTestCase(String string) {
       super(string);
    }
 
    @Override
    protected void cleanupTest() throws Exception {
       Context ctx = new InitialContext(props);
       unbind(JNDI_NAME, ctx);
       namingServer.destroy();
       namingMain.stop();
       manager.stop(); // Need to stop cos JNDI region factory does not stop it.
    }
 
    @Override
    protected Class<? extends RegionFactory> getCacheRegionFactory() {
       return JndiInfinispanRegionFactory.class;
    }
 
    @Override
    public void afterConfigurationBuilt(Mappings mappings, Dialect dialect) {
       if (bindToJndi) {
          try {
             // Create an in-memory jndi
             namingServer = new SingletonNamingServer();
             namingMain = new Main();
             namingMain.setInstallGlobalService(true);
             namingMain.setPort(-1);
             namingMain.start();
             props = new Properties();
             props.put("java.naming.factory.initial", "org.jnp.interfaces.NamingContextFactory");
             props.put("java.naming.factory.url.pkgs", "org.jboss.naming:org.jnp.interfaces");
 
             manager = new DefaultCacheManager(InfinispanRegionFactory.DEF_INFINISPAN_CONFIG_RESOURCE, false);
             Context ctx = new InitialContext(props);
             bind(JNDI_NAME, manager, EmbeddedCacheManager.class, ctx);
          } catch(Exception e) {
             throw new RuntimeException("Failure to set up JNDI", e);
          }
       }
    }
 
    @Override
    public void configure(Configuration cfg) {
       super.configure(cfg);
       cfg.setProperty(JndiInfinispanRegionFactory.CACHE_MANAGER_RESOURCE_PROP, JNDI_NAME);
       cfg.setProperty(Environment.JNDI_CLASS, "org.jnp.interfaces.NamingContextFactory");
       cfg.setProperty("java.naming.factory.url.pkgs", "org.jboss.naming:org.jnp.interfaces");
    }
 
    public void testRedeployment() throws Exception {
       addEntityCheckCache();
       getEnvironment().getSessionFactory().close();
       bindToJndi = false;
       ExecutionEnvironment environment = new ExecutionEnvironment( this );
-      environment.initialize();
+      environment.initialize( getConnectionProviderInjectionProperties() );
       setEnvironment(environment);
       addEntityCheckCache();
       JndiInfinispanRegionFactory regionFactory = (JndiInfinispanRegionFactory) ((SessionFactoryImplementor)
             environment.getSessionFactory()).getSettings().getRegionFactory();
       Cache cache = regionFactory.getCacheManager().getCache("org.hibernate.test.cache.infinispan.functional.Item");
       assertEquals(ComponentStatus.RUNNING, cache.getStatus());
    }
 
    private void addEntityCheckCache() throws Exception {
       Item item = new Item("chris", "Chris's Item");
       beginTx();
       try {
          Session s = openSession();
          s.getTransaction().begin();
          s.persist(item);
          s.getTransaction().commit();
          s.close();
       } catch (Exception e) {
          setRollbackOnlyTx(e);
       } finally {
          commitOrRollbackTx();
       }
 
       beginTx();
       try {
          Session s = openSession();
          Item found = (Item) s.load(Item.class, item.getId());
          Statistics stats = s.getSessionFactory().getStatistics();
          log.info(stats.toString());
          assertEquals(item.getDescription(), found.getDescription());
          assertEquals(0, stats.getSecondLevelCacheMissCount());
          assertEquals(1, stats.getSecondLevelCacheHitCount());
          s.delete(found);
          s.close();
       } catch (Exception e) {
          setRollbackOnlyTx(e);
       } finally {
          commitOrRollbackTx();
       }
 
    }
 
    /**
     * Helper method that binds the a non serializable object to the JNDI tree.
     *
     * @param jndiName Name under which the object must be bound
     * @param who Object to bind in JNDI
     * @param classType Class type under which should appear the bound object
     * @param ctx Naming context under which we bind the object
     * @throws Exception Thrown if a naming exception occurs during binding
     */
    private void bind(String jndiName, Object who, Class<?> classType, Context ctx) throws Exception {
       // Ah ! This service isn't serializable, so we use a helper class
       NonSerializableFactory.bind(jndiName, who);
       Name n = ctx.getNameParser("").parse(jndiName);
       while (n.size() > 1) {
          String ctxName = n.get(0);
          try {
             ctx = (Context) ctx.lookup(ctxName);
          } catch (NameNotFoundException e) {
             log.debug("creating Subcontext " + ctxName);
             ctx = ctx.createSubcontext(ctxName);
          }
          n = n.getSuffix(1);
       }
 
       // The helper class NonSerializableFactory uses address type nns, we go on to
       // use the helper class to bind the service object in JNDI
       StringRefAddr addr = new StringRefAddr("nns", jndiName);
       Reference ref = new Reference(classType.getName(), addr, NonSerializableFactory.class.getName(), null);
       ctx.rebind(n.get(0), ref);
    }
 
    private void unbind(String jndiName, Context ctx) throws Exception {
       NonSerializableFactory.unbind(jndiName);
 //      ctx.unbind(jndiName);
    }
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/SingleNodeTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/SingleNodeTestCase.java
index 8e40eafa9e..88ad695cfb 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/SingleNodeTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/SingleNodeTestCase.java
@@ -1,115 +1,115 @@
 package org.hibernate.test.cache.infinispan.functional;
 
 import javax.transaction.Status;
 import javax.transaction.TransactionManager;
 
 import org.hibernate.cache.RegionFactory;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
-import org.hibernate.connection.ConnectionProvider;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.testing.junit.functional.FunctionalTestCase;
 import org.hibernate.stat.SecondLevelCacheStatistics;
 import org.hibernate.stat.Statistics;
 import org.hibernate.transaction.CMTTransactionFactory;
 import org.hibernate.transaction.TransactionFactory;
 import org.hibernate.transaction.TransactionManagerLookup;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 /**
  * @author Galder Zamarreo
  * @since 3.5
  */
 public abstract class SingleNodeTestCase extends FunctionalTestCase {
    private static final Log log = LogFactory.getLog(SingleNodeTestCase.class);
    private final TransactionManager tm;
 
    public SingleNodeTestCase(String string) {
       super(string);
       tm = getTransactionManager();
    }
 
    protected TransactionManager getTransactionManager() {
       try {
          if (getTransactionManagerLookupClass() == null)
             return null;
          else
             return getTransactionManagerLookupClass().newInstance().getTransactionManager(null);
       } catch (Exception e) {
          log.error("Error", e);
          throw new RuntimeException(e);
       }
    }
 
    
    public String[] getMappings() {
       return new String[] { 
                "cache/infinispan/functional/Item.hbm.xml", 
                "cache/infinispan/functional/Customer.hbm.xml", 
                "cache/infinispan/functional/Contact.hbm.xml"};
    }
 
    @Override
    public String getCacheConcurrencyStrategy() {
       return "transactional";
    }
 
    protected Class<? extends RegionFactory> getCacheRegionFactory() {
       return InfinispanRegionFactory.class;
    }
 
    protected Class<? extends TransactionFactory> getTransactionFactoryClass() {
       return CMTTransactionFactory.class;
    }
 
    protected Class<? extends ConnectionProvider> getConnectionProviderClass() {
       return org.hibernate.test.cache.infinispan.tm.XaConnectionProvider.class;
    }
 
    protected Class<? extends TransactionManagerLookup> getTransactionManagerLookupClass() {
       return org.hibernate.test.cache.infinispan.tm.XaTransactionManagerLookup.class;
    }
 
    protected boolean getUseQueryCache() {
       return true;
    }
 
    public void configure(Configuration cfg) {
       super.configure(cfg);
       cfg.setProperty(Environment.USE_SECOND_LEVEL_CACHE, "true");
       cfg.setProperty(Environment.GENERATE_STATISTICS, "true");
       cfg.setProperty(Environment.USE_QUERY_CACHE, String.valueOf(getUseQueryCache()));
       cfg.setProperty(Environment.CACHE_REGION_FACTORY, getCacheRegionFactory().getName());
       cfg.setProperty(Environment.CONNECTION_PROVIDER, getConnectionProviderClass().getName());
       if (getTransactionManagerLookupClass() != null) {
          cfg.setProperty(Environment.TRANSACTION_MANAGER_STRATEGY, getTransactionManagerLookupClass().getName());
       }
       cfg.setProperty(Environment.TRANSACTION_STRATEGY, getTransactionFactoryClass().getName());
    }
 
    protected void beginTx() throws Exception {
       tm.begin();
    }
 
    protected void setRollbackOnlyTx() throws Exception {
       tm.setRollbackOnly();
    }
 
    protected void setRollbackOnlyTx(Exception e) throws Exception {
       log.error("Error", e);
       tm.setRollbackOnly();
       throw e;
    }
 
    protected void setRollbackOnlyTxExpected(Exception e) throws Exception {
       log.debug("Expected behaivour", e);
       tm.setRollbackOnly();
    }
 
    protected void commitOrRollbackTx() throws Exception {
       if (tm.getStatus() == Status.STATUS_ACTIVE) tm.commit();
       else tm.rollback();
    }
    
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/bulk/BulkOperationsTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/bulk/BulkOperationsTestCase.java
index b638497534..d737cd6c4c 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/bulk/BulkOperationsTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/bulk/BulkOperationsTestCase.java
@@ -1,372 +1,372 @@
 /*
  * JBoss, Home of Professional Open Source.
  * Copyright 2009, Red Hat, Inc. and/or it's affiliates, and individual contributors
  * as indicated by the @author tags. See the copyright.txt file in the
  * distribution for a full listing of individual contributors.
  *
  * This is free software; you can redistribute it and/or modify it
  * under the terms of the GNU Lesser General Public License as
  * published by the Free Software Foundation; either version 2.1 of
  * the License, or (at your option) any later version.
  *
  * This software is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * Lesser General Public License for more details.
  *
  * You should have received a copy of the GNU Lesser General Public
  * License along with this software; if not, write to the Free
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
 package org.hibernate.test.cache.infinispan.functional.bulk;
 
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 
 import javax.transaction.Status;
 import javax.transaction.TransactionManager;
 
 import org.hibernate.FlushMode;
 import org.hibernate.cache.RegionFactory;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.classic.Session;
-import org.hibernate.connection.ConnectionProvider;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.testing.junit.functional.FunctionalTestCase;
 import org.hibernate.stat.SecondLevelCacheStatistics;
 import org.hibernate.test.cache.infinispan.functional.Contact;
 import org.hibernate.test.cache.infinispan.functional.Customer;
 import org.hibernate.transaction.CMTTransactionFactory;
 import org.hibernate.transaction.TransactionFactory;
 import org.hibernate.transaction.TransactionManagerLookup;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 /**
  * BulkOperationsTestCase.
  * 
  * @author Galder Zamarreo
  * @since 3.5
  */
 public class BulkOperationsTestCase extends FunctionalTestCase {
    private static final Log log = LogFactory.getLog(BulkOperationsTestCase.class);
 
    private TransactionManager tm;
 
    public BulkOperationsTestCase(String string) {
       super(string);
    }
 
    public String[] getMappings() {
       return new String[] { "cache/infinispan/functional/Contact.hbm.xml",
                "cache/infinispan/functional/Customer.hbm.xml" };
    }
 
    @Override
    public String getCacheConcurrencyStrategy() {
       return "transactional";
    }
 
    protected Class<? extends RegionFactory> getCacheRegionFactory() {
       return InfinispanRegionFactory.class;
    }
 
    protected Class<? extends TransactionFactory> getTransactionFactoryClass() {
       return CMTTransactionFactory.class;
    }
 
    protected Class<? extends ConnectionProvider> getConnectionProviderClass() {
       return org.hibernate.test.cache.infinispan.tm.XaConnectionProvider.class;
    }
 
    protected Class<? extends TransactionManagerLookup> getTransactionManagerLookupClass() {
       return org.hibernate.test.cache.infinispan.tm.XaTransactionManagerLookup.class;
    }
 
    public void configure(Configuration cfg) {
       super.configure(cfg);
       cfg.setProperty(Environment.USE_SECOND_LEVEL_CACHE, "true");
       cfg.setProperty(Environment.GENERATE_STATISTICS, "true");
       cfg.setProperty(Environment.USE_QUERY_CACHE, "false");
       cfg.setProperty(Environment.CACHE_REGION_FACTORY, getCacheRegionFactory().getName());
       cfg.setProperty(Environment.CONNECTION_PROVIDER, getConnectionProviderClass().getName());
       cfg.setProperty(Environment.TRANSACTION_MANAGER_STRATEGY, getTransactionManagerLookupClass().getName());
       cfg.setProperty(Environment.TRANSACTION_STRATEGY, getTransactionFactoryClass().getName());
    }
 
    public void testBulkOperations() throws Throwable {
       log.info("*** testBulkOperations()");
       boolean cleanedUp = false;
       try {
          tm = getTransactionManagerLookupClass().newInstance().getTransactionManager(null);
 
          createContacts();
 
          List<Integer> rhContacts = getContactsByCustomer("Red Hat");
          assertNotNull("Red Hat contacts exist", rhContacts);
          assertEquals("Created expected number of Red Hat contacts", 10, rhContacts.size());
 
          SecondLevelCacheStatistics contactSlcs = getEnvironment().getSessionFactory()
                   .getStatistics().getSecondLevelCacheStatistics(Contact.class.getName());
          assertEquals(20, contactSlcs.getElementCountInMemory());
 
          assertEquals("Deleted all Red Hat contacts", 10, deleteContacts());
          assertEquals(0, contactSlcs.getElementCountInMemory());
 
          List<Integer> jbContacts = getContactsByCustomer("JBoss");
          assertNotNull("JBoss contacts exist", jbContacts);
          assertEquals("JBoss contacts remain", 10, jbContacts.size());
 
          for (Integer id : rhContacts) {
             assertNull("Red Hat contact " + id + " cannot be retrieved", getContact(id));
          }
          rhContacts = getContactsByCustomer("Red Hat");
          if (rhContacts != null) {
             assertEquals("No Red Hat contacts remain", 0, rhContacts.size());
          }
 
          updateContacts("Kabir", "Updated");
          assertEquals(0, contactSlcs.getElementCountInMemory());
          for (Integer id : jbContacts) {
             Contact contact = getContact(id);
             assertNotNull("JBoss contact " + id + " exists", contact);
             String expected = ("Kabir".equals(contact.getName())) ? "Updated" : "2222";
             assertEquals("JBoss contact " + id + " has correct TLF", expected, contact.getTlf());
          }
 
          List<Integer> updated = getContactsByTLF("Updated");
          assertNotNull("Got updated contacts", updated);
          assertEquals("Updated contacts", 5, updated.size());
 
          updateContactsWithOneManual("Kabir", "UpdatedAgain");
          assertEquals(contactSlcs.getElementCountInMemory(), 0);
          for (Integer id : jbContacts) {
             Contact contact = getContact(id);
             assertNotNull("JBoss contact " + id + " exists", contact);
             String expected = ("Kabir".equals(contact.getName())) ? "UpdatedAgain" : "2222";
             assertEquals("JBoss contact " + id + " has correct TLF", expected, contact.getTlf());
          }
 
          updated = getContactsByTLF("UpdatedAgain");
          assertNotNull("Got updated contacts", updated);
          assertEquals("Updated contacts", 5, updated.size());
       } catch (Throwable t) {
          cleanedUp = true;
          log.debug("Exceptional cleanup");
          cleanup(true);
          throw t;
       } finally {
          // cleanup the db so we can run this test multiple times w/o restarting the cluster
          if (!cleanedUp) {
             log.debug("Non exceptional cleanup");
             cleanup(false);
          }
       }
    }
 
    public void createContacts() throws Exception {
       log.debug("Create 10 contacts");
       tm.begin();
       try {
          for (int i = 0; i < 10; i++) createCustomer(i);
       } catch (Exception e) {
          log.error("Unable to create customer", e);
          tm.setRollbackOnly();
          throw e;
       } finally {
          if (tm.getStatus() == Status.STATUS_ACTIVE) tm.commit();
          else tm.rollback();
       }
    }
 
    public int deleteContacts() throws Exception {
       String deleteHQL = "delete Contact where customer in ";
       deleteHQL += " (select customer FROM Customer as customer ";
       deleteHQL += " where customer.name = :cName)";
 
       tm.begin();
       try {
          Session session = getSessions().getCurrentSession();
          int rowsAffected = session.createQuery(deleteHQL).setFlushMode(FlushMode.AUTO)
                   .setParameter("cName", "Red Hat").executeUpdate();
          tm.commit();
          return rowsAffected;
       } catch (Exception e) {
          log.error("Unable to delete contac", e);
          tm.setRollbackOnly();
          throw e;
       } finally {
          if (tm.getStatus() == Status.STATUS_ACTIVE) {
             tm.commit();
          } else {
             try {
                tm.rollback();
             } catch (Exception ee) {
                // ignored
             }
          }
       }
    }
 
    public List<Integer> getContactsByCustomer(String customerName) throws Exception {
       String selectHQL = "select contact.id from Contact contact";
       selectHQL += " where contact.customer.name = :cName";
 
       log.debug("Get contacts for customer " + customerName);
       tm.begin();
       try {
 
          Session session = getSessions().getCurrentSession();
          List results = session.createQuery(selectHQL).setFlushMode(FlushMode.AUTO).setParameter(
                   "cName", customerName).list();
          return results;
       } catch (Exception e) {
          log.error("Unable to get contacts by customer", e);
          tm.setRollbackOnly();
          throw e;
       } finally {
          if (tm.getStatus() == Status.STATUS_ACTIVE) tm.commit();
          else tm.rollback();
       }
    }
 
    public List<Integer> getContactsByTLF(String tlf) throws Exception {
       String selectHQL = "select contact.id from Contact contact";
       selectHQL += " where contact.tlf = :cTLF";
 
       tm.begin();
       try {
          Session session = getSessions().getCurrentSession();
          List results = session.createQuery(selectHQL).setFlushMode(FlushMode.AUTO).setParameter(
                   "cTLF", tlf).list();
          return results;
       } catch (Exception e) {
          log.error("Unable to get contacts", e);
          tm.setRollbackOnly();
          throw e;
       } finally {
          if (tm.getStatus() == Status.STATUS_ACTIVE) tm.commit();
          else tm.rollback();
       }
    }
 
    public int updateContacts(String name, String newTLF) throws Exception {
       String updateHQL = "update Contact set tlf = :cNewTLF where name = :cName";
       tm.begin();
       try {
          Session session = getSessions().getCurrentSession();
          int rowsAffected = session.createQuery(updateHQL).setFlushMode(FlushMode.AUTO)
                   .setParameter("cNewTLF", newTLF).setParameter("cName", name).executeUpdate();
          return rowsAffected;
       } catch (Exception e) {
          log.error("Unable to update contacts", e);
          tm.setRollbackOnly();
          throw e;
       } finally {
          if (tm.getStatus() == Status.STATUS_ACTIVE) tm.commit();
          else tm.rollback();
       }
    }
 
    public int updateContactsWithOneManual(String name, String newTLF) throws Exception {
       String queryHQL = "from Contact c where c.name = :cName";
       String updateHQL = "update Contact set tlf = :cNewTLF where name = :cName";
       tm.begin();
       try {
          Session session = getSessions().getCurrentSession();
          @SuppressWarnings("unchecked")
          List<Contact> list = session.createQuery(queryHQL).setParameter("cName", name).list();
          list.get(0).setTlf(newTLF);
          int rowsAffected = session.createQuery(updateHQL).setFlushMode(FlushMode.AUTO)
                   .setParameter("cNewTLF", newTLF).setParameter("cName", name).executeUpdate();
          return rowsAffected;
       } catch (Exception e) {
          log.error("Unable to update contacts with one manual", e);
          tm.setRollbackOnly();
          throw e;
       } finally {
          if (tm.getStatus() == Status.STATUS_ACTIVE) tm.commit();
          else tm.rollback();
       }
    }
 
    public Contact getContact(Integer id) throws Exception {
       tm.begin();
       try {
          Session session = getSessions().getCurrentSession();
          Contact contact = (Contact) session.get(Contact.class, id);
          return contact;
       } catch (Exception e) {
          log.error("Unable to get contact", e);
          tm.setRollbackOnly();
          throw e;
       } finally {
          if (tm.getStatus() == Status.STATUS_ACTIVE) tm.commit();
          else tm.rollback();
       }
    }
 
    public void cleanup(boolean ignore) throws Exception {
       String deleteContactHQL = "delete from Contact";
       String deleteCustomerHQL = "delete from Customer";
       tm.begin();
       try {
          Session session = getSessions().getCurrentSession();
          session.createQuery(deleteContactHQL).setFlushMode(FlushMode.AUTO).executeUpdate();
          session.createQuery(deleteCustomerHQL).setFlushMode(FlushMode.AUTO).executeUpdate();
       } catch (Exception e) {
          log.error("Unable to get contact", e);
          tm.setRollbackOnly();
          throw e;
       } finally {
          if (tm.getStatus() == Status.STATUS_ACTIVE) {
             tm.commit();
          } else {
             if (!ignore) {
                try {
                   tm.rollback();
                } catch (Exception ee) {
                   // ignored
                }
             }
          }
       }
    }
 
    private Customer createCustomer(int id) throws Exception {
       System.out.println("CREATE CUSTOMER " + id);
       try {
          Customer customer = new Customer();
          customer.setName((id % 2 == 0) ? "JBoss" : "Red Hat");
          Set<Contact> contacts = new HashSet<Contact>();
 
          Contact kabir = new Contact();
          kabir.setCustomer(customer);
          kabir.setName("Kabir");
          kabir.setTlf("1111");
          contacts.add(kabir);
 
          Contact bill = new Contact();
          bill.setCustomer(customer);
          bill.setName("Bill");
          bill.setTlf("2222");
          contacts.add(bill);
 
          customer.setContacts(contacts);
 
          Session s = openSession();
          s.getTransaction().begin();
          s.persist(customer);
          s.getTransaction().commit();
          s.close();
 
          return customer;
       } finally {
          System.out.println("CREATE CUSTOMER " + id + " -  END");
       }
    }
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/DualNodeConnectionProviderImpl.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/DualNodeConnectionProviderImpl.java
index e6c735d793..ef97c350b2 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/DualNodeConnectionProviderImpl.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/DualNodeConnectionProviderImpl.java
@@ -1,85 +1,89 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.functional.cluster;
 
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
-import org.hibernate.connection.ConnectionProvider;
-import org.hibernate.connection.ConnectionProviderFactory;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
+import org.hibernate.service.spi.Stoppable;
+import org.hibernate.test.common.ConnectionProviderBuilder;
 
 /**
  * A {@link ConnectionProvider} implementation adding JTA-style transactionality around the returned
  * connections using the {@link DualNodeJtaTransactionManagerImpl}.
  * 
  * @author Brian Stansberry
  */
 public class DualNodeConnectionProviderImpl implements ConnectionProvider {
-   private static ConnectionProvider actualConnectionProvider = ConnectionProviderFactory.newConnectionProvider();
+   private static ConnectionProvider actualConnectionProvider = ConnectionProviderBuilder.buildConnectionProvider();
    private String nodeId;
    private boolean isTransactional;
 
    public static ConnectionProvider getActualConnectionProvider() {
       return actualConnectionProvider;
    }
 
-   public void configure(Properties props) throws HibernateException {
-      nodeId = props.getProperty(DualNodeTestCase.NODE_ID_PROP);
-      if (nodeId == null)
-         throw new HibernateException(DualNodeTestCase.NODE_ID_PROP + " not configured");
+   public void setNodeId(String nodeId) throws HibernateException {
+      if (nodeId == null) {
+         throw new HibernateException( "nodeId not configured" );
+	  }
+	  this.nodeId = nodeId;
    }
 
    public Connection getConnection() throws SQLException {
       DualNodeJtaTransactionImpl currentTransaction = DualNodeJtaTransactionManagerImpl
                .getInstance(nodeId).getCurrentTransaction();
       if (currentTransaction == null) {
          isTransactional = false;
          return actualConnectionProvider.getConnection();
       } else {
          isTransactional = true;
          Connection connection = currentTransaction.getEnlistedConnection();
          if (connection == null) {
             connection = actualConnectionProvider.getConnection();
             currentTransaction.enlistConnection(connection);
          }
          return connection;
       }
    }
 
    public void closeConnection(Connection conn) throws SQLException {
       if (!isTransactional) {
          conn.close();
       }
    }
 
    public void close() throws HibernateException {
-      actualConnectionProvider.close();
+	   if ( actualConnectionProvider instanceof Stoppable ) {
+		   ( ( Stoppable ) actualConnectionProvider ).stop();
+	   }
    }
 
    public boolean supportsAggressiveRelease() {
       return true;
    }
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/DualNodeTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/DualNodeTestCase.java
index a8cc2d7ae1..a63d0ea325 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/DualNodeTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/DualNodeTestCase.java
@@ -1,243 +1,260 @@
 /*
  * JBoss, Home of Professional Open Source.
  * Copyright 2009, Red Hat, Inc. and/or it's affiliates, and individual contributors
  * as indicated by the @author tags. See the copyright.txt file in the
  * distribution for a full listing of individual contributors.
  *
  * This is free software; you can redistribute it and/or modify it
  * under the terms of the GNU Lesser General Public License as
  * published by the Free Software Foundation; either version 2.1 of
  * the License, or (at your option) any later version.
  *
  * This software is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * Lesser General Public License for more details.
  *
  * You should have received a copy of the GNU Lesser General Public
  * License along with this software; if not, write to the Free
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
 package org.hibernate.test.cache.infinispan.functional.cluster;
 
+import java.util.Collections;
+import java.util.Map;
+
 import org.hibernate.Session;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Mappings;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.testing.junit.functional.ExecutionEnvironment;
 import org.hibernate.testing.junit.functional.FunctionalTestCase;
 import org.hibernate.transaction.CMTTransactionFactory;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 /**
  * AbstractDualNodeTestCase.
  * 
  * @author Galder Zamarreo
  * @since 3.5
  */
 public abstract class DualNodeTestCase extends FunctionalTestCase {
    
    private static final Log log = LogFactory.getLog(DualNodeTestCase.class);
    public static final String NODE_ID_PROP = "hibernate.test.cluster.node.id";
+   public static final String NODE_ID_FIELD = "nodeId";
    public static final String LOCAL = "local";
    public static final String REMOTE = "remote";
    private ExecutionEnvironment secondNodeEnvironment;
    private Session secondNodeSession;
 
    public DualNodeTestCase(String string) {
       super(string);
    }
    
    public String[] getMappings() {
       return new String[] { "cache/infinispan/functional/Contact.hbm.xml", "cache/infinispan/functional/Customer.hbm.xml" };
    }
    
    @Override
    public String getCacheConcurrencyStrategy() {
       return "transactional";
    }
    
    protected Class getCacheRegionFactory() {
       return ClusterAwareRegionFactory.class;
    }
 
    @Override
    public void configure(Configuration cfg) {
       standardConfigure(cfg);
       configureFirstNode(cfg);
    }
 
    @Override
+   protected Map getConnectionProviderInjectionProperties() {
+	   return getFirstNodeConnectionProviderInjectionProperties();
+   }
+
+   @Override
    protected void prepareTest() throws Exception {
       log.info("Building second node locally managed execution env");
       secondNodeEnvironment = new ExecutionEnvironment(new SecondNodeSettings());
-      secondNodeEnvironment.initialize();
+      secondNodeEnvironment.initialize( getSecondNodeConnectionProviderInjectionProperties() );
       super.prepareTest();
    }
    
    @Override
    protected void runTest() throws Throwable {
       try {
           super.runTest();
       } finally {
          if ( secondNodeSession != null && secondNodeSession.isOpen() ) {
              if ( secondNodeSession.isConnected() ) {
                 secondNodeSession.connection().rollback();
              }
              secondNodeSession.close();
              secondNodeSession = null;
              fail( "unclosed session" );
          } else {
             secondNodeSession = null;
          }
          
       }
    }
 
    @Override
    protected void cleanupTest() throws Exception {
       try {
           super.cleanupTest();
       
           log.info( "Destroying second node locally managed execution env" );
           secondNodeEnvironment.complete();
           secondNodeEnvironment = null;
       } finally {
          cleanupTransactionManagement();
       }
    }
    
    protected void cleanupTransactionManagement() {
       DualNodeJtaTransactionManagerImpl.cleanupTransactions();
       DualNodeJtaTransactionManagerImpl.cleanupTransactionManagers();
    }
 
    public ExecutionEnvironment getSecondNodeEnvironment() {
       return secondNodeEnvironment;
    }
 
    protected Class getConnectionProviderClass() {
       return DualNodeConnectionProviderImpl.class;
    }
 
    protected Class getTransactionManagerLookupClass() {
       return DualNodeTransactionManagerLookup.class;
    }
 
    protected Class getTransactionFactoryClass() {
       return CMTTransactionFactory.class;
    }
 
    /**
     * Apply any node-specific configurations to our first node.
     * 
     * @param the
     *           Configuration to update.
     */
    protected void configureFirstNode(Configuration cfg) {
       cfg.setProperty(NODE_ID_PROP, LOCAL);
    }
 
+	protected Map getFirstNodeConnectionProviderInjectionProperties() {
+		return Collections.singletonMap( NODE_ID_FIELD, LOCAL );
+	}
+
    /**
     * Apply any node-specific configurations to our second node.
     * 
     * @param the
     *           Configuration to update.
     */
    protected void configureSecondNode(Configuration cfg) {
       cfg.setProperty(NODE_ID_PROP, REMOTE);
    }
-   
+
+	protected Map getSecondNodeConnectionProviderInjectionProperties() {
+		return Collections.singletonMap( NODE_ID_FIELD, REMOTE );
+	}
+
    protected void sleep(long ms) {
       try {
           Thread.sleep(ms);
       }
       catch (InterruptedException e) {
           log.warn("Interrupted during sleep", e);
       }
   }
 
    protected boolean getUseQueryCache() {
       return true;
    }
 
    protected void standardConfigure(Configuration cfg) {
       super.configure(cfg);
 
       cfg.setProperty(Environment.CONNECTION_PROVIDER, getConnectionProviderClass().getName());
       cfg.setProperty(Environment.TRANSACTION_MANAGER_STRATEGY, getTransactionManagerLookupClass().getName());
       cfg.setProperty(Environment.TRANSACTION_STRATEGY, getTransactionFactoryClass().getName());
       cfg.setProperty(Environment.CACHE_REGION_FACTORY, getCacheRegionFactory().getName());
       cfg.setProperty(Environment.USE_QUERY_CACHE, String.valueOf(getUseQueryCache()));
    }
 
    /**
     * Settings impl that delegates most calls to the DualNodeTestCase itself, but overrides the
     * configure method to allow separate cache settings for the second node.
     */
    public class SecondNodeSettings implements ExecutionEnvironment.Settings {
       private final DualNodeTestCase delegate;
 
       public SecondNodeSettings() {
          this.delegate = DualNodeTestCase.this;
       }
 
       /**
        * This is the important one -- we extend the delegate's work by adding second-node specific
        * settings
        */
       public void configure(Configuration arg0) {
          delegate.standardConfigure(arg0);
          configureSecondNode(arg0);
       }
 
       /**
        * Disable creating of schemas; we let the primary session factory do that to our shared
        * database.
        */
       public boolean createSchema() {
          return false;
       }
 
       /**
        * Disable creating of schemas; we let the primary session factory do that to our shared
        * database.
        */
       public boolean recreateSchemaAfterFailure() {
          return false;
       }
 
       public void afterConfigurationBuilt(Mappings arg0, Dialect arg1) {
          delegate.afterConfigurationBuilt(arg0, arg1);
       }
 
       public void afterSessionFactoryBuilt(SessionFactoryImplementor arg0) {
          delegate.afterSessionFactoryBuilt(arg0);
       }
 
       public boolean appliesTo(Dialect arg0) {
          return delegate.appliesTo(arg0);
       }
 
       public String getBaseForMappings() {
          return delegate.getBaseForMappings();
       }
 
       public String getCacheConcurrencyStrategy() {
          return delegate.getCacheConcurrencyStrategy();
       }
 
       public String[] getMappings() {
          return delegate.getMappings();
       }
 
       public boolean overrideCacheStrategy() {
          return delegate.overrideCacheStrategy();
       }
    }
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/query/QueryRegionImplTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/query/QueryRegionImplTestCase.java
index e0565d4041..a9b49acec0 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/query/QueryRegionImplTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/query/QueryRegionImplTestCase.java
@@ -1,300 +1,303 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.query;
 
 import java.util.Properties;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 
 import junit.framework.AssertionFailedError;
 
 import org.hibernate.cache.CacheDataDescription;
 import org.hibernate.cache.QueryResultsRegion;
 import org.hibernate.cache.Region;
 import org.hibernate.cache.StandardQueryCache;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.cache.infinispan.util.CacheAdapterImpl;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.test.cache.infinispan.AbstractGeneralDataRegionTestCase;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryVisited;
 import org.infinispan.notifications.cachelistener.event.CacheEntryVisitedEvent;
 import org.infinispan.transaction.tm.BatchModeTransactionManager;
 import org.infinispan.util.concurrent.IsolationLevel;
 
 /**
  * Tests of QueryResultRegionImpl.
  * 
  * @author Galder Zamarreo
  * @since 3.5
  */
 public class QueryRegionImplTestCase extends AbstractGeneralDataRegionTestCase {
 
    // protected static final String REGION_NAME = "test/" + StandardQueryCache.class.getName();
 
    /**
     * Create a new EntityRegionImplTestCase.
     * 
     * @param name
     */
    public QueryRegionImplTestCase(String name) {
       super(name);
    }
 
    @Override
    protected Region createRegion(InfinispanRegionFactory regionFactory, String regionName, Properties properties, CacheDataDescription cdd) {
       return regionFactory.buildQueryResultsRegion(regionName, properties);
    }
 
    @Override
    protected String getStandardRegionName(String regionPrefix) {
       return regionPrefix + "/" + StandardQueryCache.class.getName();
    }
 
    @Override
    protected CacheAdapter getInfinispanCache(InfinispanRegionFactory regionFactory) {
       return CacheAdapterImpl.newInstance(regionFactory.getCacheManager().getCache("local-query"));
    }
    
    @Override
    protected Configuration createConfiguration() {
       return CacheTestUtil.buildCustomQueryCacheConfiguration("test", "replicated-query");
    }
 
    public void testPutDoesNotBlockGet() throws Exception {
       putDoesNotBlockGetTest();
    }
 
    private void putDoesNotBlockGetTest() throws Exception {
       Configuration cfg = createConfiguration();
-      InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(cfg, getCacheTestSupport());
+      InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
+			  getConnectionProvider(), cfg, getCacheTestSupport());
 
       // Sleep a bit to avoid concurrent FLUSH problem
       avoidConcurrentFlush();
 
       final QueryResultsRegion region = regionFactory.buildQueryResultsRegion(getStandardRegionName(REGION_PREFIX), cfg
                .getProperties());
 
       region.put(KEY, VALUE1);
       assertEquals(VALUE1, region.get(KEY));
 
       final CountDownLatch readerLatch = new CountDownLatch(1);
       final CountDownLatch writerLatch = new CountDownLatch(1);
       final CountDownLatch completionLatch = new CountDownLatch(1);
       final ExceptionHolder holder = new ExceptionHolder();
 
       Thread reader = new Thread() {
          public void run() {
             try {
                BatchModeTransactionManager.getInstance().begin();
                log.debug("Transaction began, get value for key");
                assertTrue(VALUE2.equals(region.get(KEY)) == false);
                BatchModeTransactionManager.getInstance().commit();
             } catch (AssertionFailedError e) {
                holder.a1 = e;
                rollback();
             } catch (Exception e) {
                holder.e1 = e;
                rollback();
             } finally {
                readerLatch.countDown();
             }
          }
       };
 
       Thread writer = new Thread() {
          public void run() {
             try {
                BatchModeTransactionManager.getInstance().begin();
                log.debug("Put value2");
                region.put(KEY, VALUE2);
                log.debug("Put finished for value2, await writer latch");
                writerLatch.await();
                log.debug("Writer latch finished");
                BatchModeTransactionManager.getInstance().commit();
                log.debug("Transaction committed");
             } catch (Exception e) {
                holder.e2 = e;
                rollback();
             } finally {
                completionLatch.countDown();
             }
          }
       };
 
       reader.setDaemon(true);
       writer.setDaemon(true);
 
       writer.start();
       assertFalse("Writer is blocking", completionLatch.await(100, TimeUnit.MILLISECONDS));
 
       // Start the reader
       reader.start();
       assertTrue("Reader finished promptly", readerLatch.await(1000000000, TimeUnit.MILLISECONDS));
 
       writerLatch.countDown();
       assertTrue("Reader finished promptly", completionLatch.await(100, TimeUnit.MILLISECONDS));
 
       assertEquals(VALUE2, region.get(KEY));
 
       if (holder.a1 != null)
          throw holder.a1;
       else if (holder.a2 != null)
          throw holder.a2;
 
       assertEquals("writer saw no exceptions", null, holder.e1);
       assertEquals("reader saw no exceptions", null, holder.e2);
    }
 
    public void testGetDoesNotBlockPut() throws Exception {
       getDoesNotBlockPutTest();
    }
 
    private void getDoesNotBlockPutTest() throws Exception {
       Configuration cfg = createConfiguration();
-      InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(cfg, getCacheTestSupport());
+      InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
+			  getConnectionProvider(), cfg, getCacheTestSupport()
+	  );
 
       // Sleep a bit to avoid concurrent FLUSH problem
       avoidConcurrentFlush();
 
       final QueryResultsRegion region = regionFactory.buildQueryResultsRegion(getStandardRegionName(REGION_PREFIX), cfg
                .getProperties());
 
       region.put(KEY, VALUE1);
       assertEquals(VALUE1, region.get(KEY));
 
       // final Fqn rootFqn = getRegionFqn(getStandardRegionName(REGION_PREFIX), REGION_PREFIX);
       final CacheAdapter jbc = getInfinispanCache(regionFactory);
 
       final CountDownLatch blockerLatch = new CountDownLatch(1);
       final CountDownLatch writerLatch = new CountDownLatch(1);
       final CountDownLatch completionLatch = new CountDownLatch(1);
       final ExceptionHolder holder = new ExceptionHolder();
 
       Thread blocker = new Thread() {
 
          public void run() {
             // Fqn toBlock = new Fqn(rootFqn, KEY);
             GetBlocker blocker = new GetBlocker(blockerLatch, KEY);
             try {
                jbc.addListener(blocker);
 
                BatchModeTransactionManager.getInstance().begin();
                region.get(KEY);
                BatchModeTransactionManager.getInstance().commit();
             } catch (Exception e) {
                holder.e1 = e;
                rollback();
             } finally {
                jbc.removeListener(blocker);
             }
          }
       };
 
       Thread writer = new Thread() {
 
          public void run() {
             try {
                writerLatch.await();
 
                BatchModeTransactionManager.getInstance().begin();
                region.put(KEY, VALUE2);
                BatchModeTransactionManager.getInstance().commit();
             } catch (Exception e) {
                holder.e2 = e;
                rollback();
             } finally {
                completionLatch.countDown();
             }
          }
       };
 
       blocker.setDaemon(true);
       writer.setDaemon(true);
 
       boolean unblocked = false;
       try {
          blocker.start();
          writer.start();
 
          assertFalse("Blocker is blocking", completionLatch.await(100, TimeUnit.MILLISECONDS));
          // Start the writer
          writerLatch.countDown();
          assertTrue("Writer finished promptly", completionLatch.await(100, TimeUnit.MILLISECONDS));
 
          blockerLatch.countDown();
          unblocked = true;
 
          if (IsolationLevel.REPEATABLE_READ.equals(jbc.getConfiguration().getIsolationLevel())) {
             assertEquals(VALUE1, region.get(KEY));
          } else {
             assertEquals(VALUE2, region.get(KEY));
          }
 
          if (holder.a1 != null)
             throw holder.a1;
          else if (holder.a2 != null)
             throw holder.a2;
 
          assertEquals("blocker saw no exceptions", null, holder.e1);
          assertEquals("writer saw no exceptions", null, holder.e2);
       } finally {
          if (!unblocked)
             blockerLatch.countDown();
       }
    }
 
    @Listener
    public class GetBlocker {
 
       private CountDownLatch latch;
       // private Fqn fqn;
       private Object key;
 
       GetBlocker(CountDownLatch latch, Object key) {
          this.latch = latch;
          this.key = key;
       }
 
       @CacheEntryVisited
       public void nodeVisisted(CacheEntryVisitedEvent event) {
          if (event.isPre() && event.getKey().equals(key)) {
             try {
                latch.await();
             } catch (InterruptedException e) {
                log.error("Interrupted waiting for latch", e);
             }
          }
       }
    }
 
    private class ExceptionHolder {
       Exception e1;
       Exception e2;
       AssertionFailedError a1;
       AssertionFailedError a2;
    }
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/timestamp/TimestampsRegionImplTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/timestamp/TimestampsRegionImplTestCase.java
index ff8cdd4379..8d2c572e12 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/timestamp/TimestampsRegionImplTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/timestamp/TimestampsRegionImplTestCase.java
@@ -1,210 +1,214 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.timestamp;
 
 import java.util.Properties;
 
 import org.hibernate.cache.CacheDataDescription;
 import org.hibernate.cache.Region;
 import org.hibernate.cache.RegionFactory;
 import org.hibernate.cache.UpdateTimestampsCache;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.impl.ClassLoaderAwareCache;
 import org.hibernate.cache.infinispan.timestamp.TimestampsRegionImpl;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.cache.infinispan.util.CacheAdapterImpl;
 import org.hibernate.cache.infinispan.util.FlagAdapter;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.test.cache.infinispan.AbstractGeneralDataRegionTestCase;
 import org.hibernate.test.cache.infinispan.functional.classloader.Account;
 import org.hibernate.test.cache.infinispan.functional.classloader.AccountHolder;
 import org.hibernate.test.cache.infinispan.functional.classloader.SelectedClassnameClassLoader;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 import org.infinispan.AdvancedCache;
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryActivated;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryCreated;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryEvicted;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryInvalidated;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryLoaded;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryModified;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryPassivated;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryRemoved;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryVisited;
 import org.infinispan.notifications.cachelistener.event.CacheEntryModifiedEvent;
 import org.infinispan.notifications.cachelistener.event.Event;
 
 import javax.transaction.TransactionManager;
 
 /**
  * Tests of TimestampsRegionImpl.
  * 
  * @author Galder Zamarreo
  * @since 3.5
  */
 public class TimestampsRegionImplTestCase extends AbstractGeneralDataRegionTestCase {
 
    public TimestampsRegionImplTestCase(String name) {
       super(name);
    }
 
     @Override
    protected String getStandardRegionName(String regionPrefix) {
       return regionPrefix + "/" + UpdateTimestampsCache.class.getName();
    }
 
    @Override
    protected Region createRegion(InfinispanRegionFactory regionFactory, String regionName, Properties properties, CacheDataDescription cdd) {
       return regionFactory.buildTimestampsRegion(regionName, properties);
    }
 
    @Override
    protected CacheAdapter getInfinispanCache(InfinispanRegionFactory regionFactory) {
       return CacheAdapterImpl.newInstance(regionFactory.getCacheManager().getCache("timestamps"));
    }
 
    public void testClearTimestampsRegionInIsolated() throws Exception {
       Configuration cfg = createConfiguration();
-      InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(cfg, getCacheTestSupport());
+      InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
+			  getConnectionProvider(), cfg, getCacheTestSupport()
+	  );
       // Sleep a bit to avoid concurrent FLUSH problem
       avoidConcurrentFlush();
 
       Configuration cfg2 = createConfiguration();
-      InfinispanRegionFactory regionFactory2 = CacheTestUtil.startRegionFactory(cfg2, getCacheTestSupport());
+      InfinispanRegionFactory regionFactory2 = CacheTestUtil.startRegionFactory(
+			  getConnectionProvider(), cfg2, getCacheTestSupport()
+	  );
       // Sleep a bit to avoid concurrent FLUSH problem
       avoidConcurrentFlush();
 
       TimestampsRegionImpl region = (TimestampsRegionImpl) regionFactory.buildTimestampsRegion(getStandardRegionName(REGION_PREFIX), cfg.getProperties());
       TimestampsRegionImpl region2 = (TimestampsRegionImpl) regionFactory2.buildTimestampsRegion(getStandardRegionName(REGION_PREFIX), cfg2.getProperties());
 //      QueryResultsRegion region2 = regionFactory2.buildQueryResultsRegion(getStandardRegionName(REGION_PREFIX), cfg2.getProperties());
 
 //      ClassLoader cl = Thread.currentThread().getContextClassLoader();
 //      Thread.currentThread().setContextClassLoader(cl.getParent());
 //      log.info("TCCL is " + cl.getParent());
 
       Account acct = new Account();
       acct.setAccountHolder(new AccountHolder());
       region.getCacheAdapter().withFlags(FlagAdapter.FORCE_SYNCHRONOUS).put(acct, "boo");
 
 //      region.put(acct, "boo");
 //
 //      region.evictAll();
 
 //      Account acct = new Account();
 //      acct.setAccountHolder(new AccountHolder());
 
 
 
    }
 
    @Override
    protected Configuration createConfiguration() {
       Configuration cfg = CacheTestUtil.buildConfiguration("test", MockInfinispanRegionFactory.class, false, true);
       return cfg;
    }
 
    public static class MockInfinispanRegionFactory extends InfinispanRegionFactory {
 
       public MockInfinispanRegionFactory() {
       }
 
       public MockInfinispanRegionFactory(Properties props) {
          super(props);
       }
 
 //      @Override
 //      protected TimestampsRegionImpl createTimestampsRegion(CacheAdapter cacheAdapter, String regionName) {
 //         return new MockTimestampsRegionImpl(cacheAdapter, regionName, getTransactionManager(), this);
 //      }
 
       @Override
       protected ClassLoaderAwareCache createCacheWrapper(AdvancedCache cache) {
          return new ClassLoaderAwareCache(cache, Thread.currentThread().getContextClassLoader()) {
             @Override
             public void addListener(Object listener) {
                super.addListener(new MockClassLoaderAwareListener(listener, this));
             }
          };
       }
 
       //      @Override
 //      protected EmbeddedCacheManager createCacheManager(Properties properties) throws CacheException {
 //         try {
 //            EmbeddedCacheManager manager = new DefaultCacheManager(InfinispanRegionFactory.DEF_INFINISPAN_CONFIG_RESOURCE);
 //            org.infinispan.config.Configuration ispnCfg = new org.infinispan.config.Configuration();
 //            ispnCfg.setCacheMode(org.infinispan.config.Configuration.CacheMode.REPL_SYNC);
 //            manager.defineConfiguration("timestamps", ispnCfg);
 //            return manager;
 //         } catch (IOException e) {
 //            throw new CacheException("Unable to create default cache manager", e);
 //         }
 //      }
 
       @Listener      
       public static class MockClassLoaderAwareListener extends ClassLoaderAwareCache.ClassLoaderAwareListener {
          MockClassLoaderAwareListener(Object listener, ClassLoaderAwareCache cache) {
             super(listener, cache);
          }
 
          @CacheEntryActivated
          @CacheEntryCreated
          @CacheEntryEvicted
          @CacheEntryInvalidated
          @CacheEntryLoaded
          @CacheEntryModified
          @CacheEntryPassivated
          @CacheEntryRemoved
          @CacheEntryVisited
          public void event(Event event) throws Throwable {
             ClassLoader cl = Thread.currentThread().getContextClassLoader();
             String notFoundPackage = "org.hibernate.test.cache.infinispan.functional.classloader";
             String[] notFoundClasses = { notFoundPackage + ".Account", notFoundPackage + ".AccountHolder" };
             SelectedClassnameClassLoader visible = new SelectedClassnameClassLoader(null, null, notFoundClasses, cl);
             Thread.currentThread().setContextClassLoader(visible);
             super.event(event);
             Thread.currentThread().setContextClassLoader(cl);            
          }
       }
    }
 
 //   @Listener
 //   public static class MockTimestampsRegionImpl extends TimestampsRegionImpl {
 //
 //      public MockTimestampsRegionImpl(CacheAdapter cacheAdapter, String name, TransactionManager transactionManager, RegionFactory factory) {
 //         super(cacheAdapter, name, transactionManager, factory);
 //      }
 //
 //      @CacheEntryModified
 //      public void nodeModified(CacheEntryModifiedEvent event) {
 ////         ClassLoader cl = Thread.currentThread().getContextClassLoader();
 ////         String notFoundPackage = "org.hibernate.test.cache.infinispan.functional.classloader";
 ////         String[] notFoundClasses = { notFoundPackage + ".Account", notFoundPackage + ".AccountHolder" };
 ////         SelectedClassnameClassLoader visible = new SelectedClassnameClassLoader(null, null, notFoundClasses, cl);
 ////         Thread.currentThread().setContextClassLoader(visible);
 //         super.nodeModified(event);
 ////         Thread.currentThread().setContextClassLoader(cl);
 //      }
 //   }
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/tm/JBossStandaloneJtaExampleTest.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/tm/JBossStandaloneJtaExampleTest.java
index b8b4082f01..3b3ce958f9 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/tm/JBossStandaloneJtaExampleTest.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/tm/JBossStandaloneJtaExampleTest.java
@@ -1,295 +1,306 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.tm;
 
 import junit.framework.TestCase;
 import org.enhydra.jdbc.standard.StandardXADataSource;
 import org.hibernate.Session;
 import org.hibernate.SessionFactory;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.stat.Statistics;
 import org.hibernate.test.cache.infinispan.functional.Item;
+import org.hibernate.test.common.ServiceRegistryHolder;
+
 import org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 import org.jboss.util.naming.NonSerializableFactory;
 import org.jnp.interfaces.NamingContext;
 import org.jnp.server.Main;
 import org.jnp.server.NamingServer;
 
 import javax.naming.Context;
 import javax.naming.InitialContext;
 import javax.naming.Name;
 import javax.naming.NameNotFoundException;
 import javax.naming.Reference;
 import javax.naming.StringRefAddr;
 import javax.transaction.Status;
 import javax.transaction.TransactionManager;
 import javax.transaction.UserTransaction;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.Iterator;
 import java.util.Properties;
 
 /**
  * This is an example test based on http://community.jboss.org/docs/DOC-14617 that shows how to interact with
  * Hibernate configured with Infinispan second level cache provider using JTA transactions.
  *
  * In this test, an XADataSource wrapper is in use where we have associated our transaction manager to it so that
  * commits/rollbacks are propagated to the database as well.
  *
  * @author Galder Zamarreo
  * @since 3.5
  */
 public class JBossStandaloneJtaExampleTest extends TestCase {
    private static final Log log = LogFactory.getLog(JBossStandaloneJtaExampleTest.class);
    private static final JBossStandaloneJTAManagerLookup lookup = new JBossStandaloneJTAManagerLookup();
    Context ctx;
    Main jndiServer;
+   private ServiceRegistryHolder serviceRegistryHolder;
 
    @Override
    protected void setUp() throws Exception {
       super.setUp();
+	  serviceRegistryHolder = new ServiceRegistryHolder( Environment.getProperties() );
       jndiServer = startJndiServer();
       ctx = createJndiContext();
       bindTransactionManager();
       bindUserTransaction();
       bindDataSource();
    }
 
    @Override
    protected void tearDown() throws Exception {
-      super.tearDown();
-      ctx.close();
-      jndiServer.stop();
+      try {
+         super.tearDown();
+         ctx.close();
+         jndiServer.stop();
+	  }
+	  finally {
+		  if ( serviceRegistryHolder != null ) {
+			  serviceRegistryHolder.destroy();
+		  }
+	  }
    }
 
    public void testPersistAndLoadUnderJta() throws Exception {
       Item item;
       SessionFactory sessionFactory = buildSessionFactory();
       try {
          UserTransaction ut = (UserTransaction) ctx.lookup("UserTransaction");
          ut.begin();
          try {
             Session session = sessionFactory.openSession();
             session.getTransaction().begin();
             item = new Item("anItem", "An item owned by someone");
             session.persist(item);
             session.getTransaction().commit();
             session.close();
          } catch(Exception e) {
             ut.setRollbackOnly();
             throw e;
          } finally {
             if (ut.getStatus() == Status.STATUS_ACTIVE)
                ut.commit();
             else
                ut.rollback();
          }
 
          ut = (UserTransaction) ctx.lookup("UserTransaction");
          ut.begin();
          try {
             Session session = sessionFactory.openSession();
             session.getTransaction().begin();
             Item found = (Item) session.load(Item.class, item.getId());
             Statistics stats = session.getSessionFactory().getStatistics();
             log.info(stats.toString());
             assertEquals(item.getDescription(), found.getDescription());
             assertEquals(0, stats.getSecondLevelCacheMissCount());
             assertEquals(1, stats.getSecondLevelCacheHitCount());
             session.delete(found);
             session.getTransaction().commit();
             session.close();
          } catch(Exception e) {
             ut.setRollbackOnly();
             throw e;
          } finally {
             if (ut.getStatus() == Status.STATUS_ACTIVE)
                ut.commit();
             else
                ut.rollback();
          }
 
          ut = (UserTransaction) ctx.lookup("UserTransaction");
          ut.begin();
          try {
             Session session = sessionFactory.openSession();
             session.getTransaction().begin();
             assertNull(session.get(Item.class, item.getId()));
             session.getTransaction().commit();
             session.close();
          } catch(Exception e) {
             ut.setRollbackOnly();
             throw e;
          } finally {
             if (ut.getStatus() == Status.STATUS_ACTIVE)
                ut.commit();
             else
                ut.rollback();
          }
       } finally {
          if (sessionFactory != null)
             sessionFactory.close();
       }
 
    }
 
    public static class ExtendedXADataSource extends StandardXADataSource { // XAPOOL
       @Override
       public Connection getConnection() throws SQLException {
 
          if (getTransactionManager() == null) { // although already set before, it results null again after retrieving the datasource by jndi
             TransactionManager tm;  // this is because the TransactionManager information is not serialized.
             try {
                tm = lookup.getTransactionManager();
             } catch (Exception e) {
                throw new SQLException(e);
             }
             setTransactionManager(tm);  //  resets the TransactionManager on the datasource retrieved by jndi,
             //  this makes the datasource JTA-aware
          }
 
          // According to Enhydra documentation, here we must return the connection of our XAConnection
          // see http://cvs.forge.objectweb.org/cgi-bin/viewcvs.cgi/xapool/xapool/examples/xapooldatasource/DatabaseHelper.java?sortby=rev
          return super.getXAConnection().getConnection();
       }
 
       @Override
       public <T> T unwrap(Class<T> iface) throws SQLException {
          return null;  // JDK6 stuff
       }
 
       @Override
       public boolean isWrapperFor(Class<?> iface) throws SQLException {
          return false;  // JDK6 stuff
       }
    }
 
    private Main startJndiServer() throws Exception {
       // Create an in-memory jndi
       NamingServer namingServer = new NamingServer();
       NamingContext.setLocal(namingServer);
       Main namingMain = new Main();
       namingMain.setInstallGlobalService(true);
       namingMain.setPort(-1);
       namingMain.start();
       return namingMain;
    }
 
    private Context createJndiContext() throws Exception {
       Properties props = new Properties();
       props.put(Context.INITIAL_CONTEXT_FACTORY, "org.jnp.interfaces.NamingContextFactory");
       props.put("java.naming.factory.url.pkgs", "org.jboss.naming:org.jnp.interfaces");
       return new InitialContext(props);
    }
 
    private void bindTransactionManager() throws Exception {
       // as JBossTransactionManagerLookup extends JNDITransactionManagerLookup we must also register the TransactionManager
       bind("java:/TransactionManager", lookup.getTransactionManager(), lookup.getTransactionManager().getClass(), ctx);
    }
 
    private void bindUserTransaction() throws Exception {
       // also the UserTransaction must be registered on jndi: org.hibernate.transaction.JTATransactionFactory#getUserTransaction() requires this
       bind("UserTransaction", lookup.getUserTransaction(), lookup.getUserTransaction().getClass(), ctx);
    }
 
    private void bindDataSource() throws Exception {
       ExtendedXADataSource xads = new ExtendedXADataSource();
       xads.setDriverName("org.h2.Driver");
       xads.setUrl("jdbc:h2:mem:db1;DB_CLOSE_DELAY=-1;MVCC=TRUE");
       ctx.bind("java:/MyDatasource", xads);
    }
 
    /**
     * Helper method that binds the a non serializable object to the JNDI tree.
     *
     * @param jndiName  Name under which the object must be bound
     * @param who       Object to bind in JNDI
     * @param classType Class type under which should appear the bound object
     * @param ctx       Naming context under which we bind the object
     * @throws Exception Thrown if a naming exception occurs during binding
     */
    private void bind(String jndiName, Object who, Class classType, Context ctx) throws Exception {
       // Ah ! This service isn't serializable, so we use a helper class
       NonSerializableFactory.bind(jndiName, who);
       Name n = ctx.getNameParser("").parse(jndiName);
       while (n.size() > 1) {
          String ctxName = n.get(0);
          try {
             ctx = (Context) ctx.lookup(ctxName);
          } catch (NameNotFoundException e) {
             System.out.println("Creating subcontext:" + ctxName);
             ctx = ctx.createSubcontext(ctxName);
          }
          n = n.getSuffix(1);
       }
 
       // The helper class NonSerializableFactory uses address type nns, we go on to
       // use the helper class to bind the service object in JNDI
       StringRefAddr addr = new StringRefAddr("nns", jndiName);
       Reference ref = new Reference(classType.getName(), addr, NonSerializableFactory.class.getName(), null);
       ctx.rebind(n.get(0), ref);
    }
 
    private void unbind(String jndiName, Context ctx) throws Exception {
       NonSerializableFactory.unbind(jndiName);
       ctx.unbind(jndiName);
    }
 
    private SessionFactory buildSessionFactory() {
       // Extra options located in src/test/resources/hibernate.properties 
       Configuration cfg = new Configuration();
       cfg.setProperty(Environment.DIALECT, "org.hibernate.dialect.HSQLDialect");
       cfg.setProperty(Environment.HBM2DDL_AUTO, "create-drop");
       cfg.setProperty(Environment.DATASOURCE, "java:/MyDatasource");
       cfg.setProperty(Environment.JNDI_CLASS, "org.jnp.interfaces.NamingContextFactory");
       cfg.setProperty(Environment.TRANSACTION_MANAGER_STRATEGY, "org.hibernate.transaction.JBossTransactionManagerLookup");
       cfg.setProperty(Environment.TRANSACTION_STRATEGY, "org.hibernate.transaction.JTATransactionFactory");
       cfg.setProperty(Environment.CURRENT_SESSION_CONTEXT_CLASS, "jta");
       cfg.setProperty(Environment.RELEASE_CONNECTIONS, "auto");
       cfg.setProperty(Environment.USE_SECOND_LEVEL_CACHE, "true");
       cfg.setProperty(Environment.USE_QUERY_CACHE, "true");
       cfg.setProperty(Environment.CACHE_REGION_FACTORY, "org.hibernate.cache.infinispan.InfinispanRegionFactory");
       String[] mappings = new String[]{"org/hibernate/test/cache/infinispan/functional/Item.hbm.xml"};
       for (String mapping : mappings) {
          cfg.addResource(mapping, Thread.currentThread().getContextClassLoader());
       }
       cfg.buildMappings();
       Iterator iter = cfg.getClassMappings();
       while (iter.hasNext()) {
          PersistentClass clazz = (PersistentClass) iter.next();
          cfg.setCacheConcurrencyStrategy(clazz.getEntityName(), "transactional");
       }
       iter = cfg.getCollectionMappings();
       while (iter.hasNext()) {
          Collection coll = (Collection) iter.next();
          cfg.setCollectionCacheConcurrencyStrategy(coll.getRole(), "transactional");
       }
-      return cfg.buildSessionFactory();
+      return cfg.buildSessionFactory( serviceRegistryHolder.getServiceRegistry() );
    }
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/tm/XaConnectionProvider.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/tm/XaConnectionProvider.java
index b9af7ea892..45bfcb1611 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/tm/XaConnectionProvider.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/tm/XaConnectionProvider.java
@@ -1,78 +1,81 @@
 /*
  * JBoss, Home of Professional Open Source.
  * Copyright 2009, Red Hat, Inc. and/or it's affiliates, and individual contributors
  * as indicated by the @author tags. See the copyright.txt file in the
  * distribution for a full listing of individual contributors.
  *
  * This is free software; you can redistribute it and/or modify it
  * under the terms of the GNU Lesser General Public License as
  * published by the Free Software Foundation; either version 2.1 of
  * the License, or (at your option) any later version.
  *
  * This software is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * Lesser General Public License for more details.
  *
  * You should have received a copy of the GNU Lesser General Public
  * License along with this software; if not, write to the Free
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
 package org.hibernate.test.cache.infinispan.tm;
 
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
-import org.hibernate.connection.ConnectionProvider;
-import org.hibernate.connection.ConnectionProviderFactory;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
+import org.hibernate.service.spi.Stoppable;
+import org.hibernate.test.common.ConnectionProviderBuilder;
 
 /**
  * XaConnectionProvider.
  * 
  * @author Galder Zamarreo
  * @since 3.5
  */
 public class XaConnectionProvider implements ConnectionProvider {
-   private static ConnectionProvider actualConnectionProvider = ConnectionProviderFactory.newConnectionProvider();
+   private static ConnectionProvider actualConnectionProvider = ConnectionProviderBuilder.buildConnectionProvider();
    private boolean isTransactional;
 
    public static ConnectionProvider getActualConnectionProvider() {
       return actualConnectionProvider;
    }
 
    public void configure(Properties props) throws HibernateException {
    }
 
    public Connection getConnection() throws SQLException {
       XaTransactionImpl currentTransaction = XaTransactionManagerImpl.getInstance().getCurrentTransaction();
       if (currentTransaction == null) {
          isTransactional = false;
          return actualConnectionProvider.getConnection();
       } else {
          isTransactional = true;
          Connection connection = currentTransaction.getEnlistedConnection();
          if (connection == null) {
             connection = actualConnectionProvider.getConnection();
             currentTransaction.enlistConnection(connection);
          }
          return connection;
       }
    }
 
    public void closeConnection(Connection conn) throws SQLException {
       if (!isTransactional) {
          conn.close();
       }
    }
 
    public void close() throws HibernateException {
-      actualConnectionProvider.close();
+	   if ( actualConnectionProvider instanceof Stoppable ) {
+		   ( ( Stoppable ) actualConnectionProvider ).stop();
+	   }
    }
 
    public boolean supportsAggressiveRelease() {
       return true;
    }
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/util/CacheTestUtil.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/util/CacheTestUtil.java
index e614bb6b4a..152854f26d 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/util/CacheTestUtil.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/util/CacheTestUtil.java
@@ -1,145 +1,150 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.util;
 
 import java.util.Enumeration;
 import java.util.HashSet;
 import java.util.Properties;
 import java.util.Set;
 
 import junit.framework.Test;
 import junit.framework.TestCase;
 import junit.framework.TestSuite;
 
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Settings;
+import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
+import org.hibernate.service.spi.ServicesRegistry;
 
 /**
  * Utilities for cache testing.
  * 
  * @author <a href="brian.stansberry@jboss.com">Brian Stansberry</a>
  */
 public class CacheTestUtil {
 
    public static Configuration buildConfiguration(String regionPrefix, Class regionFactory, boolean use2ndLevel, boolean useQueries) {
       Configuration cfg = new Configuration();
       cfg.setProperty(Environment.GENERATE_STATISTICS, "true");
       cfg.setProperty(Environment.USE_STRUCTURED_CACHE, "true");
       cfg.setProperty(Environment.TRANSACTION_MANAGER_STRATEGY, BatchModeTransactionManagerLookup.class.getName());
 
       cfg.setProperty(Environment.CACHE_REGION_FACTORY, regionFactory.getName());
       cfg.setProperty(Environment.CACHE_REGION_PREFIX, regionPrefix);
       cfg.setProperty(Environment.USE_SECOND_LEVEL_CACHE, String.valueOf(use2ndLevel));
       cfg.setProperty(Environment.USE_QUERY_CACHE, String.valueOf(useQueries));
 
       return cfg;
    }
 
    public static Configuration buildLocalOnlyConfiguration(String regionPrefix, boolean use2ndLevel, boolean useQueries) {
       Configuration cfg = buildConfiguration(regionPrefix, InfinispanRegionFactory.class, use2ndLevel, useQueries);
       cfg.setProperty(InfinispanRegionFactory.INFINISPAN_CONFIG_RESOURCE_PROP,
                InfinispanRegionFactory.DEF_INFINISPAN_CONFIG_RESOURCE);
       return cfg;
    }
    
    public static Configuration buildCustomQueryCacheConfiguration(String regionPrefix, String queryCacheName) {
       Configuration cfg = buildConfiguration(regionPrefix, InfinispanRegionFactory.class, true, true);
       cfg.setProperty(InfinispanRegionFactory.QUERY_CACHE_RESOURCE_PROP, queryCacheName);
       return cfg;
    }
 
-   public static InfinispanRegionFactory startRegionFactory(Configuration cfg) throws ClassNotFoundException,
-            InstantiationException, IllegalAccessException {
+   public static InfinispanRegionFactory startRegionFactory(ConnectionProvider connectionProvider,
+															Configuration cfg)
+		   throws ClassNotFoundException, InstantiationException, IllegalAccessException {
 
-      Settings settings = cfg.buildSettings();
+      Settings settings = cfg.buildSettings( connectionProvider );
       Properties properties = cfg.getProperties();
 
       String factoryType = cfg.getProperty(Environment.CACHE_REGION_FACTORY);
       Class factoryClass = Thread.currentThread().getContextClassLoader().loadClass(factoryType);
       InfinispanRegionFactory regionFactory = (InfinispanRegionFactory) factoryClass.newInstance();
 
       regionFactory.start(settings, properties);
 
       return regionFactory;
    }
 
-   public static InfinispanRegionFactory startRegionFactory(Configuration cfg, CacheTestSupport testSupport)
+   public static InfinispanRegionFactory startRegionFactory(ConnectionProvider connectionProvider,
+															Configuration cfg,
+															CacheTestSupport testSupport)
             throws ClassNotFoundException, InstantiationException, IllegalAccessException {
-      InfinispanRegionFactory factory = startRegionFactory(cfg);
+      InfinispanRegionFactory factory = startRegionFactory(connectionProvider, cfg);
       testSupport.registerFactory(factory);
       return factory;
    }
 
    public static void stopRegionFactory(InfinispanRegionFactory factory, CacheTestSupport testSupport) {
       factory.stop();
       testSupport.unregisterFactory(factory);
    }
 
    /**
     * Supports easy creation of a TestSuite where a subclass' "FailureExpected" version of a base
     * test is included in the suite, while the base test is excluded. E.g. test class FooTestCase
     * includes method testBar(), while test class SubFooTestCase extends FooTestCase includes method
     * testBarFailureExcluded(). Passing SubFooTestCase.class to this method will return a suite that
     * does not include testBar().
     * 
     * FIXME Move this to UnitTestCase
     */
    public static TestSuite createFailureExpectedSuite(Class testClass) {
 
       TestSuite allTests = new TestSuite(testClass);
       Set failureExpected = new HashSet();
       Enumeration tests = allTests.tests();
       while (tests.hasMoreElements()) {
          Test t = (Test) tests.nextElement();
          if (t instanceof TestCase) {
             String name = ((TestCase) t).getName();
             if (name.endsWith("FailureExpected"))
                failureExpected.add(name);
          }
       }
 
       TestSuite result = new TestSuite();
       tests = allTests.tests();
       while (tests.hasMoreElements()) {
          Test t = (Test) tests.nextElement();
          if (t instanceof TestCase) {
             String name = ((TestCase) t).getName();
             if (!failureExpected.contains(name + "FailureExpected")) {
                result.addTest(t);
             }
          }
       }
 
       return result;
    }
 
    /**
     * Prevent instantiation.
     */
    private CacheTestUtil() {
    }
 
 }
