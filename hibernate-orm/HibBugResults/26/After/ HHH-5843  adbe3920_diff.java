diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/HqlParser.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/HqlParser.java
index a7bea13c04..9f5db99b8a 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/HqlParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/HqlParser.java
@@ -1,384 +1,388 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast;
 
 import java.io.PrintStream;
 import java.io.PrintWriter;
 import java.io.StringReader;
 
 import antlr.ASTPair;
 import antlr.MismatchedTokenException;
 import antlr.RecognitionException;
 import antlr.Token;
 import antlr.TokenStream;
 import antlr.TokenStreamException;
 import antlr.collections.AST;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.hibernate.hql.antlr.HqlBaseParser;
 import org.hibernate.hql.antlr.HqlTokenTypes;
 import org.hibernate.hql.ast.util.ASTPrinter;
 import org.hibernate.hql.ast.util.ASTUtil;
 import org.hibernate.QueryException;
 import org.hibernate.util.StringHelper;
 
 /**
  * Implements the semantic action methods defined in the HQL base parser to keep the grammar
  * source file a little cleaner.  Extends the parser class generated by ANTLR.
  *
  * @author Joshua Davis (pgmjsd@sourceforge.net)
  */
 public final class HqlParser extends HqlBaseParser {
 	/**
 	 * A logger for this class.
 	 */
 	private static final Logger log = LoggerFactory.getLogger( HqlParser.class );
+	private final boolean trace = log.isTraceEnabled();
 
 	private ParseErrorHandler parseErrorHandler;
 	private ASTPrinter printer = getASTPrinter();
 
 	private static ASTPrinter getASTPrinter() {
 		return new ASTPrinter( org.hibernate.hql.antlr.HqlTokenTypes.class );
 	}
 
 	public static HqlParser getInstance(String hql) {
         // [jsd] The fix for HHH-558...
         HqlLexer lexer = new HqlLexer( new StringReader( hql ) );
 		return new HqlParser( lexer );
 	}
 
 	private HqlParser(TokenStream lexer) {
 		super( lexer );
 		initialize();
 	}
 
 
 	// handle trace logging ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-    private int traceDepth = 0;
-
+	private int traceDepth = 0;
 
 	public void traceIn(String ruleName) {
-		if ( inputState.guessing > 0 ) {
-			return;
+		if (trace) {
+			if ( inputState.guessing > 0 ) {
+				return;
+			}
+			String prefix = StringHelper.repeat( '-', (traceDepth++ * 2) ) + "-> ";
+			log.trace( prefix + ruleName );
 		}
-		String prefix = StringHelper.repeat( '-', (traceDepth++ * 2) ) + "-> ";
-		log.trace( prefix + ruleName );
 	}
 
 	public void traceOut(String ruleName) {
-		if ( inputState.guessing > 0 ) {
-			return;
+		if (trace) {
+			if ( inputState.guessing > 0 ) {
+				return;
+			}
+			String prefix = "<-" + StringHelper.repeat( '-', (--traceDepth * 2) ) + " ";
+			log.trace( prefix + ruleName );
 		}
-		String prefix = "<-" + StringHelper.repeat( '-', (--traceDepth * 2) ) + " ";
-		log.trace( prefix + ruleName );
 	}
 
 	public void reportError(RecognitionException e) {
 		parseErrorHandler.reportError( e ); // Use the delegate.
 	}
 
 	public void reportError(String s) {
 		parseErrorHandler.reportError( s ); // Use the delegate.
 	}
 
 	public void reportWarning(String s) {
 		parseErrorHandler.reportWarning( s );
 	}
 
 	public ParseErrorHandler getParseErrorHandler() {
 		return parseErrorHandler;
 	}
 
 	/**
 	 * Overrides the base behavior to retry keywords as identifiers.
 	 *
 	 * @param token The token.
 	 * @param ex    The recognition exception.
 	 * @return AST - The new AST.
 	 * @throws antlr.RecognitionException if the substitution was not possible.
 	 * @throws antlr.TokenStreamException if the substitution was not possible.
 	 */
 	public AST handleIdentifierError(Token token, RecognitionException ex) throws RecognitionException, TokenStreamException {
 		// If the token can tell us if it could be an identifier...
 		if ( token instanceof HqlToken ) {
 			HqlToken hqlToken = ( HqlToken ) token;
 			// ... and the token could be an identifer and the error is
 			// a mismatched token error ...
 			if ( hqlToken.isPossibleID() && ( ex instanceof MismatchedTokenException ) ) {
 				MismatchedTokenException mte = ( MismatchedTokenException ) ex;
 				// ... and the expected token type was an identifier, then:
 				if ( mte.expecting == HqlTokenTypes.IDENT ) {
 					// Use the token as an identifier.
 					reportWarning( "Keyword  '"
 							+ token.getText()
 							+ "' is being interpreted as an identifier due to: " + mte.getMessage() );
 					// Add the token to the AST.
 					ASTPair currentAST = new ASTPair();
 					token.setType( HqlTokenTypes.WEIRD_IDENT );
 					astFactory.addASTChild( currentAST, astFactory.create( token ) );
 					consume();
 					AST identifierAST = currentAST.root;
 					return identifierAST;
 				}
 			} // if
 		} // if
 		// Otherwise, handle the error normally.
 		return super.handleIdentifierError( token, ex );
 	}
 
 	/**
 	 * Returns an equivalent tree for (NOT (a relop b) ), for example:<pre>
 	 * (NOT (GT a b) ) => (LE a b)
 	 * </pre>
 	 *
 	 * @param x The sub tree to transform, the parent is assumed to be NOT.
 	 * @return AST - The equivalent sub-tree.
 	 */
 	public AST negateNode(AST x) {
 		//TODO: switch statements are always evil! We already had bugs because 
 		//      of forgotten token types. Use polymorphism for this!
 		switch ( x.getType() ) {
 			case OR:
 				x.setType(AND);
 				x.setText("{and}");
 				negateNode( x.getFirstChild() );
 				negateNode( x.getFirstChild().getNextSibling() );
 				return x;
 			case AND:
 				x.setType(OR);
 				x.setText("{or}");
 				negateNode( x.getFirstChild() );
 				negateNode( x.getFirstChild().getNextSibling() );
 				return x;
 			case EQ:
 				x.setType( NE );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (EQ a b) ) => (NE a b)
 			case NE:
 				x.setType( EQ );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (NE a b) ) => (EQ a b)
 			case GT:
 				x.setType( LE );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (GT a b) ) => (LE a b)
 			case LT:
 				x.setType( GE );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (LT a b) ) => (GE a b)
 			case GE:
 				x.setType( LT );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (GE a b) ) => (LT a b)
 			case LE:
 				x.setType( GT );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (LE a b) ) => (GT a b)
 			case LIKE:
 				x.setType( NOT_LIKE );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (LIKE a b) ) => (NOT_LIKE a b)
 			case NOT_LIKE:
 				x.setType( LIKE );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (NOT_LIKE a b) ) => (LIKE a b)
 			case IN:
 				x.setType( NOT_IN );
 				x.setText( "{not}" + x.getText() );
 				return x;
 			case NOT_IN:
 				x.setType( IN );
 				x.setText( "{not}" + x.getText() );
 				return x;
 			case IS_NULL:
 				x.setType( IS_NOT_NULL );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (IS_NULL a b) ) => (IS_NOT_NULL a b)
 			case IS_NOT_NULL:
 				x.setType( IS_NULL );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (IS_NOT_NULL a b) ) => (IS_NULL a b)
 			case BETWEEN:
 				x.setType( NOT_BETWEEN );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (BETWEEN a b) ) => (NOT_BETWEEN a b)
 			case NOT_BETWEEN:
 				x.setType( BETWEEN );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (NOT_BETWEEN a b) ) => (BETWEEN a b)
 /* This can never happen because this rule will always eliminate the child NOT.
 			case NOT:
 				return x.getFirstChild();			// (NOT (NOT x) ) => (x)
 */
 			default:
 				return super.negateNode( x );		// Just add a 'not' parent.
 		}
 	}
 
 	/**
 	 * Post process equality expressions, clean up the subtree.
 	 *
 	 * @param x The equality expression.
 	 * @return AST - The clean sub-tree.
 	 */
 	public AST processEqualityExpression(AST x) {
 		if ( x == null ) {
 			log.warn( "processEqualityExpression() : No expression to process!" );
 			return null;
 		}
 
 		int type = x.getType();
 		if ( type == EQ || type == NE ) {
 			boolean negated = type == NE;
 			if ( x.getNumberOfChildren() == 2 ) {
 				AST a = x.getFirstChild();
 				AST b = a.getNextSibling();
 				// (EQ NULL b) => (IS_NULL b)
 				if ( a.getType() == NULL && b.getType() != NULL ) {
 					return createIsNullParent( b, negated );
 				}
 				// (EQ a NULL) => (IS_NULL a)
 				else if ( b.getType() == NULL && a.getType() != NULL ) {
 					return createIsNullParent( a, negated );
 				}
 				else if ( b.getType() == EMPTY ) {
 					return processIsEmpty( a, negated );
 				}
 				else {
 					return x;
 				}
 			}
 			else {
 				return x;
 			}
 		}
 		else {
 			return x;
 		}
 	}
 
 	private AST createIsNullParent(AST node, boolean negated) {
 		node.setNextSibling( null );
 		int type = negated ? IS_NOT_NULL : IS_NULL;
 		String text = negated ? "is not null" : "is null";
 		return ASTUtil.createParent( astFactory, type, text, node );
 	}
 
 	private AST processIsEmpty(AST node, boolean negated) {
 		node.setNextSibling( null );
 		// NOTE: Because we're using ASTUtil.createParent(), the tree must be created from the bottom up.
 		// IS EMPTY x => (EXISTS (QUERY (SELECT_FROM (FROM x) ) ) )
 		AST ast = createSubquery( node );
 		ast = ASTUtil.createParent( astFactory, EXISTS, "exists", ast );
 		// Add NOT if it's negated.
 		if ( !negated ) {
 			ast = ASTUtil.createParent( astFactory, NOT, "not", ast );
 		}
 		return ast;
 	}
 
 	private AST createSubquery(AST node) {
 		AST ast = ASTUtil.createParent( astFactory, RANGE, "RANGE", node );
 		ast = ASTUtil.createParent( astFactory, FROM, "from", ast );
 		ast = ASTUtil.createParent( astFactory, SELECT_FROM, "SELECT_FROM", ast );
 		ast = ASTUtil.createParent( astFactory, QUERY, "QUERY", ast );
 		return ast;
 	}
 
 	public void showAst(AST ast, PrintStream out) {
 		showAst( ast, new PrintWriter( out ) );
 	}
 
 	private void showAst(AST ast, PrintWriter pw) {
 		printer.showAst( ast, pw );
 	}
 
 	private void initialize() {
 		// Initialize the error handling delegate.
 		parseErrorHandler = new ErrorCounter();
 		setASTFactory(new HqlASTFactory());	// Create nodes that track line and column number.
 	}
 
 	public void weakKeywords() throws TokenStreamException {
 
 		int t = LA( 1 );
 		switch ( t ) {
 			case ORDER:
 			case GROUP:
                 // Case 1: Multi token keywords GROUP BY and ORDER BY
 				// The next token ( LT(2) ) should be 'by'... otherwise, this is just an ident.
 				if ( LA( 2 ) != LITERAL_by ) {
 					LT( 1 ).setType( IDENT );
 					if ( log.isDebugEnabled() ) {
 						log.debug( "weakKeywords() : new LT(1) token - " + LT( 1 ) );
 					}
 				}
 				break;
 			default:
                 // Case 2: The current token is after FROM and before '.'.
                 if (LA(0) == FROM && t != IDENT && LA(2) == DOT) {
                     HqlToken hqlToken = (HqlToken)LT(1);
                     if (hqlToken.isPossibleID()) {
                         hqlToken.setType(IDENT);
                         if ( log.isDebugEnabled() ) {
                             log.debug( "weakKeywords() : new LT(1) token - " + LT( 1 ) );
                         }
                     }
                 }
 				break;
 		}
 	}
 
     public void handleDotIdent() throws TokenStreamException {
         // This handles HHH-354, where there is a strange property name in a where clause.
         // If the lookahead contains a DOT then something that isn't an IDENT...
         if (LA(1) == DOT && LA(2) != IDENT) {
             // See if the second lookahed token can be an identifier.
             HqlToken t = (HqlToken)LT(2);
             if (t.isPossibleID())
             {
                 // Set it!
                 LT( 2 ).setType( IDENT );
                 if ( log.isDebugEnabled() ) {
                     log.debug( "handleDotIdent() : new LT(2) token - " + LT( 1 ) );
                 }
             }
         }
     }
 
 	public void processMemberOf(Token n, AST p, ASTPair currentAST) {
 		AST inAst = n == null ? astFactory.create( IN, "in" ) : astFactory.create( NOT_IN, "not in" );
 		astFactory.makeASTRoot( currentAST, inAst );
 		AST ast = createSubquery( p );
 		ast = ASTUtil.createParent( astFactory, IN_LIST, "inList", ast );
 		inAst.addChild( ast );
 	}
 
 	static public void panic() {
 		//overriden to avoid System.exit
 		throw new QueryException("Parser: panic");
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/HqlSqlWalker.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/HqlSqlWalker.java
index e7f0e3964c..7a04057d2e 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/HqlSqlWalker.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/HqlSqlWalker.java
@@ -1,1220 +1,1225 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Calendar;
 import java.util.Date;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.Arrays;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.hibernate.QueryException;
 import org.hibernate.HibernateException;
 import org.hibernate.engine.JoinSequence;
 import org.hibernate.engine.ParameterBinder;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.hql.QueryTranslator;
 import org.hibernate.hql.antlr.HqlSqlBaseWalker;
 import org.hibernate.hql.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.antlr.HqlTokenTypes;
 import org.hibernate.hql.antlr.SqlTokenTypes;
 import org.hibernate.hql.ast.tree.AggregateNode;
 import org.hibernate.hql.ast.tree.AssignmentSpecification;
 import org.hibernate.hql.ast.tree.CollectionFunction;
 import org.hibernate.hql.ast.tree.ConstructorNode;
 import org.hibernate.hql.ast.tree.DeleteStatement;
 import org.hibernate.hql.ast.tree.DotNode;
 import org.hibernate.hql.ast.tree.FromClause;
 import org.hibernate.hql.ast.tree.FromElement;
 import org.hibernate.hql.ast.tree.FromReferenceNode;
 import org.hibernate.hql.ast.tree.IdentNode;
 import org.hibernate.hql.ast.tree.IndexNode;
 import org.hibernate.hql.ast.tree.InsertStatement;
 import org.hibernate.hql.ast.tree.IntoClause;
 import org.hibernate.hql.ast.tree.MethodNode;
 import org.hibernate.hql.ast.tree.ParameterNode;
 import org.hibernate.hql.ast.tree.QueryNode;
 import org.hibernate.hql.ast.tree.ResolvableNode;
 import org.hibernate.hql.ast.tree.RestrictableStatement;
 import org.hibernate.hql.ast.tree.ResultVariableRefNode;
 import org.hibernate.hql.ast.tree.SelectClause;
 import org.hibernate.hql.ast.tree.SelectExpression;
 import org.hibernate.hql.ast.tree.UpdateStatement;
 import org.hibernate.hql.ast.tree.OperatorNode;
 import org.hibernate.hql.ast.tree.ParameterContainer;
 import org.hibernate.hql.ast.tree.FromElementFactory;
 import org.hibernate.hql.ast.util.ASTPrinter;
 import org.hibernate.hql.ast.util.ASTUtil;
 import org.hibernate.hql.ast.util.AliasGenerator;
 import org.hibernate.hql.ast.util.JoinProcessor;
 import org.hibernate.hql.ast.util.LiteralProcessor;
 import org.hibernate.hql.ast.util.SessionFactoryHelper;
 import org.hibernate.hql.ast.util.SyntheticAndFactory;
 import org.hibernate.hql.ast.util.NodeTraverser;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.PostInsertIdentifierGenerator;
 import org.hibernate.id.SequenceGenerator;
 import org.hibernate.param.NamedParameterSpecification;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.param.PositionalParameterSpecification;
 import org.hibernate.param.VersionTypeSeedParameterSpecification;
 import org.hibernate.param.CollectionFilterKeyParameterSpecification;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 import org.hibernate.type.DbTimestampType;
 import org.hibernate.type.ComponentType;
 import org.hibernate.usertype.UserVersionType;
 import org.hibernate.util.ArrayHelper;
 import org.hibernate.util.StringHelper;
 
 import antlr.ASTFactory;
 import antlr.RecognitionException;
 import antlr.SemanticException;
 import antlr.collections.AST;
 
 /**
  * Implements methods used by the HQL->SQL tree transform grammar (a.k.a. the second phase).
  * <ul>
  * <li>Isolates the Hibernate API-specific code from the ANTLR generated code.</li>
- * <li>Handles the SQL framgents generated by the persisters in order to create the SELECT and FROM clauses,
+ * <li>Handles the SQL fragments generated by the persisters in order to create the SELECT and FROM clauses,
  * taking into account the joins and projections that are implied by the mappings (persister/queryable).</li>
  * <li>Uses SqlASTFactory to create customized AST nodes.</li>
  * </ul>
  *
  * @see SqlASTFactory
  */
 public class HqlSqlWalker extends HqlSqlBaseWalker implements ErrorReporter, ParameterBinder.NamedParameterSource {
 	private static final Logger log = LoggerFactory.getLogger( HqlSqlWalker.class );
+	private final boolean trace = log.isTraceEnabled();
 
 	private final QueryTranslatorImpl queryTranslatorImpl;
 	private final HqlParser hqlParser;
 	private final SessionFactoryHelper sessionFactoryHelper;
 	private final Map tokenReplacements;
 	private final AliasGenerator aliasGenerator = new AliasGenerator();
 	private final LiteralProcessor literalProcessor;
 	private final ParseErrorHandler parseErrorHandler;
 	private final ASTPrinter printer;
 	private final String collectionFilterRole;
 
 	private FromClause currentFromClause = null;
 	private SelectClause selectClause;
 
 	/**
 	 * Maps each top-level result variable to its SelectExpression;
 	 * (excludes result variables defined in subqueries)
 	 **/
 	private Map<String, SelectExpression> selectExpressionsByResultVariable = new HashMap();
 
 	private Set querySpaces = new HashSet();
 
 	private int parameterCount;
 	private Map namedParameters = new HashMap();
 	private ArrayList parameters = new ArrayList();
 	private int numberOfParametersInSetClause;
 	private int positionalParameterCount;
 
 	private ArrayList assignmentSpecifications = new ArrayList();
 
 	private int impliedJoinType;
 
 	/**
 	 * Create a new tree transformer.
 	 *
 	 * @param qti Back pointer to the query translator implementation that is using this tree transform.
 	 * @param sfi The session factory implementor where the Hibernate mappings can be found.
 	 * @param parser A reference to the phase-1 parser
 	 * @param tokenReplacements Registers the token replacement map with the walker.  This map will
 	 * be used to substitute function names and constants.
 	 * @param collectionRole The collection role name of the collection used as the basis for the
 	 * filter, NULL if this is not a collection filter compilation.
 	 */
 	public HqlSqlWalker(
 			QueryTranslatorImpl qti,
 			SessionFactoryImplementor sfi,
 			HqlParser parser,
 			Map tokenReplacements,
 			String collectionRole) {
 		setASTFactory( new SqlASTFactory( this ) );
 		// Initialize the error handling delegate.
 		this.parseErrorHandler = new ErrorCounter();
 		this.queryTranslatorImpl = qti;
 		this.sessionFactoryHelper = new SessionFactoryHelper( sfi );
 		this.literalProcessor = new LiteralProcessor( this );
 		this.tokenReplacements = tokenReplacements;
 		this.collectionFilterRole = collectionRole;
 		this.hqlParser = parser;
 		this.printer = new ASTPrinter( SqlTokenTypes.class );
 	}
 
 
 	// handle trace logging ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-    private int traceDepth = 0;
+	private int traceDepth = 0;
 
 	public void traceIn(String ruleName, AST tree) {
-		if ( inputState.guessing > 0 ) {
-			return;
+		if (trace) {
+			if ( inputState.guessing > 0 ) {
+				return;
+			}
+			String prefix = StringHelper.repeat( '-', (traceDepth++ * 2) ) + "-> ";
+			String traceText = ruleName + " (" + buildTraceNodeName(tree) + ")";
+			log.trace( prefix + traceText );
 		}
-		String prefix = StringHelper.repeat( '-', (traceDepth++ * 2) ) + "-> ";
-		String traceText = ruleName + " (" + buildTraceNodeName(tree) + ")";
-		log.trace( prefix + traceText );
 	}
 
 	private String buildTraceNodeName(AST tree) {
 		return tree == null
 				? "???"
 				: tree.getText() + " [" + printer.getTokenTypeName( tree.getType() ) + "]";
 	}
 
 	public void traceOut(String ruleName, AST tree) {
-		if ( inputState.guessing > 0 ) {
-			return;
+		if (trace) {
+			if ( inputState.guessing > 0 ) {
+				return;
+			}
+			String prefix = "<-" + StringHelper.repeat( '-', (--traceDepth * 2) ) + " ";
+			log.trace( prefix + ruleName );
 		}
-		String prefix = "<-" + StringHelper.repeat( '-', (--traceDepth * 2) ) + " ";
-		log.trace( prefix + ruleName );
 	}
 
 
 	protected void prepareFromClauseInputTree(AST fromClauseInput) {
 		if ( !isSubQuery() ) {
 //			// inject param specifications to account for dynamic filter param values
 //			if ( ! getEnabledFilters().isEmpty() ) {
 //				Iterator filterItr = getEnabledFilters().values().iterator();
 //				while ( filterItr.hasNext() ) {
 //					FilterImpl filter = ( FilterImpl ) filterItr.next();
 //					if ( ! filter.getFilterDefinition().getParameterNames().isEmpty() ) {
 //						Iterator paramItr = filter.getFilterDefinition().getParameterNames().iterator();
 //						while ( paramItr.hasNext() ) {
 //							String parameterName = ( String ) paramItr.next();
 //							// currently param filters *only* work with single-column parameter types;
 //							// if that limitation is ever lifted, this logic will need to change to account for that
 //							ParameterNode collectionFilterKeyParameter = ( ParameterNode ) astFactory.create( PARAM, "?" );
 //							DynamicFilterParameterSpecification paramSpec = new DynamicFilterParameterSpecification(
 //									filter.getName(),
 //									parameterName,
 //									filter.getFilterDefinition().getParameterType( parameterName ),
 //									 positionalParameterCount++
 //							);
 //							collectionFilterKeyParameter.setHqlParameterSpecification( paramSpec );
 //							parameters.add( paramSpec );
 //						}
 //					}
 //				}
 //			}
 
 			if ( isFilter() ) {
 				// Handle collection-fiter compilation.
 				// IMPORTANT NOTE: This is modifying the INPUT (HQL) tree, not the output tree!
 				QueryableCollection persister = sessionFactoryHelper.getCollectionPersister( collectionFilterRole );
 				Type collectionElementType = persister.getElementType();
 				if ( !collectionElementType.isEntityType() ) {
 					throw new QueryException( "collection of values in filter: this" );
 				}
 
 				String collectionElementEntityName = persister.getElementPersister().getEntityName();
 				ASTFactory inputAstFactory = hqlParser.getASTFactory();
 				AST fromElement = ASTUtil.create( inputAstFactory, HqlTokenTypes.FILTER_ENTITY, collectionElementEntityName );
 				ASTUtil.createSibling( inputAstFactory, HqlTokenTypes.ALIAS, "this", fromElement );
 				fromClauseInput.addChild( fromElement );
 				// Show the modified AST.
 				if ( log.isDebugEnabled() ) {
 					log.debug( "prepareFromClauseInputTree() : Filter - Added 'this' as a from element..." );
 				}
 				queryTranslatorImpl.showHqlAst( hqlParser.getAST() );
 
 				// Create a parameter specification for the collection filter...
 				Type collectionFilterKeyType = sessionFactoryHelper.requireQueryableCollection( collectionFilterRole ).getKeyType();
 				ParameterNode collectionFilterKeyParameter = ( ParameterNode ) astFactory.create( PARAM, "?" );
 				CollectionFilterKeyParameterSpecification collectionFilterKeyParameterSpec = new CollectionFilterKeyParameterSpecification(
 						collectionFilterRole, collectionFilterKeyType, positionalParameterCount++
 				);
 				collectionFilterKeyParameter.setHqlParameterSpecification( collectionFilterKeyParameterSpec );
 				parameters.add( collectionFilterKeyParameterSpec );
 			}
 		}
 	}
 
 	public boolean isFilter() {
 		return collectionFilterRole != null;
 	}
 
 	public String getCollectionFilterRole() {
 		return collectionFilterRole;
 	}
 
 	public SessionFactoryHelper getSessionFactoryHelper() {
 		return sessionFactoryHelper;
 	}
 
 	public Map getTokenReplacements() {
 		return tokenReplacements;
 	}
 
 	public AliasGenerator getAliasGenerator() {
 		return aliasGenerator;
 	}
 
 	public FromClause getCurrentFromClause() {
 		return currentFromClause;
 	}
 
 	public ParseErrorHandler getParseErrorHandler() {
 		return parseErrorHandler;
 	}
 
 	public void reportError(RecognitionException e) {
 		parseErrorHandler.reportError( e ); // Use the delegate.
 	}
 
 	public void reportError(String s) {
 		parseErrorHandler.reportError( s ); // Use the delegate.
 	}
 
 	public void reportWarning(String s) {
 		parseErrorHandler.reportWarning( s );
 	}
 
 	/**
 	 * Returns the set of unique query spaces (a.k.a.
 	 * table names) that occurred in the query.
 	 *
 	 * @return A set of table names (Strings).
 	 */
 	public Set getQuerySpaces() {
 		return querySpaces;
 	}
 
 	protected AST createFromElement(String path, AST alias, AST propertyFetch) throws SemanticException {
 		FromElement fromElement = currentFromClause.addFromElement( path, alias );
 		fromElement.setAllPropertyFetch(propertyFetch!=null);
 		return fromElement;
 	}
 
 	protected AST createFromFilterElement(AST filterEntity, AST alias) throws SemanticException {
 		FromElement fromElement = currentFromClause.addFromElement( filterEntity.getText(), alias );
 		FromClause fromClause = fromElement.getFromClause();
 		QueryableCollection persister = sessionFactoryHelper.getCollectionPersister( collectionFilterRole );
 		// Get the names of the columns used to link between the collection
 		// owner and the collection elements.
 		String[] keyColumnNames = persister.getKeyColumnNames();
 		String fkTableAlias = persister.isOneToMany()
 				? fromElement.getTableAlias()
 				: fromClause.getAliasGenerator().createName( collectionFilterRole );
 		JoinSequence join = sessionFactoryHelper.createJoinSequence();
 		join.setRoot( persister, fkTableAlias );
 		if ( !persister.isOneToMany() ) {
 			join.addJoin( ( AssociationType ) persister.getElementType(),
 					fromElement.getTableAlias(),
 					JoinFragment.INNER_JOIN,
 					persister.getElementColumnNames( fkTableAlias ) );
 		}
 		join.addCondition( fkTableAlias, keyColumnNames, " = ?" );
 		fromElement.setJoinSequence( join );
 		fromElement.setFilter( true );
 		if ( log.isDebugEnabled() ) {
 			log.debug( "createFromFilterElement() : processed filter FROM element." );
 		}
 		return fromElement;
 	}
 
 	protected void createFromJoinElement(
 	        AST path,
 	        AST alias,
 	        int joinType,
 	        AST fetchNode,
 	        AST propertyFetch,
 	        AST with) throws SemanticException {
 		boolean fetch = fetchNode != null;
 		if ( fetch && isSubQuery() ) {
 			throw new QueryException( "fetch not allowed in subquery from-elements" );
 		}
 		// The path AST should be a DotNode, and it should have been evaluated already.
 		if ( path.getType() != SqlTokenTypes.DOT ) {
 			throw new SemanticException( "Path expected for join!" );
 		}
 		DotNode dot = ( DotNode ) path;
 		int hibernateJoinType = JoinProcessor.toHibernateJoinType( joinType );
 		dot.setJoinType( hibernateJoinType );	// Tell the dot node about the join type.
 		dot.setFetch( fetch );
 		// Generate an explicit join for the root dot node.   The implied joins will be collected and passed up
 		// to the root dot node.
 		dot.resolve( true, false, alias == null ? null : alias.getText() );
 
 		final FromElement fromElement;
 		if ( dot.getDataType() != null && dot.getDataType().isComponentType() ) {
 			FromElementFactory factory = new FromElementFactory( 
 					getCurrentFromClause(),
 					dot.getLhs().getFromElement(),
 					dot.getPropertyPath(),
 					alias == null ? null : alias.getText(),
 					null,
 					false
 			);
 			fromElement = factory.createComponentJoin( (ComponentType) dot.getDataType() );
 		}
 		else {
 			fromElement = dot.getImpliedJoin();
 			fromElement.setAllPropertyFetch( propertyFetch != null );
 
 			if ( with != null ) {
 				if ( fetch ) {
 					throw new SemanticException( "with-clause not allowed on fetched associations; use filters" );
 				}
 				handleWithFragment( fromElement, with );
 			}
 		}
 
 		if ( log.isDebugEnabled() ) {
 			log.debug( "createFromJoinElement() : " + getASTPrinter().showAsString( fromElement, "-- join tree --" ) );
 		}
 	}
 	private void handleWithFragment(FromElement fromElement, AST hqlWithNode) throws SemanticException {
 		try {
 			withClause( hqlWithNode );
 			AST hqlSqlWithNode = returnAST;
 			if ( log.isDebugEnabled() ) {
 				log.debug( "handleWithFragment() : " + getASTPrinter().showAsString( hqlSqlWithNode, "-- with clause --" ) );
 			}
 			WithClauseVisitor visitor = new WithClauseVisitor( fromElement );
 			NodeTraverser traverser = new NodeTraverser( visitor );
 			traverser.traverseDepthFirst( hqlSqlWithNode );
 
 			String withClauseJoinAlias = visitor.getJoinAlias();
 			if ( withClauseJoinAlias == null ) {
 				withClauseJoinAlias = fromElement.getCollectionTableAlias();
 			}
 			else {
 				FromElement referencedFromElement = visitor.getReferencedFromElement();
 				if ( referencedFromElement != fromElement ) {
 					throw new InvalidWithClauseException( "with-clause expressions did not reference from-clause element to which the with-clause was associated" );
 				}
 			}
 
 			SqlGenerator sql = new SqlGenerator( getSessionFactoryHelper().getFactory() );
 			sql.whereExpr( hqlSqlWithNode.getFirstChild() );
 
 			fromElement.setWithClauseFragment( withClauseJoinAlias, "(" + sql.getSQL() + ")" );
 		}
 		catch( SemanticException e ) {
 			throw e;
 		}
 		catch( InvalidWithClauseException e ) {
 			throw e;
 		}
 		catch ( Exception e) {
 			throw new SemanticException( e.getMessage() );
 		}
 	}
 
 	private static class WithClauseVisitor implements NodeTraverser.VisitationStrategy {
 		private final FromElement joinFragment;
 		private FromElement referencedFromElement;
 		private String joinAlias;
 
 		public WithClauseVisitor(FromElement fromElement) {
 			this.joinFragment = fromElement;
 		}
 
 		public void visit(AST node) {
 			// todo : currently expects that the individual with expressions apply to the same sql table join.
 			//      This may not be the case for joined-subclass where the property values
 			//      might be coming from different tables in the joined hierarchy.  At some
 			//      point we should expand this to support that capability.  However, that has
 			//      some difficulties:
 			//          1) the biggest is how to handle ORs when the individual comparisons are
 			//              linked to different sql joins.
 			//          2) here we would need to track each comparison individually, along with
 			//              the join alias to which it applies and then pass that information
 			//              back to the FromElement so it can pass it along to the JoinSequence
 			if ( node instanceof DotNode ) {
 				DotNode dotNode = ( DotNode ) node;
 				FromElement fromElement = dotNode.getFromElement();
 				if ( referencedFromElement != null ) {
 					if ( fromElement != referencedFromElement ) {
 						throw new HibernateException( "with-clause referenced two different from-clause elements" );
 					}
 				}
 				else {
 					referencedFromElement = fromElement;
 					joinAlias = extractAppliedAlias( dotNode );
 					// todo : temporary
 					//      needed because currently persister is the one that
 					//      creates and renders the join fragments for inheritence
 					//      hierarchies...
 					if ( !joinAlias.equals( referencedFromElement.getTableAlias() ) ) {
 						throw new InvalidWithClauseException( "with clause can only reference columns in the driving table" );
 					}
 				}
 			}
 			else if ( node instanceof ParameterNode ) {
 				applyParameterSpecification( ( ( ParameterNode ) node ).getHqlParameterSpecification() );
 			}
 			else if ( node instanceof ParameterContainer ) {
 				applyParameterSpecifications( ( ParameterContainer ) node );
 			}
 		}
 
 		private void applyParameterSpecifications(ParameterContainer parameterContainer) {
 			if ( parameterContainer.hasEmbeddedParameters() ) {
 				ParameterSpecification[] specs = parameterContainer.getEmbeddedParameters();
 				for ( int i = 0; i < specs.length; i++ ) {
 					applyParameterSpecification( specs[i] );
 				}
 			}
 		}
 
 		private void applyParameterSpecification(ParameterSpecification paramSpec) {
 			joinFragment.addEmbeddedParameter( paramSpec );
 		}
 
 		private String extractAppliedAlias(DotNode dotNode) {
 			return dotNode.getText().substring( 0, dotNode.getText().indexOf( '.' ) );
 		}
 
 		public FromElement getReferencedFromElement() {
 			return referencedFromElement;
 		}
 
 		public String getJoinAlias() {
 			return joinAlias;
 		}
 	}
 
 	/**
 	 * Sets the current 'FROM' context.
 	 *
 	 * @param fromNode      The new 'FROM' context.
 	 * @param inputFromNode The from node from the input AST.
 	 */
 	protected void pushFromClause(AST fromNode, AST inputFromNode) {
 		FromClause newFromClause = ( FromClause ) fromNode;
 		newFromClause.setParentFromClause( currentFromClause );
 		currentFromClause = newFromClause;
 	}
 
 	/**
 	 * Returns to the previous 'FROM' context.
 	 */
 	private void popFromClause() {
 		currentFromClause = currentFromClause.getParentFromClause();
 	}
 
 	protected void lookupAlias(AST aliasRef)
 			throws SemanticException {
 		FromElement alias = currentFromClause.getFromElement( aliasRef.getText() );
 		FromReferenceNode aliasRefNode = ( FromReferenceNode ) aliasRef;
 		aliasRefNode.setFromElement( alias );
 	}
 
 	protected void setImpliedJoinType(int joinType) {
 		impliedJoinType = JoinProcessor.toHibernateJoinType( joinType );
 	}
 
 	public int getImpliedJoinType() {
 		return impliedJoinType;
 	}
 
 	protected AST lookupProperty(AST dot, boolean root, boolean inSelect) throws SemanticException {
 		DotNode dotNode = ( DotNode ) dot;
 		FromReferenceNode lhs = dotNode.getLhs();
 		AST rhs = lhs.getNextSibling();
 		switch ( rhs.getType() ) {
 			case SqlTokenTypes.ELEMENTS:
 			case SqlTokenTypes.INDICES:
 				if ( log.isDebugEnabled() ) {
 					log.debug( "lookupProperty() " + dotNode.getPath() + " => " + rhs.getText() + "(" + lhs.getPath() + ")" );
 				}
 				CollectionFunction f = ( CollectionFunction ) rhs;
 				// Re-arrange the tree so that the collection function is the root and the lhs is the path.
 				f.setFirstChild( lhs );
 				lhs.setNextSibling( null );
 				dotNode.setFirstChild( f );
 				resolve( lhs );			// Don't forget to resolve the argument!
 				f.resolve( inSelect );	// Resolve the collection function now.
 				return f;
 			default:
 				// Resolve everything up to this dot, but don't resolve the placeholders yet.
 				dotNode.resolveFirstChild();
 				return dotNode;
 		}
 	}
 
 	protected boolean isNonQualifiedPropertyRef(AST ident) {
 		final String identText = ident.getText();
 		if ( currentFromClause.isFromElementAlias( identText ) ) {
 			return false;
 		}
 
 		List fromElements = currentFromClause.getExplicitFromElements();
 		if ( fromElements.size() == 1 ) {
 			final FromElement fromElement = ( FromElement ) fromElements.get( 0 );
 			try {
-				log.trace( "attempting to resolve property [" + identText + "] as a non-qualified ref" );
+				if (trace) log.trace( "attempting to resolve property [" + identText + "] as a non-qualified ref" );
 				return fromElement.getPropertyMapping( identText ).toType( identText ) != null;
 			}
 			catch( QueryException e ) {
 				// Should mean that no such property was found
 			}
 		}
 
 		return false;
 	}
 
 	protected AST lookupNonQualifiedProperty(AST property) throws SemanticException {
 		final FromElement fromElement = ( FromElement ) currentFromClause.getExplicitFromElements().get( 0 );
 		AST syntheticDotNode = generateSyntheticDotNodeForNonQualifiedPropertyRef( property, fromElement );
 		return lookupProperty( syntheticDotNode, false, getCurrentClauseType() == HqlSqlTokenTypes.SELECT );
 	}
 
 	private AST generateSyntheticDotNodeForNonQualifiedPropertyRef(AST property, FromElement fromElement) {
 		AST dot = getASTFactory().create( DOT, "{non-qualified-property-ref}" );
 		// TODO : better way?!?
 		( ( DotNode ) dot ).setPropertyPath( ( ( FromReferenceNode ) property ).getPath() );
 
 		IdentNode syntheticAlias = ( IdentNode ) getASTFactory().create( IDENT, "{synthetic-alias}" );
 		syntheticAlias.setFromElement( fromElement );
 		syntheticAlias.setResolved();
 
 		dot.setFirstChild( syntheticAlias );
 		dot.addChild( property );
 
 		return dot;
 	}
 
 	protected void processQuery(AST select, AST query) throws SemanticException {
 		if ( log.isDebugEnabled() ) {
 			log.debug( "processQuery() : " + query.toStringTree() );
 		}
 
 		try {
 			QueryNode qn = ( QueryNode ) query;
 
 			// Was there an explicit select expression?
 			boolean explicitSelect = select != null && select.getNumberOfChildren() > 0;
 
 			if ( !explicitSelect ) {
 				// No explicit select expression; render the id and properties
 				// projection lists for every persister in the from clause into
 				// a single 'token node'.
 				//TODO: the only reason we need this stuff now is collection filters,
 				//      we should get rid of derived select clause completely!
 				createSelectClauseFromFromClause( qn );
 			}
 			else {
 				// Use the explicitly declared select expression; determine the
 				// return types indicated by each select token
 				useSelectClause( select );
 			}
 
 			// After that, process the JOINs.
 			// Invoke a delegate to do the work, as this is farily complex.
 			JoinProcessor joinProcessor = new JoinProcessor( this );
 			joinProcessor.processJoins( qn );
 
 			// Attach any mapping-defined "ORDER BY" fragments
 			Iterator itr = qn.getFromClause().getProjectionList().iterator();
 			while ( itr.hasNext() ) {
 				final FromElement fromElement = ( FromElement ) itr.next();
 //			if ( fromElement.isFetch() && fromElement.isCollectionJoin() ) {
 				if ( fromElement.isFetch() && fromElement.getQueryableCollection() != null ) {
 					// Does the collection referenced by this FromElement
 					// specify an order-by attribute?  If so, attach it to
 					// the query's order-by
 					if ( fromElement.getQueryableCollection().hasOrdering() ) {
 						String orderByFragment = fromElement
 								.getQueryableCollection()
 								.getSQLOrderByString( fromElement.getCollectionTableAlias() );
 						qn.getOrderByClause().addOrderFragment( orderByFragment );
 					}
 					if ( fromElement.getQueryableCollection().hasManyToManyOrdering() ) {
 						String orderByFragment = fromElement.getQueryableCollection()
 								.getManyToManyOrderByString( fromElement.getTableAlias() );
 						qn.getOrderByClause().addOrderFragment( orderByFragment );
 					}
 				}
 			}
 		}
 		finally {
 			popFromClause();
 		}
 	}
 
 	protected void postProcessDML(RestrictableStatement statement) throws SemanticException {
 		statement.getFromClause().resolve();
 
 		FromElement fromElement = ( FromElement ) statement.getFromClause().getFromElements().get( 0 );
 		Queryable persister = fromElement.getQueryable();
 		// Make #@%$^#^&# sure no alias is applied to the table name
 		fromElement.setText( persister.getTableName() );
 
 //		// append any filter fragments; the EMPTY_MAP is used under the assumption that
 //		// currently enabled filters should not affect this process
 //		if ( persister.getDiscriminatorType() != null ) {
 //			new SyntheticAndFactory( getASTFactory() ).addDiscriminatorWhereFragment(
 //			        statement,
 //			        persister,
 //			        java.util.Collections.EMPTY_MAP,
 //			        fromElement.getTableAlias()
 //			);
 //		}
 		if ( persister.getDiscriminatorType() != null || ! queryTranslatorImpl.getEnabledFilters().isEmpty() ) {
 			new SyntheticAndFactory( this ).addDiscriminatorWhereFragment(
 			        statement,
 			        persister,
 			        queryTranslatorImpl.getEnabledFilters(),
 			        fromElement.getTableAlias()
 			);
 		}
 
 	}
 
 	protected void postProcessUpdate(AST update) throws SemanticException {
 		UpdateStatement updateStatement = ( UpdateStatement ) update;
 
 		postProcessDML( updateStatement );
 	}
 
 	protected void postProcessDelete(AST delete) throws SemanticException {
 		postProcessDML( ( DeleteStatement ) delete );
 	}
 
 	public static boolean supportsIdGenWithBulkInsertion(IdentifierGenerator generator) {
 		return SequenceGenerator.class.isAssignableFrom( generator.getClass() )
 		        || PostInsertIdentifierGenerator.class.isAssignableFrom( generator.getClass() );
 	}
 
 	protected void postProcessInsert(AST insert) throws SemanticException, QueryException {
 		InsertStatement insertStatement = ( InsertStatement ) insert;
 		insertStatement.validate();
 
 		SelectClause selectClause = insertStatement.getSelectClause();
 		Queryable persister = insertStatement.getIntoClause().getQueryable();
 
 		if ( !insertStatement.getIntoClause().isExplicitIdInsertion() ) {
 			// We need to generate ids as part of this bulk insert.
 			//
 			// Note that this is only supported for sequence-style generators and
 			// post-insert-style generators; basically, only in-db generators
 			IdentifierGenerator generator = persister.getIdentifierGenerator();
 			if ( !supportsIdGenWithBulkInsertion( generator ) ) {
 				throw new QueryException( "can only generate ids as part of bulk insert with either sequence or post-insert style generators" );
 			}
 
 			AST idSelectExprNode = null;
 
 			if ( SequenceGenerator.class.isAssignableFrom( generator.getClass() ) ) {
 				String seqName = ( String ) ( ( SequenceGenerator ) generator ).generatorKey();
 				String nextval = sessionFactoryHelper.getFactory().getDialect().getSelectSequenceNextValString( seqName );
 				idSelectExprNode = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, nextval );
 			}
 			else {
 				//Don't need this, because we should never ever be selecting no columns in an insert ... select...
 				//and because it causes a bug on DB2
 				/*String idInsertString = sessionFactoryHelper.getFactory().getDialect().getIdentityInsertString();
 				if ( idInsertString != null ) {
 					idSelectExprNode = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, idInsertString );
 				}*/
 			}
 
 			if ( idSelectExprNode != null ) {
 				AST currentFirstSelectExprNode = selectClause.getFirstChild();
 				selectClause.setFirstChild( idSelectExprNode );
 				idSelectExprNode.setNextSibling( currentFirstSelectExprNode );
 
 				insertStatement.getIntoClause().prependIdColumnSpec();
 			}
 		}
 
 		final boolean includeVersionProperty = persister.isVersioned() &&
 				!insertStatement.getIntoClause().isExplicitVersionInsertion() &&
 				persister.isVersionPropertyInsertable();
 		if ( includeVersionProperty ) {
 			// We need to seed the version value as part of this bulk insert
 			VersionType versionType = persister.getVersionType();
 			AST versionValueNode = null;
 
 			if ( sessionFactoryHelper.getFactory().getDialect().supportsParametersInInsertSelect() ) {
 				int sqlTypes[] = versionType.sqlTypes( sessionFactoryHelper.getFactory() );
 				if ( sqlTypes == null || sqlTypes.length == 0 ) {
 					throw new IllegalStateException( versionType.getClass() + ".sqlTypes() returns null or empty array" );
 				}
 				if ( sqlTypes.length > 1 ) {
 					throw new IllegalStateException(
 							versionType.getClass() +
 									".sqlTypes() returns > 1 element; only single-valued versions are allowed."
 					);
 				}
 				versionValueNode = getASTFactory().create( HqlSqlTokenTypes.PARAM, "?" );
 				ParameterSpecification paramSpec = new VersionTypeSeedParameterSpecification( versionType );
 				( ( ParameterNode ) versionValueNode ).setHqlParameterSpecification( paramSpec );
 				parameters.add( 0, paramSpec );
 
 				if ( sessionFactoryHelper.getFactory().getDialect().requiresCastingOfParametersInSelectClause() ) {
 					// we need to wrtap the param in a cast()
 					MethodNode versionMethodNode = ( MethodNode ) getASTFactory().create( HqlSqlTokenTypes.METHOD_CALL, "(" );
 					AST methodIdentNode = getASTFactory().create( HqlSqlTokenTypes.IDENT, "cast" );
 					versionMethodNode.addChild( methodIdentNode );
 					versionMethodNode.initializeMethodNode(methodIdentNode, true );
 					AST castExprListNode = getASTFactory().create( HqlSqlTokenTypes.EXPR_LIST, "exprList" );
 					methodIdentNode.setNextSibling( castExprListNode );
 					castExprListNode.addChild( versionValueNode );
 					versionValueNode.setNextSibling(
 							getASTFactory().create(
 									HqlSqlTokenTypes.IDENT,
 									sessionFactoryHelper.getFactory().getDialect().getTypeName( sqlTypes[0] ) )
 					);
 					processFunction( versionMethodNode, true );
 					versionValueNode = versionMethodNode;
 				}
 			}
 			else {
 				if ( isIntegral( versionType ) ) {
 					try {
 						Object seedValue = versionType.seed( null );
 						versionValueNode = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, seedValue.toString() );
 					}
 					catch( Throwable t ) {
 						throw new QueryException( "could not determine seed value for version on bulk insert [" + versionType + "]" );
 					}
 				}
 				else if ( isDatabaseGeneratedTimestamp( versionType ) ) {
 					String functionName = sessionFactoryHelper.getFactory().getDialect().getCurrentTimestampSQLFunctionName();
 					versionValueNode = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, functionName );
 				}
 				else {
 					throw new QueryException( "cannot handle version type [" + versionType + "] on bulk inserts with dialects not supporting parameters in insert-select statements" );
 				}
 			}
 
 			AST currentFirstSelectExprNode = selectClause.getFirstChild();
 			selectClause.setFirstChild( versionValueNode );
 			versionValueNode.setNextSibling( currentFirstSelectExprNode );
 
 			insertStatement.getIntoClause().prependVersionColumnSpec();
 		}
 
 		if ( insertStatement.getIntoClause().isDiscriminated() ) {
 			String sqlValue = insertStatement.getIntoClause().getQueryable().getDiscriminatorSQLValue();
 			AST discrimValue = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, sqlValue );
 			insertStatement.getSelectClause().addChild( discrimValue );
 		}
 
 	}
 
 	private boolean isDatabaseGeneratedTimestamp(Type type) {
 		// currently only the Hibernate-supplied DbTimestampType is supported here
 		return DbTimestampType.class.isAssignableFrom( type.getClass() );
 	}
 
 	private boolean isIntegral(Type type) {
 		return Long.class.isAssignableFrom( type.getReturnedClass() )
 		       || Integer.class.isAssignableFrom( type.getReturnedClass() )
 		       || long.class.isAssignableFrom( type.getReturnedClass() )
 		       || int.class.isAssignableFrom( type.getReturnedClass() );
 	}
 
 	private void useSelectClause(AST select) throws SemanticException {
 		selectClause = ( SelectClause ) select;
 		selectClause.initializeExplicitSelectClause( currentFromClause );
 	}
 
 	private void createSelectClauseFromFromClause(QueryNode qn) throws SemanticException {
 		AST select = astFactory.create( SELECT_CLAUSE, "{derived select clause}" );
 		AST sibling = qn.getFromClause();
 		qn.setFirstChild( select );
 		select.setNextSibling( sibling );
 		selectClause = ( SelectClause ) select;
 		selectClause.initializeDerivedSelectClause( currentFromClause );
 		if ( log.isDebugEnabled() ) {
 			log.debug( "Derived SELECT clause created." );
 		}
 	}
 
 	protected void resolve(AST node) throws SemanticException {
 		if ( node != null ) {
 			// This is called when it's time to fully resolve a path expression.
 			ResolvableNode r = ( ResolvableNode ) node;
 			if ( isInFunctionCall() ) {
 				r.resolveInFunctionCall( false, true );
 			}
 			else {
 				r.resolve( false, true );	// Generate implicit joins, only if necessary.
 			}
 		}
 	}
 
 	protected void resolveSelectExpression(AST node) throws SemanticException {
 		// This is called when it's time to fully resolve a path expression.
 		int type = node.getType();
 		switch ( type ) {
 			case DOT: {
 				DotNode dot = ( DotNode ) node;
 				dot.resolveSelectExpression();
 				break;
 			}
 			case ALIAS_REF: {
 				// Notify the FROM element that it is being referenced by the select.
 				FromReferenceNode aliasRefNode = ( FromReferenceNode ) node;
 				//aliasRefNode.resolve( false, false, aliasRefNode.getText() ); //TODO: is it kosher to do it here?
 				aliasRefNode.resolve( false, false ); //TODO: is it kosher to do it here?
 				FromElement fromElement = aliasRefNode.getFromElement();
 				if ( fromElement != null ) {
 					fromElement.setIncludeSubclasses( true );
 				}
 				break;
 			}
 			default: {
 				break;
 			}
 		}
 	}
 
 	protected void beforeSelectClause() throws SemanticException {
 		// Turn off includeSubclasses on all FromElements.
 		FromClause from = getCurrentFromClause();
 		List fromElements = from.getFromElements();
 		for ( Iterator iterator = fromElements.iterator(); iterator.hasNext(); ) {
 			FromElement fromElement = ( FromElement ) iterator.next();
 			fromElement.setIncludeSubclasses( false );
 		}
 	}
 
 	protected AST generatePositionalParameter(AST inputNode) throws SemanticException {
 		if ( namedParameters.size() > 0 ) {
 			throw new SemanticException( "cannot define positional parameter after any named parameters have been defined" );
 		}
 		ParameterNode parameter = ( ParameterNode ) astFactory.create( PARAM, "?" );
 		PositionalParameterSpecification paramSpec = new PositionalParameterSpecification(
 				inputNode.getLine(),
 		        inputNode.getColumn(),
 				positionalParameterCount++
 		);
 		parameter.setHqlParameterSpecification( paramSpec );
 		parameters.add( paramSpec );
 		return parameter;
 	}
 
 	protected AST generateNamedParameter(AST delimiterNode, AST nameNode) throws SemanticException {
 		String name = nameNode.getText();
 		trackNamedParameterPositions( name );
 
 		// create the node initially with the param name so that it shows
 		// appropriately in the "original text" attribute
 		ParameterNode parameter = ( ParameterNode ) astFactory.create( NAMED_PARAM, name );
 		parameter.setText( "?" );
 
 		NamedParameterSpecification paramSpec = new NamedParameterSpecification(
 				delimiterNode.getLine(),
 		        delimiterNode.getColumn(),
 				name
 		);
 		parameter.setHqlParameterSpecification( paramSpec );
 		parameters.add( paramSpec );
 		return parameter;
 	}
 
 	private void trackNamedParameterPositions(String name) {
 		Integer loc = new Integer( parameterCount++ );
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			namedParameters.put( name, loc );
 		}
 		else if ( o instanceof Integer ) {
 			ArrayList list = new ArrayList( 4 );
 			list.add( o );
 			list.add( loc );
 			namedParameters.put( name, list );
 		}
 		else {
 			( ( ArrayList ) o ).add( loc );
 		}
 	}
 
 	protected void processConstant(AST constant) throws SemanticException {
 		literalProcessor.processConstant( constant, true );  // Use the delegate, resolve identifiers as FROM element aliases.
 	}
 
 	protected void processBoolean(AST constant) throws SemanticException {
 		literalProcessor.processBoolean( constant );  // Use the delegate.
 	}
 
 	protected void processNumericLiteral(AST literal) {
 		literalProcessor.processNumeric( literal );
 	}
 
 	protected void processIndex(AST indexOp) throws SemanticException {
 		IndexNode indexNode = ( IndexNode ) indexOp;
 		indexNode.resolve( true, true );
 	}
 
 	protected void processFunction(AST functionCall, boolean inSelect) throws SemanticException {
 		MethodNode methodNode = ( MethodNode ) functionCall;
 		methodNode.resolve( inSelect );
 	}
 
 	protected void processAggregation(AST node, boolean inSelect) throws SemanticException {
 		AggregateNode aggregateNode = ( AggregateNode ) node;
 		aggregateNode.resolve();
 	}
 
 	protected void processConstructor(AST constructor) throws SemanticException {
 		ConstructorNode constructorNode = ( ConstructorNode ) constructor;
 		constructorNode.prepare();
 	}
 
     protected void setAlias(AST selectExpr, AST ident) {
         ((SelectExpression) selectExpr).setAlias(ident.getText());
 		// only put the alias (i.e., result variable) in selectExpressionsByResultVariable
 		// if is not defined in a subquery.
 		if ( ! isSubQuery() ) {
 			selectExpressionsByResultVariable.put( ident.getText(), ( SelectExpression ) selectExpr );
 		}
     }
 
 	protected boolean isOrderExpressionResultVariableRef(AST orderExpressionNode) throws SemanticException {
 		// ORDER BY is not supported in a subquery
 		// TODO: should an exception be thrown if an ORDER BY is in a subquery?
 		if ( ! isSubQuery() &&
 				orderExpressionNode.getType() == IDENT &&
 				selectExpressionsByResultVariable.containsKey( orderExpressionNode.getText() ) ) {
 			return true;
 		}
 		return false;
 	}
 
 	protected void handleResultVariableRef(AST resultVariableRef) throws SemanticException {
 		if ( isSubQuery() ) {
 			throw new SemanticException(
 					"References to result variables in subqueries are not supported."
 			);
 		}
 		( ( ResultVariableRefNode ) resultVariableRef ).setSelectExpression(
 				selectExpressionsByResultVariable.get( resultVariableRef.getText() )
 		);
 	}
 	
 	/**
 	 * Returns the locations of all occurrences of the named parameter.
 	 */
 	public int[] getNamedParameterLocations(String name) throws QueryException {
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			QueryException qe = new QueryException( QueryTranslator.ERROR_NAMED_PARAMETER_DOES_NOT_APPEAR + name );
 			qe.setQueryString( queryTranslatorImpl.getQueryString() );
 			throw qe;
 		}
 		if ( o instanceof Integer ) {
 			return new int[]{( ( Integer ) o ).intValue()};
 		}
 		else {
 			return ArrayHelper.toIntArray( ( ArrayList ) o );
 		}
 	}
 
 	public void addQuerySpaces(Serializable[] spaces) {
 		querySpaces.addAll( Arrays.asList( spaces ) );
 	}
 
 	public Type[] getReturnTypes() {
 		return selectClause.getQueryReturnTypes();
 	}
 
 	public String[] getReturnAliases() {
 		return selectClause.getQueryReturnAliases();
 	}
 
 	public SelectClause getSelectClause() {
 		return selectClause;
 	}
 	
 	public FromClause getFinalFromClause() {
 		FromClause top = currentFromClause;
 		while ( top.getParentFromClause() != null ) {
 			top = top.getParentFromClause();
 		}
 		return top;
 	}
 
 	public boolean isShallowQuery() {
 		// select clauses for insert statements should alwasy be treated as shallow
 		return getStatementType() == INSERT || queryTranslatorImpl.isShallowQuery();
 	}
 
 	public Map getEnabledFilters() {
 		return queryTranslatorImpl.getEnabledFilters();
 	}
 
 	public LiteralProcessor getLiteralProcessor() {
 		return literalProcessor;
 	}
 
 	public ASTPrinter getASTPrinter() {
 		return printer;
 	}
 
 	public ArrayList getParameters() {
 		return parameters;
 	}
 
 	public int getNumberOfParametersInSetClause() {
 		return numberOfParametersInSetClause;
 	}
 
 	protected void evaluateAssignment(AST eq) throws SemanticException {
 		prepareLogicOperator( eq );
 		Queryable persister = getCurrentFromClause().getFromElement().getQueryable();
 		evaluateAssignment( eq, persister, -1 );
 	}
 
 	private void evaluateAssignment(AST eq, Queryable persister, int targetIndex) {
 		if ( persister.isMultiTable() ) {
 			// no need to even collect this information if the persister is considered multi-table
 			AssignmentSpecification specification = new AssignmentSpecification( eq, persister );
 			if ( targetIndex >= 0 ) {
 				assignmentSpecifications.add( targetIndex, specification );
 			}
 			else {
 				assignmentSpecifications.add( specification );
 			}
 			numberOfParametersInSetClause += specification.getParameters().length;
 		}
 	}
 
 	public ArrayList getAssignmentSpecifications() {
 		return assignmentSpecifications;
 	}
 
 	protected AST createIntoClause(String path, AST propertySpec) throws SemanticException {
 		Queryable persister = ( Queryable ) getSessionFactoryHelper().requireClassPersister( path );
 
 		IntoClause intoClause = ( IntoClause ) getASTFactory().create( INTO, persister.getEntityName() );
 		intoClause.setFirstChild( propertySpec );
 		intoClause.initialize( persister );
 
 		addQuerySpaces( persister.getQuerySpaces() );
 
 		return intoClause;
 	}
 
 	protected void prepareVersioned(AST updateNode, AST versioned) throws SemanticException {
 		UpdateStatement updateStatement = ( UpdateStatement ) updateNode;
 		FromClause fromClause = updateStatement.getFromClause();
 		if ( versioned != null ) {
 			// Make sure that the persister is versioned
 			Queryable persister = fromClause.getFromElement().getQueryable();
 			if ( !persister.isVersioned() ) {
 				throw new SemanticException( "increment option specified for update of non-versioned entity" );
 			}
 
 			VersionType versionType = persister.getVersionType();
 			if ( versionType instanceof UserVersionType ) {
 				throw new SemanticException( "user-defined version types not supported for increment option" );
 			}
 
 			AST eq = getASTFactory().create( HqlSqlTokenTypes.EQ, "=" );
 			AST versionPropertyNode = generateVersionPropertyNode( persister );
 
 			eq.setFirstChild( versionPropertyNode );
 
 			AST versionIncrementNode = null;
 			if ( isTimestampBasedVersion( versionType ) ) {
 				versionIncrementNode = getASTFactory().create( HqlSqlTokenTypes.PARAM, "?" );
 				ParameterSpecification paramSpec = new VersionTypeSeedParameterSpecification( versionType );
 				( ( ParameterNode ) versionIncrementNode ).setHqlParameterSpecification( paramSpec );
 				parameters.add( 0, paramSpec );
 			}
 			else {
 				// Not possible to simply re-use the versionPropertyNode here as it causes
 				// OOM errors due to circularity :(
 				versionIncrementNode = getASTFactory().create( HqlSqlTokenTypes.PLUS, "+" );
 				versionIncrementNode.setFirstChild( generateVersionPropertyNode( persister ) );
 				versionIncrementNode.addChild( getASTFactory().create( HqlSqlTokenTypes.IDENT, "1" ) );
 			}
 
 			eq.addChild( versionIncrementNode );
 
 			evaluateAssignment( eq, persister, 0 );
 
 			AST setClause = updateStatement.getSetClause();
 			AST currentFirstSetElement = setClause.getFirstChild();
 			setClause.setFirstChild( eq );
 			eq.setNextSibling( currentFirstSetElement );
 		}
 	}
 
 	private boolean isTimestampBasedVersion(VersionType versionType) {
 		final Class javaType = versionType.getReturnedClass();
 		return Date.class.isAssignableFrom( javaType )
 				|| Calendar.class.isAssignableFrom( javaType );
 	}
 
 	private AST generateVersionPropertyNode(Queryable persister) throws SemanticException {
 		String versionPropertyName = persister.getPropertyNames()[ persister.getVersionProperty() ];
 		AST versionPropertyRef = getASTFactory().create( HqlSqlTokenTypes.IDENT, versionPropertyName );
 		AST versionPropertyNode = lookupNonQualifiedProperty( versionPropertyRef );
 		resolve( versionPropertyNode );
 		return versionPropertyNode;
 	}
 
 	protected void prepareLogicOperator(AST operator) throws SemanticException {
 		( ( OperatorNode ) operator ).initialize();
 	}
 
 	protected void prepareArithmeticOperator(AST operator) throws SemanticException {
 		( ( OperatorNode ) operator ).initialize();
 	}
 
 	protected void validateMapPropertyExpression(AST node) throws SemanticException {
 		try {
 			FromReferenceNode fromReferenceNode = (FromReferenceNode) node;
 			QueryableCollection collectionPersister = fromReferenceNode.getFromElement().getQueryableCollection();
 			if ( ! Map.class.isAssignableFrom( collectionPersister.getCollectionType().getReturnedClass() ) ) {
 				throw new SemanticException( "node did not reference a map" );
 			}
 		}
 		catch ( SemanticException se ) {
 			throw se;
 		}
 		catch ( Throwable t ) {
 			throw new SemanticException( "node did not reference a map" );
 		}
 	}
 
 	public static void panic() {
 		throw new QueryException( "TreeWalker: panic" );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/ast/SqlGenerator.java b/hibernate-core/src/main/java/org/hibernate/hql/ast/SqlGenerator.java
index 27872ff3e1..1fcb4495dd 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/ast/SqlGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/ast/SqlGenerator.java
@@ -1,360 +1,363 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.ast;
 
 import java.util.ArrayList;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Arrays;
 
 import antlr.RecognitionException;
 import antlr.collections.AST;
 import org.hibernate.QueryException;
 import org.hibernate.hql.ast.tree.FunctionNode;
-import org.hibernate.hql.ast.tree.SqlNode;
 import org.hibernate.type.Type;
 import org.hibernate.util.StringHelper;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.hql.antlr.SqlGeneratorBase;
 import org.hibernate.hql.antlr.SqlTokenTypes;
-import org.hibernate.hql.ast.tree.MethodNode;
 import org.hibernate.hql.ast.tree.FromElement;
 import org.hibernate.hql.ast.tree.Node;
 import org.hibernate.hql.ast.tree.ParameterNode;
 import org.hibernate.hql.ast.tree.ParameterContainer;
 import org.hibernate.hql.ast.util.ASTPrinter;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
  * Generates SQL by overriding callback methods in the base class, which does
  * the actual SQL AST walking.
  *
  * @author Joshua Davis
  * @author Steve Ebersole
  */
 public class SqlGenerator extends SqlGeneratorBase implements ErrorReporter {
 	private static final Logger log = LoggerFactory.getLogger( SqlGenerator.class );
+	private final boolean trace = log.isTraceEnabled();
 
 	public static boolean REGRESSION_STYLE_CROSS_JOINS = false;
 
 	/**
 	 * all append invocations on the buf should go through this Output instance variable.
-	 * The value of this variable may be temporarily substitued by sql function processing code
+	 * The value of this variable may be temporarily substituted by sql function processing code
 	 * to catch generated arguments.
-	 * This is because sql function templates need arguments as seperate string chunks
+	 * This is because sql function templates need arguments as separate string chunks
 	 * that will be assembled into the target dialect-specific function call.
 	 */
 	private SqlWriter writer = new DefaultWriter();
 
 	private ParseErrorHandler parseErrorHandler;
 	private SessionFactoryImplementor sessionFactory;
 	private LinkedList<SqlWriter> outputStack = new LinkedList<SqlWriter>();
 	private final ASTPrinter printer = new ASTPrinter( SqlTokenTypes.class );
 	private List collectedParameters = new ArrayList();
 
 
 	// handle trace logging ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-    private int traceDepth = 0;
+	private int traceDepth = 0;
 
 	public void traceIn(String ruleName, AST tree) {
-		if ( inputState.guessing > 0 ) {
-			return;
+		if (trace) {
+			if ( inputState.guessing > 0 ) {
+				return;
+			}
+			String prefix = StringHelper.repeat( '-', (traceDepth++ * 2) ) + "-> ";
+			String traceText = ruleName + " (" + buildTraceNodeName(tree) + ")";
+			log.trace( prefix + traceText );
 		}
-		String prefix = StringHelper.repeat( '-', (traceDepth++ * 2) ) + "-> ";
-		String traceText = ruleName + " (" + buildTraceNodeName(tree) + ")";
-		log.trace( prefix + traceText );
 	}
 
 	private String buildTraceNodeName(AST tree) {
 		return tree == null
 				? "???"
 				: tree.getText() + " [" + printer.getTokenTypeName( tree.getType() ) + "]";
 	}
 
 	public void traceOut(String ruleName, AST tree) {
-		if ( inputState.guessing > 0 ) {
-			return;
+		if (trace) {
+			if ( inputState.guessing > 0 ) {
+				return;
+			}
+			String prefix = "<-" + StringHelper.repeat( '-', (--traceDepth * 2) ) + " ";
+			log.trace( prefix + ruleName );
 		}
-		String prefix = "<-" + StringHelper.repeat( '-', (--traceDepth * 2) ) + " ";
-		log.trace( prefix + ruleName );
 	}
 
 	public List getCollectedParameters() {
 		return collectedParameters;
 	}
 
 	protected void out(String s) {
 		writer.clause( s );
 	}
 
 	protected void out(AST n) {
 		if ( n instanceof Node ) {
 			out( ( ( Node ) n ).getRenderText( sessionFactory ) );
 		}
 		else {
 			super.out( n );
 		}
 
 		if ( n instanceof ParameterNode ) {
 			collectedParameters.add( ( ( ParameterNode ) n ).getHqlParameterSpecification() );
 		}
 		else if ( n instanceof ParameterContainer ) {
 			if ( ( ( ParameterContainer ) n ).hasEmbeddedParameters() ) {
 				ParameterSpecification[] specifications = ( ( ParameterContainer ) n ).getEmbeddedParameters();
 				if ( specifications != null ) {
 					collectedParameters.addAll( Arrays.asList( specifications ) );
 				}
 			}
 		}
 	}
 
 	protected void commaBetweenParameters(String comma) {
 		writer.commaBetweenParameters( comma );
 	}
 
 	public void reportError(RecognitionException e) {
 		parseErrorHandler.reportError( e ); // Use the delegate.
 	}
 
 	public void reportError(String s) {
 		parseErrorHandler.reportError( s ); // Use the delegate.
 	}
 
 	public void reportWarning(String s) {
 		parseErrorHandler.reportWarning( s );
 	}
 
 	public ParseErrorHandler getParseErrorHandler() {
 		return parseErrorHandler;
 	}
 
 	public SqlGenerator(SessionFactoryImplementor sfi) {
 		super();
 		parseErrorHandler = new ErrorCounter();
 		sessionFactory = sfi;
 	}
 
 	public String getSQL() {
 		return getStringBuffer().toString();
 	}
 
 	protected void optionalSpace() {
 		int c = getLastChar();
 		switch ( c ) {
 			case -1:
 				return;
 			case ' ':
 				return;
 			case ')':
 				return;
 			case '(':
 				return;
 			default:
 				out( " " );
 		}
 	}
 
 	protected void beginFunctionTemplate(AST node, AST nameNode) {
 		// NOTE for AGGREGATE both nodes are the same; for METHOD the first is the METHOD, the second is the
 		// 		METHOD_NAME
 		FunctionNode functionNode = ( FunctionNode ) node;
 		SQLFunction sqlFunction = functionNode.getSQLFunction();
 		if ( sqlFunction == null ) {
 			// if SQLFunction is null we just write the function out as it appears in the hql statement
 			super.beginFunctionTemplate( node, nameNode );
 		}
 		else {
 			// this function has a registered SQLFunction -> redirect output and catch the arguments
 			outputStack.addFirst( writer );
 			writer = new FunctionArguments();
 		}
 	}
 
 	protected void endFunctionTemplate(AST node) {
 		FunctionNode functionNode = ( FunctionNode ) node;
 		SQLFunction sqlFunction = functionNode.getSQLFunction();
 		if ( sqlFunction == null ) {
 			super.endFunctionTemplate( node );
 		}
 		else {
 			final Type functionType = functionNode.getFirstArgumentType();
 			// this function has a registered SQLFunction -> redirect output and catch the arguments
 			FunctionArguments functionArguments = ( FunctionArguments ) writer;
 			writer = outputStack.removeFirst();
 			out( sqlFunction.render( functionType, functionArguments.getArgs(), sessionFactory ) );
 		}
 	}
 
 	// --- Inner classes (moved here from sql-gen.g) ---
 
 	/**
 	 * Writes SQL fragments.
 	 */
 	interface SqlWriter {
 		void clause(String clause);
 
 		/**
 		 * todo remove this hack
 		 * The parameter is either ", " or " , ". This is needed to pass sql generating tests as the old
 		 * sql generator uses " , " in the WHERE and ", " in SELECT.
 		 *
 		 * @param comma either " , " or ", "
 		 */
 		void commaBetweenParameters(String comma);
 	}
 
 	/**
 	 * SQL function processing code redirects generated SQL output to an instance of this class
 	 * which catches function arguments.
 	 */
 	class FunctionArguments implements SqlWriter {
 		private int argInd;
 		private final List<String> args = new ArrayList<String>(3);
 
 		public void clause(String clause) {
 			if ( argInd == args.size() ) {
 				args.add( clause );
 			}
 			else {
 				args.set( argInd, args.get( argInd ) + clause );
 			}
 		}
 
 		public void commaBetweenParameters(String comma) {
 			++argInd;
 		}
 
 		public List getArgs() {
 			return args;
 		}
 	}
 
 	/**
 	 * The default SQL writer.
 	 */
 	class DefaultWriter implements SqlWriter {
 		public void clause(String clause) {
 			getStringBuffer().append( clause );
 		}
 
 		public void commaBetweenParameters(String comma) {
 			getStringBuffer().append( comma );
 		}
 	}
 
     public static void panic() {
 		throw new QueryException( "TreeWalker: panic" );
 	}
 
 	protected void fromFragmentSeparator(AST a) {
 		// check two "adjecent" nodes at the top of the from-clause tree
 		AST next = a.getNextSibling();
 		if ( next == null || !hasText( a ) ) {
 			return;
 		}
 
 		FromElement left = ( FromElement ) a;
 		FromElement right = ( FromElement ) next;
 
 		///////////////////////////////////////////////////////////////////////
 		// HACK ALERT !!!!!!!!!!!!!!!!!!!!!!!!!!!!
 		// Attempt to work around "ghost" ImpliedFromElements that occasionally
 		// show up between the actual things being joined.  This consistently
 		// occurs from index nodes (at least against many-to-many).  Not sure
 		// if there are other conditions
 		//
 		// Essentially, look-ahead to the next FromElement that actually
 		// writes something to the SQL
 		while ( right != null && !hasText( right ) ) {
 			right = ( FromElement ) right.getNextSibling();
 		}
 		if ( right == null ) {
 			return;
 		}
 		///////////////////////////////////////////////////////////////////////
 
 		if ( !hasText( right ) ) {
 			return;
 		}
 
 		if ( right.getRealOrigin() == left ||
 		     ( right.getRealOrigin() != null && right.getRealOrigin() == left.getRealOrigin() ) ) {
 			// right represents a joins originating from left; or
 			// both right and left reprersent joins originating from the same FromElement
 			if ( right.getJoinSequence() != null && right.getJoinSequence().isThetaStyle() ) {
 				writeCrossJoinSeparator();
 			}
 			else {
 				out( " " );
 			}
 		}
 		else {
 			// these are just two unrelated table references
 			writeCrossJoinSeparator();
 		}
 	}
 
 	private void writeCrossJoinSeparator() {
 		if ( REGRESSION_STYLE_CROSS_JOINS ) {
 			out( ", " );
 		}
 		else {
 			out( sessionFactory.getDialect().getCrossJoinSeparator() );
 		}
 	}
 
 	protected void nestedFromFragment(AST d, AST parent) {
 		// check a set of parent/child nodes in the from-clause tree
 		// to determine if a comma is required between them
 		if ( d != null && hasText( d ) ) {
 			if ( parent != null && hasText( parent ) ) {
 				// again, both should be FromElements
 				FromElement left = ( FromElement ) parent;
 				FromElement right = ( FromElement ) d;
 				if ( right.getRealOrigin() == left ) {
 					// right represents a joins originating from left...
 					if ( right.getJoinSequence() != null && right.getJoinSequence().isThetaStyle() ) {
 						out( ", " );
 					}
 					else {
 						out( " " );
 					}
 				}
 				else {
 					// not so sure this is even valid subtree.  but if it was, it'd
 					// represent two unrelated table references...
 					out( ", " );
 				}
 			}
 			out( d );
 		}
 	}
 
 }
