diff --git a/changelog.txt b/changelog.txt
index 0fc28e8fac..c9e8a736a9 100644
--- a/changelog.txt
+++ b/changelog.txt
@@ -1,1286 +1,1286 @@
 Hibernate Changelog
 ===================
 Note: Newer entries are automatically generated and the description might not
 match the actual issue resolution (i.e. a bug might not be a bug). Please
 refer to the particular case on JIRA using the issue tracking number to learn
 more about each case.
 
 Changes in version 4.0.0.Alpha2 (2011.04.06)
 ------------------------------------------------------------------------------------------------------------------------
 
 ** Bug
     * [HHH-4999] - createSQLQuery(query).list() result screw up when when columns in different tables have same name
     * [HHH-5803] - Better handling of implicit literal numeric expression typing
     * [HHH-5940] - @MapKeyJoinColumns always throws an exception
     * [HHH-5989] - Add tests of JPA-style transaction joining
     * [HHH-5996] - Wire in JdbcServices into SchemaUpdateTask, SchemaExportTask,  SchemaValidatorTask, HibernateService.dropSchema(), HibernateService.createSchema()
     * [HHH-6001] - Add a top-level directory inside the release bundle archives
     * [HHH-6002] - Use today's year when building copyright footer for aggregated javadocs
     * [HHH-6028] - Remove o.h.classic stuff
     * [HHH-6057] - hibernate.cfg.xml references wrong hbm.xml files and doesn't include reference to DTD file
     * [HHH-6058] - Error in mapping file in Event.hbm.xml file for documentation in download
     * [HHH-6061] - ValidatoryFactory type checking
     * [HHH-6076] - query with setFirstResult throws Exception on derby
 
 ** Improvement
     * [HHH-2680] - Blobs not updated on Session.merge() for detached instances
     * [HHH-2860] - Consolidate Session creation options/parameters
     * [HHH-4362] - @RowId
     * [HHH-5244] - Flesh out H2Dialect temp table support
     * [HHH-5284] - Allow Type to dictate the default length/scale/precision
     * [HHH-5562] - Introduce a locator pattern for integrators to be able to leverage to more easily integrate with Hibernate
     * [HHH-5947] - Improve error message, documentation and tests on @UniqueConstraint
     * [HHH-5993] - Expose SessionFactoryObserver to Hibernate EntityManager configuration
     * [HHH-6053] - Create an interface for centralizing the contract that is shared between Session and StatelessSession
 
 ** New Feature
     * [HHH-5697] - Support for multi-tenancy
 
 ** Patch
     * [HHH-3646] - implement Criteria API querying of collection-of-component (David Mansfield)
     * [HHH-5348] - support for TypedQuery jpaql/hql "scalar" queries
 
 ** Task
     * [HHH-5650] - Pull documentation building into 'release' module
     * [HHH-5682] - Modify service infrastructure to leverage CDI annotations
     * [HHH-5683] - Create Weld-specific ServiceRegistry
     * [HHH-5913] - Implement set of event listeners as a service
     * [HHH-5942] - Migrate to JUnit 4
     * [HHH-5966] - Finish up loose ends for overriding a SqlTypeDescriptor
     * [HHH-6010] - Remove duplication in code involving Work and ReturningWork
     * [HHH-6013] - Consolidate on single JTA impl for testing
     * [HHH-6015] - Investigate hibernate-infinispan test failures since migration to JUnit4
     * [HHH-6016] - Migrate version injection plugin to Gradle
     * [HHH-6025] - Remove cglib dependencies
     * [HHH-6026] - Migrate bytecode provider integrations to api/spi/internal split
     * [HHH-6027] - Migrate o.h.action pakcage to api/spi/internal split
     * [HHH-6033] - Migrate stats to api/spi/internal split
     * [HHH-6036] - integration documentation generation
     * [HHH-6038] - Migrate to use newly separated gradle-upload-auth-plugin
     * [HHH-6047] - allow nesting of ServiceRegistry
     * [HHH-6050] - Remove direct compile-time dependencies to slf4j from build
     * [HHH-6051] - Create a SessionFactory scoped ServiceRegistry
     * [HHH-6052] - Make statistics a service
     * [HHH-6073] - Dialects cannot use the Thread Context ClassLoader with AS7, please change to use the
     * [HHH-6081] - Finish up Integrator
     * [HHH-6088] - Move to slf4j-log4j12 for test logging
 
 
 Changes in version 4.0.0.Alpha1 (2011.03.09)
 ------------------------------------------------------------------------------------------------------------------------
 http://opensource.atlassian.com/projects/hibernate/browse/HHH/fixforversion/11161
 
 ** Sub-task
     * [HHH-5662] - Import the initial work
     * [HHH-5765] - Wire in JdbcServices
     * [HHH-5949] - Migrate, complete and integrate TransactionFactory as a service
 
 ** Bug
     * [HHH-3873] - DB2Dialect.getLimitString raise DB2 error message when called with limit=0
     * [HHH-4646] - Inconsistent behavior with Audited and MappedSuperclass annotations
     * [HHH-5126] - JPA Query with InExpression and Collection_valued_input_parameter Complains About Bad Syntax
     * [HHH-5136] - map-key-column is broken
     * [HHH-5163] - ClassCastException when Hibernate tries to cache results using ResultTransformer
     * [HHH-5168] - DB2Dialect generates CROSS JOINs which aren't supported
     * [HHH-5177] - auditing a child of a mapped superclass forces auditing on siblings
     * [HHH-5280] - Exception on unidirectional collection whose elements are owned by several collection: "java.lang.IllegalArgumentException: object is not an instance of declaring class"
     * [HHH-5306] - Dialect resolution: Cannot set a custom dialect resolver programatically or using hibernate.cfg.xml
     * [HHH-5359] - Derived entity usecase fails when the association is bidirectional
     * [HHH-5590] - Don't log and rethrow exceptions in AbstractFlushingEventListener
     * [HHH-5599] - NPE occurs when using Infinispan as L2 Cache
     * [HHH-5669] - Fix gradle build issues with Infinispan 2LC
     * [HHH-5686] - Collections should be loaded by default using "lazy collection fetch" instead of "extra lazy collection" fetch
     * [HHH-5693] - Re-enable entitymanager tests
     * [HHH-5704] - New getSubString() handling in ClobProxy is incompatible with MySQL JDBC PS.setClob(int, Clob) for empty CLOB
     * [HHH-5706] - Incorrect accounting for 1-based LOB offsets
     * [HHH-5709] - JPA Metamodel: EntityType.getName != @Entity.name
     * [HHH-5710] - incorrect test logic of org.hibernate.test.readonly.ReadOnlyCriteriaQueryTest
     * [HHH-5717] - LockOptions not being set correctly
     * [HHH-5725] - SqlServerDialect should support SQL 2000 which does not support the row_number function
     * [HHH-5727] - Collection member declaration not handling optional AS in HQL.
     * [HHH-5729] - Only one check constraint is generated when @Min and @Max annotation is used on a single field
     * [HHH-5736] - Problem with "not" function of CriteriaBuilder
     * [HHH-5750] - Envers unset session on proxy
     * [HHH-5756] - Envers creates new revisions when only collection changed for entity
     * [HHH-5766] - New services are not wired into standalone SchemaExport, SchemaUpdate, and SchemaValidator
     * [HHH-5782] - Remove HibernateException and SQLException from ConnectionManager method signatures
     * [HHH-5783] - Transaction timeout should be applied by ConnectionManager, not LogicalConnection
     * [HHH-5791] - NullPointerException merging a transient entity with non-nullable properties that are null if insert is delayed and check_nullability is false
     * [HHH-5793] - Query and timestamp caches to use cluster cache loader to avoid behaving like sync repl caches
     * [HHH-5800] - Implement missing element-collection related xml in JPAOverridenAnnotationReader
     * [HHH-5807] - Weird characters in license headers lead to compilation errors with UTF-8 character set
     * [HHH-5817] - Passing char[] or byte[] to equal function of CriteriaBuilder throws java.lang.ClassCastException (Vyacheslav Dimitrov)
     * [HHH-5821] - JPA EntityType's (or ManagedType's) getSingularAttributes() returns the version attribute with isVersion set to false.
     * [HHH-5826] - org.hibernate.util.SerializationHelper#resolveClass never tries loader3
     * [HHH-5838] - Proxool connection pool should only close pools it opened
     * [HHH-5839] - non-utf8 characters in AuditReaderImpl
     * [HHH-5842] - Types.Binary column type should be registered as "binary($l) for HSQLDialect (Fred Toussi)
     * [HHH-5853] - Problem loading cachable collections defined with a property-ref key with a versioned owner
     * [HHH-5883] - @Lob annotated field throws MappingException
     * [HHH-5888] - CLONE: Problem using BLOB and CLOB fields in Oracle
     * [HHH-5889] - CLONE: Using materialized blobs with PostgreSQL causes error
     * [HHH-5890] - Parent POM: License comment in points to 404
     * [HHH-5893] - Tests fail for dialects that return null for empty LOBs
     * [HHH-5900] - Revert change to add upload repositiory authentication handling in build script
     * [HHH-5907] - derby does not support materialize a LOB locator outside the transaction in  which it was created
     * [HHH-5922] - Type overrides do not affect functions registered with the dialect
     * [HHH-5961] - Contextual LOB creator is used when the JDBC driver does not support JDBC4 Connection.createBlob()
     * [HHH-5982] - Flush checker logic bugs
     * [HHH-5983] - Entiy actions contain non-transient references to session and entity  causing inconsistencies after serialization
     * [HHH-5987] - Remove org.hibernate.ejb.CurrentEntityManagerImpl
     * [HHH-5994] - Inserts may be delayed because TransactionCoordinatorImpl.isTransactionInProgress() returns false for non-JTA transactions
     * [HHH-5995] - Compile error because Statement is undefined in SqlExceptionHelper
 
 ** Remove Feature
     * [HHH-5981] - Clarify Session.disconnect() and Session.reconnect() behavior
 
 ** Improvement
     * [HHH-3965] - Expose the ability to use varchar(max) or nvarchar(max)
     * [HHH-4539] - Make UPPER and LOWER work on MS SQL Server text and ntext columns
     * [HHH-5325] - Minor issues in test suite and suggestions for improvements (fixes HSQDB 2.0 failures)
     * [HHH-5588] - Improve support for entityNames - determine the entityName for a retrieved object v√≠a envers
     * [HHH-5655] - In Gradle build, better account for non-standard local maven repo cache locations
     * [HHH-5658] - Better .gitignore
     * [HHH-5701] - Add .metadata/* to .gitignore
     * [HHH-5724] - Improve the error message on Bean Validation exception by showing the constraint violation data
     * [HHH-5726] - SqlServer2005Dialect should support variable limit
     * [HHH-5761] - Update source repository links in Envers documentation
     * [HHH-5794] - Add support for additional orm.xml elements for Map handling and element collections
     * [HHH-5823] - Poor multithread performance in UpdateTimestampsCache class
     * [HHH-5824] - Poor multithread performance in SessionFactoryImpl.getQueryCache method
     * [HHH-5843] - Avoid useless branches during HQL parsing when trace logging is disabled
     * [HHH-5859] - Upgrade to Infinispan 4.2.1.CR1
     * [HHH-5904] - Deploy just testing artifacts from hibernate-core, not all tests
     * [HHH-5906] - Expose AbstractEntityPersister.getPropertyUniqueness() as public for OGM to use
     * [HHH-5943] - Make ServiceRegistry mutable
     * [HHH-5977] - Add tests for @JoinColumn using secondary table
     * [HHH-5986] - Refactor org.hibernate.util package for spi/internal split
     * [HHH-5993] - Expose SessionFactoryObserver to Hibernate EntityManager configuration
 
 ** New Feature
     * [HHH-2655] - SQLServer2005Dialect (ROW_NUMBER for Paging)
     * [HHH-5371] - Add support for REVEND_TSTMP which will enable SQL table partitioning by time
     * [HHH-5611] - Add management capability via JMX
     * [HHH-5687] - Extract SQL keywords from DatabaseMetaData
     * [HHH-5879] - Expose state from AbstractEntityPersister / Type / SessionFactoryImplementor  for OGM usage
     * [HHH-5898] - Improve authentication for Gradle uploads
     * [HHH-5916] - Add support for a programmatic way to define a default EntityPersister and CollectionPersister class implementation
     * [HHH-5957] - Provide a way for dialects to override a SqlTypeDescriptor
 
 ** Task
     * [HHH-5615] - Switch to JBoss logging
     * [HHH-5616] - Switch to Gradle for builds
     * [HHH-5617] - Migrate to Git for source control
     * [HHH-5618] - Support legacy ConnectionProvider names
     * [HHH-5619] - Support legacy TransactionFactory names
     * [HHH-5623] - Baseline on JDK 1.6
     * [HHH-5632] - Import initial services work
     * [HHH-5634] - Clean up stuff no longer needed
     * [HHH-5638] - Import JDBC batching service
     * [HHH-5639] - Import ConnectionProvider service
     * [HHH-5640] - Import DialectFactory and DialectResolver services
     * [HHH-5641] - Import JtaPlatform services
     * [HHH-5647] - Develop release process using Gradle
     * [HHH-5651] - Wire in new services in org.hibernate.service
     * [HHH-5656] - Import ServicesRegistry bootstrap code and service tests
     * [HHH-5714] - Upgrade metamodel generator dependency in entitymanager to 1.1.0.Final
     * [HHH-5768] - upgrade H2 version to 1.2.145 (was 1.2.140)
     * [HHH-5778] - Wire in new batch code
     * [HHH-5781] - Refactor code in org.hibernate.jdbc to spi/internal and remove obsolete code
     * [HHH-5788] - Move settings required by JdbcServices into JdbcSupport
     * [HHH-5880] - Gradle has to deploy testing artifacts
     * [HHH-5897] - Upgrade to Gradle 0.9.2
     * [HHH-5903] - Rename ServicesRegistry to ServiceRegistry
     * [HHH-5928] - Clean up compilation warnings
     * [HHH-5941] - Remove deprecated set(), nullSafeSet(), get(), nullSafeGet() methods and add SessionImplementer argument to UserType.nullSafeGet()/nullSafeSet()
     * [HHH-5985] - Remove TransactionHelper in preference of IsolationDelegate
     * [HHH-5990] - Remove non-maintained second level cache integrations
     * [HHH-5991] - Revist passing of ServiceRegistry to Configuration to build a SessionFactory
     * [HHH-6000] - split annotation processor execution out into separate tasks
 
 
 Changes in version 3.6.0.CR2 (2010.09.29)
 -------------------------------------------
 http://opensource.atlassian.com/projects/hibernate/browse/HHH/fixforversion/11131
 
 ** Bug
     * [HHH-892] - HQL parser does not resolve alias in ORDER BY clause
     * [HHH-2917] - Using subselects as operands for arithmetic operations causes NullPointerException
     * [HHH-4510] - Add column-level read/write support (HHH-4440) to annotations
     * [HHH-5490] - dirty data be inserted into 2L cache
     * [HHH-5552] - Infinispan listener implementations need to load entities and keys using application classloader.
     * [HHH-5563] - JndiInfinispanRegionFactory creates region with a stopped cache, if region previously existed
     * [HHH-5568] - correct wrong format in document
     * [HHH-5573] - Change TestCase to rebuildSessionFactory() whenever sessions var is accessed
     * [HHH-5590] - Don't log and rethrow exceptions in AbstractFlushingEventListener
     * [HHH-5591] - ConcurrentStatisticsImpl#queryExecuted() does not update queryExecutionMaxTimeQueryString
     * [HHH-5592] - org.hibernate.test.hql.ASTParserLoadingOrderByTest hangs on postgresql
     * [HHH-5593] - org.hibernate.test.legacy.FooBarTest.testCollectionWhere fails on hsqldb
     * [HHH-5594] - org.hibernate.test.jpa.lock.JPALockTest fails on hsqldb
     * [HHH-5595] - postgresql jdbc driver does not implement the setQueryTimeout method
     * [HHH-5596] - org.hibernate.test.annotations.onetoone.OneToOneTest.testPkOneToOneSelectStatementDoesNotGenerateExtraJoin() fails on postgresql
     * [HHH-5597] - org.hibernate.test.criteria.LikeTest.testLike fails on postgresql because of the default escape charactor
 
 ** Improvement
     * [HHH-5560] - Envers ValidAuditTimeStrategy needs a better name
     * [HHH-5589] - mysql does not support column check
 
 ** New Feature
     * [HHH-5190] - Provide annotation support for <discriminator>'s force and insert
     * [HHH-5205] - Add support for source="db" for timestamp versions
 
 ** Patch
     * [HHH-5581] - Improve InformixDialect sequence support
 
 
 Changes in version 3.6.0.CR1 (2010.09.15)
 -------------------------------------------
 http://opensource.atlassian.com/projects/hibernate/browse/HHH/fixforversion/11141
 
 ** Sub-task
     * [HHH-3766] - Modify the queries executed to use the "end-revision" column, when available
     * [HHH-5446] - Write an envers tutorial guide
     * [HHH-5499] - Extend AuditReader interface with findRevisions() method
 
 ** Bug
     * [HHH-5310] - orm_2_0.xsd compliant mapping files break in JEE use cases
     * [HHH-5356] - Sybase 15 does not support cross join
     * [HHH-5484] - org.hibernate.type.UUIDCharType incorrectly mapped to char and causes test fail due to the padding space
     * [HHH-5542] - Infinispan region factory uses same cache instance for all timestamp regions
     * [HHH-5545] - Resolve query cache results not up to date testsuite failures
 
 ** Improvement
     * [HHH-3709] - Add StartRevision/EndRevison fileds to audit tables
     * [HHH-5372] - Improve envers query performance by using new REVEND column
     * [HHH-5441] - Create "Getting Started Guide"
     * [HHH-5543] - JEE bootstrapping should only parse and validate mapping files once
     * [HHH-5557] - Sybase supports alias length upto 30 characters
     * [HHH-5564] - Upgrade to Infinispan 4.2.x
 
 ** Task
     * [HHH-5524] - Move tagRelease.sh into svn
 
 
 Changes in version 3.6.0.Beta4 (2010.09.01)
 -------------------------------------------
 http://opensource.atlassian.com/projects/hibernate/browse/HHH/fixforversion/11140
 
 ** Sub-task
     * [HHH-5442] - Write native tutorial chapter
     * [HHH-5444] - Write annotations tutorial chapter
     * [HHH-5445] - Write a jpa/entitymanager tutorial guide
     * [HHH-5462] - Write preface
     * [HHH-5463] - Write a community chapter
 
 ** Bug
     * [HHH-817] - Projection aliases should not be applied to where-clause (Milosz Tylenda)
     * [HHH-1189] - interfaces for Proxies are not regonized as interfaces
     * [HHH-3334] - Cascade-save breaks if parent ID is assigned (delays insert) and child has identity ID (early insert) (Wallace Wadge)
     * [HHH-5142] - Exception when initializing lazy @ManyToMany indexed collection containing not audited entities
     * [HHH-5225] - Cannot parse order-by fragment if it contains a registered function without parentheses
     * [HHH-5440] - Joined collection expressions not properly "rendered" in JPA Criteria queries
     * [HHH-5511] - Infinispan Region.destroy() impl should call cache.stop()
     * [HHH-5512] - JndiInfinispanRegionFactory shouldn't try to stop CacheManager
     * [HHH-5517] - Switch uuid generation in SessionFactory to org.hibernate.id.UUIDGenerator instead
     * [HHH-5519] - VersionedItem should not extend Item, otherwise query cache results are confusing
-    * [HHH-5520] - Per org.hibernate.cache.RegionFactory javadocs, implementors should be allowed to use no-arg constructor
+    * [HHH-5520] - Per org.hibernate.cache.spi.RegionFactory javadocs, implementors should be allowed to use no-arg constructor
 
 ** Deprecation
     * [HHH-5489] - Deprecate jbosscache as a second level cache provider, in favor of infinispan
 
 ** Improvement
     * [HHH-5427] - derby 10.6.1.0 native sequence support broken
     * [HHH-5507] - Add @MapKeyType annotation
     * [HHH-5509] - Leverage StandardBasicTypes internaly
     * [HHH-5515] - Upgrade to Infinispan 4.1.0.CR3
 
 ** Patch
     * [HHH-5197] - Envers documentation doesn't include the correct configuration when using Hibernate directly
     * [HHH-5453] - ByteCodeHelper.readByteCode won't load classes bigger than a constant size
 
 ** Task
     * [HHH-5502] - Upgrade to maven-jdocbook-plugin 2.3.2
     * [HHH-5505] - enable Sybase 15.5 in the test db profile
     * [HHH-5506] - rollback maven-jdocbook-plugin to 2.3.0
     * [HHH-5510] - Upgrade to maven-jdocbook-plugin 2.3.3
 
 
 Changes in version 3.6.0.Beta3 (2010.08.18)
 -------------------------------------------
 http://opensource.atlassian.com/projects/hibernate/browse/HHH/fixforversion/11133
 
 ** Sub-task
     * [HHH-5464] - Write a chapter about obtaining Hibernate
 
 ** Bug
     * [HHH-1643] - Sub-query as function parameter - either sub-query is missed from SQL or NullPointerException raised
     * [HHH-5180] - StandardQueryCache.get() does not handle EntityNotFoundException for natural key lookups
     * [HHH-5426] - HQL update/delete does not invalidate the query cache
     * [HHH-5449] - Versioned HQL update might issue incorrect SQL
     * [HHH-5469] - HHH-3659 is only half done, due to HHH-4989 (i.e. no HQL performance log when running Java 5)
     * [HHH-5473] - Default for CHECK_NULLABILITY does not allow merge retries
 
 ** Improvement
     * [HHH-5438] - Skip deployment of "irrelevant" modules
     * [HHH-5439] - Deployment of site.xml
     * [HHH-5474] - Clean up usages of now deprecated ExtendedMappings
     * [HHH-5477] - Introduce StandardBasicTypes for standard basic type constants
 
 ** Patch
     * [HHH-5300] - Configurable QueryPlanCache reference counts (Manuel Dominguez Sarmiento)
 
 ** Task
     * [HHH-5451] - deprecate cglib as bytecode provider
     * [HHH-5479] - Upgrade jDocBook plugin to 2.3.0
     * [HHH-5485] - Move hiberante dtd files from http://hibernate.sourceforge.net to http://www.hibernate.org/dtd
 
 
 Changes in version 3.6.0.Beta2 (2010.08.04)
 -------------------------------------------
 http://opensource.atlassian.com/projects/hibernate/browse/HHH/fixforversion/11132
 
 ** Bug
     * [HHH-2350] - 2nd level cache broken for non-inverse bidirectional one-to-many relation
     * [HHH-4011] - ChainedPropertyAccessor is not serializable, which breaks caching to disk and replicated caches.
     * [HHH-5097] - Bug in ParameterizedFunctionExpression with two or more parameters: IllegalArgumentException
     * [HHH-5296] - AbstractFromImpl::getJoin() shall return empty set, not null
     * [HHH-5355] - org.hibernate.test.id.uuid.sqlrep.sqlchar.UUIDCharTest errors with IngresDialect
     * [HHH-5400] - Binding BLOB values via byte[] (MaterializedBlobType) fails in 3.6 on MySQL
     * [HHH-5408] - Revise JPA compliance wording used in documentation according to Oracle policies
     * [HHH-5415] - org.hibernate.type.descriptor.java.DataHelper dumping "NClob not found" exception to stderr
     * [HHH-5425] - PropertyAccessException when caching results from a Query with a ResultTransformer that as 1 value per row
     * [HHH-5431] - Infinispan's CacheAdapterImpl.putAllowingTimeout not using silent flag
 
 ** Improvement
     * [HHH-2510] - override equals() and fix hashCode() in AliasToBeanResultTransformer
     * [HHH-5212] - Alter SQLFunction contract to be more flexible
     * [HHH-5283] - Add BasicType handling of java.net.URL
     * [HHH-5295] - Rendered JPAQL query shall be the same all the times, aliases shall not have random indexes
     * [HHH-5331] - Remove reflection calls on SessionFactory for JDK 1.5 detection in relation to Statistics
     * [HHH-5375] - Merge AnnotationConfiguration into Configuration
     * [HHH-5418] - Have Configuration delay parsing/binding of mappings until buildMappings() is called
     * [HHH-5420] - introducing new dialect for ms sql server 2008 with jdbc 3.0 and above
     * [HHH-5424] - ResultTransformer should only be set in the QueryKey if putting/getting data that is actually transformed
 
 ** New Feature
     * [HHH-3908] - Expose way to fully control fetching and result mapping on SQLQuery
     * [HHH-5423] - Provide a JBoss TS TransactionManagerLookup implementation for standalone (non JNDI) usage
 
 ** Patch
     * [HHH-5246] - Addition of withClause for DetachedCriteria (Shawn Clowater)
     * [HHH-5349] - CriteriaHQLAlignmentTest fails with an error running with the Ingres dialect
     * [HHH-5401] - Update to HHH-5381  HSQLDB new dialect (Fred Toussi)
     * [HHH-5435] - Add identity column support to the Ingres10Dialect
 
 ** Task
     * [HHH-5259] - Invalid reflection optimization configuration property name in Hibernate documentation.
     * [HHH-5416] - upgrade to h2 1.2.140
 
 
 Changes in version 3.6.0.Beta1 (2010.07.21)
 -------------------------------------------
 http://opensource.atlassian.com/projects/hibernate/browse/HHH/fixforversion/10941
 
 ** Sub-task
     * [HHH-3764] - Add the "end-revision" column when generating metadata
     * [HHH-3765] - Fill the "end revision" column with appropriate data in add/mod/del/collection work units
     * [HHH-5115] - Migrate Annotations documentation system to jdocbook's maven plugin (like core)
     * [HHH-5149] - Update "Basic O/R Mapping" (chapter 5) and "Collection Mapping" (chapter 6) of Core manual to use annotations
     * [HHH-5150] - Update settings section to reflect merge from Annotations and Core documentation
     * [HHH-5153] - Update Filters chapter to also show annotation configuration
     * [HHH-5155] - Move Additional modules chapter from Annotations to Core probably in Appendix
     * [HHH-5366] - Move annotations module tests into testsuite module
     * [HHH-5367] - Move annotations module sources into core module
     * [HHH-5379] - Update "Transitive persistence" (10.11) section to incorporate annotations
     * [HHH-5380] - Update "Cache mappings" (20.2.1) section to incorporate annotations
     * [HHH-5388] - Add @NamedQuery, @NamedNativeQuery, @SqlResultSetMapping, @Tuplizers and @FetchProfile to Core documentation
     * [HHH-5389] - Update custom CRUD chapter
 
 ** Bug
     * [HHH-2269] - Many-to-one cascade fails with TransientObjectException if the inverse collection is marked CascadeType.DELETE_ORPHAN
     * [HHH-2277] - bidirectional <key-many-to-one> both lazy=false fetch=join lead to infinite loop
     * [HHH-3001] - The NoopOptimizer is not thread safe
     * [HHH-3005] - DTD: map-key should allow nested type rather than attribute.
     * [HHH-3096] - COUNT DISTINCT operator with idenfication variable w/ composite primary key produces bad sql
     * [HHH-3377] - Update H2Dialect to use DECIMAL SQL type instead of NUMERIC
     * [HHH-3694] - ResultTransformer not used when scroll() is used on a named SQLQuery
     * [HHH-4036] - EntityMetamodel entityNameByInheritenceClassNameMap field used inconsistently
     * [HHH-4147] - Eager Bidirectional association with @ManyToOne in PK lead to infinite loop
     * [HHH-4156] - c3p0 is not used when only specific hibernate.c3p0.* properties
     * [HHH-4240] - SecondaryTables not recognized when using JOINED inheritance
     * [HHH-4250] - @ManyToOne - @OneToMany doesn't work with @Inheritance(strategy= InheritanceType.JOINED)
     * [HHH-4568] - Sybase - Test "BatchTest" fails due to "unexpected row count from update"
     * [HHH-4647] - Problems with @JoinColumn referencedColumnName and quoted column and table names
     * [HHH-4716] -  NotAuditedException using the entity name concept of hibernate.
     * [HHH-4773] - @CollectionId does not force the id column to not-null
     * [HHH-4957] - Criteria Projections.countDistinct() function broken
     * [HHH-4966] - Entity Manager bug with ParameterExpressionImpl
     * [HHH-4968] - Cannot deactivate default BeanValidationListener independently of DDL constraints generation (Vladimir Klyushnikov)
     * [HHH-4991] - ManyToMany table not joined due to max_fetch_depth parameter, results to SQL exceptions
     * [HHH-5006] - hibernate.globally_quoted_identifiers=true and Annotations tests
     * [HHH-5032] - Setting LockModeType.OPTIMISTIC_FORCE_INCREMENT defaults to only OPTIMISTIC
     * [HHH-5042] - TableGenerator does not increment hibernate_sequences.next_hi_value anymore after having exhausted the current lo-range
     * [HHH-5063] - Projections that have aliases same as the property name result in invalid sql
     * [HHH-5069] - Fix annotation documentation wrt setup
     * [HHH-5094] - PersistenceUtilHelper cannot access non-public fields/methods (it should be able to)
     * [HHH-5098] - AssertionFailure thrown when collection contains a parameterized type
     * [HHH-5109] - @OneToOne - too many joins
     * [HHH-5125] - The annotations @Entity and @MappedSuperclass used in one class produce a nullpointerexception
     * [HHH-5131] - SchemaExport drop fails if constraint names change
     * [HHH-5135] - "Ambiguous column" exception thrown with columns having the same name as a function registered with the dialect (e.g. to_date, floor)
     * [HHH-5173] - hql - average returns double but looses the decimal part
     * [HHH-5178] - Unit tests in org.hibernate.test.immutable fail on mssql and sybase due to keyword used for table and column name
     * [HHH-5191] - CollectionMetadataGenerator fails to obtain mappedBy attribute when is defined on superclasses
     * [HHH-5195] - FilterImpl.validate() throws NullPointerExeption on deserialization
     * [HHH-5204] - Introduce @RequiresDialectFeature annotation
     * [HHH-5207] - Unexpected exception occurs during refresh of a transient immutable business object.
     * [HHH-5208] - Oracle 11g R2 RAC - Test SequenceIdentityTest fails because first value of sequence is "2"
     * [HHH-5210] - Query Cache effective only after closing the session that created the cache
     * [HHH-5211] - no need to create a schema first when run this test org.hibernate.test.sql.hand.custom.db2.DB2CustomSQLTest
     * [HHH-5220] - Unit tests related to HHH-5063 and HHH-5135 fail on some dialects
     * [HHH-5230] - Regresion! @SequenceGenerator with allocationSize=1 fails Other allocationSizes appear to be decremented by 1
     * [HHH-5231] - Unit test failures lock up when they run on DB2 and PostgreSQL
     * [HHH-5233] - @FetchProfile fails to take more than one @FetchProfile.FetchOverride
     * [HHH-5253] - TableHiLoGenerator does not increment hi-value any more when lo-range es exhausted
     * [HHH-5258] - Persistence.isLoaded(Object, String) fails if the annotated property does not have a public getter or field
     * [HHH-5272] - Typo in tutorial at web site
     * [HHH-5286] - Jar Scanner instances cannot be passed to EntityManagerFactory creation method
     * [HHH-5288] - Envers auditReader.find() returns wrong data for embedded components using fields with default values
     * [HHH-5298] - @AuditMappedBy doesn't work on an inherited relation
     * [HHH-5315] - AuditJoinTable rows are no longer flushed to the database
     * [HHH-5318] - Wrong logic for RequiresDialectFeature in org.hibernate.test.annotations.HibernateTestCase
     * [HHH-5319] - Clean up data created in org.hibernate.test.annotations.onetomany.OneToManyTest#testUnidirectionalExplicit
     * [HHH-5322] - Regression in PersistenceUtilHelper
     * [HHH-5323] - correct jdbc driver version for testing
     * [HHH-5324] - Tests fail on mysql
     * [HHH-5329] - NoClassDefFoundError when using Hibernate 3.5 with J2SE 1.4 because of a wrong catch block
     * [HHH-5332] - JndiInfinispanRegionFactory cannot be instantiated
     * [HHH-5334] - PersistenceUtilHelpe.findMember(Class, String) private method doesn't work with members of a superclass
     * [HHH-5340] - Typo in tutorial at web site
     * [HHH-5370] - Building IN condition with CriteriaBuilder providing collection of values not working.
     * [HHH-5384] - HEM should not register its own Synchronization
     * [HHH-5395] - Fix the failing Lobs test
 
 ** Improvement
     * [HHH-3050] - Convert usage of Hibernate's FastHashMap to ConcurrentHashMap (Java 1.5)
     * [HHH-4945] - Replace all usages of EJB3TestCase with org.hibernate.ejb.test.TestCase
     * [HHH-5138] - Redesign types + introduce TypeRegistry & TypeResolver
     * [HHH-5144] - Dont restrict on jdk5 in hibernate core development
     * [HHH-5162] - Deprecate @Entity.mutable in favor of @Immutable
     * [HHH-5171] - Allow usage of standalone @JoinFormula annotation
     * [HHH-5182] - Inject SessionFactory into "non-basic" Types
     * [HHH-5217] - Minimize double sequence value reads in PooledOptimizer
     * [HHH-5218] - Provide a new "pooled value" based optimizer which interprets the database value as the low boundary instead of upper boundary
     * [HHH-5245] - Introduce LobHelper
     * [HHH-5248] - Introduce CompositeType interface (to replace AbstractComponentType interface)
     * [HHH-5251] - NativeSQLQueryReturn impls pre-cache a final hashcode based on non-final fields
     * [HHH-5252] - AttributeFactory needs more info in AssertionFailure
     * [HHH-5262] - Allow UserType and CompositeUserType to be registered with BasicTypeRegistry
     * [HHH-5268] - Support for java.util.UUID properties/generators
     * [HHH-5285] - Add support for CompositeUserType to implement org.hibernate.usertype.LoggableUserType
     * [HHH-5362] - Upgrade trunk to latest Infinispan 4.1
     * [HHH-5373] - Better account for SQLWarnings in temp table creation
 
 ** New Feature
     * [HHH-3579] - Support for PostgreSQL UUID data type
     * [HHH-3659] - statistics: Execution time of a query
     * [HHH-5260] - Allow query region name specific eviction settings
     * [HHH-5337] - Allow customization of "import.sql" file name and multi files import
 
 ** Patch
     * [HHH-1574] - AbstractEntityPersister.getNaturalIdentifierSnapshot doesn't work with many-to-one ids (Alex Burgel)
     * [HHH-2268] - Skip bridge methods during getter determination (JDK Bug 5062759)
     * [HHH-3220] - Patch to prevent "org.hibernate.AssertionFailure: possible non-threadsafe access to the session" error caused by stateless sessions
     * [HHH-5064] - OrderBy string getting dumped to console on session factory creation (Shawn Clowater)
     * [HHH-5078] - JPA criteria query numeric expressions produce wrong result (due to wrong bracketing)
     * [HHH-5147] - EnumType speed up in initEnumValues()
     * [HHH-5213] - Add native SQL Boolean type to Ingres10Dialect
     * [HHH-5336] - a few typo fixes
     * [HHH-5381] - HSQLDB new dialect (Fred Toussi)
 
 ** Task
     * [HHH-4868] - Upgrade to Javassist 3.12.0.GA
     * [HHH-5139] - Increase minimum language level from 1.4 to 1.5
     * [HHH-5145] - Update pom to use the new distributationManagement information
     * [HHH-5148] - Merge Hibernate Annotations reference documentation into Core
     * [HHH-5181] - Merge hibernate-annotations module code into hibernate-core
     * [HHH-5186] - update db profiles id and jdbc properties' name to use dballocator
     * [HHH-5200] - Prepare to use H2 as the default testing datbase
     * [HHH-5254] - Present document on Types as a separate chapter
     * [HHH-5281] - TypeSafeActivator should also generate constraints for @Length
     * [HHH-5294] - declare source files encoding to utf-8 to avoid maven warning
     * [HHH-5317] - Update Annotations and EM to use latest version of Hibernate Validator
     * [HHH-5357] - Rename hibernate-testing packages
     * [HHH-5358] - Merge jmx module back into core
     * [HHH-5365] - merge annotations module into core module
     * [HHH-5374] - Upgrade to H2 version 1.2.139
     * [HHH-5382] - Upgrade to slf4j 1.6
     * [HHH-5397] - Odds and ends from documentation merge
 
 
 
 Changes in version 3.5.1 (2010.04.14)
 -------------------------------------------
 http://opensource.atlassian.com/projects/hibernate/browse/HHH/fixforversion/11021
 
 ** Bug
     * [HHH-2809] - dialect changes: limit string
     * [HHH-3543] - method org.hibernate.transaction.JDBCTransaction.notifyLocalSynchsBeforeTransactionCompletion "swallows" all exceptions occured inside it
     * [HHH-4077] - Misuse of NamingStrategy and logical column names in HbmBinder
     * [HHH-4721] - Error in AuditSync.beforeCompletion() does not result in faillure of JDBCTransaction
     * [HHH-4912] - testManyToManyWithFormula induces error with Ingres dialect
     * [HHH-4938] - Multiple errors reported during legacy FooBarTest with Ingres
     * [HHH-4961] - org.hibernate.test.hql.ASTParserLoadingTest error running  testPaginationWithPolymorphicQuery with Ingres
     * [HHH-4965] - Implicit parameters abusively use TypeFactory.heuristicType losing UserType and XToOneType info
     * [HHH-4970] - org.hibernate.test.hql.ASTParserLoadingTest error running testComponentParameterBinding with Ingres
     * [HHH-4973] - org.hibernate.test.hql.ASTParserLoadingTest error running testSelectClauseSubselect with Ingres
     * [HHH-4976] - org.hibernate.test.hql.ASTParserLoadingTest error running testImplicitPolymorphism with Ingres
     * [HHH-4977] - org.hibernate.test.hql.ASTParserLoadingTest error running testOneToManyFilter with Ingres
     * [HHH-5045] - org.hibernate.test.hql.HQLTest failure running testConcatenation with Ingres
     * [HHH-5059] - callouts and programlistings with highlighting
     * [HHH-5082] - QueryException thrown when grouping by component
     * [HHH-5096] -  FetchingScrollableResultsImpl.last() does not move to the last result if cursor is after the last result
     * [HHH-5102] - Instances of a subclass can't be loaded
     * [HHH-5103] - Specifying the referencedColumnName in a @JoinColumn in backtics like `uid` fails
     * [HHH-5104] - EntityType.isEqual() test x equals x but should test x equals y  (Thierry-Dimitri Roy)
     * [HHH-5106] - UnsupportedOperationException on SQL named native queries when using the type-safe API
 
 ** Improvement
     * [HHH-3962] - Ingres Hibernate dialect for EAP 4.3.0 GA CP04
 
 ** Patch
     * [HHH-2470] - Use of session.createSQLQuery causes memory leak (Harry Mark and Michael Stevens)
     * [HHH-5003] - IngresDialect requires query substitutions for boolean values
     * [HHH-5076] - Multiple failures reported during ReadOnlyProxyTest with Ingres
 
 ** Task
     * [HHH-3997] - Build aggregated javadocs
     * [HHH-5083] - Align javadoc styles better with docbook / website
     * [HHH-5084] - Improve overview for aggregated javadocs
     * [HHH-5116] - Remove copyrighted fonts from annotations
 
 
 Changes in version 3.5.0-Final (2010.03.31)
 -------------------------------------------
 http://opensource.atlassian.com/projects/hibernate/browse/HHH/fixforversion/11022
 
 ** Sub-task
     * [HHH-4599] - An embeddable class may contain ToOne or ToMany associations
     * [HHH-4666] - Implement the clarified rules for resource discovery (esp for <mapping-file> and co)
     * [HHH-4691] - Validate all new concepts are supported in orm.xml
 
 ** Bug
     * [HHH-2088] - TypeMismatchException on object equality expression from one-to-one relationship
     * [HHH-2997] - LikeExpression case sensitive not working properly
     * [HHH-4784] - JDBCTransaction -> commit() -> notifyLocalSynchsBeforeTransactionCompletion()
     * [HHH-4870] - Cannot determine java-type from given member [null]
     * [HHH-4919] - DefaultMergeEventListener does not call Interceptor.instantiate() for a new persistent entity (Francesco Degrassi)
     * [HHH-4931] - two tests in org.hibernate.test.legacy.MultiTableTest fail on Ingres
     * [HHH-4946] - org.hibernate.test.legacy.FooBarTests testLimit failure with Ingres
     * [HHH-4958] - Immutable entity snapshot is retained after insert
     * [HHH-4972] - javax.persistence.query.timeout and javax.persistence.lock.timeout can be passed when creating an EMF
     * [HHH-4993] - Updates to read-only entity associations made while in persistent state are ignored by flush
     * [HHH-4998] - org.hibernate.test.hql.ASTParserLoadingTest failure running  testStr with Ingres
     * [HHH-5000] - duplicate words in the documents
     * [HHH-5010] - org.hibernate.test.hql.CriteriaHQLAlignmentTest.testCriteriaAggregationReturnType() needs call flush before do the query
     * [HHH-5013] - the previous select query should not to hold locks in TypeParameterTest#testSave
 
 ** Improvement
     * [HHH-1088] - Add support for projections using composite keys and components
     * [HHH-4374] - @Subselect
     * [HHH-4907] - Support for tuple syntax in HQL/Criteria on databases which do not support tuple syntax
     * [HHH-4940] - Document immutable/read-only entity and immutable collection functionality
     * [HHH-4989] - Make Statistics concurrent safe when Java 5 is present (Alex Snaps)
     * [HHH-5008] - Log query lock mode in EntityLoader constructor
     * [HHH-5022] - Small documentation improvements in chapter 6
 
 ** New Feature
     * [HHH-4812] - Add fetch profile support in annotations
     * [HHH-4994] - find(Class<T> entityClass, Object primaryKey, Map<String, Object> properties) and refresh(Object entity, Map<String, Object> properties) do not honor properties
     * [HHH-5026] - Ability to customize Scanner strategies
 
 ** Patch
     * [HHH-4419] -  <synchronize table="table_name"/> is missed using annotations
     * [HHH-5049] - org.hibernate.test.legacy.ParentChildTest error running testLoadAfterNonExists with Ingres
 
 ** Task
     * [HHH-4933] - Write documentation on JPA 2
     * [HHH-4990] - Move to commons-annotations 3.2.0.Final
     * [HHH-4995] - Update dependency versions for JPA 2 and Metamodel Generator
     * [HHH-4996] - Use monospace fonts in docbook programlistings
     * [HHH-5035] - upgrade to jdocbook 2.2.3
     * [HHH-5047] - Remove column coordinates from areaspecs
     * [HHH-5058] - Include hibernate-jpa-2.0-api (JPA 2 API) in release bundle
 
 
 Changes in version 3.5.0-CR-2 (2010.02.24)
 -------------------------------------------
 http://opensource.atlassian.com/projects/hibernate/browse/HHH/fixforversion/11011
 
 ** Sub-task
     * [HHH-4605] - Add support for @OneToMany @JoinColumn in XML
     * [HHH-4606] - Add support for @*ToOne @JoinTable in XML
     * [HHH-4662] - Implement javax.persistence.query.timeout
     * [HHH-4676] - Any interceptor exception (RTE) should mark the tx for rollback
     * [HHH-4765] - Enhance Dialect support for JPA-2 locking
 
 ** Bug
     * [HHH-3817] - JBC second level cache integration can cache stale collection data
     * [HHH-4583] - Incorrect handling of empty conjunction and disjunction
     * [HHH-4613] - KEY, VALUE and ENTRY should not be strict keywords
     * [HHH-4693] - MapProxy - problems during marshalling/demarchalling
     * [HHH-4809] - Immutable entities added to a session have Status.MANAGED unless loaded by the Session
     * [HHH-4810] - Persistent immutable and read-only entities are updated before being deleted
     * [HHH-4825] - mapping order impacting behavior leading to bug
     * [HHH-4836] - Infinispan: 2L QueryCache don't considers cached queries which belong to current transaction
     * [HHH-4845] - Investigate why entitymanager test cannot be run in forkMode once
     * [HHH-4899] - Type not supported: org.hibernate.type.TimestampType
     * [HHH-4917] - Keyword TYPE not supported
     * [HHH-4926] - Upgrade to jDocBook 2.2.1
     * [HHH-4928] - Non-Audited Entity with @ManyToOne in PK causes error in Envers 1.2.2
     * [HHH-4932] - Upgrade EM to use the latest metamodel generator (CR-1)
     * [HHH-4944] - putFromLoad calls could store stale data
     * [HHH-4948] - Session.flush()  does not always cascade save or update to read-only or immutable entities
 
 ** Improvement
     * [HHH-4905] - Allow consistent handling of numeric primary key values by any integral data type
     * [HHH-4911] - Make referencedColumnName case insensitive
     * [HHH-4930] - Drop org. prefix on hibernate.cache.default_cache_concurrency_strategy and hibernate.id.new_generator_mappings for consistency
     * [HHH-4934] - Improve logging in MetadataContext and AttributeFactory
     * [HHH-4942] - Refactor PackagedEntityManagerTest and JarVisitorTest to use ShrinkWrap
 
 ** New Feature
     * [HHH-3841] - Add support for lock timeouts
 
 ** Patch
     * [HHH-4908] - Multiple failures reported during ReadOnlyProxyTest with Ingres
 
 ** Task
     * [HHH-4640] - Add test with JNDI bound JBoss Transactions Transaction Manager
     * [HHH-4936] - Document JPA criteria queries
     * [HHH-4949] - Document JPA 2 metamodel
     * [HHH-4951] - Correct DTD entities for injecting version and date into docs
 
 
 Changes in version 3.5.0-CR-1 (2010.02.10)
 -------------------------------------------
 http://opensource.atlassian.com/projects/hibernate/browse/HHH/fixforversion/11014
 
 ** Sub-task
     * [HHH-4661] - Properly propagate Query.setLockMode to Hibernate Core
     * [HHH-4664] - Implement EntityManagerFactory#getProperties()
     * [HHH-4848] - Derived identities: Derived entities using @IdClass and mapping a @XToOne are not supported
 
 ** Bug
     * [HHH-4317] - Memory leak in EnumType class.
     * [HHH-4824] - localpath appeared in the doc xml
     * [HHH-4841] - Read-only proxies in NonFlushedChanges are not read-only when applied to a new session
     * [HHH-4861] - Allow lookup by the "simple" pk type of "parent entity" in "derived identities" cases
     * [HHH-4877] - "Check Nullability" logging incorrectness in SettingsFactory
     * [HHH-4880] - EntityManager.refresh does not throw EntityNotFoundException for removed entity
     * [HHH-4883] - Unable to join across a component
     * [HHH-4884] - Fix binding of @TableGenerator#initialValue into org.hibernate.id.enhanced.TableGenerator
     * [HHH-4889] - @IdClass containing an associated entity reference (instead of the pk of this associated entity) should still work
     * [HHH-4895] - property mappings incorrect for composite ids with many-to-one
     * [HHH-4896] - Read-only proxy targets initialized from second-level cache are not read-only
     * [HHH-4898] - Results from read-only Criteria and Query obtained from query cache are not read-only
     * [HHH-4900] - Wrong immutable type check in IdMetadataGenerator
     * [HHH-4902] - Handle JPA 2 requirement of setting id attribute to non-null with its equivalent of foreign-generator
 
 ** Improvement
     * [HHH-4578] - Criteria is missing read-only flag
     * [HHH-4704] - Pass session into EntityTuplizer#setIdentifier
     * [HHH-4879] - Support HQL index-refering functions for many-to-many, indexed collections
     * [HHH-4894] - Process composite-id sub-generators PersistentIdentifierGenerator contract(s)
 
 ** New Feature
     * [HHH-4731] - Public API to know if an entity class is audited
 
 ** Patch
     * [HHH-4886] - Merge minor change from IngresDialect.java from 3.3.2 for Ingres 9.2 compatibility
 
 ** Task
     * [HHH-4892] - Simplify testing of persistence packages
 
 
 Changes in version 3.5.0-Beta-4 (2010.01.28)
 -------------------------------------------
 - http://opensource.atlassian.com/projects/hibernate/browse/HHH/fixforversion/11012
 
 ** Sub-task
     * [HHH-4529] - Partial support for derived identity (including @MapsId)
     * [HHH-4651] - Add support for EntityManager properties
     * [HHH-4659] - Add support for standard declarative cache (@Cacheable)
     * [HHH-4660] - Support Cache Retrieve Mode and Cache Store Mode Properties
     * [HHH-4669] - Implement JDBC driver properties support
     * [HHH-4677] - implement PersistenceUnitInfo#getPersistenceXMLSchemaVersion(); and the same in PersistenceMetadata
     * [HHH-4678] - Apply PersistenceUnitInfo#getSharedCacheMode and #getValidationMode
     * [HHH-4690] - Consider adding a flag for legacy/new generators
     * [HHH-4725] - implement orphanRemoval for OneToOne
     * [HHH-4849] - Derived Identity: default @JoinColumn is not honored for properties linked to @MapsId
 
 ** Bug
     * [HHH-3828] - Criteria: Restriction whith class does not work
     * [HHH-4736] - Cannot pass ValidatorFactory into PersistenceProvider.createContainerEntityManagerFactory(PersistenceUnitInfo, Map)
     * [HHH-4781] - When a read-only entity is refreshed it is changed to modifiable
     * [HHH-4789] - Check  annotations and entitymanager poms for consistent plugin configuration
     * [HHH-4796] - NullPointerException when an @AssociationOverride joinColumn is set but no @AssociationOverride joinTable is on a given property
     * [HHH-4797] - Backref properties should be ignored when building the JPA 2 metamodel (leading atm to java.lang.IllegalArgumentException: Cannot determine java-type from given member [null])
     * [HHH-4804] - Entities in non-lazy associations loaded by a read-only HQL Query are not read-only
     * [HHH-4805] - JPA 2 metamodel impl ignores nested generics
     * [HHH-4806] - em.getTransaction.commit() does not always wrap in a RollbackException
     * [HHH-4807] - not-null checking no longer applied even if Bean Validation is not present
     * [HHH-4828] - Entities returned by Query...setReadOnly(true)...iterate() should be read-only 
     * [HHH-4834] - Exception in the metamodel population when raw types are used in collections
     * [HHH-4843] - org.hibernate.ejb.util.LogHelper assumes javax.persistence.spi.PersistenceUnitInfo#getProperties is never null
     * [HHH-4846] - NPE in AbstractIdentifiableType.checkDeclaredVersion
     * [HHH-4847] - In nested id generators, use the context aka idObject for set operation and the raw entity as input for generation
     * [HHH-4850] - Transaction commit throws RollbackException instead of PessimisticLockException
     * [HHH-4851] - OneToOneSecondPass Metadata is mistakenly interpreted
     * [HHH-4853] - 3.4.4.3 Lock Mode Properties and Uses, "Vendor-specific hints must be ignored if they are not understood. "
     * [HHH-4855] - Incorrectly tries to search a secondary table when globally quoted identifiers are used
     * [HHH-4858] - Implicitly add a cascade PERSIST when @MapsId is used
     * [HHH-4859] - NPE when the entity uses a core-style "embedded" id (ie not an @IdClass nor an explicit @EmbeddedId)
     * [HHH-4862] - quoted column/alias names not properly handled in org.hibernate.loader.EntityAliases
 
 ** Improvement
     * [HHH-4552] - Support generated value within composite keys
     * [HHH-4813] - annotation and entitymanager module should use the maven-injection-plugin to generate version string
     * [HHH-4816] - Cleanup JPA setting name constants
 
 ** New Feature
     * [HHH-2501] - Add capability to set a default read-only/modifiable setting for a session
     * [HHH-2762] - SessionImplementor.getNonFlushedChanges()/applyNonFlushedChanges() API and initial implementation
     * [HHH-4616] - Configure global/cache level JMX statistics from Hibernate configuration file
     * [HHH-4726] - Add support for delete-orphan cascading to <one-to-one/>
     * [HHH-4840] - Support embedded id properties like core
 
 ** Task
     * [HHH-4792] - Validate fix for HHH-4791
     * [HHH-4793] - Revert disabling of VersionsJoinTableRangeComponentNamingTest and fix underlying issue
     * [HHH-4799] - Create a *unit* test that asserts SerializationHelper's ability to deser a class using an "isolated classloader" (aka a TCCL)
     * [HHH-4822] - Add @FailureExpected annotation to annotations and entitymananger modules to allow the skipping of tests 
     * [HHH-4823] - Reorder modules in top level pom so that testsuite runs directly after core
     * [HHH-4856] - Upgrade dependency to jpa metamodel generator
 
 
 Changes in version 3.5.0-Beta-3 (2010.01.13)
 -------------------------------------------
 - http://opensource.atlassian.com/projects/hibernate/browse/HHH/fixforversion/10981
 
 ** Sub-task
     * [HHH-4203] - Implement JPA 2.0 criteria apis (compiling)
     * [HHH-4352] - implement @AttributeOverride for Map (key, value)
     * [HHH-4353] - implement default column naming strategy for Collections and Map of basic types
     * [HHH-4527] - Implement @j.p.Access support
     * [HHH-4536] - Fix the mismatch between JPA 2's logical model and mapping.* physical model wrt t*toOne and *ToMany
     * [HHH-4546] - add JPA 2.0 locking
     * [HHH-4553] - Hibernate doesn't support official JPA2 escape char for table name
     * [HHH-4584] - Query Language needs to support joins on embedded values
     * [HHH-4598] - An embeddable class may contains collection of basic types or embeddable objects
     * [HHH-4600] - Implements full support for JPA 2 Maps
     * [HHH-4601] - implement orphanRemoval for *ToMany
     * [HHH-4649] - support for <delimited-identifier/> in ORM.xml files
     * [HHH-4654] - Criteria quries must support referencing parameters by name
     * [HHH-4657] - support CascadeType.DETACH and em.detach()
     * [HHH-4663] - Make sure CriteriaQuery is serializable
     * [HHH-4665] - Implement emf.getPersistentUnitUtil().getIdentifier(Object)
     * [HHH-4667] - Properly parse the new orm.xml xsd and persistence.xml xsd
     * [HHH-4675] - Bean Validation ConstraintViolationException should trigger a tx rollback as per JPA's spec
     * [HHH-4679] - Make sure @AssociationOverride support the dot notation (section 11.1.2)
     * [HHH-4680] - Implement @AssociationOverride .value for Map value overriding (section 11.1.2)
     * [HHH-4681] - Implement @AttributeOverride "key." or "value." for Maps
     * [HHH-4682] - Check that @CollectionTable (or its absence) defaults to the right table/column names
     * [HHH-4684] - Make sure @Lob works with @ElementCollection
     * [HHH-4685] - Make sure bidirectional @*To* works from an embedded object to another entity
     * [HHH-4686] - Implement @MapKeyEnumerated
     * [HHH-4687] - implement @MapKeyTemporal
     * [HHH-4688] - Make sure @OrderBy works for @ElementCollection
     * [HHH-4689] - Make sure @OrderBy supports dotted notation to point to embedded properties
     * [HHH-4692] - add the new orm_2_0.xsd file
     * [HHH-4696] - Add persistence.xsd version 2
     * [HHH-4724] - query.multiselect() on a CriteriaQuery<Tuple> returns List<Object[]> instead of List<Tuple>
     * [HHH-4752] - @AttributeOverride for column name should use no prefix for @ElementCollection (legacy uses "element")
     * [HHH-4753] - Default table name for @CollectionTable is not inferred correctly according to spec requirement
     * [HHH-4756] - javax.persistence.criteria.Path#get should result in *delayed* join rendering
     * [HHH-4758] - Rename org.hibernate.ejb.criteria.AbstractNode#queryBuilder to #criteriaBuilder
     * [HHH-4766] - Properly support criteria notion of SUM aggregation return types
     * [HHH-4771] - @ElementCollection fk column should default to entityName_columnNameOfOwningId
     * [HHH-4782] - Implement @AssociationOverride.joinTable
 
 ** Bug
     * [HHH-1352] - Session.setReadOnly(Object, boolean) fails for proxies
     * [HHH-1575] - Expression.in on component object gives parameters til SQL in wrong order
     * [HHH-2166] - Long "in" lists in queries results in a Java stack overflow exception.
     * [HHH-2990] - Fix SerializationHelper$CustomObjectInputStream to use Class.forName and better classloader
     * [HHH-3164] - "id in ..." with EmbeddedId and criteria API
     * [HHH-3240] - In Derby field type 'text' is converted to CLOB(255)
     * [HHH-3338] - Order of attributes in generated SQL query is dependent on Java version
     * [HHH-3529] - ConnectionWrapper is not visible from class loader
     * [HHH-4041] - Null Pointer Exception when using @NotAudited on an entity with discriminator column, inherited from base entity with InheritanceType.SINGLE_TABLE
     * [HHH-4063] - NPE reading metadata from an mapped interface
     * [HHH-4065] - Incorrect SQL is used for HQL if the number of values for a filter collection parameter is changed
     * [HHH-4090] - RelationTargetAuditMode.NOT_AUDITED not working with many-to-many relations
     * [HHH-4257] - map key type no longer inferred correctly, throws exception at runtime
     * [HHH-4283] - Bidirectional indexed collection mapped incorrectly for IndexedCollectionTest
     * [HHH-4457] - SchemaUpdate fails on Sybase ASE 15 when a new column is added without a default value
     * [HHH-4519] - Hibernate/Infinispan integration doesn't property handle Entity/CollectionRegionAccessStrategy evictAll
     * [HHH-4520] - Infinispan second level cache integration can cache stale collection data
     * [HHH-4531] - Derby dialect should not support comments
     * [HHH-4542] - Annotation processor does not handle "bag" mappings correctly
     * [HHH-4560] - JDBC4 support inadvertently missed 1.4 compatibility
     * [HHH-4565] - Maven deps: HSQLDB shouldn't be a dependency in compile scope.
     * [HHH-4566] - Maven deps: JAXB API and JAXB RI shouldn't be dependencies of Hibernate Annotations.
     * [HHH-4567] - EntiytManager's QueryImpl mishandles ordinal position of HQL-style positional parameters
     * [HHH-4571] - Infinispan not properly being built into distribution bundle
     * [HHH-4572] - check if the connection supports jdbc4 before looking for the createClob method
     * [HHH-4574] - ConnectionProviderFactory.getConnectionProperties() includes extra properties
     * [HHH-4581] - Embedded objects in criteria API does not work
     * [HHH-4586] - Parameterized functions built throught CriteriaBuilder missing parameters when rendered
     * [HHH-4588] - Seam 2.x depends on ReaderInputStream which it shouldn't.  Deprecate the current Hibernate ReaderInputStream class
     * [HHH-4590] - CASTs from CriteriaBuilder.toXXX methods still need to be fleshed out
     * [HHH-4604] - IllegalArgumentException should be raised when an ordinal parameter is not present in the query
     * [HHH-4611] - When the revision number in the revision entity uses a @Column(columnDefinition=), the sql-type is not properly set on the REV property of audit entities
     * [HHH-4614] - (javassist) Instrumented model with abstract MappedSuperclass and field access doesn't work
     * [HHH-4625] - Use of maven-injection-plugin intermittently leads to build failures
     * [HHH-4631] - Infinispan integration module is causing build problems
     * [HHH-4633] - Using same table for multiple relations doesn't work
     * [HHH-4634] - A many-to-many relation owned by both sides causes a mapping exception
     * [HHH-4641] - @PrimaryKeyJoinColumn on an inherited entity doesn't affect the column name
     * [HHH-4644] - When using join-inheritance and a custom revision entity, the child mapping uses incorrect revision number column sql type
     * [HHH-4645] - Rename properties used to configure Envers from camel case to _
     * [HHH-4650] - Removing an item from a persistent collection, flushing, and adding the same item again fails
     * [HHH-4653] - Setting the "referencedColumnName" in @JoinColumnOrFormula throws an NPE
     * [HHH-4670] - Incorrect revision types when in a add-flush-mod-flush sequence
     * [HHH-4698] - Better handling of JPA criteria expressions
     * [HHH-4702] - org.hibernate.ejb.metamodel.AttributeFactory should use member for javaType, et al
     * [HHH-4707] - Currently no support for modulus operator
     * [HHH-4708] - Make CompoundSelectionImpl implement ExpressionImplementor
     * [HHH-4709] - registered length functions should return Integer
     * [HHH-4711] - persistence.xml is not validated during parsing
     * [HHH-4715] - Unexpected results when an updated entity that is already modifiable is set to modifiable again
     * [HHH-4720] - Improve javax.persistence.metamodel.Attribute support
     * [HHH-4735] - Proxy can be associated with a new session when it is already connected to a different one
     * [HHH-4741] - org.hibernate.test.filter.DynamicFilterTest.testSqlSyntaxOfFiltersWithUnions fails on MySQL
     * [HHH-4743] - Bug in BooleanLiteralNode with CustomType
     * [HHH-4764] - org.hibernate.test.pagination.PaginationTest.testLimitOffset() fails on oracle and db2 due to
     * [HHH-4767] - Bug in how Criteria Subquery selections are handled
     * [HHH-4768] - Bug in how Criteria Subquery correlations are handled
     * [HHH-4769] - In HQL, function ROUND always returns an Integer, it truncate the decimal part of Double number.
     * [HHH-4772] - Empty conjunction/disjunction in criteria does not follow spec rules
     * [HHH-4774] - Do not handle literals using parameters in JPA criteria select
     * [HHH-4775] - CriteriaBuilder#notEqual being interpreted oppositely
     * [HHH-4776] - Add a NullLiteralExpression for CriteriaBuilder#nullLiteral
     * [HHH-4777] - org.hibernate.ejb.test.PackagedEntityManagerTest.testOverridenPar() hard code hsqldb connection info
     * [HHH-4778] - Need better handling of criteria expression casting
     * [HHH-4780] - Allow BigDecimal and BigInteger to be specified as numeric literal types
     * [HHH-4785] - BinaryArithmeticOperation reverses incoming arguments
     * [HHH-4786] - SerializableType + custom Serializable class + L2 cache causes problems
     * [HHH-4788] - antrun plugin version is not explicitly specified in the parent pom
     * [HHH-4790] - Envers test failing, disabling for beta-3 release
     * [HHH-4791] - Invalid assumption made in org.hibernate.envers.tools.Tools#getTargetFromProxy
 
 ** Deprecation
     * [HHH-4561] - Deprecate openConnection()/closeConnection() methods on Batcher interface
 
 ** Improvement
     * [HHH-2576] - Allow native-sql to have placeholders for default schema and catalog
     * [HHH-4000] - Utlize jhighlight hooks for rendered syntax coloration of XML and Java based programlisting docbook elements
     * [HHH-4540] - Allow the revision timestamp to be a Date
     * [HHH-4545] - Allow o.h.action.Executable to register for either (or both) before or after transaction completion callbacks
     * [HHH-4548] - Alter poms to not use javax.* artifacts under Sun proprietary license
     * [HHH-4550] - Document that update-timestamps cache region should not be configured for expiry.
     * [HHH-4569] - Split focus of ConfigurationPerformanceTest
     * [HHH-4573] - Minor typo, formatting and cleanup fixes
     * [HHH-4575] - When Infinispan is configured for INVALIDATION don't send cluster message on entity insert
     * [HHH-4671] - Derby is one of those dialects that should not support "cross join"
     * [HHH-4697] - Add means to get HibernateEntityManagerFactory from HibernateEntityManagerImplementor
     * [HHH-4705] - Derby does now in fact support the full ANSI SQL TRIM function
     * [HHH-4719] - Support modulo operator
     * [HHH-4737] - Cache the EntityKey in EntityEntry when id is non-null
     * [HHH-4763] - Change antrun plugin configuration in entitymanager module to allow metamodel generation without processing all life cycles
 
 ** New Feature
     * [HHH-2308] - Adding predicates to the join condition using Criteria Query
     * [HHH-4608] - Add new properties that will allow to specify the default schema and catalog that should be used for audit tables
     * [HHH-4694] - Support "fake" many-to-one bidirectional relations
     * [HHH-4749] - Don't block calls to getListeners on SessionImplementor when using thread scoped sessions
 
 ** Patch
     * [HHH-1918] - enable non-hilo identity generation in DerbyDialect
     * [HHH-2347] - Improvement to DerbyDialect default identy generation mode
     * [HHH-2584] - PersistentMap.remove() incorrect on uninitialized, non-extra-lazy map
     * [HHH-3860] - Cascading performance problems when session contains many entities
 
 ** Task
     * [HHH-4006] - Document fetch profiles
     * [HHH-4498] - Move the xml configuration files in the annotations module into the default resource directory /src/test/resources
     * [HHH-4655] - Upgrade jpamodelgen dependency in entitymanager to use 1.0.0.Beta1
     * [HHH-4672] - Upgrade JPA dependency to hibernate-jpa-2.0-api-1.0.0-CR-1
     * [HHH-4673] - Upgrade JPA Static Metamodel Generator dependency to 1.0.0.Beta1
     * [HHH-4674] - JBoss has renamed its JACC artifact
     * [HHH-4783] - Remove obsolete changelog.txt files in annotations and entitymanager modules
 
 
 Changes in version 3.5.0-Beta-2 (2009.11.02)
 -------------------------------------------
 
 ** Sub-task
     * [HHH-4047] - Phase 1 - API & implement join-strategy
     * [HHH-4196] - Implement JPA 2.0 criteria apis (building)
     * [HHH-4202] - Implement JPA 2.0 metamodel APIs
     * [HHH-4528] - Read mapping annotations from entity properties rather than the composite pk
     * [HHH-4533] - Support for @MappedSuperclass such that we can build javax.persistence.metamodel.MappedSuperclassType
     * [HHH-4537] - Expose Members for MappedSuperclass properties
 
 ** Bug
     * [HHH-1724] - Critieria needs to be aligned with new aggreation type rules
     * [HHH-3817] - JBC second level cache integration can cache stale collection data
     * [HHH-3818] - Hibernate/JBC integration doesn't property handle Entity/CollectionRegionAccessStrategy evictAll
     * [HHH-4095] - bug in org.hibernate.Hibernate.createBlob( InputStream in )
     * [HHH-4100] - Problems with Envers docbook sources
     * [HHH-4105] - SessionFactory mispells method to obtain fetch profile definition
     * [HHH-4114] - ASTParserLoadingTest fails due to missing "bit_length" function
     * [HHH-4115] - FooBarTest - "operator does not exist: character varying = integer"
     * [HHH-4435] - DataVersionAdapter.newerThan incorrect when comparing to self
     * [HHH-4437] - ToOneDelegateSessionImplementor breaks Hibernate.getClass(auditedEntity.proxyOfnotAuditedEntity)
     * [HHH-4441] - SessionImpl serialization violates java serialization spec
     * [HHH-4447] - Envers proxy.getId() returns null if proxy was not initialized yet
     * [HHH-4449] - NPE during inserting new audited entity with reference to another proxy entity if proxy.lazyInitializer.session is null
     * [HHH-4463] - Native queries should not be automatically paginated in getSingleResult() as it fails for some DB and or queries
     * [HHH-4475] - Constants point to non-existing default JBC/JGroups config file locations
     * [HHH-4486] - Account for MySQL's <DROP TEMPORARY TABLE> statement
     * [HHH-4494] - cglib log warning says BytecodeProvider impl is considered deprecated
     * [HHH-4500] - MSSQL, Oracle - Mapping inconsistency
     * [HHH-4503] - Sybase - Annotations - unit tests using LOBs fail
     * [HHH-4507] - Persistence units in entitymanager's testsuite are using fixed hsqldb configuration
     * [HHH-4513] - AnotationConfiguration does not honor hibernate.validator.apply_to_ddl property in case Hibernate Validator 4 is activated
     * [HHH-4522] - CallbackAndDirtyTest throws exception when run against PostgreSQL
     * [HHH-4525] - Trunk is not including the newly added modules to the distribution bundle
     * [HHH-4532] - Unit Tests in test/idgen/enhanced/forcedtable need update
 
 ** Improvement
     * [HHH-3461] - Enhance DialectFactory to support Sybase Adaptive Server Anywhere
     * [HHH-4364] - Support @NamedQuery on a @MappedSuperclass (Sharath Reddy)
     * [HHH-4382] - @ManyToOne not working wth @Formula
     * [HHH-4397] - Split test involving database specific features (like sequence / identity)
     * [HHH-4405] - Integrate new long string and binary property types in core with  annotations
     * [HHH-4415] - TestCase could check for superclass of Dialect before skipping it
     * [HHH-4442] - Change StandardDialectResolver to use SybaseASE15Dialect over deprecated SybaseDialect
     * [HHH-4443] - Allow generic handling of any Hibernate type for post-insert generated identifiers
     * [HHH-4476] - Move cache-jbosscache to JBoss Cache 3.2.1
     * [HHH-4484] - When JBoss Cache is configured for INVALIDATION don't send cluster message on entity insert
     * [HHH-4502] - Update database profiles in pom.xml
     * [HHH-4508] - Typo in DialectFactory - avalable should be available
     * [HHH-4523] - Some of the tests in the entitymanager have hard coded connection settings - these tests should use filtered connection settings
     * [HHH-4526] - Add better metainf information tot he hibernate all jar gennerated for dist
 
 ** New Feature
     * [HHH-1012] - Index not created by SchemaUpdate
     * [HHH-1480] - JOIN precendence rules per SQL-99
     * [HHH-3000] - Allow a TypeDef to be associated with a class (Sharath Reddy)
     * [HHH-4103] - Implement an Infinispan 2nd level cache provider
     * [HHH-4232] - TypeDef support on @Embeddable or @MappedSuperClass classes (Sharath Reddy)
     * [HHH-4332] - Filters for MappedSuperClass
     * [HHH-4473] - Create documentation to explain the usage of the new 'defaultForType' attribute of the TypeDef annotation
     * [HHH-4479] - We should be able to implement Joins using formulas with Annotations
     * [HHH-4512] - TypeDef annotation should support both 'name' and 'defaultForType' attributes
 
 ** Patch
     * [HHH-3972] - Adding FETCH FIRST and OFFSET support to DerbyDialect
     * [HHH-4440] - Support for column-level read/write fragments (Rob Hasselbaum)
     * [HHH-4488] - ListProxy, MapProxy etc. - problems during marshalling/demarchalling
 
 ** Task
     * [HHH-2412] - Support for JDBC4
     * [HHH-3580] - import entitymanager into core as a module
     * [HHH-3849] - Disable lock striping in JBoss Cache configs
     * [HHH-4355] - Allow running tests against different databases by using a simple switch
     * [HHH-4485] - Replace the JBoss Cache integration configuration properties with "jbc2"-less versions
     * [HHH-4487] - Restore versions of the old public API jbc2 package classes
     * [HHH-4499] - Account for modules needing JDK 1.6
     * [HHH-4501] - Use Maven wagon-scm provider for release deployments
     * [HHH-4530] - Change the docbook style for Annotations and EntityManager to the latest styles used in the other Core modules
     * [HHH-4538] - Update to Bean Validation 1.0.0 and Hibernate Validator 4.0.0
 
 
 Changes in version 3.5.0.Beta-1 (2009.08.18)
 -------------------------------------------
 
 ** Sub-task
     * [HHH-3801] - Create a cache-jbosscache-legacy module
     * [HHH-3802] - Move the up-to-date JBC integration into cache-jbosscache
     * [HHH-3803] - Repackage JBC integration to org.hibernate.cache.jbc
     * [HHH-4027] - Remove current cache-jbosscache module content
     * [HHH-4028] - Move current cache-jbosscache2 module content to cache-jbosscache
     * [HHH-4029] - Remove cache-jbosscache2 module
 
 ** Bug
     * [HHH-1930] - QuerySyntaxException "with-clause expressions did not reference from-clause element to which the with-clause was associated"
     * [HHH-2146] - NullpointerException in DefaultDeleteEventListener.deleteTransientEntity
     * [HHH-2694] - create-drop with c3p0 causes SQLException
     * [HHH-2745] - NullPointerException when eager fetching joined many-to-many with native SQL query
     * [HHH-3046] - Merge fails on complicated data structure because of cycle references
     * [HHH-3216] - Incorrect parse result in ParameterParser
     * [HHH-3231] - org.hibernate.id.enhanced.TableGenerator throws "IllegalArgumentException: alias not found: tbl" under Oracle
     * [HHH-3351] - Dynamic entity model and inheritance - exception when trying to persist
     * [HHH-3392] - Query Cache entries are not distributable
     * [HHH-3472] - JTASessionContext broken for WebSphere
     * [HHH-3481] - JTATransactionFactory bug when Transaction cannot be found in JNDI
     * [HHH-3506] - enabled filters should apply to HQL update/delete statements
     * [HHH-3508] - Sybase Dialect - Override supportsCascadeDelete to return "false"
     * [HHH-3519] - account for parameters in select clause of INSERT-SELECT for DB2
     * [HHH-3528] - FETCH JOIN query doesn't work in a StatelessSession
     * [HHH-3573] - Incorrect support for columns which aren't insertable
     * [HHH-3575] - Empty versions-query (both types) will cause a runtime exception
     * [HHH-3584] - Generate SQL when Dynamic Update is true is including version field even when marked as updateable=false
     * [HHH-3594] - Hibernate collection listener throw exception when adding entity to the collection
     * [HHH-3600] - exception while saving bidirectional association
     * [HHH-3602] - Inheritence issue
     * [HHH-3621] - Assertion failure in MigrationTest
     * [HHH-3623] - Make at least ListProxy serializable
     * [HHH-3633] - Envers ignores empty discriminator classes
     * [HHH-3636] - Attempt to read invalid column when loading collection of subclasses mapped with table-per-subclass with discriminator
     * [HHH-3640] - Some standard SQL functions are not implemented in Sybase
     * [HHH-3647] - instance not of expected entity type: java.util.HashMap is not a: smx3.schema3.Party_AUD
     * [HHH-3652] - CompositeIdWithGeneratorTest needs a standard way to compare timestamps
     * [HHH-3662] - Merging read-only entities causes AssertionError("Merged entity does not have status set to MANAGED...")
     * [HHH-3668] - Sybase does not support implicit conversion from character types to numeric types causes failing unit tests
     * [HHH-3670] - Invalid test for str() for SQL Server and Sybase
     * [HHH-3671] - The revision type field is not persisted when setting a custom revision type field name throught the properties
     * [HHH-3672] - Sybase - second(), minute(), hour(), and extract() cause GenericJDBCException
     * [HHH-3675] - Limitations on Sybase ResultSet implementation cause unit test failures
     * [HHH-3679] - Sybase conversion of Java byte to tinyint fails with 8-bit values causing unit test failures
     * [HHH-3680] - Sybase - composite primary key in unit test exceeds maximum for index causing failure
     * [HHH-3686] - Sybase - QueryCacheTest.testQueryCacheInvalidation fails
     * [HHH-3693] - Implicit Polymorphic query + pagination returning zero result
     * [HHH-3696] - Sybase - unit tests fail when numeric values overflow in precision or scale on insert
     * [HHH-3698] - Problem with HQL parameter bindings as indexed collection selectors
     * [HHH-3699] - Problem with HQL parameter bindings for parameters in WITH join clause
     * [HHH-3701] - SQL function "trim" is not available in Sybase Dialect
     * [HHH-3703] - RevisionEntity with compound primary key fails
     * [HHH-3705] - NPE encountered on using AnnotationConfiguration
     * [HHH-3706] - Audit Table Schema not generated using <annotationconfiguration>
     * [HHH-3729] - @AuditJoinTable annotation has no effect for embedded concrete subclasses of a MappedSuperClass
     * [HHH-3736] - Envers EntityInstantiator does not support private constructors for immutable entities
     * [HHH-3740] - Unable to build EntityManagerFactory when using a non-audited ManyToOne in Audited components
     * [HHH-3741] - Join tables are not audited if the join is defined in an abstract
     * [HHH-3773] - NPE when generating schema containing OneToMany relations
     * [HHH-3779] - "org.hibernate.MappingException: An audited relation to a non-audited entity" during schema-export ant task
     * [HHH-3782] - Saving a one-to-many relationship results in unsaved transient instance exception
     * [HHH-3794] - Issue when method return type is Interface
     * [HHH-3810] - Transient entities can be inserted twice on merge
     * [HHH-3830] - Problem with inheritance and @ManyToMany relation
     * [HHH-3847] - java.lang.NullPointerException on onPreRemoveCollection on replicate of persistent class
     * [HHH-3871] - unnecessary proxy initialization on audit record save
     * [HHH-3878] - Exception when querying historical data for deleted Entites
     * [HHH-3880] - org.hibernate.id.enhanced.TableStructure missing "as" keyword in select statment column renames; required for PostgreSQL
     * [HHH-3888] - Envers schema generation (ant) ignoring columnDefinition ( atribute of @Column, JPA )
     * [HHH-3912] - Change for HHH-3159 causes InstantiationException
     * [HHH-3918] - Use standard JDK exception nesting
     * [HHH-3923] - Enver throws Nullpointer exception with a self reference entities
     * [HHH-3939] - @NotAudited association requires and joins to the associated table
     * [HHH-3957] - Audited Null Embeddable objects not returned as null
     * [HHH-3980] - Fix for HHH-2980 introduced bug that allows the same bag collection role to be fetched multiple times
     * [HHH-4003] - many-to-many loaders should use inner joins from the collection table to element table
     * [HHH-4034] - Update org.hibernate.action.BulkOperationCleanupAction to use new Region cache APIs
     * [HHH-4088] - Session.getSession should always return sessions from parent (or root) session
     * [HHH-4091] - HQLTest#testDuplicateImplicitJoinInSelect
     * [HHH-4099] - Doc build error (http://jira.codehaus.org/browse/MNG-1323)
 
 ** Improvement
     * [HHH-1234] - allow tuplizers the opportunity to influence getSubclassEntityPersister() processing
     * [HHH-2592] - force hibernate to generate use offset qeury when offset is zero
     * [HHH-2686] - Include a primary key in the sequence table used by id.enhanced.TableGenerator
     * [HHH-2802] - Support HQL style order by (JPA @OrderBy)
     * [HHH-2980] - Error "org.hibernate.HibernateException: cannot simultaneously fetch multiple bags" not specific enough
     * [HHH-3159] - Oracle 11g - desupport of oracle.jdbc.driver
     * [HHH-3249] - Make o.h.id.enhanced.TableGenerator more extension-friendly
     * [HHH-3275] - Allow pluggable tuplizers for composite elements
     * [HHH-3357] - improve performance of session.clear()
     * [HHH-3383] - QueryKey is storing references to entities instead of identifiers
     * [HHH-3424] - concat() with param binding fails function on derby
     * [HHH-3439] - Change o.h.cfg.Mappings to not require constructor
     * [HHH-3454] - Allow enhanced.TableGenerator to segment itself per entity as default
     * [HHH-3456] - Make o.h.id.enhanced.SequenceStyleGenerator more extension-friendly
     * [HHH-3471] - Provide true-false type that maps to int values
     * [HHH-3515] - Introduce EntityNameResolver interface
     * [HHH-3517] - Allow definition of the default tuplizer class to use
     * [HHH-3518] - Remove Suite classes from testsuite module
     * [HHH-3525] - Clean up reflection code trying to determine JDK 1.4 capabilities
     * [HHH-3532] - schema update task should look for foreign key signature
     * [HHH-3708] - Suboptimal exception on m:n relations with an unaudited entity
     * [HHH-3712] - Reorganize the Sybase dialect class hierarchy, add SybaseASE15Dialect, and mark SybaseDialect as deprecated
     * [HHH-3737] - Support Hibernate 3.3 branch in Envers until 3.4.0GA is out
     * [HHH-3750] - Allow dialects to handle difference in how Query.setFirstResult() should be interpreted
     * [HHH-3753] - Upgrade to SLF4J version 1.5.8
     * [HHH-3832] - Upgrade to cglib-2.2.jar
     * [HHH-3842] - Update maven profiles to use the databases in QA Lab
     * [HHH-3886] - Update database credentials for QA Lab
     * [HHH-3892] - Improve support for mapping SQL LONGVARCHAR and CLOB to Java String, SQL LONGVARBINARY and BLOB  to Java byte[]
     * [HHH-3944] - Document known database portability strategies
     * [HHH-3978] - Expose Hibernate version via non-compile-time constant expression
     * [HHH-3982] - Apply build version to org.hibernate.Version
     * [HHH-3998] - Fix spurious failures in ConfigurationPerformanceTest
     * [HHH-3999] - Change mysql hostname in pom.xml
     * [HHH-4016] - SAPDialect should not use oracle style outer joins, ANSI style is prefered by MaxDB
     * [HHH-4022] - Add an actual API contract for querying/managing cache regions (from app code)
 
 ** New Feature
     * [HHH-3343] - Postgres Plus Dialect
     * [HHH-3512] - Registration of IdentifierGenerators (short naming)
     * [HHH-3559] - Possibility to do versioning and non-versioning commits as required
     * [HHH-3560] - Assume entities relationships as unversioned by default
     * [HHH-3563] - Support relations in components
     * [HHH-3564] - Support for the three types of inheritance
     * [HHH-3565] - Direct property access
     * [HHH-3568] - In the hibernate mapping of versions entities, mark them as not updateable
     * [HHH-3570] - Move from "Versioning" to "Auditing"
     * [HHH-3588] - RevisionType available via public API
     * [HHH-3598] - Add the possibility to specify restrictions on RevisionType, using RevisionTypeProperty
     * [HHH-3611] - Extend revision restrictions in the query system
     * [HHH-3663] - Request to add Joined inheritance strategy supported for versioning
     * [HHH-3697] - Turn on/turn off versioning in runtime
     * [HHH-3723] - Publish sources to maven (snapshot) repository
     * [HHH-3781] - Echo version information to the console in main()
     * [HHH-3819] - Deleted entries with non null properties
     * [HHH-3823] - Obtain current revision entity by AuditReader
     * [HHH-3898] - Add a flag to disable Nullability.checkNullability() and the exception raised in this case
     * [HHH-3906] - Move to JPA 2 API as a dependency
     * [HHH-4010] - support auditing of entity having reference (many-to-one relation) to not audited entity
     * [HHH-4081] - Support for JPA 2.0 "qualified identification variables" (KEY, VALUE and ENTRY)
 
 ** Patch
     * [HHH-530] - Allow application of filters on subqueries
     * [HHH-2933] - allow custom resolution of Dialect (Tomoto Shimizu Washio)
     * [HHH-3401] - H2 Database Dialect Fixes
     * [HHH-3450] - Include SingletonEhCacheProvider as an additional caching provider (Greg Luck)
     * [HHH-3639] - Sybase keywords - rename columns
     * [HHH-3649] - DB2Dialect inherits supportsPooledSequences() as false, but it does support
     * [HHH-3650] - TableGenerator doesn't marks the "primary key" as not null, causing errors in some RDBMS's which expects the PK to be not-null
     * [HHH-3742] - Documentation corrections
     * [HHH-3744] - Improved support for persistence of subclasses
     * [HHH-4037] - Fixing build errors in documentation/manual
 
 ** Task
     * [HHH-3214] - Update unit tests and config files to use non-depracated Oracle dialects
     * [HHH-3474] - Upgrade to use slf4j 1.5 (1.5.2)
     * [HHH-3547] - import Envers into Hibernate core as a module
     * [HHH-3549] - import commons-annotations back into core as a module
     * [HHH-3550] - import annotations into core as a module
     * [HHH-3556] - Convert documentation to docbook
     * [HHH-3585] - Upgrade to JBoss Cache 3
     * [HHH-3760] - Document EntityNameResolver
     * [HHH-3761] - Document DialectResolver
     * [HHH-3879] - Envers documentation: configuration of event listeners is incomplete for JPA: @PostPersist, @PostUpdate  @PostRemove no longer work
     * [HHH-3953] - Update tutorial chapter
     * [HHH-3979] - Upgrade to javassist 3.9.0
     * [HHH-3981] - Upgrade to jDocBook 2.2.0
 
 
 Changes in version 3.3.0.GA (2008.08.13)
 -------------------------------------------
 
 ** Bug
     * [HHH-3430] - distribution bundles cglib directly instead of the hibernate repackaging
 
 
 Changes in version 3.3.0.CR2 (2008.07.31)
 -------------------------------------------
 
 ** Bug
     * [HHH-1697] - OracleDialect fails to recognize sequence accessible through syonyms when validating schema
     * [HHH-2604] - Isolator.JdbcDelegate masks the exception if it isn't possible to open a connection.
     * [HHH-2683] - "datediff" is declared as NoArgSQLFunction in H2Dialect, but actually accepts 3 arguments.
     * [HHH-3006] - ConcurrentModificationException in AbstractBatcher results in infinite loop
     * [HHH-3229] - Merge can fail when there is a transient entity reachable by multiple paths and at least one path does not cascade on merge
     * [HHH-3257] - Content images not displayed
     * [HHH-3260] - Hibernate wraps a listener init or destroy exception into an AssertionFailure
     * [HHH-3261] - Do not wrap exceptions raised by event listeners (at init or destroy time)
     * [HHH-3265] - change license url in pom to http://www.gnu.org/licenses/lgpl-2.1.html
     * [HHH-3266] - distribution bundle missing jta dependency
     * [HHH-3272] - using of Integer.valueOf(int), which is not available in JDK 1.4
     * [HHH-3282] - DB2Dialect should report supportsLobValueChangePropogation() == false
     * [HHH-3309] - Serialize/Deserialize problem in AbstractLazyInitializer with entitymode.MAP.
     * [HHH-3409] - ResultTransformers need smarter equals() and hashCode() impls
 
 ** Improvement
     * [HHH-1786] - JTASessionContext.CleanupSynch does not remove sessions from currentSessionMap
     * [HHH-2060] - To be able to use <generator> with <composite-id>
     * [HHH-2506] - Make javassist the default ByteCodeProvider
     * [HHH-2875] - repackage cglib/asm under org.hibernate namespace
     * [HHH-3269] - upgrade to jDocBook plugin version 2.1.1
     * [HHH-3283] - protect BulkManipulationTest#testInsertWithGeneratedTimestampVersion where Dialect#supportsParametersInInsertSelect == false
     * [HHH-3358] - Enable JTATransactionFactory and JTATransaction factory to work without JNDI
     * [HHH-3390] - Use READ_COMMITTED for JBC 2 cache
 
 ** Patch
     * [HHH-3294] - Version incorrectly incremented for unchanged persistent entity that is parent of a one to many relationship
 
 ** Task
     * [HHH-3270] - follow up on documentation license questions
 
 
 
 Changes in version 3.3.0.CR1 (2008.04.28)
 -------------------------------------------
 
 ** Bug
     * [HHH-1312] - Unclosed ResultSet when using Identity
     * [HHH-1396] - Table.validateColumns fails on valid column
     * [HHH-1569] - Immutable Natural Id check fails with ArrayIndexOutOfBounds in some cases
     * [HHH-1593] - Infinite loop/StackOverflow when calling configuration.setListener(null)
     * [HHH-1753] - DB2Dialect.getCurrentTimestampSQLFunctionName() uses Oracle syntax
     * [HHH-1916] - param values in generator element should be trimmed during HbmBinding
     * [HHH-1920] - Incorrect documentation regarding XML manipulation in Hibernate reference manual (chapter 18.3).
     * [HHH-1956] - Interceptor.afterTransactionCompletion not called with JTATransaction (CacheSynchronization.hibernateTransaction not set)
     * [HHH-2159] - NullPointerException in FromElement#findIntendedAliasedFromElementBasedOnCrazyJPARequirements with 'hibernate.query.jpaql_strict_compliance' enabled
     * [HHH-2164] - Minor bug in section "20.1.1. Customizing the schema"
     * [HHH-2200] - Memory leak in AbstractBatcher with Generated Properties
     * [HHH-2320] - Regression: optional properties under a <join> tag no longer update properly
     * [HHH-2503] - AbstractEntityPersister swallows JDBCExceptions in processGeneratedProperties
     * [HHH-2513] - Abusive WARN logged during deserialization of replicated SessionFactory
     * [HHH-2542] - NullPointerException in TypeFactory.replaceAssociations for ComponentType
     * [HHH-2553] - New LoadContexts Implementation causing possible performance degradation
     * [HHH-2593] - Keyword UNION is prefixed with "this_." in filter conditions
     * [HHH-2616] - No event is fired on Collection recreate/remove/update action
     * [HHH-2627] - Generated properties leak prepared statements in Hibernate 3.2.3 and higher.
     * [HHH-2631] - Leaking PreparedStatement and ResultSet via CollectionLoadContext instances maintained in Map collectionLoadContexts in LoadContexts
     * [HHH-2711] - PropertyAccessException with backref and <composite-map-key/>
     * [HHH-2726] - spelling o your CLASSPATH
     * [HHH-2728] - Calling session.clear() while retrieving objects via an iterator will cause a "LazyInitializationException - No Session" by the CGLIBLazyInitializer
     * [HHH-2788] - Oracl8iDialect No Dialect mapping for JDBC type 91
     * [HHH-2795] - CollectionLoadContexts for empy collections are not removed until PersistenceContext.clear()
     * [HHH-2816] - DefaultFlushEntityEventListener.checkNaturalId() causes extra SELECTs on read-only entities
     * [HHH-2833] - insert-select query fails with NPE when select includes join
     * [HHH-2857] - schemaSupport for HSQLDialect remote connections doesn't work
     * [HHH-2861] - cascade="delete-orphan,all" is ignored
     * [HHH-2863] - testsuite fix-ups for maven and/or directory changes
     * [HHH-2864] - Merging a detached instance with a new child in a unidirectional one-to-many association fails if the parent was previously loaded as a proxy
     * [HHH-2892] - skip up-to-date checks of query cache for natural-id only if immutable
     * [HHH-2928] - optimizers for enhanced id generators should be synchronized against multi-threaded access
     * [HHH-2948] - QueryStatistics.executionMinTime always = 0
     * [HHH-3111] - WebSphereExtendedJTATransactionLookup$TransactionManagerAdapter.getStatus() implemented incorrect
     * [HHH-3140] - Region prefix ignored for entities and collections
 
 ** Deprecation
     * [HHH-2755] - Wrong "jsdk.jar" referenced in the tutorial
 
 ** Improvement
     * [HHH-1786] - JTASessionContext.CleanupSynch does not remove sessions from currentSessionMap
     * [HHH-2048] - Incomplete MappingException at org.hibernate.mapping.SimpleValue
     * [HHH-2156] - Section 19.3, "Managing the caches" doesn't document CacheMode.IGNORE
     * [HHH-2533] - redesign Cache/CacheProviders
     * [HHH-2662] - Workaround PostgreSQL issues in testsuite
     * [HHH-2663] - Map java.sql.Types.REAL to Hibernate FloatType for auto-discovery stuff
     * [HHH-2665] - Split Oracle9Dialect into Oracle9iDialect and Oracle10gDialect
     * [HHH-2669] - Unequivocally map MySQL LOB types to the LONG variant
     * [HHH-2682] - support for auto-discovery of H2 dialect
     * [HHH-2696] - Consider migrating to slf4j
     * [HHH-2761] - Handle null and empty string consistently in PropertiesHelper
     * [HHH-2778] - TransactionManagerLookup implementation for Bitronix Transaction Manager
     * [HHH-2789] - Section 19.2 of the documentation does not show OSCache as supporting clusters. It does.
     * [HHH-2822] - timestamp extraction functions for SAPDBDialect
     * [HHH-2826] - IS [NOT] NULL checks with component values
     * [HHH-2859] - Introduce a 'Work' API for user to perform JDBC work
     * [HHH-3131] - Add a method to ActionQueue to tell whether there are currently entries in the executions collection
diff --git a/documentation/src/main/docbook/devguide/en-US/Caching.xml b/documentation/src/main/docbook/devguide/en-US/Caching.xml
index 0470e79d5e..9a1a773ba4 100644
--- a/documentation/src/main/docbook/devguide/en-US/Caching.xml
+++ b/documentation/src/main/docbook/devguide/en-US/Caching.xml
@@ -1,583 +1,583 @@
 <?xml version='1.0' encoding='utf-8' ?>
 <!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd" [
 <!ENTITY % BOOK_ENTITIES SYSTEM "Hibernate_Development_Guide.ent">
 %BOOK_ENTITIES;
 ]>
 <chapter>
   <title>Caching</title>
 
 
   <section>
     <title>The query cache</title>
     <para>
       If you have queries that run over and over, with the same parameters, query caching provides performance gains.
     </para>
     <para>
       Caching introduces overhead in the area of transactional processing. For example, if you cache results of a query
       against an object, Hibernate needs to keep track of whether any changes have been committed against the object,
       and invalidate the cache accordingly. In addition, the benefit from caching query results is limited, and highly
       dependent on the usage patterns of your application. For these reasons, Hibernate disables the query cache by
       default.
     </para>
     <procedure>
       <title>Enabling the query cache</title>
       <step>
         <title>Set the <property>hibernate.cache.use_query_cache</property> property to <literal>true</literal>.</title>
         <para>
           This setting creates two new cache regions:
         </para>
         <itemizedlist>
           <listitem>
             <para>
-              <code>org.hibernate.cache.StandardQueryCache</code> holds the cached query results.
+              <code>org.hibernate.cache.internal.StandardQueryCache</code> holds the cached query results.
             </para>
           </listitem>
           <listitem>
             <para>
-              <code>org.hibernate.cache.UpdateTimestampsCache</code> holds timestamps of the most recent updates to
+              <code>org.hibernate.cache.spi.UpdateTimestampsCache</code> holds timestamps of the most recent updates to
               queryable tables. These timestamps validate results served from the query cache.
             </para>
           </listitem>
         </itemizedlist>
       </step>
       <step>
         <title>Adjust the cache timeout of the underlying cache region</title>
         <para>
           If you configure your underlying cache implementation to use expiry or timeouts, set the cache timeout of the
           underlying cache region for the <code>UpdateTimestampsCache</code> to a higher value than the timeouts of any
           of the query caches. It is possible, and recommended, to set the UpdateTimestampsCache region never to
           expire. To be specific, a LRU (Least Recently Used) cache expiry policy is never appropriate.
         </para>
       </step>
       <step>
         <title>Enable results caching for specific queries</title>
         <para>
           Since most queries do not benefit from caching of their results, you need to enable caching for individual
           queries, e ven after enabling query caching overall. To enable results caching for a particular query, call
           <methodname>org.hibernate.Query.setCacheable(true)</methodname>. This call allows the query to look for
           existing cache results or add its results to the cache when it is executed.
         </para>
       </step>
     </procedure>
     <para>
       The query cache does not cache the state of the actual entities in the cache. It caches identifier values and
       results of value type. Therefore, always use the query cache in conjunction with the second-level
       cache for those entities which should be cached as part of a query result cache.
     </para>
     
     <section>
       <title>Query cache regions</title>
       <para>
         For fine-grained control over query cache expiration policies, specify a named cache region for a particular
         query by calling <methodname>Query.setCacheRegion()</methodname>.
       </para>
 
       <example>
         <title>Method <methodname>setCacheRegion</methodname></title>
         <programlisting language="Java" role="JAVA"><xi:include href="extras/setCacheRegion.java" xmlns:xi="http://www.w3.org/2001/XInclude" parse="text" /></programlisting>
       </example>
 
       <para>
         To force the query cache to refresh one of its regions and disregard any cached results in the region, call
         <code>org.hibernate.Query.setCacheMode(CacheMode.REFRESH)</code>. In conjunction with the region defined for the
         given query, Hibernate selectively refreshes the results cached in that particular region. This is much more
         efficient than bulk eviction of the region via <code>org.hibernate.SessionFactory.evictQueries()</code>.
       </para>
       
     </section>
 
   </section>
   
   <section>
     <title>Second-level cache providers</title>
     <para>
       Hibernate is compatible with several second-level cache providers. None of the providers support all of
       Hibernate's possible caching strategies. <xref linkend="caching-provider-table" /> lists the providers, along with
       their interfaces and supported caching strategies. For definitions of caching strategies, see <xref
       linkend="caching-strategies-list" />.
     </para>
     
     <section>
       <title>Configuring your cache providers</title>
       <para>
         You can configure your cache providers using either annotations or mapping files.
       </para>
       <formalpara>
         <title>Entities</title>
         <para>
           By default, entities are not part of the second-level cache, and their use is not recommended. If you
           absolutely must use entities, set the <code>shared-cache-mode</code> element in
           <filename>persistence.xml</filename>, or use property <property>javax.persistence.sharedCache.mode</property>
           in your configuration. Use one of the values in <xref linkend="shared-cache-mode-values" />.
         </para>
       </formalpara>
       <table id="shared-cache-mode-values">
         <title>Possible values for Shared Cache Mode</title>
         <tgroup cols="2">
           <thead>
             <row>
               <entry>Value</entry>
               <entry>Description</entry>
             </row>
           </thead>
           <tbody>
             <row>
               <entry>ENABLE_SELECTIVE</entry>
               <entry>
                 <para>
                   Entities are not cached unless you explicitly mark them as cachable. This is the default and
                   recommended value.
                 </para>
               </entry>
             </row>
             <row>
               <entry>DISABLE_SELECTIVE</entry>
               <entry>
                 <para>
                   Entities are cached unless you explicitly mark them as not cacheable.
                 </para>
               </entry>
             </row>
             <row>
               <entry>ALL</entry>
               <entry>
                 <para>
                   All entities are always cached even if you mark them as not cacheable.
                 </para>
               </entry>
             </row>
             <row>
               <entry>NONE</entry>
               <entry>
                 <para>
                   No entities are cached even if you mark them as cacheable. This option basically disables second-level
                   caching.
                 </para>
               </entry>
             </row>
           </tbody>
         </tgroup>
       </table>
       <para>
         Set the global default cache concurrency strategy The cache concurrency strategy with the
         <property>hibernate.cache.default_cache_concurrency_strategy</property> configuration property. See <xref
         linkend="caching-strategies-list" /> for possible values.
       </para>
       <note>
         <para>
           When possible, define the cache concurrency strategy per entity rather than globally. Use the
           <code>@org.hibernate.annotations.Cache</code> annotation.
         </para>
       </note>
       <example id="configuring-cache-providers-annotations">
         <title>Configuring cache providers using annotations</title>
         <programlisting language="Java" role="JAVA"><xi:include href="extras/cache_providers_mapping.java" xmlns:xi="http://www.w3.org/2001/XInclude" parse="text" /></programlisting>
         <para>
           You can cache the content of a collection or the identifiers, if the collection contains other entities. Use
           the <code>@Cache</code> annotation on the Collection property.
         </para>
         <para>
           <code>@Cache</code> can take several attributes.
         </para>
         <variablelist>
           <title>Attributes of <code>@Cache</code> annotation</title>
           <varlistentry>
             <term>usage</term>
             <listitem>
               <para>
                 The given cache concurrency strategy, which may be:
               </para>
               <itemizedlist>
                 <listitem>
                   <para>
                     <literal>NONE</literal>
                   </para>
                 </listitem>
                 <listitem>
                   <para>
                     <literal>READ_ONLY</literal>
                   </para>
                 </listitem>
                 <listitem>
                   <para>
                     <literal>NONSTRICT_READ_WRITE</literal>
                   </para>
                 </listitem>
                 <listitem>
                   <para>
                     <literal>READ_WRITE</literal>
                   </para>
                 </listitem>
                 <listitem>
                   <para>
                     <literal>TRANSACTIONAL</literal>
                   </para>
                 </listitem>
               </itemizedlist>
             </listitem>
           </varlistentry>
           <varlistentry>
             <term>region</term>
             <listitem>
               <para>
                 The cache region. This attribute is optional, and defaults to the fully-qualified class name of the
                 class, or the qually-qualified role name of the collection.
               </para>
             </listitem>
           </varlistentry>
           <varlistentry>
             <term>include</term>
             <listitem>
               <para>
                 Whether or not to include all properties.. Optional, and can take one of two possible values.
               </para>
               <itemizedlist>
                 <listitem>
                   <para>
                     A value of <literal>all</literal> includes all properties. This is the default.
                   </para>
                 </listitem>
                 <listitem>
                   <para>
                     A value of <literal>non-lazy</literal> only includes non-lazy properties.
                   </para>
                 </listitem>
               </itemizedlist>
             </listitem>
           </varlistentry>
         </variablelist>
       </example>
 
       <example>
         <title>Configuring cache providers using mapping files</title>
         <programlisting language="XML" role="XML"><xi:include href="extras/cache_providers.xml"
         xmlns:xi="http://www.w3.org/2001/XInclude" parse="text" /></programlisting>
         <para>
           Just as in the <xref linkend="configuring-cache-providers-annotations" />, you can provide attributes in the
           mapping file. There are some specific differences in the syntax for the attributes in a mapping file.
         </para>
         <variablelist>
           <varlistentry>
             <term>usage</term>
             <listitem>
               <para>
                 The caching strategy. This attribute is required, and can be any of the following values.
               </para>
               <itemizedlist>
                 <listitem><para>transactional</para></listitem>
                 <listitem><para>read-write</para></listitem>
                 <listitem><para>nonstrict-read-write</para></listitem>
                 <listitem><para>read-only</para></listitem>
               </itemizedlist>
             </listitem>
           </varlistentry>
           <varlistentry>
             <term>region</term>
             <listitem>
               <para>
                 The name of the second-level cache region. This optional attribute defaults to the class or collection
                 role name.
               </para>
             </listitem>
           </varlistentry>
           <varlistentry>
             <term>include</term>
             <listitem>
               <para>
                 Whether properties of the entity mapped with <literal>lazy=true</literal> can be cached when
                 attribute-level lazy fetching is enabled. Defaults to <literal>all</literal> and can also be
                 <literal>non-lazy</literal>.
               </para>
             </listitem>
           </varlistentry>
         </variablelist>
         <para>
           Instead of <code>&lt;cache&gt;</code>, you can use <code>&lt;class-cache&gt;</code> and
           <code>&lt;collection-cache&gt;</code> elements in <filename>hibernate.cfg.xml</filename>.
         </para>
       </example>
     </section>
     <section id="caching-strategies-list">
       <title>Caching strategies</title>
       <variablelist>
         <varlistentry>
           <term>read-only</term>
           <listitem>
             <para>
               A read-only cache is good for data that needs to be read often but not modified. It is simple, performs
               well, and is safe to use in a clustered environment.
             </para>
           </listitem>
         </varlistentry>
         <varlistentry>
           <term>nonstrict read-write</term>
           <listitem>
             <para>
               Some applications only rarely need to modify data. This is the case if two transactions are unlikely to
               try to update the same item simultaneously. In this case, you do not need strict transaction isolation,
               and a nonstrict-read-write cache might be appropriate. If the cache is used in a JTA environment, you must
               specify <classname>hibernate.transaction.manager_lookup_class</classname>. In other environments, ensore
               that the transaction is complete before you call <methodname>Session.close()</methodname> or
               <methodname>Session.disconnect()</methodname>.
             </para>
           </listitem>
         </varlistentry>
         <varlistentry>
           <term>read-write</term>
           <listitem>
             <para>
               A read-write cache is appropriate for an application which needs to update data regularly. Do not use a
               read-write strategy if you need serializable transaction isolation. In a JTA environment, specify a
               strategy for obtaining the JTA TransactionManager by setting the property
               <property>hibernate.transaction.manager_lookup_class</property>. In non-JTA environments, be sure the
               transaction is complete before you call <methodname>Session.close()</methodname> or
               <methodname>Session.disconnect()</methodname>.
             </para>
             <note>
               <para>
                 To use the read-write strategy in a clustered environment, the underlying cache implementation must
                 support locking. The build-in cache providers do not support locking.
               </para>
             </note>
           </listitem>
         </varlistentry>
         <varlistentry>
           <term>transactional</term>
           <listitem>
             <para>
               The transactional cache strategy provides support for transactional cache providers such as JBoss
               TreeCache. You can only use such a cache in a JTA environment, and you must first specify
               <classname>hibernate.transaction.manager_lookup_class</classname>.
             </para>
           </listitem>
         </varlistentry>
       </variablelist>
     </section>
     <section id="caching-provider-table">
       <title>Second-level cache providers for Hibernate</title>
       <informaltable>
         <tgroup cols="5">
           <thead>
             <row>
               <entry>Cache</entry>
               <entry>Interface</entry>
               <entry>Supported strategies</entry>
             </row>
           </thead>
           <tbody>
             <row>
               <entry>HashTable (testing only)</entry>
               <entry></entry>
               <entry>
                 <itemizedlist>
                   <listitem><para>read-only</para></listitem>
                   <listitem><para>nontrict read-write</para></listitem>
                   <listitem><para>read-write</para></listitem>
                 </itemizedlist>
               </entry>
             </row>
             <row>
               <entry>EHCache</entry>
               <entry></entry>
               <entry>
                 <itemizedlist>
                   <listitem><para>read-only</para></listitem>
                   <listitem><para>nontrict read-write</para></listitem>
                   <listitem><para>read-write</para></listitem>
                 </itemizedlist>
               </entry>
             </row>
             <row>
               <entry>OSCache</entry>
               <entry></entry>
               <entry>
                 <itemizedlist>
                   <listitem><para>read-only</para></listitem>
                   <listitem><para>nontrict read-write</para></listitem>
                   <listitem><para>read-write</para></listitem>
                 </itemizedlist>
               </entry>
             </row>
             <row>
               <entry>SwarmCache</entry>
               <entry></entry>
               <entry>
                 <itemizedlist>
                   <listitem><para>read-only</para></listitem>
                   <listitem><para>nontrict read-write</para></listitem>
                 </itemizedlist>
               </entry>
             </row>
             <row>
               <entry>JBoss Cache 1.x</entry>
               <entry></entry>
               <entry>
                 <itemizedlist>
                   <listitem><para>read-only</para></listitem>
                   <listitem><para>transactional</para></listitem>
                 </itemizedlist>
               </entry>
             </row>
             <row>
               <entry>JBoss Cache 2.x</entry>
               <entry></entry>
               <entry>
                 <itemizedlist>
                   <listitem><para>read-only</para></listitem>
                   <listitem><para>transactional</para></listitem>
                 </itemizedlist>
               </entry>
             </row>
           </tbody>
         </tgroup>
       </informaltable>
     </section>
   </section>
 
   <section>
     <title>Managing the cache</title>
     
     <section>
       <title>Moving items into and out of the cache</title>
       <variablelist>
         <title>Actions that add an item to internal cache of the Session</title>
         <varlistentry>
           <term>Saving or updating an item</term>
           <listitem>
             <itemizedlist>
               <listitem>
                 <para>
                   <methodname>save()</methodname>
                 </para>
               </listitem>
               <listitem>
                 <para>
                   <methodname>update()</methodname>
                 </para>
               </listitem>
               <listitem>
                 <para>
                   <methodname>saveOrUpdate()</methodname>
                 </para>
               </listitem>
             </itemizedlist>
           </listitem>
         </varlistentry>
         <varlistentry>
           <term>Retrieving an item</term>
           <listitem>
             <itemizedlist>
               <listitem>
                 <para>
                   <methodname>load()</methodname>
                 </para>
               </listitem>
               <listitem>
                 <para>
                   <methodname>get()</methodname>
                 </para>
               </listitem>
               <listitem>
                 <para>
                   <methodname>list()</methodname>
                 </para>
               </listitem>
               <listitem>
                 <para>
                   <methodname>iterate()</methodname>
                 </para>
               </listitem>
               <listitem>
                 <para>
                   <methodname>scroll()</methodname>
                 </para>
               </listitem>
             </itemizedlist>
           </listitem>
         </varlistentry>
       </variablelist>
       <formalpara>
         <title>Syncing or removing a cached item</title>
         <para>
           The state of an object is synchronized with the database when you call method
           <methodname>flush()</methodname>. To avoid this synchronization, you can remove the object and all collections
           from the first-level cache with the <methodname>evict()</methodname> method. To remove all items from the
           Session cache, use method <methodname>Session.clear()</methodname>.
         </para>
       </formalpara>
       <example>
         <title>Evicting an item from the first-level cache</title>
         <programlisting language="Java" role="JAVA"><xi:include href="extras/evicting_item.java" xmlns:xi="http://www.w3.org/2001/XInclude" parse="text" /></programlisting>
       </example>
       <formalpara>
         <title>Determining whether an item belongs to the Session cache</title>
         <para>
           The Session provides a <methodname>contains()</methodname> method to determine if an instance belongs to the
           session cache.
         </para>
       </formalpara>
       
       <example>
         <title>Second-level cache eviction</title>
         <para>
           You can evict the cached state of an instance, entire class, collection instance or entire collection role,
           using methods of <classname>SessionFactory</classname>.
         </para>
         <programlisting language="Java" role="JAVA"><xi:include href="extras/evicting_from_second_level_cache.java" xmlns:xi="http://www.w3.org/2001/XInclude" parse="text" /></programlisting>
       </example>       
       <section>
         <title>Interactions between a Session and the second-level cache</title>
         <para>
           The CacheMode controls how a particular session interacts with the second-level cache.
         </para>
         <informaltable>
           <tgroup cols="2">
             <tbody>
               <row>
                 <entry>CacheMode.NORMAL</entry>
                 <entry>reads items from and writes them to the second-level cache.</entry>
               </row>
               <row>
                 <entry>CacheMode.GET</entry>
                 <entry>reads items from the second-level cache, but does not write to the second-level cache except to
                 update data.</entry>
               </row>
               <row>
                 <entry>CacheMode.PUT</entry>
                 <entry>writes items to the second-level cache. It does not read from the second-level cache. It bypasses
                 the effect of <property>hibernate.cache.use_minimal_puts</property> and forces a refresh of the
                 second-level cache for all items read from the database.</entry>
               </row>
             </tbody>
           </tgroup>
         </informaltable>
       </section>
       
       <section>
         <title>Browsing the contents of a second-level or query cache region</title>
         <para>
           After enabling statistics, you can browse the contents of a second-level cache or query cache region.
         </para>
         <procedure>
           <title>Enabling Statistics</title>
           <step>
             <para>
               Set <code>hibernate.generate_statistics</code> to <literal>true</literal>.
             </para>
           </step>
           <step>
             <para>
               Optionally, set <code>hibernate.cache.use_structured_entries</code> to <literal>true</literal>, to cause
               Hibernate to store the cache entries in a human-readable format.
             </para>
           </step>
         </procedure>
         <example>
           <title>Browsing the second-level cache entries via the Statistics API</title> <programlisting language="Java"
           role="JAVA"><xi:include href="extras/browsing_cache.java" xmlns:xi="http://www.w3.org/2001/XInclude"
           parse="text" /></programlisting>
         </example>
       </section>
     </section>
   </section>
 </chapter>
diff --git a/documentation/src/main/docbook/devguide/en-US/extras/hibernate.cfg.xml b/documentation/src/main/docbook/devguide/en-US/extras/hibernate.cfg.xml
index 657bf4a140..3b142fd28c 100644
--- a/documentation/src/main/docbook/devguide/en-US/extras/hibernate.cfg.xml
+++ b/documentation/src/main/docbook/devguide/en-US/extras/hibernate.cfg.xml
@@ -1,33 +1,33 @@
 <?xml version='1.0' encoding='utf-8'?>
 <!DOCTYPE hibernate-configuration PUBLIC
 "-//Hibernate/Hibernate Configuration DTD 3.0//EN"
 "http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd">
 
 <hibernate-configuration>
   <session-factory>
     <!-- Database connection settings -->
     <property name="connection.driver_class">org.hsqldb.jdbcDriver</property>
     <property name="connection.url">jdbc:hsqldb:hsql://localhost</property>
     <property name="connection.username">sa</property>
     <property name="connection.password"></property>
 
     <!-- JDBC connection pool (use the built-in) -->
     <property name="connection.pool_size">1</property>
 
     <!-- SQL dialect -->
     <property name="dialect">org.hibernate.dialect.HSQLDialect</property>
 
     <!-- Enable Hibernate's automatic session context management -->
     <property name="current_session_context_class">thread</property>
 
     <!-- Disable the second-level cache  -->
-    <property name="cache.provider_class">org.hibernate.cache.NoCacheProvider</property>
+    <property name="cache.provider_class">org.hibernate.cache.internal.NoCacheProvider</property>
 
     <!-- Echo all executed SQL to stdout -->
     <property name="show_sql">true</property>
 
     <!-- Drop and re-create the database schema on startup -->
     <property name="hbm2ddl.auto">update</property>
     <mapping resource="org/hibernate/tutorial/domain/Event.hbm.xml"/>
   </session-factory>
 </hibernate-configuration>
diff --git a/documentation/src/main/docbook/manual/en-US/content/performance.xml b/documentation/src/main/docbook/manual/en-US/content/performance.xml
index 2582f7f402..6ca4d017d8 100644
--- a/documentation/src/main/docbook/manual/en-US/content/performance.xml
+++ b/documentation/src/main/docbook/manual/en-US/content/performance.xml
@@ -1,1693 +1,1693 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <!--
   ~ Hibernate, Relational Persistence for Idiomatic Java
   ~
   ~ Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
   ~ indicated by the @author tags or express copyright attribution
   ~ statements applied by the authors.  All third-party contributions are
   ~ distributed under license by Red Hat Middleware LLC.
   ~
   ~ This copyrighted material is made available to anyone wishing to use, modify,
   ~ copy, or redistribute it subject to the terms and conditions of the GNU
   ~ Lesser General Public License, as published by the Free Software Foundation.
   ~
   ~ This program is distributed in the hope that it will be useful,
   ~ but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
   ~ or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
   ~ for more details.
   ~
   ~ You should have received a copy of the GNU Lesser General Public License
   ~ along with this distribution; if not, write to:
   ~ Free Software Foundation, Inc.
   ~ 51 Franklin Street, Fifth Floor
   ~ Boston, MA  02110-1301  USA
   -->
 <!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
 "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd" [
 <!ENTITY % BOOK_ENTITIES SYSTEM "../HIBERNATE_-_Relational_Persistence_for_Idiomatic_Java.ent">
 %BOOK_ENTITIES;
 ]>
 <chapter id="performance">
   <title>Improving performance</title>
 
   <section id="performance-fetching" revision="2">
     <title>Fetching strategies</title>
 
     <para>Hibernate uses a <emphasis>fetching strategy</emphasis> to retrieve
     associated objects if the application needs to navigate the association.
     Fetch strategies can be declared in the O/R mapping metadata, or
     over-ridden by a particular HQL or <literal>Criteria</literal>
     query.</para>
 
     <para>Hibernate3 defines the following fetching strategies:</para>
 
     <itemizedlist>
       <listitem>
         <para><emphasis>Join fetching</emphasis>: Hibernate retrieves the
         associated instance or collection in the same
         <literal>SELECT</literal>, using an <literal>OUTER
         JOIN</literal>.</para>
       </listitem>
 
       <listitem>
         <para><emphasis>Select fetching</emphasis>: a second
         <literal>SELECT</literal> is used to retrieve the associated entity or
         collection. Unless you explicitly disable lazy fetching by specifying
         <literal>lazy="false"</literal>, this second select will only be
         executed when you access the association.</para>
       </listitem>
 
       <listitem>
         <para><emphasis>Subselect fetching</emphasis>: a second
         <literal>SELECT</literal> is used to retrieve the associated
         collections for all entities retrieved in a previous query or fetch.
         Unless you explicitly disable lazy fetching by specifying
         <literal>lazy="false"</literal>, this second select will only be
         executed when you access the association.</para>
       </listitem>
 
       <listitem>
         <para><emphasis>Batch fetching</emphasis>: an optimization strategy
         for select fetching. Hibernate retrieves a batch of entity instances
         or collections in a single <literal>SELECT</literal> by specifying a
         list of primary or foreign keys.</para>
       </listitem>
     </itemizedlist>
 
     <para>Hibernate also distinguishes between:</para>
 
     <itemizedlist>
       <listitem>
         <para><emphasis>Immediate fetching</emphasis>: an association,
         collection or attribute is fetched immediately when the owner is
         loaded.</para>
       </listitem>
 
       <listitem>
         <para><emphasis>Lazy collection fetching</emphasis>: a collection is
         fetched when the application invokes an operation upon that
         collection. This is the default for collections.</para>
       </listitem>
 
       <listitem>
         <para><emphasis>"Extra-lazy" collection fetching</emphasis>:
         individual elements of the collection are accessed from the database
         as needed. Hibernate tries not to fetch the whole collection into
         memory unless absolutely needed. It is suitable for large
         collections.</para>
       </listitem>
 
       <listitem>
         <para><emphasis>Proxy fetching</emphasis>: a single-valued association
         is fetched when a method other than the identifier getter is invoked
         upon the associated object.</para>
       </listitem>
 
       <listitem>
         <para><emphasis>"No-proxy" fetching</emphasis>: a single-valued
         association is fetched when the instance variable is accessed.
         Compared to proxy fetching, this approach is less lazy; the
         association is fetched even when only the identifier is accessed. It
         is also more transparent, since no proxy is visible to the
         application. This approach requires buildtime bytecode instrumentation
         and is rarely necessary.</para>
       </listitem>
 
       <listitem>
         <para><emphasis>Lazy attribute fetching</emphasis>: an attribute or
         single valued association is fetched when the instance variable is
         accessed. This approach requires buildtime bytecode instrumentation
         and is rarely necessary.</para>
       </listitem>
     </itemizedlist>
 
     <para>We have two orthogonal notions here: <emphasis>when</emphasis> is
     the association fetched and <emphasis>how</emphasis> is it fetched. It is
     important that you do not confuse them. We use <literal>fetch</literal> to
     tune performance. We can use <literal>lazy</literal> to define a contract
     for what data is always available in any detached instance of a particular
     class.</para>
 
     <section id="performance-fetching-lazy">
       <title>Working with lazy associations</title>
 
       <para>By default, Hibernate3 uses lazy select fetching for collections
       and lazy proxy fetching for single-valued associations. These defaults
       make sense for most associations in the majority of applications.</para>
 
       <para>If you set <literal>hibernate.default_batch_fetch_size</literal>,
       Hibernate will use the batch fetch optimization for lazy fetching. This
       optimization can also be enabled at a more granular level.</para>
 
       <para>Please be aware that access to a lazy association outside of the
       context of an open Hibernate session will result in an exception. For
       example:</para>
 
       <programlisting role="JAVA">s = sessions.openSession();
 Transaction tx = s.beginTransaction();
             
 User u = (User) s.createQuery("from User u where u.name=:userName")
     .setString("userName", userName).uniqueResult();
 Map permissions = u.getPermissions();
 
 tx.commit();
 s.close();
 
 Integer accessLevel = (Integer) permissions.get("accounts");  // Error!</programlisting>
 
       <para>Since the permissions collection was not initialized when the
       <literal>Session</literal> was closed, the collection will not be able
       to load its state. <emphasis>Hibernate does not support lazy
       initialization for detached objects</emphasis>. This can be fixed by
       moving the code that reads from the collection to just before the
       transaction is committed.</para>
 
       <para>Alternatively, you can use a non-lazy collection or association,
       by specifying <literal>lazy="false"</literal> for the association
       mapping. However, it is intended that lazy initialization be used for
       almost all collections and associations. If you define too many non-lazy
       associations in your object model, Hibernate will fetch the entire
       database into memory in every transaction.</para>
 
       <para>On the other hand, you can use join fetching, which is non-lazy by
       nature, instead of select fetching in a particular transaction. We will
       now explain how to customize the fetching strategy. In Hibernate3, the
       mechanisms for choosing a fetch strategy are identical for single-valued
       associations and collections.</para>
     </section>
 
     <section id="performance-fetching-custom" revision="4">
       <title>Tuning fetch strategies</title>
 
       <para>Select fetching (the default) is extremely vulnerable to N+1
       selects problems, so we might want to enable join fetching in the
       mapping document:</para>
 
       <programlisting role="XML">&lt;set name="permissions"
             fetch="join"&gt;
     &lt;key column="userId"/&gt;
     &lt;one-to-many class="Permission"/&gt;
 &lt;/set</programlisting>
 
       <programlisting role="XML">&lt;many-to-one name="mother" class="Cat" fetch="join"/&gt;</programlisting>
 
       <para>The <literal>fetch</literal> strategy defined in the mapping
       document affects:</para>
 
       <itemizedlist>
         <listitem>
           <para>retrieval via <literal>get()</literal> or
           <literal>load()</literal></para>
         </listitem>
 
         <listitem>
           <para>retrieval that happens implicitly when an association is
           navigated</para>
         </listitem>
 
         <listitem>
           <para><literal>Criteria</literal> queries</para>
         </listitem>
 
         <listitem>
           <para>HQL queries if <literal>subselect</literal> fetching is
           used</para>
         </listitem>
       </itemizedlist>
 
       <para>Irrespective of the fetching strategy you use, the defined
       non-lazy graph is guaranteed to be loaded into memory. This might,
       however, result in several immediate selects being used to execute a
       particular HQL query.</para>
 
       <para>Usually, the mapping document is not used to customize fetching.
       Instead, we keep the default behavior, and override it for a particular
       transaction, using <literal>left join fetch</literal> in HQL. This tells
       Hibernate to fetch the association eagerly in the first select, using an
       outer join. In the <literal>Criteria</literal> query API, you would use
       <literal>setFetchMode(FetchMode.JOIN)</literal>.</para>
 
       <para>If you want to change the fetching strategy used by
       <literal>get()</literal> or <literal>load()</literal>, you can use a
       <literal>Criteria</literal> query. For example:</para>
 
       <programlisting role="JAVA">User user = (User) session.createCriteria(User.class)
                 .setFetchMode("permissions", FetchMode.JOIN)
                 .add( Restrictions.idEq(userId) )
                 .uniqueResult();</programlisting>
 
       <para>This is Hibernate's equivalent of what some ORM solutions call a
       "fetch plan".</para>
 
       <para>A completely different approach to problems with N+1 selects is to
       use the second-level cache.</para>
     </section>
 
     <section id="performance-fetching-proxies" revision="2">
       <title>Single-ended association proxies</title>
 
       <para>Lazy fetching for collections is implemented using Hibernate's own
       implementation of persistent collections. However, a different mechanism
       is needed for lazy behavior in single-ended associations. The target
       entity of the association must be proxied. Hibernate implements lazy
       initializing proxies for persistent objects using runtime bytecode
       enhancement which is accessed via the CGLIB library.</para>
 
       <para>At startup, Hibernate3 generates proxies by default for all
       persistent classes and uses them to enable lazy fetching of
       <literal>many-to-one</literal> and <literal>one-to-one</literal>
       associations.</para>
 
       <para>The mapping file may declare an interface to use as the proxy
       interface for that class, with the <literal>proxy</literal> attribute.
       By default, Hibernate uses a subclass of the class. <emphasis>The
       proxied class must implement a default constructor with at least package
       visibility. This constructor is recommended for all persistent
       classes</emphasis>.</para>
 
       <para>There are potential problems to note when extending this approach
       to polymorphic classes.For example:</para>
 
       <programlisting role="XML">&lt;class name="Cat" proxy="Cat"&gt;
     ......
     &lt;subclass name="DomesticCat"&gt;
         .....
     &lt;/subclass&gt;
 &lt;/class&gt;</programlisting>
 
       <para>Firstly, instances of <literal>Cat</literal> will never be
       castable to <literal>DomesticCat</literal>, even if the underlying
       instance is an instance of <literal>DomesticCat</literal>:</para>
 
       <programlisting role="JAVA">Cat cat = (Cat) session.load(Cat.class, id);  // instantiate a proxy (does not hit the db)
 if ( cat.isDomesticCat() ) {                  // hit the db to initialize the proxy
     DomesticCat dc = (DomesticCat) cat;       // Error!
     ....
 }</programlisting>
 
       <para>Secondly, it is possible to break proxy
       <literal>==</literal>:</para>
 
       <programlisting role="JAVA">Cat cat = (Cat) session.load(Cat.class, id);            // instantiate a Cat proxy
 DomesticCat dc = 
         (DomesticCat) session.load(DomesticCat.class, id);  // acquire new DomesticCat proxy!
 System.out.println(cat==dc);                            // false</programlisting>
 
       <para>However, the situation is not quite as bad as it looks. Even
       though we now have two references to different proxy objects, the
       underlying instance will still be the same object:</para>
 
       <programlisting role="JAVA">cat.setWeight(11.0);  // hit the db to initialize the proxy
 System.out.println( dc.getWeight() );  // 11.0</programlisting>
 
       <para>Third, you cannot use a CGLIB proxy for a <literal>final</literal>
       class or a class with any <literal>final</literal> methods.</para>
 
       <para>Finally, if your persistent object acquires any resources upon
       instantiation (e.g. in initializers or default constructor), then those
       resources will also be acquired by the proxy. The proxy class is an
       actual subclass of the persistent class.</para>
 
       <para>These problems are all due to fundamental limitations in Java's
       single inheritance model. To avoid these problems your persistent
       classes must each implement an interface that declares its business
       methods. You should specify these interfaces in the mapping file where
       <literal>CatImpl</literal> implements the interface
       <literal>Cat</literal> and <literal>DomesticCatImpl</literal> implements
       the interface <literal>DomesticCat</literal>. For example:</para>
 
       <programlisting role="XML">&lt;class name="CatImpl" proxy="Cat"&gt;
     ......
     &lt;subclass name="DomesticCatImpl" proxy="DomesticCat"&gt;
         .....
     &lt;/subclass&gt;
 &lt;/class&gt;</programlisting>
 
       <para>Then proxies for instances of <literal>Cat</literal> and
       <literal>DomesticCat</literal> can be returned by
       <literal>load()</literal> or <literal>iterate()</literal>.</para>
 
       <programlisting role="JAVA">Cat cat = (Cat) session.load(CatImpl.class, catid);
 Iterator iter = session.createQuery("from CatImpl as cat where cat.name='fritz'").iterate();
 Cat fritz = (Cat) iter.next();</programlisting>
 
       <note>
         <title>Note</title>
 
         <para><literal>list()</literal> does not usually return
         proxies.</para>
       </note>
 
       <para>Relationships are also lazily initialized. This means you must
       declare any properties to be of type <literal>Cat</literal>, not
       <literal>CatImpl</literal>.</para>
 
       <para>Certain operations do <emphasis>not</emphasis> require proxy
       initialization:</para>
 
       <itemizedlist spacing="compact">
         <listitem>
           <para><literal>equals()</literal>: if the persistent class does not
           override <literal>equals()</literal></para>
         </listitem>
 
         <listitem>
           <para><literal>hashCode()</literal>: if the persistent class does
           not override <literal>hashCode()</literal></para>
         </listitem>
 
         <listitem>
           <para>The identifier getter method</para>
         </listitem>
       </itemizedlist>
 
       <para>Hibernate will detect persistent classes that override
       <literal>equals()</literal> or <literal>hashCode()</literal>.</para>
 
       <para>By choosing <literal>lazy="no-proxy"</literal> instead of the
       default <literal>lazy="proxy"</literal>, you can avoid problems
       associated with typecasting. However, buildtime bytecode instrumentation
       is required, and all operations will result in immediate proxy
       initialization.</para>
     </section>
 
     <section id="performance-fetching-initialization" revision="1">
       <title>Initializing collections and proxies</title>
 
       <para>A <literal>LazyInitializationException</literal> will be thrown by
       Hibernate if an uninitialized collection or proxy is accessed outside of
       the scope of the <literal>Session</literal>, i.e., when the entity
       owning the collection or having the reference to the proxy is in the
       detached state.</para>
 
       <para>Sometimes a proxy or collection needs to be initialized before
       closing the <literal>Session</literal>. You can force initialization by
       calling <literal>cat.getSex()</literal> or
       <literal>cat.getKittens().size()</literal>, for example. However, this
       can be confusing to readers of the code and it is not convenient for
       generic code.</para>
 
       <para>The static methods <literal>Hibernate.initialize()</literal> and
       <literal>Hibernate.isInitialized()</literal>, provide the application
       with a convenient way of working with lazily initialized collections or
       proxies. <literal>Hibernate.initialize(cat)</literal> will force the
       initialization of a proxy, <literal>cat</literal>, as long as its
       <literal>Session</literal> is still open. <literal>Hibernate.initialize(
       cat.getKittens() )</literal> has a similar effect for the collection of
       kittens.</para>
 
       <para>Another option is to keep the <literal>Session</literal> open
       until all required collections and proxies have been loaded. In some
       application architectures, particularly where the code that accesses
       data using Hibernate, and the code that uses it are in different
       application layers or different physical processes, it can be a problem
       to ensure that the <literal>Session</literal> is open when a collection
       is initialized. There are two basic ways to deal with this issue:</para>
 
       <itemizedlist>
         <listitem>
           <para>In a web-based application, a servlet filter can be used to
           close the <literal>Session</literal> only at the end of a user
           request, once the rendering of the view is complete (the
           <emphasis>Open Session in View</emphasis> pattern). Of course, this
           places heavy demands on the correctness of the exception handling of
           your application infrastructure. It is vitally important that the
           <literal>Session</literal> is closed and the transaction ended
           before returning to the user, even when an exception occurs during
           rendering of the view. See the Hibernate Wiki for examples of this
           "Open Session in View" pattern.</para>
         </listitem>
 
         <listitem>
           <para>In an application with a separate business tier, the business
           logic must "prepare" all collections that the web tier needs before
           returning. This means that the business tier should load all the
           data and return all the data already initialized to the
           presentation/web tier that is required for a particular use case.
           Usually, the application calls
           <literal>Hibernate.initialize()</literal> for each collection that
           will be needed in the web tier (this call must occur before the
           session is closed) or retrieves the collection eagerly using a
           Hibernate query with a <literal>FETCH</literal> clause or a
           <literal>FetchMode.JOIN</literal> in <literal>Criteria</literal>.
           This is usually easier if you adopt the <emphasis>Command</emphasis>
           pattern instead of a <emphasis>Session Facade</emphasis>.</para>
         </listitem>
 
         <listitem>
           <para>You can also attach a previously loaded object to a new
           <literal>Session</literal> with <literal>merge()</literal> or
           <literal>lock()</literal> before accessing uninitialized collections
           or other proxies. Hibernate does not, and certainly
           <emphasis>should</emphasis> not, do this automatically since it
           would introduce impromptu transaction semantics.</para>
         </listitem>
       </itemizedlist>
 
       <para>Sometimes you do not want to initialize a large collection, but
       still need some information about it, like its size, for example, or a
       subset of the data.</para>
 
       <para>You can use a collection filter to get the size of a collection
       without initializing it:</para>
 
       <programlisting role="JAVA">( (Integer) s.createFilter( collection, "select count(*)" ).list().get(0) ).intValue()</programlisting>
 
       <para>The <literal>createFilter()</literal> method is also used to
       efficiently retrieve subsets of a collection without needing to
       initialize the whole collection:</para>
 
       <programlisting role="JAVA">s.createFilter( lazyCollection, "").setFirstResult(0).setMaxResults(10).list();</programlisting>
     </section>
 
     <section id="performance-fetching-batch">
       <title>Using batch fetching</title>
 
       <para>Using batch fetching, Hibernate can load several uninitialized
       proxies if one proxy is accessed. Batch fetching is an optimization of
       the lazy select fetching strategy. There are two ways you can configure
       batch fetching: on the class level and the collection level.</para>
 
       <para>Batch fetching for classes/entities is easier to understand.
       Consider the following example: at runtime you have 25
       <literal>Cat</literal> instances loaded in a <literal>Session</literal>,
       and each <literal>Cat</literal> has a reference to its
       <literal>owner</literal>, a <literal>Person</literal>. The
       <literal>Person</literal> class is mapped with a proxy,
       <literal>lazy="true"</literal>. If you now iterate through all cats and
       call <literal>getOwner()</literal> on each, Hibernate will, by default,
       execute 25 <literal>SELECT</literal> statements to retrieve the proxied
       owners. You can tune this behavior by specifying a
       <literal>batch-size</literal> in the mapping of
       <literal>Person</literal>:</para>
 
       <programlisting role="XML">&lt;class name="Person" batch-size="10"&gt;...&lt;/class&gt;</programlisting>
 
       <para>Hibernate will now execute only three queries: the pattern is 10,
       10, 5.</para>
 
       <para>You can also enable batch fetching of collections. For example, if
       each <literal>Person</literal> has a lazy collection of
       <literal>Cat</literal>s, and 10 persons are currently loaded in the
       <literal>Session</literal>, iterating through all persons will generate
       10 <literal>SELECT</literal>s, one for every call to
       <literal>getCats()</literal>. If you enable batch fetching for the
       <literal>cats</literal> collection in the mapping of
       <literal>Person</literal>, Hibernate can pre-fetch collections:</para>
 
       <programlisting role="XML">&lt;class name="Person"&gt;
     &lt;set name="cats" batch-size="3"&gt;
         ...
     &lt;/set&gt;
 &lt;/class&gt;</programlisting>
 
       <para>With a <literal>batch-size</literal> of 3, Hibernate will load 3,
       3, 3, 1 collections in four <literal>SELECT</literal>s. Again, the value
       of the attribute depends on the expected number of uninitialized
       collections in a particular <literal>Session</literal>.</para>
 
       <para>Batch fetching of collections is particularly useful if you have a
       nested tree of items, i.e. the typical bill-of-materials pattern.
       However, a <emphasis>nested set</emphasis> or a <emphasis>materialized
       path</emphasis> might be a better option for read-mostly trees.</para>
     </section>
 
     <section id="performance-fetching-subselect">
       <title>Using subselect fetching</title>
 
       <para>If one lazy collection or single-valued proxy has to be fetched,
       Hibernate will load all of them, re-running the original query in a
       subselect. This works in the same way as batch-fetching but without the
       piecemeal loading.</para>
 
       <!-- TODO: Write more about this -->
     </section>
 
     <section id="performance-fetching-profiles">
       <title>Fetch profiles</title>
 
       <para>Another way to affect the fetching strategy for loading associated
       objects is through something called a fetch profile, which is a named
       configuration associated with the
       <interfacename>org.hibernate.SessionFactory</interfacename> but enabled,
       by name, on the <interfacename>org.hibernate.Session</interfacename>.
       Once enabled on a <interfacename>org.hibernate.Session</interfacename>,
       the fetch profile will be in affect for that
       <interfacename>org.hibernate.Session</interfacename> until it is
       explicitly disabled.</para>
 
       <para>So what does that mean? Well lets explain that by way of an
       example which show the different available approaches to configure a
       fetch profile:</para>
 
       <example>
         <title>Specifying a fetch profile using
         <classname>@FetchProfile</classname></title>
 
         <programlisting role="XML">@Entity
 @FetchProfile(name = "customer-with-orders", fetchOverrides = {
    @FetchProfile.FetchOverride(entity = Customer.class, association = "orders", mode = FetchMode.JOIN)
 })
 public class Customer {
    @Id
    @GeneratedValue
    private long id;
 
    private String name;
 
    private long customerNumber;
 
    @OneToMany
    private Set&lt;Order&gt; orders;
 
    // standard getter/setter
    ...
 }</programlisting>
       </example>
 
       <example>
         <title>Specifying a fetch profile using
         <literal>&lt;fetch-profile&gt;</literal> outside
         <literal>&lt;class&gt;</literal> node</title>
 
         <programlisting role="XML">&lt;hibernate-mapping&gt;
     &lt;class name="Customer"&gt;
         ...
         &lt;set name="orders" inverse="true"&gt;
             &lt;key column="cust_id"/&gt;
             &lt;one-to-many class="Order"/&gt;
         &lt;/set&gt;
     &lt;/class&gt;
     &lt;class name="Order"&gt;
         ...
     &lt;/class&gt;
     &lt;fetch-profile name="customer-with-orders"&gt;
         &lt;fetch entity="Customer" association="orders" style="join"/&gt;
     &lt;/fetch-profile&gt;
 &lt;/hibernate-mapping&gt;
 </programlisting>
       </example>
 
       <example>
         <title>Specifying a fetch profile using
         <literal>&lt;fetch-profile&gt;</literal> inside
         <literal>&lt;class&gt;</literal> node</title>
 
         <programlisting role="XML">&lt;hibernate-mapping&gt;
     &lt;class name="Customer"&gt;
         ...
         &lt;set name="orders" inverse="true"&gt;
             &lt;key column="cust_id"/&gt;
             &lt;one-to-many class="Order"/&gt;
         &lt;/set&gt;
         &lt;fetch-profile name="customer-with-orders"&gt;
             &lt;fetch association="orders" style="join"/&gt;
         &lt;/fetch-profile&gt;
     &lt;/class&gt;
     &lt;class name="Order"&gt;
         ...
     &lt;/class&gt;
 &lt;/hibernate-mapping&gt;
 </programlisting>
       </example>
 
       <para>Now normally when you get a reference to a particular customer,
       that customer's set of orders will be lazy meaning we will not yet have
       loaded those orders from the database. Normally this is a good thing.
       Now lets say that you have a certain use case where it is more efficient
       to load the customer and their orders together. One way certainly is to
       use "dynamic fetching" strategies via an HQL or criteria queries. But
       another option is to use a fetch profile to achieve that. The following
       code will load both the customer <emphasis>and</emphasis>their
       orders:</para>
 
       <example>
         <title>Activating a fetch profile for a given
         <classname>Session</classname></title>
 
         <programlisting role="JAVA">Session session = ...;
 session.enableFetchProfile( "customer-with-orders" );  // name matches from mapping
 Customer customer = (Customer) session.get( Customer.class, customerId );
 </programlisting>
       </example>
 
       <note>
         <para><classname>@FetchProfile </classname>definitions are global and
         it does not matter on which class you place them. You can place the
         <classname>@FetchProfile</classname> annotation either onto a class or
         package (package-info.java). In order to define multiple fetch
         profiles for the same class or package
         <classname>@FetchProfiles</classname> can be used.</para>
       </note>
 
       <para>Currently only join style fetch profiles are supported, but they
       plan is to support additional styles. See <ulink
       url="http://opensource.atlassian.com/projects/hibernate/browse/HHH-3414">HHH-3414</ulink>
       for details.</para>
     </section>
 
     <section id="performance-fetching-lazyproperties">
       <title>Using lazy property fetching</title>
 
       <para>Hibernate3 supports the lazy fetching of individual properties.
       This optimization technique is also known as <emphasis>fetch
       groups</emphasis>. Please note that this is mostly a marketing feature;
       optimizing row reads is much more important than optimization of column
       reads. However, only loading some properties of a class could be useful
       in extreme cases. For example, when legacy tables have hundreds of
       columns and the data model cannot be improved.</para>
 
       <para>To enable lazy property loading, set the <literal>lazy</literal>
       attribute on your particular property mappings:</para>
 
       <programlisting role="XML">&lt;class name="Document"&gt;
        &lt;id name="id"&gt;
         &lt;generator class="native"/&gt;
     &lt;/id&gt;
     &lt;property name="name" not-null="true" length="50"/&gt;
     &lt;property name="summary" not-null="true" length="200" lazy="true"/&gt;
     &lt;property name="text" not-null="true" length="2000" lazy="true"/&gt;
 &lt;/class&gt;</programlisting>
 
       <para>Lazy property loading requires buildtime bytecode instrumentation.
       If your persistent classes are not enhanced, Hibernate will ignore lazy
       property settings and return to immediate fetching.</para>
 
       <para>For bytecode instrumentation, use the following Ant task:</para>
 
       <programlisting role="XML">&lt;target name="instrument" depends="compile"&gt;
     &lt;taskdef name="instrument" classname="org.hibernate.tool.instrument.InstrumentTask"&gt;
         &lt;classpath path="${jar.path}"/&gt;
         &lt;classpath path="${classes.dir}"/&gt;
         &lt;classpath refid="lib.class.path"/&gt;
     &lt;/taskdef&gt;
 
     &lt;instrument verbose="true"&gt;
         &lt;fileset dir="${testclasses.dir}/org/hibernate/auction/model"&gt;
             &lt;include name="*.class"/&gt;
         &lt;/fileset&gt;
     &lt;/instrument&gt;
 &lt;/target&gt;</programlisting>
 
       <para>A different way of avoiding unnecessary column reads, at least for
       read-only transactions, is to use the projection features of HQL or
       Criteria queries. This avoids the need for buildtime bytecode processing
       and is certainly a preferred solution.</para>
 
       <para>You can force the usual eager fetching of properties using
       <literal>fetch all properties</literal> in HQL.</para>
     </section>
   </section>
 
   <section id="performance-cache" revision="1">
     <title>The Second Level Cache</title>
 
     <para>A Hibernate <literal>Session</literal> is a transaction-level cache
     of persistent data. It is possible to configure a cluster or JVM-level
     (<literal>SessionFactory</literal>-level) cache on a class-by-class and
     collection-by-collection basis. You can even plug in a clustered cache. Be
     aware that caches are not aware of changes made to the persistent store by
     another application. They can, however, be configured to regularly expire
     cached data.</para>
 
     <para revision="1">You have the option to tell Hibernate which caching
     implementation to use by specifying the name of a class that implements
-    <literal>org.hibernate.cache.CacheProvider</literal> using the property
+    <literal>org.hibernate.cache.spi.CacheProvider</literal> using the property
     <literal>hibernate.cache.provider_class</literal>. Hibernate is bundled
     with a number of built-in integrations with the open-source cache
     providers that are listed in <xref linkend="cacheproviders" />. You can
     also implement your own and plug it in as outlined above. Note that
     versions prior to Hibernate 3.2 use EhCache as the default cache
     provider.</para>
 
     <table frame="topbot" id="cacheproviders" revision="1">
       <title>Cache Providers</title>
 
       <tgroup align="left" cols="5" colsep="1" rowsep="1">
         <colspec colname="c1" colwidth="1*" />
 
         <colspec colname="c2" colwidth="3*" />
 
         <colspec colname="c3" colwidth="1*" />
 
         <colspec colname="c4" colwidth="1*" />
 
         <colspec colname="c5" colwidth="1*" />
 
         <thead>
           <row>
             <entry>Cache</entry>
 
             <entry>Provider class</entry>
 
             <entry>Type</entry>
 
             <entry>Cluster Safe</entry>
 
             <entry>Query Cache Supported</entry>
           </row>
         </thead>
 
         <tbody>
           <row>
             <entry>Hashtable (not intended for production use)</entry>
 
-            <entry><literal>org.hibernate.cache.HashtableCacheProvider</literal></entry>
+            <entry><literal>org.hibernate.cache.internal.HashtableCacheProvider</literal></entry>
 
             <entry>memory</entry>
 
             <entry></entry>
 
             <entry>yes</entry>
           </row>
 
           <row>
             <entry>EHCache</entry>
 
             <entry><literal>org.hibernate.cache.internal.EhCacheProvider</literal></entry>
 
             <entry>memory, disk</entry>
 
             <entry></entry>
 
             <entry>yes</entry>
           </row>
 
           <row>
             <entry>OSCache</entry>
 
             <entry><literal>org.hibernate.cache.OSCacheProvider</literal></entry>
 
             <entry>memory, disk</entry>
 
             <entry></entry>
 
             <entry>yes</entry>
           </row>
 
           <row>
             <entry>SwarmCache</entry>
 
             <entry><literal>org.hibernate.cache.SwarmCacheProvider</literal></entry>
 
             <entry>clustered (ip multicast)</entry>
 
             <entry>yes (clustered invalidation)</entry>
 
             <entry></entry>
           </row>
 
           <row>
             <entry>JBoss Cache 1.x</entry>
 
             <entry><literal>org.hibernate.cache.TreeCacheProvider</literal></entry>
 
             <entry>clustered (ip multicast), transactional</entry>
 
             <entry>yes (replication)</entry>
 
             <entry>yes (clock sync req.)</entry>
           </row>
 
           <row>
             <entry>JBoss Cache 2</entry>
 
             <entry><literal>org.hibernate.cache.jbc.JBossCacheRegionFactory</literal></entry>
 
             <entry>clustered (ip multicast), transactional</entry>
 
             <entry>yes (replication or invalidation)</entry>
 
             <entry>yes (clock sync req.)</entry>
           </row>
         </tbody>
       </tgroup>
     </table>
 
     <section id="performance-cache-mapping" revision="2">
       <title>Cache mappings</title>
 
       <para>As we have done in previous chapters we are looking at the two
       different possibiltites to configure caching. First configuration via
       annotations and then via Hibernate mapping files.</para>
 
       <para>By default, entities are not part of the second level cache and we
       recommend you to stick to this setting. However, you can override this
       by setting the <literal>shared-cache-mode</literal> element in your
       <filename>persistence.xml</filename> file or by using the
       <literal>javax.persistence.sharedCache.mode </literal>property in your
       configuration. The following values are possible:</para>
 
       <itemizedlist>
         <listitem>
           <para><literal>ENABLE_SELECTIVE</literal> (Default and recommended
           value): entities are not cached unless explicitly marked as
           cacheable.</para>
         </listitem>
 
         <listitem>
           <para><literal>DISABLE_SELECTIVE</literal>: entities are cached
           unless explicitly marked as not cacheable.</para>
         </listitem>
 
         <listitem>
           <para><literal>ALL</literal>: all entities are always cached even if
           marked as non cacheable.</para>
         </listitem>
 
         <listitem>
           <para><literal>NONE</literal>: no entity are cached even if marked
           as cacheable. This option can make sense to disable second-level
           cache altogether.</para>
         </listitem>
       </itemizedlist>
 
       <para>The cache concurrency strategy used by default can be set globaly
       via the
       <literal>hibernate.cache.default_cache_concurrency_strategy</literal>
       configuration property. The values for this property are:</para>
 
       <itemizedlist>
         <listitem>
           <para><literal>read-only</literal></para>
         </listitem>
 
         <listitem>
           <para><literal>read-write</literal></para>
         </listitem>
 
         <listitem>
           <para><literal>nonstrict-read-write</literal></para>
         </listitem>
 
         <listitem>
           <para><literal>transactional</literal></para>
         </listitem>
       </itemizedlist>
 
       <note>
         <para>It is recommended to define the cache concurrency strategy per
         entity rather than using a global one. Use the
         <classname>@org.hibernate.annotations.Cache</classname> annotation for
         that.</para>
       </note>
 
       <example id="example-cache-concurrency-with-cache-annotation">
         <title>Definition of cache concurrency strategy via
         <classname>@Cache</classname></title>
 
         <programlisting language="JAVA" role="JAVA">@Entity 
 @Cacheable
 @Cache(usage = CacheConcurrencyStrategy.NONSTRICT_READ_WRITE)
 public class Forest { ... }</programlisting>
       </example>
 
       <para>Hibernate also let's you cache the content of a collection or the
       identifiers if the collection contains other entities. Use the
       <classname>@Cache</classname> annotation on the collection
       property.</para>
 
       <example>
         <title>Caching collections using annotations</title>
 
         <programlisting language="JAVA" role="JAVA">@OneToMany(cascade=CascadeType.ALL, fetch=FetchType.EAGER)
 @JoinColumn(name="CUST_ID")
 @Cache(usage = CacheConcurrencyStrategy.NONSTRICT_READ_WRITE)
 public SortedSet&lt;Ticket&gt; getTickets() {
     return tickets;
 }</programlisting>
       </example>
 
       <para><xref linkend="example-cache-annotation-with-attributes" />shows
       the<literal> @org.hibernate.annotations.Cache</literal> annotations with
       its attributes. It allows you to define the caching strategy and region
       of a given second level cache.</para>
 
       <example id="example-cache-annotation-with-attributes">
         <title><classname>@Cache</classname> annotation with
         attributes</title>
 
         <programlistingco>
           <areaspec>
             <area coords="2" id="cache-hm1" />
 
             <area coords="3" id="cache-hm2" />
 
             <area coords="4" id="cache-hm3" />
           </areaspec>
 
           <programlisting>@Cache(
     CacheConcurrencyStrategy usage();
     String region() default "";
     String include() default "all";
 )</programlisting>
 
           <calloutlist>
             <callout arearefs="cache-hm1">
               <para>usage: the given cache concurrency strategy (NONE,
               READ_ONLY, NONSTRICT_READ_WRITE, READ_WRITE,
               TRANSACTIONAL)</para>
             </callout>
 
             <callout arearefs="cache-hm2">
               <para>region (optional): the cache region (default to the fqcn
               of the class or the fq role name of the collection)</para>
             </callout>
 
             <callout arearefs="cache-hm3">
               <para><literal>include</literal> (optional): all to include all
               properties, non-lazy to only include non lazy properties
               (default all).</para>
             </callout>
           </calloutlist>
         </programlistingco>
       </example>
 
       <para>Let's now take a look at Hibernate mapping files. There the
       <literal>&lt;cache&gt;</literal> element of a class or collection
       mapping is used to configure the second level cache. Looking at <xref
       linkend="example-hibernate-cache-mapping-element" /> the parallels to
       anotations is obvious.</para>
 
       <example id="example-hibernate-cache-mapping-element">
         <title>The Hibernate <literal>&lt;cache&gt;</literal> mapping
         element</title>
 
         <programlistingco>
           <areaspec>
             <area coords="2" id="cache1" />
 
             <area coords="3" id="cache2" />
 
             <area coords="4" id="cache3" />
           </areaspec>
 
           <programlisting>&lt;cache
     usage="transactional|read-write|nonstrict-read-write|read-only"
     region="RegionName"
     include="all|non-lazy"
 /&gt;</programlisting>
 
           <calloutlist>
             <callout arearefs="cache1">
               <para><literal>usage</literal> (required) specifies the caching
               strategy: <literal>transactional</literal>,
               <literal>read-write</literal>,
               <literal>nonstrict-read-write</literal> or
               <literal>read-only</literal></para>
             </callout>
 
             <callout arearefs="cache2">
               <para><literal>region</literal> (optional: defaults to the class
               or collection role name): specifies the name of the second level
               cache region</para>
             </callout>
 
             <callout arearefs="cache3">
               <para><literal>include</literal> (optional: defaults to
               <literal>all</literal>) <literal>non-lazy</literal>: specifies
               that properties of the entity mapped with
               <literal>lazy="true"</literal> cannot be cached when
               attribute-level lazy fetching is enabled</para>
             </callout>
           </calloutlist>
         </programlistingco>
       </example>
 
       <para>Alternatively to <literal>&lt;cache&gt;</literal>, you can use
       <literal>&lt;class-cache&gt;</literal> and
       <literal>&lt;collection-cache&gt;</literal> elements in
       <literal>hibernate.cfg.xml</literal>.</para>
 
       <para>Let's now have a closer look at the different usage
       strategies</para>
     </section>
 
     <section id="performance-cache-readonly">
       <title>Strategy: read only</title>
 
       <para>If your application needs to read, but not modify, instances of a
       persistent class, a <literal>read-only</literal> cache can be used. This
       is the simplest and optimal performing strategy. It is even safe for use
       in a cluster.</para>
     </section>
 
     <section id="performance-cache-readwrite">
       <title>Strategy: read/write</title>
 
       <para>If the application needs to update data, a
       <literal>read-write</literal> cache might be appropriate. This cache
       strategy should never be used if serializable transaction isolation
       level is required. If the cache is used in a JTA environment, you must
       specify the property
       <literal>hibernate.transaction.manager_lookup_class</literal> and naming
       a strategy for obtaining the JTA <literal>TransactionManager</literal>.
       In other environments, you should ensure that the transaction is
       completed when <literal>Session.close()</literal> or
       <literal>Session.disconnect()</literal> is called. If you want to use
       this strategy in a cluster, you should ensure that the underlying cache
       implementation supports locking. The built-in cache providers
       <emphasis>do not</emphasis> support locking.</para>
     </section>
 
     <section id="performance-cache-nonstrict">
       <title>Strategy: nonstrict read/write</title>
 
       <para>If the application only occasionally needs to update data (i.e. if
       it is extremely unlikely that two transactions would try to update the
       same item simultaneously), and strict transaction isolation is not
       required, a <literal>nonstrict-read-write</literal> cache might be
       appropriate. If the cache is used in a JTA environment, you must specify
       <literal>hibernate.transaction.manager_lookup_class</literal>. In other
       environments, you should ensure that the transaction is completed when
       <literal>Session.close()</literal> or
       <literal>Session.disconnect()</literal> is called.</para>
     </section>
 
     <section id="performance-cache-transactional">
       <title>Strategy: transactional</title>
 
       <para>The <literal>transactional</literal> cache strategy provides
       support for fully transactional cache providers such as JBoss TreeCache.
       Such a cache can only be used in a JTA environment and you must specify
       <literal>hibernate.transaction.manager_lookup_class</literal>.</para>
     </section>
 
     <section id="performance-cache-compat-matrix">
       <title>Cache-provider/concurrency-strategy compatibility</title>
 
       <important>
         <para>None of the cache providers support all of the cache concurrency
         strategies.</para>
       </important>
 
       <para>The following table shows which providers are compatible with
       which concurrency strategies.</para>
 
       <table frame="topbot">
         <title>Cache Concurrency Strategy Support</title>
 
         <tgroup align="left" cols="5" colsep="1" rowsep="1">
           <colspec colname="c1" colwidth="1*" />
 
           <colspec colname="c2" colwidth="1*" />
 
           <colspec colname="c3" colwidth="1*" />
 
           <colspec colname="c4" colwidth="1*" />
 
           <colspec colname="c5" colwidth="1*" />
 
           <thead>
             <row>
               <entry>Cache</entry>
 
               <entry>read-only</entry>
 
               <entry>nonstrict-read-write</entry>
 
               <entry>read-write</entry>
 
               <entry>transactional</entry>
             </row>
           </thead>
 
           <tbody>
             <row>
               <entry>Hashtable (not intended for production use)</entry>
 
               <entry>yes</entry>
 
               <entry>yes</entry>
 
               <entry>yes</entry>
 
               <entry></entry>
             </row>
 
             <row>
               <entry>EHCache</entry>
 
               <entry>yes</entry>
 
               <entry>yes</entry>
 
               <entry>yes</entry>
 
               <entry></entry>
             </row>
 
             <row>
               <entry>OSCache</entry>
 
               <entry>yes</entry>
 
               <entry>yes</entry>
 
               <entry>yes</entry>
 
               <entry></entry>
             </row>
 
             <row>
               <entry>SwarmCache</entry>
 
               <entry>yes</entry>
 
               <entry>yes</entry>
 
               <entry></entry>
 
               <entry></entry>
             </row>
 
             <row>
               <entry>JBoss Cache 1.x</entry>
 
               <entry>yes</entry>
 
               <entry></entry>
 
               <entry></entry>
 
               <entry>yes</entry>
             </row>
 
             <row>
               <entry>JBoss Cache 2</entry>
 
               <entry>yes</entry>
 
               <entry></entry>
 
               <entry></entry>
 
               <entry>yes</entry>
             </row>
           </tbody>
         </tgroup>
       </table>
     </section>
   </section>
 
   <section id="performance-sessioncache" revision="2">
     <title>Managing the caches</title>
 
     <para>Whenever you pass an object to <literal>save()</literal>,
     <literal>update()</literal> or <literal>saveOrUpdate()</literal>, and
     whenever you retrieve an object using <literal>load()</literal>,
     <literal>get()</literal>, <literal>list()</literal>,
     <literal>iterate()</literal> or <literal>scroll()</literal>, that object
     is added to the internal cache of the <literal>Session</literal>.</para>
 
     <para>When <literal>flush()</literal> is subsequently called, the state of
     that object will be synchronized with the database. If you do not want
     this synchronization to occur, or if you are processing a huge number of
     objects and need to manage memory efficiently, the
     <literal>evict()</literal> method can be used to remove the object and its
     collections from the first-level cache.</para>
 
     <example>
       <title>Explcitly evicting a cached instance from the first level cache
       using <methodname>Session.evict()</methodname></title>
 
       <programlisting role="JAVA">ScrollableResult cats = sess.createQuery("from Cat as cat").scroll(); //a huge result set
 while ( cats.next() ) {
     Cat cat = (Cat) cats.get(0);
     doSomethingWithACat(cat);
     sess.evict(cat);
 }</programlisting>
     </example>
 
     <para>The <literal>Session</literal> also provides a
     <literal>contains()</literal> method to determine if an instance belongs
     to the session cache.</para>
 
     <para>To evict all objects from the session cache, call
     <literal>Session.clear()</literal></para>
 
     <para>For the second-level cache, there are methods defined on
     <literal>SessionFactory</literal> for evicting the cached state of an
     instance, entire class, collection instance or entire collection
     role.</para>
 
     <example>
       <title>Second-level cache eviction via
       <methodname>SessionFactoty.evict() </methodname>and
       <methodname>SessionFacyory.evictCollection()</methodname></title>
 
       <programlisting role="JAVA">sessionFactory.evict(Cat.class, catId); //evict a particular Cat
 sessionFactory.evict(Cat.class);  //evict all Cats
 sessionFactory.evictCollection("Cat.kittens", catId); //evict a particular collection of kittens
 sessionFactory.evictCollection("Cat.kittens"); //evict all kitten collections</programlisting>
     </example>
 
     <para>The <literal>CacheMode</literal> controls how a particular session
     interacts with the second-level cache:</para>
 
     <itemizedlist>
       <listitem>
         <para><literal>CacheMode.NORMAL</literal>: will read items from and
         write items to the second-level cache</para>
       </listitem>
 
       <listitem>
         <para><literal>CacheMode.GET</literal>: will read items from the
         second-level cache. Do not write to the second-level cache except when
         updating data</para>
       </listitem>
 
       <listitem>
         <para><literal>CacheMode.PUT</literal>: will write items to the
         second-level cache. Do not read from the second-level cache</para>
       </listitem>
 
       <listitem>
         <para><literal>CacheMode.REFRESH</literal>: will write items to the
         second-level cache. Do not read from the second-level cache. Bypass
         the effect of <literal>hibernate.cache.use_minimal_puts</literal>
         forcing a refresh of the second-level cache for all items read from
         the database</para>
       </listitem>
     </itemizedlist>
 
     <para>To browse the contents of a second-level or query cache region, use
     the <literal>Statistics</literal> API:</para>
 
     <example>
       <title>Browsing the second-level cache entries via the
       <classname>Statistics</classname> API</title>
 
       <programlisting role="JAVA">Map cacheEntries = sessionFactory.getStatistics()
         .getSecondLevelCacheStatistics(regionName)
         .getEntries();</programlisting>
     </example>
 
     <para>You will need to enable statistics and, optionally, force Hibernate
     to keep the cache entries in a more readable format:</para>
 
     <example>
       <title>Enabling Hibernate statistics</title>
 
       <programlisting>hibernate.generate_statistics true
 hibernate.cache.use_structured_entries true</programlisting>
     </example>
   </section>
 
   <section id="performance-querycache" revision="1">
     <title>The Query Cache</title>
 
     <para>Query result sets can also be cached. This is only useful for
     queries that are run frequently with the same parameters.</para>
 
     <section id="performance-querycache-enable">
       <title>Enabling query caching</title>
 
       <para>Caching of query results introduces some overhead in terms of your
       applications normal transactional processing. For example, if you cache
       results of a query against Person Hibernate will need to keep track of
       when those results should be invalidated because changes have been
       committed against Person. That, coupled with the fact that most
       applications simply gain no benefit from caching query results, leads
       Hibernate to disable caching of query results by default. To use query
       caching, you will first need to enable the query cache:</para>
 
       <programlisting>hibernate.cache.use_query_cache true</programlisting>
 
       <para>This setting creates two new cache regions: <itemizedlist>
           <listitem>
-            <para><classname>org.hibernate.cache.StandardQueryCache</classname>,
+            <para><classname>org.hibernate.cache.internal.StandardQueryCache</classname>,
             holding the cached query results</para>
           </listitem>
 
           <listitem>
-            <para><classname>org.hibernate.cache.UpdateTimestampsCache</classname>,
+            <para><classname>org.hibernate.cache.spi.UpdateTimestampsCache</classname>,
             holding timestamps of the most recent updates to queryable tables.
             These are used to validate the results as they are served from the
             query cache.</para>
           </listitem>
         </itemizedlist></para>
 
       <important>
         <para>If you configure your underlying cache implementation to use
         expiry or timeouts is very important that the cache timeout of the
         underlying cache region for the UpdateTimestampsCache be set to a
         higher value than the timeouts of any of the query caches. In fact, we
         recommend that the the UpdateTimestampsCache region not be configured
         for expiry at all. Note, in particular, that an LRU cache expiry
         policy is never appropriate.</para>
       </important>
 
       <para>As mentioned above, most queries do not benefit from caching or
       their results. So by default, individual queries are not cached even
       after enabling query caching. To enable results caching for a particular
       query, call <literal>org.hibernate.Query.setCacheable(true)</literal>.
       This call allows the query to look for existing cache results or add its
       results to the cache when it is executed.</para>
 
       <note>
         <para>The query cache does not cache the state of the actual entities
         in the cache; it caches only identifier values and results of value
         type. For this reaso, the query cache should always be used in
         conjunction with the second-level cache for those entities expected to
         be cached as part of a query result cache (just as with collection
         caching).</para>
       </note>
     </section>
 
     <section id="performance-querycache-regions">
       <title>Query cache regions</title>
 
       <para>If you require fine-grained control over query cache expiration
       policies, you can specify a named cache region for a particular query by
       calling <literal>Query.setCacheRegion()</literal>.</para>
 
       <programlisting role="JAVA">List blogs = sess.createQuery("from Blog blog where blog.blogger = :blogger")
         .setEntity("blogger", blogger)
         .setMaxResults(15)
         .setCacheable(true)
         .setCacheRegion("frontpages")
         .list();</programlisting>
 
       <para>If you want to force the query cache to refresh one of its regions
       (disregard any cached results it finds there) you can use
       <literal>org.hibernate.Query.setCacheMode(CacheMode.REFRESH)</literal>.
       In conjunction with the region you have defined for the given query,
       Hibernate will selectively force the results cached in that particular
       region to be refreshed. This is particularly useful in cases where
       underlying data may have been updated via a separate process and is a
       far more efficient alternative to bulk eviction of the region via
       <literal>org.hibernate.SessionFactory.evictQueries()</literal>.</para>
     </section>
   </section>
 
   <section id="performance-collections">
     <title>Understanding Collection performance</title>
 
     <para>In the previous sections we have covered collections and their
     applications. In this section we explore some more issues in relation to
     collections at runtime.</para>
 
     <section id="performance-collections-taxonomy">
       <title>Taxonomy</title>
 
       <para>Hibernate defines three basic kinds of collections:</para>
 
       <itemizedlist>
         <listitem>
           <para>collections of values</para>
         </listitem>
 
         <listitem>
           <para>one-to-many associations</para>
         </listitem>
 
         <listitem>
           <para>many-to-many associations</para>
         </listitem>
       </itemizedlist>
 
       <para>This classification distinguishes the various table and foreign
       key relationships but does not tell us quite everything we need to know
       about the relational model. To fully understand the relational structure
       and performance characteristics, we must also consider the structure of
       the primary key that is used by Hibernate to update or delete collection
       rows. This suggests the following classification:</para>
 
       <itemizedlist>
         <listitem>
           <para>indexed collections</para>
         </listitem>
 
         <listitem>
           <para>sets</para>
         </listitem>
 
         <listitem>
           <para>bags</para>
         </listitem>
       </itemizedlist>
 
       <para>All indexed collections (maps, lists, and arrays) have a primary
       key consisting of the <literal>&lt;key&gt;</literal> and
       <literal>&lt;index&gt;</literal> columns. In this case, collection
       updates are extremely efficient. The primary key can be efficiently
       indexed and a particular row can be efficiently located when Hibernate
       tries to update or delete it.</para>
 
       <para>Sets have a primary key consisting of
       <literal>&lt;key&gt;</literal> and element columns. This can be less
       efficient for some types of collection element, particularly composite
       elements or large text or binary fields, as the database may not be able
       to index a complex primary key as efficiently. However, for one-to-many
       or many-to-many associations, particularly in the case of synthetic
       identifiers, it is likely to be just as efficient. If you want
       <literal>SchemaExport</literal> to actually create the primary key of a
       <literal>&lt;set&gt;</literal>, you must declare all columns as
       <literal>not-null="true"</literal>.</para>
 
       <para><literal>&lt;idbag&gt;</literal> mappings define a surrogate key,
       so they are efficient to update. In fact, they are the best case.</para>
 
       <para>Bags are the worst case since they permit duplicate element values
       and, as they have no index column, no primary key can be defined.
       Hibernate has no way of distinguishing between duplicate rows. Hibernate
       resolves this problem by completely removing in a single
       <literal>DELETE</literal> and recreating the collection whenever it
       changes. This can be inefficient.</para>
 
       <para>For a one-to-many association, the "primary key" may not be the
       physical primary key of the database table. Even in this case, the above
       classification is still useful. It reflects how Hibernate "locates"
       individual rows of the collection.</para>
     </section>
 
     <section id="performance-collections-mostefficientupdate">
       <title>Lists, maps, idbags and sets are the most efficient collections
       to update</title>
 
       <para>From the discussion above, it should be clear that indexed
       collections and sets allow the most efficient operation in terms of
       adding, removing and updating elements.</para>
 
       <para>There is, arguably, one more advantage that indexed collections
       have over sets for many-to-many associations or collections of values.
       Because of the structure of a <literal>Set</literal>, Hibernate does not
       <literal>UPDATE</literal> a row when an element is "changed". Changes to
       a <literal>Set</literal> always work via <literal>INSERT</literal> and
       <literal>DELETE</literal> of individual rows. Once again, this
       consideration does not apply to one-to-many associations.</para>
 
       <para>After observing that arrays cannot be lazy, you can conclude that
       lists, maps and idbags are the most performant (non-inverse) collection
       types, with sets not far behind. You can expect sets to be the most
       common kind of collection in Hibernate applications. This is because the
       "set" semantics are most natural in the relational model.</para>
 
       <para>However, in well-designed Hibernate domain models, most
       collections are in fact one-to-many associations with
       <literal>inverse="true"</literal>. For these associations, the update is
       handled by the many-to-one end of the association, and so considerations
       of collection update performance simply do not apply.</para>
     </section>
 
     <section id="performance-collections-mostefficentinverse">
       <title>Bags and lists are the most efficient inverse collections</title>
 
       <para>There is a particular case, however, in which bags, and also
       lists, are much more performant than sets. For a collection with
       <literal>inverse="true"</literal>, the standard bidirectional
       one-to-many relationship idiom, for example, we can add elements to a
       bag or list without needing to initialize (fetch) the bag elements. This
       is because, unlike a <literal>set</literal>,
       <literal>Collection.add()</literal> or
       <literal>Collection.addAll()</literal> must always return true for a bag
       or <literal>List</literal>. This can make the following common code much
       faster:</para>
 
       <programlisting role="JAVA">Parent p = (Parent) sess.load(Parent.class, id);
 Child c = new Child();
 c.setParent(p);
 p.getChildren().add(c);  //no need to fetch the collection!
 sess.flush();</programlisting>
     </section>
 
     <section id="performance-collections-oneshotdelete">
       <title>One shot delete</title>
 
       <para>Deleting collection elements one by one can sometimes be extremely
       inefficient. Hibernate knows not to do that in the case of an
       newly-empty collection (if you called <literal>list.clear()</literal>,
       for example). In this case, Hibernate will issue a single
       <literal>DELETE</literal>.</para>
 
       <para>Suppose you added a single element to a collection of size twenty
       and then remove two elements. Hibernate will issue one
       <literal>INSERT</literal> statement and two <literal>DELETE</literal>
       statements, unless the collection is a bag. This is certainly
       desirable.</para>
 
       <para>However, suppose that we remove eighteen elements, leaving two and
       then add thee new elements. There are two possible ways to
       proceed</para>
 
       <itemizedlist>
         <listitem>
           <para>delete eighteen rows one by one and then insert three
           rows</para>
         </listitem>
 
         <listitem>
           <para>remove the whole collection in one SQL
           <literal>DELETE</literal> and insert all five current elements one
           by one</para>
         </listitem>
       </itemizedlist>
 
       <para>Hibernate cannot know that the second option is probably quicker.
       It would probably be undesirable for Hibernate to be that intuitive as
       such behavior might confuse database triggers, etc.</para>
 
       <para>Fortunately, you can force this behavior (i.e. the second
       strategy) at any time by discarding (i.e. dereferencing) the original
       collection and returning a newly instantiated collection with all the
       current elements.</para>
 
       <para>One-shot-delete does not apply to collections mapped
       <literal>inverse="true"</literal>.</para>
     </section>
   </section>
 
   <section id="performance-monitoring" revision="1">
     <title>Monitoring performance</title>
 
     <para>Optimization is not much use without monitoring and access to
     performance numbers. Hibernate provides a full range of figures about its
     internal operations. Statistics in Hibernate are available per
     <literal>SessionFactory</literal>.</para>
 
     <section id="performance-monitoring-sf" revision="2">
       <title>Monitoring a SessionFactory</title>
 
       <para>You can access <literal>SessionFactory</literal> metrics in two
       ways. Your first option is to call
       <literal>sessionFactory.getStatistics()</literal> and read or display
       the <literal>Statistics</literal> yourself.</para>
 
       <para>Hibernate can also use JMX to publish metrics if you enable the
       <literal>StatisticsService</literal> MBean. You can enable a single
       MBean for all your <literal>SessionFactory</literal> or one per factory.
       See the following code for minimalistic configuration examples:</para>
 
       <programlisting role="JAVA">// MBean service registration for a specific SessionFactory
 Hashtable tb = new Hashtable();
 tb.put("type", "statistics");
 tb.put("sessionFactory", "myFinancialApp");
 ObjectName on = new ObjectName("hibernate", tb); // MBean object name
 
 StatisticsService stats = new StatisticsService(); // MBean implementation
 stats.setSessionFactory(sessionFactory); // Bind the stats to a SessionFactory
 server.registerMBean(stats, on); // Register the Mbean on the server</programlisting>
 
       <programlisting role="JAVA">// MBean service registration for all SessionFactory's
 Hashtable tb = new Hashtable();
 tb.put("type", "statistics");
 tb.put("sessionFactory", "all");
 ObjectName on = new ObjectName("hibernate", tb); // MBean object name
 
 StatisticsService stats = new StatisticsService(); // MBean implementation
 server.registerMBean(stats, on); // Register the MBean on the server</programlisting>
 
       <para>You can activate and deactivate the monitoring for a
       <literal>SessionFactory</literal>:</para>
 
       <itemizedlist>
         <listitem>
           <para>at configuration time, set
           <literal>hibernate.generate_statistics</literal> to
           <literal>false</literal></para>
         </listitem>
       </itemizedlist>
 
       <itemizedlist>
         <listitem>
           <para>at runtime:
           <literal>sf.getStatistics().setStatisticsEnabled(true)</literal> or
           <literal>hibernateStatsBean.setStatisticsEnabled(true)</literal></para>
         </listitem>
       </itemizedlist>
 
       <para>Statistics can be reset programmatically using the
       <literal>clear()</literal> method. A summary can be sent to a logger
       (info level) using the <literal>logSummary()</literal> method.</para>
     </section>
 
     <section id="performance-monitoring-metrics" revision="1">
       <title>Metrics</title>
 
       <para>Hibernate provides a number of metrics, from basic information to
       more specialized information that is only relevant in certain scenarios.
       All available counters are described in the
       <literal>Statistics</literal> interface API, in three categories:</para>
 
       <itemizedlist>
         <listitem>
           <para>Metrics related to the general <literal>Session</literal>
           usage, such as number of open sessions, retrieved JDBC connections,
           etc.</para>
         </listitem>
 
         <listitem>
           <para>Metrics related to the entities, collections, queries, and
           caches as a whole (aka global metrics).</para>
         </listitem>
 
         <listitem>
           <para>Detailed metrics related to a particular entity, collection,
           query or cache region.</para>
         </listitem>
       </itemizedlist>
 
       <para>For example, you can check the cache hit, miss, and put ratio of
       entities, collections and queries, and the average time a query needs.
       Be aware that the number of milliseconds is subject to approximation in
       Java. Hibernate is tied to the JVM precision and on some platforms this
       might only be accurate to 10 seconds.</para>
 
       <para>Simple getters are used to access the global metrics (i.e. not
       tied to a particular entity, collection, cache region, etc.). You can
       access the metrics of a particular entity, collection or cache region
       through its name, and through its HQL or SQL representation for queries.
       Please refer to the <literal>Statistics</literal>,
       <literal>EntityStatistics</literal>,
       <literal>CollectionStatistics</literal>,
       <literal>SecondLevelCacheStatistics</literal>, and
       <literal>QueryStatistics</literal> API Javadoc for more information. The
       following code is a simple example:</para>
 
       <programlisting role="JAVA">Statistics stats = HibernateUtil.sessionFactory.getStatistics();
 
 double queryCacheHitCount  = stats.getQueryCacheHitCount();
 double queryCacheMissCount = stats.getQueryCacheMissCount();
 double queryCacheHitRatio =
   queryCacheHitCount / (queryCacheHitCount + queryCacheMissCount);
 
 log.info("Query Hit ratio:" + queryCacheHitRatio);
 
 EntityStatistics entityStats =
   stats.getEntityStatistics( Cat.class.getName() );
 long changes =
         entityStats.getInsertCount()
         + entityStats.getUpdateCount()
         + entityStats.getDeleteCount();
 log.info(Cat.class.getName() + " changed " + changes + "times"  );</programlisting>
 
       <para>You can work on all entities, collections, queries and region
       caches, by retrieving the list of names of entities, collections,
       queries and region caches using the following methods:
       <literal>getQueries()</literal>, <literal>getEntityNames()</literal>,
       <literal>getCollectionRoleNames()</literal>, and
       <literal>getSecondLevelCacheRegionNames()</literal>.</para>
     </section>
   </section>
 </chapter>
diff --git a/documentation/src/main/docbook/manual/en-US/content/tutorial.xml b/documentation/src/main/docbook/manual/en-US/content/tutorial.xml
index 62cb679ba7..f5048307da 100644
--- a/documentation/src/main/docbook/manual/en-US/content/tutorial.xml
+++ b/documentation/src/main/docbook/manual/en-US/content/tutorial.xml
@@ -1,1496 +1,1496 @@
 <?xml version='1.0' encoding="UTF-8"?>
 <!--
   ~ Hibernate, Relational Persistence for Idiomatic Java
   ~
   ~ Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
   ~ indicated by the @author tags or express copyright attribution
   ~ statements applied by the authors.  All third-party contributions are
   ~ distributed under license by Red Hat Middleware LLC.
   ~
   ~ This copyrighted material is made available to anyone wishing to use, modify,
   ~ copy, or redistribute it subject to the terms and conditions of the GNU
   ~ Lesser General Public License, as published by the Free Software Foundation.
   ~
   ~ This program is distributed in the hope that it will be useful,
   ~ but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
   ~ or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
   ~ for more details.
   ~
   ~ You should have received a copy of the GNU Lesser General Public License
   ~ along with this distribution; if not, write to:
   ~ Free Software Foundation, Inc.
   ~ 51 Franklin Street, Fifth Floor
   ~ Boston, MA  02110-1301  USA
   -->
 
 <!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd" [
 <!ENTITY % BOOK_ENTITIES SYSTEM "../HIBERNATE_-_Relational_Persistence_for_Idiomatic_Java.ent">
 %BOOK_ENTITIES;
 <!ENTITY mdash "-">
 ]>
         
 
 <chapter id="tutorial">
     <title>Tutorial</title>
 
     <para>
         Intended for new users, this chapter provides an step-by-step introduction
         to Hibernate, starting with a simple application using an in-memory database.  The
         tutorial is based on an earlier tutorial developed by Michael Gloegl.  All
         code is contained in the <filename>tutorials/web</filename> directory of the project
         source.
     </para>
 
     <important>
         <para>
             This tutorial expects the user have knowledge of both Java and
             SQL.  If you have a limited knowledge of JAVA or SQL, it is advised
             that you start with a good introduction to that technology prior
             to attempting to learn Hibernate.
         </para>
     </important>
 
     <note>
         <para>
             The distribution contains another example application under
             the <filename>tutorial/eg</filename> project source
             directory.
         </para>
     </note>
 
     <section id="tutorial-firstapp">
         <title>Part 1 - The first Hibernate Application</title>
 
         <para>
             For this example, we will set up a small database application that can store
             events we want to attend and information about the host(s) of these events.
         </para>
 
         <note>
             <para>
                 Although you can use whatever database you feel comfortable using, we
                 will use <ulink url="http://hsqldb.org/">HSQLDB</ulink> (an in-memory,
                 Java database) to avoid describing installation/setup of any particular
                 database servers.
             </para>
         </note>
 
         <section id="tutorial-firstapp-setup">
             <title>Setup</title>
 
             <para>
                 The first thing we need to do is to set up the development environment.  We
                 will be using the "standard layout" advocated by alot of build tools such
                 as <ulink url="http://maven.org">Maven</ulink>.  Maven, in particular, has a
                 good resource describing this <ulink url="http://maven.apache.org/guides/introduction/introduction-to-the-standard-directory-layout.html">layout</ulink>.
                 As this tutorial is to be a web application, we will be creating and making
                 use of <filename>src/main/java</filename>, <filename>src/main/resources</filename>
                 and <filename>src/main/webapp</filename> directories.
             </para>
 
             <para>
                 We will be using Maven in this tutorial, taking advantage of its
                 transitive dependency management capabilities as well as the ability of
                 many IDEs to automatically set up a project for us based on the maven descriptor.
             </para>
 
         <programlisting role="XML"><![CDATA[<project xmlns="http://maven.apache.org/POM/4.0.0"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
 
     <modelVersion>4.0.0</modelVersion>
 
     <groupId>org.hibernate.tutorials</groupId>
     <artifactId>hibernate-tutorial</artifactId>
     <version>1.0.0-SNAPSHOT</version>
     <name>First Hibernate Tutorial</name>
 
     <build>
          <!-- we dont want the version to be part of the generated war file name -->
          <finalName>${artifactId}</finalName>
     </build>
 
     <dependencies>
         <dependency>
             <groupId>org.hibernate</groupId>
             <artifactId>hibernate-core</artifactId>
         </dependency>
 
         <!-- Because this is a web app, we also have a dependency on the servlet api. -->
         <dependency>
             <groupId>javax.servlet</groupId>
             <artifactId>servlet-api</artifactId>
         </dependency>
 
         <!-- Hibernate uses slf4j for logging, for our purposes here use the simple backend -->
         <dependency>
             <groupId>org.slf4j</groupId>
             <artifactId>slf4j-simple</artifactId>
         </dependency>
 
         <!-- Hibernate gives you a choice of bytecode providers between cglib and javassist -->
         <dependency>
             <groupId>javassist</groupId>
             <artifactId>javassist</artifactId>
         </dependency>
     </dependencies>
 
 </project>]]></programlisting>
 
             <tip>
                 <para>
                     It is not a requirement to use Maven.  If you wish to use something else to
                     build this tutorial (such as Ant), the layout will remain the same.  The only
                     change is that you will need to manually account for all the needed
                     dependencies.  If you use something like <ulink url="http://ant.apache.org/ivy/">Ivy</ulink>
                     providing transitive dependency management you would still use the dependencies
                     mentioned below.  Otherwise, you'd need to grab <emphasis>all</emphasis>
                     dependencies, both explicit and transitive, and add them to the project's
                     classpath.  If working from the Hibernate distribution bundle, this would mean
                     <filename>hibernate3.jar</filename>, all artifacts in the
                     <filename>lib/required</filename> directory and all files from either the
                     <filename>lib/bytecode/cglib</filename> or <filename>lib/bytecode/javassist</filename>
                     directory; additionally you will need both the servlet-api jar and one of the slf4j
                     logging backends.
                 </para>
             </tip>
 
             <para>
                 Save this file as <filename>pom.xml</filename> in the project root directory.
             </para>
         </section>
 
 
         <section id="tutorial-firstapp-firstclass">
             <title>The first class</title>
             
             <para>
                 Next, we create a class that represents the event we want to store in the
                 database; it is a simple JavaBean class with some properties:
             </para>
 
             <programlisting role="JAVA"><![CDATA[package org.hibernate.tutorial.domain;
 
 import java.util.Date;
 
 public class Event {
     private Long id;
 
     private String title;
     private Date date;
 
     public Event() {}
 
     public Long getId() {
         return id;
     }
 
     private void setId(Long id) {
         this.id = id;
     }
 
     public Date getDate() {
         return date;
     }
 
     public void setDate(Date date) {
         this.date = date;
     }
 
     public String getTitle() {
         return title;
     }
 
     public void setTitle(String title) {
         this.title = title;
     }
 }]]></programlisting>
 
             <para>
                 This class uses standard JavaBean naming conventions for property
                 getter and setter methods, as well as private visibility for the
                 fields.  Although this is the recommended design, it is not required.
                 Hibernate can also access fields directly,  the benefit of accessor
                 methods is robustness for refactoring.
             </para>
 
             <para>
                 The <literal>id</literal> property holds a unique identifier value
                 for a particular event.  All persistent entity classes (there are
                 less important dependent classes as well) will need such an identifier
                 property if we want to use the full feature set of Hibernate. In fact,
                 most applications, especially web applications, need to distinguish
                 objects by identifier, so you should consider this a feature rather
                 than a limitation.  However, we usually do not manipulate the identity
                 of an object, hence the setter method should be private.  Only Hibernate
                 will assign identifiers when an object is saved.  Hibernate can access
                 public, private, and protected accessor methods, as well as public,
                 private and protected fields directly.  The choice is up to you and
                 you can match it to fit your application design.
             </para>
 
             <para>
                 The no-argument constructor is a requirement for all persistent
                 classes; Hibernate has to create objects for you, using Java
                 Reflection.  The constructor can be private, however package or public
                 visibility is required for runtime proxy generation and efficient data
                 retrieval without bytecode instrumentation.
             </para>
 
             <para>
                 Save this file to the <filename>src/main/java/org/hibernate/tutorial/domain</filename>
                 directory.
             </para>
         </section>
 
         <section id="tutorial-firstapp-mapping">
             <title>The mapping file</title>
 
             <para>
                 Hibernate needs to know how to load and store objects of the
                 persistent class.  This is where the Hibernate mapping file
                 comes into play. The mapping file tells Hibernate what table in
                 the database it has to access, and what columns in that table
                 it should use.
             </para>
 
             <para>
                 The basic structure of a mapping file looks like this:
             </para>
 
             <programlisting role="XML"><![CDATA[<?xml version="1.0"?>
 <!DOCTYPE hibernate-mapping PUBLIC
         "-//Hibernate/Hibernate Mapping DTD 3.0//EN"
         "http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd">
 
 <hibernate-mapping package="org.hibernate.tutorial.domain">
 [...]
 </hibernate-mapping>]]></programlisting>
 
             <para>
                 Hibernate DTD is sophisticated.  You can use it for auto-completion
                 of XML mapping elements and attributes in your editor or IDE.
                 Opening up the DTD file in your text editor is the easiest way to
                 get an overview of all elements and attributes, and to view the
                 defaults, as well as some comments.  Hibernate will not load the
                 DTD file from the web, but first look it up from the classpath of
                 the application.  The DTD file is included in
                 <filename>hibernate-core.jar</filename> (it is also included in the
                 <filename>hibernate3.jar</filename>, if using the distribution bundle).
             </para>
 
             <important>
                 <para>
                     We will omit the DTD declaration in future examples to shorten the code. It is,
                     of course, not optional.
                 </para>
             </important>
 
             <para>
                 Between the two <literal>hibernate-mapping</literal> tags, include a
                 <literal>class</literal> element. All persistent entity classes (again, there
                 might be dependent classes later on, which are not first-class entities) need
                 a mapping to a table in the SQL database:
             </para>
 
             <programlisting role="XML"><![CDATA[<hibernate-mapping package="org.hibernate.tutorial.domain">
 
     <class name="Event" table="EVENTS">
 
     </class>
 
 </hibernate-mapping>]]></programlisting>
 
             <para>
                 So far we have told Hibernate how to persist and load object of
                 class <literal>Event</literal> to the table
                 <literal>EVENTS</literal>. Each instance is now represented by a
                 row in that table.  Now we can continue by mapping the unique
                 identifier property to the tables primary key.  As we do not want
                 to care about handling this identifier, we configure Hibernate's
                 identifier generation strategy for a surrogate primary key column:
             </para>
 
             <programlisting role="XML"><![CDATA[<hibernate-mapping package="org.hibernate.tutorial.domain">
 
     <class name="Event" table="EVENTS">
         <id name="id" column="EVENT_ID">
             <generator class="native"/>
         </id>
     </class>
 
 </hibernate-mapping>]]></programlisting>
 
             <para>
                 The <literal>id</literal> element is the declaration of the
                 identifier property.  The <literal>name="id"</literal> mapping
                 attribute declares the name of the JavaBean property and tells
                 Hibernate to use the <literal>getId()</literal> and
                 <literal>setId()</literal> methods to access the property.  The
                 column attribute tells Hibernate which column of the
                 <literal>EVENTS</literal> table holds the primary key value.
             </para>
 
             <para>
                 The nested <literal>generator</literal> element specifies the
                 identifier generation strategy (aka how are identifier values
                 generated?).  In this case we choose <literal>native</literal>,
                 which offers a level of portability depending on the configured
                 database dialect.  Hibernate supports database generated, globally
                 unique, as well as application assigned, identifiers.  Identifier
                 value generation is also one of Hibernate's many extension points
                 and you can plugin in your own strategy.
             </para>
 
             <tip>
                 <para>
                     <literal>native</literal> is no longer consider the best strategy in terms of portability.  for further
                     discussion, see <xref linkend="portability-idgen"/>
                 </para>
             </tip>
 
             <para>
                 Lastly, we need to tell Hibernate about the remaining entity class
                 properties.  By default, no properties of the class are considered
                 persistent:
             </para>
             
             <programlisting role="XML"><![CDATA[
 <hibernate-mapping package="org.hibernate.tutorial.domain">
 
     <class name="Event" table="EVENTS">
         <id name="id" column="EVENT_ID">
             <generator class="native"/>
         </id>
         <property name="date" type="timestamp" column="EVENT_DATE"/>
         <property name="title"/>
     </class>
 
 </hibernate-mapping>]]></programlisting>
             
             <para>
                 Similar to the <literal>id</literal> element, the
                 <literal>name</literal> attribute of the
                 <literal>property</literal> element tells Hibernate which getter
                 and setter methods to use.  In this case, Hibernate will search
                 for <literal>getDate()</literal>, <literal>setDate()</literal>,
                 <literal>getTitle()</literal> and <literal>setTitle()</literal>
                 methods.
             </para>
 
             <note>
                 <para>
                     Why does the <literal>date</literal> property mapping include the
                     <literal>column</literal> attribute, but the <literal>title</literal>
                     does not? Without the <literal>column</literal> attribute, Hibernate
                     by default uses the property name as the column name. This works for
                     <literal>title</literal>, however, <literal>date</literal> is a reserved
                     keyword in most databases so you will need to map it to a different name.
                 </para>
             </note>
 
             <para>
                 The <literal>title</literal> mapping also lacks a <literal>type</literal> attribute. The
                 types declared and used in the mapping files are not Java data types; they are not SQL
                 database types either.  These types are called <emphasis>Hibernate mapping types</emphasis>,
                 converters which can translate from Java to SQL data types and vice versa.  Again,
                 Hibernate will try to determine the correct conversion and mapping type itself if
                 the <literal>type</literal> attribute is not present in the mapping. In some cases this
                 automatic detection using Reflection on the Java class might not have the default you
                 expect or need. This is the case with the <literal>date</literal> property. Hibernate cannot
                 know if the property, which is of <literal>java.util.Date</literal>, should map to a
                 SQL <literal>date</literal>, <literal>timestamp</literal>, or <literal>time</literal> column.
                 Full date and time information is preserved by mapping the property with a
                 <literal>timestamp</literal> converter.
             </para>
 
             <tip>
                 <para>
                     Hibernate makes this mapping type determination using reflection when the mapping files
                     are processed.  This can take time and resources, so if startup performance is important
                     you should consider explicitly defining the type to use.
                 </para>
             </tip>
 
             <para>
                 Save this mapping file as
                 <filename>src/main/resources/org/hibernate/tutorial/domain/Event.hbm.xml</filename>.
             </para>
 
         </section>
 
         <section id="tutorial-firstapp-configuration" revision="2">
             <title>Hibernate configuration</title>
 
             <para>
                 At this point, you should have the persistent class and its mapping
                 file in place. It is now time to configure Hibernate.  First let's set up
                 HSQLDB to run in "server mode"
             </para>
 
             <note>
                 <para>
                     We do this do that the data remains between runs.
                 </para>
             </note>
 
             <para>
                 We will utilize the Maven exec plugin to launch the HSQLDB server
                 by running:
                 <command> mvn exec:java -Dexec.mainClass="org.hsqldb.Server" -Dexec.args="-database.0 file:target/data/tutorial"</command>
                 You will see it start up and bind to a TCP/IP socket; this is where
                 our application will connect later.  If you want to start
                 with a fresh database during this tutorial, shutdown HSQLDB, delete
                 all files in the <filename>target/data</filename> directory,
                 and start HSQLDB again.
             </para>
 
             <para>
                 Hibernate will be connecting to the database on behalf of your application, so it needs to know
                 how to obtain connections.  For this tutorial we will be using a standalone connection
                 pool (as opposed to a <interfacename>javax.sql.DataSource</interfacename>).  Hibernate comes with
                 support for two third-party open source JDBC connection pools:
                 <ulink url="https://sourceforge.net/projects/c3p0">c3p0</ulink> and
                 <ulink url="http://proxool.sourceforge.net/">proxool</ulink>.  However, we will be using the
                 Hibernate built-in connection pool for this tutorial.
             </para>
 
             <caution>
                 <para>
                     The built-in Hibernate connection pool is in no way intended for production use.  It
                     lacks several features found on any decent connection pool.
                 </para>
             </caution>
 
             <para>
                 For Hibernate's configuration, we can use a simple <literal>hibernate.properties</literal> file, a
                 more sophisticated <literal>hibernate.cfg.xml</literal> file, or even complete
                 programmatic setup. Most users prefer the XML configuration file:
             </para>
 
             <programlisting role="XML"><![CDATA[<?xml version='1.0' encoding='utf-8'?>
 <!DOCTYPE hibernate-configuration PUBLIC
         "-//Hibernate/Hibernate Configuration DTD 3.0//EN"
         "http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd">
 
 <hibernate-configuration>
 
     <session-factory>
 
         <!-- Database connection settings -->
         <property name="connection.driver_class">org.hsqldb.jdbcDriver</property>
         <property name="connection.url">jdbc:hsqldb:hsql://localhost</property>
         <property name="connection.username">sa</property>
         <property name="connection.password"></property>
 
         <!-- JDBC connection pool (use the built-in) -->
         <property name="connection.pool_size">1</property>
 
         <!-- SQL dialect -->
         <property name="dialect">org.hibernate.dialect.HSQLDialect</property>
 
         <!-- Enable Hibernate's automatic session context management -->
         <property name="current_session_context_class">thread</property>
 
         <!-- Disable the second-level cache  -->
-        <property name="cache.provider_class">org.hibernate.cache.NoCacheProvider</property>
+        <property name="cache.provider_class">org.hibernate.cache.internal.NoCacheProvider</property>
 
         <!-- Echo all executed SQL to stdout -->
         <property name="show_sql">true</property>
 
         <!-- Drop and re-create the database schema on startup -->
         <property name="hbm2ddl.auto">update</property>
 
         <mapping resource="org/hibernate/tutorial/domain/Event.hbm.xml"/>
 
     </session-factory>
 
 </hibernate-configuration>]]></programlisting>
 
             <note>
                 <para>Notice that this configuration file specifies a different DTD</para>
             </note>
 
             <para>
                 You configure Hibernate's <literal>SessionFactory</literal>. SessionFactory is a global
                 factory responsible for a particular database. If you have several databases, for easier
                 startup you should use several <literal>&lt;session-factory&gt;</literal> configurations in
                 several configuration files.
             </para>
 
             <para>
                 The first four <literal>property</literal> elements contain the necessary
                 configuration for the JDBC connection. The dialect <literal>property</literal>
                 element specifies the particular SQL variant Hibernate generates.
             </para>
 
             <tip>
                 <para>
                     In most cases, Hibernate is able to properly determine which dialect to use.  See
                     <xref linkend="portability-dialectresolver"/> for more information.
                 </para>
             </tip>
 
             <para>
                 Hibernate's automatic session management for persistence contexts is particularly useful
                 in this context.  The <literal>hbm2ddl.auto</literal> option turns on automatic generation of
                 database schemas directly into the database. This can also be turned
                 off by removing the configuration option, or redirected to a file with the help of
                 the <literal>SchemaExport</literal> Ant task. Finally, add the mapping file(s)
                 for persistent classes to the configuration.
             </para>
 
             <para>
                 Save this file as <filename>hibernate.cfg.xml</filename> into the
                 <filename>src/main/resources</filename> directory.
             </para>
 
         </section>
 
         <section id="tutorial-firstapp-mvn" revision="1">
             <title>Building with Maven</title>
 
             <para>
                 We will now build the tutorial with Maven.  You will need to
                 have Maven installed; it is available from the
                 <ulink url="http://maven.apache.org/download.html">Maven download page</ulink>.
                 Maven will read the <filename>/pom.xml</filename> file we created
                 earlier and know how to perform some basic project tasks.  First,
                 lets run the <literal>compile</literal> goal to make sure we can compile
                 everything so far:
             </para>
 
             <programlisting><![CDATA[[hibernateTutorial]$ mvn compile
 [INFO] Scanning for projects...
 [INFO] ------------------------------------------------------------------------
 [INFO] Building First Hibernate Tutorial
 [INFO]    task-segment: [compile]
 [INFO] ------------------------------------------------------------------------
 [INFO] [resources:resources]
 [INFO] Using default encoding to copy filtered resources.
 [INFO] [compiler:compile]
 [INFO] Compiling 1 source file to /home/steve/projects/sandbox/hibernateTutorial/target/classes
 [INFO] ------------------------------------------------------------------------
 [INFO] BUILD SUCCESSFUL
 [INFO] ------------------------------------------------------------------------
 [INFO] Total time: 2 seconds
 [INFO] Finished at: Tue Jun 09 12:25:25 CDT 2009
 [INFO] Final Memory: 5M/547M
 [INFO] ------------------------------------------------------------------------]]></programlisting>
 
         </section>
 
         <section id="tutorial-firstapp-helpers" revision="3">
             <title>Startup and helpers</title>
 
             <para>
                 It is time to load and store some <literal>Event</literal>
                 objects, but first you have to complete the setup with some
                 infrastructure code. You have to startup Hibernate by building
                 a global <interfacename>org.hibernate.SessionFactory</interfacename>
                 object and storing it somewhere for easy access in application code.  A
                 <interfacename>org.hibernate.SessionFactory</interfacename> is used to
                 obtain <interfacename>org.hibernate.Session</interfacename> instances.
                 A <interfacename>org.hibernate.Session</interfacename> represents a
                 single-threaded unit of work.  The
                 <interfacename>org.hibernate.SessionFactory</interfacename> is a
                 thread-safe global object that is instantiated once.
             </para>
 
             <para>
                 We will create a <literal>HibernateUtil</literal> helper class that
                 takes care of startup and makes accessing the
                 <interfacename>org.hibernate.SessionFactory</interfacename> more convenient.
             </para>
 
             <programlisting role="JAVA"><![CDATA[package org.hibernate.tutorial.util;
 
 import org.hibernate.SessionFactory;
 import org.hibernate.cfg.Configuration;
 
 public class HibernateUtil {
 
     private static final SessionFactory sessionFactory = buildSessionFactory();
 
     private static SessionFactory buildSessionFactory() {
         try {
             // Create the SessionFactory from hibernate.cfg.xml
             return new Configuration().configure().buildSessionFactory();
         }
         catch (Throwable ex) {
             // Make sure you log the exception, as it might be swallowed
             System.err.println("Initial SessionFactory creation failed." + ex);
             throw new ExceptionInInitializerError(ex);
         }
     }
 
     public static SessionFactory getSessionFactory() {
         return sessionFactory;
     }
 
 }]]></programlisting>
 
             <para>
                 Save this code as
                 <filename>src/main/java/org/hibernate/tutorial/util/HibernateUtil.java</filename>
             </para>
 
             <para>
                 This class not only produces the global
                 <interfacename>org.hibernate.SessionFactory</interfacename> reference in
                 its static initializer; it also hides the fact that it uses a
                 static singleton.  We might just as well have looked up the
                 <interfacename>org.hibernate.SessionFactory</interfacename> reference from
                 JNDI in an application server or any other location for that matter.
             </para>
 
             <para>
                 If you give the <interfacename>org.hibernate.SessionFactory</interfacename>
                 a name in your configuration, Hibernate will try to bind it to
                 JNDI under that name after it has been built.  Another, better option is to
                 use a JMX deployment and let the JMX-capable container instantiate and bind
                 a <literal>HibernateService</literal> to JNDI. Such advanced options are
                 discussed later.
             </para>
 
             <para>
                 You now need to configure a logging
                 system.  Hibernate uses commons logging and provides two choices: Log4j and
                 JDK 1.4 logging. Most developers prefer Log4j: copy <literal>log4j.properties</literal>
                 from the Hibernate distribution in the <literal>etc/</literal> directory to
                 your <literal>src</literal> directory, next to <literal>hibernate.cfg.xml</literal>.
                 If you prefer to have
                 more verbose output than that provided in the example configuration, you can change the settings.  By default, only the Hibernate startup message is shown on stdout.
             </para>
 
             <para>
                 The tutorial infrastructure is complete and you are now ready to do some real work with
                 Hibernate.
             </para>
 
         </section>
 
         <section id="tutorial-firstapp-workingpersistence" revision="5">
             <title>Loading and storing objects</title>
 
             <para>
                 We are now ready to start doing some real work with Hibernate.
                 Let's start by writing an <literal>EventManager</literal> class
                 with a <literal>main()</literal> method:
             </para>
 
             <programlisting role="JAVA"><![CDATA[package org.hibernate.tutorial;
 
 import org.hibernate.Session;
 
 import java.util.*;
 
 import org.hibernate.tutorial.domain.Event;
 import org.hibernate.tutorial.util.HibernateUtil;
 
 public class EventManager {
 
     public static void main(String[] args) {
         EventManager mgr = new EventManager();
 
         if (args[0].equals("store")) {
             mgr.createAndStoreEvent("My Event", new Date());
         }
 
         HibernateUtil.getSessionFactory().close();
     }
 
     private void createAndStoreEvent(String title, Date theDate) {
         Session session = HibernateUtil.getSessionFactory().getCurrentSession();
         session.beginTransaction();
 
         Event theEvent = new Event();
         theEvent.setTitle(title);
         theEvent.setDate(theDate);
         session.save(theEvent);
 
         session.getTransaction().commit();
     }
 
 }]]></programlisting>
 
             <para>
                 In <literal>createAndStoreEvent()</literal> we created a new
                 <literal>Event</literal> object and handed it over to Hibernate.
                 At that point, Hibernate takes care of the SQL and executes an
                 <literal>INSERT</literal> on the database.
             </para>
 
             <para>
                 A <interface>org.hibernate.Session</interface> is designed to
                 represent a single unit of work (a single atomic piece of work
                 to be performed).  For now we will keep things simple and assume
                 a one-to-one granularity between a Hibernate
                 <interface>org.hibernate.Session</interface> and a database
                 transaction.  To shield our code from the actual underlying
                 transaction system we use the Hibernate
                 <interfacename>org.hibernate.Transaction</interfacename> API.
                 In this particular case we are using JDBC-based transactional
                 semantics, but it could also run with JTA.
             </para>
 
             <para>
                 What does <literal>sessionFactory.getCurrentSession()</literal> do?
                 First, you can call it as many times and anywhere you like
                 once you get hold of your
                 <interfacename>org.hibernate.SessionFactory</interfacename>.
                 The <literal>getCurrentSession()</literal> method always returns
                 the "current" unit of work.  Remember that we switched
                 the configuration option for this mechanism to "thread" in our
                 <filename>src/main/resources/hibernate.cfg.xml</filename>?
                 Due to that setting, the context of a current unit of work is bound
                 to the current Java thread that executes the application.
             </para>
 
             <important>
                 <para>
                     Hibernate offers three methods of current session tracking.
                     The "thread" based method is not intended for production use;
                     it is merely useful for prototyping and tutorials such as this
                     one.  Current session tracking is discussed in more detail
                     later on.
                 </para>
             </important>
 
             <para>
                 A <interface>org.hibernate.Session</interface> begins when the
                 first call to <literal>getCurrentSession()</literal> is made for
                 the current thread.  It is then bound by Hibernate to the current
                 thread.  When the transaction ends, either through commit or
                 rollback, Hibernate automatically unbinds the
                 <interface>org.hibernate.Session</interface> from the thread
                 and closes it for you. If you call
                 <literal>getCurrentSession()</literal> again, you get a new
                 <interface>org.hibernate.Session</interface> and can start a
                 new unit of work.
             </para>
 
             <para>
                 Related to the unit of work scope, should the Hibernate
                 <interface>org.hibernate.Session</interface> be used to execute
                 one or several database operations?  The above example uses one
                 <interface>org.hibernate.Session</interface> for one operation.
                 However this is pure coincidence; the example is just not complex
                 enough to show any other approach. The scope of a Hibernate
                 <interface>org.hibernate.Session</interface> is flexible but you
                 should never design your application to use a new Hibernate
                 <interface>org.hibernate.Session</interface> for
                 <emphasis>every</emphasis> database operation. Even though it is
                 used in the following examples, consider
                 <emphasis>session-per-operation</emphasis> an anti-pattern.
                 A real web application is shown later in the tutorial which will
                 help illustrate this.
             </para>
 
             <para>
                 See <xref linkend="transactions"/> for more information
                 about transaction handling and demarcation. The previous
                 example also skipped any error handling and rollback.
             </para>
 
             <para>
                 To run this, we will make use of the Maven exec plugin to call our class
                 with the necessary classpath setup:
                 <command>mvn exec:java -Dexec.mainClass="org.hibernate.tutorial.EventManager" -Dexec.args="store"</command>
             </para>
 
             <note>
                 <para>
                     You may need to perform <command>mvn compile</command> first.
                 </para>
             </note>
 
             <para>
                 You should see Hibernate starting up and, depending on your configuration,
                 lots of log output. Towards the end, the following line will be displayed:
             </para>
 
             <programlisting><![CDATA[[java] Hibernate: insert into EVENTS (EVENT_DATE, title, EVENT_ID) values (?, ?, ?)]]></programlisting>
 
             <para>
                 This is the <literal>INSERT</literal> executed by Hibernate.
             </para>
 
             <para>
                 To list stored events an option is added to the main method:
             </para>
 
             <programlisting role="JAVA"><![CDATA[        if (args[0].equals("store")) {
             mgr.createAndStoreEvent("My Event", new Date());
         }
         else if (args[0].equals("list")) {
             List events = mgr.listEvents();
             for (int i = 0; i < events.size(); i++) {
                 Event theEvent = (Event) events.get(i);
                 System.out.println(
                         "Event: " + theEvent.getTitle() + " Time: " + theEvent.getDate()
                 );
             }
         }]]></programlisting>
 
             <para>
                 A new <literal>listEvents() method is also added</literal>:
             </para>
 
             <programlisting role="JAVA"><![CDATA[    private List listEvents() {
         Session session = HibernateUtil.getSessionFactory().getCurrentSession();
         session.beginTransaction();
         List result = session.createQuery("from Event").list();
         session.getTransaction().commit();
         return result;
     }]]></programlisting>
 
             <para>
                 Here, we are using a Hibernate Query Language (HQL) query to load all existing
                 <literal>Event</literal> objects from the database. Hibernate will generate the
                 appropriate SQL, send it to the database and populate <literal>Event</literal> objects
                 with the data. You can create more complex queries with HQL. See <xref linkend="queryhql"/>
                 for more information.
             </para>
 
             <para>
                 Now we can call our new functionality, again using the Maven exec plugin:
                 <command>mvn exec:java -Dexec.mainClass="org.hibernate.tutorial.EventManager" -Dexec.args="list"</command>
             </para>
 
         </section>
 
     </section>
 
     <section id="tutorial-associations">
         <title>Part 2 - Mapping associations</title>
 
         <para>
             So far we have mapped a single persistent entity class to a table in
             isolation.  Let's expand on that a bit and add some class associations.
             We will add people to the application and store a list of events in
             which they participate.
         </para>
 
         <section id="tutorial-associations-mappinguser" revision="1">
             <title>Mapping the Person class</title>
 
             <para>
                 The first cut of the <literal>Person</literal> class looks like this:
             </para>
 
             <programlisting role="JAVA"><![CDATA[package org.hibernate.tutorial.domain;
 
 public class Person {
 
     private Long id;
     private int age;
     private String firstname;
     private String lastname;
 
     public Person() {}
 
     // Accessor methods for all properties, private setter for 'id'
 
 }]]></programlisting>
 
             <para>
                 Save this to a file named
                 <filename>src/main/java/org/hibernate/tutorial/domain/Person.java</filename>
             </para>
 
             <para>
                 Next, create the new mapping file as
                 <filename>src/main/resources/org/hibernate/tutorial/domain/Person.hbm.xml</filename>
             </para>
 
             <programlisting role="XML"><![CDATA[<hibernate-mapping package="org.hibernate.tutorial.domain">
 
     <class name="Person" table="PERSON">
         <id name="id" column="PERSON_ID">
             <generator class="native"/>
         </id>
         <property name="age"/>
         <property name="firstname"/>
         <property name="lastname"/>
     </class>
 
 </hibernate-mapping>]]></programlisting>
 
             <para>
                 Finally, add the new mapping to Hibernate's configuration:
             </para>
 
             <programlisting role="XML"><![CDATA[<mapping resource="org/hibernate/tutorial/domain/Event.hbm.xml"/>
 <mapping resource="org/hibernate/tutorial/domain/Person.hbm.xml"/>]]></programlisting>
 
             <para>
                 Create an association between these two entities. Persons
                 can participate in events, and events have participants. The design questions
                 you have to deal with are: directionality, multiplicity, and collection
                 behavior.
             </para>
 
         </section>
 
         <section id="tutorial-associations-unidirset" revision="3">
             <title>A unidirectional Set-based association</title>
 
             <para>
                 By adding a collection of events to the <literal>Person</literal>
                 class, you can easily navigate to the events for a particular person,
                 without executing an explicit query - by calling
                 <literal>Person#getEvents</literal>.  Multi-valued associations
                 are represented in Hibernate by one of the Java Collection Framework
                 contracts; here we choose a <interfacename>java.util.Set</interfacename>
                 because the collection will not contain duplicate elements and the ordering
                 is not relevant to our examples:
             </para>
 
             <programlisting role="JAVA"><![CDATA[public class Person {
 
     private Set events = new HashSet();
 
     public Set getEvents() {
         return events;
     }
 
     public void setEvents(Set events) {
         this.events = events;
     }
 }]]></programlisting>
 
             <para>
                 Before mapping this association, let's consider the other side.
                 We could just keep this unidirectional or create another
                 collection on the <literal>Event</literal>, if we wanted to be
                 able to navigate it from both directions.  This is not necessary,
                 from a functional perspective. You can always execute an explicit
                 query to retrieve the participants for a particular event.  This
                 is a design choice left to you, but what is clear from this
                 discussion is the multiplicity of the association: "many" valued
                 on both sides is called a <emphasis>many-to-many</emphasis>
                 association. Hence, we use Hibernate's many-to-many mapping:
             </para>
 
             <programlisting role="XML"><![CDATA[<class name="Person" table="PERSON">
     <id name="id" column="PERSON_ID">
         <generator class="native"/>
     </id>
     <property name="age"/>
     <property name="firstname"/>
     <property name="lastname"/>
 
     <set name="events" table="PERSON_EVENT">
         <key column="PERSON_ID"/>
         <many-to-many column="EVENT_ID" class="Event"/>
     </set>
 
 </class>]]></programlisting>
 
             <para>
                 Hibernate supports a broad range of collection mappings, a
                 <literal>set</literal> being most common.  For a many-to-many
                 association, or <emphasis>n:m</emphasis> entity relationship, an
                 association table is required.  Each row in this table represents
                 a link between a person and an event.  The table name is
                 decalred using the <literal>table</literal> attribute of the
                 <literal>set</literal> element.  The identifier column name in
                 the association, for the person side, is defined with the
                 <literal>key</literal> element, the column name for the event's
                 side with the <literal>column</literal> attribute of the
                 <literal>many-to-many</literal>. You also have to tell Hibernate
                 the class of the objects in your collection (the class on the
                 other side of the collection of references).
             </para>
 
             <para>
                 The database schema for this mapping is therefore:
             </para>
 
             <programlisting><![CDATA[
     _____________        __________________
    |             |      |                  |       _____________
    |   EVENTS    |      |   PERSON_EVENT   |      |             |
    |_____________|      |__________________|      |    PERSON   |
    |             |      |                  |      |_____________|
    | *EVENT_ID   | <--> | *EVENT_ID        |      |             |
    |  EVENT_DATE |      | *PERSON_ID       | <--> | *PERSON_ID  |
    |  TITLE      |      |__________________|      |  AGE        |
    |_____________|                                |  FIRSTNAME  |
                                                   |  LASTNAME   |
                                                   |_____________|
  ]]></programlisting>
 
         </section>
 
         <section id="tutorial-associations-working" revision="2">
             <title>Working the association</title>
 
             <para>
                 Now we will bring some people and events together in a new method in <literal>EventManager</literal>:
             </para>
 
             <programlisting role="JAVA"><![CDATA[    private void addPersonToEvent(Long personId, Long eventId) {
         Session session = HibernateUtil.getSessionFactory().getCurrentSession();
         session.beginTransaction();
 
         Person aPerson = (Person) session.load(Person.class, personId);
         Event anEvent = (Event) session.load(Event.class, eventId);
         aPerson.getEvents().add(anEvent);
 
         session.getTransaction().commit();
     }]]></programlisting>
 
             <para>
                 After loading a <literal>Person</literal> and an
                 <literal>Event</literal>, simply modify the collection using the
                 normal collection methods. There is no explicit call to
                 <literal>update()</literal> or <literal>save()</literal>;
                 Hibernate automatically detects that the collection has been modified
                 and needs to be updated. This is called
                 <emphasis>automatic dirty checking</emphasis>. You can also try
                 it by modifying the name or the date property of any of your
                 objects.  As long as they are in <emphasis>persistent</emphasis>
                 state, that is, bound to a particular Hibernate
                 <interfacename>org.hibernate.Session</interfacename>, Hibernate
                 monitors any changes and executes SQL in a write-behind fashion.
                 The process of synchronizing the memory state with the database,
                 usually only at the end of a unit of work, is called
                 <emphasis>flushing</emphasis>.  In our code, the unit of work
                 ends with a commit, or rollback, of the database transaction.
             </para>
 
             <para>
                 You can load person and event in different units of work.  Or
                 you can modify an object outside of a
                 <interfacename>org.hibernate.Session</interfacename>, when it
                 is not in persistent state (if it was persistent before, this
                 state is called <emphasis>detached</emphasis>).  You can even
                 modify a collection when it is detached:
             </para>
 
             <programlisting role="JAVA"><![CDATA[    private void addPersonToEvent(Long personId, Long eventId) {
         Session session = HibernateUtil.getSessionFactory().getCurrentSession();
         session.beginTransaction();
 
         Person aPerson = (Person) session
                 .createQuery("select p from Person p left join fetch p.events where p.id = :pid")
                 .setParameter("pid", personId)
                 .uniqueResult(); // Eager fetch the collection so we can use it detached
         Event anEvent = (Event) session.load(Event.class, eventId);
 
         session.getTransaction().commit();
 
         // End of first unit of work
 
         aPerson.getEvents().add(anEvent); // aPerson (and its collection) is detached
 
         // Begin second unit of work
 
         Session session2 = HibernateUtil.getSessionFactory().getCurrentSession();
         session2.beginTransaction();
         session2.update(aPerson); // Reattachment of aPerson
 
         session2.getTransaction().commit();
     }]]></programlisting>
 
             <para>
                 The call to <literal>update</literal> makes a detached object
                 persistent again by binding it to a new unit of work, so any
                 modifications you made to it while detached can be saved to
                 the database. This includes any modifications
                 (additions/deletions) you made to a collection of that entity
                 object.
             </para>
 
             <para>
                 This is not much use in our example, but it is an important concept you can
                 incorporate into your own application. Complete this exercise by adding a new action
                 to the  main method of the <literal>EventManager</literal> and call it from the command line. If
                 you need the identifiers of a person and an event - the <literal>save()</literal> method
                 returns it (you might have to modify some of the previous methods to return that identifier):
             </para>
 
             <programlisting role="JAVA"><![CDATA[        else if (args[0].equals("addpersontoevent")) {
             Long eventId = mgr.createAndStoreEvent("My Event", new Date());
             Long personId = mgr.createAndStorePerson("Foo", "Bar");
             mgr.addPersonToEvent(personId, eventId);
             System.out.println("Added person " + personId + " to event " + eventId);
         }]]></programlisting>
 
             <para>
                 This is an example of an association between two equally important
                 classes : two entities.  As mentioned earlier, there are other
                 classes and types in a typical model, usually "less important".
                 Some you have already seen, like an <literal>int</literal> or a
                 <classname>java.lang.String</classname>.  We call these classes
                 <emphasis>value types</emphasis>, and their instances
                 <emphasis>depend</emphasis> on a particular entity.  Instances of
                 these types do not have their own identity, nor are they shared
                 between entities.  Two persons do not reference the same
                 <literal>firstname</literal> object, even if they have the same
                 first name.  Value types cannot only be found in the JDK , but
                 you can also write dependent classes yourself
                 such as an <literal>Address</literal> or
                 <literal>MonetaryAmount</literal> class.  In fact, in a Hibernate
                 application all JDK classes are considered value types.
             </para>
 
             <para>
                 You can also design a collection of value types.  This is
                 conceptually different from a collection of references to other
                 entities, but looks almost the same in Java.
             </para>
 
         </section>
 
         <section id="tutorial-associations-valuecollections">
             <title>Collection of values</title>
 
             <para>
                 Let's add a collection of email addresses to the
                 <literal>Person</literal> entity.  This will be represented as a
                 <interfacename>java.util.Set</interfacename> of
                 <classname>java.lang.String</classname> instances:
             </para>
             <programlisting role="JAVA"><![CDATA[    private Set emailAddresses = new HashSet();
 
     public Set getEmailAddresses() {
         return emailAddresses;
     }
 
     public void setEmailAddresses(Set emailAddresses) {
         this.emailAddresses = emailAddresses;
     }]]></programlisting>
 
             <para>
                 The mapping of this <literal>Set</literal> is as follows:
             </para>
 
             <programlisting role="XML"><![CDATA[        <set name="emailAddresses" table="PERSON_EMAIL_ADDR">
             <key column="PERSON_ID"/>
             <element type="string" column="EMAIL_ADDR"/>
         </set>]]></programlisting>
 
             <para>
                 The difference compared with the earlier mapping is the use of
                 the <literal>element</literal> part which tells Hibernate that the
                 collection does not contain references to another entity, but is
                 rather a collection whose elements are values types, here specifically
                 of type <literal>string</literal>.  The lowercase name tells you
                 it is a Hibernate mapping type/converter.  Again the
                 <literal>table</literal> attribute of the <literal>set</literal>
                 element determines the table name for the collection.   The
                 <literal>key</literal> element defines the foreign-key column
                 name in the collection table. The <literal>column</literal>
                 attribute in the <literal>element</literal> element defines the
                 column name where the email address values will actually
                 be stored.
             </para>
 
             <para>
                 Here is the updated schema:
             </para>
 
             <programlisting><![CDATA[
   _____________        __________________
  |             |      |                  |       _____________
  |   EVENTS    |      |   PERSON_EVENT   |      |             |       ___________________
  |_____________|      |__________________|      |    PERSON   |      |                   |
  |             |      |                  |      |_____________|      | PERSON_EMAIL_ADDR |
  | *EVENT_ID   | <--> | *EVENT_ID        |      |             |      |___________________|
  |  EVENT_DATE |      | *PERSON_ID       | <--> | *PERSON_ID  | <--> |  *PERSON_ID       |
  |  TITLE      |      |__________________|      |  AGE        |      |  *EMAIL_ADDR      |
  |_____________|                                |  FIRSTNAME  |      |___________________|
                                                 |  LASTNAME   |
                                                 |_____________|
  ]]></programlisting>
 
             <para>
                 You can see that the primary key of the collection table is in fact a composite key that
                 uses both columns. This also implies that there cannot be duplicate email addresses
                 per person, which is exactly the semantics we need for a set in Java.
             </para>
 
             <para>
                 You can now try to add elements to this collection, just like we did before by
                 linking persons and events. It is the same code in Java:
             </para>
 
             <programlisting role="JAVA"><![CDATA[    private void addEmailToPerson(Long personId, String emailAddress) {
         Session session = HibernateUtil.getSessionFactory().getCurrentSession();
         session.beginTransaction();
 
         Person aPerson = (Person) session.load(Person.class, personId);
         // adding to the emailAddress collection might trigger a lazy load of the collection
         aPerson.getEmailAddresses().add(emailAddress);
 
         session.getTransaction().commit();
     }]]></programlisting>
 
             <para>
                 This time we did not use a <emphasis>fetch</emphasis> query to
                 initialize the collection.  Monitor the SQL log and try to
                 optimize this with an eager fetch.
             </para>
 
         </section>
 
         <section id="tutorial-associations-bidirectional" revision="1">
             <title>Bi-directional associations</title>
 
             <para>
                 Next you will map a bi-directional association.  You will make
                 the association between person and event work from both sides
                 in Java.  The database schema does not change, so you will still
                 have many-to-many multiplicity.
             </para>
 
             <note>
                 <para>
                     A relational database is more flexible than a network
                     programming language, in that it does not need a navigation
                     direction; data can be viewed and retrieved in any possible
                     way.
                 </para>
             </note>
 
             <para>
                 First, add a collection of participants to the
                 <literal>Event</literal> class:
             </para>
 
             <programlisting role="JAVA"><![CDATA[    private Set participants = new HashSet();
 
     public Set getParticipants() {
         return participants;
     }
 
     public void setParticipants(Set participants) {
         this.participants = participants;
     }]]></programlisting>
 
             <para>
                 Now map this side of the association in <literal>Event.hbm.xml</literal>.
             </para>
 
             <programlisting role="XML"><![CDATA[        <set name="participants" table="PERSON_EVENT" inverse="true">
             <key column="EVENT_ID"/>
             <many-to-many column="PERSON_ID" class="Person"/>
         </set>]]></programlisting>
 
             <para>
                 These are normal <literal>set</literal> mappings in both mapping documents.
                 Notice that the column names in <literal>key</literal> and <literal>many-to-many</literal> 
                 swap in both mapping documents. The most important addition here is the
                 <literal>inverse="true"</literal> attribute in the <literal>set</literal> element of the
                 <literal>Event</literal>'s collection mapping.
             </para>
 
             <para>
                 What this means is that Hibernate should take the other side, the <literal>Person</literal> class,
                 when it needs to find out information about the link between the two. This will be a lot easier to
                 understand once you see how the bi-directional link between our two entities is created.
             </para>
 
         </section>
 
         <section id="tutorial-associations-usingbidir">
             <title>Working bi-directional links</title>
 
             <para>
                 First, keep in mind that Hibernate does not affect normal Java semantics. How did we create a
                 link between a <literal>Person</literal> and an <literal>Event</literal> in the unidirectional
                 example? You add an instance of <literal>Event</literal> to the collection of event references,
                 of an instance of <literal>Person</literal>.  If you want to make this link
                 bi-directional, you have to do the same on the other side by adding a <literal>Person</literal>
                 reference to the collection in an <literal>Event</literal>. This process of "setting the link on both sides"
                 is absolutely necessary with bi-directional links.
             </para>
 
             <para>
                 Many developers program defensively and create link management methods to
                 correctly set both sides (for example, in <literal>Person</literal>):
             </para>
 
             <programlisting role="JAVA"><![CDATA[    protected Set getEvents() {
         return events;
     }
 
     protected void setEvents(Set events) {
         this.events = events;
     }
 
     public void addToEvent(Event event) {
         this.getEvents().add(event);
         event.getParticipants().add(this);
     }
 
     public void removeFromEvent(Event event) {
         this.getEvents().remove(event);
         event.getParticipants().remove(this);
     }]]></programlisting>
 
             <para>
                 The get and set methods for the collection are now protected. This allows classes in the
                 same package and subclasses to still access the methods, but prevents everybody else from altering
                 the collections directly. Repeat the steps for the collection
                 on the other side.
             </para>
 
             <para>
                 What about the <literal>inverse</literal> mapping attribute? For you, and for Java, a bi-directional
                 link is simply a matter of setting the references on both sides correctly. Hibernate, however, does not
                 have enough information to correctly arrange SQL <literal>INSERT</literal> and <literal>UPDATE</literal>
                 statements (to avoid constraint violations). Making one side of the association <literal>inverse</literal> tells Hibernate to consider it a <emphasis>mirror</emphasis> of the other side. That is all that is necessary
                 for Hibernate to resolve any issues that arise when transforming a directional navigation model to
                 a SQL database schema. The rules are straightforward: all bi-directional associations
                 need one side as <literal>inverse</literal>. In a one-to-many association it has to be the many-side,
                 and in many-to-many association you can select either side.
             </para>
 
         </section>
 
     </section>
 
     <section id="tutorial-webapp">
         <title>Part 3 - The EventManager web application</title>
 
         <para>
             A Hibernate web application uses <literal>Session</literal> and <literal>Transaction</literal>
             almost like a standalone application. However, some common patterns are useful. You can now write
             an <literal>EventManagerServlet</literal>. This servlet can list all events stored in the
             database, and it provides an HTML form to enter new events.
         </para>
 
         <section id="tutorial-webapp-servlet" revision="2">
             <title>Writing the basic servlet</title>
 
             <para>
                 First we need create our basic processing servlet.  Since our
                 servlet only handles HTTP <literal>GET</literal> requests, we
                 will only implement the <literal>doGet()</literal> method:
             </para>
 
             <programlisting role="JAVA"><![CDATA[package org.hibernate.tutorial.web;
 
 // Imports
 
 public class EventManagerServlet extends HttpServlet {
 
     protected void doGet(
             HttpServletRequest request,
             HttpServletResponse response) throws ServletException, IOException {
 
         SimpleDateFormat dateFormatter = new SimpleDateFormat( "dd.MM.yyyy" );
 
         try {
             // Begin unit of work
             HibernateUtil.getSessionFactory().getCurrentSession().beginTransaction();
 
             // Process request and render page...
 
             // End unit of work
             HibernateUtil.getSessionFactory().getCurrentSession().getTransaction().commit();
         }
         catch (Exception ex) {
             HibernateUtil.getSessionFactory().getCurrentSession().getTransaction().rollback();
             if ( ServletException.class.isInstance( ex ) ) {
                 throw ( ServletException ) ex;
             }
             else {
                 throw new ServletException( ex );
             }
         }
     }
 
 }]]></programlisting>
 
             <para>
                 Save this servlet as
                 <filename>src/main/java/org/hibernate/tutorial/web/EventManagerServlet.java</filename>
             </para>
 
             <para>
                 The pattern applied here is called <emphasis>session-per-request</emphasis>.
                 When a request hits the servlet, a new Hibernate <literal>Session</literal> is
                 opened through the first call to <literal>getCurrentSession()</literal> on the
                 <literal>SessionFactory</literal>. A database transaction is then started. All
                 data access occurs inside a transaction irrespective of whether the data is read or written.
                 Do not use the auto-commit mode in applications.
             </para>
 
             <para>
                 Do <emphasis>not</emphasis> use a new Hibernate <literal>Session</literal> for
                 every database operation. Use one Hibernate <literal>Session</literal> that is
                 scoped to the whole request. Use <literal>getCurrentSession()</literal>, so that
                 it is automatically bound to the current Java thread.
             </para>
 
             <para>
                 Next, the possible actions of the request are processed and the response HTML
                 is rendered. We will get to that part soon.
             </para>
 
             <para>
                 Finally, the unit of work ends when processing and rendering are complete. If any
                 problems occurred during processing or rendering, an exception will be thrown
                 and the database transaction rolled back. This completes the
                 <literal>session-per-request</literal> pattern. Instead of the transaction
                 demarcation code in every servlet, you could also write a servlet filter.
                 See the Hibernate website and Wiki for more information about this pattern
                 called <emphasis>Open Session in View</emphasis>. You will need it as soon
                 as you consider rendering your view in JSP, not in a servlet.
             </para>
 
         </section>
 
         <section id="tutorial-webapp-processing" revision="1">
             <title>Processing and rendering</title>
 
             <para>
                 Now you can implement the processing of the request and the rendering of the page.
             </para>
 
 <programlisting role="JAVA"><![CDATA[        // Write HTML header
         PrintWriter out = response.getWriter();
         out.println("<html><head><title>Event Manager</title></head><body>");
 
         // Handle actions
         if ( "store".equals(request.getParameter("action")) ) {
 
             String eventTitle = request.getParameter("eventTitle");
             String eventDate = request.getParameter("eventDate");
 
             if ( "".equals(eventTitle) || "".equals(eventDate) ) {
                 out.println("<b><i>Please enter event title and date.</i></b>");
             }
             else {
                 createAndStoreEvent(eventTitle, dateFormatter.parse(eventDate));
                 out.println("<b><i>Added event.</i></b>");
             }
         }
 
         // Print page
        printEventForm(out);
        listEvents(out, dateFormatter);
 
        // Write HTML footer
        out.println("</body></html>");
        out.flush();
        out.close();]]></programlisting>
 
             <para>
                 This coding style, with a mix of Java and HTML, would not scale
                 in a more complex application&mdash;keep in mind that we are only illustrating
                 basic Hibernate concepts in this tutorial. The code prints an HTML
                 header and a footer. Inside this page, an HTML form for event entry and
                 a list of all events in the database are printed. The first method is
                 trivial and only outputs HTML:
             </para>
 
             <programlisting role="JAVA"><![CDATA[    private void printEventForm(PrintWriter out) {
         out.println("<h2>Add new event:</h2>");
         out.println("<form>");
         out.println("Title: <input name='eventTitle' length='50'/><br/>");
diff --git a/documentation/src/main/docbook/quickstart/tutorials/annotations/src/test/resources/hibernate.cfg.xml b/documentation/src/main/docbook/quickstart/tutorials/annotations/src/test/resources/hibernate.cfg.xml
index 881e817d10..aa1abfdeae 100644
--- a/documentation/src/main/docbook/quickstart/tutorials/annotations/src/test/resources/hibernate.cfg.xml
+++ b/documentation/src/main/docbook/quickstart/tutorials/annotations/src/test/resources/hibernate.cfg.xml
@@ -1,59 +1,59 @@
 <?xml version='1.0' encoding='utf-8'?>
 <!--
   ~ Hibernate, Relational Persistence for Idiomatic Java
   ~
   ~ Copyright (c) 2010, Red Hat Inc. or third-party contributors as
   ~ indicated by the @author tags or express copyright attribution
   ~ statements applied by the authors.  All third-party contributions are
   ~ distributed under license by Red Hat Inc.
   ~
   ~ This copyrighted material is made available to anyone wishing to use, modify,
   ~ copy, or redistribute it subject to the terms and conditions of the GNU
   ~ Lesser General Public License, as published by the Free Software Foundation.
   ~
   ~ This program is distributed in the hope that it will be useful,
   ~ but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
   ~ or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
   ~ for more details.
   ~
   ~ You should have received a copy of the GNU Lesser General Public License
   ~ along with this distribution; if not, write to:
   ~ Free Software Foundation, Inc.
   ~ 51 Franklin Street, Fifth Floor
   ~ Boston, MA  02110-1301  USA
   -->
 <!DOCTYPE hibernate-configuration PUBLIC
         "-//Hibernate/Hibernate Configuration DTD 3.0//EN"
         "http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd">
 
 <hibernate-configuration>
 
     <session-factory>
 
         <!-- Database connection settings -->
         <property name="connection.driver_class">org.h2.Driver</property>
         <property name="connection.url">jdbc:h2:mem:db1;DB_CLOSE_DELAY=-1;MVCC=TRUE</property>
         <property name="connection.username">sa</property>
         <property name="connection.password"></property>
 
         <!-- JDBC connection pool (use the built-in) -->
         <property name="connection.pool_size">1</property>
 
         <!-- SQL dialect -->
         <property name="dialect">org.hibernate.dialect.H2Dialect</property>
 
         <!-- Disable the second-level cache  -->
-        <property name="cache.provider_class">org.hibernate.cache.NoCacheProvider</property>
+        <property name="cache.provider_class">org.hibernate.cache.internal.NoCacheProvider</property>
 
         <!-- Echo all executed SQL to stdout -->
         <property name="show_sql">true</property>
 
         <!-- Drop and re-create the database schema on startup -->
         <property name="hbm2ddl.auto">create</property>
 
         <!-- Names the annotated entity class -->
         <mapping class="org.hibernate.tutorial.annotations.Event"/>
 
     </session-factory>
 
 </hibernate-configuration>
\ No newline at end of file
diff --git a/documentation/src/main/docbook/quickstart/tutorials/basic/src/test/resources/hibernate.cfg.xml b/documentation/src/main/docbook/quickstart/tutorials/basic/src/test/resources/hibernate.cfg.xml
index 692a0e268f..dc79584059 100644
--- a/documentation/src/main/docbook/quickstart/tutorials/basic/src/test/resources/hibernate.cfg.xml
+++ b/documentation/src/main/docbook/quickstart/tutorials/basic/src/test/resources/hibernate.cfg.xml
@@ -1,58 +1,58 @@
 <?xml version='1.0' encoding='utf-8'?>
 <!--
   ~ Hibernate, Relational Persistence for Idiomatic Java
   ~
   ~ Copyright (c) 2010, Red Hat Inc. or third-party contributors as
   ~ indicated by the @author tags or express copyright attribution
   ~ statements applied by the authors.  All third-party contributions are
   ~ distributed under license by Red Hat Inc.
   ~
   ~ This copyrighted material is made available to anyone wishing to use, modify,
   ~ copy, or redistribute it subject to the terms and conditions of the GNU
   ~ Lesser General Public License, as published by the Free Software Foundation.
   ~
   ~ This program is distributed in the hope that it will be useful,
   ~ but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
   ~ or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
   ~ for more details.
   ~
   ~ You should have received a copy of the GNU Lesser General Public License
   ~ along with this distribution; if not, write to:
   ~ Free Software Foundation, Inc.
   ~ 51 Franklin Street, Fifth Floor
   ~ Boston, MA  02110-1301  USA
   -->
 <!DOCTYPE hibernate-configuration PUBLIC
         "-//Hibernate/Hibernate Configuration DTD 3.0//EN"
         "http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd">
 
 <hibernate-configuration>
 
     <session-factory>
 
         <!-- Database connection settings -->
         <property name="connection.driver_class">org.h2.Driver</property>
         <property name="connection.url">jdbc:h2:mem:db1;DB_CLOSE_DELAY=-1;MVCC=TRUE</property>
         <property name="connection.username">sa</property>
         <property name="connection.password"/>
 
         <!-- JDBC connection pool (use the built-in) -->
         <property name="connection.pool_size">1</property>
 
         <!-- SQL dialect -->
         <property name="dialect">org.hibernate.dialect.H2Dialect</property>
 
         <!-- Disable the second-level cache  -->
-        <property name="cache.provider_class">org.hibernate.cache.NoCacheProvider</property>
+        <property name="cache.provider_class">org.hibernate.cache.internal.NoCacheProvider</property>
 
         <!-- Echo all executed SQL to stdout -->
         <property name="show_sql">true</property>
 
         <!-- Drop and re-create the database schema on startup -->
         <property name="hbm2ddl.auto">create</property>
 
         <mapping resource="org/hibernate/tutorial/hbm/Event.hbm.xml"/>
 
     </session-factory>
 
 </hibernate-configuration>
\ No newline at end of file
diff --git a/etc/hibernate.properties b/etc/hibernate.properties
index b4f93cf380..098787d587 100644
--- a/etc/hibernate.properties
+++ b/etc/hibernate.properties
@@ -1,529 +1,529 @@
 ######################
 ### Query Language ###
 ######################
 
 ## define query language constants / function names
 
 hibernate.query.substitutions yes 'Y', no 'N'
 
 
 ## select the classic query parser
 
 #hibernate.query.factory_class org.hibernate.hql.classic.ClassicQueryTranslatorFactory
 
 
 
 #################
 ### Platforms ###
 #################
 
 ## JNDI Datasource
 
 #hibernate.connection.datasource jdbc/test
 #hibernate.connection.username db2
 #hibernate.connection.password db2
 
 
 ## HypersonicSQL
 
 hibernate.dialect org.hibernate.dialect.HSQLDialect
 hibernate.connection.driver_class org.hsqldb.jdbcDriver
 hibernate.connection.username sa
 hibernate.connection.password
 hibernate.connection.url jdbc:hsqldb:./build/db/hsqldb/hibernate
 #hibernate.connection.url jdbc:hsqldb:hsql://localhost
 #hibernate.connection.url jdbc:hsqldb:test
 
 ## H2 (www.h2database.com)
 #hibernate.dialect org.hibernate.dialect.H2Dialect
 #hibernate.connection.driver_class org.h2.Driver
 #hibernate.connection.username sa
 #hibernate.connection.password
 #hibernate.connection.url jdbc:h2:mem:./build/db/h2/hibernate
 #hibernate.connection.url jdbc:h2:testdb/h2test
 #hibernate.connection.url jdbc:h2:mem:imdb1
 #hibernate.connection.url jdbc:h2:tcp://dbserv:8084/sample; 	
 #hibernate.connection.url jdbc:h2:ssl://secureserv:8085/sample; 	
 #hibernate.connection.url jdbc:h2:ssl://secureserv/testdb;cipher=AES
 
 ## MySQL
 
 #hibernate.dialect org.hibernate.dialect.MySQLDialect
 #hibernate.dialect org.hibernate.dialect.MySQLInnoDBDialect
 #hibernate.dialect org.hibernate.dialect.MySQLMyISAMDialect
 #hibernate.connection.driver_class com.mysql.jdbc.Driver
 #hibernate.connection.url jdbc:mysql:///test
 #hibernate.connection.username gavin
 #hibernate.connection.password
 
 
 ## Oracle
 
 #hibernate.dialect org.hibernate.dialect.Oracle8iDialect
 #hibernate.dialect org.hibernate.dialect.Oracle9iDialect
 #hibernate.dialect org.hibernate.dialect.Oracle10gDialect
 #hibernate.connection.driver_class oracle.jdbc.driver.OracleDriver
 #hibernate.connection.username ora
 #hibernate.connection.password ora
 #hibernate.connection.url jdbc:oracle:thin:@localhost:1521:orcl
 #hibernate.connection.url jdbc:oracle:thin:@localhost:1522:XE
 
 
 ## PostgreSQL
 
 #hibernate.dialect org.hibernate.dialect.PostgreSQLDialect
 #hibernate.connection.driver_class org.postgresql.Driver
 #hibernate.connection.url jdbc:postgresql:template1
 #hibernate.connection.username pg
 #hibernate.connection.password
 
 
 ## DB2
 
 #hibernate.dialect org.hibernate.dialect.DB2Dialect
 #hibernate.connection.driver_class com.ibm.db2.jcc.DB2Driver
 #hibernate.connection.driver_class COM.ibm.db2.jdbc.app.DB2Driver
 #hibernate.connection.url jdbc:db2://localhost:50000/somename
 #hibernate.connection.url jdbc:db2:somename
 #hibernate.connection.username db2
 #hibernate.connection.password db2
 
 ## TimesTen
 
 #hibernate.dialect org.hibernate.dialect.TimesTenDialect
 #hibernate.connection.driver_class com.timesten.jdbc.TimesTenDriver
 #hibernate.connection.url jdbc:timesten:direct:test
 #hibernate.connection.username
 #hibernate.connection.password 
 
 ## DB2/400
 
 #hibernate.dialect org.hibernate.dialect.DB2400Dialect
 #hibernate.connection.username user
 #hibernate.connection.password password
 
 ## Native driver
 #hibernate.connection.driver_class COM.ibm.db2.jdbc.app.DB2Driver
 #hibernate.connection.url jdbc:db2://systemname
 
 ## Toolbox driver
 #hibernate.connection.driver_class com.ibm.as400.access.AS400JDBCDriver
 #hibernate.connection.url jdbc:as400://systemname
 
 
 ## Derby (not supported!)
 
 #hibernate.dialect org.hibernate.dialect.DerbyDialect
 #hibernate.connection.driver_class org.apache.derby.jdbc.EmbeddedDriver
 #hibernate.connection.username
 #hibernate.connection.password
 #hibernate.connection.url jdbc:derby:build/db/derby/hibernate;create=true
 
 
 ## Sybase
 
 #hibernate.dialect org.hibernate.dialect.SybaseDialect
 #hibernate.connection.driver_class com.sybase.jdbc2.jdbc.SybDriver
 #hibernate.connection.username sa
 #hibernate.connection.password sasasa
 #hibernate.connection.url jdbc:sybase:Tds:co3061835-a:5000/tempdb
 
 
 ## Mckoi SQL
 
 #hibernate.dialect org.hibernate.dialect.MckoiDialect
 #hibernate.connection.driver_class com.mckoi.JDBCDriver
 #hibernate.connection.url jdbc:mckoi:///
 #hibernate.connection.url jdbc:mckoi:local://C:/mckoi1.0.3/db.conf
 #hibernate.connection.username admin
 #hibernate.connection.password nimda
 
 
 ## SAP DB
 
 #hibernate.dialect org.hibernate.dialect.SAPDBDialect
 #hibernate.connection.driver_class com.sap.dbtech.jdbc.DriverSapDB
 #hibernate.connection.url jdbc:sapdb://localhost/TST
 #hibernate.connection.username TEST
 #hibernate.connection.password TEST
 #hibernate.query.substitutions yes 'Y', no 'N'
 
 
 ## MS SQL Server
 
 #hibernate.dialect org.hibernate.dialect.SQLServerDialect
 #hibernate.connection.username sa
 #hibernate.connection.password sa
 
 ## JSQL Driver
 #hibernate.connection.driver_class com.jnetdirect.jsql.JSQLDriver
 #hibernate.connection.url jdbc:JSQLConnect://1E1/test
 
 ## JTURBO Driver
 #hibernate.connection.driver_class com.newatlanta.jturbo.driver.Driver
 #hibernate.connection.url jdbc:JTurbo://1E1:1433/test
 
 ## WebLogic Driver
 #hibernate.connection.driver_class weblogic.jdbc.mssqlserver4.Driver
 #hibernate.connection.url jdbc:weblogic:mssqlserver4:1E1:1433
 
 ## Microsoft Driver (not recommended!)
 #hibernate.connection.driver_class com.microsoft.jdbc.sqlserver.SQLServerDriver
 #hibernate.connection.url jdbc:microsoft:sqlserver://1E1;DatabaseName=test;SelectMethod=cursor
 
 ## The New Microsoft Driver 
 #hibernate.connection.driver_class com.microsoft.sqlserver.jdbc.SQLServerDriver
 #hibernate.connection.url jdbc:sqlserver://localhost
 
 ## jTDS (since version 0.9)
 #hibernate.connection.driver_class net.sourceforge.jtds.jdbc.Driver
 #hibernate.connection.url jdbc:jtds:sqlserver://1E1/test
 
 ## Interbase
 
 #hibernate.dialect org.hibernate.dialect.InterbaseDialect
 #hibernate.connection.username sysdba
 #hibernate.connection.password masterkey
 
 ## DO NOT specify hibernate.connection.sqlDialect
 
 ## InterClient
 
 #hibernate.connection.driver_class interbase.interclient.Driver
 #hibernate.connection.url jdbc:interbase://localhost:3060/C:/firebird/test.gdb
 
 ## Pure Java
 
 #hibernate.connection.driver_class org.firebirdsql.jdbc.FBDriver
 #hibernate.connection.url jdbc:firebirdsql:localhost/3050:/firebird/test.gdb
 
 
 ## Pointbase
 
 #hibernate.dialect org.hibernate.dialect.PointbaseDialect
 #hibernate.connection.driver_class com.pointbase.jdbc.jdbcUniversalDriver
 #hibernate.connection.url jdbc:pointbase:embedded:sample
 #hibernate.connection.username PBPUBLIC
 #hibernate.connection.password PBPUBLIC
 
 
 ## Ingres
 
 ## older versions (before Ingress 2006)
 
 #hibernate.dialect org.hibernate.dialect.IngresDialect
 #hibernate.connection.driver_class ca.edbc.jdbc.EdbcDriver
 #hibernate.connection.url jdbc:edbc://localhost:II7/database
 #hibernate.connection.username user
 #hibernate.connection.password password
 
 ## Ingres 2006 or later
 
 #hibernate.dialect org.hibernate.dialect.IngresDialect
 #hibernate.connection.driver_class com.ingres.jdbc.IngresDriver
 #hibernate.connection.url jdbc:ingres://localhost:II7/database;CURSOR=READONLY;auto=multi
 #hibernate.connection.username user
 #hibernate.connection.password password
 
 ## Mimer SQL
 
 #hibernate.dialect org.hibernate.dialect.MimerSQLDialect
 #hibernate.connection.driver_class com.mimer.jdbc.Driver
 #hibernate.connection.url jdbc:mimer:multi1
 #hibernate.connection.username hibernate
 #hibernate.connection.password hibernate
 
 
 ## InterSystems Cache
 
 #hibernate.dialect org.hibernate.dialect.Cache71Dialect
 #hibernate.connection.driver_class com.intersys.jdbc.CacheDriver
 #hibernate.connection.username _SYSTEM
 #hibernate.connection.password SYS
 #hibernate.connection.url jdbc:Cache://127.0.0.1:1972/HIBERNATE
 
 
 #################################
 ### Hibernate Connection Pool ###
 #################################
 
 hibernate.connection.pool_size 1
 
 
 
 ###########################
 ### C3P0 Connection Pool###
 ###########################
 
 #hibernate.c3p0.max_size 2
 #hibernate.c3p0.min_size 2
 #hibernate.c3p0.timeout 5000
 #hibernate.c3p0.max_statements 100
 #hibernate.c3p0.idle_test_period 3000
 #hibernate.c3p0.acquire_increment 2
 #hibernate.c3p0.validate false
 
 
 
 ##############################
 ### Proxool Connection Pool###
 ##############################
 
 ## Properties for external configuration of Proxool
 
 hibernate.proxool.pool_alias pool1
 
 ## Only need one of the following
 
 #hibernate.proxool.existing_pool true
 #hibernate.proxool.xml proxool.xml
 #hibernate.proxool.properties proxool.properties
 
 
 
 #################################
 ### Plugin ConnectionProvider ###
 #################################
 
 ## use a custom ConnectionProvider (if not set, Hibernate will choose a built-in ConnectionProvider using hueristics)
 
 #hibernate.connection.provider_class org.hibernate.connection.DriverManagerConnectionProvider
 #hibernate.connection.provider_class org.hibernate.connection.DatasourceConnectionProvider
 #hibernate.connection.provider_class org.hibernate.connection.C3P0ConnectionProvider
 #hibernate.connection.provider_class org.hibernate.connection.ProxoolConnectionProvider
 
 
 
 #######################
 ### Transaction API ###
 #######################
 
 ## Enable automatic flush during the JTA beforeCompletion() callback
 ## (This setting is relevant with or without the Transaction API)
 
 #hibernate.transaction.flush_before_completion
 
 
 ## Enable automatic session close at the end of transaction
 ## (This setting is relevant with or without the Transaction API)
 
 #hibernate.transaction.auto_close_session
 
 
 ## the Transaction API abstracts application code from the underlying JTA or JDBC transactions
 
 #hibernate.transaction.factory_class org.hibernate.transaction.JTATransactionFactory
 #hibernate.transaction.factory_class org.hibernate.transaction.JDBCTransactionFactory
 
 
 ## to use JTATransactionFactory, Hibernate must be able to locate the UserTransaction in JNDI
 ## default is java:comp/UserTransaction
 ## you do NOT need this setting if you specify hibernate.transaction.manager_lookup_class
 
 #jta.UserTransaction jta/usertransaction
 #jta.UserTransaction javax.transaction.UserTransaction
 #jta.UserTransaction UserTransaction
 
 
 ## to use the second-level cache with JTA, Hibernate must be able to obtain the JTA TransactionManager
 
 #hibernate.transaction.manager_lookup_class org.hibernate.transaction.JBossTransactionManagerLookup
 #hibernate.transaction.manager_lookup_class org.hibernate.transaction.WeblogicTransactionManagerLookup
 #hibernate.transaction.manager_lookup_class org.hibernate.transaction.WebSphereTransactionManagerLookup
 #hibernate.transaction.manager_lookup_class org.hibernate.transaction.OrionTransactionManagerLookup
 #hibernate.transaction.manager_lookup_class org.hibernate.transaction.ResinTransactionManagerLookup
 
 
 
 ##############################
 ### Miscellaneous Settings ###
 ##############################
 
 ## print all generated SQL to the console
 
 #hibernate.show_sql true
 
 
 ## format SQL in log and console
 
 hibernate.format_sql true
 
 
 ## add comments to the generated SQL
 
 #hibernate.use_sql_comments true
 
 
 ## generate statistics
 
 #hibernate.generate_statistics true
 
 
 ## auto schema export
 
 #hibernate.hbm2ddl.auto create-drop
 #hibernate.hbm2ddl.auto create
 #hibernate.hbm2ddl.auto update
 #hibernate.hbm2ddl.auto validate
 
 
 ## specify a default schema and catalog for unqualified tablenames
 
 #hibernate.default_schema test
 #hibernate.default_catalog test
 
 
 ## enable ordering of SQL UPDATEs by primary key
 
 #hibernate.order_updates true
 
 
 ## set the maximum depth of the outer join fetch tree
 
 hibernate.max_fetch_depth 1
 
 
 ## set the default batch size for batch fetching
 
 #hibernate.default_batch_fetch_size 8
 
 
 ## rollback generated identifier values of deleted entities to default values
 
 #hibernate.use_identifer_rollback true
 
 
 ## enable bytecode reflection optimizer (disabled by default)
 
 #hibernate.bytecode.use_reflection_optimizer true
 
 
 
 #####################
 ### JDBC Settings ###
 #####################
 
 ## specify a JDBC isolation level
 
 #hibernate.connection.isolation 4
 
 
 ## enable JDBC autocommit (not recommended!)
 
 #hibernate.connection.autocommit true
 
 
 ## set the JDBC fetch size
 
 #hibernate.jdbc.fetch_size 25
 
 
 ## set the maximum JDBC 2 batch size (a nonzero value enables batching)
 
 #hibernate.jdbc.batch_size 5
 #hibernate.jdbc.batch_size 0
 
 
 ## enable batch updates even for versioned data
 
 hibernate.jdbc.batch_versioned_data true
 
 
 ## enable use of JDBC 2 scrollable ResultSets (specifying a Dialect will cause Hibernate to use a sensible default)
 
 #hibernate.jdbc.use_scrollable_resultset true
 
 
 ## use streams when writing binary types to / from JDBC
 
 hibernate.jdbc.use_streams_for_binary true
 
 
 ## use JDBC 3 PreparedStatement.getGeneratedKeys() to get the identifier of an inserted row
 
 #hibernate.jdbc.use_get_generated_keys false
 
 
 ## choose a custom JDBC batcher
 
 # hibernate.jdbc.factory_class
 
 
 ## enable JDBC result set column alias caching 
 ## (minor performance enhancement for broken JDBC drivers)
 
 # hibernate.jdbc.wrap_result_sets
 
 
 ## choose a custom SQL exception converter
 
 #hibernate.jdbc.sql_exception_converter
 
 
 
 ##########################
 ### Second-level Cache ###
 ##########################
 
 ## optimize chache for minimal "puts" instead of minimal "gets" (good for clustered cache)
 
 #hibernate.cache.use_minimal_puts true
 
 
 ## set a prefix for cache region names
 
 hibernate.cache.region_prefix hibernate.test
 
 
 ## disable the second-level cache
 
 #hibernate.cache.use_second_level_cache false
 
 
 ## enable the query cache
 
 #hibernate.cache.use_query_cache true
 
 
 ## store the second-level cache entries in a more human-friendly format
 
 #hibernate.cache.use_structured_entries true
 
 
 ## choose a cache implementation
 
 #hibernate.cache.provider_class org.hibernate.cache.EhCacheProvider
 #hibernate.cache.provider_class org.hibernate.cache.EmptyCacheProvider
-hibernate.cache.provider_class org.hibernate.cache.HashtableCacheProvider
+hibernate.cache.provider_class org.hibernate.cache.internal.HashtableCacheProvider
 #hibernate.cache.provider_class org.hibernate.cache.TreeCacheProvider
 #hibernate.cache.provider_class org.hibernate.cache.OSCacheProvider
 #hibernate.cache.provider_class org.hibernate.cache.SwarmCacheProvider
 
 
 ## choose a custom query cache implementation
 
 #hibernate.cache.query_cache_factory
 
 
 
 ############
 ### JNDI ###
 ############
 
 ## specify a JNDI name for the SessionFactory
 
 #hibernate.session_factory_name hibernate/session_factory
 
 
 ## Hibernate uses JNDI to bind a name to a SessionFactory and to look up the JTA UserTransaction;
 ## if hibernate.jndi.* are not specified, Hibernate will use the default InitialContext() which
 ## is the best approach in an application server
 
 #file system
 #hibernate.jndi.class com.sun.jndi.fscontext.RefFSContextFactory
 #hibernate.jndi.url file:/
 
 #WebSphere
 #hibernate.jndi.class com.ibm.websphere.naming.WsnInitialContextFactory
 #hibernate.jndi.url iiop://localhost:900/
 
diff --git a/hibernate-core/src/main/java/org/hibernate/action/internal/BulkOperationCleanupAction.java b/hibernate-core/src/main/java/org/hibernate/action/internal/BulkOperationCleanupAction.java
index 1465ac119b..2b6fc021f4 100644
--- a/hibernate-core/src/main/java/org/hibernate/action/internal/BulkOperationCleanupAction.java
+++ b/hibernate-core/src/main/java/org/hibernate/action/internal/BulkOperationCleanupAction.java
@@ -1,237 +1,237 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.action.internal;
 
 import java.io.Serializable;
 import java.util.Arrays;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashSet;
 import java.util.Set;
 
 import org.hibernate.HibernateException;
 import org.hibernate.action.spi.AfterTransactionCompletionProcess;
 import org.hibernate.action.spi.BeforeTransactionCompletionProcess;
 import org.hibernate.action.spi.Executable;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
-import org.hibernate.cache.access.SoftLock;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.spi.access.SoftLock;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Queryable;
 
 /**
  * An {@link org.hibernate.engine.ActionQueue} {@link org.hibernate.action.spi.Executable} for ensuring
  * shared cache cleanup in relation to performed bulk HQL queries.
  * <p/>
  * NOTE: currently this executes for <tt>INSERT</tt> queries as well as
  * <tt>UPDATE</tt> and <tt>DELETE</tt> queries.  For <tt>INSERT</tt> it is
  * really not needed as we'd have no invalid entity/collection data to
  * cleanup (we'd still nee to invalidate the appropriate update-timestamps
  * regions) as a result of this query.
  *
  * @author Steve Ebersole
  */
 public class BulkOperationCleanupAction implements Executable, Serializable {
 	private final Serializable[] affectedTableSpaces;
 
 	private final Set<EntityCleanup> entityCleanups = new HashSet<EntityCleanup>();
 	private final Set<CollectionCleanup> collectionCleanups = new HashSet<CollectionCleanup>();
 
 	/**
 	 * Constructs an action to cleanup "affected cache regions" based on the
 	 * affected entity persisters.  The affected regions are defined as the
 	 * region (if any) of the entity persisters themselves, plus the
 	 * collection regions for any collection in which those entity
 	 * persisters participate as elements/keys/etc.
 	 *
 	 * @param session The session to which this request is tied.
 	 * @param affectedQueryables The affected entity persisters.
 	 */
 	public BulkOperationCleanupAction(SessionImplementor session, Queryable[] affectedQueryables) {
 		SessionFactoryImplementor factory = session.getFactory();
 		LinkedHashSet<String> spacesList = new LinkedHashSet<String>();
 		for ( Queryable persister : affectedQueryables ) {
 			spacesList.addAll( Arrays.asList( (String[]) persister.getQuerySpaces() ) );
 
 			if ( persister.hasCache() ) {
 				entityCleanups.add( new EntityCleanup( persister.getCacheAccessStrategy() ) );
 			}
 
 			Set<String> roles = factory.getCollectionRolesByEntityParticipant( persister.getEntityName() );
 			if ( roles != null ) {
 				for ( String role : roles ) {
 					CollectionPersister collectionPersister = factory.getCollectionPersister( role );
 					if ( collectionPersister.hasCache() ) {
 						collectionCleanups.add( new CollectionCleanup( collectionPersister.getCacheAccessStrategy() ) );
 					}
 				}
 			}
 		}
 
 		this.affectedTableSpaces = spacesList.toArray( new String[ spacesList.size() ] );
 	}
 
 	/**
 	 * Constructs an action to cleanup "affected cache regions" based on a
 	 * set of affected table spaces.  This differs from {@link #BulkOperationCleanupAction(SessionImplementor, Queryable[])}
 	 * in that here we have the affected <strong>table names</strong>.  From those
 	 * we deduce the entity persisters which are affected based on the defined
 	 * {@link EntityPersister#getQuerySpaces() table spaces}; and from there, we
 	 * determine the affected collection regions based on any collections
 	 * in which those entity persisters participate as elements/keys/etc.
 	 *
 	 * @param session The session to which this request is tied.
 	 * @param tableSpaces The table spaces.
 	 */
 	@SuppressWarnings({ "unchecked" })
 	public BulkOperationCleanupAction(SessionImplementor session, Set tableSpaces) {
 		LinkedHashSet<String> spacesList = new LinkedHashSet<String>();
 		spacesList.addAll( tableSpaces );
 
 		SessionFactoryImplementor factory = session.getFactory();
 		for ( String entityName : factory.getAllClassMetadata().keySet() ) {
 			final EntityPersister persister = factory.getEntityPersister( entityName );
 			final String[] entitySpaces = (String[]) persister.getQuerySpaces();
 			if ( affectedEntity( tableSpaces, entitySpaces ) ) {
 				spacesList.addAll( Arrays.asList( entitySpaces ) );
 
 				if ( persister.hasCache() ) {
 					entityCleanups.add( new EntityCleanup( persister.getCacheAccessStrategy() ) );
 				}
 				Set<String> roles = session.getFactory().getCollectionRolesByEntityParticipant( persister.getEntityName() );
 				if ( roles != null ) {
 					for ( String role : roles ) {
 						CollectionPersister collectionPersister = factory.getCollectionPersister( role );
 						if ( collectionPersister.hasCache() ) {
 							collectionCleanups.add(
 									new CollectionCleanup( collectionPersister.getCacheAccessStrategy() )
 							);
 						}
 					}
 				}
 			}
 		}
 
 		this.affectedTableSpaces = spacesList.toArray( new String[ spacesList.size() ] );
 	}
 
 
 	/**
 	 * Check to determine whether the table spaces reported by an entity
 	 * persister match against the defined affected table spaces.
 	 *
 	 * @param affectedTableSpaces The table spaces reported to be affected by
 	 * the query.
 	 * @param checkTableSpaces The table spaces (from the entity persister)
 	 * to check against the affected table spaces.
 	 *
 	 * @return True if there are affected table spaces and any of the incoming
 	 * check table spaces occur in that set.
 	 */
 	private boolean affectedEntity(Set affectedTableSpaces, Serializable[] checkTableSpaces) {
 		if ( affectedTableSpaces == null || affectedTableSpaces.isEmpty() ) {
 			return true;
 		}
 
 		for ( Serializable checkTableSpace : checkTableSpaces ) {
 			if ( affectedTableSpaces.contains( checkTableSpace ) ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	@Override
 	public Serializable[] getPropertySpaces() {
 		return affectedTableSpaces;
 	}
 
 	@Override
 	public BeforeTransactionCompletionProcess getBeforeTransactionCompletionProcess() {
 		return null;
 	}
 
 	@Override
 	public AfterTransactionCompletionProcess getAfterTransactionCompletionProcess() {
 		return new AfterTransactionCompletionProcess() {
 			@Override
 			public void doAfterTransactionCompletion(boolean success, SessionImplementor session) {
 				Iterator itr = entityCleanups.iterator();
 				while ( itr.hasNext() ) {
 					final EntityCleanup cleanup = ( EntityCleanup ) itr.next();
 					cleanup.release();
 				}
 
 				itr = collectionCleanups.iterator();
 				while ( itr.hasNext() ) {
 					final CollectionCleanup cleanup = ( CollectionCleanup ) itr.next();
 					cleanup.release();
 				}
 			}
 		};
 	}
 
 	@Override
 	public void beforeExecutions() throws HibernateException {
 		// nothing to do
 	}
 
 	@Override
 	public void execute() throws HibernateException {
 		// nothing to do		
 	}
 
 	private static class EntityCleanup {
 		private final EntityRegionAccessStrategy cacheAccess;
 		private final SoftLock cacheLock;
 
 		private EntityCleanup(EntityRegionAccessStrategy cacheAccess) {
 			this.cacheAccess = cacheAccess;
 			this.cacheLock = cacheAccess.lockRegion();
 			cacheAccess.removeAll();
 		}
 
 		private void release() {
 			cacheAccess.unlockRegion( cacheLock );
 		}
 	}
 
 	private static class CollectionCleanup {
 		private final CollectionRegionAccessStrategy cacheAccess;
 		private final SoftLock cacheLock;
 
 		private CollectionCleanup(CollectionRegionAccessStrategy cacheAccess) {
 			this.cacheAccess = cacheAccess;
 			this.cacheLock = cacheAccess.lockRegion();
 			cacheAccess.removeAll();
 		}
 
 		private void release() {
 			cacheAccess.unlockRegion( cacheLock );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/action/internal/CollectionAction.java b/hibernate-core/src/main/java/org/hibernate/action/internal/CollectionAction.java
index ec3ec06f46..aa9598964d 100644
--- a/hibernate-core/src/main/java/org/hibernate/action/internal/CollectionAction.java
+++ b/hibernate-core/src/main/java/org/hibernate/action/internal/CollectionAction.java
@@ -1,216 +1,216 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.action.internal;
 
 import java.io.Serializable;
 
 import org.hibernate.action.spi.AfterTransactionCompletionProcess;
 import org.hibernate.action.spi.BeforeTransactionCompletionProcess;
 import org.hibernate.action.spi.Executable;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.CacheKey;
-import org.hibernate.cache.access.SoftLock;
+import org.hibernate.cache.spi.CacheKey;
+import org.hibernate.cache.spi.access.SoftLock;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.EventType;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.event.service.spi.EventListenerGroup;
 import org.hibernate.event.service.spi.EventListenerRegistry;
 
 /**
  * Any action relating to insert/update/delete of a collection
  *
  * @author Gavin King
  */
 public abstract class CollectionAction implements Executable, Serializable, Comparable {
 	private transient CollectionPersister persister;
 	private transient SessionImplementor session;
 	private final PersistentCollection collection;
 
 	private final Serializable key;
 	private final String collectionRole;
 
 	public CollectionAction(
 			final CollectionPersister persister, 
 			final PersistentCollection collection, 
 			final Serializable key, 
 			final SessionImplementor session) {
 		this.persister = persister;
 		this.session = session;
 		this.key = key;
 		this.collectionRole = persister.getRole();
 		this.collection = collection;
 	}
 
 	protected PersistentCollection getCollection() {
 		return collection;
 	}
 
 	/**
 	 * Reconnect to session after deserialization...
 	 *
 	 * @param session The session being deserialized
 	 */
 	public void afterDeserialize(SessionImplementor session) {
 		if ( this.session != null || this.persister != null ) {
 			throw new IllegalStateException( "already attached to a session." );
 		}
 		// IMPL NOTE: non-flushed changes code calls this method with session == null...
 		// guard against NullPointerException
 		if ( session != null ) {
 			this.session = session;
 			this.persister = session.getFactory().getCollectionPersister( collectionRole );
 		}
 	}
 
 	@Override
 	public final void beforeExecutions() throws CacheException {
 		// we need to obtain the lock before any actions are executed, since this may be an inverse="true"
 		// bidirectional association and it is one of the earlier entity actions which actually updates
 		// the database (this action is responsible for second-level cache invalidation only)
 		if ( persister.hasCache() ) {
 			final CacheKey ck = session.generateCacheKey(
 					key,
 					persister.getKeyType(),
 					persister.getRole()
 			);
 			final SoftLock lock = persister.getCacheAccessStrategy().lockItem( ck, null );
 			// the old behavior used key as opposed to getKey()
 			afterTransactionProcess = new CacheCleanupProcess( key, persister, lock );
 		}
 	}
 
 	@Override
 	public BeforeTransactionCompletionProcess getBeforeTransactionCompletionProcess() {
 		return null;
 	}
 
 	private AfterTransactionCompletionProcess afterTransactionProcess;
 
 	@Override
 	public AfterTransactionCompletionProcess getAfterTransactionCompletionProcess() {
 		return afterTransactionProcess;
 	}
 
 	@Override
 	public Serializable[] getPropertySpaces() {
 		return persister.getCollectionSpaces();
 	}
 
 	protected final CollectionPersister getPersister() {
 		return persister;
 	}
 
 	protected final Serializable getKey() {
 		Serializable finalKey = key;
 		if ( key instanceof DelayedPostInsertIdentifier ) {
 			// need to look it up from the persistence-context
 			finalKey = session.getPersistenceContext().getEntry( collection.getOwner() ).getId();
 			if ( finalKey == key ) {
 				// we may be screwed here since the collection action is about to execute
 				// and we do not know the final owner key value
 			}
 		}
 		return finalKey;
 	}
 
 	protected final SessionImplementor getSession() {
 		return session;
 	}
 
 	protected final void evict() throws CacheException {
 		if ( persister.hasCache() ) {
 			CacheKey ck = session.generateCacheKey(
 					key, 
 					persister.getKeyType(), 
 					persister.getRole()
 			);
 			persister.getCacheAccessStrategy().remove( ck );
 		}
 	}
 
 	@Override
 	public String toString() {
 		return StringHelper.unqualify( getClass().getName() ) + 
 				MessageHelper.infoString( collectionRole, key );
 	}
 
 	@Override
 	public int compareTo(Object other) {
 		CollectionAction action = ( CollectionAction ) other;
 		//sort first by role name
 		int roleComparison = collectionRole.compareTo( action.collectionRole );
 		if ( roleComparison != 0 ) {
 			return roleComparison;
 		}
 		else {
 			//then by fk
 			return persister.getKeyType()
 					.compare( key, action.key, session.getEntityMode() );
 		}
 	}
 
 	private static class CacheCleanupProcess implements AfterTransactionCompletionProcess {
 		private final Serializable key;
 		private final CollectionPersister persister;
 		private final SoftLock lock;
 
 		private CacheCleanupProcess(Serializable key, CollectionPersister persister, SoftLock lock) {
 			this.key = key;
 			this.persister = persister;
 			this.lock = lock;
 		}
 
 		@Override
 		public void doAfterTransactionCompletion(boolean success, SessionImplementor session) {
 			final CacheKey ck = session.generateCacheKey(
 					key,
 					persister.getKeyType(),
 					persister.getRole()
 			);
 			persister.getCacheAccessStrategy().unlockItem( ck, lock );
 		}
 	}
 
 	protected <T> EventListenerGroup<T> listenerGroup(EventType<T> eventType) {
 		return getSession()
 				.getFactory()
 				.getServiceRegistry()
 				.getService( EventListenerRegistry.class )
 				.getEventListenerGroup( eventType );
 	}
 
 	protected EventSource eventSource() {
 		return (EventSource) getSession();
 	}
 }
 
 
 
 
 
 
diff --git a/hibernate-core/src/main/java/org/hibernate/action/internal/EntityDeleteAction.java b/hibernate-core/src/main/java/org/hibernate/action/internal/EntityDeleteAction.java
index 7adba234f2..97a82661e4 100644
--- a/hibernate-core/src/main/java/org/hibernate/action/internal/EntityDeleteAction.java
+++ b/hibernate-core/src/main/java/org/hibernate/action/internal/EntityDeleteAction.java
@@ -1,180 +1,180 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.action.internal;
 
 import java.io.Serializable;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
-import org.hibernate.cache.CacheKey;
-import org.hibernate.cache.access.SoftLock;
+import org.hibernate.cache.spi.CacheKey;
+import org.hibernate.cache.spi.access.SoftLock;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.PersistenceContext;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.event.EventType;
 import org.hibernate.event.PostDeleteEvent;
 import org.hibernate.event.PostDeleteEventListener;
 import org.hibernate.event.PreDeleteEvent;
 import org.hibernate.event.PreDeleteEventListener;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.event.service.spi.EventListenerGroup;
 
 public final class EntityDeleteAction extends EntityAction {
 	private final Object version;
 	private final boolean isCascadeDeleteEnabled;
 	private final Object[] state;
 
 	private SoftLock lock;
 
 	public EntityDeleteAction(
 			final Serializable id,
 	        final Object[] state,
 	        final Object version,
 	        final Object instance,
 	        final EntityPersister persister,
 	        final boolean isCascadeDeleteEnabled,
 	        final SessionImplementor session) {
 		super( session, id, instance, persister );
 		this.version = version;
 		this.isCascadeDeleteEnabled = isCascadeDeleteEnabled;
 		this.state = state;
 	}
 
 	@Override
 	public void execute() throws HibernateException {
 		Serializable id = getId();
 		EntityPersister persister = getPersister();
 		SessionImplementor session = getSession();
 		Object instance = getInstance();
 
 		boolean veto = preDelete();
 
 		Object version = this.version;
 		if ( persister.isVersionPropertyGenerated() ) {
 			// we need to grab the version value from the entity, otherwise
 			// we have issues with generated-version entities that may have
 			// multiple actions queued during the same flush
 			version = persister.getVersion( instance, session.getEntityMode() );
 		}
 
 		final CacheKey ck;
 		if ( persister.hasCache() ) {
 			ck = session.generateCacheKey( id, persister.getIdentifierType(), persister.getRootEntityName() );
 			lock = persister.getCacheAccessStrategy().lockItem( ck, version );
 		}
 		else {
 			ck = null;
 		}
 
 		if ( !isCascadeDeleteEnabled && !veto ) {
 			persister.delete( id, version, instance, session );
 		}
 		
 		//postDelete:
 		// After actually deleting a row, record the fact that the instance no longer 
 		// exists on the database (needed for identity-column key generation), and
 		// remove it from the session cache
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		EntityEntry entry = persistenceContext.removeEntry( instance );
 		if ( entry == null ) {
 			throw new AssertionFailure( "possible nonthreadsafe access to session" );
 		}
 		entry.postDelete();
 
 		persistenceContext.removeEntity( entry.getEntityKey() );
 		persistenceContext.removeProxy( entry.getEntityKey() );
 		
 		if ( persister.hasCache() ) {
 			persister.getCacheAccessStrategy().remove( ck );
 		}
 
 		postDelete();
 
 		if ( getSession().getFactory().getStatistics().isStatisticsEnabled() && !veto ) {
 			getSession().getFactory().getStatisticsImplementor().deleteEntity( getPersister().getEntityName() );
 		}
 	}
 
 	private boolean preDelete() {
 		boolean veto = false;
 		EventListenerGroup<PreDeleteEventListener> listenerGroup = listenerGroup( EventType.PRE_DELETE );
 		if ( listenerGroup.isEmpty() ) {
 			return veto;
 		}
 		final PreDeleteEvent event = new PreDeleteEvent( getInstance(), getId(), state, getPersister(), eventSource() );
 		for ( PreDeleteEventListener listener : listenerGroup.listeners() ) {
 			veto |= listener.onPreDelete( event );
 		}
 		return veto;
 	}
 
 	private void postDelete() {
 		EventListenerGroup<PostDeleteEventListener> listenerGroup = listenerGroup( EventType.POST_DELETE );
 		if ( listenerGroup.isEmpty() ) {
 			return;
 		}
 		final PostDeleteEvent event = new PostDeleteEvent(
 				getInstance(),
 				getId(),
 				state,
 				getPersister(),
 				eventSource()
 		);
 		for ( PostDeleteEventListener listener : listenerGroup.listeners() ) {
 			listener.onPostDelete( event );
 		}
 	}
 
 	private void postCommitDelete() {
 		EventListenerGroup<PostDeleteEventListener> listenerGroup = listenerGroup( EventType.POST_COMMIT_DELETE );
 		if ( listenerGroup.isEmpty() ) {
 			return;
 		}
 		final PostDeleteEvent event = new PostDeleteEvent(
 				getInstance(),
 				getId(),
 				state,
 				getPersister(),
 				eventSource()
 		);
 	}
 
 	@Override
 	public void doAfterTransactionCompletion(boolean success, SessionImplementor session) throws HibernateException {
 		if ( getPersister().hasCache() ) {
 			final CacheKey ck = getSession().generateCacheKey(
 					getId(),
 					getPersister().getIdentifierType(),
 					getPersister().getRootEntityName()
 			);
 			getPersister().getCacheAccessStrategy().unlockItem( ck, lock );
 		}
 		postCommitDelete();
 	}
 
 	@Override
 	protected boolean hasPostCommitEventListeners() {
 		return ! listenerGroup( EventType.POST_COMMIT_DELETE ).isEmpty();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/action/internal/EntityInsertAction.java b/hibernate-core/src/main/java/org/hibernate/action/internal/EntityInsertAction.java
index c9fccab70a..e003185ab7 100644
--- a/hibernate-core/src/main/java/org/hibernate/action/internal/EntityInsertAction.java
+++ b/hibernate-core/src/main/java/org/hibernate/action/internal/EntityInsertAction.java
@@ -1,206 +1,206 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.action.internal;
 
 import java.io.Serializable;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
-import org.hibernate.cache.CacheKey;
-import org.hibernate.cache.entry.CacheEntry;
+import org.hibernate.cache.spi.CacheKey;
+import org.hibernate.cache.spi.entry.CacheEntry;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.Versioning;
 import org.hibernate.event.EventType;
 import org.hibernate.event.PostInsertEvent;
 import org.hibernate.event.PostInsertEventListener;
 import org.hibernate.event.PreInsertEvent;
 import org.hibernate.event.PreInsertEventListener;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.event.service.spi.EventListenerGroup;
 
 public final class EntityInsertAction extends EntityAction {
 
 	private Object[] state;
 	private Object version;
 	private Object cacheEntry;
 
 	public EntityInsertAction(
 	        Serializable id,
 	        Object[] state,
 	        Object instance,
 	        Object version,
 	        EntityPersister persister,
 	        SessionImplementor session) throws HibernateException {
 		super( session, id, instance, persister );
 		this.state = state;
 		this.version = version;
 	}
 
 	public Object[] getState() {
 		return state;
 	}
 
 	@Override
 	public void execute() throws HibernateException {
 		EntityPersister persister = getPersister();
 		SessionImplementor session = getSession();
 		Object instance = getInstance();
 		Serializable id = getId();
 
 		boolean veto = preInsert();
 
 		// Don't need to lock the cache here, since if someone
 		// else inserted the same pk first, the insert would fail
 
 		if ( !veto ) {
 			
 			persister.insert( id, state, instance, session );
 		
 			EntityEntry entry = session.getPersistenceContext().getEntry( instance );
 			if ( entry == null ) {
 				throw new AssertionFailure( "possible nonthreadsafe access to session" );
 			}
 			
 			entry.postInsert();
 	
 			if ( persister.hasInsertGeneratedProperties() ) {
 				persister.processInsertGeneratedProperties( id, instance, state, session );
 				if ( persister.isVersionPropertyGenerated() ) {
 					version = Versioning.getVersion(state, persister);
 				}
 				entry.postUpdate(instance, state, version);
 			}
 
 			getSession().getPersistenceContext().registerInsertedKey( getPersister(), getId() );
 		}
 
 		final SessionFactoryImplementor factory = getSession().getFactory();
 
 		if ( isCachePutEnabled( persister, session ) ) {
 			
 			CacheEntry ce = new CacheEntry(
 					state,
 					persister, 
 					persister.hasUninitializedLazyProperties( instance, session.getEntityMode() ),
 					version,
 					session,
 					instance
 				);
 			
 			cacheEntry = persister.getCacheEntryStructure().structure(ce);
 			final CacheKey ck = session.generateCacheKey( id, persister.getIdentifierType(), persister.getRootEntityName() );
 			boolean put = persister.getCacheAccessStrategy().insert( ck, cacheEntry, version );
 			
 			if ( put && factory.getStatistics().isStatisticsEnabled() ) {
 				factory.getStatisticsImplementor().secondLevelCachePut( getPersister().getCacheAccessStrategy().getRegion().getName() );
 			}
 			
 		}
 
 		postInsert();
 
 		if ( factory.getStatistics().isStatisticsEnabled() && !veto ) {
 			factory.getStatisticsImplementor()
 					.insertEntity( getPersister().getEntityName() );
 		}
 
 	}
 
 	private void postInsert() {
 		EventListenerGroup<PostInsertEventListener> listenerGroup = listenerGroup( EventType.POST_INSERT );
 		if ( listenerGroup.isEmpty() ) {
 			return;
 		}
 		final PostInsertEvent event = new PostInsertEvent(
 				getInstance(),
 				getId(),
 				state,
 				getPersister(),
 				eventSource()
 		);
 		for ( PostInsertEventListener listener : listenerGroup.listeners() ) {
 			listener.onPostInsert( event );
 		}
 	}
 
 	private void postCommitInsert() {
 		EventListenerGroup<PostInsertEventListener> listenerGroup = listenerGroup( EventType.POST_COMMIT_INSERT );
 		if ( listenerGroup.isEmpty() ) {
 			return;
 		}
 		final PostInsertEvent event = new PostInsertEvent(
 				getInstance(),
 				getId(),
 				state,
 				getPersister(),
 				eventSource()
 		);
 		for ( PostInsertEventListener listener : listenerGroup.listeners() ) {
 			listener.onPostInsert( event );
 		}
 	}
 
 	private boolean preInsert() {
 		boolean veto = false;
 
 		EventListenerGroup<PreInsertEventListener> listenerGroup = listenerGroup( EventType.PRE_INSERT );
 		if ( listenerGroup.isEmpty() ) {
 			return veto;
 		}
 		final PreInsertEvent event = new PreInsertEvent( getInstance(), getId(), state, getPersister(), eventSource() );
 		for ( PreInsertEventListener listener : listenerGroup.listeners() ) {
 			veto |= listener.onPreInsert( event );
 		}
 		return veto;
 	}
 
 	@Override
 	public void doAfterTransactionCompletion(boolean success, SessionImplementor session) throws HibernateException {
 		EntityPersister persister = getPersister();
 		if ( success && isCachePutEnabled( persister, getSession() ) ) {
 			final CacheKey ck = getSession().generateCacheKey( getId(), persister.getIdentifierType(), persister.getRootEntityName() );
 			boolean put = persister.getCacheAccessStrategy().afterInsert( ck, cacheEntry, version );
 			
 			if ( put && getSession().getFactory().getStatistics().isStatisticsEnabled() ) {
 				getSession().getFactory().getStatisticsImplementor()
 						.secondLevelCachePut( getPersister().getCacheAccessStrategy().getRegion().getName() );
 			}
 		}
 		postCommitInsert();
 	}
 
 	@Override
 	protected boolean hasPostCommitEventListeners() {
 		return ! listenerGroup( EventType.POST_COMMIT_INSERT ).isEmpty();
 	}
 	
 	private boolean isCachePutEnabled(EntityPersister persister, SessionImplementor session) {
 		return persister.hasCache()
 				&& !persister.isCacheInvalidationRequired()
 				&& session.getCacheMode().isPutEnabled();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/action/internal/EntityUpdateAction.java b/hibernate-core/src/main/java/org/hibernate/action/internal/EntityUpdateAction.java
index 3c5036cfa0..8778f1b655 100644
--- a/hibernate-core/src/main/java/org/hibernate/action/internal/EntityUpdateAction.java
+++ b/hibernate-core/src/main/java/org/hibernate/action/internal/EntityUpdateAction.java
@@ -1,274 +1,274 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.action.internal;
 
 import java.io.Serializable;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.CacheKey;
-import org.hibernate.cache.access.SoftLock;
-import org.hibernate.cache.entry.CacheEntry;
+import org.hibernate.cache.spi.CacheKey;
+import org.hibernate.cache.spi.access.SoftLock;
+import org.hibernate.cache.spi.entry.CacheEntry;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.Status;
 import org.hibernate.engine.Versioning;
 import org.hibernate.event.EventType;
 import org.hibernate.event.PostUpdateEvent;
 import org.hibernate.event.PostUpdateEventListener;
 import org.hibernate.event.PreUpdateEvent;
 import org.hibernate.event.PreUpdateEventListener;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.event.service.spi.EventListenerGroup;
 import org.hibernate.type.TypeHelper;
 
 public final class EntityUpdateAction extends EntityAction {
 	private final Object[] state;
 	private final Object[] previousState;
 	private final Object previousVersion;
 	private final int[] dirtyFields;
 	private final boolean hasDirtyCollection;
 	private final Object rowId;
 	private Object nextVersion;
 	private Object cacheEntry;
 	private SoftLock lock;
 
 	public EntityUpdateAction(
 	        final Serializable id,
 	        final Object[] state,
 	        final int[] dirtyProperties,
 	        final boolean hasDirtyCollection,
 	        final Object[] previousState,
 	        final Object previousVersion,
 	        final Object nextVersion,
 	        final Object instance,
 	        final Object rowId,
 	        final EntityPersister persister,
 	        final SessionImplementor session) throws HibernateException {
 		super( session, id, instance, persister );
 		this.state = state;
 		this.previousState = previousState;
 		this.previousVersion = previousVersion;
 		this.nextVersion = nextVersion;
 		this.dirtyFields = dirtyProperties;
 		this.hasDirtyCollection = hasDirtyCollection;
 		this.rowId = rowId;
 	}
 
 	@Override
 	public void execute() throws HibernateException {
 		Serializable id = getId();
 		EntityPersister persister = getPersister();
 		SessionImplementor session = getSession();
 		Object instance = getInstance();
 
 		boolean veto = preUpdate();
 
 		final SessionFactoryImplementor factory = getSession().getFactory();
 		Object previousVersion = this.previousVersion;
 		if ( persister.isVersionPropertyGenerated() ) {
 			// we need to grab the version value from the entity, otherwise
 			// we have issues with generated-version entities that may have
 			// multiple actions queued during the same flush
 			previousVersion = persister.getVersion( instance, session.getEntityMode() );
 		}
 		
 		final CacheKey ck;
 		if ( persister.hasCache() ) {
 			ck = session.generateCacheKey(
 					id, 
 					persister.getIdentifierType(), 
 					persister.getRootEntityName()
 			);
 			lock = persister.getCacheAccessStrategy().lockItem( ck, previousVersion );
 		}
 		else {
 			ck = null;
 		}
 
 		if ( !veto ) {
 			persister.update( 
 					id, 
 					state, 
 					dirtyFields, 
 					hasDirtyCollection, 
 					previousState, 
 					previousVersion, 
 					instance, 
 					rowId, 
 					session 
 			);
 		}
 
 		EntityEntry entry = getSession().getPersistenceContext().getEntry( instance );
 		if ( entry == null ) {
 			throw new AssertionFailure( "possible nonthreadsafe access to session" );
 		}
 		
 		if ( entry.getStatus()==Status.MANAGED || persister.isVersionPropertyGenerated() ) {
 			// get the updated snapshot of the entity state by cloning current state;
 			// it is safe to copy in place, since by this time no-one else (should have)
 			// has a reference  to the array
 			TypeHelper.deepCopy(
 					state,
 					persister.getPropertyTypes(),
 					persister.getPropertyCheckability(),
 					state,
 					session
 			);
 			if ( persister.hasUpdateGeneratedProperties() ) {
 				// this entity defines proeprty generation, so process those generated
 				// values...
 				persister.processUpdateGeneratedProperties( id, instance, state, session );
 				if ( persister.isVersionPropertyGenerated() ) {
 					nextVersion = Versioning.getVersion( state, persister );
 				}
 			}
 			// have the entity entry doAfterTransactionCompletion post-update processing, passing it the
 			// update state and the new version (if one).
 			entry.postUpdate( instance, state, nextVersion );
 		}
 
 		if ( persister.hasCache() ) {
 			if ( persister.isCacheInvalidationRequired() || entry.getStatus()!=Status.MANAGED ) {
 				persister.getCacheAccessStrategy().remove( ck );
 			}
 			else {
 				//TODO: inefficient if that cache is just going to ignore the updated state!
 				CacheEntry ce = new CacheEntry(
 						state, 
 						persister, 
 						persister.hasUninitializedLazyProperties( instance, session.getEntityMode() ), 
 						nextVersion,
 						getSession(),
 						instance
 				);
 				cacheEntry = persister.getCacheEntryStructure().structure( ce );
 				boolean put = persister.getCacheAccessStrategy().update( ck, cacheEntry, nextVersion, previousVersion );
 				if ( put && factory.getStatistics().isStatisticsEnabled() ) {
 					factory.getStatisticsImplementor().secondLevelCachePut( getPersister().getCacheAccessStrategy().getRegion().getName() );
 				}
 			}
 		}
 
 		postUpdate();
 
 		if ( factory.getStatistics().isStatisticsEnabled() && !veto ) {
 			factory.getStatisticsImplementor()
 					.updateEntity( getPersister().getEntityName() );
 		}
 	}
 
 	private boolean preUpdate() {
 		boolean veto = false;
 		EventListenerGroup<PreUpdateEventListener> listenerGroup = listenerGroup( EventType.PRE_UPDATE );
 		if ( listenerGroup.isEmpty() ) {
 			return veto;
 		}
 		final PreUpdateEvent event = new PreUpdateEvent(
 				getInstance(),
 				getId(),
 				state,
 				previousState,
 				getPersister(),
 				eventSource()
 		);
 		for ( PreUpdateEventListener listener : listenerGroup.listeners() ) {
 			veto |= listener.onPreUpdate( event );
 		}
 		return veto;
 	}
 
 	private void postUpdate() {
 		EventListenerGroup<PostUpdateEventListener> listenerGroup = listenerGroup( EventType.POST_UPDATE );
 		if ( listenerGroup.isEmpty() ) {
 			return;
 		}
 		final PostUpdateEvent event = new PostUpdateEvent(
 				getInstance(),
 				getId(),
 				state,
 				previousState,
 				dirtyFields,
 				getPersister(),
 				eventSource()
 		);
 		for ( PostUpdateEventListener listener : listenerGroup.listeners() ) {
 			listener.onPostUpdate( event );
 		}
 	}
 
 	private void postCommitUpdate() {
 		EventListenerGroup<PostUpdateEventListener> listenerGroup = listenerGroup( EventType.POST_COMMIT_UPDATE );
 		if ( listenerGroup.isEmpty() ) {
 			return;
 		}
 		final PostUpdateEvent event = new PostUpdateEvent(
 				getInstance(),
 				getId(),
 				state,
 				previousState,
 				dirtyFields,
 				getPersister(),
 				eventSource()
 		);
 		for ( PostUpdateEventListener listener : listenerGroup.listeners() ) {
 			listener.onPostUpdate( event );
 		}
 	}
 
 	@Override
 	protected boolean hasPostCommitEventListeners() {
 		return ! listenerGroup( EventType.POST_COMMIT_UPDATE ).isEmpty();
 	}
 
 	@Override
 	public void doAfterTransactionCompletion(boolean success, SessionImplementor session) throws CacheException {
 		EntityPersister persister = getPersister();
 		if ( persister.hasCache() ) {
 			
 			final CacheKey ck = getSession().generateCacheKey(
 					getId(), 
 					persister.getIdentifierType(), 
 					persister.getRootEntityName()
 				);
 			
 			if ( success && cacheEntry!=null /*!persister.isCacheInvalidationRequired()*/ ) {
 				boolean put = persister.getCacheAccessStrategy().afterUpdate( ck, cacheEntry, nextVersion, previousVersion, lock );
 				
 				if ( put && getSession().getFactory().getStatistics().isStatisticsEnabled() ) {
 					getSession().getFactory().getStatisticsImplementor().secondLevelCachePut( getPersister().getCacheAccessStrategy().getRegion().getName() );
 				}
 			}
 			else {
 				persister.getCacheAccessStrategy().unlockItem( ck, lock );
 			}
 		}
 		postCommitUpdate();
 	}
 
 }
 
diff --git a/hibernate-core/src/main/java/org/hibernate/annotations/CacheConcurrencyStrategy.java b/hibernate-core/src/main/java/org/hibernate/annotations/CacheConcurrencyStrategy.java
index 5a17cb737e..5d4ba88d94 100644
--- a/hibernate-core/src/main/java/org/hibernate/annotations/CacheConcurrencyStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/annotations/CacheConcurrencyStrategy.java
@@ -1,88 +1,90 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.annotations;
-import org.hibernate.cache.access.AccessType;
+
+import org.hibernate.cache.spi.access.AccessType;
 
 /**
  * Cache concurrency strategy
  *
  * @author Emmanuel Bernard
  */
 public enum CacheConcurrencyStrategy {
 	NONE( null ),
 	READ_ONLY( AccessType.READ_ONLY ),
 	NONSTRICT_READ_WRITE( AccessType.NONSTRICT_READ_WRITE ),
 	READ_WRITE( AccessType.READ_WRITE ),
 	TRANSACTIONAL( AccessType.TRANSACTIONAL );
 
 	private final AccessType accessType;
 
 	private CacheConcurrencyStrategy(AccessType accessType) {
 		this.accessType = accessType;
 	}
 
 	public static CacheConcurrencyStrategy fromAccessType(AccessType accessType) {
-		final String name = accessType == null ? null : accessType.getName();
-		if ( AccessType.READ_ONLY.getName().equals( name ) ) {
-			return READ_ONLY;
-		}
-		else if ( AccessType.READ_WRITE.getName().equals( name ) ) {
-			return READ_WRITE;
-		}
-		else if ( AccessType.NONSTRICT_READ_WRITE.getName().equals( name ) ) {
-			return NONSTRICT_READ_WRITE;
-		}
-		else if ( AccessType.TRANSACTIONAL.getName().equals( name ) ) {
-			return TRANSACTIONAL;
-		}
-		else {
-			return NONE;
+		switch ( accessType ) {
+			case READ_ONLY: {
+				return READ_ONLY;
+			}
+			case READ_WRITE: {
+				return READ_WRITE;
+			}
+			case NONSTRICT_READ_WRITE: {
+				return NONSTRICT_READ_WRITE;
+			}
+			case TRANSACTIONAL: {
+				return TRANSACTIONAL;
+			}
+			default: {
+				return NONE;
+			}
 		}
 	}
 
 	public static CacheConcurrencyStrategy parse(String name) {
-		if ( READ_ONLY.accessType.getName().equalsIgnoreCase( name ) ) {
+		if ( READ_ONLY.accessType.getExternalName().equalsIgnoreCase( name ) ) {
 			return READ_ONLY;
 		}
-		else if ( READ_WRITE.accessType.getName().equalsIgnoreCase( name ) ) {
+		else if ( READ_WRITE.accessType.getExternalName().equalsIgnoreCase( name ) ) {
 			return READ_WRITE;
 		}
-		else if ( NONSTRICT_READ_WRITE.accessType.getName().equalsIgnoreCase( name ) ) {
+		else if ( NONSTRICT_READ_WRITE.accessType.getExternalName().equalsIgnoreCase( name ) ) {
 			return NONSTRICT_READ_WRITE;
 		}
-		else if ( TRANSACTIONAL.accessType.getName().equalsIgnoreCase( name ) ) {
+		else if ( TRANSACTIONAL.accessType.getExternalName().equalsIgnoreCase( name ) ) {
 			return TRANSACTIONAL;
 		}
 		else if ( "none".equalsIgnoreCase( name ) ) {
 			return NONE;
 		}
 		else {
 			return null;
 		}
 	}
 
 	public AccessType toAccessType() {
 		return accessType;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/RegionFactory.java b/hibernate-core/src/main/java/org/hibernate/cache/RegionFactory.java
index 8e4abde6b9..8934f2d6f0 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/RegionFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/RegionFactory.java
@@ -1,137 +1,33 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.cache;
-import java.util.Properties;
-import org.hibernate.cache.access.AccessType;
-import org.hibernate.cfg.Settings;
 
 /**
- * Contract for building second level cache regions.
- * <p/>
- * Implementors should define a constructor in one of two forms:<ul>
- * <li>MyRegionFactoryImpl({@link java.util.Properties})</li>
- * <li>MyRegionFactoryImpl()</li>
- * </ul>
- * Use the first when we need to read config properties prior to
- * {@link #start} being called.  For an example, have a look at
- * {@link org.hibernate.cache.impl.bridge.RegionFactoryCacheProviderBridge}
- * where we need the properties in order to determine which legacy 
- * {@link CacheProvider} to use so that we can answer the
- * {@link #isMinimalPutsEnabledByDefault()} question for the
- * {@link org.hibernate.cfg.SettingsFactory}.
- *
  * @author Steve Ebersole
+ *
+ * @deprecated Moved, but still need this definition for ehcache 
  */
-public interface RegionFactory {
-
-	/**
-	 * Lifecycle callback to perform any necessary initialization of the
-	 * underlying cache implementation(s).  Called exactly once during the
-	 * construction of a {@link org.hibernate.internal.SessionFactoryImpl}.
-	 *
-	 * @param settings The settings in effect.
-	 * @param properties The defined cfg properties
-	 * @throws CacheException Indicates problems starting the L2 cache impl;
-	 * considered as a sign to stop {@link org.hibernate.SessionFactory}
-	 * building.
-	 */
-	public void start(Settings settings, Properties properties) throws CacheException;
-
-	/**
-	 * Lifecycle callback to perform any necessary cleanup of the underlying
-	 * cache implementation(s).  Called exactly once during
-	 * {@link org.hibernate.SessionFactory#close}.
-	 */
-	public void stop();
-
-	/**
-	 * By default should we perform "minimal puts" when using this second
-	 * level cache implementation?
-	 *
-	 * @return True if "minimal puts" should be performed by default; false
-	 * otherwise.
-	 */
-	public boolean isMinimalPutsEnabledByDefault();
-
-	/**
-	 * Get the default access type for {@link EntityRegion entity} and
-	 * {@link CollectionRegion collection} regions.
-	 *
-	 * @return This factory's default access type.
-	 */
-	public AccessType getDefaultAccessType();
-
-	/**
-	 * Generate a timestamp.
-	 * <p/>
-	 * This is generally used for cache content locking/unlocking purposes
-	 * depending upon the access-strategy being used.
-	 *
-	 * @return The generated timestamp.
-	 */
-	public long nextTimestamp();
-
-	/**
-	 * Build a cache region specialized for storing entity data.
-	 *
-	 * @param regionName The name of the region.
-	 * @param properties Configuration properties.
-	 * @param metadata Information regarding the type of data to be cached
-	 * @return The built region
-	 * @throws CacheException Indicates problems building the region.
-	 */
-	public EntityRegion buildEntityRegion(String regionName, Properties properties, CacheDataDescription metadata) throws CacheException;
-
-	/**
-	 * Build a cache region specialized for storing collection data.
-	 *
-	 * @param regionName The name of the region.
-	 * @param properties Configuration properties.
-	 * @param metadata Information regarding the type of data to be cached
-	 * @return The built region
-	 * @throws CacheException Indicates problems building the region.
-	 */
-	public CollectionRegion buildCollectionRegion(String regionName, Properties properties, CacheDataDescription metadata) throws CacheException;
-
-	/**
-	 * Build a cache region specialized for storing query results
-	 *
-	 * @param regionName The name of the region.
-	 * @param properties Configuration properties.
-	 * @return The built region
-	 * @throws CacheException Indicates problems building the region.
-	 */
-	public QueryResultsRegion buildQueryResultsRegion(String regionName, Properties properties) throws CacheException;
-
-	/**
-	 * Build a cache region specialized for storing update-timestamps data.
-	 *
-	 * @param regionName The name of the region.
-	 * @param properties Configuration properties.
-	 * @return The built region
-	 * @throws CacheException Indicates problems building the region.
-	 */
-	public TimestampsRegion buildTimestampsRegion(String regionName, Properties properties) throws CacheException;
+@Deprecated
+public interface RegionFactory extends org.hibernate.cache.spi.RegionFactory {
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/access/AccessType.java b/hibernate-core/src/main/java/org/hibernate/cache/access/AccessType.java
deleted file mode 100644
index cfc7d722fb..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/cache/access/AccessType.java
+++ /dev/null
@@ -1,85 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache.access;
-import java.io.Serializable;
-
-/**
- * The types of access strategies available.
- *
- * @author Steve Ebersole
- */
-public class AccessType implements Serializable {
-	public static final AccessType READ_ONLY = new AccessType( "read-only" );
-	public static final AccessType READ_WRITE = new AccessType( "read-write" );
-	public static final AccessType NONSTRICT_READ_WRITE = new AccessType( "nonstrict-read-write" );
-	public static final AccessType TRANSACTIONAL = new AccessType( "transactional" );
-
-	private final String name;
-
-	private AccessType(String name) {
-		this.name = name;
-	}
-
-	public String getName() {
-		return name;
-	}
-
-	public String toString() {
-		return "AccessType[" + name + "]";
-	}
-
-	private static AccessType resolve(String name) {
-		if ( READ_ONLY.name.equals( name ) ) {
-			return READ_ONLY;
-		}
-		else if ( READ_WRITE.name.equals( name ) ) {
-			return READ_WRITE;
-		}
-		else if ( NONSTRICT_READ_WRITE.name.equals( name ) ) {
-			return NONSTRICT_READ_WRITE;
-		}
-		else if ( TRANSACTIONAL.name.equals( name ) ) {
-			return TRANSACTIONAL;
-		}
-		else {
-			return null;
-		}
-	}
-
-	public static AccessType parse(String name) {
-		return resolve( name );
-	}
-
-	private Object readResolve() {
-		return resolve( name );
-	}
-
-	public static String getValidUsageString() {
-		return "cache usage attribute should be " + READ_ONLY.name +
-				", " + READ_WRITE.name +
-				", " + NONSTRICT_READ_WRITE.name +
-				", or " + TRANSACTIONAL.name;
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/impl/CacheDataDescriptionImpl.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/CacheDataDescriptionImpl.java
similarity index 88%
rename from hibernate-core/src/main/java/org/hibernate/cache/impl/CacheDataDescriptionImpl.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/CacheDataDescriptionImpl.java
index 886a1da748..425dfac570 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/impl/CacheDataDescriptionImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/CacheDataDescriptionImpl.java
@@ -1,75 +1,76 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache.impl;
-import java.util.Comparator;
-import org.hibernate.cache.CacheDataDescription;
-import org.hibernate.mapping.Collection;
-import org.hibernate.mapping.PersistentClass;
-import org.hibernate.type.VersionType;
-
-/**
- * {@inheritDoc}
- *
- * @author Steve Ebersole
- */
-public class CacheDataDescriptionImpl implements CacheDataDescription {
-	private final boolean mutable;
-	private final boolean versioned;
-	private final Comparator versionComparator;
-
-	public CacheDataDescriptionImpl(boolean mutable, boolean versioned, Comparator versionComparator) {
-		this.mutable = mutable;
-		this.versioned = versioned;
-		this.versionComparator = versionComparator;
-	}
-
-	public boolean isMutable() {
-		return mutable;
-	}
-
-	public boolean isVersioned() {
-		return versioned;
-	}
-
-	public Comparator getVersionComparator() {
-		return versionComparator;
-	}
-
-	public static CacheDataDescriptionImpl decode(PersistentClass model) {
-		return new CacheDataDescriptionImpl(
-				model.isMutable(),
-				model.isVersioned(),
-				model.isVersioned() ? ( ( VersionType ) model.getVersion().getType() ).getComparator() : null
-		);
-	}
-
-	public static CacheDataDescriptionImpl decode(Collection model) {
-		return new CacheDataDescriptionImpl(
-				model.isMutable(),
-				model.getOwner().isVersioned(),
-				model.getOwner().isVersioned() ? ( ( VersionType ) model.getOwner().getVersion().getType() ).getComparator() : null
-		);
-	}
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.internal;
+
+import java.util.Comparator;
+
+import org.hibernate.cache.spi.CacheDataDescription;
+import org.hibernate.mapping.Collection;
+import org.hibernate.mapping.PersistentClass;
+import org.hibernate.type.VersionType;
+
+/**
+ * {@inheritDoc}
+ *
+ * @author Steve Ebersole
+ */
+public class CacheDataDescriptionImpl implements CacheDataDescription {
+	private final boolean mutable;
+	private final boolean versioned;
+	private final Comparator versionComparator;
+
+	public CacheDataDescriptionImpl(boolean mutable, boolean versioned, Comparator versionComparator) {
+		this.mutable = mutable;
+		this.versioned = versioned;
+		this.versionComparator = versionComparator;
+	}
+
+	public boolean isMutable() {
+		return mutable;
+	}
+
+	public boolean isVersioned() {
+		return versioned;
+	}
+
+	public Comparator getVersionComparator() {
+		return versionComparator;
+	}
+
+	public static CacheDataDescriptionImpl decode(PersistentClass model) {
+		return new CacheDataDescriptionImpl(
+				model.isMutable(),
+				model.isVersioned(),
+				model.isVersioned() ? ( ( VersionType ) model.getVersion().getType() ).getComparator() : null
+		);
+	}
+
+	public static CacheDataDescriptionImpl decode(Collection model) {
+		return new CacheDataDescriptionImpl(
+				model.isMutable(),
+				model.getOwner().isVersioned(),
+				model.getOwner().isVersioned() ? ( ( VersionType ) model.getOwner().getVersion().getType() ).getComparator() : null
+		);
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/HashtableCache.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/HashtableCache.java
similarity index 91%
rename from hibernate-core/src/main/java/org/hibernate/cache/HashtableCache.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/HashtableCache.java
index f95b2bded4..519f9f5b2e 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/HashtableCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/HashtableCache.java
@@ -1,111 +1,114 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.internal;
+
 import java.util.Collections;
 import java.util.Hashtable;
 import java.util.Map;
 
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.Cache;
+
 /**
  * A lightweight implementation of the <tt>Cache</tt> interface
  * @author Gavin King
  */
 public class HashtableCache implements Cache {
 	
 	private final Map hashtable = new Hashtable();
 	private final String regionName;
 	
 	public HashtableCache(String regionName) {
 		this.regionName = regionName;
 	}
 
 	public String getRegionName() {
 		return regionName;
 	}
 
 	public Object read(Object key) throws CacheException {
 		return hashtable.get(key);
 	}
 
 	public Object get(Object key) throws CacheException {
 		return hashtable.get(key);
 	}
 
 	public void update(Object key, Object value) throws CacheException {
 		put(key, value);
 	}
 	
 	public void put(Object key, Object value) throws CacheException {
 		hashtable.put(key, value);
 	}
 
 	public void remove(Object key) throws CacheException {
 		hashtable.remove(key);
 	}
 
 	public void clear() throws CacheException {
 		hashtable.clear();
 	}
 
 	public void destroy() throws CacheException {
 
 	}
 
 	public void lock(Object key) throws CacheException {
 		// local cache, so we use synchronization
 	}
 
 	public void unlock(Object key) throws CacheException {
 		// local cache, so we use synchronization
 	}
 
 	public long nextTimestamp() {
 		return Timestamper.next();
 	}
 
 	public int getTimeout() {
 		return Timestamper.ONE_MS * 60000; //ie. 60 seconds
 	}
 
 	public long getSizeInMemory() {
 		return -1;
 	}
 
 	public long getElementCountInMemory() {
 		return hashtable.size();
 	}
 
 	public long getElementCountOnDisk() {
 		return 0;
 	}
 	
 	public Map toMap() {
 		return Collections.unmodifiableMap(hashtable);
 	}
 
 	public String toString() {
 		return "HashtableCache(" + regionName + ')';
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/HashtableCacheProvider.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/HashtableCacheProvider.java
similarity index 86%
rename from hibernate-core/src/main/java/org/hibernate/cache/HashtableCacheProvider.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/HashtableCacheProvider.java
index a652778899..ea4830d43e 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/HashtableCacheProvider.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/HashtableCacheProvider.java
@@ -1,64 +1,68 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.internal;
+
 import java.util.Properties;
 
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.Cache;
+import org.hibernate.cache.spi.CacheProvider;
+
 /**
  * A simple in-memory Hashtable-based cache impl.
  * 
  * @author Gavin King
  */
 public class HashtableCacheProvider implements CacheProvider {
 
 	public Cache buildCache(String regionName, Properties properties) throws CacheException {
 		return new HashtableCache( regionName );
 	}
 
 	public long nextTimestamp() {
 		return Timestamper.next();
 	}
 
 	/**
 	 * Callback to perform any necessary initialization of the underlying cache implementation
 	 * during SessionFactory construction.
 	 *
 	 * @param properties current configuration settings.
 	 */
 	public void start(Properties properties) throws CacheException {
 	}
 
 	/**
 	 * Callback to perform any necessary cleanup of the underlying cache implementation
 	 * during SessionFactory.close().
 	 */
 	public void stop() {
 	}
 
 	public boolean isMinimalPutsEnabledByDefault() {
 		return false;
 	}
 
 }
 
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/NoCacheProvider.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/NoCacheProvider.java
similarity index 86%
rename from hibernate-core/src/main/java/org/hibernate/cache/NoCacheProvider.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/NoCacheProvider.java
index 0f3e058023..30c455a44d 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/NoCacheProvider.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/NoCacheProvider.java
@@ -1,80 +1,86 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.internal;
+
 import java.util.Properties;
 
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.NoCachingEnabledException;
+import org.hibernate.cache.spi.Cache;
+import org.hibernate.cache.spi.CacheProvider;
+
 /**
  * Implementation of NoCacheProvider.
  *
  * @author Steve Ebersole
  */
+@Deprecated
 public class NoCacheProvider implements CacheProvider {
 	/**
 	 * Configure the cache
 	 *
 	 * @param regionName the name of the cache region
 	 * @param properties configuration settings
 	 *
-	 * @throws CacheException
+	 * @throws org.hibernate.cache.CacheException
 	 */
 	public Cache buildCache(String regionName, Properties properties) throws CacheException {
 		throw new NoCachingEnabledException();
 	}
 
 	/**
 	 * Generate a timestamp
 	 */
 	public long nextTimestamp() {
 		// This, is used by SessionFactoryImpl to hand to the generated SessionImpl;
 		// was the only reason I could see that we cannot just use null as
 		// Settings.cacheProvider
 		return System.currentTimeMillis() / 100;
 	}
 
 	/**
 	 * Callback to perform any necessary initialization of the underlying cache implementation during SessionFactory
 	 * construction.
 	 *
 	 * @param properties current configuration settings.
 	 */
 	public void start(Properties properties) throws CacheException {
 		// this is called by SessionFactory irregardless; we just disregard here;
 		// could also add a check to SessionFactory to only conditionally call start
 	}
 
 	/**
 	 * Callback to perform any necessary cleanup of the underlying cache implementation during SessionFactory.close().
 	 */
 	public void stop() {
 		// this is called by SessionFactory irregardless; we just disregard here;
 		// could also add a check to SessionFactory to only conditionally call stop
 	}
 
 	public boolean isMinimalPutsEnabledByDefault() {
 		// this is called from SettingsFactory irregardless; trivial to simply disregard
 		return false;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/impl/NoCachingRegionFactory.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/NoCachingRegionFactory.java
similarity index 84%
rename from hibernate-core/src/main/java/org/hibernate/cache/impl/NoCachingRegionFactory.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/NoCachingRegionFactory.java
index e2c214caa9..0fdaf19e20 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/impl/NoCachingRegionFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/NoCachingRegionFactory.java
@@ -1,83 +1,85 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.cache.impl;
-import java.util.Properties;
-import org.hibernate.cache.CacheDataDescription;
-import org.hibernate.cache.CacheException;
-import org.hibernate.cache.CollectionRegion;
-import org.hibernate.cache.EntityRegion;
-import org.hibernate.cache.NoCachingEnabledException;
-import org.hibernate.cache.QueryResultsRegion;
-import org.hibernate.cache.RegionFactory;
-import org.hibernate.cache.TimestampsRegion;
-import org.hibernate.cache.access.AccessType;
-import org.hibernate.cfg.Settings;
-
-/**
- * Factory used if no caching enabled in config...
- *
- * @author Steve Ebersole
- */
-public class NoCachingRegionFactory implements RegionFactory {
-
-
-	public NoCachingRegionFactory(Properties properties) {
-	}
-
-	public void start(Settings settings, Properties properties) throws CacheException {
-	}
-
-	public void stop() {
-	}
-
-	public boolean isMinimalPutsEnabledByDefault() {
-		return false;
-	}
-
-	public AccessType getDefaultAccessType() {
-		return null;
-	}
-
-	public long nextTimestamp() {
-		return System.currentTimeMillis() / 100;
-	}
-
-	public EntityRegion buildEntityRegion(String regionName, Properties properties, CacheDataDescription metadata)
-			throws CacheException {
-		throw new NoCachingEnabledException();
-	}
-
-	public CollectionRegion buildCollectionRegion(String regionName, Properties properties, CacheDataDescription metadata)
-			throws CacheException {
-		throw new NoCachingEnabledException();
-	}
-
-	public QueryResultsRegion buildQueryResultsRegion(String regionName, Properties properties) throws CacheException {
-		throw new NoCachingEnabledException();
-	}
-
-	public TimestampsRegion buildTimestampsRegion(String regionName, Properties properties) throws CacheException {
-		throw new NoCachingEnabledException();
-	}
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.internal;
+
+import java.util.Properties;
+
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.NoCachingEnabledException;
+import org.hibernate.cache.spi.CacheDataDescription;
+import org.hibernate.cache.spi.CollectionRegion;
+import org.hibernate.cache.spi.EntityRegion;
+import org.hibernate.cache.spi.QueryResultsRegion;
+import org.hibernate.cache.spi.RegionFactory;
+import org.hibernate.cache.spi.TimestampsRegion;
+import org.hibernate.cache.spi.access.AccessType;
+import org.hibernate.cfg.Settings;
+
+/**
+ * Factory used if no caching enabled in config...
+ *
+ * @author Steve Ebersole
+ */
+public class NoCachingRegionFactory implements RegionFactory {
+
+
+	public NoCachingRegionFactory(Properties properties) {
+	}
+
+	public void start(Settings settings, Properties properties) throws CacheException {
+	}
+
+	public void stop() {
+	}
+
+	public boolean isMinimalPutsEnabledByDefault() {
+		return false;
+	}
+
+	public AccessType getDefaultAccessType() {
+		return null;
+	}
+
+	public long nextTimestamp() {
+		return System.currentTimeMillis() / 100;
+	}
+
+	public EntityRegion buildEntityRegion(String regionName, Properties properties, CacheDataDescription metadata)
+			throws CacheException {
+		throw new NoCachingEnabledException();
+	}
+
+	public CollectionRegion buildCollectionRegion(String regionName, Properties properties, CacheDataDescription metadata)
+			throws CacheException {
+		throw new NoCachingEnabledException();
+	}
+
+	public QueryResultsRegion buildQueryResultsRegion(String regionName, Properties properties) throws CacheException {
+		throw new NoCachingEnabledException();
+	}
+
+	public TimestampsRegion buildTimestampsRegion(String regionName, Properties properties) throws CacheException {
+		throw new NoCachingEnabledException();
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/StandardQueryCache.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/StandardQueryCache.java
similarity index 97%
rename from hibernate-core/src/main/java/org/hibernate/cache/StandardQueryCache.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/StandardQueryCache.java
index ebdc3c18a7..9a697903c5 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/StandardQueryCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/StandardQueryCache.java
@@ -1,237 +1,245 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.cache;
+package org.hibernate.cache.internal;
+
+import javax.persistence.EntityNotFoundException;
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Properties;
 import java.util.Set;
-import javax.persistence.EntityNotFoundException;
+
+import org.jboss.logging.Logger;
+
 import org.hibernate.HibernateException;
-import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.UnresolvableObjectException;
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.QueryCache;
+import org.hibernate.cache.spi.QueryKey;
+import org.hibernate.cache.spi.QueryResultsRegion;
+import org.hibernate.cache.spi.UpdateTimestampsCache;
 import org.hibernate.cfg.Settings;
 import org.hibernate.engine.SessionImplementor;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeHelper;
-import org.jboss.logging.Logger;
 
 /**
  * The standard implementation of the Hibernate QueryCache interface.  This
  * implementation is very good at recognizing stale query results and
  * and re-running queries when it detects this condition, recaching the new
  * results.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class StandardQueryCache implements QueryCache {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, StandardQueryCache.class.getName());
 
 	private QueryResultsRegion cacheRegion;
 	private UpdateTimestampsCache updateTimestampsCache;
 
 	public void clear() throws CacheException {
 		cacheRegion.evictAll();
 	}
 
 	public StandardQueryCache(
 			final Settings settings,
 			final Properties props,
 			final UpdateTimestampsCache updateTimestampsCache,
 			String regionName) throws HibernateException {
 		if ( regionName == null ) {
 			regionName = StandardQueryCache.class.getName();
 		}
 		String prefix = settings.getCacheRegionPrefix();
 		if ( prefix != null ) {
 			regionName = prefix + '.' + regionName;
 		}
         LOG.startingQueryCache(regionName);
 
 		this.cacheRegion = settings.getRegionFactory().buildQueryResultsRegion( regionName, props );
 		this.updateTimestampsCache = updateTimestampsCache;
 	}
 
 	@SuppressWarnings({ "UnnecessaryBoxing", "unchecked" })
 	public boolean put(
 			QueryKey key,
 			Type[] returnTypes,
 			List result,
 			boolean isNaturalKeyLookup,
 			SessionImplementor session) throws HibernateException {
         if (isNaturalKeyLookup && result.size() == 0) return false;
         Long ts = new Long(session.getFactory().getSettings().getRegionFactory().nextTimestamp());
 
         LOG.debugf("Caching query results in region: %s; timestamp=%s", cacheRegion.getName(), ts);
 
 		List cacheable = new ArrayList(result.size() + 1);
         logCachedResultDetails(key, null, returnTypes, cacheable);
         cacheable.add(ts);
         for (Object aResult : result) {
             if (returnTypes.length == 1) cacheable.add(returnTypes[0].disassemble(aResult, session, null));
             else cacheable.add(TypeHelper.disassemble((Object[])aResult, returnTypes, null, session, null));
             logCachedResultRowDetails(returnTypes, aResult);
         }
 
 		cacheRegion.put(key, cacheable);
         return true;
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public List get(
 			QueryKey key,
 			Type[] returnTypes,
 			boolean isNaturalKeyLookup,
 			Set spaces,
 			SessionImplementor session) throws HibernateException {
         LOG.debugf("Checking cached query results in region: %s", cacheRegion.getName());
 
 		List cacheable = ( List ) cacheRegion.get( key );
         logCachedResultDetails(key, spaces, returnTypes, cacheable);
 
 		if ( cacheable == null ) {
             LOG.debugf("Query results were not found in cache");
 			return null;
 		}
 
 		Long timestamp = ( Long ) cacheable.get( 0 );
 		if ( !isNaturalKeyLookup && !isUpToDate( spaces, timestamp ) ) {
             LOG.debugf("Cached query results were not up-to-date");
 			return null;
 		}
 
         LOG.debugf("Returning cached query results");
 		for ( int i = 1; i < cacheable.size(); i++ ) {
 			if ( returnTypes.length == 1 ) {
 				returnTypes[0].beforeAssemble( ( Serializable ) cacheable.get( i ), session );
 			}
 			else {
 				TypeHelper.beforeAssemble( ( Serializable[] ) cacheable.get( i ), returnTypes, session );
 			}
 		}
 		List result = new ArrayList( cacheable.size() - 1 );
 		for ( int i = 1; i < cacheable.size(); i++ ) {
 			try {
 				if ( returnTypes.length == 1 ) {
 					result.add( returnTypes[0].assemble( ( Serializable ) cacheable.get( i ), session, null ) );
 				}
 				else {
 					result.add(
 							TypeHelper.assemble( ( Serializable[] ) cacheable.get( i ), returnTypes, session, null )
 					);
 				}
                 logCachedResultRowDetails(returnTypes, result.get(i - 1));
 			}
 			catch ( RuntimeException ex ) {
 				if ( isNaturalKeyLookup &&
 						( UnresolvableObjectException.class.isInstance( ex ) ||
 						EntityNotFoundException.class.isInstance( ex ) ) ) {
 					//TODO: not really completely correct, since
 					//      the uoe could occur while resolving
 					//      associations, leaving the PC in an
 					//      inconsistent state
                     LOG.debugf("Unable to reassemble cached result set");
 					cacheRegion.evict( key );
 					return null;
 				}
                 throw ex;
 			}
 		}
 		return result;
 	}
 
 	protected boolean isUpToDate(Set spaces, Long timestamp) {
         LOG.debugf("Checking query spaces are up-to-date: %s", spaces);
 		return updateTimestampsCache.isUpToDate( spaces, timestamp );
 	}
 
 	public void destroy() {
 		try {
 			cacheRegion.destroy();
 		}
 		catch ( Exception e ) {
             LOG.unableToDestroyQueryCache(cacheRegion.getName(), e.getMessage());
 		}
 	}
 
 	public QueryResultsRegion getRegion() {
 		return cacheRegion;
 	}
 
 	@Override
     public String toString() {
 		return "StandardQueryCache(" + cacheRegion.getName() + ')';
 	}
 
 	private static void logCachedResultDetails(QueryKey key, Set querySpaces, Type[] returnTypes, List result) {
         if (!LOG.isTraceEnabled()) return;
         LOG.trace("key.hashCode=" + key.hashCode());
         LOG.trace("querySpaces=" + querySpaces);
         if (returnTypes == null || returnTypes.length == 0) LOG.trace("Unexpected returnTypes is "
                                                                       + (returnTypes == null ? "null" : "empty") + "! result"
                                                                       + (result == null ? " is null" : ".size()=" + result.size()));
 		else {
 			StringBuffer returnTypeInfo = new StringBuffer();
 			for ( int i=0; i<returnTypes.length; i++ ) {
 				returnTypeInfo.append( "typename=" )
 						.append( returnTypes[ i ].getName() )
 						.append(" class=" )
 						.append( returnTypes[ i ].getReturnedClass().getName() ).append(' ');
 			}
             LOG.trace("unexpected returnTypes is " + returnTypeInfo.toString() + "! result");
 		}
 	}
 
 	private static void logCachedResultRowDetails(Type[] returnTypes, Object result) {
         if (!LOG.isTraceEnabled()) return;
 		logCachedResultRowDetails(
 				returnTypes,
 				( result instanceof Object[] ? ( Object[] ) result : new Object[] { result } )
 		);
 	}
 
 	private static void logCachedResultRowDetails(Type[] returnTypes, Object[] tuple) {
         if (!LOG.isTraceEnabled()) return;
 		if ( tuple == null ) {
             LOG.trace(" tuple is null; returnTypes is " + returnTypes == null ? "null" : "Type[" + returnTypes.length + "]");
             if (returnTypes != null && returnTypes.length > 1) LOG.trace("Unexpected result tuple! tuple is null; should be Object["
                                                                          + returnTypes.length + "]!");
 		}
 		else {
             if (returnTypes == null || returnTypes.length == 0) LOG.trace("Unexpected result tuple! tuple is null; returnTypes is "
                                                                           + (returnTypes == null ? "null" : "empty"));
             LOG.trace(" tuple is Object[" + tuple.length + "]; returnTypes is Type[" + returnTypes.length + "]");
             if (tuple.length != returnTypes.length) LOG.trace("Unexpected tuple length! transformer= expected="
                                                               + returnTypes.length + " got=" + tuple.length);
             else for (int j = 0; j < tuple.length; j++) {
                 if (tuple[j] != null && !returnTypes[j].getReturnedClass().isInstance(tuple[j])) LOG.trace("Unexpected tuple value type! transformer= expected="
                                                                                                            + returnTypes[j].getReturnedClass().getName()
                                                                                                            + " got="
                                                                                                            + tuple[j].getClass().getName());
             }
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/StandardQueryCacheFactory.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/StandardQueryCacheFactory.java
similarity index 76%
rename from hibernate-core/src/main/java/org/hibernate/cache/StandardQueryCacheFactory.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/StandardQueryCacheFactory.java
index 29264b9a10..26f742dc5f 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/StandardQueryCacheFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/StandardQueryCacheFactory.java
@@ -1,45 +1,47 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.internal;
+
 import java.util.Properties;
+
 import org.hibernate.HibernateException;
+import org.hibernate.cache.spi.QueryCache;
+import org.hibernate.cache.spi.QueryCacheFactory;
+import org.hibernate.cache.spi.UpdateTimestampsCache;
 import org.hibernate.cfg.Settings;
 
 /**
- * Standard Hibernate implementation of the QueryCacheFactory interface.  Returns
- * instances of {@link StandardQueryCache}.
+ * Standard Hibernate implementation of the QueryCacheFactory interface.  Returns instances of
+ * {@link StandardQueryCache}.
  */
 public class StandardQueryCacheFactory implements QueryCacheFactory {
-
+	@Override
 	public QueryCache getQueryCache(
 	        final String regionName,
 	        final UpdateTimestampsCache updateTimestampsCache,
 	        final Settings settings,
-	        final Properties props) 
-	throws HibernateException {
+	        final Properties props) throws HibernateException {
 		return new StandardQueryCache(settings, props, updateTimestampsCache, regionName);
 	}
-
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/Timestamper.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/Timestamper.java
similarity index 79%
rename from hibernate-core/src/main/java/org/hibernate/cache/Timestamper.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/Timestamper.java
index bdbae9e67c..fc9c9d1e54 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/Timestamper.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/Timestamper.java
@@ -1,61 +1,59 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
-
+package org.hibernate.cache.internal;
 
 /**
- * Generates increasing identifiers (in a single VM only).
- * Not valid across multiple VMs. Identifiers are not necessarily
- * strictly increasing, but usually are.
+ * Generates increasing identifiers (in a single VM only). Not valid across multiple VMs.  Identifiers are not
+ * necessarily strictly increasing, but usually are.
  */
 public final class Timestamper {
 	private static short counter = 0;
 	private static long time;
 	private static final int BIN_DIGITS = 12;
 	public static final short ONE_MS = 1<<BIN_DIGITS;
 	
 	public static long next() {
 		synchronized(Timestamper.class) {
 			long newTime = System.currentTimeMillis() << BIN_DIGITS;
 			if (time<newTime) {
 				time = newTime;
 				counter = 0;
 			}
 			else if (counter < ONE_MS - 1 ) {
 				counter++;
 			}
 			
 			return time + counter;
 		}
 	}
 
-	private Timestamper() {}
+	private Timestamper() {
+	}
 }
 
 
 
 
 
 
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/BaseGeneralDataRegionAdapter.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/BaseGeneralDataRegionAdapter.java
similarity index 84%
rename from hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/BaseGeneralDataRegionAdapter.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/BaseGeneralDataRegionAdapter.java
index c843a81509..37a17fb75f 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/BaseGeneralDataRegionAdapter.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/BaseGeneralDataRegionAdapter.java
@@ -1,57 +1,57 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache.impl.bridge;
-import org.hibernate.cache.Cache;
-import org.hibernate.cache.CacheException;
-import org.hibernate.cache.GeneralDataRegion;
-import org.hibernate.cfg.Settings;
-
-/**
- * {@inheritDoc}
- *
- * @author Steve Ebersole
- */
-public abstract class BaseGeneralDataRegionAdapter extends BaseRegionAdapter implements GeneralDataRegion {
-
-	protected BaseGeneralDataRegionAdapter(Cache underlyingCache, Settings settings) {
-		super( underlyingCache, settings );
-	}
-
-	public Object get(Object key) throws CacheException {
-		return underlyingCache.get( key );
-	}
-
-	public void put(Object key, Object value) throws CacheException {
-		underlyingCache.put( key, value );
-	}
-
-	public void evict(Object key) throws CacheException {
-		underlyingCache.remove( key );
-	}
-
-	public void evictAll() throws CacheException {
-		underlyingCache.clear();
-	}
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.internal.bridge;
+
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.Cache;
+import org.hibernate.cache.spi.GeneralDataRegion;
+import org.hibernate.cfg.Settings;
+
+/**
+ * {@inheritDoc}
+ *
+ * @author Steve Ebersole
+ */
+public abstract class BaseGeneralDataRegionAdapter extends BaseRegionAdapter implements GeneralDataRegion {
+
+	protected BaseGeneralDataRegionAdapter(Cache underlyingCache, Settings settings) {
+		super( underlyingCache, settings );
+	}
+
+	public Object get(Object key) throws CacheException {
+		return underlyingCache.get( key );
+	}
+
+	public void put(Object key, Object value) throws CacheException {
+		underlyingCache.put( key, value );
+	}
+
+	public void evict(Object key) throws CacheException {
+		underlyingCache.remove( key );
+	}
+
+	public void evictAll() throws CacheException {
+		underlyingCache.clear();
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/BaseRegionAdapter.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/BaseRegionAdapter.java
similarity index 87%
rename from hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/BaseRegionAdapter.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/BaseRegionAdapter.java
index ac418984fd..36d5408666 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/BaseRegionAdapter.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/BaseRegionAdapter.java
@@ -1,86 +1,87 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache.impl.bridge;
-import java.util.Map;
-import org.hibernate.cache.Cache;
-import org.hibernate.cache.CacheException;
-import org.hibernate.cache.Region;
-import org.hibernate.cfg.Settings;
-
-/**
- * Basic adapter bridging between {@link Region} and {@link Cache}.
- *
- * @author Steve Ebersole
- */
-public abstract class BaseRegionAdapter implements Region {
-	protected final Cache underlyingCache;
-	protected final Settings settings;
-
-	protected BaseRegionAdapter(Cache underlyingCache, Settings settings) {
-		this.underlyingCache = underlyingCache;
-		this.settings = settings;
-	}
-
-	public String getName() {
-		return underlyingCache.getRegionName();
-	}
-
-	public void clear() throws CacheException {
-		underlyingCache.clear();
-	}
-
-	public void destroy() throws CacheException {
-		underlyingCache.destroy();
-	}
-
-	public boolean contains(Object key) {
-		// safer to utilize the toMap() as oposed to say get(key) != null
-		return underlyingCache.toMap().containsKey( key );
-	}
-
-	public long getSizeInMemory() {
-		return underlyingCache.getSizeInMemory();
-	}
-
-	public long getElementCountInMemory() {
-		return underlyingCache.getElementCountInMemory();
-	}
-
-	public long getElementCountOnDisk() {
-		return underlyingCache.getElementCountOnDisk();
-	}
-
-	public Map toMap() {
-		return underlyingCache.toMap();
-	}
-
-	public long nextTimestamp() {
-		return underlyingCache.nextTimestamp();
-	}
-
-	public int getTimeout() {
-		return underlyingCache.getTimeout();
-	}
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.internal.bridge;
+
+import java.util.Map;
+
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.Cache;
+import org.hibernate.cache.spi.Region;
+import org.hibernate.cfg.Settings;
+
+/**
+ * Basic adapter bridging between {@link Region} and {@link Cache}.
+ *
+ * @author Steve Ebersole
+ */
+public abstract class BaseRegionAdapter implements Region {
+	protected final Cache underlyingCache;
+	protected final Settings settings;
+
+	protected BaseRegionAdapter(Cache underlyingCache, Settings settings) {
+		this.underlyingCache = underlyingCache;
+		this.settings = settings;
+	}
+
+	public String getName() {
+		return underlyingCache.getRegionName();
+	}
+
+	public void clear() throws CacheException {
+		underlyingCache.clear();
+	}
+
+	public void destroy() throws CacheException {
+		underlyingCache.destroy();
+	}
+
+	public boolean contains(Object key) {
+		// safer to utilize the toMap() as oposed to say get(key) != null
+		return underlyingCache.toMap().containsKey( key );
+	}
+
+	public long getSizeInMemory() {
+		return underlyingCache.getSizeInMemory();
+	}
+
+	public long getElementCountInMemory() {
+		return underlyingCache.getElementCountInMemory();
+	}
+
+	public long getElementCountOnDisk() {
+		return underlyingCache.getElementCountOnDisk();
+	}
+
+	public Map toMap() {
+		return underlyingCache.toMap();
+	}
+
+	public long nextTimestamp() {
+		return underlyingCache.nextTimestamp();
+	}
+
+	public int getTimeout() {
+		return underlyingCache.getTimeout();
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/BaseTransactionalDataRegionAdapter.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/BaseTransactionalDataRegionAdapter.java
similarity index 77%
rename from hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/BaseTransactionalDataRegionAdapter.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/BaseTransactionalDataRegionAdapter.java
index d770130156..aedcd4f77a 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/BaseTransactionalDataRegionAdapter.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/BaseTransactionalDataRegionAdapter.java
@@ -1,54 +1,55 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache.impl.bridge;
-import org.hibernate.cache.Cache;
-import org.hibernate.cache.CacheDataDescription;
-import org.hibernate.cache.TransactionalDataRegion;
-import org.hibernate.cfg.Settings;
-
-/**
- * {@inheritDoc}
- *
- * @author Steve Ebersole
- */
-public abstract class BaseTransactionalDataRegionAdapter
-		extends BaseRegionAdapter
-		implements TransactionalDataRegion {
-
-	protected final CacheDataDescription metadata;
-
-	protected BaseTransactionalDataRegionAdapter(Cache underlyingCache, Settings settings, CacheDataDescription metadata) {
-		super( underlyingCache, settings );
-		this.metadata = metadata;
-	}
-
-	public boolean isTransactionAware() {
-		return underlyingCache instanceof org.hibernate.cache.TransactionAwareCache;
-	}
-
-	public CacheDataDescription getCacheDataDescription() {
-		return metadata;
-	}
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.internal.bridge;
+
+import org.hibernate.cache.spi.Cache;
+import org.hibernate.cache.spi.CacheDataDescription;
+import org.hibernate.cache.spi.TransactionAwareCache;
+import org.hibernate.cache.spi.TransactionalDataRegion;
+import org.hibernate.cfg.Settings;
+
+/**
+ * {@inheritDoc}
+ *
+ * @author Steve Ebersole
+ */
+public abstract class BaseTransactionalDataRegionAdapter
+		extends BaseRegionAdapter
+		implements TransactionalDataRegion {
+
+	protected final CacheDataDescription metadata;
+
+	protected BaseTransactionalDataRegionAdapter(Cache underlyingCache, Settings settings, CacheDataDescription metadata) {
+		super( underlyingCache, settings );
+		this.metadata = metadata;
+	}
+
+	public boolean isTransactionAware() {
+		return underlyingCache instanceof TransactionAwareCache;
+	}
+
+	public CacheDataDescription getCacheDataDescription() {
+		return metadata;
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/CollectionAccessStrategyAdapter.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/CollectionAccessStrategyAdapter.java
similarity index 87%
rename from hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/CollectionAccessStrategyAdapter.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/CollectionAccessStrategyAdapter.java
index c96bec9497..54907784c9 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/CollectionAccessStrategyAdapter.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/CollectionAccessStrategyAdapter.java
@@ -1,114 +1,114 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache.impl.bridge;
-import org.hibernate.cache.CacheConcurrencyStrategy;
-import org.hibernate.cache.CacheException;
-import org.hibernate.cache.CollectionRegion;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
-import org.hibernate.cache.access.SoftLock;
-import org.hibernate.cfg.Settings;
-
-/**
- * Adapter specifically bridging {@link CollectionRegionAccessStrategy} to {@link CacheConcurrencyStrategy}.
- *
- * @author Steve Ebersole
- */
-public class CollectionAccessStrategyAdapter implements CollectionRegionAccessStrategy {
-	private final CollectionRegion region;
-	private final CacheConcurrencyStrategy ccs;
-	private final Settings settings;
-
-	public CollectionAccessStrategyAdapter(CollectionRegion region, CacheConcurrencyStrategy ccs, Settings settings) {
-		this.region = region;
-		this.ccs = ccs;
-		this.settings = settings;
-	}
-
-	public CollectionRegion getRegion() {
-		return region;
-	}
-
-	public Object get(Object key, long txTimestamp) throws CacheException {
-		return ccs.get( key, txTimestamp );
-	}
-
-	public boolean putFromLoad(Object key, Object value, long txTimestamp, Object version) throws CacheException {
-		return putFromLoad( key, value, txTimestamp, version, settings.isMinimalPutsEnabled() );
-	}
-
-	public boolean putFromLoad(
-			Object key, 
-			Object value,
-			long txTimestamp,
-			Object version,
-			boolean minimalPutOverride) throws CacheException {
-		return ccs.put( key, value, txTimestamp, version, region.getCacheDataDescription().getVersionComparator(), minimalPutOverride );
-	}
-
-	public SoftLock lockItem(Object key, Object version) throws CacheException {
-		return ccs.lock( key, version );
-	}
-
-	public SoftLock lockRegion() throws CacheException {
-		// no-op; CCS did not have such a concept
-		return null;
-	}
-
-	public void unlockItem(Object key, SoftLock lock) throws CacheException {
-		ccs.release( key, lock );
-	}
-
-	public void unlockRegion(SoftLock lock) throws CacheException {
-		// again, CCS did not have such a concept; but a reasonable
-		// proximity is to clear the cache after transaction *as long as*
-		// the underlying cache is not JTA aware.
-		if ( !region.isTransactionAware() ) {
-			ccs.clear();
-		}
-	}
-
-	public void remove(Object key) throws CacheException {
-		ccs.evict( key );
-	}
-
-	public void removeAll() throws CacheException {
-		// again, CCS did not have such a concept; however a reasonable
-		// proximity is to clear the cache.  For non-transaction aware
-		// caches, we will also do a clear at the end of the transaction
-		ccs.clear();
-	}
-
-	public void evict(Object key) throws CacheException {
-		ccs.remove( key );
-	}
-
-	public void evictAll() throws CacheException {
-		ccs.clear();
-	}
-
-	public void destroy() {
-		ccs.destroy();
-	}
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.internal.bridge;
+
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.CacheConcurrencyStrategy;
+import org.hibernate.cache.spi.CollectionRegion;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
+import org.hibernate.cache.spi.access.SoftLock;
+import org.hibernate.cfg.Settings;
+
+/**
+ * Adapter specifically bridging {@link CollectionRegionAccessStrategy} to {@link CacheConcurrencyStrategy}.
+ *
+ * @author Steve Ebersole
+ */
+public class CollectionAccessStrategyAdapter implements CollectionRegionAccessStrategy {
+	private final CollectionRegion region;
+	private final CacheConcurrencyStrategy ccs;
+	private final Settings settings;
+
+	public CollectionAccessStrategyAdapter(CollectionRegion region, CacheConcurrencyStrategy ccs, Settings settings) {
+		this.region = region;
+		this.ccs = ccs;
+		this.settings = settings;
+	}
+
+	public CollectionRegion getRegion() {
+		return region;
+	}
+
+	public Object get(Object key, long txTimestamp) throws CacheException {
+		return ccs.get( key, txTimestamp );
+	}
+
+	public boolean putFromLoad(Object key, Object value, long txTimestamp, Object version) throws CacheException {
+		return putFromLoad( key, value, txTimestamp, version, settings.isMinimalPutsEnabled() );
+	}
+
+	public boolean putFromLoad(
+			Object key, 
+			Object value,
+			long txTimestamp,
+			Object version,
+			boolean minimalPutOverride) throws CacheException {
+		return ccs.put( key, value, txTimestamp, version, region.getCacheDataDescription().getVersionComparator(), minimalPutOverride );
+	}
+
+	public SoftLock lockItem(Object key, Object version) throws CacheException {
+		return ccs.lock( key, version );
+	}
+
+	public SoftLock lockRegion() throws CacheException {
+		// no-op; CCS did not have such a concept
+		return null;
+	}
+
+	public void unlockItem(Object key, SoftLock lock) throws CacheException {
+		ccs.release( key, lock );
+	}
+
+	public void unlockRegion(SoftLock lock) throws CacheException {
+		// again, CCS did not have such a concept; but a reasonable
+		// proximity is to clear the cache after transaction *as long as*
+		// the underlying cache is not JTA aware.
+		if ( !region.isTransactionAware() ) {
+			ccs.clear();
+		}
+	}
+
+	public void remove(Object key) throws CacheException {
+		ccs.evict( key );
+	}
+
+	public void removeAll() throws CacheException {
+		// again, CCS did not have such a concept; however a reasonable
+		// proximity is to clear the cache.  For non-transaction aware
+		// caches, we will also do a clear at the end of the transaction
+		ccs.clear();
+	}
+
+	public void evict(Object key) throws CacheException {
+		ccs.remove( key );
+	}
+
+	public void evictAll() throws CacheException {
+		ccs.clear();
+	}
+
+	public void destroy() {
+		ccs.destroy();
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/CollectionRegionAdapter.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/CollectionRegionAdapter.java
similarity index 78%
rename from hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/CollectionRegionAdapter.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/CollectionRegionAdapter.java
index 82a327d21c..af5ececce2 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/CollectionRegionAdapter.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/CollectionRegionAdapter.java
@@ -1,81 +1,81 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache.impl.bridge;
-import org.hibernate.internal.CoreMessageLogger;
-import org.hibernate.cache.Cache;
-import org.hibernate.cache.CacheConcurrencyStrategy;
-import org.hibernate.cache.CacheDataDescription;
-import org.hibernate.cache.CacheException;
-import org.hibernate.cache.CollectionRegion;
-import org.hibernate.cache.NonstrictReadWriteCache;
-import org.hibernate.cache.OptimisticCache;
-import org.hibernate.cache.ReadOnlyCache;
-import org.hibernate.cache.ReadWriteCache;
-import org.hibernate.cache.TransactionalCache;
-import org.hibernate.cache.access.AccessType;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
-import org.hibernate.cfg.Settings;
+package org.hibernate.cache.internal.bridge;
 
 import org.jboss.logging.Logger;
 
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.Cache;
+import org.hibernate.cache.spi.CacheConcurrencyStrategy;
+import org.hibernate.cache.spi.CacheDataDescription;
+import org.hibernate.cache.spi.CollectionRegion;
+import org.hibernate.cache.spi.NonstrictReadWriteCache;
+import org.hibernate.cache.spi.OptimisticCache;
+import org.hibernate.cache.spi.ReadOnlyCache;
+import org.hibernate.cache.spi.ReadWriteCache;
+import org.hibernate.cache.spi.TransactionalCache;
+import org.hibernate.cache.spi.access.AccessType;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
+import org.hibernate.cfg.Settings;
+import org.hibernate.internal.CoreMessageLogger;
+
 /**
  * Adapter specifically bridging {@link CollectionRegion} to {@link Cache}.
  *
  * @author Steve Ebersole
  */
 public class CollectionRegionAdapter extends BaseTransactionalDataRegionAdapter implements CollectionRegion {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        CollectionRegionAdapter.class.getName());
 
 	public CollectionRegionAdapter(Cache underlyingCache, Settings settings, CacheDataDescription metadata) {
 		super( underlyingCache, settings, metadata );
 		if ( underlyingCache instanceof OptimisticCache ) {
 			( ( OptimisticCache ) underlyingCache ).setSource( new OptimisticCacheSourceAdapter( metadata ) );
 		}
 	}
 
 	public CollectionRegionAccessStrategy buildAccessStrategy(AccessType accessType) throws CacheException {
 		CacheConcurrencyStrategy ccs;
 		if ( AccessType.READ_ONLY.equals( accessType ) ) {
             if (metadata.isMutable()) LOG.readOnlyCacheConfiguredForMutableCollection(getName());
 			ccs = new ReadOnlyCache();
 		}
 		else if ( AccessType.READ_WRITE.equals( accessType ) ) {
 			ccs = new ReadWriteCache();
 		}
 		else if ( AccessType.NONSTRICT_READ_WRITE.equals( accessType ) ) {
 			ccs = new NonstrictReadWriteCache();
 		}
 		else if ( AccessType.TRANSACTIONAL.equals( accessType ) ) {
 			ccs = new TransactionalCache();
 		}
 		else {
 			throw new IllegalArgumentException( "unrecognized access strategy type [" + accessType + "]" );
 		}
 		ccs.setCache( underlyingCache );
 		return new CollectionAccessStrategyAdapter( this, ccs, settings );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/EntityAccessStrategyAdapter.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/EntityAccessStrategyAdapter.java
similarity index 88%
rename from hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/EntityAccessStrategyAdapter.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/EntityAccessStrategyAdapter.java
index 8ec1a0570f..6ba18e29cc 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/EntityAccessStrategyAdapter.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/EntityAccessStrategyAdapter.java
@@ -1,132 +1,132 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache.impl.bridge;
-import org.hibernate.cache.CacheConcurrencyStrategy;
-import org.hibernate.cache.CacheException;
-import org.hibernate.cache.EntityRegion;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
-import org.hibernate.cache.access.SoftLock;
-import org.hibernate.cfg.Settings;
-
-/**
- * Adapter specifically bridging {@link EntityRegionAccessStrategy} to {@link CacheConcurrencyStrategy}.
- *
- * @author Steve Ebersole
- */
-public class EntityAccessStrategyAdapter implements EntityRegionAccessStrategy {
-	private final EntityRegion region;
-	private final CacheConcurrencyStrategy ccs;
-	private final Settings settings;
-
-	public EntityAccessStrategyAdapter(EntityRegion region, CacheConcurrencyStrategy ccs, Settings settings) {
-		this.region = region;
-		this.ccs = ccs;
-		this.settings = settings;
-	}
-
-	public EntityRegion getRegion() {
-		return region;
-	}
-
-	public Object get(Object key, long txTimestamp) throws CacheException {
-		return ccs.get( key, txTimestamp );
-	}
-
-	public boolean putFromLoad(Object key, Object value, long txTimestamp, Object version) throws CacheException {
-		return putFromLoad( key, value, txTimestamp, version, settings.isMinimalPutsEnabled() );
-	}
-
-	public boolean putFromLoad(
-			Object key,
-			Object value,
-			long txTimestamp,
-			Object version,
-			boolean minimalPutOverride) throws CacheException {
-		return ccs.put( key, value, txTimestamp, version, region.getCacheDataDescription().getVersionComparator(), minimalPutOverride );
-	}
-
-	public SoftLock lockItem(Object key, Object version) throws CacheException {
-		return ccs.lock( key, version );
-	}
-
-	public SoftLock lockRegion() throws CacheException {
-		// no-op; CCS did not have such a concept
-		return null;
-	}
-
-	public void unlockItem(Object key, SoftLock lock) throws CacheException {
-		ccs.release( key, lock );
-	}
-
-	public void unlockRegion(SoftLock lock) throws CacheException {
-		// again, CCS did not have such a concept; but a reasonable
-		// proximity is to clear the cache after transaction *as long as*
-		// the underlying cache is not JTA aware.
-		if ( !region.isTransactionAware() ) {
-			ccs.clear();
-		}
-	}
-
-	public boolean insert(Object key, Object value, Object version) throws CacheException {
-		return ccs.insert( key, value, version );
-	}
-
-	public boolean afterInsert(Object key, Object value, Object version) throws CacheException {
-		return ccs.afterInsert( key, value, version );
-	}
-
-	public boolean update(Object key, Object value, Object currentVersion, Object previousVersion)
-			throws CacheException {
-		return ccs.update( key, value, currentVersion, previousVersion );
-	}
-
-	public boolean afterUpdate(Object key, Object value, Object currentVersion, Object previousVersion, SoftLock lock)
-			throws CacheException {
-		return ccs.afterUpdate( key, value, currentVersion, lock );
-	}
-
-	public void remove(Object key) throws CacheException {
-		ccs.evict( key );
-	}
-
-	public void removeAll() throws CacheException {
-		// again, CCS did not have such a concept; however a reasonable
-		// proximity is to clear the cache.  For non-transaction aware
-		// caches, we will also do a clear at the end of the transaction
-		ccs.clear();
-	}
-
-	public void evict(Object key) throws CacheException {
-		ccs.remove( key );
-	}
-
-	public void evictAll() throws CacheException {
-		ccs.clear();
-	}
-
-	public void destroy() {
-		ccs.destroy();
-	}
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.internal.bridge;
+
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.CacheConcurrencyStrategy;
+import org.hibernate.cache.spi.EntityRegion;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.spi.access.SoftLock;
+import org.hibernate.cfg.Settings;
+
+/**
+ * Adapter specifically bridging {@link EntityRegionAccessStrategy} to {@link CacheConcurrencyStrategy}.
+ *
+ * @author Steve Ebersole
+ */
+public class EntityAccessStrategyAdapter implements EntityRegionAccessStrategy {
+	private final EntityRegion region;
+	private final CacheConcurrencyStrategy ccs;
+	private final Settings settings;
+
+	public EntityAccessStrategyAdapter(EntityRegion region, CacheConcurrencyStrategy ccs, Settings settings) {
+		this.region = region;
+		this.ccs = ccs;
+		this.settings = settings;
+	}
+
+	public EntityRegion getRegion() {
+		return region;
+	}
+
+	public Object get(Object key, long txTimestamp) throws CacheException {
+		return ccs.get( key, txTimestamp );
+	}
+
+	public boolean putFromLoad(Object key, Object value, long txTimestamp, Object version) throws CacheException {
+		return putFromLoad( key, value, txTimestamp, version, settings.isMinimalPutsEnabled() );
+	}
+
+	public boolean putFromLoad(
+			Object key,
+			Object value,
+			long txTimestamp,
+			Object version,
+			boolean minimalPutOverride) throws CacheException {
+		return ccs.put( key, value, txTimestamp, version, region.getCacheDataDescription().getVersionComparator(), minimalPutOverride );
+	}
+
+	public SoftLock lockItem(Object key, Object version) throws CacheException {
+		return ccs.lock( key, version );
+	}
+
+	public SoftLock lockRegion() throws CacheException {
+		// no-op; CCS did not have such a concept
+		return null;
+	}
+
+	public void unlockItem(Object key, SoftLock lock) throws CacheException {
+		ccs.release( key, lock );
+	}
+
+	public void unlockRegion(SoftLock lock) throws CacheException {
+		// again, CCS did not have such a concept; but a reasonable
+		// proximity is to clear the cache after transaction *as long as*
+		// the underlying cache is not JTA aware.
+		if ( !region.isTransactionAware() ) {
+			ccs.clear();
+		}
+	}
+
+	public boolean insert(Object key, Object value, Object version) throws CacheException {
+		return ccs.insert( key, value, version );
+	}
+
+	public boolean afterInsert(Object key, Object value, Object version) throws CacheException {
+		return ccs.afterInsert( key, value, version );
+	}
+
+	public boolean update(Object key, Object value, Object currentVersion, Object previousVersion)
+			throws CacheException {
+		return ccs.update( key, value, currentVersion, previousVersion );
+	}
+
+	public boolean afterUpdate(Object key, Object value, Object currentVersion, Object previousVersion, SoftLock lock)
+			throws CacheException {
+		return ccs.afterUpdate( key, value, currentVersion, lock );
+	}
+
+	public void remove(Object key) throws CacheException {
+		ccs.evict( key );
+	}
+
+	public void removeAll() throws CacheException {
+		// again, CCS did not have such a concept; however a reasonable
+		// proximity is to clear the cache.  For non-transaction aware
+		// caches, we will also do a clear at the end of the transaction
+		ccs.clear();
+	}
+
+	public void evict(Object key) throws CacheException {
+		ccs.remove( key );
+	}
+
+	public void evictAll() throws CacheException {
+		ccs.clear();
+	}
+
+	public void destroy() {
+		ccs.destroy();
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/EntityRegionAdapter.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/EntityRegionAdapter.java
similarity index 74%
rename from hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/EntityRegionAdapter.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/EntityRegionAdapter.java
index d43e9b02c4..c19ff829f0 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/EntityRegionAdapter.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/EntityRegionAdapter.java
@@ -1,80 +1,80 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache.impl.bridge;
-import org.hibernate.internal.CoreMessageLogger;
-import org.hibernate.cache.Cache;
-import org.hibernate.cache.CacheConcurrencyStrategy;
-import org.hibernate.cache.CacheDataDescription;
-import org.hibernate.cache.CacheException;
-import org.hibernate.cache.EntityRegion;
-import org.hibernate.cache.NonstrictReadWriteCache;
-import org.hibernate.cache.OptimisticCache;
-import org.hibernate.cache.ReadOnlyCache;
-import org.hibernate.cache.ReadWriteCache;
-import org.hibernate.cache.TransactionalCache;
-import org.hibernate.cache.access.AccessType;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
-import org.hibernate.cfg.Settings;
+package org.hibernate.cache.internal.bridge;
 
 import org.jboss.logging.Logger;
 
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.Cache;
+import org.hibernate.cache.spi.CacheConcurrencyStrategy;
+import org.hibernate.cache.spi.CacheDataDescription;
+import org.hibernate.cache.spi.EntityRegion;
+import org.hibernate.cache.spi.NonstrictReadWriteCache;
+import org.hibernate.cache.spi.OptimisticCache;
+import org.hibernate.cache.spi.ReadOnlyCache;
+import org.hibernate.cache.spi.ReadWriteCache;
+import org.hibernate.cache.spi.TransactionalCache;
+import org.hibernate.cache.spi.access.AccessType;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
+import org.hibernate.cfg.Settings;
+import org.hibernate.internal.CoreMessageLogger;
+
 /**
- * Adapter specifically bridging {@link EntityRegion} to {@link Cache}.
+ * Adapter specifically bridging {@link EntityRegion} to {@link org.hibernate.cache.spi.Cache}.
  *
  * @author Steve Ebersole
  */
 public class EntityRegionAdapter extends BaseTransactionalDataRegionAdapter implements EntityRegion {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, EntityRegionAdapter.class.getName());
 
 	public EntityRegionAdapter(Cache underlyingCache, Settings settings, CacheDataDescription metadata) {
 		super( underlyingCache, settings, metadata );
 		if ( underlyingCache instanceof OptimisticCache ) {
-			( ( OptimisticCache ) underlyingCache ).setSource( new OptimisticCacheSourceAdapter( metadata ) );
+			( (OptimisticCache) underlyingCache ).setSource( new OptimisticCacheSourceAdapter( metadata ) );
 		}
 	}
 
 	public EntityRegionAccessStrategy buildAccessStrategy(AccessType accessType) throws CacheException {
 		CacheConcurrencyStrategy ccs;
 		if ( AccessType.READ_ONLY.equals( accessType ) ) {
             if (metadata.isMutable()) LOG.readOnlyCacheConfiguredForMutableCollection(getName());
 			ccs = new ReadOnlyCache();
 		}
 		else if ( AccessType.READ_WRITE.equals( accessType ) ) {
 			ccs = new ReadWriteCache();
 		}
 		else if ( AccessType.NONSTRICT_READ_WRITE.equals( accessType ) ) {
 			ccs = new NonstrictReadWriteCache();
 		}
 		else if ( AccessType.TRANSACTIONAL.equals( accessType ) ) {
 			ccs = new TransactionalCache();
 		}
 		else {
 			throw new IllegalArgumentException( "unrecognized access strategy type [" + accessType + "]" );
 		}
 		ccs.setCache( underlyingCache );
 		return new EntityAccessStrategyAdapter( this, ccs, settings );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/OptimisticCacheSourceAdapter.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/OptimisticCacheSourceAdapter.java
similarity index 81%
rename from hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/OptimisticCacheSourceAdapter.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/OptimisticCacheSourceAdapter.java
index 6c02477ce4..2fe6592e21 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/OptimisticCacheSourceAdapter.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/OptimisticCacheSourceAdapter.java
@@ -1,49 +1,50 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache.impl.bridge;
-import java.util.Comparator;
-import org.hibernate.cache.CacheDataDescription;
-import org.hibernate.cache.OptimisticCacheSource;
-
-/**
- * {@inheritDoc}
-*
-* @author Steve Ebersole
-*/
-public class OptimisticCacheSourceAdapter implements OptimisticCacheSource {
-	private final CacheDataDescription dataDescription;
-
-	public OptimisticCacheSourceAdapter(CacheDataDescription dataDescription) {
-		this.dataDescription = dataDescription;
-	}
-
-	public boolean isVersioned() {
-		return dataDescription.isVersioned();
-	}
-
-	public Comparator getVersionComparator() {
-		return dataDescription.getVersionComparator();
-	}
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.internal.bridge;
+
+import java.util.Comparator;
+
+import org.hibernate.cache.spi.CacheDataDescription;
+import org.hibernate.cache.spi.OptimisticCacheSource;
+
+/**
+ * {@inheritDoc}
+*
+* @author Steve Ebersole
+*/
+public class OptimisticCacheSourceAdapter implements OptimisticCacheSource {
+	private final CacheDataDescription dataDescription;
+
+	public OptimisticCacheSourceAdapter(CacheDataDescription dataDescription) {
+		this.dataDescription = dataDescription;
+	}
+
+	public boolean isVersioned() {
+		return dataDescription.isVersioned();
+	}
+
+	public Comparator getVersionComparator() {
+		return dataDescription.getVersionComparator();
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/QueryResultsRegionAdapter.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/QueryResultsRegionAdapter.java
similarity index 76%
rename from hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/QueryResultsRegionAdapter.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/QueryResultsRegionAdapter.java
index d3ac00ebe7..16bf631dee 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/QueryResultsRegionAdapter.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/QueryResultsRegionAdapter.java
@@ -1,39 +1,39 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache.impl.bridge;
-import org.hibernate.cache.Cache;
-import org.hibernate.cache.QueryResultsRegion;
-import org.hibernate.cfg.Settings;
-
-/**
- * Adapter specifically briding {@link QueryResultsRegion} to {@link Cache}.
-*
-* @author Steve Ebersole
- */
-public class QueryResultsRegionAdapter extends BaseGeneralDataRegionAdapter implements QueryResultsRegion {
-	protected QueryResultsRegionAdapter(Cache underlyingCache, Settings settings) {
-		super( underlyingCache, settings );
-	}
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.internal.bridge;
+
+import org.hibernate.cache.spi.Cache;
+import org.hibernate.cache.spi.QueryResultsRegion;
+import org.hibernate.cfg.Settings;
+
+/**
+ * Adapter specifically briding {@link org.hibernate.cache.spi.QueryResultsRegion} to {@link Cache}.
+*
+* @author Steve Ebersole
+ */
+public class QueryResultsRegionAdapter extends BaseGeneralDataRegionAdapter implements QueryResultsRegion {
+	protected QueryResultsRegionAdapter(Cache underlyingCache, Settings settings) {
+		super( underlyingCache, settings );
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/RegionFactoryCacheProviderBridge.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/RegionFactoryCacheProviderBridge.java
similarity index 89%
rename from hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/RegionFactoryCacheProviderBridge.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/RegionFactoryCacheProviderBridge.java
index 2ac014dd2b..47f756678e 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/RegionFactoryCacheProviderBridge.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/RegionFactoryCacheProviderBridge.java
@@ -1,124 +1,125 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.cache.impl.bridge;
+package org.hibernate.cache.internal.bridge;
 
 import java.util.Properties;
 
-import org.hibernate.internal.CoreMessageLogger;
-import org.hibernate.cache.CacheDataDescription;
+import org.jboss.logging.Logger;
+
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.CacheProvider;
-import org.hibernate.cache.CollectionRegion;
-import org.hibernate.cache.EntityRegion;
-import org.hibernate.cache.NoCacheProvider;
-import org.hibernate.cache.QueryResultsRegion;
-import org.hibernate.cache.RegionFactory;
-import org.hibernate.cache.TimestampsRegion;
-import org.hibernate.cache.access.AccessType;
+import org.hibernate.cache.internal.NoCacheProvider;
+import org.hibernate.cache.spi.CacheDataDescription;
+import org.hibernate.cache.spi.CacheProvider;
+import org.hibernate.cache.spi.CollectionRegion;
+import org.hibernate.cache.spi.EntityRegion;
+import org.hibernate.cache.spi.QueryResultsRegion;
+import org.hibernate.cache.spi.RegionFactory;
+import org.hibernate.cache.spi.TimestampsRegion;
+import org.hibernate.cache.spi.access.AccessType;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Settings;
+import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
-import org.jboss.logging.Logger;
 
 /**
  * Acts as a bridge between the {@link RegionFactory} contract and the older
  * {@link CacheProvider} contract.
  *
  * @author Steve Ebersole
  */
 public class RegionFactoryCacheProviderBridge implements RegionFactory {
 	public static final String DEF_PROVIDER = NoCacheProvider.class.getName();
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        RegionFactoryCacheProviderBridge.class.getName());
 
 	private CacheProvider cacheProvider;
 	private Settings settings;
 
 	public RegionFactoryCacheProviderBridge(Properties properties) {
 		String providerClassName = ConfigurationHelper.getString( Environment.CACHE_PROVIDER, properties, DEF_PROVIDER );
         LOG.cacheProvider(providerClassName);
 		try {
 			cacheProvider = ( CacheProvider ) ReflectHelper.classForName( providerClassName ).newInstance();
 		}
 		catch ( Exception cnfe ) {
 			throw new CacheException( "could not instantiate CacheProvider [" + providerClassName + "]", cnfe );
 		}
 	}
 
 	public void start(Settings settings, Properties properties) throws CacheException {
 		this.settings = settings;
 		cacheProvider.start( properties );
 	}
 
 	public void stop() {
 		cacheProvider.stop();
 		cacheProvider = null;
 	}
 
 	public boolean isMinimalPutsEnabledByDefault() {
 		return cacheProvider.isMinimalPutsEnabledByDefault();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public AccessType getDefaultAccessType() {
 		// we really have no idea
 		return null;
 	}
 
 	public long nextTimestamp() {
 		return cacheProvider.nextTimestamp();
 	}
 
 	public CacheProvider getCacheProvider() {
 		return cacheProvider;
 	}
 
 	public EntityRegion buildEntityRegion(
 			String regionName,
 			Properties properties,
 			CacheDataDescription metadata) throws CacheException {
 		return new EntityRegionAdapter( cacheProvider.buildCache( regionName, properties ), settings, metadata );
 	}
 
 	public CollectionRegion buildCollectionRegion(
 			String regionName,
 			Properties properties,
 			CacheDataDescription metadata) throws CacheException {
 		return new CollectionRegionAdapter( cacheProvider.buildCache( regionName, properties ), settings, metadata );
 	}
 
 	public QueryResultsRegion buildQueryResultsRegion(String regionName, Properties properties) throws CacheException {
 		return new QueryResultsRegionAdapter( cacheProvider.buildCache( regionName, properties ), settings );
 	}
 
 	public TimestampsRegion buildTimestampsRegion(String regionName, Properties properties) throws CacheException {
 		return new TimestampsRegionAdapter( cacheProvider.buildCache( regionName, properties ), settings );
 	}
 
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/TimestampsRegionAdapter.java b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/TimestampsRegionAdapter.java
similarity index 76%
rename from hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/TimestampsRegionAdapter.java
rename to hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/TimestampsRegionAdapter.java
index 9a7d949ddb..1f05acf9ce 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/impl/bridge/TimestampsRegionAdapter.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/internal/bridge/TimestampsRegionAdapter.java
@@ -1,39 +1,39 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache.impl.bridge;
-import org.hibernate.cache.Cache;
-import org.hibernate.cache.TimestampsRegion;
-import org.hibernate.cfg.Settings;
-
-/**
- * Adapter specifically briding {@link TimestampsRegion} to {@link Cache}.
-*
-* @author Steve Ebersole
- */
-public class TimestampsRegionAdapter extends BaseGeneralDataRegionAdapter implements TimestampsRegion {
-	protected TimestampsRegionAdapter(Cache underlyingCache, Settings settings) {
-		super( underlyingCache, settings );
-	}
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.internal.bridge;
+
+import org.hibernate.cache.spi.Cache;
+import org.hibernate.cache.spi.TimestampsRegion;
+import org.hibernate.cfg.Settings;
+
+/**
+ * Adapter specifically bridging {@link TimestampsRegion} to {@link org.hibernate.cache.spi.Cache}.
+*
+* @author Steve Ebersole
+ */
+public class TimestampsRegionAdapter extends BaseGeneralDataRegionAdapter implements TimestampsRegion {
+	protected TimestampsRegionAdapter(Cache underlyingCache, Settings settings) {
+		super( underlyingCache, settings );
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/package.html b/hibernate-core/src/main/java/org/hibernate/cache/package.html
index 5cf1b052b2..d486044d52 100755
--- a/hibernate-core/src/main/java/org/hibernate/cache/package.html
+++ b/hibernate-core/src/main/java/org/hibernate/cache/package.html
@@ -1,61 +1,62 @@
 <!--
   ~ Hibernate, Relational Persistence for Idiomatic Java
   ~
   ~ Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
   ~ indicated by the @author tags or express copyright attribution
   ~ statements applied by the authors.  All third-party contributions are
   ~ distributed under license by Red Hat Middleware LLC.
   ~
   ~ This copyrighted material is made available to anyone wishing to use, modify,
   ~ copy, or redistribute it subject to the terms and conditions of the GNU
   ~ Lesser General Public License, as published by the Free Software Foundation.
   ~
   ~ This program is distributed in the hope that it will be useful,
   ~ but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
   ~ or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
   ~ for more details.
   ~
   ~ You should have received a copy of the GNU Lesser General Public License
   ~ along with this distribution; if not, write to:
   ~ Free Software Foundation, Inc.
   ~ 51 Franklin Street, Fifth Floor
   ~ Boston, MA  02110-1301  USA
   ~
   -->
 
 <html>
     <head>
     </head>
 
     <body>
         <p>
-            This package defines APIs/SPIs and implementations for the Hibernate second-level cache.
+            This package defines Hibernate second level cache service.  {@link org.hibernate.cache.spi} defines the
+            SPI used to integrate with Hibernate internals.
         </p>
         <p>
             The legacy (and now deprecated) approach to caching is defined by the {@link org.hibernate.cache.CacheProvider} and
             {@link org.hibernate.cache.Cache} interfaces as well as the {@link org.hibernate.cache.CacheConcurrencyStrategy}
             interface along with the various implementations of all these interfaces.  In that scheme, a
             {@link org.hibernate.cache.CacheProvider} defined how to configure and perform lifecycle operations
             in regards to a particular underlying caching library; it also defined how to build {@link org.hibernate.cache.Cache}
             instances which in turn defined how to access the "regions" of the underlying cache instance.
             For entity and collection data cache regions, {@link org.hibernate.cache.CacheConcurrencyStrategy} wrapped
             access to those cache regions to apply transactional/concurrent access semantics.
         </p>
         <p>
             The improved approach is based on {@link org.hibernate.cache.RegionFactory}, the various
             {@link org.hibernate.cache.Region} specializations and the two access strategies contracts
             ({@link org.hibernate.cache.access.EntityRegionAccessStrategy} and
             {@link org.hibernate.cache.access.CollectionRegionAccessStrategy}).  The general approach here is that
             {@link org.hibernate.cache.RegionFactory} defined how to configure and perform lifecycle operations
             in regards to a particular underlying caching library (<b>or libraries</b>).
             {@link org.hibernate.cache.RegionFactory} also defines how to build specialized
             {@link org.hibernate.cache.Region} instances based on the type of data we will be storing in that given
             region.  The fact that {@link org.hibernate.cache.RegionFactory} is asked to build <b>specialized</b>
             regions (as opposed to just general access) is the first <i>improvement</i> over the legacy scheme.  The
             second <i>improvement</i> is the fact that the regions (well the ones like entity and collection regions
             that are responsible for storing {@link org.hibernate.cache.TransactionalDataRegion transactional} data) are
             asked to build their own access strategies (see {@link org.hibernate.cache.EntityRegion#buildAccessStrategy}
             and {@link org.hibernate.cache.CollectionRegion#buildAccessStrategy}).
         </p>
     </body>
 </html>
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/AbstractJndiBoundCacheProvider.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/AbstractJndiBoundCacheProvider.java
similarity index 94%
rename from hibernate-core/src/main/java/org/hibernate/cache/AbstractJndiBoundCacheProvider.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/AbstractJndiBoundCacheProvider.java
index 6dacd4b163..a063366074 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/AbstractJndiBoundCacheProvider.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/AbstractJndiBoundCacheProvider.java
@@ -1,111 +1,111 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.spi;
 
 import java.util.Properties;
 import javax.naming.Context;
 import javax.naming.InitialContext;
 import javax.naming.NamingException;
 
+import org.hibernate.cache.CacheException;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.cfg.Environment;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.jndi.JndiHelper;
 
 import org.jboss.logging.Logger;
 
 /**
  * Support for CacheProvider implementations which are backed by caches bound
  * into JNDI namespace.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractJndiBoundCacheProvider implements CacheProvider {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractJndiBoundCacheProvider.class.getName());
 
 	private Object cache;
 
 	protected void prepare(Properties properties) {
 		// Do nothing; subclasses may override.
 	}
 
 	protected void release() {
 		// Do nothing; subclasses may override.
 	}
 
 	/**
 	 * Callback to perform any necessary initialization of the underlying cache implementation during SessionFactory
 	 * construction.
 	 *
 	 * @param properties current configuration settings.
 	 */
 	public final void start(Properties properties) throws CacheException {
 		String jndiNamespace = properties.getProperty( Environment.CACHE_NAMESPACE );
 		if ( StringHelper.isEmpty( jndiNamespace ) ) {
 			throw new CacheException( "No JNDI namespace specified for cache" );
 		}
 		cache = locateCache( jndiNamespace, JndiHelper.extractJndiProperties( properties ) );
 		prepare( properties );
 	}
 
 	/**
 	 * Callback to perform any necessary cleanup of the underlying cache
 	 * implementation during SessionFactory.close().
 	 */
 	public final void stop() {
 		release();
 		cache = null;
 	}
 
 	private Object locateCache(String jndiNamespace, Properties jndiProperties) {
 
 		Context ctx = null;
 		try {
 			ctx = new InitialContext( jndiProperties );
 			return ctx.lookup( jndiNamespace );
 		}
 		catch (NamingException ne) {
 			String msg = "Unable to retreive Cache from JNDI [" + jndiNamespace + "]";
             LOG.unableToRetrieveCache(jndiNamespace, ne.getMessage());
 			throw new CacheException( msg );
 		}
 		finally {
 			if ( ctx != null ) {
 				try {
 					ctx.close();
 				}
 				catch( NamingException ne ) {
                     LOG.unableToReleaseContext(ne.getMessage());
 				}
 			}
 		}
 	}
 
 	public Object getCache() {
 		return cache;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/Cache.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/Cache.java
similarity index 93%
rename from hibernate-core/src/main/java/org/hibernate/cache/Cache.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/Cache.java
index 54fcb4ef71..e591a50072 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/Cache.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/Cache.java
@@ -1,130 +1,132 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.spi;
+
 import java.util.Map;
 
+import org.hibernate.cache.CacheException;
+
 /**
  * Implementors define a caching algorithm. All implementors
  * <b>must</b> be threadsafe.
  *
  * @deprecated As of 3.3; see <a href="package.html"/> for details.
  */
 public interface Cache {
 	/**
 	 * Get an item from the cache
 	 * @param key
 	 * @return the cached object or <tt>null</tt>
-	 * @throws CacheException
+	 * @throws org.hibernate.cache.CacheException
 	 */
 	public Object read(Object key) throws CacheException;
 	/**
 	 * Get an item from the cache, nontransactionally
 	 * @param key
 	 * @return the cached object or <tt>null</tt>
 	 * @throws CacheException
 	 */
 	public Object get(Object key) throws CacheException;
 	/**
 	 * Add an item to the cache, nontransactionally, with
 	 * failfast semantics
 	 * @param key
 	 * @param value
 	 * @throws CacheException
 	 */
 	public void put(Object key, Object value) throws CacheException;
 	/**
 	 * Add an item to the cache
 	 * @param key
 	 * @param value
 	 * @throws CacheException
 	 */
 	public void update(Object key, Object value) throws CacheException;
 	/**
 	 * Remove an item from the cache
 	 */
 	public void remove(Object key) throws CacheException;
 	/**
 	 * Clear the cache
 	 */
 	public void clear() throws CacheException;
 	/**
 	 * Clean up
 	 */
 	public void destroy() throws CacheException;
 	/**
 	 * If this is a clustered cache, lock the item
 	 */
 	public void lock(Object key) throws CacheException;
 	/**
 	 * If this is a clustered cache, unlock the item
 	 */
 	public void unlock(Object key) throws CacheException;
 	/**
 	 * Generate a timestamp
 	 */
 	public long nextTimestamp();
 	/**
 	 * Get a reasonable "lock timeout"
 	 */
 	public int getTimeout();
 	
 	/**
 	 * Get the name of the cache region
 	 */
 	public String getRegionName();
 
 	/**
 	 * The number of bytes is this cache region currently consuming in memory.
 	 *
 	 * @return The number of bytes consumed by this region; -1 if unknown or
 	 * unsupported.
 	 */
 	public long getSizeInMemory();
 
 	/**
 	 * The count of entries currently contained in the regions in-memory store.
 	 *
 	 * @return The count of entries in memory; -1 if unknown or unsupported.
 	 */
 	public long getElementCountInMemory();
 
 	/**
 	 * The count of entries currently contained in the regions disk store.
 	 *
 	 * @return The count of entries on disk; -1 if unknown or unsupported.
 	 */
 	public long getElementCountOnDisk();
 	
 	/**
 	 * optional operation
 	 */
 	public Map toMap();
 }
 
 
 
 
 
 
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/CacheConcurrencyStrategy.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/CacheConcurrencyStrategy.java
similarity index 95%
rename from hibernate-core/src/main/java/org/hibernate/cache/CacheConcurrencyStrategy.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/CacheConcurrencyStrategy.java
index eab56424fe..ff593635fb 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/CacheConcurrencyStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/CacheConcurrencyStrategy.java
@@ -1,195 +1,197 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.spi;
+
 import java.util.Comparator;
-import org.hibernate.cache.access.SoftLock;
+
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.access.SoftLock;
 
 /**
  * Implementors manage transactional access to cached data. Transactions
  * pass in a timestamp indicating transaction start time. Two different
  * implementation patterns are provided for.<ul>
  * <li>A transaction-aware cache implementation might be wrapped by a
  * "synchronous" concurrency strategy, where updates to the cache are written
  * to the cache inside the transaction.</li>
  * <li>A non transaction-aware cache would be wrapped by an "asynchronous"
  * concurrency strategy, where items are merely "soft locked" during the 
  * transaction and then updated during the "after transaction completion"
  * phase; the soft lock is not an actual lock on the database row -
  * only upon the cached representation of the item.</li>
  * </ul>
  * <p/>
  * In terms of entity caches, the expected call sequences are: <ul>
  * <li><b>DELETES</b> : {@link #lock} -> {@link #evict} -> {@link #release}</li>
  * <li><b>UPDATES</b> : {@link #lock} -> {@link #update} -> {@link #afterUpdate}</li>
  * <li><b>INSERTS</b> : {@link #insert} -> {@link #afterInsert}</li>
  * </ul>
  * <p/>
  * In terms of collection caches, all modification actions actually just
  * invalidate the entry(s).  The call sequence here is:
  * {@link #lock} -> {@link #evict} -> {@link #release}
  * <p/>
  * Note that, for an asynchronous cache, cache invalidation must be a two 
  * step process (lock->release, or lock-afterUpdate), since this is the only 
  * way to guarantee consistency with the database for a nontransactional cache
  * implementation. For a synchronous cache, cache invalidation is a single 
  * step process (evict, or update). Hence, this interface defines a three
  * step process, to cater for both models.
  * <p/>
  * Note that query result caching does not go through a concurrency strategy; they
  * are managed directly against the underlying {@link Cache cache regions}.
  *
  * @deprecated As of 3.3; see <a href="package.html"/> for details.
  */
 public interface CacheConcurrencyStrategy {
 
 	/**
 	 * Attempt to retrieve an object from the cache. Mainly used in attempting
 	 * to resolve entities/collections from the second level cache.
 	 *
 	 * @param key
 	 * @param txTimestamp a timestamp prior to the transaction start time
 	 * @return the cached object or <tt>null</tt>
-	 * @throws CacheException
+	 * @throws org.hibernate.cache.CacheException
 	 */
 	public Object get(Object key, long txTimestamp) throws CacheException;
 
 	/**
 	 * Attempt to cache an object, after loading from the database.
 	 *
 	 * @param key
 	 * @param value
 	 * @param txTimestamp a timestamp prior to the transaction start time
 	 * @param version the item version number
 	 * @param versionComparator a comparator used to compare version numbers
 	 * @param minimalPut indicates that the cache should avoid a put is the item is already cached
 	 * @return <tt>true</tt> if the object was successfully cached
 	 * @throws CacheException
 	 */
 	public boolean put(
 			Object key, 
 			Object value, 
 			long txTimestamp, 
 			Object version, 
 			Comparator versionComparator,
 			boolean minimalPut) 
 	throws CacheException;
 
 	/**
 	 * We are going to attempt to update/delete the keyed object. This
 	 * method is used by "asynchronous" concurrency strategies.
 	 * <p/>
 	 * The returned object must be passed back to release(), to release the
 	 * lock. Concurrency strategies which do not support client-visible
 	 * locks may silently return null.
 	 * 
 	 * @param key
 	 * @param version 
 	 * @throws CacheException
 	 */
 	public SoftLock lock(Object key, Object version) throws CacheException;
 
 	/**
 	 * Called after an item has become stale (before the transaction completes).
 	 * This method is used by "synchronous" concurrency strategies.
 	 */
 	public void evict(Object key) throws CacheException;
 
 	/**
 	 * Called after an item has been updated (before the transaction completes),
 	 * instead of calling evict().
 	 * This method is used by "synchronous" concurrency strategies.
 	 */
 	public boolean update(Object key, Object value, Object currentVersion, Object previousVersion) throws CacheException;
 
 	/**
 	 * Called after an item has been inserted (before the transaction completes),
 	 * instead of calling evict().
 	 * This method is used by "synchronous" concurrency strategies.
 	 */
 	public boolean insert(Object key, Object value, Object currentVersion) throws CacheException;
 	
 	
 	/**
 	 * Called when we have finished the attempted update/delete (which may or 
 	 * may not have been successful), after transaction completion.
 	 * This method is used by "asynchronous" concurrency strategies.
 	 * @param key
 	 * @throws CacheException
 	 */
 	public void release(Object key, SoftLock lock) throws CacheException;
 	/**
 	 * Called after an item has been updated (after the transaction completes),
 	 * instead of calling release().
 	 * This method is used by "asynchronous" concurrency strategies.
 	 */
 	public boolean afterUpdate(Object key, Object value, Object version, SoftLock lock)
 	throws CacheException;
 	/**
 	 * Called after an item has been inserted (after the transaction completes),
 	 * instead of calling release().
 	 * This method is used by "asynchronous" concurrency strategies.
 	 */
 	public boolean afterInsert(Object key, Object value, Object version) 
 	throws CacheException;
 	
 	
 	/**
 	 * Evict an item from the cache immediately (without regard for transaction
 	 * isolation).
 	 * @param key
 	 * @throws CacheException
 	 */
 	public void remove(Object key) throws CacheException;
 	/**
 	 * Evict all items from the cache immediately.
 	 * @throws CacheException
 	 */
 	public void clear() throws CacheException;
 	/**
 	 * Clean up all resources.
 	 */
 	public void destroy();
 	/**
 	 * Set the underlying cache implementation.
 	 * @param cache
 	 */
 	public void setCache(Cache cache);
 		
 	/**
 	 * Get the cache region name
 	 */
 	public String getRegionName();
 	
 	/**
 	 * Get the wrapped cache implementation
 	 */
 	public Cache getCache();
 }
 
 
 
 
 
 
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/CacheDataDescription.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/CacheDataDescription.java
similarity index 88%
rename from hibernate-core/src/main/java/org/hibernate/cache/CacheDataDescription.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/CacheDataDescription.java
index 097e2c6449..64daa6f07d 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/CacheDataDescription.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/CacheDataDescription.java
@@ -1,58 +1,58 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache;
-import java.util.Comparator;
-
-/**
- * Describes attributes regarding the type of data to be cached.
- *
- * @author Steve Ebersole
- */
-public interface CacheDataDescription {
-	/**
-	 * Is the data marked as being mutable?
-	 *
-	 * @return True if the data is mutable; false otherwise.
-	 */
-	public boolean isMutable();
-
-	/**
-	 * Is the data to be cached considered versioned?
-	 * <p/>
-	 * If true, it is illegal for {@link #getVersionComparator} to return
-	 * null.
-	 *
-	 * @return True if the data is versioned; false otherwise.
-	 */
-	public boolean isVersioned();
-
-	/**
-	 * Get the comparator used to compare two different version values.
-	 * <p/>
-	 * May return null <b>if</b> {@link #isVersioned()} returns false.
-	 * @return
-	 */
-	public Comparator getVersionComparator();
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.spi;
+
+import java.util.Comparator;
+
+/**
+ * Describes attributes regarding the type of data to be cached.
+ *
+ * @author Steve Ebersole
+ */
+public interface CacheDataDescription {
+	/**
+	 * Is the data marked as being mutable?
+	 *
+	 * @return True if the data is mutable; false otherwise.
+	 */
+	public boolean isMutable();
+
+	/**
+	 * Is the data to be cached considered versioned?
+	 * <p/>
+	 * If true, it is illegal for {@link #getVersionComparator} to return
+	 * null.
+	 *
+	 * @return True if the data is versioned; false otherwise.
+	 */
+	public boolean isVersioned();
+
+	/**
+	 * Get the comparator used to compare two different version values.
+	 * <p/>
+	 * May return null <b>if</b> {@link #isVersioned()} returns false.
+	 * @return
+	 */
+	public Comparator getVersionComparator();
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/CacheKey.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/CacheKey.java
similarity index 99%
rename from hibernate-core/src/main/java/org/hibernate/cache/CacheKey.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/CacheKey.java
index cc011d88e8..c7d4b09715 100755
--- a/hibernate-core/src/main/java/org/hibernate/cache/CacheKey.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/CacheKey.java
@@ -1,105 +1,105 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.cache;
+package org.hibernate.cache.spi;
 
 import java.io.Serializable;
 
 import org.hibernate.EntityMode;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.internal.util.compare.EqualsHelper;
 import org.hibernate.type.Type;
 
 /**
  * Allows multiple entity classes / collection roles to be
  * stored in the same cache region. Also allows for composite
  * keys which do not properly implement equals()/hashCode().
  *
  * @author Gavin King
  */
 public class CacheKey implements Serializable {
 	private final Serializable key;
 	private final Type type;
 	private final String entityOrRoleName;
 	private final EntityMode entityMode;
 	private final String tenantId;
 	private final int hashCode;
 
 	/**
 	 * Construct a new key for a collection or entity instance.
 	 * Note that an entity name should always be the root entity
 	 * name, not a subclass entity name.
 	 *
 	 * @param id The identifier associated with the cached data
 	 * @param type The Hibernate type mapping
 	 * @param entityOrRoleName The entity or collection-role name.
 	 * @param entityMode The entity mode of the originating session
 	 * @param tenantId The tenant identifier associated this data.
 	 * @param factory The session factory for which we are caching
 	 */
 	public CacheKey(
 			final Serializable id,
 			final Type type,
 			final String entityOrRoleName,
 			final EntityMode entityMode,
 			final String tenantId,
 			final SessionFactoryImplementor factory) {
 		this.key = id;
 		this.type = type;
 		this.entityOrRoleName = entityOrRoleName;
 		this.entityMode = entityMode;
 		this.tenantId = tenantId;
 		this.hashCode = type.getHashCode( key, entityMode, factory );
 	}
 
 	@Override
 	public String toString() {
 		// Mainly for OSCache
 		return entityOrRoleName + '#' + key.toString();//"CacheKey#" + type.toString(key, sf);
 	}
 
 	@Override
 	public boolean equals(Object other) {
 		if ( !(other instanceof CacheKey) ) {
 			return false;
 		}
 		CacheKey that = (CacheKey) other;
 		return entityOrRoleName.equals( that.entityOrRoleName ) &&
 				type.isEqual( key, that.key, entityMode ) &&
 				EqualsHelper.equals( tenantId, that.tenantId );
 	}
 
 	@Override
 	public int hashCode() {
 		return hashCode;
 	}
 
 	public Serializable getKey() {
 		return key;
 	}
 
 	public String getEntityOrRoleName() {
 		return entityOrRoleName;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/CacheProvider.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/CacheProvider.java
similarity index 88%
rename from hibernate-core/src/main/java/org/hibernate/cache/CacheProvider.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/CacheProvider.java
index 6f93922c82..2e28daf04f 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/CacheProvider.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/CacheProvider.java
@@ -1,66 +1,68 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.spi;
+
 import java.util.Properties;
 
+import org.hibernate.cache.CacheException;
+
 /**
  * Support for pluggable caches.
  *
  * @author Gavin King
  * @deprecated As of 3.3; see <a href="package.html"/> for details.
  */
 public interface CacheProvider {
 
 	/**
 	 * Configure the cache
 	 *
 	 * @param regionName the name of the cache region
 	 * @param properties configuration settings
-	 * @throws CacheException
+	 * @throws org.hibernate.cache.CacheException
 	 */
 	public Cache buildCache(String regionName, Properties properties) throws CacheException;
 
 	/**
 	 * Generate a timestamp
 	 */
 	public long nextTimestamp();
 
 	/**
 	 * Callback to perform any necessary initialization of the underlying cache implementation
 	 * during SessionFactory construction.
 	 *
 	 * @param properties current configuration settings.
 	 */
 	public void start(Properties properties) throws CacheException;
 
 	/**
 	 * Callback to perform any necessary cleanup of the underlying cache implementation
 	 * during SessionFactory.close().
 	 */
 	public void stop();
 	
 	public boolean isMinimalPutsEnabledByDefault();
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/CollectionRegion.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/CollectionRegion.java
similarity index 81%
rename from hibernate-core/src/main/java/org/hibernate/cache/CollectionRegion.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/CollectionRegion.java
index 21a612e0c8..5b3fac4579 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/CollectionRegion.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/CollectionRegion.java
@@ -1,51 +1,52 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache;
-import org.hibernate.cache.access.AccessType;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
-
-/**
- * Defines the contract for a cache region which will specifically be used to
- * store collection data.
- * <p/>
- * Impl note: Hibernate always deals with changes to collections which
- * (potentially) has its data in the L2 cache by removing that collection
- * data; in other words it never tries to update the cached state, thereby
- * allowing it to avoid a bunch of concurrency problems.
- *
- * @author Steve Ebersole
- */
-public interface CollectionRegion extends TransactionalDataRegion {
-
-	/**
-	 * Build an access strategy for the requested access type.
-	 *
-	 * @param accessType The type of access strategy to build; never null.
-	 * @return The appropriate strategy contract for accessing this region
-	 * for the requested type of access.
-	 * @throws CacheException Usually indicates mis-configuration.
-	 */
-	public CollectionRegionAccessStrategy buildAccessStrategy(AccessType accessType) throws CacheException;
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.spi;
+
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.access.AccessType;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
+
+/**
+ * Defines the contract for a cache region which will specifically be used to
+ * store collection data.
+ * <p/>
+ * Impl note: Hibernate always deals with changes to collections which
+ * (potentially) has its data in the L2 cache by removing that collection
+ * data; in other words it never tries to update the cached state, thereby
+ * allowing it to avoid a bunch of concurrency problems.
+ *
+ * @author Steve Ebersole
+ */
+public interface CollectionRegion extends TransactionalDataRegion {
+
+	/**
+	 * Build an access strategy for the requested access type.
+	 *
+	 * @param accessType The type of access strategy to build; never null.
+	 * @return The appropriate strategy contract for accessing this region
+	 * for the requested type of access.
+	 * @throws org.hibernate.cache.CacheException Usually indicates mis-configuration.
+	 */
+	public CollectionRegionAccessStrategy buildAccessStrategy(AccessType accessType) throws CacheException;
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/EntityRegion.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/EntityRegion.java
similarity index 79%
rename from hibernate-core/src/main/java/org/hibernate/cache/EntityRegion.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/EntityRegion.java
index 626cadcdbf..bdda74756a 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/EntityRegion.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/EntityRegion.java
@@ -1,46 +1,47 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache;
-import org.hibernate.cache.access.AccessType;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
-
-/**
- * Defines the contract for a cache region which will specifically be used to
- * store entity data.
- *
- * @author Steve Ebersole
- */
-public interface EntityRegion extends TransactionalDataRegion {
-
-	/**
-	 * Build an access strategy for the requested access type.
-	 *
-	 * @param accessType The type of access strategy to build; never null.
-	 * @return The appropriate strategy contract for accessing this region
-	 * for the requested type of access.
-	 * @throws CacheException Usually indicates mis-configuration.
-	 */
-	public EntityRegionAccessStrategy buildAccessStrategy(AccessType accessType) throws CacheException;
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.spi;
+
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.access.AccessType;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
+
+/**
+ * Defines the contract for a cache region which will specifically be used to
+ * store entity data.
+ *
+ * @author Steve Ebersole
+ */
+public interface EntityRegion extends TransactionalDataRegion {
+
+	/**
+	 * Build an access strategy for the requested access type.
+	 *
+	 * @param accessType The type of access strategy to build; never null.
+	 * @return The appropriate strategy contract for accessing this region
+	 * for the requested type of access.
+	 * @throws org.hibernate.cache.CacheException Usually indicates mis-configuration.
+	 */
+	public EntityRegionAccessStrategy buildAccessStrategy(AccessType accessType) throws CacheException;
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/FilterKey.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/FilterKey.java
similarity index 94%
rename from hibernate-core/src/main/java/org/hibernate/cache/FilterKey.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/FilterKey.java
index 6280b249a9..ea3cd1f9e0 100755
--- a/hibernate-core/src/main/java/org/hibernate/cache/FilterKey.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/FilterKey.java
@@ -1,91 +1,92 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.spi;
+
 import java.io.Serializable;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Set;
+
 import org.hibernate.EntityMode;
 import org.hibernate.engine.TypedValue;
 import org.hibernate.internal.FilterImpl;
 import org.hibernate.type.Type;
 
 /**
  * Allows cached queries to be keyed by enabled filters.
  * 
  * @author Gavin King
  */
 public final class FilterKey implements Serializable {
 	private String filterName;
 	private Map filterParameters = new HashMap();
 	
 	public FilterKey(String name, Map params, Map types, EntityMode entityMode) {
 		filterName = name;
 		Iterator iter = params.entrySet().iterator();
 		while ( iter.hasNext() ) {
 			Map.Entry me = (Map.Entry) iter.next();
 			Type type = (Type) types.get( me.getKey() );
 			filterParameters.put( me.getKey(), new TypedValue( type, me.getValue(), entityMode ) );
 		}
 	}
 	
 	public int hashCode() {
 		int result = 13;
 		result = 37 * result + filterName.hashCode();
 		result = 37 * result + filterParameters.hashCode();
 		return result;
 	}
 	
 	public boolean equals(Object other) {
 		if ( !(other instanceof FilterKey) ) return false;
 		FilterKey that = (FilterKey) other;
 		if ( !that.filterName.equals(filterName) ) return false;
 		if ( !that.filterParameters.equals(filterParameters) ) return false;
 		return true;
 	}
 	
 	public String toString() {
 		return "FilterKey[" + filterName + filterParameters + ']';
 	}
 	
 	public static Set createFilterKeys(Map enabledFilters, EntityMode entityMode) {
 		if ( enabledFilters.size()==0 ) return null;
 		Set result = new HashSet();
 		Iterator iter = enabledFilters.values().iterator();
 		while ( iter.hasNext() ) {
 			FilterImpl filter = (FilterImpl) iter.next();
 			FilterKey key = new FilterKey(
 					filter.getName(), 
 					filter.getParameters(), 
 					filter.getFilterDefinition().getParameterTypes(), 
 					entityMode
 				);
 			result.add(key);
 		}
 		return result;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/GeneralDataRegion.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/GeneralDataRegion.java
similarity index 86%
rename from hibernate-core/src/main/java/org/hibernate/cache/GeneralDataRegion.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/GeneralDataRegion.java
index 0f593a8ce7..fdeb3c45cb 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/GeneralDataRegion.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/GeneralDataRegion.java
@@ -1,69 +1,69 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache;
-
-
-/**
- * Contract for general-purpose cache regions.
- *
- * @author Steve Ebersole
- */
-public interface GeneralDataRegion extends Region {
-
-	/**
-	 * Get an item from the cache.
-	 *
-	 * @param key The key of the item to be retrieved.
-	 * @return the cached object or <tt>null</tt>
-	 * @throws CacheException Indicates a problem accessing the item or region.
-	 */
-	public Object get(Object key) throws CacheException;
-
-	/**
-	 * Put an item into the cache.
-	 *
-	 * @param key The key under which to cache the item.
-	 * @param value The item to cache.
-	 * @throws CacheException Indicates a problem accessing the region.
-	 */
-	public void put(Object key, Object value) throws CacheException;
-
-	/**
-	 * Evict an item from the cache immediately (without regard for transaction
-	 * isolation).
-	 *
-	 * @param key The key of the item to remove
-	 * @throws CacheException Indicates a problem accessing the item or region.
-	 */
-	public void evict(Object key) throws CacheException;
-
-	/**
-	 * Evict all contents of this particular cache region (without regard for transaction
-	 * isolation).
-	 *
-	 * @throws CacheException Indicates problem accessing the region.
-	 */
-	public void evictAll() throws CacheException;
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.spi;
+
+import org.hibernate.cache.CacheException;
+
+/**
+ * Contract for general-purpose cache regions.
+ *
+ * @author Steve Ebersole
+ */
+public interface GeneralDataRegion extends Region {
+
+	/**
+	 * Get an item from the cache.
+	 *
+	 * @param key The key of the item to be retrieved.
+	 * @return the cached object or <tt>null</tt>
+	 * @throws org.hibernate.cache.CacheException Indicates a problem accessing the item or region.
+	 */
+	public Object get(Object key) throws CacheException;
+
+	/**
+	 * Put an item into the cache.
+	 *
+	 * @param key The key under which to cache the item.
+	 * @param value The item to cache.
+	 * @throws CacheException Indicates a problem accessing the region.
+	 */
+	public void put(Object key, Object value) throws CacheException;
+
+	/**
+	 * Evict an item from the cache immediately (without regard for transaction
+	 * isolation).
+	 *
+	 * @param key The key of the item to remove
+	 * @throws CacheException Indicates a problem accessing the item or region.
+	 */
+	public void evict(Object key) throws CacheException;
+
+	/**
+	 * Evict all contents of this particular cache region (without regard for transaction
+	 * isolation).
+	 *
+	 * @throws CacheException Indicates problem accessing the region.
+	 */
+	public void evictAll() throws CacheException;
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/NonstrictReadWriteCache.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/NonstrictReadWriteCache.java
similarity index 94%
rename from hibernate-core/src/main/java/org/hibernate/cache/NonstrictReadWriteCache.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/NonstrictReadWriteCache.java
index f81ffa52d0..efd34e0b1c 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/NonstrictReadWriteCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/NonstrictReadWriteCache.java
@@ -1,176 +1,178 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
-import java.util.Comparator;
+package org.hibernate.cache.spi;
 
-import org.hibernate.internal.CoreMessageLogger;
-import org.hibernate.cache.access.SoftLock;
+import java.util.Comparator;
 
 import org.jboss.logging.Logger;
 
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.access.SoftLock;
+import org.hibernate.internal.CoreMessageLogger;
+
 /**
  * Caches data that is sometimes updated without ever locking the cache.
  * If concurrent access to an item is possible, this concurrency strategy
  * makes no guarantee that the item returned from the cache is the latest
  * version available in the database. Configure your cache timeout accordingly!
  * This is an "asynchronous" concurrency strategy.
  *
  * @author Gavin King
  * @see ReadWriteCache for a much stricter algorithm
  */
+@Deprecated
 public class NonstrictReadWriteCache implements CacheConcurrencyStrategy {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        NonstrictReadWriteCache.class.getName());
 
 	private Cache cache;
 
 	public NonstrictReadWriteCache() {
 	}
 
 	public void setCache(Cache cache) {
 		this.cache = cache;
 	}
 
 	public Cache getCache() {
 		return cache;
 	}
 
 	/**
 	 * Get the most recent version, if available.
 	 */
 	public Object get(Object key, long txTimestamp) throws CacheException {
         LOG.debugf("Cache lookup: %s", key);
 
 		Object result = cache.get( key );
         if (result != null) LOG.debugf("Cache hit: %s", key);
         else LOG.debugf("Cache miss: %s", key);
 		return result;
 	}
 
 	/**
 	 * Add an item to the cache.
 	 */
 	public boolean put(
 			Object key,
 	        Object value,
 	        long txTimestamp,
 	        Object version,
 	        Comparator versionComparator,
 	        boolean minimalPut) throws CacheException {
 		if ( minimalPut && cache.get( key ) != null ) {
             LOG.debugf("Item already cached: %s", key);
 			return false;
 		}
         LOG.debugf("Caching: %s", key);
 
 		cache.put( key, value );
 		return true;
 
 	}
 
 	/**
 	 * Do nothing.
 	 *
 	 * @return null, no lock
 	 */
 	public SoftLock lock(Object key, Object version) throws CacheException {
 		return null;
 	}
 
 	public void remove(Object key) throws CacheException {
         LOG.debugf("Removing: %s", key);
 		cache.remove( key );
 	}
 
 	public void clear() throws CacheException {
         LOG.debugf("Clearing");
 		cache.clear();
 	}
 
 	public void destroy() {
 		try {
 			cache.destroy();
 		}
 		catch ( Exception e ) {
             LOG.unableToDestroyCache(e.getMessage());
 		}
 	}
 
 	/**
 	 * Invalidate the item
 	 */
 	public void evict(Object key) throws CacheException {
         LOG.debugf("Invalidating: %s", key);
 		cache.remove( key );
 	}
 
 	/**
 	 * Invalidate the item
 	 */
 	public boolean insert(Object key, Object value, Object currentVersion) {
 		return false;
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public boolean update(Object key, Object value, Object currentVersion, Object previousVersion) {
 		evict( key );
 		return false;
 	}
 
 	/**
 	 * Invalidate the item (again, for safety).
 	 */
 	public void release(Object key, SoftLock lock) throws CacheException {
         LOG.debugf("Invalidating: %s", key);
 		cache.remove( key );
 	}
 
 	/**
 	 * Invalidate the item (again, for safety).
 	 */
 	public boolean afterUpdate(Object key, Object value, Object version, SoftLock lock) throws CacheException {
 		release( key, lock );
 		return false;
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public boolean afterInsert(Object key, Object value, Object version) throws CacheException {
 		return false;
 	}
 
 	public String getRegionName() {
 		return cache.getRegionName();
 	}
 
 	@Override
     public String toString() {
 		return cache + "(nonstrict-read-write)";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/OptimisticCache.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/OptimisticCache.java
similarity index 91%
rename from hibernate-core/src/main/java/org/hibernate/cache/OptimisticCache.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/OptimisticCache.java
index c9e63c0668..40dcaf6b9b 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/OptimisticCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/OptimisticCache.java
@@ -1,89 +1,87 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
-
+package org.hibernate.cache.spi;
 
 /**
  * A contract for transactional cache implementations which support
  * optimistic locking of items within the cache.
  * <p/>
- * The optimisitic locking capabilities are only utilized for
+ * The optimistic locking capabilities are only utilized for
  * the entity cache regions.
  * <p/>
  * Unlike the methods on the {@link Cache} interface, all the methods
  * here will only ever be called from access scenarios where versioned
- * data is actually a possiblity (i.e., entity data).  Be sure to consult
+ * data is actually a possibility (i.e., entity data).  Be sure to consult
  * with {@link OptimisticCacheSource#isVersioned()} to determine whether
  * versioning is actually in effect.
  *
  * @author Steve Ebersole
  */
 public interface OptimisticCache extends Cache {
 	/**
 	 * Indicates the "source" of the cached data.  Currently this will
 	 * only ever represent an {@link org.hibernate.persister.entity.EntityPersister}.
 	 * <p/>
 	 * Made available to the cache so that it can access certain information
 	 * about versioning strategy.
 	 *
 	 * @param source The source.
 	 */
 	public void setSource(OptimisticCacheSource source);
 
 	/**
 	 * Called during {@link CacheConcurrencyStrategy#insert} processing for
 	 * transactional strategies.  Indicates we have just performed an insert
 	 * into the DB and now need to cache that entity's data.
 	 *
 	 * @param key The cache key.
 	 * @param value The data to be cached.
 	 * @param currentVersion The entity's version; or null if not versioned.
 	 */
 	public void writeInsert(Object key, Object value, Object currentVersion);
 
 	/**
 	 * Called during {@link CacheConcurrencyStrategy#update} processing for
 	 * transactional strategies.  Indicates we have just performed an update
 	 * against the DB and now need to cache the updated state.
 	 *
 	 * @param key The cache key.
 	 * @param value The data to be cached.
 	 * @param currentVersion The entity's current version
 	 * @param previousVersion The entity's previous version (before the update);
 	 * or null if not versioned.
 	 */
 	public void writeUpdate(Object key, Object value, Object currentVersion, Object previousVersion);
 
 	/**
 	 * Called during {@link CacheConcurrencyStrategy#put} processing for
 	 * transactional strategies.  Indicates we have just loaded an entity's
 	 * state from the database and need it cached.
 	 *
 	 * @param key The cache key.
 	 * @param value The data to be cached.
 	 * @param currentVersion The entity's version; or null if not versioned.
 	 */
 	public void writeLoad(Object key, Object value, Object currentVersion);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/OptimisticCacheSource.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/OptimisticCacheSource.java
similarity index 91%
rename from hibernate-core/src/main/java/org/hibernate/cache/OptimisticCacheSource.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/OptimisticCacheSource.java
index 9ac3d1cd54..9279f04e60 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/OptimisticCacheSource.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/OptimisticCacheSource.java
@@ -1,55 +1,55 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.spi;
+
 import java.util.Comparator;
 
 /**
  * Contract for sources of optimistically lockable data sent to the second level
  * cache.
  * <p/>
  * Note currently {@link org.hibernate.persister.entity.EntityPersister}s are
  * the only viable source.
  *
  * @author Steve Ebersole
  */
 public interface OptimisticCacheSource {
 	/**
 	 * Is the data to be cached considered versioned?
 	 * <p/>
 	 * If true, it is illegal for {@link #getVersionComparator} to return
 	 * null.
 	 *
 	 * @return True if the data is versioned; false otherwise.
 	 */
 	public boolean isVersioned();
 
 	/**
 	 * Get the comparator used to compare two different version values.
 	 * <p/>
 	 * May return null <b>if</b> {@link #isVersioned()} returns false.
 	 * @return
 	 */
 	public Comparator getVersionComparator();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/QueryCache.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/QueryCache.java
similarity index 90%
rename from hibernate-core/src/main/java/org/hibernate/cache/QueryCache.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/QueryCache.java
index 91a2ae0d13..a54cf28e8f 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/QueryCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/QueryCache.java
@@ -1,52 +1,54 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.spi;
+
 import java.util.List;
 import java.util.Set;
+
 import org.hibernate.HibernateException;
+import org.hibernate.cache.CacheException;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.type.Type;
 
 /**
  * Defines the contract for caches capable of storing query results.  These
  * caches should only concern themselves with storing the matching result ids.
  * The transactional semantics are necessarily less strict than the semantics
  * of an item cache.
  * 
  * @author Gavin King
  */
 public interface QueryCache {
 
 	public void clear() throws CacheException;
 	
 	public boolean put(QueryKey key, Type[] returnTypes, List result, boolean isNaturalKeyLookup, SessionImplementor session) throws HibernateException;
 
 	public List get(QueryKey key, Type[] returnTypes, boolean isNaturalKeyLookup, Set spaces, SessionImplementor session) throws HibernateException;
 
 	public void destroy();
 
 	public QueryResultsRegion getRegion();
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/QueryCacheFactory.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/QueryCacheFactory.java
similarity index 86%
rename from hibernate-core/src/main/java/org/hibernate/cache/QueryCacheFactory.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/QueryCacheFactory.java
index b9f239dd1b..4e83677995 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/QueryCacheFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/QueryCacheFactory.java
@@ -1,45 +1,43 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.spi;
+
 import java.util.Properties;
+
 import org.hibernate.HibernateException;
 import org.hibernate.cfg.Settings;
 
 /**
  * Defines a factory for query cache instances.  These factories are responsible for
  * creating individual QueryCache instances.
  *
  * @author Steve Ebersole
  */
 public interface QueryCacheFactory {
-
 	public QueryCache getQueryCache(
 	        String regionName,
 	        UpdateTimestampsCache updateTimestampsCache,
 			Settings settings,
-	        Properties props) 
-	throws HibernateException;
-
+	        Properties props) throws HibernateException;
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/QueryKey.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/QueryKey.java
similarity index 98%
rename from hibernate-core/src/main/java/org/hibernate/cache/QueryKey.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/QueryKey.java
index 08322b33a3..38755f9781 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/QueryKey.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/QueryKey.java
@@ -1,300 +1,301 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.cache;
+package org.hibernate.cache.spi;
 
 import java.io.IOException;
 import java.io.Serializable;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Set;
+
 import org.hibernate.EntityMode;
 import org.hibernate.engine.QueryParameters;
 import org.hibernate.engine.RowSelection;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.TypedValue;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.internal.util.compare.EqualsHelper;
 import org.hibernate.transform.CacheableResultTransformer;
 import org.hibernate.type.Type;
 
 /**
  * A key that identifies a particular query with bound parameter values.  This is the object Hibernate uses
  * as its key into its query cache.
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class QueryKey implements Serializable {
 	private final String sqlQueryString;
 	private final Type[] positionalParameterTypes;
 	private final Object[] positionalParameterValues;
 	private final Map namedParameters;
 	private final Integer firstRow;
 	private final Integer maxRows;
 	private final EntityMode entityMode;
 	private final String tenantIdentifier;
 	private final Set filterKeys;
 
 	// the user provided resulttransformer, not the one used with "select new". Here to avoid mangling
 	// transformed/non-transformed results.
 	private final CacheableResultTransformer customTransformer;
 
 	/**
 	 * For performance reasons, the hashCode is cached; however, it is marked transient so that it can be
 	 * recalculated as part of the serialization process which allows distributed query caches to work properly.
 	 */
 	private transient int hashCode;
 
 	/**
 	 * Generates a QueryKey.
 	 *
 	 * @param queryString The sql query string.
 	 * @param queryParameters The query parameters
 	 * @param filterKeys The keys of any enabled filters.
 	 * @param session The current session.
 	 * @param customTransformer The result transformer; should be
 	 *            null if data is not transformed before being cached.
 	 *
 	 * @return The generate query cache key.
 	 */
 	public static QueryKey generateQueryKey(
 			String queryString,
 			QueryParameters queryParameters,
 			Set filterKeys,
 			SessionImplementor session,
 			CacheableResultTransformer customTransformer) {
 		// disassemble positional parameters
 		final int positionalParameterCount = queryParameters.getPositionalParameterTypes().length;
 		final Type[] types = new Type[positionalParameterCount];
 		final Object[] values = new Object[positionalParameterCount];
 		for ( int i = 0; i < positionalParameterCount; i++ ) {
 			types[i] = queryParameters.getPositionalParameterTypes()[i];
 			values[i] = types[i].disassemble( queryParameters.getPositionalParameterValues()[i], session, null );
 		}
 
 		// disassemble named parameters
 		final Map namedParameters;
 		if ( queryParameters.getNamedParameters() == null ) {
 			namedParameters = null;
 		}
 		else {
 			namedParameters = CollectionHelper.mapOfSize( queryParameters.getNamedParameters().size() );
 			Iterator itr = queryParameters.getNamedParameters().entrySet().iterator();
 			while ( itr.hasNext() ) {
 				final Map.Entry namedParameterEntry = ( Map.Entry ) itr.next();
 				final TypedValue original = ( TypedValue ) namedParameterEntry.getValue();
 				namedParameters.put(
 						namedParameterEntry.getKey(),
 						new TypedValue(
 								original.getType(),
 								original.getType().disassemble( original.getValue(), session, null ),
 								session.getEntityMode()
 						)
 				);
 			}
 		}
 
 		// decode row selection...
 		final RowSelection selection = queryParameters.getRowSelection();
 		final Integer firstRow;
 		final Integer maxRows;
 		if ( selection != null ) {
 			firstRow = selection.getFirstRow();
 			maxRows = selection.getMaxRows();
 		}
 		else {
 			firstRow = null;
 			maxRows = null;
 		}
 
 		return new QueryKey(
 				queryString,
 				types,
 				values,
 				namedParameters,
 				firstRow,
 				maxRows,
 				filterKeys,
 				session.getEntityMode(),
 				session.getTenantIdentifier(),
 				customTransformer
 		);
 	}
 
 	/**
 	 * Package-protected constructor.
 	 *
 	 * @param sqlQueryString The sql query string.
 	 * @param positionalParameterTypes Positional parameter types.
 	 * @param positionalParameterValues Positional parameter values.
 	 * @param namedParameters Named parameters.
 	 * @param firstRow First row selection, if any.
 	 * @param maxRows Max-rows selection, if any.
 	 * @param filterKeys Enabled filter keys, if any.
 	 * @param entityMode The entity mode.
 	 * @param customTransformer Custom result transformer, if one.
 	 */
 	QueryKey(
 			String sqlQueryString,
 			Type[] positionalParameterTypes,
 			Object[] positionalParameterValues,
 			Map namedParameters,
 			Integer firstRow,
 			Integer maxRows,
 			Set filterKeys,
 			EntityMode entityMode,
 			String tenantIdentifier,
 			CacheableResultTransformer customTransformer) {
 		this.sqlQueryString = sqlQueryString;
 		this.positionalParameterTypes = positionalParameterTypes;
 		this.positionalParameterValues = positionalParameterValues;
 		this.namedParameters = namedParameters;
 		this.firstRow = firstRow;
 		this.maxRows = maxRows;
 		this.entityMode = entityMode;
 		this.tenantIdentifier = tenantIdentifier;
 		this.filterKeys = filterKeys;
 		this.customTransformer = customTransformer;
 		this.hashCode = generateHashCode();
 	}
 
 	public CacheableResultTransformer getResultTransformer() {
 		return customTransformer;
 	}
 
 	/**
 	 * Deserialization hook used to re-init the cached hashcode which is needed for proper clustering support.
 	 *
 	 * @param in The object input stream.
 	 *
 	 * @throws IOException Thrown by normal deserialization
 	 * @throws ClassNotFoundException Thrown by normal deserialization
 	 */
 	private void readObject(java.io.ObjectInputStream in) throws IOException, ClassNotFoundException {
 		in.defaultReadObject();
 		this.hashCode = generateHashCode();
 	}
 
 	private int generateHashCode() {
 		int result = 13;
 		result = 37 * result + ( firstRow==null ? 0 : firstRow.hashCode() );
 		result = 37 * result + ( maxRows==null ? 0 : maxRows.hashCode() );
 		for ( int i=0; i< positionalParameterValues.length; i++ ) {
 			result = 37 * result + ( positionalParameterValues[i]==null ? 0 : positionalParameterTypes[i].getHashCode( positionalParameterValues[i], entityMode ) );
 		}
 		result = 37 * result + ( namedParameters==null ? 0 : namedParameters.hashCode() );
 		result = 37 * result + ( filterKeys ==null ? 0 : filterKeys.hashCode() );
 		result = 37 * result + ( customTransformer==null ? 0 : customTransformer.hashCode() );
 		result = 37 * result + ( tenantIdentifier==null ? 0 : tenantIdentifier.hashCode() );
 		result = 37 * result + sqlQueryString.hashCode();
 		return result;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     public boolean equals(Object other) {
 		if ( !( other instanceof QueryKey ) ) {
 			return false;
 		}
 		QueryKey that = ( QueryKey ) other;
 		if ( !sqlQueryString.equals( that.sqlQueryString ) ) {
 			return false;
 		}
 		if ( !EqualsHelper.equals( firstRow, that.firstRow ) || !EqualsHelper.equals( maxRows, that.maxRows ) ) {
 			return false;
 		}
 		if ( !EqualsHelper.equals( customTransformer, that.customTransformer ) ) {
 			return false;
 		}
 		if ( positionalParameterTypes == null ) {
 			if ( that.positionalParameterTypes != null ) {
 				return false;
 			}
 		}
 		else {
 			if ( that.positionalParameterTypes == null ) {
 				return false;
 			}
 			if ( positionalParameterTypes.length != that.positionalParameterTypes.length ) {
 				return false;
 			}
 			for ( int i = 0; i < positionalParameterTypes.length; i++ ) {
 				if ( positionalParameterTypes[i].getReturnedClass() != that.positionalParameterTypes[i].getReturnedClass() ) {
 					return false;
 				}
 				if ( !positionalParameterTypes[i].isEqual( positionalParameterValues[i], that.positionalParameterValues[i], entityMode ) ) {
 					return false;
 				}
 			}
 		}
 
 		return EqualsHelper.equals( filterKeys, that.filterKeys )
 				&& EqualsHelper.equals( namedParameters, that.namedParameters )
 				&& EqualsHelper.equals( entityMode, that.entityMode )
 				&& EqualsHelper.equals( tenantIdentifier, that.tenantIdentifier );
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     public int hashCode() {
 		return hashCode;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	@Override
     public String toString() {
 		StringBuffer buf = new StringBuffer()
 				.append( "sql: " )
 				.append( sqlQueryString );
 		if ( positionalParameterValues != null ) {
 			buf.append( "; parameters: " );
 			for ( int i = 0; i < positionalParameterValues.length; i++ ) {
 				buf.append( positionalParameterValues[i] ).append( ", " );
 			}
 		}
 		if ( namedParameters != null ) {
 			buf.append( "; named parameters: " ).append( namedParameters );
 		}
 		if ( filterKeys != null ) {
 			buf.append( "; filterKeys: " ).append( filterKeys );
 		}
 		if ( firstRow != null ) {
 			buf.append( "; first row: " ).append( firstRow );
 		}
 		if ( maxRows != null ) {
 			buf.append( "; max rows: " ).append( maxRows );
 		}
 		if ( customTransformer != null ) {
 			buf.append( "; transformer: " ).append( customTransformer );
 		}
 		return buf.toString();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/QueryResultsRegion.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/QueryResultsRegion.java
similarity index 85%
rename from hibernate-core/src/main/java/org/hibernate/cache/QueryResultsRegion.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/QueryResultsRegion.java
index 7dc528028f..423b823b39 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/QueryResultsRegion.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/QueryResultsRegion.java
@@ -1,35 +1,33 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache;
-
-
-/**
- * Defines the contract for a cache region which will specifically be used to
- * store query results.
- *
- * @author Steve Ebersole
- */
-public interface QueryResultsRegion extends GeneralDataRegion {
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.spi;
+
+/**
+ * Defines the contract for a cache region which will specifically be used to
+ * store query results.
+ *
+ * @author Steve Ebersole
+ */
+public interface QueryResultsRegion extends GeneralDataRegion {
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/ReadOnlyCache.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/ReadOnlyCache.java
similarity index 92%
rename from hibernate-core/src/main/java/org/hibernate/cache/ReadOnlyCache.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/ReadOnlyCache.java
index 8c0fbc35cb..cf8d62d945 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/ReadOnlyCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/ReadOnlyCache.java
@@ -1,162 +1,165 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.spi;
+
 import java.util.Comparator;
-import org.hibernate.internal.CoreMessageLogger;
-import org.hibernate.cache.access.SoftLock;
 
 import org.jboss.logging.Logger;
 
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.access.SoftLock;
+import org.hibernate.internal.CoreMessageLogger;
+
 /**
  * Caches data that is never updated.
- * @see CacheConcurrencyStrategy
+ * @see org.hibernate.cache.spi.CacheConcurrencyStrategy
  */
+@Deprecated
 public class ReadOnlyCache implements CacheConcurrencyStrategy {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ReadOnlyCache.class.getName());
 
 	private Cache cache;
 
 	public ReadOnlyCache() {}
 
 	public void setCache(Cache cache) {
 		this.cache=cache;
 	}
 
 	public Cache getCache() {
 		return cache;
 	}
 
 	public String getRegionName() {
 		return cache.getRegionName();
 	}
 
 	public synchronized Object get(Object key, long timestamp) throws CacheException {
 		Object result = cache.get(key);
         if (result != null) LOG.debugf("Cache hit: %s", key);
 		return result;
 	}
 
 	/**
 	 * Unsupported!
 	 */
 	public SoftLock lock(Object key, Object version) {
         LOG.invalidEditOfReadOnlyItem(key);
 		throw new UnsupportedOperationException("Can't write to a readonly object");
 	}
 
 	public synchronized boolean put(
 			Object key,
 			Object value,
 			long timestamp,
 			Object version,
 			Comparator versionComparator,
 			boolean minimalPut)
 	throws CacheException {
 		if ( minimalPut && cache.get(key)!=null ) {
             LOG.debugf("Item already cached: %s", key);
 			return false;
 		}
         LOG.debugf("Caching: %s", key);
 		cache.put(key, value);
 		return true;
 	}
 
 	/**
 	 * Unsupported!
 	 */
 	public void release(Object key, SoftLock lock) {
         LOG.invalidEditOfReadOnlyItem(key);
 		//throw new UnsupportedOperationException("Can't write to a readonly object");
 	}
 
 	public void clear() throws CacheException {
 		cache.clear();
 	}
 
 	public void remove(Object key) throws CacheException {
 		cache.remove(key);
 	}
 
 	public void destroy() {
 		try {
 			cache.destroy();
 		}
 		catch (Exception e) {
             LOG.unableToDestroyCache(e.getMessage());
 		}
 	}
 
 	/**
 	 * Unsupported!
 	 */
 	public boolean afterUpdate(Object key, Object value, Object version, SoftLock lock) throws CacheException {
         LOG.invalidEditOfReadOnlyItem(key);
 		throw new UnsupportedOperationException("Can't write to a readonly object");
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public boolean afterInsert(Object key, Object value, Object version) throws CacheException {
         LOG.debugf("Caching after insert: %s", key);
 		cache.update(key, value);
 		return true;
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public void evict(Object key) throws CacheException {
 		// noop
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public boolean insert(Object key, Object value, Object currentVersion) {
 		return false;
 	}
 
 	/**
 	 * Unsupported!
 	 */
 	public boolean update(Object key, Object value, Object currentVersion, Object previousVersion) {
         LOG.invalidEditOfReadOnlyItem(key);
 		throw new UnsupportedOperationException("Can't write to a readonly object");
 	}
 
 	@Override
     public String toString() {
 		return cache + "(read-only)";
 	}
 
 }
 
 
 
 
 
 
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/ReadWriteCache.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/ReadWriteCache.java
similarity index 97%
rename from hibernate-core/src/main/java/org/hibernate/cache/ReadWriteCache.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/ReadWriteCache.java
index 552afb9b4a..89ab5e0f97 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/ReadWriteCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/ReadWriteCache.java
@@ -1,498 +1,500 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
+package org.hibernate.cache.spi;
+
 import java.io.Serializable;
 import java.util.Comparator;
 
-import org.hibernate.internal.CoreMessageLogger;
-import org.hibernate.cache.access.SoftLock;
-
 import org.jboss.logging.Logger;
 
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.access.SoftLock;
+import org.hibernate.internal.CoreMessageLogger;
+
 /**
  * Caches data that is sometimes updated while maintaining the semantics of
  * "read committed" isolation level. If the database is set to "repeatable
  * read", this concurrency strategy <em>almost</em> maintains the semantics.
  * Repeatable read isolation is compromised in the case of concurrent writes.
  * This is an "asynchronous" concurrency strategy.<br>
  * <br>
  * If this strategy is used in a cluster, the underlying cache implementation
  * must support distributed hard locks (which are held only momentarily). This
  * strategy also assumes that the underlying cache implementation does not do
  * asynchronous replication and that state has been fully replicated as soon
  * as the lock is released.
  *
  * @see NonstrictReadWriteCache for a faster algorithm
- * @see CacheConcurrencyStrategy
+ * @see org.hibernate.cache.spi.CacheConcurrencyStrategy
  */
+@Deprecated
 public class ReadWriteCache implements CacheConcurrencyStrategy {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ReadWriteCache.class.getName());
 
 	private Cache cache;
 	private int nextLockId;
 
 	public ReadWriteCache() {}
 
 	public void setCache(Cache cache) {
 		this.cache=cache;
 	}
 
 	public Cache getCache() {
 		return cache;
 	}
 
 	public String getRegionName() {
 		return cache.getRegionName();
 	}
 
 	/**
 	 * Generate an id for a new lock. Uniqueness per cache instance is very
 	 * desirable but not absolutely critical. Must be called from one of the
 	 * synchronized methods of this class.
 	 */
 	private int nextLockId() {
 		if (nextLockId==Integer.MAX_VALUE) nextLockId = Integer.MIN_VALUE;
 		return nextLockId++;
 	}
 
 	/**
 	 * Do not return an item whose timestamp is later than the current
 	 * transaction timestamp. (Otherwise we might compromise repeatable
 	 * read unnecessarily.) Do not return an item which is soft-locked.
 	 * Always go straight to the database instead.<br>
 	 * <br>
 	 * Note that since reading an item from that cache does not actually
 	 * go to the database, it is possible to see a kind of phantom read
 	 * due to the underlying row being updated after we have read it
 	 * from the cache. This would not be possible in a lock-based
 	 * implementation of repeatable read isolation. It is also possible
 	 * to overwrite changes made and committed by another transaction
 	 * after the current transaction read the item from the cache. This
 	 * problem would be caught by the update-time version-checking, if
 	 * the data is versioned or timestamped.
 	 */
 	public synchronized Object get(Object key, long txTimestamp) throws CacheException {
         LOG.debugf("Cache lookup: %s", key);
 		Lockable lockable = (Lockable)cache.get(key);
 		boolean gettable = lockable != null && lockable.isGettable(txTimestamp);
 		if (gettable) {
             LOG.debugf("Cache hit: %s", key);
             return ((Item)lockable).getValue();
         }
         if (lockable == null) LOG.debugf("Cache miss: %s", key);
         else LOG.debugf("Cached item was locked: %s", key);
         return null;
 	}
 
 	/**
 	 * Stop any other transactions reading or writing this item to/from
 	 * the cache. Send them straight to the database instead. (The lock
 	 * does time out eventually.) This implementation tracks concurrent
 	 * locks of transactions which simultaneously attempt to write to an
 	 * item.
 	 */
 	public synchronized SoftLock lock(Object key, Object version) throws CacheException {
         LOG.debugf("Invalidating: %s", key);
 		try {
 			cache.lock(key);
 
 			Lockable lockable = (Lockable) cache.get(key);
 			long timeout = cache.nextTimestamp() + cache.getTimeout();
 			final Lock lock = (lockable==null) ?
 				new Lock( timeout, nextLockId(), version ) :
 				lockable.lock( timeout, nextLockId() );
 			cache.update(key, lock);
 			return lock;
 		}
 		finally {
 			cache.unlock(key);
 		}
 
 	}
 
 	/**
 	 * Do not add an item to the cache unless the current transaction
 	 * timestamp is later than the timestamp at which the item was
 	 * invalidated. (Otherwise, a stale item might be re-added if the
 	 * database is operating in repeatable read isolation mode.)
 	 * For versioned data, don't add the item unless it is the later
 	 * version.
 	 */
 	public synchronized boolean put(
 			Object key,
 			Object value,
 			long txTimestamp,
 			Object version,
 			Comparator versionComparator,
 			boolean minimalPut)
 	throws CacheException {
         LOG.debugf("Caching: %s", key);
 
 		try {
 			cache.lock(key);
 
 			Lockable lockable = (Lockable) cache.get(key);
 
 			boolean puttable = lockable==null ||
 				lockable.isPuttable(txTimestamp, version, versionComparator);
 
 			if (puttable) {
 				cache.put( key, new Item( value, version, cache.nextTimestamp() ) );
                 LOG.debugf("Cached: %s", key);
 				return true;
 			}
             if (lockable.isLock()) LOG.debugf("Cached item was locked: %s", key);
             else LOG.debugf("Item already cached: %s", key);
             return false;
 		}
 		finally {
 			cache.unlock(key);
 		}
 	}
 
 	/**
 	 * decrement a lock and put it back in the cache
 	 */
 	private void decrementLock(Object key, Lock lock) throws CacheException {
 		//decrement the lock
 		lock.unlock( cache.nextTimestamp() );
 		cache.update(key, lock);
 	}
 
 	/**
 	 * Release the soft lock on the item. Other transactions may now
 	 * re-cache the item (assuming that no other transaction holds a
 	 * simultaneous lock).
 	 */
 	public synchronized void release(Object key, SoftLock clientLock) throws CacheException {
         LOG.debugf("Releasing: %s", key);
 
 		try {
 			cache.lock(key);
 
 			Lockable lockable = (Lockable) cache.get(key);
 			if ( isUnlockable(clientLock, lockable) ) {
 				decrementLock(key, (Lock) lockable);
 			}
 			else {
 				handleLockExpiry(key);
 			}
 		}
 		finally {
 			cache.unlock(key);
 		}
 	}
 
 	void handleLockExpiry(Object key) throws CacheException {
         LOG.expired(key);
 		long ts = cache.nextTimestamp() + cache.getTimeout();
 		// create new lock that times out immediately
 		Lock lock = new Lock( ts, nextLockId(), null );
 		lock.unlock(ts);
 		cache.update(key, lock);
 	}
 
 	public void clear() throws CacheException {
 		cache.clear();
 	}
 
 	public void remove(Object key) throws CacheException {
 		cache.remove(key);
 	}
 
 	public void destroy() {
 		try {
 			cache.destroy();
 		}
 		catch (Exception e) {
             LOG.unableToDestroyCache(e.getMessage());
 		}
 	}
 
 	/**
 	 * Re-cache the updated state, if and only if there there are
 	 * no other concurrent soft locks. Release our lock.
 	 */
 	public synchronized boolean afterUpdate(Object key, Object value, Object version, SoftLock clientLock)
 	throws CacheException {
 
         LOG.debugf("Updating: %s", key);
 
 		try {
 			cache.lock(key);
 
 			Lockable lockable = (Lockable) cache.get(key);
 			if ( isUnlockable(clientLock, lockable) ) {
 				Lock lock = (Lock) lockable;
 				if ( lock.wasLockedConcurrently() ) {
 					// just decrement the lock, don't recache
 					// (we don't know which transaction won)
 					decrementLock(key, lock);
 					return false;
 				}
                 // recache the updated state
                 cache.update(key, new Item(value, version, cache.nextTimestamp()));
                 LOG.debugf("Updated: %s", key);
                 return true;
 			}
             handleLockExpiry(key);
             return false;
 		}
 		finally {
 			cache.unlock(key);
 		}
 	}
 
 	/**
 	 * Add the new item to the cache, checking that no other transaction has
 	 * accessed the item.
 	 */
 	public synchronized boolean afterInsert(Object key, Object value, Object version)
 	throws CacheException {
 
         LOG.debugf("Inserting: %s", key);
 		try {
 			cache.lock(key);
 
 			Lockable lockable = (Lockable) cache.get(key);
 			if (lockable==null) {
 				cache.update( key, new Item( value, version, cache.nextTimestamp() ) );
                 LOG.debugf("Inserted: %s", key);
 				return true;
 			}
             return false;
 		}
 		finally {
 			cache.unlock(key);
 		}
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public void evict(Object key) throws CacheException {
 		// noop
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public boolean insert(Object key, Object value, Object currentVersion) {
 		return false;
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public boolean update(Object key, Object value, Object currentVersion, Object previousVersion) {
 		return false;
 	}
 
 	/**
 	 * Is the client's lock commensurate with the item in the cache?
 	 * If it is not, we know that the cache expired the original
 	 * lock.
 	 */
 	private boolean isUnlockable(SoftLock clientLock, Lockable myLock)
 	throws CacheException {
 		//null clientLock is remotely possible but will never happen in practice
 		return myLock!=null &&
 			myLock.isLock() &&
 			clientLock!=null &&
 			( (Lock) clientLock ).getId()==( (Lock) myLock ).getId();
 	}
 
 	public static interface Lockable {
 		public Lock lock(long timeout, int id);
 		public boolean isLock();
 		public boolean isGettable(long txTimestamp);
 		public boolean isPuttable(long txTimestamp, Object newVersion, Comparator comparator);
 	}
 
 	/**
 	 * An item of cached data, timestamped with the time it was cached,.
 	 * @see ReadWriteCache
 	 */
 	public static final class Item implements Serializable, Lockable {
 
 		private final long freshTimestamp;
 		private final Object value;
 		private final Object version;
 
 		public Item(Object value, Object version, long currentTimestamp) {
 			this.value = value;
 			this.version = version;
 			freshTimestamp = currentTimestamp;
 		}
 		/**
 		 * The timestamp on the cached data
 		 */
 		public long getFreshTimestamp() {
 			return freshTimestamp;
 		}
 		/**
 		 * The actual cached data
 		 */
 		public Object getValue() {
 			return value;
 		}
 
 		/**
 		 * Lock the item
 		 */
 		public Lock lock(long timeout, int id) {
 			return new Lock(timeout, id, version);
 		}
 		/**
 		 * Not a lock!
 		 */
 		public boolean isLock() {
 			return false;
 		}
 		/**
 		 * Is this item visible to the timestamped
 		 * transaction?
 		 */
 		public boolean isGettable(long txTimestamp) {
 			return freshTimestamp < txTimestamp;
 		}
 
 		/**
 		 * Don't overwite already cached items
 		 */
 		public boolean isPuttable(long txTimestamp, Object newVersion, Comparator comparator) {
 			// we really could refresh the item if it
 			// is not a lock, but it might be slower
 			//return freshTimestamp < txTimestamp
 			return version!=null && comparator.compare(version, newVersion) < 0;
 		}
 
 		@Override
         public String toString() {
 			return "Item{version=" + version +
 				",freshTimestamp=" + freshTimestamp;
 		}
 	}
 
 	/**
 	 * A soft lock which supports concurrent locking,
 	 * timestamped with the time it was released
 	 * @author Gavin King
 	 */
 	public static final class Lock implements Serializable, Lockable, SoftLock {
 		private long unlockTimestamp = -1;
 		private int multiplicity = 1;
 		private boolean concurrentLock = false;
 		private long timeout;
 		private final int id;
 		private final Object version;
 
 		public Lock(long timeout, int id, Object version) {
 			this.timeout = timeout;
 			this.id = id;
 			this.version = version;
 		}
 
 		public long getUnlockTimestamp() {
 			return unlockTimestamp;
 		}
 		/**
 		 * Increment the lock, setting the
 		 * new lock timeout
 		 */
 		public Lock lock(long timeout, int id) {
 			concurrentLock = true;
 			multiplicity++;
 			this.timeout = timeout;
 			return this;
 		}
 		/**
 		 * Decrement the lock, setting the unlock
 		 * timestamp if now unlocked
 		 * @param currentTimestamp
 		 */
 		public void unlock(long currentTimestamp) {
 			if ( --multiplicity == 0 ) {
 				unlockTimestamp = currentTimestamp;
 			}
 		}
 
 		/**
 		 * Can the timestamped transaction re-cache this
 		 * locked item now?
 		 */
 		public boolean isPuttable(long txTimestamp, Object newVersion, Comparator comparator) {
 			if (timeout < txTimestamp) return true;
 			if (multiplicity>0) return false;
 			return version==null ?
 				unlockTimestamp < txTimestamp :
 				comparator.compare(version, newVersion) < 0; //by requiring <, we rely on lock timeout in the case of an unsuccessful update!
 		}
 
 		/**
 		 * Was this lock held concurrently by multiple
 		 * transactions?
 		 */
 		public boolean wasLockedConcurrently() {
 			return concurrentLock;
 		}
 		/**
 		 * Yes, this is a lock
 		 */
 		public boolean isLock() {
 			return true;
 		}
 		/**
 		 * locks are not returned to the client!
 		 */
 		public boolean isGettable(long txTimestamp) {
 			return false;
 		}
 
 		public int getId() { return id; }
 
 		@Override
         public String toString() {
 			return "Lock{id=" + id +
 				",version=" + version +
 				",multiplicity=" + multiplicity +
 				",unlockTimestamp=" + unlockTimestamp;
 		}
 
 	}
 
 	@Override
     public String toString() {
 		return cache + "(read-write)";
 	}
 
 }
 
 
 
 
 
 
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/Region.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/Region.java
similarity index 89%
rename from hibernate-core/src/main/java/org/hibernate/cache/Region.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/Region.java
index 348e231398..22b9292373 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/Region.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/Region.java
@@ -1,99 +1,101 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache;
-import java.util.Map;
-
-/**
- * Defines a contract for accessing a particular named region within the 
- * underlying cache implementation.
- *
- * @author Steve Ebersole
- */
-public interface Region {
-	/**
-	 * Retrieve the name of this region.
-	 *
-	 * @return The region name
-	 */
-	public String getName();
-
-	/**
-	 * The "end state" contract of the region's lifecycle.  Called
-	 * during {@link org.hibernate.SessionFactory#close()} to give
-	 * the region a chance to cleanup.
-	 *
-	 * @throws CacheException Indicates problem shutting down
-	 */
-	public void destroy() throws CacheException;
-
-	/**
-	 * Determine whether this region contains data for the given key.
-	 * <p/>
-	 * The semantic here is whether the cache contains data visible for the
-	 * current call context.  This should be viewed as a "best effort", meaning
-	 * blocking should be avoid if possible.
-	 *
-	 * @param key The cache key
-	 *
-	 * @return True if the underlying cache contains corresponding data; false
-	 * otherwise.
-	 */
-	public boolean contains(Object key);
-
-	/**
-	 * The number of bytes is this cache region currently consuming in memory.
-	 *
-	 * @return The number of bytes consumed by this region; -1 if unknown or
-	 * unsupported.
-	 */
-	public long getSizeInMemory();
-
-	/**
-	 * The count of entries currently contained in the regions in-memory store.
-	 *
-	 * @return The count of entries in memory; -1 if unknown or unsupported.
-	 */
-	public long getElementCountInMemory();
-
-	/**
-	 * The count of entries currently contained in the regions disk store.
-	 *
-	 * @return The count of entries on disk; -1 if unknown or unsupported.
-	 */
-	public long getElementCountOnDisk();
-
-	/**
-	 * Get the contents of this region as a map.
-	 * <p/>
-	 * Implementors which do not support this notion
-	 * should simply return an empty map.
-	 *
-	 * @return The content map.
-	 */
-	public Map toMap();
-
-	public long nextTimestamp();
-	public int getTimeout();
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.spi;
+
+import java.util.Map;
+
+import org.hibernate.cache.CacheException;
+
+/**
+ * Defines a contract for accessing a particular named region within the 
+ * underlying cache implementation.
+ *
+ * @author Steve Ebersole
+ */
+public interface Region {
+	/**
+	 * Retrieve the name of this region.
+	 *
+	 * @return The region name
+	 */
+	public String getName();
+
+	/**
+	 * The "end state" contract of the region's lifecycle.  Called
+	 * during {@link org.hibernate.SessionFactory#close()} to give
+	 * the region a chance to cleanup.
+	 *
+	 * @throws org.hibernate.cache.CacheException Indicates problem shutting down
+	 */
+	public void destroy() throws CacheException;
+
+	/**
+	 * Determine whether this region contains data for the given key.
+	 * <p/>
+	 * The semantic here is whether the cache contains data visible for the
+	 * current call context.  This should be viewed as a "best effort", meaning
+	 * blocking should be avoid if possible.
+	 *
+	 * @param key The cache key
+	 *
+	 * @return True if the underlying cache contains corresponding data; false
+	 * otherwise.
+	 */
+	public boolean contains(Object key);
+
+	/**
+	 * The number of bytes is this cache region currently consuming in memory.
+	 *
+	 * @return The number of bytes consumed by this region; -1 if unknown or
+	 * unsupported.
+	 */
+	public long getSizeInMemory();
+
+	/**
+	 * The count of entries currently contained in the regions in-memory store.
+	 *
+	 * @return The count of entries in memory; -1 if unknown or unsupported.
+	 */
+	public long getElementCountInMemory();
+
+	/**
+	 * The count of entries currently contained in the regions disk store.
+	 *
+	 * @return The count of entries on disk; -1 if unknown or unsupported.
+	 */
+	public long getElementCountOnDisk();
+
+	/**
+	 * Get the contents of this region as a map.
+	 * <p/>
+	 * Implementors which do not support this notion
+	 * should simply return an empty map.
+	 *
+	 * @return The content map.
+	 */
+	public Map toMap();
+
+	public long nextTimestamp();
+	public int getTimeout();
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/spi/RegionFactory.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/RegionFactory.java
new file mode 100644
index 0000000000..be9fae261f
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/RegionFactory.java
@@ -0,0 +1,139 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.spi;
+
+import java.util.Properties;
+
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.access.AccessType;
+import org.hibernate.cfg.Settings;
+
+/**
+ * Contract for building second level cache regions.
+ * <p/>
+ * Implementors should define a constructor in one of two forms:<ul>
+ * <li>MyRegionFactoryImpl({@link java.util.Properties})</li>
+ * <li>MyRegionFactoryImpl()</li>
+ * </ul>
+ * Use the first when we need to read config properties prior to
+ * {@link #start} being called.  For an example, have a look at
+ * {@link org.hibernate.cache.internal.bridge.RegionFactoryCacheProviderBridge}
+ * where we need the properties in order to determine which legacy 
+ * {@link CacheProvider} to use so that we can answer the
+ * {@link #isMinimalPutsEnabledByDefault()} question for the
+ * {@link org.hibernate.cfg.SettingsFactory}.
+ *
+ * @author Steve Ebersole
+ */
+public interface RegionFactory {
+
+	/**
+	 * Lifecycle callback to perform any necessary initialization of the
+	 * underlying cache implementation(s).  Called exactly once during the
+	 * construction of a {@link org.hibernate.internal.SessionFactoryImpl}.
+	 *
+	 * @param settings The settings in effect.
+	 * @param properties The defined cfg properties
+	 * @throws org.hibernate.cache.CacheException Indicates problems starting the L2 cache impl;
+	 * considered as a sign to stop {@link org.hibernate.SessionFactory}
+	 * building.
+	 */
+	public void start(Settings settings, Properties properties) throws CacheException;
+
+	/**
+	 * Lifecycle callback to perform any necessary cleanup of the underlying
+	 * cache implementation(s).  Called exactly once during
+	 * {@link org.hibernate.SessionFactory#close}.
+	 */
+	public void stop();
+
+	/**
+	 * By default should we perform "minimal puts" when using this second
+	 * level cache implementation?
+	 *
+	 * @return True if "minimal puts" should be performed by default; false
+	 * otherwise.
+	 */
+	public boolean isMinimalPutsEnabledByDefault();
+
+	/**
+	 * Get the default access type for {@link EntityRegion entity} and
+	 * {@link CollectionRegion collection} regions.
+	 *
+	 * @return This factory's default access type.
+	 */
+	public AccessType getDefaultAccessType();
+
+	/**
+	 * Generate a timestamp.
+	 * <p/>
+	 * This is generally used for cache content locking/unlocking purposes
+	 * depending upon the access-strategy being used.
+	 *
+	 * @return The generated timestamp.
+	 */
+	public long nextTimestamp();
+
+	/**
+	 * Build a cache region specialized for storing entity data.
+	 *
+	 * @param regionName The name of the region.
+	 * @param properties Configuration properties.
+	 * @param metadata Information regarding the type of data to be cached
+	 * @return The built region
+	 * @throws CacheException Indicates problems building the region.
+	 */
+	public EntityRegion buildEntityRegion(String regionName, Properties properties, CacheDataDescription metadata) throws CacheException;
+
+	/**
+	 * Build a cache region specialized for storing collection data.
+	 *
+	 * @param regionName The name of the region.
+	 * @param properties Configuration properties.
+	 * @param metadata Information regarding the type of data to be cached
+	 * @return The built region
+	 * @throws CacheException Indicates problems building the region.
+	 */
+	public CollectionRegion buildCollectionRegion(String regionName, Properties properties, CacheDataDescription metadata) throws CacheException;
+
+	/**
+	 * Build a cache region specialized for storing query results
+	 *
+	 * @param regionName The name of the region.
+	 * @param properties Configuration properties.
+	 * @return The built region
+	 * @throws CacheException Indicates problems building the region.
+	 */
+	public QueryResultsRegion buildQueryResultsRegion(String regionName, Properties properties) throws CacheException;
+
+	/**
+	 * Build a cache region specialized for storing update-timestamps data.
+	 *
+	 * @param regionName The name of the region.
+	 * @param properties Configuration properties.
+	 * @return The built region
+	 * @throws CacheException Indicates problems building the region.
+	 */
+	public TimestampsRegion buildTimestampsRegion(String regionName, Properties properties) throws CacheException;
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/TimestampsRegion.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/TimestampsRegion.java
similarity index 85%
rename from hibernate-core/src/main/java/org/hibernate/cache/TimestampsRegion.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/TimestampsRegion.java
index af8fc81a4e..37bb645618 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/TimestampsRegion.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/TimestampsRegion.java
@@ -1,35 +1,33 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache;
-
-
-/**
- * Defines the contract for a cache region which will specifically be used to
- * store entity "update timestamps".
- *
- * @author Steve Ebersole
- */
-public interface TimestampsRegion extends GeneralDataRegion {
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.spi;
+
+/**
+ * Defines the contract for a cache region which will specifically be used to
+ * store entity "update timestamps".
+ *
+ * @author Steve Ebersole
+ */
+public interface TimestampsRegion extends GeneralDataRegion {
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/TransactionAwareCache.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/TransactionAwareCache.java
similarity index 80%
rename from hibernate-core/src/main/java/org/hibernate/cache/TransactionAwareCache.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/TransactionAwareCache.java
index d93bbdf3bb..f4edb4074a 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/TransactionAwareCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/TransactionAwareCache.java
@@ -1,36 +1,33 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
-
+package org.hibernate.cache.spi;
 
 /**
- * Marker interface for identifying cache impls which are aware of
- * JTA transactions
+ * Marker interface for identifying {@link Cache} implementations which are aware of JTA transactions
  *
  * @author Steve Ebersole
  */
 public interface TransactionAwareCache {
 }
 
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/TransactionalCache.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/TransactionalCache.java
similarity index 94%
rename from hibernate-core/src/main/java/org/hibernate/cache/TransactionalCache.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/TransactionalCache.java
index d1268901d3..f408404f30 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/TransactionalCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/TransactionalCache.java
@@ -1,181 +1,183 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache;
-import java.util.Comparator;
+package org.hibernate.cache.spi;
 
-import org.hibernate.internal.CoreMessageLogger;
-import org.hibernate.cache.access.SoftLock;
+import java.util.Comparator;
 
 import org.jboss.logging.Logger;
 
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.access.SoftLock;
+import org.hibernate.internal.CoreMessageLogger;
+
 /**
  * Support for fully transactional cache implementations like
  * JBoss TreeCache. Note that this might be a less scalable
  * concurrency strategy than <tt>ReadWriteCache</tt>. This is
  * a "synchronous" concurrency strategy.
  *
  * @author Gavin King
  */
+@Deprecated
 public class TransactionalCache implements CacheConcurrencyStrategy {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, TransactionalCache.class.getName());
 
 	private Cache cache;
 
 	public String getRegionName() {
 		return cache.getRegionName();
 	}
 
 	public Object get(Object key, long txTimestamp) throws CacheException {
         LOG.debugf("Cache lookup: %s", key);
 		Object result = cache.read( key );
         if (result == null) LOG.debugf("Cache miss: %s", key);
         else LOG.debugf("Cache hit: %s", key);
 		return result;
 	}
 
 	public boolean put(
 			Object key,
 	        Object value,
 	        long txTimestamp,
 	        Object version,
 	        Comparator versionComparator,
 	        boolean minimalPut) throws CacheException {
 		if ( minimalPut && cache.read( key ) != null ) {
             LOG.debugf("Item already cached: %s", key);
 			return false;
 		}
         LOG.debugf("Caching: %s", key);
 		if ( cache instanceof OptimisticCache ) {
 			( ( OptimisticCache ) cache ).writeLoad( key, value, version );
 		}
 		else {
 			cache.put( key, value );
 		}
 		return true;
 	}
 
 	/**
 	 * Do nothing, returning null.
 	 */
 	public SoftLock lock(Object key, Object version) throws CacheException {
 		//noop
 		return null;
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public void release(Object key, SoftLock clientLock) throws CacheException {
 		//noop
 	}
 
 	public boolean update(
 			Object key,
 	        Object value,
 	        Object currentVersion,
 	        Object previousVersion) throws CacheException {
         LOG.debugf("Updating: %s", key);
 		if ( cache instanceof OptimisticCache ) {
 			( ( OptimisticCache ) cache ).writeUpdate( key, value, currentVersion, previousVersion );
 		}
 		else {
 			cache.update( key, value );
 		}
 		return true;
 	}
 
 	public boolean insert(
 			Object key,
 	        Object value,
 	        Object currentVersion) throws CacheException {
         LOG.debugf("Inserting: %s", key);
 		if ( cache instanceof OptimisticCache ) {
 			( ( OptimisticCache ) cache ).writeInsert( key, value, currentVersion );
 		}
 		else {
 			cache.update( key, value );
 		}
 		return true;
 	}
 
 	public void evict(Object key) throws CacheException {
 		cache.remove( key );
 	}
 
 	public void remove(Object key) throws CacheException {
         LOG.debugf("Removing: %s", key);
 		cache.remove( key );
 	}
 
 	public void clear() throws CacheException {
         LOG.debugf("Clearing");
 		cache.clear();
 	}
 
 	public void destroy() {
 		try {
 			cache.destroy();
 		}
 		catch ( Exception e ) {
             LOG.unableToDestroyCache(e.getMessage());
 		}
 	}
 
 	public void setCache(Cache cache) {
 		this.cache = cache;
 	}
 
 	public Cache getCache() {
 		return cache;
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public boolean afterInsert(
 			Object key,
 	        Object value,
 	        Object version) throws CacheException {
 		return false;
 	}
 
 	/**
 	 * Do nothing.
 	 */
 	public boolean afterUpdate(
 			Object key,
 	        Object value,
 	        Object version,
 	        SoftLock clientLock) throws CacheException {
 		return false;
 	}
 
 	@Override
     public String toString() {
 		return cache + "(transactional)";
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/TransactionalDataRegion.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/TransactionalDataRegion.java
similarity index 90%
rename from hibernate-core/src/main/java/org/hibernate/cache/TransactionalDataRegion.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/TransactionalDataRegion.java
index c7d9b5f2db..17380f04b1 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/TransactionalDataRegion.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/TransactionalDataRegion.java
@@ -1,56 +1,54 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache;
-
-
-/**
- * Defines contract for regions which hold transactionally-managed data.
- * <p/>
- * The data is not transactionally managed within the region; merely it is
- * transactionally-managed in relation to its association with a particular
- * {@link org.hibernate.Session}.
- *
- * @author Steve Ebersole
- */
-public interface TransactionalDataRegion extends Region {
-	/**
-	 * Is the underlying cache implementation aware of (and "participating in")
-	 * ongoing JTA transactions?
-	 * <p/>
-	 * Regions which report that they are transaction-aware are considered
-	 * "synchronous", in that we assume we can immediately (i.e. synchronously)
-	 * write the changes to the cache and that the cache will properly manage
-	 * application of the written changes within the bounds of ongoing JTA
-	 * transactions.  Conversely, regions reporting false are considered
-	 * "asynchronous", where it is assumed that changes must be manually
-	 * delayed by Hibernate until we are certain that the current transaction
-	 * is successful (i.e. maintaining READ_COMMITTED isolation).
-	 *
-	 * @return True if transaction aware; false otherwise.
-	 */
-	public boolean isTransactionAware();
-
-	public CacheDataDescription getCacheDataDescription();
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.spi;
+
+/**
+ * Defines contract for regions which hold transactionally-managed data.
+ * <p/>
+ * The data is not transactionally managed within the region; merely it is
+ * transactionally-managed in relation to its association with a particular
+ * {@link org.hibernate.Session}.
+ *
+ * @author Steve Ebersole
+ */
+public interface TransactionalDataRegion extends Region {
+	/**
+	 * Is the underlying cache implementation aware of (and "participating in")
+	 * ongoing JTA transactions?
+	 * <p/>
+	 * Regions which report that they are transaction-aware are considered
+	 * "synchronous", in that we assume we can immediately (i.e. synchronously)
+	 * write the changes to the cache and that the cache will properly manage
+	 * application of the written changes within the bounds of ongoing JTA
+	 * transactions.  Conversely, regions reporting false are considered
+	 * "asynchronous", where it is assumed that changes must be manually
+	 * delayed by Hibernate until we are certain that the current transaction
+	 * is successful (i.e. maintaining READ_COMMITTED isolation).
+	 *
+	 * @return True if transaction aware; false otherwise.
+	 */
+	public boolean isTransactionAware();
+
+	public CacheDataDescription getCacheDataDescription();
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/UpdateTimestampsCache.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/UpdateTimestampsCache.java
similarity index 98%
rename from hibernate-core/src/main/java/org/hibernate/cache/UpdateTimestampsCache.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/UpdateTimestampsCache.java
index f40b9a9ac1..f369d421d5 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/UpdateTimestampsCache.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/UpdateTimestampsCache.java
@@ -1,150 +1,153 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.cache;
+package org.hibernate.cache.spi;
+
 import java.io.Serializable;
 import java.util.Properties;
 import java.util.Set;
 import java.util.concurrent.locks.ReentrantReadWriteLock;
-import org.hibernate.HibernateException;
-import org.hibernate.internal.CoreMessageLogger;
-import org.hibernate.cfg.Settings;
 
 import org.jboss.logging.Logger;
 
+import org.hibernate.HibernateException;
+import org.hibernate.cache.CacheException;
+import org.hibernate.cfg.Settings;
+import org.hibernate.internal.CoreMessageLogger;
+
 /**
  * Tracks the timestamps of the most recent updates to particular tables. It is
  * important that the cache timeout of the underlying cache implementation be set
  * to a higher value than the timeouts of any of the query caches. In fact, we
  * recommend that the the underlying cache not be configured for expiry at all.
  * Note, in particular, that an LRU cache expiry policy is never appropriate.
  *
  * @author Gavin King
  * @author Mikheil Kapanadze
  */
 public class UpdateTimestampsCache {
 
 	public static final String REGION_NAME = UpdateTimestampsCache.class.getName();
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                                 UpdateTimestampsCache.class.getName());
 
 	private ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock();
 	private final TimestampsRegion region;
 
 	public UpdateTimestampsCache(Settings settings, Properties props) throws HibernateException {
 		String prefix = settings.getCacheRegionPrefix();
 		String regionName = prefix == null ? REGION_NAME : prefix + '.' + REGION_NAME;
         LOG.startingUpdateTimestampsCache(regionName);
 		this.region = settings.getRegionFactory().buildTimestampsRegion( regionName, props );
 	}
 
 	@SuppressWarnings({"UnnecessaryBoxing"})
 	public void preinvalidate(Serializable[] spaces) throws CacheException {
 		// TODO: to handle concurrent writes correctly, this should return a Lock to the client
 
 		readWriteLock.writeLock().lock();
 
 		try {
 			Long ts = new Long( region.nextTimestamp() + region.getTimeout() );
 			for ( Serializable space : spaces ) {
 	            LOG.debugf("Pre-invalidating space [%s]", space);
 				//put() has nowait semantics, is this really appropriate?
 				//note that it needs to be async replication, never local or sync
 				region.put( space, ts );
 			}
 			//TODO: return new Lock(ts);
 		}
 		finally {
 			readWriteLock.writeLock().unlock();
 		}
 	}
 
 	 @SuppressWarnings({"UnnecessaryBoxing"})
 	public void invalidate(Serializable[] spaces) throws CacheException {
 		//TODO: to handle concurrent writes correctly, the client should pass in a Lock
 
 		readWriteLock.writeLock().lock();
 
 		try {
 			Long ts = new Long( region.nextTimestamp() );
 			//TODO: if lock.getTimestamp().equals(ts)
 			for (Serializable space : spaces) {
 		        LOG.debugf("Invalidating space [%s], timestamp: %s", space, ts);
 		        //put() has nowait semantics, is this really appropriate?
 				//note that it needs to be async replication, never local or sync
 				region.put( space, ts );
 			}
 		}
 		finally {
 		    readWriteLock.writeLock().unlock();
 		}
 	}
 
 	@SuppressWarnings({"unchecked", "UnnecessaryUnboxing"})
 	public boolean isUpToDate(Set spaces, Long timestamp) throws HibernateException {
 		readWriteLock.readLock().lock();
 
 		try {
 			for ( Serializable space : (Set<Serializable>) spaces ) {
 				Long lastUpdate = (Long) region.get( space );
 				if ( lastUpdate == null ) {
 					//the last update timestamp was lost from the cache
 					//(or there were no updates since startup!)
 					//updateTimestamps.put( space, new Long( updateTimestamps.nextTimestamp() ) );
 					//result = false; // safer
 				}
 				else {
 	                LOG.debugf("[%s] last update timestamp: %s", space, lastUpdate + ", result set timestamp: " + timestamp);
 					if ( lastUpdate.longValue() >= timestamp.longValue() ) return false;
 				}
 			}
 			return true;
 		}
 		finally {
 			readWriteLock.readLock().unlock();
 		}
 	}
 
 	public void clear() throws CacheException {
 		region.evictAll();
 	}
 
 	public void destroy() {
 		try {
 			region.destroy();
 		}
 		catch (Exception e) {
             LOG.unableToDestroyUpdateTimestampsCache(region.getName(), e.getMessage());
 		}
 	}
 
 	public TimestampsRegion getRegion() {
 		return region;
 	}
 
 	@Override
     public String toString() {
         return "UpdateTimestampsCache";
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/spi/access/AccessType.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/access/AccessType.java
new file mode 100644
index 0000000000..336a6295f6
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/access/AccessType.java
@@ -0,0 +1,62 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.spi.access;
+
+/**
+ * The types of access strategies available.
+ *
+ * @author Steve Ebersole
+ */
+public enum AccessType {
+	READ_ONLY( "read-only" ),
+	READ_WRITE( "read-write" ),
+	NONSTRICT_READ_WRITE( "nonstrict-read-write" ),
+	TRANSACTIONAL( "transactional" );
+
+	private final String externalName;
+
+	private AccessType(String externalName) {
+		this.externalName = externalName;
+	}
+
+	public String getExternalName() {
+		return externalName;
+	}
+
+	public String toString() {
+		return "AccessType[" + externalName + "]";
+	}
+
+	public static AccessType fromExternalName(String externalName) {
+		if ( externalName == null ) {
+			return null;
+		}
+		for ( AccessType accessType : AccessType.values() ) {
+			if ( accessType.getExternalName().equals( externalName ) ) {
+				return accessType;
+			}
+		}
+		throw new UnknownAccessTypeException( externalName );
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/access/CollectionRegionAccessStrategy.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/access/CollectionRegionAccessStrategy.java
similarity index 89%
rename from hibernate-core/src/main/java/org/hibernate/cache/access/CollectionRegionAccessStrategy.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/access/CollectionRegionAccessStrategy.java
index 07fdc530ff..6f88fd1c6a 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/access/CollectionRegionAccessStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/access/CollectionRegionAccessStrategy.java
@@ -1,172 +1,172 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache.access;
-import org.hibernate.cache.CacheException;
-import org.hibernate.cache.CollectionRegion;
-
-/**
- * Contract for managing transactional and concurrent access to cached collection
- * data.  For cached collection data, all modification actions actually just
- * invalidate the entry(s).  The call sequence here is:
- * {@link #lockItem} -> {@link #remove} -> {@link #unlockItem}
- * <p/>
- * There is another usage pattern that is used to invalidate entries
- * after performing "bulk" HQL/SQL operations:
- * {@link #lockRegion} -> {@link #removeAll} -> {@link #unlockRegion}
- *
- * @author Gavin King
- * @author Steve Ebersole
- */
-public interface CollectionRegionAccessStrategy {
-
-	/**
-	 * Get the wrapped collection cache region
-	 *
-	 * @return The underlying region
-	 */
-	public CollectionRegion getRegion();
-
-	/**
-	 * Attempt to retrieve an object from the cache. Mainly used in attempting
-	 * to resolve entities/collections from the second level cache.
-	 *
-	 * @param key The key of the item to be retrieved.
-	 * @param txTimestamp a timestamp prior to the transaction start time
-	 * @return the cached object or <tt>null</tt>
-	 * @throws org.hibernate.cache.CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public Object get(Object key, long txTimestamp) throws CacheException;
-
-	/**
-	 * Attempt to cache an object, after loading from the database.
-	 *
-	 * @param key The item key
-	 * @param value The item
-	 * @param txTimestamp a timestamp prior to the transaction start time
-	 * @param version the item version number
-	 * @return <tt>true</tt> if the object was successfully cached
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public boolean putFromLoad(
-			Object key,
-			Object value,
-			long txTimestamp,
-			Object version) throws CacheException;
-
-	/**
-	 * Attempt to cache an object, after loading from the database, explicitly
-	 * specifying the minimalPut behavior.
-	 *
-	 * @param key The item key
-	 * @param value The item
-	 * @param txTimestamp a timestamp prior to the transaction start time
-	 * @param version the item version number
-	 * @param minimalPutOverride Explicit minimalPut flag
-	 * @return <tt>true</tt> if the object was successfully cached
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public boolean putFromLoad(
-			Object key,
-			Object value,
-			long txTimestamp,
-			Object version,
-			boolean minimalPutOverride) throws CacheException;
-
-	/**
-	 * We are going to attempt to update/delete the keyed object. This
-	 * method is used by "asynchronous" concurrency strategies.
-	 * <p/>
-	 * The returned object must be passed back to release(), to release the
-	 * lock. Concurrency strategies which do not support client-visible
-	 * locks may silently return null.
-	 *
-	 * @param key The key of the item to lock
-	 * @param version The item's current version value
-	 * @return A representation of our lock on the item; or null.
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public SoftLock lockItem(Object key, Object version) throws CacheException;
-
-	/**
-	 * Lock the entire region
-	 *
-	 * @return A representation of our lock on the item; or null.
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public SoftLock lockRegion() throws CacheException;
-
-	/**
-	 * Called when we have finished the attempted update/delete (which may or
-	 * may not have been successful), after transaction completion.  This method
-	 * is used by "asynchronous" concurrency strategies.
-	 *
-	 * @param key The item key
-	 * @param lock The lock previously obtained from {@link #lockItem}
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public void unlockItem(Object key, SoftLock lock) throws CacheException;
-
-	/**
-	 * Called after we have finished the attempted invalidation of the entire
-	 * region
-	 *
-	 * @param lock The lock previously obtained from {@link #lockRegion}
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public void unlockRegion(SoftLock lock) throws CacheException;
-
-	/**
-	 * Called after an item has become stale (before the transaction completes).
-	 * This method is used by "synchronous" concurrency strategies.
-	 *
-	 * @param key The key of the item to remove
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public void remove(Object key) throws CacheException;
-
-	/**
-	 * Called to evict data from the entire region
-	 *
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public void removeAll() throws CacheException;
-
-	/**
-	 * Forcibly evict an item from the cache immediately without regard for transaction
-	 * isolation.
-	 *
-	 * @param key The key of the item to remove
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public void evict(Object key) throws CacheException;
-
-	/**
-	 * Forcibly evict all items from the cache immediately without regard for transaction
-	 * isolation.
-	 *
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public void evictAll() throws CacheException;
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.spi.access;
+
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.CollectionRegion;
+
+/**
+ * Contract for managing transactional and concurrent access to cached collection
+ * data.  For cached collection data, all modification actions actually just
+ * invalidate the entry(s).  The call sequence here is:
+ * {@link #lockItem} -> {@link #remove} -> {@link #unlockItem}
+ * <p/>
+ * There is another usage pattern that is used to invalidate entries
+ * after performing "bulk" HQL/SQL operations:
+ * {@link #lockRegion} -> {@link #removeAll} -> {@link #unlockRegion}
+ *
+ * @author Gavin King
+ * @author Steve Ebersole
+ */
+public interface CollectionRegionAccessStrategy {
+
+	/**
+	 * Get the wrapped collection cache region
+	 *
+	 * @return The underlying region
+	 */
+	public CollectionRegion getRegion();
+
+	/**
+	 * Attempt to retrieve an object from the cache. Mainly used in attempting
+	 * to resolve entities/collections from the second level cache.
+	 *
+	 * @param key The key of the item to be retrieved.
+	 * @param txTimestamp a timestamp prior to the transaction start time
+	 * @return the cached object or <tt>null</tt>
+	 * @throws org.hibernate.cache.CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public Object get(Object key, long txTimestamp) throws CacheException;
+
+	/**
+	 * Attempt to cache an object, after loading from the database.
+	 *
+	 * @param key The item key
+	 * @param value The item
+	 * @param txTimestamp a timestamp prior to the transaction start time
+	 * @param version the item version number
+	 * @return <tt>true</tt> if the object was successfully cached
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public boolean putFromLoad(
+			Object key,
+			Object value,
+			long txTimestamp,
+			Object version) throws CacheException;
+
+	/**
+	 * Attempt to cache an object, after loading from the database, explicitly
+	 * specifying the minimalPut behavior.
+	 *
+	 * @param key The item key
+	 * @param value The item
+	 * @param txTimestamp a timestamp prior to the transaction start time
+	 * @param version the item version number
+	 * @param minimalPutOverride Explicit minimalPut flag
+	 * @return <tt>true</tt> if the object was successfully cached
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public boolean putFromLoad(
+			Object key,
+			Object value,
+			long txTimestamp,
+			Object version,
+			boolean minimalPutOverride) throws CacheException;
+
+	/**
+	 * We are going to attempt to update/delete the keyed object. This
+	 * method is used by "asynchronous" concurrency strategies.
+	 * <p/>
+	 * The returned object must be passed back to release(), to release the
+	 * lock. Concurrency strategies which do not support client-visible
+	 * locks may silently return null.
+	 *
+	 * @param key The key of the item to lock
+	 * @param version The item's current version value
+	 * @return A representation of our lock on the item; or null.
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public SoftLock lockItem(Object key, Object version) throws CacheException;
+
+	/**
+	 * Lock the entire region
+	 *
+	 * @return A representation of our lock on the item; or null.
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public SoftLock lockRegion() throws CacheException;
+
+	/**
+	 * Called when we have finished the attempted update/delete (which may or
+	 * may not have been successful), after transaction completion.  This method
+	 * is used by "asynchronous" concurrency strategies.
+	 *
+	 * @param key The item key
+	 * @param lock The lock previously obtained from {@link #lockItem}
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public void unlockItem(Object key, SoftLock lock) throws CacheException;
+
+	/**
+	 * Called after we have finished the attempted invalidation of the entire
+	 * region
+	 *
+	 * @param lock The lock previously obtained from {@link #lockRegion}
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public void unlockRegion(SoftLock lock) throws CacheException;
+
+	/**
+	 * Called after an item has become stale (before the transaction completes).
+	 * This method is used by "synchronous" concurrency strategies.
+	 *
+	 * @param key The key of the item to remove
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public void remove(Object key) throws CacheException;
+
+	/**
+	 * Called to evict data from the entire region
+	 *
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public void removeAll() throws CacheException;
+
+	/**
+	 * Forcibly evict an item from the cache immediately without regard for transaction
+	 * isolation.
+	 *
+	 * @param key The key of the item to remove
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public void evict(Object key) throws CacheException;
+
+	/**
+	 * Forcibly evict all items from the cache immediately without regard for transaction
+	 * isolation.
+	 *
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public void evictAll() throws CacheException;
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/access/EntityRegionAccessStrategy.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/access/EntityRegionAccessStrategy.java
similarity index 91%
rename from hibernate-core/src/main/java/org/hibernate/cache/access/EntityRegionAccessStrategy.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/access/EntityRegionAccessStrategy.java
index 678725ac5c..7b110fe46c 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/access/EntityRegionAccessStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/access/EntityRegionAccessStrategy.java
@@ -1,229 +1,229 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache.access;
-import org.hibernate.cache.CacheException;
-import org.hibernate.cache.EntityRegion;
-
-/**
- * Contract for managing transactional and concurrent access to cached entity
- * data.  The expected call sequences related to various operations are:<ul>
- * <li><b>INSERTS</b> : {@link #insert} -> {@link #afterInsert}</li>
- * <li><b>UPDATES</b> : {@link #lockItem} -> {@link #update} -> {@link #afterUpdate}</li>
- * <li><b>DELETES</b> : {@link #lockItem} -> {@link #remove} -> {@link #unlockItem}</li>
- * </ul>
- * <p/>
- * There is another usage pattern that is used to invalidate entries
- * after performing "bulk" HQL/SQL operations:
- * {@link #lockRegion} -> {@link #removeAll} -> {@link #unlockRegion}
- *
- * @author Gavin King
- * @author Steve Ebersole
- */
-public interface EntityRegionAccessStrategy {
-
-	/**
-	 * Get the wrapped entity cache region
-	 *
-	 * @return The underlying region
-	 */
-	public EntityRegion getRegion();
-
-	/**
-	 * Attempt to retrieve an object from the cache. Mainly used in attempting
-	 * to resolve entities/collections from the second level cache.
-	 *
-	 * @param key The key of the item to be retrieved.
-	 * @param txTimestamp a timestamp prior to the transaction start time
-	 * @return the cached object or <tt>null</tt>
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public Object get(Object key, long txTimestamp) throws CacheException;
-
-	/**
-	 * Attempt to cache an object, after loading from the database.
-	 *
-	 * @param key The item key
-	 * @param value The item
-	 * @param txTimestamp a timestamp prior to the transaction start time
-	 * @param version the item version number
-	 * @return <tt>true</tt> if the object was successfully cached
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public boolean putFromLoad(
-			Object key,
-			Object value,
-			long txTimestamp,
-			Object version) throws CacheException;
-
-	/**
-	 * Attempt to cache an object, after loading from the database, explicitly
-	 * specifying the minimalPut behavior.
-	 *
-	 * @param key The item key
-	 * @param value The item
-	 * @param txTimestamp a timestamp prior to the transaction start time
-	 * @param version the item version number
-	 * @param minimalPutOverride Explicit minimalPut flag
-	 * @return <tt>true</tt> if the object was successfully cached
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public boolean putFromLoad(
-			Object key,
-			Object value,
-			long txTimestamp,
-			Object version,
-			boolean minimalPutOverride) throws CacheException;
-
-	/**
-	 * We are going to attempt to update/delete the keyed object. This
-	 * method is used by "asynchronous" concurrency strategies.
-	 * <p/>
-	 * The returned object must be passed back to release(), to release the
-	 * lock. Concurrency strategies which do not support client-visible
-	 * locks may silently return null.
-	 *
-	 * @param key The key of the item to lock
-	 * @param version The item's current version value
-	 * @return A representation of our lock on the item; or null.
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public SoftLock lockItem(Object key, Object version) throws CacheException;
-
-	/**
-	 * Lock the entire region
-	 *
-	 * @return A representation of our lock on the item; or null.
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public SoftLock lockRegion() throws CacheException;
-
-	/**
-	 * Called when we have finished the attempted update/delete (which may or
-	 * may not have been successful), after transaction completion.  This method
-	 * is used by "asynchronous" concurrency strategies.
-	 *
-	 * @param key The item key
-	 * @param lock The lock previously obtained from {@link #lockItem}
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public void unlockItem(Object key, SoftLock lock) throws CacheException;
-
-	/**
-	 * Called after we have finished the attempted invalidation of the entire
-	 * region
-	 *
-	 * @param lock The lock previously obtained from {@link #lockRegion}
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public void unlockRegion(SoftLock lock) throws CacheException;
-
-	/**
-	 * Called after an item has been inserted (before the transaction completes),
-	 * instead of calling evict().
-	 * This method is used by "synchronous" concurrency strategies.
-	 *
-	 * @param key The item key
-	 * @param value The item
-	 * @param version The item's version value
-	 * @return Were the contents of the cache actual changed by this operation?
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public boolean insert(Object key, Object value, Object version) throws CacheException;
-
-	/**
-	 * Called after an item has been inserted (after the transaction completes),
-	 * instead of calling release().
-	 * This method is used by "asynchronous" concurrency strategies.
-	 *
-	 * @param key The item key
-	 * @param value The item
-	 * @param version The item's version value
-	 * @return Were the contents of the cache actual changed by this operation?
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public boolean afterInsert(Object key, Object value, Object version) throws CacheException;
-
-	/**
-	 * Called after an item has been updated (before the transaction completes),
-	 * instead of calling evict(). This method is used by "synchronous" concurrency
-	 * strategies.
-	 *
-	 * @param key The item key
-	 * @param value The item
-	 * @param currentVersion The item's current version value
-	 * @param previousVersion The item's previous version value
-	 * @return Were the contents of the cache actual changed by this operation?
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public boolean update(Object key, Object value, Object currentVersion, Object previousVersion) throws CacheException;
-
-	/**
-	 * Called after an item has been updated (after the transaction completes),
-	 * instead of calling release().  This method is used by "asynchronous"
-	 * concurrency strategies.
-	 *
-	 * @param key The item key
-	 * @param value The item
-	 * @param currentVersion The item's current version value
-	 * @param previousVersion The item's previous version value
-	 * @param lock The lock previously obtained from {@link #lockItem}
-	 * @return Were the contents of the cache actual changed by this operation?
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public boolean afterUpdate(Object key, Object value, Object currentVersion, Object previousVersion, SoftLock lock) throws CacheException;
-
-	/**
-	 * Called after an item has become stale (before the transaction completes).
-	 * This method is used by "synchronous" concurrency strategies.
-	 *
-	 * @param key The key of the item to remove
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public void remove(Object key) throws CacheException;
-
-	/**
-	 * Called to evict data from the entire region
-	 *
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public void removeAll() throws CacheException;
-
-	/**
-	 * Forcibly evict an item from the cache immediately without regard for transaction
-	 * isolation.
-	 *
-	 * @param key The key of the item to remove
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public void evict(Object key) throws CacheException;
-
-	/**
-	 * Forcibly evict all items from the cache immediately without regard for transaction
-	 * isolation.
-	 *
-	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.Region}
-	 */
-	public void evictAll() throws CacheException;
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.spi.access;
+
+import org.hibernate.cache.CacheException;
+import org.hibernate.cache.spi.EntityRegion;
+
+/**
+ * Contract for managing transactional and concurrent access to cached entity
+ * data.  The expected call sequences related to various operations are:<ul>
+ * <li><b>INSERTS</b> : {@link #insert} -> {@link #afterInsert}</li>
+ * <li><b>UPDATES</b> : {@link #lockItem} -> {@link #update} -> {@link #afterUpdate}</li>
+ * <li><b>DELETES</b> : {@link #lockItem} -> {@link #remove} -> {@link #unlockItem}</li>
+ * </ul>
+ * <p/>
+ * There is another usage pattern that is used to invalidate entries
+ * after performing "bulk" HQL/SQL operations:
+ * {@link #lockRegion} -> {@link #removeAll} -> {@link #unlockRegion}
+ *
+ * @author Gavin King
+ * @author Steve Ebersole
+ */
+public interface EntityRegionAccessStrategy {
+
+	/**
+	 * Get the wrapped entity cache region
+	 *
+	 * @return The underlying region
+	 */
+	public EntityRegion getRegion();
+
+	/**
+	 * Attempt to retrieve an object from the cache. Mainly used in attempting
+	 * to resolve entities/collections from the second level cache.
+	 *
+	 * @param key The key of the item to be retrieved.
+	 * @param txTimestamp a timestamp prior to the transaction start time
+	 * @return the cached object or <tt>null</tt>
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public Object get(Object key, long txTimestamp) throws CacheException;
+
+	/**
+	 * Attempt to cache an object, after loading from the database.
+	 *
+	 * @param key The item key
+	 * @param value The item
+	 * @param txTimestamp a timestamp prior to the transaction start time
+	 * @param version the item version number
+	 * @return <tt>true</tt> if the object was successfully cached
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public boolean putFromLoad(
+			Object key,
+			Object value,
+			long txTimestamp,
+			Object version) throws CacheException;
+
+	/**
+	 * Attempt to cache an object, after loading from the database, explicitly
+	 * specifying the minimalPut behavior.
+	 *
+	 * @param key The item key
+	 * @param value The item
+	 * @param txTimestamp a timestamp prior to the transaction start time
+	 * @param version the item version number
+	 * @param minimalPutOverride Explicit minimalPut flag
+	 * @return <tt>true</tt> if the object was successfully cached
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public boolean putFromLoad(
+			Object key,
+			Object value,
+			long txTimestamp,
+			Object version,
+			boolean minimalPutOverride) throws CacheException;
+
+	/**
+	 * We are going to attempt to update/delete the keyed object. This
+	 * method is used by "asynchronous" concurrency strategies.
+	 * <p/>
+	 * The returned object must be passed back to release(), to release the
+	 * lock. Concurrency strategies which do not support client-visible
+	 * locks may silently return null.
+	 *
+	 * @param key The key of the item to lock
+	 * @param version The item's current version value
+	 * @return A representation of our lock on the item; or null.
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public SoftLock lockItem(Object key, Object version) throws CacheException;
+
+	/**
+	 * Lock the entire region
+	 *
+	 * @return A representation of our lock on the item; or null.
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public SoftLock lockRegion() throws CacheException;
+
+	/**
+	 * Called when we have finished the attempted update/delete (which may or
+	 * may not have been successful), after transaction completion.  This method
+	 * is used by "asynchronous" concurrency strategies.
+	 *
+	 * @param key The item key
+	 * @param lock The lock previously obtained from {@link #lockItem}
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public void unlockItem(Object key, SoftLock lock) throws CacheException;
+
+	/**
+	 * Called after we have finished the attempted invalidation of the entire
+	 * region
+	 *
+	 * @param lock The lock previously obtained from {@link #lockRegion}
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public void unlockRegion(SoftLock lock) throws CacheException;
+
+	/**
+	 * Called after an item has been inserted (before the transaction completes),
+	 * instead of calling evict().
+	 * This method is used by "synchronous" concurrency strategies.
+	 *
+	 * @param key The item key
+	 * @param value The item
+	 * @param version The item's version value
+	 * @return Were the contents of the cache actual changed by this operation?
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public boolean insert(Object key, Object value, Object version) throws CacheException;
+
+	/**
+	 * Called after an item has been inserted (after the transaction completes),
+	 * instead of calling release().
+	 * This method is used by "asynchronous" concurrency strategies.
+	 *
+	 * @param key The item key
+	 * @param value The item
+	 * @param version The item's version value
+	 * @return Were the contents of the cache actual changed by this operation?
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public boolean afterInsert(Object key, Object value, Object version) throws CacheException;
+
+	/**
+	 * Called after an item has been updated (before the transaction completes),
+	 * instead of calling evict(). This method is used by "synchronous" concurrency
+	 * strategies.
+	 *
+	 * @param key The item key
+	 * @param value The item
+	 * @param currentVersion The item's current version value
+	 * @param previousVersion The item's previous version value
+	 * @return Were the contents of the cache actual changed by this operation?
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public boolean update(Object key, Object value, Object currentVersion, Object previousVersion) throws CacheException;
+
+	/**
+	 * Called after an item has been updated (after the transaction completes),
+	 * instead of calling release().  This method is used by "asynchronous"
+	 * concurrency strategies.
+	 *
+	 * @param key The item key
+	 * @param value The item
+	 * @param currentVersion The item's current version value
+	 * @param previousVersion The item's previous version value
+	 * @param lock The lock previously obtained from {@link #lockItem}
+	 * @return Were the contents of the cache actual changed by this operation?
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public boolean afterUpdate(Object key, Object value, Object currentVersion, Object previousVersion, SoftLock lock) throws CacheException;
+
+	/**
+	 * Called after an item has become stale (before the transaction completes).
+	 * This method is used by "synchronous" concurrency strategies.
+	 *
+	 * @param key The key of the item to remove
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public void remove(Object key) throws CacheException;
+
+	/**
+	 * Called to evict data from the entire region
+	 *
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public void removeAll() throws CacheException;
+
+	/**
+	 * Forcibly evict an item from the cache immediately without regard for transaction
+	 * isolation.
+	 *
+	 * @param key The key of the item to remove
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public void evict(Object key) throws CacheException;
+
+	/**
+	 * Forcibly evict all items from the cache immediately without regard for transaction
+	 * isolation.
+	 *
+	 * @throws CacheException Propogated from underlying {@link org.hibernate.cache.spi.Region}
+	 */
+	public void evictAll() throws CacheException;
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/access/SoftLock.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/access/SoftLock.java
similarity index 79%
rename from hibernate-core/src/main/java/org/hibernate/cache/access/SoftLock.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/access/SoftLock.java
index 02fc359d8b..54ff19a0b0 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/access/SoftLock.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/access/SoftLock.java
@@ -1,35 +1,33 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- *
- */
-package org.hibernate.cache.access;
-
-
-/**
- * Moved up from inner definition on the now deprecated
- * {@link org.hibernate.cache.CacheConcurrencyStrategy}.
- *
- * @author Steve Ebersole
- */
-public interface SoftLock {
-}
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.spi.access;
+
+/**
+ * Moved up from inner definition on the now deprecated
+ * {@link org.hibernate.cache.spi.CacheConcurrencyStrategy}.
+ *
+ * @author Steve Ebersole
+ */
+public interface SoftLock {
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/spi/access/UnknownAccessTypeException.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/access/UnknownAccessTypeException.java
new file mode 100644
index 0000000000..26753d2d5b
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/access/UnknownAccessTypeException.java
@@ -0,0 +1,35 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.cache.spi.access;
+
+import org.hibernate.HibernateException;
+
+/**
+ * @author Steve Ebersole
+ */
+public class UnknownAccessTypeException extends HibernateException {
+	public UnknownAccessTypeException(String accessTypeName) {
+		super( "Unknown access type [" + accessTypeName + "]" );
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/access/package.html b/hibernate-core/src/main/java/org/hibernate/cache/spi/access/package.html
similarity index 98%
rename from hibernate-core/src/main/java/org/hibernate/cache/access/package.html
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/access/package.html
index 048697c6a1..9b6f2e3afe 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/access/package.html
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/access/package.html
@@ -1,66 +1,66 @@
-<!--
-  ~ Hibernate, Relational Persistence for Idiomatic Java
-  ~
-  ~ Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
-  ~ indicated by the @author tags or express copyright attribution
-  ~ statements applied by the authors.  All third-party contributions are
-  ~ distributed under license by Red Hat Middleware LLC.
-  ~
-  ~ This copyrighted material is made available to anyone wishing to use, modify,
-  ~ copy, or redistribute it subject to the terms and conditions of the GNU
-  ~ Lesser General Public License, as published by the Free Software Foundation.
-  ~
-  ~ This program is distributed in the hope that it will be useful,
-  ~ but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
-  ~ or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
-  ~ for more details.
-  ~
-  ~ You should have received a copy of the GNU Lesser General Public License
-  ~ along with this distribution; if not, write to:
-  ~ Free Software Foundation, Inc.
-  ~ 51 Franklin Street, Fifth Floor
-  ~ Boston, MA  02110-1301  USA
-  ~
-  -->
-
-<html>
-<head></head>
-<body>
-<p>
-	Defines contracts for transactional and concurrent access to cached
-    {@link org.hibernate.cache.access.EntityRegionAccessStrategy entity} and
-    {@link org.hibernate.cache.access.CollectionRegionAccessStrategy collection} data.  Transactions pass in a
-    timestamp indicating transaction start time which is then used to protect against concurrent access (exactly how
-    that occurs is based on the actual access-strategy impl used). Two different implementation patterns are provided
-    for.
-    <ul>
-        <li>
-            A transaction-aware cache implementation might be wrapped by a <i>synchronous</i> access strategy,
-            where updates to the cache are written to the cache inside the transaction.
-        </li>
-        <li>
-            A non-transaction-aware cache would be wrapped by an <i>asynchronous</i> access strategy, where items
-            are merely "soft locked" during the transaction and then updated during the "after transaction completion"
-            phase; the soft lock is not an actual lock on the database row - only upon the cached representation of the
-            item.
-        </li>
-    </ul>
-    The <i>asynchronous</i> access strategies are: {@link org.hibernate.cache.access.AccessType.READ_ONLY read-only},
-    {@link org.hibernate.cache.access.AccessType.READ_WRITE read-write} and
-    {@link org.hibernate.cache.access.AccessType.NONSTRICT_READ_WRITE nonstrict-read-write}.  The only
-    <i>synchronous</i> access strategy is {@link org.hibernate.cache.access.AccessType.TRANSACTIONAL transactional}.
-</p>
-<p>
-    Note that, for an <i>asynchronous</i> cache, cache invalidation must be a two step process (lock->unlock or
-    lock->afterUpdate), since this is the only way to guarantee consistency with the database for a nontransactional
-    cache implementation. For a <i>synchronous</i> cache, cache invalidation is a single step process (evict or update).
-    Hence, these contracts ({@link org.hibernate.cache.access.EntityRegionAcessStrategy} and
-    {@link org.hibernate.cache.access.CollectionRegionAccessStrategy}) define a three step process to cater for both 
-    models (see the individual contracts for details).
-</p>
-<p>
-    Note that query result caching does not go through an access strategy; those caches are managed directly against
-    the underlying {@link org.hibernate.cache.QueryResultsRegion}.
-</p>
-</body>
-</html>
+<!--
+  ~ Hibernate, Relational Persistence for Idiomatic Java
+  ~
+  ~ Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+  ~ indicated by the @author tags or express copyright attribution
+  ~ statements applied by the authors.  All third-party contributions are
+  ~ distributed under license by Red Hat Middleware LLC.
+  ~
+  ~ This copyrighted material is made available to anyone wishing to use, modify,
+  ~ copy, or redistribute it subject to the terms and conditions of the GNU
+  ~ Lesser General Public License, as published by the Free Software Foundation.
+  ~
+  ~ This program is distributed in the hope that it will be useful,
+  ~ but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+  ~ or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+  ~ for more details.
+  ~
+  ~ You should have received a copy of the GNU Lesser General Public License
+  ~ along with this distribution; if not, write to:
+  ~ Free Software Foundation, Inc.
+  ~ 51 Franklin Street, Fifth Floor
+  ~ Boston, MA  02110-1301  USA
+  ~
+  -->
+
+<html>
+<head></head>
+<body>
+<p>
+	Defines contracts for transactional and concurrent access to cached
+    {@link org.hibernate.cache.access.EntityRegionAccessStrategy entity} and
+    {@link org.hibernate.cache.access.CollectionRegionAccessStrategy collection} data.  Transactions pass in a
+    timestamp indicating transaction start time which is then used to protect against concurrent access (exactly how
+    that occurs is based on the actual access-strategy impl used). Two different implementation patterns are provided
+    for.
+    <ul>
+        <li>
+            A transaction-aware cache implementation might be wrapped by a <i>synchronous</i> access strategy,
+            where updates to the cache are written to the cache inside the transaction.
+        </li>
+        <li>
+            A non-transaction-aware cache would be wrapped by an <i>asynchronous</i> access strategy, where items
+            are merely "soft locked" during the transaction and then updated during the "after transaction completion"
+            phase; the soft lock is not an actual lock on the database row - only upon the cached representation of the
+            item.
+        </li>
+    </ul>
+    The <i>asynchronous</i> access strategies are: {@link org.hibernate.cache.access.AccessType.READ_ONLY read-only},
+    {@link org.hibernate.cache.access.AccessType.READ_WRITE read-write} and
+    {@link org.hibernate.cache.access.AccessType.NONSTRICT_READ_WRITE nonstrict-read-write}.  The only
+    <i>synchronous</i> access strategy is {@link org.hibernate.cache.access.AccessType.TRANSACTIONAL transactional}.
+</p>
+<p>
+    Note that, for an <i>asynchronous</i> cache, cache invalidation must be a two step process (lock->unlock or
+    lock->afterUpdate), since this is the only way to guarantee consistency with the database for a nontransactional
+    cache implementation. For a <i>synchronous</i> cache, cache invalidation is a single step process (evict or update).
+    Hence, these contracts ({@link org.hibernate.cache.access.EntityRegionAcessStrategy} and
+    {@link org.hibernate.cache.access.CollectionRegionAccessStrategy}) define a three step process to cater for both 
+    models (see the individual contracts for details).
+</p>
+<p>
+    Note that query result caching does not go through an access strategy; those caches are managed directly against
+    the underlying {@link org.hibernate.cache.QueryResultsRegion}.
+</p>
+</body>
+</html>
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/entry/CacheEntry.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/entry/CacheEntry.java
similarity index 99%
rename from hibernate-core/src/main/java/org/hibernate/cache/entry/CacheEntry.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/entry/CacheEntry.java
index bb7ec2c92b..1b7a63724d 100644
--- a/hibernate-core/src/main/java/org/hibernate/cache/entry/CacheEntry.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/entry/CacheEntry.java
@@ -1,171 +1,171 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.cache.entry;
+package org.hibernate.cache.spi.entry;
 
 import java.io.Serializable;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.EventType;
 import org.hibernate.event.PreLoadEvent;
 import org.hibernate.event.PreLoadEventListener;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.event.service.spi.EventListenerGroup;
 import org.hibernate.event.service.spi.EventListenerRegistry;
 import org.hibernate.type.TypeHelper;
 
 /**
  * A cached instance of a persistent class
  *
  * @author Gavin King
  */
 public final class CacheEntry implements Serializable {
 
 	private final Serializable[] disassembledState;
 	private final String subclass;
 	private final boolean lazyPropertiesAreUnfetched;
 	private final Object version;
 	
 	public String getSubclass() {
 		return subclass;
 	}
 	
 	public boolean areLazyPropertiesUnfetched() {
 		return lazyPropertiesAreUnfetched;
 	}
 	
 	public CacheEntry(
 			final Object[] state, 
 			final EntityPersister persister, 
 			final boolean unfetched, 
 			final Object version,
 			final SessionImplementor session, 
 			final Object owner) 
 	throws HibernateException {
 		//disassembled state gets put in a new array (we write to cache by value!)
 		this.disassembledState = TypeHelper.disassemble(
 				state, 
 				persister.getPropertyTypes(), 
 				persister.isLazyPropertiesCacheable() ? 
 					null : persister.getPropertyLaziness(),
 				session, 
 				owner 
 			);
 		subclass = persister.getEntityName();
 		lazyPropertiesAreUnfetched = unfetched || !persister.isLazyPropertiesCacheable();
 		this.version = version;
 	}
 	
 	public Object getVersion() {
 		return version;
 	}
 
 	CacheEntry(Serializable[] state, String subclass, boolean unfetched, Object version) {
 		this.disassembledState = state;
 		this.subclass = subclass;
 		this.lazyPropertiesAreUnfetched = unfetched;
 		this.version = version;
 	}
 
 	public Object[] assemble(
 			final Object instance, 
 			final Serializable id, 
 			final EntityPersister persister, 
 			final Interceptor interceptor, 
 			final EventSource session) 
 	throws HibernateException {
 
 		if ( !persister.getEntityName().equals(subclass) ) {
 			throw new AssertionFailure("Tried to assemble a different subclass instance");
 		}
 
 		return assemble(disassembledState, instance, id, persister, interceptor, session);
 
 	}
 
 	private static Object[] assemble(
 			final Serializable[] values, 
 			final Object result, 
 			final Serializable id, 
 			final EntityPersister persister, 
 			final Interceptor interceptor, 
 			final EventSource session) throws HibernateException {
 			
 		//assembled state gets put in a new array (we read from cache by value!)
 		Object[] assembledProps = TypeHelper.assemble(
 				values, 
 				persister.getPropertyTypes(), 
 				session, result 
 			);
 
 		//persister.setIdentifier(result, id); //before calling interceptor, for consistency with normal load
 
 		//TODO: reuse the PreLoadEvent
 		final PreLoadEvent preLoadEvent = new PreLoadEvent( session )
 				.setEntity( result )
 				.setState( assembledProps )
 				.setId( id )
 				.setPersister( persister );
 
 		final EventListenerGroup<PreLoadEventListener> listenerGroup = session
 				.getFactory()
 				.getServiceRegistry()
 				.getService( EventListenerRegistry.class )
 				.getEventListenerGroup( EventType.PRE_LOAD );
 		for ( PreLoadEventListener listener : listenerGroup.listeners() ) {
 			listener.onPreLoad( preLoadEvent );
 		}
 
 		persister.setPropertyValues( 
 				result, 
 				assembledProps, 
 				session.getEntityMode() 
 			);
 
 		return assembledProps;
 	}
 
     public Serializable[] getDisassembledState() {
 	    // todo: this was added to support initializing an entity's EntityEntry snapshot during reattach;
 	    // this should be refactored to instead expose a method to assemble a EntityEntry based on this
 	    // state for return.
 	    return disassembledState;
     }
 
 	public String toString() {
 		return "CacheEntry(" + subclass + ')' + 
 				ArrayHelper.toString(disassembledState);
 	}
 
 }
 
 
 
 
 
 
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/entry/CacheEntryStructure.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/entry/CacheEntryStructure.java
similarity index 87%
rename from hibernate-core/src/main/java/org/hibernate/cache/entry/CacheEntryStructure.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/entry/CacheEntryStructure.java
index 3a8223a6e8..2558e23b03 100755
--- a/hibernate-core/src/main/java/org/hibernate/cache/entry/CacheEntryStructure.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/entry/CacheEntryStructure.java
@@ -1,35 +1,34 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache.entry;
-import org.hibernate.engine.SessionFactoryImplementor;
+package org.hibernate.cache.spi.entry;
 
+import org.hibernate.engine.SessionFactoryImplementor;
 
 /**
  * @author Gavin King
  */
 public interface CacheEntryStructure {
 	public Object structure(Object item);
 	public Object destructure(Object map, SessionFactoryImplementor factory);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/entry/CollectionCacheEntry.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/entry/CollectionCacheEntry.java
similarity index 91%
rename from hibernate-core/src/main/java/org/hibernate/cache/entry/CollectionCacheEntry.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/entry/CollectionCacheEntry.java
index a24bfc7a99..cf266bdb46 100755
--- a/hibernate-core/src/main/java/org/hibernate/cache/entry/CollectionCacheEntry.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/entry/CollectionCacheEntry.java
@@ -1,64 +1,65 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache.entry;
+package org.hibernate.cache.spi.entry;
+
 import java.io.Serializable;
+
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.persister.collection.CollectionPersister;
 
 /**
  * @author Gavin King
  */
 public class CollectionCacheEntry implements Serializable {
 
 	private final Serializable state;
 	
 	public Serializable[] getState() {
 		//TODO: assumes all collections disassemble to an array!
 		return (Serializable[]) state;
 	}
 
 	public CollectionCacheEntry(PersistentCollection collection, CollectionPersister persister) {
 		this.state = collection.disassemble(persister);
 	}
 	
 	CollectionCacheEntry(Serializable state) {
 		this.state = state;
 	}
 	
 	public void assemble(
 		final PersistentCollection collection, 
 		final CollectionPersister persister,
 		final Object owner
 	) {
 		collection.initializeFromCache(persister, state, owner);
 		collection.afterInitialize();
 	}
 	
 	public String toString() {
 		return "CollectionCacheEntry" + ArrayHelper.toString( getState() );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/entry/StructuredCacheEntry.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/entry/StructuredCacheEntry.java
similarity index 93%
rename from hibernate-core/src/main/java/org/hibernate/cache/entry/StructuredCacheEntry.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/entry/StructuredCacheEntry.java
index 706c50d940..7437ebb28f 100755
--- a/hibernate-core/src/main/java/org/hibernate/cache/entry/StructuredCacheEntry.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/entry/StructuredCacheEntry.java
@@ -1,69 +1,70 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache.entry;
+package org.hibernate.cache.spi.entry;
+
 import java.io.Serializable;
 import java.util.HashMap;
 import java.util.Map;
+
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.persister.entity.EntityPersister;
 
 /**
  * @author Gavin King
  */
 public class StructuredCacheEntry implements CacheEntryStructure {
 
 	private EntityPersister persister;
 
 	public StructuredCacheEntry(EntityPersister persister) {
 		this.persister = persister;
 	}
 	
 	public Object destructure(Object item, SessionFactoryImplementor factory) {
 		Map map = (Map) item;
 		boolean lazyPropertiesUnfetched = ( (Boolean) map.get("_lazyPropertiesUnfetched") ).booleanValue();
 		String subclass = (String) map.get("_subclass");
 		Object version = map.get("_version");
 		EntityPersister subclassPersister = factory.getEntityPersister(subclass);
 		String[] names = subclassPersister.getPropertyNames();
 		Serializable[] state = new Serializable[names.length];
 		for ( int i=0; i<names.length; i++ ) {
 			state[i] = (Serializable) map.get( names[i] );
 		}
 		return new CacheEntry(state, subclass, lazyPropertiesUnfetched, version);
 	}
 
 	public Object structure(Object item) {
 		CacheEntry entry = (CacheEntry) item;
 		String[] names = persister.getPropertyNames();
 		Map map = new HashMap(names.length+2);
 		map.put( "_subclass", entry.getSubclass() );
 		map.put( "_version", entry.getVersion() );
 		map.put( "_lazyPropertiesUnfetched", entry.areLazyPropertiesUnfetched() ? Boolean.TRUE : Boolean.FALSE );
 		for ( int i=0; i<names.length; i++ ) {
 			map.put( names[i], entry.getDisassembledState()[i] );
 		}
 		return map;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/entry/StructuredCollectionCacheEntry.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/entry/StructuredCollectionCacheEntry.java
similarity index 89%
rename from hibernate-core/src/main/java/org/hibernate/cache/entry/StructuredCollectionCacheEntry.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/entry/StructuredCollectionCacheEntry.java
index f610c3ad3e..1642ff2a2f 100755
--- a/hibernate-core/src/main/java/org/hibernate/cache/entry/StructuredCollectionCacheEntry.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/entry/StructuredCollectionCacheEntry.java
@@ -1,46 +1,47 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache.entry;
+package org.hibernate.cache.spi.entry;
+
 import java.io.Serializable;
 import java.util.Arrays;
 import java.util.List;
+
 import org.hibernate.engine.SessionFactoryImplementor;
 
 /**
  * @author Gavin King
  */
 public class StructuredCollectionCacheEntry implements CacheEntryStructure {
 
 	public Object structure(Object item) {
 		CollectionCacheEntry entry = (CollectionCacheEntry) item;
 		return Arrays.asList( entry.getState() );
 	}
 	
 	public Object destructure(Object item, SessionFactoryImplementor factory) {
 		List list = (List) item;
 		return new CollectionCacheEntry( list.toArray( new Serializable[list.size()] ) );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/entry/StructuredMapCacheEntry.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/entry/StructuredMapCacheEntry.java
similarity index 91%
rename from hibernate-core/src/main/java/org/hibernate/cache/entry/StructuredMapCacheEntry.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/entry/StructuredMapCacheEntry.java
index a21a51fdcf..5aaf5a73cc 100755
--- a/hibernate-core/src/main/java/org/hibernate/cache/entry/StructuredMapCacheEntry.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/entry/StructuredMapCacheEntry.java
@@ -1,60 +1,61 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache.entry;
+package org.hibernate.cache.spi.entry;
+
 import java.io.Serializable;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
+
 import org.hibernate.engine.SessionFactoryImplementor;
 
 /**
  * @author Gavin King
  */
 public class StructuredMapCacheEntry implements CacheEntryStructure {
 
 	public Object structure(Object item) {
 		CollectionCacheEntry entry = (CollectionCacheEntry) item;
 		Serializable[] state = entry.getState();
 		Map map = new HashMap(state.length);
 		for ( int i=0; i<state.length; ) {
 			map.put( state[i++], state[i++] );
 		}
 		return map;
 	}
 	
 	public Object destructure(Object item, SessionFactoryImplementor factory) {
 		Map map = (Map) item;
 		Serializable[] state = new Serializable[ map.size()*2 ];
 		int i=0;
 		Iterator iter = map.entrySet().iterator();
 		while ( iter.hasNext() ) {
 			Map.Entry me = (Map.Entry) iter.next();
 			state[i++] = (Serializable) me.getKey();
 			state[i++] = (Serializable) me.getValue();
 		}
 		return new CollectionCacheEntry(state);
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/entry/UnstructuredCacheEntry.java b/hibernate-core/src/main/java/org/hibernate/cache/spi/entry/UnstructuredCacheEntry.java
similarity index 87%
rename from hibernate-core/src/main/java/org/hibernate/cache/entry/UnstructuredCacheEntry.java
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/entry/UnstructuredCacheEntry.java
index c8de0682d9..a0976c51d0 100755
--- a/hibernate-core/src/main/java/org/hibernate/cache/entry/UnstructuredCacheEntry.java
+++ b/hibernate-core/src/main/java/org/hibernate/cache/spi/entry/UnstructuredCacheEntry.java
@@ -1,42 +1,41 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
-package org.hibernate.cache.entry;
-import org.hibernate.engine.SessionFactoryImplementor;
+package org.hibernate.cache.spi.entry;
 
+import org.hibernate.engine.SessionFactoryImplementor;
 
 /**
  * @author Gavin King
  */
 public class UnstructuredCacheEntry implements CacheEntryStructure {
 
 	public Object structure(Object item) {
 		return item;
 	}
 
 	public Object destructure(Object map, SessionFactoryImplementor factory) {
 		return map;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cache/entry/package.html b/hibernate-core/src/main/java/org/hibernate/cache/spi/entry/package.html
similarity index 100%
rename from hibernate-core/src/main/java/org/hibernate/cache/entry/package.html
rename to hibernate-core/src/main/java/org/hibernate/cache/spi/entry/package.html
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/AnnotationBinder.java b/hibernate-core/src/main/java/org/hibernate/cfg/AnnotationBinder.java
index 5fb38d4a2b..0eb2ee5f91 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/AnnotationBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/AnnotationBinder.java
@@ -1,1137 +1,1137 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 import java.lang.annotation.Annotation;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.EnumSet;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import javax.persistence.Basic;
 import javax.persistence.Cacheable;
 import javax.persistence.CollectionTable;
 import javax.persistence.Column;
 import javax.persistence.DiscriminatorType;
 import javax.persistence.DiscriminatorValue;
 import javax.persistence.ElementCollection;
 import javax.persistence.Embeddable;
 import javax.persistence.Embedded;
 import javax.persistence.EmbeddedId;
 import javax.persistence.Entity;
 import javax.persistence.FetchType;
 import javax.persistence.GeneratedValue;
 import javax.persistence.GenerationType;
 import javax.persistence.Id;
 import javax.persistence.IdClass;
 import javax.persistence.InheritanceType;
 import javax.persistence.JoinColumn;
 import javax.persistence.JoinTable;
 import javax.persistence.ManyToMany;
 import javax.persistence.ManyToOne;
 import javax.persistence.MapKey;
 import javax.persistence.MapKeyColumn;
 import javax.persistence.MapKeyJoinColumn;
 import javax.persistence.MapKeyJoinColumns;
 import javax.persistence.MappedSuperclass;
 import javax.persistence.MapsId;
 import javax.persistence.NamedNativeQueries;
 import javax.persistence.NamedNativeQuery;
 import javax.persistence.NamedQueries;
 import javax.persistence.NamedQuery;
 import javax.persistence.OneToMany;
 import javax.persistence.OneToOne;
 import javax.persistence.OrderColumn;
 import javax.persistence.PrimaryKeyJoinColumn;
 import javax.persistence.PrimaryKeyJoinColumns;
 import javax.persistence.SequenceGenerator;
 import javax.persistence.SharedCacheMode;
 import javax.persistence.SqlResultSetMapping;
 import javax.persistence.SqlResultSetMappings;
 import javax.persistence.Table;
 import javax.persistence.TableGenerator;
 import javax.persistence.UniqueConstraint;
 import javax.persistence.Version;
 import org.hibernate.AnnotationException;
 import org.hibernate.AssertionFailure;
 import org.hibernate.EntityMode;
 import org.hibernate.FetchMode;
+import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.annotations.BatchSize;
 import org.hibernate.annotations.Cache;
 import org.hibernate.annotations.CacheConcurrencyStrategy;
 import org.hibernate.annotations.Cascade;
 import org.hibernate.annotations.CascadeType;
 import org.hibernate.annotations.Check;
 import org.hibernate.annotations.CollectionId;
 import org.hibernate.annotations.CollectionOfElements;
 import org.hibernate.annotations.Columns;
 import org.hibernate.annotations.DiscriminatorOptions;
 import org.hibernate.annotations.Fetch;
 import org.hibernate.annotations.FetchProfile;
 import org.hibernate.annotations.FetchProfiles;
 import org.hibernate.annotations.Filter;
 import org.hibernate.annotations.FilterDef;
 import org.hibernate.annotations.FilterDefs;
 import org.hibernate.annotations.Filters;
 import org.hibernate.annotations.ForceDiscriminator;
 import org.hibernate.annotations.ForeignKey;
 import org.hibernate.annotations.Formula;
 import org.hibernate.annotations.GenericGenerator;
 import org.hibernate.annotations.GenericGenerators;
 import org.hibernate.annotations.Index;
 import org.hibernate.annotations.LazyToOne;
 import org.hibernate.annotations.LazyToOneOption;
 import org.hibernate.annotations.ManyToAny;
 import org.hibernate.annotations.MapKeyType;
 import org.hibernate.annotations.NaturalId;
 import org.hibernate.annotations.NotFound;
 import org.hibernate.annotations.NotFoundAction;
 import org.hibernate.annotations.OnDelete;
 import org.hibernate.annotations.OnDeleteAction;
 import org.hibernate.annotations.OrderBy;
 import org.hibernate.annotations.ParamDef;
 import org.hibernate.annotations.Parameter;
 import org.hibernate.annotations.Parent;
 import org.hibernate.annotations.Proxy;
 import org.hibernate.annotations.Sort;
 import org.hibernate.annotations.Source;
 import org.hibernate.annotations.Tuplizer;
 import org.hibernate.annotations.Tuplizers;
 import org.hibernate.annotations.TypeDef;
 import org.hibernate.annotations.TypeDefs;
 import org.hibernate.annotations.Where;
 import org.hibernate.annotations.common.reflection.ReflectionManager;
 import org.hibernate.annotations.common.reflection.XAnnotatedElement;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.annotations.common.reflection.XMethod;
 import org.hibernate.annotations.common.reflection.XPackage;
 import org.hibernate.annotations.common.reflection.XProperty;
-import org.hibernate.cache.RegionFactory;
 import org.hibernate.cfg.annotations.CollectionBinder;
 import org.hibernate.cfg.annotations.EntityBinder;
 import org.hibernate.cfg.annotations.MapKeyColumnDelegator;
 import org.hibernate.cfg.annotations.MapKeyJoinColumnDelegator;
 import org.hibernate.cfg.annotations.Nullability;
 import org.hibernate.cfg.annotations.PropertyBinder;
 import org.hibernate.cfg.annotations.QueryBinder;
 import org.hibernate.cfg.annotations.SimpleValueBinder;
 import org.hibernate.cfg.annotations.TableBinder;
 import org.hibernate.engine.FilterDefinition;
 import org.hibernate.engine.Versioning;
 import org.hibernate.id.MultipleHiLoPerTableGenerator;
 import org.hibernate.id.PersistentIdentifierGenerator;
 import org.hibernate.id.SequenceHiLoGenerator;
 import org.hibernate.id.TableHiLoGenerator;
 import org.hibernate.id.enhanced.SequenceStyleGenerator;
 import org.hibernate.mapping.Any;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.DependantValue;
 import org.hibernate.mapping.IdGenerator;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.JoinedSubclass;
 import org.hibernate.mapping.KeyValue;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.mapping.SingleTableSubclass;
 import org.hibernate.mapping.Subclass;
 import org.hibernate.mapping.ToOne;
 import org.hibernate.mapping.UnionSubclass;
 import org.hibernate.persister.entity.JoinedSubclassEntityPersister;
 import org.hibernate.persister.entity.SingleTableEntityPersister;
 import org.hibernate.persister.entity.UnionSubclassEntityPersister;
 import org.jboss.logging.Logger;
 
 /**
  * JSR 175 annotation binder which reads the annotations from classes, applies the
  * principles of the EJB3 spec and produces the Hibernate configuration-time metamodel
  * (the classes in the {@code org.hibernate.mapping} package)
  *
  * @author Emmanuel Bernard
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public final class AnnotationBinder {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, AnnotationBinder.class.getName());
 
     /*
      * Some design description
      * I tried to remove any link to annotation except from the 2 first level of
      * method call.
      * It'll enable to:
      *   - facilitate annotation overriding
      *   - mutualize one day xml and annotation binder (probably a dream though)
      *   - split this huge class in smaller mapping oriented classes
      *
      * bindSomething usually create the mapping container and is accessed by one of the 2 first level method
      * makeSomething usually create the mapping container and is accessed by bindSomething[else]
      * fillSomething take the container into parameter and fill it.
      */
 
 	private AnnotationBinder() {
 	}
 
 	public static void bindDefaults(Mappings mappings) {
 		Map defaults = mappings.getReflectionManager().getDefaults();
 		{
 			List<SequenceGenerator> anns = ( List<SequenceGenerator> ) defaults.get( SequenceGenerator.class );
 			if ( anns != null ) {
 				for ( SequenceGenerator ann : anns ) {
 					IdGenerator idGen = buildIdGenerator( ann, mappings );
 					if ( idGen != null ) {
 						mappings.addDefaultGenerator( idGen );
 					}
 				}
 			}
 		}
 		{
 			List<TableGenerator> anns = ( List<TableGenerator> ) defaults.get( TableGenerator.class );
 			if ( anns != null ) {
 				for ( TableGenerator ann : anns ) {
 					IdGenerator idGen = buildIdGenerator( ann, mappings );
 					if ( idGen != null ) {
 						mappings.addDefaultGenerator( idGen );
 					}
 				}
 			}
 		}
 		{
 			List<NamedQuery> anns = ( List<NamedQuery> ) defaults.get( NamedQuery.class );
 			if ( anns != null ) {
 				for ( NamedQuery ann : anns ) {
 					QueryBinder.bindQuery( ann, mappings, true );
 				}
 			}
 		}
 		{
 			List<NamedNativeQuery> anns = ( List<NamedNativeQuery> ) defaults.get( NamedNativeQuery.class );
 			if ( anns != null ) {
 				for ( NamedNativeQuery ann : anns ) {
 					QueryBinder.bindNativeQuery( ann, mappings, true );
 				}
 			}
 		}
 		{
 			List<SqlResultSetMapping> anns = ( List<SqlResultSetMapping> ) defaults.get( SqlResultSetMapping.class );
 			if ( anns != null ) {
 				for ( SqlResultSetMapping ann : anns ) {
 					QueryBinder.bindSqlResultsetMapping( ann, mappings, true );
 				}
 			}
 		}
 	}
 
 	public static void bindPackage(String packageName, Mappings mappings) {
 		XPackage pckg;
 		try {
 			pckg = mappings.getReflectionManager().packageForName( packageName );
 		}
 		catch ( ClassNotFoundException cnf ) {
             LOG.packageNotFound(packageName);
 			return;
 		}
 		if ( pckg.isAnnotationPresent( SequenceGenerator.class ) ) {
 			SequenceGenerator ann = pckg.getAnnotation( SequenceGenerator.class );
 			IdGenerator idGen = buildIdGenerator( ann, mappings );
 			mappings.addGenerator( idGen );
             LOG.trace("Add sequence generator with name: " + idGen.getName());
 		}
 		if ( pckg.isAnnotationPresent( TableGenerator.class ) ) {
 			TableGenerator ann = pckg.getAnnotation( TableGenerator.class );
 			IdGenerator idGen = buildIdGenerator( ann, mappings );
 			mappings.addGenerator( idGen );
 
 		}
 		bindGenericGenerators( pckg, mappings );
 		bindQueries( pckg, mappings );
 		bindFilterDefs( pckg, mappings );
 		bindTypeDefs( pckg, mappings );
 		bindFetchProfiles( pckg, mappings );
 		BinderHelper.bindAnyMetaDefs( pckg, mappings );
 	}
 
 	private static void bindGenericGenerators(XAnnotatedElement annotatedElement, Mappings mappings) {
 		GenericGenerator defAnn = annotatedElement.getAnnotation( GenericGenerator.class );
 		GenericGenerators defsAnn = annotatedElement.getAnnotation( GenericGenerators.class );
 		if ( defAnn != null ) {
 			bindGenericGenerator( defAnn, mappings );
 		}
 		if ( defsAnn != null ) {
 			for ( GenericGenerator def : defsAnn.value() ) {
 				bindGenericGenerator( def, mappings );
 			}
 		}
 	}
 
 	private static void bindGenericGenerator(GenericGenerator def, Mappings mappings) {
 		IdGenerator idGen = buildIdGenerator( def, mappings );
 		mappings.addGenerator( idGen );
 	}
 
 	private static void bindQueries(XAnnotatedElement annotatedElement, Mappings mappings) {
 		{
 			SqlResultSetMapping ann = annotatedElement.getAnnotation( SqlResultSetMapping.class );
 			QueryBinder.bindSqlResultsetMapping( ann, mappings, false );
 		}
 		{
 			SqlResultSetMappings ann = annotatedElement.getAnnotation( SqlResultSetMappings.class );
 			if ( ann != null ) {
 				for ( SqlResultSetMapping current : ann.value() ) {
 					QueryBinder.bindSqlResultsetMapping( current, mappings, false );
 				}
 			}
 		}
 		{
 			NamedQuery ann = annotatedElement.getAnnotation( NamedQuery.class );
 			QueryBinder.bindQuery( ann, mappings, false );
 		}
 		{
 			org.hibernate.annotations.NamedQuery ann = annotatedElement.getAnnotation(
 					org.hibernate.annotations.NamedQuery.class
 			);
 			QueryBinder.bindQuery( ann, mappings );
 		}
 		{
 			NamedQueries ann = annotatedElement.getAnnotation( NamedQueries.class );
 			QueryBinder.bindQueries( ann, mappings, false );
 		}
 		{
 			org.hibernate.annotations.NamedQueries ann = annotatedElement.getAnnotation(
 					org.hibernate.annotations.NamedQueries.class
 			);
 			QueryBinder.bindQueries( ann, mappings );
 		}
 		{
 			NamedNativeQuery ann = annotatedElement.getAnnotation( NamedNativeQuery.class );
 			QueryBinder.bindNativeQuery( ann, mappings, false );
 		}
 		{
 			org.hibernate.annotations.NamedNativeQuery ann = annotatedElement.getAnnotation(
 					org.hibernate.annotations.NamedNativeQuery.class
 			);
 			QueryBinder.bindNativeQuery( ann, mappings );
 		}
 		{
 			NamedNativeQueries ann = annotatedElement.getAnnotation( NamedNativeQueries.class );
 			QueryBinder.bindNativeQueries( ann, mappings, false );
 		}
 		{
 			org.hibernate.annotations.NamedNativeQueries ann = annotatedElement.getAnnotation(
 					org.hibernate.annotations.NamedNativeQueries.class
 			);
 			QueryBinder.bindNativeQueries( ann, mappings );
 		}
 	}
 
 	private static IdGenerator buildIdGenerator(java.lang.annotation.Annotation ann, Mappings mappings) {
 		IdGenerator idGen = new IdGenerator();
 		if ( mappings.getSchemaName() != null ) {
 			idGen.addParam( PersistentIdentifierGenerator.SCHEMA, mappings.getSchemaName() );
 		}
 		if ( mappings.getCatalogName() != null ) {
 			idGen.addParam( PersistentIdentifierGenerator.CATALOG, mappings.getCatalogName() );
 		}
 		final boolean useNewGeneratorMappings = mappings.useNewGeneratorMappings();
 		if ( ann == null ) {
 			idGen = null;
 		}
 		else if ( ann instanceof TableGenerator ) {
 			TableGenerator tabGen = ( TableGenerator ) ann;
 			idGen.setName( tabGen.name() );
 			if ( useNewGeneratorMappings ) {
 				idGen.setIdentifierGeneratorStrategy( org.hibernate.id.enhanced.TableGenerator.class.getName() );
 				idGen.addParam( org.hibernate.id.enhanced.TableGenerator.CONFIG_PREFER_SEGMENT_PER_ENTITY, "true" );
 
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.catalog() ) ) {
 					idGen.addParam( PersistentIdentifierGenerator.CATALOG, tabGen.catalog() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.schema() ) ) {
 					idGen.addParam( PersistentIdentifierGenerator.SCHEMA, tabGen.schema() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.table() ) ) {
 					idGen.addParam( org.hibernate.id.enhanced.TableGenerator.TABLE_PARAM, tabGen.table() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.pkColumnName() ) ) {
 					idGen.addParam(
 							org.hibernate.id.enhanced.TableGenerator.SEGMENT_COLUMN_PARAM, tabGen.pkColumnName()
 					);
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.pkColumnValue() ) ) {
 					idGen.addParam(
 							org.hibernate.id.enhanced.TableGenerator.SEGMENT_VALUE_PARAM, tabGen.pkColumnValue()
 					);
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.valueColumnName() ) ) {
 					idGen.addParam(
 							org.hibernate.id.enhanced.TableGenerator.VALUE_COLUMN_PARAM, tabGen.valueColumnName()
 					);
 				}
 				idGen.addParam(
 						org.hibernate.id.enhanced.TableGenerator.INCREMENT_PARAM,
 						String.valueOf( tabGen.allocationSize() )
 				);
 				// See comment on HHH-4884 wrt initialValue.  Basically initialValue is really the stated value + 1
 				idGen.addParam(
 						org.hibernate.id.enhanced.TableGenerator.INITIAL_PARAM,
 						String.valueOf( tabGen.initialValue() + 1 )
 				);
                 if (tabGen.uniqueConstraints() != null && tabGen.uniqueConstraints().length > 0) LOG.warn(tabGen.name());
 			}
 			else {
 				idGen.setIdentifierGeneratorStrategy( MultipleHiLoPerTableGenerator.class.getName() );
 
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.table() ) ) {
 					idGen.addParam( MultipleHiLoPerTableGenerator.ID_TABLE, tabGen.table() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.catalog() ) ) {
 					idGen.addParam( PersistentIdentifierGenerator.CATALOG, tabGen.catalog() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.schema() ) ) {
 					idGen.addParam( PersistentIdentifierGenerator.SCHEMA, tabGen.schema() );
 				}
 				//FIXME implement uniqueconstrains
                 if (tabGen.uniqueConstraints() != null && tabGen.uniqueConstraints().length > 0) LOG.ignoringTableGeneratorConstraints(tabGen.name());
 
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.pkColumnName() ) ) {
 					idGen.addParam( MultipleHiLoPerTableGenerator.PK_COLUMN_NAME, tabGen.pkColumnName() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.valueColumnName() ) ) {
 					idGen.addParam( MultipleHiLoPerTableGenerator.VALUE_COLUMN_NAME, tabGen.valueColumnName() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( tabGen.pkColumnValue() ) ) {
 					idGen.addParam( MultipleHiLoPerTableGenerator.PK_VALUE_NAME, tabGen.pkColumnValue() );
 				}
 				idGen.addParam( TableHiLoGenerator.MAX_LO, String.valueOf( tabGen.allocationSize() - 1 ) );
 			}
             LOG.trace("Add table generator with name: " + idGen.getName());
 		}
 		else if ( ann instanceof SequenceGenerator ) {
 			SequenceGenerator seqGen = ( SequenceGenerator ) ann;
 			idGen.setName( seqGen.name() );
 			if ( useNewGeneratorMappings ) {
 				idGen.setIdentifierGeneratorStrategy( SequenceStyleGenerator.class.getName() );
 
 				if ( !BinderHelper.isEmptyAnnotationValue( seqGen.catalog() ) ) {
 					idGen.addParam( PersistentIdentifierGenerator.CATALOG, seqGen.catalog() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( seqGen.schema() ) ) {
 					idGen.addParam( PersistentIdentifierGenerator.SCHEMA, seqGen.schema() );
 				}
 				if ( !BinderHelper.isEmptyAnnotationValue( seqGen.sequenceName() ) ) {
 					idGen.addParam( SequenceStyleGenerator.SEQUENCE_PARAM, seqGen.sequenceName() );
 				}
 				idGen.addParam( SequenceStyleGenerator.INCREMENT_PARAM, String.valueOf( seqGen.allocationSize() ) );
 				idGen.addParam( SequenceStyleGenerator.INITIAL_PARAM, String.valueOf( seqGen.initialValue() ) );
 			}
 			else {
 				idGen.setIdentifierGeneratorStrategy( "seqhilo" );
 
 				if ( !BinderHelper.isEmptyAnnotationValue( seqGen.sequenceName() ) ) {
 					idGen.addParam( org.hibernate.id.SequenceGenerator.SEQUENCE, seqGen.sequenceName() );
 				}
 				//FIXME: work on initialValue() through SequenceGenerator.PARAMETERS
 				//		steve : or just use o.h.id.enhanced.SequenceStyleGenerator
                 if (seqGen.initialValue() != 1) LOG.unsupportedInitialValue( AvailableSettings.USE_NEW_ID_GENERATOR_MAPPINGS);
 				idGen.addParam( SequenceHiLoGenerator.MAX_LO, String.valueOf( seqGen.allocationSize() - 1 ) );
                 LOG.trace("Add sequence generator with name: " + idGen.getName());
 			}
 		}
 		else if ( ann instanceof GenericGenerator ) {
 			GenericGenerator genGen = ( GenericGenerator ) ann;
 			idGen.setName( genGen.name() );
 			idGen.setIdentifierGeneratorStrategy( genGen.strategy() );
 			Parameter[] params = genGen.parameters();
 			for ( Parameter parameter : params ) {
 				idGen.addParam( parameter.name(), parameter.value() );
 			}
             LOG.trace("Add generic generator with name: " + idGen.getName());
 		}
 		else {
 			throw new AssertionFailure( "Unknown Generator annotation: " + ann );
 		}
 		return idGen;
 	}
 
 	/**
 	 * Bind a class having JSR175 annotations. Subclasses <b>have to</b> be bound after its parent class.
 	 *
 	 * @param clazzToProcess entity to bind as {@code XClass} instance
 	 * @param inheritanceStatePerClass Meta data about the inheritance relationships for all mapped classes
 	 * @param mappings Mapping meta data
 	 *
 	 * @throws MappingException in case there is an configuration error
 	 */
 	public static void bindClass(
 			XClass clazzToProcess,
 			Map<XClass, InheritanceState> inheritanceStatePerClass,
 			Mappings mappings) throws MappingException {
 		//@Entity and @MappedSuperclass on the same class leads to a NPE down the road
 		if ( clazzToProcess.isAnnotationPresent( Entity.class )
 				&&  clazzToProcess.isAnnotationPresent( MappedSuperclass.class ) ) {
 			throw new AnnotationException( "An entity cannot be annotated with both @Entity and @MappedSuperclass: "
 					+ clazzToProcess.getName() );
 		}
 
 		//TODO: be more strict with secondarytable allowance (not for ids, not for secondary table join columns etc)
 		InheritanceState inheritanceState = inheritanceStatePerClass.get( clazzToProcess );
 		AnnotatedClassType classType = mappings.getClassType( clazzToProcess );
 
 		//Queries declared in MappedSuperclass should be usable in Subclasses
 		if ( AnnotatedClassType.EMBEDDABLE_SUPERCLASS.equals( classType ) ) {
 			bindQueries( clazzToProcess, mappings );
 			bindTypeDefs( clazzToProcess, mappings );
 			bindFilterDefs( clazzToProcess, mappings );
 		}
 
 		if ( !isEntityClassType( clazzToProcess, classType ) ) {
 			return;
 		}
 
         LOG.debugf( "Binding entity from annotated class: %s", clazzToProcess.getName() );
 
 		PersistentClass superEntity = getSuperEntity(
 				clazzToProcess, inheritanceStatePerClass, mappings, inheritanceState
 		);
 
 		PersistentClass persistentClass = makePersistentClass( inheritanceState, superEntity );
 		Entity entityAnn = clazzToProcess.getAnnotation( Entity.class );
 		org.hibernate.annotations.Entity hibEntityAnn = clazzToProcess.getAnnotation(
 				org.hibernate.annotations.Entity.class
 		);
 		EntityBinder entityBinder = new EntityBinder(
 				entityAnn, hibEntityAnn, clazzToProcess, persistentClass, mappings
 		);
 		entityBinder.setInheritanceState( inheritanceState );
 
 		bindQueries( clazzToProcess, mappings );
 		bindFilterDefs( clazzToProcess, mappings );
 		bindTypeDefs( clazzToProcess, mappings );
 		bindFetchProfiles( clazzToProcess, mappings );
 		BinderHelper.bindAnyMetaDefs( clazzToProcess, mappings );
 
 		String schema = "";
 		String table = ""; //might be no @Table annotation on the annotated class
 		String catalog = "";
 		List<UniqueConstraintHolder> uniqueConstraints = new ArrayList<UniqueConstraintHolder>();
 		if ( clazzToProcess.isAnnotationPresent( javax.persistence.Table.class ) ) {
 			javax.persistence.Table tabAnn = clazzToProcess.getAnnotation( javax.persistence.Table.class );
 			table = tabAnn.name();
 			schema = tabAnn.schema();
 			catalog = tabAnn.catalog();
 			uniqueConstraints = TableBinder.buildUniqueConstraintHolders( tabAnn.uniqueConstraints() );
 		}
 
 		Ejb3JoinColumn[] inheritanceJoinedColumns = makeInheritanceJoinColumns(
 				clazzToProcess, mappings, inheritanceState, superEntity
 		);
 		Ejb3DiscriminatorColumn discriminatorColumn = null;
 		if ( InheritanceType.SINGLE_TABLE.equals( inheritanceState.getType() ) ) {
 			discriminatorColumn = processDiscriminatorProperties(
 					clazzToProcess, mappings, inheritanceState, entityBinder
 			);
 		}
 
 		entityBinder.setProxy( clazzToProcess.getAnnotation( Proxy.class ) );
 		entityBinder.setBatchSize( clazzToProcess.getAnnotation( BatchSize.class ) );
 		entityBinder.setWhere( clazzToProcess.getAnnotation( Where.class ) );
 	    entityBinder.setCache( determineCacheSettings( clazzToProcess, mappings ) );
 
 		//Filters are not allowed on subclasses
 		if ( !inheritanceState.hasParents() ) {
 			bindFilters( clazzToProcess, entityBinder, mappings );
 		}
 
 		entityBinder.bindEntity();
 
 		if ( inheritanceState.hasTable() ) {
 			Check checkAnn = clazzToProcess.getAnnotation( Check.class );
 			String constraints = checkAnn == null ?
 					null :
 					checkAnn.constraints();
 			entityBinder.bindTable(
 					schema, catalog, table, uniqueConstraints,
 					constraints, inheritanceState.hasDenormalizedTable() ?
 							superEntity.getTable() :
 							null
 			);
         } else if (clazzToProcess.isAnnotationPresent(Table.class)) LOG.invalidTableAnnotation(clazzToProcess.getName());
 
 
 		PropertyHolder propertyHolder = PropertyHolderBuilder.buildPropertyHolder(
 				clazzToProcess,
 				persistentClass,
 				entityBinder, mappings, inheritanceStatePerClass
 		);
 
 		javax.persistence.SecondaryTable secTabAnn = clazzToProcess.getAnnotation(
 				javax.persistence.SecondaryTable.class
 		);
 		javax.persistence.SecondaryTables secTabsAnn = clazzToProcess.getAnnotation(
 				javax.persistence.SecondaryTables.class
 		);
 		entityBinder.firstLevelSecondaryTablesBinding( secTabAnn, secTabsAnn );
 
 		OnDelete onDeleteAnn = clazzToProcess.getAnnotation( OnDelete.class );
 		boolean onDeleteAppropriate = false;
 		if ( InheritanceType.JOINED.equals( inheritanceState.getType() ) && inheritanceState.hasParents() ) {
 			onDeleteAppropriate = true;
 			final JoinedSubclass jsc = ( JoinedSubclass ) persistentClass;
 			if ( persistentClass.getEntityPersisterClass() == null ) {
 				persistentClass.getRootClass().setEntityPersisterClass( JoinedSubclassEntityPersister.class );
 			}
 			SimpleValue key = new DependantValue( mappings, jsc.getTable(), jsc.getIdentifier() );
 			jsc.setKey( key );
 			ForeignKey fk = clazzToProcess.getAnnotation( ForeignKey.class );
 			if ( fk != null && !BinderHelper.isEmptyAnnotationValue( fk.name() ) ) {
 				key.setForeignKeyName( fk.name() );
 			}
 			if ( onDeleteAnn != null ) {
 				key.setCascadeDeleteEnabled( OnDeleteAction.CASCADE.equals( onDeleteAnn.action() ) );
 			}
 			else {
 				key.setCascadeDeleteEnabled( false );
 			}
 			//we are never in a second pass at that stage, so queue it
 			SecondPass sp = new JoinedSubclassFkSecondPass( jsc, inheritanceJoinedColumns, key, mappings );
 			mappings.addSecondPass( sp );
 			mappings.addSecondPass( new CreateKeySecondPass( jsc ) );
 
 		}
 		else if ( InheritanceType.SINGLE_TABLE.equals( inheritanceState.getType() ) ) {
 			if ( inheritanceState.hasParents() ) {
 				if ( persistentClass.getEntityPersisterClass() == null ) {
 					persistentClass.getRootClass().setEntityPersisterClass( SingleTableEntityPersister.class );
 				}
 			}
 			else {
 				if ( inheritanceState.hasSiblings() || !discriminatorColumn.isImplicit() ) {
 					//need a discriminator column
 					bindDiscriminatorToPersistentClass(
 							( RootClass ) persistentClass,
 							discriminatorColumn,
 							entityBinder.getSecondaryTables(),
 							propertyHolder,
 							mappings
 					);
 					entityBinder.bindDiscriminatorValue();//bind it again since the type might have changed
 				}
 			}
 		}
 		else if ( InheritanceType.TABLE_PER_CLASS.equals( inheritanceState.getType() ) ) {
 			if ( inheritanceState.hasParents() ) {
 				if ( persistentClass.getEntityPersisterClass() == null ) {
 					persistentClass.getRootClass().setEntityPersisterClass( UnionSubclassEntityPersister.class );
 				}
 			}
 		}
         if (onDeleteAnn != null && !onDeleteAppropriate) LOG.invalidOnDeleteAnnotation(propertyHolder.getEntityName());
 
 		// try to find class level generators
 		HashMap<String, IdGenerator> classGenerators = buildLocalGenerators( clazzToProcess, mappings );
 
 		// check properties
 		final InheritanceState.ElementsToProcess elementsToProcess = inheritanceState.getElementsToProcess();
 		inheritanceState.postProcess( persistentClass, entityBinder );
 
 		final boolean subclassAndSingleTableStrategy = inheritanceState.getType() == InheritanceType.SINGLE_TABLE
 				&& inheritanceState.hasParents();
 		Set<String> idPropertiesIfIdClass = new HashSet<String>();
 		boolean isIdClass = mapAsIdClass(
 				inheritanceStatePerClass,
 				inheritanceState,
 				persistentClass,
 				entityBinder,
 				propertyHolder,
 				elementsToProcess,
 				idPropertiesIfIdClass,
 				mappings
 		);
 
 		if ( !isIdClass ) {
 			entityBinder.setWrapIdsInEmbeddedComponents( elementsToProcess.getIdPropertyCount() > 1 );
 		}
 
 		processIdPropertiesIfNotAlready(
 				inheritanceStatePerClass,
 				mappings,
 				persistentClass,
 				entityBinder,
 				propertyHolder,
 				classGenerators,
 				elementsToProcess,
 				subclassAndSingleTableStrategy,
 				idPropertiesIfIdClass
 		);
 
 		if ( !inheritanceState.hasParents() ) {
 			final RootClass rootClass = ( RootClass ) persistentClass;
 			mappings.addSecondPass( new CreateKeySecondPass( rootClass ) );
 		}
 		else {
 			superEntity.addSubclass( ( Subclass ) persistentClass );
 		}
 
 		mappings.addClass( persistentClass );
 
 		//Process secondary tables and complementary definitions (ie o.h.a.Table)
 		mappings.addSecondPass( new SecondaryTableSecondPass( entityBinder, propertyHolder, clazzToProcess ) );
 
 		//add process complementary Table definition (index & all)
 		entityBinder.processComplementaryTableDefinitions( clazzToProcess.getAnnotation( org.hibernate.annotations.Table.class ) );
 		entityBinder.processComplementaryTableDefinitions( clazzToProcess.getAnnotation( org.hibernate.annotations.Tables.class ) );
 
 	}
 
 	// parse everything discriminator column relevant in case of single table inheritance
 	private static Ejb3DiscriminatorColumn processDiscriminatorProperties(XClass clazzToProcess, Mappings mappings, InheritanceState inheritanceState, EntityBinder entityBinder) {
 		Ejb3DiscriminatorColumn discriminatorColumn = null;
 		javax.persistence.DiscriminatorColumn discAnn = clazzToProcess.getAnnotation(
 				javax.persistence.DiscriminatorColumn.class
 		);
 		DiscriminatorType discriminatorType = discAnn != null ?
 				discAnn.discriminatorType() :
 				DiscriminatorType.STRING;
 
 		org.hibernate.annotations.DiscriminatorFormula discFormulaAnn = clazzToProcess.getAnnotation(
 				org.hibernate.annotations.DiscriminatorFormula.class
 		);
 		if ( !inheritanceState.hasParents() ) {
 			discriminatorColumn = Ejb3DiscriminatorColumn.buildDiscriminatorColumn(
 					discriminatorType, discAnn, discFormulaAnn, mappings
 			);
 		}
         if (discAnn != null && inheritanceState.hasParents()) LOG.invalidDiscriminatorAnnotation( clazzToProcess.getName() );
 
 		String discrimValue = clazzToProcess.isAnnotationPresent( DiscriminatorValue.class ) ?
 				clazzToProcess.getAnnotation( DiscriminatorValue.class ).value() :
 				null;
 		entityBinder.setDiscriminatorValue( discrimValue );
 
 		if ( clazzToProcess.isAnnotationPresent( ForceDiscriminator.class ) ) {
             LOG.deprecatedForceDescriminatorAnnotation();
 			entityBinder.setForceDiscriminator( true );
 		}
 
 		DiscriminatorOptions discriminatorOptions = clazzToProcess.getAnnotation( DiscriminatorOptions.class );
 		if ( discriminatorOptions != null) {
 			entityBinder.setForceDiscriminator( discriminatorOptions.force() );
 			entityBinder.setInsertableDiscriminator( discriminatorOptions.insert() );
 		}
 
 		return discriminatorColumn;
 	}
 
 	private static void processIdPropertiesIfNotAlready(
 			Map<XClass, InheritanceState> inheritanceStatePerClass,
 			Mappings mappings,
 			PersistentClass persistentClass,
 			EntityBinder entityBinder,
 			PropertyHolder propertyHolder,
 			HashMap<String, IdGenerator> classGenerators,
 			InheritanceState.ElementsToProcess elementsToProcess,
 			boolean subclassAndSingleTableStrategy,
 			Set<String> idPropertiesIfIdClass) {
 		Set<String> missingIdProperties = new HashSet<String>( idPropertiesIfIdClass );
 		for ( PropertyData propertyAnnotatedElement : elementsToProcess.getElements() ) {
 			String propertyName = propertyAnnotatedElement.getPropertyName();
 			if ( !idPropertiesIfIdClass.contains( propertyName ) ) {
 				processElementAnnotations(
 						propertyHolder,
 						subclassAndSingleTableStrategy ?
 								Nullability.FORCED_NULL :
 								Nullability.NO_CONSTRAINT,
 						propertyAnnotatedElement, classGenerators, entityBinder,
 						false, false, false, mappings, inheritanceStatePerClass
 				);
 			}
 			else {
 				missingIdProperties.remove( propertyName );
 			}
 		}
 
 		if ( missingIdProperties.size() != 0 ) {
 			StringBuilder missings = new StringBuilder();
 			for ( String property : missingIdProperties ) {
 				missings.append( property ).append( ", " );
 			}
 			throw new AnnotationException(
 					"Unable to find properties ("
 							+ missings.substring( 0, missings.length() - 2 )
 							+ ") in entity annotated with @IdClass:" + persistentClass.getEntityName()
 			);
 		}
 	}
 
 	private static boolean mapAsIdClass(
 			Map<XClass, InheritanceState> inheritanceStatePerClass,
 			InheritanceState inheritanceState,
 			PersistentClass persistentClass,
 			EntityBinder entityBinder,
 			PropertyHolder propertyHolder,
 			InheritanceState.ElementsToProcess elementsToProcess,
 			Set<String> idPropertiesIfIdClass,
 			Mappings mappings) {
 		/*
 		 * We are looking for @IdClass
 		 * In general we map the id class as identifier using the mapping metadata of the main entity's properties
 		 * and we create an identifier mapper containing the id properties of the main entity
 		 *
 		 * In JPA 2, there is a shortcut if the id class is the Pk of the associated class pointed to by the id
 		 * it ought to be treated as an embedded and not a real IdClass (at least in the Hibernate's internal way
 		 */
 		XClass classWithIdClass = inheritanceState.getClassWithIdClass( false );
 		if ( classWithIdClass != null ) {
 			IdClass idClass = classWithIdClass.getAnnotation( IdClass.class );
 			XClass compositeClass = mappings.getReflectionManager().toXClass( idClass.value() );
 			PropertyData inferredData = new PropertyPreloadedData(
 					entityBinder.getPropertyAccessType(), "id", compositeClass
 			);
 			PropertyData baseInferredData = new PropertyPreloadedData(
 					entityBinder.getPropertyAccessType(), "id", classWithIdClass
 			);
 			AccessType propertyAccessor = entityBinder.getPropertyAccessor( compositeClass );
 			//In JPA 2, there is a shortcut if the IdClass is the Pk of the associated class pointed to by the id
 			//it ought to be treated as an embedded and not a real IdClass (at least in the Hibernate's internal way
 			final boolean isFakeIdClass = isIdClassPkOfTheAssociatedEntity(
 					elementsToProcess,
 					compositeClass,
 					inferredData,
 					baseInferredData,
 					propertyAccessor,
 					inheritanceStatePerClass,
 					mappings
 			);
 
 			if ( isFakeIdClass ) {
 				return false;
 			}
 
 			boolean isComponent = true;
 			String generatorType = "assigned";
 			String generator = BinderHelper.ANNOTATION_STRING_DEFAULT;
 
 			boolean ignoreIdAnnotations = entityBinder.isIgnoreIdAnnotations();
 			entityBinder.setIgnoreIdAnnotations( true );
 			propertyHolder.setInIdClass( true );
 			bindIdClass(
 					generatorType,
 					generator,
 					inferredData,
 					baseInferredData,
 					null,
 					propertyHolder,
 					isComponent,
 					propertyAccessor,
 					entityBinder,
 					true,
 					false,
 					mappings,
 					inheritanceStatePerClass
 			);
 			propertyHolder.setInIdClass( null );
 			inferredData = new PropertyPreloadedData(
 					propertyAccessor, "_identifierMapper", compositeClass
 			);
 			Component mapper = fillComponent(
 					propertyHolder,
 					inferredData,
 					baseInferredData,
 					propertyAccessor,
 					false,
 					entityBinder,
 					true,
 					true,
 					false,
 					mappings,
 					inheritanceStatePerClass
 			);
 			entityBinder.setIgnoreIdAnnotations( ignoreIdAnnotations );
 			persistentClass.setIdentifierMapper( mapper );
 
 			//If id definition is on a mapped superclass, update the mapping
 			final org.hibernate.mapping.MappedSuperclass superclass =
 					BinderHelper.getMappedSuperclassOrNull(
 							inferredData.getDeclaringClass(),
 							inheritanceStatePerClass,
 							mappings
 					);
 			if ( superclass != null ) {
 				superclass.setDeclaredIdentifierMapper( mapper );
 			}
 			else {
 				//we are for sure on the entity
 				persistentClass.setDeclaredIdentifierMapper( mapper );
 			}
 
 			Property property = new Property();
 			property.setName( "_identifierMapper" );
 			property.setNodeName( "id" );
 			property.setUpdateable( false );
 			property.setInsertable( false );
 			property.setValue( mapper );
 			property.setPropertyAccessorName( "embedded" );
 			persistentClass.addProperty( property );
 			entityBinder.setIgnoreIdAnnotations( true );
 
 			Iterator properties = mapper.getPropertyIterator();
 			while ( properties.hasNext() ) {
 				idPropertiesIfIdClass.add( ( ( Property ) properties.next() ).getName() );
 			}
 			return true;
 		}
 		else {
 			return false;
 		}
 	}
 
 	private static boolean isIdClassPkOfTheAssociatedEntity(
 			InheritanceState.ElementsToProcess elementsToProcess,
 			XClass compositeClass,
 			PropertyData inferredData,
 			PropertyData baseInferredData,
 			AccessType propertyAccessor,
 			Map<XClass, InheritanceState> inheritanceStatePerClass,
 			Mappings mappings) {
 		if ( elementsToProcess.getIdPropertyCount() == 1 ) {
 			final PropertyData idPropertyOnBaseClass = getUniqueIdPropertyFromBaseClass(
 					inferredData, baseInferredData, propertyAccessor, mappings
 			);
 			final InheritanceState state = inheritanceStatePerClass.get( idPropertyOnBaseClass.getClassOrElement() );
 			if ( state == null ) {
 				return false; //while it is likely a user error, let's consider it is something that might happen
 			}
 			final XClass associatedClassWithIdClass = state.getClassWithIdClass( true );
 			if ( associatedClassWithIdClass == null ) {
 				//we cannot know for sure here unless we try and find the @EmbeddedId
 				//Let's not do this thorough checking but do some extra validation
 				final XProperty property = idPropertyOnBaseClass.getProperty();
 				return property.isAnnotationPresent( ManyToOne.class )
 						|| property.isAnnotationPresent( OneToOne.class );
 
 			}
 			else {
 				final XClass idClass = mappings.getReflectionManager().toXClass(
 						associatedClassWithIdClass.getAnnotation( IdClass.class ).value()
 				);
 				return idClass.equals( compositeClass );
 			}
 		}
 		else {
 			return false;
 		}
 	}
 
 	private static Cache determineCacheSettings(XClass clazzToProcess, Mappings mappings) {
 		Cache cacheAnn = clazzToProcess.getAnnotation( Cache.class );
 		if ( cacheAnn != null ) {
 			return cacheAnn;
 		}
 
 		Cacheable cacheableAnn = clazzToProcess.getAnnotation( Cacheable.class );
 		SharedCacheMode mode = determineSharedCacheMode( mappings );
 		switch ( mode ) {
 			case ALL: {
 				cacheAnn = buildCacheMock( clazzToProcess.getName(), mappings );
 				break;
 			}
 			case ENABLE_SELECTIVE: {
 				if ( cacheableAnn != null && cacheableAnn.value() ) {
 					cacheAnn = buildCacheMock( clazzToProcess.getName(), mappings );
 				}
 				break;
 			}
 			case DISABLE_SELECTIVE: {
 				if ( cacheableAnn == null || cacheableAnn.value() ) {
 					cacheAnn = buildCacheMock( clazzToProcess.getName(), mappings );
 				}
 				break;
 			}
 			default: {
 				// treat both NONE and UNSPECIFIED the same
 				break;
 			}
 		}
 		return cacheAnn;
 	}
 
 	private static SharedCacheMode determineSharedCacheMode(Mappings mappings) {
 		SharedCacheMode mode;
 		final Object value = mappings.getConfigurationProperties().get( "javax.persistence.sharedCache.mode" );
 		if ( value == null ) {
             LOG.debugf("No value specified for 'javax.persistence.sharedCache.mode'; using UNSPECIFIED");
 			mode = SharedCacheMode.UNSPECIFIED;
 		}
 		else {
 			if ( SharedCacheMode.class.isInstance( value ) ) {
 				mode = ( SharedCacheMode ) value;
 			}
 			else {
 				try {
 					mode = SharedCacheMode.valueOf( value.toString() );
 				}
 				catch ( Exception e ) {
                     LOG.debugf("Unable to resolve given mode name [%s]; using UNSPECIFIED : %s", value, e);
 					mode = SharedCacheMode.UNSPECIFIED;
 				}
 			}
 		}
 		return mode;
 	}
 
 	private static Cache buildCacheMock(String region, Mappings mappings) {
 		return new LocalCacheAnnotationImpl( region, determineCacheConcurrencyStrategy( mappings ) );
 	}
 
 	private static CacheConcurrencyStrategy DEFAULT_CACHE_CONCURRENCY_STRATEGY;
 
 	static void prepareDefaultCacheConcurrencyStrategy(Properties properties) {
 		if ( DEFAULT_CACHE_CONCURRENCY_STRATEGY != null ) {
             LOG.trace("Default cache concurrency strategy already defined");
 			return;
 		}
 
 		if ( !properties.containsKey( AvailableSettings.DEFAULT_CACHE_CONCURRENCY_STRATEGY ) ) {
             LOG.trace("Given properties did not contain any default cache concurrency strategy setting");
 			return;
 		}
 
 		final String strategyName = properties.getProperty( AvailableSettings.DEFAULT_CACHE_CONCURRENCY_STRATEGY );
         LOG.trace("Discovered default cache concurrency strategy via config [" + strategyName + "]");
 		CacheConcurrencyStrategy strategy = CacheConcurrencyStrategy.parse( strategyName );
 		if ( strategy == null ) {
             LOG.trace("Discovered default cache concurrency strategy specified nothing");
 			return;
 		}
 
         LOG.debugf("Setting default cache concurrency strategy via config [%s]", strategy.name());
 		DEFAULT_CACHE_CONCURRENCY_STRATEGY = strategy;
 	}
 
 	private static CacheConcurrencyStrategy determineCacheConcurrencyStrategy(Mappings mappings) {
 		if ( DEFAULT_CACHE_CONCURRENCY_STRATEGY == null ) {
 			final RegionFactory cacheRegionFactory = SettingsFactory.createRegionFactory(
 					mappings.getConfigurationProperties(), true
 			);
 			DEFAULT_CACHE_CONCURRENCY_STRATEGY = CacheConcurrencyStrategy.fromAccessType( cacheRegionFactory.getDefaultAccessType() );
 		}
 		return DEFAULT_CACHE_CONCURRENCY_STRATEGY;
 	}
 
 	@SuppressWarnings({ "ClassExplicitlyAnnotation" })
 	private static class LocalCacheAnnotationImpl implements Cache {
 		private final String region;
 		private final CacheConcurrencyStrategy usage;
 
 		private LocalCacheAnnotationImpl(String region, CacheConcurrencyStrategy usage) {
 			this.region = region;
 			this.usage = usage;
 		}
 
 		public CacheConcurrencyStrategy usage() {
 			return usage;
 		}
 
 		public String region() {
 			return region;
 		}
 
 		public String include() {
 			return "all";
 		}
 
 		public Class<? extends Annotation> annotationType() {
 			return Cache.class;
 		}
 	}
 
 	private static PersistentClass makePersistentClass(InheritanceState inheritanceState, PersistentClass superEntity) {
 		//we now know what kind of persistent entity it is
 		PersistentClass persistentClass;
 		//create persistent class
 		if ( !inheritanceState.hasParents() ) {
 			persistentClass = new RootClass();
 		}
 		else if ( InheritanceType.SINGLE_TABLE.equals( inheritanceState.getType() ) ) {
 			persistentClass = new SingleTableSubclass( superEntity );
 		}
 		else if ( InheritanceType.JOINED.equals( inheritanceState.getType() ) ) {
 			persistentClass = new JoinedSubclass( superEntity );
 		}
 		else if ( InheritanceType.TABLE_PER_CLASS.equals( inheritanceState.getType() ) ) {
 			persistentClass = new UnionSubclass( superEntity );
 		}
 		else {
 			throw new AssertionFailure( "Unknown inheritance type: " + inheritanceState.getType() );
 		}
 		return persistentClass;
 	}
 
 	private static Ejb3JoinColumn[] makeInheritanceJoinColumns(
 			XClass clazzToProcess,
 			Mappings mappings,
 			InheritanceState inheritanceState,
 			PersistentClass superEntity) {
 		Ejb3JoinColumn[] inheritanceJoinedColumns = null;
 		final boolean hasJoinedColumns = inheritanceState.hasParents()
 				&& InheritanceType.JOINED.equals( inheritanceState.getType() );
 		if ( hasJoinedColumns ) {
 			//@Inheritance(JOINED) subclass need to link back to the super entity
 			PrimaryKeyJoinColumns jcsAnn = clazzToProcess.getAnnotation( PrimaryKeyJoinColumns.class );
 			boolean explicitInheritanceJoinedColumns = jcsAnn != null && jcsAnn.value().length != 0;
 			if ( explicitInheritanceJoinedColumns ) {
 				int nbrOfInhJoinedColumns = jcsAnn.value().length;
 				PrimaryKeyJoinColumn jcAnn;
 				inheritanceJoinedColumns = new Ejb3JoinColumn[nbrOfInhJoinedColumns];
 				for ( int colIndex = 0; colIndex < nbrOfInhJoinedColumns; colIndex++ ) {
 					jcAnn = jcsAnn.value()[colIndex];
 					inheritanceJoinedColumns[colIndex] = Ejb3JoinColumn.buildJoinColumn(
 							jcAnn, null, superEntity.getIdentifier(),
 							( Map<String, Join> ) null, ( PropertyHolder ) null, mappings
 					);
 				}
 			}
 			else {
 				PrimaryKeyJoinColumn jcAnn = clazzToProcess.getAnnotation( PrimaryKeyJoinColumn.class );
 				inheritanceJoinedColumns = new Ejb3JoinColumn[1];
 				inheritanceJoinedColumns[0] = Ejb3JoinColumn.buildJoinColumn(
 						jcAnn, null, superEntity.getIdentifier(),
 						( Map<String, Join> ) null, ( PropertyHolder ) null, mappings
 				);
 			}
             LOG.trace("Subclass joined column(s) created");
 		}
 		else {
             if (clazzToProcess.isAnnotationPresent(PrimaryKeyJoinColumns.class)
                 || clazzToProcess.isAnnotationPresent(PrimaryKeyJoinColumn.class)) LOG.invalidPrimaryKeyJoinColumnAnnotation();
 		}
 		return inheritanceJoinedColumns;
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/AvailableSettings.java b/hibernate-core/src/main/java/org/hibernate/cfg/AvailableSettings.java
index 65d1d787cc..27e21e5188 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/AvailableSettings.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/AvailableSettings.java
@@ -1,531 +1,531 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 /**
  * @author Steve Ebersole
  */
 public interface AvailableSettings {
 	/**
 	 * Names a {@literal JNDI} namespace into which the {@link org.hibernate.SessionFactory} should be bound.
 	 */
 	public static final String SESSION_FACTORY_NAME = "hibernate.session_factory_name";
 
 	/**
 	 * Names the {@link org.hibernate.service.jdbc.connections.spi.ConnectionProvider} to use for obtaining
 	 * JDBC connections.  Can either reference an instance of
 	 * {@link org.hibernate.service.jdbc.connections.spi.ConnectionProvider} or a {@link Class} or {@link String}
 	 * reference to the {@link org.hibernate.service.jdbc.connections.spi.ConnectionProvider} implementation
 	 * class.
 	 */
 	public static final String CONNECTION_PROVIDER ="hibernate.connection.provider_class";
 
 	/**
 	 * Names the {@literal JDBC} driver class
 	 */
 	public static final String DRIVER ="hibernate.connection.driver_class";
 
 	/**
 	 * Names the {@literal JDBC} connection url.
 	 */
 	public static final String URL ="hibernate.connection.url";
 
 	/**
 	 * Names the connection user.  This might mean one of 2 things in out-of-the-box Hibernate
 	 * {@link org.hibernate.service.jdbc.connections.spi.ConnectionProvider}: <ul>
 	 *     <li>The username used to pass along to creating the JDBC connection</li>
 	 *     <li>The username used to obtain a JDBC connection from a data source</li>
 	 * </ul>
 	 */
 	public static final String USER ="hibernate.connection.username";
 
 	/**
 	 * Names the connection password.  See usage discussion on {@link #USER}
 	 */
 	public static final String PASS ="hibernate.connection.password";
 
 	/**
 	 * Names the {@literal JDBC} transaction isolation level
 	 */
 	public static final String ISOLATION ="hibernate.connection.isolation";
 
 	/**
 	 * Names the {@literal JDBC} autocommit mode
 	 */
 	public static final String AUTOCOMMIT ="hibernate.connection.autocommit";
 
 	/**
 	 * Maximum number of inactive connections for the built-in Hibernate connection pool.
 	 */
 	public static final String POOL_SIZE ="hibernate.connection.pool_size";
 
 	/**
 	 * Names a {@link javax.sql.DataSource}.  Can either reference a {@link javax.sql.DataSource} instance or
 	 * a {@literal JNDI} name under which to locate the {@link javax.sql.DataSource}.
 	 */
 	public static final String DATASOURCE ="hibernate.connection.datasource";
 
 	/**
 	 * Names a prefix used to define arbitrary JDBC connection properties.  These properties are passed along to
 	 * the {@literal JDBC} provider when creating a connection.
 	 */
 	public static final String CONNECTION_PREFIX = "hibernate.connection";
 
 	/**
 	 * Names the {@literal JNDI} {@link javax.naming.InitialContext} class.
 	 *
 	 * @see javax.naming.Context#INITIAL_CONTEXT_FACTORY
 	 */
 	public static final String JNDI_CLASS ="hibernate.jndi.class";
 
 	/**
 	 * Names the {@literal JNDI} provider/connection url
 	 *
 	 * @see javax.naming.Context#PROVIDER_URL
 	 */
 	public static final String JNDI_URL ="hibernate.jndi.url";
 
 	/**
 	 * Names a prefix used to define arbitrary {@literal JNDI} {@link javax.naming.InitialContext} properties.  These
 	 * properties are passed along to {@link javax.naming.InitialContext#InitialContext(java.util.Hashtable)}
 	 */
 	public static final String JNDI_PREFIX = "hibernate.jndi";
 
 	/**
 	 * Names the Hibernate {@literal SQL} {@link org.hibernate.dialect.Dialect} class
 	 */
 	public static final String DIALECT ="hibernate.dialect";
 
 	/**
 	 * Names any additional {@link org.hibernate.service.jdbc.dialect.spi.DialectResolver} implementations to
 	 * register with the standard {@link org.hibernate.service.jdbc.dialect.spi.DialectFactory}.
 	 */
 	public static final String DIALECT_RESOLVERS = "hibernate.dialect_resolvers";
 
 
 	/**
 	 * A default database schema (owner) name to use for unqualified tablenames
 	 */
 	public static final String DEFAULT_SCHEMA = "hibernate.default_schema";
 	/**
 	 * A default database catalog name to use for unqualified tablenames
 	 */
 	public static final String DEFAULT_CATALOG = "hibernate.default_catalog";
 
 	/**
 	 * Enable logging of generated SQL to the console
 	 */
 	public static final String SHOW_SQL ="hibernate.show_sql";
 	/**
 	 * Enable formatting of SQL logged to the console
 	 */
 	public static final String FORMAT_SQL ="hibernate.format_sql";
 	/**
 	 * Add comments to the generated SQL
 	 */
 	public static final String USE_SQL_COMMENTS ="hibernate.use_sql_comments";
 	/**
 	 * Maximum depth of outer join fetching
 	 */
 	public static final String MAX_FETCH_DEPTH = "hibernate.max_fetch_depth";
 	/**
 	 * The default batch size for batch fetching
 	 */
 	public static final String DEFAULT_BATCH_FETCH_SIZE = "hibernate.default_batch_fetch_size";
 	/**
 	 * Use <tt>java.io</tt> streams to read / write binary data from / to JDBC
 	 */
 	public static final String USE_STREAMS_FOR_BINARY = "hibernate.jdbc.use_streams_for_binary";
 	/**
 	 * Use JDBC scrollable <tt>ResultSet</tt>s. This property is only necessary when there is
 	 * no <tt>ConnectionProvider</tt>, ie. the user is supplying JDBC connections.
 	 */
 	public static final String USE_SCROLLABLE_RESULTSET = "hibernate.jdbc.use_scrollable_resultset";
 	/**
 	 * Tells the JDBC driver to attempt to retrieve row Id with the JDBC 3.0 PreparedStatement.getGeneratedKeys()
 	 * method. In general, performance will be better if this property is set to true and the underlying
 	 * JDBC driver supports getGeneratedKeys().
 	 */
 	public static final String USE_GET_GENERATED_KEYS = "hibernate.jdbc.use_get_generated_keys";
 	/**
 	 * Gives the JDBC driver a hint as to the number of rows that should be fetched from the database
 	 * when more rows are needed. If <tt>0</tt>, JDBC driver default settings will be used.
 	 */
 	public static final String STATEMENT_FETCH_SIZE = "hibernate.jdbc.fetch_size";
 	/**
 	 * Maximum JDBC batch size. A nonzero value enables batch updates.
 	 */
 	public static final String STATEMENT_BATCH_SIZE = "hibernate.jdbc.batch_size";
 	/**
 	 * Select a custom batcher.
 	 */
 	public static final String BATCH_STRATEGY = "hibernate.jdbc.factory_class";
 	/**
 	 * Should versioned data be included in batching?
 	 */
 	public static final String BATCH_VERSIONED_DATA = "hibernate.jdbc.batch_versioned_data";
 	/**
 	 * An XSLT resource used to generate "custom" XML
 	 */
 	public static final String OUTPUT_STYLESHEET ="hibernate.xml.output_stylesheet";
 
 	/**
 	 * Maximum size of C3P0 connection pool
 	 */
 	public static final String C3P0_MAX_SIZE = "hibernate.c3p0.max_size";
 	/**
 	 * Minimum size of C3P0 connection pool
 	 */
 	public static final String C3P0_MIN_SIZE = "hibernate.c3p0.min_size";
 
 	/**
 	 * Maximum idle time for C3P0 connection pool
 	 */
 	public static final String C3P0_TIMEOUT = "hibernate.c3p0.timeout";
 	/**
 	 * Maximum size of C3P0 statement cache
 	 */
 	public static final String C3P0_MAX_STATEMENTS = "hibernate.c3p0.max_statements";
 	/**
 	 * Number of connections acquired when pool is exhausted
 	 */
 	public static final String C3P0_ACQUIRE_INCREMENT = "hibernate.c3p0.acquire_increment";
 	/**
 	 * Idle time before a C3P0 pooled connection is validated
 	 */
 	public static final String C3P0_IDLE_TEST_PERIOD = "hibernate.c3p0.idle_test_period";
 
 	/**
 	 * Proxool/Hibernate property prefix
 	 * @deprecated Use {@link #PROXOOL_CONFIG_PREFIX} instead
 	 */
 	public static final String PROXOOL_PREFIX = "hibernate.proxool";
 	/**
 	 * Proxool property to configure the Proxool Provider using an XML (<tt>/path/to/file.xml</tt>)
 	 */
 	public static final String PROXOOL_XML = "hibernate.proxool.xml";
 	/**
 	 * Proxool property to configure the Proxool Provider  using a properties file (<tt>/path/to/proxool.properties</tt>)
 	 */
 	public static final String PROXOOL_PROPERTIES = "hibernate.proxool.properties";
 	/**
 	 * Proxool property to configure the Proxool Provider from an already existing pool (<tt>true</tt> / <tt>false</tt>)
 	 */
 	public static final String PROXOOL_EXISTING_POOL = "hibernate.proxool.existing_pool";
 	/**
 	 * Proxool property with the Proxool pool alias to use
 	 * (Required for <tt>PROXOOL_EXISTING_POOL</tt>, <tt>PROXOOL_PROPERTIES</tt>, or
 	 * <tt>PROXOOL_XML</tt>)
 	 */
 	public static final String PROXOOL_POOL_ALIAS = "hibernate.proxool.pool_alias";
 
 	/**
 	 * Enable automatic session close at end of transaction
 	 */
 	public static final String AUTO_CLOSE_SESSION = "hibernate.transaction.auto_close_session";
 	/**
 	 * Enable automatic flush during the JTA <tt>beforeCompletion()</tt> callback
 	 */
 	public static final String FLUSH_BEFORE_COMPLETION = "hibernate.transaction.flush_before_completion";
 	/**
 	 * Specifies how Hibernate should release JDBC connections.
 	 */
 	public static final String RELEASE_CONNECTIONS = "hibernate.connection.release_mode";
 	/**
 	 * Context scoping impl for {@link org.hibernate.SessionFactory#getCurrentSession()} processing.
 	 */
 	public static final String CURRENT_SESSION_CONTEXT_CLASS = "hibernate.current_session_context_class";
 
 	/**
 	 * Names the implementation of {@link org.hibernate.engine.transaction.spi.TransactionContext} to use for
 	 * creating {@link org.hibernate.Transaction} instances
 	 */
 	public static final String TRANSACTION_STRATEGY = "hibernate.transaction.factory_class";
 
 	/**
 	 * Names the {@link org.hibernate.service.jta.platform.spi.JtaPlatform} implementation to use for integrating
 	 * with {@literal JTA} systems.  Can reference either a {@link org.hibernate.service.jta.platform.spi.JtaPlatform}
 	 * instance or the name of the {@link org.hibernate.service.jta.platform.spi.JtaPlatform} implementation class
 	 * @since 4.0
 	 */
 	public static final String JTA_PLATFORM = "hibernate.transaction.jta.platform";
 
 	/**
 	 * Names the {@link org.hibernate.transaction.TransactionManagerLookup} implementation to use for obtaining
 	 * reference to the {@literal JTA} {@link javax.transaction.TransactionManager}
 	 *
 	 * @deprecated See {@link #JTA_PLATFORM}
 	 */
 	@Deprecated
 	public static final String TRANSACTION_MANAGER_STRATEGY = "hibernate.transaction.manager_lookup_class";
 
 	/**
 	 * JNDI name of JTA <tt>UserTransaction</tt> object
 	 *
 	 * @deprecated See {@link #JTA_PLATFORM}
 	 */
 	@Deprecated
 	public static final String USER_TRANSACTION = "jta.UserTransaction";
 
 	/**
 	 * The <tt>CacheProvider</tt> implementation class
 	 *
 	 * @deprecated See {@link #CACHE_REGION_FACTORY}
 	 */
 	public static final String CACHE_PROVIDER = "hibernate.cache.provider_class";
 
 	/**
-	 * The {@link org.hibernate.cache.RegionFactory} implementation class
+	 * The {@link org.hibernate.cache.spi.RegionFactory} implementation class
 	 */
 	public static final String CACHE_REGION_FACTORY = "hibernate.cache.region.factory_class";
 
 	/**
 	 * The <tt>CacheProvider</tt> implementation class
 	 */
 	public static final String CACHE_PROVIDER_CONFIG = "hibernate.cache.provider_configuration_file_resource_path";
 	/**
 	 * The <tt>CacheProvider</tt> JNDI namespace, if pre-bound to JNDI.
 	 */
 	public static final String CACHE_NAMESPACE = "hibernate.cache.jndi";
 	/**
 	 * Enable the query cache (disabled by default)
 	 */
 	public static final String USE_QUERY_CACHE = "hibernate.cache.use_query_cache";
 	/**
 	 * The <tt>QueryCacheFactory</tt> implementation class.
 	 */
 	public static final String QUERY_CACHE_FACTORY = "hibernate.cache.query_cache_factory";
 	/**
 	 * Enable the second-level cache (enabled by default)
 	 */
 	public static final String USE_SECOND_LEVEL_CACHE = "hibernate.cache.use_second_level_cache";
 	/**
 	 * Optimize the cache for minimal puts instead of minimal gets
 	 */
 	public static final String USE_MINIMAL_PUTS = "hibernate.cache.use_minimal_puts";
 	/**
 	 * The <tt>CacheProvider</tt> region name prefix
 	 */
 	public static final String CACHE_REGION_PREFIX = "hibernate.cache.region_prefix";
 	/**
 	 * Enable use of structured second-level cache entries
 	 */
 	public static final String USE_STRUCTURED_CACHE = "hibernate.cache.use_structured_entries";
 
 	/**
 	 * Enable statistics collection
 	 */
 	public static final String GENERATE_STATISTICS = "hibernate.generate_statistics";
 
 	public static final String USE_IDENTIFIER_ROLLBACK = "hibernate.use_identifier_rollback";
 
 	/**
 	 * Use bytecode libraries optimized property access
 	 */
 	public static final String USE_REFLECTION_OPTIMIZER = "hibernate.bytecode.use_reflection_optimizer";
 
 	/**
 	 * The classname of the HQL query parser factory
 	 */
 	public static final String QUERY_TRANSLATOR = "hibernate.query.factory_class";
 
 	/**
 	 * A comma-separated list of token substitutions to use when translating a Hibernate
 	 * query to SQL
 	 */
 	public static final String QUERY_SUBSTITUTIONS = "hibernate.query.substitutions";
 
 	/**
 	 * Should named queries be checked during startup (the default is enabled).
 	 * <p/>
 	 * Mainly intended for test environments.
 	 */
 	public static final String QUERY_STARTUP_CHECKING = "hibernate.query.startup_check";
 
 	/**
 	 * Auto export/update schema using hbm2ddl tool. Valid values are <tt>update</tt>,
 	 * <tt>create</tt>, <tt>create-drop</tt> and <tt>validate</tt>.
 	 */
 	public static final String HBM2DDL_AUTO = "hibernate.hbm2ddl.auto";
 
 	/**
 	 * Comma-separated names of the optional files containing SQL DML statements executed
 	 * during the SessionFactory creation.
 	 * File order matters, the statements of a give file are executed before the statements of the
 	 * following files.
 	 *
 	 * These statements are only executed if the schema is created ie if <tt>hibernate.hbm2ddl.auto</tt>
 	 * is set to <tt>create</tt> or <tt>create-drop</tt>.
 	 *
 	 * The default value is <tt>/import.sql</tt>
 	 */
 	public static final String HBM2DDL_IMPORT_FILES = "hibernate.hbm2ddl.import_files";
 
 	/**
 	 * The {@link org.hibernate.exception.SQLExceptionConverter} to use for converting SQLExceptions
 	 * to Hibernate's JDBCException hierarchy.  The default is to use the configured
 	 * {@link org.hibernate.dialect.Dialect}'s preferred SQLExceptionConverter.
 	 */
 	public static final String SQL_EXCEPTION_CONVERTER = "hibernate.jdbc.sql_exception_converter";
 
 	/**
 	 * Enable wrapping of JDBC result sets in order to speed up column name lookups for
 	 * broken JDBC drivers
 	 */
 	public static final String WRAP_RESULT_SETS = "hibernate.jdbc.wrap_result_sets";
 
 	/**
 	 * Enable ordering of update statements by primary key value
 	 */
 	public static final String ORDER_UPDATES = "hibernate.order_updates";
 
 	/**
 	 * Enable ordering of insert statements for the purpose of more efficient JDBC batching.
 	 */
 	public static final String ORDER_INSERTS = "hibernate.order_inserts";
 
 	/**
 	 * The EntityMode in which set the Session opened from the SessionFactory.
 	 */
     public static final String DEFAULT_ENTITY_MODE = "hibernate.default_entity_mode";
 
     /**
      * The jacc context id of the deployment
      */
     public static final String JACC_CONTEXTID = "hibernate.jacc_context_id";
 
 	/**
 	 * Should all database identifiers be quoted.
 	 */
 	public static final String GLOBALLY_QUOTED_IDENTIFIERS = "hibernate.globally_quoted_identifiers";
 
 	/**
 	 * Enable nullability checking.
 	 * Raises an exception if a property marked as not-null is null.
 	 * Default to false if Bean Validation is present in the classpath and Hibernate Annotations is used,
 	 * true otherwise.
 	 */
 	public static final String CHECK_NULLABILITY = "hibernate.check_nullability";
 
 
 	public static final String BYTECODE_PROVIDER = "hibernate.bytecode.provider";
 
 	public static final String JPAQL_STRICT_COMPLIANCE= "hibernate.query.jpaql_strict_compliance";
 
 	/**
 	 * When using pooled {@link org.hibernate.id.enhanced.Optimizer optimizers}, prefer interpreting the
 	 * database value as the lower (lo) boundary.  The default is to interpret it as the high boundary.
 	 */
 	public static final String PREFER_POOLED_VALUES_LO = "hibernate.id.optimizer.pooled.prefer_lo";
 
 	/**
 	 * The maximum number of strong references maintained by {@link org.hibernate.internal.util.collections.SoftLimitMRUCache}. Default is 128.
 	 */
 	public static final String QUERY_PLAN_CACHE_MAX_STRONG_REFERENCES = "hibernate.query.plan_cache_max_strong_references";
 
 	/**
 	 * The maximum number of soft references maintained by {@link org.hibernate.internal.util.collections.SoftLimitMRUCache}. Default is 2048.
 	 */
 	public static final String QUERY_PLAN_CACHE_MAX_SOFT_REFERENCES = "hibernate.query.plan_cache_max_soft_references";
 
 	/**
 	 * Should we not use contextual LOB creation (aka based on {@link java.sql.Connection#createBlob()} et al).
 	 */
 	public static final String NON_CONTEXTUAL_LOB_CREATION = "hibernate.jdbc.lob.non_contextual_creation";
 
 	/**
 	 * Strategy for multi-tenancy.
 
 	 * @see org.hibernate.MultiTenancyStrategy
 	 * @since 4.0
 	 */
 	public static final String MULTI_TENANT = "hibernate.multiTenancy";
 
 	/**
 	 * Names the {@link ClassLoader} used to load user application classes.
 	 * @since 4.0
 	 */
 	public static final String APP_CLASSLOADER = "hibernate.classLoader.application";
 
 	/**
 	 * Names the {@link ClassLoader} Hibernate should use to perform resource loading.
 	 * @since 4.0
 	 */
 	public static final String RESOURCES_CLASSLOADER = "hibernate.classLoader.resources";
 
 	/**
 	 * Names the {@link ClassLoader} responsible for loading Hibernate classes.  By default this is
 	 * the {@link ClassLoader} that loaded this class.
 	 * @since 4.0
 	 */
 	public static final String HIBERNATE_CLASSLOADER = "hibernate.classLoader.hibernate";
 
 	/**
 	 * Names the {@link ClassLoader} used when Hibernate is unable to locates classes on the
 	 * {@link #APP_CLASSLOADER} or {@link #HIBERNATE_CLASSLOADER}.
 	 * @since 4.0
 	 */
 	public static final String ENVIRONMENT_CLASSLOADER = "hibernate.classLoader.environment";
 
 
 	public static final String C3P0_CONFIG_PREFIX = "hibernate.c3p0";
 
 	public static final String PROXOOL_CONFIG_PREFIX = "hibernate.proxool";
 
 
 	public static final String JMX_ENABLED = "hibernate.jmx.enabled";
 	public static final String JMX_PLATFORM_SERVER = "hibernate.jmx.usePlatformServer";
 	public static final String JMX_AGENT_ID = "hibernate.jmx.agentId";
 	public static final String JMX_DOMAIN_NAME = "hibernate.jmx.defaultDomain";
 	public static final String JMX_SF_NAME = "hibernate.jmx.sessionFactoryName";
 	public static final String JMX_DEFAULT_OBJ_NAME_DOMAIN = "org.hibernate.core";
 
 	/**
 	 * A configuration value key used to indicate that it is safe to cache
 	 * {@link javax.transaction.TransactionManager} references.
 	 * @since 4.0
 	 */
 	public static final String JTA_CACHE_TM = "hibernate.jta.cacheTransactionManager";
 
 	/**
 	 * A configuration value key used to indicate that it is safe to cache
 	 * {@link javax.transaction.UserTransaction} references.
 	 * @since 4.0
 	 */
 	public static final String JTA_CACHE_UT = "hibernate.jta.cacheUserTransaction";
 
 	/**
 	 * Setting used to give the name of the default {@link org.hibernate.annotations.CacheConcurrencyStrategy}
 	 * to use when either {@link javax.persistence.Cacheable @Cacheable} or
 	 * {@link org.hibernate.annotations.Cache @Cache} is used.  {@link org.hibernate.annotations.Cache @Cache(strategy="..")} is used to override.
 	 */
 	public static final String DEFAULT_CACHE_CONCURRENCY_STRATEGY = "hibernate.cache.default_cache_concurrency_strategy";
 
 	/**
 	 * Setting which indicates whether or not the new {@link org.hibernate.id.IdentifierGenerator} are used
 	 * for AUTO, TABLE and SEQUENCE.
 	 * Default to false to keep backward compatibility.
 	 */
 	public static final String USE_NEW_ID_GENERATOR_MAPPINGS = "hibernate.id.new_generator_mappings";
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/Environment.java b/hibernate-core/src/main/java/org/hibernate/cfg/Environment.java
index 41a105205f..f5a73c5a9f 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/Environment.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/Environment.java
@@ -1,359 +1,359 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.sql.Connection;
 import java.sql.Timestamp;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Properties;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
 import org.hibernate.Version;
 import org.hibernate.bytecode.spi.BytecodeProvider;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ConfigHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 
 
 /**
  * Provides access to configuration info passed in <tt>Properties</tt> objects.
  * <br><br>
  * Hibernate has two property scopes:
  * <ul>
  * <li><b>Factory-level</b> properties may be passed to the <tt>SessionFactory</tt> when it
  * instantiated. Each instance might have different property values. If no
  * properties are specified, the factory calls <tt>Environment.getProperties()</tt>.
  * <li><b>System-level</b> properties are shared by all factory instances and are always
  * determined by the <tt>Environment</tt> properties.
  * </ul>
  * The only system-level properties are
  * <ul>
  * <li><tt>hibernate.jdbc.use_streams_for_binary</tt>
  * <li><tt>hibernate.cglib.use_reflection_optimizer</tt>
  * </ul>
  * <tt>Environment</tt> properties are populated by calling <tt>System.getProperties()</tt>
  * and then from a resource named <tt>/hibernate.properties</tt> if it exists. System
  * properties override properties specified in <tt>hibernate.properties</tt>.<br>
  * <br>
  * The <tt>SessionFactory</tt> is controlled by the following properties.
  * Properties may be either be <tt>System</tt> properties, properties
  * defined in a resource named <tt>/hibernate.properties</tt> or an instance of
  * <tt>java.util.Properties</tt> passed to
  * <tt>Configuration.buildSessionFactory()</tt><br>
  * <br>
  * <table>
  * <tr><td><b>property</b></td><td><b>meaning</b></td></tr>
  * <tr>
  *   <td><tt>hibernate.dialect</tt></td>
  *   <td>classname of <tt>org.hibernate.dialect.Dialect</tt> subclass</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.cache.provider_class</tt></td>
- *   <td>classname of <tt>org.hibernate.cache.CacheProvider</tt>
+ *   <td>classname of <tt>org.hibernate.cache.spi.CacheProvider</tt>
  *   subclass (if not specified EHCache is used)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.connection.provider_class</tt></td>
  *   <td>classname of <tt>org.hibernate.service.jdbc.connections.spi.ConnectionProvider</tt>
  *   subclass (if not specified hueristics are used)</td>
  * </tr>
  * <tr><td><tt>hibernate.connection.username</tt></td><td>database username</td></tr>
  * <tr><td><tt>hibernate.connection.password</tt></td><td>database password</td></tr>
  * <tr>
  *   <td><tt>hibernate.connection.url</tt></td>
  *   <td>JDBC URL (when using <tt>java.sql.DriverManager</tt>)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.connection.driver_class</tt></td>
  *   <td>classname of JDBC driver</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.connection.isolation</tt></td>
  *   <td>JDBC transaction isolation level (only when using
  *     <tt>java.sql.DriverManager</tt>)
  *   </td>
  * </tr>
  *   <td><tt>hibernate.connection.pool_size</tt></td>
  *   <td>the maximum size of the connection pool (only when using
  *     <tt>java.sql.DriverManager</tt>)
  *   </td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.connection.datasource</tt></td>
  *   <td>databasource JNDI name (when using <tt>javax.sql.Datasource</tt>)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jndi.url</tt></td><td>JNDI <tt>InitialContext</tt> URL</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jndi.class</tt></td><td>JNDI <tt>InitialContext</tt> classname</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.max_fetch_depth</tt></td>
  *   <td>maximum depth of outer join fetching</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jdbc.batch_size</tt></td>
  *   <td>enable use of JDBC2 batch API for drivers which support it</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jdbc.fetch_size</tt></td>
  *   <td>set the JDBC fetch size</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jdbc.use_scrollable_resultset</tt></td>
  *   <td>enable use of JDBC2 scrollable resultsets (you only need this specify
  *   this property when using user supplied connections)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.jdbc.use_getGeneratedKeys</tt></td>
  *   <td>enable use of JDBC3 PreparedStatement.getGeneratedKeys() to retrieve
  *   natively generated keys after insert. Requires JDBC3+ driver and JRE1.4+</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.hbm2ddl.auto</tt></td>
  *   <td>enable auto DDL export</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.default_schema</tt></td>
  *   <td>use given schema name for unqualified tables (always optional)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.default_catalog</tt></td>
  *   <td>use given catalog name for unqualified tables (always optional)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.session_factory_name</tt></td>
  *   <td>If set, the factory attempts to bind this name to itself in the
  *   JNDI context. This name is also used to support cross JVM <tt>
  *   Session</tt> (de)serialization.</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.transaction.manager_lookup_class</tt></td>
  *   <td>classname of <tt>org.hibernate.transaction.TransactionManagerLookup</tt>
  *   implementor</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.transaction.factory_class</tt></td>
  *   <td>the factory to use for instantiating <tt>Transaction</tt>s.
  *   (Defaults to <tt>JdbcTransactionFactory</tt>.)</td>
  * </tr>
  * <tr>
  *   <td><tt>hibernate.query.substitutions</tt></td><td>query language token substitutions</td>
  * </tr>
  * </table>
  *
  * @see org.hibernate.SessionFactory
  * @author Gavin King
  */
 public final class Environment implements AvailableSettings {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Environment.class.getName());
 
 	private static final BytecodeProvider BYTECODE_PROVIDER_INSTANCE;
 	private static final boolean ENABLE_BINARY_STREAMS;
 	private static final boolean ENABLE_REFLECTION_OPTIMIZER;
 	private static final boolean JVM_HAS_TIMESTAMP_BUG;
 
 	private static final Properties GLOBAL_PROPERTIES;
 	private static final HashMap ISOLATION_LEVELS = new HashMap();
 
 	private static final Map OBSOLETE_PROPERTIES = new HashMap();
 	private static final Map RENAMED_PROPERTIES = new HashMap();
 
 	/**
 	 * Issues warnings to the user when any obsolete or renamed property names are used.
 	 *
 	 * @param configurationValues The specified properties.
 	 */
 	public static void verifyProperties(Map<?,?> configurationValues) {
 		final Map propertiesToAdd = new HashMap();
 		for ( Map.Entry entry : configurationValues.entrySet() ) {
 			final Object replacementKey = OBSOLETE_PROPERTIES.get( entry.getKey() );
 			if ( replacementKey != null ) {
 				LOG.unsupportedProperty( entry.getKey(), replacementKey );
 			}
 			final Object renamedKey = RENAMED_PROPERTIES.get( entry.getKey() );
 			if ( renamedKey != null ) {
 				LOG.renamedProperty( entry.getKey(), renamedKey );
 				propertiesToAdd.put( renamedKey, entry.getValue() );
 			}
 		}
 		configurationValues.putAll( propertiesToAdd );
 	}
 
 	static {
 
         LOG.version(Version.getVersionString());
 
 		ISOLATION_LEVELS.put( new Integer(Connection.TRANSACTION_NONE), "NONE" );
 		ISOLATION_LEVELS.put( new Integer(Connection.TRANSACTION_READ_UNCOMMITTED), "READ_UNCOMMITTED" );
 		ISOLATION_LEVELS.put( new Integer(Connection.TRANSACTION_READ_COMMITTED), "READ_COMMITTED" );
 		ISOLATION_LEVELS.put( new Integer(Connection.TRANSACTION_REPEATABLE_READ), "REPEATABLE_READ" );
 		ISOLATION_LEVELS.put( new Integer(Connection.TRANSACTION_SERIALIZABLE), "SERIALIZABLE" );
 
 		GLOBAL_PROPERTIES = new Properties();
 		//Set USE_REFLECTION_OPTIMIZER to false to fix HHH-227
 		GLOBAL_PROPERTIES.setProperty( USE_REFLECTION_OPTIMIZER, Boolean.FALSE.toString() );
 
 		try {
 			InputStream stream = ConfigHelper.getResourceAsStream( "/hibernate.properties" );
 			try {
 				GLOBAL_PROPERTIES.load(stream);
                 LOG.propertiesLoaded(ConfigurationHelper.maskOut(GLOBAL_PROPERTIES, PASS));
 			}
 			catch (Exception e) {
                 LOG.unableToLoadProperties();
 			}
 			finally {
 				try{
 					stream.close();
 				}
 				catch (IOException ioe){
                     LOG.unableToCloseStreamError(ioe);
 				}
 			}
 		}
 		catch (HibernateException he) {
             LOG.propertiesNotFound();
 		}
 
 		try {
 			GLOBAL_PROPERTIES.putAll( System.getProperties() );
 		}
 		catch (SecurityException se) {
             LOG.unableToCopySystemProperties();
 		}
 
 		verifyProperties(GLOBAL_PROPERTIES);
 
 		ENABLE_BINARY_STREAMS = ConfigurationHelper.getBoolean(USE_STREAMS_FOR_BINARY, GLOBAL_PROPERTIES);
         if (ENABLE_BINARY_STREAMS) {
 			LOG.usingStreams();
 		}
 
 		ENABLE_REFLECTION_OPTIMIZER = ConfigurationHelper.getBoolean(USE_REFLECTION_OPTIMIZER, GLOBAL_PROPERTIES);
         if (ENABLE_REFLECTION_OPTIMIZER) {
 			LOG.usingReflectionOptimizer();
 		}
 
 		BYTECODE_PROVIDER_INSTANCE = buildBytecodeProvider( GLOBAL_PROPERTIES );
 
 		long x = 123456789;
 		JVM_HAS_TIMESTAMP_BUG = new Timestamp(x).getTime() != x;
         if (JVM_HAS_TIMESTAMP_BUG) {
 			LOG.usingTimestampWorkaround();
 		}
 	}
 
 	public static BytecodeProvider getBytecodeProvider() {
 		return BYTECODE_PROVIDER_INSTANCE;
 	}
 
 	/**
 	 * Does this JVM's implementation of {@link java.sql.Timestamp} have a bug in which the following is true:<code>
 	 * new java.sql.Timestamp( x ).getTime() != x
 	 * </code>
 	 * <p/>
 	 * NOTE : IBM JDK 1.3.1 the only known JVM to exhibit this behavior.
 	 *
 	 * @return True if the JVM's {@link Timestamp} implementa
 	 */
 	public static boolean jvmHasTimestampBug() {
 		return JVM_HAS_TIMESTAMP_BUG;
 	}
 
 	/**
 	 * Should we use streams to bind binary types to JDBC IN parameters?
 	 *
 	 * @return True if streams should be used for binary data handling; false otherwise.
 	 *
 	 * @see #USE_STREAMS_FOR_BINARY
 	 */
 	public static boolean useStreamsForBinary() {
 		return ENABLE_BINARY_STREAMS;
 	}
 
 	/**
 	 * Should we use reflection optimization?
 	 *
 	 * @return True if reflection optimization should be used; false otherwise.
 	 *
 	 * @see #USE_REFLECTION_OPTIMIZER
 	 * @see #getBytecodeProvider()
 	 * @see BytecodeProvider#getReflectionOptimizer
 	 */
 	public static boolean useReflectionOptimizer() {
 		return ENABLE_REFLECTION_OPTIMIZER;
 	}
 
 	/**
 	 * Disallow instantiation
 	 */
 	private Environment() {
 		throw new UnsupportedOperationException();
 	}
 
 	/**
 	 * Return <tt>System</tt> properties, extended by any properties specified
 	 * in <tt>hibernate.properties</tt>.
 	 * @return Properties
 	 */
 	public static Properties getProperties() {
 		Properties copy = new Properties();
 		copy.putAll(GLOBAL_PROPERTIES);
 		return copy;
 	}
 
 	/**
 	 * Get the name of a JDBC transaction isolation level
 	 *
 	 * @see java.sql.Connection
 	 * @param isolation as defined by <tt>java.sql.Connection</tt>
 	 * @return a human-readable name
 	 */
 	public static String isolationLevelToString(int isolation) {
 		return (String) ISOLATION_LEVELS.get( new Integer(isolation) );
 	}
 
 	public static BytecodeProvider buildBytecodeProvider(Properties properties) {
 		String provider = ConfigurationHelper.getString( BYTECODE_PROVIDER, properties, "javassist" );
         LOG.bytecodeProvider(provider);
 		return buildBytecodeProvider( provider );
 	}
 
 	private static BytecodeProvider buildBytecodeProvider(String providerName) {
 		if ( "javassist".equals( providerName ) ) {
 			return new org.hibernate.bytecode.internal.javassist.BytecodeProviderImpl();
 		}
 
         LOG.unknownBytecodeProvider( providerName );
 		return new org.hibernate.bytecode.internal.javassist.BytecodeProviderImpl();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/Settings.java b/hibernate-core/src/main/java/org/hibernate/cfg/Settings.java
index 3628b4d4ae..dc5664e8da 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/Settings.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/Settings.java
@@ -1,451 +1,451 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import java.util.Map;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.EntityMode;
 import org.hibernate.MultiTenancyStrategy;
-import org.hibernate.cache.QueryCacheFactory;
-import org.hibernate.cache.RegionFactory;
+import org.hibernate.cache.spi.QueryCacheFactory;
+import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.hql.QueryTranslatorFactory;
 import org.hibernate.service.jta.platform.spi.JtaPlatform;
 import org.hibernate.tuple.entity.EntityTuplizerFactory;
 
 /**
  * Settings that affect the behaviour of Hibernate at runtime.
  *
  * @author Gavin King
  */
 public final class Settings {
 
 	private Integer maximumFetchDepth;
 	private Map querySubstitutions;
 	private int jdbcBatchSize;
 	private int defaultBatchFetchSize;
 	private boolean scrollableResultSetsEnabled;
 	private boolean getGeneratedKeysEnabled;
 	private String defaultSchemaName;
 	private String defaultCatalogName;
 	private Integer jdbcFetchSize;
 	private String sessionFactoryName;
 	private boolean autoCreateSchema;
 	private boolean autoDropSchema;
 	private boolean autoUpdateSchema;
 	private boolean autoValidateSchema;
 	private boolean queryCacheEnabled;
 	private boolean structuredCacheEntriesEnabled;
 	private boolean secondLevelCacheEnabled;
 	private String cacheRegionPrefix;
 	private boolean minimalPutsEnabled;
 	private boolean commentsEnabled;
 	private boolean statisticsEnabled;
 	private boolean jdbcBatchVersionedData;
 	private boolean identifierRollbackEnabled;
 	private boolean flushBeforeCompletionEnabled;
 	private boolean autoCloseSessionEnabled;
 	private ConnectionReleaseMode connectionReleaseMode;
 	private RegionFactory regionFactory;
 	private QueryCacheFactory queryCacheFactory;
 	private QueryTranslatorFactory queryTranslatorFactory;
 	private boolean wrapResultSetsEnabled;
 	private boolean orderUpdatesEnabled;
 	private boolean orderInsertsEnabled;
 	private EntityMode defaultEntityMode;
 	private boolean dataDefinitionImplicitCommit;
 	private boolean dataDefinitionInTransactionSupported;
 	private boolean strictJPAQLCompliance;
 	private boolean namedQueryStartupCheckingEnabled;
 	private EntityTuplizerFactory entityTuplizerFactory;
 	private boolean checkNullability;
 //	private ComponentTuplizerFactory componentTuplizerFactory; todo : HHH-3517 and HHH-1907
 //	private BytecodeProvider bytecodeProvider;
 	private String importFiles;
 	private MultiTenancyStrategy multiTenancyStrategy;
 
 	private JtaPlatform jtaPlatform;
 
 	/**
 	 * Package protected constructor
 	 */
 	Settings() {
 	}
 
 	// public getters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public String getImportFiles() {
 		return importFiles;
 	}
 
 	public void setImportFiles(String importFiles) {
 		this.importFiles = importFiles;
 	}
 
 	public String getDefaultSchemaName() {
 		return defaultSchemaName;
 	}
 
 	public String getDefaultCatalogName() {
 		return defaultCatalogName;
 	}
 
 	public int getJdbcBatchSize() {
 		return jdbcBatchSize;
 	}
 
 	public int getDefaultBatchFetchSize() {
 		return defaultBatchFetchSize;
 	}
 
 	public Map getQuerySubstitutions() {
 		return querySubstitutions;
 	}
 
 	public boolean isIdentifierRollbackEnabled() {
 		return identifierRollbackEnabled;
 	}
 
 	public boolean isScrollableResultSetsEnabled() {
 		return scrollableResultSetsEnabled;
 	}
 
 	public boolean isGetGeneratedKeysEnabled() {
 		return getGeneratedKeysEnabled;
 	}
 
 	public boolean isMinimalPutsEnabled() {
 		return minimalPutsEnabled;
 	}
 
 	public Integer getJdbcFetchSize() {
 		return jdbcFetchSize;
 	}
 
 	public String getSessionFactoryName() {
 		return sessionFactoryName;
 	}
 
 	public boolean isAutoCreateSchema() {
 		return autoCreateSchema;
 	}
 
 	public boolean isAutoDropSchema() {
 		return autoDropSchema;
 	}
 
 	public boolean isAutoUpdateSchema() {
 		return autoUpdateSchema;
 	}
 
 	public Integer getMaximumFetchDepth() {
 		return maximumFetchDepth;
 	}
 
 	public RegionFactory getRegionFactory() {
 		return regionFactory;
 	}
 
 	public boolean isQueryCacheEnabled() {
 		return queryCacheEnabled;
 	}
 
 	public boolean isCommentsEnabled() {
 		return commentsEnabled;
 	}
 
 	public boolean isSecondLevelCacheEnabled() {
 		return secondLevelCacheEnabled;
 	}
 
 	public String getCacheRegionPrefix() {
 		return cacheRegionPrefix;
 	}
 
 	public QueryCacheFactory getQueryCacheFactory() {
 		return queryCacheFactory;
 	}
 
 	public boolean isStatisticsEnabled() {
 		return statisticsEnabled;
 	}
 
 	public boolean isJdbcBatchVersionedData() {
 		return jdbcBatchVersionedData;
 	}
 
 	public boolean isFlushBeforeCompletionEnabled() {
 		return flushBeforeCompletionEnabled;
 	}
 
 	public boolean isAutoCloseSessionEnabled() {
 		return autoCloseSessionEnabled;
 	}
 
 	public ConnectionReleaseMode getConnectionReleaseMode() {
 		return connectionReleaseMode;
 	}
 
 	public QueryTranslatorFactory getQueryTranslatorFactory() {
 		return queryTranslatorFactory;
 	}
 
 	public boolean isWrapResultSetsEnabled() {
 		return wrapResultSetsEnabled;
 	}
 
 	public boolean isOrderUpdatesEnabled() {
 		return orderUpdatesEnabled;
 	}
 
 	public boolean isOrderInsertsEnabled() {
 		return orderInsertsEnabled;
 	}
 
 	public boolean isStructuredCacheEntriesEnabled() {
 		return structuredCacheEntriesEnabled;
 	}
 
 	public EntityMode getDefaultEntityMode() {
 		return defaultEntityMode;
 	}
 
 	public boolean isAutoValidateSchema() {
 		return autoValidateSchema;
 	}
 
 	public boolean isDataDefinitionImplicitCommit() {
 		return dataDefinitionImplicitCommit;
 	}
 
 	public boolean isDataDefinitionInTransactionSupported() {
 		return dataDefinitionInTransactionSupported;
 	}
 
 	public boolean isStrictJPAQLCompliance() {
 		return strictJPAQLCompliance;
 	}
 
 	public boolean isNamedQueryStartupCheckingEnabled() {
 		return namedQueryStartupCheckingEnabled;
 	}
 
 	public EntityTuplizerFactory getEntityTuplizerFactory() {
 		return entityTuplizerFactory;
 	}
 
 //	public ComponentTuplizerFactory getComponentTuplizerFactory() {
 //		return componentTuplizerFactory;
 //	}
 
 	// package protected setters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	void setDefaultSchemaName(String string) {
 		defaultSchemaName = string;
 	}
 
 	void setDefaultCatalogName(String string) {
 		defaultCatalogName = string;
 	}
 
 	void setJdbcBatchSize(int i) {
 		jdbcBatchSize = i;
 	}
 
 	void setDefaultBatchFetchSize(int i) {
 		defaultBatchFetchSize = i;
 	}
 
 	void setQuerySubstitutions(Map map) {
 		querySubstitutions = map;
 	}
 
 	void setIdentifierRollbackEnabled(boolean b) {
 		identifierRollbackEnabled = b;
 	}
 
 	void setMinimalPutsEnabled(boolean b) {
 		minimalPutsEnabled = b;
 	}
 
 	void setScrollableResultSetsEnabled(boolean b) {
 		scrollableResultSetsEnabled = b;
 	}
 
 	void setGetGeneratedKeysEnabled(boolean b) {
 		getGeneratedKeysEnabled = b;
 	}
 
 	void setJdbcFetchSize(Integer integer) {
 		jdbcFetchSize = integer;
 	}
 
 	void setSessionFactoryName(String string) {
 		sessionFactoryName = string;
 	}
 
 	void setAutoCreateSchema(boolean b) {
 		autoCreateSchema = b;
 	}
 
 	void setAutoDropSchema(boolean b) {
 		autoDropSchema = b;
 	}
 
 	void setAutoUpdateSchema(boolean b) {
 		autoUpdateSchema = b;
 	}
 
 	void setMaximumFetchDepth(Integer i) {
 		maximumFetchDepth = i;
 	}
 
 	void setRegionFactory(RegionFactory regionFactory) {
 		this.regionFactory = regionFactory;
 	}
 
 	void setQueryCacheEnabled(boolean b) {
 		queryCacheEnabled = b;
 	}
 
 	void setCommentsEnabled(boolean commentsEnabled) {
 		this.commentsEnabled = commentsEnabled;
 	}
 
 	void setSecondLevelCacheEnabled(boolean secondLevelCacheEnabled) {
 		this.secondLevelCacheEnabled = secondLevelCacheEnabled;
 	}
 
 	void setCacheRegionPrefix(String cacheRegionPrefix) {
 		this.cacheRegionPrefix = cacheRegionPrefix;
 	}
 
 	void setQueryCacheFactory(QueryCacheFactory queryCacheFactory) {
 		this.queryCacheFactory = queryCacheFactory;
 	}
 
 	void setStatisticsEnabled(boolean statisticsEnabled) {
 		this.statisticsEnabled = statisticsEnabled;
 	}
 
 	void setJdbcBatchVersionedData(boolean jdbcBatchVersionedData) {
 		this.jdbcBatchVersionedData = jdbcBatchVersionedData;
 	}
 
 	void setFlushBeforeCompletionEnabled(boolean flushBeforeCompletionEnabled) {
 		this.flushBeforeCompletionEnabled = flushBeforeCompletionEnabled;
 	}
 
 	void setAutoCloseSessionEnabled(boolean autoCloseSessionEnabled) {
 		this.autoCloseSessionEnabled = autoCloseSessionEnabled;
 	}
 
 	void setConnectionReleaseMode(ConnectionReleaseMode connectionReleaseMode) {
 		this.connectionReleaseMode = connectionReleaseMode;
 	}
 
 	void setQueryTranslatorFactory(QueryTranslatorFactory queryTranslatorFactory) {
 		this.queryTranslatorFactory = queryTranslatorFactory;
 	}
 
 	void setWrapResultSetsEnabled(boolean wrapResultSetsEnabled) {
 		this.wrapResultSetsEnabled = wrapResultSetsEnabled;
 	}
 
 	void setOrderUpdatesEnabled(boolean orderUpdatesEnabled) {
 		this.orderUpdatesEnabled = orderUpdatesEnabled;
 	}
 
 	void setOrderInsertsEnabled(boolean orderInsertsEnabled) {
 		this.orderInsertsEnabled = orderInsertsEnabled;
 	}
 
 	void setStructuredCacheEntriesEnabled(boolean structuredCacheEntriesEnabled) {
 		this.structuredCacheEntriesEnabled = structuredCacheEntriesEnabled;
 	}
 
 	void setDefaultEntityMode(EntityMode defaultEntityMode) {
 		this.defaultEntityMode = defaultEntityMode;
 	}
 
 	void setAutoValidateSchema(boolean autoValidateSchema) {
 		this.autoValidateSchema = autoValidateSchema;
 	}
 
 	void setDataDefinitionImplicitCommit(boolean dataDefinitionImplicitCommit) {
 		this.dataDefinitionImplicitCommit = dataDefinitionImplicitCommit;
 	}
 
 	void setDataDefinitionInTransactionSupported(boolean dataDefinitionInTransactionSupported) {
 		this.dataDefinitionInTransactionSupported = dataDefinitionInTransactionSupported;
 	}
 
 	void setStrictJPAQLCompliance(boolean strictJPAQLCompliance) {
 		this.strictJPAQLCompliance = strictJPAQLCompliance;
 	}
 
 	void setNamedQueryStartupCheckingEnabled(boolean namedQueryStartupCheckingEnabled) {
 		this.namedQueryStartupCheckingEnabled = namedQueryStartupCheckingEnabled;
 	}
 
 	void setEntityTuplizerFactory(EntityTuplizerFactory entityTuplizerFactory) {
 		this.entityTuplizerFactory = entityTuplizerFactory;
 	}
 
 	public boolean isCheckNullability() {
 		return checkNullability;
 	}
 
 	public void setCheckNullability(boolean checkNullability) {
 		this.checkNullability = checkNullability;
 	}
 
 	//	void setComponentTuplizerFactory(ComponentTuplizerFactory componentTuplizerFactory) {
 //		this.componentTuplizerFactory = componentTuplizerFactory;
 //	}
 
 	//	public BytecodeProvider getBytecodeProvider() {
 //		return bytecodeProvider;
 //	}
 //
 //	void setBytecodeProvider(BytecodeProvider bytecodeProvider) {
 //		this.bytecodeProvider = bytecodeProvider;
 //	}
 
 
 	public JtaPlatform getJtaPlatform() {
 		return jtaPlatform;
 	}
 
 	void setJtaPlatform(JtaPlatform jtaPlatform) {
 		this.jtaPlatform = jtaPlatform;
 	}
 
 	public MultiTenancyStrategy getMultiTenancyStrategy() {
 		return multiTenancyStrategy;
 	}
 
 	void setMultiTenancyStrategy(MultiTenancyStrategy multiTenancyStrategy) {
 		this.multiTenancyStrategy = multiTenancyStrategy;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/SettingsFactory.java b/hibernate-core/src/main/java/org/hibernate/cfg/SettingsFactory.java
index 0453f8dd93..1240b36824 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/SettingsFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/SettingsFactory.java
@@ -1,410 +1,410 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import java.io.Serializable;
 import java.util.Map;
 import java.util.Properties;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
 import org.hibernate.MultiTenancyStrategy;
-import org.hibernate.cache.QueryCacheFactory;
-import org.hibernate.cache.RegionFactory;
-import org.hibernate.cache.impl.NoCachingRegionFactory;
-import org.hibernate.cache.impl.bridge.RegionFactoryCacheProviderBridge;
+import org.hibernate.cache.internal.NoCachingRegionFactory;
+import org.hibernate.cache.spi.QueryCacheFactory;
+import org.hibernate.cache.spi.RegionFactory;
+import org.hibernate.cache.internal.bridge.RegionFactoryCacheProviderBridge;
 import org.hibernate.engine.jdbc.spi.ExtractedDatabaseMetaData;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.transaction.spi.TransactionFactory;
 import org.hibernate.hql.QueryTranslatorFactory;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.service.classloading.spi.ClassLoaderService;
 import org.hibernate.service.jta.platform.spi.JtaPlatform;
 
 /**
  * Reads configuration properties and builds a {@link Settings} instance.
  *
  * @author Gavin King
  */
 public class SettingsFactory implements Serializable {
 
     private static final long serialVersionUID = -1194386144994524825L;
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SettingsFactory.class.getName());
 
 	public static final String DEF_CACHE_REG_FACTORY = NoCachingRegionFactory.class.getName();
 
 	protected SettingsFactory() {
 	}
 
 	public Settings buildSettings(Properties props, ServiceRegistry serviceRegistry) {
 		final JdbcServices jdbcServices = serviceRegistry.getService( JdbcServices.class );
 		Settings settings = new Settings();
 
 		//SessionFactory name:
 
 		String sessionFactoryName = props.getProperty(Environment.SESSION_FACTORY_NAME);
 		settings.setSessionFactoryName(sessionFactoryName);
 
 		//JDBC and connection settings:
 
 		//Interrogate JDBC metadata
 		ExtractedDatabaseMetaData meta = jdbcServices.getExtractedMetaDataSupport();
 
 		settings.setDataDefinitionImplicitCommit( meta.doesDataDefinitionCauseTransactionCommit() );
 		settings.setDataDefinitionInTransactionSupported( meta.supportsDataDefinitionInTransaction() );
 
 		//use dialect default properties
 		final Properties properties = new Properties();
 		properties.putAll( jdbcServices.getDialect().getDefaultProperties() );
 		properties.putAll( props );
 
 		// Transaction settings:
 		settings.setJtaPlatform( serviceRegistry.getService( JtaPlatform.class ) );
 
 		boolean flushBeforeCompletion = ConfigurationHelper.getBoolean(Environment.FLUSH_BEFORE_COMPLETION, properties);
         LOG.debugf( "Automatic flush during beforeCompletion(): %s", enabledDisabled(flushBeforeCompletion) );
 		settings.setFlushBeforeCompletionEnabled(flushBeforeCompletion);
 
 		boolean autoCloseSession = ConfigurationHelper.getBoolean(Environment.AUTO_CLOSE_SESSION, properties);
         LOG.debugf( "Automatic session close at end of transaction: %s", enabledDisabled(autoCloseSession) );
 		settings.setAutoCloseSessionEnabled(autoCloseSession);
 
 		//JDBC and connection settings:
 
 		int batchSize = ConfigurationHelper.getInt(Environment.STATEMENT_BATCH_SIZE, properties, 0);
 		if ( !meta.supportsBatchUpdates() ) {
 			batchSize = 0;
 		}
 		if ( batchSize > 0 ) {
 			LOG.debugf( "JDBC batch size: %s", batchSize );
 		}
 		settings.setJdbcBatchSize(batchSize);
 
 		boolean jdbcBatchVersionedData = ConfigurationHelper.getBoolean(Environment.BATCH_VERSIONED_DATA, properties, false);
         if ( batchSize > 0 ) {
 			LOG.debugf( "JDBC batch updates for versioned data: %s", enabledDisabled(jdbcBatchVersionedData) );
 		}
 		settings.setJdbcBatchVersionedData(jdbcBatchVersionedData);
 
 		boolean useScrollableResultSets = ConfigurationHelper.getBoolean(
 				Environment.USE_SCROLLABLE_RESULTSET,
 				properties,
 				meta.supportsScrollableResults()
 		);
         LOG.debugf( "Scrollable result sets: %s", enabledDisabled(useScrollableResultSets) );
 		settings.setScrollableResultSetsEnabled(useScrollableResultSets);
 
 		boolean wrapResultSets = ConfigurationHelper.getBoolean(Environment.WRAP_RESULT_SETS, properties, false);
         LOG.debugf( "Wrap result sets: %s", enabledDisabled(wrapResultSets) );
 		settings.setWrapResultSetsEnabled(wrapResultSets);
 
 		boolean useGetGeneratedKeys = ConfigurationHelper.getBoolean(Environment.USE_GET_GENERATED_KEYS, properties, meta.supportsGetGeneratedKeys());
         LOG.debugf( "JDBC3 getGeneratedKeys(): %s", enabledDisabled(useGetGeneratedKeys) );
 		settings.setGetGeneratedKeysEnabled(useGetGeneratedKeys);
 
 		Integer statementFetchSize = ConfigurationHelper.getInteger(Environment.STATEMENT_FETCH_SIZE, properties);
         if (statementFetchSize != null) {
 			LOG.debugf( "JDBC result set fetch size: %s", statementFetchSize );
 		}
 		settings.setJdbcFetchSize(statementFetchSize);
 
 		String releaseModeName = ConfigurationHelper.getString( Environment.RELEASE_CONNECTIONS, properties, "auto" );
         LOG.debugf( "Connection release mode: %s", releaseModeName );
 		ConnectionReleaseMode releaseMode;
 		if ( "auto".equals(releaseModeName) ) {
 			releaseMode = serviceRegistry.getService( TransactionFactory.class ).getDefaultReleaseMode();
 		}
 		else {
 			releaseMode = ConnectionReleaseMode.parse( releaseModeName );
 			if ( releaseMode == ConnectionReleaseMode.AFTER_STATEMENT &&
 					! jdbcServices.getConnectionProvider().supportsAggressiveRelease() ) {
                 LOG.unsupportedAfterStatement();
 				releaseMode = ConnectionReleaseMode.AFTER_TRANSACTION;
 			}
 		}
 		settings.setConnectionReleaseMode( releaseMode );
 
 		//SQL Generation settings:
 
 		String defaultSchema = properties.getProperty( Environment.DEFAULT_SCHEMA );
 		String defaultCatalog = properties.getProperty( Environment.DEFAULT_CATALOG );
         if ( defaultSchema != null ) {
 			LOG.debugf( "Default schema: %s", defaultSchema );
 		}
         if (defaultCatalog != null) {
 			LOG.debugf( "Default catalog: %s", defaultCatalog );
 		}
 		settings.setDefaultSchemaName( defaultSchema );
 		settings.setDefaultCatalogName( defaultCatalog );
 
 		Integer maxFetchDepth = ConfigurationHelper.getInteger( Environment.MAX_FETCH_DEPTH, properties );
         if ( maxFetchDepth != null ) {
 			LOG.debugf( "Maximum outer join fetch depth: %s", maxFetchDepth );
 		}
 		settings.setMaximumFetchDepth( maxFetchDepth );
 
 		int batchFetchSize = ConfigurationHelper.getInt(Environment.DEFAULT_BATCH_FETCH_SIZE, properties, 1);
         LOG.debugf( "Default batch fetch size: %s", batchFetchSize );
 		settings.setDefaultBatchFetchSize( batchFetchSize );
 
 		boolean comments = ConfigurationHelper.getBoolean( Environment.USE_SQL_COMMENTS, properties );
         LOG.debugf( "Generate SQL with comments: %s", enabledDisabled(comments) );
 		settings.setCommentsEnabled( comments );
 
 		boolean orderUpdates = ConfigurationHelper.getBoolean( Environment.ORDER_UPDATES, properties );
         LOG.debugf( "Order SQL updates by primary key: %s", enabledDisabled(orderUpdates) );
 		settings.setOrderUpdatesEnabled( orderUpdates );
 
 		boolean orderInserts = ConfigurationHelper.getBoolean(Environment.ORDER_INSERTS, properties);
         LOG.debugf( "Order SQL inserts for batching: %s", enabledDisabled(orderInserts) );
 		settings.setOrderInsertsEnabled( orderInserts );
 
 		//Query parser settings:
 
 		settings.setQueryTranslatorFactory( createQueryTranslatorFactory( properties, serviceRegistry ) );
 
         Map querySubstitutions = ConfigurationHelper.toMap( Environment.QUERY_SUBSTITUTIONS, " ,=;:\n\t\r\f", properties );
         LOG.debugf( "Query language substitutions: %s", querySubstitutions );
 		settings.setQuerySubstitutions( querySubstitutions );
 
 		boolean jpaqlCompliance = ConfigurationHelper.getBoolean( Environment.JPAQL_STRICT_COMPLIANCE, properties, false );
 		LOG.debugf( "JPA-QL strict compliance: %s", enabledDisabled(jpaqlCompliance) );
 		settings.setStrictJPAQLCompliance( jpaqlCompliance );
 
 		// Second-level / query cache:
 
 		boolean useSecondLevelCache = ConfigurationHelper.getBoolean( Environment.USE_SECOND_LEVEL_CACHE, properties, true );
         LOG.debugf( "Second-level cache: %s", enabledDisabled(useSecondLevelCache) );
 		settings.setSecondLevelCacheEnabled( useSecondLevelCache );
 
 		boolean useQueryCache = ConfigurationHelper.getBoolean(Environment.USE_QUERY_CACHE, properties);
         LOG.debugf( "Query cache: %s", enabledDisabled(useQueryCache) );
 		settings.setQueryCacheEnabled( useQueryCache );
 		if (useQueryCache) {
 			settings.setQueryCacheFactory( createQueryCacheFactory( properties, serviceRegistry ) );
 		}
 
 		// The cache provider is needed when we either have second-level cache enabled
 		// or query cache enabled.  Note that useSecondLevelCache is enabled by default
 		settings.setRegionFactory( createRegionFactory( properties, ( useSecondLevelCache || useQueryCache ), serviceRegistry ) );
 
 		boolean useMinimalPuts = ConfigurationHelper.getBoolean(
 				Environment.USE_MINIMAL_PUTS, properties, settings.getRegionFactory().isMinimalPutsEnabledByDefault()
 		);
         LOG.debugf( "Optimize cache for minimal puts: %s", enabledDisabled(useMinimalPuts) );
 		settings.setMinimalPutsEnabled( useMinimalPuts );
 
 		String prefix = properties.getProperty( Environment.CACHE_REGION_PREFIX );
 		if ( StringHelper.isEmpty(prefix) ) {
 			prefix=null;
 		}
         if (prefix != null) {
 			LOG.debugf( "Cache region prefix: %s", prefix );
 		}
 		settings.setCacheRegionPrefix( prefix );
 
 		boolean useStructuredCacheEntries = ConfigurationHelper.getBoolean( Environment.USE_STRUCTURED_CACHE, properties, false );
         LOG.debugf( "Structured second-level cache entries: %s", enabledDisabled(useStructuredCacheEntries) );
 		settings.setStructuredCacheEntriesEnabled( useStructuredCacheEntries );
 
 
 		//Statistics and logging:
 
 		boolean useStatistics = ConfigurationHelper.getBoolean( Environment.GENERATE_STATISTICS, properties );
 		LOG.debugf( "Statistics: %s", enabledDisabled(useStatistics) );
 		settings.setStatisticsEnabled( useStatistics );
 
 		boolean useIdentifierRollback = ConfigurationHelper.getBoolean( Environment.USE_IDENTIFIER_ROLLBACK, properties );
         LOG.debugf( "Deleted entity synthetic identifier rollback: %s", enabledDisabled(useIdentifierRollback) );
 		settings.setIdentifierRollbackEnabled( useIdentifierRollback );
 
 		//Schema export:
 
 		String autoSchemaExport = properties.getProperty( Environment.HBM2DDL_AUTO );
 		if ( "validate".equals(autoSchemaExport) ) {
 			settings.setAutoValidateSchema( true );
 		}
 		if ( "update".equals(autoSchemaExport) ) {
 			settings.setAutoUpdateSchema( true );
 		}
 		if ( "create".equals(autoSchemaExport) ) {
 			settings.setAutoCreateSchema( true );
 		}
 		if ( "create-drop".equals( autoSchemaExport ) ) {
 			settings.setAutoCreateSchema( true );
 			settings.setAutoDropSchema( true );
 		}
 		settings.setImportFiles( properties.getProperty( Environment.HBM2DDL_IMPORT_FILES ) );
 
 		EntityMode defaultEntityMode = EntityMode.parse( properties.getProperty( Environment.DEFAULT_ENTITY_MODE ) );
         LOG.debugf( "Default entity-mode: %s", defaultEntityMode );
 		settings.setDefaultEntityMode( defaultEntityMode );
 
 		boolean namedQueryChecking = ConfigurationHelper.getBoolean( Environment.QUERY_STARTUP_CHECKING, properties, true );
         LOG.debugf( "Named query checking : %s", enabledDisabled(namedQueryChecking) );
 		settings.setNamedQueryStartupCheckingEnabled( namedQueryChecking );
 
 		boolean checkNullability = ConfigurationHelper.getBoolean(Environment.CHECK_NULLABILITY, properties, true);
         LOG.debugf( "Check Nullability in Core (should be disabled when Bean Validation is on): %s", enabledDisabled(checkNullability) );
 		settings.setCheckNullability(checkNullability);
 
 		MultiTenancyStrategy multiTenancyStrategy = MultiTenancyStrategy.determineMultiTenancyStrategy( properties );
 		LOG.debugf( "multi-tenancy strategy : %s", multiTenancyStrategy );
 		settings.setMultiTenancyStrategy( multiTenancyStrategy );
 
 //		String provider = properties.getProperty( Environment.BYTECODE_PROVIDER );
 //		log.info( "Bytecode provider name : " + provider );
 //		BytecodeProvider bytecodeProvider = buildBytecodeProvider( provider );
 //		settings.setBytecodeProvider( bytecodeProvider );
 
 		return settings;
 
 	}
 
 //	protected BytecodeProvider buildBytecodeProvider(String providerName) {
 //		if ( "javassist".equals( providerName ) ) {
 //			return new org.hibernate.bytecode.internal.javassist.BytecodeProviderImpl();
 //		}
 //		else {
 //            LOG.debugf("Using javassist as bytecode provider by default");
 //			return new org.hibernate.bytecode.internal.javassist.BytecodeProviderImpl();
 //		}
 //	}
 
 	private static String enabledDisabled(boolean value) {
 		return value ? "enabled" : "disabled";
 	}
 
 	protected QueryCacheFactory createQueryCacheFactory(Properties properties, ServiceRegistry serviceRegistry) {
 		String queryCacheFactoryClassName = ConfigurationHelper.getString(
-				Environment.QUERY_CACHE_FACTORY, properties, "org.hibernate.cache.StandardQueryCacheFactory"
+				Environment.QUERY_CACHE_FACTORY, properties, "org.hibernate.cache.internal.StandardQueryCacheFactory"
 		);
         LOG.debugf( "Query cache factory: %s", queryCacheFactoryClassName );
 		try {
 			return (QueryCacheFactory) serviceRegistry.getService( ClassLoaderService.class )
 					.classForName( queryCacheFactoryClassName )
 					.newInstance();
 		}
 		catch (Exception e) {
 			throw new HibernateException( "could not instantiate QueryCacheFactory: " + queryCacheFactoryClassName, e );
 		}
 	}
 
 	public static RegionFactory createRegionFactory(Properties properties, boolean cachingEnabled, ServiceRegistry serviceRegistry) {
 		String regionFactoryClassName = ConfigurationHelper.getString(
 				Environment.CACHE_REGION_FACTORY, properties, null
 		);
 		if ( regionFactoryClassName == null && cachingEnabled ) {
 			String providerClassName = ConfigurationHelper.getString( Environment.CACHE_PROVIDER, properties, null );
 			if ( providerClassName != null ) {
 				// legacy behavior, apply the bridge...
 				regionFactoryClassName = RegionFactoryCacheProviderBridge.class.getName();
 			}
 		}
 		if ( regionFactoryClassName == null ) {
 			regionFactoryClassName = DEF_CACHE_REG_FACTORY;
 		}
         LOG.debugf( "Cache region factory : %s", regionFactoryClassName );
 		try {
 			try {
 				return (RegionFactory) serviceRegistry.getService( ClassLoaderService.class )
 						.classForName( regionFactoryClassName )
 						.getConstructor( Properties.class )
 						.newInstance( properties );
 			}
 			catch ( NoSuchMethodException e ) {
 				// no constructor accepting Properties found, try no arg constructor
                 LOG.debugf(
 						"%s did not provide constructor accepting java.util.Properties; attempting no-arg constructor.",
 						regionFactoryClassName
 				);
 				return (RegionFactory) serviceRegistry.getService( ClassLoaderService.class )
 						.classForName( regionFactoryClassName )
 						.newInstance();
 			}
 		}
 		catch ( Exception e ) {
 			throw new HibernateException( "could not instantiate RegionFactory [" + regionFactoryClassName + "]", e );
 		}
 	}
 
 	protected QueryTranslatorFactory createQueryTranslatorFactory(Properties properties, ServiceRegistry serviceRegistry) {
 		String className = ConfigurationHelper.getString(
 				Environment.QUERY_TRANSLATOR, properties, "org.hibernate.hql.ast.ASTQueryTranslatorFactory"
 		);
         LOG.debugf( "Query translator: %s", className );
 		try {
 			return (QueryTranslatorFactory) serviceRegistry.getService( ClassLoaderService.class )
 					.classForName( className )
 					.newInstance();
 		}
 		catch (Exception e) {
 			throw new HibernateException( "could not instantiate QueryTranslatorFactory: " + className, e );
 		}
 	}
 
 	public static RegionFactory createRegionFactory(Properties properties, boolean cachingEnabled) {
 		// todo : REMOVE!  THIS IS TOTALLY A TEMPORARY HACK FOR org.hibernate.cfg.AnnotationBinder which will be going away
 		String regionFactoryClassName = ConfigurationHelper.getString(
 				Environment.CACHE_REGION_FACTORY, properties, null
 		);
 		if ( regionFactoryClassName == null && cachingEnabled ) {
 			String providerClassName = ConfigurationHelper.getString( Environment.CACHE_PROVIDER, properties, null );
 			if ( providerClassName != null ) {
 				// legacy behavior, apply the bridge...
 				regionFactoryClassName = RegionFactoryCacheProviderBridge.class.getName();
 			}
 		}
 		if ( regionFactoryClassName == null ) {
 			regionFactoryClassName = DEF_CACHE_REG_FACTORY;
 		}
         LOG.debugf( "Cache region factory : %s", regionFactoryClassName );
 		try {
 			try {
 				return (RegionFactory) org.hibernate.internal.util.ReflectHelper.classForName( regionFactoryClassName )
 						.getConstructor( Properties.class )
 						.newInstance( properties );
 			}
 			catch ( NoSuchMethodException e ) {
 				// no constructor accepting Properties found, try no arg constructor
                 LOG.debugf(
 						"%s did not provide constructor accepting java.util.Properties; attempting no-arg constructor.",
 						regionFactoryClassName
 				);
 				return (RegionFactory) org.hibernate.internal.util.ReflectHelper.classForName( regionFactoryClassName )
 						.newInstance();
 			}
 		}
 		catch ( Exception e ) {
 			throw new HibernateException( "could not instantiate RegionFactory [" + regionFactoryClassName + "]", e );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/EntityBinder.java b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/EntityBinder.java
index 032ab0f404..36b604e12f 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/annotations/EntityBinder.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/annotations/EntityBinder.java
@@ -1,930 +1,930 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg.annotations;
 
 import javax.persistence.Access;
 import javax.persistence.Entity;
 import javax.persistence.JoinColumn;
 import javax.persistence.JoinTable;
 import javax.persistence.PrimaryKeyJoinColumn;
 import javax.persistence.SecondaryTable;
 import javax.persistence.SecondaryTables;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AnnotationException;
 import org.hibernate.AssertionFailure;
 import org.hibernate.EntityMode;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.annotations.BatchSize;
 import org.hibernate.annotations.Cache;
 import org.hibernate.annotations.CacheConcurrencyStrategy;
 import org.hibernate.annotations.FetchMode;
 import org.hibernate.annotations.Immutable;
 import org.hibernate.annotations.Loader;
 import org.hibernate.annotations.OptimisticLockType;
 import org.hibernate.annotations.Persister;
 import org.hibernate.annotations.PolymorphismType;
 import org.hibernate.annotations.Proxy;
 import org.hibernate.annotations.RowId;
 import org.hibernate.annotations.SQLDelete;
 import org.hibernate.annotations.SQLDeleteAll;
 import org.hibernate.annotations.SQLInsert;
 import org.hibernate.annotations.SQLUpdate;
 import org.hibernate.annotations.Subselect;
 import org.hibernate.annotations.Synchronize;
 import org.hibernate.annotations.Tables;
 import org.hibernate.annotations.Tuplizer;
 import org.hibernate.annotations.Tuplizers;
 import org.hibernate.annotations.Where;
 import org.hibernate.annotations.common.reflection.XAnnotatedElement;
 import org.hibernate.annotations.common.reflection.XClass;
 import org.hibernate.cfg.AccessType;
 import org.hibernate.cfg.AnnotationBinder;
 import org.hibernate.cfg.BinderHelper;
 import org.hibernate.cfg.Ejb3JoinColumn;
 import org.hibernate.cfg.InheritanceState;
 import org.hibernate.cfg.Mappings;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.cfg.ObjectNameNormalizer;
 import org.hibernate.cfg.ObjectNameSource;
 import org.hibernate.cfg.PropertyHolder;
 import org.hibernate.cfg.UniqueConstraintHolder;
 import org.hibernate.engine.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.FilterDefinition;
 import org.hibernate.engine.Versioning;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.DependantValue;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.mapping.Table;
 import org.hibernate.mapping.TableOwner;
 import org.hibernate.mapping.Value;
 
 /**
  * Stateful holder and processor for binding Entity information
  *
  * @author Emmanuel Bernard
  */
 public class EntityBinder {
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, EntityBinder.class.getName());
 
 	private String name;
 	private XClass annotatedClass;
 	private PersistentClass persistentClass;
 	private Mappings mappings;
 	private String discriminatorValue = "";
 	private Boolean forceDiscriminator;
 	private Boolean insertableDiscriminator;
 	private boolean dynamicInsert;
 	private boolean dynamicUpdate;
 	private boolean explicitHibernateEntityAnnotation;
 	private OptimisticLockType optimisticLockType;
 	private PolymorphismType polymorphismType;
 	private boolean selectBeforeUpdate;
 	private int batchSize;
 	private boolean lazy;
 	private XClass proxyClass;
 	private String where;
 	private java.util.Map<String, Join> secondaryTables = new HashMap<String, Join>();
 	private java.util.Map<String, Object> secondaryTableJoins = new HashMap<String, Object>();
 	private String cacheConcurrentStrategy;
 	private String cacheRegion;
 	private java.util.Map<String, String> filters = new HashMap<String, String>();
 	private InheritanceState inheritanceState;
 	private boolean ignoreIdAnnotations;
 	private boolean cacheLazyProperty;
 	private AccessType propertyAccessType = AccessType.DEFAULT;
 	private boolean wrapIdsInEmbeddedComponents;
 	private String subselect;
 
 	public boolean wrapIdsInEmbeddedComponents() {
 		return wrapIdsInEmbeddedComponents;
 	}
 
 	/**
 	 * Use as a fake one for Collection of elements
 	 */
 	public EntityBinder() {
 	}
 
 	public EntityBinder(
 			Entity ejb3Ann,
 			org.hibernate.annotations.Entity hibAnn,
 			XClass annotatedClass,
 			PersistentClass persistentClass,
 			Mappings mappings) {
 		this.mappings = mappings;
 		this.persistentClass = persistentClass;
 		this.annotatedClass = annotatedClass;
 		bindEjb3Annotation( ejb3Ann );
 		bindHibernateAnnotation( hibAnn );
 	}
 
 	private void bindHibernateAnnotation(org.hibernate.annotations.Entity hibAnn) {
 		if ( hibAnn != null ) {
 			dynamicInsert = hibAnn.dynamicInsert();
 			dynamicUpdate = hibAnn.dynamicUpdate();
 			optimisticLockType = hibAnn.optimisticLock();
 			selectBeforeUpdate = hibAnn.selectBeforeUpdate();
 			polymorphismType = hibAnn.polymorphism();
 			explicitHibernateEntityAnnotation = true;
 			//persister handled in bind
 		}
 		else {
 			//default values when the annotation is not there
 			dynamicInsert = false;
 			dynamicUpdate = false;
 			optimisticLockType = OptimisticLockType.VERSION;
 			polymorphismType = PolymorphismType.IMPLICIT;
 			selectBeforeUpdate = false;
 		}
 	}
 
 	private void bindEjb3Annotation(Entity ejb3Ann) {
 		if ( ejb3Ann == null ) throw new AssertionFailure( "@Entity should always be not null" );
 		if ( BinderHelper.isEmptyAnnotationValue( ejb3Ann.name() ) ) {
 			name = StringHelper.unqualify( annotatedClass.getName() );
 		}
 		else {
 			name = ejb3Ann.name();
 		}
 	}
 
 	public void setDiscriminatorValue(String discriminatorValue) {
 		this.discriminatorValue = discriminatorValue;
 	}
 
 	public void setForceDiscriminator(boolean forceDiscriminator) {
 		this.forceDiscriminator = forceDiscriminator;
 	}
 
 	public void setInsertableDiscriminator(boolean insertableDiscriminator) {
 		this.insertableDiscriminator = insertableDiscriminator;
 	}
 
 	public void bindEntity() {
 		persistentClass.setAbstract( annotatedClass.isAbstract() );
 		persistentClass.setClassName( annotatedClass.getName() );
 		persistentClass.setNodeName( name );
 		persistentClass.setJpaEntityName(name);
 		//persistentClass.setDynamic(false); //no longer needed with the Entity name refactoring?
 		persistentClass.setEntityName( annotatedClass.getName() );
 		bindDiscriminatorValue();
 
 		persistentClass.setLazy( lazy );
 		if ( proxyClass != null ) {
 			persistentClass.setProxyInterfaceName( proxyClass.getName() );
 		}
 		persistentClass.setDynamicInsert( dynamicInsert );
 		persistentClass.setDynamicUpdate( dynamicUpdate );
 
 		if ( persistentClass instanceof RootClass ) {
 			RootClass rootClass = (RootClass) persistentClass;
 			boolean mutable = true;
 			//priority on @Immutable, then @Entity.mutable()
 			if ( annotatedClass.isAnnotationPresent( Immutable.class ) ) {
 				mutable = false;
 			}
 			else {
 				org.hibernate.annotations.Entity entityAnn =
 						annotatedClass.getAnnotation( org.hibernate.annotations.Entity.class );
 				if ( entityAnn != null ) {
 					mutable = entityAnn.mutable();
 				}
 			}
 			rootClass.setMutable( mutable );
 			rootClass.setExplicitPolymorphism( isExplicitPolymorphism( polymorphismType ) );
 			if ( StringHelper.isNotEmpty( where ) ) rootClass.setWhere( where );
 			if ( cacheConcurrentStrategy != null ) {
 				rootClass.setCacheConcurrencyStrategy( cacheConcurrentStrategy );
 				rootClass.setCacheRegionName( cacheRegion );
 				rootClass.setLazyPropertiesCacheable( cacheLazyProperty );
 			}
 			if(forceDiscriminator != null) {
 				rootClass.setForceDiscriminator( forceDiscriminator );
 			}
 			if( insertableDiscriminator != null) {
 				rootClass.setDiscriminatorInsertable( insertableDiscriminator );
 			}
 		}
 		else {
             if (explicitHibernateEntityAnnotation) {
 				LOG.entityAnnotationOnNonRoot(annotatedClass.getName());
 			}
             if (annotatedClass.isAnnotationPresent(Immutable.class)) {
 				LOG.immutableAnnotationOnNonRoot(annotatedClass.getName());
 			}
 		}
 		persistentClass.setOptimisticLockMode( getVersioning( optimisticLockType ) );
 		persistentClass.setSelectBeforeUpdate( selectBeforeUpdate );
 
 		//set persister if needed
 		Persister persisterAnn = annotatedClass.getAnnotation( Persister.class );
 		Class persister = null;
 		if ( persisterAnn != null ) {
 			persister = persisterAnn.impl();
 		}
 		else {
 			org.hibernate.annotations.Entity entityAnn = annotatedClass.getAnnotation( org.hibernate.annotations.Entity.class );
 			if ( entityAnn != null && !BinderHelper.isEmptyAnnotationValue( entityAnn.persister() ) ) {
 				try {
 					persister = ReflectHelper.classForName( entityAnn.persister() );
 				}
 				catch (ClassNotFoundException cnfe) {
 					throw new AnnotationException( "Could not find persister class: " + persister );
 				}
 			}
 		}
 		if ( persister != null ) {
 			persistentClass.setEntityPersisterClass( persister );
 		}
 
 		persistentClass.setBatchSize( batchSize );
 
 		//SQL overriding
 		SQLInsert sqlInsert = annotatedClass.getAnnotation( SQLInsert.class );
 		SQLUpdate sqlUpdate = annotatedClass.getAnnotation( SQLUpdate.class );
 		SQLDelete sqlDelete = annotatedClass.getAnnotation( SQLDelete.class );
 		SQLDeleteAll sqlDeleteAll = annotatedClass.getAnnotation( SQLDeleteAll.class );
 		Loader loader = annotatedClass.getAnnotation( Loader.class );
 
 		if ( sqlInsert != null ) {
 			persistentClass.setCustomSQLInsert( sqlInsert.sql().trim(), sqlInsert.callable(),
 					ExecuteUpdateResultCheckStyle.parse( sqlInsert.check().toString().toLowerCase() )
 			);
 
 		}
 		if ( sqlUpdate != null ) {
 			persistentClass.setCustomSQLUpdate( sqlUpdate.sql(), sqlUpdate.callable(),
 					ExecuteUpdateResultCheckStyle.parse( sqlUpdate.check().toString().toLowerCase() )
 			);
 		}
 		if ( sqlDelete != null ) {
 			persistentClass.setCustomSQLDelete( sqlDelete.sql(), sqlDelete.callable(),
 					ExecuteUpdateResultCheckStyle.parse( sqlDelete.check().toString().toLowerCase() )
 			);
 		}
 		if ( sqlDeleteAll != null ) {
 			persistentClass.setCustomSQLDelete( sqlDeleteAll.sql(), sqlDeleteAll.callable(),
 					ExecuteUpdateResultCheckStyle.parse( sqlDeleteAll.check().toString().toLowerCase() )
 			);
 		}
 		if ( loader != null ) {
 			persistentClass.setLoaderName( loader.namedQuery() );
 		}
 
 		if ( annotatedClass.isAnnotationPresent( Synchronize.class )) {
 			Synchronize synchronizedWith = annotatedClass.getAnnotation(Synchronize.class);
 
 			String [] tables = synchronizedWith.value();
 			for (String table : tables) {
 				persistentClass.addSynchronizedTable(table);
 			}
 		}
 
 		if ( annotatedClass.isAnnotationPresent(Subselect.class )) {
 			Subselect subselect = annotatedClass.getAnnotation(Subselect.class);
 			this.subselect = subselect.value();
 		}
 
 		//tuplizers
 		if ( annotatedClass.isAnnotationPresent( Tuplizers.class ) ) {
 			for (Tuplizer tuplizer : annotatedClass.getAnnotation( Tuplizers.class ).value()) {
 				EntityMode mode = EntityMode.parse( tuplizer.entityMode() );
 				persistentClass.addTuplizer( mode, tuplizer.impl().getName() );
 			}
 		}
 		if ( annotatedClass.isAnnotationPresent( Tuplizer.class ) ) {
 			Tuplizer tuplizer = annotatedClass.getAnnotation( Tuplizer.class );
 			EntityMode mode = EntityMode.parse( tuplizer.entityMode() );
 			persistentClass.addTuplizer( mode, tuplizer.impl().getName() );
 		}
 
 		if ( !inheritanceState.hasParents() ) {
 			for ( Map.Entry<String, String> filter : filters.entrySet() ) {
 				String filterName = filter.getKey();
 				String cond = filter.getValue();
 				if ( BinderHelper.isEmptyAnnotationValue( cond ) ) {
 					FilterDefinition definition = mappings.getFilterDefinition( filterName );
 					cond = definition == null ? null : definition.getDefaultFilterCondition();
 					if ( StringHelper.isEmpty( cond ) ) {
 						throw new AnnotationException(
 								"no filter condition found for filter " + filterName + " in " + this.name
 						);
 					}
 				}
 				persistentClass.addFilter( filterName, cond );
 			}
         } else if (filters.size() > 0) LOG.filterAnnotationOnSubclass(persistentClass.getEntityName());
         LOG.debugf("Import with entity name %s", name);
 		try {
 			mappings.addImport( persistentClass.getEntityName(), name );
 			String entityName = persistentClass.getEntityName();
 			if ( !entityName.equals( name ) ) {
 				mappings.addImport( entityName, entityName );
 			}
 		}
 		catch (MappingException me) {
 			throw new AnnotationException( "Use of the same entity name twice: " + name, me );
 		}
 	}
 
 	public void bindDiscriminatorValue() {
 		if ( StringHelper.isEmpty( discriminatorValue ) ) {
 			Value discriminator = persistentClass.getDiscriminator();
 			if ( discriminator == null ) {
 				persistentClass.setDiscriminatorValue( name );
 			}
 			else if ( "character".equals( discriminator.getType().getName() ) ) {
 				throw new AnnotationException(
 						"Using default @DiscriminatorValue for a discriminator of type CHAR is not safe"
 				);
 			}
 			else if ( "integer".equals( discriminator.getType().getName() ) ) {
 				persistentClass.setDiscriminatorValue( String.valueOf( name.hashCode() ) );
 			}
 			else {
 				persistentClass.setDiscriminatorValue( name ); //Spec compliant
 			}
 		}
 		else {
 			//persistentClass.getDiscriminator()
 			persistentClass.setDiscriminatorValue( discriminatorValue );
 		}
 	}
 
 	int getVersioning(OptimisticLockType type) {
 		switch ( type ) {
 			case VERSION:
 				return Versioning.OPTIMISTIC_LOCK_VERSION;
 			case NONE:
 				return Versioning.OPTIMISTIC_LOCK_NONE;
 			case DIRTY:
 				return Versioning.OPTIMISTIC_LOCK_DIRTY;
 			case ALL:
 				return Versioning.OPTIMISTIC_LOCK_ALL;
 			default:
 				throw new AssertionFailure( "optimistic locking not supported: " + type );
 		}
 	}
 
 	private boolean isExplicitPolymorphism(PolymorphismType type) {
 		switch ( type ) {
 			case IMPLICIT:
 				return false;
 			case EXPLICIT:
 				return true;
 			default:
 				throw new AssertionFailure( "Unknown polymorphism type: " + type );
 		}
 	}
 
 	public void setBatchSize(BatchSize sizeAnn) {
 		if ( sizeAnn != null ) {
 			batchSize = sizeAnn.size();
 		}
 		else {
 			batchSize = -1;
 		}
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	public void setProxy(Proxy proxy) {
 		if ( proxy != null ) {
 			lazy = proxy.lazy();
 			if ( !lazy ) {
 				proxyClass = null;
 			}
 			else {
 				if ( AnnotationBinder.isDefault(
 						mappings.getReflectionManager().toXClass( proxy.proxyClass() ), mappings
 				) ) {
 					proxyClass = annotatedClass;
 				}
 				else {
 					proxyClass = mappings.getReflectionManager().toXClass( proxy.proxyClass() );
 				}
 			}
 		}
 		else {
 			lazy = true; //needed to allow association lazy loading.
 			proxyClass = annotatedClass;
 		}
 	}
 
 	public void setWhere(Where whereAnn) {
 		if ( whereAnn != null ) {
 			where = whereAnn.clause();
 		}
 	}
 
 	public void setWrapIdsInEmbeddedComponents(boolean wrapIdsInEmbeddedComponents) {
 		this.wrapIdsInEmbeddedComponents = wrapIdsInEmbeddedComponents;
 	}
 
 
 	private static class EntityTableObjectNameSource implements ObjectNameSource {
 		private final String explicitName;
 		private final String logicalName;
 
 		private EntityTableObjectNameSource(String explicitName, String entityName) {
 			this.explicitName = explicitName;
 			this.logicalName = StringHelper.isNotEmpty( explicitName )
 					? explicitName
 					: StringHelper.unqualify( entityName );
 		}
 
 		public String getExplicitName() {
 			return explicitName;
 		}
 
 		public String getLogicalName() {
 			return logicalName;
 		}
 	}
 
 	private static class EntityTableNamingStrategyHelper implements ObjectNameNormalizer.NamingStrategyHelper {
 		private final String entityName;
 
 		private EntityTableNamingStrategyHelper(String entityName) {
 			this.entityName = entityName;
 		}
 
 		public String determineImplicitName(NamingStrategy strategy) {
 			return strategy.classToTableName( entityName );
 		}
 
 		public String handleExplicitName(NamingStrategy strategy, String name) {
 			return strategy.tableName( name );
 		}
 	}
 
 	public void bindTable(
 			String schema,
 			String catalog,
 			String tableName,
 			List<UniqueConstraintHolder> uniqueConstraints,
 			String constraints,
 			Table denormalizedSuperclassTable) {
 		EntityTableObjectNameSource tableNameContext = new EntityTableObjectNameSource( tableName, name );
 		EntityTableNamingStrategyHelper namingStrategyHelper = new EntityTableNamingStrategyHelper( name );
 		final Table table = TableBinder.buildAndFillTable(
 				schema,
 				catalog,
 				tableNameContext,
 				namingStrategyHelper,
 				persistentClass.isAbstract(),
 				uniqueConstraints,
 				constraints,
 				denormalizedSuperclassTable,
 				mappings,
 				this.subselect
 		);
 		final RowId rowId = annotatedClass.getAnnotation( RowId.class );
 		if ( rowId != null ) {
 			table.setRowId( rowId.value() );
 		}
 
 		if ( persistentClass instanceof TableOwner ) {
             LOG.debugf( "Bind entity %s on table %s", persistentClass.getEntityName(), table.getName() );
 			( (TableOwner) persistentClass ).setTable( table );
 		}
 		else {
 			throw new AssertionFailure( "binding a table for a subclass" );
 		}
 	}
 
 	public void finalSecondaryTableBinding(PropertyHolder propertyHolder) {
 		/*
 		 * Those operations has to be done after the id definition of the persistence class.
 		 * ie after the properties parsing
 		 */
 		Iterator joins = secondaryTables.values().iterator();
 		Iterator joinColumns = secondaryTableJoins.values().iterator();
 
 		while ( joins.hasNext() ) {
 			Object uncastedColumn = joinColumns.next();
 			Join join = (Join) joins.next();
 			createPrimaryColumnsToSecondaryTable( uncastedColumn, propertyHolder, join );
 		}
 		mappings.addJoins( persistentClass, secondaryTables );
 	}
 
 	private void createPrimaryColumnsToSecondaryTable(Object uncastedColumn, PropertyHolder propertyHolder, Join join) {
 		Ejb3JoinColumn[] ejb3JoinColumns;
 		PrimaryKeyJoinColumn[] pkColumnsAnn = null;
 		JoinColumn[] joinColumnsAnn = null;
 		if ( uncastedColumn instanceof PrimaryKeyJoinColumn[] ) {
 			pkColumnsAnn = (PrimaryKeyJoinColumn[]) uncastedColumn;
 		}
 		if ( uncastedColumn instanceof JoinColumn[] ) {
 			joinColumnsAnn = (JoinColumn[]) uncastedColumn;
 		}
 		if ( pkColumnsAnn == null && joinColumnsAnn == null ) {
 			ejb3JoinColumns = new Ejb3JoinColumn[1];
 			ejb3JoinColumns[0] = Ejb3JoinColumn.buildJoinColumn(
 					null,
 					null,
 					persistentClass.getIdentifier(),
 					secondaryTables,
 					propertyHolder, mappings
 			);
 		}
 		else {
 			int nbrOfJoinColumns = pkColumnsAnn != null ?
 					pkColumnsAnn.length :
 					joinColumnsAnn.length;
 			if ( nbrOfJoinColumns == 0 ) {
 				ejb3JoinColumns = new Ejb3JoinColumn[1];
 				ejb3JoinColumns[0] = Ejb3JoinColumn.buildJoinColumn(
 						null,
 						null,
 						persistentClass.getIdentifier(),
 						secondaryTables,
 						propertyHolder, mappings
 				);
 			}
 			else {
 				ejb3JoinColumns = new Ejb3JoinColumn[nbrOfJoinColumns];
 				if ( pkColumnsAnn != null ) {
 					for (int colIndex = 0; colIndex < nbrOfJoinColumns; colIndex++) {
 						ejb3JoinColumns[colIndex] = Ejb3JoinColumn.buildJoinColumn(
 								pkColumnsAnn[colIndex],
 								null,
 								persistentClass.getIdentifier(),
 								secondaryTables,
 								propertyHolder, mappings
 						);
 					}
 				}
 				else {
 					for (int colIndex = 0; colIndex < nbrOfJoinColumns; colIndex++) {
 						ejb3JoinColumns[colIndex] = Ejb3JoinColumn.buildJoinColumn(
 								null,
 								joinColumnsAnn[colIndex],
 								persistentClass.getIdentifier(),
 								secondaryTables,
 								propertyHolder, mappings
 						);
 					}
 				}
 			}
 		}
 
 		for (Ejb3JoinColumn joinColumn : ejb3JoinColumns) {
 			joinColumn.forceNotNull();
 		}
 		bindJoinToPersistentClass( join, ejb3JoinColumns, mappings );
 	}
 
 	private void bindJoinToPersistentClass(Join join, Ejb3JoinColumn[] ejb3JoinColumns, Mappings mappings) {
 		SimpleValue key = new DependantValue( mappings, join.getTable(), persistentClass.getIdentifier() );
 		join.setKey( key );
 		setFKNameIfDefined( join );
 		key.setCascadeDeleteEnabled( false );
 		TableBinder.bindFk( persistentClass, null, ejb3JoinColumns, key, false, mappings );
 		join.createPrimaryKey();
 		join.createForeignKey();
 		persistentClass.addJoin( join );
 	}
 
 	private void setFKNameIfDefined(Join join) {
 		org.hibernate.annotations.Table matchingTable = findMatchingComplimentTableAnnotation( join );
 		if ( matchingTable != null && !BinderHelper.isEmptyAnnotationValue( matchingTable.foreignKey().name() ) ) {
 			( (SimpleValue) join.getKey() ).setForeignKeyName( matchingTable.foreignKey().name() );
 		}
 	}
 
 	private org.hibernate.annotations.Table findMatchingComplimentTableAnnotation(Join join) {
 		String tableName = join.getTable().getQuotedName();
 		org.hibernate.annotations.Table table = annotatedClass.getAnnotation( org.hibernate.annotations.Table.class );
 		org.hibernate.annotations.Table matchingTable = null;
 		if ( table != null && tableName.equals( table.appliesTo() ) ) {
 			matchingTable = table;
 		}
 		else {
 			Tables tables = annotatedClass.getAnnotation( Tables.class );
 			if ( tables != null ) {
 				for (org.hibernate.annotations.Table current : tables.value()) {
 					if ( tableName.equals( current.appliesTo() ) ) {
 						matchingTable = current;
 						break;
 					}
 				}
 			}
 		}
 		return matchingTable;
 	}
 
 	public void firstLevelSecondaryTablesBinding(
 			SecondaryTable secTable, SecondaryTables secTables
 	) {
 		if ( secTables != null ) {
 			//loop through it
 			for (SecondaryTable tab : secTables.value()) {
 				addJoin( tab, null, null, false );
 			}
 		}
 		else {
 			if ( secTable != null ) addJoin( secTable, null, null, false );
 		}
 	}
 
 	//Used for @*ToMany @JoinTable
 	public Join addJoin(JoinTable joinTable, PropertyHolder holder, boolean noDelayInPkColumnCreation) {
 		return addJoin( null, joinTable, holder, noDelayInPkColumnCreation );
 	}
 
 	private static class SecondaryTableNameSource implements ObjectNameSource {
 		// always has an explicit name
 		private final String explicitName;
 
 		private SecondaryTableNameSource(String explicitName) {
 			this.explicitName = explicitName;
 		}
 
 		public String getExplicitName() {
 			return explicitName;
 		}
 
 		public String getLogicalName() {
 			return explicitName;
 		}
 	}
 
 	private static class SecondaryTableNamingStrategyHelper implements ObjectNameNormalizer.NamingStrategyHelper {
 		public String determineImplicitName(NamingStrategy strategy) {
 			// todo : throw an error?
 			return null;
 		}
 
 		public String handleExplicitName(NamingStrategy strategy, String name) {
 			return strategy.tableName( name );
 		}
 	}
 
 	private static SecondaryTableNamingStrategyHelper SEC_TBL_NS_HELPER = new SecondaryTableNamingStrategyHelper();
 
 	private Join addJoin(
 			SecondaryTable secondaryTable,
 			JoinTable joinTable,
 			PropertyHolder propertyHolder,
 			boolean noDelayInPkColumnCreation) {
 		// A non null propertyHolder means than we process the Pk creation without delay
 		Join join = new Join();
 		join.setPersistentClass( persistentClass );
 
 		final String schema;
 		final String catalog;
 		final SecondaryTableNameSource secondaryTableNameContext;
 		final Object joinColumns;
 		final List<UniqueConstraintHolder> uniqueConstraintHolders;
 
 		if ( secondaryTable != null ) {
 			schema = secondaryTable.schema();
 			catalog = secondaryTable.catalog();
 			secondaryTableNameContext = new SecondaryTableNameSource( secondaryTable.name() );
 			joinColumns = secondaryTable.pkJoinColumns();
 			uniqueConstraintHolders = TableBinder.buildUniqueConstraintHolders( secondaryTable.uniqueConstraints() );
 		}
 		else if ( joinTable != null ) {
 			schema = joinTable.schema();
 			catalog = joinTable.catalog();
 			secondaryTableNameContext = new SecondaryTableNameSource( joinTable.name() );
 			joinColumns = joinTable.joinColumns();
 			uniqueConstraintHolders = TableBinder.buildUniqueConstraintHolders( joinTable.uniqueConstraints() );
 		}
 		else {
 			throw new AssertionFailure( "Both JoinTable and SecondaryTable are null" );
 		}
 
 		final Table table = TableBinder.buildAndFillTable(
 				schema,
 				catalog,
 				secondaryTableNameContext,
 				SEC_TBL_NS_HELPER,
 				false,
 				uniqueConstraintHolders,
 				null,
 				null,
 				mappings,
 				null
 		);
 
 		//no check constraints available on joins
 		join.setTable( table );
 
 		//somehow keep joins() for later.
 		//Has to do the work later because it needs persistentClass id!
 		LOG.debugf( "Adding secondary table to entity %s -> %s", persistentClass.getEntityName(), join.getTable().getName() );
 		org.hibernate.annotations.Table matchingTable = findMatchingComplimentTableAnnotation( join );
 		if ( matchingTable != null ) {
 			join.setSequentialSelect( FetchMode.JOIN != matchingTable.fetch() );
 			join.setInverse( matchingTable.inverse() );
 			join.setOptional( matchingTable.optional() );
 			if ( !BinderHelper.isEmptyAnnotationValue( matchingTable.sqlInsert().sql() ) ) {
 				join.setCustomSQLInsert( matchingTable.sqlInsert().sql().trim(),
 						matchingTable.sqlInsert().callable(),
 						ExecuteUpdateResultCheckStyle.parse( matchingTable.sqlInsert().check().toString().toLowerCase() )
 				);
 			}
 			if ( !BinderHelper.isEmptyAnnotationValue( matchingTable.sqlUpdate().sql() ) ) {
 				join.setCustomSQLUpdate( matchingTable.sqlUpdate().sql().trim(),
 						matchingTable.sqlUpdate().callable(),
 						ExecuteUpdateResultCheckStyle.parse( matchingTable.sqlUpdate().check().toString().toLowerCase() )
 				);
 			}
 			if ( !BinderHelper.isEmptyAnnotationValue( matchingTable.sqlDelete().sql() ) ) {
 				join.setCustomSQLDelete( matchingTable.sqlDelete().sql().trim(),
 						matchingTable.sqlDelete().callable(),
 						ExecuteUpdateResultCheckStyle.parse( matchingTable.sqlDelete().check().toString().toLowerCase() )
 				);
 			}
 		}
 		else {
 			//default
 			join.setSequentialSelect( false );
 			join.setInverse( false );
 			join.setOptional( true ); //perhaps not quite per-spec, but a Good Thing anyway
 		}
 
 		if ( noDelayInPkColumnCreation ) {
 			createPrimaryColumnsToSecondaryTable( joinColumns, propertyHolder, join );
 		}
 		else {
 			secondaryTables.put( table.getQuotedName(), join );
 			secondaryTableJoins.put( table.getQuotedName(), joinColumns );
 		}
 		return join;
 	}
 
 	public java.util.Map<String, Join> getSecondaryTables() {
 		return secondaryTables;
 	}
 
 	public void setCache(Cache cacheAnn) {
 		if ( cacheAnn != null ) {
 			cacheRegion = BinderHelper.isEmptyAnnotationValue( cacheAnn.region() ) ?
 					null :
 					cacheAnn.region();
 			cacheConcurrentStrategy = getCacheConcurrencyStrategy( cacheAnn.usage() );
 			if ( "all".equalsIgnoreCase( cacheAnn.include() ) ) {
 				cacheLazyProperty = true;
 			}
 			else if ( "non-lazy".equalsIgnoreCase( cacheAnn.include() ) ) {
 				cacheLazyProperty = false;
 			}
 			else {
 				throw new AnnotationException( "Unknown lazy property annotations: " + cacheAnn.include() );
 			}
 		}
 		else {
 			cacheConcurrentStrategy = null;
 			cacheRegion = null;
 			cacheLazyProperty = true;
 		}
 	}
 
 	public static String getCacheConcurrencyStrategy(CacheConcurrencyStrategy strategy) {
-		org.hibernate.cache.access.AccessType accessType = strategy.toAccessType();
-		return accessType == null ? null : accessType.getName();
+		org.hibernate.cache.spi.access.AccessType accessType = strategy.toAccessType();
+		return accessType == null ? null : accessType.getExternalName();
 	}
 
 	public void addFilter(String name, String condition) {
 		filters.put( name, condition );
 	}
 
 	public void setInheritanceState(InheritanceState inheritanceState) {
 		this.inheritanceState = inheritanceState;
 	}
 
 	public boolean isIgnoreIdAnnotations() {
 		return ignoreIdAnnotations;
 	}
 
 	public void setIgnoreIdAnnotations(boolean ignoreIdAnnotations) {
 		this.ignoreIdAnnotations = ignoreIdAnnotations;
 	}
 
 	public void processComplementaryTableDefinitions(org.hibernate.annotations.Table table) {
 		//comment and index are processed here
 		if ( table == null ) return;
 		String appliedTable = table.appliesTo();
 		Iterator tables = persistentClass.getTableClosureIterator();
 		Table hibTable = null;
 		while ( tables.hasNext() ) {
 			Table pcTable = (Table) tables.next();
 			if ( pcTable.getQuotedName().equals( appliedTable ) ) {
 				//we are in the correct table to find columns
 				hibTable = pcTable;
 				break;
 			}
 			hibTable = null;
 		}
 		if ( hibTable == null ) {
 			//maybe a join/secondary table
 			for ( Join join : secondaryTables.values() ) {
 				if ( join.getTable().getQuotedName().equals( appliedTable ) ) {
 					hibTable = join.getTable();
 					break;
 				}
 			}
 		}
 		if ( hibTable == null ) {
 			throw new AnnotationException(
 					"@org.hibernate.annotations.Table references an unknown table: " + appliedTable
 			);
 		}
 		if ( !BinderHelper.isEmptyAnnotationValue( table.comment() ) ) hibTable.setComment( table.comment() );
 		TableBinder.addIndexes( hibTable, table.indexes(), mappings );
 	}
 
 	public void processComplementaryTableDefinitions(Tables tables) {
 		if ( tables == null ) return;
 		for (org.hibernate.annotations.Table table : tables.value()) {
 			processComplementaryTableDefinitions( table );
 		}
 	}
 
 	public AccessType getPropertyAccessType() {
 		return propertyAccessType;
 	}
 
 	public void setPropertyAccessType(AccessType propertyAccessor) {
 		this.propertyAccessType = getExplicitAccessType( annotatedClass );
 		// only set the access type if there is no explicit access type for this class
 		if( this.propertyAccessType == null ) {
 			this.propertyAccessType = propertyAccessor;
 		}
 	}
 
 	public AccessType getPropertyAccessor(XAnnotatedElement element) {
 		AccessType accessType = getExplicitAccessType( element );
 		if ( accessType == null ) {
 		   accessType = propertyAccessType;
 		}
 		return accessType;
 	}
 
 	public AccessType getExplicitAccessType(XAnnotatedElement element) {
 		AccessType accessType = null;
 
 		AccessType hibernateAccessType = null;
 		AccessType jpaAccessType = null;
 
 		org.hibernate.annotations.AccessType accessTypeAnnotation = element.getAnnotation( org.hibernate.annotations.AccessType.class );
 		if ( accessTypeAnnotation != null ) {
 			hibernateAccessType = AccessType.getAccessStrategy( accessTypeAnnotation.value() );
 		}
 
 		Access access = element.getAnnotation( Access.class );
 		if ( access != null ) {
 			jpaAccessType = AccessType.getAccessStrategy( access.value() );
 		}
 
 		if ( hibernateAccessType != null && jpaAccessType != null && hibernateAccessType != jpaAccessType ) {
 			throw new MappingException(
 					"Found @Access and @AccessType with conflicting values on a property in class " + annotatedClass.toString()
 			);
 		}
 
 		if ( hibernateAccessType != null ) {
 			accessType = hibernateAccessType;
 		}
 		else if ( jpaAccessType != null ) {
 			accessType = jpaAccessType;
 		}
 
 		return accessType;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/BatchFetchQueue.java b/hibernate-core/src/main/java/org/hibernate/engine/BatchFetchQueue.java
index ddac97ddc3..8af52712d1 100755
--- a/hibernate-core/src/main/java/org/hibernate/engine/BatchFetchQueue.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/BatchFetchQueue.java
@@ -1,288 +1,288 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2--8-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine;
 
 import java.io.Serializable;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.Map;
 
 import org.hibernate.EntityMode;
-import org.hibernate.cache.CacheKey;
+import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.internal.util.MarkerObject;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 
 /**
  * Tracks entity and collection keys that are available for batch
  * fetching, and the queries which were used to load entities, which
  * can be re-used as a subquery for loading owned collections.
  *
  * @author Gavin King
  */
 public class BatchFetchQueue {
 
 	public static final Object MARKER = new MarkerObject( "MARKER" );
 
 	/**
 	 * Defines a sequence of {@link EntityKey} elements that are currently
 	 * elegible for batch-fetching.
 	 * <p/>
 	 * Even though this is a map, we only use the keys.  A map was chosen in
 	 * order to utilize a {@link LinkedHashMap} to maintain sequencing
 	 * as well as uniqueness.
 	 * <p/>
 	 * TODO : this would be better as a SequencedReferenceSet, but no such beast exists!
 	 */
 	private final Map batchLoadableEntityKeys = new LinkedHashMap(8);
 
 	/**
 	 * A map of {@link SubselectFetch subselect-fetch descriptors} keyed by the
 	 * {@link EntityKey) against which the descriptor is registered.
 	 */
 	private final Map subselectsByEntityKey = new HashMap(8);
 
 	/**
 	 * The owning persistence context.
 	 */
 	private final PersistenceContext context;
 
 	/**
 	 * Constructs a queue for the given context.
 	 *
 	 * @param context The owning context.
 	 */
 	public BatchFetchQueue(PersistenceContext context) {
 		this.context = context;
 	}
 
 	/**
 	 * Clears all entries from this fetch queue.
 	 */
 	public void clear() {
 		batchLoadableEntityKeys.clear();
 		subselectsByEntityKey.clear();
 	}
 
 	/**
 	 * Retrieve the fetch descriptor associated with the given entity key.
 	 *
 	 * @param key The entity key for which to locate any defined subselect fetch.
 	 * @return The fetch descriptor; may return null if no subselect fetch queued for
 	 * this entity key.
 	 */
 	public SubselectFetch getSubselect(EntityKey key) {
 		return (SubselectFetch) subselectsByEntityKey.get(key);
 	}
 
 	/**
 	 * Adds a subselect fetch decriptor for the given entity key.
 	 *
 	 * @param key The entity for which to register the subselect fetch.
 	 * @param subquery The fetch descriptor.
 	 */
 	public void addSubselect(EntityKey key, SubselectFetch subquery) {
 		subselectsByEntityKey.put(key, subquery);
 	}
 
 	/**
 	 * After evicting or deleting an entity, we don't need to
 	 * know the query that was used to load it anymore (don't
 	 * call this after loading the entity, since we might still
 	 * need to load its collections)
 	 */
 	public void removeSubselect(EntityKey key) {
 		subselectsByEntityKey.remove(key);
 	}
 
 	/**
 	 * Clears all pending subselect fetches from the queue.
 	 * <p/>
 	 * Called after flushing.
 	 */
 	public void clearSubselects() {
 		subselectsByEntityKey.clear();
 	}
 
 	/**
 	 * If an EntityKey represents a batch loadable entity, add
 	 * it to the queue.
 	 * <p/>
 	 * Note that the contract here is such that any key passed in should
 	 * previously have been been checked for existence within the
 	 * {@link PersistenceContext}; failure to do so may cause the
 	 * referenced entity to be included in a batch even though it is
 	 * already associated with the {@link PersistenceContext}.
 	 */
 	public void addBatchLoadableEntityKey(EntityKey key) {
 		if ( key.isBatchLoadable() ) {
 			batchLoadableEntityKeys.put( key, MARKER );
 		}
 	}
 
 	/**
 	 * After evicting or deleting or loading an entity, we don't
 	 * need to batch fetch it anymore, remove it from the queue
 	 * if necessary
 	 */
 	public void removeBatchLoadableEntityKey(EntityKey key) {
 		if ( key.isBatchLoadable() ) batchLoadableEntityKeys.remove(key);
 	}
 
 	/**
 	 * Get a batch of uninitialized collection keys for a given role
 	 *
 	 * @param collectionPersister The persister for the collection role.
 	 * @param id A key that must be included in the batch fetch
 	 * @param batchSize the maximum number of keys to return
 	 * @return an array of collection keys, of length batchSize (padded with nulls)
 	 */
 	public Serializable[] getCollectionBatch(
 			final CollectionPersister collectionPersister,
 			final Serializable id,
 			final int batchSize,
 			final EntityMode entityMode) {
 		Serializable[] keys = new Serializable[batchSize];
 		keys[0] = id;
 		int i = 1;
 		//int count = 0;
 		int end = -1;
 		boolean checkForEnd = false;
 		// this only works because collection entries are kept in a sequenced
 		// map by persistence context (maybe we should do like entities and
 		// keep a separate sequences set...)
 		Iterator iter = context.getCollectionEntries().entrySet().iterator(); //TODO: calling entrySet on an IdentityMap is SLOW!!
 		while ( iter.hasNext() ) {
 			Map.Entry me = (Map.Entry) iter.next();
 
 			CollectionEntry ce = (CollectionEntry) me.getValue();
 			PersistentCollection collection = (PersistentCollection) me.getKey();
 			if ( !collection.wasInitialized() && ce.getLoadedPersister() == collectionPersister ) {
 
 				if ( checkForEnd && i == end ) {
 					return keys; //the first key found after the given key
 				}
 
 				//if ( end == -1 && count > batchSize*10 ) return keys; //try out ten batches, max
 
 				final boolean isEqual = collectionPersister.getKeyType().isEqual(
 						id,
 						ce.getLoadedKey(),
 						entityMode,
 						collectionPersister.getFactory()
 				);
 
 				if ( isEqual ) {
 					end = i;
 					//checkForEnd = false;
 				}
 				else if ( !isCached( ce.getLoadedKey(), collectionPersister ) ) {
 					keys[i++] = ce.getLoadedKey();
 					//count++;
 				}
 
 				if ( i == batchSize ) {
 					i = 1; //end of array, start filling again from start
 					if ( end != -1 ) {
 						checkForEnd = true;
 					}
 				}
 			}
 
 		}
 		return keys; //we ran out of keys to try
 	}
 
 	/**
 	 * Get a batch of unloaded identifiers for this class, using a slightly
 	 * complex algorithm that tries to grab keys registered immediately after
 	 * the given key.
 	 *
 	 * @param persister The persister for the entities being loaded.
 	 * @param id The identifier of the entity currently demanding load.
 	 * @param batchSize The maximum number of keys to return
 	 * @return an array of identifiers, of length batchSize (possibly padded with nulls)
 	 */
 	public Serializable[] getEntityBatch(
 			final EntityPersister persister,
 			final Serializable id,
 			final int batchSize,
 			final EntityMode entityMode) {
 		Serializable[] ids = new Serializable[batchSize];
 		ids[0] = id; //first element of array is reserved for the actual instance we are loading!
 		int i = 1;
 		int end = -1;
 		boolean checkForEnd = false;
 
 		Iterator iter = batchLoadableEntityKeys.keySet().iterator();
 		while ( iter.hasNext() ) {
 			EntityKey key = (EntityKey) iter.next();
 			if ( key.getEntityName().equals( persister.getEntityName() ) ) { //TODO: this needn't exclude subclasses...
 				if ( checkForEnd && i == end ) {
 					//the first id found after the given id
 					return ids;
 				}
 				if ( persister.getIdentifierType().isEqual( id, key.getIdentifier(), entityMode ) ) {
 					end = i;
 				}
 				else {
 					if ( !isCached( key, persister ) ) {
 						ids[i++] = key.getIdentifier();
 					}
 				}
 				if ( i == batchSize ) {
 					i = 1; //end of array, start filling again from start
 					if (end!=-1) checkForEnd = true;
 				}
 			}
 		}
 		return ids; //we ran out of ids to try
 	}
 
 	private boolean isCached(EntityKey entityKey, EntityPersister persister) {
 		if ( persister.hasCache() ) {
 			CacheKey key = context.getSession().generateCacheKey(
 					entityKey.getIdentifier(),
 					persister.getIdentifierType(),
 					entityKey.getEntityName()
 			);
 			return persister.getCacheAccessStrategy().get( key, context.getSession().getTimestamp() ) != null;
 		}
 		return false;
 	}
 
 	private boolean isCached(Serializable collectionKey, CollectionPersister persister) {
 		if ( persister.hasCache() ) {
 			CacheKey cacheKey = context.getSession().generateCacheKey(
 					collectionKey,
 			        persister.getKeyType(),
 			        persister.getRole()
 			);
 			return persister.getCacheAccessStrategy().get( cacheKey, context.getSession().getTimestamp() ) != null;
 		}
 		return false;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/SessionFactoryImplementor.java b/hibernate-core/src/main/java/org/hibernate/engine/SessionFactoryImplementor.java
index 950d67e654..1302c1f4b1 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/SessionFactoryImplementor.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/SessionFactoryImplementor.java
@@ -1,241 +1,241 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.engine;
 
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.MappingException;
 import org.hibernate.Session;
 import org.hibernate.SessionFactory;
 import org.hibernate.SessionFactoryObserver;
-import org.hibernate.cache.QueryCache;
-import org.hibernate.cache.Region;
-import org.hibernate.cache.UpdateTimestampsCache;
+import org.hibernate.cache.spi.QueryCache;
+import org.hibernate.cache.spi.Region;
+import org.hibernate.cache.spi.UpdateTimestampsCache;
 import org.hibernate.cfg.Settings;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.profile.FetchProfile;
 import org.hibernate.engine.query.QueryPlanCache;
 import org.hibernate.exception.SQLExceptionConverter;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.proxy.EntityNotFoundDelegate;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.stat.spi.StatisticsImplementor;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeResolver;
 
 /**
  * Defines the internal contract between the <tt>SessionFactory</tt> and other parts of
  * Hibernate such as implementors of <tt>Type</tt>.
  *
  * @see org.hibernate.SessionFactory
  * @see org.hibernate.internal.SessionFactoryImpl
  * @author Gavin King
  */
 public interface SessionFactoryImplementor extends Mapping, SessionFactory {
 	/**
 	 * Retrieve the {@link Type} resolver associated with this factory.
 	 *
 	 * @return The type resolver
 	 */
 	public TypeResolver getTypeResolver();
 
 	/**
 	 * Get a copy of the Properties used to configure this session factory.
 	 *
 	 * @return The properties.
 	 */
 	public Properties getProperties();
 
 	/**
 	 * Get the persister for the named entity
 	 *
 	 * @param entityName The name of the entity for which to retrieve the persister.
 	 * @return The persister
 	 * @throws MappingException Indicates persister could not be found with that name.
 	 */
 	public EntityPersister getEntityPersister(String entityName) throws MappingException;
 
 	/**
 	 * Get the persister object for a collection role.
 	 *
 	 * @param role The role (name) of the collection for which to retrieve the
 	 * persister.
 	 * @return The persister
 	 * @throws MappingException Indicates persister could not be found with that role.
 	 */
 	public CollectionPersister getCollectionPersister(String role) throws MappingException;
 
 	/**
 	 * Get the JdbcServices.
 	 * @return the JdbcServices
 	 */
 	public JdbcServices getJdbcServices();
 
 	/**
 	 * Get the SQL dialect.
 	 * <p/>
 	 * Shorthand for {@link #getJdbcServices().getDialect()}.{@link JdbcServices#getDialect()}
 	 *
 	 * @return The dialect
 	 */
 	public Dialect getDialect();
 
 	/**
 	 * Get the factory scoped interceptor for this factory.
 	 *
 	 * @return The factory scope interceptor, or null if none.
 	 */
 	public Interceptor getInterceptor();
 
 	public QueryPlanCache getQueryPlanCache();
 
 	/**
 	 * Get the return types of a query
 	 */
 	public Type[] getReturnTypes(String queryString) throws HibernateException;
 
 	/**
 	 * Get the return aliases of a query
 	 */
 	public String[] getReturnAliases(String queryString) throws HibernateException;
 
 	/**
 	 * Get the connection provider
 	 */
 	public ConnectionProvider getConnectionProvider();
 	/**
 	 * Get the names of all persistent classes that implement/extend the given interface/class
 	 */
 	public String[] getImplementors(String className) throws MappingException;
 	/**
 	 * Get a class name, using query language imports
 	 */
 	public String getImportedClassName(String name);
 
 	/**
 	 * Get the default query cache
 	 */
 	public QueryCache getQueryCache();
 	/**
 	 * Get a particular named query cache, or the default cache
 	 * @param regionName the name of the cache region, or null for the default query cache
 	 * @return the existing cache, or a newly created cache if none by that region name
 	 */
 	public QueryCache getQueryCache(String regionName) throws HibernateException;
 
 	/**
 	 * Get the cache of table update timestamps
 	 */
 	public UpdateTimestampsCache getUpdateTimestampsCache();
 	/**
 	 * Statistics SPI
 	 */
 	public StatisticsImplementor getStatisticsImplementor();
 
 	public NamedQueryDefinition getNamedQuery(String queryName);
 	public NamedSQLQueryDefinition getNamedSQLQuery(String queryName);
 	public ResultSetMappingDefinition getResultSetMapping(String name);
 
 	/**
 	 * Get the identifier generator for the hierarchy
 	 */
 	public IdentifierGenerator getIdentifierGenerator(String rootEntityName);
 
 	/**
 	 * Get a named second-level cache region
 	 *
 	 * @param regionName The name of the region to retrieve.
 	 * @return The region
 	 */
 	public Region getSecondLevelCacheRegion(String regionName);
 
 	/**
 	 * Get a map of all the second level cache regions currently maintained in
 	 * this session factory.  The map is structured with the region name as the
 	 * key and the {@link Region} instances as the values.
 	 *
 	 * @return The map of regions
 	 */
 	public Map getAllSecondLevelCacheRegions();
 
 	/**
 	 * Retrieves the SQLExceptionConverter in effect for this SessionFactory.
 	 *
 	 * @return The SQLExceptionConverter for this SessionFactory.
 	 *
 	 */
 	public SQLExceptionConverter getSQLExceptionConverter();
 	   // TODO: deprecate???
 
 	/**
 	 * Retrieves the SqlExceptionHelper in effect for this SessionFactory.
 	 *
 	 * @return The SqlExceptionHelper for this SessionFactory.
 	 *
 	 */
     public SqlExceptionHelper getSQLExceptionHelper();
 
 	public Settings getSettings();
 
 	/**
 	 * Get a nontransactional "current" session for Hibernate EntityManager
 	 */
 	public Session openTemporarySession() throws HibernateException;
 
 	/**
 	 * Retrieves a set of all the collection roles in which the given entity
 	 * is a participant, as either an index or an element.
 	 *
 	 * @param entityName The entity name for which to get the collection roles.
 	 * @return set of all the collection roles in which the given entityName participates.
 	 */
 	public Set<String> getCollectionRolesByEntityParticipant(String entityName);
 
 	public EntityNotFoundDelegate getEntityNotFoundDelegate();
 
 	public SQLFunctionRegistry getSqlFunctionRegistry();
 
 	/**
 	 * Retrieve fetch profile by name.
 	 *
 	 * @param name The name of the profile to retrieve.
 	 * @return The profile definition
 	 */
 	public FetchProfile getFetchProfile(String name);
 
 	public ServiceRegistryImplementor getServiceRegistry();
 
 	public void addObserver(SessionFactoryObserver observer);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/SessionImplementor.java b/hibernate-core/src/main/java/org/hibernate/engine/SessionImplementor.java
index 4574015f4f..c4743e1703 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/SessionImplementor.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/SessionImplementor.java
@@ -1,392 +1,392 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import org.hibernate.CacheMode;
 import org.hibernate.EntityMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.Query;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
-import org.hibernate.cache.CacheKey;
+import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.jdbc.LobCreationContext;
 import org.hibernate.engine.jdbc.spi.JdbcConnectionAccess;
 import org.hibernate.engine.query.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.internal.CriteriaImpl;
 import org.hibernate.loader.custom.CustomQuery;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.type.Type;
 
 /**
  * Defines the internal contract between {@link org.hibernate.Session} / {@link org.hibernate.StatelessSession} and
  * other parts of Hibernate such as {@link Type}, {@link EntityPersister} and
  * {@link org.hibernate.persister.collection.CollectionPersister} implementors
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public interface SessionImplementor extends Serializable, LobCreationContext {
 	/**
 	 * Match te method on {@link org.hibernate.Session} and {@link org.hibernate.StatelessSession}
 	 *
 	 * @return The tenant identifier of this session
 	 */
 	public String getTenantIdentifier();
 
 	/**
 	 * Provides access to JDBC connections
 	 *
 	 * @return The contract for accessing JDBC connections.
 	 */
 	public JdbcConnectionAccess getJdbcConnectionAccess();
 
 	/**
 	 * Hide the changing requirements of entity key creation
 	 *
 	 * @param id The entity id
 	 * @param persister The entity persister
 	 *
 	 * @return The entity key
 	 */
 	public EntityKey generateEntityKey(Serializable id, EntityPersister persister);
 
 	/**
 	 * Hide the changing requirements of cache key creation.
 	 *
 	 * @param id The entity identifier or collection key.
 	 * @param type The type
 	 * @param entityOrRoleName The entity name or collection role.
 	 *
 	 * @return The cache key
 	 */
 	public CacheKey generateCacheKey(Serializable id, final Type type, final String entityOrRoleName);
 
 	/**
 	 * Retrieves the interceptor currently in use by this event source.
 	 *
 	 * @return The interceptor.
 	 */
 	public Interceptor getInterceptor();
 
 	/**
 	 * Enable/disable automatic cache clearing from after transaction
 	 * completion (for EJB3)
 	 */
 	public void setAutoClear(boolean enabled);
 
 	/**
 	 * Disable automatic transaction joining.  The really only has any effect for CMT transactions.  The default
 	 * Hibernate behavior is to auto join any active JTA transaction (register {@link javax.transaction.Synchronization}).
 	 * JPA however defines an explicit join transaction operation.
 	 *
 	 * See javax.persistence.EntityManager#joinTransaction
 	 */
 	public void disableTransactionAutoJoin();
 
 	/**
 	 * Does this <tt>Session</tt> have an active Hibernate transaction
 	 * or is there a JTA transaction in progress?
 	 */
 	public boolean isTransactionInProgress();
 
 	/**
 	 * Initialize the collection (if not already initialized)
 	 */
 	public void initializeCollection(PersistentCollection collection, boolean writing)
 	throws HibernateException;
 
 	/**
 	 * Load an instance without checking if it was deleted.
 	 *
 	 * When <tt>nullable</tt> is disabled this method may create a new proxy or
 	 * return an existing proxy; if it does not exist, throw an exception.
 	 *
 	 * When <tt>nullable</tt> is enabled, the method does not create new proxies
 	 * (but might return an existing proxy); if it does not exist, return
 	 * <tt>null</tt>.
 	 *
 	 * When <tt>eager</tt> is enabled, the object is eagerly fetched
 	 */
 	public Object internalLoad(String entityName, Serializable id, boolean eager, boolean nullable)
 	throws HibernateException;
 
 	/**
 	 * Load an instance immediately. This method is only called when lazily initializing a proxy.
 	 * Do not return the proxy.
 	 */
 	public Object immediateLoad(String entityName, Serializable id) throws HibernateException;
 
 	/**
 	 * System time before the start of the transaction
 	 */
 	public long getTimestamp();
 	/**
 	 * Get the creating <tt>SessionFactoryImplementor</tt>
 	 */
 	public SessionFactoryImplementor getFactory();
 
 	/**
 	 * Execute a <tt>find()</tt> query
 	 */
 	public List list(String query, QueryParameters queryParameters) throws HibernateException;
 	/**
 	 * Execute an <tt>iterate()</tt> query
 	 */
 	public Iterator iterate(String query, QueryParameters queryParameters) throws HibernateException;
 	/**
 	 * Execute a <tt>scroll()</tt> query
 	 */
 	public ScrollableResults scroll(String query, QueryParameters queryParameters) throws HibernateException;
 	/**
 	 * Execute a criteria query
 	 */
 	public ScrollableResults scroll(CriteriaImpl criteria, ScrollMode scrollMode);
 	/**
 	 * Execute a criteria query
 	 */
 	public List list(CriteriaImpl criteria);
 
 	/**
 	 * Execute a filter
 	 */
 	public List listFilter(Object collection, String filter, QueryParameters queryParameters) throws HibernateException;
 	/**
 	 * Iterate a filter
 	 */
 	public Iterator iterateFilter(Object collection, String filter, QueryParameters queryParameters) throws HibernateException;
 
 	/**
 	 * Get the <tt>EntityPersister</tt> for any instance
 	 * @param entityName optional entity name
 	 * @param object the entity instance
 	 */
 	public EntityPersister getEntityPersister(String entityName, Object object) throws HibernateException;
 
 	/**
 	 * Get the entity instance associated with the given <tt>Key</tt>,
 	 * calling the Interceptor if necessary
 	 */
 	public Object getEntityUsingInterceptor(EntityKey key) throws HibernateException;
 
 	/**
 	 * Return the identifier of the persistent object, or null if
 	 * not associated with the session
 	 */
 	public Serializable getContextEntityIdentifier(Object object);
 
 	/**
 	 * The best guess entity name for an entity not in an association
 	 */
 	public String bestGuessEntityName(Object object);
 
 	/**
 	 * The guessed entity name for an entity not in an association
 	 */
 	public String guessEntityName(Object entity) throws HibernateException;
 
 	/**
 	 * Instantiate the entity class, initializing with the given identifier
 	 */
 	public Object instantiate(String entityName, Serializable id) throws HibernateException;
 
 	/**
 	 * Execute an SQL Query
 	 */
 	public List listCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
 	throws HibernateException;
 
 	/**
 	 * Execute an SQL Query
 	 */
 	public ScrollableResults scrollCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
 	throws HibernateException;
 
 	/**
 	 * Execute a native SQL query, and return the results as a fully built list.
 	 *
 	 * @param spec The specification of the native SQL query to execute.
 	 * @param queryParameters The parameters by which to perform the execution.
 	 * @return The result list.
 	 * @throws HibernateException
 	 */
 	public List list(NativeSQLQuerySpecification spec, QueryParameters queryParameters)
 	throws HibernateException;
 
 	/**
 	 * Execute a native SQL query, and return the results as a scrollable result.
 	 *
 	 * @param spec The specification of the native SQL query to execute.
 	 * @param queryParameters The parameters by which to perform the execution.
 	 * @return The resulting scrollable result.
 	 * @throws HibernateException
 	 */
 	public ScrollableResults scroll(NativeSQLQuerySpecification spec, QueryParameters queryParameters)
 	throws HibernateException;
 
 	/**
 	 * Retreive the currently set value for a filter parameter.
 	 *
 	 * @param filterParameterName The filter parameter name in the format
 	 * {FILTER_NAME.PARAMETER_NAME}.
 	 * @return The filter parameter value.
 	 * @deprecated use #getLoadQueryInfluencers instead
 	 */
 	@Deprecated
     public Object getFilterParameterValue(String filterParameterName);
 
 	/**
 	 * Retreive the type for a given filter parrameter.
 	 *
 	 * @param filterParameterName The filter parameter name in the format
 	 * {FILTER_NAME.PARAMETER_NAME}.
 	 * @return The filter param type
 	 * @deprecated use #getLoadQueryInfluencers instead
 	 */
 	@Deprecated
     public Type getFilterParameterType(String filterParameterName);
 
 	/**
 	 * Return the currently enabled filters.  The filter map is keyed by filter
 	 * name, with values corresponding to the {@link org.hibernate.internal.FilterImpl}
 	 * instance.
 	 * @return The currently enabled filters.
 	 * @deprecated use #getLoadQueryInfluencers instead
 	 */
 	@Deprecated
     public Map getEnabledFilters();
 
 	public int getDontFlushFromFind();
 
 	//TODO: temporary
 
 	/**
 	 * Get the persistence context for this session
 	 */
 	public PersistenceContext getPersistenceContext();
 
 	/**
 	 * Execute a HQL update or delete query
 	 */
 	int executeUpdate(String query, QueryParameters queryParameters) throws HibernateException;
 
 	/**
 	 * Execute a native SQL update or delete query
 	 */
 	int executeNativeUpdate(NativeSQLQuerySpecification specification, QueryParameters queryParameters) throws HibernateException;
 
 
 	/**
 	 * Return changes to this session that have not been flushed yet.
 	 *
 	 * @return The non-flushed changes.
 	 */
 	public NonFlushedChanges getNonFlushedChanges() throws HibernateException;
 
 	/**
 	 * Apply non-flushed changes from a different session to this session. It is assumed
 	 * that this SessionImpl is "clean" (e.g., has no non-flushed changes, no cached entities,
 	 * no cached collections, no queued actions). The specified NonFlushedChanges object cannot
 	 * be bound to any session.
 	 * <p/>
 	 * @param nonFlushedChanges the non-flushed changes
 	 */
 	public void applyNonFlushedChanges(NonFlushedChanges nonFlushedChanges) throws HibernateException;
 
 	// copied from Session:
 
 	public EntityMode getEntityMode();
 	public CacheMode getCacheMode();
 	public void setCacheMode(CacheMode cm);
 	public boolean isOpen();
 	public boolean isConnected();
 	public FlushMode getFlushMode();
 	public void setFlushMode(FlushMode fm);
 	public Connection connection();
 	public void flush();
 
 	/**
 	 * Get a Query instance for a named query or named native SQL query
 	 */
 	public Query getNamedQuery(String name);
 	/**
 	 * Get a Query instance for a named native SQL query
 	 */
 	public Query getNamedSQLQuery(String name);
 
 	public boolean isEventSource();
 
 	public void afterScrollOperation();
 
 	/**
 	 * Get the <i>internal</i> fetch profile currently associated with this session.
 	 *
 	 * @return The current internal fetch profile, or null if none currently associated.
 	 * @deprecated use #getLoadQueryInfluencers instead
 	 */
 	@Deprecated
     public String getFetchProfile();
 
 	/**
 	 * Set the current <i>internal</i> fetch profile for this session.
 	 *
 	 * @param name The internal fetch profile name to use
 	 * @deprecated use #getLoadQueryInfluencers instead
 	 */
 	@Deprecated
     public void setFetchProfile(String name);
 
 	/**
 	 * Retrieve access to the session's transaction coordinator.
 	 *
 	 * @return The transaction coordinator.
 	 */
 	public TransactionCoordinator getTransactionCoordinator();
 
 	/**
 	 * Determine whether the session is closed.  Provided separately from
 	 * {@link #isOpen()} as this method does not attempt any JTA synchronization
 	 * registration, where as {@link #isOpen()} does; which makes this one
 	 * nicer to use for most internal purposes.
 	 *
 	 * @return True if the session is closed; false otherwise.
 	 */
 	public boolean isClosed();
 
 	/**
 	 * Get the load query influencers associated with this session.
 	 *
 	 * @return the load query influencers associated with this session;
 	 * should never be null.
 	 */
 	public LoadQueryInfluencers getLoadQueryInfluencers();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/TwoPhaseLoad.java b/hibernate-core/src/main/java/org/hibernate/engine/TwoPhaseLoad.java
index eea9204636..ec933dc79d 100755
--- a/hibernate-core/src/main/java/org/hibernate/engine/TwoPhaseLoad.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/TwoPhaseLoad.java
@@ -1,334 +1,334 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine;
 
 import java.io.Serializable;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.CacheMode;
 import org.hibernate.HibernateException;
+import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.bytecode.instrumentation.spi.LazyPropertyInitializer;
-import org.hibernate.cache.CacheKey;
-import org.hibernate.cache.entry.CacheEntry;
+import org.hibernate.cache.spi.entry.CacheEntry;
 import org.hibernate.event.EventType;
 import org.hibernate.event.PostLoadEvent;
 import org.hibernate.event.PostLoadEventListener;
 import org.hibernate.event.PreLoadEvent;
 import org.hibernate.event.PreLoadEventListener;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.property.BackrefPropertyAccessor;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.event.service.spi.EventListenerGroup;
 import org.hibernate.event.service.spi.EventListenerRegistry;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeHelper;
 
 /**
  * Functionality relating to Hibernate's two-phase loading process,
  * that may be reused by persisters that do not use the Loader
  * framework
  *
  * @author Gavin King
  */
 public final class TwoPhaseLoad {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class, TwoPhaseLoad.class.getName()
 	);
 
 	private TwoPhaseLoad() {}
 
 	/**
 	 * Register the "hydrated" state of an entity instance, after the first step of 2-phase loading.
 	 *
 	 * Add the "hydrated state" (an array) of an uninitialized entity to the session. We don't try
 	 * to resolve any associations yet, because there might be other entities waiting to be
 	 * read from the JDBC result set we are currently processing
 	 */
 	public static void postHydrate(
 		final EntityPersister persister,
 		final Serializable id,
 		final Object[] values,
 		final Object rowId,
 		final Object object,
 		final LockMode lockMode,
 		final boolean lazyPropertiesAreUnfetched,
 		final SessionImplementor session)
 	throws HibernateException {
 
 		Object version = Versioning.getVersion(values, persister);
 		session.getPersistenceContext().addEntry(
 				object,
 				Status.LOADING,
 				values,
 				rowId,
 				id,
 				version,
 				lockMode,
 				true,
 				persister,
 				false,
 				lazyPropertiesAreUnfetched
 			);
 
         if (LOG.isTraceEnabled() && version != null) {
 			String versionStr = persister.isVersioned()
 					? persister.getVersionType().toLoggableString( version, session.getFactory() )
 			        : "null";
             LOG.trace("Version: " + versionStr);
 		}
 
 	}
 
 	/**
 	 * Perform the second step of 2-phase load. Fully initialize the entity
 	 * instance.
 	 *
 	 * After processing a JDBC result set, we "resolve" all the associations
 	 * between the entities which were instantiated and had their state
 	 * "hydrated" into an array
 	 */
 	public static void initializeEntity(
 			final Object entity,
 			final boolean readOnly,
 			final SessionImplementor session,
 			final PreLoadEvent preLoadEvent,
 			final PostLoadEvent postLoadEvent) throws HibernateException {
 
 		//TODO: Should this be an InitializeEntityEventListener??? (watch out for performance!)
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		EntityEntry entityEntry = persistenceContext.getEntry(entity);
 		if ( entityEntry == null ) {
 			throw new AssertionFailure( "possible non-threadsafe access to the session" );
 		}
 		EntityPersister persister = entityEntry.getPersister();
 		Serializable id = entityEntry.getId();
 		Object[] hydratedState = entityEntry.getLoadedState();
 
         if (LOG.isDebugEnabled()) LOG.debugf(
 				"Resolving associations for %s",
 				MessageHelper.infoString( persister, id, session.getFactory() )
 		);
 
 		Type[] types = persister.getPropertyTypes();
 		for ( int i = 0; i < hydratedState.length; i++ ) {
 			final Object value = hydratedState[i];
 			if ( value!=LazyPropertyInitializer.UNFETCHED_PROPERTY && value!=BackrefPropertyAccessor.UNKNOWN ) {
 				hydratedState[i] = types[i].resolve( value, session, entity );
 			}
 		}
 
 		//Must occur after resolving identifiers!
 		if ( session.isEventSource() ) {
 			preLoadEvent.setEntity( entity ).setState( hydratedState ).setId( id ).setPersister( persister );
 
 			final EventListenerGroup<PreLoadEventListener> listenerGroup = session
 					.getFactory()
 					.getServiceRegistry()
 					.getService( EventListenerRegistry.class )
 					.getEventListenerGroup( EventType.PRE_LOAD );
 			for ( PreLoadEventListener listener : listenerGroup.listeners() ) {
 				listener.onPreLoad( preLoadEvent );
 			}
 		}
 
 		persister.setPropertyValues( entity, hydratedState, session.getEntityMode() );
 
 		final SessionFactoryImplementor factory = session.getFactory();
 		if ( persister.hasCache() && session.getCacheMode().isPutEnabled() ) {
 
             if (LOG.isDebugEnabled()) LOG.debugf(
 					"Adding entity to second-level cache: %s",
 					MessageHelper.infoString( persister, id, session.getFactory() )
 			);
 
 			Object version = Versioning.getVersion(hydratedState, persister);
 			CacheEntry entry = new CacheEntry(
 					hydratedState,
 					persister,
 					entityEntry.isLoadedWithLazyPropertiesUnfetched(),
 					version,
 					session,
 					entity
 			);
 			CacheKey cacheKey = session.generateCacheKey( id, persister.getIdentifierType(), persister.getRootEntityName() );
 
 			// explicit handling of caching for rows just inserted and then somehow forced to be read
 			// from the database *within the same transaction*.  usually this is done by
 			// 		1) Session#refresh, or
 			// 		2) Session#clear + some form of load
 			//
 			// we need to be careful not to clobber the lock here in the cache so that it can be rolled back if need be
 			if ( session.getPersistenceContext().wasInsertedDuringTransaction( persister, id ) ) {
 				persister.getCacheAccessStrategy().update(
 						cacheKey,
 						persister.getCacheEntryStructure().structure( entry ),
 						version,
 						version
 				);
 			}
 			else {
 				boolean put = persister.getCacheAccessStrategy().putFromLoad(
 						cacheKey,
 						persister.getCacheEntryStructure().structure( entry ),
 						session.getTimestamp(),
 						version,
 						useMinimalPuts( session, entityEntry )
 				);
 
 				if ( put && factory.getStatistics().isStatisticsEnabled() ) {
 					factory.getStatisticsImplementor().secondLevelCachePut( persister.getCacheAccessStrategy().getRegion().getName() );
 				}
 			}
 		}
 
 		boolean isReallyReadOnly = readOnly;
 		if ( !persister.isMutable() ) {
 			isReallyReadOnly = true;
 		}
 		else {
 			Object proxy = persistenceContext.getProxy( entityEntry.getEntityKey() );
 			if ( proxy != null ) {
 				// there is already a proxy for this impl
 				// only set the status to read-only if the proxy is read-only
 				isReallyReadOnly = ( ( HibernateProxy ) proxy ).getHibernateLazyInitializer().isReadOnly();
 			}
 		}
 		if ( isReallyReadOnly ) {
 			//no need to take a snapshot - this is a
 			//performance optimization, but not really
 			//important, except for entities with huge
 			//mutable property values
 			persistenceContext.setEntryStatus(entityEntry, Status.READ_ONLY);
 		}
 		else {
 			//take a snapshot
 			TypeHelper.deepCopy(
 					hydratedState,
 					persister.getPropertyTypes(),
 					persister.getPropertyUpdateability(),
 					hydratedState,  //after setting values to object, entityMode
 					session
 			);
 			persistenceContext.setEntryStatus(entityEntry, Status.MANAGED);
 		}
 
 		persister.afterInitialize(
 				entity,
 				entityEntry.isLoadedWithLazyPropertiesUnfetched(),
 				session
 			);
 
 		if ( session.isEventSource() ) {
 			postLoadEvent.setEntity( entity ).setId( id ).setPersister( persister );
 
 			final EventListenerGroup<PostLoadEventListener> listenerGroup = session
 					.getFactory()
 					.getServiceRegistry()
 					.getService( EventListenerRegistry.class )
 					.getEventListenerGroup( EventType.POST_LOAD );
 			for ( PostLoadEventListener listener : listenerGroup.listeners() ) {
 				listener.onPostLoad( postLoadEvent );
 			}
 		}
 
         if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"Done materializing entity %s",
 					MessageHelper.infoString( persister, id, session.getFactory() )
 			);
 		}
 
 		if ( factory.getStatistics().isStatisticsEnabled() ) {
 			factory.getStatisticsImplementor().loadEntity( persister.getEntityName() );
 		}
 
 	}
 
 	private static boolean useMinimalPuts(SessionImplementor session, EntityEntry entityEntry) {
 		return ( session.getFactory().getSettings().isMinimalPutsEnabled() &&
 						session.getCacheMode()!=CacheMode.REFRESH ) ||
 				( entityEntry.getPersister().hasLazyProperties() &&
 						entityEntry.isLoadedWithLazyPropertiesUnfetched() &&
 						entityEntry.getPersister().isLazyPropertiesCacheable() );
 	}
 
 	/**
 	 * Add an uninitialized instance of an entity class, as a placeholder to ensure object
 	 * identity. Must be called before <tt>postHydrate()</tt>.
 	 *
 	 * Create a "temporary" entry for a newly instantiated entity. The entity is uninitialized,
 	 * but we need the mapping from id to instance in order to guarantee uniqueness.
 	 */
 	public static void addUninitializedEntity(
 			final EntityKey key,
 			final Object object,
 			final EntityPersister persister,
 			final LockMode lockMode,
 			final boolean lazyPropertiesAreUnfetched,
 			final SessionImplementor session
 	) {
 		session.getPersistenceContext().addEntity(
 				object,
 				Status.LOADING,
 				null,
 				key,
 				null,
 				lockMode,
 				true,
 				persister,
 				false,
 				lazyPropertiesAreUnfetched
 			);
 	}
 
 	public static void addUninitializedCachedEntity(
 			final EntityKey key,
 			final Object object,
 			final EntityPersister persister,
 			final LockMode lockMode,
 			final boolean lazyPropertiesAreUnfetched,
 			final Object version,
 			final SessionImplementor session
 	) {
 		session.getPersistenceContext().addEntity(
 				object,
 				Status.LOADING,
 				null,
 				key,
 				version,
 				lockMode,
 				true,
 				persister,
 				false,
 				lazyPropertiesAreUnfetched
 			);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/loading/CollectionLoadContext.java b/hibernate-core/src/main/java/org/hibernate/engine/loading/CollectionLoadContext.java
index ebe4480703..5fd523e908 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/loading/CollectionLoadContext.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/loading/CollectionLoadContext.java
@@ -1,343 +1,343 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.loading;
 
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.CacheMode;
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
+import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.internal.CoreMessageLogger;
-import org.hibernate.cache.CacheKey;
-import org.hibernate.cache.entry.CollectionCacheEntry;
+import org.hibernate.cache.spi.entry.CollectionCacheEntry;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.CollectionEntry;
 import org.hibernate.engine.CollectionKey;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.Status;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.pretty.MessageHelper;
 
 /**
  * Represents state associated with the processing of a given {@link ResultSet}
  * in regards to loading collections.
  * <p/>
  * Another implementation option to consider is to not expose {@link ResultSet}s
  * directly (in the JDBC redesign) but to always "wrap" them and apply a
  * [series of] context[s] to that wrapper.
  *
  * @author Steve Ebersole
  */
 public class CollectionLoadContext {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, CollectionLoadContext.class.getName());
 
 	private final LoadContexts loadContexts;
 	private final ResultSet resultSet;
 	private Set localLoadingCollectionKeys = new HashSet();
 
 	/**
 	 * Creates a collection load context for the given result set.
 	 *
 	 * @param loadContexts Callback to other collection load contexts.
 	 * @param resultSet The result set this is "wrapping".
 	 */
 	public CollectionLoadContext(LoadContexts loadContexts, ResultSet resultSet) {
 		this.loadContexts = loadContexts;
 		this.resultSet = resultSet;
 	}
 
 	public ResultSet getResultSet() {
 		return resultSet;
 	}
 
 	public LoadContexts getLoadContext() {
 		return loadContexts;
 	}
 
 	/**
 	 * Retrieve the collection that is being loaded as part of processing this
 	 * result set.
 	 * <p/>
 	 * Basically, there are two valid return values from this method:<ul>
 	 * <li>an instance of {@link PersistentCollection} which indicates to
 	 * continue loading the result set row data into that returned collection
 	 * instance; this may be either an instance already associated and in the
 	 * midst of being loaded, or a newly instantiated instance as a matching
 	 * associated collection was not found.</li>
 	 * <li><i>null</i> indicates to ignore the corresponding result set row
 	 * data relating to the requested collection; this indicates that either
 	 * the collection was found to already be associated with the persistence
 	 * context in a fully loaded state, or it was found in a loading state
 	 * associated with another result set processing context.</li>
 	 * </ul>
 	 *
 	 * @param persister The persister for the collection being requested.
 	 * @param key The key of the collection being requested.
 	 *
 	 * @return The loading collection (see discussion above).
 	 */
 	public PersistentCollection getLoadingCollection(final CollectionPersister persister, final Serializable key) {
 		final EntityMode em = loadContexts.getPersistenceContext().getSession().getEntityMode();
 		final CollectionKey collectionKey = new CollectionKey( persister, key, em );
         if (LOG.isTraceEnabled()) LOG.trace("Starting attempt to find loading collection ["
                                             + MessageHelper.collectionInfoString(persister.getRole(), key) + "]");
 		final LoadingCollectionEntry loadingCollectionEntry = loadContexts.locateLoadingCollectionEntry( collectionKey );
 		if ( loadingCollectionEntry == null ) {
 			// look for existing collection as part of the persistence context
 			PersistentCollection collection = loadContexts.getPersistenceContext().getCollection( collectionKey );
 			if ( collection != null ) {
 				if ( collection.wasInitialized() ) {
                     LOG.trace("Collection already initialized; ignoring");
 					return null; // ignore this row of results! Note the early exit
                 }
                 LOG.trace("Collection not yet initialized; initializing");
 			}
 			else {
 				Object owner = loadContexts.getPersistenceContext().getCollectionOwner( key, persister );
 				final boolean newlySavedEntity = owner != null
 						&& loadContexts.getPersistenceContext().getEntry( owner ).getStatus() != Status.LOADING
 						&& em != EntityMode.DOM4J;
 				if ( newlySavedEntity ) {
 					// important, to account for newly saved entities in query
 					// todo : some kind of check for new status...
                     LOG.trace("Owning entity already loaded; ignoring");
 					return null;
 				}
                 // create one
                 LOG.trace("Instantiating new collection [key=" + key + ", rs=" + resultSet + "]");
                 collection = persister.getCollectionType().instantiate(loadContexts.getPersistenceContext().getSession(),
                                                                        persister,
                                                                        key);
 			}
 			collection.beforeInitialize( persister, -1 );
 			collection.beginRead();
 			localLoadingCollectionKeys.add( collectionKey );
 			loadContexts.registerLoadingCollectionXRef( collectionKey, new LoadingCollectionEntry( resultSet, persister, key, collection ) );
 			return collection;
 		}
         if (loadingCollectionEntry.getResultSet() == resultSet) {
             LOG.trace("Found loading collection bound to current result set processing; reading row");
             return loadingCollectionEntry.getCollection();
 		}
         // ignore this row, the collection is in process of
         // being loaded somewhere further "up" the stack
         LOG.trace("Collection is already being initialized; ignoring row");
         return null;
 	}
 
 	/**
 	 * Finish the process of collection-loading for this bound result set.  Mainly this
 	 * involves cleaning up resources and notifying the collections that loading is
 	 * complete.
 	 *
 	 * @param persister The persister for which to complete loading.
 	 */
 	public void endLoadingCollections(CollectionPersister persister) {
 		SessionImplementor session = getLoadContext().getPersistenceContext().getSession();
 		if ( !loadContexts.hasLoadingCollectionEntries()
 				&& localLoadingCollectionKeys.isEmpty() ) {
 			return;
 		}
 
 		// in an effort to avoid concurrent-modification-exceptions (from
 		// potential recursive calls back through here as a result of the
 		// eventual call to PersistentCollection#endRead), we scan the
 		// internal loadingCollections map for matches and store those matches
 		// in a temp collection.  the temp collection is then used to "drive"
 		// the #endRead processing.
 		List matches = null;
 		Iterator iter = localLoadingCollectionKeys.iterator();
 		while ( iter.hasNext() ) {
 			final CollectionKey collectionKey = (CollectionKey) iter.next();
 			final LoadingCollectionEntry lce = loadContexts.locateLoadingCollectionEntry( collectionKey );
             if (lce == null) LOG.loadingCollectionKeyNotFound(collectionKey);
 			else if ( lce.getResultSet() == resultSet && lce.getPersister() == persister ) {
 				if ( matches == null ) {
 					matches = new ArrayList();
 				}
 				matches.add( lce );
 				if ( lce.getCollection().getOwner() == null ) {
 					session.getPersistenceContext().addUnownedCollection(
 							new CollectionKey( persister, lce.getKey(), session.getEntityMode() ),
 							lce.getCollection()
 					);
 				}
                 LOG.trace("Removing collection load entry [" + lce + "]");
 
 				// todo : i'd much rather have this done from #endLoadingCollection(CollectionPersister,LoadingCollectionEntry)...
 				loadContexts.unregisterLoadingCollectionXRef( collectionKey );
 				iter.remove();
 			}
 		}
 
 		endLoadingCollections( persister, matches );
 		if ( localLoadingCollectionKeys.isEmpty() ) {
 			// todo : hack!!!
 			// NOTE : here we cleanup the load context when we have no more local
 			// LCE entries.  This "works" for the time being because really
 			// only the collection load contexts are implemented.  Long term,
 			// this cleanup should become part of the "close result set"
 			// processing from the (sandbox/jdbc) jdbc-container code.
 			loadContexts.cleanup( resultSet );
 		}
 	}
 
 	private void endLoadingCollections(CollectionPersister persister, List matchedCollectionEntries) {
 		if ( matchedCollectionEntries == null ) {
             LOG.debugf("No collections were found in result set for role: %s", persister.getRole());
 			return;
 		}
 
 		final int count = matchedCollectionEntries.size();
         LOG.debugf("%s collections were found in result set for role: %s", count, persister.getRole());
 
 		for ( int i = 0; i < count; i++ ) {
 			LoadingCollectionEntry lce = ( LoadingCollectionEntry ) matchedCollectionEntries.get( i );
 			endLoadingCollection( lce, persister );
 		}
 
         LOG.debugf("%s collections initialized for role: %s", count, persister.getRole());
 	}
 
 	private void endLoadingCollection(LoadingCollectionEntry lce, CollectionPersister persister) {
         LOG.trace("Ending loading collection [" + lce + "]");
 		final SessionImplementor session = getLoadContext().getPersistenceContext().getSession();
 		final EntityMode em = session.getEntityMode();
 
 		boolean hasNoQueuedAdds = lce.getCollection().endRead(); // warning: can cause a recursive calls! (proxy initialization)
 
 		if ( persister.getCollectionType().hasHolder( em ) ) {
 			getLoadContext().getPersistenceContext().addCollectionHolder( lce.getCollection() );
 		}
 
 		CollectionEntry ce = getLoadContext().getPersistenceContext().getCollectionEntry( lce.getCollection() );
 		if ( ce == null ) {
 			ce = getLoadContext().getPersistenceContext().addInitializedCollection( persister, lce.getCollection(), lce.getKey() );
 		}
 		else {
 			ce.postInitialize( lce.getCollection() );
 		}
 
 		boolean addToCache = hasNoQueuedAdds && // there were no queued additions
 				persister.hasCache() &&             // and the role has a cache
 				session.getCacheMode().isPutEnabled() &&
 				!ce.isDoremove();                   // and this is not a forced initialization during flush
         if (addToCache) addCollectionToCache(lce, persister);
 
         if (LOG.isDebugEnabled()) LOG.debugf("Collection fully initialized: %s",
                                              MessageHelper.collectionInfoString(persister, lce.getKey(), session.getFactory()));
         if (session.getFactory().getStatistics().isStatisticsEnabled()) session.getFactory().getStatisticsImplementor().loadCollection(persister.getRole());
 	}
 
 	/**
 	 * Add the collection to the second-level cache
 	 *
 	 * @param lce The entry representing the collection to add
 	 * @param persister The persister
 	 */
 	private void addCollectionToCache(LoadingCollectionEntry lce, CollectionPersister persister) {
 		final SessionImplementor session = getLoadContext().getPersistenceContext().getSession();
 		final SessionFactoryImplementor factory = session.getFactory();
 
         if (LOG.isDebugEnabled()) LOG.debugf("Caching collection: %s",
                                              MessageHelper.collectionInfoString(persister, lce.getKey(), factory));
 
 		if ( !session.getEnabledFilters().isEmpty() && persister.isAffectedByEnabledFilters( session ) ) {
 			// some filters affecting the collection are enabled on the session, so do not do the put into the cache.
             LOG.debugf("Refusing to add to cache due to enabled filters");
 			// todo : add the notion of enabled filters to the CacheKey to differentiate filtered collections from non-filtered;
 			//      but CacheKey is currently used for both collections and entities; would ideally need to define two seperate ones;
 			//      currently this works in conjuction with the check on
 			//      DefaultInitializeCollectionEventHandler.initializeCollectionFromCache() (which makes sure to not read from
 			//      cache with enabled filters).
 			return; // EARLY EXIT!!!!!
 		}
 
 		final Object version;
 		if ( persister.isVersioned() ) {
 			Object collectionOwner = getLoadContext().getPersistenceContext().getCollectionOwner( lce.getKey(), persister );
 			if ( collectionOwner == null ) {
 				// generally speaking this would be caused by the collection key being defined by a property-ref, thus
 				// the collection key and the owner key would not match up.  In this case, try to use the key of the
 				// owner instance associated with the collection itself, if one.  If the collection does already know
 				// about its owner, that owner should be the same instance as associated with the PC, but we do the
 				// resolution against the PC anyway just to be safe since the lookup should not be costly.
 				if ( lce.getCollection() != null ) {
 					Object linkedOwner = lce.getCollection().getOwner();
 					if ( linkedOwner != null ) {
 						final Serializable ownerKey = persister.getOwnerEntityPersister().getIdentifier( linkedOwner, session );
 						collectionOwner = getLoadContext().getPersistenceContext().getCollectionOwner( ownerKey, persister );
 					}
 				}
 				if ( collectionOwner == null ) {
 					throw new HibernateException(
 							"Unable to resolve owner of loading collection [" +
 									MessageHelper.collectionInfoString( persister, lce.getKey(), factory ) +
 									"] for second level caching"
 					);
 				}
 			}
 			version = getLoadContext().getPersistenceContext().getEntry( collectionOwner ).getVersion();
 		}
 		else {
 			version = null;
 		}
 
 		CollectionCacheEntry entry = new CollectionCacheEntry( lce.getCollection(), persister );
 		CacheKey cacheKey = session.generateCacheKey( lce.getKey(), persister.getKeyType(), persister.getRole() );
 		boolean put = persister.getCacheAccessStrategy().putFromLoad(
 				cacheKey,
 				persister.getCacheEntryStructure().structure(entry),
 				session.getTimestamp(),
 				version,
 				factory.getSettings().isMinimalPutsEnabled() && session.getCacheMode()!= CacheMode.REFRESH
 		);
 
 		if ( put && factory.getStatistics().isStatisticsEnabled() ) {
 			factory.getStatisticsImplementor().secondLevelCachePut( persister.getCacheAccessStrategy().getRegion().getName() );
 		}
 	}
 
 	void cleanup() {
         if (!localLoadingCollectionKeys.isEmpty()) LOG.localLoadingCollectionKeysCount(localLoadingCollectionKeys.size());
 		loadContexts.cleanupCollectionXRefs( localLoadingCollectionKeys );
 		localLoadingCollectionKeys.clear();
 	}
 
 
 	@Override
     public String toString() {
 		return super.toString() + "<rs=" + resultSet + ">";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/AbstractLockUpgradeEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/AbstractLockUpgradeEventListener.java
index 9c9d82b90a..9519ecfe09 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/def/AbstractLockUpgradeEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/AbstractLockUpgradeEventListener.java
@@ -1,114 +1,114 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 
 import org.jboss.logging.Logger;
 
+import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.ObjectDeletedException;
-import org.hibernate.cache.CacheKey;
-import org.hibernate.cache.access.SoftLock;
+import org.hibernate.cache.spi.access.SoftLock;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.Status;
 import org.hibernate.event.EventSource;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 
 /**
  * A convenience base class for listeners that respond to requests to perform a
  * pessimistic lock upgrade on an entity.
  *
  * @author Gavin King
  */
 public class AbstractLockUpgradeEventListener extends AbstractReassociateEventListener {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractLockUpgradeEventListener.class.getName());
 
 	/**
 	 * Performs a pessimistic lock upgrade on a given entity, if needed.
 	 *
 	 * @param object The entity for which to upgrade the lock.
 	 * @param entry The entity's EntityEntry instance.
 	 * @param lockOptions contains the requested lock mode.
 	 * @param source The session which is the source of the event being processed.
 	 */
 	protected void upgradeLock(Object object, EntityEntry entry, LockOptions lockOptions, EventSource source) {
 
 		LockMode requestedLockMode = lockOptions.getLockMode();
 		if ( requestedLockMode.greaterThan( entry.getLockMode() ) ) {
 			// The user requested a "greater" (i.e. more restrictive) form of
 			// pessimistic lock
 
 			if ( entry.getStatus() != Status.MANAGED ) {
 				throw new ObjectDeletedException(
 						"attempted to lock a deleted instance",
 						entry.getId(),
 						entry.getPersister().getEntityName()
 				);
 			}
 
 			final EntityPersister persister = entry.getPersister();
 
             if (LOG.isTraceEnabled()) LOG.trace("Locking "
                                                 + MessageHelper.infoString(persister, entry.getId(), source.getFactory())
                                                 + " in mode: " + requestedLockMode);
 
 			final SoftLock lock;
 			final CacheKey ck;
 			if ( persister.hasCache() ) {
 				ck = source.generateCacheKey( entry.getId(), persister.getIdentifierType(), persister.getRootEntityName() );
 				lock = persister.getCacheAccessStrategy().lockItem( ck, entry.getVersion() );
 			}
 			else {
 				ck = null;
 				lock = null;
 			}
 
 			try {
 				if ( persister.isVersioned() && requestedLockMode == LockMode.FORCE  ) {
 					// todo : should we check the current isolation mode explicitly?
 					Object nextVersion = persister.forceVersionIncrement(
 							entry.getId(), entry.getVersion(), source
 					);
 					entry.forceLocked( object, nextVersion );
 				}
 				else {
 					persister.lock( entry.getId(), entry.getVersion(), object, lockOptions, source );
 				}
 				entry.setLockMode(requestedLockMode);
 			}
 			finally {
 				// the database now holds a lock + the object is flushed from the cache,
 				// so release the soft lock
 				if ( persister.hasCache() ) {
 					persister.getCacheAccessStrategy().unlockItem( ck, lock );
 				}
 			}
 
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultInitializeCollectionEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultInitializeCollectionEventListener.java
index b3e789ba86..24163fbf99 100755
--- a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultInitializeCollectionEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultInitializeCollectionEventListener.java
@@ -1,146 +1,146 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 
 import java.io.Serializable;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
+import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.internal.CoreMessageLogger;
-import org.hibernate.cache.CacheKey;
-import org.hibernate.cache.entry.CollectionCacheEntry;
+import org.hibernate.cache.spi.entry.CollectionCacheEntry;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.CollectionEntry;
 import org.hibernate.engine.PersistenceContext;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.event.InitializeCollectionEvent;
 import org.hibernate.event.InitializeCollectionEventListener;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.pretty.MessageHelper;
 
 /**
  * @author Gavin King
  */
 public class DefaultInitializeCollectionEventListener implements InitializeCollectionEventListener {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DefaultInitializeCollectionEventListener.class.getName());
 
 	/**
 	 * called by a collection that wants to initialize itself
 	 */
 	public void onInitializeCollection(InitializeCollectionEvent event)
 	throws HibernateException {
 
 		PersistentCollection collection = event.getCollection();
 		SessionImplementor source = event.getSession();
 
 		CollectionEntry ce = source.getPersistenceContext().getCollectionEntry(collection);
 		if (ce==null) throw new HibernateException("collection was evicted");
 		if ( !collection.wasInitialized() ) {
             if (LOG.isTraceEnabled()) LOG.trace("Initializing collection "
                                                 + MessageHelper.collectionInfoString(ce.getLoadedPersister(),
                                                                                      ce.getLoadedKey(),
                                                                                      source.getFactory()));
 
             LOG.trace("Checking second-level cache");
 			final boolean foundInCache = initializeCollectionFromCache(
 					ce.getLoadedKey(),
 					ce.getLoadedPersister(),
 					collection,
 					source
 				);
 
             if (foundInCache) LOG.trace("Collection initialized from cache");
 			else {
                 LOG.trace("Collection not cached");
 				ce.getLoadedPersister().initialize( ce.getLoadedKey(), source );
                 LOG.trace("Collection initialized");
 
 				if ( source.getFactory().getStatistics().isStatisticsEnabled() ) {
 					source.getFactory().getStatisticsImplementor().fetchCollection(
 							ce.getLoadedPersister().getRole()
 						);
 				}
 			}
 		}
 	}
 
 	/**
 	 * Try to initialize a collection from the cache
 	 *
 	 * @param id The id of the collection of initialize
 	 * @param persister The collection persister
 	 * @param collection The collection to initialize
 	 * @param source The originating session
 	 * @return true if we were able to initialize the collection from the cache;
 	 * false otherwise.
 	 */
 	private boolean initializeCollectionFromCache(
 			Serializable id,
 			CollectionPersister persister,
 			PersistentCollection collection,
 			SessionImplementor source) {
 
 		if ( !source.getEnabledFilters().isEmpty() && persister.isAffectedByEnabledFilters( source ) ) {
             LOG.trace("Disregarding cached version (if any) of collection due to enabled filters");
 			return false;
 		}
 
 		final boolean useCache = persister.hasCache() &&
 				source.getCacheMode().isGetEnabled();
 
         if (!useCache) return false;
 
         final SessionFactoryImplementor factory = source.getFactory();
 
         final CacheKey ck = source.generateCacheKey( id, persister.getKeyType(), persister.getRole() );
         Object ce = persister.getCacheAccessStrategy().get(ck, source.getTimestamp());
 
 		if ( factory.getStatistics().isStatisticsEnabled() ) {
             if (ce == null) {
                 factory.getStatisticsImplementor()
 						.secondLevelCacheMiss( persister.getCacheAccessStrategy().getRegion().getName() );
             }
 			else {
                 factory.getStatisticsImplementor()
 						.secondLevelCacheHit( persister.getCacheAccessStrategy().getRegion().getName() );
             }
 		}
 
         if ( ce == null ) {
 			return false;
 		}
 
 		CollectionCacheEntry cacheEntry = (CollectionCacheEntry)persister.getCacheEntryStructure().destructure(ce, factory);
 
 		final PersistenceContext persistenceContext = source.getPersistenceContext();
         cacheEntry.assemble(collection, persister, persistenceContext.getCollectionOwner(id, persister));
         persistenceContext.getCollectionEntry(collection).postInitialize(collection);
         // addInitializedCollection(collection, persister, id);
         return true;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultLoadEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultLoadEventListener.java
index 9ceed6463f..d47cfe66ce 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultLoadEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultLoadEventListener.java
@@ -1,668 +1,668 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 
 import java.io.Serializable;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
+import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.NonUniqueObjectException;
 import org.hibernate.PersistentObjectException;
 import org.hibernate.TypeMismatchException;
-import org.hibernate.cache.CacheKey;
-import org.hibernate.cache.access.SoftLock;
-import org.hibernate.cache.entry.CacheEntry;
+import org.hibernate.cache.spi.access.SoftLock;
+import org.hibernate.cache.spi.entry.CacheEntry;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.PersistenceContext;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.Status;
 import org.hibernate.engine.TwoPhaseLoad;
 import org.hibernate.engine.Versioning;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.EventType;
 import org.hibernate.event.LoadEvent;
 import org.hibernate.event.LoadEventListener;
 import org.hibernate.event.PostLoadEvent;
 import org.hibernate.event.PostLoadEventListener;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.LazyInitializer;
 import org.hibernate.event.service.spi.EventListenerRegistry;
 import org.hibernate.type.EmbeddedComponentType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeHelper;
 
 /**
  * Defines the default load event listeners used by hibernate for loading entities
  * in response to generated load events.
  *
  * @author Steve Ebersole
  */
 public class DefaultLoadEventListener extends AbstractLockUpgradeEventListener implements LoadEventListener {
 
 	public static final Object REMOVED_ENTITY_MARKER = new Object();
 	public static final Object INCONSISTENT_RTN_CLASS_MARKER = new Object();
 	public static final LockMode DEFAULT_LOCK_MODE = LockMode.NONE;
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DefaultLoadEventListener.class.getName());
 
 
 	/**
 	 * Handle the given load event.
 	 *
 	 * @param event The load event to be handled.
 	 * @throws HibernateException
 	 */
 	public void onLoad(LoadEvent event, LoadEventListener.LoadType loadType) throws HibernateException {
 
 		final SessionImplementor source = event.getSession();
 
 		EntityPersister persister;
 		if ( event.getInstanceToLoad() != null ) {
 			persister = source.getEntityPersister( null, event.getInstanceToLoad() ); //the load() which takes an entity does not pass an entityName
 			event.setEntityClassName( event.getInstanceToLoad().getClass().getName() );
 		}
 		else {
 			persister = source.getFactory().getEntityPersister( event.getEntityClassName() );
 		}
 
 		if ( persister == null ) {
 			throw new HibernateException(
 					"Unable to locate persister: " +
 					event.getEntityClassName()
 				);
 		}
 
 		final Class idClass = persister.getIdentifierType().getReturnedClass();
 		if ( persister.getIdentifierType().isComponentType() && EntityMode.DOM4J == event.getSession().getEntityMode() ) {
 			// skip this check for composite-ids relating to dom4j entity-mode;
 			// alternatively, we could add a check to make sure the incoming id value is
 			// an instance of Element...
 		}
 		else {
 			if ( idClass != null && ! idClass.isInstance( event.getEntityId() ) ) {
 				// we may have the kooky jpa requirement of allowing find-by-id where
 				// "id" is the "simple pk value" of a dependent objects parent.  This
 				// is part of its generally goofy "derived identity" "feature"
 				if ( persister.getEntityMetamodel().getIdentifierProperty().isEmbedded() ) {
 					final EmbeddedComponentType dependentIdType =
 							(EmbeddedComponentType) persister.getEntityMetamodel().getIdentifierProperty().getType();
 					if ( dependentIdType.getSubtypes().length == 1 ) {
 						final Type singleSubType = dependentIdType.getSubtypes()[0];
 						if ( singleSubType.isEntityType() ) {
 							final EntityType dependentParentType = (EntityType) singleSubType;
 							final Type dependentParentIdType = dependentParentType.getIdentifierOrUniqueKeyType( source.getFactory() );
 							if ( dependentParentIdType.getReturnedClass().isInstance( event.getEntityId() ) ) {
 								// yep that's what we have...
 								loadByDerivedIdentitySimplePkValue(
 										event,
 										loadType,
 										persister,
 										dependentIdType,
 										source.getFactory().getEntityPersister( dependentParentType.getAssociatedEntityName() )
 								);
 								return;
 							}
 						}
 					}
 				}
 				throw new TypeMismatchException(
 						"Provided id of the wrong type for class " + persister.getEntityName() + ". Expected: " + idClass + ", got " + event.getEntityId().getClass()
 				);
 			}
 		}
 
 		final  EntityKey keyToLoad = source.generateEntityKey( event.getEntityId(), persister );
 
 		try {
 			if ( loadType.isNakedEntityReturned() ) {
 				//do not return a proxy!
 				//(this option indicates we are initializing a proxy)
 				event.setResult( load(event, persister, keyToLoad, loadType) );
 			}
 			else {
 				//return a proxy if appropriate
 				if ( event.getLockMode() == LockMode.NONE ) {
 					event.setResult( proxyOrLoad(event, persister, keyToLoad, loadType) );
 				}
 				else {
 					event.setResult( lockAndLoad(event, persister, keyToLoad, loadType, source) );
 				}
 			}
 		}
 		catch(HibernateException e) {
             LOG.unableToLoadCommand(e);
 			throw e;
 		}
 	}
 
 	private void loadByDerivedIdentitySimplePkValue(
 			LoadEvent event,
 			LoadEventListener.LoadType options,
 			EntityPersister dependentPersister,
 			EmbeddedComponentType dependentIdType,
 			EntityPersister parentPersister) {
 		final EntityKey parentEntityKey = event.getSession().generateEntityKey( event.getEntityId(), parentPersister );
 		final Object parent = doLoad( event, parentPersister, parentEntityKey, options );
 
 		final Serializable dependent = (Serializable) dependentIdType.instantiate( parent, event.getSession() );
 		dependentIdType.setPropertyValues( dependent, new Object[] {parent}, event.getSession().getEntityMode() );
 		final EntityKey dependentEntityKey = event.getSession().generateEntityKey( dependent, dependentPersister );
 		event.setEntityId( dependent );
 
 		event.setResult( doLoad( event, dependentPersister, dependentEntityKey, options ) );
 	}
 
 	/**
 	 * Performs the load of an entity.
 	 *
 	 * @param event The initiating load request event
 	 * @param persister The persister corresponding to the entity to be loaded
 	 * @param keyToLoad The key of the entity to be loaded
 	 * @param options The defined load options
 	 * @return The loaded entity.
 	 * @throws HibernateException
 	 */
 	protected Object load(
 		final LoadEvent event,
 		final EntityPersister persister,
 		final EntityKey keyToLoad,
 		final LoadEventListener.LoadType options) {
 
 		if ( event.getInstanceToLoad() != null ) {
 			if ( event.getSession().getPersistenceContext().getEntry( event.getInstanceToLoad() ) != null ) {
 				throw new PersistentObjectException(
 						"attempted to load into an instance that was already associated with the session: " +
 						MessageHelper.infoString( persister, event.getEntityId(), event.getSession().getFactory() )
 					);
 			}
 			persister.setIdentifier( event.getInstanceToLoad(), event.getEntityId(), event.getSession() );
 		}
 
 		Object entity = doLoad(event, persister, keyToLoad, options);
 
 		boolean isOptionalInstance = event.getInstanceToLoad() != null;
 
 		if ( !options.isAllowNulls() || isOptionalInstance ) {
 			if ( entity == null ) {
 				event.getSession().getFactory().getEntityNotFoundDelegate().handleEntityNotFound( event.getEntityClassName(), event.getEntityId() );
 			}
 		}
 
 		if ( isOptionalInstance && entity != event.getInstanceToLoad() ) {
 			throw new NonUniqueObjectException( event.getEntityId(), event.getEntityClassName() );
 		}
 
 		return entity;
 	}
 
 	/**
 	 * Based on configured options, will either return a pre-existing proxy,
 	 * generate a new proxy, or perform an actual load.
 	 *
 	 * @param event The initiating load request event
 	 * @param persister The persister corresponding to the entity to be loaded
 	 * @param keyToLoad The key of the entity to be loaded
 	 * @param options The defined load options
 	 * @return The result of the proxy/load operation.
 	 */
 	protected Object proxyOrLoad(
 		final LoadEvent event,
 		final EntityPersister persister,
 		final EntityKey keyToLoad,
 		final LoadEventListener.LoadType options) {
 
         if (LOG.isTraceEnabled()) LOG.trace("Loading entity: "
                                             + MessageHelper.infoString(persister,
                                                                              event.getEntityId(),
                                                                              event.getSession().getFactory()));
 
         // this class has no proxies (so do a shortcut)
         if (!persister.hasProxy()) return load(event, persister, keyToLoad, options);
         final PersistenceContext persistenceContext = event.getSession().getPersistenceContext();
 
 		// look for a proxy
         Object proxy = persistenceContext.getProxy(keyToLoad);
         if (proxy != null) return returnNarrowedProxy(event, persister, keyToLoad, options, persistenceContext, proxy);
         if (options.isAllowProxyCreation()) return createProxyIfNecessary(event, persister, keyToLoad, options, persistenceContext);
         // return a newly loaded object
         return load(event, persister, keyToLoad, options);
 	}
 
 	/**
 	 * Given a proxy, initialize it and/or narrow it provided either
 	 * is necessary.
 	 *
 	 * @param event The initiating load request event
 	 * @param persister The persister corresponding to the entity to be loaded
 	 * @param keyToLoad The key of the entity to be loaded
 	 * @param options The defined load options
 	 * @param persistenceContext The originating session
 	 * @param proxy The proxy to narrow
 	 * @return The created/existing proxy
 	 */
 	private Object returnNarrowedProxy(
 			final LoadEvent event,
 			final EntityPersister persister,
 			final EntityKey keyToLoad,
 			final LoadEventListener.LoadType options,
 			final PersistenceContext persistenceContext,
 			final Object proxy) {
         LOG.trace("Entity proxy found in session cache");
 		LazyInitializer li = ( (HibernateProxy) proxy ).getHibernateLazyInitializer();
 		if ( li.isUnwrap() ) {
 			return li.getImplementation();
 		}
 		Object impl = null;
 		if ( !options.isAllowProxyCreation() ) {
 			impl = load( event, persister, keyToLoad, options );
 			if ( impl == null ) {
 				event.getSession().getFactory().getEntityNotFoundDelegate().handleEntityNotFound( persister.getEntityName(), keyToLoad.getIdentifier());
 			}
 		}
 		return persistenceContext.narrowProxy( proxy, persister, keyToLoad, impl );
 	}
 
 	/**
 	 * If there is already a corresponding proxy associated with the
 	 * persistence context, return it; otherwise create a proxy, associate it
 	 * with the persistence context, and return the just-created proxy.
 	 *
 	 * @param event The initiating load request event
 	 * @param persister The persister corresponding to the entity to be loaded
 	 * @param keyToLoad The key of the entity to be loaded
 	 * @param options The defined load options
 	 * @param persistenceContext The originating session
 	 * @return The created/existing proxy
 	 */
 	private Object createProxyIfNecessary(
 			final LoadEvent event,
 			final EntityPersister persister,
 			final EntityKey keyToLoad,
 			final LoadEventListener.LoadType options,
 			final PersistenceContext persistenceContext) {
 		Object existing = persistenceContext.getEntity( keyToLoad );
 		if ( existing != null ) {
 			// return existing object or initialized proxy (unless deleted)
             LOG.trace("Entity found in session cache");
 			if ( options.isCheckDeleted() ) {
 				EntityEntry entry = persistenceContext.getEntry( existing );
 				Status status = entry.getStatus();
 				if ( status == Status.DELETED || status == Status.GONE ) {
 					return null;
 				}
 			}
 			return existing;
 		}
         LOG.trace("Creating new proxy for entity");
         // return new uninitialized proxy
         Object proxy = persister.createProxy(event.getEntityId(), event.getSession());
         persistenceContext.getBatchFetchQueue().addBatchLoadableEntityKey(keyToLoad);
         persistenceContext.addProxy(keyToLoad, proxy);
         return proxy;
 	}
 
 	/**
 	 * If the class to be loaded has been configured with a cache, then lock
 	 * given id in that cache and then perform the load.
 	 *
 	 * @param event The initiating load request event
 	 * @param persister The persister corresponding to the entity to be loaded
 	 * @param keyToLoad The key of the entity to be loaded
 	 * @param options The defined load options
 	 * @param source The originating session
 	 * @return The loaded entity
 	 * @throws HibernateException
 	 */
 	protected Object lockAndLoad(
 			final LoadEvent event,
 			final EntityPersister persister,
 			final EntityKey keyToLoad,
 			final LoadEventListener.LoadType options,
 			final SessionImplementor source) {
 		SoftLock lock = null;
 		final CacheKey ck;
 		if ( persister.hasCache() ) {
 			ck = source.generateCacheKey(
 					event.getEntityId(),
 					persister.getIdentifierType(),
 					persister.getRootEntityName()
 			);
 			lock = persister.getCacheAccessStrategy().lockItem( ck, null );
 		}
 		else {
 			ck = null;
 		}
 
 		Object entity;
 		try {
 			entity = load(event, persister, keyToLoad, options);
 		}
 		finally {
 			if ( persister.hasCache() ) {
 				persister.getCacheAccessStrategy().unlockItem( ck, lock );
 			}
 		}
 
 		return event.getSession().getPersistenceContext().proxyFor( persister, keyToLoad, entity );
 	}
 
 
 	/**
 	 * Coordinates the efforts to load a given entity.  First, an attempt is
 	 * made to load the entity from the session-level cache.  If not found there,
 	 * an attempt is made to locate it in second-level cache.  Lastly, an
 	 * attempt is made to load it directly from the datasource.
 	 *
 	 * @param event The load event
 	 * @param persister The persister for the entity being requested for load
 	 * @param keyToLoad The EntityKey representing the entity to be loaded.
 	 * @param options The load options.
 	 * @return The loaded entity, or null.
 	 */
 	protected Object doLoad(
 			final LoadEvent event,
 			final EntityPersister persister,
 			final EntityKey keyToLoad,
 			final LoadEventListener.LoadType options) {
 
         if (LOG.isTraceEnabled()) LOG.trace("Attempting to resolve: "
                                             + MessageHelper.infoString(persister,
                                                                        event.getEntityId(),
                                                                        event.getSession().getFactory()));
 
 		Object entity = loadFromSessionCache( event, keyToLoad, options );
 		if ( entity == REMOVED_ENTITY_MARKER ) {
             LOG.debugf("Load request found matching entity in context, but it is scheduled for removal; returning null");
 			return null;
 		}
 		if ( entity == INCONSISTENT_RTN_CLASS_MARKER ) {
             LOG.debugf("Load request found matching entity in context, but the matched entity was of an inconsistent return type; returning null");
 			return null;
 		}
 		if ( entity != null ) {
             if (LOG.isTraceEnabled()) LOG.trace("Resolved object in session cache: "
                                                 + MessageHelper.infoString(persister,
                                                                            event.getEntityId(),
                                                                            event.getSession().getFactory()));
 			return entity;
 		}
 
 		entity = loadFromSecondLevelCache(event, persister, options);
 		if ( entity != null ) {
             if (LOG.isTraceEnabled()) LOG.trace("Resolved object in second-level cache: "
                                                 + MessageHelper.infoString(persister,
                                                                            event.getEntityId(),
                                                                            event.getSession().getFactory()));
 			return entity;
 		}
 
         if (LOG.isTraceEnabled()) LOG.trace("Object not resolved in any cache: "
                                             + MessageHelper.infoString(persister,
                                                                        event.getEntityId(),
                                                                        event.getSession().getFactory()));
 
 		return loadFromDatasource(event, persister, keyToLoad, options);
 	}
 
 	/**
 	 * Performs the process of loading an entity from the configured
 	 * underlying datasource.
 	 *
 	 * @param event The load event
 	 * @param persister The persister for the entity being requested for load
 	 * @param keyToLoad The EntityKey representing the entity to be loaded.
 	 * @param options The load options.
 	 * @return The object loaded from the datasource, or null if not found.
 	 */
 	protected Object loadFromDatasource(
 			final LoadEvent event,
 			final EntityPersister persister,
 			final EntityKey keyToLoad,
 			final LoadEventListener.LoadType options) {
 		final SessionImplementor source = event.getSession();
 		Object entity = persister.load(
 				event.getEntityId(),
 				event.getInstanceToLoad(),
 				event.getLockOptions(),
 				source
 		);
 
 		if ( event.isAssociationFetch() && source.getFactory().getStatistics().isStatisticsEnabled() ) {
 			source.getFactory().getStatisticsImplementor().fetchEntity( event.getEntityClassName() );
 		}
 
 		return entity;
 	}
 
 	/**
 	 * Attempts to locate the entity in the session-level cache.
 	 * <p/>
 	 * If allowed to return nulls, then if the entity happens to be found in
 	 * the session cache, we check the entity type for proper handling
 	 * of entity hierarchies.
 	 * <p/>
 	 * If checkDeleted was set to true, then if the entity is found in the
 	 * session-level cache, it's current status within the session cache
 	 * is checked to see if it has previously been scheduled for deletion.
 	 *
 	 * @param event The load event
 	 * @param keyToLoad The EntityKey representing the entity to be loaded.
 	 * @param options The load options.
 	 * @return The entity from the session-level cache, or null.
 	 * @throws HibernateException Generally indicates problems applying a lock-mode.
 	 */
 	protected Object loadFromSessionCache(
 			final LoadEvent event,
 			final EntityKey keyToLoad,
 			final LoadEventListener.LoadType options) throws HibernateException {
 
 		SessionImplementor session = event.getSession();
 		Object old = session.getEntityUsingInterceptor( keyToLoad );
 
 		if ( old != null ) {
 			// this object was already loaded
 			EntityEntry oldEntry = session.getPersistenceContext().getEntry( old );
 			if ( options.isCheckDeleted() ) {
 				Status status = oldEntry.getStatus();
 				if ( status == Status.DELETED || status == Status.GONE ) {
 					return REMOVED_ENTITY_MARKER;
 				}
 			}
 			if ( options.isAllowNulls() ) {
 //				EntityPersister persister = event.getSession().getFactory().getEntityPersister( event.getEntityClassName() );
 				EntityPersister persister = event.getSession().getFactory().getEntityPersister( keyToLoad.getEntityName() );
 				if ( ! persister.isInstance( old, event.getSession().getEntityMode() ) ) {
 					return INCONSISTENT_RTN_CLASS_MARKER;
 				}
 			}
 			upgradeLock( old, oldEntry, event.getLockOptions(), event.getSession() );
 		}
 
 		return old;
 	}
 
 	/**
 	 * Attempts to load the entity from the second-level cache.
 	 *
 	 * @param event The load event
 	 * @param persister The persister for the entity being requested for load
 	 * @param options The load options.
 	 * @return The entity from the second-level cache, or null.
 	 */
 	protected Object loadFromSecondLevelCache(
 			final LoadEvent event,
 			final EntityPersister persister,
 			final LoadEventListener.LoadType options) {
 
 		final SessionImplementor source = event.getSession();
 
 		final boolean useCache = persister.hasCache()
 				&& source.getCacheMode().isGetEnabled()
 				&& event.getLockMode().lessThan(LockMode.READ);
 
 		if ( useCache ) {
 
 			final SessionFactoryImplementor factory = source.getFactory();
 
 			final CacheKey ck = source.generateCacheKey(
 					event.getEntityId(),
 					persister.getIdentifierType(),
 					persister.getRootEntityName()
 			);
 			Object ce = persister.getCacheAccessStrategy().get( ck, source.getTimestamp() );
 			if ( factory.getStatistics().isStatisticsEnabled() ) {
 				if ( ce == null ) {
 					factory.getStatisticsImplementor().secondLevelCacheMiss(
 							persister.getCacheAccessStrategy().getRegion().getName()
 					);
 				}
 				else {
 					factory.getStatisticsImplementor().secondLevelCacheHit(
 							persister.getCacheAccessStrategy().getRegion().getName()
 					);
 				}
 			}
 
 			if ( ce != null ) {
 				CacheEntry entry = (CacheEntry) persister.getCacheEntryStructure().destructure( ce, factory );
 
 				// Entity was found in second-level cache...
 				return assembleCacheEntry(
 						entry,
 						event.getEntityId(),
 						persister,
 						event
 				);
 			}
 		}
 
 		return null;
 	}
 
 	private Object assembleCacheEntry(
 			final CacheEntry entry,
 			final Serializable id,
 			final EntityPersister persister,
 			final LoadEvent event) throws HibernateException {
 
 		final Object optionalObject = event.getInstanceToLoad();
 		final EventSource session = event.getSession();
 		final SessionFactoryImplementor factory = session.getFactory();
 
         if (LOG.isTraceEnabled()) LOG.trace("Assembling entity from second-level cache: "
                                             + MessageHelper.infoString(persister, id, factory));
 
 		EntityPersister subclassPersister = factory.getEntityPersister( entry.getSubclass() );
 		Object result = optionalObject == null ?
 				session.instantiate( subclassPersister, id ) : optionalObject;
 
 		// make it circular-reference safe
 		final EntityKey entityKey = session.generateEntityKey( id, subclassPersister );
 		TwoPhaseLoad.addUninitializedCachedEntity(
 				entityKey,
 				result,
 				subclassPersister,
 				LockMode.NONE,
 				entry.areLazyPropertiesUnfetched(),
 				entry.getVersion(),
 				session
 			);
 
 		Type[] types = subclassPersister.getPropertyTypes();
 		Object[] values = entry.assemble( result, id, subclassPersister, session.getInterceptor(), session ); // intializes result by side-effect
 		TypeHelper.deepCopy(
 				values,
 				types,
 				subclassPersister.getPropertyUpdateability(),
 				values,
 				session
 		);
 
 		Object version = Versioning.getVersion( values, subclassPersister );
         if (LOG.isTraceEnabled()) LOG.trace("Cached Version: " + version);
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		boolean isReadOnly = session.isDefaultReadOnly();
 		if ( persister.isMutable() ) {
 			Object proxy = persistenceContext.getProxy( entityKey );
 			if ( proxy != null ) {
 				// there is already a proxy for this impl
 				// only set the status to read-only if the proxy is read-only
 				isReadOnly = ( ( HibernateProxy ) proxy ).getHibernateLazyInitializer().isReadOnly();
 			}
 		}
 		else {
 			isReadOnly = true;
 		}
 		persistenceContext.addEntry(
 				result,
 				( isReadOnly ? Status.READ_ONLY : Status.MANAGED ),
 				values,
 				null,
 				id,
 				version,
 				LockMode.NONE,
 				true,
 				subclassPersister,
 				false,
 				entry.areLazyPropertiesUnfetched()
 			);
 		subclassPersister.afterInitialize( result, entry.areLazyPropertiesUnfetched(), session );
 		persistenceContext.initializeNonLazyCollections();
 		// upgrade the lock if necessary:
 		//lock(result, lockMode);
 
 		//PostLoad is needed for EJB3
 		//TODO: reuse the PostLoadEvent...
 		PostLoadEvent postLoadEvent = new PostLoadEvent( session )
 				.setEntity( result )
 				.setId( id )
 				.setPersister( persister );
 
 		for ( PostLoadEventListener listener : postLoadEventListeners( session ) ) {
 			listener.onPostLoad( postLoadEvent );
 		}
 
 		return result;
 	}
 
 	private Iterable<PostLoadEventListener> postLoadEventListeners(EventSource session) {
 		return session
 				.getFactory()
 				.getServiceRegistry()
 				.getService( EventListenerRegistry.class )
 				.getEventListenerGroup( EventType.POST_LOAD )
 				.listeners();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultRefreshEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultRefreshEventListener.java
index 37cd79cfe9..baf11a1994 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/def/DefaultRefreshEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/def/DefaultRefreshEventListener.java
@@ -1,176 +1,176 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.def;
 
 import java.io.Serializable;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.PersistentObjectException;
 import org.hibernate.UnresolvableObjectException;
-import org.hibernate.cache.CacheKey;
+import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.engine.Cascade;
 import org.hibernate.engine.CascadingAction;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.RefreshEvent;
 import org.hibernate.event.RefreshEventListener;
 import org.hibernate.internal.util.collections.IdentityMap;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.Type;
 
 /**
  * Defines the default refresh event listener used by hibernate for refreshing entities
  * in response to generated refresh events.
  *
  * @author Steve Ebersole
  */
 public class DefaultRefreshEventListener implements RefreshEventListener {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        DefaultRefreshEventListener.class.getName());
 
 	public void onRefresh(RefreshEvent event) throws HibernateException {
 		onRefresh( event, IdentityMap.instantiate(10) );
 	}
 
 	/**
 	 * Handle the given refresh event.
 	 *
 	 * @param event The refresh event to be handled.
 	 */
 	public void onRefresh(RefreshEvent event, Map refreshedAlready) {
 
 		final EventSource source = event.getSession();
 
 		boolean isTransient = ! source.contains( event.getObject() );
 		if ( source.getPersistenceContext().reassociateIfUninitializedProxy( event.getObject() ) ) {
 			if ( isTransient ) {
 				source.setReadOnly( event.getObject(), source.isDefaultReadOnly() );
 			}
 			return;
 		}
 
 		final Object object = source.getPersistenceContext().unproxyAndReassociate( event.getObject() );
 
 		if ( refreshedAlready.containsKey(object) ) {
             LOG.trace("Already refreshed");
 			return;
 		}
 
 		final EntityEntry e = source.getPersistenceContext().getEntry( object );
 		final EntityPersister persister;
 		final Serializable id;
 
 		if ( e == null ) {
 			persister = source.getEntityPersister(null, object); //refresh() does not pass an entityName
 			id = persister.getIdentifier( object, event.getSession() );
             if (LOG.isTraceEnabled()) LOG.trace("Refreshing transient "
                                                 + MessageHelper.infoString(persister, id, source.getFactory()));
 			final EntityKey key = source.generateEntityKey( id, persister );
 			if ( source.getPersistenceContext().getEntry(key) != null ) {
 				throw new PersistentObjectException(
 						"attempted to refresh transient instance when persistent instance was already associated with the Session: " +
 						MessageHelper.infoString(persister, id, source.getFactory() )
 					);
 			}
 		}
 		else {
             if (LOG.isTraceEnabled()) LOG.trace("Refreshing "
                                                 + MessageHelper.infoString(e.getPersister(), e.getId(), source.getFactory()));
 			if ( !e.isExistsInDatabase() ) {
 				throw new HibernateException( "this instance does not yet exist as a row in the database" );
 			}
 
 			persister = e.getPersister();
 			id = e.getId();
 		}
 
 		// cascade the refresh prior to refreshing this entity
 		refreshedAlready.put(object, object);
 		new Cascade(CascadingAction.REFRESH, Cascade.BEFORE_REFRESH, source)
 				.cascade( persister, object, refreshedAlready );
 
 		if ( e != null ) {
 			final EntityKey key = source.generateEntityKey( id, persister );
 			source.getPersistenceContext().removeEntity(key);
 			if ( persister.hasCollections() ) new EvictVisitor( source ).process(object, persister);
 		}
 
 		if ( persister.hasCache() ) {
 			final CacheKey ck = source.generateCacheKey(
 					id,
 					persister.getIdentifierType(),
 					persister.getRootEntityName()
 			);
 			persister.getCacheAccessStrategy().evict( ck );
 		}
 
 		evictCachedCollections( persister, id, source.getFactory() );
 
 		String previousFetchProfile = source.getFetchProfile();
 		source.setFetchProfile("refresh");
 		Object result = persister.load( id, object, event.getLockOptions(), source );
 		// Keep the same read-only/modifiable setting for the entity that it had before refreshing;
 		// If it was transient, then set it to the default for the source.
 		if ( result != null ) {
 			if ( ! persister.isMutable() ) {
 				// this is probably redundant; it should already be read-only
 				source.setReadOnly( result, true );
 			}
 			else {
 				source.setReadOnly( result, ( e == null ? source.isDefaultReadOnly() : e.isReadOnly() ) );
 			}
 		}
 		source.setFetchProfile(previousFetchProfile);
 
 		UnresolvableObjectException.throwIfNull( result, id, persister.getEntityName() );
 
 	}
 
 	private void evictCachedCollections(EntityPersister persister, Serializable id, SessionFactoryImplementor factory) {
 		evictCachedCollections( persister.getPropertyTypes(), id, factory );
 	}
 
 	private void evictCachedCollections(Type[] types, Serializable id, SessionFactoryImplementor factory)
 	throws HibernateException {
 		for ( int i = 0; i < types.length; i++ ) {
 			if ( types[i].isCollectionType() ) {
 				factory.evictCollection( ( (CollectionType) types[i] ).getRole(), id );
 			}
 			else if ( types[i].isComponentType() ) {
 				CompositeType actype = (CompositeType) types[i];
 				evictCachedCollections( actype.getSubtypes(), id, factory );
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/AbstractSessionImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/AbstractSessionImpl.java
index 1cb31ff28f..26156c03c7 100755
--- a/hibernate-core/src/main/java/org/hibernate/internal/AbstractSessionImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/AbstractSessionImpl.java
@@ -1,307 +1,307 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.List;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.MultiTenancyStrategy;
 import org.hibernate.Query;
 import org.hibernate.SQLQuery;
 import org.hibernate.ScrollableResults;
 import org.hibernate.SessionException;
 import org.hibernate.SharedSessionContract;
-import org.hibernate.cache.CacheKey;
+import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.NamedQueryDefinition;
 import org.hibernate.engine.NamedSQLQueryDefinition;
 import org.hibernate.engine.QueryParameters;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.jdbc.LobCreationContext;
 import org.hibernate.engine.jdbc.spi.JdbcConnectionAccess;
 import org.hibernate.engine.query.HQLQueryPlan;
 import org.hibernate.engine.query.NativeSQLQueryPlan;
 import org.hibernate.engine.query.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.transaction.spi.TransactionContext;
 import org.hibernate.engine.transaction.spi.TransactionEnvironment;
 import org.hibernate.jdbc.WorkExecutor;
 import org.hibernate.jdbc.WorkExecutorVisitable;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.service.jdbc.connections.spi.MultiTenantConnectionProvider;
 import org.hibernate.type.Type;
 
 /**
  * Functionality common to stateless and stateful sessions
  *
  * @author Gavin King
  */
 public abstract class AbstractSessionImpl implements Serializable, SharedSessionContract, SessionImplementor, TransactionContext {
 	protected transient SessionFactoryImpl factory;
 	private final String tenantIdentifier;
 	private boolean closed = false;
 
 	protected AbstractSessionImpl(SessionFactoryImpl factory, String tenantIdentifier) {
 		this.factory = factory;
 		this.tenantIdentifier = tenantIdentifier;
 		if ( MultiTenancyStrategy.NONE == factory.getSettings().getMultiTenancyStrategy() ) {
 			if ( tenantIdentifier != null ) {
 				throw new HibernateException( "SessionFactory was not configured for multi-tenancy" );
 			}
 		}
 		else {
 			if ( tenantIdentifier == null ) {
 				throw new HibernateException( "SessionFactory configured for multi-tenancy, but no tenant identifier specified" );
 			}
 		}
 	}
 
 	public SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	@Override
 	public TransactionEnvironment getTransactionEnvironment() {
 		return factory.getTransactionEnvironment();
 	}
 
 	@Override
 	public <T> T execute(final LobCreationContext.Callback<T> callback) {
 		return getTransactionCoordinator().getJdbcCoordinator().coordinateWork(
 				new WorkExecutorVisitable<T>() {
 					@Override
 					public T accept(WorkExecutor<T> workExecutor, Connection connection) throws SQLException {
 						try {
 							return callback.executeOnConnection( connection );
 						}
 						catch (SQLException e) {
 							throw getFactory().getSQLExceptionHelper().convert(
 									e,
 									"Error creating contextual LOB : " + e.getMessage()
 							);
 						}
 					}
 				}
 		);
 	}
 
 	@Override
 	public boolean isClosed() {
 		return closed;
 	}
 
 	protected void setClosed() {
 		closed = true;
 	}
 
 	protected void errorIfClosed() {
 		if ( closed ) {
 			throw new SessionException( "Session is closed!" );
 		}
 	}
 
 	@Override
 	public Query getNamedQuery(String queryName) throws MappingException {
 		errorIfClosed();
 		NamedQueryDefinition nqd = factory.getNamedQuery( queryName );
 		final Query query;
 		if ( nqd != null ) {
 			String queryString = nqd.getQueryString();
 			query = new QueryImpl(
 					queryString,
 			        nqd.getFlushMode(),
 			        this,
 			        getHQLQueryPlan( queryString, false ).getParameterMetadata()
 			);
 			query.setComment( "named HQL query " + queryName );
 		}
 		else {
 			NamedSQLQueryDefinition nsqlqd = factory.getNamedSQLQuery( queryName );
 			if ( nsqlqd==null ) {
 				throw new MappingException( "Named query not known: " + queryName );
 			}
 			query = new SQLQueryImpl(
 					nsqlqd,
 			        this,
 			        factory.getQueryPlanCache().getSQLParameterMetadata( nsqlqd.getQueryString() )
 			);
 			query.setComment( "named native SQL query " + queryName );
 			nqd = nsqlqd;
 		}
 		initQuery( query, nqd );
 		return query;
 	}
 
 	@Override
 	public Query getNamedSQLQuery(String queryName) throws MappingException {
 		errorIfClosed();
 		NamedSQLQueryDefinition nsqlqd = factory.getNamedSQLQuery( queryName );
 		if ( nsqlqd==null ) {
 			throw new MappingException( "Named SQL query not known: " + queryName );
 		}
 		Query query = new SQLQueryImpl(
 				nsqlqd,
 		        this,
 		        factory.getQueryPlanCache().getSQLParameterMetadata( nsqlqd.getQueryString() )
 		);
 		query.setComment( "named native SQL query " + queryName );
 		initQuery( query, nsqlqd );
 		return query;
 	}
 
 	private void initQuery(Query query, NamedQueryDefinition nqd) {
 		query.setCacheable( nqd.isCacheable() );
 		query.setCacheRegion( nqd.getCacheRegion() );
 		if ( nqd.getTimeout()!=null ) query.setTimeout( nqd.getTimeout().intValue() );
 		if ( nqd.getFetchSize()!=null ) query.setFetchSize( nqd.getFetchSize().intValue() );
 		if ( nqd.getCacheMode() != null ) query.setCacheMode( nqd.getCacheMode() );
 		query.setReadOnly( nqd.isReadOnly() );
 		if ( nqd.getComment() != null ) query.setComment( nqd.getComment() );
 	}
 
 	@Override
 	public Query createQuery(String queryString) {
 		errorIfClosed();
 		QueryImpl query = new QueryImpl(
 				queryString,
 		        this,
 		        getHQLQueryPlan( queryString, false ).getParameterMetadata()
 		);
 		query.setComment( queryString );
 		return query;
 	}
 
 	@Override
 	public SQLQuery createSQLQuery(String sql) {
 		errorIfClosed();
 		SQLQueryImpl query = new SQLQueryImpl(
 				sql,
 		        this,
 		        factory.getQueryPlanCache().getSQLParameterMetadata( sql )
 		);
 		query.setComment( "dynamic native SQL query" );
 		return query;
 	}
 
 	protected HQLQueryPlan getHQLQueryPlan(String query, boolean shallow) throws HibernateException {
 		return factory.getQueryPlanCache().getHQLQueryPlan( query, shallow, getEnabledFilters() );
 	}
 
 	protected NativeSQLQueryPlan getNativeSQLQueryPlan(NativeSQLQuerySpecification spec) throws HibernateException {
 		return factory.getQueryPlanCache().getNativeSQLQueryPlan( spec );
 	}
 
 	@Override
 	public List list(NativeSQLQuerySpecification spec, QueryParameters queryParameters)
 			throws HibernateException {
 		return listCustomQuery( getNativeSQLQueryPlan( spec ).getCustomQuery(), queryParameters );
 	}
 
 	@Override
 	public ScrollableResults scroll(NativeSQLQuerySpecification spec, QueryParameters queryParameters)
 			throws HibernateException {
 		return scrollCustomQuery( getNativeSQLQueryPlan( spec ).getCustomQuery(), queryParameters );
 	}
 
 	@Override
 	public String getTenantIdentifier() {
 		return tenantIdentifier;
 	}
 
 	@Override
 	public EntityKey generateEntityKey(Serializable id, EntityPersister persister) {
 		return new EntityKey( id, persister, getEntityMode(), getTenantIdentifier() );
 	}
 
 	@Override
 	public CacheKey generateCacheKey(Serializable id, Type type, String entityOrRoleName) {
 		return new CacheKey( id, type, entityOrRoleName, getEntityMode(), getTenantIdentifier(), getFactory() );
 	}
 
 	private transient JdbcConnectionAccess jdbcConnectionAccess;
 
 	@Override
 	public JdbcConnectionAccess getJdbcConnectionAccess() {
 		if ( jdbcConnectionAccess == null ) {
 			if ( MultiTenancyStrategy.NONE == factory.getSettings().getMultiTenancyStrategy() ) {
 				jdbcConnectionAccess = new NonContextualJdbcConnectionAccess(
 						factory.getServiceRegistry().getService( ConnectionProvider.class )
 				);
 			}
 			else {
 				jdbcConnectionAccess = new ContextualJdbcConnectionAccess(
 						factory.getServiceRegistry().getService( MultiTenantConnectionProvider.class )
 				);
 			}
 		}
 		return jdbcConnectionAccess;
 	}
 
 	private static class NonContextualJdbcConnectionAccess implements JdbcConnectionAccess, Serializable {
 		private final ConnectionProvider connectionProvider;
 
 		private NonContextualJdbcConnectionAccess(ConnectionProvider connectionProvider) {
 			this.connectionProvider = connectionProvider;
 		}
 
 		@Override
 		public Connection obtainConnection() throws SQLException {
 			return connectionProvider.getConnection();
 		}
 
 		@Override
 		public void releaseConnection(Connection connection) throws SQLException {
 			connectionProvider.closeConnection( connection );
 		}
 	}
 
 	private class ContextualJdbcConnectionAccess implements JdbcConnectionAccess, Serializable {
 		private final MultiTenantConnectionProvider connectionProvider;
 
 		private ContextualJdbcConnectionAccess(MultiTenantConnectionProvider connectionProvider) {
 			this.connectionProvider = connectionProvider;
 		}
 
 		@Override
 		public Connection obtainConnection() throws SQLException {
 			if ( tenantIdentifier == null ) {
 				throw new HibernateException( "Tenant identifier required!" );
 			}
 			return connectionProvider.getConnection( tenantIdentifier );
 		}
 
 		@Override
 		public void releaseConnection(Connection connection) throws SQLException {
 			if ( tenantIdentifier == null ) {
 				throw new HibernateException( "Tenant identifier required!" );
 			}
 			connectionProvider.releaseConnection( tenantIdentifier, connection );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
index fbde496e03..4ce1fd8cc6 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
@@ -1,1332 +1,1333 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import javax.naming.NamingException;
 import javax.naming.Reference;
 import javax.naming.StringRefAddr;
 import java.io.IOException;
 import java.io.InvalidObjectException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.ObjectStreamException;
 import java.io.Serializable;
 import java.sql.Connection;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashSet;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.Cache;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.EntityMode;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.MappingException;
 import org.hibernate.ObjectNotFoundException;
 import org.hibernate.QueryException;
 import org.hibernate.Session;
 import org.hibernate.SessionBuilder;
 import org.hibernate.SessionFactory;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.StatelessSession;
 import org.hibernate.StatelessSessionBuilder;
 import org.hibernate.TypeHelper;
-import org.hibernate.cache.CacheKey;
-import org.hibernate.cache.CollectionRegion;
-import org.hibernate.cache.EntityRegion;
-import org.hibernate.cache.QueryCache;
-import org.hibernate.cache.Region;
-import org.hibernate.cache.UpdateTimestampsCache;
-import org.hibernate.cache.access.AccessType;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
-import org.hibernate.cache.impl.CacheDataDescriptionImpl;
+import org.hibernate.cache.internal.CacheDataDescriptionImpl;
+import org.hibernate.cache.spi.CacheKey;
+import org.hibernate.cache.spi.CollectionRegion;
+import org.hibernate.cache.spi.EntityRegion;
+import org.hibernate.cache.spi.QueryCache;
+import org.hibernate.cache.spi.Region;
+import org.hibernate.cache.spi.UpdateTimestampsCache;
+import org.hibernate.cache.spi.access.AccessType;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Settings;
 import org.hibernate.context.CurrentSessionContext;
 import org.hibernate.context.JTASessionContext;
 import org.hibernate.context.ManagedSessionContext;
 import org.hibernate.context.ThreadLocalSessionContext;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.engine.FilterDefinition;
 import org.hibernate.engine.Mapping;
 import org.hibernate.engine.NamedQueryDefinition;
 import org.hibernate.engine.NamedSQLQueryDefinition;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.profile.Association;
 import org.hibernate.engine.profile.Fetch;
 import org.hibernate.engine.profile.FetchProfile;
 import org.hibernate.engine.query.QueryPlanCache;
 import org.hibernate.engine.query.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl;
 import org.hibernate.engine.transaction.spi.TransactionEnvironment;
 import org.hibernate.exception.SQLExceptionConverter;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.UUIDGenerator;
 import org.hibernate.id.factory.IdentifierGeneratorFactory;
 import org.hibernate.integrator.spi.Integrator;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.internal.util.collections.EmptyIterator;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.metadata.CollectionMetadata;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.persister.spi.PersisterFactory;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.EntityNotFoundDelegate;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.integrator.spi.IntegratorService;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.service.jndi.spi.JndiService;
 import org.hibernate.service.jta.platform.spi.JtaPlatform;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.spi.SessionFactoryServiceRegistry;
 import org.hibernate.service.spi.SessionFactoryServiceRegistryFactory;
 import org.hibernate.stat.Statistics;
 import org.hibernate.stat.spi.StatisticsImplementor;
 import org.hibernate.tool.hbm2ddl.SchemaExport;
 import org.hibernate.tool.hbm2ddl.SchemaUpdate;
 import org.hibernate.tool.hbm2ddl.SchemaValidator;
 import org.hibernate.tuple.entity.EntityTuplizer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeResolver;
 
 
 /**
  * Concrete implementation of the <tt>SessionFactory</tt> interface. Has the following
  * responsibilities
  * <ul>
  * <li>caches configuration settings (immutably)
  * <li>caches "compiled" mappings ie. <tt>EntityPersister</tt>s and
  *     <tt>CollectionPersister</tt>s (immutable)
  * <li>caches "compiled" queries (memory sensitive cache)
  * <li>manages <tt>PreparedStatement</tt>s
  * <li> delegates JDBC <tt>Connection</tt> management to the <tt>ConnectionProvider</tt>
  * <li>factory for instances of <tt>SessionImpl</tt>
  * </ul>
  * This class must appear immutable to clients, even if it does all kinds of caching
  * and pooling under the covers. It is crucial that the class is not only thread
  * safe, but also highly concurrent. Synchronization must be used extremely sparingly.
  *
  * @see org.hibernate.service.jdbc.connections.spi.ConnectionProvider
  * @see org.hibernate.Session
  * @see org.hibernate.hql.QueryTranslator
  * @see org.hibernate.persister.entity.EntityPersister
  * @see org.hibernate.persister.collection.CollectionPersister
  * @author Gavin King
  */
 public final class SessionFactoryImpl
 		implements SessionFactory, SessionFactoryImplementor {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SessionFactoryImpl.class.getName());
 	private static final IdentifierGenerator UUID_GENERATOR = UUIDGenerator.buildSessionFactoryUniqueIdentifierGenerator();
 
 	private final String name;
 	private final String uuid;
 
 	private final transient Map entityPersisters;
 	private final transient Map<String,ClassMetadata> classMetadata;
 	private final transient Map collectionPersisters;
 	private final transient Map collectionMetadata;
 	private final transient Map<String,Set<String>> collectionRolesByEntityParticipant;
 	private final transient Map identifierGenerators;
 	private final transient Map namedQueries;
 	private final transient Map namedSqlQueries;
 	private final transient Map sqlResultSetMappings;
 	private final transient Map filters;
 	private final transient Map fetchProfiles;
 	private final transient Map imports;
 	private final transient Interceptor interceptor;
 	private final transient SessionFactoryServiceRegistry serviceRegistry;
 	private final transient Settings settings;
 	private final transient Properties properties;
 	private transient SchemaExport schemaExport;
 	private final transient QueryCache queryCache;
 	private final transient UpdateTimestampsCache updateTimestampsCache;
 	private final transient Map<String,QueryCache> queryCaches;
 	private final transient ConcurrentMap<String,Region> allCacheRegions = new ConcurrentHashMap<String, Region>();
 	private final transient CurrentSessionContext currentSessionContext;
 	private final transient EntityNotFoundDelegate entityNotFoundDelegate;
 	private final transient SQLFunctionRegistry sqlFunctionRegistry;
 	private final transient SessionFactoryObserverChain observer = new SessionFactoryObserverChain();
 	private final transient HashMap entityNameResolvers = new HashMap();
 	private final transient QueryPlanCache queryPlanCache;
 	private final transient Cache cacheAccess = new CacheImpl();
 	private transient boolean isClosed = false;
 	private final transient TypeResolver typeResolver;
 	private final transient TypeHelper typeHelper;
 	private final transient TransactionEnvironment transactionEnvironment;
 
 	public SessionFactoryImpl(
 			Configuration cfg,
 	        Mapping mapping,
 			ServiceRegistry serviceRegistry,
 	        Settings settings,
 			SessionFactoryObserver observer) throws HibernateException {
         LOG.debug( "Building session factory" );
 
 		this.settings = settings;
 		this.interceptor = cfg.getInterceptor();
 
 		this.properties = new Properties();
 		this.properties.putAll( cfg.getProperties() );
 
 		this.serviceRegistry = serviceRegistry.getService( SessionFactoryServiceRegistryFactory.class ).buildServiceRegistry(
 				this,
 				cfg
 		);
 		this.sqlFunctionRegistry = new SQLFunctionRegistry( getDialect(), cfg.getSqlFunctions() );
 		if ( observer != null ) {
 			this.observer.addObserver( observer );
 		}
 
 		this.typeResolver = cfg.getTypeResolver().scope( this );
 		this.typeHelper = new TypeLocatorImpl( typeResolver );
 
 		this.filters = new HashMap();
 		this.filters.putAll( cfg.getFilterDefinitions() );
 
         LOG.debugf("Session factory constructed with filter configurations : %s", filters);
         LOG.debugf("Instantiating session factory with properties: %s", properties);
 
 		// Caches
 		settings.getRegionFactory().start( settings, properties );
 		this.queryPlanCache = new QueryPlanCache( this );
 
 		// todo : everything above here consider implementing as standard SF service.  specifically: stats, caches, types, function-reg
 
 		class IntegratorObserver implements SessionFactoryObserver {
 			private ArrayList<Integrator> integrators = new ArrayList<Integrator>();
 
 			@Override
 			public void sessionFactoryCreated(SessionFactory factory) {
 			}
 
 			@Override
 			public void sessionFactoryClosed(SessionFactory factory) {
 				for ( Integrator integrator : integrators ) {
 					integrator.disintegrate( SessionFactoryImpl.this, SessionFactoryImpl.this.serviceRegistry );
 				}
 			}
 		}
 
 		final IntegratorObserver integratorObserver = new IntegratorObserver();
 		this.observer.addObserver( integratorObserver );
 		for ( Integrator integrator : serviceRegistry.getService( IntegratorService.class ).getIntegrators() ) {
 			integrator.integrate( cfg, this, this.serviceRegistry );
 			integratorObserver.integrators.add( integrator );
 		}
 
 		//Generators:
 
 		identifierGenerators = new HashMap();
 		Iterator classes = cfg.getClassMappings();
 		while ( classes.hasNext() ) {
 			PersistentClass model = (PersistentClass) classes.next();
 			if ( !model.isInherited() ) {
 				IdentifierGenerator generator = model.getIdentifier().createIdentifierGenerator(
 						cfg.getIdentifierGeneratorFactory(),
 						getDialect(),
 				        settings.getDefaultCatalogName(),
 				        settings.getDefaultSchemaName(),
 				        (RootClass) model
 				);
 				identifierGenerators.put( model.getEntityName(), generator );
 			}
 		}
 
 
 		///////////////////////////////////////////////////////////////////////
 		// Prepare persisters and link them up with their cache
 		// region/access-strategy
 
 		final String cacheRegionPrefix = settings.getCacheRegionPrefix() == null ? "" : settings.getCacheRegionPrefix() + ".";
 
 		entityPersisters = new HashMap();
 		Map entityAccessStrategies = new HashMap();
 		Map<String,ClassMetadata> classMeta = new HashMap<String,ClassMetadata>();
 		classes = cfg.getClassMappings();
 		while ( classes.hasNext() ) {
 			final PersistentClass model = (PersistentClass) classes.next();
 			model.prepareTemporaryTables( mapping, getDialect() );
 			final String cacheRegionName = cacheRegionPrefix + model.getRootClass().getCacheRegionName();
 			// cache region is defined by the root-class in the hierarchy...
 			EntityRegionAccessStrategy accessStrategy = ( EntityRegionAccessStrategy ) entityAccessStrategies.get( cacheRegionName );
 			if ( accessStrategy == null && settings.isSecondLevelCacheEnabled() ) {
-				final AccessType accessType = AccessType.parse( model.getCacheConcurrencyStrategy() );
+				final AccessType accessType = AccessType.fromExternalName( model.getCacheConcurrencyStrategy() );
 				if ( accessType != null ) {
                     LOG.trace("Building cache for entity data [" + model.getEntityName() + "]");
 					EntityRegion entityRegion = settings.getRegionFactory().buildEntityRegion( cacheRegionName, properties, CacheDataDescriptionImpl.decode( model ) );
 					accessStrategy = entityRegion.buildAccessStrategy( accessType );
 					entityAccessStrategies.put( cacheRegionName, accessStrategy );
 					allCacheRegions.put( cacheRegionName, entityRegion );
 				}
 			}
 			EntityPersister cp = serviceRegistry.getService( PersisterFactory.class ).createEntityPersister(
 					model,
 					accessStrategy,
 					this,
 					mapping
 			);
 			entityPersisters.put( model.getEntityName(), cp );
 			classMeta.put( model.getEntityName(), cp.getClassMetadata() );
 		}
 		this.classMetadata = Collections.unmodifiableMap(classMeta);
 
 		Map<String,Set<String>> tmpEntityToCollectionRoleMap = new HashMap<String,Set<String>>();
 		collectionPersisters = new HashMap();
 		Iterator collections = cfg.getCollectionMappings();
 		while ( collections.hasNext() ) {
 			Collection model = (Collection) collections.next();
 			final String cacheRegionName = cacheRegionPrefix + model.getCacheRegionName();
-			final AccessType accessType = AccessType.parse( model.getCacheConcurrencyStrategy() );
+			final AccessType accessType = AccessType.fromExternalName( model.getCacheConcurrencyStrategy() );
 			CollectionRegionAccessStrategy accessStrategy = null;
 			if ( accessType != null && settings.isSecondLevelCacheEnabled() ) {
                 LOG.trace("Building cache for collection data [" + model.getRole() + "]");
-				CollectionRegion collectionRegion = settings.getRegionFactory().buildCollectionRegion( cacheRegionName, properties, CacheDataDescriptionImpl.decode( model ) );
+				CollectionRegion collectionRegion = settings.getRegionFactory().buildCollectionRegion( cacheRegionName, properties, CacheDataDescriptionImpl
+						.decode( model ) );
 				accessStrategy = collectionRegion.buildAccessStrategy( accessType );
 				entityAccessStrategies.put( cacheRegionName, accessStrategy );
 				allCacheRegions.put( cacheRegionName, collectionRegion );
 			}
 			CollectionPersister persister = serviceRegistry.getService( PersisterFactory.class ).createCollectionPersister(
 					cfg,
 					model,
 					accessStrategy,
 					this
 			) ;
 			collectionPersisters.put( model.getRole(), persister.getCollectionMetadata() );
 			Type indexType = persister.getIndexType();
 			if ( indexType != null && indexType.isAssociationType() && !indexType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) indexType ).getAssociatedEntityName( this );
 				Set roles = tmpEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet();
 					tmpEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 			Type elementType = persister.getElementType();
 			if ( elementType.isAssociationType() && !elementType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) elementType ).getAssociatedEntityName( this );
 				Set roles = tmpEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet();
 					tmpEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 		}
 		collectionMetadata = Collections.unmodifiableMap(collectionPersisters);
 		Iterator itr = tmpEntityToCollectionRoleMap.entrySet().iterator();
 		while ( itr.hasNext() ) {
 			final Map.Entry entry = ( Map.Entry ) itr.next();
 			entry.setValue( Collections.unmodifiableSet( ( Set ) entry.getValue() ) );
 		}
 		collectionRolesByEntityParticipant = Collections.unmodifiableMap( tmpEntityToCollectionRoleMap );
 
 		//Named Queries:
 		namedQueries = new HashMap( cfg.getNamedQueries() );
 		namedSqlQueries = new HashMap( cfg.getNamedSQLQueries() );
 		sqlResultSetMappings = new HashMap( cfg.getSqlResultSetMappings() );
 		imports = new HashMap( cfg.getImports() );
 
 		// after *all* persisters and named queries are registered
 		Iterator iter = entityPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			final EntityPersister persister = ( ( EntityPersister ) iter.next() );
 			persister.postInstantiate();
 			registerEntityNameResolvers( persister );
 
 		}
 		iter = collectionPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			final CollectionPersister persister = ( ( CollectionPersister ) iter.next() );
 			persister.postInstantiate();
 		}
 
 		//JNDI + Serialization:
 
 		name = settings.getSessionFactoryName();
 		try {
 			uuid = (String) UUID_GENERATOR.generate(null, null);
 		}
 		catch (Exception e) {
 			throw new AssertionFailure("Could not generate UUID");
 		}
 		SessionFactoryRegistry.INSTANCE.addSessionFactory( uuid, name, this, serviceRegistry.getService( JndiService.class ) );
 
         LOG.debugf("Instantiated session factory");
 
 		if ( settings.isAutoCreateSchema() ) {
 			new SchemaExport( serviceRegistry, cfg ).create( false, true );
 		}
 		if ( settings.isAutoUpdateSchema() ) {
 			new SchemaUpdate( serviceRegistry, cfg ).execute( false, true );
 		}
 		if ( settings.isAutoValidateSchema() ) {
 			new SchemaValidator( serviceRegistry, cfg ).validate();
 		}
 		if ( settings.isAutoDropSchema() ) {
 			schemaExport = new SchemaExport( serviceRegistry, cfg );
 		}
 
 		currentSessionContext = buildCurrentSessionContext();
 
 		if ( settings.isQueryCacheEnabled() ) {
 			updateTimestampsCache = new UpdateTimestampsCache(settings, properties);
 			queryCache = settings.getQueryCacheFactory()
 			        .getQueryCache(null, updateTimestampsCache, settings, properties);
 			queryCaches = new HashMap<String,QueryCache>();
 			allCacheRegions.put( updateTimestampsCache.getRegion().getName(), updateTimestampsCache.getRegion() );
 			allCacheRegions.put( queryCache.getRegion().getName(), queryCache.getRegion() );
 		}
 		else {
 			updateTimestampsCache = null;
 			queryCache = null;
 			queryCaches = null;
 		}
 
 		//checking for named queries
 		if ( settings.isNamedQueryStartupCheckingEnabled() ) {
 			Map errors = checkNamedQueries();
 			if ( !errors.isEmpty() ) {
 				Set keys = errors.keySet();
 				StringBuffer failingQueries = new StringBuffer( "Errors in named queries: " );
 				for ( Iterator iterator = keys.iterator() ; iterator.hasNext() ; ) {
 					String queryName = ( String ) iterator.next();
 					HibernateException e = ( HibernateException ) errors.get( queryName );
 					failingQueries.append( queryName );
                     if (iterator.hasNext()) failingQueries.append(", ");
                     LOG.namedQueryError(queryName, e);
 				}
 				throw new HibernateException( failingQueries.toString() );
 			}
 		}
 
 		// EntityNotFoundDelegate
 		EntityNotFoundDelegate entityNotFoundDelegate = cfg.getEntityNotFoundDelegate();
 		if ( entityNotFoundDelegate == null ) {
 			entityNotFoundDelegate = new EntityNotFoundDelegate() {
 				public void handleEntityNotFound(String entityName, Serializable id) {
 					throw new ObjectNotFoundException( id, entityName );
 				}
 			};
 		}
 		this.entityNotFoundDelegate = entityNotFoundDelegate;
 
 		// this needs to happen after persisters are all ready to go...
 		this.fetchProfiles = new HashMap();
 		itr = cfg.iterateFetchProfiles();
 		while ( itr.hasNext() ) {
 			final org.hibernate.mapping.FetchProfile mappingProfile =
 					( org.hibernate.mapping.FetchProfile ) itr.next();
 			final FetchProfile fetchProfile = new FetchProfile( mappingProfile.getName() );
 			Iterator fetches = mappingProfile.getFetches().iterator();
 			while ( fetches.hasNext() ) {
 				final org.hibernate.mapping.FetchProfile.Fetch mappingFetch =
 						( org.hibernate.mapping.FetchProfile.Fetch ) fetches.next();
 				// resolve the persister owning the fetch
 				final String entityName = getImportedClassName( mappingFetch.getEntity() );
 				final EntityPersister owner = ( EntityPersister ) ( entityName == null ? null : entityPersisters.get( entityName ) );
 				if ( owner == null ) {
 					throw new HibernateException(
 							"Unable to resolve entity reference [" + mappingFetch.getEntity()
 									+ "] in fetch profile [" + fetchProfile.getName() + "]"
 					);
 				}
 
 				// validate the specified association fetch
 				Type associationType = owner.getPropertyType( mappingFetch.getAssociation() );
 				if ( associationType == null || !associationType.isAssociationType() ) {
 					throw new HibernateException( "Fetch profile [" + fetchProfile.getName() + "] specified an invalid association" );
 				}
 
 				// resolve the style
 				final Fetch.Style fetchStyle = Fetch.Style.parse( mappingFetch.getStyle() );
 
 				// then construct the fetch instance...
 				fetchProfile.addFetch( new Association( owner, mappingFetch.getAssociation() ), fetchStyle );
 				( ( Loadable ) owner ).registerAffectingFetchProfile( fetchProfile.getName() );
 			}
 			fetchProfiles.put( fetchProfile.getName(), fetchProfile );
 		}
 
 		this.transactionEnvironment = new TransactionEnvironmentImpl( this );
 		this.observer.sessionFactoryCreated( this );
 	}
 
 	public Session openSession() throws HibernateException {
 		return withOptions().openSession();
 	}
 
 	public Session openTemporarySession() throws HibernateException {
 		return withOptions()
 				.autoClose( false )
 				.flushBeforeCompletion( false )
 				.connectionReleaseMode( ConnectionReleaseMode.AFTER_STATEMENT )
 				.openSession();
 	}
 
 	public Session getCurrentSession() throws HibernateException {
 		if ( currentSessionContext == null ) {
 			throw new HibernateException( "No CurrentSessionContext configured!" );
 		}
 		return currentSessionContext.currentSession();
 	}
 
 	@Override
 	public SessionBuilder withOptions() {
 		return new SessionBuilderImpl( this );
 	}
 
 	@Override
 	public StatelessSessionBuilder withStatelessOptions() {
 		return new StatelessSessionBuilderImpl( this );
 	}
 
 	public StatelessSession openStatelessSession() {
 		return withStatelessOptions().openStatelessSession();
 	}
 
 	public StatelessSession openStatelessSession(Connection connection) {
 		return withStatelessOptions().connection( connection ).openStatelessSession();
 	}
 
 	@Override
 	public void addObserver(SessionFactoryObserver observer) {
 		this.observer.addObserver( observer );
 	}
 
 	public TransactionEnvironment getTransactionEnvironment() {
 		return transactionEnvironment;
 	}
 
 	public Properties getProperties() {
 		return properties;
 	}
 
 	public IdentifierGeneratorFactory getIdentifierGeneratorFactory() {
 		return null;
 	}
 
 	public TypeResolver getTypeResolver() {
 		return typeResolver;
 	}
 
 	private void registerEntityNameResolvers(EntityPersister persister) {
 		if ( persister.getEntityMetamodel() == null || persister.getEntityMetamodel().getTuplizerMapping() == null ) {
 			return;
 		}
 		Iterator itr = persister.getEntityMetamodel().getTuplizerMapping().iterateTuplizers();
 		while ( itr.hasNext() ) {
 			final EntityTuplizer tuplizer = ( EntityTuplizer ) itr.next();
 			registerEntityNameResolvers( tuplizer );
 		}
 	}
 
 	private void registerEntityNameResolvers(EntityTuplizer tuplizer) {
 		EntityNameResolver[] resolvers = tuplizer.getEntityNameResolvers();
 		if ( resolvers == null ) {
 			return;
 		}
 
 		for ( int i = 0; i < resolvers.length; i++ ) {
 			registerEntityNameResolver( resolvers[i], tuplizer.getEntityMode() );
 		}
 	}
 
 	public void registerEntityNameResolver(EntityNameResolver resolver, EntityMode entityMode) {
 		LinkedHashSet resolversForMode = ( LinkedHashSet ) entityNameResolvers.get( entityMode );
 		if ( resolversForMode == null ) {
 			resolversForMode = new LinkedHashSet();
 			entityNameResolvers.put( entityMode, resolversForMode );
 		}
 		resolversForMode.add( resolver );
 	}
 
 	public Iterator iterateEntityNameResolvers(EntityMode entityMode) {
 		Set actualEntityNameResolvers = ( Set ) entityNameResolvers.get( entityMode );
 		return actualEntityNameResolvers == null
 				? EmptyIterator.INSTANCE
 				: actualEntityNameResolvers.iterator();
 	}
 
 	public QueryPlanCache getQueryPlanCache() {
 		return queryPlanCache;
 	}
 
 	private Map checkNamedQueries() throws HibernateException {
 		Map errors = new HashMap();
 
 		// Check named HQL queries
         LOG.debugf("Checking %s named HQL queries", namedQueries.size());
 		Iterator itr = namedQueries.entrySet().iterator();
 		while ( itr.hasNext() ) {
 			final Map.Entry entry = ( Map.Entry ) itr.next();
 			final String queryName = ( String ) entry.getKey();
 			final NamedQueryDefinition qd = ( NamedQueryDefinition ) entry.getValue();
 			// this will throw an error if there's something wrong.
 			try {
                 LOG.debugf("Checking named query: %s", queryName);
 				//TODO: BUG! this currently fails for named queries for non-POJO entities
 				queryPlanCache.getHQLQueryPlan( qd.getQueryString(), false, CollectionHelper.EMPTY_MAP );
 			}
 			catch ( QueryException e ) {
 				errors.put( queryName, e );
 			}
 			catch ( MappingException e ) {
 				errors.put( queryName, e );
 			}
 		}
 
         LOG.debugf("Checking %s named SQL queries", namedSqlQueries.size());
 		itr = namedSqlQueries.entrySet().iterator();
 		while ( itr.hasNext() ) {
 			final Map.Entry entry = ( Map.Entry ) itr.next();
 			final String queryName = ( String ) entry.getKey();
 			final NamedSQLQueryDefinition qd = ( NamedSQLQueryDefinition ) entry.getValue();
 			// this will throw an error if there's something wrong.
 			try {
                 LOG.debugf("Checking named SQL query: %s", queryName);
 				// TODO : would be really nice to cache the spec on the query-def so as to not have to re-calc the hash;
 				// currently not doable though because of the resultset-ref stuff...
 				NativeSQLQuerySpecification spec;
 				if ( qd.getResultSetRef() != null ) {
 					ResultSetMappingDefinition definition = ( ResultSetMappingDefinition ) sqlResultSetMappings.get( qd.getResultSetRef() );
 					if ( definition == null ) {
 						throw new MappingException( "Unable to find resultset-ref definition: " + qd.getResultSetRef() );
 					}
 					spec = new NativeSQLQuerySpecification(
 							qd.getQueryString(),
 					        definition.getQueryReturns(),
 					        qd.getQuerySpaces()
 					);
 				}
 				else {
 					spec =  new NativeSQLQuerySpecification(
 							qd.getQueryString(),
 					        qd.getQueryReturns(),
 					        qd.getQuerySpaces()
 					);
 				}
 				queryPlanCache.getNativeSQLQueryPlan( spec );
 			}
 			catch ( QueryException e ) {
 				errors.put( queryName, e );
 			}
 			catch ( MappingException e ) {
 				errors.put( queryName, e );
 			}
 		}
 
 		return errors;
 	}
 
 	public EntityPersister getEntityPersister(String entityName) throws MappingException {
 		EntityPersister result = (EntityPersister) entityPersisters.get(entityName);
 		if (result==null) {
 			throw new MappingException( "Unknown entity: " + entityName );
 		}
 		return result;
 	}
 
 	public CollectionPersister getCollectionPersister(String role) throws MappingException {
 		CollectionPersister result = (CollectionPersister) collectionPersisters.get(role);
 		if (result==null) {
 			throw new MappingException( "Unknown collection role: " + role );
 		}
 		return result;
 	}
 
 	public Settings getSettings() {
 		return settings;
 	}
 
 	public JdbcServices getJdbcServices() {
 		return serviceRegistry.getService( JdbcServices.class );
 	}
 
 	public Dialect getDialect() {
 		if ( serviceRegistry == null ) {
 			throw new IllegalStateException( "Cannot determine dialect because serviceRegistry is null." );
 		}
 		return getJdbcServices().getDialect();
 	}
 
 	public Interceptor getInterceptor()
 	{
 		return interceptor;
 	}
 
 	public SQLExceptionConverter getSQLExceptionConverter() {
 		return getSQLExceptionHelper().getSqlExceptionConverter();
 	}
 
 	public SqlExceptionHelper getSQLExceptionHelper() {
 		return getJdbcServices().getSqlExceptionHelper();
 	}
 
 	public Set<String> getCollectionRolesByEntityParticipant(String entityName) {
 		return collectionRolesByEntityParticipant.get( entityName );
 	}
 
 	@Override
 	public Reference getReference() throws NamingException {
 		// from javax.naming.Referenceable
         LOG.debug( "Returning a Reference to the SessionFactory" );
 		return new Reference(
 				SessionFactoryImpl.class.getName(),
 				new StringRefAddr("uuid", uuid),
 				SessionFactoryRegistry.ObjectFactoryImpl.class.getName(),
 				null
 		);
 	}
 
 	private Object readResolve() throws ObjectStreamException {
         LOG.trace("Resolving serialized SessionFactory");
 		// look for the instance by uuid
 		Object result = SessionFactoryRegistry.INSTANCE.getSessionFactory( uuid );
 		if ( result == null ) {
 			// in case we were deserialized in a different JVM, look for an instance with the same name
 			// (alternatively we could do an actual JNDI lookup here....)
 			result = SessionFactoryRegistry.INSTANCE.getNamedSessionFactory( name );
             if ( result == null ) {
 				throw new InvalidObjectException( "Could not find a SessionFactory [uuid=" + uuid + ",name=" + name + "]" );
 			}
             LOG.debugf("Resolved SessionFactory by name");
         }
 		else {
 			LOG.debugf("Resolved SessionFactory by UUID");
 		}
 		return result;
 	}
 
 	public NamedQueryDefinition getNamedQuery(String queryName) {
 		return (NamedQueryDefinition) namedQueries.get(queryName);
 	}
 
 	public NamedSQLQueryDefinition getNamedSQLQuery(String queryName) {
 		return (NamedSQLQueryDefinition) namedSqlQueries.get(queryName);
 	}
 
 	public ResultSetMappingDefinition getResultSetMapping(String resultSetName) {
 		return (ResultSetMappingDefinition) sqlResultSetMappings.get(resultSetName);
 	}
 
 	public Type getIdentifierType(String className) throws MappingException {
 		return getEntityPersister(className).getIdentifierType();
 	}
 	public String getIdentifierPropertyName(String className) throws MappingException {
 		return getEntityPersister(className).getIdentifierPropertyName();
 	}
 
 	private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException {
         LOG.trace( "Deserializing" );
 		in.defaultReadObject();
         LOG.debugf( "Deserialized: %s", uuid );
 	}
 
 	private void writeObject(ObjectOutputStream out) throws IOException {
         LOG.debugf("Serializing: %s", uuid);
 		out.defaultWriteObject();
         LOG.trace("Serialized");
 	}
 
 	public Type[] getReturnTypes(String queryString) throws HibernateException {
 		return queryPlanCache.getHQLQueryPlan( queryString, false, CollectionHelper.EMPTY_MAP ).getReturnMetadata().getReturnTypes();
 	}
 
 	public String[] getReturnAliases(String queryString) throws HibernateException {
 		return queryPlanCache.getHQLQueryPlan( queryString, false, CollectionHelper.EMPTY_MAP ).getReturnMetadata().getReturnAliases();
 	}
 
 	public ClassMetadata getClassMetadata(Class persistentClass) throws HibernateException {
 		return getClassMetadata( persistentClass.getName() );
 	}
 
 	public CollectionMetadata getCollectionMetadata(String roleName) throws HibernateException {
 		return (CollectionMetadata) collectionMetadata.get(roleName);
 	}
 
 	public ClassMetadata getClassMetadata(String entityName) throws HibernateException {
 		return classMetadata.get(entityName);
 	}
 
 	/**
 	 * Return the names of all persistent (mapped) classes that extend or implement the
 	 * given class or interface, accounting for implicit/explicit polymorphism settings
 	 * and excluding mapped subclasses/joined-subclasses of other classes in the result.
 	 */
 	public String[] getImplementors(String className) throws MappingException {
 
 		final Class clazz;
 		try {
 			clazz = ReflectHelper.classForName(className);
 		}
 		catch (ClassNotFoundException cnfe) {
 			return new String[] { className }; //for a dynamic-class
 		}
 
 		ArrayList results = new ArrayList();
 		Iterator iter = entityPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			//test this entity to see if we must query it
 			EntityPersister testPersister = (EntityPersister) iter.next();
 			if ( testPersister instanceof Queryable ) {
 				Queryable testQueryable = (Queryable) testPersister;
 				String testClassName = testQueryable.getEntityName();
 				boolean isMappedClass = className.equals(testClassName);
 				if ( testQueryable.isExplicitPolymorphism() ) {
 					if ( isMappedClass ) {
 						return new String[] {className}; //NOTE EARLY EXIT
 					}
 				}
 				else {
 					if (isMappedClass) {
 						results.add(testClassName);
 					}
 					else {
 						final Class mappedClass = testQueryable.getMappedClass( EntityMode.POJO );
 						if ( mappedClass!=null && clazz.isAssignableFrom( mappedClass ) ) {
 							final boolean assignableSuperclass;
 							if ( testQueryable.isInherited() ) {
 								Class mappedSuperclass = getEntityPersister( testQueryable.getMappedSuperclass() ).getMappedClass( EntityMode.POJO);
 								assignableSuperclass = clazz.isAssignableFrom(mappedSuperclass);
 							}
 							else {
 								assignableSuperclass = false;
 							}
 							if ( !assignableSuperclass ) {
 								results.add( testClassName );
 							}
 						}
 					}
 				}
 			}
 		}
 		return (String[]) results.toArray( new String[ results.size() ] );
 	}
 
 	public String getImportedClassName(String className) {
 		String result = (String) imports.get(className);
 		if (result==null) {
 			try {
 				ReflectHelper.classForName( className );
 				return className;
 			}
 			catch (ClassNotFoundException cnfe) {
 				return null;
 			}
 		}
 		else {
 			return result;
 		}
 	}
 
 	public Map<String,ClassMetadata> getAllClassMetadata() throws HibernateException {
 		return classMetadata;
 	}
 
 	public Map getAllCollectionMetadata() throws HibernateException {
 		return collectionMetadata;
 	}
 
 	public Type getReferencedPropertyType(String className, String propertyName)
 		throws MappingException {
 		return getEntityPersister( className ).getPropertyType( propertyName );
 	}
 
 	public ConnectionProvider getConnectionProvider() {
 		return serviceRegistry.getService( JdbcServices.class ).getConnectionProvider();
 	}
 
 	/**
 	 * Closes the session factory, releasing all held resources.
 	 *
 	 * <ol>
 	 * <li>cleans up used cache regions and "stops" the cache provider.
 	 * <li>close the JDBC connection
 	 * <li>remove the JNDI binding
 	 * </ol>
 	 *
 	 * Note: Be aware that the sessionFactory instance still can
 	 * be a "heavy" object memory wise after close() has been called.  Thus
 	 * it is important to not keep referencing the instance to let the garbage
 	 * collector release the memory.
 	 */
 	public void close() throws HibernateException {
 
 		if ( isClosed ) {
             LOG.trace("Already closed");
 			return;
 		}
 
         LOG.closing();
 
 		isClosed = true;
 
 		Iterator iter = entityPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			EntityPersister p = (EntityPersister) iter.next();
 			if ( p.hasCache() ) {
 				p.getCacheAccessStrategy().getRegion().destroy();
 			}
 		}
 
 		iter = collectionPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			CollectionPersister p = (CollectionPersister) iter.next();
 			if ( p.hasCache() ) {
 				p.getCacheAccessStrategy().getRegion().destroy();
 			}
 		}
 
 		if ( settings.isQueryCacheEnabled() )  {
 			queryCache.destroy();
 
 			iter = queryCaches.values().iterator();
 			while ( iter.hasNext() ) {
 				QueryCache cache = (QueryCache) iter.next();
 				cache.destroy();
 			}
 			updateTimestampsCache.destroy();
 		}
 
 		settings.getRegionFactory().stop();
 
 		if ( settings.isAutoDropSchema() ) {
 			schemaExport.drop( false, true );
 		}
 
 		SessionFactoryRegistry.INSTANCE.removeSessionFactory(
 				uuid, name, serviceRegistry.getService( JndiService.class )
 		);
 
 		observer.sessionFactoryClosed( this );
 		serviceRegistry.destroy();
 	}
 
 	private class CacheImpl implements Cache {
 		public boolean containsEntity(Class entityClass, Serializable identifier) {
 			return containsEntity( entityClass.getName(), identifier );
 		}
 
 		public boolean containsEntity(String entityName, Serializable identifier) {
 			EntityPersister p = getEntityPersister( entityName );
 			return p.hasCache() &&
 					p.getCacheAccessStrategy().getRegion().contains( buildCacheKey( identifier, p ) );
 		}
 
 		public void evictEntity(Class entityClass, Serializable identifier) {
 			evictEntity( entityClass.getName(), identifier );
 		}
 
 		public void evictEntity(String entityName, Serializable identifier) {
 			EntityPersister p = getEntityPersister( entityName );
 			if ( p.hasCache() ) {
                 if (LOG.isDebugEnabled()) LOG.debugf("Evicting second-level cache: %s",
                                                      MessageHelper.infoString(p, identifier, SessionFactoryImpl.this));
 				p.getCacheAccessStrategy().evict( buildCacheKey( identifier, p ) );
 			}
 		}
 
 		private CacheKey buildCacheKey(Serializable identifier, EntityPersister p) {
 			return new CacheKey(
 					identifier,
 					p.getIdentifierType(),
 					p.getRootEntityName(),
 					EntityMode.POJO,			// we have to assume POJO
 					null, 						// and also assume non tenancy
 					SessionFactoryImpl.this
 			);
 		}
 
 		public void evictEntityRegion(Class entityClass) {
 			evictEntityRegion( entityClass.getName() );
 		}
 
 		public void evictEntityRegion(String entityName) {
 			EntityPersister p = getEntityPersister( entityName );
 			if ( p.hasCache() ) {
                 LOG.debugf("Evicting second-level cache: %s", p.getEntityName());
 				p.getCacheAccessStrategy().evictAll();
 			}
 		}
 
 		public void evictEntityRegions() {
 			Iterator entityNames = entityPersisters.keySet().iterator();
 			while ( entityNames.hasNext() ) {
 				evictEntityRegion( ( String ) entityNames.next() );
 			}
 		}
 
 		public boolean containsCollection(String role, Serializable ownerIdentifier) {
 			CollectionPersister p = getCollectionPersister( role );
 			return p.hasCache() &&
 					p.getCacheAccessStrategy().getRegion().contains( buildCacheKey( ownerIdentifier, p ) );
 		}
 
 		public void evictCollection(String role, Serializable ownerIdentifier) {
 			CollectionPersister p = getCollectionPersister( role );
 			if ( p.hasCache() ) {
                 if (LOG.isDebugEnabled()) LOG.debugf("Evicting second-level cache: %s",
                                                      MessageHelper.collectionInfoString(p, ownerIdentifier, SessionFactoryImpl.this));
 				CacheKey cacheKey = buildCacheKey( ownerIdentifier, p );
 				p.getCacheAccessStrategy().evict( cacheKey );
 			}
 		}
 
 		private CacheKey buildCacheKey(Serializable ownerIdentifier, CollectionPersister p) {
 			return new CacheKey(
 					ownerIdentifier,
 					p.getKeyType(),
 					p.getRole(),
 					EntityMode.POJO,			// we have to assume POJO
 					null,						// and also assume non tenancy
 					SessionFactoryImpl.this
 			);
 		}
 
 		public void evictCollectionRegion(String role) {
 			CollectionPersister p = getCollectionPersister( role );
 			if ( p.hasCache() ) {
                 LOG.debugf("Evicting second-level cache: %s", p.getRole());
 				p.getCacheAccessStrategy().evictAll();
 			}
 		}
 
 		public void evictCollectionRegions() {
 			Iterator collectionRoles = collectionPersisters.keySet().iterator();
 			while ( collectionRoles.hasNext() ) {
 				evictCollectionRegion( ( String ) collectionRoles.next() );
 			}
 		}
 
 		public boolean containsQuery(String regionName) {
 			return queryCaches.get( regionName ) != null;
 		}
 
 		public void evictDefaultQueryRegion() {
 			if ( settings.isQueryCacheEnabled() ) {
 				queryCache.clear();
 			}
 		}
 
 		public void evictQueryRegion(String regionName) {
             if (regionName == null) throw new NullPointerException(
                                                                    "Region-name cannot be null (use Cache#evictDefaultQueryRegion to evict the default query cache)");
             if (settings.isQueryCacheEnabled()) {
                 QueryCache namedQueryCache = queryCaches.get(regionName);
                 // TODO : cleanup entries in queryCaches + allCacheRegions ?
                 if (namedQueryCache != null) namedQueryCache.clear();
 			}
 		}
 
 		public void evictQueryRegions() {
 			if ( queryCaches != null ) {
 				for ( QueryCache queryCache : queryCaches.values() ) {
 					queryCache.clear();
 					// TODO : cleanup entries in queryCaches + allCacheRegions ?
 				}
 			}
 		}
 	}
 
 	public Cache getCache() {
 		return cacheAccess;
 	}
 
 	public void evictEntity(String entityName, Serializable id) throws HibernateException {
 		getCache().evictEntity( entityName, id );
 	}
 
 	public void evictEntity(String entityName) throws HibernateException {
 		getCache().evictEntityRegion( entityName );
 	}
 
 	public void evict(Class persistentClass, Serializable id) throws HibernateException {
 		getCache().evictEntity( persistentClass, id );
 	}
 
 	public void evict(Class persistentClass) throws HibernateException {
 		getCache().evictEntityRegion( persistentClass );
 	}
 
 	public void evictCollection(String roleName, Serializable id) throws HibernateException {
 		getCache().evictCollection( roleName, id );
 	}
 
 	public void evictCollection(String roleName) throws HibernateException {
 		getCache().evictCollectionRegion( roleName );
 	}
 
 	public void evictQueries() throws HibernateException {
 		if ( settings.isQueryCacheEnabled() ) {
 			queryCache.clear();
 		}
 	}
 
 	public void evictQueries(String regionName) throws HibernateException {
 		getCache().evictQueryRegion( regionName );
 	}
 
 	public UpdateTimestampsCache getUpdateTimestampsCache() {
 		return updateTimestampsCache;
 	}
 
 	public QueryCache getQueryCache() {
 		return queryCache;
 	}
 
 	public QueryCache getQueryCache(String regionName) throws HibernateException {
 		if ( regionName == null ) {
 			return getQueryCache();
 		}
 
 		if ( !settings.isQueryCacheEnabled() ) {
 			return null;
 		}
 
 		QueryCache currentQueryCache = queryCaches.get( regionName );
 		if ( currentQueryCache == null ) {
 			currentQueryCache = settings.getQueryCacheFactory().getQueryCache( regionName, updateTimestampsCache, settings, properties );
 			queryCaches.put( regionName, currentQueryCache );
 			allCacheRegions.put( currentQueryCache.getRegion().getName(), currentQueryCache.getRegion() );
 		}
 
 		return currentQueryCache;
 	}
 
 	public Region getSecondLevelCacheRegion(String regionName) {
 		return allCacheRegions.get( regionName );
 	}
 
 	public Map getAllSecondLevelCacheRegions() {
 		return new HashMap( allCacheRegions );
 	}
 
 	public boolean isClosed() {
 		return isClosed;
 	}
 
 	public Statistics getStatistics() {
 		return getStatisticsImplementor();
 	}
 
 	public StatisticsImplementor getStatisticsImplementor() {
 		return serviceRegistry.getService( StatisticsImplementor.class );
 	}
 
 	public FilterDefinition getFilterDefinition(String filterName) throws HibernateException {
 		FilterDefinition def = ( FilterDefinition ) filters.get( filterName );
 		if ( def == null ) {
 			throw new HibernateException( "No such filter configured [" + filterName + "]" );
 		}
 		return def;
 	}
 
 	public boolean containsFetchProfileDefinition(String name) {
 		return fetchProfiles.containsKey( name );
 	}
 
 	public Set getDefinedFilterNames() {
 		return filters.keySet();
 	}
 
 	public IdentifierGenerator getIdentifierGenerator(String rootEntityName) {
 		return (IdentifierGenerator) identifierGenerators.get(rootEntityName);
 	}
 
 	private org.hibernate.engine.transaction.spi.TransactionFactory transactionFactory() {
 		return serviceRegistry.getService( org.hibernate.engine.transaction.spi.TransactionFactory.class );
 	}
 
 	private boolean canAccessTransactionManager() {
 		try {
 			return serviceRegistry.getService( JtaPlatform.class ).retrieveTransactionManager() != null;
 		}
 		catch (Exception e) {
 			return false;
 		}
 	}
 
 	private CurrentSessionContext buildCurrentSessionContext() {
 		String impl = properties.getProperty( Environment.CURRENT_SESSION_CONTEXT_CLASS );
 		// for backward-compatibility
 		if ( impl == null ) {
 			if ( canAccessTransactionManager() ) {
 				impl = "jta";
 			}
 			else {
 				return null;
 			}
 		}
 
 		if ( "jta".equals( impl ) ) {
 			if ( ! transactionFactory().compatibleWithJtaSynchronization() ) {
                 LOG.autoFlushWillNotWork();
 			}
 			return new JTASessionContext( this );
 		}
 		else if ( "thread".equals( impl ) ) {
 			return new ThreadLocalSessionContext( this );
 		}
 		else if ( "managed".equals( impl ) ) {
 			return new ManagedSessionContext( this );
 		}
 		else {
 			try {
 				Class implClass = ReflectHelper.classForName( impl );
 				return ( CurrentSessionContext ) implClass
 						.getConstructor( new Class[] { SessionFactoryImplementor.class } )
 						.newInstance( this );
 			}
 			catch( Throwable t ) {
                 LOG.unableToConstructCurrentSessionContext(impl, t);
 				return null;
 			}
 		}
 	}
 
 	@Override
 	public ServiceRegistryImplementor getServiceRegistry() {
 		return serviceRegistry;
 	}
 
 	@Override
 	public EntityNotFoundDelegate getEntityNotFoundDelegate() {
 		return entityNotFoundDelegate;
 	}
 
 	public SQLFunctionRegistry getSqlFunctionRegistry() {
 		return sqlFunctionRegistry;
 	}
 
 	public FetchProfile getFetchProfile(String name) {
 		return ( FetchProfile ) fetchProfiles.get( name );
 	}
 
 	public TypeHelper getTypeHelper() {
 		return typeHelper;
 	}
 
 	/**
 	 * Custom serialization hook used during Session serialization.
 	 *
 	 * @param oos The stream to which to write the factory
 	 * @throws IOException Indicates problems writing out the serial data stream
 	 */
 	void serialize(ObjectOutputStream oos) throws IOException {
 		oos.writeUTF( uuid );
 		oos.writeBoolean( name != null );
 		if ( name != null ) {
 			oos.writeUTF( name );
 		}
 	}
 
 	/**
 	 * Custom deserialization hook used during Session deserialization.
 	 *
 	 * @param ois The stream from which to "read" the factory
 	 * @return The deserialized factory
 	 * @throws IOException indicates problems reading back serial data stream
 	 * @throws ClassNotFoundException indicates problems reading back serial data stream
 	 */
 	static SessionFactoryImpl deserialize(ObjectInputStream ois) throws IOException, ClassNotFoundException {
 		final String uuid = ois.readUTF();
 		boolean isNamed = ois.readBoolean();
 		final String name = isNamed ? ois.readUTF() : null;
 		Object result = SessionFactoryRegistry.INSTANCE.getSessionFactory( uuid );
 		if ( result == null ) {
             LOG.trace("Could not locate session factory by uuid [" + uuid + "] during session deserialization; trying name");
 			if ( isNamed ) {
 				result = SessionFactoryRegistry.INSTANCE.getNamedSessionFactory( name );
 			}
 			if ( result == null ) {
 				throw new InvalidObjectException( "could not resolve session factory during session deserialization [uuid=" + uuid + ", name=" + name + "]" );
 			}
 		}
 		return ( SessionFactoryImpl ) result;
 	}
 
 	static class SessionBuilderImpl implements SessionBuilder {
 		private final SessionFactoryImpl sessionFactory;
 		private Interceptor interceptor;
 		private Connection connection;
 		private ConnectionReleaseMode connectionReleaseMode;
 		private EntityMode entityMode;
 		private boolean autoClose;
 		private boolean autoJoinTransactions = true;
 		private boolean flushBeforeCompletion;
 		private String tenantIdentifier;
 
 		SessionBuilderImpl(SessionFactoryImpl sessionFactory) {
 			this.sessionFactory = sessionFactory;
 			final Settings settings = sessionFactory.settings;
 
 			// set up default builder values...
 			this.interceptor = sessionFactory.getInterceptor();
 			this.connectionReleaseMode = settings.getConnectionReleaseMode();
 			this.entityMode = settings.getDefaultEntityMode();
 			this.autoClose = settings.isAutoCloseSessionEnabled();
 			this.flushBeforeCompletion = settings.isFlushBeforeCompletionEnabled();
 		}
 
 		protected TransactionCoordinatorImpl getTransactionCoordinator() {
 			return null;
 		}
 
 		@Override
 		public Session openSession() {
 			return new SessionImpl(
 					connection,
 					sessionFactory,
 					getTransactionCoordinator(),
 					autoJoinTransactions,
 					sessionFactory.settings.getRegionFactory().nextTimestamp(),
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/StatelessSessionImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/StatelessSessionImpl.java
index ed673342d5..af3d1f8d4a 100755
--- a/hibernate-core/src/main/java/org/hibernate/internal/StatelessSessionImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/StatelessSessionImpl.java
@@ -1,707 +1,707 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.util.Collections;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.CacheMode;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.Criteria;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.EntityMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.LockMode;
 import org.hibernate.MappingException;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.SessionException;
 import org.hibernate.StatelessSession;
 import org.hibernate.Transaction;
 import org.hibernate.UnresolvableObjectException;
-import org.hibernate.cache.CacheKey;
+import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.LoadQueryInfluencers;
 import org.hibernate.engine.NonFlushedChanges;
 import org.hibernate.engine.PersistenceContext;
 import org.hibernate.engine.QueryParameters;
 import org.hibernate.engine.StatefulPersistenceContext;
 import org.hibernate.engine.Versioning;
 import org.hibernate.engine.query.HQLQueryPlan;
 import org.hibernate.engine.query.NativeSQLQueryPlan;
 import org.hibernate.engine.query.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl;
 import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.engine.transaction.spi.TransactionEnvironment;
 import org.hibernate.engine.transaction.spi.TransactionImplementor;
 import org.hibernate.id.IdentifierGeneratorHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.loader.criteria.CriteriaLoader;
 import org.hibernate.loader.custom.CustomLoader;
 import org.hibernate.loader.custom.CustomQuery;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.type.Type;
 
 /**
  * @author Gavin King
  */
 public class StatelessSessionImpl extends AbstractSessionImpl implements StatelessSession {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, StatelessSessionImpl.class.getName());
 
 	private TransactionCoordinator transactionCoordinator;
 	private PersistenceContext temporaryPersistenceContext = new StatefulPersistenceContext( this );
 
 	StatelessSessionImpl(Connection connection, String tenantIdentifier, SessionFactoryImpl factory) {
 		super( factory, tenantIdentifier );
 		this.transactionCoordinator = new TransactionCoordinatorImpl( connection, this );
 	}
 
 	// TransactionContext ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public TransactionCoordinator getTransactionCoordinator() {
 		return transactionCoordinator;
 	}
 
 	@Override
 	public TransactionEnvironment getTransactionEnvironment() {
 		return factory.getTransactionEnvironment();
 	}
 
 	// inserts ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public Serializable insert(Object entity) {
 		errorIfClosed();
 		return insert(null, entity);
 	}
 
 	public Serializable insert(String entityName, Object entity) {
 		errorIfClosed();
 		EntityPersister persister = getEntityPersister(entityName, entity);
 		Serializable id = persister.getIdentifierGenerator().generate(this, entity);
 		Object[] state = persister.getPropertyValues(entity, EntityMode.POJO);
 		if ( persister.isVersioned() ) {
 			boolean substitute = Versioning.seedVersion(state, persister.getVersionProperty(), persister.getVersionType(), this);
 			if ( substitute ) {
 				persister.setPropertyValues( entity, state, EntityMode.POJO );
 			}
 		}
 		if ( id == IdentifierGeneratorHelper.POST_INSERT_INDICATOR ) {
 			id = persister.insert(state, entity, this);
 		}
 		else {
 			persister.insert(id, state, entity, this);
 		}
 		persister.setIdentifier( entity, id, this );
 		return id;
 	}
 
 
 	// deletes ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void delete(Object entity) {
 		errorIfClosed();
 		delete(null, entity);
 	}
 
 	public void delete(String entityName, Object entity) {
 		errorIfClosed();
 		EntityPersister persister = getEntityPersister(entityName, entity);
 		Serializable id = persister.getIdentifier( entity, this );
 		Object version = persister.getVersion(entity, EntityMode.POJO);
 		persister.delete(id, version, entity, this);
 	}
 
 
 	// updates ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void update(Object entity) {
 		errorIfClosed();
 		update(null, entity);
 	}
 
 	public void update(String entityName, Object entity) {
 		errorIfClosed();
 		EntityPersister persister = getEntityPersister(entityName, entity);
 		Serializable id = persister.getIdentifier( entity, this );
 		Object[] state = persister.getPropertyValues(entity, EntityMode.POJO);
 		Object oldVersion;
 		if ( persister.isVersioned() ) {
 			oldVersion = persister.getVersion(entity, EntityMode.POJO);
 			Object newVersion = Versioning.increment( oldVersion, persister.getVersionType(), this );
 			Versioning.setVersion(state, newVersion, persister);
 			persister.setPropertyValues(entity, state, EntityMode.POJO);
 		}
 		else {
 			oldVersion = null;
 		}
 		persister.update(id, state, null, false, null, oldVersion, entity, null, this);
 	}
 
 
 	// loading ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public Object get(Class entityClass, Serializable id) {
 		return get( entityClass.getName(), id );
 	}
 
 	public Object get(Class entityClass, Serializable id, LockMode lockMode) {
 		return get( entityClass.getName(), id, lockMode );
 	}
 
 	public Object get(String entityName, Serializable id) {
 		return get(entityName, id, LockMode.NONE);
 	}
 
 	public Object get(String entityName, Serializable id, LockMode lockMode) {
 		errorIfClosed();
 		Object result = getFactory().getEntityPersister(entityName)
 				.load(id, null, lockMode, this);
 		if ( temporaryPersistenceContext.isLoadFinished() ) {
 			temporaryPersistenceContext.clear();
 		}
 		return result;
 	}
 
 	public void refresh(Object entity) {
 		refresh( bestGuessEntityName( entity ), entity, LockMode.NONE );
 	}
 
 	public void refresh(String entityName, Object entity) {
 		refresh( entityName, entity, LockMode.NONE );
 	}
 
 	public void refresh(Object entity, LockMode lockMode) {
 		refresh( bestGuessEntityName( entity ), entity, lockMode );
 	}
 
 	public void refresh(String entityName, Object entity, LockMode lockMode) {
 		final EntityPersister persister = this.getEntityPersister( entityName, entity );
 		final Serializable id = persister.getIdentifier( entity, this );
         if (LOG.isTraceEnabled()) LOG.trace("Refreshing transient " + MessageHelper.infoString(persister, id, this.getFactory()));
 		// TODO : can this ever happen???
 //		EntityKey key = new EntityKey( id, persister, source.getEntityMode() );
 //		if ( source.getPersistenceContext().getEntry( key ) != null ) {
 //			throw new PersistentObjectException(
 //					"attempted to refresh transient instance when persistent " +
 //					"instance was already associated with the Session: " +
 //					MessageHelper.infoString( persister, id, source.getFactory() )
 //			);
 //		}
 
 		if ( persister.hasCache() ) {
 			final CacheKey ck = generateCacheKey( id, persister.getIdentifierType(), persister.getRootEntityName() );
 			persister.getCacheAccessStrategy().evict( ck );
 		}
 
 		String previousFetchProfile = this.getFetchProfile();
 		Object result = null;
 		try {
 			this.setFetchProfile( "refresh" );
 			result = persister.load( id, entity, lockMode, this );
 		}
 		finally {
 			this.setFetchProfile( previousFetchProfile );
 		}
 		UnresolvableObjectException.throwIfNull( result, id, persister.getEntityName() );
 	}
 
 	public Object immediateLoad(String entityName, Serializable id)
 			throws HibernateException {
 		throw new SessionException("proxies cannot be fetched by a stateless session");
 	}
 
 	public void initializeCollection(
 			PersistentCollection collection,
 	        boolean writing) throws HibernateException {
 		throw new SessionException("collections cannot be fetched by a stateless session");
 	}
 
 	public Object instantiate(
 			String entityName,
 	        Serializable id) throws HibernateException {
 		errorIfClosed();
 		return getFactory().getEntityPersister( entityName )
 				.instantiate( id, this );
 	}
 
 	public Object internalLoad(
 			String entityName,
 	        Serializable id,
 	        boolean eager,
 	        boolean nullable) throws HibernateException {
 		errorIfClosed();
 		EntityPersister persister = getFactory().getEntityPersister( entityName );
 		// first, try to load it from the temp PC associated to this SS
 		Object loaded = temporaryPersistenceContext.getEntity( generateEntityKey( id, persister ) );
 		if ( loaded != null ) {
 			// we found it in the temp PC.  Should indicate we are in the midst of processing a result set
 			// containing eager fetches via join fetch
 			return loaded;
 		}
 		if ( !eager && persister.hasProxy() ) {
 			// if the metadata allowed proxy creation and caller did not request forceful eager loading,
 			// generate a proxy
 			return persister.createProxy( id, this );
 		}
 		// otherwise immediately materialize it
 		return get( entityName, id );
 	}
 
 	public Iterator iterate(String query, QueryParameters queryParameters) throws HibernateException {
 		throw new UnsupportedOperationException();
 	}
 
 	public Iterator iterateFilter(Object collection, String filter, QueryParameters queryParameters)
 	throws HibernateException {
 		throw new UnsupportedOperationException();
 	}
 
 	public List listFilter(Object collection, String filter, QueryParameters queryParameters)
 	throws HibernateException {
 		throw new UnsupportedOperationException();
 	}
 
 
 	public boolean isOpen() {
 		return !isClosed();
 	}
 
 	public void close() {
 		managedClose();
 	}
 
 	public ConnectionReleaseMode getConnectionReleaseMode() {
 		return factory.getSettings().getConnectionReleaseMode();
 	}
 
 	@Override
 	public boolean shouldAutoJoinTransaction() {
 		return true;
 	}
 
 	public boolean isAutoCloseSessionEnabled() {
 		return factory.getSettings().isAutoCloseSessionEnabled();
 	}
 
 	public boolean isFlushBeforeCompletionEnabled() {
 		return true;
 	}
 
 	public boolean isFlushModeNever() {
 		return false;
 	}
 
 	public void managedClose() {
 		if ( isClosed() ) {
 			throw new SessionException( "Session was already closed!" );
 		}
 		transactionCoordinator.close();
 		setClosed();
 	}
 
 	public void managedFlush() {
 		errorIfClosed();
 		getTransactionCoordinator().getJdbcCoordinator().executeBatch();
 	}
 
 	public boolean shouldAutoClose() {
 		return isAutoCloseSessionEnabled() && !isClosed();
 	}
 
 	@Override
 	public void afterTransactionBegin(TransactionImplementor hibernateTransaction) {
 		// nothing to do here
 	}
 
 	@Override
 	public void beforeTransactionCompletion(TransactionImplementor hibernateTransaction) {
 		// nothing to do here
 	}
 
 	@Override
 	public void afterTransactionCompletion(TransactionImplementor hibernateTransaction, boolean successful) {
 		// nothing to do here
 	}
 
 	public String bestGuessEntityName(Object object) {
 		if (object instanceof HibernateProxy) {
 			object = ( (HibernateProxy) object ).getHibernateLazyInitializer().getImplementation();
 		}
 		return guessEntityName(object);
 	}
 
 	public Connection connection() {
 		errorIfClosed();
 		return transactionCoordinator.getJdbcCoordinator().getLogicalConnection().getDistinctConnectionProxy();
 	}
 
 	public int executeUpdate(String query, QueryParameters queryParameters)
 			throws HibernateException {
 		errorIfClosed();
 		queryParameters.validateParameters();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		boolean success = false;
 		int result = 0;
 		try {
 			result = plan.performExecuteUpdate( queryParameters, this );
 			success = true;
 		}
 		finally {
 			afterOperation(success);
 		}
 		temporaryPersistenceContext.clear();
 		return result;
 	}
 
 	public CacheMode getCacheMode() {
 		return CacheMode.IGNORE;
 	}
 
 	public int getDontFlushFromFind() {
 		return 0;
 	}
 
 	public Map getEnabledFilters() {
 		return CollectionHelper.EMPTY_MAP;
 	}
 
 	public Serializable getContextEntityIdentifier(Object object) {
 		errorIfClosed();
 		return null;
 	}
 
 	public EntityMode getEntityMode() {
 		return EntityMode.POJO;
 	}
 
 	public EntityPersister getEntityPersister(String entityName, Object object)
 			throws HibernateException {
 		errorIfClosed();
 		if ( entityName==null ) {
 			return factory.getEntityPersister( guessEntityName( object ) );
 		}
 		else {
 			return factory.getEntityPersister( entityName )
 					.getSubclassEntityPersister( object, getFactory(), EntityMode.POJO );
 		}
 	}
 
 	public Object getEntityUsingInterceptor(EntityKey key) throws HibernateException {
 		errorIfClosed();
 		return null;
 	}
 
 	public Type getFilterParameterType(String filterParameterName) {
 		throw new UnsupportedOperationException();
 	}
 
 	public Object getFilterParameterValue(String filterParameterName) {
 		throw new UnsupportedOperationException();
 	}
 
 	public FlushMode getFlushMode() {
 		return FlushMode.COMMIT;
 	}
 
 	public Interceptor getInterceptor() {
 		return EmptyInterceptor.INSTANCE;
 	}
 
 	public PersistenceContext getPersistenceContext() {
 		return temporaryPersistenceContext;
 	}
 
 	public long getTimestamp() {
 		throw new UnsupportedOperationException();
 	}
 
 	public String guessEntityName(Object entity) throws HibernateException {
 		errorIfClosed();
 		return entity.getClass().getName();
 	}
 
 
 	public boolean isConnected() {
 		return transactionCoordinator.getJdbcCoordinator().getLogicalConnection().isPhysicallyConnected();
 	}
 
 	public boolean isTransactionInProgress() {
 		return transactionCoordinator.isTransactionInProgress();
 	}
 
 	public void setAutoClear(boolean enabled) {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public void disableTransactionAutoJoin() {
 		throw new UnsupportedOperationException();
 	}
 
 	public void setCacheMode(CacheMode cm) {
 		throw new UnsupportedOperationException();
 	}
 
 	public void setFlushMode(FlushMode fm) {
 		throw new UnsupportedOperationException();
 	}
 
 	public Transaction getTransaction() throws HibernateException {
 		errorIfClosed();
 		return transactionCoordinator.getTransaction();
 	}
 
 	public Transaction beginTransaction() throws HibernateException {
 		errorIfClosed();
 		Transaction result = getTransaction();
 		result.begin();
 		return result;
 	}
 
 	public boolean isEventSource() {
 		return false;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public boolean isDefaultReadOnly() {
 		return false;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public void setDefaultReadOnly(boolean readOnly) throws HibernateException {
 		if ( readOnly == true ) {
 			throw new UnsupportedOperationException();
 		}
 	}
 
 /////////////////////////////////////////////////////////////////////////////////////////////////////
 
 	//TODO: COPY/PASTE FROM SessionImpl, pull up!
 
 	public List list(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		queryParameters.validateParameters();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		boolean success = false;
 		List results = CollectionHelper.EMPTY_LIST;
 		try {
 			results = plan.performList( queryParameters, this );
 			success = true;
 		}
 		finally {
 			afterOperation(success);
 		}
 		temporaryPersistenceContext.clear();
 		return results;
 	}
 
 	public void afterOperation(boolean success) {
 		if ( ! transactionCoordinator.isTransactionInProgress() ) {
 			transactionCoordinator.afterNonTransactionalQuery( success );;
 		}
 	}
 
 	public Criteria createCriteria(Class persistentClass, String alias) {
 		errorIfClosed();
 		return new CriteriaImpl( persistentClass.getName(), alias, this );
 	}
 
 	public Criteria createCriteria(String entityName, String alias) {
 		errorIfClosed();
 		return new CriteriaImpl(entityName, alias, this);
 	}
 
 	public Criteria createCriteria(Class persistentClass) {
 		errorIfClosed();
 		return new CriteriaImpl( persistentClass.getName(), this );
 	}
 
 	public Criteria createCriteria(String entityName) {
 		errorIfClosed();
 		return new CriteriaImpl(entityName, this);
 	}
 
 	public ScrollableResults scroll(CriteriaImpl criteria, ScrollMode scrollMode) {
 		errorIfClosed();
 		String entityName = criteria.getEntityOrClassName();
 		CriteriaLoader loader = new CriteriaLoader(
 				getOuterJoinLoadable( entityName ),
 		        factory,
 		        criteria,
 		        entityName,
 		        getLoadQueryInfluencers()
 		);
 		return loader.scroll(this, scrollMode);
 	}
 
 	public List list(CriteriaImpl criteria) throws HibernateException {
 		errorIfClosed();
 		String[] implementors = factory.getImplementors( criteria.getEntityOrClassName() );
 		int size = implementors.length;
 
 		CriteriaLoader[] loaders = new CriteriaLoader[size];
 		for( int i=0; i <size; i++ ) {
 			loaders[i] = new CriteriaLoader(
 					getOuterJoinLoadable( implementors[i] ),
 			        factory,
 			        criteria,
 			        implementors[i],
 			        getLoadQueryInfluencers()
 			);
 		}
 
 
 		List results = Collections.EMPTY_LIST;
 		boolean success = false;
 		try {
 			for( int i=0; i<size; i++ ) {
 				final List currentResults = loaders[i].list(this);
 				currentResults.addAll(results);
 				results = currentResults;
 			}
 			success = true;
 		}
 		finally {
 			afterOperation(success);
 		}
 		temporaryPersistenceContext.clear();
 		return results;
 	}
 
 	private OuterJoinLoadable getOuterJoinLoadable(String entityName) throws MappingException {
 		EntityPersister persister = factory.getEntityPersister(entityName);
 		if ( !(persister instanceof OuterJoinLoadable) ) {
 			throw new MappingException( "class persister is not OuterJoinLoadable: " + entityName );
 		}
 		return ( OuterJoinLoadable ) persister;
 	}
 
 	public List listCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
 	throws HibernateException {
 		errorIfClosed();
 		CustomLoader loader = new CustomLoader( customQuery, getFactory() );
 
 		boolean success = false;
 		List results;
 		try {
 			results = loader.list(this, queryParameters);
 			success = true;
 		}
 		finally {
 			afterOperation(success);
 		}
 		temporaryPersistenceContext.clear();
 		return results;
 	}
 
 	public ScrollableResults scrollCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
 	throws HibernateException {
 		errorIfClosed();
 		CustomLoader loader = new CustomLoader( customQuery, getFactory() );
 		return loader.scroll( queryParameters, this );
 	}
 
 	public ScrollableResults scroll(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		return plan.performScroll( queryParameters, this );
 	}
 
 	public void afterScrollOperation() {
 		temporaryPersistenceContext.clear();
 	}
 
 	public void flush() {}
 
 	public NonFlushedChanges getNonFlushedChanges() {
 		throw new UnsupportedOperationException();
 	}
 
 	public void applyNonFlushedChanges(NonFlushedChanges nonFlushedChanges) {
 		throw new UnsupportedOperationException();
 	}
 
 	public String getFetchProfile() {
 		return null;
 	}
 
 	public LoadQueryInfluencers getLoadQueryInfluencers() {
 		return LoadQueryInfluencers.NONE;
 	}
 
 	public void registerInsertedKey(EntityPersister persister, Serializable id) {
 		errorIfClosed();
 		// nothing to do
 	}
 
 	public boolean wasInsertedDuringTransaction(EntityPersister persister, Serializable id) {
 		errorIfClosed();
 		// not in any meaning we need to worry about here.
 		return false;
 	}
 
 	public void setFetchProfile(String name) {}
 
 	protected boolean autoFlushIfRequired(Set querySpaces) throws HibernateException {
 		// no auto-flushing to support in stateless session
 		return false;
 	}
 
 	public int executeNativeUpdate(NativeSQLQuerySpecification nativeSQLQuerySpecification,
 			QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		queryParameters.validateParameters();
 		NativeSQLQueryPlan plan = getNativeSQLQueryPlan(nativeSQLQuerySpecification);
 
 		boolean success = false;
 		int result = 0;
 		try {
 			result = plan.performExecuteUpdate(queryParameters, this);
 			success = true;
 		} finally {
 			afterOperation(success);
 		}
 		temporaryPersistenceContext.clear();
 		return result;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/Loader.java b/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
index 4f3a876807..1cb3b488eb 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
@@ -1,1054 +1,1054 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 
 import java.io.Serializable;
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
+import org.hibernate.cache.spi.QueryCache;
+import org.hibernate.cache.spi.QueryKey;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.WrongClassException;
-import org.hibernate.cache.FilterKey;
-import org.hibernate.cache.QueryCache;
-import org.hibernate.cache.QueryKey;
+import org.hibernate.cache.spi.FilterKey;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.EntityUniqueKey;
 import org.hibernate.engine.PersistenceContext;
 import org.hibernate.engine.QueryParameters;
 import org.hibernate.engine.RowSelection;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.SubselectFetch;
 import org.hibernate.engine.TwoPhaseLoad;
 import org.hibernate.engine.TypedValue;
 import org.hibernate.engine.jdbc.ColumnNameCache;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.PostLoadEvent;
 import org.hibernate.event.PreLoadEvent;
 import org.hibernate.hql.HolderInstantiator;
 import org.hibernate.internal.FetchingScrollableResultsImpl;
 import org.hibernate.internal.ScrollableResultsImpl;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.UniqueKeyLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.transform.CacheableResultTransformer;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 
 /**
  * Abstract superclass of object loading (and querying) strategies. This class implements
  * useful common functionality that concrete loaders delegate to. It is not intended that this
  * functionality would be directly accessed by client code. (Hence, all methods of this class
  * are declared <tt>protected</tt> or <tt>private</tt>.) This class relies heavily upon the
  * <tt>Loadable</tt> interface, which is the contract between this class and
  * <tt>EntityPersister</tt>s that may be loaded by it.<br>
  * <br>
  * The present implementation is able to load any number of columns of entities and at most
  * one collection role per query.
  *
  * @author Gavin King
  * @see org.hibernate.persister.entity.Loadable
  */
 public abstract class Loader {
 
     protected static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Loader.class.getName());
 
 	private final SessionFactoryImplementor factory;
 	private ColumnNameCache columnNameCache;
 
 	public Loader(SessionFactoryImplementor factory) {
 		this.factory = factory;
 	}
 
 	/**
 	 * The SQL query string to be called; implemented by all subclasses
 	 *
 	 * @return The sql command this loader should use to get its {@link ResultSet}.
 	 */
 	protected abstract String getSQLString();
 
 	/**
 	 * An array of persisters of entity classes contained in each row of results;
 	 * implemented by all subclasses
 	 *
 	 * @return The entity persisters.
 	 */
 	protected abstract Loadable[] getEntityPersisters();
 
 	/**
 	 * An array indicating whether the entities have eager property fetching
 	 * enabled.
 	 *
 	 * @return Eager property fetching indicators.
 	 */
 	protected boolean[] getEntityEagerPropertyFetches() {
 		return null;
 	}
 
 	/**
 	 * An array of indexes of the entity that owns a one-to-one association
 	 * to the entity at the given index (-1 if there is no "owner").  The
 	 * indexes contained here are relative to the result of
 	 * {@link #getEntityPersisters}.
 	 *
 	 * @return The owner indicators (see discussion above).
 	 */
 	protected int[] getOwners() {
 		return null;
 	}
 
 	/**
 	 * An array of the owner types corresponding to the {@link #getOwners()}
 	 * returns.  Indices indicating no owner would be null here.
 	 *
 	 * @return The types for the owners.
 	 */
 	protected EntityType[] getOwnerAssociationTypes() {
 		return null;
 	}
 
 	/**
 	 * An (optional) persister for a collection to be initialized; only
 	 * collection loaders return a non-null value
 	 */
 	protected CollectionPersister[] getCollectionPersisters() {
 		return null;
 	}
 
 	/**
 	 * Get the index of the entity that owns the collection, or -1
 	 * if there is no owner in the query results (ie. in the case of a
 	 * collection initializer) or no collection.
 	 */
 	protected int[] getCollectionOwners() {
 		return null;
 	}
 
 	protected int[][] getCompositeKeyManyToOneTargetIndices() {
 		return null;
 	}
 
 	/**
 	 * What lock options does this load entities with?
 	 *
 	 * @param lockOptions a collection of lock options specified dynamically via the Query interface
 	 */
 	//protected abstract LockOptions[] getLockOptions(Map lockOptions);
 	protected abstract LockMode[] getLockModes(LockOptions lockOptions);
 
 	/**
 	 * Append <tt>FOR UPDATE OF</tt> clause, if necessary. This
 	 * empty superclass implementation merely returns its first
 	 * argument.
 	 */
 	protected String applyLocks(String sql, LockOptions lockOptions, Dialect dialect) throws HibernateException {
 		return sql;
 	}
 
 	/**
 	 * Does this query return objects that might be already cached
 	 * by the session, whose lock mode may need upgrading
 	 */
 	protected boolean upgradeLocks() {
 		return false;
 	}
 
 	/**
 	 * Return false is this loader is a batch entity loader
 	 */
 	protected boolean isSingleRowLoader() {
 		return false;
 	}
 
 	/**
 	 * Get the SQL table aliases of entities whose
 	 * associations are subselect-loadable, returning
 	 * null if this loader does not support subselect
 	 * loading
 	 */
 	protected String[] getAliases() {
 		return null;
 	}
 
 	/**
 	 * Modify the SQL, adding lock hints and comments, if necessary
 	 */
 	protected String preprocessSQL(String sql, QueryParameters parameters, Dialect dialect)
 			throws HibernateException {
 
 		sql = applyLocks( sql, parameters.getLockOptions(), dialect );
 
 		return getFactory().getSettings().isCommentsEnabled() ?
 				prependComment( sql, parameters ) : sql;
 	}
 
 	private String prependComment(String sql, QueryParameters parameters) {
 		String comment = parameters.getComment();
 		if ( comment == null ) {
 			return sql;
 		}
 		else {
 			return new StringBuffer( comment.length() + sql.length() + 5 )
 					.append( "/* " )
 					.append( comment )
 					.append( " */ " )
 					.append( sql )
 					.toString();
 		}
 	}
 
 	/**
 	 * Execute an SQL query and attempt to instantiate instances of the class mapped by the given
 	 * persister from each row of the <tt>ResultSet</tt>. If an object is supplied, will attempt to
 	 * initialize that object. If a collection is supplied, attempt to initialize that collection.
 	 */
 	private List doQueryAndInitializeNonLazyCollections(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies) throws HibernateException, SQLException {
 		return doQueryAndInitializeNonLazyCollections(
 				session,
 				queryParameters,
 				returnProxies,
 				null
 		);
 	}
 
 	private List doQueryAndInitializeNonLazyCollections(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final ResultTransformer forcedResultTransformer)
 			throws HibernateException, SQLException {
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		boolean defaultReadOnlyOrig = persistenceContext.isDefaultReadOnly();
 		if ( queryParameters.isReadOnlyInitialized() ) {
 			// The read-only/modifiable mode for the query was explicitly set.
 			// Temporarily set the default read-only/modifiable setting to the query's setting.
 			persistenceContext.setDefaultReadOnly( queryParameters.isReadOnly() );
 		}
 		else {
 			// The read-only/modifiable setting for the query was not initialized.
 			// Use the default read-only/modifiable from the persistence context instead.
 			queryParameters.setReadOnly( persistenceContext.isDefaultReadOnly() );
 		}
 		persistenceContext.beforeLoad();
 		List result;
 		try {
 			try {
 				result = doQuery( session, queryParameters, returnProxies, forcedResultTransformer );
 			}
 			finally {
 				persistenceContext.afterLoad();
 			}
 			persistenceContext.initializeNonLazyCollections();
 		}
 		finally {
 			// Restore the original default
 			persistenceContext.setDefaultReadOnly( defaultReadOnlyOrig );
 		}
 		return result;
 	}
 
 	/**
 	 * Loads a single row from the result set.  This is the processing used from the
 	 * ScrollableResults where no collection fetches were encountered.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
 	 * @return The loaded "row".
 	 * @throws HibernateException
 	 */
 	public Object loadSingleRow(
 	        final ResultSet resultSet,
 	        final SessionImplementor session,
 	        final QueryParameters queryParameters,
 	        final boolean returnProxies) throws HibernateException {
 
 		final int entitySpan = getEntityPersisters().length;
 		final List hydratedObjects = entitySpan == 0 ?
 				null : new ArrayList( entitySpan );
 
 		final Object result;
 		try {
 			result = getRowFromResultSet(
 			        resultSet,
 					session,
 					queryParameters,
 					getLockModes( queryParameters.getLockOptions() ),
 					null,
 					hydratedObjects,
 					new EntityKey[entitySpan],
 					returnProxies
 				);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not read next row of results",
 			        getSQLString()
 				);
 		}
 
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				resultSet,
 				session,
 				queryParameters.isReadOnly( session )
 			);
 		session.getPersistenceContext().initializeNonLazyCollections();
 		return result;
 	}
 
 	private Object sequentialLoad(
 	        final ResultSet resultSet,
 	        final SessionImplementor session,
 	        final QueryParameters queryParameters,
 	        final boolean returnProxies,
 	        final EntityKey keyToRead) throws HibernateException {
 
 		final int entitySpan = getEntityPersisters().length;
 		final List hydratedObjects = entitySpan == 0 ?
 				null : new ArrayList( entitySpan );
 
 		Object result = null;
 		final EntityKey[] loadedKeys = new EntityKey[entitySpan];
 
 		try {
 			do {
 				Object loaded = getRowFromResultSet(
 						resultSet,
 						session,
 						queryParameters,
 						getLockModes( queryParameters.getLockOptions() ),
 						null,
 						hydratedObjects,
 						loadedKeys,
 						returnProxies
 					);
 				if ( result == null ) {
 					result = loaded;
 				}
 			}
 			while ( keyToRead.equals( loadedKeys[0] ) && resultSet.next() );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not doAfterTransactionCompletion sequential read of results (forward)",
 			        getSQLString()
 				);
 		}
 
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				resultSet,
 				session,
 				queryParameters.isReadOnly( session )
 			);
 		session.getPersistenceContext().initializeNonLazyCollections();
 		return result;
 	}
 
 	/**
 	 * Loads a single logical row from the result set moving forward.  This is the
 	 * processing used from the ScrollableResults where there were collection fetches
 	 * encountered; thus a single logical row may have multiple rows in the underlying
 	 * result set.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
 	 * @return The loaded "row".
 	 * @throws HibernateException
 	 */
 	public Object loadSequentialRowsForward(
 	        final ResultSet resultSet,
 	        final SessionImplementor session,
 	        final QueryParameters queryParameters,
 	        final boolean returnProxies) throws HibernateException {
 
 		// note that for sequential scrolling, we make the assumption that
 		// the first persister element is the "root entity"
 
 		try {
 			if ( resultSet.isAfterLast() ) {
 				// don't even bother trying to read further
 				return null;
 			}
 
 			if ( resultSet.isBeforeFirst() ) {
 				resultSet.next();
 			}
 
 			// We call getKeyFromResultSet() here so that we can know the
 			// key value upon which to doAfterTransactionCompletion the breaking logic.  However,
 			// it is also then called from getRowFromResultSet() which is certainly
 			// not the most efficient.  But the call here is needed, and there
 			// currently is no other way without refactoring of the doQuery()/getRowFromResultSet()
 			// methods
 			final EntityKey currentKey = getKeyFromResultSet(
 					0,
 					getEntityPersisters()[0],
 					null,
 					resultSet,
 					session
 				);
 
 			return sequentialLoad( resultSet, session, queryParameters, returnProxies, currentKey );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not doAfterTransactionCompletion sequential read of results (forward)",
 			        getSQLString()
 				);
 		}
 	}
 
 	/**
 	 * Loads a single logical row from the result set moving forward.  This is the
 	 * processing used from the ScrollableResults where there were collection fetches
 	 * encountered; thus a single logical row may have multiple rows in the underlying
 	 * result set.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
 	 * @return The loaded "row".
 	 * @throws HibernateException
 	 */
 	public Object loadSequentialRowsReverse(
 	        final ResultSet resultSet,
 	        final SessionImplementor session,
 	        final QueryParameters queryParameters,
 	        final boolean returnProxies,
 	        final boolean isLogicallyAfterLast) throws HibernateException {
 
 		// note that for sequential scrolling, we make the assumption that
 		// the first persister element is the "root entity"
 
 		try {
 			if ( resultSet.isFirst() ) {
 				// don't even bother trying to read any further
 				return null;
 			}
 
 			EntityKey keyToRead = null;
 			// This check is needed since processing leaves the cursor
 			// after the last physical row for the current logical row;
 			// thus if we are after the last physical row, this might be
 			// caused by either:
 			//      1) scrolling to the last logical row
 			//      2) scrolling past the last logical row
 			// In the latter scenario, the previous logical row
 			// really is the last logical row.
 			//
 			// In all other cases, we should process back two
 			// logical records (the current logic row, plus the
 			// previous logical row).
 			if ( resultSet.isAfterLast() && isLogicallyAfterLast ) {
 				// position cursor to the last row
 				resultSet.last();
 				keyToRead = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
 					);
 			}
 			else {
 				// Since the result set cursor is always left at the first
 				// physical row after the "last processed", we need to jump
 				// back one position to get the key value we are interested
 				// in skipping
 				resultSet.previous();
 
 				// sequentially read the result set in reverse until we recognize
 				// a change in the key value.  At that point, we are pointed at
 				// the last physical sequential row for the logical row in which
 				// we are interested in processing
 				boolean firstPass = true;
 				final EntityKey lastKey = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
 					);
 				while ( resultSet.previous() ) {
 					EntityKey checkKey = getKeyFromResultSet(
 							0,
 							getEntityPersisters()[0],
 							null,
 							resultSet,
 							session
 						);
 
 					if ( firstPass ) {
 						firstPass = false;
 						keyToRead = checkKey;
 					}
 
 					if ( !lastKey.equals( checkKey ) ) {
 						break;
 					}
 				}
 
 			}
 
 			// Read backwards until we read past the first physical sequential
 			// row with the key we are interested in loading
 			while ( resultSet.previous() ) {
 				EntityKey checkKey = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
 					);
 
 				if ( !keyToRead.equals( checkKey ) ) {
 					break;
 				}
 			}
 
 			// Finally, read ahead one row to position result set cursor
 			// at the first physical row we are interested in loading
 			resultSet.next();
 
 			// and doAfterTransactionCompletion the load
 			return sequentialLoad( resultSet, session, queryParameters, returnProxies, keyToRead );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not doAfterTransactionCompletion sequential read of results (forward)",
 			        getSQLString()
 				);
 		}
 	}
 
 	private static EntityKey getOptionalObjectKey(QueryParameters queryParameters, SessionImplementor session) {
 		final Object optionalObject = queryParameters.getOptionalObject();
 		final Serializable optionalId = queryParameters.getOptionalId();
 		final String optionalEntityName = queryParameters.getOptionalEntityName();
 
 		if ( optionalObject != null && optionalEntityName != null ) {
 			return session.generateEntityKey( optionalId, session.getEntityPersister( optionalEntityName, optionalObject ) );
 		}
 		else {
 			return null;
 		}
 
 	}
 
 	private Object getRowFromResultSet(
 	        final ResultSet resultSet,
 	        final SessionImplementor session,
 	        final QueryParameters queryParameters,
 	        final LockMode[] lockModesArray,
 	        final EntityKey optionalObjectKey,
 	        final List hydratedObjects,
 	        final EntityKey[] keys,
 	        boolean returnProxies) throws SQLException, HibernateException {
 		return getRowFromResultSet(
 				resultSet,
 				session,
 				queryParameters,
 				lockModesArray,
 				optionalObjectKey,
 				hydratedObjects,
 				keys,
 				returnProxies,
 				null
 		);
 	}
 
 	private Object getRowFromResultSet(
 	        final ResultSet resultSet,
 	        final SessionImplementor session,
 	        final QueryParameters queryParameters,
 	        final LockMode[] lockModesArray,
 	        final EntityKey optionalObjectKey,
 	        final List hydratedObjects,
 	        final EntityKey[] keys,
 	        boolean returnProxies,
 	        ResultTransformer forcedResultTransformer) throws SQLException, HibernateException {
 		final Loadable[] persisters = getEntityPersisters();
 		final int entitySpan = persisters.length;
 		extractKeysFromResultSet( persisters, queryParameters, resultSet, session, keys, lockModesArray, hydratedObjects );
 
 		registerNonExists( keys, persisters, session );
 
 		// this call is side-effecty
 		Object[] row = getRow(
 		        resultSet,
 				persisters,
 				keys,
 				queryParameters.getOptionalObject(),
 				optionalObjectKey,
 				lockModesArray,
 				hydratedObjects,
 				session
 		);
 
 		readCollectionElements( row, resultSet, session );
 
 		if ( returnProxies ) {
 			// now get an existing proxy for each row element (if there is one)
 			for ( int i = 0; i < entitySpan; i++ ) {
 				Object entity = row[i];
 				Object proxy = session.getPersistenceContext().proxyFor( persisters[i], keys[i], entity );
 				if ( entity != proxy ) {
 					// force the proxy to resolve itself
 					( (HibernateProxy) proxy ).getHibernateLazyInitializer().setImplementation(entity);
 					row[i] = proxy;
 				}
 			}
 		}
 
 		applyPostLoadLocks( row, lockModesArray, session );
 
 		return forcedResultTransformer == null ?
 				getResultColumnOrRow( row, queryParameters.getResultTransformer(), resultSet, session ) :
 				forcedResultTransformer.transformTuple(
 						getResultRow( row, resultSet, session ),
 						getResultRowAliases()
 				)
 		;
 	}
 
 	protected void extractKeysFromResultSet(
 			Loadable[] persisters,
 			QueryParameters queryParameters,
 			ResultSet resultSet,
 			SessionImplementor session,
 			EntityKey[] keys,
 			LockMode[] lockModes,
 			List hydratedObjects) throws SQLException {
 		final int entitySpan = persisters.length;
 
 		final int numberOfPersistersToProcess;
 		final Serializable optionalId = queryParameters.getOptionalId();
 		if ( isSingleRowLoader() && optionalId != null ) {
 			keys[ entitySpan - 1 ] = session.generateEntityKey( optionalId, persisters[ entitySpan - 1 ] );
 			// skip the last persister below...
 			numberOfPersistersToProcess = entitySpan - 1;
 		}
 		else {
 			numberOfPersistersToProcess = entitySpan;
 		}
 
 		final Object[] hydratedKeyState = new Object[numberOfPersistersToProcess];
 
 		for ( int i = 0; i < numberOfPersistersToProcess; i++ ) {
 			final Type idType = persisters[i].getIdentifierType();
 			hydratedKeyState[i] = idType.hydrate( resultSet, getEntityAliases()[i].getSuffixedKeyAliases(), session, null );
 		}
 
 		for ( int i = 0; i < numberOfPersistersToProcess; i++ ) {
 			final Type idType = persisters[i].getIdentifierType();
 			if ( idType.isComponentType() && getCompositeKeyManyToOneTargetIndices() != null ) {
 				// we may need to force resolve any key-many-to-one(s)
 				int[] keyManyToOneTargetIndices = getCompositeKeyManyToOneTargetIndices()[i];
 				// todo : better solution is to order the index processing based on target indices
 				//		that would account for multiple levels whereas this scheme does not
 				if ( keyManyToOneTargetIndices != null ) {
 					for ( int targetIndex : keyManyToOneTargetIndices ) {
 						if ( targetIndex < numberOfPersistersToProcess ) {
 							final Type targetIdType = persisters[targetIndex].getIdentifierType();
 							final Serializable targetId = (Serializable) targetIdType.resolve(
 									hydratedKeyState[targetIndex],
 									session,
 									null
 							);
 							// todo : need a way to signal that this key is resolved and its data resolved
 							keys[targetIndex] = session.generateEntityKey( targetId, persisters[targetIndex] );
 						}
 
 						// this part copied from #getRow, this section could be refactored out
 						Object object = session.getEntityUsingInterceptor( keys[targetIndex] );
 						if ( object != null ) {
 							//its already loaded so don't need to hydrate it
 							instanceAlreadyLoaded(
 									resultSet,
 									targetIndex,
 									persisters[targetIndex],
 									keys[targetIndex],
 									object,
 									lockModes[targetIndex],
 									session
 							);
 						}
 						else {
 							instanceNotYetLoaded(
 									resultSet,
 									targetIndex,
 									persisters[targetIndex],
 									getEntityAliases()[targetIndex].getRowIdAlias(),
 									keys[targetIndex],
 									lockModes[targetIndex],
 									getOptionalObjectKey( queryParameters, session ),
 									queryParameters.getOptionalObject(),
 									hydratedObjects,
 									session
 							);
 						}
 					}
 				}
 			}
 			final Serializable resolvedId = (Serializable) idType.resolve( hydratedKeyState[i], session, null );
 			keys[i] = resolvedId == null ? null : session.generateEntityKey( resolvedId, persisters[i] );
 		}
 	}
 
 	private Serializable determineResultId(SessionImplementor session, Serializable optionalId, Type idType, Serializable resolvedId) {
 		final boolean idIsResultId = optionalId != null
 				&& resolvedId != null
 				&& idType.isEqual( optionalId, resolvedId, session.getEntityMode(), factory );
 		final Serializable resultId = idIsResultId ? optionalId : resolvedId;
 		return resultId;
 	}
 
 	protected void applyPostLoadLocks(Object[] row, LockMode[] lockModesArray, SessionImplementor session) {
 	}
 
 	/**
 	 * Read any collection elements contained in a single row of the result set
 	 */
 	private void readCollectionElements(Object[] row, ResultSet resultSet, SessionImplementor session)
 			throws SQLException, HibernateException {
 
 		//TODO: make this handle multiple collection roles!
 
 		final CollectionPersister[] collectionPersisters = getCollectionPersisters();
 		if ( collectionPersisters != null ) {
 
 			final CollectionAliases[] descriptors = getCollectionAliases();
 			final int[] collectionOwners = getCollectionOwners();
 
 			for ( int i=0; i<collectionPersisters.length; i++ ) {
 
 				final boolean hasCollectionOwners = collectionOwners !=null &&
 						collectionOwners[i] > -1;
 				//true if this is a query and we are loading multiple instances of the same collection role
 				//otherwise this is a CollectionInitializer and we are loading up a single collection or batch
 
 				final Object owner = hasCollectionOwners ?
 						row[ collectionOwners[i] ] :
 						null; //if null, owner will be retrieved from session
 
 				final CollectionPersister collectionPersister = collectionPersisters[i];
 				final Serializable key;
 				if ( owner == null ) {
 					key = null;
 				}
 				else {
 					key = collectionPersister.getCollectionType().getKeyOfOwner( owner, session );
 					//TODO: old version did not require hashmap lookup:
 					//keys[collectionOwner].getIdentifier()
 				}
 
 				readCollectionElement(
 						owner,
 						key,
 						collectionPersister,
 						descriptors[i],
 						resultSet,
 						session
 					);
 
 			}
 
 		}
 	}
 
 	private List doQuery(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final ResultTransformer forcedResultTransformer) throws SQLException, HibernateException {
 
 		final RowSelection selection = queryParameters.getRowSelection();
 		final int maxRows = hasMaxRows( selection ) ?
 				selection.getMaxRows().intValue() :
 				Integer.MAX_VALUE;
 
 		final int entitySpan = getEntityPersisters().length;
 
 		final ArrayList hydratedObjects = entitySpan == 0 ? null : new ArrayList( entitySpan * 10 );
 		final PreparedStatement st = prepareQueryStatement( queryParameters, false, session );
 		final ResultSet rs = getResultSet( st, queryParameters.hasAutoDiscoverScalarTypes(), queryParameters.isCallable(), selection, session );
 
 // would be great to move all this below here into another method that could also be used
 // from the new scrolling stuff.
 //
 // Would need to change the way the max-row stuff is handled (i.e. behind an interface) so
 // that I could do the control breaking at the means to know when to stop
 
 		final EntityKey optionalObjectKey = getOptionalObjectKey( queryParameters, session );
 		final LockMode[] lockModesArray = getLockModes( queryParameters.getLockOptions() );
 		final boolean createSubselects = isSubselectLoadingEnabled();
 		final List subselectResultKeys = createSubselects ? new ArrayList() : null;
 		final List results = new ArrayList();
 
 		try {
 
 			handleEmptyCollections( queryParameters.getCollectionKeys(), rs, session );
 
 			EntityKey[] keys = new EntityKey[entitySpan]; //we can reuse it for each row
 
             LOG.trace("Processing result set");
 
 			int count;
 			for ( count = 0; count < maxRows && rs.next(); count++ ) {
 
                 LOG.debugf("Result set row: %s", count);
 
 				Object result = getRowFromResultSet(
 						rs,
 						session,
 						queryParameters,
 						lockModesArray,
 						optionalObjectKey,
 						hydratedObjects,
 						keys,
 						returnProxies,
 						forcedResultTransformer
 				);
 				results.add( result );
 
 				if ( createSubselects ) {
 					subselectResultKeys.add(keys);
 					keys = new EntityKey[entitySpan]; //can't reuse in this case
 				}
 
 			}
 
             LOG.trace("Done processing result set (" + count + " rows)");
 
 		}
 		finally {
 			st.close();
 		}
 
 		initializeEntitiesAndCollections( hydratedObjects, rs, session, queryParameters.isReadOnly( session ) );
 
 		if ( createSubselects ) createSubselects( subselectResultKeys, queryParameters, session );
 
 		return results; //getResultList(results);
 
 	}
 
 	protected boolean isSubselectLoadingEnabled() {
 		return false;
 	}
 
 	protected boolean hasSubselectLoadableCollections() {
 		final Loadable[] loadables = getEntityPersisters();
 		for (int i=0; i<loadables.length; i++ ) {
 			if ( loadables[i].hasSubselectLoadableCollections() ) return true;
 		}
 		return false;
 	}
 
 	private static Set[] transpose( List keys ) {
 		Set[] result = new Set[ ( ( EntityKey[] ) keys.get(0) ).length ];
 		for ( int j=0; j<result.length; j++ ) {
 			result[j] = new HashSet( keys.size() );
 			for ( int i=0; i<keys.size(); i++ ) {
 				result[j].add( ( ( EntityKey[] ) keys.get(i) ) [j] );
 			}
 		}
 		return result;
 	}
 
 	private void createSubselects(List keys, QueryParameters queryParameters, SessionImplementor session) {
 		if ( keys.size() > 1 ) { //if we only returned one entity, query by key is more efficient
 
 			Set[] keySets = transpose(keys);
 
 			Map namedParameterLocMap = buildNamedParameterLocMap( queryParameters );
 
 			final Loadable[] loadables = getEntityPersisters();
 			final String[] aliases = getAliases();
 			final Iterator iter = keys.iterator();
 			while ( iter.hasNext() ) {
 
 				final EntityKey[] rowKeys = (EntityKey[]) iter.next();
 				for ( int i=0; i<rowKeys.length; i++ ) {
 
 					if ( rowKeys[i]!=null && loadables[i].hasSubselectLoadableCollections() ) {
 
 						SubselectFetch subselectFetch = new SubselectFetch(
 								//getSQLString(),
 								aliases[i],
 								loadables[i],
 								queryParameters,
 								keySets[i],
 								namedParameterLocMap
 							);
 
 						session.getPersistenceContext()
 								.getBatchFetchQueue()
 								.addSubselect( rowKeys[i], subselectFetch );
 					}
 
 				}
 
 			}
 		}
 	}
 
 	private Map buildNamedParameterLocMap(QueryParameters queryParameters) {
 		if ( queryParameters.getNamedParameters()!=null ) {
 			final Map namedParameterLocMap = new HashMap();
 			Iterator piter = queryParameters.getNamedParameters().keySet().iterator();
 			while ( piter.hasNext() ) {
 				String name = (String) piter.next();
 				namedParameterLocMap.put(
 						name,
 						getNamedParameterLocs(name)
 					);
 			}
 			return namedParameterLocMap;
 		}
 		else {
 			return null;
 		}
 	}
 
 	private void initializeEntitiesAndCollections(
 			final List hydratedObjects,
 			final Object resultSetId,
 			final SessionImplementor session,
 			final boolean readOnly)
 	throws HibernateException {
 
 		final CollectionPersister[] collectionPersisters = getCollectionPersisters();
 		if ( collectionPersisters != null ) {
 			for ( int i=0; i<collectionPersisters.length; i++ ) {
 				if ( collectionPersisters[i].isArray() ) {
 					//for arrays, we should end the collection load before resolving
 					//the entities, since the actual array instances are not instantiated
 					//during loading
 					//TODO: or we could do this polymorphically, and have two
 					//      different operations implemented differently for arrays
 					endCollectionLoad( resultSetId, session, collectionPersisters[i] );
 				}
 			}
 		}
 
 		//important: reuse the same event instances for performance!
 		final PreLoadEvent pre;
 		final PostLoadEvent post;
 		if ( session.isEventSource() ) {
 			pre = new PreLoadEvent( (EventSource) session );
 			post = new PostLoadEvent( (EventSource) session );
 		}
 		else {
 			pre = null;
 			post = null;
 		}
 
 		if ( hydratedObjects!=null ) {
 			int hydratedObjectsSize = hydratedObjects.size();
             LOG.trace("Total objects hydrated: " + hydratedObjectsSize);
 			for ( int i = 0; i < hydratedObjectsSize; i++ ) {
 				TwoPhaseLoad.initializeEntity( hydratedObjects.get(i), readOnly, session, pre, post );
 			}
 		}
 
 		if ( collectionPersisters != null ) {
 			for ( int i=0; i<collectionPersisters.length; i++ ) {
 				if ( !collectionPersisters[i].isArray() ) {
 					//for sets, we should end the collection load after resolving
 					//the entities, since we might call hashCode() on the elements
 					//TODO: or we could do this polymorphically, and have two
 					//      different operations implemented differently for arrays
 					endCollectionLoad( resultSetId, session, collectionPersisters[i] );
 				}
 			}
 		}
 
 	}
 
 	private void endCollectionLoad(
 			final Object resultSetId,
 			final SessionImplementor session,
 			final CollectionPersister collectionPersister) {
 		//this is a query and we are loading multiple instances of the same collection role
 		session.getPersistenceContext()
 				.getLoadContexts()
 				.getCollectionLoadContext( ( ResultSet ) resultSetId )
 				.endLoadingCollections( collectionPersister );
 	}
 
 	/**
 	 * Determine the actual ResultTransformer that will be used to
 	 * transform query results.
 	 *
 	 * @param resultTransformer the specified result transformer
 	 * @return the actual result transformer
 	 */
 	protected ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer) {
 		return resultTransformer;
 	}
 
 	protected List getResultList(List results, ResultTransformer resultTransformer) throws QueryException {
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
index 4e9096db94..f8256e5610 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
@@ -1,1049 +1,1049 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.collection;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.FetchMode;
 import org.hibernate.HibernateException;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
-import org.hibernate.cache.entry.CacheEntryStructure;
-import org.hibernate.cache.entry.StructuredCollectionCacheEntry;
-import org.hibernate.cache.entry.StructuredMapCacheEntry;
-import org.hibernate.cache.entry.UnstructuredCacheEntry;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
+import org.hibernate.cache.spi.entry.CacheEntryStructure;
+import org.hibernate.cache.spi.entry.StructuredCollectionCacheEntry;
+import org.hibernate.cache.spi.entry.StructuredMapCacheEntry;
+import org.hibernate.cache.spi.entry.UnstructuredCacheEntry;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.LoadQueryInfluencers;
 import org.hibernate.engine.PersistenceContext;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.SubselectFetch;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.exception.SQLExceptionConverter;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.internal.FilterHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.loader.collection.CollectionInitializer;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Formula;
 import org.hibernate.mapping.IdentifierCollection;
 import org.hibernate.mapping.IndexedCollection;
 import org.hibernate.mapping.List;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.mapping.Table;
 import org.hibernate.metadata.CollectionMetadata;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Alias;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.SimpleSelect;
 import org.hibernate.sql.Template;
 import org.hibernate.sql.ordering.antlr.ColumnMapper;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 
 /**
  * Base implementation of the <tt>QueryableCollection</tt> interface.
  *
  * @author Gavin King
  * @see BasicCollectionPersister
  * @see OneToManyPersister
  */
 public abstract class AbstractCollectionPersister
 		implements CollectionMetadata, SQLLoadableCollection {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractCollectionPersister.class.getName());
 
     // TODO: encapsulate the protected instance variables!
 
 	private final String role;
 
 	//SQL statements
 	private final String sqlDeleteString;
 	private final String sqlInsertRowString;
 	private final String sqlUpdateRowString;
 	private final String sqlDeleteRowString;
 	private final String sqlSelectSizeString;
 	private final String sqlSelectRowByIndexString;
 	private final String sqlDetectRowByIndexString;
 	private final String sqlDetectRowByElementString;
 
 	protected final String sqlWhereString;
 	private final String sqlOrderByStringTemplate;
 	private final String sqlWhereStringTemplate;
 	private final boolean hasOrder;
 	protected final boolean hasWhere;
 	private final int baseIndex;
 
 	private final String nodeName;
 	private final String elementNodeName;
 	private final String indexNodeName;
 
 	protected final boolean indexContainsFormula;
 	protected final boolean elementIsPureFormula;
 
 	//types
 	private final Type keyType;
 	private final Type indexType;
 	protected final Type elementType;
 	private final Type identifierType;
 
 	//columns
 	protected final String[] keyColumnNames;
 	protected final String[] indexColumnNames;
 	protected final String[] indexFormulaTemplates;
 	protected final String[] indexFormulas;
 	protected final boolean[] indexColumnIsSettable;
 	protected final String[] elementColumnNames;
 	protected final String[] elementColumnWriters;
 	protected final String[] elementColumnReaders;
 	protected final String[] elementColumnReaderTemplates;
 	protected final String[] elementFormulaTemplates;
 	protected final String[] elementFormulas;
 	protected final boolean[] elementColumnIsSettable;
 	protected final boolean[] elementColumnIsInPrimaryKey;
 	protected final String[] indexColumnAliases;
 	protected final String[] elementColumnAliases;
 	protected final String[] keyColumnAliases;
 
 	protected final String identifierColumnName;
 	private final String identifierColumnAlias;
 	//private final String unquotedIdentifierColumnName;
 
 	protected final String qualifiedTableName;
 
 	private final String queryLoaderName;
 
 	private final boolean isPrimitiveArray;
 	private final boolean isArray;
 	protected final boolean hasIndex;
 	protected final boolean hasIdentifier;
 	private final boolean isLazy;
 	private final boolean isExtraLazy;
 	private final boolean isInverse;
 	private final boolean isMutable;
 	private final boolean isVersioned;
 	protected final int batchSize;
 	private final FetchMode fetchMode;
 	private final boolean hasOrphanDelete;
 	private final boolean subselectLoadable;
 
 	//extra information about the element type
 	private final Class elementClass;
 	private final String entityName;
 
 	private final Dialect dialect;
 	private final SqlExceptionHelper sqlExceptionHelper;
 	private final SessionFactoryImplementor factory;
 	private final EntityPersister ownerPersister;
 	private final IdentifierGenerator identifierGenerator;
 	private final PropertyMapping elementPropertyMapping;
 	private final EntityPersister elementPersister;
 	private final CollectionRegionAccessStrategy cacheAccessStrategy;
 	private final CollectionType collectionType;
 	private CollectionInitializer initializer;
 
 	private final CacheEntryStructure cacheEntryStructure;
 
 	// dynamic filters for the collection
 	private final FilterHelper filterHelper;
 
 	// dynamic filters specifically for many-to-many inside the collection
 	private final FilterHelper manyToManyFilterHelper;
 
 	private final String manyToManyWhereString;
 	private final String manyToManyWhereTemplate;
 
 	private final boolean hasManyToManyOrder;
 	private final String manyToManyOrderByTemplate;
 
 	// custom sql
 	private final boolean insertCallable;
 	private final boolean updateCallable;
 	private final boolean deleteCallable;
 	private final boolean deleteAllCallable;
 	private ExecuteUpdateResultCheckStyle insertCheckStyle;
 	private ExecuteUpdateResultCheckStyle updateCheckStyle;
 	private ExecuteUpdateResultCheckStyle deleteCheckStyle;
 	private ExecuteUpdateResultCheckStyle deleteAllCheckStyle;
 
 	private final Serializable[] spaces;
 
 	private Map collectionPropertyColumnAliases = new HashMap();
 	private Map collectionPropertyColumnNames = new HashMap();
 
 	public AbstractCollectionPersister(
 			final Collection collection,
 			final CollectionRegionAccessStrategy cacheAccessStrategy,
 			final Configuration cfg,
 			final SessionFactoryImplementor factory) throws MappingException, CacheException {
 
 		this.factory = factory;
 		this.cacheAccessStrategy = cacheAccessStrategy;
 		if ( factory.getSettings().isStructuredCacheEntriesEnabled() ) {
 			cacheEntryStructure = collection.isMap() ?
 					( CacheEntryStructure ) new StructuredMapCacheEntry() :
 					( CacheEntryStructure ) new StructuredCollectionCacheEntry();
 		}
 		else {
 			cacheEntryStructure = new UnstructuredCacheEntry();
 		}
 
 		dialect = factory.getDialect();
 		sqlExceptionHelper = factory.getSQLExceptionHelper();
 		collectionType = collection.getCollectionType();
 		role = collection.getRole();
 		entityName = collection.getOwnerEntityName();
 		ownerPersister = factory.getEntityPersister(entityName);
 		queryLoaderName = collection.getLoaderName();
 		nodeName = collection.getNodeName();
 		isMutable = collection.isMutable();
 
 		Table table = collection.getCollectionTable();
 		fetchMode = collection.getElement().getFetchMode();
 		elementType = collection.getElement().getType();
 		//isSet = collection.isSet();
 		//isSorted = collection.isSorted();
 		isPrimitiveArray = collection.isPrimitiveArray();
 		isArray = collection.isArray();
 		subselectLoadable = collection.isSubselectLoadable();
 
 		qualifiedTableName = table.getQualifiedName(
 				dialect,
 				factory.getSettings().getDefaultCatalogName(),
 				factory.getSettings().getDefaultSchemaName()
 			);
 
 		int spacesSize = 1 + collection.getSynchronizedTables().size();
 		spaces = new String[spacesSize];
 		spaces[0] = qualifiedTableName;
 		Iterator iter = collection.getSynchronizedTables().iterator();
 		for ( int i = 1; i < spacesSize; i++ ) {
 			spaces[i] = (String) iter.next();
 		}
 
 		sqlWhereString = StringHelper.isNotEmpty( collection.getWhere() ) ? "( " + collection.getWhere() + ") " : null;
 		hasWhere = sqlWhereString != null;
 		sqlWhereStringTemplate = hasWhere ?
 				Template.renderWhereStringTemplate(sqlWhereString, dialect, factory.getSqlFunctionRegistry()) :
 				null;
 
 		hasOrphanDelete = collection.hasOrphanDelete();
 
 		int batch = collection.getBatchSize();
 		if ( batch == -1 ) {
 			batch = factory.getSettings().getDefaultBatchFetchSize();
 		}
 		batchSize = batch;
 
 		isVersioned = collection.isOptimisticLocked();
 
 		// KEY
 
 		keyType = collection.getKey().getType();
 		iter = collection.getKey().getColumnIterator();
 		int keySpan = collection.getKey().getColumnSpan();
 		keyColumnNames = new String[keySpan];
 		keyColumnAliases = new String[keySpan];
 		int k = 0;
 		while ( iter.hasNext() ) {
 			// NativeSQL: collect key column and auto-aliases
 			Column col = ( (Column) iter.next() );
 			keyColumnNames[k] = col.getQuotedName(dialect);
 			keyColumnAliases[k] = col.getAlias(dialect,collection.getOwner().getRootTable());
 			k++;
 		}
 
 		//unquotedKeyColumnNames = StringHelper.unQuote(keyColumnAliases);
 
 		//ELEMENT
 
 		String elemNode = collection.getElementNodeName();
 		if ( elementType.isEntityType() ) {
 			String entityName = ( (EntityType) elementType ).getAssociatedEntityName();
 			elementPersister = factory.getEntityPersister(entityName);
 			if ( elemNode==null ) {
 				elemNode = cfg.getClassMapping(entityName).getNodeName();
 			}
 			// NativeSQL: collect element column and auto-aliases
 
 		}
 		else {
 			elementPersister = null;
 		}
 		elementNodeName = elemNode;
 
 		int elementSpan = collection.getElement().getColumnSpan();
 		elementColumnAliases = new String[elementSpan];
 		elementColumnNames = new String[elementSpan];
 		elementColumnWriters = new String[elementSpan];
 		elementColumnReaders = new String[elementSpan];
 		elementColumnReaderTemplates = new String[elementSpan];
 		elementFormulaTemplates = new String[elementSpan];
 		elementFormulas = new String[elementSpan];
 		elementColumnIsSettable = new boolean[elementSpan];
 		elementColumnIsInPrimaryKey = new boolean[elementSpan];
 		boolean isPureFormula = true;
 		boolean hasNotNullableColumns = false;
 		int j = 0;
 		iter = collection.getElement().getColumnIterator();
 		while ( iter.hasNext() ) {
 			Selectable selectable = (Selectable) iter.next();
 			elementColumnAliases[j] = selectable.getAlias(dialect);
 			if ( selectable.isFormula() ) {
 				Formula form = (Formula) selectable;
 				elementFormulaTemplates[j] = form.getTemplate(dialect, factory.getSqlFunctionRegistry());
 				elementFormulas[j] = form.getFormula();
 			}
 			else {
 				Column col = (Column) selectable;
 				elementColumnNames[j] = col.getQuotedName(dialect);
 				elementColumnWriters[j] = col.getWriteExpr();
 				elementColumnReaders[j] = col.getReadExpr(dialect);
 				elementColumnReaderTemplates[j] = col.getTemplate(dialect, factory.getSqlFunctionRegistry());
 				elementColumnIsSettable[j] = true;
 				elementColumnIsInPrimaryKey[j] = !col.isNullable();
 				if ( !col.isNullable() ) {
 					hasNotNullableColumns = true;
 				}
 				isPureFormula = false;
 			}
 			j++;
 		}
 		elementIsPureFormula = isPureFormula;
 
 		//workaround, for backward compatibility of sets with no
 		//not-null columns, assume all columns are used in the
 		//row locator SQL
 		if ( !hasNotNullableColumns ) {
 			Arrays.fill( elementColumnIsInPrimaryKey, true );
 		}
 
 
 		// INDEX AND ROW SELECT
 
 		hasIndex = collection.isIndexed();
 		if (hasIndex) {
 			// NativeSQL: collect index column and auto-aliases
 			IndexedCollection indexedCollection = (IndexedCollection) collection;
 			indexType = indexedCollection.getIndex().getType();
 			int indexSpan = indexedCollection.getIndex().getColumnSpan();
 			iter = indexedCollection.getIndex().getColumnIterator();
 			indexColumnNames = new String[indexSpan];
 			indexFormulaTemplates = new String[indexSpan];
 			indexFormulas = new String[indexSpan];
 			indexColumnIsSettable = new boolean[indexSpan];
 			indexColumnAliases = new String[indexSpan];
 			int i = 0;
 			boolean hasFormula = false;
 			while ( iter.hasNext() ) {
 				Selectable s = (Selectable) iter.next();
 				indexColumnAliases[i] = s.getAlias(dialect);
 				if ( s.isFormula() ) {
 					Formula indexForm = (Formula) s;
 					indexFormulaTemplates[i] = indexForm.getTemplate(dialect, factory.getSqlFunctionRegistry());
 					indexFormulas[i] = indexForm.getFormula();
 					hasFormula = true;
 				}
 				else {
 					Column indexCol = (Column) s;
 					indexColumnNames[i] = indexCol.getQuotedName(dialect);
 					indexColumnIsSettable[i] = true;
 				}
 				i++;
 			}
 			indexContainsFormula = hasFormula;
 			baseIndex = indexedCollection.isList() ?
 					( (List) indexedCollection ).getBaseIndex() : 0;
 
 			indexNodeName = indexedCollection.getIndexNodeName();
 
 		}
 		else {
 			indexContainsFormula = false;
 			indexColumnIsSettable = null;
 			indexFormulaTemplates = null;
 			indexFormulas = null;
 			indexType = null;
 			indexColumnNames = null;
 			indexColumnAliases = null;
 			baseIndex = 0;
 			indexNodeName = null;
 		}
 
 		hasIdentifier = collection.isIdentified();
 		if (hasIdentifier) {
 			if ( collection.isOneToMany() ) {
 				throw new MappingException( "one-to-many collections with identifiers are not supported" );
 			}
 			IdentifierCollection idColl = (IdentifierCollection) collection;
 			identifierType = idColl.getIdentifier().getType();
 			iter = idColl.getIdentifier().getColumnIterator();
 			Column col = ( Column ) iter.next();
 			identifierColumnName = col.getQuotedName(dialect);
 			identifierColumnAlias = col.getAlias(dialect);
 			//unquotedIdentifierColumnName = identifierColumnAlias;
 			identifierGenerator = idColl.getIdentifier().createIdentifierGenerator(
 					cfg.getIdentifierGeneratorFactory(),
 					factory.getDialect(),
 					factory.getSettings().getDefaultCatalogName(),
 					factory.getSettings().getDefaultSchemaName(),
 					null
 			);
 		}
 		else {
 			identifierType = null;
 			identifierColumnName = null;
 			identifierColumnAlias = null;
 			//unquotedIdentifierColumnName = null;
 			identifierGenerator = null;
 		}
 
 		//GENERATE THE SQL:
 
 		//sqlSelectString = sqlSelectString();
 		//sqlSelectRowString = sqlSelectRowString();
 
 		if ( collection.getCustomSQLInsert() == null ) {
 			sqlInsertRowString = generateInsertRowString();
 			insertCallable = false;
 			insertCheckStyle = ExecuteUpdateResultCheckStyle.COUNT;
 		}
 		else {
 			sqlInsertRowString = collection.getCustomSQLInsert();
 			insertCallable = collection.isCustomInsertCallable();
 			insertCheckStyle = collection.getCustomSQLInsertCheckStyle() == null
 					? ExecuteUpdateResultCheckStyle.determineDefault( collection.getCustomSQLInsert(), insertCallable )
 		            : collection.getCustomSQLInsertCheckStyle();
 		}
 
 		if ( collection.getCustomSQLUpdate() == null ) {
 			sqlUpdateRowString = generateUpdateRowString();
 			updateCallable = false;
 			updateCheckStyle = ExecuteUpdateResultCheckStyle.COUNT;
 		}
 		else {
 			sqlUpdateRowString = collection.getCustomSQLUpdate();
 			updateCallable = collection.isCustomUpdateCallable();
 			updateCheckStyle = collection.getCustomSQLUpdateCheckStyle() == null
 					? ExecuteUpdateResultCheckStyle.determineDefault( collection.getCustomSQLUpdate(), insertCallable )
 		            : collection.getCustomSQLUpdateCheckStyle();
 		}
 
 		if ( collection.getCustomSQLDelete() == null ) {
 			sqlDeleteRowString = generateDeleteRowString();
 			deleteCallable = false;
 			deleteCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 		else {
 			sqlDeleteRowString = collection.getCustomSQLDelete();
 			deleteCallable = collection.isCustomDeleteCallable();
 			deleteCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 
 		if ( collection.getCustomSQLDeleteAll() == null ) {
 			sqlDeleteString = generateDeleteString();
 			deleteAllCallable = false;
 			deleteAllCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 		else {
 			sqlDeleteString = collection.getCustomSQLDeleteAll();
 			deleteAllCallable = collection.isCustomDeleteAllCallable();
 			deleteAllCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 
 		sqlSelectSizeString = generateSelectSizeString(  collection.isIndexed() && !collection.isMap() );
 		sqlDetectRowByIndexString = generateDetectRowByIndexString();
 		sqlDetectRowByElementString = generateDetectRowByElementString();
 		sqlSelectRowByIndexString = generateSelectRowByIndexString();
 
 		logStaticSQL();
 
 		isLazy = collection.isLazy();
 		isExtraLazy = collection.isExtraLazy();
 
 		isInverse = collection.isInverse();
 
 		if ( collection.isArray() ) {
 			elementClass = ( (org.hibernate.mapping.Array) collection ).getElementClass();
 		}
 		else {
 			// for non-arrays, we don't need to know the element class
 			elementClass = null; //elementType.returnedClass();
 		}
 
 		if ( elementType.isComponentType() ) {
 			elementPropertyMapping = new CompositeElementPropertyMapping(
 					elementColumnNames,
 					elementColumnReaders,
 					elementColumnReaderTemplates,
 					elementFormulaTemplates,
 					(CompositeType) elementType,
 					factory
 				);
 		}
 		else if ( !elementType.isEntityType() ) {
 			elementPropertyMapping = new ElementPropertyMapping(
 					elementColumnNames,
 					elementType
 				);
 		}
 		else {
 			if ( elementPersister instanceof PropertyMapping ) { //not all classpersisters implement PropertyMapping!
 				elementPropertyMapping = (PropertyMapping) elementPersister;
 			}
 			else {
 				elementPropertyMapping = new ElementPropertyMapping(
 						elementColumnNames,
 						elementType
 					);
 			}
 		}
 
 		hasOrder = collection.getOrderBy() != null;
 		if ( hasOrder ) {
 			ColumnMapper mapper = new ColumnMapper() {
 				public String[] map(String reference) {
 					return elementPropertyMapping.toColumns( reference );
 				}
 			};
 			sqlOrderByStringTemplate = Template.renderOrderByStringTemplate(
 					collection.getOrderBy(),
 					mapper,
 					factory,
 					dialect,
 					factory.getSqlFunctionRegistry()
 			);
 		}
 		else {
 			sqlOrderByStringTemplate = null;
 		}
 
 		// Handle any filters applied to this collection
 		filterHelper = new FilterHelper( collection.getFilterMap(), dialect, factory.getSqlFunctionRegistry() );
 
 		// Handle any filters applied to this collection for many-to-many
 		manyToManyFilterHelper = new FilterHelper( collection.getManyToManyFilterMap(), dialect, factory.getSqlFunctionRegistry() );
 		manyToManyWhereString = StringHelper.isNotEmpty( collection.getManyToManyWhere() ) ?
 				"( " + collection.getManyToManyWhere() + ")" :
 				null;
 		manyToManyWhereTemplate = manyToManyWhereString == null ?
 				null :
 				Template.renderWhereStringTemplate( manyToManyWhereString, factory.getDialect(), factory.getSqlFunctionRegistry() );
 
 		hasManyToManyOrder = collection.getManyToManyOrdering() != null;
 		if ( hasManyToManyOrder ) {
 			ColumnMapper mapper = new ColumnMapper() {
 				public String[] map(String reference) {
 					return elementPropertyMapping.toColumns( reference );
 				}
 			};
 			manyToManyOrderByTemplate = Template.renderOrderByStringTemplate(
 					collection.getManyToManyOrdering(),
 					mapper,
 					factory,
 					dialect,
 					factory.getSqlFunctionRegistry()
 			);
 		}
 		else {
 			manyToManyOrderByTemplate = null;
 		}
 
 		initCollectionPropertyMap();
 	}
 
 	public void postInstantiate() throws MappingException {
 		initializer = queryLoaderName == null ?
 				createCollectionInitializer( LoadQueryInfluencers.NONE ) :
 				new NamedQueryCollectionInitializer( queryLoaderName, this );
 	}
 
 	protected void logStaticSQL() {
         if (LOG.isDebugEnabled()) {
             LOG.debugf("Static SQL for collection: %s", getRole());
             if (getSQLInsertRowString() != null) LOG.debugf(" Row insert: %s", getSQLInsertRowString());
             if (getSQLUpdateRowString() != null) LOG.debugf(" Row update: %s", getSQLUpdateRowString());
             if (getSQLDeleteRowString() != null) LOG.debugf(" Row delete: %s", getSQLDeleteRowString());
             if (getSQLDeleteString() != null) LOG.debugf(" One-shot delete: %s", getSQLDeleteString());
 		}
 	}
 
 	public void initialize(Serializable key, SessionImplementor session) throws HibernateException {
 		getAppropriateInitializer( key, session ).initialize( key, session );
 	}
 
 	protected CollectionInitializer getAppropriateInitializer(Serializable key, SessionImplementor session) {
 		if ( queryLoaderName != null ) {
 			//if there is a user-specified loader, return that
 			//TODO: filters!?
 			return initializer;
 		}
 		CollectionInitializer subselectInitializer = getSubselectInitializer( key, session );
 		if ( subselectInitializer != null ) {
 			return subselectInitializer;
 		}
 		else if ( session.getEnabledFilters().isEmpty() ) {
 			return initializer;
 		}
 		else {
 			return createCollectionInitializer( session.getLoadQueryInfluencers() );
 		}
 	}
 
 	private CollectionInitializer getSubselectInitializer(Serializable key, SessionImplementor session) {
 
 		if ( !isSubselectLoadable() ) {
 			return null;
 		}
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 
 		SubselectFetch subselect = persistenceContext.getBatchFetchQueue()
 				.getSubselect( session.generateEntityKey( key, getOwnerEntityPersister() ) );
 
 		if (subselect == null) {
 			return null;
 		}
 		else {
 
 			// Take care of any entities that might have
 			// been evicted!
 			Iterator iter = subselect.getResult().iterator();
 			while ( iter.hasNext() ) {
 				if ( !persistenceContext.containsEntity( (EntityKey) iter.next() ) ) {
 					iter.remove();
 				}
 			}
 
 			// Run a subquery loader
 			return createSubselectInitializer( subselect, session );
 		}
 	}
 
 	protected abstract CollectionInitializer createSubselectInitializer(SubselectFetch subselect, SessionImplementor session);
 
 	protected abstract CollectionInitializer createCollectionInitializer(LoadQueryInfluencers loadQueryInfluencers)
 			throws MappingException;
 
 	public CollectionRegionAccessStrategy getCacheAccessStrategy() {
 		return cacheAccessStrategy;
 	}
 
 	public boolean hasCache() {
 		return cacheAccessStrategy != null;
 	}
 
 	public CollectionType getCollectionType() {
 		return collectionType;
 	}
 
 	protected String getSQLWhereString(String alias) {
 		return StringHelper.replace( sqlWhereStringTemplate, Template.TEMPLATE, alias );
 	}
 
 	public String getSQLOrderByString(String alias) {
 		return hasOrdering()
 				? StringHelper.replace( sqlOrderByStringTemplate, Template.TEMPLATE, alias )
 				: "";
 	}
 
 	public String getManyToManyOrderByString(String alias) {
 		return hasManyToManyOrdering()
 				? StringHelper.replace( manyToManyOrderByTemplate, Template.TEMPLATE, alias )
 				: "";
 	}
 	public FetchMode getFetchMode() {
 		return fetchMode;
 	}
 
 	public boolean hasOrdering() {
 		return hasOrder;
 	}
 
 	public boolean hasManyToManyOrdering() {
 		return isManyToMany() && hasManyToManyOrder;
 	}
 
 	public boolean hasWhere() {
 		return hasWhere;
 	}
 
 	protected String getSQLDeleteString() {
 		return sqlDeleteString;
 	}
 
 	protected String getSQLInsertRowString() {
 		return sqlInsertRowString;
 	}
 
 	protected String getSQLUpdateRowString() {
 		return sqlUpdateRowString;
 	}
 
 	protected String getSQLDeleteRowString() {
 		return sqlDeleteRowString;
 	}
 
 	public Type getKeyType() {
 		return keyType;
 	}
 
 	public Type getIndexType() {
 		return indexType;
 	}
 
 	public Type getElementType() {
 		return elementType;
 	}
 
 	/**
 	 * Return the element class of an array, or null otherwise
 	 */
 	public Class getElementClass() { //needed by arrays
 		return elementClass;
 	}
 
 	public Object readElement(ResultSet rs, Object owner, String[] aliases, SessionImplementor session)
 	throws HibernateException, SQLException {
 		return getElementType().nullSafeGet( rs, aliases, session, owner );
 	}
 
 	public Object readIndex(ResultSet rs, String[] aliases, SessionImplementor session)
 	throws HibernateException, SQLException {
 		Object index = getIndexType().nullSafeGet( rs, aliases, session, null );
 		if ( index == null ) {
 			throw new HibernateException( "null index column for collection: " + role );
 		}
 		index = decrementIndexByBase( index );
 		return index;
 	}
 
 	protected Object decrementIndexByBase(Object index) {
 		if (baseIndex!=0) {
 			index = new Integer( ( (Integer) index ).intValue() - baseIndex );
 		}
 		return index;
 	}
 
 	public Object readIdentifier(ResultSet rs, String alias, SessionImplementor session)
 	throws HibernateException, SQLException {
 		Object id = getIdentifierType().nullSafeGet( rs, alias, session, null );
 		if ( id == null ) {
 			throw new HibernateException( "null identifier column for collection: " + role );
 		}
 		return id;
 	}
 
 	public Object readKey(ResultSet rs, String[] aliases, SessionImplementor session)
 	throws HibernateException, SQLException {
 		return getKeyType().nullSafeGet( rs, aliases, session, null );
 	}
 
 	/**
 	 * Write the key to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeKey(PreparedStatement st, Serializable key, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 
 		if ( key == null ) {
 			throw new NullPointerException( "null key for collection: " + role );  //an assertion
 		}
 		getKeyType().nullSafeSet( st, key, i, session );
 		return i + keyColumnAliases.length;
 	}
 
 	/**
 	 * Write the element to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeElement(PreparedStatement st, Object elt, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		getElementType().nullSafeSet(st, elt, i, elementColumnIsSettable, session);
 		return i + ArrayHelper.countTrue( elementColumnIsSettable );
 
 	}
 
 	/**
 	 * Write the index to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeIndex(PreparedStatement st, Object index, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		getIndexType().nullSafeSet( st, incrementIndexByBase(index), i, indexColumnIsSettable, session );
 		return i + ArrayHelper.countTrue(indexColumnIsSettable);
 	}
 
 	protected Object incrementIndexByBase(Object index) {
 		if (baseIndex!=0) {
 			index = new Integer( ( (Integer) index ).intValue() + baseIndex );
 		}
 		return index;
 	}
 
 	/**
 	 * Write the element to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeElementToWhere(PreparedStatement st, Object elt, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		if (elementIsPureFormula) {
 			throw new AssertionFailure("cannot use a formula-based element in the where condition");
 		}
 		getElementType().nullSafeSet(st, elt, i, elementColumnIsInPrimaryKey, session);
 		return i + elementColumnAliases.length;
 
 	}
 
 	/**
 	 * Write the index to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeIndexToWhere(PreparedStatement st, Object index, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		if (indexContainsFormula) {
 			throw new AssertionFailure("cannot use a formula-based index in the where condition");
 		}
 		getIndexType().nullSafeSet( st, incrementIndexByBase(index), i, session );
 		return i + indexColumnAliases.length;
 	}
 
 	/**
 	 * Write the identifier to a JDBC <tt>PreparedStatement</tt>
 	 */
 	public int writeIdentifier(PreparedStatement st, Object id, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 
 		getIdentifierType().nullSafeSet( st, id, i, session );
 		return i + 1;
 	}
 
 	public boolean isPrimitiveArray() {
 		return isPrimitiveArray;
 	}
 
 	public boolean isArray() {
 		return isArray;
 	}
 
 	public String[] getKeyColumnAliases(String suffix) {
 		return new Alias( suffix ).toAliasStrings( keyColumnAliases );
 	}
 
 	public String[] getElementColumnAliases(String suffix) {
 		return new Alias( suffix ).toAliasStrings( elementColumnAliases );
 	}
 
 	public String[] getIndexColumnAliases(String suffix) {
 		if ( hasIndex ) {
 			return new Alias( suffix ).toAliasStrings( indexColumnAliases );
 		}
 		else {
 			return null;
 		}
 	}
 
 	public String getIdentifierColumnAlias(String suffix) {
 		if ( hasIdentifier ) {
 			return new Alias( suffix ).toAliasString( identifierColumnAlias );
 		}
 		else {
 			return null;
 		}
 	}
 
 	public String getIdentifierColumnName() {
 		if ( hasIdentifier ) {
 			return identifierColumnName;
 		} else {
 			return null;
 		}
 	}
 
 	/**
 	 * Generate a list of collection index, key and element columns
 	 */
 	public String selectFragment(String alias, String columnSuffix) {
 		SelectFragment frag = generateSelectFragment( alias, columnSuffix );
 		appendElementColumns( frag, alias );
 		appendIndexColumns( frag, alias );
 		appendIdentifierColumns( frag, alias );
 
 		return frag.toFragmentString()
 				.substring( 2 ); //strip leading ','
 	}
 
 	protected String generateSelectSizeString(boolean isIntegerIndexed) {
 		String selectValue = isIntegerIndexed ?
 			"max(" + getIndexColumnNames()[0] + ") + 1": //lists, arrays
 			"count(" + getElementColumnNames()[0] + ")"; //sets, maps, bags
 		return new SimpleSelect(dialect)
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addColumn(selectValue)
 				.toStatementString();
 	}
 
 	protected String generateDetectRowByIndexString() {
 		if ( !hasIndex() ) {
 			return null;
 		}
 		return new SimpleSelect(dialect)
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getIndexColumnNames(), "=?" )
 				.addCondition( indexFormulas, "=?" )
 				.addColumn("1")
 				.toStatementString();
 	}
 
 	protected String generateSelectRowByIndexString() {
 		if ( !hasIndex() ) {
 			return null;
 		}
 		return new SimpleSelect(dialect)
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getIndexColumnNames(), "=?" )
 				.addCondition( indexFormulas, "=?" )
 				.addColumns( getElementColumnNames(), elementColumnAliases )
 				.addColumns( indexFormulas, indexColumnAliases )
 				.toStatementString();
 	}
 
 	protected String generateDetectRowByElementString() {
 		return new SimpleSelect(dialect)
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getElementColumnNames(), "=?" )
 				.addCondition( elementFormulas, "=?" )
 				.addColumn("1")
 				.toStatementString();
 	}
 
 	protected SelectFragment generateSelectFragment(String alias, String columnSuffix) {
 		return new SelectFragment()
 				.setSuffix( columnSuffix )
 				.addColumns( alias, keyColumnNames, keyColumnAliases );
 	}
 
 	protected void appendElementColumns(SelectFragment frag, String elemAlias) {
 		for ( int i=0; i<elementColumnIsSettable.length; i++ ) {
 			if ( elementColumnIsSettable[i] ) {
 				frag.addColumnTemplate( elemAlias, elementColumnReaderTemplates[i], elementColumnAliases[i] );
 			}
 			else {
 				frag.addFormula( elemAlias, elementFormulaTemplates[i], elementColumnAliases[i] );
 			}
 		}
 	}
 
 	protected void appendIndexColumns(SelectFragment frag, String alias) {
 		if ( hasIndex ) {
 			for ( int i=0; i<indexColumnIsSettable.length; i++ ) {
 				if ( indexColumnIsSettable[i] ) {
 					frag.addColumn( alias, indexColumnNames[i], indexColumnAliases[i] );
 				}
 				else {
 					frag.addFormula( alias, indexFormulaTemplates[i], indexColumnAliases[i] );
 				}
 			}
 		}
 	}
 
 	protected void appendIdentifierColumns(SelectFragment frag, String alias) {
 		if ( hasIdentifier ) {
 			frag.addColumn( alias, identifierColumnName, identifierColumnAlias );
 		}
 	}
 
 	public String[] getIndexColumnNames() {
 		return indexColumnNames;
 	}
 
 	public String[] getIndexFormulas() {
 		return indexFormulas;
 	}
 
 	public String[] getIndexColumnNames(String alias) {
 		return qualify(alias, indexColumnNames, indexFormulaTemplates);
 
 	}
 
 	public String[] getElementColumnNames(String alias) {
 		return qualify(alias, elementColumnNames, elementFormulaTemplates);
 	}
 
 	private static String[] qualify(String alias, String[] columnNames, String[] formulaTemplates) {
 		int span = columnNames.length;
 		String[] result = new String[span];
 		for (int i=0; i<span; i++) {
 			if ( columnNames[i]==null ) {
 				result[i] = StringHelper.replace( formulaTemplates[i], Template.TEMPLATE, alias );
 			}
 			else {
 				result[i] = StringHelper.qualify( alias, columnNames[i] );
 			}
 		}
 		return result;
 	}
 
 	public String[] getElementColumnNames() {
 		return elementColumnNames; //TODO: something with formulas...
 	}
 
 	public String[] getKeyColumnNames() {
 		return keyColumnNames;
 	}
 
 	public boolean hasIndex() {
 		return hasIndex;
 	}
 
 	public boolean isLazy() {
 		return isLazy;
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/BasicCollectionPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/BasicCollectionPersister.java
index 2c3f82e5ae..13ba09db05 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/BasicCollectionPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/BasicCollectionPersister.java
@@ -1,356 +1,356 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.collection;
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Iterator;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.LoadQueryInfluencers;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.SubselectFetch;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.loader.collection.BatchingCollectionInitializer;
 import org.hibernate.loader.collection.CollectionInitializer;
 import org.hibernate.loader.collection.SubselectCollectionLoader;
 import org.hibernate.mapping.Collection;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Delete;
 import org.hibernate.sql.Insert;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.Update;
 import org.hibernate.type.AssociationType;
 
 /**
  * Collection persister for collections of values and many-to-many associations.
  *
  * @author Gavin King
  */
 public class BasicCollectionPersister extends AbstractCollectionPersister {
 
 	public boolean isCascadeDeleteEnabled() {
 		return false;
 	}
 
 	public BasicCollectionPersister(
 			Collection collection,
 			CollectionRegionAccessStrategy cacheAccessStrategy,
 			Configuration cfg,
 			SessionFactoryImplementor factory) throws MappingException, CacheException {
 		super( collection, cacheAccessStrategy, cfg, factory );
 	}
 
 	/**
 	 * Generate the SQL DELETE that deletes all rows
 	 */
 	@Override
     protected String generateDeleteString() {
 		
 		Delete delete = new Delete()
 				.setTableName( qualifiedTableName )
 				.addPrimaryKeyColumns( keyColumnNames );
 		
 		if ( hasWhere ) delete.setWhere( sqlWhereString );
 		
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			delete.setComment( "delete collection " + getRole() );
 		}
 		
 		return delete.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL INSERT that creates a new row
 	 */
 	@Override
     protected String generateInsertRowString() {
 		
 		Insert insert = new Insert( getDialect() )
 				.setTableName( qualifiedTableName )
 				.addColumns( keyColumnNames );
 		
 		if ( hasIdentifier) insert.addColumn( identifierColumnName );
 		
 		if ( hasIndex /*&& !indexIsFormula*/ ) {
 			insert.addColumns( indexColumnNames, indexColumnIsSettable );
 		}
 		
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			insert.setComment( "insert collection row " + getRole() );
 		}
 		
 		//if ( !elementIsFormula ) {
 			insert.addColumns( elementColumnNames, elementColumnIsSettable, elementColumnWriters );
 		//}
 		
 		return insert.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that updates a row
 	 */
 	@Override
     protected String generateUpdateRowString() {
 		
 		Update update = new Update( getDialect() )
 			.setTableName( qualifiedTableName );
 		
 		//if ( !elementIsFormula ) {
 			update.addColumns( elementColumnNames, elementColumnIsSettable, elementColumnWriters );
 		//}
 		
 		if ( hasIdentifier ) {
 			update.addPrimaryKeyColumns( new String[]{ identifierColumnName } );
 		}
 		else if ( hasIndex && !indexContainsFormula ) {
 			update.addPrimaryKeyColumns( ArrayHelper.join( keyColumnNames, indexColumnNames ) );
 		}
 		else {
 			update.addPrimaryKeyColumns( keyColumnNames );
 			update.addPrimaryKeyColumns( elementColumnNames, elementColumnIsInPrimaryKey, elementColumnWriters );
 		}
 		
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			update.setComment( "update collection row " + getRole() );
 		}
 		
 		return update.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL DELETE that deletes a particular row
 	 */
 	@Override
     protected String generateDeleteRowString() {
 		
 		Delete delete = new Delete()
 			.setTableName( qualifiedTableName );
 		
 		if ( hasIdentifier ) {
 			delete.addPrimaryKeyColumns( new String[]{ identifierColumnName } );
 		}
 		else if ( hasIndex && !indexContainsFormula ) {
 			delete.addPrimaryKeyColumns( ArrayHelper.join( keyColumnNames, indexColumnNames ) );
 		}
 		else {
 			delete.addPrimaryKeyColumns( keyColumnNames );
 			delete.addPrimaryKeyColumns( elementColumnNames, elementColumnIsInPrimaryKey, elementColumnWriters );
 		}
 		
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			delete.setComment( "delete collection row " + getRole() );
 		}
 		
 		return delete.toStatementString();
 	}
 
 	public boolean consumesEntityAlias() {
 		return false;
 	}
 
 	public boolean consumesCollectionAlias() {
 //		return !isOneToMany();
 		return true;
 	}
 
 	public boolean isOneToMany() {
 		return false;
 	}
 
 	@Override
     public boolean isManyToMany() {
 		return elementType.isEntityType(); //instanceof AssociationType;
 	}
 
 	private BasicBatchKey updateBatchKey;
 
 	@Override
     protected int doUpdateRows(Serializable id, PersistentCollection collection, SessionImplementor session)
 			throws HibernateException {
 		
 		if ( ArrayHelper.isAllFalse(elementColumnIsSettable) ) return 0;
 
 		try {
 			PreparedStatement st = null;
 			Expectation expectation = Expectations.appropriateExpectation( getUpdateCheckStyle() );
 			boolean callable = isUpdateCallable();
 			boolean useBatch = expectation.canBeBatched();
 			Iterator entries = collection.entries( this );
 			String sql = getSQLUpdateRowString();
 			int i = 0;
 			int count = 0;
 			while ( entries.hasNext() ) {
 				Object entry = entries.next();
 				if ( collection.needsUpdating( entry, i, elementType ) ) {
 					int offset = 1;
 
 					if ( useBatch ) {
 						if ( updateBatchKey == null ) {
 							updateBatchKey = new BasicBatchKey(
 									getRole() + "#UPDATE",
 									expectation
 							);
 						}
 						st = session.getTransactionCoordinator()
 								.getJdbcCoordinator()
 								.getBatch( updateBatchKey )
 								.getBatchStatement( sql, callable );
 					}
 					else {
 						st = session.getTransactionCoordinator()
 								.getJdbcCoordinator()
 								.getStatementPreparer()
 								.prepareStatement( sql, callable );
 					}
 
 					try {
 						offset+= expectation.prepare( st );
 						int loc = writeElement( st, collection.getElement( entry ), offset, session );
 						if ( hasIdentifier ) {
 							writeIdentifier( st, collection.getIdentifier( entry, i ), loc, session );
 						}
 						else {
 							loc = writeKey( st, id, loc, session );
 							if ( hasIndex && !indexContainsFormula ) {
 								writeIndexToWhere( st, collection.getIndex( entry, i, this ), loc, session );
 							}
 							else {
 								writeElementToWhere( st, collection.getSnapshotElement( entry, i ), loc, session );
 							}
 						}
 
 						if ( useBatch ) {
 							session.getTransactionCoordinator()
 									.getJdbcCoordinator()
 									.getBatch( updateBatchKey )
 									.addToBatch();
 						}
 						else {
 							expectation.verifyOutcome( st.executeUpdate(), st, -1 );
 						}
 					}
 					catch ( SQLException sqle ) {
 						if ( useBatch ) {
 							session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
 						}
 						throw sqle;
 					}
 					finally {
 						if ( !useBatch ) {
 							st.close();
 						}
 					}
 					count++;
 				}
 				i++;
 			}
 			return count;
 		}
 		catch ( SQLException sqle ) {
 			throw getSQLExceptionHelper().convert(
 					sqle,
 					"could not update collection rows: " + MessageHelper.collectionInfoString( this, id, getFactory() ),
 					getSQLUpdateRowString()
 				);
 		}
 	}
 
 	public String selectFragment(
 	        Joinable rhs,
 	        String rhsAlias,
 	        String lhsAlias,
 	        String entitySuffix,
 	        String collectionSuffix,
 	        boolean includeCollectionColumns) {
 		// we need to determine the best way to know that two joinables
 		// represent a single many-to-many...
 		if ( rhs != null && isManyToMany() && !rhs.isCollection() ) {
 			AssociationType elementType = ( ( AssociationType ) getElementType() );
 			if ( rhs.equals( elementType.getAssociatedJoinable( getFactory() ) ) ) {
 				return manyToManySelectFragment( rhs, rhsAlias, lhsAlias, collectionSuffix );
 			}
 		}
 		return includeCollectionColumns ? selectFragment( lhsAlias, collectionSuffix ) : "";
 	}
 
 	private String manyToManySelectFragment(
 	        Joinable rhs,
 	        String rhsAlias,
 	        String lhsAlias,
 	        String collectionSuffix) {
 		SelectFragment frag = generateSelectFragment( lhsAlias, collectionSuffix );
 
 		String[] elementColumnNames = rhs.getKeyColumnNames();
 		frag.addColumns( rhsAlias, elementColumnNames, elementColumnAliases );
 		appendIndexColumns( frag, lhsAlias );
 		appendIdentifierColumns( frag, lhsAlias );
 
 		return frag.toFragmentString()
 				.substring( 2 ); //strip leading ','
 	}
 
 	/**
 	 * Create the <tt>CollectionLoader</tt>
 	 *
 	 * @see org.hibernate.loader.collection.BasicCollectionLoader
 	 */
 	@Override
     protected CollectionInitializer createCollectionInitializer(LoadQueryInfluencers loadQueryInfluencers)
 			throws MappingException {
 		return BatchingCollectionInitializer.createBatchingCollectionInitializer( this, batchSize, getFactory(), loadQueryInfluencers );
 	}
 
 	public String fromJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		return "";
 	}
 
 	public String whereJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		return "";
 	}
 
 	@Override
     protected CollectionInitializer createSubselectInitializer(SubselectFetch subselect, SessionImplementor session) {
 		return new SubselectCollectionLoader( 
 				this,
 				subselect.toSubselectString( getCollectionType().getLHSPropertyName() ),
 				subselect.getResult(),
 				subselect.getQueryParameters(),
 				subselect.getNamedParameterLocMap(),
 				session.getFactory(),
 				session.getLoadQueryInfluencers() 
 		);
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/CollectionPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/CollectionPersister.java
index a41c22e0ef..0dc1be8611 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/CollectionPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/CollectionPersister.java
@@ -1,309 +1,309 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.collection;
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Map;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
-import org.hibernate.cache.entry.CacheEntryStructure;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
+import org.hibernate.cache.spi.entry.CacheEntryStructure;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.metadata.CollectionMetadata;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.Type;
 
 /**
  * A strategy for persisting a collection role. Defines a contract between
  * the persistence strategy and the actual persistent collection framework
  * and session. Does not define operations that are required for querying
  * collections, or loading by outer join.<br>
  * <br>
  * Implements persistence of a collection instance while the instance is
  * referenced in a particular role.<br>
  * <br>
  * This class is highly coupled to the <tt>PersistentCollection</tt>
  * hierarchy, since double dispatch is used to load and update collection
  * elements.<br>
  * <br>
  * May be considered an immutable view of the mapping object
  *
  * @see QueryableCollection
  * @see PersistentCollection
  * @author Gavin King
  */
 public interface CollectionPersister {
 	/**
 	 * Initialize the given collection with the given key
 	 */
 	public void initialize(Serializable key, SessionImplementor session) //TODO: add owner argument!!
 	throws HibernateException;
 	/**
 	 * Is this collection role cacheable
 	 */
 	public boolean hasCache();
 	/**
 	 * Get the cache
 	 */
 	public CollectionRegionAccessStrategy getCacheAccessStrategy();
 	/**
 	 * Get the cache structure
 	 */
 	public CacheEntryStructure getCacheEntryStructure();
 	/**
 	 * Get the associated <tt>Type</tt>
 	 */
 	public CollectionType getCollectionType();
 	/**
 	 * Get the "key" type (the type of the foreign key)
 	 */
 	public Type getKeyType();
 	/**
 	 * Get the "index" type for a list or map (optional operation)
 	 */
 	public Type getIndexType();
 	/**
 	 * Get the "element" type
 	 */
 	public Type getElementType();
 	/**
 	 * Return the element class of an array, or null otherwise
 	 */
 	public Class getElementClass();
 	/**
 	 * Read the key from a row of the JDBC <tt>ResultSet</tt>
 	 */
 	public Object readKey(ResultSet rs, String[] keyAliases, SessionImplementor session)
 		throws HibernateException, SQLException;
 	/**
 	 * Read the element from a row of the JDBC <tt>ResultSet</tt>
 	 */
 	public Object readElement(
 		ResultSet rs,
 		Object owner,
 		String[] columnAliases,
 		SessionImplementor session)
 		throws HibernateException, SQLException;
 	/**
 	 * Read the index from a row of the JDBC <tt>ResultSet</tt>
 	 */
 	public Object readIndex(ResultSet rs, String[] columnAliases, SessionImplementor session)
 		throws HibernateException, SQLException;
 	/**
 	 * Read the identifier from a row of the JDBC <tt>ResultSet</tt>
 	 */
 	public Object readIdentifier(
 		ResultSet rs,
 		String columnAlias,
 		SessionImplementor session)
 		throws HibernateException, SQLException;
 	/**
 	 * Is this an array or primitive values?
 	 */
 	public boolean isPrimitiveArray();
 	/**
 	 * Is this an array?
 	 */
 	public boolean isArray();
 	/**
 	 * Is this a one-to-many association?
 	 */
 	public boolean isOneToMany();
 	/**
 	 * Is this a many-to-many association?  Note that this is mainly
 	 * a convenience feature as the single persister does not
 	 * conatin all the information needed to handle a many-to-many
 	 * itself, as internally it is looked at as two many-to-ones.
 	 */
 	public boolean isManyToMany();
 
 	public String getManyToManyFilterFragment(String alias, Map enabledFilters);
 
 	/**
 	 * Is this an "indexed" collection? (list or map)
 	 */
 	public boolean hasIndex();
 	/**
 	 * Is this collection lazyily initialized?
 	 */
 	public boolean isLazy();
 	/**
 	 * Is this collection "inverse", so state changes are not
 	 * propogated to the database.
 	 */
 	public boolean isInverse();
 	/**
 	 * Completely remove the persistent state of the collection
 	 */
 	public void remove(Serializable id, SessionImplementor session)
 		throws HibernateException;
 	/**
 	 * (Re)create the collection's persistent state
 	 */
 	public void recreate(
 		PersistentCollection collection,
 		Serializable key,
 		SessionImplementor session)
 		throws HibernateException;
 	/**
 	 * Delete the persistent state of any elements that were removed from
 	 * the collection
 	 */
 	public void deleteRows(
 		PersistentCollection collection,
 		Serializable key,
 		SessionImplementor session)
 		throws HibernateException;
 	/**
 	 * Update the persistent state of any elements that were modified
 	 */
 	public void updateRows(
 		PersistentCollection collection,
 		Serializable key,
 		SessionImplementor session)
 		throws HibernateException;
 	/**
 	 * Insert the persistent state of any new collection elements
 	 */
 	public void insertRows(
 		PersistentCollection collection,
 		Serializable key,
 		SessionImplementor session)
 		throws HibernateException;
 	/**
 	 * Get the name of this collection role (the fully qualified class name,
 	 * extended by a "property path")
 	 */
 	public String getRole();
 	/**
 	 * Get the persister of the entity that "owns" this collection
 	 */
 	public EntityPersister getOwnerEntityPersister();
 	/**
 	 * Get the surrogate key generation strategy (optional operation)
 	 */
 	public IdentifierGenerator getIdentifierGenerator();
 	/**
 	 * Get the type of the surrogate key
 	 */
 	public Type getIdentifierType();
 	/**
 	 * Does this collection implement "orphan delete"?
 	 */
 	public boolean hasOrphanDelete();
 	/**
 	 * Is this an ordered collection? (An ordered collection is
 	 * ordered by the initialization operation, not by sorting
 	 * that happens in memory, as in the case of a sorted collection.)
 	 */
 	public boolean hasOrdering();
 
 	public boolean hasManyToManyOrdering();
 
 	/**
 	 * Get the "space" that holds the persistent state
 	 */
 	public Serializable[] getCollectionSpaces();
 
 	public CollectionMetadata getCollectionMetadata();
 
 	/**
 	 * Is cascade delete handled by the database-level
 	 * foreign key constraint definition?
 	 */
 	public abstract boolean isCascadeDeleteEnabled();
 	
 	/**
 	 * Does this collection cause version increment of the 
 	 * owning entity?
 	 */
 	public boolean isVersioned();
 	
 	/**
 	 * Can the elements of this collection change?
 	 */
 	public boolean isMutable();
 	
 	//public boolean isSubselectLoadable();
 	
 	public String getNodeName();
 	
 	public String getElementNodeName();
 	
 	public String getIndexNodeName();
 
 	public void postInstantiate() throws MappingException;
 	
 	public SessionFactoryImplementor getFactory();
 
 	public boolean isAffectedByEnabledFilters(SessionImplementor session);
 
 	/**
 	 * Generates the collection's key column aliases, based on the given
 	 * suffix.
 	 *
 	 * @param suffix The suffix to use in the key column alias generation.
 	 * @return The key column aliases.
 	 */
 	public String[] getKeyColumnAliases(String suffix);
 
 	/**
 	 * Generates the collection's index column aliases, based on the given
 	 * suffix.
 	 *
 	 * @param suffix The suffix to use in the index column alias generation.
 	 * @return The key column aliases, or null if not indexed.
 	 */
 	public String[] getIndexColumnAliases(String suffix);
 
 	/**
 	 * Generates the collection's element column aliases, based on the given
 	 * suffix.
 	 *
 	 * @param suffix The suffix to use in the element column alias generation.
 	 * @return The key column aliases.
 	 */
 	public String[] getElementColumnAliases(String suffix);
 
 	/**
 	 * Generates the collection's identifier column aliases, based on the given
 	 * suffix.
 	 *
 	 * @param suffix The suffix to use in the key column alias generation.
 	 * @return The key column aliases.
 	 */
 	public String getIdentifierColumnAlias(String suffix);
 	
 	public boolean isExtraLazy();
 	public int getSize(Serializable key, SessionImplementor session);
 	public boolean indexExists(Serializable key, Object index, SessionImplementor session);
 	public boolean elementExists(Serializable key, Object element, SessionImplementor session);
 	public Object getElementByIndex(Serializable key, Object index, SessionImplementor session, Object owner);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/OneToManyPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/OneToManyPersister.java
index 7cca7a51fc..bec0064b41 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/OneToManyPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/OneToManyPersister.java
@@ -1,409 +1,409 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.collection;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Iterator;
 import org.hibernate.MappingException;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.LoadQueryInfluencers;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.SubselectFetch;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.loader.collection.BatchingCollectionInitializer;
 import org.hibernate.loader.collection.CollectionInitializer;
 import org.hibernate.loader.collection.SubselectOneToManyLoader;
 import org.hibernate.loader.entity.CollectionElementLoader;
 import org.hibernate.mapping.Collection;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Update;
 
 /**
  * Collection persister for one-to-many associations.
  *
  * @author Gavin King
  */
 public class OneToManyPersister extends AbstractCollectionPersister {
 
 	private final boolean cascadeDeleteEnabled;
 	private final boolean keyIsNullable;
 	private final boolean keyIsUpdateable;
 
 	@Override
     protected boolean isRowDeleteEnabled() {
 		return keyIsUpdateable && keyIsNullable;
 	}
 
 	@Override
     protected boolean isRowInsertEnabled() {
 		return keyIsUpdateable;
 	}
 
 	public boolean isCascadeDeleteEnabled() {
 		return cascadeDeleteEnabled;
 	}
 
 	public OneToManyPersister(
 			Collection collection,
 			CollectionRegionAccessStrategy cacheAccessStrategy,
 			Configuration cfg,
 			SessionFactoryImplementor factory) throws MappingException, CacheException {
 		super( collection, cacheAccessStrategy, cfg, factory );
 		cascadeDeleteEnabled = collection.getKey().isCascadeDeleteEnabled() &&
 				factory.getDialect().supportsCascadeDelete();
 		keyIsNullable = collection.getKey().isNullable();
 		keyIsUpdateable = collection.getKey().isUpdateable();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that updates all the foreign keys to null
 	 */
 	@Override
     protected String generateDeleteString() {
 		
 		Update update = new Update( getDialect() )
 				.setTableName( qualifiedTableName )
 				.addColumns( keyColumnNames, "null" )
 				.addPrimaryKeyColumns( keyColumnNames );
 		
 		if ( hasIndex && !indexContainsFormula ) update.addColumns( indexColumnNames, "null" );
 		
 		if ( hasWhere ) update.setWhere( sqlWhereString );
 		
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			update.setComment( "delete one-to-many " + getRole() );
 		}
 		
 		return update.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that updates a foreign key to a value
 	 */
 	@Override
     protected String generateInsertRowString() {
 		
 		Update update = new Update( getDialect() )
 				.setTableName( qualifiedTableName )
 				.addColumns( keyColumnNames );
 		
 		if ( hasIndex && !indexContainsFormula ) update.addColumns( indexColumnNames );
 		
 		//identifier collections not supported for 1-to-many
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			update.setComment( "create one-to-many row " + getRole() );
 		}
 		
 		return update.addPrimaryKeyColumns( elementColumnNames, elementColumnWriters )
 				.toStatementString();
 	}
 
 	/**
 	 * Not needed for one-to-many association
 	 */
 	@Override
     protected String generateUpdateRowString() {
 		return null;
 	}
 
 	/**
 	 * Generate the SQL UPDATE that updates a particular row's foreign
 	 * key to null
 	 */
 	@Override
     protected String generateDeleteRowString() {
 		
 		Update update = new Update( getDialect() )
 				.setTableName( qualifiedTableName )
 				.addColumns( keyColumnNames, "null" );
 		
 		if ( hasIndex && !indexContainsFormula ) update.addColumns( indexColumnNames, "null" );
 		
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			update.setComment( "delete one-to-many row " + getRole() );
 		}
 		
 		//use a combination of foreign key columns and pk columns, since
 		//the ordering of removal and addition is not guaranteed when
 		//a child moves from one parent to another
 		String[] rowSelectColumnNames = ArrayHelper.join( keyColumnNames, elementColumnNames );
 		return update.addPrimaryKeyColumns( rowSelectColumnNames )
 				.toStatementString();
 	}
 
 	public boolean consumesEntityAlias() {
 		return true;
 	}
 	public boolean consumesCollectionAlias() {
 		return true;
 	}
 
 	public boolean isOneToMany() {
 		return true;
 	}
 
 	@Override
     public boolean isManyToMany() {
 		return false;
 	}
 
 	private BasicBatchKey deleteRowBatchKey;
 	private BasicBatchKey insertRowBatchKey;
 
 	@Override
     protected int doUpdateRows(Serializable id, PersistentCollection collection, SessionImplementor session) {
 
 		// we finish all the "removes" first to take care of possible unique
 		// constraints and so that we can take better advantage of batching
 		
 		try {
 			int count = 0;
 			if ( isRowDeleteEnabled() ) {
 				final Expectation deleteExpectation = Expectations.appropriateExpectation( getDeleteCheckStyle() );
 				final boolean useBatch = deleteExpectation.canBeBatched();
 				if ( useBatch && deleteRowBatchKey == null ) {
 					deleteRowBatchKey = new BasicBatchKey(
 							getRole() + "#DELETEROW",
 							deleteExpectation
 					);
 				}
 				final String sql = getSQLDeleteRowString();
 
 				PreparedStatement st = null;
 				// update removed rows fks to null
 				try {
 					int i = 0;
 					Iterator entries = collection.entries( this );
 					int offset = 1;
 					while ( entries.hasNext() ) {
 						Object entry = entries.next();
 						if ( collection.needsUpdating( entry, i, elementType ) ) {  // will still be issued when it used to be null
 							if ( useBatch ) {
 								st = session.getTransactionCoordinator()
 										.getJdbcCoordinator()
 										.getBatch( deleteRowBatchKey )
 										.getBatchStatement( sql, isDeleteCallable() );
 							}
 							else {
 								st = session.getTransactionCoordinator()
 										.getJdbcCoordinator()
 										.getStatementPreparer()
 										.prepareStatement( sql, isDeleteCallable() );
 							}
 							int loc = writeKey( st, id, offset, session );
 							writeElementToWhere( st, collection.getSnapshotElement(entry, i), loc, session );
 							if ( useBatch ) {
 								session.getTransactionCoordinator()
 										.getJdbcCoordinator()
 										.getBatch( deleteRowBatchKey )
 										.addToBatch();
 							}
 							else {
 								deleteExpectation.verifyOutcome( st.executeUpdate(), st, -1 );
 							}
 							count++;
 						}
 						i++;
 					}
 				}
 				catch ( SQLException e ) {
 					if ( useBatch ) {
 						session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
 					}
 					throw e;
 				}
 				finally {
 					if ( !useBatch ) {
 						st.close();
 					}
 				}
 			}
 			
 			if ( isRowInsertEnabled() ) {
 				final Expectation insertExpectation = Expectations.appropriateExpectation( getInsertCheckStyle() );
 				boolean useBatch = insertExpectation.canBeBatched();
 				boolean callable = isInsertCallable();
 				if ( useBatch && insertRowBatchKey == null ) {
 					insertRowBatchKey = new BasicBatchKey(
 							getRole() + "#INSERTROW",
 							insertExpectation
 					);
 				}
 				final String sql = getSQLInsertRowString();
 
 				PreparedStatement st = null;
 				// now update all changed or added rows fks
 				try {
 					int i = 0;
 					Iterator entries = collection.entries( this );
 					while ( entries.hasNext() ) {
 						Object entry = entries.next();
 						int offset = 1;
 						if ( collection.needsUpdating( entry, i, elementType ) ) {
 							if ( useBatch ) {
 								st = session.getTransactionCoordinator()
 										.getJdbcCoordinator()
 										.getBatch( insertRowBatchKey )
 										.getBatchStatement( sql, callable );
 							}
 							else {
 								st = session.getTransactionCoordinator()
 										.getJdbcCoordinator()
 										.getStatementPreparer()
 										.prepareStatement( sql, callable );
 							}
 
 							offset += insertExpectation.prepare( st );
 
 							int loc = writeKey( st, id, offset, session );
 							if ( hasIndex && !indexContainsFormula ) {
 								loc = writeIndexToWhere( st, collection.getIndex( entry, i, this ), loc, session );
 							}
 
 							writeElementToWhere( st, collection.getElement( entry ), loc, session );
 
 							if ( useBatch ) {
 								session.getTransactionCoordinator().getJdbcCoordinator().getBatch( insertRowBatchKey ).addToBatch();
 							}
 							else {
 								insertExpectation.verifyOutcome( st.executeUpdate(), st, -1 );
 							}
 							count++;
 						}
 						i++;
 					}
 				}
 				catch ( SQLException sqle ) {
 					if ( useBatch ) {
 						session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
 					}
 					throw sqle;
 				}
 				finally {
 					if ( !useBatch ) {
 						st.close();
 					}
 				}
 			}
 
 			return count;
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not update collection rows: " + 
 					MessageHelper.collectionInfoString( this, id, getFactory() ),
 					getSQLInsertRowString()
 			);
 		}
 	}
 
 	public String selectFragment(
 	        Joinable rhs,
 	        String rhsAlias,
 	        String lhsAlias,
 	        String entitySuffix,
 	        String collectionSuffix,
 	        boolean includeCollectionColumns) {
 		StringBuffer buf = new StringBuffer();
 		if ( includeCollectionColumns ) {
 //			buf.append( selectFragment( lhsAlias, "" ) )//ignore suffix for collection columns!
 			buf.append( selectFragment( lhsAlias, collectionSuffix ) )
 					.append( ", " );
 		}
 		OuterJoinLoadable ojl = ( OuterJoinLoadable ) getElementPersister();
 		return buf.append( ojl.selectFragment( lhsAlias, entitySuffix ) )//use suffix for the entity columns
 				.toString();
 	}
 
 	/**
 	 * Create the <tt>OneToManyLoader</tt>
 	 *
 	 * @see org.hibernate.loader.collection.OneToManyLoader
 	 */
 	@Override
     protected CollectionInitializer createCollectionInitializer(LoadQueryInfluencers loadQueryInfluencers) 
 			throws MappingException {
 		return BatchingCollectionInitializer.createBatchingOneToManyInitializer( this, batchSize, getFactory(), loadQueryInfluencers );
 	}
 
 	public String fromJoinFragment(String alias,
 								   boolean innerJoin,
 								   boolean includeSubclasses) {
 		return ( ( Joinable ) getElementPersister() ).fromJoinFragment( alias, innerJoin, includeSubclasses );
 	}
 
 	public String whereJoinFragment(String alias,
 									boolean innerJoin,
 									boolean includeSubclasses) {
 		return ( ( Joinable ) getElementPersister() ).whereJoinFragment( alias, innerJoin, includeSubclasses );
 	}
 
 	@Override
     public String getTableName() {
 		return ( ( Joinable ) getElementPersister() ).getTableName();
 	}
 
 	@Override
     public String filterFragment(String alias) throws MappingException {
 		String result = super.filterFragment( alias );
 		if ( getElementPersister() instanceof Joinable ) {
 			result += ( ( Joinable ) getElementPersister() ).oneToManyFilterFragment( alias );
 		}
 		return result;
 
 	}
 
 	@Override
     protected CollectionInitializer createSubselectInitializer(SubselectFetch subselect, SessionImplementor session) {
 		return new SubselectOneToManyLoader( 
 				this,
 				subselect.toSubselectString( getCollectionType().getLHSPropertyName() ),
 				subselect.getResult(),
 				subselect.getQueryParameters(),
 				subselect.getNamedParameterLocMap(),
 				session.getFactory(),
 				session.getLoadQueryInfluencers()
 			);
 	}
 
 	@Override
     public Object getElementByIndex(Serializable key, Object index, SessionImplementor session, Object owner) {
 		return new CollectionElementLoader( this, getFactory(), session.getLoadQueryInfluencers() )
 				.loadElement( session, key, incrementIndexByBase(index) );
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
index efd8bc8d80..0e528375d3 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
@@ -1,1060 +1,1060 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.entity;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Comparator;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.EntityMode;
 import org.hibernate.FetchMode;
 import org.hibernate.HibernateException;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.StaleStateException;
 import org.hibernate.bytecode.instrumentation.internal.FieldInterceptionHelper;
 import org.hibernate.bytecode.instrumentation.spi.FieldInterceptor;
 import org.hibernate.bytecode.instrumentation.spi.LazyPropertyInitializer;
-import org.hibernate.cache.CacheKey;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
-import org.hibernate.cache.entry.CacheEntry;
-import org.hibernate.cache.entry.CacheEntryStructure;
-import org.hibernate.cache.entry.StructuredCacheEntry;
-import org.hibernate.cache.entry.UnstructuredCacheEntry;
+import org.hibernate.cache.spi.CacheKey;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.spi.entry.CacheEntry;
+import org.hibernate.cache.spi.entry.CacheEntryStructure;
+import org.hibernate.cache.spi.entry.StructuredCacheEntry;
+import org.hibernate.cache.spi.entry.UnstructuredCacheEntry;
 import org.hibernate.dialect.lock.LockingStrategy;
 import org.hibernate.engine.CascadeStyle;
 import org.hibernate.engine.CascadingAction;
 import org.hibernate.engine.EntityEntry;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.LoadQueryInfluencers;
 import org.hibernate.engine.Mapping;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.ValueInclusion;
 import org.hibernate.engine.Versioning;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.PostInsertIdentifierGenerator;
 import org.hibernate.id.PostInsertIdentityPersister;
 import org.hibernate.id.insert.Binder;
 import org.hibernate.id.insert.InsertGeneratedIdentifierDelegate;
 import org.hibernate.internal.FilterHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.jdbc.TooManyRowsAffectedException;
 import org.hibernate.loader.entity.BatchingEntityLoader;
 import org.hibernate.loader.entity.CascadeEntityLoader;
 import org.hibernate.loader.entity.EntityLoader;
 import org.hibernate.loader.entity.UniqueEntityLoader;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.property.BackrefPropertyAccessor;
 import org.hibernate.sql.Alias;
 import org.hibernate.sql.Delete;
 import org.hibernate.sql.Insert;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.Select;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.SimpleSelect;
 import org.hibernate.sql.Template;
 import org.hibernate.sql.Update;
 import org.hibernate.tuple.Tuplizer;
 import org.hibernate.tuple.entity.EntityMetamodel;
 import org.hibernate.tuple.entity.EntityTuplizer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeHelper;
 import org.hibernate.type.VersionType;
 
 /**
  * Basic functionality for persisting an entity via JDBC
  * through either generated or custom SQL
  *
  * @author Gavin King
  */
 public abstract class AbstractEntityPersister
 		implements OuterJoinLoadable, Queryable, ClassMetadata, UniqueKeyLoadable,
 				   SQLLoadable, LazyPropertyInitializer, PostInsertIdentityPersister, Lockable {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        AbstractEntityPersister.class.getName());
 
 	public static final String ENTITY_CLASS = "class";
 
 	// moved up from AbstractEntityPersister ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	private final SessionFactoryImplementor factory;
 	private final EntityRegionAccessStrategy cacheAccessStrategy;
 	private final boolean isLazyPropertiesCacheable;
 	private final CacheEntryStructure cacheEntryStructure;
 	private final EntityMetamodel entityMetamodel;
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private final String[] rootTableKeyColumnNames;
 	private final String[] rootTableKeyColumnReaders;
 	private final String[] rootTableKeyColumnReaderTemplates;
 	private final String[] identifierAliases;
 	private final int identifierColumnSpan;
 	private final String versionColumnName;
 	private final boolean hasFormulaProperties;
 	private final int batchSize;
 	private final boolean hasSubselectLoadableCollections;
 	protected final String rowIdName;
 
 	private final Set lazyProperties;
 
 	// The optional SQL string defined in the where attribute
 	private final String sqlWhereString;
 	private final String sqlWhereStringTemplate;
 
 	//information about properties of this class,
 	//including inherited properties
 	//(only really needed for updatable/insertable properties)
 	private final int[] propertyColumnSpans;
 	private final String[] propertySubclassNames;
 	private final String[][] propertyColumnAliases;
 	private final String[][] propertyColumnNames;
 	private final String[][] propertyColumnFormulaTemplates;
 	private final String[][] propertyColumnReaderTemplates;
 	private final String[][] propertyColumnWriters;
 	private final boolean[][] propertyColumnUpdateable;
 	private final boolean[][] propertyColumnInsertable;
 	private final boolean[] propertyUniqueness;
 	private final boolean[] propertySelectable;
 
 	//information about lazy properties of this class
 	private final String[] lazyPropertyNames;
 	private final int[] lazyPropertyNumbers;
 	private final Type[] lazyPropertyTypes;
 	private final String[][] lazyPropertyColumnAliases;
 
 	//information about all properties in class hierarchy
 	private final String[] subclassPropertyNameClosure;
 	private final String[] subclassPropertySubclassNameClosure;
 	private final Type[] subclassPropertyTypeClosure;
 	private final String[][] subclassPropertyFormulaTemplateClosure;
 	private final String[][] subclassPropertyColumnNameClosure;
 	private final String[][] subclassPropertyColumnReaderClosure;
 	private final String[][] subclassPropertyColumnReaderTemplateClosure;
 	private final FetchMode[] subclassPropertyFetchModeClosure;
 	private final boolean[] subclassPropertyNullabilityClosure;
 	private final boolean[] propertyDefinedOnSubclass;
 	private final int[][] subclassPropertyColumnNumberClosure;
 	private final int[][] subclassPropertyFormulaNumberClosure;
 	private final CascadeStyle[] subclassPropertyCascadeStyleClosure;
 
 	//information about all columns/formulas in class hierarchy
 	private final String[] subclassColumnClosure;
 	private final boolean[] subclassColumnLazyClosure;
 	private final String[] subclassColumnAliasClosure;
 	private final boolean[] subclassColumnSelectableClosure;
 	private final String[] subclassColumnReaderTemplateClosure;
 	private final String[] subclassFormulaClosure;
 	private final String[] subclassFormulaTemplateClosure;
 	private final String[] subclassFormulaAliasClosure;
 	private final boolean[] subclassFormulaLazyClosure;
 
 	// dynamic filters attached to the class-level
 	private final FilterHelper filterHelper;
 
 	private final Set affectingFetchProfileNames = new HashSet();
 
 	private final Map uniqueKeyLoaders = new HashMap();
 	private final Map lockers = new HashMap();
 	private final Map loaders = new HashMap();
 
 	// SQL strings
 	private String sqlVersionSelectString;
 	private String sqlSnapshotSelectString;
 	private String sqlLazySelectString;
 
 	private String sqlIdentityInsertString;
 	private String sqlUpdateByRowIdString;
 	private String sqlLazyUpdateByRowIdString;
 
 	private String[] sqlDeleteStrings;
 	private String[] sqlInsertStrings;
 	private String[] sqlUpdateStrings;
 	private String[] sqlLazyUpdateStrings;
 
 	private String sqlInsertGeneratedValuesSelectString;
 	private String sqlUpdateGeneratedValuesSelectString;
 
 	//Custom SQL (would be better if these were private)
 	protected boolean[] insertCallable;
 	protected boolean[] updateCallable;
 	protected boolean[] deleteCallable;
 	protected String[] customSQLInsert;
 	protected String[] customSQLUpdate;
 	protected String[] customSQLDelete;
 	protected ExecuteUpdateResultCheckStyle[] insertResultCheckStyles;
 	protected ExecuteUpdateResultCheckStyle[] updateResultCheckStyles;
 	protected ExecuteUpdateResultCheckStyle[] deleteResultCheckStyles;
 
 	private InsertGeneratedIdentifierDelegate identityDelegate;
 
 	private boolean[] tableHasColumns;
 
 	private final String loaderName;
 
 	private UniqueEntityLoader queryLoader;
 
 	private final String temporaryIdTableName;
 	private final String temporaryIdTableDDL;
 
 	private final Map subclassPropertyAliases = new HashMap();
 	private final Map subclassPropertyColumnNames = new HashMap();
 
 	protected final BasicEntityPropertyMapping propertyMapping;
 
 	protected void addDiscriminatorToInsert(Insert insert) {}
 
 	protected void addDiscriminatorToSelect(SelectFragment select, String name, String suffix) {}
 
 	protected abstract int[] getSubclassColumnTableNumberClosure();
 
 	protected abstract int[] getSubclassFormulaTableNumberClosure();
 
 	public abstract String getSubclassTableName(int j);
 
 	protected abstract String[] getSubclassTableKeyColumns(int j);
 
 	protected abstract boolean isClassOrSuperclassTable(int j);
 
 	protected abstract int getSubclassTableSpan();
 
 	protected abstract int getTableSpan();
 
 	protected abstract boolean isTableCascadeDeleteEnabled(int j);
 
 	protected abstract String getTableName(int j);
 
 	protected abstract String[] getKeyColumns(int j);
 
 	protected abstract boolean isPropertyOfTable(int property, int j);
 
 	protected abstract int[] getPropertyTableNumbersInSelect();
 
 	protected abstract int[] getPropertyTableNumbers();
 
 	protected abstract int getSubclassPropertyTableNumber(int i);
 
 	protected abstract String filterFragment(String alias) throws MappingException;
 
 	private static final String DISCRIMINATOR_ALIAS = "clazz_";
 
 	public String getDiscriminatorColumnName() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	public String getDiscriminatorColumnReaders() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	public String getDiscriminatorColumnReaderTemplate() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	protected String getDiscriminatorAlias() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	protected String getDiscriminatorFormulaTemplate() {
 		return null;
 	}
 
 	protected boolean isInverseTable(int j) {
 		return false;
 	}
 
 	protected boolean isNullableTable(int j) {
 		return false;
 	}
 
 	protected boolean isNullableSubclassTable(int j) {
 		return false;
 	}
 
 	protected boolean isInverseSubclassTable(int j) {
 		return false;
 	}
 
 	public boolean isSubclassEntityName(String entityName) {
 		return entityMetamodel.getSubclassEntityNames().contains(entityName);
 	}
 
 	private boolean[] getTableHasColumns() {
 		return tableHasColumns;
 	}
 
 	public String[] getRootTableKeyColumnNames() {
 		return rootTableKeyColumnNames;
 	}
 
 	protected String[] getSQLUpdateByRowIdStrings() {
 		if ( sqlUpdateByRowIdString == null ) {
 			throw new AssertionFailure( "no update by row id" );
 		}
 		String[] result = new String[getTableSpan() + 1];
 		result[0] = sqlUpdateByRowIdString;
 		System.arraycopy( sqlUpdateStrings, 0, result, 1, getTableSpan() );
 		return result;
 	}
 
 	protected String[] getSQLLazyUpdateByRowIdStrings() {
 		if ( sqlLazyUpdateByRowIdString == null ) {
 			throw new AssertionFailure( "no update by row id" );
 		}
 		String[] result = new String[getTableSpan()];
 		result[0] = sqlLazyUpdateByRowIdString;
 		for ( int i = 1; i < getTableSpan(); i++ ) {
 			result[i] = sqlLazyUpdateStrings[i];
 		}
 		return result;
 	}
 
 	protected String getSQLSnapshotSelectString() {
 		return sqlSnapshotSelectString;
 	}
 
 	protected String getSQLLazySelectString() {
 		return sqlLazySelectString;
 	}
 
 	protected String[] getSQLDeleteStrings() {
 		return sqlDeleteStrings;
 	}
 
 	protected String[] getSQLInsertStrings() {
 		return sqlInsertStrings;
 	}
 
 	protected String[] getSQLUpdateStrings() {
 		return sqlUpdateStrings;
 	}
 
 	protected String[] getSQLLazyUpdateStrings() {
 		return sqlLazyUpdateStrings;
 	}
 
 	/**
 	 * The query that inserts a row, letting the database generate an id
 	 *
 	 * @return The IDENTITY-based insertion query.
 	 */
 	protected String getSQLIdentityInsertString() {
 		return sqlIdentityInsertString;
 	}
 
 	protected String getVersionSelectString() {
 		return sqlVersionSelectString;
 	}
 
 	protected boolean isInsertCallable(int j) {
 		return insertCallable[j];
 	}
 
 	protected boolean isUpdateCallable(int j) {
 		return updateCallable[j];
 	}
 
 	protected boolean isDeleteCallable(int j) {
 		return deleteCallable[j];
 	}
 
 	protected boolean isSubclassPropertyDeferred(String propertyName, String entityName) {
 		return false;
 	}
 
 	protected boolean isSubclassTableSequentialSelect(int j) {
 		return false;
 	}
 
 	public boolean hasSequentialSelect() {
 		return false;
 	}
 
 	/**
 	 * Decide which tables need to be updated.
 	 * <p/>
 	 * The return here is an array of boolean values with each index corresponding
 	 * to a given table in the scope of this persister.
 	 *
 	 * @param dirtyProperties The indices of all the entity properties considered dirty.
 	 * @param hasDirtyCollection Whether any collections owned by the entity which were considered dirty.
 	 *
 	 * @return Array of booleans indicating which table require updating.
 	 */
 	protected boolean[] getTableUpdateNeeded(final int[] dirtyProperties, boolean hasDirtyCollection) {
 
 		if ( dirtyProperties == null ) {
 			return getTableHasColumns(); // for objects that came in via update()
 		}
 		else {
 			boolean[] updateability = getPropertyUpdateability();
 			int[] propertyTableNumbers = getPropertyTableNumbers();
 			boolean[] tableUpdateNeeded = new boolean[ getTableSpan() ];
 			for ( int i = 0; i < dirtyProperties.length; i++ ) {
 				int property = dirtyProperties[i];
 				int table = propertyTableNumbers[property];
 				tableUpdateNeeded[table] = tableUpdateNeeded[table] ||
 						( getPropertyColumnSpan(property) > 0 && updateability[property] );
 			}
 			if ( isVersioned() ) {
 				tableUpdateNeeded[0] = tableUpdateNeeded[0] ||
 					Versioning.isVersionIncrementRequired( dirtyProperties, hasDirtyCollection, getPropertyVersionability() );
 			}
 			return tableUpdateNeeded;
 		}
 	}
 
 	public boolean hasRowId() {
 		return rowIdName != null;
 	}
 
 	protected boolean[][] getPropertyColumnUpdateable() {
 		return propertyColumnUpdateable;
 	}
 
 	protected boolean[][] getPropertyColumnInsertable() {
 		return propertyColumnInsertable;
 	}
 
 	protected boolean[] getPropertySelectable() {
 		return propertySelectable;
 	}
 
 	public AbstractEntityPersister(
 			final PersistentClass persistentClass,
 			final EntityRegionAccessStrategy cacheAccessStrategy,
 			final SessionFactoryImplementor factory) throws HibernateException {
 
 		// moved up from AbstractEntityPersister ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		this.factory = factory;
 		this.cacheAccessStrategy = cacheAccessStrategy;
 		isLazyPropertiesCacheable = persistentClass.isLazyPropertiesCacheable();
 		this.cacheEntryStructure = factory.getSettings().isStructuredCacheEntriesEnabled() ?
 				(CacheEntryStructure) new StructuredCacheEntry(this) :
 				(CacheEntryStructure) new UnstructuredCacheEntry();
 
 		this.entityMetamodel = new EntityMetamodel( persistentClass, factory );
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		int batch = persistentClass.getBatchSize();
 		if ( batch == -1 ) {
 			batch = factory.getSettings().getDefaultBatchFetchSize();
 		}
 		batchSize = batch;
 		hasSubselectLoadableCollections = persistentClass.hasSubselectLoadableCollections();
 
 		propertyMapping = new BasicEntityPropertyMapping( this );
 
 		// IDENTIFIER
 
 		identifierColumnSpan = persistentClass.getIdentifier().getColumnSpan();
 		rootTableKeyColumnNames = new String[identifierColumnSpan];
 		rootTableKeyColumnReaders = new String[identifierColumnSpan];
 		rootTableKeyColumnReaderTemplates = new String[identifierColumnSpan];
 		identifierAliases = new String[identifierColumnSpan];
 
 		rowIdName = persistentClass.getRootTable().getRowId();
 
 		loaderName = persistentClass.getLoaderName();
 
 		Iterator iter = persistentClass.getIdentifier().getColumnIterator();
 		int i = 0;
 		while ( iter.hasNext() ) {
 			Column col = ( Column ) iter.next();
 			rootTableKeyColumnNames[i] = col.getQuotedName( factory.getDialect() );
 			rootTableKeyColumnReaders[i] = col.getReadExpr( factory.getDialect() );
 			rootTableKeyColumnReaderTemplates[i] = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 			identifierAliases[i] = col.getAlias( factory.getDialect(), persistentClass.getRootTable() );
 			i++;
 		}
 
 		// VERSION
 
 		if ( persistentClass.isVersioned() ) {
 			versionColumnName = ( ( Column ) persistentClass.getVersion().getColumnIterator().next() ).getQuotedName( factory.getDialect() );
 		}
 		else {
 			versionColumnName = null;
 		}
 
 		//WHERE STRING
 
 		sqlWhereString = StringHelper.isNotEmpty( persistentClass.getWhere() ) ? "( " + persistentClass.getWhere() + ") " : null;
 		sqlWhereStringTemplate = sqlWhereString == null ?
 				null :
 				Template.renderWhereStringTemplate( sqlWhereString, factory.getDialect(), factory.getSqlFunctionRegistry() );
 
 		// PROPERTIES
 
 		final boolean lazyAvailable = isInstrumented(EntityMode.POJO);
 
 		int hydrateSpan = entityMetamodel.getPropertySpan();
 		propertyColumnSpans = new int[hydrateSpan];
 		propertySubclassNames = new String[hydrateSpan];
 		propertyColumnAliases = new String[hydrateSpan][];
 		propertyColumnNames = new String[hydrateSpan][];
 		propertyColumnFormulaTemplates = new String[hydrateSpan][];
 		propertyColumnReaderTemplates = new String[hydrateSpan][];
 		propertyColumnWriters = new String[hydrateSpan][];
 		propertyUniqueness = new boolean[hydrateSpan];
 		propertySelectable = new boolean[hydrateSpan];
 		propertyColumnUpdateable = new boolean[hydrateSpan][];
 		propertyColumnInsertable = new boolean[hydrateSpan][];
 		HashSet thisClassProperties = new HashSet();
 
 		lazyProperties = new HashSet();
 		ArrayList lazyNames = new ArrayList();
 		ArrayList lazyNumbers = new ArrayList();
 		ArrayList lazyTypes = new ArrayList();
 		ArrayList lazyColAliases = new ArrayList();
 
 		iter = persistentClass.getPropertyClosureIterator();
 		i = 0;
 		boolean foundFormula = false;
 		while ( iter.hasNext() ) {
 			Property prop = ( Property ) iter.next();
 			thisClassProperties.add( prop );
 
 			int span = prop.getColumnSpan();
 			propertyColumnSpans[i] = span;
 			propertySubclassNames[i] = prop.getPersistentClass().getEntityName();
 			String[] colNames = new String[span];
 			String[] colAliases = new String[span];
 			String[] colReaderTemplates = new String[span];
 			String[] colWriters = new String[span];
 			String[] formulaTemplates = new String[span];
 			Iterator colIter = prop.getColumnIterator();
 			int k = 0;
 			while ( colIter.hasNext() ) {
 				Selectable thing = ( Selectable ) colIter.next();
 				colAliases[k] = thing.getAlias( factory.getDialect() , prop.getValue().getTable() );
 				if ( thing.isFormula() ) {
 					foundFormula = true;
 					formulaTemplates[k] = thing.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 				}
 				else {
 					Column col = (Column)thing;
 					colNames[k] = col.getQuotedName( factory.getDialect() );
 					colReaderTemplates[k] = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					colWriters[k] = col.getWriteExpr();
 				}
 				k++;
 			}
 			propertyColumnNames[i] = colNames;
 			propertyColumnFormulaTemplates[i] = formulaTemplates;
 			propertyColumnReaderTemplates[i] = colReaderTemplates;
 			propertyColumnWriters[i] = colWriters;
 			propertyColumnAliases[i] = colAliases;
 
 			if ( lazyAvailable && prop.isLazy() ) {
 				lazyProperties.add( prop.getName() );
 				lazyNames.add( prop.getName() );
 				lazyNumbers.add( new Integer( i ) );
 				lazyTypes.add( prop.getValue().getType() );
 				lazyColAliases.add( colAliases );
 			}
 
 			propertyColumnUpdateable[i] = prop.getValue().getColumnUpdateability();
 			propertyColumnInsertable[i] = prop.getValue().getColumnInsertability();
 
 			propertySelectable[i] = prop.isSelectable();
 
 			propertyUniqueness[i] = prop.getValue().isAlternateUniqueKey();
 
 			i++;
 
 		}
 		hasFormulaProperties = foundFormula;
 		lazyPropertyColumnAliases = ArrayHelper.to2DStringArray( lazyColAliases );
 		lazyPropertyNames = ArrayHelper.toStringArray( lazyNames );
 		lazyPropertyNumbers = ArrayHelper.toIntArray( lazyNumbers );
 		lazyPropertyTypes = ArrayHelper.toTypeArray( lazyTypes );
 
 		// SUBCLASS PROPERTY CLOSURE
 
 		ArrayList columns = new ArrayList();
 		ArrayList columnsLazy = new ArrayList();
 		ArrayList columnReaderTemplates = new ArrayList();
 		ArrayList aliases = new ArrayList();
 		ArrayList formulas = new ArrayList();
 		ArrayList formulaAliases = new ArrayList();
 		ArrayList formulaTemplates = new ArrayList();
 		ArrayList formulasLazy = new ArrayList();
 		ArrayList types = new ArrayList();
 		ArrayList names = new ArrayList();
 		ArrayList classes = new ArrayList();
 		ArrayList templates = new ArrayList();
 		ArrayList propColumns = new ArrayList();
 		ArrayList propColumnReaders = new ArrayList();
 		ArrayList propColumnReaderTemplates = new ArrayList();
 		ArrayList joinedFetchesList = new ArrayList();
 		ArrayList cascades = new ArrayList();
 		ArrayList definedBySubclass = new ArrayList();
 		ArrayList propColumnNumbers = new ArrayList();
 		ArrayList propFormulaNumbers = new ArrayList();
 		ArrayList columnSelectables = new ArrayList();
 		ArrayList propNullables = new ArrayList();
 
 		iter = persistentClass.getSubclassPropertyClosureIterator();
 		while ( iter.hasNext() ) {
 			Property prop = ( Property ) iter.next();
 			names.add( prop.getName() );
 			classes.add( prop.getPersistentClass().getEntityName() );
 			boolean isDefinedBySubclass = !thisClassProperties.contains( prop );
 			definedBySubclass.add( Boolean.valueOf( isDefinedBySubclass ) );
 			propNullables.add( Boolean.valueOf( prop.isOptional() || isDefinedBySubclass ) ); //TODO: is this completely correct?
 			types.add( prop.getType() );
 
 			Iterator colIter = prop.getColumnIterator();
 			String[] cols = new String[prop.getColumnSpan()];
 			String[] readers = new String[prop.getColumnSpan()];
 			String[] readerTemplates = new String[prop.getColumnSpan()];
 			String[] forms = new String[prop.getColumnSpan()];
 			int[] colnos = new int[prop.getColumnSpan()];
 			int[] formnos = new int[prop.getColumnSpan()];
 			int l = 0;
 			Boolean lazy = Boolean.valueOf( prop.isLazy() && lazyAvailable );
 			while ( colIter.hasNext() ) {
 				Selectable thing = ( Selectable ) colIter.next();
 				if ( thing.isFormula() ) {
 					String template = thing.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					formnos[l] = formulaTemplates.size();
 					colnos[l] = -1;
 					formulaTemplates.add( template );
 					forms[l] = template;
 					formulas.add( thing.getText( factory.getDialect() ) );
 					formulaAliases.add( thing.getAlias( factory.getDialect() ) );
 					formulasLazy.add( lazy );
 				}
 				else {
 					Column col = (Column)thing;
 					String colName = col.getQuotedName( factory.getDialect() );
 					colnos[l] = columns.size(); //before add :-)
 					formnos[l] = -1;
 					columns.add( colName );
 					cols[l] = colName;
 					aliases.add( thing.getAlias( factory.getDialect(), prop.getValue().getTable() ) );
 					columnsLazy.add( lazy );
 					columnSelectables.add( Boolean.valueOf( prop.isSelectable() ) );
 
 					readers[l] = col.getReadExpr( factory.getDialect() );
 					String readerTemplate = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					readerTemplates[l] = readerTemplate;
 					columnReaderTemplates.add( readerTemplate );
 				}
 				l++;
 			}
 			propColumns.add( cols );
 			propColumnReaders.add( readers );
 			propColumnReaderTemplates.add( readerTemplates );
 			templates.add( forms );
 			propColumnNumbers.add( colnos );
 			propFormulaNumbers.add( formnos );
 
 			joinedFetchesList.add( prop.getValue().getFetchMode() );
 			cascades.add( prop.getCascadeStyle() );
 		}
 		subclassColumnClosure = ArrayHelper.toStringArray( columns );
 		subclassColumnAliasClosure = ArrayHelper.toStringArray( aliases );
 		subclassColumnLazyClosure = ArrayHelper.toBooleanArray( columnsLazy );
 		subclassColumnSelectableClosure = ArrayHelper.toBooleanArray( columnSelectables );
 		subclassColumnReaderTemplateClosure = ArrayHelper.toStringArray( columnReaderTemplates );
 
 		subclassFormulaClosure = ArrayHelper.toStringArray( formulas );
 		subclassFormulaTemplateClosure = ArrayHelper.toStringArray( formulaTemplates );
 		subclassFormulaAliasClosure = ArrayHelper.toStringArray( formulaAliases );
 		subclassFormulaLazyClosure = ArrayHelper.toBooleanArray( formulasLazy );
 
 		subclassPropertyNameClosure = ArrayHelper.toStringArray( names );
 		subclassPropertySubclassNameClosure = ArrayHelper.toStringArray( classes );
 		subclassPropertyTypeClosure = ArrayHelper.toTypeArray( types );
 		subclassPropertyNullabilityClosure = ArrayHelper.toBooleanArray( propNullables );
 		subclassPropertyFormulaTemplateClosure = ArrayHelper.to2DStringArray( templates );
 		subclassPropertyColumnNameClosure = ArrayHelper.to2DStringArray( propColumns );
 		subclassPropertyColumnReaderClosure = ArrayHelper.to2DStringArray( propColumnReaders );
 		subclassPropertyColumnReaderTemplateClosure = ArrayHelper.to2DStringArray( propColumnReaderTemplates );
 		subclassPropertyColumnNumberClosure = ArrayHelper.to2DIntArray( propColumnNumbers );
 		subclassPropertyFormulaNumberClosure = ArrayHelper.to2DIntArray( propFormulaNumbers );
 
 		subclassPropertyCascadeStyleClosure = new CascadeStyle[cascades.size()];
 		iter = cascades.iterator();
 		int j = 0;
 		while ( iter.hasNext() ) {
 			subclassPropertyCascadeStyleClosure[j++] = ( CascadeStyle ) iter.next();
 		}
 		subclassPropertyFetchModeClosure = new FetchMode[joinedFetchesList.size()];
 		iter = joinedFetchesList.iterator();
 		j = 0;
 		while ( iter.hasNext() ) {
 			subclassPropertyFetchModeClosure[j++] = ( FetchMode ) iter.next();
 		}
 
 		propertyDefinedOnSubclass = new boolean[definedBySubclass.size()];
 		iter = definedBySubclass.iterator();
 		j = 0;
 		while ( iter.hasNext() ) {
 			propertyDefinedOnSubclass[j++] = ( ( Boolean ) iter.next() ).booleanValue();
 		}
 
 		// Handle any filters applied to the class level
 		filterHelper = new FilterHelper( persistentClass.getFilterMap(), factory.getDialect(), factory.getSqlFunctionRegistry() );
 
 		temporaryIdTableName = persistentClass.getTemporaryIdTableName();
 		temporaryIdTableDDL = persistentClass.getTemporaryIdTableDDL();
 	}
 
 	protected String generateLazySelectString() {
 
 		if ( !entityMetamodel.hasLazyProperties() ) {
 			return null;
 		}
 
 		HashSet tableNumbers = new HashSet();
 		ArrayList columnNumbers = new ArrayList();
 		ArrayList formulaNumbers = new ArrayList();
 		for ( int i = 0; i < lazyPropertyNames.length; i++ ) {
 			// all this only really needs to consider properties
 			// of this class, not its subclasses, but since we
 			// are reusing code used for sequential selects, we
 			// use the subclass closure
 			int propertyNumber = getSubclassPropertyIndex( lazyPropertyNames[i] );
 
 			int tableNumber = getSubclassPropertyTableNumber( propertyNumber );
 			tableNumbers.add( new Integer( tableNumber ) );
 
 			int[] colNumbers = subclassPropertyColumnNumberClosure[propertyNumber];
 			for ( int j = 0; j < colNumbers.length; j++ ) {
 				if ( colNumbers[j]!=-1 ) {
 					columnNumbers.add( new Integer( colNumbers[j] ) );
 				}
 			}
 			int[] formNumbers = subclassPropertyFormulaNumberClosure[propertyNumber];
 			for ( int j = 0; j < formNumbers.length; j++ ) {
 				if ( formNumbers[j]!=-1 ) {
 					formulaNumbers.add( new Integer( formNumbers[j] ) );
 				}
 			}
 		}
 
 		if ( columnNumbers.size()==0 && formulaNumbers.size()==0 ) {
 			// only one-to-one is lazy fetched
 			return null;
 		}
 
 		return renderSelect( ArrayHelper.toIntArray( tableNumbers ),
 				ArrayHelper.toIntArray( columnNumbers ),
 				ArrayHelper.toIntArray( formulaNumbers ) );
 
 	}
 
 	public Object initializeLazyProperty(String fieldName, Object entity, SessionImplementor session)
 			throws HibernateException {
 
 		final Serializable id = session.getContextEntityIdentifier( entity );
 
 		final EntityEntry entry = session.getPersistenceContext().getEntry( entity );
 		if ( entry == null ) {
 			throw new HibernateException( "entity is not associated with the session: " + id );
 		}
 
         if ( LOG.isTraceEnabled() ) {
 			LOG.trace(
 					"Initializing lazy properties of: " +
 							MessageHelper.infoString( this, id, getFactory() ) +
 							", field access: " + fieldName
 			);
 		}
 
 		if ( hasCache() ) {
 			CacheKey cacheKey = session.generateCacheKey( id, getIdentifierType(), getEntityName() );
 			Object ce = getCacheAccessStrategy().get( cacheKey, session.getTimestamp() );
 			if (ce!=null) {
 				CacheEntry cacheEntry = (CacheEntry) getCacheEntryStructure().destructure(ce, factory);
 				if ( !cacheEntry.areLazyPropertiesUnfetched() ) {
 					//note early exit here:
 					return initializeLazyPropertiesFromCache( fieldName, entity, session, entry, cacheEntry );
 				}
 			}
 		}
 
 		return initializeLazyPropertiesFromDatastore( fieldName, entity, session, id, entry );
 
 	}
 
 	private Object initializeLazyPropertiesFromDatastore(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final Serializable id,
 			final EntityEntry entry) {
 
         if (!hasLazyProperties()) throw new AssertionFailure("no lazy properties");
 
         LOG.trace("Initializing lazy properties from datastore");
 
 		try {
 
 			Object result = null;
 			PreparedStatement ps = null;
 			try {
 				final String lazySelect = getSQLLazySelectString();
 				ResultSet rs = null;
 				try {
 					if ( lazySelect != null ) {
 						// null sql means that the only lazy properties
 						// are shared PK one-to-one associations which are
 						// handled differently in the Type#nullSafeGet code...
 						ps = session.getTransactionCoordinator()
 								.getJdbcCoordinator()
 								.getStatementPreparer()
 								.prepareStatement( lazySelect );
 						getIdentifierType().nullSafeSet( ps, id, 1, session );
 						rs = ps.executeQuery();
 						rs.next();
 					}
 					final Object[] snapshot = entry.getLoadedState();
 					for ( int j = 0; j < lazyPropertyNames.length; j++ ) {
 						Object propValue = lazyPropertyTypes[j].nullSafeGet( rs, lazyPropertyColumnAliases[j], session, entity );
 						if ( initializeLazyProperty( fieldName, entity, session, snapshot, j, propValue ) ) {
 							result = propValue;
 						}
 					}
 				}
 				finally {
 					if ( rs != null ) {
 						rs.close();
 					}
 				}
 			}
 			finally {
 				if ( ps != null ) {
 					ps.close();
 				}
 			}
 
             LOG.trace("Done initializing lazy properties");
 
 			return result;
 
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not initialize lazy properties: " +
 					MessageHelper.infoString( this, id, getFactory() ),
 					getSQLLazySelectString()
 				);
 		}
 	}
 
 	private Object initializeLazyPropertiesFromCache(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final EntityEntry entry,
 			final CacheEntry cacheEntry
 	) {
 
         LOG.trace("Initializing lazy properties from second-level cache");
 
 		Object result = null;
 		Serializable[] disassembledValues = cacheEntry.getDisassembledState();
 		final Object[] snapshot = entry.getLoadedState();
 		for ( int j = 0; j < lazyPropertyNames.length; j++ ) {
 			final Object propValue = lazyPropertyTypes[j].assemble(
 					disassembledValues[ lazyPropertyNumbers[j] ],
 					session,
 					entity
 				);
 			if ( initializeLazyProperty( fieldName, entity, session, snapshot, j, propValue ) ) {
 				result = propValue;
 			}
 		}
 
         LOG.trace("Done initializing lazy properties");
 
 		return result;
 	}
 
 	private boolean initializeLazyProperty(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final Object[] snapshot,
 			final int j,
 			final Object propValue) {
 		setPropertyValue( entity, lazyPropertyNumbers[j], propValue, session.getEntityMode() );
 		if (snapshot != null) {
 			// object have been loaded with setReadOnly(true); HHH-2236
 			snapshot[ lazyPropertyNumbers[j] ] = lazyPropertyTypes[j].deepCopy( propValue, session.getEntityMode(), factory );
 		}
 		return fieldName.equals( lazyPropertyNames[j] );
 	}
 
 	public boolean isBatchable() {
 		return optimisticLockMode()==Versioning.OPTIMISTIC_LOCK_NONE ||
 			( !isVersioned() && optimisticLockMode()==Versioning.OPTIMISTIC_LOCK_VERSION ) ||
 			getFactory().getSettings().isJdbcBatchVersionedData();
 	}
 
 	public Serializable[] getQuerySpaces() {
 		return getPropertySpaces();
 	}
 
 	protected Set getLazyProperties() {
 		return lazyProperties;
 	}
 
 	public boolean isBatchLoadable() {
 		return batchSize > 1;
 	}
 
 	public String[] getIdentifierColumnNames() {
 		return rootTableKeyColumnNames;
 	}
 
 	public String[] getIdentifierColumnReaders() {
 		return rootTableKeyColumnReaders;
 	}
 
 	public String[] getIdentifierColumnReaderTemplates() {
 		return rootTableKeyColumnReaderTemplates;
 	}
 
 	protected int getIdentifierColumnSpan() {
 		return identifierColumnSpan;
 	}
 
 	protected String[] getIdentifierAliases() {
 		return identifierAliases;
 	}
 
 	public String getVersionColumnName() {
 		return versionColumnName;
 	}
 
 	protected String getVersionedTableName() {
 		return getTableName( 0 );
 	}
 
 	protected boolean[] getSubclassColumnLazyiness() {
 		return subclassColumnLazyClosure;
 	}
 
 	protected boolean[] getSubclassFormulaLazyiness() {
 		return subclassFormulaLazyClosure;
 	}
 
 	/**
 	 * We can't immediately add to the cache if we have formulas
 	 * which must be evaluated, or if we have the possibility of
 	 * two concurrent updates to the same item being merged on
 	 * the database. This can happen if (a) the item is not
 	 * versioned and either (b) we have dynamic update enabled
 	 * or (c) we have multiple tables holding the state of the
 	 * item.
 	 */
 	public boolean isCacheInvalidationRequired() {
 		return hasFormulaProperties() ||
 				( !isVersioned() && ( entityMetamodel.isDynamicUpdate() || getTableSpan() > 1 ) );
 	}
 
 	public boolean isLazyPropertiesCacheable() {
 		return isLazyPropertiesCacheable;
 	}
 
 	public String selectFragment(String alias, String suffix) {
 		return identifierSelectFragment( alias, suffix ) +
 				propertySelectFragment( alias, suffix, false );
 	}
 
 	public String[] getIdentifierAliases(String suffix) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		// was toUnqotedAliasStrings( getIdentiferColumnNames() ) before - now tried
 		// to remove that unqoting and missing aliases..
 		return new Alias( suffix ).toAliasStrings( getIdentifierAliases() );
 	}
 
 	public String[] getPropertyAliases(String suffix, int i) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		return new Alias( suffix ).toUnquotedAliasStrings( propertyColumnAliases[i] );
 	}
 
 	public String getDiscriminatorAlias(String suffix) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		// was toUnqotedAliasStrings( getdiscriminatorColumnName() ) before - now tried
 		// to remove that unqoting and missing aliases..
 		return entityMetamodel.hasSubclasses() ?
 				new Alias( suffix ).toAliasString( getDiscriminatorAlias() ) :
 				null;
 	}
 
 	public String identifierSelectFragment(String name, String suffix) {
 		return new SelectFragment()
 				.setSuffix( suffix )
 				.addColumns( name, getIdentifierColumnNames(), getIdentifierAliases() )
 				.toFragmentString()
 				.substring( 2 ); //strip leading ", "
 	}
 
 
 	public String propertySelectFragment(String tableAlias, String suffix, boolean allProperties) {
 		return propertySelectFragmentFragment( tableAlias, suffix, allProperties ).toFragmentString();
 	}
 
 	public SelectFragment propertySelectFragmentFragment(
 			String tableAlias,
 			String suffix,
 			boolean allProperties) {
 		SelectFragment select = new SelectFragment()
 				.setSuffix( suffix )
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/EntityPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/EntityPersister.java
index 7216062c19..24f4c8a3f7 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/EntityPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/EntityPersister.java
@@ -1,764 +1,764 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.entity;
 import java.io.Serializable;
 import java.util.Map;
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
-import org.hibernate.cache.OptimisticCacheSource;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
-import org.hibernate.cache.entry.CacheEntryStructure;
+import org.hibernate.cache.spi.OptimisticCacheSource;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.spi.entry.CacheEntryStructure;
 import org.hibernate.engine.CascadeStyle;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.ValueInclusion;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.tuple.entity.EntityMetamodel;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 
 /**
  * Implementors define mapping and persistence logic for a particular
  * strategy of entity mapping.  An instance of entity persisters corresponds
  * to a given mapped entity.
  * <p/>
  * Implementors must be threadsafe (preferrably immutable) and must provide a constructor
  * matching the signature of: {@link org.hibernate.mapping.PersistentClass}, {@link org.hibernate.engine.SessionFactoryImplementor}
  *
  * @author Gavin King
  */
 public interface EntityPersister extends OptimisticCacheSource {
 
 	/**
 	 * The property name of the "special" identifier property in HQL
 	 */
 	public static final String ENTITY_ID = "id";
 
 	/**
 	 * Finish the initialization of this object.
 	 * <p/>
 	 * Called only once per {@link org.hibernate.SessionFactory} lifecycle,
 	 * after all entity persisters have been instantiated.
 	 *
 	 * @throws org.hibernate.MappingException Indicates an issue in the metadata.
 	 */
 	public void postInstantiate() throws MappingException;
 
 	/**
 	 * Return the SessionFactory to which this persister "belongs".
 	 *
 	 * @return The owning SessionFactory.
 	 */
 	public SessionFactoryImplementor getFactory();
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     // stuff that is persister-centric and/or EntityInfo-centric ~~~~~~~~~~~~~~
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Returns an object that identifies the space in which identifiers of
 	 * this entity hierarchy are unique.  Might be a table name, a JNDI URL, etc.
 	 *
 	 * @return The root entity name.
 	 */
 	public String getRootEntityName();
 
 	/**
 	 * The entity name which this persister maps.
 	 *
 	 * @return The name of the entity which this persister maps.
 	 */
 	public String getEntityName();
 
 	/**
 	 * Retrieve the underlying entity metamodel instance...
 	 *
 	 *@return The metamodel
 	 */
 	public EntityMetamodel getEntityMetamodel();
 
 	/**
 	 * Determine whether the given name represents a subclass entity
 	 * (or this entity itself) of the entity mapped by this persister.
 	 *
 	 * @param entityName The entity name to be checked.
 	 * @return True if the given entity name represents either the entity
 	 * mapped by this persister or one of its subclass entities; false
 	 * otherwise.
 	 */
 	public boolean isSubclassEntityName(String entityName);
 
 	/**
 	 * Returns an array of objects that identify spaces in which properties of
 	 * this entity are persisted, for instances of this class only.
 	 * <p/>
 	 * For most implementations, this returns the complete set of table names
 	 * to which instances of the mapped entity are persisted (not accounting
 	 * for superclass entity mappings).
 	 *
 	 * @return The property spaces.
 	 */
 	public Serializable[] getPropertySpaces();
 
 	/**
 	 * Returns an array of objects that identify spaces in which properties of
 	 * this entity are persisted, for instances of this class and its subclasses.
 	 * <p/>
 	 * Much like {@link #getPropertySpaces()}, except that here we include subclass
 	 * entity spaces.
 	 *
 	 * @return The query spaces.
 	 */
 	public Serializable[] getQuerySpaces();
 
 	/**
 	 * Determine whether this entity supports dynamic proxies.
 	 *
 	 * @return True if the entity has dynamic proxy support; false otherwise.
 	 */
 	public boolean hasProxy();
 
 	/**
 	 * Determine whether this entity contains references to persistent collections.
 	 *
 	 * @return True if the entity does contain persistent collections; false otherwise.
 	 */
 	public boolean hasCollections();
 
 	/**
 	 * Determine whether any properties of this entity are considered mutable.
 	 *
 	 * @return True if any properties of the entity are mutable; false otherwise (meaning none are).
 	 */
 	public boolean hasMutableProperties();
 
 	/**
 	 * Determine whether this entity contains references to persistent collections
 	 * which are fetchable by subselect?
 	 *
 	 * @return True if the entity contains collections fetchable by subselect; false otherwise.
 	 */
 	public boolean hasSubselectLoadableCollections();
 
 	/**
 	 * Determine whether this entity has any non-none cascading.
 	 *
 	 * @return True if the entity has any properties with a cascade other than NONE;
 	 * false otherwise (aka, no cascading).
 	 */
 	public boolean hasCascades();
 
 	/**
 	 * Determine whether instances of this entity are considered mutable.
 	 *
 	 * @return True if the entity is considered mutable; false otherwise.
 	 */
 	public boolean isMutable();
 
 	/**
 	 * Determine whether the entity is inherited one or more other entities.
 	 * In other words, is this entity a subclass of other entities.
 	 *
 	 * @return True if other entities extend this entity; false otherwise.
 	 */
 	public boolean isInherited();
 
 	/**
 	 * Are identifiers of this entity assigned known before the insert execution?
 	 * Or, are they generated (in the database) by the insert execution.
 	 *
 	 * @return True if identifiers for this entity are generated by the insert
 	 * execution.
 	 */
 	public boolean isIdentifierAssignedByInsert();
 
 	/**
 	 * Get the type of a particular property by name.
 	 *
 	 * @param propertyName The name of the property for which to retrieve
 	 * the type.
 	 * @return The type.
 	 * @throws org.hibernate.MappingException Typically indicates an unknown
 	 * property name.
 	 */
 	public Type getPropertyType(String propertyName) throws MappingException;
 
 	/**
 	 * Compare the two snapshots to determine if they represent dirty state.
 	 *
 	 * @param currentState The current snapshot
 	 * @param previousState The baseline snapshot
 	 * @param owner The entity containing the state
 	 * @param session The originating session
 	 * @return The indices of all dirty properties, or null if no properties
 	 * were dirty.
 	 */
 	public int[] findDirty(Object[] currentState, Object[] previousState, Object owner, SessionImplementor session);
 
 	/**
 	 * Compare the two snapshots to determine if they represent modified state.
 	 *
 	 * @param old The baseline snapshot
 	 * @param current The current snapshot
 	 * @param object The entity containing the state
 	 * @param session The originating session
 	 * @return The indices of all modified properties, or null if no properties
 	 * were modified.
 	 */
 	public int[] findModified(Object[] old, Object[] current, Object object, SessionImplementor session);
 
 	/**
 	 * Determine whether the entity has a particular property holding
 	 * the identifier value.
 	 *
 	 * @return True if the entity has a specific property holding identifier value.
 	 */
 	public boolean hasIdentifierProperty();
 
 	/**
 	 * Determine whether detached instances of this entity carry their own
 	 * identifier value.
 	 * <p/>
 	 * The other option is the deprecated feature where users could supply
 	 * the id during session calls.
 	 *
 	 * @return True if either (1) {@link #hasIdentifierProperty()} or
 	 * (2) the identifier is an embedded composite identifier; false otherwise.
 	 */
 	public boolean canExtractIdOutOfEntity();
 
 	/**
 	 * Determine whether optimistic locking by column is enabled for this
 	 * entity.
 	 *
 	 * @return True if optimistic locking by column (i.e., <version/> or
 	 * <timestamp/>) is enabled; false otherwise.
 	 */
 	public boolean isVersioned();
 
 	/**
 	 * If {@link #isVersioned()}, then what is the type of the property
 	 * holding the locking value.
 	 *
 	 * @return The type of the version property; or null, if not versioned.
 	 */
 	public VersionType getVersionType();
 
 	/**
 	 * If {@link #isVersioned()}, then what is the index of the property
 	 * holding the locking value.
 	 *
 	 * @return The type of the version property; or -66, if not versioned.
 	 */
 	public int getVersionProperty();
 
 	/**
 	 * Determine whether this entity defines a natural identifier.
 	 *
 	 * @return True if the entity defines a natural id; false otherwise.
 	 */
 	public boolean hasNaturalIdentifier();
 
 	/**
 	 * If the entity defines a natural id ({@link #hasNaturalIdentifier()}), which
 	 * properties make up the natural id.
 	 *
 	 * @return The indices of the properties making of the natural id; or
 	 * null, if no natural id is defined.
 	 */
 	public int[] getNaturalIdentifierProperties();
 
 	/**
 	 * Retrieve the current state of the natural-id properties from the database.
 	 *
 	 * @param id The identifier of the entity for which to retrieve the natural-id values.
 	 * @param session The session from which the request originated.
 	 * @return The natural-id snapshot.
 	 */
 	public Object[] getNaturalIdentifierSnapshot(Serializable id, SessionImplementor session);
 
 	/**
 	 * Determine which identifier generation strategy is used for this entity.
 	 *
 	 * @return The identifier generation strategy.
 	 */
 	public IdentifierGenerator getIdentifierGenerator();
 
 	/**
 	 * Determine whether this entity defines any lazy properties (ala
 	 * bytecode instrumentation).
 	 *
 	 * @return True if the entity has properties mapped as lazy; false otherwise.
 	 */
 	public boolean hasLazyProperties();
 
 	/**
 	 * Load an instance of the persistent class.
 	 */
 	public Object load(Serializable id, Object optionalObject, LockMode lockMode, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Load an instance of the persistent class.
 	 */
 	public Object load(Serializable id, Object optionalObject, LockOptions lockOptions, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Do a version check (optional operation)
 	 */
 	public void lock(Serializable id, Object version, Object object, LockMode lockMode, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Do a version check (optional operation)
 	 */
 	public void lock(Serializable id, Object version, Object object, LockOptions lockOptions, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Persist an instance
 	 */
 	public void insert(Serializable id, Object[] fields, Object object, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Persist an instance, using a natively generated identifier (optional operation)
 	 */
 	public Serializable insert(Object[] fields, Object object, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Delete a persistent instance
 	 */
 	public void delete(Serializable id, Object version, Object object, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Update a persistent instance
 	 */
 	public void update(
 		Serializable id,
 		Object[] fields,
 		int[] dirtyFields,
 		boolean hasDirtyCollection,
 		Object[] oldFields,
 		Object oldVersion,
 		Object object,
 		Object rowId,
 		SessionImplementor session
 	) throws HibernateException;
 
 	/**
 	 * Get the Hibernate types of the class properties
 	 */
 	public Type[] getPropertyTypes();
 
 	/**
 	 * Get the names of the class properties - doesn't have to be the names of the
 	 * actual Java properties (used for XML generation only)
 	 */
 	public String[] getPropertyNames();
 
 	/**
 	 * Get the "insertability" of the properties of this class
 	 * (does the property appear in an SQL INSERT)
 	 */
 	public boolean[] getPropertyInsertability();
 
 	/**
 	 * Which of the properties of this class are database generated values on insert?
 	 */
 	public ValueInclusion[] getPropertyInsertGenerationInclusions();
 
 	/**
 	 * Which of the properties of this class are database generated values on update?
 	 */
 	public ValueInclusion[] getPropertyUpdateGenerationInclusions();
 
 	/**
 	 * Get the "updateability" of the properties of this class
 	 * (does the property appear in an SQL UPDATE)
 	 */
 	public boolean[] getPropertyUpdateability();
 
 	/**
 	 * Get the "checkability" of the properties of this class
 	 * (is the property dirty checked, does the cache need
 	 * to be updated)
 	 */
 	public boolean[] getPropertyCheckability();
 
 	/**
 	 * Get the nullability of the properties of this class
 	 */
 	public boolean[] getPropertyNullability();
 
 	/**
 	 * Get the "versionability" of the properties of this class
 	 * (is the property optimistic-locked)
 	 */
 	public boolean[] getPropertyVersionability();
 	public boolean[] getPropertyLaziness();
 	/**
 	 * Get the cascade styles of the properties (optional operation)
 	 */
 	public CascadeStyle[] getPropertyCascadeStyles();
 
 	/**
 	 * Get the identifier type
 	 */
 	public Type getIdentifierType();
 
 	/**
 	 * Get the name of the identifier property (or return null) - need not return the
 	 * name of an actual Java property
 	 */
 	public String getIdentifierPropertyName();
 
 	/**
 	 * Should we always invalidate the cache instead of
 	 * recaching updated state
 	 */
 	public boolean isCacheInvalidationRequired();
 	/**
 	 * Should lazy properties of this entity be cached?
 	 */
 	public boolean isLazyPropertiesCacheable();
 	/**
 	 * Does this class have a cache.
 	 */
 	public boolean hasCache();
 	/**
 	 * Get the cache (optional operation)
 	 */
 	public EntityRegionAccessStrategy getCacheAccessStrategy();
 	/**
 	 * Get the cache structure
 	 */
 	public CacheEntryStructure getCacheEntryStructure();
 
 	/**
 	 * Get the user-visible metadata for the class (optional operation)
 	 */
 	public ClassMetadata getClassMetadata();
 
 	/**
 	 * Is batch loading enabled?
 	 */
 	public boolean isBatchLoadable();
 
 	/**
 	 * Is select snapshot before update enabled?
 	 */
 	public boolean isSelectBeforeUpdateRequired();
 
 	/**
 	 * Get the current database state of the object, in a "hydrated" form, without
 	 * resolving identifiers
 	 * @return null if there is no row in the database
 	 */
 	public Object[] getDatabaseSnapshot(Serializable id, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Get the current version of the object, or return null if there is no row for
 	 * the given identifier. In the case of unversioned data, return any object
 	 * if the row exists.
 	 */
 	public Object getCurrentVersion(Serializable id, SessionImplementor session)
 	throws HibernateException;
 
 	public Object forceVersionIncrement(Serializable id, Object currentVersion, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Try to discover the entity mode from the entity instance
 	 */
 	public EntityMode guessEntityMode(Object object);
 
 	/**
 	 * Has the class actually been bytecode instrumented?
 	 */
 	public boolean isInstrumented(EntityMode entityMode);
 
 	/**
 	 * Does this entity define any properties as being database generated on insert?
 	 *
 	 * @return True if this entity contains at least one property defined
 	 * as generated (including version property, but not identifier).
 	 */
 	public boolean hasInsertGeneratedProperties();
 
 	/**
 	 * Does this entity define any properties as being database generated on update?
 	 *
 	 * @return True if this entity contains at least one property defined
 	 * as generated (including version property, but not identifier).
 	 */
 	public boolean hasUpdateGeneratedProperties();
 
 	/**
 	 * Does this entity contain a version property that is defined
 	 * to be database generated?
 	 *
 	 * @return true if this entity contains a version property and that
 	 * property has been marked as generated.
 	 */
 	public boolean isVersionPropertyGenerated();
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// stuff that is tuplizer-centric, but is passed a session ~~~~~~~~~~~~~~~~
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Called just after the entities properties have been initialized
 	 */
 	public void afterInitialize(Object entity, boolean lazyPropertiesAreUnfetched, SessionImplementor session);
 
 	/**
 	 * Called just after the entity has been reassociated with the session
 	 */
 	public void afterReassociate(Object entity, SessionImplementor session);
 
 	/**
 	 * Create a new proxy instance
 	 */
 	public Object createProxy(Serializable id, SessionImplementor session)
 	throws HibernateException;
 
 	/**
 	 * Is this a new transient instance?
 	 */
 	public Boolean isTransient(Object object, SessionImplementor session) throws HibernateException;
 
 	/**
 	 * Return the values of the insertable properties of the object (including backrefs)
 	 */
 	public Object[] getPropertyValuesToInsert(Object object, Map mergeMap, SessionImplementor session) throws HibernateException;
 
 	/**
 	 * Perform a select to retrieve the values of any generated properties
 	 * back from the database, injecting these generated values into the
 	 * given entity as well as writing this state to the
 	 * {@link org.hibernate.engine.PersistenceContext}.
 	 * <p/>
 	 * Note, that because we update the PersistenceContext here, callers
 	 * need to take care that they have already written the initial snapshot
 	 * to the PersistenceContext before calling this method.
 	 *
 	 * @param id The entity's id value.
 	 * @param entity The entity for which to get the state.
 	 * @param state
 	 * @param session The session
 	 */
 	public void processInsertGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session);
 	/**
 	 * Perform a select to retrieve the values of any generated properties
 	 * back from the database, injecting these generated values into the
 	 * given entity as well as writing this state to the
 	 * {@link org.hibernate.engine.PersistenceContext}.
 	 * <p/>
 	 * Note, that because we update the PersistenceContext here, callers
 	 * need to take care that they have already written the initial snapshot
 	 * to the PersistenceContext before calling this method.
 	 *
 	 * @param id The entity's id value.
 	 * @param entity The entity for which to get the state.
 	 * @param state
 	 * @param session The session
 	 */
 	public void processUpdateGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session);
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// stuff that is Tuplizer-centric ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * The persistent class, or null
 	 */
 	public Class getMappedClass(EntityMode entityMode);
 
 	/**
 	 * Does the class implement the <tt>Lifecycle</tt> interface.
 	 */
 	public boolean implementsLifecycle(EntityMode entityMode);
 
 	/**
 	 * Get the proxy interface that instances of <em>this</em> concrete class will be
 	 * cast to (optional operation).
 	 */
 	public Class getConcreteProxyClass(EntityMode entityMode);
 
 	/**
 	 * Set the given values to the mapped properties of the given object
 	 */
 	public void setPropertyValues(Object object, Object[] values, EntityMode entityMode) throws HibernateException;
 
 	/**
 	 * Set the value of a particular property
 	 */
 	public void setPropertyValue(Object object, int i, Object value, EntityMode entityMode) throws HibernateException;
 
 	/**
 	 * Return the (loaded) values of the mapped properties of the object (not including backrefs)
 	 */
 	public Object[] getPropertyValues(Object object, EntityMode entityMode) throws HibernateException;
 
 	/**
 	 * Get the value of a particular property
 	 */
 	public Object getPropertyValue(Object object, int i, EntityMode entityMode) throws HibernateException;
 
 	/**
 	 * Get the value of a particular property
 	 */
 	public Object getPropertyValue(Object object, String propertyName, EntityMode entityMode) throws HibernateException;
 
 	/**
 	 * Get the identifier of an instance (throw an exception if no identifier property)
 	 * @deprecated Use {@link #getIdentifier(Object,SessionImplementor)} instead
 	 * @noinspection JavaDoc
 	 */
 	public Serializable getIdentifier(Object object, EntityMode entityMode) throws HibernateException;
 
 	/**
 	 * Get the identifier of an instance (throw an exception if no identifier property)
 	 *
 	 * @param entity The entity for which to get the identifier
 	 * @param session The session from which the request originated
 	 *
 	 * @return The identifier
 	 */
 	public Serializable getIdentifier(Object entity, SessionImplementor session);
 
     /**
      * Inject the identifier value into the given entity.
      * </p>
      * Has no effect if the entity does not define an identifier property
      *
      * @param entity The entity to inject with the identifier value.
      * @param id The value to be injected as the identifier.
 	 * @param entityMode The entity mode
 	 *
 	 * @deprecated Use {@link #setIdentifier(Object, Serializable, SessionImplementor)} instead.
 	 * @noinspection JavaDoc
      */
 	public void setIdentifier(Object entity, Serializable id, EntityMode entityMode) throws HibernateException;
 
     /**
      * Inject the identifier value into the given entity.
      *
      * @param entity The entity to inject with the identifier value.
      * @param id The value to be injected as the identifier.
 	 * @param session The session from which is requests originates
      */
 	public void setIdentifier(Object entity, Serializable id, SessionImplementor session);
 
 	/**
 	 * Get the version number (or timestamp) from the object's version property (or return null if not versioned)
 	 */
 	public Object getVersion(Object object, EntityMode entityMode) throws HibernateException;
 
 	/**
 	 * Create a class instance initialized with the given identifier
 	 *
 	 * @deprecated Use {@link #instantiate(Serializable, SessionImplementor)} instead
 	 * @noinspection JavaDoc
 	 */
 	public Object instantiate(Serializable id, EntityMode entityMode) throws HibernateException;
 
 	/**
 	 * Create a class instance initialized with the given identifier
 	 *
 	 * @param id The identifier value to use (may be null to represent no value)
 	 * @param session The session from which the request originated.
 	 *
 	 * @return The instantiated entity.
 	 */
 	public Object instantiate(Serializable id, SessionImplementor session);
 
 	/**
 	 * Is the given object an instance of this entity?
 	 */
 	public boolean isInstance(Object object, EntityMode entityMode);
 
 	/**
 	 * Does the given instance have any uninitialized lazy properties?
 	 */
 	public boolean hasUninitializedLazyProperties(Object object, EntityMode entityMode);
 
 	/**
 	 * Set the identifier and version of the given instance back to its "unsaved" value.
 	 *
 	 * @param entity The entity instance
 	 * @param currentId The currently assigned identifier value.
 	 * @param currentVersion The currently assigned version value.
 	 * @param entityMode The entity mode represented by the entity instance.
 	 *
 	 * @deprecated Use {@link #resetIdentifier(Object, Serializable, Object, SessionImplementor)} instead
 	 */
 	public void resetIdentifier(Object entity, Serializable currentId, Object currentVersion, EntityMode entityMode);
 
 	/**
 	 * Set the identifier and version of the given instance back to its "unsaved" value.
 	 *
 	 * @param entity The entity instance
 	 * @param currentId The currently assigned identifier value.
 	 * @param currentVersion The currently assigned version value.
 	 * @param session The session from which the request originated.
 	 */
 	public void resetIdentifier(Object entity, Serializable currentId, Object currentVersion, SessionImplementor session);
 
 	/**
 	 * A request has already identified the entity-name of this persister as the mapping for the given instance.
 	 * However, we still need to account for possible subclassing and potentially re-route to the more appropriate
 	 * persister.
 	 * <p/>
 	 * For example, a request names <tt>Animal</tt> as the entity-name which gets resolved to this persister.  But the
 	 * actual instance is really an instance of <tt>Cat</tt> which is a subclass of <tt>Animal</tt>.  So, here the
 	 * <tt>Animal</tt> persister is being asked to return the persister specific to <tt>Cat</tt>.
 	 * <p/>
 	 * It is also possible that the instance is actually an <tt>Animal</tt> instance in the above example in which
 	 * case we would return <tt>this</tt> from this method.
 	 *
 	 * @param instance The entity instance
 	 * @param factory Reference to the SessionFactory
 	 * @param entityMode The entity mode represented by the entity instance.
 	 *
 	 * @return The appropriate persister
 	 *
 	 * @throws HibernateException Indicates that instance was deemed to not be a subclass of the entity mapped by
 	 * this persister.
 	 */
 	public EntityPersister getSubclassEntityPersister(Object instance, SessionFactoryImplementor factory, EntityMode entityMode);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/JoinedSubclassEntityPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/JoinedSubclassEntityPersister.java
index afeb6008b9..a61aada7c6 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/JoinedSubclassEntityPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/JoinedSubclassEntityPersister.java
@@ -1,779 +1,779 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.entity;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.engine.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.Mapping;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.Versioning;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.KeyValue;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.mapping.Subclass;
 import org.hibernate.mapping.Table;
 import org.hibernate.sql.CaseFragment;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.Type;
 
 /**
  * An <tt>EntityPersister</tt> implementing the normalized "table-per-subclass"
  * mapping strategy
  *
  * @author Gavin King
  */
 public class JoinedSubclassEntityPersister extends AbstractEntityPersister {
 
 	// the class hierarchy structure
 	private final int tableSpan;
 	private final String[] tableNames;
 	private final String[] naturalOrderTableNames;
 	private final String[][] tableKeyColumns;
 	private final String[][] tableKeyColumnReaders;
 	private final String[][] tableKeyColumnReaderTemplates;
 	private final String[][] naturalOrderTableKeyColumns;
 	private final String[][] naturalOrderTableKeyColumnReaders;
 	private final String[][] naturalOrderTableKeyColumnReaderTemplates;
 	private final boolean[] naturalOrderCascadeDeleteEnabled;
 
 	private final String[] spaces;
 
 	private final String[] subclassClosure;
 
 	private final String[] subclassTableNameClosure;
 	private final String[][] subclassTableKeyColumnClosure;
 	private final boolean[] isClassOrSuperclassTable;
 
 	// properties of this class, including inherited properties
 	private final int[] naturalOrderPropertyTableNumbers;
 	private final int[] propertyTableNumbers;
 
 	// the closure of all properties in the entire hierarchy including
 	// subclasses and superclasses of this class
 	private final int[] subclassPropertyTableNumberClosure;
 
 	// the closure of all columns used by the entire hierarchy including
 	// subclasses and superclasses of this class
 	private final int[] subclassColumnTableNumberClosure;
 	private final int[] subclassFormulaTableNumberClosure;
 
 	private final boolean[] subclassTableSequentialSelect;
 	private final boolean[] subclassTableIsLazyClosure;
 	
 	// subclass discrimination works by assigning particular
 	// values to certain combinations of null primary key
 	// values in the outer join using an SQL CASE
 	private final Map subclassesByDiscriminatorValue = new HashMap();
 	private final String[] discriminatorValues;
 	private final String[] notNullColumnNames;
 	private final int[] notNullColumnTableNumbers;
 
 	private final String[] constraintOrderedTableNames;
 	private final String[][] constraintOrderedKeyColumnNames;
 
 	private final String discriminatorSQLString;
 
 	//INITIALIZATION:
 
 	public JoinedSubclassEntityPersister(
 			final PersistentClass persistentClass,
 			final EntityRegionAccessStrategy cacheAccessStrategy,
 			final SessionFactoryImplementor factory,
 			final Mapping mapping) throws HibernateException {
 
 		super( persistentClass, cacheAccessStrategy, factory );
 
 		// DISCRIMINATOR
 
 		final Object discriminatorValue;
 		if ( persistentClass.isPolymorphic() ) {
 			try {
 				discriminatorValue = new Integer( persistentClass.getSubclassId() );
 				discriminatorSQLString = discriminatorValue.toString();
 			}
 			catch (Exception e) {
 				throw new MappingException("Could not format discriminator value to SQL string", e );
 			}
 		}
 		else {
 			discriminatorValue = null;
 			discriminatorSQLString = null;
 		}
 
 		if ( optimisticLockMode() > Versioning.OPTIMISTIC_LOCK_VERSION ) {
 			throw new MappingException( "optimistic-lock=all|dirty not supported for joined-subclass mappings [" + getEntityName() + "]" );
 		}
 
 		//MULTITABLES
 
 		final int idColumnSpan = getIdentifierColumnSpan();
 
 		ArrayList tables = new ArrayList();
 		ArrayList keyColumns = new ArrayList();
 		ArrayList keyColumnReaders = new ArrayList();
 		ArrayList keyColumnReaderTemplates = new ArrayList();
 		ArrayList cascadeDeletes = new ArrayList();
 		Iterator titer = persistentClass.getTableClosureIterator();
 		Iterator kiter = persistentClass.getKeyClosureIterator();
 		while ( titer.hasNext() ) {
 			Table tab = (Table) titer.next();
 			KeyValue key = (KeyValue) kiter.next();
 			String tabname = tab.getQualifiedName(
 					factory.getDialect(),
 					factory.getSettings().getDefaultCatalogName(),
 					factory.getSettings().getDefaultSchemaName()
 			);
 			tables.add(tabname);
 			String[] keyCols = new String[idColumnSpan];
 			String[] keyColReaders = new String[idColumnSpan];
 			String[] keyColReaderTemplates = new String[idColumnSpan];
 			Iterator citer = key.getColumnIterator();
 			for ( int k=0; k<idColumnSpan; k++ ) {
 				Column column = (Column) citer.next();
 				keyCols[k] = column.getQuotedName( factory.getDialect() );
 				keyColReaders[k] = column.getReadExpr( factory.getDialect() );
 				keyColReaderTemplates[k] = column.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 			}
 			keyColumns.add(keyCols);
 			keyColumnReaders.add(keyColReaders);
 			keyColumnReaderTemplates.add(keyColReaderTemplates);
 			cascadeDeletes.add( new Boolean( key.isCascadeDeleteEnabled() && factory.getDialect().supportsCascadeDelete() ) );
 		}
 		
 		//Span of the tables directly mapped by this entity and super-classes, if any
 		int coreTableSpan = tables.size();
 		
 		Iterator joinIter = persistentClass.getJoinClosureIterator();
 		while ( joinIter.hasNext() ) {
 			Join join = (Join) joinIter.next();
 			
 			Table tab = join.getTable();
 			 
 			String tabname = tab.getQualifiedName(
 					factory.getDialect(),
 					factory.getSettings().getDefaultCatalogName(),
 					factory.getSettings().getDefaultSchemaName()
 			);
 			tables.add(tabname);
 			
 			KeyValue key = join.getKey();
 			int joinIdColumnSpan = 	key.getColumnSpan();		
 			
 			String[] keyCols = new String[joinIdColumnSpan];
 			String[] keyColReaders = new String[joinIdColumnSpan];
 			String[] keyColReaderTemplates = new String[joinIdColumnSpan];
 						
 			Iterator citer = key.getColumnIterator();
 			
 			for ( int k=0; k<joinIdColumnSpan; k++ ) {
 				Column column = (Column) citer.next();
 				keyCols[k] = column.getQuotedName( factory.getDialect() );
 				keyColReaders[k] = column.getReadExpr( factory.getDialect() );
 				keyColReaderTemplates[k] = column.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 			}
 			keyColumns.add(keyCols);
 			keyColumnReaders.add(keyColReaders);
 			keyColumnReaderTemplates.add(keyColReaderTemplates);
 			cascadeDeletes.add( new Boolean( key.isCascadeDeleteEnabled() && factory.getDialect().supportsCascadeDelete() ) );
 		}
 		
 		naturalOrderTableNames = ArrayHelper.toStringArray( tables );
 		naturalOrderTableKeyColumns = ArrayHelper.to2DStringArray(keyColumns);
 		naturalOrderTableKeyColumnReaders = ArrayHelper.to2DStringArray(keyColumnReaders);
 		naturalOrderTableKeyColumnReaderTemplates = ArrayHelper.to2DStringArray(keyColumnReaderTemplates);
 		naturalOrderCascadeDeleteEnabled = ArrayHelper.toBooleanArray(cascadeDeletes);
 
 		ArrayList subtables = new ArrayList();
 		ArrayList isConcretes = new ArrayList();
 		ArrayList isDeferreds = new ArrayList();
 		ArrayList isLazies = new ArrayList();
 		
 		keyColumns = new ArrayList();
 		titer = persistentClass.getSubclassTableClosureIterator();
 		while ( titer.hasNext() ) {
 			Table tab = (Table) titer.next();
 			isConcretes.add( new Boolean( persistentClass.isClassOrSuperclassTable(tab) ) );
 			isDeferreds.add(Boolean.FALSE);
 			isLazies.add(Boolean.FALSE);
 			String tabname = tab.getQualifiedName(
 					factory.getDialect(),
 					factory.getSettings().getDefaultCatalogName(),
 					factory.getSettings().getDefaultSchemaName()
 			);
 			subtables.add(tabname);
 			String[] key = new String[idColumnSpan];
 			Iterator citer = tab.getPrimaryKey().getColumnIterator();
 			for ( int k=0; k<idColumnSpan; k++ ) {
 				key[k] = ( (Column) citer.next() ).getQuotedName( factory.getDialect() );
 			}
 			keyColumns.add(key);
 		}
 		
 		//Add joins
 		joinIter = persistentClass.getSubclassJoinClosureIterator();
 		while ( joinIter.hasNext() ) {
 			Join join = (Join) joinIter.next();
 			
 			Table tab = join.getTable();
 			 
 			isConcretes.add( new Boolean( persistentClass.isClassOrSuperclassTable(tab) ) );
 			isDeferreds.add( new Boolean( join.isSequentialSelect() ) );
 			isLazies.add(new Boolean(join.isLazy()));
 			
 			String tabname = tab.getQualifiedName(
 					factory.getDialect(),
 					factory.getSettings().getDefaultCatalogName(),
 					factory.getSettings().getDefaultSchemaName()
 			);
 			subtables.add(tabname);
 			String[] key = new String[idColumnSpan];
 			Iterator citer = tab.getPrimaryKey().getColumnIterator();
 			for ( int k=0; k<idColumnSpan; k++ ) {
 				key[k] = ( (Column) citer.next() ).getQuotedName( factory.getDialect() );
 			}
 			keyColumns.add(key);
 						
 		}
 				
 		String [] naturalOrderSubclassTableNameClosure = ArrayHelper.toStringArray(subtables);
 		String[][] naturalOrderSubclassTableKeyColumnClosure = ArrayHelper.to2DStringArray(keyColumns);
 		isClassOrSuperclassTable = ArrayHelper.toBooleanArray(isConcretes);
 		subclassTableSequentialSelect = ArrayHelper.toBooleanArray(isDeferreds);
 		subclassTableIsLazyClosure = ArrayHelper.toBooleanArray(isLazies);
 		
 		constraintOrderedTableNames = new String[naturalOrderSubclassTableNameClosure.length];
 		constraintOrderedKeyColumnNames = new String[naturalOrderSubclassTableNameClosure.length][];
 		int currentPosition = 0;
 		for ( int i = naturalOrderSubclassTableNameClosure.length - 1; i >= 0 ; i--, currentPosition++ ) {
 			constraintOrderedTableNames[currentPosition] = naturalOrderSubclassTableNameClosure[i];
 			constraintOrderedKeyColumnNames[currentPosition] = naturalOrderSubclassTableKeyColumnClosure[i];
 		} 
 
 		/**
 		 * Suppose an entity Client extends Person, mapped to the tables CLIENT and PERSON respectively.
 		 * For the Client entity:
 		 * naturalOrderTableNames -> PERSON, CLIENT; this reflects the sequence in which the tables are 
 		 * added to the meta-data when the annotated entities are processed.
 		 * However, in some instances, for example when generating joins, the CLIENT table needs to be 
 		 * the first table as it will the driving table.
 		 * tableNames -> CLIENT, PERSON
 		 */
 				
 		tableSpan = naturalOrderTableNames.length;
  		tableNames = reverse(naturalOrderTableNames, coreTableSpan);
 		tableKeyColumns = reverse(naturalOrderTableKeyColumns, coreTableSpan);
 		tableKeyColumnReaders = reverse(naturalOrderTableKeyColumnReaders, coreTableSpan);
 		tableKeyColumnReaderTemplates = reverse(naturalOrderTableKeyColumnReaderTemplates, coreTableSpan);
 		subclassTableNameClosure = reverse(naturalOrderSubclassTableNameClosure, coreTableSpan);
 		subclassTableKeyColumnClosure = reverse(naturalOrderSubclassTableKeyColumnClosure, coreTableSpan);
  
 		spaces = ArrayHelper.join(
 				tableNames,
 				ArrayHelper.toStringArray( persistentClass.getSynchronizedTables() )
 		);
 
 		// Custom sql
 		customSQLInsert = new String[tableSpan];
 		customSQLUpdate = new String[tableSpan];
 		customSQLDelete = new String[tableSpan];
 		insertCallable = new boolean[tableSpan];
 		updateCallable = new boolean[tableSpan];
 		deleteCallable = new boolean[tableSpan];
 		insertResultCheckStyles = new ExecuteUpdateResultCheckStyle[tableSpan];
 		updateResultCheckStyles = new ExecuteUpdateResultCheckStyle[tableSpan];
 		deleteResultCheckStyles = new ExecuteUpdateResultCheckStyle[tableSpan];
 
 		PersistentClass pc = persistentClass;
 		int jk = coreTableSpan-1;
 		while (pc!=null) {
 			customSQLInsert[jk] = pc.getCustomSQLInsert();
 			insertCallable[jk] = customSQLInsert[jk] != null && pc.isCustomInsertCallable();
 			insertResultCheckStyles[jk] = pc.getCustomSQLInsertCheckStyle() == null
 			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLInsert[jk], insertCallable[jk] )
 		                                  : pc.getCustomSQLInsertCheckStyle();
 			customSQLUpdate[jk] = pc.getCustomSQLUpdate();
 			updateCallable[jk] = customSQLUpdate[jk] != null && pc.isCustomUpdateCallable();
 			updateResultCheckStyles[jk] = pc.getCustomSQLUpdateCheckStyle() == null
 			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLUpdate[jk], updateCallable[jk] )
 		                                  : pc.getCustomSQLUpdateCheckStyle();
 			customSQLDelete[jk] = pc.getCustomSQLDelete();
 			deleteCallable[jk] = customSQLDelete[jk] != null && pc.isCustomDeleteCallable();
 			deleteResultCheckStyles[jk] = pc.getCustomSQLDeleteCheckStyle() == null
 			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLDelete[jk], deleteCallable[jk] )
 		                                  : pc.getCustomSQLDeleteCheckStyle();
 			jk--;
 			pc = pc.getSuperclass();
 		}
 		
 		if ( jk != -1 ) {
 			throw new AssertionFailure( "Tablespan does not match height of joined-subclass hiearchy." );
 		}
  
 		joinIter = persistentClass.getJoinClosureIterator();
 		int j = coreTableSpan;
 		while ( joinIter.hasNext() ) {
 			Join join = (Join) joinIter.next();
 			
 			customSQLInsert[j] = join.getCustomSQLInsert();
 			insertCallable[j] = customSQLInsert[j] != null && join.isCustomInsertCallable();
 			insertResultCheckStyles[j] = join.getCustomSQLInsertCheckStyle() == null
 			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLInsert[j], insertCallable[j] )
 		                                  : join.getCustomSQLInsertCheckStyle();
 			customSQLUpdate[j] = join.getCustomSQLUpdate();
 			updateCallable[j] = customSQLUpdate[j] != null && join.isCustomUpdateCallable();
 			updateResultCheckStyles[j] = join.getCustomSQLUpdateCheckStyle() == null
 			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLUpdate[j], updateCallable[j] )
 		                                  : join.getCustomSQLUpdateCheckStyle();
 			customSQLDelete[j] = join.getCustomSQLDelete();
 			deleteCallable[j] = customSQLDelete[j] != null && join.isCustomDeleteCallable();
 			deleteResultCheckStyles[j] = join.getCustomSQLDeleteCheckStyle() == null
 			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLDelete[j], deleteCallable[j] )
 		                                  : join.getCustomSQLDeleteCheckStyle();
 			j++;
 		}
 		
 		// PROPERTIES
 		int hydrateSpan = getPropertySpan();
 		naturalOrderPropertyTableNumbers = new int[hydrateSpan];
 		propertyTableNumbers = new int[hydrateSpan];
 		Iterator iter = persistentClass.getPropertyClosureIterator();
 		int i=0;
 		while( iter.hasNext() ) {
 			Property prop = (Property) iter.next();
 			String tabname = prop.getValue().getTable().getQualifiedName(
 				factory.getDialect(),
 				factory.getSettings().getDefaultCatalogName(),
 				factory.getSettings().getDefaultSchemaName()
 			);
 			propertyTableNumbers[i] = getTableId(tabname, tableNames);
 			naturalOrderPropertyTableNumbers[i] = getTableId(tabname, naturalOrderTableNames);
 			i++;
 		}
 
 		// subclass closure properties
 
 		//TODO: code duplication with SingleTableEntityPersister
 
 		ArrayList columnTableNumbers = new ArrayList();
 		ArrayList formulaTableNumbers = new ArrayList();
 		ArrayList propTableNumbers = new ArrayList();
 
 		iter = persistentClass.getSubclassPropertyClosureIterator();
 		while ( iter.hasNext() ) {
 			Property prop = (Property) iter.next();
 			Table tab = prop.getValue().getTable();
 			String tabname = tab.getQualifiedName(
 					factory.getDialect(),
 					factory.getSettings().getDefaultCatalogName(),
 					factory.getSettings().getDefaultSchemaName()
 			);
 			Integer tabnum = new Integer( getTableId(tabname, subclassTableNameClosure) );
   			propTableNumbers.add(tabnum);
 
 			Iterator citer = prop.getColumnIterator();
 			while ( citer.hasNext() ) {
 				Selectable thing = (Selectable) citer.next();
 				if ( thing.isFormula() ) {
 					formulaTableNumbers.add(tabnum);
 				}
 				else {
 					columnTableNumbers.add(tabnum);
 				}
 			}
 
 		}
 
 		subclassColumnTableNumberClosure = ArrayHelper.toIntArray(columnTableNumbers);
 		subclassPropertyTableNumberClosure = ArrayHelper.toIntArray(propTableNumbers);
 		subclassFormulaTableNumberClosure = ArrayHelper.toIntArray(formulaTableNumbers);
 
 		// SUBCLASSES
  
 		int subclassSpan = persistentClass.getSubclassSpan() + 1;
 		subclassClosure = new String[subclassSpan];
 		subclassClosure[subclassSpan-1] = getEntityName();
 		if ( persistentClass.isPolymorphic() ) {
 			subclassesByDiscriminatorValue.put( discriminatorValue, getEntityName() );
 			discriminatorValues = new String[subclassSpan];
 			discriminatorValues[subclassSpan-1] = discriminatorSQLString;
 			notNullColumnTableNumbers = new int[subclassSpan];
 			final int id = getTableId(
 				persistentClass.getTable().getQualifiedName(
 						factory.getDialect(),
 						factory.getSettings().getDefaultCatalogName(),
 						factory.getSettings().getDefaultSchemaName()
 				),
 				subclassTableNameClosure
 			);
 			notNullColumnTableNumbers[subclassSpan-1] = id;
 			notNullColumnNames = new String[subclassSpan];
 			notNullColumnNames[subclassSpan-1] =  subclassTableKeyColumnClosure[id][0]; //( (Column) model.getTable().getPrimaryKey().getColumnIterator().next() ).getName();
 		}
 		else {
 			discriminatorValues = null;
 			notNullColumnTableNumbers = null;
 			notNullColumnNames = null;
 		}
 
 		iter = persistentClass.getSubclassIterator();
 		int k=0;
 		while ( iter.hasNext() ) {
 			Subclass sc = (Subclass) iter.next();
 			subclassClosure[k] = sc.getEntityName();
 			try {
 				if ( persistentClass.isPolymorphic() ) {
 					// we now use subclass ids that are consistent across all
 					// persisters for a class hierarchy, so that the use of
 					// "foo.class = Bar" works in HQL
 					Integer subclassId = new Integer( sc.getSubclassId() );//new Integer(k+1);
 					subclassesByDiscriminatorValue.put( subclassId, sc.getEntityName() );
 					discriminatorValues[k] = subclassId.toString();
 					int id = getTableId(
 						sc.getTable().getQualifiedName(
 								factory.getDialect(),
 								factory.getSettings().getDefaultCatalogName(),
 								factory.getSettings().getDefaultSchemaName()
 						),
 						subclassTableNameClosure
 					);
 					notNullColumnTableNumbers[k] = id;
 					notNullColumnNames[k] = subclassTableKeyColumnClosure[id][0]; //( (Column) sc.getTable().getPrimaryKey().getColumnIterator().next() ).getName();
 				}
 			}
 			catch (Exception e) {
 				throw new MappingException("Error parsing discriminator value", e );
 			}
 			k++;
 		}
 
 		initLockers();
 
 		initSubclassPropertyAliasesMap(persistentClass);
 
 		postConstruct(mapping);
 
 	}
 
 	protected boolean isSubclassTableSequentialSelect(int j) {
 		return subclassTableSequentialSelect[j] && !isClassOrSuperclassTable[j];
 	}
 	
 	
 	/*public void postInstantiate() throws MappingException {
 		super.postInstantiate();
 		//TODO: other lock modes?
 		loader = createEntityLoader(LockMode.NONE, CollectionHelper.EMPTY_MAP);
 	}*/
 
 	public String getSubclassPropertyTableName(int i) {
 		return subclassTableNameClosure[ subclassPropertyTableNumberClosure[i] ];
 	}
 
 	public Type getDiscriminatorType() {
 		return StandardBasicTypes.INTEGER;
 	}
 
 	public String getDiscriminatorSQLValue() {
 		return discriminatorSQLString;
 	}
 
 
 	public String getSubclassForDiscriminatorValue(Object value) {
 		return (String) subclassesByDiscriminatorValue.get(value);
 	}
 
 	public Serializable[] getPropertySpaces() {
 		return spaces; // don't need subclass tables, because they can't appear in conditions
 	}
 
 
 	protected String getTableName(int j) {
 		return naturalOrderTableNames[j];
 	}
 
 	protected String[] getKeyColumns(int j) {
 		return naturalOrderTableKeyColumns[j];
 	}
 
 	protected boolean isTableCascadeDeleteEnabled(int j) {
 		return naturalOrderCascadeDeleteEnabled[j];
 	}
 
 	protected boolean isPropertyOfTable(int property, int j) {
 		return naturalOrderPropertyTableNumbers[property]==j;
 	}
 
 	/**
 	 * Load an instance using either the <tt>forUpdateLoader</tt> or the outer joining <tt>loader</tt>,
 	 * depending upon the value of the <tt>lock</tt> parameter
 	 */
 	/*public Object load(Serializable id,	Object optionalObject, LockMode lockMode, SessionImplementor session)
 	throws HibernateException {
 
 		if ( log.isTraceEnabled() ) log.trace( "Materializing entity: " + MessageHelper.infoString(this, id) );
 
 		final UniqueEntityLoader loader = hasQueryLoader() ?
 				getQueryLoader() :
 				this.loader;
 		try {
 
 			final Object result = loader.load(id, optionalObject, session);
 
 			if (result!=null) lock(id, getVersion(result), result, lockMode, session);
 
 			return result;
 
 		}
 		catch (SQLException sqle) {
 			throw new JDBCException( "could not load by id: " +  MessageHelper.infoString(this, id), sqle );
 		}
 	}*/
 
 	private static final void reverse(Object[] objects, int len) {
 		Object[] temp = new Object[len];
 		for (int i=0; i<len; i++) {
 			temp[i] = objects[len-i-1];
 		}
 		for (int i=0; i<len; i++) {
 			objects[i] = temp[i];
 		}
 	}
 
 	
 	/**
 	 * Reverse the first n elements of the incoming array
 	 * @param objects
 	 * @param n
 	 * @return New array with the first n elements in reversed order 
 	 */
 	private static final String[] reverse(String [] objects, int n) {
 		
 		int size = objects.length;
 		String[] temp = new String[size];
 		
 		for (int i=0; i<n; i++) {
 			temp[i] = objects[n-i-1];
 		}
 		
 		for (int i=n; i < size; i++) {
 			temp[i] =  objects[i];
 		}
 		
 		return temp;
 	}
 		
 	/**
 	 * Reverse the first n elements of the incoming array
 	 * @param objects
 	 * @param n
 	 * @return New array with the first n elements in reversed order 
 	 */
 	private static final String[][] reverse(String[][] objects, int n) {
 		int size = objects.length;
 		String[][] temp = new String[size][];
 		for (int i=0; i<n; i++) {
 			temp[i] = objects[n-i-1];
 		}
 		
 		for (int i=n; i<size; i++) {
 			temp[i] = objects[i];
 		}
 		
 		return temp;
 	}
 	
 	
 	
 	public String fromTableFragment(String alias) {
 		return getTableName() + ' ' + alias;
 	}
 
 	public String getTableName() {
 		return tableNames[0];
 	}
 
 	private static int getTableId(String tableName, String[] tables) {
 		for ( int j=0; j<tables.length; j++ ) {
 			if ( tableName.equals( tables[j] ) ) {
 				return j;
 			}
 		}
 		throw new AssertionFailure("Table " + tableName + " not found");
 	}
 
 	public void addDiscriminatorToSelect(SelectFragment select, String name, String suffix) {
 		if ( hasSubclasses() ) {
 			select.setExtraSelectList( discriminatorFragment(name), getDiscriminatorAlias() );
 		}
 	}
 
 	private CaseFragment discriminatorFragment(String alias) {
 		CaseFragment cases = getFactory().getDialect().createCaseFragment();
 
 		for ( int i=0; i<discriminatorValues.length; i++ ) {
 			cases.addWhenColumnNotNull(
 				generateTableAlias( alias, notNullColumnTableNumbers[i] ),
 				notNullColumnNames[i],
 				discriminatorValues[i]
 			);
 		}
 
 		return cases;
 	}
 
 	public String filterFragment(String alias) {
 		return hasWhere() ?
 			" and " + getSQLWhereString( generateFilterConditionAlias( alias ) ) :
 			"";
 	}
 
 	public String generateFilterConditionAlias(String rootAlias) {
 		return generateTableAlias( rootAlias, tableSpan-1 );
 	}
 
 	public String[] getIdentifierColumnNames() {
 		return tableKeyColumns[0];
 	}
 
 	public String[] getIdentifierColumnReaderTemplates() {
 		return tableKeyColumnReaderTemplates[0];
 	}
 
 	public String[] getIdentifierColumnReaders() {
 		return tableKeyColumnReaders[0];
 	}		
 	
 	public String[] toColumns(String alias, String propertyName) throws QueryException {
 
 		if ( ENTITY_CLASS.equals(propertyName) ) {
 			// This doesn't actually seem to work but it *might*
 			// work on some dbs. Also it doesn't work if there
 			// are multiple columns of results because it
 			// is not accounting for the suffix:
 			// return new String[] { getDiscriminatorColumnName() };
 
 			return new String[] { discriminatorFragment(alias).toFragmentString() };
 		}
 		else {
 			return super.toColumns(alias, propertyName);
 		}
 
 	}
 
 	protected int[] getPropertyTableNumbersInSelect() {
 		return propertyTableNumbers;
 	}
 
 	protected int getSubclassPropertyTableNumber(int i) {
 		return subclassPropertyTableNumberClosure[i];
 	}
 
 	public int getTableSpan() {
 		return tableSpan;
 	}
 
 	public boolean isMultiTable() {
 		return true;
 	}
 
 	protected int[] getSubclassColumnTableNumberClosure() {
 		return subclassColumnTableNumberClosure;
 	}
 
 	protected int[] getSubclassFormulaTableNumberClosure() {
 		return subclassFormulaTableNumberClosure;
 	}
 
 	protected int[] getPropertyTableNumbers() {
 		return naturalOrderPropertyTableNumbers;
 	}
 
 	protected String[] getSubclassTableKeyColumns(int j) {
 		return subclassTableKeyColumnClosure[j];
 	}
 
 	public String getSubclassTableName(int j) {
 		return subclassTableNameClosure[j];
 	}
 
 	public int getSubclassTableSpan() {
 		return subclassTableNameClosure.length;
 	}
 
 	protected boolean isSubclassTableLazy(int j) {
 		return subclassTableIsLazyClosure[j];
 	}
 	
 	
 	protected boolean isClassOrSuperclassTable(int j) {
 		return isClassOrSuperclassTable[j];
 	}
 
 	public String getPropertyTableName(String propertyName) {
 		Integer index = getEntityMetamodel().getPropertyIndexOrNull(propertyName);
 		if ( index == null ) {
 			return null;
 		}
 		return tableNames[ propertyTableNumbers[ index.intValue() ] ];
 	}
 
 	public String[] getConstraintOrderedTableNameClosure() {
 		return constraintOrderedTableNames;
 	}
 
 	public String[][] getContraintOrderedTableKeyColumnClosure() {
 		return constraintOrderedKeyColumnNames;
 	}
 
 	public String getRootTableName() {
 		return naturalOrderTableNames[0];
 	}
 
 	public String getRootTableAlias(String drivingAlias) {
 		return generateTableAlias( drivingAlias, getTableId( getRootTableName(), tableNames ) );
 	}
 
 	public Declarer getSubclassPropertyDeclarer(String propertyPath) {
 		if ( "class".equals( propertyPath ) ) {
 			// special case where we need to force incloude all subclass joins
 			return Declarer.SUBCLASS;
 		}
 		return super.getSubclassPropertyDeclarer( propertyPath );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/SingleTableEntityPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/SingleTableEntityPersister.java
index 59ef273f66..ad23970f83 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/SingleTableEntityPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/SingleTableEntityPersister.java
@@ -1,750 +1,750 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.entity;
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Map;
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.engine.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.Mapping;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.internal.util.MarkerObject;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Formula;
 import org.hibernate.mapping.Join;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.mapping.Subclass;
 import org.hibernate.mapping.Table;
 import org.hibernate.mapping.Value;
 import org.hibernate.sql.InFragment;
 import org.hibernate.sql.Insert;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.DiscriminatorType;
 import org.hibernate.type.Type;
 
 /**
  * The default implementation of the <tt>EntityPersister</tt> interface.
  * Implements the "table-per-class-hierarchy" or "roll-up" mapping strategy
  * for an entity class and its inheritence hierarchy.  This is implemented
  * as a single table holding all classes in the hierarchy with a discrimator
  * column used to determine which concrete class is referenced.
  *
  * @author Gavin King
  */
 public class SingleTableEntityPersister extends AbstractEntityPersister {
 
 	// the class hierarchy structure
 	private final int joinSpan;
 	private final String[] qualifiedTableNames;
 	private final boolean[] isInverseTable;
 	private final boolean[] isNullableTable;
 	private final String[][] keyColumnNames;
 	private final boolean[] cascadeDeleteEnabled;
 	private final boolean hasSequentialSelects;
 	
 	private final String[] spaces;
 
 	private final String[] subclassClosure;
 
 	private final String[] subclassTableNameClosure;
 	private final boolean[] subclassTableIsLazyClosure;
 	private final boolean[] isInverseSubclassTable;
 	private final boolean[] isNullableSubclassTable;
 	private final boolean[] subclassTableSequentialSelect;
 	private final String[][] subclassTableKeyColumnClosure;
 	private final boolean[] isClassOrSuperclassTable;
 
 	// properties of this class, including inherited properties
 	private final int[] propertyTableNumbers;
 
 	// the closure of all columns used by the entire hierarchy including
 	// subclasses and superclasses of this class
 	private final int[] subclassPropertyTableNumberClosure;
 
 	private final int[] subclassColumnTableNumberClosure;
 	private final int[] subclassFormulaTableNumberClosure;
 
 	// discriminator column
 	private final Map subclassesByDiscriminatorValue = new HashMap();
 	private final boolean forceDiscriminator;
 	private final String discriminatorColumnName;
 	private final String discriminatorColumnReaders;
 	private final String discriminatorColumnReaderTemplate;
 	private final String discriminatorFormula;
 	private final String discriminatorFormulaTemplate;
 	private final String discriminatorAlias;
 	private final Type discriminatorType;
 	private final String discriminatorSQLValue;
 	private final boolean discriminatorInsertable;
 
 	private final String[] constraintOrderedTableNames;
 	private final String[][] constraintOrderedKeyColumnNames;
 
 	//private final Map propertyTableNumbersByName = new HashMap();
 	private final Map propertyTableNumbersByNameAndSubclass = new HashMap();
 	
 	private final Map sequentialSelectStringsByEntityName = new HashMap();
 
 	private static final Object NULL_DISCRIMINATOR = new MarkerObject("<null discriminator>");
 	private static final Object NOT_NULL_DISCRIMINATOR = new MarkerObject("<not null discriminator>");
 
 	//INITIALIZATION:
 
 	public SingleTableEntityPersister(
 			final PersistentClass persistentClass, 
 			final EntityRegionAccessStrategy cacheAccessStrategy,
 			final SessionFactoryImplementor factory,
 			final Mapping mapping) throws HibernateException {
 
 		super( persistentClass, cacheAccessStrategy, factory );
 
 		// CLASS + TABLE
 
 		joinSpan = persistentClass.getJoinClosureSpan()+1;
 		qualifiedTableNames = new String[joinSpan];
 		isInverseTable = new boolean[joinSpan];
 		isNullableTable = new boolean[joinSpan];
 		keyColumnNames = new String[joinSpan][];
 		final Table table = persistentClass.getRootTable();
 		qualifiedTableNames[0] = table.getQualifiedName( 
 				factory.getDialect(), 
 				factory.getSettings().getDefaultCatalogName(), 
 				factory.getSettings().getDefaultSchemaName() 
 		);
 		isInverseTable[0] = false;
 		isNullableTable[0] = false;
 		keyColumnNames[0] = getIdentifierColumnNames();
 		cascadeDeleteEnabled = new boolean[joinSpan];
 
 		// Custom sql
 		customSQLInsert = new String[joinSpan];
 		customSQLUpdate = new String[joinSpan];
 		customSQLDelete = new String[joinSpan];
 		insertCallable = new boolean[joinSpan];
 		updateCallable = new boolean[joinSpan];
 		deleteCallable = new boolean[joinSpan];
 		insertResultCheckStyles = new ExecuteUpdateResultCheckStyle[joinSpan];
 		updateResultCheckStyles = new ExecuteUpdateResultCheckStyle[joinSpan];
 		deleteResultCheckStyles = new ExecuteUpdateResultCheckStyle[joinSpan];
 
 		customSQLInsert[0] = persistentClass.getCustomSQLInsert();
 		insertCallable[0] = customSQLInsert[0] != null && persistentClass.isCustomInsertCallable();
 		insertResultCheckStyles[0] = persistentClass.getCustomSQLInsertCheckStyle() == null
 									  ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLInsert[0], insertCallable[0] )
 									  : persistentClass.getCustomSQLInsertCheckStyle();
 		customSQLUpdate[0] = persistentClass.getCustomSQLUpdate();
 		updateCallable[0] = customSQLUpdate[0] != null && persistentClass.isCustomUpdateCallable();
 		updateResultCheckStyles[0] = persistentClass.getCustomSQLUpdateCheckStyle() == null
 									  ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLUpdate[0], updateCallable[0] )
 									  : persistentClass.getCustomSQLUpdateCheckStyle();
 		customSQLDelete[0] = persistentClass.getCustomSQLDelete();
 		deleteCallable[0] = customSQLDelete[0] != null && persistentClass.isCustomDeleteCallable();
 		deleteResultCheckStyles[0] = persistentClass.getCustomSQLDeleteCheckStyle() == null
 									  ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLDelete[0], deleteCallable[0] )
 									  : persistentClass.getCustomSQLDeleteCheckStyle();
 
 		// JOINS
 
 		Iterator joinIter = persistentClass.getJoinClosureIterator();
 		int j = 1;
 		while ( joinIter.hasNext() ) {
 			Join join = (Join) joinIter.next();
 			qualifiedTableNames[j] = join.getTable().getQualifiedName( 
 					factory.getDialect(), 
 					factory.getSettings().getDefaultCatalogName(), 
 					factory.getSettings().getDefaultSchemaName() 
 			);
 			isInverseTable[j] = join.isInverse();
 			isNullableTable[j] = join.isOptional();
 			cascadeDeleteEnabled[j] = join.getKey().isCascadeDeleteEnabled() && 
 				factory.getDialect().supportsCascadeDelete();
 
 			customSQLInsert[j] = join.getCustomSQLInsert();
 			insertCallable[j] = customSQLInsert[j] != null && join.isCustomInsertCallable();
 			insertResultCheckStyles[j] = join.getCustomSQLInsertCheckStyle() == null
 			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLInsert[j], insertCallable[j] )
 		                                  : join.getCustomSQLInsertCheckStyle();
 			customSQLUpdate[j] = join.getCustomSQLUpdate();
 			updateCallable[j] = customSQLUpdate[j] != null && join.isCustomUpdateCallable();
 			updateResultCheckStyles[j] = join.getCustomSQLUpdateCheckStyle() == null
 			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLUpdate[j], updateCallable[j] )
 		                                  : join.getCustomSQLUpdateCheckStyle();
 			customSQLDelete[j] = join.getCustomSQLDelete();
 			deleteCallable[j] = customSQLDelete[j] != null && join.isCustomDeleteCallable();
 			deleteResultCheckStyles[j] = join.getCustomSQLDeleteCheckStyle() == null
 			                              ? ExecuteUpdateResultCheckStyle.determineDefault( customSQLDelete[j], deleteCallable[j] )
 		                                  : join.getCustomSQLDeleteCheckStyle();
 
 			Iterator iter = join.getKey().getColumnIterator();
 			keyColumnNames[j] = new String[ join.getKey().getColumnSpan() ];
 			int i = 0;
 			while ( iter.hasNext() ) {
 				Column col = (Column) iter.next();
 				keyColumnNames[j][i++] = col.getQuotedName( factory.getDialect() );
 			}
 
 			j++;
 		}
 
 		constraintOrderedTableNames = new String[qualifiedTableNames.length];
 		constraintOrderedKeyColumnNames = new String[qualifiedTableNames.length][];
 		for ( int i = qualifiedTableNames.length - 1, position = 0; i >= 0; i--, position++ ) {
 			constraintOrderedTableNames[position] = qualifiedTableNames[i];
 			constraintOrderedKeyColumnNames[position] = keyColumnNames[i];
 		}
 
 		spaces = ArrayHelper.join(
 				qualifiedTableNames, 
 				ArrayHelper.toStringArray( persistentClass.getSynchronizedTables() )
 		);
 		
 		final boolean lazyAvailable = isInstrumented(EntityMode.POJO);
 
 		boolean hasDeferred = false;
 		ArrayList subclassTables = new ArrayList();
 		ArrayList joinKeyColumns = new ArrayList();
 		ArrayList isConcretes = new ArrayList();
 		ArrayList isDeferreds = new ArrayList();
 		ArrayList isInverses = new ArrayList();
 		ArrayList isNullables = new ArrayList();
 		ArrayList isLazies = new ArrayList();
 		subclassTables.add( qualifiedTableNames[0] );
 		joinKeyColumns.add( getIdentifierColumnNames() );
 		isConcretes.add(Boolean.TRUE);
 		isDeferreds.add(Boolean.FALSE);
 		isInverses.add(Boolean.FALSE);
 		isNullables.add(Boolean.FALSE);
 		isLazies.add(Boolean.FALSE);
 		joinIter = persistentClass.getSubclassJoinClosureIterator();
 		while ( joinIter.hasNext() ) {
 			Join join = (Join) joinIter.next();
 			isConcretes.add( new Boolean( persistentClass.isClassOrSuperclassJoin(join) ) );
 			isDeferreds.add( new Boolean( join.isSequentialSelect() ) );
 			isInverses.add( new Boolean( join.isInverse() ) );
 			isNullables.add( new Boolean( join.isOptional() ) );
 			isLazies.add( new Boolean( lazyAvailable && join.isLazy() ) );
 			if ( join.isSequentialSelect() && !persistentClass.isClassOrSuperclassJoin(join) ) hasDeferred = true;
 			subclassTables.add( join.getTable().getQualifiedName( 
 					factory.getDialect(), 
 					factory.getSettings().getDefaultCatalogName(), 
 					factory.getSettings().getDefaultSchemaName() 
 			) );
 			Iterator iter = join.getKey().getColumnIterator();
 			String[] keyCols = new String[ join.getKey().getColumnSpan() ];
 			int i = 0;
 			while ( iter.hasNext() ) {
 				Column col = (Column) iter.next();
 				keyCols[i++] = col.getQuotedName( factory.getDialect() );
 			}
 			joinKeyColumns.add(keyCols);
 		}
 		
 		subclassTableSequentialSelect = ArrayHelper.toBooleanArray(isDeferreds);
 		subclassTableNameClosure = ArrayHelper.toStringArray(subclassTables);
 		subclassTableIsLazyClosure = ArrayHelper.toBooleanArray(isLazies);
 		subclassTableKeyColumnClosure = ArrayHelper.to2DStringArray( joinKeyColumns );
 		isClassOrSuperclassTable = ArrayHelper.toBooleanArray(isConcretes);
 		isInverseSubclassTable = ArrayHelper.toBooleanArray(isInverses);
 		isNullableSubclassTable = ArrayHelper.toBooleanArray(isNullables);
 		hasSequentialSelects = hasDeferred;
 
 		// DISCRIMINATOR
 
 		final Object discriminatorValue;
 		if ( persistentClass.isPolymorphic() ) {
 			Value discrimValue = persistentClass.getDiscriminator();
 			if (discrimValue==null) {
 				throw new MappingException("discriminator mapping required for single table polymorphic persistence");
 			}
 			forceDiscriminator = persistentClass.isForceDiscriminator();
 			Selectable selectable = (Selectable) discrimValue.getColumnIterator().next();
 			if ( discrimValue.hasFormula() ) {
 				Formula formula = (Formula) selectable;
 				discriminatorFormula = formula.getFormula();
 				discriminatorFormulaTemplate = formula.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 				discriminatorColumnName = null;
 				discriminatorColumnReaders = null;
 				discriminatorColumnReaderTemplate = null;
 				discriminatorAlias = "clazz_";
 			}
 			else {
 				Column column = (Column) selectable;
 				discriminatorColumnName = column.getQuotedName( factory.getDialect() );
 				discriminatorColumnReaders = column.getReadExpr( factory.getDialect() );
 				discriminatorColumnReaderTemplate = column.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 				discriminatorAlias = column.getAlias( factory.getDialect(), persistentClass.getRootTable() );
 				discriminatorFormula = null;
 				discriminatorFormulaTemplate = null;
 			}
 			discriminatorType = persistentClass.getDiscriminator().getType();
 			if ( persistentClass.isDiscriminatorValueNull() ) {
 				discriminatorValue = NULL_DISCRIMINATOR;
 				discriminatorSQLValue = InFragment.NULL;
 				discriminatorInsertable = false;
 			}
 			else if ( persistentClass.isDiscriminatorValueNotNull() ) {
 				discriminatorValue = NOT_NULL_DISCRIMINATOR;
 				discriminatorSQLValue = InFragment.NOT_NULL;
 				discriminatorInsertable = false;
 			}
 			else {
 				discriminatorInsertable = persistentClass.isDiscriminatorInsertable() && !discrimValue.hasFormula();
 				try {
 					DiscriminatorType dtype = (DiscriminatorType) discriminatorType;
 					discriminatorValue = dtype.stringToObject( persistentClass.getDiscriminatorValue() );
 					discriminatorSQLValue = dtype.objectToSQLString( discriminatorValue, factory.getDialect() );
 				}
 				catch (ClassCastException cce) {
 					throw new MappingException("Illegal discriminator type: " + discriminatorType.getName() );
 				}
 				catch (Exception e) {
 					throw new MappingException("Could not format discriminator value to SQL string", e);
 				}
 			}
 		}
 		else {
 			forceDiscriminator = false;
 			discriminatorInsertable = false;
 			discriminatorColumnName = null;
 			discriminatorColumnReaders = null;
 			discriminatorColumnReaderTemplate = null;
 			discriminatorAlias = null;
 			discriminatorType = null;
 			discriminatorValue = null;
 			discriminatorSQLValue = null;
 			discriminatorFormula = null;
 			discriminatorFormulaTemplate = null;
 		}
 
 		// PROPERTIES
 
 		propertyTableNumbers = new int[ getPropertySpan() ];
 		Iterator iter = persistentClass.getPropertyClosureIterator();
 		int i=0;
 		while( iter.hasNext() ) {
 			Property prop = (Property) iter.next();
 			propertyTableNumbers[i++] = persistentClass.getJoinNumber(prop);
 
 		}
 
 		//TODO: code duplication with JoinedSubclassEntityPersister
 		
 		ArrayList columnJoinNumbers = new ArrayList();
 		ArrayList formulaJoinedNumbers = new ArrayList();
 		ArrayList propertyJoinNumbers = new ArrayList();
 		
 		iter = persistentClass.getSubclassPropertyClosureIterator();
 		while ( iter.hasNext() ) {
 			Property prop = (Property) iter.next();
 			Integer join = new Integer( persistentClass.getJoinNumber(prop) );
 			propertyJoinNumbers.add(join);
 
 			//propertyTableNumbersByName.put( prop.getName(), join );
 			propertyTableNumbersByNameAndSubclass.put( 
 					prop.getPersistentClass().getEntityName() + '.' + prop.getName(), 
 					join 
 			);
 
 			Iterator citer = prop.getColumnIterator();
 			while ( citer.hasNext() ) {
 				Selectable thing = (Selectable) citer.next();
 				if ( thing.isFormula() ) {
 					formulaJoinedNumbers.add(join);
 				}
 				else {
 					columnJoinNumbers.add(join);
 				}
 			}
 		}
 		subclassColumnTableNumberClosure = ArrayHelper.toIntArray(columnJoinNumbers);
 		subclassFormulaTableNumberClosure = ArrayHelper.toIntArray(formulaJoinedNumbers);
 		subclassPropertyTableNumberClosure = ArrayHelper.toIntArray(propertyJoinNumbers);
 
 		int subclassSpan = persistentClass.getSubclassSpan() + 1;
 		subclassClosure = new String[subclassSpan];
 		subclassClosure[0] = getEntityName();
 		if ( persistentClass.isPolymorphic() ) {
 			subclassesByDiscriminatorValue.put( discriminatorValue, getEntityName() );
 		}
 
 		// SUBCLASSES
 		if ( persistentClass.isPolymorphic() ) {
 			iter = persistentClass.getSubclassIterator();
 			int k=1;
 			while ( iter.hasNext() ) {
 				Subclass sc = (Subclass) iter.next();
 				subclassClosure[k++] = sc.getEntityName();
 				if ( sc.isDiscriminatorValueNull() ) {
 					subclassesByDiscriminatorValue.put( NULL_DISCRIMINATOR, sc.getEntityName() );
 				}
 				else if ( sc.isDiscriminatorValueNotNull() ) {
 					subclassesByDiscriminatorValue.put( NOT_NULL_DISCRIMINATOR, sc.getEntityName() );
 				}
 				else {
 					try {
 						DiscriminatorType dtype = (DiscriminatorType) discriminatorType;
 						subclassesByDiscriminatorValue.put(
 							dtype.stringToObject( sc.getDiscriminatorValue() ),
 							sc.getEntityName()
 						);
 					}
 					catch (ClassCastException cce) {
 						throw new MappingException("Illegal discriminator type: " + discriminatorType.getName() );
 					}
 					catch (Exception e) {
 						throw new MappingException("Error parsing discriminator value", e);
 					}
 				}
 			}
 		}
 
 		initLockers();
 
 		initSubclassPropertyAliasesMap(persistentClass);
 		
 		postConstruct(mapping);
 
 	}
 
 	protected boolean isInverseTable(int j) {
 		return isInverseTable[j];
 	}
 
 	protected boolean isInverseSubclassTable(int j) {
 		return isInverseSubclassTable[j];
 	}
 
 	public String getDiscriminatorColumnName() {
 		return discriminatorColumnName;
 	}
 
 	public String getDiscriminatorColumnReaders() {
 		return discriminatorColumnReaders;
 	}			
 	
 	public String getDiscriminatorColumnReaderTemplate() {
 		return discriminatorColumnReaderTemplate;
 	}	
 	
 	protected String getDiscriminatorAlias() {
 		return discriminatorAlias;
 	}
 
 	protected String getDiscriminatorFormulaTemplate() {
 		return discriminatorFormulaTemplate;
 	}
 
 	public String getTableName() {
 		return qualifiedTableNames[0];
 	}
 
 	public Type getDiscriminatorType() {
 		return discriminatorType;
 	}
 
 	public String getDiscriminatorSQLValue() {
 		return discriminatorSQLValue;
 	}
 
 	public String[] getSubclassClosure() {
 		return subclassClosure;
 	}
 
 	public String getSubclassForDiscriminatorValue(Object value) {
 		if (value==null) {
 			return (String) subclassesByDiscriminatorValue.get(NULL_DISCRIMINATOR);
 		}
 		else {
 			String result = (String) subclassesByDiscriminatorValue.get(value);
 			if (result==null) result = (String) subclassesByDiscriminatorValue.get(NOT_NULL_DISCRIMINATOR);
 			return result;
 		}
 	}
 
 	public Serializable[] getPropertySpaces() {
 		return spaces;
 	}
 
 	//Access cached SQL
 
 	protected boolean isDiscriminatorFormula() {
 		return discriminatorColumnName==null;
 	}
 
 	protected String getDiscriminatorFormula() {
 		return discriminatorFormula;
 	}
 
 	protected String getTableName(int j) {
 		return qualifiedTableNames[j];
 	}
 	
 	protected String[] getKeyColumns(int j) {
 		return keyColumnNames[j];
 	}
 	
 	protected boolean isTableCascadeDeleteEnabled(int j) {
 		return cascadeDeleteEnabled[j];
 	}
 	
 	protected boolean isPropertyOfTable(int property, int j) {
 		return propertyTableNumbers[property]==j;
 	}
 
 	protected boolean isSubclassTableSequentialSelect(int j) {
 		return subclassTableSequentialSelect[j] && !isClassOrSuperclassTable[j];
 	}
 	
 	// Execute the SQL:
 
 	public String fromTableFragment(String name) {
 		return getTableName() + ' ' + name;
 	}
 
 	public String filterFragment(String alias) throws MappingException {
 		String result = discriminatorFilterFragment(alias);
 		if ( hasWhere() ) result += " and " + getSQLWhereString(alias);
 		return result;
 	}
 	
 	public String oneToManyFilterFragment(String alias) throws MappingException {
 		return forceDiscriminator ?
 			discriminatorFilterFragment(alias) :
 			"";
 	}
 
 	private String discriminatorFilterFragment(String alias) throws MappingException {
 		if ( needsDiscriminator() ) {
 			InFragment frag = new InFragment();
 
 			if ( isDiscriminatorFormula() ) {
 				frag.setFormula( alias, getDiscriminatorFormulaTemplate() );
 			}
 			else {
 				frag.setColumn( alias, getDiscriminatorColumnName() );
 			}
 
 			String[] subclasses = getSubclassClosure();
 			for ( int i=0; i<subclasses.length; i++ ) {
 				final Queryable queryable = (Queryable) getFactory().getEntityPersister( subclasses[i] );
 				if ( !queryable.isAbstract() ) frag.addValue( queryable.getDiscriminatorSQLValue() );
 			}
 
 			StringBuffer buf = new StringBuffer(50)
 				.append(" and ")
 				.append( frag.toFragmentString() );
 
 			return buf.toString();
 		}
 		else {
 			return "";
 		}
 	}
 
 	private boolean needsDiscriminator() {
 		return forceDiscriminator || isInherited();
 	}
 
 	public String getSubclassPropertyTableName(int i) {
 		return subclassTableNameClosure[ subclassPropertyTableNumberClosure[i] ];
 	}
 
 	protected void addDiscriminatorToSelect(SelectFragment select, String name, String suffix) {
 		if ( isDiscriminatorFormula() ) {
 			select.addFormula( name, getDiscriminatorFormulaTemplate(), getDiscriminatorAlias() );
 		}
 		else {
 			select.addColumn( name, getDiscriminatorColumnName(),  getDiscriminatorAlias() );
 		}
 	}
 	
 	protected int[] getPropertyTableNumbersInSelect() {
 		return propertyTableNumbers;
 	}
 
 	protected int getSubclassPropertyTableNumber(int i) {
 		return subclassPropertyTableNumberClosure[i];
 	}
 
 	public int getTableSpan() {
 		return joinSpan;
 	}
 
 	protected void addDiscriminatorToInsert(Insert insert) {
 
 		if (discriminatorInsertable) {
 			insert.addColumn( getDiscriminatorColumnName(), discriminatorSQLValue );
 		}
 
 	}
 
 	protected int[] getSubclassColumnTableNumberClosure() {
 		return subclassColumnTableNumberClosure;
 	}
 
 	protected int[] getSubclassFormulaTableNumberClosure() {
 		return subclassFormulaTableNumberClosure;
 	}
 
 	protected int[] getPropertyTableNumbers() {
 		return propertyTableNumbers;
 	}
 		
 	protected boolean isSubclassPropertyDeferred(String propertyName, String entityName) {
 		return hasSequentialSelects && 
 			isSubclassTableSequentialSelect( getSubclassPropertyTableNumber(propertyName, entityName) );
 	}
 	
 	public boolean hasSequentialSelect() {
 		return hasSequentialSelects;
 	}
 	
 	private int getSubclassPropertyTableNumber(String propertyName, String entityName) {
 		Type type = propertyMapping.toType(propertyName);
 		if ( type.isAssociationType() && ( (AssociationType) type ).useLHSPrimaryKey() ) return 0;
 		final Integer tabnum = (Integer) propertyTableNumbersByNameAndSubclass.get(entityName + '.' + propertyName);
 		return tabnum==null ? 0 : tabnum.intValue();
 	}
 	
 	protected String getSequentialSelect(String entityName) {
 		return (String) sequentialSelectStringsByEntityName.get(entityName);
 	}
 
 	private String generateSequentialSelect(Loadable persister) {
 		//if ( this==persister || !hasSequentialSelects ) return null;
 
 		//note that this method could easily be moved up to BasicEntityPersister,
 		//if we ever needed to reuse it from other subclasses
 		
 		//figure out which tables need to be fetched
 		AbstractEntityPersister subclassPersister = (AbstractEntityPersister) persister;
 		HashSet tableNumbers = new HashSet();
 		String[] props = subclassPersister.getPropertyNames();
 		String[] classes = subclassPersister.getPropertySubclassNames();
 		for ( int i=0; i<props.length; i++ ) {
 			int propTableNumber = getSubclassPropertyTableNumber( props[i], classes[i] );
 			if ( isSubclassTableSequentialSelect(propTableNumber) && !isSubclassTableLazy(propTableNumber) ) {
 				tableNumbers.add( new Integer(propTableNumber) );
 			}
 		}
 		if ( tableNumbers.isEmpty() ) return null;
 		
 		//figure out which columns are needed
 		ArrayList columnNumbers = new ArrayList();
 		final int[] columnTableNumbers = getSubclassColumnTableNumberClosure();
 		for ( int i=0; i<getSubclassColumnClosure().length; i++ ) {
 			if ( tableNumbers.contains( new Integer( columnTableNumbers[i] ) ) ) {
 				columnNumbers.add( new Integer(i) );
 			}
 		}
 		
 		//figure out which formulas are needed
 		ArrayList formulaNumbers = new ArrayList();
 		final int[] formulaTableNumbers = getSubclassColumnTableNumberClosure();
 		for ( int i=0; i<getSubclassFormulaTemplateClosure().length; i++ ) {
 			if ( tableNumbers.contains( new Integer( formulaTableNumbers[i] ) ) ) {
 				formulaNumbers.add( new Integer(i) );
 			}
 		}
 		
 		//render the SQL
 		return renderSelect( 
 			ArrayHelper.toIntArray(tableNumbers),
 			ArrayHelper.toIntArray(columnNumbers),
 			ArrayHelper.toIntArray(formulaNumbers)
 		);
 	}
 		
 		
 	protected String[] getSubclassTableKeyColumns(int j) {
 		return subclassTableKeyColumnClosure[j];
 	}
 
 	public String getSubclassTableName(int j) {
 		return subclassTableNameClosure[j];
 	}
 
 	public int getSubclassTableSpan() {
 		return subclassTableNameClosure.length;
 	}
 
 	protected boolean isClassOrSuperclassTable(int j) {
 		return isClassOrSuperclassTable[j];
 	}
 
 	protected boolean isSubclassTableLazy(int j) {
 		return subclassTableIsLazyClosure[j];
 	}
 	
 	protected boolean isNullableTable(int j) {
 		return isNullableTable[j];
 	}
 	
 	protected boolean isNullableSubclassTable(int j) {
 		return isNullableSubclassTable[j];
 	}
 
 	public String getPropertyTableName(String propertyName) {
 		Integer index = getEntityMetamodel().getPropertyIndexOrNull(propertyName);
 		if (index==null) return null;
 		return qualifiedTableNames[ propertyTableNumbers[ index.intValue() ] ];
 	}
 	
 	public void postInstantiate() {
 		super.postInstantiate();
 		if (hasSequentialSelects) {
 			String[] entityNames = getSubclassClosure();
 			for ( int i=1; i<entityNames.length; i++ ) {
 				Loadable loadable = (Loadable) getFactory().getEntityPersister( entityNames[i] );
 				if ( !loadable.isAbstract() ) { //perhaps not really necessary...
 					String sequentialSelect = generateSequentialSelect(loadable);
 					sequentialSelectStringsByEntityName.put( entityNames[i], sequentialSelect );
 				}
 			}
 		}
 	}
 
 	public boolean isMultiTable() {
 		return getTableSpan() > 1;
 	}
 
 	public String[] getConstraintOrderedTableNameClosure() {
 		return constraintOrderedTableNames;
 	}
 
 	public String[][] getContraintOrderedTableKeyColumnClosure() {
 		return constraintOrderedKeyColumnNames;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/UnionSubclassEntityPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/UnionSubclassEntityPersister.java
index b792573e3c..33c8de603e 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/UnionSubclassEntityPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/UnionSubclassEntityPersister.java
@@ -1,482 +1,482 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.entity;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashSet;
 import java.util.Map;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.MappingException;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cfg.Settings;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.Mapping;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.id.IdentityGenerator;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.internal.util.collections.JoinedIterator;
 import org.hibernate.internal.util.collections.SingletonIterator;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Subclass;
 import org.hibernate.mapping.Table;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.SimpleSelect;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.Type;
 
 /**
  * Implementation of the "table-per-concrete-class" or "roll-down" mapping 
  * strategy for an entity and its inheritence hierarchy.
  *
  * @author Gavin King
  */
 public class UnionSubclassEntityPersister extends AbstractEntityPersister {
 
 	// the class hierarchy structure
 	private final String subquery;
 	private final String tableName;
 	//private final String rootTableName;
 	private final String[] subclassClosure;
 	private final String[] spaces;
 	private final String[] subclassSpaces;
 	private final String discriminatorSQLValue;
 	private final Map subclassByDiscriminatorValue = new HashMap();
 
 	private final String[] constraintOrderedTableNames;
 	private final String[][] constraintOrderedKeyColumnNames;
 
 	//INITIALIZATION:
 
 	public UnionSubclassEntityPersister(
 			final PersistentClass persistentClass, 
 			final EntityRegionAccessStrategy cacheAccessStrategy,
 			final SessionFactoryImplementor factory,
 			final Mapping mapping) throws HibernateException {
 
 		super( persistentClass, cacheAccessStrategy, factory );
 		
 		if ( getIdentifierGenerator() instanceof IdentityGenerator ) {
 			throw new MappingException(
 					"Cannot use identity column key generation with <union-subclass> mapping for: " + 
 					getEntityName() 
 			);
 		}
 
 		// TABLE
 
 		tableName = persistentClass.getTable().getQualifiedName( 
 				factory.getDialect(), 
 				factory.getSettings().getDefaultCatalogName(), 
 				factory.getSettings().getDefaultSchemaName() 
 		);
 		/*rootTableName = persistentClass.getRootTable().getQualifiedName( 
 				factory.getDialect(), 
 				factory.getDefaultCatalog(), 
 				factory.getDefaultSchema() 
 		);*/
 
 		//Custom SQL
 
 		String sql;
 		boolean callable = false;
 		ExecuteUpdateResultCheckStyle checkStyle = null;
 		sql = persistentClass.getCustomSQLInsert();
 		callable = sql != null && persistentClass.isCustomInsertCallable();
 		checkStyle = sql == null
 				? ExecuteUpdateResultCheckStyle.COUNT
 	            : persistentClass.getCustomSQLInsertCheckStyle() == null
 						? ExecuteUpdateResultCheckStyle.determineDefault( sql, callable )
 	                    : persistentClass.getCustomSQLInsertCheckStyle();
 		customSQLInsert = new String[] { sql };
 		insertCallable = new boolean[] { callable };
 		insertResultCheckStyles = new ExecuteUpdateResultCheckStyle[] { checkStyle };
 
 		sql = persistentClass.getCustomSQLUpdate();
 		callable = sql != null && persistentClass.isCustomUpdateCallable();
 		checkStyle = sql == null
 				? ExecuteUpdateResultCheckStyle.COUNT
 	            : persistentClass.getCustomSQLUpdateCheckStyle() == null
 						? ExecuteUpdateResultCheckStyle.determineDefault( sql, callable )
 	                    : persistentClass.getCustomSQLUpdateCheckStyle();
 		customSQLUpdate = new String[] { sql };
 		updateCallable = new boolean[] { callable };
 		updateResultCheckStyles = new ExecuteUpdateResultCheckStyle[] { checkStyle };
 
 		sql = persistentClass.getCustomSQLDelete();
 		callable = sql != null && persistentClass.isCustomDeleteCallable();
 		checkStyle = sql == null
 				? ExecuteUpdateResultCheckStyle.COUNT
 	            : persistentClass.getCustomSQLDeleteCheckStyle() == null
 						? ExecuteUpdateResultCheckStyle.determineDefault( sql, callable )
 	                    : persistentClass.getCustomSQLDeleteCheckStyle();
 		customSQLDelete = new String[] { sql };
 		deleteCallable = new boolean[] { callable };
 		deleteResultCheckStyles = new ExecuteUpdateResultCheckStyle[] { checkStyle };
 
 		discriminatorSQLValue = String.valueOf( persistentClass.getSubclassId() );
 
 		// PROPERTIES
 
 		int subclassSpan = persistentClass.getSubclassSpan() + 1;
 		subclassClosure = new String[subclassSpan];
 		subclassClosure[0] = getEntityName();
 
 		// SUBCLASSES
 		subclassByDiscriminatorValue.put( 
 				new Integer( persistentClass.getSubclassId() ), 
 				persistentClass.getEntityName() 
 		);
 		if ( persistentClass.isPolymorphic() ) {
 			Iterator iter = persistentClass.getSubclassIterator();
 			int k=1;
 			while ( iter.hasNext() ) {
 				Subclass sc = (Subclass) iter.next();
 				subclassClosure[k++] = sc.getEntityName();
 				subclassByDiscriminatorValue.put( new Integer( sc.getSubclassId() ), sc.getEntityName() );
 			}
 		}
 		
 		//SPACES
 		//TODO: i'm not sure, but perhaps we should exclude
 		//      abstract denormalized tables?
 		
 		int spacesSize = 1 + persistentClass.getSynchronizedTables().size();
 		spaces = new String[spacesSize];
 		spaces[0] = tableName;
 		Iterator iter = persistentClass.getSynchronizedTables().iterator();
 		for ( int i=1; i<spacesSize; i++ ) {
 			spaces[i] = (String) iter.next();
 		}
 		
 		HashSet subclassTables = new HashSet();
 		iter = persistentClass.getSubclassTableClosureIterator();
 		while ( iter.hasNext() ) {
 			Table table = (Table) iter.next();
 			subclassTables.add( table.getQualifiedName(
 					factory.getDialect(), 
 					factory.getSettings().getDefaultCatalogName(), 
 					factory.getSettings().getDefaultSchemaName() 
 			) );
 		}
 		subclassSpaces = ArrayHelper.toStringArray(subclassTables);
 
 		subquery = generateSubquery(persistentClass, mapping);
 
 		if ( isMultiTable() ) {
 			int idColumnSpan = getIdentifierColumnSpan();
 			ArrayList tableNames = new ArrayList();
 			ArrayList keyColumns = new ArrayList();
 			if ( !isAbstract() ) {
 				tableNames.add( tableName );
 				keyColumns.add( getIdentifierColumnNames() );
 			}
 			iter = persistentClass.getSubclassTableClosureIterator();
 			while ( iter.hasNext() ) {
 				Table tab = ( Table ) iter.next();
 				if ( !tab.isAbstractUnionTable() ) {
 					String tableName = tab.getQualifiedName(
 							factory.getDialect(),
 							factory.getSettings().getDefaultCatalogName(),
 							factory.getSettings().getDefaultSchemaName()
 					);
 					tableNames.add( tableName );
 					String[] key = new String[idColumnSpan];
 					Iterator citer = tab.getPrimaryKey().getColumnIterator();
 					for ( int k=0; k<idColumnSpan; k++ ) {
 						key[k] = ( ( Column ) citer.next() ).getQuotedName( factory.getDialect() );
 					}
 					keyColumns.add( key );
 				}
 			}
 
 			constraintOrderedTableNames = ArrayHelper.toStringArray( tableNames );
 			constraintOrderedKeyColumnNames = ArrayHelper.to2DStringArray( keyColumns );
 		}
 		else {
 			constraintOrderedTableNames = new String[] { tableName };
 			constraintOrderedKeyColumnNames = new String[][] { getIdentifierColumnNames() };
 		}
 
 		initLockers();
 
 		initSubclassPropertyAliasesMap(persistentClass);
 		
 		postConstruct(mapping);
 
 	}
 
 	public Serializable[] getQuerySpaces() {
 		return subclassSpaces;
 	}
 	
 	public String getTableName() {
 		return subquery;
 	}
 
 	public Type getDiscriminatorType() {
 		return StandardBasicTypes.INTEGER;
 	}
 
 	public String getDiscriminatorSQLValue() {
 		return discriminatorSQLValue;
 	}
 
 	public String[] getSubclassClosure() {
 		return subclassClosure;
 	}
 
 	public String getSubclassForDiscriminatorValue(Object value) {
 		return (String) subclassByDiscriminatorValue.get(value);
 	}
 
 	public Serializable[] getPropertySpaces() {
 		return spaces;
 	}
 
 	protected boolean isDiscriminatorFormula() {
 		return false;
 	}
 
 	/**
 	 * Generate the SQL that selects a row by id
 	 */
 	protected String generateSelectString(LockMode lockMode) {
 		SimpleSelect select = new SimpleSelect( getFactory().getDialect() )
 			.setLockMode(lockMode)
 			.setTableName( getTableName() )
 			.addColumns( getIdentifierColumnNames() )
 			.addColumns( 
 					getSubclassColumnClosure(), 
 					getSubclassColumnAliasClosure(),
 					getSubclassColumnLazyiness()
 			)
 			.addColumns( 
 					getSubclassFormulaClosure(), 
 					getSubclassFormulaAliasClosure(),
 					getSubclassFormulaLazyiness()
 			);
 		//TODO: include the rowids!!!!
 		if ( hasSubclasses() ) {
 			if ( isDiscriminatorFormula() ) {
 				select.addColumn( getDiscriminatorFormula(), getDiscriminatorAlias() );
 			}
 			else {
 				select.addColumn( getDiscriminatorColumnName(), getDiscriminatorAlias() );
 			}
 		}
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "load " + getEntityName() );
 		}
 		return select.addCondition( getIdentifierColumnNames(), "=?" ).toStatementString();
 	}
 
 	protected String getDiscriminatorFormula() {
 		return null;
 	}
 
 	protected String getTableName(int j) {
 		return tableName;
 	}
 
 	protected String[] getKeyColumns(int j) {
 		return getIdentifierColumnNames();
 	}
 	
 	protected boolean isTableCascadeDeleteEnabled(int j) {
 		return false;
 	}
 	
 	protected boolean isPropertyOfTable(int property, int j) {
 		return true;
 	}
 
 	// Execute the SQL:
 
 	public String fromTableFragment(String name) {
 		return getTableName() + ' '  + name;
 	}
 
 	public String filterFragment(String name) {
 		return hasWhere() ?
 			" and " + getSQLWhereString(name) :
 			"";
 	}
 
 	public String getSubclassPropertyTableName(int i) {
 		return getTableName();//ie. the subquery! yuck!
 	}
 
 	protected void addDiscriminatorToSelect(SelectFragment select, String name, String suffix) {
 		select.addColumn( name, getDiscriminatorColumnName(),  getDiscriminatorAlias() );
 	}
 	
 	protected int[] getPropertyTableNumbersInSelect() {
 		return new int[ getPropertySpan() ];
 	}
 
 	protected int getSubclassPropertyTableNumber(int i) {
 		return 0;
 	}
 
 	public int getSubclassPropertyTableNumber(String propertyName) {
 		return 0;
 	}
 
 	public boolean isMultiTable() {
 		// This could also just be true all the time...
 		return isAbstract() || hasSubclasses();
 	}
 
 	public int getTableSpan() {
 		return 1;
 	}
 
 	protected int[] getSubclassColumnTableNumberClosure() {
 		return new int[ getSubclassColumnClosure().length ];
 	}
 
 	protected int[] getSubclassFormulaTableNumberClosure() {
 		return new int[ getSubclassFormulaClosure().length ];
 	}
 
 	protected boolean[] getTableHasColumns() {
 		return new boolean[] { true };
 	}
 
 	protected int[] getPropertyTableNumbers() {
 		return new int[ getPropertySpan() ];
 	}
 
 	protected String generateSubquery(PersistentClass model, Mapping mapping) {
 
 		Dialect dialect = getFactory().getDialect();
 		Settings settings = getFactory().getSettings();
 		
 		if ( !model.hasSubclasses() ) {
 			return model.getTable().getQualifiedName(
 					dialect,
 					settings.getDefaultCatalogName(),
 					settings.getDefaultSchemaName()
 				);
 		}
 
 		HashSet columns = new LinkedHashSet();
 		Iterator titer = model.getSubclassTableClosureIterator();
 		while ( titer.hasNext() ) {
 			Table table = (Table) titer.next();
 			if ( !table.isAbstractUnionTable() ) {
 				Iterator citer = table.getColumnIterator();
 				while ( citer.hasNext() ) columns.add( citer.next() );
 			}
 		}
 
 		StringBuffer buf = new StringBuffer()
 			.append("( ");
 
 		Iterator siter = new JoinedIterator(
 			new SingletonIterator(model),
 			model.getSubclassIterator()
 		);
 
 		while ( siter.hasNext() ) {
 			PersistentClass clazz = (PersistentClass) siter.next();
 			Table table = clazz.getTable();
 			if ( !table.isAbstractUnionTable() ) {
 				//TODO: move to .sql package!!
 				buf.append("select ");
 				Iterator citer = columns.iterator();
 				while ( citer.hasNext() ) {
 					Column col = (Column) citer.next();
 					if ( !table.containsColumn(col) ) {
 						int sqlType = col.getSqlTypeCode(mapping);
 						buf.append( dialect.getSelectClauseNullString(sqlType) )
 							.append(" as ");
 					}
 					buf.append( col.getName() );
 					buf.append(", ");
 				}
 				buf.append( clazz.getSubclassId() )
 					.append(" as clazz_");
 				buf.append(" from ")
 					.append( table.getQualifiedName(
 							dialect,
 							settings.getDefaultCatalogName(),
 							settings.getDefaultSchemaName()
 					) );
 				buf.append(" union ");
 				if ( dialect.supportsUnionAll() ) {
 					buf.append("all ");
 				}
 			}
 		}
 		
 		if ( buf.length() > 2 ) {
 			//chop the last union (all)
 			buf.setLength( buf.length() - ( dialect.supportsUnionAll() ? 11 : 7 ) );
 		}
 
 		return buf.append(" )").toString();
 	}
 
 	protected String[] getSubclassTableKeyColumns(int j) {
 		if (j!=0) throw new AssertionFailure("only one table");
 		return getIdentifierColumnNames();
 	}
 
 	public String getSubclassTableName(int j) {
 		if (j!=0) throw new AssertionFailure("only one table");
 		return tableName;
 	}
 
 	public int getSubclassTableSpan() {
 		return 1;
 	}
 
 	protected boolean isClassOrSuperclassTable(int j) {
 		if (j!=0) throw new AssertionFailure("only one table");
 		return true;
 	}
 
 	public String getPropertyTableName(String propertyName) {
 		//TODO: check this....
 		return getTableName();
 	}
 
 	public String[] getConstraintOrderedTableNameClosure() {
 			return constraintOrderedTableNames;
 	}
 
 	public String[][] getContraintOrderedTableKeyColumnClosure() {
 		return constraintOrderedKeyColumnNames;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/internal/PersisterFactoryImpl.java b/hibernate-core/src/main/java/org/hibernate/persister/internal/PersisterFactoryImpl.java
index 7bf9741bad..ab81f7f2af 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/internal/PersisterFactoryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/internal/PersisterFactoryImpl.java
@@ -1,184 +1,183 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.internal;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.engine.Mapping;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.spi.PersisterClassResolver;
 import org.hibernate.persister.spi.PersisterFactory;
-import org.hibernate.service.ServiceRegistry;
 import org.hibernate.service.spi.ServiceRegistryAwareService;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 
 import java.lang.reflect.Constructor;
 import java.lang.reflect.InvocationTargetException;
 
 /**
  * The standard Hibernate {@link PersisterFactory} implementation
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public final class PersisterFactoryImpl implements PersisterFactory, ServiceRegistryAwareService {
 
 	/**
 	 * The constructor signature for {@link EntityPersister} implementations
 	 *
 	 * @todo make EntityPersister *not* depend on {@link SessionFactoryImplementor} if possible.
 	 */
 	public static final Class[] ENTITY_PERSISTER_CONSTRUCTOR_ARGS = new Class[] {
 			PersistentClass.class,
 			EntityRegionAccessStrategy.class,
 			SessionFactoryImplementor.class,
 			Mapping.class
 	};
 
 	/**
 	 * The constructor signature for {@link CollectionPersister} implementations
 	 *
 	 * @todo still need to make collection persisters EntityMode-aware
 	 * @todo make EntityPersister *not* depend on {@link SessionFactoryImplementor} if possible.
 	 */
 	private static final Class[] COLLECTION_PERSISTER_CONSTRUCTOR_ARGS = new Class[] {
 			Collection.class,
 			CollectionRegionAccessStrategy.class,
 			Configuration.class,
 			SessionFactoryImplementor.class
 	};
 
 	private ServiceRegistryImplementor serviceRegistry;
 
 	@Override
 	public void injectServices(ServiceRegistryImplementor serviceRegistry) {
 		this.serviceRegistry = serviceRegistry;
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public EntityPersister createEntityPersister(
 			PersistentClass metadata,
 			EntityRegionAccessStrategy cacheAccessStrategy,
 			SessionFactoryImplementor factory,
 			Mapping cfg) {
 		Class<? extends EntityPersister> persisterClass = metadata.getEntityPersisterClass();
 		if ( persisterClass == null ) {
 			persisterClass = serviceRegistry.getService( PersisterClassResolver.class ).getEntityPersisterClass( metadata );
 		}
 		return create( persisterClass, metadata, cacheAccessStrategy, factory, cfg );
 	}
 
 	private static EntityPersister create(
 			Class<? extends EntityPersister> persisterClass,
 			PersistentClass metadata,
 			EntityRegionAccessStrategy cacheAccessStrategy,
 			SessionFactoryImplementor factory,
 			Mapping cfg) throws HibernateException {
 		try {
 			Constructor<? extends EntityPersister> constructor = persisterClass.getConstructor( ENTITY_PERSISTER_CONSTRUCTOR_ARGS );
 			try {
 				return constructor.newInstance( metadata, cacheAccessStrategy, factory, cfg );
 			}
 			catch (MappingException e) {
 				throw e;
 			}
 			catch (InvocationTargetException e) {
 				Throwable target = e.getTargetException();
 				if ( target instanceof HibernateException ) {
 					throw (HibernateException) target;
 				}
 				else {
 					throw new MappingException( "Could not instantiate persister " + persisterClass.getName(), target );
 				}
 			}
 			catch (Exception e) {
 				throw new MappingException( "Could not instantiate persister " + persisterClass.getName(), e );
 			}
 		}
 		catch (MappingException e) {
 			throw e;
 		}
 		catch (Exception e) {
 			throw new MappingException( "Could not get constructor for " + persisterClass.getName(), e );
 		}
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public CollectionPersister createCollectionPersister(
 			Configuration cfg,
 			Collection metadata,
 			CollectionRegionAccessStrategy cacheAccessStrategy,
 			SessionFactoryImplementor factory) throws HibernateException {
 		Class<? extends CollectionPersister> persisterClass = metadata.getCollectionPersisterClass();
 		if ( persisterClass == null ) {
 			persisterClass = serviceRegistry.getService( PersisterClassResolver.class ).getCollectionPersisterClass( metadata );
 		}
 
 		return create( persisterClass, cfg, metadata, cacheAccessStrategy, factory );
 	}
 
 	private static CollectionPersister create(
 			Class<? extends CollectionPersister> persisterClass,
 			Configuration cfg,
 			Collection metadata,
 			CollectionRegionAccessStrategy cacheAccessStrategy,
 			SessionFactoryImplementor factory) throws HibernateException {
 		try {
 			Constructor<? extends CollectionPersister> constructor = persisterClass.getConstructor( COLLECTION_PERSISTER_CONSTRUCTOR_ARGS );
 			try {
 				return constructor.newInstance( metadata, cacheAccessStrategy, cfg, factory );
 			}
 			catch (MappingException e) {
 				throw e;
 			}
 			catch (InvocationTargetException e) {
 				Throwable target = e.getTargetException();
 				if ( target instanceof HibernateException ) {
 					throw (HibernateException) target;
 				}
 				else {
 					throw new MappingException( "Could not instantiate collection persister " + persisterClass.getName(), target );
 				}
 			}
 			catch (Exception e) {
 				throw new MappingException( "Could not instantiate collection persister " + persisterClass.getName(), e );
 			}
 		}
 		catch (MappingException e) {
 			throw e;
 		}
 		catch (Exception e) {
 			throw new MappingException( "Could not get constructor for " + persisterClass.getName(), e );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/spi/PersisterFactory.java b/hibernate-core/src/main/java/org/hibernate/persister/spi/PersisterFactory.java
index 72e37635a4..8d4ddd8682 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/spi/PersisterFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/spi/PersisterFactory.java
@@ -1,89 +1,89 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.spi;
 
 import org.hibernate.HibernateException;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.engine.Mapping;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.service.Service;
 
 /**
  * Contract for creating persister instances (both {@link EntityPersister} and {@link CollectionPersister} varieties).
  *
  * @author Steve Ebersole
  */
 public interface PersisterFactory extends Service {
 
 	// TODO: is it really neceassry to provide Configuration to CollectionPersisters ?
 	// Should it not be enough with associated class ? or why does EntityPersister's not get access to configuration ?
 	//
 	// The only reason I could see that Configuration gets passed to collection persisters
 	// is so that they can look up the dom4j node name of the entity element in case
 	// no explicit node name was applied at the collection element level.  Are you kidding me?
 	// Trivial to fix then.  Just store and expose the node name on the entity persister
 	// (which the collection persister looks up anyway via other means...).
 
 	/**
 	 * Create an entity persister instance.
 	 *
 	 * @param model The O/R mapping metamodel definition for the entity
 	 * @param cacheAccessStrategy The caching strategy for this entity
 	 * @param factory The session factory
 	 * @param cfg The overall mapping
 	 *
 	 * @return An appropriate entity persister instance.
 	 *
 	 * @throws HibernateException Indicates a problem building the persister.
 	 */
 	public EntityPersister createEntityPersister(
 			PersistentClass model,
 			EntityRegionAccessStrategy cacheAccessStrategy,
 			SessionFactoryImplementor factory,
 			Mapping cfg) throws HibernateException;
 
 	/**
 	 * Create a collection persister instance.
 	 *
 	 * @param cfg The configuration
 	 * @param model The O/R mapping metamodel definition for the collection
 	 * @param cacheAccessStrategy The caching strategy for this collection
 	 * @param factory The session factory
 	 *
 	 * @return An appropriate collection persister instance.
 	 *
 	 * @throws HibernateException Indicates a problem building the persister.
 	 */
 	public CollectionPersister createCollectionPersister(
 			Configuration cfg,
 			Collection model,
 			CollectionRegionAccessStrategy cacheAccessStrategy,
 			SessionFactoryImplementor factory) throws HibernateException;
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentSecondLevelCacheStatisticsImpl.java b/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentSecondLevelCacheStatisticsImpl.java
index 191c80c70a..cb12e435b8 100644
--- a/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentSecondLevelCacheStatisticsImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentSecondLevelCacheStatisticsImpl.java
@@ -1,112 +1,112 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.stat.internal;
 
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicLong;
 
-import org.hibernate.cache.CacheKey;
-import org.hibernate.cache.Region;
+import org.hibernate.cache.spi.CacheKey;
+import org.hibernate.cache.spi.Region;
 import org.hibernate.stat.SecondLevelCacheStatistics;
 
 /**
  * Second level cache statistics of a specific region
  *
  * @author Alex Snaps
  */
 public class ConcurrentSecondLevelCacheStatisticsImpl extends CategorizedStatistics implements SecondLevelCacheStatistics {
 	private final transient Region region;
 	private AtomicLong hitCount = new AtomicLong();
 	private AtomicLong missCount = new AtomicLong();
 	private AtomicLong putCount = new AtomicLong();
 
 	ConcurrentSecondLevelCacheStatisticsImpl(Region region) {
 		super( region.getName() );
 		this.region = region;
 	}
 
 	public long getHitCount() {
 		return hitCount.get();
 	}
 
 	public long getMissCount() {
 		return missCount.get();
 	}
 
 	public long getPutCount() {
 		return putCount.get();
 	}
 
 	public long getElementCountInMemory() {
 		return region.getElementCountInMemory();
 	}
 
 	public long getElementCountOnDisk() {
 		return region.getElementCountOnDisk();
 	}
 
 	public long getSizeInMemory() {
 		return region.getSizeInMemory();
 	}
 
 	public Map getEntries() {
 		Map map = new HashMap();
 		Iterator iter = region.toMap().entrySet().iterator();
 		while (iter.hasNext()) {
 			Map.Entry me = (Map.Entry) iter.next();
 			map.put(((CacheKey) me.getKey()).getKey(), me.getValue());
 		}
 		return map;
 	}
 
 	public String toString() {
 		StringBuilder buf = new StringBuilder()
 				.append("SecondLevelCacheStatistics")
 				.append("[hitCount=").append(this.hitCount)
 				.append(",missCount=").append(this.missCount)
 				.append(",putCount=").append(this.putCount);
 		//not sure if this would ever be null but wanted to be careful
 		if (region != null) {
 			buf.append(",elementCountInMemory=").append(this.getElementCountInMemory())
 					.append(",elementCountOnDisk=").append(this.getElementCountOnDisk())
 					.append(",sizeInMemory=").append(this.getSizeInMemory());
 		}
 		buf.append(']');
 		return buf.toString();
 	}
 
 	void incrementHitCount() {
 		hitCount.getAndIncrement();
 	}
 
 	void incrementMissCount() {
 		missCount.getAndIncrement();
 	}
 
 	void incrementPutCount() {
 		putCount.getAndIncrement();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentStatisticsImpl.java b/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentStatisticsImpl.java
index 58d36cd9f8..a0b3ef70f3 100644
--- a/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentStatisticsImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/stat/internal/ConcurrentStatisticsImpl.java
@@ -1,720 +1,720 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.stat.internal;
 
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.atomic.AtomicLong;
 
 import org.jboss.logging.Logger;
 
+import org.hibernate.cache.spi.Region;
 import org.hibernate.internal.CoreMessageLogger;
-import org.hibernate.cache.Region;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.service.Service;
 import org.hibernate.stat.CollectionStatistics;
 import org.hibernate.stat.EntityStatistics;
 import org.hibernate.stat.QueryStatistics;
 import org.hibernate.stat.SecondLevelCacheStatistics;
 import org.hibernate.stat.spi.StatisticsImplementor;
 
 /**
  * Implementation of {@link org.hibernate.stat.Statistics} based on the {@link java.util.concurrent} package.
  *
  * @author Alex Snaps
  */
 @SuppressWarnings({ "unchecked" })
 public class ConcurrentStatisticsImpl implements StatisticsImplementor, Service {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, ConcurrentStatisticsImpl.class.getName());
 
 	private SessionFactoryImplementor sessionFactory;
 
 	private volatile boolean isStatisticsEnabled;
 	private volatile long startTime;
 	private AtomicLong sessionOpenCount = new AtomicLong();
 	private AtomicLong sessionCloseCount = new AtomicLong();
 	private AtomicLong flushCount = new AtomicLong();
 	private AtomicLong connectCount = new AtomicLong();
 
 	private AtomicLong prepareStatementCount = new AtomicLong();
 	private AtomicLong closeStatementCount = new AtomicLong();
 
 	private AtomicLong entityLoadCount = new AtomicLong();
 	private AtomicLong entityUpdateCount = new AtomicLong();
 	private AtomicLong entityInsertCount = new AtomicLong();
 	private AtomicLong entityDeleteCount = new AtomicLong();
 	private AtomicLong entityFetchCount = new AtomicLong();
 	private AtomicLong collectionLoadCount = new AtomicLong();
 	private AtomicLong collectionUpdateCount = new AtomicLong();
 	private AtomicLong collectionRemoveCount = new AtomicLong();
 	private AtomicLong collectionRecreateCount = new AtomicLong();
 	private AtomicLong collectionFetchCount = new AtomicLong();
 
 	private AtomicLong secondLevelCacheHitCount = new AtomicLong();
 	private AtomicLong secondLevelCacheMissCount = new AtomicLong();
 	private AtomicLong secondLevelCachePutCount = new AtomicLong();
 
 	private AtomicLong queryExecutionCount = new AtomicLong();
 	private AtomicLong queryExecutionMaxTime = new AtomicLong();
 	private volatile String queryExecutionMaxTimeQueryString;
 	private AtomicLong queryCacheHitCount = new AtomicLong();
 	private AtomicLong queryCacheMissCount = new AtomicLong();
 	private AtomicLong queryCachePutCount = new AtomicLong();
 
 	private AtomicLong committedTransactionCount = new AtomicLong();
 	private AtomicLong transactionCount = new AtomicLong();
 
 	private AtomicLong optimisticFailureCount = new AtomicLong();
 
 	/**
 	 * second level cache statistics per region
 	 */
 	private final ConcurrentMap secondLevelCacheStatistics = new ConcurrentHashMap();
 	/**
 	 * entity statistics per name
 	 */
 	private final ConcurrentMap entityStatistics = new ConcurrentHashMap();
 	/**
 	 * collection statistics per name
 	 */
 	private final ConcurrentMap collectionStatistics = new ConcurrentHashMap();
 	/**
 	 * entity statistics per query string (HQL or SQL)
 	 */
 	private final ConcurrentMap queryStatistics = new ConcurrentHashMap();
 
 	@SuppressWarnings({ "UnusedDeclaration" })
 	public ConcurrentStatisticsImpl() {
 		clear();
 	}
 
 	public ConcurrentStatisticsImpl(SessionFactoryImplementor sessionFactory) {
 		clear();
 		this.sessionFactory = sessionFactory;
 	}
 
 	/**
 	 * reset all statistics
 	 */
 	public void clear() {
 		secondLevelCacheHitCount.set( 0 );
 		secondLevelCacheMissCount.set( 0 );
 		secondLevelCachePutCount.set( 0 );
 
 		sessionCloseCount.set( 0 );
 		sessionOpenCount.set( 0 );
 		flushCount.set( 0 );
 		connectCount.set( 0 );
 
 		prepareStatementCount.set( 0 );
 		closeStatementCount.set( 0 );
 
 		entityDeleteCount.set( 0 );
 		entityInsertCount.set( 0 );
 		entityUpdateCount.set( 0 );
 		entityLoadCount.set( 0 );
 		entityFetchCount.set( 0 );
 
 		collectionRemoveCount.set( 0 );
 		collectionUpdateCount.set( 0 );
 		collectionRecreateCount.set( 0 );
 		collectionLoadCount.set( 0 );
 		collectionFetchCount.set( 0 );
 
 		queryExecutionCount.set( 0 );
 		queryCacheHitCount.set( 0 );
 		queryExecutionMaxTime.set( 0 );
 		queryExecutionMaxTimeQueryString = null;
 		queryCacheMissCount.set( 0 );
 		queryCachePutCount.set( 0 );
 
 		transactionCount.set( 0 );
 		committedTransactionCount.set( 0 );
 
 		optimisticFailureCount.set( 0 );
 
 		secondLevelCacheStatistics.clear();
 		entityStatistics.clear();
 		collectionStatistics.clear();
 		queryStatistics.clear();
 
 		startTime = System.currentTimeMillis();
 	}
 
 	public void openSession() {
 		sessionOpenCount.getAndIncrement();
 	}
 
 	public void closeSession() {
 		sessionCloseCount.getAndIncrement();
 	}
 
 	public void flush() {
 		flushCount.getAndIncrement();
 	}
 
 	public void connect() {
 		connectCount.getAndIncrement();
 	}
 
 	public void loadEntity(String entityName) {
 		entityLoadCount.getAndIncrement();
 		( (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName ) ).incrementLoadCount();
 	}
 
 	public void fetchEntity(String entityName) {
 		entityFetchCount.getAndIncrement();
 		( (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName ) ).incrementFetchCount();
 	}
 
 	/**
 	 * find entity statistics per name
 	 *
 	 * @param entityName entity name
 	 *
 	 * @return EntityStatistics object
 	 */
 	public EntityStatistics getEntityStatistics(String entityName) {
 		ConcurrentEntityStatisticsImpl es = (ConcurrentEntityStatisticsImpl) entityStatistics.get( entityName );
 		if ( es == null ) {
 			es = new ConcurrentEntityStatisticsImpl( entityName );
 			ConcurrentEntityStatisticsImpl previous;
 			if ( ( previous = (ConcurrentEntityStatisticsImpl) entityStatistics.putIfAbsent(
 					entityName, es
 			) ) != null ) {
 				es = previous;
 			}
 		}
 		return es;
 	}
 
 	public void updateEntity(String entityName) {
 		entityUpdateCount.getAndIncrement();
 		ConcurrentEntityStatisticsImpl es = (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName );
 		es.incrementUpdateCount();
 	}
 
 	public void insertEntity(String entityName) {
 		entityInsertCount.getAndIncrement();
 		ConcurrentEntityStatisticsImpl es = (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName );
 		es.incrementInsertCount();
 	}
 
 	public void deleteEntity(String entityName) {
 		entityDeleteCount.getAndIncrement();
 		ConcurrentEntityStatisticsImpl es = (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName );
 		es.incrementDeleteCount();
 	}
 
 	/**
 	 * Get collection statistics per role
 	 *
 	 * @param role collection role
 	 *
 	 * @return CollectionStatistics
 	 */
 	public CollectionStatistics getCollectionStatistics(String role) {
 		ConcurrentCollectionStatisticsImpl cs = (ConcurrentCollectionStatisticsImpl) collectionStatistics.get( role );
 		if ( cs == null ) {
 			cs = new ConcurrentCollectionStatisticsImpl( role );
 			ConcurrentCollectionStatisticsImpl previous;
 			if ( ( previous = (ConcurrentCollectionStatisticsImpl) collectionStatistics.putIfAbsent(
 					role, cs
 			) ) != null ) {
 				cs = previous;
 			}
 		}
 		return cs;
 	}
 
 	public void loadCollection(String role) {
 		collectionLoadCount.getAndIncrement();
 		( (ConcurrentCollectionStatisticsImpl) getCollectionStatistics( role ) ).incrementLoadCount();
 	}
 
 	public void fetchCollection(String role) {
 		collectionFetchCount.getAndIncrement();
 		( (ConcurrentCollectionStatisticsImpl) getCollectionStatistics( role ) ).incrementFetchCount();
 	}
 
 	public void updateCollection(String role) {
 		collectionUpdateCount.getAndIncrement();
 		( (ConcurrentCollectionStatisticsImpl) getCollectionStatistics( role ) ).incrementUpdateCount();
 	}
 
 	public void recreateCollection(String role) {
 		collectionRecreateCount.getAndIncrement();
 		( (ConcurrentCollectionStatisticsImpl) getCollectionStatistics( role ) ).incrementRecreateCount();
 	}
 
 	public void removeCollection(String role) {
 		collectionRemoveCount.getAndIncrement();
 		( (ConcurrentCollectionStatisticsImpl) getCollectionStatistics( role ) ).incrementRemoveCount();
 	}
 
 	/**
 	 * Second level cache statistics per region
 	 *
 	 * @param regionName region name
 	 *
 	 * @return SecondLevelCacheStatistics
 	 */
 	public SecondLevelCacheStatistics getSecondLevelCacheStatistics(String regionName) {
 		ConcurrentSecondLevelCacheStatisticsImpl slcs
 				= (ConcurrentSecondLevelCacheStatisticsImpl) secondLevelCacheStatistics.get( regionName );
 		if ( slcs == null ) {
 			if ( sessionFactory == null ) {
 				return null;
 			}
 			Region region = sessionFactory.getSecondLevelCacheRegion( regionName );
 			if ( region == null ) {
 				return null;
 			}
 			slcs = new ConcurrentSecondLevelCacheStatisticsImpl( region );
 			ConcurrentSecondLevelCacheStatisticsImpl previous;
 			if ( ( previous = (ConcurrentSecondLevelCacheStatisticsImpl) secondLevelCacheStatistics.putIfAbsent(
 					regionName, slcs
 			) ) != null ) {
 				slcs = previous;
 			}
 		}
 		return slcs;
 	}
 
 	public void secondLevelCachePut(String regionName) {
 		secondLevelCachePutCount.getAndIncrement();
 		( (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics( regionName ) ).incrementPutCount();
 	}
 
 	public void secondLevelCacheHit(String regionName) {
 		secondLevelCacheHitCount.getAndIncrement();
 		( (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics( regionName ) ).incrementHitCount();
 	}
 
 	public void secondLevelCacheMiss(String regionName) {
 		secondLevelCacheMissCount.getAndIncrement();
 		( (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics( regionName ) ).incrementMissCount();
 	}
 
 	@SuppressWarnings({ "UnnecessaryBoxing" })
 	public void queryExecuted(String hql, int rows, long time) {
         LOG.hql(hql, Long.valueOf(time), Long.valueOf(rows));
 		queryExecutionCount.getAndIncrement();
 		boolean isLongestQuery = false;
 		for ( long old = queryExecutionMaxTime.get();
 			  ( isLongestQuery = time > old ) && ( !queryExecutionMaxTime.compareAndSet( old, time ) );
 			  old = queryExecutionMaxTime.get() ) {
 			// nothing to do here given the odd loop structure...
 		}
 		if ( isLongestQuery ) {
 			queryExecutionMaxTimeQueryString = hql;
 		}
 		if ( hql != null ) {
 			ConcurrentQueryStatisticsImpl qs = (ConcurrentQueryStatisticsImpl) getQueryStatistics( hql );
 			qs.executed( rows, time );
 		}
 	}
 
 	public void queryCacheHit(String hql, String regionName) {
 		queryCacheHitCount.getAndIncrement();
 		if ( hql != null ) {
 			ConcurrentQueryStatisticsImpl qs = (ConcurrentQueryStatisticsImpl) getQueryStatistics( hql );
 			qs.incrementCacheHitCount();
 		}
 		ConcurrentSecondLevelCacheStatisticsImpl slcs = (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics(
 				regionName
 		);
 		slcs.incrementHitCount();
 	}
 
 	public void queryCacheMiss(String hql, String regionName) {
 		queryCacheMissCount.getAndIncrement();
 		if ( hql != null ) {
 			ConcurrentQueryStatisticsImpl qs = (ConcurrentQueryStatisticsImpl) getQueryStatistics( hql );
 			qs.incrementCacheMissCount();
 		}
 		ConcurrentSecondLevelCacheStatisticsImpl slcs = (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics(
 				regionName
 		);
 		slcs.incrementMissCount();
 	}
 
 	public void queryCachePut(String hql, String regionName) {
 		queryCachePutCount.getAndIncrement();
 		if ( hql != null ) {
 			ConcurrentQueryStatisticsImpl qs = (ConcurrentQueryStatisticsImpl) getQueryStatistics( hql );
 			qs.incrementCachePutCount();
 		}
 		ConcurrentSecondLevelCacheStatisticsImpl slcs = (ConcurrentSecondLevelCacheStatisticsImpl) getSecondLevelCacheStatistics(
 				regionName
 		);
 		slcs.incrementPutCount();
 	}
 
 	/**
 	 * Query statistics from query string (HQL or SQL)
 	 *
 	 * @param queryString query string
 	 *
 	 * @return QueryStatistics
 	 */
 	public QueryStatistics getQueryStatistics(String queryString) {
 		ConcurrentQueryStatisticsImpl qs = (ConcurrentQueryStatisticsImpl) queryStatistics.get( queryString );
 		if ( qs == null ) {
 			qs = new ConcurrentQueryStatisticsImpl( queryString );
 			ConcurrentQueryStatisticsImpl previous;
 			if ( ( previous = (ConcurrentQueryStatisticsImpl) queryStatistics.putIfAbsent(
 					queryString, qs
 			) ) != null ) {
 				qs = previous;
 			}
 		}
 		return qs;
 	}
 
 	/**
 	 * @return entity deletion count
 	 */
 	public long getEntityDeleteCount() {
 		return entityDeleteCount.get();
 	}
 
 	/**
 	 * @return entity insertion count
 	 */
 	public long getEntityInsertCount() {
 		return entityInsertCount.get();
 	}
 
 	/**
 	 * @return entity load (from DB)
 	 */
 	public long getEntityLoadCount() {
 		return entityLoadCount.get();
 	}
 
 	/**
 	 * @return entity fetch (from DB)
 	 */
 	public long getEntityFetchCount() {
 		return entityFetchCount.get();
 	}
 
 	/**
 	 * @return entity update
 	 */
 	public long getEntityUpdateCount() {
 		return entityUpdateCount.get();
 	}
 
 	public long getQueryExecutionCount() {
 		return queryExecutionCount.get();
 	}
 
 	public long getQueryCacheHitCount() {
 		return queryCacheHitCount.get();
 	}
 
 	public long getQueryCacheMissCount() {
 		return queryCacheMissCount.get();
 	}
 
 	public long getQueryCachePutCount() {
 		return queryCachePutCount.get();
 	}
 
 	/**
 	 * @return flush
 	 */
 	public long getFlushCount() {
 		return flushCount.get();
 	}
 
 	/**
 	 * @return session connect
 	 */
 	public long getConnectCount() {
 		return connectCount.get();
 	}
 
 	/**
 	 * @return second level cache hit
 	 */
 	public long getSecondLevelCacheHitCount() {
 		return secondLevelCacheHitCount.get();
 	}
 
 	/**
 	 * @return second level cache miss
 	 */
 	public long getSecondLevelCacheMissCount() {
 		return secondLevelCacheMissCount.get();
 	}
 
 	/**
 	 * @return second level cache put
 	 */
 	public long getSecondLevelCachePutCount() {
 		return secondLevelCachePutCount.get();
 	}
 
 	/**
 	 * @return session closing
 	 */
 	public long getSessionCloseCount() {
 		return sessionCloseCount.get();
 	}
 
 	/**
 	 * @return session opening
 	 */
 	public long getSessionOpenCount() {
 		return sessionOpenCount.get();
 	}
 
 	/**
 	 * @return collection loading (from DB)
 	 */
 	public long getCollectionLoadCount() {
 		return collectionLoadCount.get();
 	}
 
 	/**
 	 * @return collection fetching (from DB)
 	 */
 	public long getCollectionFetchCount() {
 		return collectionFetchCount.get();
 	}
 
 	/**
 	 * @return collection update
 	 */
 	public long getCollectionUpdateCount() {
 		return collectionUpdateCount.get();
 	}
 
 	/**
 	 * @return collection removal
 	 *         FIXME: even if isInverse="true"?
 	 */
 	public long getCollectionRemoveCount() {
 		return collectionRemoveCount.get();
 	}
 
 	/**
 	 * @return collection recreation
 	 */
 	public long getCollectionRecreateCount() {
 		return collectionRecreateCount.get();
 	}
 
 	/**
 	 * @return start time in ms (JVM standards {@link System#currentTimeMillis()})
 	 */
 	public long getStartTime() {
 		return startTime;
 	}
 
 	/**
 	 * log in info level the main statistics
 	 */
 	public void logSummary() {
         LOG.loggingStatistics();
         LOG.startTime(startTime);
         LOG.sessionsOpened(sessionOpenCount.get());
         LOG.sessionsClosed(sessionCloseCount.get());
         LOG.transactions(transactionCount.get());
         LOG.successfulTransactions(committedTransactionCount.get());
         LOG.optimisticLockFailures(optimisticFailureCount.get());
         LOG.flushes(flushCount.get());
         LOG.connectionsObtained(connectCount.get());
         LOG.statementsPrepared(prepareStatementCount.get());
         LOG.statementsClosed(closeStatementCount.get());
         LOG.secondLevelCachePuts(secondLevelCachePutCount.get());
         LOG.secondLevelCacheHits(secondLevelCacheHitCount.get());
         LOG.secondLevelCacheMisses(secondLevelCacheMissCount.get());
         LOG.entitiesLoaded(entityLoadCount.get());
         LOG.entitiesUpdated(entityUpdateCount.get());
         LOG.entitiesInserted(entityInsertCount.get());
         LOG.entitiesDeleted(entityDeleteCount.get());
         LOG.entitiesFetched(entityFetchCount.get());
         LOG.collectionsLoaded(collectionLoadCount.get());
         LOG.collectionsUpdated(collectionUpdateCount.get());
         LOG.collectionsRemoved(collectionRemoveCount.get());
         LOG.collectionsRecreated(collectionRecreateCount.get());
         LOG.collectionsFetched(collectionFetchCount.get());
         LOG.queriesExecuted(queryExecutionCount.get());
         LOG.queryCachePuts(queryCachePutCount.get());
         LOG.queryCacheHits(queryCacheHitCount.get());
         LOG.queryCacheMisses(queryCacheMissCount.get());
         LOG.maxQueryTime(queryExecutionMaxTime.get());
 	}
 
 	/**
 	 * Are statistics logged
 	 */
 	public boolean isStatisticsEnabled() {
 		return isStatisticsEnabled;
 	}
 
 	/**
 	 * Enable statistics logs (this is a dynamic parameter)
 	 */
 	public void setStatisticsEnabled(boolean b) {
 		isStatisticsEnabled = b;
 	}
 
 	/**
 	 * @return Returns the max query execution time,
 	 *         for all queries
 	 */
 	public long getQueryExecutionMaxTime() {
 		return queryExecutionMaxTime.get();
 	}
 
 	/**
 	 * Get all executed query strings
 	 */
 	public String[] getQueries() {
 		return ArrayHelper.toStringArray( queryStatistics.keySet() );
 	}
 
 	/**
 	 * Get the names of all entities
 	 */
 	public String[] getEntityNames() {
 		if ( sessionFactory == null ) {
 			return ArrayHelper.toStringArray( entityStatistics.keySet() );
 		}
 		else {
 			return ArrayHelper.toStringArray( sessionFactory.getAllClassMetadata().keySet() );
 		}
 	}
 
 	/**
 	 * Get the names of all collection roles
 	 */
 	public String[] getCollectionRoleNames() {
 		if ( sessionFactory == null ) {
 			return ArrayHelper.toStringArray( collectionStatistics.keySet() );
 		}
 		else {
 			return ArrayHelper.toStringArray( sessionFactory.getAllCollectionMetadata().keySet() );
 		}
 	}
 
 	/**
 	 * Get all second-level cache region names
 	 */
 	public String[] getSecondLevelCacheRegionNames() {
 		if ( sessionFactory == null ) {
 			return ArrayHelper.toStringArray( secondLevelCacheStatistics.keySet() );
 		}
 		else {
 			return ArrayHelper.toStringArray( sessionFactory.getAllSecondLevelCacheRegions().keySet() );
 		}
 	}
 
 	public void endTransaction(boolean success) {
 		transactionCount.getAndIncrement();
 		if ( success ) {
 			committedTransactionCount.getAndIncrement();
 		}
 	}
 
 	public long getSuccessfulTransactionCount() {
 		return committedTransactionCount.get();
 	}
 
 	public long getTransactionCount() {
 		return transactionCount.get();
 	}
 
 	public void closeStatement() {
 		closeStatementCount.getAndIncrement();
 	}
 
 	public void prepareStatement() {
 		prepareStatementCount.getAndIncrement();
 	}
 
 	public long getCloseStatementCount() {
 		return closeStatementCount.get();
 	}
 
 	public long getPrepareStatementCount() {
 		return prepareStatementCount.get();
 	}
 
 	public void optimisticFailure(String entityName) {
 		optimisticFailureCount.getAndIncrement();
 		( (ConcurrentEntityStatisticsImpl) getEntityStatistics( entityName ) ).incrementOptimisticFailureCount();
 	}
 
 	public long getOptimisticFailureCount() {
 		return optimisticFailureCount.get();
 	}
 
 	@Override
     public String toString() {
 		return new StringBuilder()
 				.append( "Statistics[" )
 				.append( "start time=" ).append( startTime )
 				.append( ",sessions opened=" ).append( sessionOpenCount )
 				.append( ",sessions closed=" ).append( sessionCloseCount )
 				.append( ",transactions=" ).append( transactionCount )
 				.append( ",successful transactions=" ).append( committedTransactionCount )
 				.append( ",optimistic lock failures=" ).append( optimisticFailureCount )
 				.append( ",flushes=" ).append( flushCount )
 				.append( ",connections obtained=" ).append( connectCount )
 				.append( ",statements prepared=" ).append( prepareStatementCount )
 				.append( ",statements closed=" ).append( closeStatementCount )
 				.append( ",second level cache puts=" ).append( secondLevelCachePutCount )
 				.append( ",second level cache hits=" ).append( secondLevelCacheHitCount )
 				.append( ",second level cache misses=" ).append( secondLevelCacheMissCount )
 				.append( ",entities loaded=" ).append( entityLoadCount )
 				.append( ",entities updated=" ).append( entityUpdateCount )
 				.append( ",entities inserted=" ).append( entityInsertCount )
 				.append( ",entities deleted=" ).append( entityDeleteCount )
 				.append( ",entities fetched=" ).append( entityFetchCount )
 				.append( ",collections loaded=" ).append( collectionLoadCount )
 				.append( ",collections updated=" ).append( collectionUpdateCount )
 				.append( ",collections removed=" ).append( collectionRemoveCount )
 				.append( ",collections recreated=" ).append( collectionRecreateCount )
 				.append( ",collections fetched=" ).append( collectionFetchCount )
 				.append( ",queries executed to database=" ).append( queryExecutionCount )
 				.append( ",query cache puts=" ).append( queryCachePutCount )
 				.append( ",query cache hits=" ).append( queryCacheHitCount )
 				.append( ",query cache misses=" ).append( queryCacheMissCount )
 				.append( ",max query time=" ).append( queryExecutionMaxTime )
 				.append( ']' )
 				.toString();
 	}
 
 	public String getQueryExecutionMaxTimeQueryString() {
 		return queryExecutionMaxTimeQueryString;
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/cache/QueryKeyTest.java b/hibernate-core/src/test/java/org/hibernate/cache/spi/QueryKeyTest.java
similarity index 99%
rename from hibernate-core/src/test/java/org/hibernate/cache/QueryKeyTest.java
rename to hibernate-core/src/test/java/org/hibernate/cache/spi/QueryKeyTest.java
index c07e6947b2..cebd1b1bcf 100644
--- a/hibernate-core/src/test/java/org/hibernate/cache/QueryKeyTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/cache/spi/QueryKeyTest.java
@@ -1,275 +1,276 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.cache;
+package org.hibernate.cache.spi;
 
 import java.io.Serializable;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.Map;
 
 import org.junit.Test;
 
 import org.hibernate.EntityMode;
+import org.hibernate.cache.spi.QueryKey;
 import org.hibernate.internal.util.SerializationHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.testing.junit4.BaseUnitTestCase;
 import org.hibernate.transform.AliasToBeanResultTransformer;
 import org.hibernate.transform.AliasToEntityMapResultTransformer;
 import org.hibernate.transform.AliasedTupleSubsetResultTransformer;
 import org.hibernate.transform.CacheableResultTransformer;
 import org.hibernate.transform.DistinctResultTransformer;
 import org.hibernate.transform.DistinctRootEntityResultTransformer;
 import org.hibernate.transform.PassThroughResultTransformer;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.transform.RootEntityResultTransformer;
 import org.hibernate.transform.ToListResultTransformer;
 import org.hibernate.transform.TupleSubsetResultTransformer;
 
 /**
  * Tests relating to {@link QueryKey} instances.
  *
  * @author Steve Ebersole
  */
 public class QueryKeyTest extends BaseUnitTestCase {
 	private static final String QUERY_STRING = "the query string";
 
 	public static class AClass implements Serializable {
 		private String propAccessedByField;
 		private String propAccessedByMethod;
 		private int propValue;
 
 		public AClass() {
 		}
 
 		public AClass(String propAccessedByField) {
 			this.propAccessedByField = propAccessedByField;
 		}
 
 		public String getPropAccessedByMethod() {
 			return propAccessedByMethod;
 		}
 
 		public void setPropAccessedByMethod(String propAccessedByMethod) {
 			this.propAccessedByMethod = propAccessedByMethod;
 		}
 	}
 
 	@Test
 	public void testSerializedEqualityResultTransformer() throws Exception {
 		// settings are lazily initialized when calling transformTuple(),
 		// so they have not been initialized for the following test
 		// (it *should* be initialized before creating a QueryKey)
 		doResultTransformerTest( new AliasToBeanResultTransformer( AClass.class ), false );
 
 		// initialize settings for the next test
 		AliasToBeanResultTransformer transformer = new AliasToBeanResultTransformer( AClass.class );
 		transformer.transformTuple(
 				new Object[] { "abc", "def" },
 				new String[] { "propAccessedByField", "propAccessedByMethod" }
 		);
 		doResultTransformerTest( transformer, false );
 
 		doResultTransformerTest( AliasToEntityMapResultTransformer.INSTANCE, true );
 		doResultTransformerTest( DistinctResultTransformer.INSTANCE, true );
 		doResultTransformerTest( DistinctRootEntityResultTransformer.INSTANCE, true );
 		doResultTransformerTest( PassThroughResultTransformer.INSTANCE, true );
 		doResultTransformerTest( RootEntityResultTransformer.INSTANCE, true );
 		doResultTransformerTest( ToListResultTransformer.INSTANCE, true );
 	}
 
 	// Reproduces HHH-5628; commented out because FailureExpected is not working here...
 	/*
 	public void testAliasToBeanConstructorFailureExpected() throws Exception {
 		// AliasToBeanConstructorResultTransformer is not Serializable because
 		// java.lang.reflect.Constructor is not Serializable;
 		doResultTransformerTest(
 				new AliasToBeanConstructorResultTransformer( AClass.class.getConstructor( String.class ) ), false
 		);
 	}
 	*/
 
 	private void doResultTransformerTest(ResultTransformer transformer, boolean isSingleton) {
 		Map transformerMap = new HashMap();
 
 		transformerMap.put( transformer, "" );
 		assert transformerMap.size() == 1 : "really messed up";
 		Object old = transformerMap.put( transformer, "value" );
 		assert old != null && transformerMap.size() == 1 : "apparent QueryKey equals/hashCode issue";
 
 		// finally, lets serialize it and see what happens
 		ResultTransformer transformer2 = ( ResultTransformer ) SerializationHelper.clone( transformer );
 		old = transformerMap.put( transformer2, "new value" );
 		assert old != null && transformerMap.size() == 1 : "deserialization did not set hashCode or equals properly";
 		if ( isSingleton ) {
 			assert transformer == transformer2: "deserialization issue for singleton transformer";
 		}
 		else {
 			assert transformer != transformer2: "deserialization issue for non-singleton transformer";
 		}
 		assert transformer.equals( transformer2 ): "deep copy issue";
 	}
 
 	@Test
 	public void testSerializedEquality() throws Exception {
 		doTest( buildBasicKey( null ) );
 
 		doTest( buildBasicKey( CacheableResultTransformer.create( null, null, new boolean[] { true } ) ) );
 		doTest( buildBasicKey( CacheableResultTransformer.create( null, new String[] { null }, new boolean[] { true } ) ) );
 		doTest( buildBasicKey( CacheableResultTransformer.create( null, new String[] { "a" }, new boolean[] { true } ) ) );
 		doTest( buildBasicKey( CacheableResultTransformer.create( null, null, new boolean[] { false, true } ) ) );
 		doTest( buildBasicKey( CacheableResultTransformer.create( null, new String[] { "a" }, new boolean[] { true, false } ) ) );
 		doTest( buildBasicKey( CacheableResultTransformer.create( null, new String[] { "a", null }, new boolean[] { true, true } ) ) );
 	}
 
 	@Test
 	public void testSerializedEqualityWithTupleSubsetResultTransfprmer() throws Exception {
 		doTestWithTupleSubsetResultTransformer(
 				new AliasToBeanResultTransformer( AClass.class ),
 				new String[] { "propAccessedByField", "propAccessedByMethod" }
 		);
 		doTestWithTupleSubsetResultTransformer( AliasToEntityMapResultTransformer.INSTANCE, new String[] { "a", "b" } );
 		doTestWithTupleSubsetResultTransformer( DistinctRootEntityResultTransformer.INSTANCE, new String[] { "a", "b" } );
 		doTestWithTupleSubsetResultTransformer( PassThroughResultTransformer.INSTANCE, new String[] { "a", "b" } );
 		doTestWithTupleSubsetResultTransformer( RootEntityResultTransformer.INSTANCE, new String[] { "a", "b" } );
 		// The following are not TupleSubsetResultTransformers:
 		// DistinctResultTransformer.INSTANCE
 		// ToListResultTransformer.INSTANCE
 	}
 
 	public void doTestWithTupleSubsetResultTransformer(TupleSubsetResultTransformer transformer,
 													   String[] aliases) throws Exception {
 		doTest( buildBasicKey(
 				CacheableResultTransformer.create(
 						transformer,
 						new String[] { aliases[ 0 ], aliases[ 1 ] },
 						new boolean[] { true, true } )
 		) );
 		doTest( buildBasicKey(
 				CacheableResultTransformer.create(
 						transformer,
 						new String[] { aliases[ 0 ], aliases[ 1 ] },
 						new boolean[] { true, true, false } )
 		) );
 		doTest( buildBasicKey(
 				CacheableResultTransformer.create(
 						transformer,
 						new String[] { aliases[ 1 ] },
 						new boolean[] { true } )
 		) );
 		doTest( buildBasicKey(
 				CacheableResultTransformer.create(
 						transformer,
 						new String[] { null, aliases[ 1 ] },
 						new boolean[] { true, true } )
 		) );
 		doTest( buildBasicKey(
 				CacheableResultTransformer.create(
 						transformer,
 						new String[] { aliases[ 0 ], null },
 						new boolean[] { true, true } )
 		) );
 		doTest( buildBasicKey(
 				CacheableResultTransformer.create(
 						transformer,
 						new String[] { aliases[ 0 ] },
 						new boolean[] { false, true } )
 		) );
 		doTest( buildBasicKey(
 				CacheableResultTransformer.create(
 						transformer,
 						new String[] { aliases[ 0 ] },
 						new boolean[] { true, false } )
 		) );
 		doTest( buildBasicKey(
 				CacheableResultTransformer.create(
 						transformer,
 						new String[] { aliases[ 0 ] },
 						new boolean[] { false, true, false } )
 		) );
 		if ( ! ( transformer instanceof AliasedTupleSubsetResultTransformer ) ) {
 			doTestWithTupleSubsetResultTransformerNullAliases( transformer );
 		}
 	}
 
 	public void doTestWithTupleSubsetResultTransformerNullAliases(TupleSubsetResultTransformer transformer) throws Exception {
 		doTest( buildBasicKey( CacheableResultTransformer.create( transformer, null, new boolean[] { true } ) ) );
 		doTest( buildBasicKey( CacheableResultTransformer.create( transformer, null, new boolean[] { true, true } ) ) );
 		doTest( buildBasicKey( CacheableResultTransformer.create( transformer, null, new boolean[] { true, true, true } ) ) );
 		doTest( buildBasicKey( CacheableResultTransformer.create( transformer, null, new boolean[] { false, true } ) ) );
 		doTest( buildBasicKey( CacheableResultTransformer.create( transformer, null, new boolean[] { true, false } ) ) );
 		doTest( buildBasicKey( CacheableResultTransformer.create( transformer, null, new boolean[] { false, true, true } ) ) );
 		doTest( buildBasicKey( CacheableResultTransformer.create( transformer, null, new boolean[] {true, false, true } ) ) );
 		doTest( buildBasicKey( CacheableResultTransformer.create( transformer, null, new boolean[] {true, true, false } ) ) );
 		doTest( buildBasicKey( CacheableResultTransformer.create( transformer, null, new boolean[] {false, false, true } ) ) );
 		doTest( buildBasicKey( CacheableResultTransformer.create( transformer, null, new boolean[] {false, true, false } ) ) );
 		doTest( buildBasicKey( CacheableResultTransformer.create( transformer, null, new boolean[] {false, false, true } ) ) );
 	}
 
 	private QueryKey buildBasicKey(CacheableResultTransformer resultTransformer) {
 		return new QueryKey(
 				QUERY_STRING,
 				ArrayHelper.EMPTY_TYPE_ARRAY, 		// positional param types
 				ArrayHelper.EMPTY_OBJECT_ARRAY,		// positional param values
 				Collections.EMPTY_MAP,				// named params
 				null,								// firstRow selection
 				null,								// maxRows selection
 				Collections.EMPTY_SET, 				// filter keys
 				EntityMode.POJO,					// entity mode
 				null,								// tenantIdentifier
 				resultTransformer					// the result transformer
 		);
 	}
 
 	private void doTest(QueryKey key) {
 		Map keyMap = new HashMap();
 		Map transformerMap = new HashMap();
 
 		keyMap.put( key, "" );
 		assert keyMap.size() == 1 : "really messed up";
 		Object old = keyMap.put( key, "value" );
 		assert old != null && keyMap.size() == 1 : "apparent QueryKey equals/hashCode issue";
 
 		if ( key.getResultTransformer() != null ) {
 			transformerMap.put( key.getResultTransformer(), "" );
 			assert transformerMap.size() == 1 : "really messed up";
 			old = transformerMap.put( key.getResultTransformer(), "value" );
 			assert old != null && transformerMap.size() == 1 : "apparent QueryKey equals/hashCode issue";
 		}
 
 		// finally, lets serialize it and see what happens
 		QueryKey key2 = ( QueryKey ) SerializationHelper.clone( key );
 		assert key != key2 : "deep copy issue";
 		old = keyMap.put( key2, "new value" );
 		assert old != null && keyMap.size() == 1 : "deserialization did not set hashCode or equals properly";
 		if ( key.getResultTransformer() == null ) {
 			assert key2.getResultTransformer() == null;
 		}
 		else {
 			old = transformerMap.put( key2.getResultTransformer(), "new value" );
 			assert old != null && transformerMap.size() == 1 : "deserialization did not set hashCode or equals properly";
 				assert key.getResultTransformer() != key2.getResultTransformer(): "deserialization issue for non-singleton transformer";
 				assert key.getResultTransformer().equals( key2.getResultTransformer() ): "deep copy issue";
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/persister/CollectionPersister.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/persister/CollectionPersister.java
index 8319b4813a..6d80f291f8 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/persister/CollectionPersister.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/persister/CollectionPersister.java
@@ -1,18 +1,18 @@
 package org.hibernate.test.annotations.persister;
 import org.hibernate.MappingException;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.mapping.Collection;
 import org.hibernate.persister.collection.OneToManyPersister;
 
 /**
  * @author Shawn Clowater
  */
 public class CollectionPersister extends OneToManyPersister {
 	public CollectionPersister(Collection collection, CollectionRegionAccessStrategy cache, Configuration cfg,
 							   SessionFactoryImplementor factory) throws MappingException, CacheException {
 		super( collection, cache, cfg, factory );
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/persister/EntityPersister.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/persister/EntityPersister.java
index 4bad7c8b0f..68c1580cb1 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/persister/EntityPersister.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/persister/EntityPersister.java
@@ -1,17 +1,17 @@
 package org.hibernate.test.annotations.persister;
 import org.hibernate.HibernateException;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.engine.Mapping;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.persister.entity.SingleTableEntityPersister;
 
 /**
  * @author Shawn Clowater
  */
 public class EntityPersister extends SingleTableEntityPersister {
 	public EntityPersister(PersistentClass persistentClass, EntityRegionAccessStrategy cache,
 						   SessionFactoryImplementor factory, Mapping cfg) throws HibernateException {
 		super( persistentClass, cache, factory, cfg );
 	}
 }
\ No newline at end of file
diff --git a/hibernate-core/src/test/java/org/hibernate/test/cfg/persister/GoofyPersisterClassProvider.java b/hibernate-core/src/test/java/org/hibernate/test/cfg/persister/GoofyPersisterClassProvider.java
index 9c09506736..c0285a8d2c 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/cfg/persister/GoofyPersisterClassProvider.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/cfg/persister/GoofyPersisterClassProvider.java
@@ -1,700 +1,700 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * JBoss, Home of Professional Open Source
  * Copyright 2011 Red Hat Inc. and/or its affiliates and other contributors
  * as indicated by the @authors tag. All rights reserved.
  * See the copyright.txt in the distribution for a
  * full listing of individual contributors.
  *
  * This copyrighted material is made available to anyone wishing to use,
  * modify, copy, or redistribute it subject to the terms and conditions
  * of the GNU Lesser General Public License, v. 2.1.
  * This program is distributed in the hope that it will be useful, but WITHOUT A
  * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
  * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
  * You should have received a copy of the GNU Lesser General Public License,
  * v.2.1 along with this distribution; if not, write to the Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
  * MA  02110-1301, USA.
  */
 package org.hibernate.test.cfg.persister;
 
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Comparator;
 import java.util.Map;
 
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
-import org.hibernate.cache.entry.CacheEntryStructure;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.spi.entry.CacheEntryStructure;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.CascadeStyle;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.ValueInclusion;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.metadata.CollectionMetadata;
 import org.hibernate.persister.spi.PersisterClassResolver;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.tuple.entity.EntityMetamodel;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 
 /**
  * @author Emmanuel Bernard <emmanuel@hibernate.org>
  */
 public class GoofyPersisterClassProvider implements PersisterClassResolver {
 	@Override
 	public Class<? extends EntityPersister> getEntityPersisterClass(PersistentClass metadata) {
 		return NoopEntityPersister.class;
 	}
 
 	@Override
 	public Class<? extends CollectionPersister> getCollectionPersisterClass(Collection metadata) {
 		return NoopCollectionPersister.class;
 	}
 
 	public static class NoopEntityPersister implements EntityPersister {
 
 		public NoopEntityPersister(org.hibernate.mapping.PersistentClass persistentClass,
-								   org.hibernate.cache.access.EntityRegionAccessStrategy strategy,
+								   org.hibernate.cache.spi.access.EntityRegionAccessStrategy strategy,
 								   org.hibernate.engine.SessionFactoryImplementor sf,
 								   org.hibernate.engine.Mapping mapping) {
 			throw new GoofyException(NoopEntityPersister.class);
 		}
 
 		public void postInstantiate() throws MappingException {
 
 		}
 
 		public SessionFactoryImplementor getFactory() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public String getRootEntityName() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public String getEntityName() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public EntityMetamodel getEntityMetamodel() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isSubclassEntityName(String entityName) {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Serializable[] getPropertySpaces() {
 			return new Serializable[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Serializable[] getQuerySpaces() {
 			return new Serializable[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasProxy() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasCollections() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasMutableProperties() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasSubselectLoadableCollections() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasCascades() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isMutable() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isInherited() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isIdentifierAssignedByInsert() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Type getPropertyType(String propertyName) throws MappingException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public int[] findDirty(Object[] currentState, Object[] previousState, Object owner, SessionImplementor session) {
 			return new int[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public int[] findModified(Object[] old, Object[] current, Object object, SessionImplementor session) {
 			return new int[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasIdentifierProperty() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean canExtractIdOutOfEntity() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isVersioned() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Comparator getVersionComparator() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public VersionType getVersionType() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public int getVersionProperty() {
 			return 0;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasNaturalIdentifier() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public int[] getNaturalIdentifierProperties() {
 			return new int[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object[] getNaturalIdentifierSnapshot(Serializable id, SessionImplementor session) {
 			return new Object[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public IdentifierGenerator getIdentifierGenerator() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasLazyProperties() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object load(Serializable id, Object optionalObject, LockMode lockMode, SessionImplementor session)
 				throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object load(Serializable id, Object optionalObject, LockOptions lockOptions, SessionImplementor session)
 				throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void lock(Serializable id, Object version, Object object, LockMode lockMode, SessionImplementor session)
 				throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void lock(Serializable id, Object version, Object object, LockOptions lockOptions, SessionImplementor session)
 				throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void insert(Serializable id, Object[] fields, Object object, SessionImplementor session)
 				throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Serializable insert(Object[] fields, Object object, SessionImplementor session)
 				throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void delete(Serializable id, Object version, Object object, SessionImplementor session)
 				throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void update(Serializable id, Object[] fields, int[] dirtyFields, boolean hasDirtyCollection, Object[] oldFields, Object oldVersion, Object object, Object rowId, SessionImplementor session)
 				throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Type[] getPropertyTypes() {
 			return new Type[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public String[] getPropertyNames() {
 			return new String[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean[] getPropertyInsertability() {
 			return new boolean[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public ValueInclusion[] getPropertyInsertGenerationInclusions() {
 			return new ValueInclusion[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public ValueInclusion[] getPropertyUpdateGenerationInclusions() {
 			return new ValueInclusion[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean[] getPropertyUpdateability() {
 			return new boolean[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean[] getPropertyCheckability() {
 			return new boolean[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean[] getPropertyNullability() {
 			return new boolean[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean[] getPropertyVersionability() {
 			return new boolean[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean[] getPropertyLaziness() {
 			return new boolean[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public CascadeStyle[] getPropertyCascadeStyles() {
 			return new CascadeStyle[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Type getIdentifierType() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public String getIdentifierPropertyName() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isCacheInvalidationRequired() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isLazyPropertiesCacheable() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasCache() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public EntityRegionAccessStrategy getCacheAccessStrategy() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public CacheEntryStructure getCacheEntryStructure() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public ClassMetadata getClassMetadata() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isBatchLoadable() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isSelectBeforeUpdateRequired() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object[] getDatabaseSnapshot(Serializable id, SessionImplementor session) throws HibernateException {
 			return new Object[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object getCurrentVersion(Serializable id, SessionImplementor session) throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object forceVersionIncrement(Serializable id, Object currentVersion, SessionImplementor session)
 				throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public EntityMode guessEntityMode(Object object) {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isInstrumented(EntityMode entityMode) {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasInsertGeneratedProperties() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasUpdateGeneratedProperties() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isVersionPropertyGenerated() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void afterInitialize(Object entity, boolean lazyPropertiesAreUnfetched, SessionImplementor session) {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void afterReassociate(Object entity, SessionImplementor session) {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object createProxy(Serializable id, SessionImplementor session) throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Boolean isTransient(Object object, SessionImplementor session) throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object[] getPropertyValuesToInsert(Object object, Map mergeMap, SessionImplementor session)
 				throws HibernateException {
 			return new Object[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void processInsertGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session) {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void processUpdateGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session) {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Class getMappedClass(EntityMode entityMode) {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean implementsLifecycle(EntityMode entityMode) {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean implementsValidatable(EntityMode entityMode) {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Class getConcreteProxyClass(EntityMode entityMode) {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void setPropertyValues(Object object, Object[] values, EntityMode entityMode) throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void setPropertyValue(Object object, int i, Object value, EntityMode entityMode)
 				throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object[] getPropertyValues(Object object, EntityMode entityMode) throws HibernateException {
 			return new Object[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object getPropertyValue(Object object, int i, EntityMode entityMode) throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object getPropertyValue(Object object, String propertyName, EntityMode entityMode)
 				throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Serializable getIdentifier(Object object, EntityMode entityMode) throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Serializable getIdentifier(Object entity, SessionImplementor session) {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void setIdentifier(Object entity, Serializable id, EntityMode entityMode) throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void setIdentifier(Object entity, Serializable id, SessionImplementor session) {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object getVersion(Object object, EntityMode entityMode) throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object instantiate(Serializable id, EntityMode entityMode) throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object instantiate(Serializable id, SessionImplementor session) {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isInstance(Object object, EntityMode entityMode) {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasUninitializedLazyProperties(Object object, EntityMode entityMode) {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void resetIdentifier(Object entity, Serializable currentId, Object currentVersion, EntityMode entityMode) {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void resetIdentifier(Object entity, Serializable currentId, Object currentVersion, SessionImplementor session) {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public EntityPersister getSubclassEntityPersister(Object instance, SessionFactoryImplementor factory, EntityMode entityMode) {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 	}
 
 	public static class NoopCollectionPersister implements CollectionPersister {
 
 		public NoopCollectionPersister(org.hibernate.mapping.Collection collection,
-									   org.hibernate.cache.access.CollectionRegionAccessStrategy strategy,
+									   org.hibernate.cache.spi.access.CollectionRegionAccessStrategy strategy,
 									   org.hibernate.cfg.Configuration configuration,
 									   org.hibernate.engine.SessionFactoryImplementor sf) {
 			throw new GoofyException(NoopCollectionPersister.class);
 		}
 
 		public void initialize(Serializable key, SessionImplementor session) throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasCache() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public CollectionRegionAccessStrategy getCacheAccessStrategy() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public CacheEntryStructure getCacheEntryStructure() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public CollectionType getCollectionType() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Type getKeyType() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Type getIndexType() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Type getElementType() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Class getElementClass() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object readKey(ResultSet rs, String[] keyAliases, SessionImplementor session)
 				throws HibernateException, SQLException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object readElement(ResultSet rs, Object owner, String[] columnAliases, SessionImplementor session)
 				throws HibernateException, SQLException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object readIndex(ResultSet rs, String[] columnAliases, SessionImplementor session)
 				throws HibernateException, SQLException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object readIdentifier(ResultSet rs, String columnAlias, SessionImplementor session)
 				throws HibernateException, SQLException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isPrimitiveArray() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isArray() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isOneToMany() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isManyToMany() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public String getManyToManyFilterFragment(String alias, Map enabledFilters) {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasIndex() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isLazy() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isInverse() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void remove(Serializable id, SessionImplementor session) throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void recreate(PersistentCollection collection, Serializable key, SessionImplementor session)
 				throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void deleteRows(PersistentCollection collection, Serializable key, SessionImplementor session)
 				throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void updateRows(PersistentCollection collection, Serializable key, SessionImplementor session)
 				throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void insertRows(PersistentCollection collection, Serializable key, SessionImplementor session)
 				throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public String getRole() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public EntityPersister getOwnerEntityPersister() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public IdentifierGenerator getIdentifierGenerator() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Type getIdentifierType() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasOrphanDelete() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasOrdering() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasManyToManyOrdering() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Serializable[] getCollectionSpaces() {
 			return new Serializable[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public CollectionMetadata getCollectionMetadata() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isCascadeDeleteEnabled() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isVersioned() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isMutable() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public String getNodeName() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public String getElementNodeName() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public String getIndexNodeName() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void postInstantiate() throws MappingException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public SessionFactoryImplementor getFactory() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isAffectedByEnabledFilters(SessionImplementor session) {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public String[] getKeyColumnAliases(String suffix) {
 			return new String[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public String[] getIndexColumnAliases(String suffix) {
 			return new String[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public String[] getElementColumnAliases(String suffix) {
 			return new String[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public String getIdentifierColumnAlias(String suffix) {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isExtraLazy() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public int getSize(Serializable key, SessionImplementor session) {
 			return 0;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean indexExists(Serializable key, Object index, SessionImplementor session) {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean elementExists(Serializable key, Object element, SessionImplementor session) {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object getElementByIndex(Serializable key, Object index, SessionImplementor session, Object owner) {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/filter/DynamicFilterTest.java b/hibernate-core/src/test/java/org/hibernate/test/filter/DynamicFilterTest.java
index ebbd6c0b87..8722f3efbf 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/filter/DynamicFilterTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/filter/DynamicFilterTest.java
@@ -1,979 +1,979 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.filter;
 
 import java.util.ArrayList;
 import java.util.Calendar;
 import java.util.Date;
 import java.util.GregorianCalendar;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.Criteria;
 import org.hibernate.FetchMode;
 import org.hibernate.Hibernate;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
-import org.hibernate.cache.CacheKey;
-import org.hibernate.cache.entry.CollectionCacheEntry;
+import org.hibernate.cache.spi.CacheKey;
+import org.hibernate.cache.spi.entry.CollectionCacheEntry;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.criterion.DetachedCriteria;
 import org.hibernate.criterion.Property;
 import org.hibernate.criterion.Restrictions;
 import org.hibernate.criterion.Subqueries;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.transform.DistinctRootEntityResultTransformer;
 
 import org.junit.Test;
 
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertSame;
 import static org.junit.Assert.assertTrue;
 
 /**
  * Implementation of DynamicFilterTest.
  *
  * @author Steve Ebersole
  */
 public class DynamicFilterTest extends BaseCoreFunctionalTestCase {
 	private static final Logger log = Logger.getLogger( DynamicFilterTest.class );
 
 	@Override
 	public String[] getMappings() {
 		return new String[]{
 			"filter/defs.hbm.xml",
 			"filter/LineItem.hbm.xml",
 			"filter/Order.hbm.xml",
 			"filter/Product.hbm.xml",
 			"filter/Salesperson.hbm.xml",
 			"filter/Department.hbm.xml",
 			"filter/Category.hbm.xml"
 		};
 	}
 
 	@Override
 	protected String getCacheConcurrencyStrategy() {
 		return "nonstrict-read-write";
 	}
 
 	@Override
 	public void configure(Configuration cfg) {
 		cfg.setProperty( Environment.MAX_FETCH_DEPTH, "1" );
 		cfg.setProperty( Environment.GENERATE_STATISTICS, "true" );
 		cfg.setProperty( Environment.USE_QUERY_CACHE, "true" );
 	}
 
 	@Test
 	public void testSqlSyntaxOfFiltersWithUnions() {
 		Session session = openSession();
 		session.enableFilter( "unioned" );
 		session.createQuery( "from Category" ).list();
 		session.close();
 	}
 
 	@Test
 	public void testSecondLevelCachedCollectionsFiltering() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		long ts = ( ( SessionImplementor ) session ).getTimestamp();
 
 		// Force a collection into the second level cache, with its non-filtered elements
 		Salesperson sp = ( Salesperson ) session.load( Salesperson.class, testData.steveId );
 		Hibernate.initialize( sp.getOrders() );
 		CollectionPersister persister = sessionFactory().getCollectionPersister( Salesperson.class.getName() + ".orders" );
 		assertTrue( "No cache for collection", persister.hasCache() );
 		CacheKey cacheKey = ( (SessionImplementor) session ).generateCacheKey(
 				testData.steveId,
 				persister.getKeyType(),
 				persister.getRole()
 		);
 		CollectionCacheEntry cachedData = ( CollectionCacheEntry ) persister.getCacheAccessStrategy().get( cacheKey, ts );
 		assertNotNull( "collection was not in cache", cachedData );
 
 		session.close();
 
 		session = openSession();
 		ts = ( ( SessionImplementor ) session ).getTimestamp();
 		session.enableFilter( "fulfilledOrders" ).setParameter( "asOfDate", testData.lastMonth.getTime() );
 		sp = ( Salesperson ) session.createQuery( "from Salesperson as s where s.id = :id" )
 		        .setLong( "id", testData.steveId )
 		        .uniqueResult();
 		assertEquals( "Filtered-collection not bypassing 2L-cache", 1, sp.getOrders().size() );
 
 		CacheKey cacheKey2 = ( (SessionImplementor) session ).generateCacheKey(
 				testData.steveId,
 				persister.getKeyType(),
 				persister.getRole()
 		);
 		CollectionCacheEntry cachedData2 = ( CollectionCacheEntry ) persister.getCacheAccessStrategy().get( cacheKey2, ts );
 		assertNotNull( "collection no longer in cache!", cachedData2 );
 		assertSame( "Different cache values!", cachedData, cachedData2 );
 
 		session.close();
 
 		session = openSession();
 		session.enableFilter( "fulfilledOrders" ).setParameter( "asOfDate", testData.lastMonth.getTime() );
 		sp = ( Salesperson ) session.load( Salesperson.class, testData.steveId );
 		assertEquals( "Filtered-collection not bypassing 2L-cache", 1, sp.getOrders().size() );
 
 		session.close();
 
 		// Finally, make sure that the original cached version did not get over-written
 		session = openSession();
 		sp = ( Salesperson ) session.load( Salesperson.class, testData.steveId );
 		assertEquals( "Actual cached version got over-written", 2, sp.getOrders().size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testCombinedClassAndCollectionFiltersEnabled() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "regionlist" ).setParameterList( "regions", new String[]{"LA", "APAC"} );
 		session.enableFilter( "fulfilledOrders" ).setParameter( "asOfDate", testData.lastMonth.getTime() );
 
 		// test retreival through hql with the collection as non-eager
 		List salespersons = session.createQuery( "select s from Salesperson as s" ).list();
 		assertEquals( "Incorrect salesperson count", 1, salespersons.size() );
 		Salesperson sp = ( Salesperson ) salespersons.get( 0 );
 		assertEquals( "Incorrect order count", 1, sp.getOrders().size() );
 
 		session.clear();
 
 		session.disableFilter( "regionlist" );
 		session.enableFilter( "regionlist" ).setParameterList( "regions", new String[]{"LA", "APAC", "APAC"} );
 		// Second test retreival through hql with the collection as non-eager with different region list
 		salespersons = session.createQuery( "select s from Salesperson as s" ).list();
 		assertEquals( "Incorrect salesperson count", 1, salespersons.size() );
 		sp = ( Salesperson ) salespersons.get( 0 );
 		assertEquals( "Incorrect order count", 1, sp.getOrders().size() );
 
 		session.clear();
 
 
 		// test retreival through hql with the collection join fetched
 		salespersons = session.createQuery( "select s from Salesperson as s left join fetch s.orders" ).list();
 		assertEquals( "Incorrect salesperson count", 1, salespersons.size() );
 		sp = ( Salesperson ) salespersons.get( 0 );
 		assertEquals( "Incorrect order count", 1, sp.getOrders().size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testHqlFilters() {
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// HQL test
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         log.info( "Starting HQL filter tests" );
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "region" ).setParameter( "region", "APAC" );
 
 		session.enableFilter( "effectiveDate" )
 		        .setParameter( "asOfDate", testData.lastMonth.getTime() );
 
         log.info( "HQL against Salesperson..." );
 		List results = session.createQuery( "select s from Salesperson as s left join fetch s.orders" ).list();
 		assertTrue( "Incorrect filtered HQL result count [" + results.size() + "]", results.size() == 1 );
 		Salesperson result = ( Salesperson ) results.get( 0 );
 		assertTrue( "Incorrect collectionfilter count", result.getOrders().size() == 1 );
 
         log.info( "HQL against Product..." );
 		results = session.createQuery( "from Product as p where p.stockNumber = ?" ).setInteger( 0, 124 ).list();
 		assertTrue( results.size() == 1 );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testFiltersWithCustomerReadAndWrite() {
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// Custom SQL read/write with filter
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         log.info("Starting HQL filter with custom SQL get/set tests");
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "heavyProducts" ).setParameter("weightKilograms", 4d);
         log.info( "HQL against Product..." );
 		List results = session.createQuery( "from Product").list();
 		assertEquals( 1, results.size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testCriteriaQueryFilters() {
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// Criteria-query test
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         log.info("Starting Criteria-query filter tests");
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "region" ).setParameter( "region", "APAC" );
 
 		session.enableFilter( "fulfilledOrders" )
 		        .setParameter( "asOfDate", testData.lastMonth.getTime() );
 
 		session.enableFilter( "effectiveDate" )
 		        .setParameter( "asOfDate", testData.lastMonth.getTime() );
 
         log.info("Criteria query against Salesperson...");
 		List salespersons = session.createCriteria( Salesperson.class )
 		        .setFetchMode( "orders", FetchMode.JOIN )
 		        .list();
 		assertEquals( "Incorrect salesperson count", 1, salespersons.size() );
 		assertEquals( "Incorrect order count", 1, ( ( Salesperson ) salespersons.get( 0 ) ).getOrders().size() );
 
         log.info("Criteria query against Product...");
 		List products = session.createCriteria( Product.class )
 		        .add( Restrictions.eq( "stockNumber", 124 ) )
 		        .list();
 		assertEquals( "Incorrect product count", 1, products.size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testCriteriaControl() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		// the subquery...
 		DetachedCriteria subquery = DetachedCriteria.forClass( Salesperson.class )
 				.setProjection( Property.forName( "name" ) );
 
 		Session session = openSession();
 		session.beginTransaction();
 		session.enableFilter( "fulfilledOrders" ).setParameter( "asOfDate", testData.lastMonth.getTime() );
 		session.enableFilter( "regionlist" ).setParameterList( "regions", new String[] {"APAC"} );
 
 		List result = session.createCriteria( Order.class )
 				.add( Subqueries.in( "steve", subquery ) )
 				.list();
 		assertEquals( 1, result.size() );
 
 		session.getTransaction().commit();
 		session.close();
 
 		testData.release();
 	}
 
 	@Test
 	public void testCriteriaSubqueryWithFilters() {
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// Criteria-subquery test
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         log.info("Starting Criteria-subquery filter tests");
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter("region").setParameter("region", "APAC");
 
         log.info("Criteria query against Department with a subquery on Salesperson in the APAC reqion...");
 		DetachedCriteria salespersonSubquery = DetachedCriteria.forClass(Salesperson.class)
 				.add(Restrictions.eq("name", "steve"))
 				.setProjection(Property.forName("department"));
 
 		Criteria departmentsQuery = session.createCriteria(Department.class).add(Subqueries.propertyIn("id", salespersonSubquery));
 		List departments = departmentsQuery.list();
 
 		assertEquals("Incorrect department count", 1, departments.size());
 
         log.info("Criteria query against Department with a subquery on Salesperson in the FooBar reqion...");
 
 		session.enableFilter("region").setParameter("region", "Foobar");
 		departments = departmentsQuery.list();
 
 		assertEquals("Incorrect department count", 0, departments.size());
 
         log.info("Criteria query against Order with a subquery for line items with a subquery on product and sold by a given sales person...");
 		session.enableFilter("region").setParameter("region", "APAC");
 
 		DetachedCriteria lineItemSubquery = DetachedCriteria.forClass(LineItem.class)
 				.add( Restrictions.ge( "quantity", 1L ) )
 				.createCriteria( "product" )
 				.add( Restrictions.eq( "name", "Acme Hair Gel" ) )
 				.setProjection( Property.forName( "id" ) );
 
 		List orders = session.createCriteria(Order.class)
 				.add(Subqueries.exists(lineItemSubquery))
 				.add(Restrictions.eq("buyer", "gavin"))
 				.list();
 
 		assertEquals("Incorrect orders count", 1, orders.size());
 
         log.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region and the product is effective as of last month");
 		session.enableFilter("region").setParameter("region", "APAC");
 		session.enableFilter("effectiveDate").setParameter("asOfDate", testData.lastMonth.getTime());
 
 		DetachedCriteria productSubquery = DetachedCriteria.forClass(Product.class)
 				.add(Restrictions.eq("name", "Acme Hair Gel"))
 				.setProjection(Property.forName("id"));
 
 		lineItemSubquery = DetachedCriteria.forClass(LineItem.class)
 				.add(Restrictions.ge("quantity", 1L ))
 				.createCriteria("product")
 				.add(Subqueries.propertyIn("id", productSubquery))
 				.setProjection(Property.forName("id"));
 
 		orders = session.createCriteria(Order.class)
 				.add(Subqueries.exists(lineItemSubquery))
 				.add(Restrictions.eq("buyer", "gavin"))
 				.list();
 
 		assertEquals("Incorrect orders count", 1, orders.size());
 
 
         log.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region and the product is effective as of 4 months ago");
 		session.enableFilter("region").setParameter("region", "APAC");
 		session.enableFilter("effectiveDate").setParameter("asOfDate", testData.fourMonthsAgo.getTime());
 
 		orders = session.createCriteria(Order.class)
 				.add(Subqueries.exists(lineItemSubquery))
 				.add(Restrictions.eq("buyer", "gavin"))
 				.list();
 
 		assertEquals("Incorrect orders count", 0, orders.size());
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testHQLSubqueryWithFilters() {
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// HQL subquery with filters test
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         log.info("Starting HQL subquery with filters tests");
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter("region").setParameter("region", "APAC");
 
         log.info("query against Department with a subquery on Salesperson in the APAC reqion...");
 
 		List departments = session.createQuery(
 				"select d from Department as d where d.id in (select s.department from Salesperson s where s.name = ?)"
 		).setString( 0, "steve" ).list();
 
 		assertEquals("Incorrect department count", 1, departments.size());
 
         log.info("query against Department with a subquery on Salesperson in the FooBar reqion...");
 
 		session.enableFilter("region").setParameter( "region", "Foobar" );
 		departments = session.createQuery("select d from Department as d where d.id in (select s.department from Salesperson s where s.name = ?)").setString(0, "steve").list();
 
 		assertEquals( "Incorrect department count", 0, departments.size() );
 
         log.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region for a given buyer");
 		session.enableFilter("region").setParameter( "region", "APAC" );
 
 		List orders = session.createQuery("select o from Order as o where exists (select li.id from LineItem li, Product as p where p.id = li.product and li.quantity >= ? and p.name = ?) and o.buyer = ?")
 				.setLong(0, 1L).setString(1, "Acme Hair Gel").setString(2, "gavin").list();
 
 		assertEquals( "Incorrect orders count", 1, orders.size() );
 
         log.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region and the product is effective as of last month");
 
 		session.enableFilter("region").setParameter("region", "APAC");
 		session.enableFilter("effectiveDate").setParameter( "asOfDate", testData.lastMonth.getTime() );
 
 		orders = session.createQuery("select o from Order as o where exists (select li.id from LineItem li where li.quantity >= ? and li.product in (select p.id from Product p where p.name = ?)) and o.buyer = ?")
 				.setLong(0, 1L).setString(1, "Acme Hair Gel").setString(2, "gavin").list();
 
 		assertEquals( "Incorrect orders count", 1, orders.size() );
 
 
         log.info(
 				"query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region and the product is effective as of 4 months ago"
 		);
 
 		session.enableFilter("region").setParameter("region", "APAC");
 		session.enableFilter("effectiveDate").setParameter("asOfDate", testData.fourMonthsAgo.getTime());
 
 		orders = session.createQuery("select o from Order as o where exists (select li.id from LineItem li where li.quantity >= ? and li.product in (select p.id from Product p where p.name = ?)) and o.buyer = ?")
 				.setLong( 0, 1L ).setString( 1, "Acme Hair Gel" ).setString( 2, "gavin" ).list();
 
 		assertEquals("Incorrect orders count", 0, orders.size());
 
         log.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region and the product is effective as of last month with named types");
 
 		session.enableFilter("region").setParameter("region", "APAC");
 		session.enableFilter("effectiveDate").setParameter("asOfDate", testData.lastMonth.getTime());
 
 		orders = session.createQuery("select o from Order as o where exists (select li.id from LineItem li where li.quantity >= :quantity and li.product in (select p.id from Product p where p.name = :name)) and o.buyer = :buyer")
 				.setLong("quantity", 1L).setString("name", "Acme Hair Gel").setString("buyer", "gavin").list();
 
 		assertEquals("Incorrect orders count", 1, orders.size());
 
         log.info("query against Order with a subquery for line items with a subquery line items where the product name is Acme Hair Gel and the quantity is greater than 1 in a given region and the product is effective as of last month with mixed types");
 
 		session.enableFilter("region").setParameter("region", "APAC");
 		session.enableFilter("effectiveDate").setParameter("asOfDate", testData.lastMonth.getTime());
 
 		orders = session.createQuery("select o from Order as o where exists (select li.id from LineItem li where li.quantity >= ? and li.product in (select p.id from Product p where p.name = ?)) and o.buyer = :buyer")
 				.setLong( 0, 1L ).setString( 1, "Acme Hair Gel" ).setString( "buyer", "gavin" ).list();
 
 		assertEquals("Incorrect orders count", 1, orders.size());
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testFilterApplicationOnHqlQueryWithImplicitSubqueryContainingPositionalParameter() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.beginTransaction();
 
 		final String queryString = "from Order o where ? in ( select sp.name from Salesperson sp )";
 
 		// first a control-group query
 		List result = session.createQuery( queryString ).setParameter( 0, "steve" ).list();
 		assertEquals( 2, result.size() );
 
 		// now lets enable filters on Order...
 		session.enableFilter( "fulfilledOrders" ).setParameter( "asOfDate", testData.lastMonth.getTime() );
 		result = session.createQuery( queryString ).setParameter( 0, "steve" ).list();
 		assertEquals( 1, result.size() );
 
 		// now, lets additionally enable filter on Salesperson.  First a valid one...
 		session.enableFilter( "regionlist" ).setParameterList( "regions", new String[] { "APAC" } );
 		result = session.createQuery( queryString ).setParameter( 0, "steve" ).list();
 		assertEquals( 1, result.size() );
 
 		// ... then a silly one...
 		session.enableFilter( "regionlist" ).setParameterList( "regions", new String[] { "gamma quadrant" } );
 		result = session.createQuery( queryString ).setParameter( 0, "steve" ).list();
 		assertEquals( 0, result.size() );
 
 		session.getTransaction().commit();
 		session.close();
 
 		testData.release();
 	}
 
 	@Test
 	public void testFilterApplicationOnHqlQueryWithImplicitSubqueryContainingNamedParameter() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.beginTransaction();
 
 		final String queryString = "from Order o where :salesPersonName in ( select sp.name from Salesperson sp )";
 
 		// first a control-group query
 		List result = session.createQuery( queryString ).setParameter( "salesPersonName", "steve" ).list();
 		assertEquals( 2, result.size() );
 
 		// now lets enable filters on Order...
 		session.enableFilter( "fulfilledOrders" ).setParameter( "asOfDate", testData.lastMonth.getTime() );
 		result = session.createQuery( queryString ).setParameter( "salesPersonName", "steve" ).list();
 		assertEquals( 1, result.size() );
 
 		// now, lets additionally enable filter on Salesperson.  First a valid one...
 		session.enableFilter( "regionlist" ).setParameterList( "regions", new String[] { "APAC" } );
 		result = session.createQuery( queryString ).setParameter( "salesPersonName", "steve" ).list();
 		assertEquals( 1, result.size() );
 
 		// ... then a silly one...
 		session.enableFilter( "regionlist" ).setParameterList( "regions", new String[] { "gamma quadrant" } );
 		result = session.createQuery( queryString ).setParameter( "salesPersonName", "steve" ).list();
 		assertEquals( 0, result.size() );
 
 		session.getTransaction().commit();
 		session.close();
 
 		testData.release();
 	}
 
 	@Test
 	public void testFiltersOnSimpleHqlDelete() {
 		Session session = openSession();
 		session.beginTransaction();
 		Salesperson sp = new Salesperson();
 		sp.setName( "steve" );
 		sp.setRegion( "NA" );
 		session.persist( sp );
 		Salesperson sp2 = new Salesperson();
 		sp2.setName( "john" );
 		sp2.setRegion( "APAC" );
 		session.persist( sp2 );
 		session.getTransaction().commit();
 		session.close();
 
 		session = openSession();
 		session.beginTransaction();
 		session.enableFilter( "region" ).setParameter( "region", "NA" );
 		int count = session.createQuery( "delete from Salesperson" ).executeUpdate();
 		assertEquals( 1, count );
 		session.delete( sp2 );
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Test
 	public void testFiltersOnMultiTableHqlDelete() {
 		Session session = openSession();
 		session.beginTransaction();
 		Salesperson sp = new Salesperson();
 		sp.setName( "steve" );
 		sp.setRegion( "NA" );
 		session.persist( sp );
 		Salesperson sp2 = new Salesperson();
 		sp2.setName( "john" );
 		sp2.setRegion( "APAC" );
 		session.persist( sp2 );
 		session.getTransaction().commit();
 		session.close();
 
 		session = openSession();
 		session.beginTransaction();
 		session.enableFilter( "region" ).setParameter( "region", "NA" );
 		int count = session.createQuery( "delete from Salesperson" ).executeUpdate();
 		assertEquals( 1, count );
 		session.delete( sp2 );
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Test
 	public void testGetFilters() {
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// Get() test
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         log.info("Starting get() filter tests (eager assoc. fetching).");
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "region" ).setParameter( "region", "APAC" );
 
         log.info("Performing get()...");
 		Salesperson salesperson = ( Salesperson ) session.get( Salesperson.class, testData.steveId );
 		assertNotNull( salesperson );
 		assertEquals( "Incorrect order count", 1, salesperson.getOrders().size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testOneToManyFilters() {
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// one-to-many loading tests
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         log.info("Starting one-to-many collection loader filter tests.");
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "seniorSalespersons" )
 		        .setParameter( "asOfDate", testData.lastMonth.getTime() );
 
         log.info("Performing load of Department...");
 		Department department = ( Department ) session.load( Department.class, testData.deptId );
 		Set salespersons = department.getSalespersons();
 		assertEquals( "Incorrect salesperson count", 1, salespersons.size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testInStyleFilterParameter() {
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// one-to-many loading tests
 		//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         log.info("Starting one-to-many collection loader filter tests.");
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "regionlist" )
 		        .setParameterList( "regions", new String[]{"LA", "APAC"} );
 
         log.debug("Performing query of Salespersons");
 		List salespersons = session.createQuery( "from Salesperson" ).list();
 		assertEquals( "Incorrect salesperson count", 1, salespersons.size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testManyToManyFilterOnCriteria() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "effectiveDate" ).setParameter( "asOfDate", new Date() );
 
 		Product prod = ( Product ) session.createCriteria( Product.class )
 		        .setResultTransformer( DistinctRootEntityResultTransformer.INSTANCE )
 		        .add( Restrictions.eq( "id", testData.prod1Id ) )
 		        .uniqueResult();
 
 		assertNotNull( prod );
 		assertEquals( "Incorrect Product.categories count for filter", 1, prod.getCategories().size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testManyToManyFilterOnLoad() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "effectiveDate" ).setParameter( "asOfDate", new Date() );
 
 		Product prod = ( Product ) session.get( Product.class, testData.prod1Id );
 
 		long initLoadCount = sessionFactory().getStatistics().getCollectionLoadCount();
 		long initFetchCount = sessionFactory().getStatistics().getCollectionFetchCount();
 
 		// should already have been initialized...
 		int size = prod.getCategories().size();
 		assertEquals( "Incorrect filtered collection count", 1, size );
 
 		long currLoadCount = sessionFactory().getStatistics().getCollectionLoadCount();
 		long currFetchCount = sessionFactory().getStatistics().getCollectionFetchCount();
 
 		assertTrue(
 		        "load with join fetch of many-to-many did not trigger join fetch",
 		        ( initLoadCount == currLoadCount ) && ( initFetchCount == currFetchCount )
 		);
 
 		// make sure we did not get back a collection of proxies
 		long initEntityLoadCount = sessionFactory().getStatistics().getEntityLoadCount();
 		Iterator itr = prod.getCategories().iterator();
 		while ( itr.hasNext() ) {
 			Category cat = ( Category ) itr.next();
 			System.out.println( " ===> " + cat.getName() );
 		}
 		long currEntityLoadCount = sessionFactory().getStatistics().getEntityLoadCount();
 
 		assertTrue(
 		        "load with join fetch of many-to-many did not trigger *complete* join fetch",
 		        ( initEntityLoadCount == currEntityLoadCount )
 		);
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testManyToManyOnCollectionLoadAfterHQL() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "effectiveDate" ).setParameter( "asOfDate", new Date() );
 
 		// Force the categories to not get initialized here
 		List result = session.createQuery( "from Product as p where p.id = :id" )
 		        .setLong( "id", testData.prod1Id )
 		        .list();
 		assertTrue( "No products returned from HQL", !result.isEmpty() );
 
 		Product prod = ( Product ) result.get( 0 );
 		assertNotNull( prod );
 		assertEquals( "Incorrect Product.categories count for filter on collection load", 1, prod.getCategories().size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testManyToManyFilterOnQuery() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 		session.enableFilter( "effectiveDate" ).setParameter( "asOfDate", new Date() );
 
 		List result = session.createQuery( "from Product p inner join fetch p.categories" ).list();
 		assertTrue( "No products returned from HQL many-to-many filter case", !result.isEmpty() );
 
 		Product prod = ( Product ) result.get( 0 );
 
 		assertNotNull( prod );
 		assertEquals( "Incorrect Product.categories count for filter with HQL", 1, prod.getCategories().size() );
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testManyToManyBase() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 
 		Product prod = ( Product ) session.get( Product.class, testData.prod1Id );
 
 		long initLoadCount = sessionFactory().getStatistics().getCollectionLoadCount();
 		long initFetchCount = sessionFactory().getStatistics().getCollectionFetchCount();
 
 		// should already have been initialized...
 		int size = prod.getCategories().size();
 		assertEquals( "Incorrect non-filtered collection count", 2, size );
 
 		long currLoadCount = sessionFactory().getStatistics().getCollectionLoadCount();
 		long currFetchCount = sessionFactory().getStatistics().getCollectionFetchCount();
 
 		assertTrue(
 		        "load with join fetch of many-to-many did not trigger join fetch",
 		        ( initLoadCount == currLoadCount ) && ( initFetchCount == currFetchCount )
 		);
 
 		// make sure we did not get back a collection of proxies
 		long initEntityLoadCount = sessionFactory().getStatistics().getEntityLoadCount();
 		Iterator itr = prod.getCategories().iterator();
 		while ( itr.hasNext() ) {
 			Category cat = ( Category ) itr.next();
 			System.out.println( " ===> " + cat.getName() );
 		}
 		long currEntityLoadCount = sessionFactory().getStatistics().getEntityLoadCount();
 
 		assertTrue(
 		        "load with join fetch of many-to-many did not trigger *complete* join fetch",
 		        ( initEntityLoadCount == currEntityLoadCount )
 		);
 
 		session.close();
 		testData.release();
 	}
 
 	@Test
 	public void testManyToManyBaseThruCriteria() {
 		TestData testData = new TestData();
 		testData.prepare();
 
 		Session session = openSession();
 
 		List result = session.createCriteria( Product.class )
 		        .add( Restrictions.eq( "id", testData.prod1Id ) )
 		        .list();
 
 		Product prod = ( Product ) result.get( 0 );
 
 		long initLoadCount = sessionFactory().getStatistics().getCollectionLoadCount();
 		long initFetchCount = sessionFactory().getStatistics().getCollectionFetchCount();
 
 		// should already have been initialized...
 		int size = prod.getCategories().size();
 		assertEquals( "Incorrect non-filtered collection count", 2, size );
 
 		long currLoadCount = sessionFactory().getStatistics().getCollectionLoadCount();
 		long currFetchCount = sessionFactory().getStatistics().getCollectionFetchCount();
 
 		assertTrue(
 		        "load with join fetch of many-to-many did not trigger join fetch",
 		        ( initLoadCount == currLoadCount ) && ( initFetchCount == currFetchCount )
 		);
 
 		// make sure we did not get back a collection of proxies
 		long initEntityLoadCount = sessionFactory().getStatistics().getEntityLoadCount();
 		Iterator itr = prod.getCategories().iterator();
 		while ( itr.hasNext() ) {
 			Category cat = ( Category ) itr.next();
 			System.out.println( " ===> " + cat.getName() );
 		}
 		long currEntityLoadCount = sessionFactory().getStatistics().getEntityLoadCount();
 
 		assertTrue(
 		        "load with join fetch of many-to-many did not trigger *complete* join fetch",
 		        ( initEntityLoadCount == currEntityLoadCount )
 		);
 
 		session.close();
 		testData.release();
 	}
 
 	private class TestData {
 		private Long steveId;
 		private Long deptId;
 		private Long prod1Id;
 		private Calendar lastMonth;
 		private Calendar nextMonth;
 		private Calendar sixMonthsAgo;
 		private Calendar fourMonthsAgo;
 
 		private List entitiesToCleanUp = new ArrayList();
 
 		private void prepare() {
 			Session session = openSession();
 			Transaction transaction = session.beginTransaction();
 
 			lastMonth = new GregorianCalendar();
 			lastMonth.add( Calendar.MONTH, -1 );
 
 			nextMonth = new GregorianCalendar();
 			nextMonth.add( Calendar.MONTH, 1 );
 
 			sixMonthsAgo = new GregorianCalendar();
 			sixMonthsAgo.add( Calendar.MONTH, -6 );
 
 			fourMonthsAgo = new GregorianCalendar();
 			fourMonthsAgo.add( Calendar.MONTH, -4 );
 
 			Department dept = new Department();
 			dept.setName( "Sales" );
 
 			session.save( dept );
 			deptId = dept.getId();
 			entitiesToCleanUp.add( dept );
 
 			Salesperson steve = new Salesperson();
 			steve.setName( "steve" );
 			steve.setRegion( "APAC" );
 			steve.setHireDate( sixMonthsAgo.getTime() );
 
 			steve.setDepartment( dept );
 			dept.getSalespersons().add( steve );
 
 			Salesperson max = new Salesperson();
 			max.setName( "max" );
 			max.setRegion( "EMEA" );
 			max.setHireDate( nextMonth.getTime() );
 
 			max.setDepartment( dept );
 			dept.getSalespersons().add( max );
 
 			session.save( steve );
 			session.save( max );
 			entitiesToCleanUp.add( steve );
 			entitiesToCleanUp.add( max );
 
 			steveId = steve.getId();
 
 			Category cat1 = new Category( "test cat 1", lastMonth.getTime(), nextMonth.getTime() );
 			Category cat2 = new Category( "test cat 2", sixMonthsAgo.getTime(), fourMonthsAgo.getTime() );
 
 			Product product1 = new Product();
 			product1.setName( "Acme Hair Gel" );
 			product1.setStockNumber( 123 );
 			product1.setWeightPounds( 0.25 );
 			product1.setEffectiveStartDate( lastMonth.getTime() );
 			product1.setEffectiveEndDate( nextMonth.getTime() );
 
 			product1.addCategory( cat1 );
 			product1.addCategory( cat2 );
 
 			session.save( product1 );
 			entitiesToCleanUp.add( product1 );
 			prod1Id = product1.getId();
 
 			Order order1 = new Order();
 			order1.setBuyer( "gavin" );
 			order1.setRegion( "APAC" );
 			order1.setPlacementDate( sixMonthsAgo.getTime() );
 			order1.setFulfillmentDate( fourMonthsAgo.getTime() );
 			order1.setSalesperson( steve );
 			order1.addLineItem( product1, 500 );
 
 			session.save( order1 );
 			entitiesToCleanUp.add( order1 );
 
 			Product product2 = new Product();
 			product2.setName( "Acme Super-Duper DTO Factory" );
 			product2.setStockNumber( 124 );
 			product1.setWeightPounds( 10.0 );
 			product2.setEffectiveStartDate( sixMonthsAgo.getTime() );
 			product2.setEffectiveEndDate( new Date() );
 
 			Category cat3 = new Category( "test cat 2", sixMonthsAgo.getTime(), new Date() );
 			product2.addCategory( cat3 );
 
 			session.save( product2 );
 			entitiesToCleanUp.add( product2 );
 
 			// An uncategorized product
 			Product product3 = new Product();
 			product3.setName( "Uncategorized product" );
 			session.save( product3 );
 			entitiesToCleanUp.add( product3 );
 
 			Order order2 = new Order();
 			order2.setBuyer( "christian" );
 			order2.setRegion( "EMEA" );
 			order2.setPlacementDate( lastMonth.getTime() );
 			order2.setSalesperson( steve );
 			order2.addLineItem( product2, -1 );
 
 			session.save( order2 );
 			entitiesToCleanUp.add( order2 );
 
 			transaction.commit();
 			session.close();
 		}
 
 		private void release() {
 			Session session = openSession();
 			Transaction transaction = session.beginTransaction();
 
 			Iterator itr = entitiesToCleanUp.iterator();
 			while ( itr.hasNext() ) {
 				session.delete( itr.next() );
 			}
 
 			transaction.commit();
 			session.close();
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/legacy/CacheTest.java b/hibernate-core/src/test/java/org/hibernate/test/legacy/CacheTest.java
index 0c7c1c2f43..8d95027816 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/legacy/CacheTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/legacy/CacheTest.java
@@ -1,159 +1,159 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.legacy;
 
-import org.hibernate.cache.Cache;
-import org.hibernate.cache.CacheConcurrencyStrategy;
-import org.hibernate.cache.CacheProvider;
-import org.hibernate.cache.HashtableCacheProvider;
-import org.hibernate.cache.ReadWriteCache;
-import org.hibernate.cache.access.SoftLock;
+import org.hibernate.cache.spi.Cache;
+import org.hibernate.cache.spi.CacheConcurrencyStrategy;
+import org.hibernate.cache.spi.CacheProvider;
+import org.hibernate.cache.internal.HashtableCacheProvider;
+import org.hibernate.cache.spi.ReadWriteCache;
+import org.hibernate.cache.spi.access.SoftLock;
 
 import org.junit.Test;
 
 import org.hibernate.testing.junit4.BaseUnitTestCase;
 
 import static org.junit.Assert.assertTrue;
 
 public class CacheTest extends BaseUnitTestCase {
 	@Test
 	public void testCaches() throws Exception {
 		doTestCache( new HashtableCacheProvider() );
 	}
 
 	public void doTestCache(CacheProvider cacheProvider) throws Exception {
 
 		Cache cache = cacheProvider.buildCache( String.class.getName(), System.getProperties() );
 
 		long longBefore = cache.nextTimestamp();
 
 		Thread.sleep( 15 );
 
 		long before = cache.nextTimestamp();
 
 		Thread.sleep( 15 );
 
 		//cache.setTimeout(1000);
 		CacheConcurrencyStrategy ccs = new ReadWriteCache();
 		ccs.setCache( cache );
 
 		// cache something
 
 		assertTrue( ccs.put( "foo", "foo", before, null, null, false ) );
 
 		Thread.sleep( 15 );
 
 		long after = cache.nextTimestamp();
 
 		assertTrue( ccs.get( "foo", longBefore ) == null );
 		assertTrue( ccs.get( "foo", after ).equals( "foo" ) );
 
 		assertTrue( !ccs.put( "foo", "foo", before, null, null, false ) );
 
 		// update it:
 
 		SoftLock lock = ccs.lock( "foo", null );
 
 		assertTrue( ccs.get( "foo", after ) == null );
 		assertTrue( ccs.get( "foo", longBefore ) == null );
 
 		assertTrue( !ccs.put( "foo", "foo", before, null, null, false ) );
 
 		Thread.sleep( 15 );
 
 		long whileLocked = cache.nextTimestamp();
 
 		assertTrue( !ccs.put( "foo", "foo", whileLocked, null, null, false ) );
 
 		Thread.sleep( 15 );
 
 		ccs.release( "foo", lock );
 
 		assertTrue( ccs.get( "foo", after ) == null );
 		assertTrue( ccs.get( "foo", longBefore ) == null );
 
 		assertTrue( !ccs.put( "foo", "bar", whileLocked, null, null, false ) );
 		assertTrue( !ccs.put( "foo", "bar", after, null, null, false ) );
 
 		Thread.sleep( 15 );
 
 		long longAfter = cache.nextTimestamp();
 
 		assertTrue( ccs.put( "foo", "baz", longAfter, null, null, false ) );
 
 		assertTrue( ccs.get( "foo", after ) == null );
 		assertTrue( ccs.get( "foo", whileLocked ) == null );
 
 		Thread.sleep( 15 );
 
 		long longLongAfter = cache.nextTimestamp();
 
 		assertTrue( ccs.get( "foo", longLongAfter ).equals( "baz" ) );
 
 		// update it again, with multiple locks:
 
 		SoftLock lock1 = ccs.lock( "foo", null );
 		SoftLock lock2 = ccs.lock( "foo", null );
 
 		assertTrue( ccs.get( "foo", longLongAfter ) == null );
 
 		Thread.sleep( 15 );
 
 		whileLocked = cache.nextTimestamp();
 
 		assertTrue( !ccs.put( "foo", "foo", whileLocked, null, null, false ) );
 
 		Thread.sleep( 15 );
 
 		ccs.release( "foo", lock2 );
 
 		Thread.sleep( 15 );
 
 		long betweenReleases = cache.nextTimestamp();
 
 		assertTrue( !ccs.put( "foo", "bar", betweenReleases, null, null, false ) );
 		assertTrue( ccs.get( "foo", betweenReleases ) == null );
 
 		Thread.sleep( 15 );
 
 		ccs.release( "foo", lock1 );
 
 		assertTrue( !ccs.put( "foo", "bar", whileLocked, null, null, false ) );
 
 		Thread.sleep( 15 );
 
 		longAfter = cache.nextTimestamp();
 
 		assertTrue( ccs.put( "foo", "baz", longAfter, null, null, false ) );
 		assertTrue( ccs.get( "foo", whileLocked ) == null );
 
 		Thread.sleep( 15 );
 
 		longLongAfter = cache.nextTimestamp();
 
 		assertTrue( ccs.get( "foo", longLongAfter ).equals( "baz" ) );
 
 	}
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/legacy/CustomPersister.java b/hibernate-core/src/test/java/org/hibernate/test/legacy/CustomPersister.java
index dcafa88897..e3d2d3d41d 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/legacy/CustomPersister.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/legacy/CustomPersister.java
@@ -1,674 +1,674 @@
 package org.hibernate.test.legacy;
 
 import java.io.Serializable;
 import java.util.Comparator;
 import java.util.Hashtable;
 import java.util.Map;
 
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
-import org.hibernate.cache.entry.CacheEntryStructure;
-import org.hibernate.cache.entry.UnstructuredCacheEntry;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.spi.entry.CacheEntryStructure;
+import org.hibernate.cache.spi.entry.UnstructuredCacheEntry;
 import org.hibernate.engine.CascadeStyle;
 import org.hibernate.engine.Mapping;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.TwoPhaseLoad;
 import org.hibernate.engine.ValueInclusion;
 import org.hibernate.event.EventSource;
 import org.hibernate.event.PostLoadEvent;
 import org.hibernate.event.PreLoadEvent;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.UUIDHexGenerator;
 import org.hibernate.internal.util.compare.EqualsHelper;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.sql.QuerySelect;
 import org.hibernate.sql.Select;
 import org.hibernate.tuple.entity.EntityMetamodel;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 
 public class CustomPersister implements EntityPersister {
 
 	private static final Hashtable INSTANCES = new Hashtable();
 	private static final IdentifierGenerator GENERATOR = new UUIDHexGenerator();
 
 	private SessionFactoryImplementor factory;
 
 	public CustomPersister(
 			PersistentClass model,
 			EntityRegionAccessStrategy cacheAccessStrategy,
 			SessionFactoryImplementor factory,
 			Mapping mapping) {
 		this.factory = factory;
 	}
 
 	public boolean hasLazyProperties() {
 		return false;
 	}
 
 	private void checkEntityMode(EntityMode entityMode) {
 		if ( EntityMode.POJO != entityMode ) {
 			throw new IllegalArgumentException( "Unhandled EntityMode : " + entityMode );
 		}
 	}
 
 	private void checkEntityMode(SessionImplementor session) {
 		checkEntityMode( session.getEntityMode() );
 	}
 
 	public boolean isInherited() {
 		return false;
 	}
 
 	public SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	public Class getMappedClass() {
 		return Custom.class;
 	}
 
 	public void postInstantiate() throws MappingException {}
 
 	public String getEntityName() {
 		return Custom.class.getName();
 	}
 
 	public boolean isSubclassEntityName(String entityName) {
 		return Custom.class.getName().equals(entityName);
 	}
 
 	public boolean hasProxy() {
 		return false;
 	}
 
 	public boolean hasCollections() {
 		return false;
 	}
 
 	public boolean hasCascades() {
 		return false;
 	}
 
 	public boolean isMutable() {
 		return true;
 	}
 
 	public boolean isSelectBeforeUpdateRequired() {
 		return false;
 	}
 
 	public boolean isIdentifierAssignedByInsert() {
 		return false;
 	}
 
 	public Boolean isTransient(Object object, SessionImplementor session) {
 		return new Boolean( ( (Custom) object ).id==null );
 	}
 
 	public Object[] getPropertyValuesToInsert(Object object, Map mergeMap, SessionImplementor session)
 	throws HibernateException {
 		return getPropertyValues( object, session.getEntityMode() );
 	}
 
 	public void processInsertGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session) {
 	}
 
 	public void processUpdateGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session) {
 	}
 
 	public void retrieveGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session) {
 		throw new UnsupportedOperationException();
 	}
 
 	public Class getMappedClass(EntityMode entityMode) {
 		checkEntityMode( entityMode );
 		return Custom.class;
 	}
 
 	public boolean implementsLifecycle(EntityMode entityMode) {
 		checkEntityMode( entityMode );
 		return false;
 	}
 
 	public boolean implementsValidatable(EntityMode entityMode) {
 		checkEntityMode( entityMode );
 		return false;
 	}
 
 	public Class getConcreteProxyClass(EntityMode entityMode) {
 		checkEntityMode( entityMode );
 		return Custom.class;
 	}
 
 	public void setPropertyValues(Object object, Object[] values, EntityMode entityMode) throws HibernateException {
 		checkEntityMode( entityMode );
 		setPropertyValue( object, 0, values[0], entityMode );
 	}
 
 	public void setPropertyValue(Object object, int i, Object value, EntityMode entityMode) throws HibernateException {
 		checkEntityMode( entityMode );
 		( (Custom) object ).setName( (String) value );
 	}
 
 	public Object[] getPropertyValues(Object object, EntityMode entityMode) throws HibernateException {
 		checkEntityMode( entityMode );
 		Custom c = (Custom) object;
 		return new Object[] { c.getName() };
 	}
 
 	public Object getPropertyValue(Object object, int i, EntityMode entityMode) throws HibernateException {
 		checkEntityMode( entityMode );
 		return ( (Custom) object ).getName();
 	}
 
 	public Object getPropertyValue(Object object, String propertyName, EntityMode entityMode) throws HibernateException {
 		checkEntityMode( entityMode );
 		return ( (Custom) object ).getName();
 	}
 
 	public Serializable getIdentifier(Object object, EntityMode entityMode) throws HibernateException {
 		checkEntityMode( entityMode );
 		return ( (Custom) object ).id;
 	}
 
 	public Serializable getIdentifier(Object entity, SessionImplementor session) {
 		checkEntityMode( session );
 		return ( (Custom) entity ).id;
 	}
 
 	public void setIdentifier(Object object, Serializable id, EntityMode entityMode) throws HibernateException {
 		checkEntityMode( entityMode );
 		( (Custom) object ).id = (String) id;
 	}
 
 	public void setIdentifier(Object entity, Serializable id, SessionImplementor session) {
 		checkEntityMode( session );
 		( (Custom) entity ).id = (String) id;
 	}
 
 	public Object getVersion(Object object, EntityMode entityMode) throws HibernateException {
 		checkEntityMode( entityMode );
 		return null;
 	}
 
 	public Object instantiate(Serializable id, EntityMode entityMode) throws HibernateException {
 		checkEntityMode( entityMode );
 		return instantiate( id );
 	}
 
 	private Object instantiate(Serializable id) {
 		Custom c = new Custom();
 		c.id = (String) id;
 		return c;
 	}
 
 	public Object instantiate(Serializable id, SessionImplementor session) {
 		checkEntityMode( session );
 		return instantiate( id );
 	}
 
 	public boolean isInstance(Object object, EntityMode entityMode) {
 		checkEntityMode( entityMode );
 		return object instanceof Custom;
 	}
 
 	public boolean hasUninitializedLazyProperties(Object object, EntityMode entityMode) {
 		checkEntityMode( entityMode );
 		return false;
 	}
 
 	public void resetIdentifier(Object entity, Serializable currentId, Object currentVersion, EntityMode entityMode) {
 		checkEntityMode( entityMode );
 		( ( Custom ) entity ).id = ( String ) currentId;
 	}
 
 	public void resetIdentifier(Object entity, Serializable currentId, Object currentVersion, SessionImplementor session) {
 		checkEntityMode( session );
 		( ( Custom ) entity ).id = ( String ) currentId;
 	}
 
 	public EntityPersister getSubclassEntityPersister(Object instance, SessionFactoryImplementor factory, EntityMode entityMode) {
 		checkEntityMode( entityMode );
 		return this;
 	}
 
 	public int[] findDirty(
 		Object[] x,
 		Object[] y,
 		Object owner,
 		SessionImplementor session
 	) throws HibernateException {
 		if ( !EqualsHelper.equals( x[0], y[0] ) ) {
 			return new int[] { 0 };
 		}
 		else {
 			return null;
 		}
 	}
 
 	public int[] findModified(
 		Object[] x,
 		Object[] y,
 		Object owner,
 		SessionImplementor session
 	) throws HibernateException {
 		if ( !EqualsHelper.equals( x[0], y[0] ) ) {
 			return new int[] { 0 };
 		}
 		else {
 			return null;
 		}
 	}
 
 	/**
 	 * @see EntityPersister#hasIdentifierProperty()
 	 */
 	public boolean hasIdentifierProperty() {
 		return true;
 	}
 
 	/**
 	 * @see EntityPersister#isVersioned()
 	 */
 	public boolean isVersioned() {
 		return false;
 	}
 
 	/**
 	 * @see EntityPersister#getVersionType()
 	 */
 	public VersionType getVersionType() {
 		return null;
 	}
 
 	/**
 	 * @see EntityPersister#getVersionProperty()
 	 */
 	public int getVersionProperty() {
 		return 0;
 	}
 
 	/**
 	 * @see EntityPersister#getIdentifierGenerator()
 	 */
 	public IdentifierGenerator getIdentifierGenerator()
 	throws HibernateException {
 		return GENERATOR;
 	}
 
 	/**
 	 * @see EntityPersister#load(Serializable, Object, org.hibernate.LockOptions , SessionImplementor)
 	 */
 	public Object load(
 		Serializable id,
 		Object optionalObject,
 		LockOptions lockOptions,
 		SessionImplementor session
 	) throws HibernateException {
 		return load(id, optionalObject, lockOptions.getLockMode(), session);
 	}
 
 	/**
 	 * @see EntityPersister#load(Serializable, Object, LockMode, SessionImplementor)
 	 */
 	public Object load(
 		Serializable id,
 		Object optionalObject,
 		LockMode lockMode,
 		SessionImplementor session
 	) throws HibernateException {
 
 		// fails when optional object is supplied
 
 		Custom clone = null;
 		Custom obj = (Custom) INSTANCES.get(id);
 		if (obj!=null) {
 			clone = (Custom) obj.clone();
 			TwoPhaseLoad.addUninitializedEntity(
 					session.generateEntityKey( id, this ),
 					clone,
 					this,
 					LockMode.NONE,
 					false,
 					session
 				);
 			TwoPhaseLoad.postHydrate(
 					this, id,
 					new String[] { obj.getName() },
 					null,
 					clone,
 					LockMode.NONE,
 					false,
 					session
 				);
 			TwoPhaseLoad.initializeEntity(
 					clone,
 					false,
 					session,
 					new PreLoadEvent( (EventSource) session ),
 					new PostLoadEvent( (EventSource) session )
 				);
 		}
 		return clone;
 	}
 
 	/**
 	 * @see EntityPersister#lock(Serializable, Object, Object, LockMode, SessionImplementor)
 	 */
 	public void lock(
 		Serializable id,
 		Object version,
 		Object object,
 		LockOptions lockOptions,
 		SessionImplementor session
 	) throws HibernateException {
 
 		throw new UnsupportedOperationException();
 	}
 
 	/**
 	 * @see EntityPersister#lock(Serializable, Object, Object, LockMode, SessionImplementor)
 	 */
 	public void lock(
 		Serializable id,
 		Object version,
 		Object object,
 		LockMode lockMode,
 		SessionImplementor session
 	) throws HibernateException {
 
 		throw new UnsupportedOperationException();
 	}
 
 	public void insert(
 		Serializable id,
 		Object[] fields,
 		Object object,
 		SessionImplementor session
 	) throws HibernateException {
 
 		INSTANCES.put(id, ( (Custom) object ).clone() );
 	}
 
 	public Serializable insert(Object[] fields, Object object, SessionImplementor session)
 	throws HibernateException {
 
 		throw new UnsupportedOperationException();
 	}
 
 	public void delete(
 		Serializable id,
 		Object version,
 		Object object,
 		SessionImplementor session
 	) throws HibernateException {
 
 		INSTANCES.remove(id);
 	}
 
 	/**
 	 * @see EntityPersister
 	 */
 	public void update(
 		Serializable id,
 		Object[] fields,
 		int[] dirtyFields,
 		boolean hasDirtyCollection,
 		Object[] oldFields,
 		Object oldVersion,
 		Object object,
 		Object rowId,
 		SessionImplementor session
 	) throws HibernateException {
 
 		INSTANCES.put( id, ( (Custom) object ).clone() );
 
 	}
 
 	private static final Type[] TYPES = new Type[] { StandardBasicTypes.STRING };
 	private static final String[] NAMES = new String[] { "name" };
 	private static final boolean[] MUTABILITY = new boolean[] { true };
 	private static final boolean[] GENERATION = new boolean[] { false };
 
 	/**
 	 * @see EntityPersister#getPropertyTypes()
 	 */
 	public Type[] getPropertyTypes() {
 		return TYPES;
 	}
 
 	/**
 	 * @see EntityPersister#getPropertyNames()
 	 */
 	public String[] getPropertyNames() {
 		return NAMES;
 	}
 
 	/**
 	 * @see EntityPersister#getPropertyCascadeStyles()
 	 */
 	public CascadeStyle[] getPropertyCascadeStyles() {
 		return null;
 	}
 
 	/**
 	 * @see EntityPersister#getIdentifierType()
 	 */
 	public Type getIdentifierType() {
 		return StandardBasicTypes.STRING;
 	}
 
 	/**
 	 * @see EntityPersister#getIdentifierPropertyName()
 	 */
 	public String getIdentifierPropertyName() {
 		return "id";
 	}
 
 	public boolean hasCache() {
 		return false;
 	}
 
 	public EntityRegionAccessStrategy getCacheAccessStrategy() {
 		return null;
 	}
 
 	public String getRootEntityName() {
 		return "CUSTOMS";
 	}
 
 	public Serializable[] getPropertySpaces() {
 		return new String[] { "CUSTOMS" };
 	}
 
 	public Serializable[] getQuerySpaces() {
 		return new String[] { "CUSTOMS" };
 	}
 
 	/**
 	 * @see EntityPersister#getClassMetadata()
 	 */
 	public ClassMetadata getClassMetadata() {
 		return null;
 	}
 
 	public boolean[] getPropertyUpdateability() {
 		return MUTABILITY;
 	}
 
 	public boolean[] getPropertyCheckability() {
 		return MUTABILITY;
 	}
 
 	/**
 	 * @see EntityPersister#getPropertyInsertability()
 	 */
 	public boolean[] getPropertyInsertability() {
 		return MUTABILITY;
 	}
 
 	public ValueInclusion[] getPropertyInsertGenerationInclusions() {
 		return new ValueInclusion[0];
 	}
 
 	public ValueInclusion[] getPropertyUpdateGenerationInclusions() {
 		return new ValueInclusion[0];
 	}
 
 
 	public boolean canExtractIdOutOfEntity() {
 		return true;
 	}
 
 	public boolean isBatchLoadable() {
 		return false;
 	}
 
 	public Type getPropertyType(String propertyName) {
 		throw new UnsupportedOperationException();
 	}
 
 	public Object getPropertyValue(Object object, String propertyName)
 		throws HibernateException {
 		throw new UnsupportedOperationException();
 	}
 
 	public Object createProxy(Serializable id, SessionImplementor session)
 		throws HibernateException {
 		throw new UnsupportedOperationException("no proxy for this class");
 	}
 
 	public Object getCurrentVersion(
 		Serializable id,
 		SessionImplementor session)
 		throws HibernateException {
 
 		return INSTANCES.get(id);
 	}
 
 	public Object forceVersionIncrement(Serializable id, Object currentVersion, SessionImplementor session)
 			throws HibernateException {
 		return null;
 	}
 
 	public EntityMode guessEntityMode(Object object) {
 		if ( !isInstance(object, EntityMode.POJO) ) {
 			return null;
 		}
 		else {
 			return EntityMode.POJO;
 		}
 	}
 
 	public boolean[] getPropertyNullability() {
 		return MUTABILITY;
 	}
 
 	public boolean isDynamic() {
 		return false;
 	}
 
 	public boolean isCacheInvalidationRequired() {
 		return false;
 	}
 
 	public void applyFilters(QuerySelect select, String alias, Map filters) {
 	}
 
 	public void applyFilters(Select select, String alias, Map filters) {
 	}
 
 
 	public void afterInitialize(Object entity, boolean fetched, SessionImplementor session) {
 	}
 
 	public void afterReassociate(Object entity, SessionImplementor session) {
 	}
 
 	public Object[] getDatabaseSnapshot(Serializable id, SessionImplementor session)
 	throws HibernateException {
 		return null;
 	}
 
 	public boolean[] getPropertyVersionability() {
 		return MUTABILITY;
 	}
 
 	public CacheEntryStructure getCacheEntryStructure() {
 		return new UnstructuredCacheEntry();
 	}
 
 	public boolean hasSubselectLoadableCollections() {
 		return false;
 	}
 
 	public int[] getNaturalIdentifierProperties() {
 		return null;
 	}
 
 	public Type[] getNaturalIdentifierTypes() {
 		return null;
 	}
 
 	public boolean hasNaturalIdentifier() {
 		return false;
 	}
 
 	public boolean hasMutableProperties() {
 		return false;
 	}
 
 	public boolean isInstrumented(EntityMode entityMode) {
 		return false;
 	}
 
 	public boolean hasInsertGeneratedProperties() {
 		return false;
 	}
 
 	public boolean hasUpdateGeneratedProperties() {
 		return false;
 	}
 
 	public boolean[] getPropertyLaziness() {
 		return null;
 	}
 
 	public boolean isLazyPropertiesCacheable() {
 		return true;
 	}
 
 	public boolean hasGeneratedProperties() {
 		return false;
 	}
 
 	public boolean isVersionPropertyGenerated() {
 		return false;
 	}
 
 	public String[] getOrphanRemovalOneToOnePaths() {
 		return null;
 	}
 
 	public Object[] getNaturalIdentifierSnapshot(Serializable id, SessionImplementor session) throws HibernateException {
 		return null;
 	}
 
 	public Comparator getVersionComparator() {
 		return null;
 	}
 
 	public EntityMetamodel getEntityMetamodel() {
 		return null;
 	}
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/multitenancy/schema/SchemaBasedMultiTenancyTest.java b/hibernate-core/src/test/java/org/hibernate/test/multitenancy/schema/SchemaBasedMultiTenancyTest.java
index 6e88c3fae3..fd675973e6 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/multitenancy/schema/SchemaBasedMultiTenancyTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/multitenancy/schema/SchemaBasedMultiTenancyTest.java
@@ -1,288 +1,288 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.multitenancy.schema;
 
 import java.sql.Connection;
 import java.sql.SQLException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MultiTenancyStrategy;
 import org.hibernate.Session;
-import org.hibernate.cache.HashtableCacheProvider;
+import org.hibernate.cache.internal.HashtableCacheProvider;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.service.ServiceRegistryBuilder;
 import org.hibernate.service.jdbc.connections.internal.DriverManagerConnectionProviderImpl;
 import org.hibernate.service.jdbc.connections.spi.AbstractMultiTenantConnectionProvider;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.service.jdbc.connections.spi.MultiTenantConnectionProvider;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.tool.hbm2ddl.ConnectionHelper;
 import org.hibernate.tool.hbm2ddl.SchemaExport;
 
 import org.junit.After;
 import org.junit.Assert;
 import org.junit.Before;
 import org.junit.Test;
 
 import org.hibernate.testing.env.ConnectionProviderBuilder;
 import org.hibernate.testing.junit4.BaseUnitTestCase;
 
 /**
  * @author Steve Ebersole
  */
 public class SchemaBasedMultiTenancyTest extends BaseUnitTestCase {
 	private DriverManagerConnectionProviderImpl acmeProvider;
 	private DriverManagerConnectionProviderImpl jbossProvider;
 
 	private ServiceRegistryImplementor serviceRegistry;
 
 	private SessionFactoryImplementor sessionFactory;
 
 	@Before
 	public void setUp() {
 		acmeProvider = ConnectionProviderBuilder.buildConnectionProvider( "acme" );
 		jbossProvider = ConnectionProviderBuilder.buildConnectionProvider( "jboss" );
 		AbstractMultiTenantConnectionProvider multiTenantConnectionProvider = new AbstractMultiTenantConnectionProvider() {
 			@Override
 			protected ConnectionProvider getAnyConnectionProvider() {
 				return acmeProvider;
 			}
 
 			@Override
 			protected ConnectionProvider selectConnectionProvider(String tenantIdentifier) {
 				if ( "acme".equals( tenantIdentifier ) ) {
 					return acmeProvider;
 				}
 				else if ( "jboss".equals( tenantIdentifier ) ) {
 					return jbossProvider;
 				}
 				throw new HibernateException( "Unknown tenant identifier" );
 			}
 		};
 
 		Configuration cfg = new Configuration();
 		cfg.getProperties().put( Environment.MULTI_TENANT, MultiTenancyStrategy.DATABASE );
 		cfg.setProperty( Environment.CACHE_PROVIDER, HashtableCacheProvider.class.getName() );
 		cfg.setProperty( Environment.GENERATE_STATISTICS, "true" );
 		cfg.addAnnotatedClass( Customer.class );
 
 		cfg.buildMappings();
 		RootClass meta = (RootClass) cfg.getClassMapping( Customer.class.getName() );
 		meta.setCacheConcurrencyStrategy( "read-write" );
 
 		// do the acme export
 		new SchemaExport(
 				new ConnectionHelper() {
 					private Connection connection;
 					@Override
 					public void prepare(boolean needsAutoCommit) throws SQLException {
 						connection = acmeProvider.getConnection();
 					}
 
 					@Override
 					public Connection getConnection() throws SQLException {
 						return connection;
 					}
 
 					@Override
 					public void release() throws SQLException {
 						acmeProvider.closeConnection( connection );
 					}
 				},
 				cfg.generateDropSchemaScript( ConnectionProviderBuilder.getCorrespondingDialect() ),
 				cfg.generateSchemaCreationScript( ConnectionProviderBuilder.getCorrespondingDialect() )
 		).execute(		 // so stupid...
 						   false,	 // do not script the export (write it to file)
 						   true,	 // do run it against the database
 						   false,	 // do not *just* perform the drop
 						   false	// do not *just* perform the create
 		);
 
 		// do the jboss export
 		new SchemaExport(
 				new ConnectionHelper() {
 					private Connection connection;
 					@Override
 					public void prepare(boolean needsAutoCommit) throws SQLException {
 						connection = jbossProvider.getConnection();
 					}
 
 					@Override
 					public Connection getConnection() throws SQLException {
 						return connection;
 					}
 
 					@Override
 					public void release() throws SQLException {
 						jbossProvider.closeConnection( connection );
 					}
 				},
 				cfg.generateDropSchemaScript( ConnectionProviderBuilder.getCorrespondingDialect() ),
 				cfg.generateSchemaCreationScript( ConnectionProviderBuilder.getCorrespondingDialect() )
 		).execute( 		// so stupid...
 				false, 	// do not script the export (write it to file)
 				true, 	// do run it against the database
 				false, 	// do not *just* perform the drop
 				false	// do not *just* perform the create
 		);
 
 		serviceRegistry = (ServiceRegistryImplementor) new ServiceRegistryBuilder( cfg.getProperties() )
 				.addService( MultiTenantConnectionProvider.class, multiTenantConnectionProvider )
 				.buildServiceRegistry();
 
 		sessionFactory = (SessionFactoryImplementor) cfg.buildSessionFactory( serviceRegistry );
 	}
 
 	@After
 	public void tearDown() {
 		if ( sessionFactory != null ) {
 			sessionFactory.close();
 		}
 		if ( serviceRegistry != null ) {
 			serviceRegistry.destroy();
 		}
 		if ( jbossProvider != null ) {
 			jbossProvider.stop();
 		}
 		if ( acmeProvider != null ) {
 			acmeProvider.stop();
 		}
 	}
 
 	@Test
 	public void testBasicExpectedBehavior() {
 		Session session = sessionFactory.withOptions().tenantIdentifier( "jboss" ).openSession();
 		session.beginTransaction();
 		Customer steve = new Customer( 1L, "steve" );
 		session.save( steve );
 		session.getTransaction().commit();
 		session.close();
 
 		session = sessionFactory.withOptions().tenantIdentifier( "acme" ).openSession();
 		try {
 			session.beginTransaction();
 			Customer check = (Customer) session.get( Customer.class, steve.getId() );
 			Assert.assertNull( "tenancy not properly isolated", check );
 		}
 		finally {
 			session.getTransaction().commit();
 			session.close();
 		}
 
 		session = sessionFactory.withOptions().tenantIdentifier( "jboss" ).openSession();
 		session.beginTransaction();
 		session.delete( steve );
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Test
 	public void testSameIdentifiers() {
 		// create a customer 'steve' in jboss
 		Session session = sessionFactory.withOptions().tenantIdentifier( "jboss" ).openSession();
 		session.beginTransaction();
 		Customer steve = new Customer( 1L, "steve" );
 		session.save( steve );
 		session.getTransaction().commit();
 		session.close();
 
 		// now, create a customer 'john' in acme
 		session = sessionFactory.withOptions().tenantIdentifier( "acme" ).openSession();
 		session.beginTransaction();
 		Customer john = new Customer( 1L, "john" );
 		session.save( john );
 		session.getTransaction().commit();
 		session.close();
 
 		sessionFactory.getStatisticsImplementor().clear();
 
 		// make sure we get the correct people back, from cache
 		// first, jboss
 		{
 			session = sessionFactory.withOptions().tenantIdentifier( "jboss" ).openSession();
 			session.beginTransaction();
 			Customer customer = (Customer) session.load( Customer.class, 1L );
 			Assert.assertEquals( "steve", customer.getName() );
 			// also, make sure this came from second level
 			Assert.assertEquals( 1, sessionFactory.getStatisticsImplementor().getSecondLevelCacheHitCount() );
 			session.getTransaction().commit();
 			session.close();
 		}
 		sessionFactory.getStatisticsImplementor().clear();
 		// then, acme
 		{
 			session = sessionFactory.withOptions().tenantIdentifier( "acme" ).openSession();
 			session.beginTransaction();
 			Customer customer = (Customer) session.load( Customer.class, 1L );
 			Assert.assertEquals( "john", customer.getName() );
 			// also, make sure this came from second level
 			Assert.assertEquals( 1, sessionFactory.getStatisticsImplementor().getSecondLevelCacheHitCount() );
 			session.getTransaction().commit();
 			session.close();
 		}
 
 		// make sure the same works from datastore too
 		sessionFactory.getStatisticsImplementor().clear();
 		sessionFactory.getCache().evictEntityRegions();
 		// first jboss
 		{
 			session = sessionFactory.withOptions().tenantIdentifier( "jboss" ).openSession();
 			session.beginTransaction();
 			Customer customer = (Customer) session.load( Customer.class, 1L );
 			Assert.assertEquals( "steve", customer.getName() );
 			// also, make sure this came from second level
 			Assert.assertEquals( 0, sessionFactory.getStatisticsImplementor().getSecondLevelCacheHitCount() );
 			session.getTransaction().commit();
 			session.close();
 		}
 		sessionFactory.getStatisticsImplementor().clear();
 		// then, acme
 		{
 			session = sessionFactory.withOptions().tenantIdentifier( "acme" ).openSession();
 			session.beginTransaction();
 			Customer customer = (Customer) session.load( Customer.class, 1L );
 			Assert.assertEquals( "john", customer.getName() );
 			// also, make sure this came from second level
 			Assert.assertEquals( 0, sessionFactory.getStatisticsImplementor().getSecondLevelCacheHitCount() );
 			session.getTransaction().commit();
 			session.close();
 		}
 
 		session = sessionFactory.withOptions().tenantIdentifier( "jboss" ).openSession();
 		session.beginTransaction();
 		session.delete( steve );
 		session.getTransaction().commit();
 		session.close();
 
 		session = sessionFactory.withOptions().tenantIdentifier( "acme" ).openSession();
 		session.beginTransaction();
 		session.delete( john );
 		session.getTransaction().commit();
 		session.close();
 	}
 
 }
diff --git a/hibernate-core/src/test/resources/hibernate.properties b/hibernate-core/src/test/resources/hibernate.properties
index 23a0730c6f..721eef9ff8 100644
--- a/hibernate-core/src/test/resources/hibernate.properties
+++ b/hibernate-core/src/test/resources/hibernate.properties
@@ -1,36 +1,36 @@
 #
 # Hibernate, Relational Persistence for Idiomatic Java
 #
 # Copyright (c) 2010, Red Hat Inc. or third-party contributors as
 # indicated by the @author tags or express copyright attribution
 # statements applied by the authors.  All third-party contributions are
 # distributed under license by Red Hat Inc.
 #
 # This copyrighted material is made available to anyone wishing to use, modify,
 # copy, or redistribute it subject to the terms and conditions of the GNU
 # Lesser General Public License, as published by the Free Software Foundation.
 #
 # This program is distributed in the hope that it will be useful,
 # but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
 # or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
 # for more details.
 #
 # You should have received a copy of the GNU Lesser General Public License
 # along with this distribution; if not, write to:
 # Free Software Foundation, Inc.
 # 51 Franklin Street, Fifth Floor
 # Boston, MA  02110-1301  USA
 #
 hibernate.dialect org.hibernate.dialect.H2Dialect
 hibernate.connection.driver_class org.h2.Driver
 hibernate.connection.url jdbc:h2:mem:db1;DB_CLOSE_DELAY=-1;MVCC=TRUE
 hibernate.connection.username sa
 
 hibernate.connection.pool_size 5
 
 hibernate.show_sql true
 
 hibernate.max_fetch_depth 5
 
 hibernate.cache.region_prefix hibernate.test
-hibernate.cache.provider_class org.hibernate.cache.HashtableCacheProvider
+hibernate.cache.provider_class org.hibernate.cache.internal.HashtableCacheProvider
diff --git a/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/AbstractEhCacheRegionFactory.java b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/AbstractEhCacheRegionFactory.java
index fb4b67b2d3..742ca16d68 100644
--- a/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/AbstractEhCacheRegionFactory.java
+++ b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/AbstractEhCacheRegionFactory.java
@@ -1,117 +1,117 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.cache.internal;
+
 import java.util.Properties;
 
-import org.hibernate.cache.CacheDataDescription;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.CollectionRegion;
-import org.hibernate.cache.EntityRegion;
-import org.hibernate.cache.QueryResultsRegion;
-import org.hibernate.cache.RegionFactory;
-import org.hibernate.cache.TimestampsRegion;
-import org.hibernate.cache.access.AccessType;
+import org.hibernate.cache.spi.CacheDataDescription;
+import org.hibernate.cache.spi.CollectionRegion;
+import org.hibernate.cache.spi.EntityRegion;
+import org.hibernate.cache.spi.QueryResultsRegion;
+import org.hibernate.cache.spi.RegionFactory;
+import org.hibernate.cache.spi.TimestampsRegion;
+import org.hibernate.cache.spi.access.AccessType;
 import org.hibernate.cfg.Settings;
 
 /**
- * Abstract class that will delegate all calls to org.hibernate.cache.RegionFactory to the instance it wraps.
+ * Abstract class that will delegate all calls to org.hibernate.cache.spi.RegionFactory to the instance it wraps.
  * This abstracts the Singleton CacheManager construct of Ehcache
  *
  * @author Alex Snaps
  */
 class AbstractEhCacheRegionFactory implements RegionFactory {
 
 	private final RegionFactory underlyingRegionFactory;
 
 	/**
 	 * {@inheritDoc}
 	 */
 	protected AbstractEhCacheRegionFactory(RegionFactory regionFactory) {
 		underlyingRegionFactory = regionFactory;
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final void start(final Settings settings, final Properties properties) throws CacheException {
 		underlyingRegionFactory.start(settings, properties);
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final void stop() {
 		underlyingRegionFactory.stop();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final boolean isMinimalPutsEnabledByDefault() {
 		return underlyingRegionFactory.isMinimalPutsEnabledByDefault();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final AccessType getDefaultAccessType() {
 		return underlyingRegionFactory.getDefaultAccessType();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final long nextTimestamp() {
 		return underlyingRegionFactory.nextTimestamp();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final EntityRegion buildEntityRegion(final String regionName, final Properties properties, final CacheDataDescription metadata) throws CacheException {
 		return underlyingRegionFactory.buildEntityRegion(regionName, properties, metadata);
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final CollectionRegion buildCollectionRegion(final String regionName, final Properties properties, final CacheDataDescription metadata) throws CacheException {
 		return underlyingRegionFactory.buildCollectionRegion(regionName, properties, metadata);
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final QueryResultsRegion buildQueryResultsRegion(final String regionName, final Properties properties) throws CacheException {
 		return underlyingRegionFactory.buildQueryResultsRegion(regionName, properties);
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public final TimestampsRegion buildTimestampsRegion(final String regionName, final Properties properties) throws CacheException {
 		return underlyingRegionFactory.buildTimestampsRegion(regionName, properties);
 	}
 }
diff --git a/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCache.java b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCache.java
index af550b9c0f..cf8173f459 100644
--- a/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCache.java
+++ b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCache.java
@@ -1,274 +1,274 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. ¬†All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cache.internal;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 import net.sf.ehcache.CacheManager;
 import net.sf.ehcache.Element;
 import org.jboss.logging.Logger;
 
-import org.hibernate.cache.Cache;
+import org.hibernate.cache.spi.Cache;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.Timestamper;
 
 /**
  * EHCache plugin for Hibernate
  * <p/>
  * EHCache uses a {@link net.sf.ehcache.store.MemoryStore} and a
  * {@link net.sf.ehcache.store.DiskStore}.
  * The {@link net.sf.ehcache.store.DiskStore} requires that both keys and values be {@link java.io.Serializable}.
  * However the MemoryStore does not and in ehcache-1.2 nonSerializable Objects are permitted. They are discarded
  * if an attempt it made to overflow them to Disk or to replicate them to remote cache peers.
  *
  * @author Greg Luck
  * @author Emmanuel Bernard
  */
+@Deprecated
 public class EhCache implements Cache {
 
     private static final EhCacheMessageLogger LOG = Logger.getMessageLogger(EhCacheMessageLogger.class, EhCache.class.getName());
 
 	private static final int SIXTY_THOUSAND_MS = 60000;
 
 	private net.sf.ehcache.Ehcache cache;
 
 	/**
 	 * Creates a new Hibernate pluggable cache based on a cache name.
 	 * <p/>
 	 *
 	 * @param cache The underlying EhCache instance to use.
 	 */
 	public EhCache(net.sf.ehcache.Ehcache cache) {
 		this.cache = cache;
 	}
 
 	/**
 	 * Gets a value of an element which matches the given key.
 	 *
 	 * @param key the key of the element to return.
 	 * @return The value placed into the cache with an earlier put, or null if not found or expired
 	 * @throws org.hibernate.cache.CacheException
 	 */
 	public Object get(Object key) throws CacheException {
 		try {
             LOG.debugf("Key: %s", key);
             if (key == null) return null;
             Element element = cache.get(key);
             if (element == null) {
                 LOG.debugf("Element for %s is null", key);
 				return null;
 			}
             return element.getObjectValue();
 		}
 		catch (net.sf.ehcache.CacheException e) {
 			throw new CacheException( e );
 		}
 	}
 
 	public Object read(Object key) throws CacheException {
 		return get( key );
 	}
 
 
 	/**
 	 * Puts an object into the cache.
 	 *
 	 * @param key   a key
 	 * @param value a value
 	 * @throws CacheException if the {@link CacheManager}
 	 *                        is shutdown or another {@link Exception} occurs.
 	 */
 	public void update(Object key, Object value) throws CacheException {
 		put( key, value );
 	}
 
 	/**
 	 * Puts an object into the cache.
 	 *
 	 * @param key   a key
 	 * @param value a value
 	 * @throws CacheException if the {@link CacheManager}
 	 *                        is shutdown or another {@link Exception} occurs.
 	 */
 	public void put(Object key, Object value) throws CacheException {
 		try {
 			Element element = new Element( key, value );
 			cache.put( element );
 		}
 		catch (IllegalArgumentException e) {
 			throw new CacheException( e );
 		}
 		catch (IllegalStateException e) {
 			throw new CacheException( e );
 		}
 		catch (net.sf.ehcache.CacheException e) {
 			throw new CacheException( e );
 		}
 
 	}
 
 	/**
 	 * Removes the element which matches the key.
 	 * <p/>
 	 * If no element matches, nothing is removed and no Exception is thrown.
 	 *
 	 * @param key the key of the element to remove
 	 * @throws CacheException
 	 */
 	public void remove(Object key) throws CacheException {
 		try {
 			cache.remove( key );
 		}
 		catch (ClassCastException e) {
 			throw new CacheException( e );
 		}
 		catch (IllegalStateException e) {
 			throw new CacheException( e );
 		}
 		catch (net.sf.ehcache.CacheException e) {
 			throw new CacheException( e );
 		}
 	}
 
 	/**
 	 * Remove all elements in the cache, but leave the cache
 	 * in a useable state.
 	 *
 	 * @throws CacheException
 	 */
 	public void clear() throws CacheException {
 		try {
 			cache.removeAll();
 		}
 		catch (IllegalStateException e) {
 			throw new CacheException( e );
 		}
 		catch (net.sf.ehcache.CacheException e) {
 			throw new CacheException( e );
 		}
 	}
 
 	/**
 	 * Remove the cache and make it unuseable.
 	 *
 	 * @throws CacheException
 	 */
 	public void destroy() throws CacheException {
 		try {
 			cache.getCacheManager().removeCache( cache.getName() );
 		}
 		catch (IllegalStateException e) {
 			throw new CacheException( e );
 		}
 		catch (net.sf.ehcache.CacheException e) {
 			throw new CacheException( e );
 		}
 	}
 
 	/**
 	 * Calls to this method should perform there own synchronization.
 	 * It is provided for distributed caches. Because EHCache is not distributed
 	 * this method does nothing.
 	 */
 	public void lock(Object key) throws CacheException {
 	}
 
 	/**
 	 * Calls to this method should perform there own synchronization.
 	 * It is provided for distributed caches. Because EHCache is not distributed
 	 * this method does nothing.
 	 */
 	public void unlock(Object key) throws CacheException {
 	}
 
 	/**
 	 * Gets the next timestamp;
 	 */
 	public long nextTimestamp() {
 		return Timestamper.next();
 	}
 
 	/**
 	 * Returns the lock timeout for this cache.
 	 */
 	public int getTimeout() {
 		// 60 second lock timeout
 		return Timestamper.ONE_MS * SIXTY_THOUSAND_MS;
 	}
 
 	public String getRegionName() {
 		return cache.getName();
 	}
 
 	/**
 	 * Warning: This method can be very expensive to run. Allow approximately 1 second
 	 * per 1MB of entries. Running this method could create liveness problems
 	 * because the object lock is held for a long period
 	 * <p/>
 	 *
 	 * @return the approximate size of memory ehcache is using for the MemoryStore for this cache
 	 */
 	public long getSizeInMemory() {
 		try {
 			return cache.calculateInMemorySize();
 		}
 		catch (Throwable t) {
 			return -1;
 		}
 	}
 
 	public long getElementCountInMemory() {
 		try {
 			return cache.getMemoryStoreSize();
 		}
 		catch (net.sf.ehcache.CacheException ce) {
 			throw new CacheException( ce );
 		}
 	}
 
 	public long getElementCountOnDisk() {
 		return cache.getDiskStoreSize();
 	}
 
 	public Map toMap() {
 		try {
 			Map result = new HashMap();
 			Iterator iter = cache.getKeys().iterator();
 			while ( iter.hasNext() ) {
 				Object key = iter.next();
 				result.put( key, cache.get( key ).getObjectValue() );
 			}
 			return result;
 		}
 		catch (Exception e) {
 			throw new CacheException( e );
 		}
 	}
 
 	@Override
     public String toString() {
 		return "EHCache(" + getRegionName() + ')';
 	}
 
 }
\ No newline at end of file
diff --git a/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCacheProvider.java b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCacheProvider.java
index 2f217578d0..5e5e367a28 100644
--- a/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCacheProvider.java
+++ b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCacheProvider.java
@@ -1,171 +1,171 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2007, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
- * statements applied by the authors. ¬†All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cache.internal;
 
 import java.net.URL;
 import java.util.Properties;
 import net.sf.ehcache.CacheManager;
 
-import org.hibernate.cache.Cache;
+import org.hibernate.cache.spi.Cache;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.CacheProvider;
-import org.hibernate.cache.Timestamper;
+import org.hibernate.cache.spi.CacheProvider;
 import org.hibernate.cfg.Environment;
 import org.hibernate.internal.util.ConfigHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.jboss.logging.Logger;
 
 /**
  * Cache Provider plugin for Hibernate
  *
  * Use <code>hibernate.cache.provider_class=org.hibernate.cache.internal.EhCacheProvider</code>
  * in Hibernate 3.x or later
  *
  * Taken from EhCache 0.9 distribution
  * @author Greg Luck
  * @author Emmanuel Bernard
  */
 /**
  * Cache Provider plugin for ehcache-1.2. New in this provider are ehcache support for multiple
  * Hibernate session factories, each with its own ehcache configuration, and non Serializable keys and values.
  * Ehcache-1.2 also has many other features such as cluster support and listeners, which can be used seamlessly simply
  * by configurion in ehcache.xml.
  * <p/>
  * Use <code>hibernate.cache.provider_class=org.hibernate.cache.internal.EhCacheProvider</code> in the Hibernate configuration
  * to enable this provider for Hibernate's second level cache.
  * <p/>
  * When configuring multiple ehcache CacheManagers, as you would where you have multiple Hibernate Configurations and
  * multiple SessionFactories, specify in each Hibernate configuration the ehcache configuration using
  * the property <code>hibernate.cache.provider_configuration_file_resource_path</code> An example to set an ehcache configuration
  * called ehcache-2.xml would be <code>hibernate.cache.provider_configuration_file_resource_path=/ehcache-2.xml</code>. If the leading
  * slash is not there one will be added. The configuration file will be looked for in the root of the classpath.
  * <p/>
  * Updated for ehcache-1.2. Note this provider requires ehcache-1.2.jar. Make sure ehcache-1.1.jar or earlier
  * is not in the classpath or it will not work.
  * <p/>
  * See http://ehcache.sf.net for documentation on ehcache
  * <p/>
  *
  * @author Greg Luck
  * @author Emmanuel Bernard
  */
+@Deprecated
 public class EhCacheProvider implements CacheProvider {
 
     private static final EhCacheMessageLogger LOG = Logger.getMessageLogger(EhCacheMessageLogger.class, EhCacheProvider.class.getName());
 
 	private CacheManager manager;
 
     /**
      * Builds a Cache.
      * <p>
      * Even though this method provides properties, they are not used.
      * Properties for EHCache are specified in the ehcache.xml file.
      * Configuration will be read from ehcache.xml for a cache declaration
      * where the name attribute matches the name parameter in this builder.
      *
      * @param name the name of the cache. Must match a cache configured in ehcache.xml
      * @param properties not used
      * @return a newly built cache will be built and initialised
      * @throws org.hibernate.cache.CacheException inter alia, if a cache of the same name already exists
      */
     public Cache buildCache(String name, Properties properties) throws CacheException {
 	    try {
             net.sf.ehcache.Cache cache = manager.getCache(name);
             if (cache == null) {
                 LOG.unableToFindConfiguration(name);
                 manager.addCache(name);
                 cache = manager.getCache(name);
                 LOG.debugf("Started EHCache region: %s", name);
             }
             return new EhCache(cache);
 	    }
         catch (net.sf.ehcache.CacheException e) {
             throw new CacheException(e);
         }
     }
 
     /**
      * Returns the next timestamp.
      */
     public long nextTimestamp() {
         return Timestamper.next();
     }
 
 	/**
 	 * Callback to perform any necessary initialization of the underlying cache implementation
 	 * during SessionFactory construction.
 	 *
 	 * @param properties current configuration settings.
 	 */
 	public void start(Properties properties) throws CacheException {
 		if (manager != null) {
             LOG.attemptToRestartAlreadyStartedEhCacheProvider();
             return;
         }
         try {
             String configurationResourceName = null;
             if (properties != null) {
                 configurationResourceName = (String) properties.get( Environment.CACHE_PROVIDER_CONFIG );
             }
             if ( StringHelper.isEmpty( configurationResourceName ) ) {
                 manager = new CacheManager();
             } else {
                 URL url = loadResource(configurationResourceName);
                 manager = new CacheManager(url);
             }
         } catch (net.sf.ehcache.CacheException e) {
 			//yukky! Don't you have subclasses for that!
 			//TODO race conditions can happen here
 			if (e.getMessage().startsWith("Cannot parseConfiguration CacheManager. Attempt to create a new instance of " +
                     "CacheManager using the diskStorePath")) {
                 throw new CacheException("Attempt to restart an already started EhCacheProvider. Use sessionFactory.close() " +
                     " between repeated calls to buildSessionFactory. Consider using net.sf.ehcache.hibernate.SingletonEhCacheProvider."
 						, e );
             }
             throw e;
         }
 	}
 
 	private URL loadResource(String configurationResourceName) {
 		URL url = ConfigHelper.locateConfig( configurationResourceName );
         LOG.debugf("Creating EhCacheProvider from a specified resource: %s Resolved to URL: %s", configurationResourceName, url);
         return url;
     }
 
 	/**
 	 * Callback to perform any necessary cleanup of the underlying cache implementation
 	 * during SessionFactory.close().
 	 */
 	public void stop() {
 		if (manager != null) {
             manager.shutdown();
             manager = null;
         }
 	}
 
 	public boolean isMinimalPutsEnabledByDefault() {
 		return false;
 	}
 
 }
diff --git a/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCacheRegionFactory.java b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCacheRegionFactory.java
index b7894326ed..c3607e80b8 100644
--- a/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCacheRegionFactory.java
+++ b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/EhCacheRegionFactory.java
@@ -1,40 +1,40 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.cache.internal;
+
 import java.util.Properties;
 
 /**
  * Thin wrapper class around the within Ehcache-core packaged EhCacheRegionFactory.
  * It directly delegates to the wrapped instance, enabling users to upgrade Ehcache-core versions
  * by simply dropping in the new jar.
  *
  * @author Alex Snaps
  */
 public final class EhCacheRegionFactory extends AbstractEhCacheRegionFactory {
 
 	public EhCacheRegionFactory(Properties properties) {
 		super(new net.sf.ehcache.hibernate.EhCacheRegionFactory(properties));
 	}
 }
diff --git a/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/SingletonEhCacheProvider.java b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/SingletonEhCacheProvider.java
index 5f67afbf03..86eec961ed 100644
--- a/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/SingletonEhCacheProvider.java
+++ b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/SingletonEhCacheProvider.java
@@ -1,185 +1,185 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.cache.internal;
 import java.net.URL;
 import java.util.Properties;
 import net.sf.ehcache.CacheManager;
 import net.sf.ehcache.util.ClassLoaderUtil;
 import org.jboss.logging.Logger;
 import org.jboss.logging.Logger.Level;
 
-import org.hibernate.cache.Cache;
+import org.hibernate.cache.spi.Cache;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.CacheProvider;
-import org.hibernate.cache.Timestamper;
+import org.hibernate.cache.spi.CacheProvider;
 
 /**
  * Singleton cache Provider plugin for Hibernate 3.2 and ehcache-1.2. New in this provider is support for
  * non Serializable keys and values. This provider works as a Singleton. No matter how many Hibernate Configurations
  * you have, only one ehcache CacheManager is used. See EhCacheProvider for a non-singleton implementation.
  * <p/>
  * Ehcache-1.2 also has many other features such as cluster support and listeners, which can be used seamlessly simply
  * by configurion in ehcache.xml.
  * <p/>
  * Use <code>hibernate.cache.provider_class=net.sf.ehcache.hibernate.SingletonEhCacheProvider</code> in the Hibernate configuration
  * to enable this provider for Hibernate's second level cache.
  * <p/>
  * Updated for ehcache-1.2. Note this provider requires ehcache-1.2.jar. Make sure ehcache-1.1.jar or earlier
  * is not in the classpath or it will not work.
  * <p/>
  * See http://ehcache.sf.net for documentation on ehcache
  * <p/>
  *
  * @author Greg Luck
  * @author Emmanuel Bernard
  * @version $Id: SingletonEhCacheProvider.java 744 2008-08-16 20:10:49Z gregluck $
  */
+@Deprecated
 public final class SingletonEhCacheProvider implements CacheProvider {
 
 	/**
 	 * The Hibernate system property specifying the location of the ehcache configuration file name.
 	 * <p/
 	 * If not set, ehcache.xml will be looked for in the root of the classpath.
 	 * <p/>
 	 * If set to say ehcache-1.xml, ehcache-1.xml will be looked for in the root of the classpath.
 	 */
 	public static final String NET_SF_EHCACHE_CONFIGURATION_RESOURCE_NAME = "net.sf.ehcache.configurationResourceName";
 
     private static final EhCacheMessageLogger LOG = Logger.getMessageLogger(EhCacheMessageLogger.class, SingletonEhCacheProvider.class.getName());
 
 	/**
 	 * To be backwardly compatible with a lot of Hibernate code out there, allow multiple starts and stops on the
 	 * one singleton CacheManager. Keep a count of references to only stop on when only one reference is held.
 	 */
 	private static int referenceCount;
 
 	private CacheManager manager;
 
 
 	/**
 	 * Builds a Cache.
 	 * <p/>
 	 * Even though this method provides properties, they are not used.
 	 * Properties for EHCache are specified in the ehcache.xml file.
 	 * Configuration will be read from ehcache.xml for a cache declaration
 	 * where the name attribute matches the name parameter in this builder.
 	 *
 	 * @param name the name of the cache. Must match a cache configured in ehcache.xml
 	 * @param properties not used
 	 *
 	 * @return a newly built cache will be built and initialised
 	 *
 	 * @throws org.hibernate.cache.CacheException
 	 *          inter alia, if a cache of the same name already exists
 	 */
 	public final Cache buildCache(String name, Properties properties) throws CacheException {
 		try {
 			net.sf.ehcache.Ehcache cache = manager.getEhcache( name );
 			if ( cache == null ) {
                 LOG.unableToFindEhCacheConfiguration(name);
 				manager.addCache( name );
 				cache = manager.getEhcache( name );
                 LOG.debugf("Started EHCache region: %s", name);
 			}
 			return new EhCache( cache );
 		}
 		catch ( net.sf.ehcache.CacheException e ) {
 			throw new CacheException( e );
 		}
 	}
 
 	/**
 	 * Returns the next timestamp.
 	 */
 	public final long nextTimestamp() {
 		return Timestamper.next();
 	}
 
 	/**
 	 * Callback to perform any necessary initialization of the underlying cache implementation
 	 * during SessionFactory construction.
 	 * <p/>
 	 *
 	 * @param properties current configuration settings.
 	 */
 	public final void start(Properties properties) throws CacheException {
 		String configurationResourceName = null;
 		if ( properties != null ) {
 			configurationResourceName = ( String ) properties.get( NET_SF_EHCACHE_CONFIGURATION_RESOURCE_NAME );
 		}
 		if ( configurationResourceName == null || configurationResourceName.length() == 0 ) {
 			manager = CacheManager.create();
 			referenceCount++;
 		}
 		else {
 			if ( !configurationResourceName.startsWith( "/" ) ) {
 				configurationResourceName = "/" + configurationResourceName;
                 if (LOG.isDebugEnabled()) {
                     LOG.debugf("Prepending / to %s. It should be placed in the root of the classpath rather than in a package.",
                                configurationResourceName);
 				}
 			}
 			URL url = loadResource( configurationResourceName );
 			manager = CacheManager.create( url );
 			referenceCount++;
 		}
 	}
 
 	private URL loadResource(String configurationResourceName) {
 		ClassLoader standardClassloader = ClassLoaderUtil.getStandardClassLoader();
 		URL url = null;
         if (standardClassloader != null) url = standardClassloader.getResource(configurationResourceName);
         if (url == null) url = this.getClass().getResource(configurationResourceName);
         if (LOG.isDebugEnabled()) LOG.debugf("Creating EhCacheProvider from a specified resource: %s Resolved to URL: %s",
                                              configurationResourceName,
                                              url);
         if (url == null && LOG.isEnabled(Level.WARN)) LOG.unableToLoadConfiguration(configurationResourceName);
 		return url;
 	}
 
 	/**
 	 * Callback to perform any necessary cleanup of the underlying cache implementation
 	 * during SessionFactory.close().
 	 */
 	public void stop() {
 		if ( manager != null ) {
 			referenceCount--;
 			if ( referenceCount == 0 ) {
 				manager.shutdown();
 			}
 			manager = null;
 		}
 	}
 
 	/**
 	 * Not sure what this is supposed to do.
 	 *
 	 * @return false to be safe
 	 */
 	public final boolean isMinimalPutsEnabledByDefault() {
 		return false;
 	}
 
 }
diff --git a/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/SingletonEhCacheRegionFactory.java b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/SingletonEhCacheRegionFactory.java
index b76a26a89b..bec857559f 100644
--- a/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/SingletonEhCacheRegionFactory.java
+++ b/hibernate-ehcache/src/main/java/org/hibernate/cache/internal/SingletonEhCacheRegionFactory.java
@@ -1,40 +1,40 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.cache.internal;
+
 import java.util.Properties;
 
 /**
  * Thin wrapper class around the within Ehcache-core packaged SingletonEhCacheRegionFactory.
  * It directly delegates to the wrapped instance, enabling user to upgrade the Ehcache-core version
  * by simply dropping in a new jar.
  *
  * @author Alex Snaps
  */
 public final class SingletonEhCacheRegionFactory extends AbstractEhCacheRegionFactory {
 
 	public SingletonEhCacheRegionFactory(Properties properties) {
 		super(new net.sf.ehcache.hibernate.SingletonEhCacheRegionFactory(properties));
 	}
 }
diff --git a/hibernate-ehcache/src/test/java/org/hibernate/test/cache/ehcache/EhCacheTest.java b/hibernate-ehcache/src/test/java/org/hibernate/test/cache/ehcache/EhCacheTest.java
index 3f69f15041..b2dbddaf5f 100644
--- a/hibernate-ehcache/src/test/java/org/hibernate/test/cache/ehcache/EhCacheTest.java
+++ b/hibernate-ehcache/src/test/java/org/hibernate/test/cache/ehcache/EhCacheTest.java
@@ -1,208 +1,208 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.ehcache;
 
 import java.util.Map;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.cache.internal.EhCacheProvider;
-import org.hibernate.cache.ReadWriteCache;
+import org.hibernate.cache.spi.ReadWriteCache;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.transaction.internal.jdbc.JdbcTransactionFactory;
 import org.hibernate.stat.SecondLevelCacheStatistics;
 import org.hibernate.stat.Statistics;
 
 import org.junit.Test;
 
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author Emmanuel Bernard
  */
 public class EhCacheTest extends BaseCoreFunctionalTestCase {
 	@Override
 	public String getBaseForMappings() {
 		return "org/hibernate/test/cache/ehcache/";
 	}
 
 	@Override
 	public String[] getMappings() {
 		return new String[] { "Item.hbm.xml" };
 	}
 
 	@Override
 	public String getCacheConcurrencyStrategy() {
 		return "read-write";
 	}
 
 	@Override
 	public void configure(Configuration cfg) {
 		super.configure( cfg );
 		cfg.setProperty( Environment.CACHE_REGION_PREFIX, "" );
 		cfg.setProperty( Environment.USE_SECOND_LEVEL_CACHE, "true" );
 		cfg.setProperty( Environment.GENERATE_STATISTICS, "true" );
 		cfg.setProperty( Environment.USE_STRUCTURED_CACHE, "true" );
 		cfg.setProperty( Environment.CACHE_PROVIDER, EhCacheProvider.class.getName() );
 		cfg.setProperty( Environment.CACHE_PROVIDER_CONFIG, "ehcache.xml" );
 		cfg.setProperty( Environment.TRANSACTION_STRATEGY, JdbcTransactionFactory.class.getName() );
 	}
 
 	@Test
 	public void testQueryCacheInvalidation() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Item i = new Item();
 		i.setName("widget");
 		i.setDescription("A really top-quality, full-featured widget.");
 		s.persist(i);
 		t.commit();
 		s.close();
 
 		SecondLevelCacheStatistics slcs = s.getSessionFactory().getStatistics()
 				.getSecondLevelCacheStatistics( Item.class.getName() );
 
 		assertEquals( slcs.getPutCount(), 1 );
 		assertEquals( slcs.getElementCountInMemory(), 1 );
 		assertEquals( slcs.getEntries().size(), 1 );
 
 		s = openSession();
 		t = s.beginTransaction();
 		i = (Item) s.get( Item.class, i.getId() );
 
 		assertEquals( slcs.getHitCount(), 1 );
 		assertEquals( slcs.getMissCount(), 0 );
 
 		i.setDescription("A bog standard item");
 
 		t.commit();
 		s.close();
 
 		assertEquals( slcs.getPutCount(), 2 );
 
 		Object entry = slcs.getEntries().get( i.getId() );
 		Map map;
 		if ( entry instanceof ReadWriteCache.Item ) {
 			map = (Map) ( (ReadWriteCache.Item) entry ).getValue();
 		}
 		else {
 			map = (Map) entry;
 		}
 		assertTrue( map.get("description").equals("A bog standard item") );
 		assertTrue( map.get("name").equals("widget") );
 
 		// cleanup
 		s = openSession();
 		t = s.beginTransaction();
 		s.delete( i );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testEmptySecondLevelCacheEntry() throws Exception {
 		sessionFactory().getCache().evictEntityRegion( Item.class.getName() );
 		Statistics stats = sessionFactory().getStatistics();
 		stats.clear();
 		SecondLevelCacheStatistics statistics = stats.getSecondLevelCacheStatistics( Item.class.getName() );
         Map cacheEntries = statistics.getEntries();
 		assertEquals( 0, cacheEntries.size() );
 	}
 
 	@SuppressWarnings( {"UnnecessaryBoxing", "UnnecessaryUnboxing", "UnusedAssignment"})
 	@Test
 	public void testStaleWritesLeaveCacheConsistent() {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		VersionedItem item = new VersionedItem();
 		item.setName( "steve" );
 		item.setDescription( "steve's item" );
 		s.save( item );
 		txn.commit();
 		s.close();
 
 		Long initialVersion = item.getVersion();
 
 		// manually revert the version property
 		item.setVersion( Long.valueOf( item.getVersion().longValue() - 1 ) );
 
 		try {
 			s = openSession();
 			txn = s.beginTransaction();
 			s.update( item );
 			txn.commit();
 			s.close();
 			fail( "expected stale write to fail" );
 		}
 		catch( Throwable expected ) {
 			// expected behavior here
 			if ( txn != null ) {
 				try {
 					txn.rollback();
 				}
 				catch( Throwable ignore ) {
 				}
 			}
 		}
 		finally {
 			if ( s != null && s.isOpen() ) {
 				try {
 					s.close();
 				}
 				catch( Throwable ignore ) {
 				}
 			}
 		}
 
 		// check the version value in the cache...
 		SecondLevelCacheStatistics slcs = sessionFactory().getStatistics()
 				.getSecondLevelCacheStatistics( VersionedItem.class.getName() );
 
 		Object entry = slcs.getEntries().get( item.getId() );
 		Long cachedVersionValue;
 		if ( entry instanceof ReadWriteCache.Lock ) {
 			//FIXME don't know what to test here
 			cachedVersionValue = Long.valueOf( ((ReadWriteCache.Lock) entry).getUnlockTimestamp() );
 		}
 		else {
 			cachedVersionValue = ( Long ) ( (Map) entry ).get( "_version" );
 			assertEquals( initialVersion.longValue(), cachedVersionValue.longValue() );
 		}
 
 
 		// cleanup
 		s = openSession();
 		txn = s.beginTransaction();
 		item = ( VersionedItem ) s.load( VersionedItem.class, item.getId() );
 		s.delete( item );
 		txn.commit();
 		s.close();
 
 	}
 
 }
diff --git a/hibernate-entitymanager/src/test/bundles/cfgxmlpar/org/hibernate/ejb/test/pack/cfgxmlpar/hibernate.cfg.xml b/hibernate-entitymanager/src/test/bundles/cfgxmlpar/org/hibernate/ejb/test/pack/cfgxmlpar/hibernate.cfg.xml
index 33f43895d4..afcd6d6778 100644
--- a/hibernate-entitymanager/src/test/bundles/cfgxmlpar/org/hibernate/ejb/test/pack/cfgxmlpar/hibernate.cfg.xml
+++ b/hibernate-entitymanager/src/test/bundles/cfgxmlpar/org/hibernate/ejb/test/pack/cfgxmlpar/hibernate.cfg.xml
@@ -1,28 +1,28 @@
 <!DOCTYPE hibernate-configuration PUBLIC
         "-//Hibernate/Hibernate Configuration DTD 3.0//EN"
         "http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd">
 
 <hibernate-configuration>
     <session-factory>
         <property name="hibernate.dialect">org.hibernate.dialect.H2Dialect</property>
         <property name="hibernate.connection.driver_class">org.h2.Driver</property>
         <property name="hibernate.connection.username">sa</property>
         <property name="hibernate.connection.password"></property>
         <property name="hibernate.connection.url">jdbc:h2:mem:db1;DB_CLOSE_DELAY=-1;MVCC=TRUE</property>
         <property name="hibernate.cache.use_query_cache">true</property>
         <property name="hibernate.cache.region_prefix">hibernate.test</property>
         <property name="hibernate.jdbc.use_streams_for_binary">true</property>
         <property name="hibernate.jdbc.batch_size">0</property>
         <property name="hibernate.max_fetch_depth">3</property>
         <property name="hibernate.hbm2ddl.auto">create-drop</property>
         <property name="hibernate.generate_statistics">true</property>
-        <property name="hibernate.cache.provider_class">org.hibernate.cache.HashtableCacheProvider</property>
+        <property name="hibernate.cache.provider_class">org.hibernate.cache.internal.HashtableCacheProvider</property>
         <mapping class="org.hibernate.ejb.test.Item"/>
         <mapping class="org.hibernate.ejb.test.Cat"/>
         <mapping class="org.hibernate.ejb.test.Kitten"/>
         <mapping class="org.hibernate.ejb.test.Distributor"/>
         <class-cache class="org.hibernate.ejb.test.Item" usage="read-write"/>
         <collection-cache collection="org.hibernate.ejb.test.Item.distributors" usage="read-write" region="RegionName"/>
         <event type="pre-insert"/>
     </session-factory>
 </hibernate-configuration>
\ No newline at end of file
diff --git a/hibernate-entitymanager/src/test/bundles/defaultpar/META-INF/persistence.xml b/hibernate-entitymanager/src/test/bundles/defaultpar/META-INF/persistence.xml
index 02746fbe28..5172fcaa65 100644
--- a/hibernate-entitymanager/src/test/bundles/defaultpar/META-INF/persistence.xml
+++ b/hibernate-entitymanager/src/test/bundles/defaultpar/META-INF/persistence.xml
@@ -1,20 +1,20 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <!-- example of a default persistence.xml -->
 <persistence xmlns="http://java.sun.com/xml/ns/persistence"
              xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
              xsi:schemaLocation="http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd"
              version="2.0">
     <persistence-unit name="defaultpar">
         <class>org.hibernate.ejb.test.pack.defaultpar.Lighter</class>
         <validation-mode>CALLBACK</validation-mode>
         <properties>
             <property name="hibernate.dialect" value="@db.dialect@"/>
             <property name="hibernate.connection.driver_class" value="@jdbc.driver@"/>
             <property name="hibernate.connection.username" value="@jdbc.user@"/>
             <property name="hibernate.connection.password" value="@jdbc.pass@"/>
             <property name="hibernate.connection.url" value="@jdbc.url@"/>
             <property name="hibernate.hbm2ddl.auto" value="create-drop"/>
-            <property name="hibernate.cache.provider_class" value="org.hibernate.cache.HashtableCacheProvider"/>
+            <property name="hibernate.cache.provider_class" value="org.hibernate.cache.internal.HashtableCacheProvider"/>
         </properties>
     </persistence-unit>
 </persistence>
diff --git a/hibernate-entitymanager/src/test/bundles/defaultpar_1_0/META-INF/persistence.xml b/hibernate-entitymanager/src/test/bundles/defaultpar_1_0/META-INF/persistence.xml
index b60f45ddf7..ed4065d754 100644
--- a/hibernate-entitymanager/src/test/bundles/defaultpar_1_0/META-INF/persistence.xml
+++ b/hibernate-entitymanager/src/test/bundles/defaultpar_1_0/META-INF/persistence.xml
@@ -1,19 +1,19 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <!-- example of a default persistence.xml -->
 <persistence xmlns="http://java.sun.com/xml/ns/persistence"
              xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
              xsi:schemaLocation="http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_1_0.xsd"
              version="1.0">
     <persistence-unit name="defaultpar_1_0">
         <class>org.hibernate.ejb.test.pack.defaultpar.Lighter</class>
         <properties>
             <property name="hibernate.dialect" value="@db.dialect@"/>
             <property name="hibernate.connection.driver_class" value="@jdbc.driver@"/>
             <property name="hibernate.connection.username" value="@jdbc.user@"/>
             <property name="hibernate.connection.password" value="@jdbc.pass@"/>
             <property name="hibernate.connection.url" value="@jdbc.url@"/>
             <property name="hibernate.hbm2ddl.auto" value="create-drop"/>
-            <property name="hibernate.cache.provider_class" value="org.hibernate.cache.HashtableCacheProvider"/>
+            <property name="hibernate.cache.provider_class" value="org.hibernate.cache.internal.HashtableCacheProvider"/>
         </properties>
     </persistence-unit>
 </persistence>
diff --git a/hibernate-entitymanager/src/test/bundles/excludehbmpar/META-INF/persistence.xml b/hibernate-entitymanager/src/test/bundles/excludehbmpar/META-INF/persistence.xml
index 1c504a5e87..7e0e9a8755 100644
--- a/hibernate-entitymanager/src/test/bundles/excludehbmpar/META-INF/persistence.xml
+++ b/hibernate-entitymanager/src/test/bundles/excludehbmpar/META-INF/persistence.xml
@@ -1,20 +1,20 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <!-- example of a default persistence.xml -->
 <persistence xmlns="http://java.sun.com/xml/ns/persistence"
              xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
              xsi:schemaLocation="http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd"
              version="2.0">
     <persistence-unit name="excludehbmpar" transaction-type="RESOURCE_LOCAL">
         <mapping-file>META-INF/orm2.xml</mapping-file>
         <properties>
             <property name="hibernate.dialect" value="@db.dialect@"/>
             <property name="hibernate.connection.driver_class" value="@jdbc.driver@"/>
             <property name="hibernate.connection.username" value="@jdbc.user@"/>
             <property name="hibernate.connection.password" value="@jdbc.pass@"/>
             <property name="hibernate.connection.url" value="@jdbc.url@"/>
             <property name="hibernate.hbm2ddl.auto" value="create-drop"/>
-            <property name="hibernate.cache.provider_class" value="org.hibernate.cache.HashtableCacheProvider"/>
+            <property name="hibernate.cache.provider_class" value="org.hibernate.cache.internal.HashtableCacheProvider"/>
             <property name="hibernate.archive.autodetection" value="class"/>
         </properties>
     </persistence-unit>
 </persistence>
diff --git a/hibernate-entitymanager/src/test/bundles/explicitpar/META-INF/persistence.xml b/hibernate-entitymanager/src/test/bundles/explicitpar/META-INF/persistence.xml
index 129e701e6b..25d45dbd85 100644
--- a/hibernate-entitymanager/src/test/bundles/explicitpar/META-INF/persistence.xml
+++ b/hibernate-entitymanager/src/test/bundles/explicitpar/META-INF/persistence.xml
@@ -1,47 +1,47 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <persistence xmlns="http://java.sun.com/xml/ns/persistence"
              xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
              xsi:schemaLocation="http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd"
              version="2.0">
     <persistence-unit name="manager1" transaction-type="RESOURCE_LOCAL">
         <jar-file>@buildDirName@/packages/externaljar.jar</jar-file>
         <class>org.hibernate.ejb.test.Cat</class>
 		<class>org.hibernate.ejb.test.Kitten</class>
         <class>org.hibernate.ejb.test.Distributor</class>
         <class>org.hibernate.ejb.test.Item</class>
         <exclude-unlisted-classes>true</exclude-unlisted-classes>
         <properties>
             <!-- custom scanner test -->
             <property name="hibernate.ejb.resource_scanner" value="org.hibernate.ejb.test.packaging.CustomScanner"/>
 
             <property name="hibernate.dialect" value="@db.dialect@"/>
             <property name="hibernate.connection.driver_class" value="@jdbc.driver@"/>
             <property name="hibernate.connection.username" value="@jdbc.user@"/>
             <property name="hibernate.connection.password" value="@jdbc.pass@"/>
             <property name="hibernate.connection.url" value="@jdbc.url@"/>
             <property name="hibernate.cache.use_query_cache" value="true"/>
             <property name="hibernate.cache.region_prefix" value="hibernate.test"/>
             <property name="hibernate.jdbc.use_streams_for_binary" value="true"/>
             <property name="hibernate.jdbc.batch_size" value="0"/>
             <property name="hibernate.max_fetch_depth" value="3"/>
             <property name="hibernate.hbm2ddl.auto" value="create-drop"/>
             <property name="hibernate.generate_statistics" value="true"/>
-            <property name="hibernate.cache.provider_class" value="org.hibernate.cache.HashtableCacheProvider"/>
+            <property name="hibernate.cache.provider_class" value="org.hibernate.cache.internal.HashtableCacheProvider"/>
             <property name="hibernate.ejb.naming_strategy" value="org.hibernate.ejb.test.MyNamingStrategy"/>
             <!-- test naming strategy and fall back to element content -->
             <!-- property name="hibernate.ejb.naming_strategy">org.hibernate.ejb.test.MyNamingStrategy</property -->
 
             <!-- cache configuration -->
             <property name="hibernate.ejb.classcache.org.hibernate.ejb.test.Item" value="read-write"/>
             <property name="hibernate.ejb.collectioncache.org.hibernate.ejb.test.Item.distributors"
                       value="read-write, RegionName"/>
 
             <!-- event overriding -->
             <property name="hibernate.ejb.event.pre-insert" value="org.hibernate.ejb.test.NoOpListener"/>
             <!-- remove JACC and validator -->
 
             <!-- alternatively to <class> and <property> declarations, you can use a regular hibernate.cfg.xml file -->
             <!-- property name="hibernate.ejb.cfgfile" value="/org/hibernate/ejb/test/hibernate.cfg.xml"/ -->
         </properties>
     </persistence-unit>
 </persistence>
diff --git a/hibernate-entitymanager/src/test/bundles/explodedpar/META-INF/persistence.xml b/hibernate-entitymanager/src/test/bundles/explodedpar/META-INF/persistence.xml
index 9ec12169f3..7420f88654 100644
--- a/hibernate-entitymanager/src/test/bundles/explodedpar/META-INF/persistence.xml
+++ b/hibernate-entitymanager/src/test/bundles/explodedpar/META-INF/persistence.xml
@@ -1,18 +1,18 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <!-- example of a default persistence.xml -->
 <persistence xmlns="http://java.sun.com/xml/ns/persistence"
              xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
              xsi:schemaLocation="http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd"
              version="2.0">
     <persistence-unit name="explodedpar" transaction-type="RESOURCE_LOCAL">
         <properties>
             <property name="hibernate.dialect" value="@db.dialect@"/>
             <property name="hibernate.connection.driver_class" value="@jdbc.driver@"/>
             <property name="hibernate.connection.username" value="@jdbc.user@"/>
             <property name="hibernate.connection.password" value="@jdbc.pass@"/>
             <property name="hibernate.connection.url" value="@jdbc.url@"/>
             <property name="hibernate.hbm2ddl.auto" value="create-drop"/>
-            <property name="hibernate.cache.provider_class" value="org.hibernate.cache.HashtableCacheProvider"/>
+            <property name="hibernate.cache.provider_class" value="org.hibernate.cache.internal.HashtableCacheProvider"/>
         </properties>
     </persistence-unit>
 </persistence>
diff --git a/hibernate-entitymanager/src/test/bundles/overridenpar/META-INF/persistence.xml b/hibernate-entitymanager/src/test/bundles/overridenpar/META-INF/persistence.xml
index c94273298d..75e34638a5 100644
--- a/hibernate-entitymanager/src/test/bundles/overridenpar/META-INF/persistence.xml
+++ b/hibernate-entitymanager/src/test/bundles/overridenpar/META-INF/persistence.xml
@@ -1,14 +1,14 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<persistence xmlns="http://java.sun.com/xml/ns/persistence"
-             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
-             xsi:schemaLocation="http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd"
-             version="2.0">
-    <persistence-unit name="overridenpar">
-        <jta-data-source>java:/unreachableDS</jta-data-source>
-		<properties>
-            <property name="hibernate.dialect" value="@db.dialect@"/>
-            <property name="hibernate.hbm2ddl.auto" value="create-drop"/>
-            <property name="hibernate.cache.provider_class" value="org.hibernate.cache.HashtableCacheProvider"/>
-        </properties>
-    </persistence-unit>
-</persistence>
+<?xml version="1.0" encoding="UTF-8"?>
+<persistence xmlns="http://java.sun.com/xml/ns/persistence"
+             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
+             xsi:schemaLocation="http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd"
+             version="2.0">
+    <persistence-unit name="overridenpar">
+        <jta-data-source>java:/unreachableDS</jta-data-source>
+		<properties>
+            <property name="hibernate.dialect" value="@db.dialect@"/>
+            <property name="hibernate.hbm2ddl.auto" value="create-drop"/>
+            <property name="hibernate.cache.provider_class" value="org.hibernate.cache.internal.HashtableCacheProvider"/>
+        </properties>
+    </persistence-unit>
+</persistence>
diff --git a/hibernate-entitymanager/src/test/bundles/space par/META-INF/persistence.xml b/hibernate-entitymanager/src/test/bundles/space par/META-INF/persistence.xml
index 61a812da54..879b62bb74 100644
--- a/hibernate-entitymanager/src/test/bundles/space par/META-INF/persistence.xml	
+++ b/hibernate-entitymanager/src/test/bundles/space par/META-INF/persistence.xml	
@@ -1,18 +1,18 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!-- example of a default persistence.xml -->
-<persistence xmlns="http://java.sun.com/xml/ns/persistence"
-             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
-             xsi:schemaLocation="http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd"
-             version="2.0">
-    <persistence-unit name="space par">
-        <properties>
-            <property name="hibernate.dialect" value="@db.dialect@"/>
-            <property name="hibernate.connection.driver_class" value="@jdbc.driver@"/>
-            <property name="hibernate.connection.username" value="@jdbc.user@"/>
-            <property name="hibernate.connection.password" value="@jdbc.pass@"/>
-            <property name="hibernate.connection.url" value="@jdbc.url@"/>
-            <property name="hibernate.hbm2ddl.auto" value="create-drop"/>
-            <property name="hibernate.cache.provider_class" value="org.hibernate.cache.HashtableCacheProvider"/>
-        </properties>
-    </persistence-unit>
-</persistence>
+<?xml version="1.0" encoding="UTF-8"?>
+<!-- example of a default persistence.xml -->
+<persistence xmlns="http://java.sun.com/xml/ns/persistence"
+             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
+             xsi:schemaLocation="http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd"
+             version="2.0">
+    <persistence-unit name="space par">
+        <properties>
+            <property name="hibernate.dialect" value="@db.dialect@"/>
+            <property name="hibernate.connection.driver_class" value="@jdbc.driver@"/>
+            <property name="hibernate.connection.username" value="@jdbc.user@"/>
+            <property name="hibernate.connection.password" value="@jdbc.pass@"/>
+            <property name="hibernate.connection.url" value="@jdbc.url@"/>
+            <property name="hibernate.hbm2ddl.auto" value="create-drop"/>
+            <property name="hibernate.cache.provider_class" value="org.hibernate.cache.internal.HashtableCacheProvider"/>
+        </properties>
+    </persistence-unit>
+</persistence>
diff --git a/hibernate-entitymanager/src/test/bundles/war/WEB-INF/classes/META-INF/persistence.xml b/hibernate-entitymanager/src/test/bundles/war/WEB-INF/classes/META-INF/persistence.xml
index f5e942bec8..6b575739ee 100644
--- a/hibernate-entitymanager/src/test/bundles/war/WEB-INF/classes/META-INF/persistence.xml
+++ b/hibernate-entitymanager/src/test/bundles/war/WEB-INF/classes/META-INF/persistence.xml
@@ -1,20 +1,20 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <!-- example of a default persistence.xml -->
 <persistence xmlns="http://java.sun.com/xml/ns/persistence"
              xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
              xsi:schemaLocation="http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd"
              version="2.0">
     <persistence-unit name="defaultpar">
         <class>org.hibernate.ejb.test.pack.defaultpar.Lighter</class>
         <properties>
             <property name="hibernate.dialect" value="@db.dialect@"/>
             <property name="hibernate.connection.driver_class" value="@jdbc.driver@"/>
             <property name="hibernate.connection.username" value="@jdbc.user@"/>
             <property name="hibernate.connection.password" value="@jdbc.pass@"/>
             <property name="hibernate.connection.url" value="@jdbc.url@"/>
             <property name="hibernate.hbm2ddl.auto" value="create-drop"/>
-            <property name="hibernate.cache.provider_class" value="org.hibernate.cache.HashtableCacheProvider"/>
+            <property name="hibernate.cache.provider_class" value="org.hibernate.cache.internal.HashtableCacheProvider"/>
         </properties>
     </persistence-unit>
 </persistence>
 
diff --git a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/cacheable/annotation/ConfigurationTest.java b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/cacheable/annotation/ConfigurationTest.java
index 03ff90b5f1..e689433980 100644
--- a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/cacheable/annotation/ConfigurationTest.java
+++ b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/cacheable/annotation/ConfigurationTest.java
@@ -1,140 +1,140 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.ejb.test.cacheable.annotation;
 
 import javax.persistence.SharedCacheMode;
 import java.util.Properties;
 
-import org.hibernate.cache.access.AccessType;
-import org.hibernate.cache.impl.NoCachingRegionFactory;
+import org.hibernate.cache.internal.NoCachingRegionFactory;
+import org.hibernate.cache.spi.access.AccessType;
 import org.hibernate.cfg.Environment;
 import org.hibernate.ejb.AvailableSettings;
 import org.hibernate.ejb.Ejb3Configuration;
 import org.hibernate.mapping.PersistentClass;
 
 import org.junit.Test;
 
 import org.hibernate.testing.junit4.BaseUnitTestCase;
 
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNull;
 
 /**
  * @author Steve Ebersole
  */
 public class ConfigurationTest extends BaseUnitTestCase {
 	@Test
 	public void testSharedCacheModeNone() {
 		Ejb3Configuration config = buildConfiguration( SharedCacheMode.NONE );
 
 		PersistentClass pc = config.getClassMapping( ExplicitlyCacheableEntity.class.getName() );
 		assertNull( pc.getCacheConcurrencyStrategy() );
 
 		pc = config.getClassMapping( ExplicitlyNonCacheableEntity.class.getName() );
 		assertNull( pc.getCacheConcurrencyStrategy() );
 
 		pc = config.getClassMapping( NoCacheableAnnotationEntity.class.getName() );
 		assertNull( pc.getCacheConcurrencyStrategy() );
 	}
 
 	@Test
 	public void testSharedCacheModeUnspecified() {
 		Ejb3Configuration config = buildConfiguration( SharedCacheMode.UNSPECIFIED );
 
 		PersistentClass pc = config.getClassMapping( ExplicitlyCacheableEntity.class.getName() );
 		assertNull( pc.getCacheConcurrencyStrategy() );
 
 		pc = config.getClassMapping( ExplicitlyNonCacheableEntity.class.getName() );
 		assertNull( pc.getCacheConcurrencyStrategy() );
 
 		pc = config.getClassMapping( NoCacheableAnnotationEntity.class.getName() );
 		assertNull( pc.getCacheConcurrencyStrategy() );
 	}
 
 	@Test
 	public void testSharedCacheModeAll() {
 		Ejb3Configuration config = buildConfiguration( SharedCacheMode.ALL );
 
 		PersistentClass pc = config.getClassMapping( ExplicitlyCacheableEntity.class.getName() );
 		assertNotNull( pc.getCacheConcurrencyStrategy() );
 
 		pc = config.getClassMapping( ExplicitlyNonCacheableEntity.class.getName() );
 		assertNotNull( pc.getCacheConcurrencyStrategy() );
 
 		pc = config.getClassMapping( NoCacheableAnnotationEntity.class.getName() );
 		assertNotNull( pc.getCacheConcurrencyStrategy() );
 	}
 
 	@Test
 	public void testSharedCacheModeEnable() {
 		Ejb3Configuration config = buildConfiguration( SharedCacheMode.ENABLE_SELECTIVE );
 
 		PersistentClass pc = config.getClassMapping( ExplicitlyCacheableEntity.class.getName() );
 		assertNotNull( pc.getCacheConcurrencyStrategy() );
 
 		pc = config.getClassMapping( ExplicitlyNonCacheableEntity.class.getName() );
 		assertNull( pc.getCacheConcurrencyStrategy() );
 
 		pc = config.getClassMapping( NoCacheableAnnotationEntity.class.getName() );
 		assertNull( pc.getCacheConcurrencyStrategy() );
 	}
 
 	@Test
 	public void testSharedCacheModeDisable() {
 		Ejb3Configuration config = buildConfiguration( SharedCacheMode.DISABLE_SELECTIVE );
 
 		PersistentClass pc = config.getClassMapping( ExplicitlyCacheableEntity.class.getName() );
 		assertNotNull( pc.getCacheConcurrencyStrategy() );
 
 		pc = config.getClassMapping( ExplicitlyNonCacheableEntity.class.getName() );
 		assertNull( pc.getCacheConcurrencyStrategy() );
 
 		pc = config.getClassMapping( NoCacheableAnnotationEntity.class.getName() );
 		assertNotNull( pc.getCacheConcurrencyStrategy() );
 	}
 
 	private Ejb3Configuration buildConfiguration(SharedCacheMode mode) {
 		Properties properties = new Properties();
 		properties.put( AvailableSettings.SHARED_CACHE_MODE, mode );
 		properties.put( Environment.CACHE_REGION_FACTORY, CustomRegionFactory.class.getName() );
 		Ejb3Configuration config = new Ejb3Configuration();
 		config.setProperties( properties );
 		config.addAnnotatedClass( ExplicitlyCacheableEntity.class );
 		config.addAnnotatedClass( ExplicitlyNonCacheableEntity.class );
 		config.addAnnotatedClass( NoCacheableAnnotationEntity.class );
 		config.buildMappings();
 		return config;
 	}
 
 	public static class CustomRegionFactory extends NoCachingRegionFactory {
 		public CustomRegionFactory(Properties properties) {
 			super( properties );
 		}
 
 		@Override
 		public AccessType getDefaultAccessType() {
 			return AccessType.READ_WRITE;
 		}
 	}
 }
diff --git a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/ejb3configuration/PersisterClassProviderTest.java b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/ejb3configuration/PersisterClassProviderTest.java
index 16d07eaba7..0cc914ff8c 100644
--- a/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/ejb3configuration/PersisterClassProviderTest.java
+++ b/hibernate-entitymanager/src/test/java/org/hibernate/ejb/test/ejb3configuration/PersisterClassProviderTest.java
@@ -1,491 +1,491 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * JBoss, Home of Professional Open Source
  * Copyright 2011 Red Hat Inc. and/or its affiliates and other contributors
  * as indicated by the @authors tag. All rights reserved.
  * See the copyright.txt in the distribution for a
  * full listing of individual contributors.
  *
  * This copyrighted material is made available to anyone wishing to use,
  * modify, copy, or redistribute it subject to the terms and conditions
  * of the GNU Lesser General Public License, v. 2.1.
  * This program is distributed in the hope that it will be useful, but WITHOUT A
  * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
  * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
  * You should have received a copy of the GNU Lesser General Public License,
  * v.2.1 along with this distribution; if not, write to the Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
  * MA  02110-1301, USA.
  */
 package org.hibernate.ejb.test.ejb3configuration;
 
 import java.io.Serializable;
 import java.util.Comparator;
 import java.util.Map;
 
 import javax.persistence.EntityManagerFactory;
 import javax.persistence.PersistenceException;
 
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
-import org.hibernate.cache.entry.CacheEntryStructure;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.spi.entry.CacheEntryStructure;
 import org.hibernate.ejb.Ejb3Configuration;
 import org.hibernate.engine.CascadeStyle;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.ValueInclusion;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.persister.internal.PersisterClassResolverInitiator;
 import org.hibernate.persister.spi.PersisterClassResolver;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.tuple.entity.EntityMetamodel;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 
 /**
  * @author Emmanuel Bernard <emmanuel@hibernate.org>
  */
 public class PersisterClassProviderTest extends junit.framework.TestCase {
 	public void testPersisterClassProvider() {
 		Ejb3Configuration conf = new Ejb3Configuration();
 		conf.getProperties().put( PersisterClassResolverInitiator.IMPL_NAME, GoofyPersisterClassProvider.class );
 		conf.addAnnotatedClass( Bell.class );
 		try {
 			final EntityManagerFactory entityManagerFactory = conf.buildEntityManagerFactory();
 			entityManagerFactory.close();
 		}
 		catch ( PersistenceException e ) {
 			assertNotNull( e.getCause() );
 			assertNotNull( e.getCause().getCause() );
 			assertEquals( GoofyException.class, e.getCause().getCause().getClass() );
 
 		}
 	}
 
 	public static class GoofyPersisterClassProvider implements PersisterClassResolver {
 		@Override
 		public Class<? extends EntityPersister> getEntityPersisterClass(PersistentClass metadata) {
 			return GoofyProvider.class;
 		}
 
 		@Override
 		public Class<? extends CollectionPersister> getCollectionPersisterClass(Collection metadata) {
 			return null;
 		}
 	}
 
 	public static class GoofyProvider implements EntityPersister {
 
 		public GoofyProvider(org.hibernate.mapping.PersistentClass persistentClass,
-								   org.hibernate.cache.access.EntityRegionAccessStrategy strategy,
+								   org.hibernate.cache.spi.access.EntityRegionAccessStrategy strategy,
 								   org.hibernate.engine.SessionFactoryImplementor sf,
 								   org.hibernate.engine.Mapping mapping) {
 			throw new GoofyException();
 		}
 
 		public void postInstantiate() throws MappingException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public SessionFactoryImplementor getFactory() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public String getRootEntityName() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public String getEntityName() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public EntityMetamodel getEntityMetamodel() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isSubclassEntityName(String entityName) {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Serializable[] getPropertySpaces() {
 			return new Serializable[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Serializable[] getQuerySpaces() {
 			return new Serializable[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasProxy() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasCollections() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasMutableProperties() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasSubselectLoadableCollections() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasCascades() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isMutable() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isInherited() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isIdentifierAssignedByInsert() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Type getPropertyType(String propertyName) throws MappingException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public int[] findDirty(Object[] currentState, Object[] previousState, Object owner, SessionImplementor session) {
 			return new int[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public int[] findModified(Object[] old, Object[] current, Object object, SessionImplementor session) {
 			return new int[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasIdentifierProperty() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean canExtractIdOutOfEntity() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isVersioned() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Comparator getVersionComparator() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public VersionType getVersionType() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public int getVersionProperty() {
 			return 0;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasNaturalIdentifier() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public int[] getNaturalIdentifierProperties() {
 			return new int[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object[] getNaturalIdentifierSnapshot(Serializable id, SessionImplementor session) {
 			return new Object[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public IdentifierGenerator getIdentifierGenerator() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasLazyProperties() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object load(Serializable id, Object optionalObject, LockMode lockMode, SessionImplementor session)
 				throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object load(Serializable id, Object optionalObject, LockOptions lockOptions, SessionImplementor session)
 				throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void lock(Serializable id, Object version, Object object, LockMode lockMode, SessionImplementor session)
 				throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void lock(Serializable id, Object version, Object object, LockOptions lockOptions, SessionImplementor session)
 				throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void insert(Serializable id, Object[] fields, Object object, SessionImplementor session)
 				throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Serializable insert(Object[] fields, Object object, SessionImplementor session)
 				throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void delete(Serializable id, Object version, Object object, SessionImplementor session)
 				throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void update(Serializable id, Object[] fields, int[] dirtyFields, boolean hasDirtyCollection, Object[] oldFields, Object oldVersion, Object object, Object rowId, SessionImplementor session)
 				throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Type[] getPropertyTypes() {
 			return new Type[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public String[] getPropertyNames() {
 			return new String[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean[] getPropertyInsertability() {
 			return new boolean[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public ValueInclusion[] getPropertyInsertGenerationInclusions() {
 			return new ValueInclusion[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public ValueInclusion[] getPropertyUpdateGenerationInclusions() {
 			return new ValueInclusion[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean[] getPropertyUpdateability() {
 			return new boolean[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean[] getPropertyCheckability() {
 			return new boolean[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean[] getPropertyNullability() {
 			return new boolean[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean[] getPropertyVersionability() {
 			return new boolean[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean[] getPropertyLaziness() {
 			return new boolean[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public CascadeStyle[] getPropertyCascadeStyles() {
 			return new CascadeStyle[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Type getIdentifierType() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public String getIdentifierPropertyName() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isCacheInvalidationRequired() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isLazyPropertiesCacheable() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasCache() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public EntityRegionAccessStrategy getCacheAccessStrategy() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public CacheEntryStructure getCacheEntryStructure() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public ClassMetadata getClassMetadata() {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isBatchLoadable() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isSelectBeforeUpdateRequired() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object[] getDatabaseSnapshot(Serializable id, SessionImplementor session) throws HibernateException {
 			return new Object[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object getCurrentVersion(Serializable id, SessionImplementor session) throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object forceVersionIncrement(Serializable id, Object currentVersion, SessionImplementor session)
 				throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public EntityMode guessEntityMode(Object object) {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isInstrumented(EntityMode entityMode) {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasInsertGeneratedProperties() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasUpdateGeneratedProperties() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isVersionPropertyGenerated() {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void afterInitialize(Object entity, boolean lazyPropertiesAreUnfetched, SessionImplementor session) {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void afterReassociate(Object entity, SessionImplementor session) {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object createProxy(Serializable id, SessionImplementor session) throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Boolean isTransient(Object object, SessionImplementor session) throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object[] getPropertyValuesToInsert(Object object, Map mergeMap, SessionImplementor session)
 				throws HibernateException {
 			return new Object[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void processInsertGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session) {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void processUpdateGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session) {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Class getMappedClass(EntityMode entityMode) {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean implementsLifecycle(EntityMode entityMode) {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean implementsValidatable(EntityMode entityMode) {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Class getConcreteProxyClass(EntityMode entityMode) {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void setPropertyValues(Object object, Object[] values, EntityMode entityMode) throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void setPropertyValue(Object object, int i, Object value, EntityMode entityMode)
 				throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object[] getPropertyValues(Object object, EntityMode entityMode) throws HibernateException {
 			return new Object[0];  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object getPropertyValue(Object object, int i, EntityMode entityMode) throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object getPropertyValue(Object object, String propertyName, EntityMode entityMode)
 				throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Serializable getIdentifier(Object object, EntityMode entityMode) throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Serializable getIdentifier(Object entity, SessionImplementor session) {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void setIdentifier(Object entity, Serializable id, EntityMode entityMode) throws HibernateException {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void setIdentifier(Object entity, Serializable id, SessionImplementor session) {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object getVersion(Object object, EntityMode entityMode) throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object instantiate(Serializable id, EntityMode entityMode) throws HibernateException {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public Object instantiate(Serializable id, SessionImplementor session) {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean isInstance(Object object, EntityMode entityMode) {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public boolean hasUninitializedLazyProperties(Object object, EntityMode entityMode) {
 			return false;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void resetIdentifier(Object entity, Serializable currentId, Object currentVersion, EntityMode entityMode) {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public void resetIdentifier(Object entity, Serializable currentId, Object currentVersion, SessionImplementor session) {
 			//To change body of implemented methods use File | Settings | File Templates.
 		}
 
 		public EntityPersister getSubclassEntityPersister(Object instance, SessionFactoryImplementor factory, EntityMode entityMode) {
 			return null;  //To change body of implemented methods use File | Settings | File Templates.
 		}
 	}
 
 	public static class GoofyException extends RuntimeException {
 
 	}
 }
diff --git a/hibernate-entitymanager/src/test/resources/hibernate.properties b/hibernate-entitymanager/src/test/resources/hibernate.properties
index c8f50d5271..1425248df7 100644
--- a/hibernate-entitymanager/src/test/resources/hibernate.properties
+++ b/hibernate-entitymanager/src/test/resources/hibernate.properties
@@ -1,38 +1,38 @@
 #
 # Hibernate, Relational Persistence for Idiomatic Java
 #
 # Copyright (c) 2010, Red Hat Inc. or third-party contributors as
 # indicated by the @author tags or express copyright attribution
 # statements applied by the authors.  All third-party contributions are
 # distributed under license by Red Hat Inc.
 #
 # This copyrighted material is made available to anyone wishing to use, modify,
 # copy, or redistribute it subject to the terms and conditions of the GNU
 # Lesser General Public License, as published by the Free Software Foundation.
 #
 # This program is distributed in the hope that it will be useful,
 # but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
 # or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
 # for more details.
 #
 # You should have received a copy of the GNU Lesser General Public License
 # along with this distribution; if not, write to:
 # Free Software Foundation, Inc.
 # 51 Franklin Street, Fifth Floor
 # Boston, MA  02110-1301  USA
 #
 hibernate.dialect org.hibernate.dialect.H2Dialect
 hibernate.connection.driver_class org.h2.Driver
 hibernate.connection.url jdbc:h2:mem:db1;DB_CLOSE_DELAY=-1;MVCC=TRUE
 hibernate.connection.username sa
 
 hibernate.connection.pool_size 5
 
 hibernate.show_sql true
 
 hibernate.max_fetch_depth 5
 
 hibernate.cache.region_prefix hibernate.test
-hibernate.cache.provider_class org.hibernate.cache.HashtableCacheProvider
+hibernate.cache.provider_class org.hibernate.cache.internal.HashtableCacheProvider
 
 hibernate.jdbc.batch_size 0
diff --git a/hibernate-entitymanager/src/test/resources/org/hibernate/ejb/test/hibernate.cfg.xml b/hibernate-entitymanager/src/test/resources/org/hibernate/ejb/test/hibernate.cfg.xml
index 1f0146e0ec..6de66dd45c 100644
--- a/hibernate-entitymanager/src/test/resources/org/hibernate/ejb/test/hibernate.cfg.xml
+++ b/hibernate-entitymanager/src/test/resources/org/hibernate/ejb/test/hibernate.cfg.xml
@@ -1,27 +1,27 @@
 <!DOCTYPE hibernate-configuration PUBLIC
         "-//Hibernate/Hibernate Configuration DTD 3.0//EN"
         "http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd">
 
 <hibernate-configuration>
     <session-factory>
         <property name="hibernate.dialect">org.hibernate.dialect.HSQLDialect</property>
         <property name="hibernate.connection.driver_class">org.hsqldb.jdbcDriver</property>
         <property name="hibernate.connection.username">sa</property>
         <property name="hibernate.connection.password"></property>
         <property name="hibernate.connection.url">jdbc:hsqldb:.</property>
         <property name="hibernate.cache.use_query_cache">true</property>
         <property name="hibernate.cache.region_prefix">hibernate.test</property>
         <property name="hibernate.jdbc.use_streams_for_binary">true</property>
         <property name="hibernate.jdbc.batch_size">0</property>
         <property name="hibernate.max_fetch_depth">3</property>
         <property name="hibernate.hbm2ddl.auto">create-drop</property>
         <property name="hibernate.generate_statistics">true</property>
-        <property name="hibernate.cache.provider_class">org.hibernate.cache.HashtableCacheProvider</property>
+        <property name="hibernate.cache.provider_class">org.hibernate.cache.internal.HashtableCacheProvider</property>
         <mapping class="org.hibernate.ejb.test.Item"/>
         <mapping class="org.hibernate.ejb.test.Cat"/>
 		<mapping class="org.hibernate.ejb.test.Kitten"/>
         <mapping class="org.hibernate.ejb.test.Distributor"/>
         <class-cache class="org.hibernate.ejb.test.Item" usage="read-write"/>
         <collection-cache collection="org.hibernate.ejb.test.Item.distributors" usage="read-write" region="RegionName"/>
     </session-factory>
 </hibernate-configuration>
\ No newline at end of file
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/entities/mapper/relation/lazy/AbstractDelegateSessionImplementor.java b/hibernate-envers/src/main/java/org/hibernate/envers/entities/mapper/relation/lazy/AbstractDelegateSessionImplementor.java
index 2febfbf341..95e6af147e 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/entities/mapper/relation/lazy/AbstractDelegateSessionImplementor.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/entities/mapper/relation/lazy/AbstractDelegateSessionImplementor.java
@@ -1,310 +1,310 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.entities.mapper.relation.lazy;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.CacheMode;
 import org.hibernate.EntityMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.Query;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
-import org.hibernate.cache.CacheKey;
+import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.collection.PersistentCollection;
 import org.hibernate.engine.EntityKey;
 import org.hibernate.engine.LoadQueryInfluencers;
 import org.hibernate.engine.NonFlushedChanges;
 import org.hibernate.engine.PersistenceContext;
 import org.hibernate.engine.QueryParameters;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.engine.jdbc.spi.JdbcConnectionAccess;
 import org.hibernate.engine.query.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.internal.CriteriaImpl;
 import org.hibernate.loader.custom.CustomQuery;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.type.Type;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  */
 public abstract class AbstractDelegateSessionImplementor implements SessionImplementor {
     protected SessionImplementor delegate;
 
     public AbstractDelegateSessionImplementor(SessionImplementor delegate) {
         this.delegate = delegate;
     }
 
     public abstract Object doImmediateLoad(String entityName);
 
     public Object immediateLoad(String entityName, Serializable id) throws HibernateException {
         return doImmediateLoad(entityName);
     }
 
     // Delegate methods
 
 
 	@Override
 	public String getTenantIdentifier() {
 		return delegate.getTenantIdentifier();
 	}
 
 	@Override
 	public JdbcConnectionAccess getJdbcConnectionAccess() {
 		return delegate.getJdbcConnectionAccess();
 	}
 
 	@Override
 	public EntityKey generateEntityKey(Serializable id, EntityPersister persister) {
 		return delegate.generateEntityKey( id, persister );
 	}
 
 	@Override
 	public CacheKey generateCacheKey(Serializable id, Type type, String entityOrRoleName) {
 		return delegate.generateCacheKey( id, type, entityOrRoleName );
 	}
 
 	@Override
 	public <T> T execute(Callback<T> callback) {
 		return delegate.execute( callback );
 	}
 
 	public LoadQueryInfluencers getLoadQueryInfluencers() {
 		return delegate.getLoadQueryInfluencers();
 	}
 
 	public Interceptor getInterceptor() {
         return delegate.getInterceptor();
     }
 
     public void setAutoClear(boolean enabled) {
         delegate.setAutoClear(enabled);
     }
 
 	@Override
 	public void disableTransactionAutoJoin() {
 		delegate.disableTransactionAutoJoin();
 	}
 
 	public boolean isTransactionInProgress() {
         return delegate.isTransactionInProgress();
     }
 
     public void initializeCollection(PersistentCollection collection, boolean writing) throws HibernateException {
         delegate.initializeCollection(collection, writing);
     }
 
     public Object internalLoad(String entityName, Serializable id, boolean eager, boolean nullable) throws HibernateException {
         return delegate.internalLoad(entityName, id, eager, nullable);
     }
 
     public long getTimestamp() {
         return delegate.getTimestamp();
     }
 
     public SessionFactoryImplementor getFactory() {
         return delegate.getFactory();
     }
 
     public List list(String query, QueryParameters queryParameters) throws HibernateException {
         return delegate.list(query, queryParameters);
     }
 
     public Iterator iterate(String query, QueryParameters queryParameters) throws HibernateException {
         return delegate.iterate(query, queryParameters);
     }
 
     public ScrollableResults scroll(String query, QueryParameters queryParameters) throws HibernateException {
         return delegate.scroll(query, queryParameters);
     }
 
     public ScrollableResults scroll(CriteriaImpl criteria, ScrollMode scrollMode) {
         return delegate.scroll(criteria, scrollMode);
     }
 
     public List list(CriteriaImpl criteria) {
         return delegate.list(criteria);
     }
 
     public List listFilter(Object collection, String filter, QueryParameters queryParameters) throws HibernateException {
         return delegate.listFilter(collection, filter, queryParameters);
     }
 
     public Iterator iterateFilter(Object collection, String filter, QueryParameters queryParameters) throws HibernateException {
         return delegate.iterateFilter(collection, filter, queryParameters);
     }
 
     public EntityPersister getEntityPersister(String entityName, Object object) throws HibernateException {
         return delegate.getEntityPersister(entityName, object);
     }
 
     public Object getEntityUsingInterceptor(EntityKey key) throws HibernateException {
         return delegate.getEntityUsingInterceptor(key);
     }
 
     public Serializable getContextEntityIdentifier(Object object) {
         return delegate.getContextEntityIdentifier(object);
     }
 
     public String bestGuessEntityName(Object object) {
         return delegate.bestGuessEntityName(object);
     }
 
     public String guessEntityName(Object entity) throws HibernateException {
         return delegate.guessEntityName(entity);
     }
 
     public Object instantiate(String entityName, Serializable id) throws HibernateException {
         return delegate.instantiate(entityName, id);
     }
 
     public List listCustomQuery(CustomQuery customQuery, QueryParameters queryParameters) throws HibernateException {
         return delegate.listCustomQuery(customQuery, queryParameters);
     }
 
     public ScrollableResults scrollCustomQuery(CustomQuery customQuery, QueryParameters queryParameters) throws HibernateException {
         return delegate.scrollCustomQuery(customQuery, queryParameters);
     }
 
     public List list(NativeSQLQuerySpecification spec, QueryParameters queryParameters) throws HibernateException {
         return delegate.list(spec, queryParameters);
     }
 
     public ScrollableResults scroll(NativeSQLQuerySpecification spec, QueryParameters queryParameters) throws HibernateException {
         return delegate.scroll(spec, queryParameters);
     }
 
     public Object getFilterParameterValue(String filterParameterName) {
         return delegate.getFilterParameterValue(filterParameterName);
     }
 
     public Type getFilterParameterType(String filterParameterName) {
         return delegate.getFilterParameterType(filterParameterName);
     }
 
     public Map getEnabledFilters() {
         return delegate.getEnabledFilters();
     }
 
     public int getDontFlushFromFind() {
         return delegate.getDontFlushFromFind();
     }
 
     public PersistenceContext getPersistenceContext() {
         return delegate.getPersistenceContext();
     }
 
     public int executeUpdate(String query, QueryParameters queryParameters) throws HibernateException {
         return delegate.executeUpdate(query, queryParameters);
     }
 
     public int executeNativeUpdate(NativeSQLQuerySpecification specification, QueryParameters queryParameters) throws HibernateException {
         return delegate.executeNativeUpdate(specification, queryParameters);
     }
 
 	public NonFlushedChanges getNonFlushedChanges() throws HibernateException {
 		return delegate.getNonFlushedChanges();
 	}
 
 	public void applyNonFlushedChanges(NonFlushedChanges nonFlushedChanges) throws HibernateException {
 		delegate.applyNonFlushedChanges( nonFlushedChanges );
 	}
 
     public EntityMode getEntityMode() {
         return delegate.getEntityMode();
     }
 
     public CacheMode getCacheMode() {
         return delegate.getCacheMode();
     }
 
     public void setCacheMode(CacheMode cm) {
         delegate.setCacheMode(cm);
     }
 
     public boolean isOpen() {
         return delegate.isOpen();
     }
 
     public boolean isConnected() {
         return delegate.isConnected();
     }
 
     public FlushMode getFlushMode() {
         return delegate.getFlushMode();
     }
 
     public void setFlushMode(FlushMode fm) {
         delegate.setFlushMode(fm);
     }
 
     public Connection connection() {
         return delegate.connection();
     }
 
     public void flush() {
         delegate.flush();
     }
 
     public Query getNamedQuery(String name) {
         return delegate.getNamedQuery(name);
     }
 
     public Query getNamedSQLQuery(String name) {
         return delegate.getNamedSQLQuery(name);
     }
 
     public boolean isEventSource() {
         return delegate.isEventSource();
     }
 
     public void afterScrollOperation() {
         delegate.afterScrollOperation();
     }
 
     public void setFetchProfile(String name) {
         delegate.setFetchProfile(name);
     }
 
     public String getFetchProfile() {
         return delegate.getFetchProfile();
     }
 
 	@Override
 	public TransactionCoordinator getTransactionCoordinator() {
 		return delegate.getTransactionCoordinator();
 	}
 
 	public boolean isClosed() {
         return delegate.isClosed();
     }
 }
diff --git a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/InfinispanRegionFactory.java b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/InfinispanRegionFactory.java
index 7f07d72d0f..6010d4d3a4 100644
--- a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/InfinispanRegionFactory.java
+++ b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/InfinispanRegionFactory.java
@@ -1,435 +1,435 @@
 package org.hibernate.cache.infinispan;
 import java.io.IOException;
 import java.util.Collections;
 import java.util.Enumeration;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import javax.transaction.TransactionManager;
-import org.hibernate.cache.CacheDataDescription;
+import org.hibernate.cache.spi.CacheDataDescription;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.CollectionRegion;
-import org.hibernate.cache.EntityRegion;
-import org.hibernate.cache.QueryResultsRegion;
-import org.hibernate.cache.RegionFactory;
-import org.hibernate.cache.TimestampsRegion;
-import org.hibernate.cache.access.AccessType;
+import org.hibernate.cache.spi.CollectionRegion;
+import org.hibernate.cache.spi.EntityRegion;
+import org.hibernate.cache.spi.QueryResultsRegion;
+import org.hibernate.cache.spi.RegionFactory;
+import org.hibernate.cache.spi.TimestampsRegion;
+import org.hibernate.cache.spi.access.AccessType;
 import org.hibernate.cache.infinispan.collection.CollectionRegionImpl;
 import org.hibernate.cache.infinispan.entity.EntityRegionImpl;
 import org.hibernate.cache.infinispan.impl.ClassLoaderAwareCache;
 import org.hibernate.cache.infinispan.query.QueryResultsRegionImpl;
 import org.hibernate.cache.infinispan.timestamp.TimestampTypeOverrides;
 import org.hibernate.cache.infinispan.timestamp.TimestampsRegionImpl;
 import org.hibernate.cache.infinispan.tm.HibernateTransactionManagerLookup;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.cache.infinispan.util.CacheAdapterImpl;
 import org.hibernate.cfg.Settings;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.infinispan.AdvancedCache;
 import org.infinispan.Cache;
 import org.infinispan.config.Configuration;
 import org.infinispan.manager.DefaultCacheManager;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 /**
  * A {@link RegionFactory} for <a href="http://www.jboss.org/infinispan">Infinispan</a>-backed cache
  * regions.
  * 
  * @author Chris Bredesen
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public class InfinispanRegionFactory implements RegionFactory {
 
    private static final Log log = LogFactory.getLog(InfinispanRegionFactory.class);
 
    private static final String PREFIX = "hibernate.cache.infinispan.";
 
    private static final String CONFIG_SUFFIX = ".cfg";
 
    private static final String STRATEGY_SUFFIX = ".eviction.strategy";
 
    private static final String WAKE_UP_INTERVAL_SUFFIX = ".eviction.wake_up_interval";
 
    private static final String MAX_ENTRIES_SUFFIX = ".eviction.max_entries";
 
    private static final String LIFESPAN_SUFFIX = ".expiration.lifespan";
 
    private static final String MAX_IDLE_SUFFIX = ".expiration.max_idle";
 
 //   private static final String STATISTICS_SUFFIX = ".statistics";
 
    /** 
     * Classpath or filesystem resource containing Infinispan configurations the factory should use.
     * 
     * @see #DEF_INFINISPAN_CONFIG_RESOURCE
     */
    public static final String INFINISPAN_CONFIG_RESOURCE_PROP = "hibernate.cache.infinispan.cfg";
 
    public static final String INFINISPAN_GLOBAL_STATISTICS_PROP = "hibernate.cache.infinispan.statistics";
 
    private static final String ENTITY_KEY = "entity";
    
    /**
     * Name of the configuration that should be used for entity caches.
     * 
     * @see #DEF_ENTITY_RESOURCE
     */
    public static final String ENTITY_CACHE_RESOURCE_PROP = PREFIX + ENTITY_KEY + CONFIG_SUFFIX;
    
    private static final String COLLECTION_KEY = "collection";
    
    /**
     * Name of the configuration that should be used for collection caches.
     * No default value, as by default we try to use the same Infinispan cache
     * instance we use for entity caching.
     * 
     * @see #ENTITY_CACHE_RESOURCE_PROP
     * @see #DEF_ENTITY_RESOURCE
     */
    public static final String COLLECTION_CACHE_RESOURCE_PROP = PREFIX + COLLECTION_KEY + CONFIG_SUFFIX;
 
    private static final String TIMESTAMPS_KEY = "timestamps";
 
    /**
     * Name of the configuration that should be used for timestamp caches.
     * 
     * @see #DEF_TIMESTAMPS_RESOURCE
     */
    public static final String TIMESTAMPS_CACHE_RESOURCE_PROP = PREFIX + TIMESTAMPS_KEY + CONFIG_SUFFIX;
 
    private static final String QUERY_KEY = "query";
 
    /**
     * Name of the configuration that should be used for query caches.
     * 
     * @see #DEF_QUERY_RESOURCE
     */
    public static final String QUERY_CACHE_RESOURCE_PROP = PREFIX + QUERY_KEY + CONFIG_SUFFIX;
 
    /**
     * Default value for {@link #INFINISPAN_CONFIG_RESOURCE_PROP}. Specifies the "infinispan-configs.xml" file in this package.
     */
    public static final String DEF_INFINISPAN_CONFIG_RESOURCE = "org/hibernate/cache/infinispan/builder/infinispan-configs.xml";
 
    /**
     * Default value for {@link #ENTITY_CACHE_RESOURCE_PROP}.
     */
    public static final String DEF_ENTITY_RESOURCE = "entity";
 
    /**
     * Default value for {@link #TIMESTAMPS_CACHE_RESOURCE_PROP}.
     */
    public static final String DEF_TIMESTAMPS_RESOURCE = "timestamps";
 
    /**
     * Default value for {@link #QUERY_CACHE_RESOURCE_PROP}.
     */
    public static final String DEF_QUERY_RESOURCE = "local-query";
 
    private EmbeddedCacheManager manager;
 
    private final Map<String, TypeOverrides> typeOverrides = new HashMap<String, TypeOverrides>();
 
    private final Set<String> definedConfigurations = new HashSet<String>();
 
    private org.infinispan.transaction.lookup.TransactionManagerLookup transactionManagerlookup;
 
    private TransactionManager transactionManager;
 
    /**
     * Create a new instance using the default configuration.
     */
    public InfinispanRegionFactory() {
    }
 
    /**
     * Create a new instance using conifguration properties in <code>props</code>.
     * 
     * @param props
     *           Environmental properties; currently unused.
     */
    public InfinispanRegionFactory(Properties props) {
    }
 
    /** {@inheritDoc} */
    public CollectionRegion buildCollectionRegion(String regionName, Properties properties, CacheDataDescription metadata) throws CacheException {
       if (log.isDebugEnabled()) log.debug("Building collection cache region [" + regionName + "]");
       Cache cache = getCache(regionName, COLLECTION_KEY, properties);
       CacheAdapter cacheAdapter = CacheAdapterImpl.newInstance(cache);
       CollectionRegionImpl region = new CollectionRegionImpl(cacheAdapter, regionName, metadata, transactionManager, this);
       region.start();
       return region;
    }
 
    /** {@inheritDoc} */
    public EntityRegion buildEntityRegion(String regionName, Properties properties, CacheDataDescription metadata) throws CacheException {
       if (log.isDebugEnabled()) log.debug("Building entity cache region [" + regionName + "]");
       Cache cache = getCache(regionName, ENTITY_KEY, properties);
       CacheAdapter cacheAdapter = CacheAdapterImpl.newInstance(cache);
       EntityRegionImpl region = new EntityRegionImpl(cacheAdapter, regionName, metadata, transactionManager, this);
       region.start();
       return region;
    }
 
    /**
     * {@inheritDoc}
     */
    public QueryResultsRegion buildQueryResultsRegion(String regionName, Properties properties)
             throws CacheException {
       if (log.isDebugEnabled()) log.debug("Building query results cache region [" + regionName + "]");
       String cacheName = typeOverrides.get(QUERY_KEY).getCacheName();
       // If region name is not default one, lookup a cache for that region name
-      if (!regionName.equals("org.hibernate.cache.StandardQueryCache"))
+      if (!regionName.equals("org.hibernate.cache.internal.StandardQueryCache"))
          cacheName = regionName;
 
       Cache cache = getCache(cacheName, QUERY_KEY, properties);
       CacheAdapter cacheAdapter = CacheAdapterImpl.newInstance(cache);
       QueryResultsRegionImpl region = new QueryResultsRegionImpl(cacheAdapter, regionName, properties, transactionManager, this);
       region.start();
       return region;
    }
 
    /**
     * {@inheritDoc}
     */
    public TimestampsRegion buildTimestampsRegion(String regionName, Properties properties)
             throws CacheException {
       if (log.isDebugEnabled()) log.debug("Building timestamps cache region [" + regionName + "]");
       Cache cache = getCache(regionName, TIMESTAMPS_KEY, properties);
       CacheAdapter cacheAdapter = CacheAdapterImpl.newInstance(cache);
       TimestampsRegionImpl region = createTimestampsRegion(cacheAdapter, regionName);
       region.start();
       return region;
    }
 
    protected TimestampsRegionImpl createTimestampsRegion(CacheAdapter cacheAdapter, String regionName) {
       return new TimestampsRegionImpl(cacheAdapter, regionName, transactionManager, this);
    }
 
    protected TransactionManager getTransactionManager() {
       return transactionManager;
    }
 
    /**
     * {@inheritDoc}
     */
    public boolean isMinimalPutsEnabledByDefault() {
       return true;
    }
 
    @Override
    public AccessType getDefaultAccessType() {
       return AccessType.TRANSACTIONAL;
    }
 
    /**
     * {@inheritDoc}
     */
    public long nextTimestamp() {
       return System.currentTimeMillis() / 100;
    }
    
    public void setCacheManager(EmbeddedCacheManager manager) {
       this.manager = manager;
    }
 
    public EmbeddedCacheManager getCacheManager() {
       return manager;
    }
 
    /**
     * {@inheritDoc}
     */
    public void start(Settings settings, Properties properties) throws CacheException {
       log.debug("Starting Infinispan region factory");
       try {
          transactionManagerlookup = new HibernateTransactionManagerLookup(settings, properties);
          transactionManager = transactionManagerlookup.getTransactionManager();
          manager = createCacheManager(properties);
          initGenericDataTypeOverrides();
          Enumeration keys = properties.propertyNames();
          while (keys.hasMoreElements()) {
             String key = (String) keys.nextElement();
             int prefixLoc = -1;
             if ((prefixLoc = key.indexOf(PREFIX)) != -1) {
                dissectProperty(prefixLoc, key, properties);
             }
          }
          defineGenericDataTypeCacheConfigurations(settings, properties);
       } catch (CacheException ce) {
          throw ce;
       } catch (Throwable t) {
           throw new CacheException("Unable to start region factory", t);
       }
    }
 
    /**
     * {@inheritDoc}
     */
    public void stop() {
       log.debug("Stopping Infinispan CacheManager");
       manager.stop();
    }
    
    /**
     * Returns an unmodifiable map containing configured entity/collection type configuration overrides.
     * This method should be used primarily for testing/checking purpouses.
     * 
     * @return an unmodifiable map.
     */
    public Map<String, TypeOverrides> getTypeOverrides() {
       return Collections.unmodifiableMap(typeOverrides);
    }
    
    public Set<String> getDefinedConfigurations() {
       return Collections.unmodifiableSet(definedConfigurations);
    }
 
    protected EmbeddedCacheManager createCacheManager(Properties properties) throws CacheException {
       try {
          String configLoc = ConfigurationHelper.getString(INFINISPAN_CONFIG_RESOURCE_PROP, properties, DEF_INFINISPAN_CONFIG_RESOURCE);
          EmbeddedCacheManager manager = new DefaultCacheManager(configLoc, false);
          String globalStats = ConfigurationHelper.extractPropertyValue(INFINISPAN_GLOBAL_STATISTICS_PROP, properties);
          if (globalStats != null) {
             manager.getGlobalConfiguration().setExposeGlobalJmxStatistics(Boolean.parseBoolean(globalStats));
          }
          manager.start();
          return manager;
       } catch (IOException e) {
          throw new CacheException("Unable to create default cache manager", e);
       }
    }
 
    private Map<String, TypeOverrides> initGenericDataTypeOverrides() {
       TypeOverrides entityOverrides = new TypeOverrides();
       entityOverrides.setCacheName(DEF_ENTITY_RESOURCE);
       typeOverrides.put(ENTITY_KEY, entityOverrides);
       TypeOverrides collectionOverrides = new TypeOverrides();
       collectionOverrides.setCacheName(DEF_ENTITY_RESOURCE);
       typeOverrides.put(COLLECTION_KEY, collectionOverrides);
       TypeOverrides timestampOverrides = new TimestampTypeOverrides();
       timestampOverrides.setCacheName(DEF_TIMESTAMPS_RESOURCE);
       typeOverrides.put(TIMESTAMPS_KEY, timestampOverrides);
       TypeOverrides queryOverrides = new TypeOverrides();
       queryOverrides.setCacheName(DEF_QUERY_RESOURCE);
       typeOverrides.put(QUERY_KEY, queryOverrides);
       return typeOverrides;
    }
 
    private void dissectProperty(int prefixLoc, String key, Properties properties) {
       TypeOverrides cfgOverride = null;
       int suffixLoc = -1;
       if (!key.equals(INFINISPAN_CONFIG_RESOURCE_PROP) && (suffixLoc = key.indexOf(CONFIG_SUFFIX)) != -1) {
          cfgOverride = getOrCreateConfig(prefixLoc, key, suffixLoc);
          cfgOverride.setCacheName( ConfigurationHelper.extractPropertyValue(key, properties));
       } else if ((suffixLoc = key.indexOf(STRATEGY_SUFFIX)) != -1) {
          cfgOverride = getOrCreateConfig(prefixLoc, key, suffixLoc);
          cfgOverride.setEvictionStrategy( ConfigurationHelper.extractPropertyValue(key, properties));
       } else if ((suffixLoc = key.indexOf(WAKE_UP_INTERVAL_SUFFIX)) != -1) {
          cfgOverride = getOrCreateConfig(prefixLoc, key, suffixLoc);
          cfgOverride.setEvictionWakeUpInterval(Long.parseLong( ConfigurationHelper.extractPropertyValue(key, properties)));
       } else if ((suffixLoc = key.indexOf(MAX_ENTRIES_SUFFIX)) != -1) {
          cfgOverride = getOrCreateConfig(prefixLoc, key, suffixLoc);
          cfgOverride.setEvictionMaxEntries( ConfigurationHelper.getInt(key, properties, -1));
       } else if ((suffixLoc = key.indexOf(LIFESPAN_SUFFIX)) != -1) {
          cfgOverride = getOrCreateConfig(prefixLoc, key, suffixLoc);
          cfgOverride.setExpirationLifespan(Long.parseLong( ConfigurationHelper.extractPropertyValue(key, properties)));
       } else if ((suffixLoc = key.indexOf(MAX_IDLE_SUFFIX)) != -1) {
          cfgOverride = getOrCreateConfig(prefixLoc, key, suffixLoc);
          cfgOverride.setExpirationMaxIdle(Long.parseLong( ConfigurationHelper.extractPropertyValue(key, properties)));
       }
 //      else if ((suffixLoc = key.indexOf(STATISTICS_SUFFIX)) != -1) {
 //         cfgOverride = getOrCreateConfig(prefixLoc, key, suffixLoc);
 //         cfgOverride.setExposeStatistics(Boolean.parseBoolean(PropertiesHelper.extractPropertyValue(key, properties)));
 //      }
    }
 
    private TypeOverrides getOrCreateConfig(int prefixLoc, String key, int suffixLoc) {
       String name = key.substring(prefixLoc + PREFIX.length(), suffixLoc);
       TypeOverrides cfgOverride = typeOverrides.get(name);
       if (cfgOverride == null) {
          cfgOverride = new TypeOverrides();
          typeOverrides.put(name, cfgOverride);
       }
       return cfgOverride;
    }
 
    private void defineGenericDataTypeCacheConfigurations(Settings settings, Properties properties) throws CacheException {
       String[] defaultGenericDataTypes = new String[]{ENTITY_KEY, COLLECTION_KEY, TIMESTAMPS_KEY, QUERY_KEY};
       for (String type : defaultGenericDataTypes) {
          TypeOverrides override = overrideStatisticsIfPresent(typeOverrides.get(type), properties);
          String cacheName = override.getCacheName();
          Configuration newCacheCfg = override.createInfinispanConfiguration();
          // Apply overrides
          Configuration cacheConfig = manager.defineConfiguration(cacheName, cacheName, newCacheCfg);
          // Configure transaction manager
          cacheConfig = configureTransactionManager(cacheConfig, cacheName, properties);
          manager.defineConfiguration(cacheName, cacheName, cacheConfig);
          definedConfigurations.add(cacheName);
          override.validateInfinispanConfiguration(cacheConfig);
       }
    }
 
    private Cache getCache(String regionName, String typeKey, Properties properties) {
       TypeOverrides regionOverride = typeOverrides.get(regionName);
       if (!definedConfigurations.contains(regionName)) {
          String templateCacheName = null;
          Configuration regionCacheCfg = null;
          if (regionOverride != null) {
             if (log.isDebugEnabled()) log.debug("Cache region specific configuration exists: " + regionOverride);
             regionOverride = overrideStatisticsIfPresent(regionOverride, properties);
             regionCacheCfg = regionOverride.createInfinispanConfiguration();
             String cacheName = regionOverride.getCacheName();
             if (cacheName != null) // Region specific override with a given cache name
                templateCacheName = cacheName; 
             else // Region specific override without cache name, so template cache name is generic for data type.
                templateCacheName = typeOverrides.get(typeKey).getCacheName(); 
          } else {
             // No region specific overrides, template cache name is generic for data type.
             templateCacheName = typeOverrides.get(typeKey).getCacheName();
             regionCacheCfg = typeOverrides.get(typeKey).createInfinispanConfiguration();
          }
          // Configure transaction manager
          regionCacheCfg = configureTransactionManager(regionCacheCfg, templateCacheName, properties);
          // Apply overrides
          manager.defineConfiguration(regionName, templateCacheName, regionCacheCfg);
          definedConfigurations.add(regionName);
       }
       Cache cache = manager.getCache(regionName);
       if (!cache.getStatus().allowInvocations()) {
          cache.start();
       }
       return createCacheWrapper(cache.getAdvancedCache());
    }
 
    protected ClassLoaderAwareCache createCacheWrapper(AdvancedCache cache) {
       return new ClassLoaderAwareCache(cache, Thread.currentThread().getContextClassLoader());
    }
 
    private Configuration configureTransactionManager(Configuration regionOverrides, String templateCacheName, Properties properties) {
       // Get existing configuration to verify whether a tm was configured or not.
       Configuration templateConfig = manager.defineConfiguration(templateCacheName, new Configuration());
       String ispnTmLookupClassName = templateConfig.getTransactionManagerLookupClass();
       String hbTmLookupClassName = org.hibernate.cache.infinispan.tm.HibernateTransactionManagerLookup.class.getName();
       if (ispnTmLookupClassName != null && !ispnTmLookupClassName.equals(hbTmLookupClassName)) {
          log.debug("Infinispan is configured [" + ispnTmLookupClassName + "] with a different transaction manager lookup " +
                "class than Hibernate [" + hbTmLookupClassName + "]");
       } else {
          regionOverrides.setTransactionManagerLookup(transactionManagerlookup);
       }
       return regionOverrides;
    }
 
    private TypeOverrides overrideStatisticsIfPresent(TypeOverrides override, Properties properties) {
       String globalStats = ConfigurationHelper.extractPropertyValue(INFINISPAN_GLOBAL_STATISTICS_PROP, properties);
       if (globalStats != null) {
          override.setExposeStatistics(Boolean.parseBoolean(globalStats));
       }
       return override;
    }
 }
diff --git a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/JndiInfinispanRegionFactory.java b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/JndiInfinispanRegionFactory.java
index 5f82fecfce..aa8bced817 100644
--- a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/JndiInfinispanRegionFactory.java
+++ b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/JndiInfinispanRegionFactory.java
@@ -1,92 +1,91 @@
 /*
  * JBoss, Home of Professional Open Source.
  * Copyright 2009, Red Hat Middleware LLC, and individual contributors
  * as indicated by the @author tags. See the copyright.txt file in the
  * distribution for a full listing of individual contributors.
  *
  * This is free software; you can redistribute it and/or modify it
  * under the terms of the GNU Lesser General Public License as
  * published by the Free Software Foundation; either version 2.1 of
  * the License, or (at your option) any later version.
  *
  * This software is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * Lesser General Public License for more details.
  *
  * You should have received a copy of the GNU Lesser General Public
  * License along with this software; if not, write to the Free
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
 package org.hibernate.cache.infinispan;
 import java.util.Properties;
 import javax.naming.Context;
 import javax.naming.InitialContext;
 import javax.naming.NamingException;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.RegionFactory;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.internal.util.jndi.JndiHelper;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 /**
- * A {@link RegionFactory} for <a href="http://www.jboss.org/infinispan">Infinispan</a>-backed cache
+ * A {@link org.hibernate.cache.spi.RegionFactory} for <a href="http://www.jboss.org/infinispan">Infinispan</a>-backed cache
  * regions that finds its cache manager in JNDI rather than creating one itself.
  * 
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public class JndiInfinispanRegionFactory extends InfinispanRegionFactory {
 
    private static final Log log = LogFactory.getLog(JndiInfinispanRegionFactory.class);
 
    /**
     * Specifies the JNDI name under which the {@link EmbeddedCacheManager} to use is bound.
     * There is no default value -- the user must specify the property.
     */
    public static final String CACHE_MANAGER_RESOURCE_PROP = "hibernate.cache.infinispan.cachemanager";
 
    public JndiInfinispanRegionFactory() {
       super();
    }
 
    public JndiInfinispanRegionFactory(Properties props) {
       super(props);
    }
 
    @Override
    protected EmbeddedCacheManager createCacheManager(Properties properties) throws CacheException {
       String name = ConfigurationHelper.getString(CACHE_MANAGER_RESOURCE_PROP, properties, null);
       if (name == null)
          throw new CacheException("Configuration property " + CACHE_MANAGER_RESOURCE_PROP + " not set");
       return locateCacheManager(name, JndiHelper.extractJndiProperties(properties));
    }
 
    private EmbeddedCacheManager locateCacheManager(String jndiNamespace, Properties jndiProperties) {
       Context ctx = null;
       try {
           ctx = new InitialContext(jndiProperties);
           return (EmbeddedCacheManager) ctx.lookup(jndiNamespace);
       } catch (NamingException ne) {
           String msg = "Unable to retrieve CacheManager from JNDI [" + jndiNamespace + "]";
           log.info(msg, ne);
           throw new CacheException( msg );
       } finally {
           if (ctx != null) {
               try {
                   ctx.close();
               } catch( NamingException ne ) {
                   log.info("Unable to release initial context", ne);
               }
           }
       }
    }
 
    @Override
    public void stop() {
       // Do not attempt to stop a cache manager because it wasn't created by this region factory.
    }
 }
diff --git a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/access/TransactionalAccessDelegate.java b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/access/TransactionalAccessDelegate.java
index 2408d00a73..7229b9468a 100755
--- a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/access/TransactionalAccessDelegate.java
+++ b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/access/TransactionalAccessDelegate.java
@@ -1,170 +1,170 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. ¬†All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cache.infinispan.access;
 import javax.transaction.Transaction;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
-import org.hibernate.cache.access.SoftLock;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.spi.access.SoftLock;
 import org.hibernate.cache.infinispan.impl.BaseRegion;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.cache.infinispan.util.CacheHelper;
 import org.hibernate.cache.infinispan.util.FlagAdapter;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 /**
  * Defines the strategy for transactional access to entity or collection data in a Infinispan instance.
  * <p>
  * The intent of this class is to encapsulate common code and serve as a delegate for
  * {@link EntityRegionAccessStrategy} and {@link CollectionRegionAccessStrategy} implementations.
  * 
  * @author Brian Stansberry
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public class TransactionalAccessDelegate {
    private static final Log log = LogFactory.getLog(TransactionalAccessDelegate.class);
    protected final CacheAdapter cacheAdapter;
    protected final BaseRegion region;
    protected final PutFromLoadValidator putValidator;
 
    public TransactionalAccessDelegate(BaseRegion region, PutFromLoadValidator validator) {
       this.region = region;
       this.cacheAdapter = region.getCacheAdapter();
       this.putValidator = validator;
    }
 
    public Object get(Object key, long txTimestamp) throws CacheException {
       if (!region.checkValid()) 
          return null;
       Object val = cacheAdapter.get(key);
       if (val == null)
          putValidator.registerPendingPut(key);
       return val;
    }
 
    public boolean putFromLoad(Object key, Object value, long txTimestamp, Object version) throws CacheException {
       if (!region.checkValid())
          return false;
 
       if (!putValidator.acquirePutFromLoadLock(key))
          return false;
 
       try {
          cacheAdapter.putForExternalRead(key, value);
       } finally {
          putValidator.releasePutFromLoadLock(key);
       }
 
       return true;
    }
 
    public boolean putFromLoad(Object key, Object value, long txTimestamp, Object version, boolean minimalPutOverride)
             throws CacheException {
       // We ignore minimalPutOverride. Infinispan putForExternalRead is
       // already about as minimal as we can get; it will promptly return
       // if it discovers that the node we want to write to already exists
       return putFromLoad(key, value, txTimestamp, version);
    }
 
    public SoftLock lockItem(Object key, Object version) throws CacheException {
       return null;
    }
 
    public SoftLock lockRegion() throws CacheException {
       return null;
    }
 
    public void unlockItem(Object key, SoftLock lock) throws CacheException {
    }
 
    public void unlockRegion(SoftLock lock) throws CacheException {
    }
 
    public boolean insert(Object key, Object value, Object version) throws CacheException {
       if (!region.checkValid())
          return false;
 
       if (cacheAdapter.isClusteredInvalidation())
          cacheAdapter.withFlags(FlagAdapter.CACHE_MODE_LOCAL).put(key, value);
       else
          cacheAdapter.put(key, value);
 
       return true;
    }
 
    public boolean afterInsert(Object key, Object value, Object version) throws CacheException {
       return false;
    }
 
    public boolean update(Object key, Object value, Object currentVersion, Object previousVersion) throws CacheException {
       // We update whether or not the region is valid. Other nodes
       // may have already restored the region so they need to
       // be informed of the change.
       cacheAdapter.put(key, value);
       return true;
    }
 
    public boolean afterUpdate(Object key, Object value, Object currentVersion, Object previousVersion, SoftLock lock)
             throws CacheException {
       return false;
    }
 
    public void remove(Object key) throws CacheException {
       if (!putValidator.invalidateKey(key)) {
          throw new CacheException("Failed to invalidate pending putFromLoad calls for key " + key + " from region " + region.getName());
       }
       // We update whether or not the region is valid. Other nodes
       // may have already restored the region so they need to
       // be informed of the change.
       cacheAdapter.remove(key);
    }
 
    public void removeAll() throws CacheException {
        if (!putValidator.invalidateRegion()) {
          throw new CacheException("Failed to invalidate pending putFromLoad calls for region " + region.getName());
        }
       cacheAdapter.clear();
    }
 
    public void evict(Object key) throws CacheException {
       if (!putValidator.invalidateKey(key)) {
          throw new CacheException("Failed to invalidate pending putFromLoad calls for key " + key + " from region " + region.getName());
       }      
       cacheAdapter.remove(key);
    }
 
    public void evictAll() throws CacheException {
       if (!putValidator.invalidateRegion()) {
          throw new CacheException("Failed to invalidate pending putFromLoad calls for region " + region.getName());
       }
       Transaction tx = region.suspend();
       try {
          CacheHelper.sendEvictAllNotification(cacheAdapter, region.getAddress());
       } finally {
          region.resume(tx);
       }
    }
 }
diff --git a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/collection/CollectionRegionImpl.java b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/collection/CollectionRegionImpl.java
index 9b2b0ef5bf..1065e126bf 100644
--- a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/collection/CollectionRegionImpl.java
+++ b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/collection/CollectionRegionImpl.java
@@ -1,39 +1,39 @@
 package org.hibernate.cache.infinispan.collection;
 import javax.transaction.TransactionManager;
-import org.hibernate.cache.CacheDataDescription;
+import org.hibernate.cache.spi.CacheDataDescription;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.CollectionRegion;
-import org.hibernate.cache.RegionFactory;
-import org.hibernate.cache.access.AccessType;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
+import org.hibernate.cache.spi.CollectionRegion;
+import org.hibernate.cache.spi.RegionFactory;
+import org.hibernate.cache.spi.access.AccessType;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.cache.infinispan.access.PutFromLoadValidator;
 import org.hibernate.cache.infinispan.impl.BaseTransactionalDataRegion;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.infinispan.notifications.Listener;
 
 /**
  * @author Chris Bredesen
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 @Listener
 public class CollectionRegionImpl extends BaseTransactionalDataRegion implements CollectionRegion {
 
    public CollectionRegionImpl(CacheAdapter cacheAdapter, String name, CacheDataDescription metadata, 
             TransactionManager transactionManager, RegionFactory factory) {
       super(cacheAdapter, name, metadata, transactionManager, factory);
    }
 
    public CollectionRegionAccessStrategy buildAccessStrategy(AccessType accessType) throws CacheException {
       if (AccessType.READ_ONLY.equals(accessType)) {
          return new ReadOnlyAccess(this);
       } else if (AccessType.TRANSACTIONAL.equals(accessType)) {
          return new TransactionalAccess(this);
       }
-      throw new CacheException("Unsupported access type [" + accessType.getName() + "]");
+      throw new CacheException("Unsupported access type [" + accessType.getExternalName() + "]");
    }
 
    public PutFromLoadValidator getPutFromLoadValidator() {
       return new PutFromLoadValidator(transactionManager);
    }
 }
diff --git a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/collection/ReadOnlyAccess.java b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/collection/ReadOnlyAccess.java
index a7eed3acd4..7958513e23 100644
--- a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/collection/ReadOnlyAccess.java
+++ b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/collection/ReadOnlyAccess.java
@@ -1,40 +1,40 @@
 package org.hibernate.cache.infinispan.collection;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.access.SoftLock;
+import org.hibernate.cache.spi.access.SoftLock;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 /**
  * This defines the strategy for transactional access to collection data in a
  * Infinispan instance.
  * <p/>
  * The read-only access to a Infinispan really is still transactional, just with 
  * the extra semantic or guarantee that we will not update data.
  *
  * @author Chris Bredesen
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 class ReadOnlyAccess extends TransactionalAccess {
    private static final Log log = LogFactory.getLog(ReadOnlyAccess.class);
 
    ReadOnlyAccess(CollectionRegionImpl region) {
       super(region);
    }
    public SoftLock lockItem(Object key, Object version) throws CacheException {
       throw new UnsupportedOperationException("Illegal attempt to edit read only item");
    }
 
    public SoftLock lockRegion() throws CacheException {
       throw new UnsupportedOperationException("Illegal attempt to edit read only region");
    }
 
    public void unlockItem(Object key, SoftLock lock) throws CacheException {
       log.error("Illegal attempt to edit read only item");
    }
 
    public void unlockRegion(SoftLock lock) throws CacheException {
       log.error("Illegal attempt to edit read only item");
    }
 
 }
diff --git a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/collection/TransactionalAccess.java b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/collection/TransactionalAccess.java
index 68ccd0a19b..108f1548de 100644
--- a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/collection/TransactionalAccess.java
+++ b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/collection/TransactionalAccess.java
@@ -1,72 +1,72 @@
 package org.hibernate.cache.infinispan.collection;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.CollectionRegion;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
-import org.hibernate.cache.access.SoftLock;
+import org.hibernate.cache.spi.CollectionRegion;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
+import org.hibernate.cache.spi.access.SoftLock;
 import org.hibernate.cache.infinispan.access.TransactionalAccessDelegate;
 
 /**
  * Transactional collection region access for Infinispan.
  * 
  * @author Chris Bredesen
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 class TransactionalAccess implements CollectionRegionAccessStrategy {
 
    private final CollectionRegionImpl region;
    
    private final TransactionalAccessDelegate delegate;
 
    TransactionalAccess(CollectionRegionImpl region) {
       this.region = region;
       this.delegate = new TransactionalAccessDelegate(region, region.getPutFromLoadValidator());
    }
 
    public void evict(Object key) throws CacheException {
       delegate.evict(key);
    }
 
    public void evictAll() throws CacheException {
       delegate.evictAll();
    }
 
    public Object get(Object key, long txTimestamp) throws CacheException {
       return delegate.get(key, txTimestamp);
    }
 
    public boolean putFromLoad(Object key, Object value, long txTimestamp, Object version) throws CacheException {
       return delegate.putFromLoad(key, value, txTimestamp, version);
    }
 
    public boolean putFromLoad(Object key, Object value, long txTimestamp, Object version, boolean minimalPutOverride) throws CacheException {
       return delegate.putFromLoad(key, value, txTimestamp, version, minimalPutOverride);
    }
 
    public void remove(Object key) throws CacheException {
       delegate.remove(key);
    }
 
    public void removeAll() throws CacheException {
       delegate.removeAll();
    }
 
    public CollectionRegion getRegion() {
       return region;
    }
 
    public SoftLock lockItem(Object key, Object version) throws CacheException {
       return null;
    }
 
    public SoftLock lockRegion() throws CacheException {
       return null;
    }
 
    public void unlockItem(Object key, SoftLock lock) throws CacheException {
    }
 
    public void unlockRegion(SoftLock lock) throws CacheException {
    }
 
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/entity/EntityRegionImpl.java b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/entity/EntityRegionImpl.java
index 45c38dfb83..94b89f3a47 100644
--- a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/entity/EntityRegionImpl.java
+++ b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/entity/EntityRegionImpl.java
@@ -1,39 +1,39 @@
 package org.hibernate.cache.infinispan.entity;
 import javax.transaction.TransactionManager;
-import org.hibernate.cache.CacheDataDescription;
+import org.hibernate.cache.spi.CacheDataDescription;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.EntityRegion;
-import org.hibernate.cache.RegionFactory;
-import org.hibernate.cache.access.AccessType;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.spi.EntityRegion;
+import org.hibernate.cache.spi.RegionFactory;
+import org.hibernate.cache.spi.access.AccessType;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.infinispan.access.PutFromLoadValidator;
 import org.hibernate.cache.infinispan.impl.BaseTransactionalDataRegion;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.infinispan.notifications.Listener;
 
 /**
  * @author Chris Bredesen
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 @Listener
 public class EntityRegionImpl extends BaseTransactionalDataRegion implements EntityRegion {
 
    public EntityRegionImpl(CacheAdapter cacheAdapter, String name, CacheDataDescription metadata, 
             TransactionManager transactionManager, RegionFactory factory) {
       super(cacheAdapter, name, metadata, transactionManager, factory);
    }
 
    public EntityRegionAccessStrategy buildAccessStrategy(AccessType accessType) throws CacheException {
       if (AccessType.READ_ONLY.equals(accessType)) {
          return new ReadOnlyAccess(this);
       } else if (AccessType.TRANSACTIONAL.equals(accessType)) {
          return new TransactionalAccess(this);
       }
-      throw new CacheException("Unsupported access type [" + accessType.getName() + "]");
+      throw new CacheException("Unsupported access type [" + accessType.getExternalName() + "]");
    }
 
    public PutFromLoadValidator getPutFromLoadValidator() {
       return new PutFromLoadValidator(transactionManager);
    }
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/entity/ReadOnlyAccess.java b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/entity/ReadOnlyAccess.java
index 1736e4e063..213e066aa4 100644
--- a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/entity/ReadOnlyAccess.java
+++ b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/entity/ReadOnlyAccess.java
@@ -1,48 +1,48 @@
 package org.hibernate.cache.infinispan.entity;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.access.SoftLock;
+import org.hibernate.cache.spi.access.SoftLock;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 /**
  * A specialization of {@link TransactionalAccess} that ensures we never update data. Infinispan
  * access is always transactional.
  * 
  * @author Chris Bredesen
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 class ReadOnlyAccess extends TransactionalAccess {
    private static final Log log = LogFactory.getLog(ReadOnlyAccess.class);
 
    ReadOnlyAccess(EntityRegionImpl region) {
       super(region);
    }
 
    public SoftLock lockItem(Object key, Object version) throws CacheException {
       throw new UnsupportedOperationException("Illegal attempt to edit read only item");
    }
 
    public SoftLock lockRegion() throws CacheException {
       throw new UnsupportedOperationException("Illegal attempt to edit read only item");
    }
 
    public void unlockItem(Object key, SoftLock lock) throws CacheException {
       log.error("Illegal attempt to edit read only item");
    }
 
    public void unlockRegion(SoftLock lock) throws CacheException {
       log.error("Illegal attempt to edit read only item");
    }
 
    @Override
    public boolean update(Object key, Object value, Object currentVersion, Object previousVersion) throws CacheException {
       throw new UnsupportedOperationException("Illegal attempt to edit read only item");
    }
 
    @Override
    public boolean afterUpdate(Object key, Object value, Object currentVersion, Object previousVersion, SoftLock lock)
             throws CacheException {
       throw new UnsupportedOperationException("Illegal attempt to edit read only item");
    }
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/entity/TransactionalAccess.java b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/entity/TransactionalAccess.java
index 7fad9057ae..3ca63b8146 100644
--- a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/entity/TransactionalAccess.java
+++ b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/entity/TransactionalAccess.java
@@ -1,87 +1,87 @@
 package org.hibernate.cache.infinispan.entity;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.EntityRegion;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
-import org.hibernate.cache.access.SoftLock;
+import org.hibernate.cache.spi.EntityRegion;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.spi.access.SoftLock;
 import org.hibernate.cache.infinispan.access.TransactionalAccessDelegate;
 
 /**
  * Transactional entity region access for Infinispan.
  * 
  * @author Chris Bredesen
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 class TransactionalAccess implements EntityRegionAccessStrategy {
  
    private final EntityRegionImpl region;
    
    private final TransactionalAccessDelegate delegate;
 
    TransactionalAccess(EntityRegionImpl region) {
       this.region = region;
       this.delegate = new TransactionalAccessDelegate(region, region.getPutFromLoadValidator());
    }
 
    public void evict(Object key) throws CacheException {
       delegate.evict(key);
    }
 
    public void evictAll() throws CacheException {
       delegate.evictAll();
    }
 
    public Object get(Object key, long txTimestamp) throws CacheException {
       return delegate.get(key, txTimestamp);
    }
 
    public EntityRegion getRegion() {
       return this.region;
    }
 
    public boolean insert(Object key, Object value, Object version) throws CacheException {
       return delegate.insert(key, value, version);
    }
 
    public boolean putFromLoad(Object key, Object value, long txTimestamp, Object version) throws CacheException {
       return delegate.putFromLoad(key, value, txTimestamp, version);
    }
 
    public boolean putFromLoad(Object key, Object value, long txTimestamp, Object version, boolean minimalPutOverride) throws CacheException {
       return delegate.putFromLoad(key, value, txTimestamp, version, minimalPutOverride);
    }
 
    public void remove(Object key) throws CacheException {
       delegate.remove(key);
    }
 
    public void removeAll() throws CacheException {
       delegate.removeAll();
    }
 
    public boolean update(Object key, Object value, Object currentVersion, Object previousVersion) throws CacheException {
       return delegate.update(key, value, currentVersion, previousVersion);
    }
 
    public SoftLock lockItem(Object key, Object version) throws CacheException {
       return null;
    }
 
    public SoftLock lockRegion() throws CacheException {
       return null;
    }
 
    public void unlockItem(Object key, SoftLock lock) throws CacheException {
    }
 
    public void unlockRegion(SoftLock lock) throws CacheException {
    }
 
    public boolean afterInsert(Object key, Object value, Object version) throws CacheException {
       return false;
    }
 
    public boolean afterUpdate(Object key, Object value, Object currentVersion, Object previousVersion, SoftLock lock) throws CacheException {
       return false;
    }
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/impl/BaseGeneralDataRegion.java b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/impl/BaseGeneralDataRegion.java
index f21949db27..79e54e8cc7 100644
--- a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/impl/BaseGeneralDataRegion.java
+++ b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/impl/BaseGeneralDataRegion.java
@@ -1,37 +1,37 @@
 package org.hibernate.cache.infinispan.impl;
 import javax.transaction.TransactionManager;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.GeneralDataRegion;
-import org.hibernate.cache.RegionFactory;
+import org.hibernate.cache.spi.GeneralDataRegion;
+import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 
 /**
  * Support for Infinispan {@link GeneralDataRegion} implementors.
  * 
  * @author Chris Bredesen
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public abstract class BaseGeneralDataRegion extends BaseRegion implements GeneralDataRegion {
 
    public BaseGeneralDataRegion(CacheAdapter cacheAdapter, String name, TransactionManager transactionManager, RegionFactory factory) {
       super(cacheAdapter, name, transactionManager, factory);
    }
 
    public void evict(Object key) throws CacheException {
       cacheAdapter.evict(key);
    }
 
    public void evictAll() throws CacheException {
       cacheAdapter.clear();
    }
 
    public Object get(Object key) throws CacheException {
       return cacheAdapter.get(key);
    }
 
    public void put(Object key, Object value) throws CacheException {
       cacheAdapter.put(key, value);
    }
 
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/impl/BaseRegion.java b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/impl/BaseRegion.java
index a544643b42..3f9ccdd41d 100644
--- a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/impl/BaseRegion.java
+++ b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/impl/BaseRegion.java
@@ -1,303 +1,304 @@
 package org.hibernate.cache.infinispan.impl;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.atomic.AtomicReference;
 import javax.transaction.SystemException;
 import javax.transaction.Transaction;
 import javax.transaction.TransactionManager;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.Region;
-import org.hibernate.cache.RegionFactory;
+import org.hibernate.cache.spi.Region;
+import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cache.infinispan.util.AddressAdapter;
 import org.hibernate.cache.infinispan.util.AddressAdapterImpl;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.cache.infinispan.util.CacheHelper;
 import org.hibernate.cache.infinispan.util.FlagAdapter;
+
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryInvalidated;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryModified;
 import org.infinispan.notifications.cachelistener.event.CacheEntryInvalidatedEvent;
 import org.infinispan.notifications.cachelistener.event.CacheEntryModifiedEvent;
 import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
 import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 /**
  * Support for Infinispan {@link Region}s. Handles common "utility" methods for an underlying named
  * Cache. In other words, this implementation doesn't actually read or write data. Subclasses are
  * expected to provide core cache interaction appropriate to the semantics needed.
  * 
  * @author Chris Bredesen
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public abstract class BaseRegion implements Region {
    private enum InvalidateState { INVALID, CLEARING, VALID };
    private static final Log log = LogFactory.getLog(BaseRegion.class);
    private final String name;
    protected final CacheAdapter cacheAdapter;
    protected final AddressAdapter address;
    protected final Set<AddressAdapter> currentView = new HashSet<AddressAdapter>();
    protected final TransactionManager transactionManager;
    protected final boolean replication;
    protected final Object invalidationMutex = new Object();
    protected final AtomicReference<InvalidateState> invalidateState = new AtomicReference<InvalidateState>(InvalidateState.VALID);
    private final RegionFactory factory;
 
    public BaseRegion(CacheAdapter cacheAdapter, String name, TransactionManager transactionManager, RegionFactory factory) {
       this.cacheAdapter = cacheAdapter;
       this.name = name;
       this.transactionManager = transactionManager;
       this.replication = cacheAdapter.isClusteredReplication();
       this.address = this.cacheAdapter.getAddress();
       this.cacheAdapter.addListener(this);
       this.factory = factory;
    }
 
    public void start() {
       if (address != null) {
          synchronized (currentView) {
             List<AddressAdapter> view = cacheAdapter.getMembers();
             if (view != null) {
                currentView.addAll(view);
                establishInternalNodes();
             }
          }
       }
    }
 
    /**
     * Calls to this method must be done from synchronized (currentView) blocks only!!
     */
    private void establishInternalNodes() {
       Transaction tx = suspend();
       try {
          for (AddressAdapter member : currentView) {
             CacheHelper.initInternalEvict(cacheAdapter, member);
          }
       } finally {
          resume(tx);
       }
    }
 
    public String getName() {
       return name;
    }
 
    public CacheAdapter getCacheAdapter() {
       return cacheAdapter;
    }
 
    public long getElementCountInMemory() {
       if (checkValid()) {
          Set keySet = cacheAdapter.keySet();
          int size = cacheAdapter.size();
          if (CacheHelper.containsEvictAllNotification(keySet, address))
             size--;
          return size;
       }
       return 0;
    }
 
    /**
     * Not supported.
     * 
     * @return -1
     */
    public long getElementCountOnDisk() {
       return -1;
    }
 
    /**
     * Not supported.
     * 
     * @return -1
     */
    public long getSizeInMemory() {
       return -1;
    }
 
    public int getTimeout() {
       return 600; // 60 seconds
    }
 
    public long nextTimestamp() {
       return factory.nextTimestamp();
    }
 
    public Map toMap() {
       if (checkValid()) {
          // If copying causes issues, provide a lazily loaded Map
          Map map = new HashMap();
          Set<Map.Entry> entries = cacheAdapter.toMap().entrySet();
          for (Map.Entry entry : entries) {
             Object key = entry.getKey();
             if (!CacheHelper.isEvictAllNotification(key)) {
                map.put(key, entry.getValue());
             }
          }
          return map;
       }
       return Collections.EMPTY_MAP;
    }
 
    public void destroy() throws CacheException {
       try {
          cacheAdapter.stop();
 //         cacheAdapter.clear();
       } finally {
          cacheAdapter.removeListener(this);
       }
    }
 
    public boolean contains(Object key) {
       if (!checkValid())
          return false;
       // Reads are non-blocking in Infinispan, so not sure of the necessity of passing ZERO_LOCK_ACQUISITION_TIMEOUT
       return cacheAdapter.withFlags(FlagAdapter.ZERO_LOCK_ACQUISITION_TIMEOUT).containsKey(key);
    }
 
    public AddressAdapter getAddress() {
       return address;
    }
 
    public boolean checkValid() {
       boolean valid = isValid();
       if (!valid) {
          synchronized (invalidationMutex) {
             if (invalidateState.compareAndSet(InvalidateState.INVALID, InvalidateState.CLEARING)) {
                Transaction tx = suspend();
                try {
                   cacheAdapter.withFlags(FlagAdapter.CACHE_MODE_LOCAL, FlagAdapter.ZERO_LOCK_ACQUISITION_TIMEOUT).clear();
                   invalidateState.compareAndSet(InvalidateState.CLEARING, InvalidateState.VALID);
                }
                catch (Exception e) {
                   if (log.isTraceEnabled()) {
                      log.trace("Could not invalidate region: " + e.getLocalizedMessage());
                   }
                }
                finally {
                   resume(tx);
                }
             }
          }
          valid = isValid();
       }
       
       return valid;
    }
 
    protected boolean isValid() {
       return invalidateState.get() == InvalidateState.VALID;
    }
 
    /**
     * Performs a Infinispan <code>get(Fqn, Object)</code>
     *
     * @param key The key of the item to get
     * @param suppressTimeout should any TimeoutException be suppressed?
     * @param flagAdapters flags to add to the get invocation
     * @return The retrieved object
     * @throws CacheException issue managing transaction or talking to cache
     */
    protected Object get(Object key, boolean suppressTimeout, FlagAdapter... flagAdapters) throws CacheException {
       CacheAdapter localCacheAdapter = cacheAdapter;
       if (flagAdapters != null && flagAdapters.length > 0)
          localCacheAdapter = cacheAdapter.withFlags(flagAdapters);
 
       if (suppressTimeout)
          return localCacheAdapter.getAllowingTimeout(key);
       else
          return localCacheAdapter.get(key);
    }
    
    public Object getOwnerForPut() {
       Transaction tx = null;
       try {
           if (transactionManager != null) {
               tx = transactionManager.getTransaction();
           }
       } catch (SystemException se) {
           throw new CacheException("Could not obtain transaction", se);
       }
       return tx == null ? Thread.currentThread() : tx;
    }
 
    /**
     * Tell the TransactionManager to suspend any ongoing transaction.
     * 
     * @return the transaction that was suspended, or <code>null</code> if
     *         there wasn't one
     */
    public Transaction suspend() {
        Transaction tx = null;
        try {
            if (transactionManager != null) {
                tx = transactionManager.suspend();
            }
        } catch (SystemException se) {
            throw new CacheException("Could not suspend transaction", se);
        }
        return tx;
    }
 
    /**
     * Tell the TransactionManager to resume the given transaction
     * 
     * @param tx
     *            the transaction to suspend. May be <code>null</code>.
     */
    public void resume(Transaction tx) {
        try {
            if (tx != null)
                transactionManager.resume(tx);
        } catch (Exception e) {
            throw new CacheException("Could not resume transaction", e);
        }
    }
 
    @CacheEntryModified
    public void entryModified(CacheEntryModifiedEvent event) {
       handleEvictAllModification(event);
    }
 
    protected boolean handleEvictAllModification(CacheEntryModifiedEvent event) {
       if (!event.isPre() && (replication || event.isOriginLocal()) && CacheHelper.isEvictAllNotification(event.getKey(), event.getValue())) {
          if (log.isTraceEnabled()) log.trace("Set invalid state because marker cache entry was put: {0}", event);
          invalidateState.set(InvalidateState.INVALID);
          return true;
       }
       return false;
    }
 
    @CacheEntryInvalidated
    public void entryInvalidated(CacheEntryInvalidatedEvent event) {
       if (log.isTraceEnabled()) log.trace("Cache entry invalidated: {0}", event);
       handleEvictAllInvalidation(event);
    }
 
    protected boolean handleEvictAllInvalidation(CacheEntryInvalidatedEvent event) {
       if (!event.isPre() && CacheHelper.isEvictAllNotification(event.getKey())) {
          if (log.isTraceEnabled()) log.trace("Set invalid state because marker cache entry was invalidated: {0}", event);
          invalidateState.set(InvalidateState.INVALID);
          return true;
       }
       return false;
    }
 
    @ViewChanged
    public void viewChanged(ViewChangedEvent event) {
       synchronized (currentView) {
          List<AddressAdapter> view = AddressAdapterImpl.toAddressAdapter(event.getNewMembers());
          if (view != null) {
             currentView.addAll(view);
             establishInternalNodes();
          }
       }
    }
 
 }
diff --git a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/impl/BaseTransactionalDataRegion.java b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/impl/BaseTransactionalDataRegion.java
index 88c5aa331a..f0b4036340 100644
--- a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/impl/BaseTransactionalDataRegion.java
+++ b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/impl/BaseTransactionalDataRegion.java
@@ -1,32 +1,32 @@
 package org.hibernate.cache.infinispan.impl;
 import javax.transaction.TransactionManager;
-import org.hibernate.cache.CacheDataDescription;
-import org.hibernate.cache.RegionFactory;
-import org.hibernate.cache.TransactionalDataRegion;
+import org.hibernate.cache.spi.CacheDataDescription;
+import org.hibernate.cache.spi.RegionFactory;
+import org.hibernate.cache.spi.TransactionalDataRegion;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 
 /**
- * Support for Inifinispan {@link TransactionalDataRegion} implementors.
+ * Support for Inifinispan {@link org.hibernate.cache.spi.TransactionalDataRegion} implementors.
  * 
  * @author Chris Bredesen
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public abstract class BaseTransactionalDataRegion extends BaseRegion implements TransactionalDataRegion {
 
    private final CacheDataDescription metadata;
 
    public BaseTransactionalDataRegion(CacheAdapter cacheAdapter, String name, CacheDataDescription metadata, TransactionManager transactionManager, RegionFactory factory) {
       super(cacheAdapter, name, transactionManager, factory);
       this.metadata = metadata;
    }
 
    public CacheDataDescription getCacheDataDescription() {
       return metadata;
    }
 
    public boolean isTransactionAware() {
       return transactionManager != null;
    }
 
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/query/QueryResultsRegionImpl.java b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/query/QueryResultsRegionImpl.java
index 7e3c38edee..220ed3aee1 100644
--- a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/query/QueryResultsRegionImpl.java
+++ b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/query/QueryResultsRegionImpl.java
@@ -1,93 +1,94 @@
 package org.hibernate.cache.infinispan.query;
 import java.util.Properties;
 import javax.transaction.Transaction;
 import javax.transaction.TransactionManager;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.QueryResultsRegion;
-import org.hibernate.cache.RegionFactory;
+import org.hibernate.cache.spi.QueryResultsRegion;
+import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cache.infinispan.impl.BaseTransactionalDataRegion;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.cache.infinispan.util.CacheHelper;
 import org.hibernate.cache.infinispan.util.FlagAdapter;
+
 import org.infinispan.notifications.Listener;
 
 /**
  * @author Chris Bredesen
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 @Listener
 public class QueryResultsRegionImpl extends BaseTransactionalDataRegion implements QueryResultsRegion {
    private boolean localOnly;
 
    public QueryResultsRegionImpl(CacheAdapter cacheAdapter, String name, Properties properties, TransactionManager transactionManager, RegionFactory factory) {
       super(cacheAdapter, name, null, transactionManager, factory);
       // If Infinispan is using INVALIDATION for query cache, we don't want to propagate changes.
       // We use the Timestamps cache to manage invalidation
       localOnly = cacheAdapter.isClusteredInvalidation();
    }
 
    public void evict(Object key) throws CacheException {
       if (localOnly)
          cacheAdapter.withFlags(FlagAdapter.CACHE_MODE_LOCAL).remove(key);
       else 
          cacheAdapter.remove(key);
    }
 
    public void evictAll() throws CacheException {
       Transaction tx = suspend();
       try {
          CacheHelper.sendEvictAllNotification(cacheAdapter, getAddress());
       } finally {
          resume(tx);
       }
    }
 
    public Object get(Object key) throws CacheException {
       // If the region is not valid, skip cache store to avoid going remote to retrieve the query.
       // The aim of this is to maintain same logic/semantics as when state transfer was configured.
       // TODO: Once https://issues.jboss.org/browse/ISPN-835 has been resolved, revert to state transfer and remove workaround
       boolean skipCacheStore = false;
       if (!isValid())
          skipCacheStore = true;
 
       if (!checkValid())
          return null;
 
       // In Infinispan get doesn't acquire any locks, so no need to suspend the tx.
       // In the past, when get operations acquired locks, suspending the tx was a way
       // to avoid holding locks that would prevent updates.
       // Add a zero (or low) timeout option so we don't block
       // waiting for tx's that did a put to commit
       if (skipCacheStore)
          return get(key, true, FlagAdapter.ZERO_LOCK_ACQUISITION_TIMEOUT, FlagAdapter.SKIP_CACHE_STORE);
       else
          return get(key, true, FlagAdapter.ZERO_LOCK_ACQUISITION_TIMEOUT);
    }   
 
    public void put(Object key, Object value) throws CacheException {
       if (checkValid()) {
          // Here we don't want to suspend the tx. If we do:
          // 1) We might be caching query results that reflect uncommitted
          // changes. No tx == no WL on cache node, so other threads
          // can prematurely see those query results
          // 2) No tx == immediate replication. More overhead, plus we
          // spread issue #1 above around the cluster
 
          // Add a zero (or quite low) timeout option so we don't block.
          // Ignore any TimeoutException. Basically we forego caching the
          // query result in order to avoid blocking.
          // Reads are done with suspended tx, so they should not hold the
          // lock for long.  Not caching the query result is OK, since
          // any subsequent read will just see the old result with its
          // out-of-date timestamp; that result will be discarded and the
          // db query performed again.
          if (localOnly)
             cacheAdapter.withFlags(FlagAdapter.ZERO_LOCK_ACQUISITION_TIMEOUT, FlagAdapter.CACHE_MODE_LOCAL)
                .putAllowingTimeout(key, value);
          else 
             cacheAdapter.withFlags(FlagAdapter.ZERO_LOCK_ACQUISITION_TIMEOUT)
                .putAllowingTimeout(key, value);
       }
    }
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/timestamp/TimestampsRegionImpl.java b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/timestamp/TimestampsRegionImpl.java
index b5b672cd46..20bbef75f1 100644
--- a/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/timestamp/TimestampsRegionImpl.java
+++ b/hibernate-infinispan/src/main/java/org/hibernate/cache/infinispan/timestamp/TimestampsRegionImpl.java
@@ -1,149 +1,149 @@
 package org.hibernate.cache.infinispan.timestamp;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.ConcurrentHashMap;
 import javax.transaction.Transaction;
 import javax.transaction.TransactionManager;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.RegionFactory;
-import org.hibernate.cache.TimestampsRegion;
+import org.hibernate.cache.spi.RegionFactory;
+import org.hibernate.cache.spi.TimestampsRegion;
 import org.hibernate.cache.infinispan.impl.BaseGeneralDataRegion;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.cache.infinispan.util.CacheHelper;
 import org.hibernate.cache.infinispan.util.FlagAdapter;
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryModified;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryRemoved;
 import org.infinispan.notifications.cachelistener.event.CacheEntryInvalidatedEvent;
 import org.infinispan.notifications.cachelistener.event.CacheEntryModifiedEvent;
 import org.infinispan.notifications.cachelistener.event.CacheEntryRemovedEvent;
 
 /**
  * Defines the behavior of the timestamps cache region for Infinispan.
  * 
  * @author Chris Bredesen
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 @Listener
 public class TimestampsRegionImpl extends BaseGeneralDataRegion implements TimestampsRegion {
 
    private Map localCache = new ConcurrentHashMap();
 
    public TimestampsRegionImpl(CacheAdapter cacheAdapter, String name, TransactionManager transactionManager, RegionFactory factory) {
       super(cacheAdapter, name, transactionManager, factory);
       cacheAdapter.addListener(this);
       populateLocalCache();
    }
 
    @Override
    public void evict(Object key) throws CacheException {
       // TODO Is this a valid operation on a timestamps cache?
       cacheAdapter.remove(key);
    }
 
    public void evictAll() throws CacheException {
       // TODO Is this a valid operation on a timestamps cache?
       Transaction tx = suspend();
       try {        
          CacheHelper.sendEvictAllNotification(cacheAdapter, getAddress());
       } finally {
          resume(tx);
       }
    }
 
    public Object get(Object key) throws CacheException {
       Object value = localCache.get(key);
 
       // If the region is not valid, skip cache store to avoid going remote to retrieve the query.
       // The aim of this is to maintain same logic/semantics as when state transfer was configured.
       // TODO: Once https://issues.jboss.org/browse/ISPN-835 has been resolved, revert to state transfer and remove workaround
       boolean skipCacheStore = false;
       if (!isValid())
          skipCacheStore = true;
 
       if (value == null && checkValid()) {
          if (skipCacheStore)
             value = get(key, false, FlagAdapter.SKIP_CACHE_STORE);
          else
             value = get(key, false);
 
          if (value != null)
             localCache.put(key, value);
       }
       return value;
    }
 
    public void put(Object key, Object value) throws CacheException {
       // Don't hold the JBC node lock throughout the tx, as that
       // prevents reads and other updates
       Transaction tx = suspend();
       try {
          // We ensure ASYNC semantics (JBCACHE-1175) and make sure previous
          // value is not loaded from cache store cos it's not needed.
          cacheAdapter.withFlags(FlagAdapter.FORCE_ASYNCHRONOUS).put(key, value);
       } catch (Exception e) {
          throw new CacheException(e);
       } finally {
          resume(tx);
       }
    }
 
    @Override
    public void destroy() throws CacheException {
       localCache.clear();
       cacheAdapter.removeListener(this);
       super.destroy();
    }
 
    /**
     * Monitors cache events and updates the local cache
     * 
     * @param event
     */
    @CacheEntryModified
    public void nodeModified(CacheEntryModifiedEvent event) {
       if (!handleEvictAllModification(event) && !event.isPre()) {
          localCache.put(event.getKey(), event.getValue());
       }
    }
 
    /**
     * Monitors cache events and updates the local cache
     * 
     * @param event
     */
    @CacheEntryRemoved
    public void nodeRemoved(CacheEntryRemovedEvent event) {
       if (event.isPre()) return;
       localCache.remove(event.getKey());
    }
 
    @Override
    protected boolean handleEvictAllModification(CacheEntryModifiedEvent event) {
       boolean result = super.handleEvictAllModification(event);
       if (result) {
          localCache.clear();
       }
       return result;
    }
 
    @Override
    protected boolean handleEvictAllInvalidation(CacheEntryInvalidatedEvent event) {
       boolean result = super.handleEvictAllInvalidation(event);
       if (result) {
          localCache.clear();
       }
       return result;
    }
 
    /**
     * Brings all data from the distributed cache into our local cache.
     */
    private void populateLocalCache() {
       Set children = cacheAdapter.keySet();
       for (Object key : children)
          get(key);
    }
 
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractEntityCollectionRegionTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractEntityCollectionRegionTestCase.java
index aeaa155ea5..adad90e110 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractEntityCollectionRegionTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractEntityCollectionRegionTestCase.java
@@ -1,123 +1,123 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. ¬†All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan;
 
 import java.util.Properties;
 
-import org.hibernate.cache.CacheDataDescription;
-import org.hibernate.cache.RegionFactory;
-import org.hibernate.cache.TransactionalDataRegion;
-import org.hibernate.cache.access.AccessType;
+import org.hibernate.cache.spi.CacheDataDescription;
+import org.hibernate.cache.spi.RegionFactory;
+import org.hibernate.cache.spi.TransactionalDataRegion;
+import org.hibernate.cache.spi.access.AccessType;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Configuration;
 
 import org.junit.Test;
 
 import org.hibernate.testing.ServiceRegistryBuilder;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertTrue;
 
 /**
  * Base class for tests of EntityRegion and CollectionRegion implementations.
  *
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public abstract class AbstractEntityCollectionRegionTestCase extends AbstractRegionImplTestCase {
 	@Test
 	public void testSupportedAccessTypes() throws Exception {
 		supportedAccessTypeTest();
 	}
 
 	private void supportedAccessTypeTest() throws Exception {
 		Configuration cfg = CacheTestUtil.buildConfiguration( "test", InfinispanRegionFactory.class, true, false );
 		String entityCfg = "entity";
 		cfg.setProperty( InfinispanRegionFactory.ENTITY_CACHE_RESOURCE_PROP, entityCfg );
 		InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
 				ServiceRegistryBuilder.buildServiceRegistry( cfg.getProperties() ),
 				cfg,
 				getCacheTestSupport()
 		);
 		supportedAccessTypeTest( regionFactory, cfg.getProperties() );
 	}
 
 	/**
 	 * Creates a Region using the given factory, and then ensure that it handles calls to
 	 * buildAccessStrategy as expected when all the various {@link AccessType}s are passed as
 	 * arguments.
 	 */
 	protected abstract void supportedAccessTypeTest(RegionFactory regionFactory, Properties properties);
 
 	@Test
 	public void testIsTransactionAware() throws Exception {
 		Configuration cfg = CacheTestUtil.buildConfiguration( "test", InfinispanRegionFactory.class, true, false );
 		InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
 				ServiceRegistryBuilder.buildServiceRegistry( cfg.getProperties() ),
 				cfg,
 				getCacheTestSupport()
 		);
 		TransactionalDataRegion region = (TransactionalDataRegion) createRegion(
 				regionFactory, "test/test", cfg.getProperties(), getCacheDataDescription()
 		);
 		assertTrue( "Region is transaction-aware", region.isTransactionAware() );
 		CacheTestUtil.stopRegionFactory( regionFactory, getCacheTestSupport() );
 		cfg = CacheTestUtil.buildConfiguration( "test", InfinispanRegionFactory.class, true, false );
 		// Make it non-transactional
 		cfg.getProperties().remove( AvailableSettings.JTA_PLATFORM );
 		regionFactory = CacheTestUtil.startRegionFactory(
 				ServiceRegistryBuilder.buildServiceRegistry( cfg.getProperties() ),
 				cfg,
 				getCacheTestSupport()
 		);
 		region = (TransactionalDataRegion) createRegion(
 				regionFactory, "test/test", cfg.getProperties(), getCacheDataDescription()
 		);
 		assertFalse( "Region is not transaction-aware", region.isTransactionAware() );
 		CacheTestUtil.stopRegionFactory( regionFactory, getCacheTestSupport() );
 	}
 
 	@Test
 	public void testGetCacheDataDescription() throws Exception {
 		Configuration cfg = CacheTestUtil.buildConfiguration( "test", InfinispanRegionFactory.class, true, false );
 		InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
 				ServiceRegistryBuilder.buildServiceRegistry( cfg.getProperties() ),
 				cfg,
 				getCacheTestSupport()
 		);
 		TransactionalDataRegion region = (TransactionalDataRegion) createRegion(
 				regionFactory, "test/test", cfg.getProperties(), getCacheDataDescription()
 		);
 		CacheDataDescription cdd = region.getCacheDataDescription();
 		assertNotNull( cdd );
 		CacheDataDescription expected = getCacheDataDescription();
 		assertEquals( expected.isMutable(), cdd.isMutable() );
 		assertEquals( expected.isVersioned(), cdd.isVersioned() );
 		assertEquals( expected.getVersionComparator(), cdd.getVersionComparator() );
 	}
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractGeneralDataRegionTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractGeneralDataRegionTestCase.java
index 8ee94d5db0..d14652454e 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractGeneralDataRegionTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractGeneralDataRegionTestCase.java
@@ -1,228 +1,226 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. ¬†All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan;
 
 import java.util.Set;
 
 import org.infinispan.transaction.tm.BatchModeTransactionManager;
 import org.jboss.logging.Logger;
 
-import org.hibernate.cache.GeneralDataRegion;
-import org.hibernate.cache.QueryResultsRegion;
-import org.hibernate.cache.Region;
+import org.hibernate.cache.spi.GeneralDataRegion;
+import org.hibernate.cache.spi.QueryResultsRegion;
+import org.hibernate.cache.spi.Region;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.cfg.Configuration;
-import org.hibernate.service.ServiceRegistry;
 import org.hibernate.service.ServiceRegistryBuilder;
-import org.hibernate.service.internal.BasicServiceRegistryImpl;
 
 import org.junit.Test;
 
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNull;
 
 /**
  * Base class for tests of QueryResultsRegion and TimestampsRegion.
  *
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public abstract class AbstractGeneralDataRegionTestCase extends AbstractRegionImplTestCase {
 	private static final Logger log = Logger.getLogger( AbstractGeneralDataRegionTestCase.class );
 
 	protected static final String KEY = "Key";
 
 	protected static final String VALUE1 = "value1";
 	protected static final String VALUE2 = "value2";
 
 	protected Configuration createConfiguration() {
 		return CacheTestUtil.buildConfiguration( "test", InfinispanRegionFactory.class, false, true );
 	}
 
 	@Override
 	protected void putInRegion(Region region, Object key, Object value) {
 		((GeneralDataRegion) region).put( key, value );
 	}
 
 	@Override
 	protected void removeFromRegion(Region region, Object key) {
 		((GeneralDataRegion) region).evict( key );
 	}
 
 	@Test
 	public void testEvict() throws Exception {
 		evictOrRemoveTest();
 	}
 
 	private void evictOrRemoveTest() throws Exception {
 		Configuration cfg = createConfiguration();
 		InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
 				new ServiceRegistryBuilder( cfg.getProperties() ).buildServiceRegistry(),
 				cfg,
 				getCacheTestSupport()
 		);
 		CacheAdapter localCache = getInfinispanCache( regionFactory );
 		boolean invalidation = localCache.isClusteredInvalidation();
 
 		// Sleep a bit to avoid concurrent FLUSH problem
 		avoidConcurrentFlush();
 
 		GeneralDataRegion localRegion = (GeneralDataRegion) createRegion(
 				regionFactory,
 				getStandardRegionName( REGION_PREFIX ), cfg.getProperties(), null
 		);
 
 		cfg = createConfiguration();
 		regionFactory = CacheTestUtil.startRegionFactory(
 				new ServiceRegistryBuilder( cfg.getProperties() ).buildServiceRegistry(),
 				cfg,
 				getCacheTestSupport()
 		);
 
 		GeneralDataRegion remoteRegion = (GeneralDataRegion) createRegion(
 				regionFactory,
 				getStandardRegionName( REGION_PREFIX ),
 				cfg.getProperties(),
 				null
 		);
 
 		assertNull( "local is clean", localRegion.get( KEY ) );
 		assertNull( "remote is clean", remoteRegion.get( KEY ) );
 
 		localRegion.put( KEY, VALUE1 );
 		assertEquals( VALUE1, localRegion.get( KEY ) );
 
 		// allow async propagation
 		sleep( 250 );
 		Object expected = invalidation ? null : VALUE1;
 		assertEquals( expected, remoteRegion.get( KEY ) );
 
 		localRegion.evict( KEY );
 
 		// allow async propagation
 		sleep( 250 );
 		assertEquals( null, localRegion.get( KEY ) );
 		assertEquals( null, remoteRegion.get( KEY ) );
 	}
 
 	protected abstract String getStandardRegionName(String regionPrefix);
 
 	/**
 	 * Test method for {@link QueryResultsRegion#evictAll()}.
 	 * <p/>
 	 * FIXME add testing of the "immediately without regard for transaction isolation" bit in the
 	 * CollectionRegionAccessStrategy API.
 	 */
 	public void testEvictAll() throws Exception {
 		evictOrRemoveAllTest( "entity" );
 	}
 
 	private void evictOrRemoveAllTest(String configName) throws Exception {
 		Configuration cfg = createConfiguration();
 		InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
 				new ServiceRegistryBuilder( cfg.getProperties() ).buildServiceRegistry(),
 				cfg,
 				getCacheTestSupport()
 		);
 		CacheAdapter localCache = getInfinispanCache( regionFactory );
 
 		// Sleep a bit to avoid concurrent FLUSH problem
 		avoidConcurrentFlush();
 
 		GeneralDataRegion localRegion = (GeneralDataRegion) createRegion(
 				regionFactory,
 				getStandardRegionName( REGION_PREFIX ),
 				cfg.getProperties(),
 				null
 		);
 
 		cfg = createConfiguration();
 		regionFactory = CacheTestUtil.startRegionFactory(
 				new ServiceRegistryBuilder( cfg.getProperties() ).buildServiceRegistry(),
 				cfg,
 				getCacheTestSupport()
 		);
 		CacheAdapter remoteCache = getInfinispanCache( regionFactory );
 
 		// Sleep a bit to avoid concurrent FLUSH problem
 		avoidConcurrentFlush();
 
 		GeneralDataRegion remoteRegion = (GeneralDataRegion) createRegion(
 				regionFactory,
 				getStandardRegionName( REGION_PREFIX ),
 				cfg.getProperties(),
 				null
 		);
 
 		Set keys = localCache.keySet();
 		assertEquals( "No valid children in " + keys, 0, getValidKeyCount( keys ) );
 
 		keys = remoteCache.keySet();
 		assertEquals( "No valid children in " + keys, 0, getValidKeyCount( keys ) );
 
 		assertNull( "local is clean", localRegion.get( KEY ) );
 		assertNull( "remote is clean", remoteRegion.get( KEY ) );
 
 		localRegion.put( KEY, VALUE1 );
 		assertEquals( VALUE1, localRegion.get( KEY ) );
 
 		// Allow async propagation
 		sleep( 250 );
 
 		remoteRegion.put( KEY, VALUE1 );
 		assertEquals( VALUE1, remoteRegion.get( KEY ) );
 
 		// Allow async propagation
 		sleep( 250 );
 
 		localRegion.evictAll();
 
 		// allow async propagation
 		sleep( 250 );
 		// This should re-establish the region root node in the optimistic case
 		assertNull( localRegion.get( KEY ) );
 		assertEquals( "No valid children in " + keys, 0, getValidKeyCount( localCache.keySet() ) );
 
 		// Re-establishing the region root on the local node doesn't
 		// propagate it to other nodes. Do a get on the remote node to re-establish
 		// This only adds a node in the case of optimistic locking
 		assertEquals( null, remoteRegion.get( KEY ) );
 		assertEquals( "No valid children in " + keys, 0, getValidKeyCount( remoteCache.keySet() ) );
 
 		assertEquals( "local is clean", null, localRegion.get( KEY ) );
 		assertEquals( "remote is clean", null, remoteRegion.get( KEY ) );
 	}
 
 	protected void rollback() {
 		try {
 			BatchModeTransactionManager.getInstance().rollback();
 		}
 		catch (Exception e) {
 			log.error( e.getMessage(), e );
 		}
 	}
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractNonFunctionalTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractNonFunctionalTestCase.java
index 6b4ac1d498..a9ad4b88b5 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractNonFunctionalTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractNonFunctionalTestCase.java
@@ -1,118 +1,118 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. ¬†All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan;
 
 import java.util.Set;
 
 import org.infinispan.Cache;
 import org.jboss.logging.Logger;
 
-import org.hibernate.cache.RegionFactory;
+import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cache.infinispan.util.CacheHelper;
 
 import org.junit.After;
 import org.junit.Before;
 
 import org.hibernate.test.cache.infinispan.util.CacheTestSupport;
 
 /**
  * Base class for all non-functional tests of Infinispan integration.
  *
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public abstract class AbstractNonFunctionalTestCase extends org.hibernate.testing.junit4.BaseUnitTestCase {
 	private static final Logger log = Logger.getLogger( AbstractNonFunctionalTestCase.class );
 
 	public static final String REGION_PREFIX = "test";
 
 	private static final String PREFER_IPV4STACK = "java.net.preferIPv4Stack";
 	private String preferIPv4Stack;
 
     private CacheTestSupport testSupport = new CacheTestSupport();
 
 	@Before
     public void prepareCacheSupport() throws Exception {
 		preferIPv4Stack = System.getProperty( PREFER_IPV4STACK );
 		System.setProperty( PREFER_IPV4STACK, "true" );
 
         testSupport.setUp();
     }
 
     @After
     public void releaseCachSupport() throws Exception {
         testSupport.tearDown();
 
 		if ( preferIPv4Stack == null ) {
 			System.clearProperty( PREFER_IPV4STACK );
 		}
 		else {
 			System.setProperty( PREFER_IPV4STACK, preferIPv4Stack );
 		}
     }
 
     protected void registerCache(Cache cache) {
         testSupport.registerCache(cache);
     }
 
     protected void unregisterCache(Cache cache) {
         testSupport.unregisterCache(cache);
     }
 
     protected void registerFactory(RegionFactory factory) {
         testSupport.registerFactory(factory);
     }
 
     protected void unregisterFactory(RegionFactory factory) {
         testSupport.unregisterFactory(factory);
     }
 
     protected CacheTestSupport getCacheTestSupport() {
         return testSupport;
     }
 
     protected void sleep(long ms) {
         try {
             Thread.sleep(ms);
         }
         catch (InterruptedException e) {
             log.warn("Interrupted during sleep", e);
         }
     }
 
     protected void avoidConcurrentFlush() {
         testSupport.avoidConcurrentFlush();
     }
 
     protected int getValidKeyCount(Set keys) {
        int result = 0;
        for (Object key : keys) {
           if (!(CacheHelper.isEvictAllNotification(key))) {
              result++;
           }
        }
        return result;
    }
 
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractRegionImplTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractRegionImplTestCase.java
index 92208d2ede..d7202c2ac2 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractRegionImplTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/AbstractRegionImplTestCase.java
@@ -1,53 +1,54 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. ¬†All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan;
 import java.util.Properties;
-import org.hibernate.cache.CacheDataDescription;
-import org.hibernate.cache.Region;
-import org.hibernate.cache.impl.CacheDataDescriptionImpl;
+
+import org.hibernate.cache.internal.CacheDataDescriptionImpl;
+import org.hibernate.cache.spi.CacheDataDescription;
+import org.hibernate.cache.spi.Region;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.internal.util.compare.ComparableComparator;
 
 /**
  * Base class for tests of Region implementations.
  * 
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public abstract class AbstractRegionImplTestCase extends AbstractNonFunctionalTestCase {
 
    protected abstract CacheAdapter getInfinispanCache(InfinispanRegionFactory regionFactory);
 
    protected abstract Region createRegion(InfinispanRegionFactory regionFactory, String regionName, Properties properties, CacheDataDescription cdd);
 
    protected abstract void putInRegion(Region region, Object key, Object value);
 
    protected abstract void removeFromRegion(Region region, Object key);
 
    protected CacheDataDescription getCacheDataDescription() {
       return new CacheDataDescriptionImpl(true, true, ComparableComparator.INSTANCE);
    }
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/InfinispanRegionFactoryTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/InfinispanRegionFactoryTestCase.java
index a3976d1a3a..5e3ec58215 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/InfinispanRegionFactoryTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/InfinispanRegionFactoryTestCase.java
@@ -1,536 +1,536 @@
 /*
  * JBoss, Home of Professional Open Source.
  * Copyright 2009, Red Hat, Inc. and/or it's affiliates, and individual contributors
  * as indicated by the @author tags. See the copyright.txt file in the
  * distribution for a full listing of individual contributors.
  *
  * This is free software; you can redistribute it and/or modify it
  * under the terms of the GNU Lesser General Public License as
  * published by the Free Software Foundation; either version 2.1 of
  * the License, or (at your option) any later version.
  *
  * This software is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * Lesser General Public License for more details.
  *
  * You should have received a copy of the GNU Lesser General Public
  * License along with this software; if not, write to the Free
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
 package org.hibernate.test.cache.infinispan;
 import java.util.Properties;
 import junit.framework.TestCase;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.collection.CollectionRegionImpl;
 import org.hibernate.cache.infinispan.entity.EntityRegionImpl;
 import org.hibernate.cache.infinispan.query.QueryResultsRegionImpl;
 import org.hibernate.cache.infinispan.timestamp.TimestampsRegionImpl;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.infinispan.config.Configuration;
 import org.infinispan.config.Configuration.CacheMode;
 import org.infinispan.eviction.EvictionStrategy;
 import org.infinispan.manager.DefaultCacheManager;
 import org.infinispan.manager.EmbeddedCacheManager;
 
 /**
  * InfinispanRegionFactoryTestCase.
  * 
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public class InfinispanRegionFactoryTestCase extends TestCase {
 
    public void testConfigurationProcessing() {
       final String person = "com.acme.Person";
       final String addresses = "com.acme.Person.addresses";
       Properties p = new Properties();
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.cfg", "person-cache");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.eviction.strategy", "LRU");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.eviction.wake_up_interval", "2000");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.eviction.max_entries", "5000");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.expiration.lifespan", "60000");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.expiration.max_idle", "30000");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.addresses.cfg", "person-addresses-cache");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.addresses.expiration.lifespan", "120000");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.addresses.expiration.max_idle", "60000");
       p.setProperty("hibernate.cache.infinispan.query.cfg", "my-query-cache");
       p.setProperty("hibernate.cache.infinispan.query.eviction.strategy", "FIFO");
       p.setProperty("hibernate.cache.infinispan.query.eviction.wake_up_interval", "3000");
       p.setProperty("hibernate.cache.infinispan.query.eviction.max_entries", "10000");
 
       InfinispanRegionFactory factory = new InfinispanRegionFactory();
       factory.start(null, p);
 
       assertEquals("entity", factory.getTypeOverrides().get("entity").getCacheName());
       assertEquals("entity", factory.getTypeOverrides().get("collection").getCacheName());
       assertEquals("timestamps", factory.getTypeOverrides().get("timestamps").getCacheName());
 
       assertEquals("person-cache", factory.getTypeOverrides().get(person).getCacheName());
       assertEquals(EvictionStrategy.LRU, factory.getTypeOverrides().get(person).getEvictionStrategy());
       assertEquals(2000, factory.getTypeOverrides().get(person).getEvictionWakeUpInterval());
       assertEquals(5000, factory.getTypeOverrides().get(person).getEvictionMaxEntries());
       assertEquals(60000, factory.getTypeOverrides().get(person).getExpirationLifespan());
       assertEquals(30000, factory.getTypeOverrides().get(person).getExpirationMaxIdle());
 
       assertEquals("person-addresses-cache", factory.getTypeOverrides().get(addresses).getCacheName());
       assertEquals(120000, factory.getTypeOverrides().get(addresses).getExpirationLifespan());
       assertEquals(60000, factory.getTypeOverrides().get(addresses).getExpirationMaxIdle());
 
       assertEquals("my-query-cache", factory.getTypeOverrides().get("query").getCacheName());
       assertEquals(EvictionStrategy.FIFO, factory.getTypeOverrides().get("query").getEvictionStrategy());
       assertEquals(3000, factory.getTypeOverrides().get("query").getEvictionWakeUpInterval());
       assertEquals(10000, factory.getTypeOverrides().get("query").getEvictionMaxEntries());
    }
    
    public void testBuildEntityCollectionRegionsPersonPlusEntityCollectionOverrides() {
       final String person = "com.acme.Person";
       final String address = "com.acme.Address";
       final String car = "com.acme.Car";
       final String addresses = "com.acme.Person.addresses";
       final String parts = "com.acme.Car.parts";
       Properties p = new Properties();
       // First option, cache defined for entity and overrides for generic entity data type and entity itself.
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.cfg", "person-cache");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.eviction.strategy", "LRU");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.eviction.wake_up_interval", "2000");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.eviction.max_entries", "5000");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.expiration.lifespan", "60000");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.expiration.max_idle", "30000");
       p.setProperty("hibernate.cache.infinispan.entity.cfg", "myentity-cache");
       p.setProperty("hibernate.cache.infinispan.entity.eviction.strategy", "FIFO");
       p.setProperty("hibernate.cache.infinispan.entity.eviction.wake_up_interval", "3000");
       p.setProperty("hibernate.cache.infinispan.entity.eviction.max_entries", "20000");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.addresses.cfg", "addresses-cache");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.addresses.eviction.strategy", "FIFO");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.addresses.eviction.wake_up_interval", "2500");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.addresses.eviction.max_entries", "5500");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.addresses.expiration.lifespan", "65000");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.addresses.expiration.max_idle", "35000");
       p.setProperty("hibernate.cache.infinispan.collection.cfg", "mycollection-cache");
       p.setProperty("hibernate.cache.infinispan.collection.eviction.strategy", "LRU");
       p.setProperty("hibernate.cache.infinispan.collection.eviction.wake_up_interval", "3500");
       p.setProperty("hibernate.cache.infinispan.collection.eviction.max_entries", "25000");
       InfinispanRegionFactory factory = new InfinispanRegionFactory();
       factory.start(null, p);
       EmbeddedCacheManager manager = factory.getCacheManager();
       manager.getGlobalConfiguration().setTransportClass(null);
       try {
          assertFalse(manager.getGlobalConfiguration().isExposeGlobalJmxStatistics());
          assertNotNull(factory.getTypeOverrides().get(person));
          assertFalse(factory.getDefinedConfigurations().contains(person));
          assertNotNull(factory.getTypeOverrides().get(addresses));
          assertFalse(factory.getDefinedConfigurations().contains(addresses));
          CacheAdapter cache = null;
 
          EntityRegionImpl region = (EntityRegionImpl) factory.buildEntityRegion(person, p, null);
          assertNotNull(factory.getTypeOverrides().get(person));
          assertTrue(factory.getDefinedConfigurations().contains(person));
          assertNull(factory.getTypeOverrides().get(address));
          cache = region.getCacheAdapter();
          Configuration cacheCfg = cache.getConfiguration();
          assertEquals(EvictionStrategy.LRU, cacheCfg.getEvictionStrategy());
          assertEquals(2000, cacheCfg.getEvictionWakeUpInterval());
          assertEquals(5000, cacheCfg.getEvictionMaxEntries());
          assertEquals(60000, cacheCfg.getExpirationLifespan());
          assertEquals(30000, cacheCfg.getExpirationMaxIdle());
          assertFalse(cacheCfg.isExposeJmxStatistics());
 
          region = (EntityRegionImpl) factory.buildEntityRegion(address, p, null);
          assertNotNull(factory.getTypeOverrides().get(person));
          assertTrue(factory.getDefinedConfigurations().contains(person));
          assertNull(factory.getTypeOverrides().get(address));
          cache = region.getCacheAdapter();
          cacheCfg = cache.getConfiguration();
          assertEquals(EvictionStrategy.FIFO, cacheCfg.getEvictionStrategy());
          assertEquals(3000, cacheCfg.getEvictionWakeUpInterval());
          assertEquals(20000, cacheCfg.getEvictionMaxEntries());
          assertFalse(cacheCfg.isExposeJmxStatistics());
 
          region = (EntityRegionImpl) factory.buildEntityRegion(car, p, null);
          assertNotNull(factory.getTypeOverrides().get(person));
          assertTrue(factory.getDefinedConfigurations().contains(person));
          assertNull(factory.getTypeOverrides().get(address));
          cache = region.getCacheAdapter();
          cacheCfg = cache.getConfiguration();
          assertEquals(EvictionStrategy.FIFO, cacheCfg.getEvictionStrategy());
          assertEquals(3000, cacheCfg.getEvictionWakeUpInterval());
          assertEquals(20000, cacheCfg.getEvictionMaxEntries());
          assertFalse(cacheCfg.isExposeJmxStatistics());
 
          CollectionRegionImpl collectionRegion = (CollectionRegionImpl) factory.buildCollectionRegion(addresses, p, null);
          assertNotNull(factory.getTypeOverrides().get(addresses));
          assertTrue(factory.getDefinedConfigurations().contains(person));
          assertNull(factory.getTypeOverrides().get(parts));
          cache = collectionRegion .getCacheAdapter();
          cacheCfg = cache.getConfiguration();
          assertEquals(EvictionStrategy.FIFO, cacheCfg.getEvictionStrategy());
          assertEquals(2500, cacheCfg.getEvictionWakeUpInterval());
          assertEquals(5500, cacheCfg.getEvictionMaxEntries());
          assertEquals(65000, cacheCfg.getExpirationLifespan());
          assertEquals(35000, cacheCfg.getExpirationMaxIdle());
          assertFalse(cacheCfg.isExposeJmxStatistics());
 
          collectionRegion = (CollectionRegionImpl) factory.buildCollectionRegion(parts, p, null);
          assertNotNull(factory.getTypeOverrides().get(addresses));
          assertTrue(factory.getDefinedConfigurations().contains(addresses));
          assertNull(factory.getTypeOverrides().get(parts));
          cache = collectionRegion.getCacheAdapter();
          cacheCfg = cache.getConfiguration();
          assertEquals(EvictionStrategy.LRU, cacheCfg.getEvictionStrategy());
          assertEquals(3500, cacheCfg.getEvictionWakeUpInterval());
          assertEquals(25000, cacheCfg.getEvictionMaxEntries());
          assertFalse(cacheCfg.isExposeJmxStatistics());
 
          collectionRegion = (CollectionRegionImpl) factory.buildCollectionRegion(parts, p, null);
          assertNotNull(factory.getTypeOverrides().get(addresses));
          assertTrue(factory.getDefinedConfigurations().contains(addresses));
          assertNull(factory.getTypeOverrides().get(parts));
          cache = collectionRegion.getCacheAdapter();
          cacheCfg = cache.getConfiguration();
          assertEquals(EvictionStrategy.LRU, cacheCfg.getEvictionStrategy());
          assertEquals(3500, cacheCfg.getEvictionWakeUpInterval());
          assertEquals(25000, cacheCfg.getEvictionMaxEntries());
          assertFalse(cacheCfg.isExposeJmxStatistics());
       } finally {
          factory.stop();
       }
    }
 
    public void testBuildEntityCollectionRegionOverridesOnly() {
       CacheAdapter cache = null;
       Properties p = new Properties();
       p.setProperty("hibernate.cache.infinispan.entity.eviction.strategy", "FIFO");
       p.setProperty("hibernate.cache.infinispan.entity.eviction.wake_up_interval", "3000");
       p.setProperty("hibernate.cache.infinispan.entity.eviction.max_entries", "30000");
       p.setProperty("hibernate.cache.infinispan.collection.eviction.strategy", "LRU");
       p.setProperty("hibernate.cache.infinispan.collection.eviction.wake_up_interval", "3500");
       p.setProperty("hibernate.cache.infinispan.collection.eviction.max_entries", "35000");
       InfinispanRegionFactory factory = new InfinispanRegionFactory();
       factory.start(null, p);
       factory.getCacheManager();
       try {
          EntityRegionImpl region = (EntityRegionImpl) factory.buildEntityRegion("com.acme.Address", p, null);
          assertNull(factory.getTypeOverrides().get("com.acme.Address"));
          cache = region.getCacheAdapter();
          Configuration cacheCfg = cache.getConfiguration();
          assertEquals(EvictionStrategy.FIFO, cacheCfg.getEvictionStrategy());
          assertEquals(3000, cacheCfg.getEvictionWakeUpInterval());
          assertEquals(30000, cacheCfg.getEvictionMaxEntries());
          assertEquals(100000, cacheCfg.getExpirationMaxIdle());
 
          CollectionRegionImpl collectionRegion = (CollectionRegionImpl) factory.buildCollectionRegion("com.acme.Person.addresses", p, null);
          assertNull(factory.getTypeOverrides().get("com.acme.Person.addresses"));
          cache = collectionRegion.getCacheAdapter();
          cacheCfg = cache.getConfiguration();
          assertEquals(EvictionStrategy.LRU, cacheCfg.getEvictionStrategy());
          assertEquals(3500, cacheCfg.getEvictionWakeUpInterval());
          assertEquals(35000, cacheCfg.getEvictionMaxEntries());
          assertEquals(100000, cacheCfg.getExpirationMaxIdle());
       } finally {
          factory.stop();
       }
    }
 
    public void testBuildEntityRegionPersonPlusEntityOverridesWithoutCfg() {
       final String person = "com.acme.Person";
       Properties p = new Properties();
       // Third option, no cache defined for entity and overrides for generic entity data type and entity itself.
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.eviction.strategy", "LRU");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.expiration.lifespan", "60000");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.expiration.max_idle", "30000");
       p.setProperty("hibernate.cache.infinispan.entity.cfg", "myentity-cache");
       p.setProperty("hibernate.cache.infinispan.entity.eviction.strategy", "FIFO");
       p.setProperty("hibernate.cache.infinispan.entity.eviction.wake_up_interval", "3000");
       p.setProperty("hibernate.cache.infinispan.entity.eviction.max_entries", "10000");
       InfinispanRegionFactory factory = new InfinispanRegionFactory();
       factory.start(null, p);
       EmbeddedCacheManager manager = factory.getCacheManager();
       manager.getGlobalConfiguration().setTransportClass(null);
       try {
          assertNotNull(factory.getTypeOverrides().get(person));
          assertFalse(factory.getDefinedConfigurations().contains(person));
          EntityRegionImpl region = (EntityRegionImpl) factory.buildEntityRegion(person, p, null);
          assertNotNull(factory.getTypeOverrides().get(person));
          assertTrue(factory.getDefinedConfigurations().contains(person));
          CacheAdapter cache = region.getCacheAdapter();
          Configuration cacheCfg = cache.getConfiguration();
          assertEquals(EvictionStrategy.LRU, cacheCfg.getEvictionStrategy());
          assertEquals(3000, cacheCfg.getEvictionWakeUpInterval());
          assertEquals(10000, cacheCfg.getEvictionMaxEntries());
          assertEquals(60000, cacheCfg.getExpirationLifespan());
          assertEquals(30000, cacheCfg.getExpirationMaxIdle());
       } finally {
          factory.stop();
       }
    }
 
    public void testTimestampValidation() {
       Properties p = new Properties();
       final DefaultCacheManager manager = new DefaultCacheManager();
       InfinispanRegionFactory factory = new InfinispanRegionFactory() {
          @Override
          protected EmbeddedCacheManager createCacheManager(Properties properties) throws CacheException {
             return manager;
          }
       };
       Configuration config = new Configuration();
       config.setCacheMode(CacheMode.INVALIDATION_SYNC);
       manager.defineConfiguration("timestamps", config);
       try {
          factory.start(null, p);
          fail("Should have failed saying that invalidation is not allowed for timestamp caches.");
       } catch(CacheException ce) {
       }
    }
 
    public void testBuildDefaultTimestampsRegion() {
-      final String timestamps = "org.hibernate.cache.UpdateTimestampsCache";
+      final String timestamps = "org.hibernate.cache.spi.UpdateTimestampsCache";
       Properties p = new Properties();
       InfinispanRegionFactory factory = new InfinispanRegionFactory();
       factory.start(null, p);
       EmbeddedCacheManager manager = factory.getCacheManager();
       try {
          assertTrue(factory.getDefinedConfigurations().contains("timestamps"));
          assertTrue(factory.getTypeOverrides().get("timestamps").getCacheName().equals("timestamps"));
          Configuration config = new Configuration();
          config.setFetchInMemoryState(false);
          manager.defineConfiguration("timestamps", config);
          TimestampsRegionImpl region = (TimestampsRegionImpl) factory.buildTimestampsRegion(timestamps, p);
          CacheAdapter cache = region.getCacheAdapter();
          Configuration cacheCfg = cache.getConfiguration();
          assertEquals(EvictionStrategy.NONE, cacheCfg.getEvictionStrategy());
          assertEquals(CacheMode.REPL_ASYNC, cacheCfg.getCacheMode());
          assertTrue(cacheCfg.isUseLazyDeserialization());
          assertFalse(cacheCfg.isExposeJmxStatistics());
       } finally {
          factory.stop();
       }
    }
    
    public void testBuildDiffCacheNameTimestampsRegion() {
-      final String timestamps = "org.hibernate.cache.UpdateTimestampsCache";
+      final String timestamps = "org.hibernate.cache.spi.UpdateTimestampsCache";
       Properties p = new Properties();
       p.setProperty("hibernate.cache.infinispan.timestamps.cfg", "unrecommended-timestamps");
       InfinispanRegionFactory factory = new InfinispanRegionFactory();
       factory.start(null, p);
       EmbeddedCacheManager manager = factory.getCacheManager();
       try {
          assertFalse(factory.getDefinedConfigurations().contains("timestamp"));
          assertTrue(factory.getDefinedConfigurations().contains("unrecommended-timestamps"));
          assertTrue(factory.getTypeOverrides().get("timestamps").getCacheName().equals("unrecommended-timestamps"));
          Configuration config = new Configuration();
          config.setFetchInMemoryState(false);
          config.setCacheMode(CacheMode.REPL_SYNC);
          manager.defineConfiguration("unrecommended-timestamps", config);
          TimestampsRegionImpl region = (TimestampsRegionImpl) factory.buildTimestampsRegion(timestamps, p);
          CacheAdapter cache = region.getCacheAdapter();
          Configuration cacheCfg = cache.getConfiguration();
          assertEquals(EvictionStrategy.NONE, cacheCfg.getEvictionStrategy());
          assertEquals(CacheMode.REPL_SYNC, cacheCfg.getCacheMode());
          assertFalse(cacheCfg.isUseLazyDeserialization());
          assertFalse(cacheCfg.isExposeJmxStatistics());
       } finally {
          factory.stop();
       }
    }
 
    public void testBuildTimestamRegionWithCacheNameOverride() {
-      final String timestamps = "org.hibernate.cache.UpdateTimestampsCache";
+      final String timestamps = "org.hibernate.cache.spi.UpdateTimestampsCache";
       Properties p = new Properties();
       InfinispanRegionFactory factory = new InfinispanRegionFactory();
       p.setProperty("hibernate.cache.infinispan.timestamps.cfg", "mytimestamps-cache");
       factory.start(null, p);
       EmbeddedCacheManager manager = factory.getCacheManager();
       manager.getGlobalConfiguration().setTransportClass(null);
       try {
          factory.buildTimestampsRegion(timestamps, p);
          assertTrue(factory.getDefinedConfigurations().contains("mytimestamps-cache"));
       } finally {
          factory.stop();
       }
    }
    
    public void testBuildTimestamRegionWithFifoEvictionOverride() {
-      final String timestamps = "org.hibernate.cache.UpdateTimestampsCache";
+      final String timestamps = "org.hibernate.cache.spi.UpdateTimestampsCache";
       Properties p = new Properties();
       InfinispanRegionFactory factory = new InfinispanRegionFactory();
       p.setProperty("hibernate.cache.infinispan.timestamps.cfg", "mytimestamps-cache");
       p.setProperty("hibernate.cache.infinispan.timestamps.eviction.strategy", "FIFO");
       p.setProperty("hibernate.cache.infinispan.timestamps.eviction.wake_up_interval", "3000");
       p.setProperty("hibernate.cache.infinispan.timestamps.eviction.max_entries", "10000");
       try {
          factory.start(null, p);
          EmbeddedCacheManager manager = factory.getCacheManager();
          manager.getGlobalConfiguration().setTransportClass(null);
          factory.buildTimestampsRegion(timestamps, p);
          assertTrue(factory.getDefinedConfigurations().contains("mytimestamps-cache"));
          fail("Should fail cos no eviction configurations are allowed for timestamp caches");
       } catch(CacheException ce) {
       } finally {
          factory.stop();
       }
    }
 
    public void testBuildTimestamRegionWithNoneEvictionOverride() {
-      final String timestamps = "org.hibernate.cache.UpdateTimestampsCache";
+      final String timestamps = "org.hibernate.cache.spi.UpdateTimestampsCache";
       Properties p = new Properties();
       InfinispanRegionFactory factory = new InfinispanRegionFactory();
       p.setProperty("hibernate.cache.infinispan.timestamps.cfg", "timestamps-none-eviction");
       p.setProperty("hibernate.cache.infinispan.timestamps.eviction.strategy", "NONE");
       p.setProperty("hibernate.cache.infinispan.timestamps.eviction.wake_up_interval", "3000");
       p.setProperty("hibernate.cache.infinispan.timestamps.eviction.max_entries", "10000");
       factory.start(null, p);
       EmbeddedCacheManager manager = factory.getCacheManager();
       manager.getGlobalConfiguration().setTransportClass(null);
       try {
          factory.buildTimestampsRegion(timestamps, p);
          assertTrue(factory.getDefinedConfigurations().contains("timestamps-none-eviction"));
       } finally {
          factory.stop();
       }
    }
 
    public void testBuildQueryRegion() {
-      final String query = "org.hibernate.cache.StandardQueryCache";
+      final String query = "org.hibernate.cache.internal.StandardQueryCache";
       Properties p = new Properties();
       InfinispanRegionFactory factory = new InfinispanRegionFactory();
       factory.start(null, p);
       EmbeddedCacheManager manager = factory.getCacheManager();
       manager.getGlobalConfiguration().setTransportClass(null);
       try {
          assertTrue(factory.getDefinedConfigurations().contains("local-query"));
          QueryResultsRegionImpl region = (QueryResultsRegionImpl) factory.buildQueryResultsRegion(query, p);
          CacheAdapter cache = region.getCacheAdapter();
          Configuration cacheCfg = cache.getConfiguration();
          assertEquals(CacheMode.LOCAL, cacheCfg.getCacheMode());
          assertFalse(cacheCfg.isExposeJmxStatistics());
       } finally {
          factory.stop();
       }
    }
 
    public void testBuildQueryRegionWithCustomRegionName() {
       final String queryRegionName = "myquery";
       Properties p = new Properties();
       InfinispanRegionFactory factory = new InfinispanRegionFactory();
       p.setProperty("hibernate.cache.infinispan.myquery.cfg", "timestamps-none-eviction");
       p.setProperty("hibernate.cache.infinispan.myquery.eviction.strategy", "FIFO");
       p.setProperty("hibernate.cache.infinispan.myquery.eviction.wake_up_interval", "2222");
       p.setProperty("hibernate.cache.infinispan.myquery.eviction.max_entries", "11111");
       factory.start(null, p);
       EmbeddedCacheManager manager = factory.getCacheManager();
       manager.getGlobalConfiguration().setTransportClass(null);
       try {
          assertTrue(factory.getDefinedConfigurations().contains("local-query"));
          QueryResultsRegionImpl region = (QueryResultsRegionImpl) factory.buildQueryResultsRegion(queryRegionName, p);
          assertNotNull(factory.getTypeOverrides().get(queryRegionName));
          assertTrue(factory.getDefinedConfigurations().contains(queryRegionName));
          CacheAdapter cache = region.getCacheAdapter();
          Configuration cacheCfg = cache.getConfiguration();
          assertEquals(EvictionStrategy.FIFO, cacheCfg.getEvictionStrategy());
          assertEquals(2222, cacheCfg.getEvictionWakeUpInterval());
          assertEquals(11111, cacheCfg.getEvictionMaxEntries());
       } finally {
          factory.stop();
       }
    }
 
    public void testEnableStatistics() {
       Properties p = new Properties();
       p.setProperty("hibernate.cache.infinispan.statistics", "true");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.expiration.lifespan", "60000");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.expiration.max_idle", "30000");
       p.setProperty("hibernate.cache.infinispan.entity.cfg", "myentity-cache");
       p.setProperty("hibernate.cache.infinispan.entity.eviction.strategy", "FIFO");
       p.setProperty("hibernate.cache.infinispan.entity.eviction.wake_up_interval", "3000");
       p.setProperty("hibernate.cache.infinispan.entity.eviction.max_entries", "10000");
       InfinispanRegionFactory factory = new InfinispanRegionFactory();
       factory.start(null, p);
       EmbeddedCacheManager manager = factory.getCacheManager();
       try {
          assertTrue(manager.getGlobalConfiguration().isExposeGlobalJmxStatistics());
          EntityRegionImpl region = (EntityRegionImpl) factory.buildEntityRegion("com.acme.Address", p, null);
          CacheAdapter cache = region.getCacheAdapter();
          assertTrue(factory.getTypeOverrides().get("entity").isExposeStatistics());
          assertTrue(cache.getConfiguration().isExposeJmxStatistics());
 
          region = (EntityRegionImpl) factory.buildEntityRegion("com.acme.Person", p, null);
          cache = region.getCacheAdapter();
          assertTrue(factory.getTypeOverrides().get("com.acme.Person").isExposeStatistics());
          assertTrue(cache.getConfiguration().isExposeJmxStatistics());
 
-         final String query = "org.hibernate.cache.StandardQueryCache";
+         final String query = "org.hibernate.cache.internal.StandardQueryCache";
          QueryResultsRegionImpl queryRegion = (QueryResultsRegionImpl) factory.buildQueryResultsRegion(query, p);
          cache = queryRegion.getCacheAdapter();
          assertTrue(factory.getTypeOverrides().get("query").isExposeStatistics());
          assertTrue(cache.getConfiguration().isExposeJmxStatistics());
 
-         final String timestamps = "org.hibernate.cache.UpdateTimestampsCache";
+         final String timestamps = "org.hibernate.cache.spi.UpdateTimestampsCache";
          Configuration config = new Configuration();
          config.setFetchInMemoryState(false);
          manager.defineConfiguration("timestamps", config);
          TimestampsRegionImpl timestampsRegion = (TimestampsRegionImpl) factory.buildTimestampsRegion(timestamps, p);
          cache = timestampsRegion.getCacheAdapter();
          assertTrue(factory.getTypeOverrides().get("timestamps").isExposeStatistics());
          assertTrue(cache.getConfiguration().isExposeJmxStatistics());
 
          CollectionRegionImpl collectionRegion = (CollectionRegionImpl) factory.buildCollectionRegion("com.acme.Person.addresses", p, null);
          cache = collectionRegion.getCacheAdapter();
          assertTrue(factory.getTypeOverrides().get("collection").isExposeStatistics());
          assertTrue(cache.getConfiguration().isExposeJmxStatistics());
       } finally {
          factory.stop();
       }
    }
 
    public void testDisableStatistics() {
       Properties p = new Properties();
       p.setProperty("hibernate.cache.infinispan.statistics", "false");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.expiration.lifespan", "60000");
       p.setProperty("hibernate.cache.infinispan.com.acme.Person.expiration.max_idle", "30000");
       p.setProperty("hibernate.cache.infinispan.entity.cfg", "myentity-cache");
       p.setProperty("hibernate.cache.infinispan.entity.eviction.strategy", "FIFO");
       p.setProperty("hibernate.cache.infinispan.entity.eviction.wake_up_interval", "3000");
       p.setProperty("hibernate.cache.infinispan.entity.eviction.max_entries", "10000");
       InfinispanRegionFactory factory = new InfinispanRegionFactory();
       factory.start(null, p);
       EmbeddedCacheManager manager = factory.getCacheManager();
       try {
          assertFalse(manager.getGlobalConfiguration().isExposeGlobalJmxStatistics());
          EntityRegionImpl region = (EntityRegionImpl) factory.buildEntityRegion("com.acme.Address", p, null);
          CacheAdapter cache = region.getCacheAdapter();
          assertFalse(factory.getTypeOverrides().get("entity").isExposeStatistics());
          assertFalse(cache.getConfiguration().isExposeJmxStatistics());
 
          region = (EntityRegionImpl) factory.buildEntityRegion("com.acme.Person", p, null);
          cache = region.getCacheAdapter();
          assertFalse(factory.getTypeOverrides().get("com.acme.Person").isExposeStatistics());
          assertFalse(cache.getConfiguration().isExposeJmxStatistics());
 
-         final String query = "org.hibernate.cache.StandardQueryCache";
+         final String query = "org.hibernate.cache.internal.StandardQueryCache";
          QueryResultsRegionImpl queryRegion = (QueryResultsRegionImpl) factory.buildQueryResultsRegion(query, p);
          cache = queryRegion.getCacheAdapter();
          assertFalse(factory.getTypeOverrides().get("query").isExposeStatistics());
          assertFalse(cache.getConfiguration().isExposeJmxStatistics());
 
-         final String timestamps = "org.hibernate.cache.UpdateTimestampsCache";
+         final String timestamps = "org.hibernate.cache.spi.UpdateTimestampsCache";
          Configuration config = new Configuration();
          config.setFetchInMemoryState(false);
          manager.defineConfiguration("timestamps", config);
          TimestampsRegionImpl timestampsRegion = (TimestampsRegionImpl) factory.buildTimestampsRegion(timestamps, p);
          cache = timestampsRegion.getCacheAdapter();
          assertFalse(factory.getTypeOverrides().get("timestamps").isExposeStatistics());
          assertFalse(cache.getConfiguration().isExposeJmxStatistics());
 
          CollectionRegionImpl collectionRegion = (CollectionRegionImpl) factory.buildCollectionRegion("com.acme.Person.addresses", p, null);
          cache = collectionRegion.getCacheAdapter();
          assertFalse(factory.getTypeOverrides().get("collection").isExposeStatistics());
          assertFalse(cache.getConfiguration().isExposeJmxStatistics());
       } finally {
          factory.stop();
       }
    }
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/NodeEnvironment.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/NodeEnvironment.java
index c8ad070713..037b26ca90 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/NodeEnvironment.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/NodeEnvironment.java
@@ -1,139 +1,139 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan;
 
 import java.util.HashMap;
 import java.util.Map;
 
-import org.hibernate.cache.CacheDataDescription;
+import org.hibernate.cache.spi.CacheDataDescription;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.collection.CollectionRegionImpl;
 import org.hibernate.cache.infinispan.entity.EntityRegionImpl;
 import org.hibernate.cache.infinispan.util.FlagAdapter;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.service.ServiceRegistryBuilder;
 import org.hibernate.service.internal.BasicServiceRegistryImpl;
 
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 
 /**
  * Defines the environment for a node.
  *
  * @author Steve Ebersole
  */
 public class NodeEnvironment {
 	private final Configuration configuration;
 
 	private BasicServiceRegistryImpl serviceRegistry;
 	private InfinispanRegionFactory regionFactory;
 
 	private Map<String,EntityRegionImpl> entityRegionMap;
 	private Map<String,CollectionRegionImpl> collectionRegionMap;
 
 	public NodeEnvironment(Configuration configuration) {
 		this.configuration = configuration;
 	}
 
 	public Configuration getConfiguration() {
 		return configuration;
 	}
 
 	public BasicServiceRegistryImpl getServiceRegistry() {
 		return serviceRegistry;
 	}
 
 	public EntityRegionImpl getEntityRegion(String name, CacheDataDescription cacheDataDescription) {
 		if ( entityRegionMap == null ) {
 			entityRegionMap = new HashMap<String, EntityRegionImpl>();
 			return buildAndStoreEntityRegion( name, cacheDataDescription );
 		}
 		EntityRegionImpl region = entityRegionMap.get( name );
 		if ( region == null ) {
 			region = buildAndStoreEntityRegion( name, cacheDataDescription );
 		}
 		return region;
 	}
 
 	private EntityRegionImpl buildAndStoreEntityRegion(String name, CacheDataDescription cacheDataDescription) {
 		EntityRegionImpl region = (EntityRegionImpl) regionFactory.buildEntityRegion(
 				name,
 				configuration.getProperties(),
 				cacheDataDescription
 		);
 		entityRegionMap.put( name, region );
 		return region;
 	}
 
 	public CollectionRegionImpl getCollectionRegion(String name, CacheDataDescription cacheDataDescription) {
 		if ( collectionRegionMap == null ) {
 			collectionRegionMap = new HashMap<String, CollectionRegionImpl>();
 			return buildAndStoreCollectionRegion( name, cacheDataDescription );
 		}
 		CollectionRegionImpl region = collectionRegionMap.get( name );
 		if ( region == null ) {
 			region = buildAndStoreCollectionRegion( name, cacheDataDescription );
 			collectionRegionMap.put( name, region );
 		}
 		return region;
 	}
 
 	private CollectionRegionImpl buildAndStoreCollectionRegion(String name, CacheDataDescription cacheDataDescription) {
 		CollectionRegionImpl region;
 		region = (CollectionRegionImpl) regionFactory.buildCollectionRegion(
 				name,
 				configuration.getProperties(),
 				cacheDataDescription
 		);
 		return region;
 	}
 
 	public void prepare() throws Exception {
 		serviceRegistry = (BasicServiceRegistryImpl) new ServiceRegistryBuilder( configuration.getProperties() ).buildServiceRegistry();
 		regionFactory = CacheTestUtil.startRegionFactory( serviceRegistry, configuration );
 	}
 
 	public void release() throws Exception {
 		if ( entityRegionMap != null ) {
 			for ( EntityRegionImpl region : entityRegionMap.values() ) {
 				region.getCacheAdapter().withFlags( FlagAdapter.CACHE_MODE_LOCAL ).clear();
 				region.getCacheAdapter().stop();
 			}
 			entityRegionMap.clear();
 		}
 		if ( collectionRegionMap != null ) {
 			for ( CollectionRegionImpl collectionRegion : collectionRegionMap.values() ) {
 				collectionRegion.getCacheAdapter().withFlags( FlagAdapter.CACHE_MODE_LOCAL ).clear();
 				collectionRegion.getCacheAdapter().stop();
 			}
 			collectionRegionMap.clear();
 		}
 		if ( regionFactory != null ) {
 // Currently the RegionFactory is shutdown by its registration with the CacheTestSetup from CacheTestUtil when built
 			regionFactory.stop();
 		}
 		if ( serviceRegistry != null ) {
 			serviceRegistry.destroy();
 		}
 	}
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractCollectionRegionAccessStrategyTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractCollectionRegionAccessStrategyTestCase.java
index dcb7a97bfa..5f94e87c56 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractCollectionRegionAccessStrategyTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractCollectionRegionAccessStrategyTestCase.java
@@ -1,469 +1,469 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. ¬†All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.collection;
 
 import javax.transaction.TransactionManager;
 import java.util.concurrent.Callable;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
 import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 
 import org.infinispan.transaction.tm.BatchModeTransactionManager;
 import org.jboss.logging.Logger;
 
-import org.hibernate.cache.CacheDataDescription;
-import org.hibernate.cache.access.AccessType;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
-import org.hibernate.cache.impl.CacheDataDescriptionImpl;
+import org.hibernate.cache.internal.CacheDataDescriptionImpl;
+import org.hibernate.cache.spi.CacheDataDescription;
+import org.hibernate.cache.spi.access.AccessType;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.access.PutFromLoadValidator;
 import org.hibernate.cache.infinispan.access.TransactionalAccessDelegate;
 import org.hibernate.cache.infinispan.collection.CollectionRegionImpl;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.internal.util.compare.ComparableComparator;
 
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 import junit.framework.AssertionFailedError;
 
 import org.hibernate.test.cache.infinispan.AbstractNonFunctionalTestCase;
 import org.hibernate.test.cache.infinispan.NodeEnvironment;
 import org.hibernate.test.cache.infinispan.functional.cluster.DualNodeJtaTransactionManagerImpl;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertTrue;
 
 /**
  * Base class for tests of CollectionRegionAccessStrategy impls.
  *
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public abstract class AbstractCollectionRegionAccessStrategyTestCase extends AbstractNonFunctionalTestCase {
 	private static final Logger log = Logger.getLogger( AbstractCollectionRegionAccessStrategyTestCase.class );
 
 	public static final String REGION_NAME = "test/com.foo.test";
 	public static final String KEY_BASE = "KEY";
 	public static final String VALUE1 = "VALUE1";
 	public static final String VALUE2 = "VALUE2";
 
 	protected static int testCount;
 
 	protected NodeEnvironment localEnvironment;
 	protected CollectionRegionImpl localCollectionRegion;
 	protected CollectionRegionAccessStrategy localAccessStrategy;
 
 	protected NodeEnvironment remoteEnvironment;
 	protected CollectionRegionImpl remoteCollectionRegion;
 	protected CollectionRegionAccessStrategy remoteAccessStrategy;
 
 	protected boolean invalidation;
 	protected boolean synchronous;
 
 	protected Exception node1Exception;
 	protected Exception node2Exception;
 
 	protected AssertionFailedError node1Failure;
 	protected AssertionFailedError node2Failure;
 
 	protected abstract AccessType getAccessType();
 
 	@Before
 	public void prepareResources() throws Exception {
 		// to mimic exactly the old code results, both environments here are exactly the same...
 		Configuration cfg = createConfiguration( getConfigurationName() );
 		localEnvironment = new NodeEnvironment( cfg );
 		localEnvironment.prepare();
 
 		localCollectionRegion = localEnvironment.getCollectionRegion( REGION_NAME, getCacheDataDescription() );
 		localAccessStrategy = localCollectionRegion.buildAccessStrategy( getAccessType() );
 
 		invalidation = localCollectionRegion.getCacheAdapter().isClusteredInvalidation();
 		synchronous = localCollectionRegion.getCacheAdapter().isSynchronous();
 
 		// Sleep a bit to avoid concurrent FLUSH problem
 		avoidConcurrentFlush();
 
 		remoteEnvironment = new NodeEnvironment( cfg );
 		remoteEnvironment.prepare();
 
 		remoteCollectionRegion = remoteEnvironment.getCollectionRegion( REGION_NAME, getCacheDataDescription() );
 		remoteAccessStrategy = remoteCollectionRegion.buildAccessStrategy( getAccessType() );
 	}
 
 	protected abstract String getConfigurationName();
 
 	protected static Configuration createConfiguration(String configName) {
 		Configuration cfg = CacheTestUtil.buildConfiguration(
 				REGION_PREFIX, InfinispanRegionFactory.class, true, false
 		);
 		cfg.setProperty( InfinispanRegionFactory.ENTITY_CACHE_RESOURCE_PROP, configName );
 		return cfg;
 	}
 
 	protected CacheDataDescription getCacheDataDescription() {
 		return new CacheDataDescriptionImpl( true, true, ComparableComparator.INSTANCE );
 	}
 
 	@After
 	public void releaseResources() throws Exception {
 		if ( localEnvironment != null ) {
 			localEnvironment.release();
 		}
 		if ( remoteEnvironment != null ) {
 			remoteEnvironment.release();
 		}
 	}
 
 	protected boolean isUsingInvalidation() {
 		return invalidation;
 	}
 
 	protected boolean isSynchronous() {
 		return synchronous;
 	}
 
 	@Test
 	public abstract void testCacheConfiguration();
 
 	@Test
 	public void testGetRegion() {
 		assertEquals( "Correct region", localCollectionRegion, localAccessStrategy.getRegion() );
 	}
 
 	@Test
 	public void testPutFromLoadRemoveDoesNotProduceStaleData() throws Exception {
 		final CountDownLatch pferLatch = new CountDownLatch( 1 );
 		final CountDownLatch removeLatch = new CountDownLatch( 1 );
 		TransactionManager tm = DualNodeJtaTransactionManagerImpl.getInstance( "test1234" );
 		PutFromLoadValidator validator = new PutFromLoadValidator( tm ) {
 			@Override
 			public boolean acquirePutFromLoadLock(Object key) {
 				boolean acquired = super.acquirePutFromLoadLock( key );
 				try {
 					removeLatch.countDown();
 					pferLatch.await( 2, TimeUnit.SECONDS );
 				}
 				catch (InterruptedException e) {
 					log.debug( "Interrupted" );
 					Thread.currentThread().interrupt();
 				}
 				catch (Exception e) {
 					log.error( "Error", e );
 					throw new RuntimeException( "Error", e );
 				}
 				return acquired;
 			}
 		};
 		final TransactionalAccessDelegate delegate = new TransactionalAccessDelegate(
 				(CollectionRegionImpl) localCollectionRegion, validator
 		);
 
 		Callable<Void> pferCallable = new Callable<Void>() {
 			public Void call() throws Exception {
 				delegate.putFromLoad( "k1", "v1", 0, null );
 				return null;
 			}
 		};
 
 		Callable<Void> removeCallable = new Callable<Void>() {
 			public Void call() throws Exception {
 				removeLatch.await();
 				delegate.remove( "k1" );
 				pferLatch.countDown();
 				return null;
 			}
 		};
 
 		ExecutorService executorService = Executors.newCachedThreadPool();
 		Future<Void> pferFuture = executorService.submit( pferCallable );
 		Future<Void> removeFuture = executorService.submit( removeCallable );
 
 		pferFuture.get();
 		removeFuture.get();
 
 		assertFalse( localCollectionRegion.getCacheAdapter().containsKey( "k1" ) );
 	}
 
 	@Test
 	public void testPutFromLoad() throws Exception {
 		putFromLoadTest( false );
 	}
 
 	@Test
 	public void testPutFromLoadMinimal() throws Exception {
 		putFromLoadTest( true );
 	}
 
 	private void putFromLoadTest(final boolean useMinimalAPI) throws Exception {
 
 		final String KEY = KEY_BASE + testCount++;
 
 		final CountDownLatch writeLatch1 = new CountDownLatch( 1 );
 		final CountDownLatch writeLatch2 = new CountDownLatch( 1 );
 		final CountDownLatch completionLatch = new CountDownLatch( 2 );
 
 		Thread node1 = new Thread() {
 
 			public void run() {
 
 				try {
 					long txTimestamp = System.currentTimeMillis();
 					BatchModeTransactionManager.getInstance().begin();
 
 					assertEquals( "node1 starts clean", null, localAccessStrategy.get( KEY, txTimestamp ) );
 
 					writeLatch1.await();
 
 					if ( useMinimalAPI ) {
 						localAccessStrategy.putFromLoad( KEY, VALUE2, txTimestamp, new Integer( 2 ), true );
 					}
 					else {
 						localAccessStrategy.putFromLoad( KEY, VALUE2, txTimestamp, new Integer( 2 ) );
 					}
 
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
 					log.error( "node1 caught exception", e );
 					node1Exception = e;
 					rollback();
 				}
 				catch (AssertionFailedError e) {
 					node1Failure = e;
 					rollback();
 				}
 				finally {
 					// Let node2 write
 					writeLatch2.countDown();
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		Thread node2 = new Thread() {
 
 			public void run() {
 
 				try {
 					long txTimestamp = System.currentTimeMillis();
 					BatchModeTransactionManager.getInstance().begin();
 
 					assertNull( "node2 starts clean", remoteAccessStrategy.get( KEY, txTimestamp ) );
 
 					// Let node1 write
 					writeLatch1.countDown();
 					// Wait for node1 to finish
 					writeLatch2.await();
 
 					// Let the first PFER propagate
 					sleep( 200 );
 
 					if ( useMinimalAPI ) {
 						remoteAccessStrategy.putFromLoad( KEY, VALUE1, txTimestamp, new Integer( 1 ), true );
 					}
 					else {
 						remoteAccessStrategy.putFromLoad( KEY, VALUE1, txTimestamp, new Integer( 1 ) );
 					}
 
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
 					log.error( "node2 caught exception", e );
 					node2Exception = e;
 					rollback();
 				}
 				catch (AssertionFailedError e) {
 					node2Failure = e;
 					rollback();
 				}
 				finally {
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		node1.setDaemon( true );
 		node2.setDaemon( true );
 
 		node1.start();
 		node2.start();
 
 		assertTrue( "Threads completed", completionLatch.await( 2, TimeUnit.SECONDS ) );
 
 		if ( node1Failure != null ) {
 			throw node1Failure;
 		}
 		if ( node2Failure != null ) {
 			throw node2Failure;
 		}
 
 		assertEquals( "node1 saw no exceptions", null, node1Exception );
 		assertEquals( "node2 saw no exceptions", null, node2Exception );
 
 		// let the final PFER propagate
 		sleep( 100 );
 
 		long txTimestamp = System.currentTimeMillis();
 		String msg1 = "Correct node1 value";
 		String msg2 = "Correct node2 value";
 		Object expected1 = null;
 		Object expected2 = null;
 		if ( isUsingInvalidation() ) {
 			// PFER does not generate any invalidation, so each node should
 			// succeed. We count on database locking and Hibernate removing
 			// the collection on any update to prevent the situation we have
 			// here where the caches have inconsistent data
 			expected1 = VALUE2;
 			expected2 = VALUE1;
 		}
 		else {
 			// the initial VALUE2 should prevent the node2 put
 			expected1 = VALUE2;
 			expected2 = VALUE2;
 		}
 
 		assertEquals( msg1, expected1, localAccessStrategy.get( KEY, txTimestamp ) );
 		assertEquals( msg2, expected2, remoteAccessStrategy.get( KEY, txTimestamp ) );
 	}
 
 	@Test
 	public void testRemove() {
 		evictOrRemoveTest( false );
 	}
 
 	@Test
 	public void testRemoveAll() {
 		evictOrRemoveAllTest( false );
 	}
 
 	@Test
 	public void testEvict() {
 		evictOrRemoveTest( true );
 	}
 
 	@Test
 	public void testEvictAll() {
 		evictOrRemoveAllTest( true );
 	}
 
 	private void evictOrRemoveTest(boolean evict) {
 
 		final String KEY = KEY_BASE + testCount++;
 
 		assertNull( "local is clean", localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertNull( "remote is clean", remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		localAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		remoteAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		// Wait for async propagation
 		sleep( 250 );
 
 		if ( evict ) {
 			localAccessStrategy.evict( KEY );
 		}
 		else {
 			localAccessStrategy.remove( KEY );
 		}
 
 		assertEquals( null, localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		assertEquals( null, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 	}
 
 	private void evictOrRemoveAllTest(boolean evict) {
 
 		final String KEY = KEY_BASE + testCount++;
 
 		assertEquals( 0, getValidKeyCount( localCollectionRegion.getCacheAdapter().keySet() ) );
 
 		assertEquals( 0, getValidKeyCount( remoteCollectionRegion.getCacheAdapter().keySet() ) );
 
 		assertNull( "local is clean", localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertNull( "remote is clean", remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		localAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		remoteAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		// Wait for async propagation
 		sleep( 250 );
 
 		if ( evict ) {
 			localAccessStrategy.evictAll();
 		}
 		else {
 			localAccessStrategy.removeAll();
 		}
 
 		// This should re-establish the region root node
 		assertNull( localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		assertEquals( 0, getValidKeyCount( localCollectionRegion.getCacheAdapter().keySet() ) );
 
 		// Re-establishing the region root on the local node doesn't
 		// propagate it to other nodes. Do a get on the remote node to re-establish
 		assertEquals( null, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		assertEquals( 0, getValidKeyCount( remoteCollectionRegion.getCacheAdapter().keySet() ) );
 
 		// Test whether the get above messes up the optimistic version
 		remoteAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		assertEquals( 1, getValidKeyCount( remoteCollectionRegion.getCacheAdapter().keySet() ) );
 
 		// Wait for async propagation of the putFromLoad
 		sleep( 250 );
 
 		assertEquals(
 				"local is correct", (isUsingInvalidation() ? null : VALUE1), localAccessStrategy.get(
 				KEY, System
 				.currentTimeMillis()
 		)
 		);
 		assertEquals( "remote is correct", VALUE1, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 	}
 
 	private void rollback() {
 		try {
 			BatchModeTransactionManager.getInstance().rollback();
 		}
 		catch (Exception e) {
 			log.error( e.getMessage(), e );
 		}
 
 	}
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractReadOnlyAccessTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractReadOnlyAccessTestCase.java
index 847ae276dd..fb35b325c0 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractReadOnlyAccessTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractReadOnlyAccessTestCase.java
@@ -1,38 +1,38 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. ¬†All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.collection;
 
-import org.hibernate.cache.access.AccessType;
+import org.hibernate.cache.spi.access.AccessType;
 
 /**
  * Base class for tests of TRANSACTIONAL access.
  * 
  * @author <a href="brian.stansberry@jboss.com">Brian Stansberry</a>
  */
 public abstract class AbstractReadOnlyAccessTestCase extends AbstractCollectionRegionAccessStrategyTestCase {
     @Override
     protected AccessType getAccessType() {
         return AccessType.READ_ONLY;
     }
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractTransactionalAccessTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractTransactionalAccessTestCase.java
index 5540f7fd09..505363a8c2 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractTransactionalAccessTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/AbstractTransactionalAccessTestCase.java
@@ -1,37 +1,37 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. ¬†All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.collection;
-import org.hibernate.cache.access.AccessType;
+import org.hibernate.cache.spi.access.AccessType;
 
 /**
  * Base class for tests of TRANSACTIONAL access.
  * 
  * @author <a href="brian.stansberry@jboss.com">Brian Stansberry</a>
  */
 public abstract class AbstractTransactionalAccessTestCase extends AbstractCollectionRegionAccessStrategyTestCase {
     @Override
     protected AccessType getAccessType() {
         return AccessType.TRANSACTIONAL;
     }
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/CollectionRegionImplTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/CollectionRegionImplTestCase.java
index da2d05f27b..fdb7b81dee 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/CollectionRegionImplTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/CollectionRegionImplTestCase.java
@@ -1,93 +1,93 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. ¬†All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.collection;
 import java.util.Properties;
-import org.hibernate.cache.CacheDataDescription;
+import org.hibernate.cache.spi.CacheDataDescription;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.CollectionRegion;
-import org.hibernate.cache.Region;
-import org.hibernate.cache.RegionFactory;
-import org.hibernate.cache.access.AccessType;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
+import org.hibernate.cache.spi.CollectionRegion;
+import org.hibernate.cache.spi.Region;
+import org.hibernate.cache.spi.RegionFactory;
+import org.hibernate.cache.spi.access.AccessType;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.cache.infinispan.util.CacheAdapterImpl;
 
 import org.hibernate.test.cache.infinispan.AbstractEntityCollectionRegionTestCase;
 
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.fail;
 
 /**
  * Tests of CollectionRegionImpl.
  * 
  * @author Galder Zamarre√±o
  */
 public class CollectionRegionImplTestCase extends AbstractEntityCollectionRegionTestCase {
    @Override
    protected void supportedAccessTypeTest(RegionFactory regionFactory, Properties properties) {
       CollectionRegion region = regionFactory.buildCollectionRegion("test", properties, null);
       assertNull("Got TRANSACTIONAL", region.buildAccessStrategy(AccessType.TRANSACTIONAL)
                .lockRegion());
       try {
          region.buildAccessStrategy(AccessType.READ_ONLY).lockRegion();
          fail("Did not get READ_ONLY");
       } catch (UnsupportedOperationException good) {
       }
 
       try {
          region.buildAccessStrategy(AccessType.NONSTRICT_READ_WRITE);
          fail("Incorrectly got NONSTRICT_READ_WRITE");
       } catch (CacheException good) {
       }
 
       try {
          region.buildAccessStrategy(AccessType.READ_WRITE);
          fail("Incorrectly got READ_WRITE");
       } catch (CacheException good) {
       }
    }
 
    @Override
    protected Region createRegion(InfinispanRegionFactory regionFactory, String regionName, Properties properties, CacheDataDescription cdd) {
       return regionFactory.buildCollectionRegion(regionName, properties, cdd);
    }
 
    @Override
    protected CacheAdapter getInfinispanCache(InfinispanRegionFactory regionFactory) {
       return CacheAdapterImpl.newInstance(regionFactory.getCacheManager().getCache(InfinispanRegionFactory.DEF_ENTITY_RESOURCE));
    }
 
    @Override
    protected void putInRegion(Region region, Object key, Object value) {
       CollectionRegionAccessStrategy strategy = ((CollectionRegion) region).buildAccessStrategy(AccessType.TRANSACTIONAL);
       strategy.putFromLoad(key, value, System.currentTimeMillis(), new Integer(1));
    }
 
    @Override
    protected void removeFromRegion(Region region, Object key) {
       ((CollectionRegion) region).buildAccessStrategy(AccessType.TRANSACTIONAL).remove(key);
    }
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/ReadOnlyExtraAPITestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/ReadOnlyExtraAPITestCase.java
index cc4f735e10..a49057f88e 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/ReadOnlyExtraAPITestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/ReadOnlyExtraAPITestCase.java
@@ -1,62 +1,62 @@
 /*
  * JBoss, Home of Professional Open Source.
  * Copyright 2009, Red Hat, Inc. and/or it's affiliates, and individual contributors
  * as indicated by the @author tags. See the copyright.txt file in the
  * distribution for a full listing of individual contributors.
  *
  * This is free software; you can redistribute it and/or modify it
  * under the terms of the GNU Lesser General Public License as
  * published by the Free Software Foundation; either version 2.1 of
  * the License, or (at your option) any later version.
  *
  * This software is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * Lesser General Public License for more details.
  *
  * You should have received a copy of the GNU Lesser General Public
  * License along with this software; if not, write to the Free
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
 package org.hibernate.test.cache.infinispan.collection;
-import org.hibernate.cache.access.AccessType;
+import org.hibernate.cache.spi.access.AccessType;
 
 import org.junit.Test;
 
 import static org.junit.Assert.fail;
 /**
  * ReadOnlyExtraAPITestCase.
  *
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public class ReadOnlyExtraAPITestCase extends TransactionalExtraAPITestCase {
 	@Override
 	protected AccessType getAccessType() {
 		return AccessType.READ_ONLY;
 	}
 
 	@Test
 	@Override
 	public void testLockItem() {
 		try {
 			getCollectionAccessStrategy().lockItem( KEY, new Integer( 1 ) );
 			fail( "Call to lockItem did not throw exception" );
 		}
 		catch (UnsupportedOperationException expected) {
 		}
 	}
 
 	@Test
 	@Override
 	public void testLockRegion() {
 		try {
 			getCollectionAccessStrategy().lockRegion();
 			fail( "Call to lockRegion did not throw exception" );
 		}
 		catch (UnsupportedOperationException expected) {
 		}
 	}
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/TransactionalExtraAPITestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/TransactionalExtraAPITestCase.java
index 9aadb36a74..47bb6c6612 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/TransactionalExtraAPITestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/collection/TransactionalExtraAPITestCase.java
@@ -1,116 +1,116 @@
 /*
  * JBoss, Home of Professional Open Source.
  * Copyright 2009, Red Hat, Inc. and/or it's affiliates, and individual contributors
  * as indicated by the @author tags. See the copyright.txt file in the
  * distribution for a full listing of individual contributors.
  *
  * This is free software; you can redistribute it and/or modify it
  * under the terms of the GNU Lesser General Public License as
  * published by the Free Software Foundation; either version 2.1 of
  * the License, or (at your option) any later version.
  *
  * This software is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * Lesser General Public License for more details.
  *
  * You should have received a copy of the GNU Lesser General Public
  * License along with this software; if not, write to the Free
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
 package org.hibernate.test.cache.infinispan.collection;
 
-import org.hibernate.cache.access.AccessType;
-import org.hibernate.cache.access.CollectionRegionAccessStrategy;
-import org.hibernate.cache.access.SoftLock;
+import org.hibernate.cache.spi.access.AccessType;
+import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
+import org.hibernate.cache.spi.access.SoftLock;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cfg.Configuration;
 
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 
 import org.hibernate.test.cache.infinispan.AbstractNonFunctionalTestCase;
 import org.hibernate.test.cache.infinispan.NodeEnvironment;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 
 import static org.junit.Assert.assertNull;
 
 /**
  * TransactionalExtraAPITestCase.
  *
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public class TransactionalExtraAPITestCase extends AbstractNonFunctionalTestCase {
 
 	public static final String REGION_NAME = "test/com.foo.test";
 	public static final String KEY = "KEY";
 	public static final String VALUE1 = "VALUE1";
 	public static final String VALUE2 = "VALUE2";
 
 	private NodeEnvironment environment;
 	private static CollectionRegionAccessStrategy accessStrategy;
 
 	@Before
 	public final void prepareLocalAccessStrategy() throws Exception {
 		environment = new NodeEnvironment( createConfiguration() );
 		environment.prepare();
 
 		// Sleep a bit to avoid concurrent FLUSH problem
 		avoidConcurrentFlush();
 
 		accessStrategy = environment.getCollectionRegion( REGION_NAME, null ).buildAccessStrategy( getAccessType() );
 	}
 
 	protected Configuration createConfiguration() {
 		Configuration cfg = CacheTestUtil.buildConfiguration(
 				REGION_PREFIX, InfinispanRegionFactory.class, true, false
 		);
 		cfg.setProperty( InfinispanRegionFactory.ENTITY_CACHE_RESOURCE_PROP, getCacheConfigName() );
 		return cfg;
 	}
 
 	protected String getCacheConfigName() {
 		return "entity";
 	}
 
 	protected AccessType getAccessType() {
 		return AccessType.TRANSACTIONAL;
 	}
 
 	@After
 	public final void releaseLocalAccessStrategy() throws Exception {
 		if ( environment != null ) {
 			environment.release();
 		}
 	}
 
 	protected CollectionRegionAccessStrategy getCollectionAccessStrategy() {
 		return accessStrategy;
 	}
 
 	@Test
 	public void testLockItem() {
 		assertNull( getCollectionAccessStrategy().lockItem( KEY, new Integer( 1 ) ) );
 	}
 
 	@Test
 	public void testLockRegion() {
 		assertNull( getCollectionAccessStrategy().lockRegion() );
 	}
 
 	@Test
 	public void testUnlockItem() {
 		getCollectionAccessStrategy().unlockItem( KEY, new MockSoftLock() );
 	}
 
 	@Test
 	public void testUnlockRegion() {
 		getCollectionAccessStrategy().unlockItem( KEY, new MockSoftLock() );
 	}
 
 	public static class MockSoftLock implements SoftLock {
 	}
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractEntityRegionAccessStrategyTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractEntityRegionAccessStrategyTestCase.java
index 2ab0b03c39..d7949ce146 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractEntityRegionAccessStrategyTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractEntityRegionAccessStrategyTestCase.java
@@ -1,615 +1,615 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.entity;
 
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 
 import org.infinispan.transaction.tm.BatchModeTransactionManager;
 import org.jboss.logging.Logger;
 
-import org.hibernate.cache.CacheDataDescription;
-import org.hibernate.cache.access.AccessType;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
-import org.hibernate.cache.impl.CacheDataDescriptionImpl;
+import org.hibernate.cache.spi.CacheDataDescription;
+import org.hibernate.cache.spi.access.AccessType;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.internal.CacheDataDescriptionImpl;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.entity.EntityRegionImpl;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.internal.util.compare.ComparableComparator;
 
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 import junit.framework.AssertionFailedError;
 
 import org.hibernate.test.cache.infinispan.AbstractNonFunctionalTestCase;
 import org.hibernate.test.cache.infinispan.NodeEnvironment;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertTrue;
 
 /**
  * Base class for tests of EntityRegionAccessStrategy impls.
  *
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public abstract class AbstractEntityRegionAccessStrategyTestCase extends AbstractNonFunctionalTestCase {
 	private static final Logger log = Logger.getLogger( AbstractEntityRegionAccessStrategyTestCase.class );
 
 	public static final String REGION_NAME = "test/com.foo.test";
 	public static final String KEY_BASE = "KEY";
 	public static final String VALUE1 = "VALUE1";
 	public static final String VALUE2 = "VALUE2";
 
 	protected static int testCount;
 
 	protected NodeEnvironment localEnvironment;
 	protected EntityRegionImpl localEntityRegion;
 	protected EntityRegionAccessStrategy localAccessStrategy;
 
 	protected NodeEnvironment remoteEnvironment;
 	protected EntityRegionImpl remoteEntityRegion;
 	protected EntityRegionAccessStrategy remoteAccessStrategy;
 
 	protected boolean invalidation;
 	protected boolean synchronous;
 
 	protected Exception node1Exception;
 	protected Exception node2Exception;
 
 	protected AssertionFailedError node1Failure;
 	protected AssertionFailedError node2Failure;
 
 	@Before
 	public void prepareResources() throws Exception {
 		// to mimic exactly the old code results, both environments here are exactly the same...
 		Configuration cfg = createConfiguration( getConfigurationName() );
 		localEnvironment = new NodeEnvironment( cfg );
 		localEnvironment.prepare();
 
 		localEntityRegion = localEnvironment.getEntityRegion( REGION_NAME, getCacheDataDescription() );
 		localAccessStrategy = localEntityRegion.buildAccessStrategy( getAccessType() );
 
 		invalidation = localEntityRegion.getCacheAdapter().isClusteredInvalidation();
 		synchronous = localEntityRegion.getCacheAdapter().isSynchronous();
 
 		// Sleep a bit to avoid concurrent FLUSH problem
 		avoidConcurrentFlush();
 
 		remoteEnvironment = new NodeEnvironment( cfg );
 		remoteEnvironment.prepare();
 
 		remoteEntityRegion = remoteEnvironment.getEntityRegion( REGION_NAME, getCacheDataDescription() );
 		remoteAccessStrategy = remoteEntityRegion.buildAccessStrategy( getAccessType() );
 	}
 
 	protected abstract String getConfigurationName();
 
 	protected static Configuration createConfiguration(String configName) {
 		Configuration cfg = CacheTestUtil.buildConfiguration(
 				REGION_PREFIX,
 				InfinispanRegionFactory.class,
 				true,
 				false
 		);
 		cfg.setProperty( InfinispanRegionFactory.ENTITY_CACHE_RESOURCE_PROP, configName );
 		return cfg;
 	}
 
 	protected CacheDataDescription getCacheDataDescription() {
 		return new CacheDataDescriptionImpl( true, true, ComparableComparator.INSTANCE );
 	}
 
 	@After
 	public void releaseResources() throws Exception {
 		if ( localEnvironment != null ) {
 			localEnvironment.release();
 		}
 		if ( remoteEnvironment != null ) {
 			remoteEnvironment.release();
 		}
 	}
 
 	protected abstract AccessType getAccessType();
 
 	protected boolean isUsingInvalidation() {
 		return invalidation;
 	}
 
 	protected boolean isSynchronous() {
 		return synchronous;
 	}
 
 	protected void assertThreadsRanCleanly() {
 		if ( node1Failure != null ) {
 			throw node1Failure;
 		}
 		if ( node2Failure != null ) {
 			throw node2Failure;
 		}
 
 		if ( node1Exception != null ) {
             log.error("node1 saw an exception", node1Exception);
 			assertEquals( "node1 saw no exceptions", null, node1Exception );
 		}
 
 		if ( node2Exception != null ) {
             log.error("node2 saw an exception", node2Exception);
 			assertEquals( "node2 saw no exceptions", null, node2Exception );
 		}
 	}
 
 	@Test
 	public abstract void testCacheConfiguration();
 
 	@Test
 	public void testGetRegion() {
 		assertEquals( "Correct region", localEntityRegion, localAccessStrategy.getRegion() );
 	}
 
 	@Test
 	public void testPutFromLoad() throws Exception {
 		putFromLoadTest( false );
 	}
 
 	@Test
 	public void testPutFromLoadMinimal() throws Exception {
 		putFromLoadTest( true );
 	}
 
 	/**
 	 * Simulate 2 nodes, both start, tx do a get, experience a cache miss, then 'read from db.' First
 	 * does a putFromLoad, then an update. Second tries to do a putFromLoad with stale data (i.e. it
 	 * took longer to read from the db). Both commit their tx. Then both start a new tx and get.
 	 * First should see the updated data; second should either see the updated data (isInvalidation()
 	 * == false) or null (isInvalidation() == true).
 	 *
 	 * @param useMinimalAPI
 	 * @throws Exception
 	 */
 	private void putFromLoadTest(final boolean useMinimalAPI) throws Exception {
 
 		final String KEY = KEY_BASE + testCount++;
 
 		final CountDownLatch writeLatch1 = new CountDownLatch( 1 );
 		final CountDownLatch writeLatch2 = new CountDownLatch( 1 );
 		final CountDownLatch completionLatch = new CountDownLatch( 2 );
 
 		Thread node1 = new Thread() {
 
 			@Override
             public void run() {
 
 				try {
 					long txTimestamp = System.currentTimeMillis();
 					BatchModeTransactionManager.getInstance().begin();
 
 					assertNull( "node1 starts clean", localAccessStrategy.get( KEY, txTimestamp ) );
 
 					writeLatch1.await();
 
 					if ( useMinimalAPI ) {
 						localAccessStrategy.putFromLoad( KEY, VALUE1, txTimestamp, new Integer( 1 ), true );
 					}
 					else {
 						localAccessStrategy.putFromLoad( KEY, VALUE1, txTimestamp, new Integer( 1 ) );
 					}
 
 					localAccessStrategy.update( KEY, VALUE2, new Integer( 2 ), new Integer( 1 ) );
 
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
                     log.error("node1 caught exception", e);
 					node1Exception = e;
 					rollback();
 				}
 				catch (AssertionFailedError e) {
 					node1Failure = e;
 					rollback();
 				}
 				finally {
 					// Let node2 write
 					writeLatch2.countDown();
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		Thread node2 = new Thread() {
 
 			@Override
             public void run() {
 
 				try {
 					long txTimestamp = System.currentTimeMillis();
 					BatchModeTransactionManager.getInstance().begin();
 
 					assertNull( "node1 starts clean", remoteAccessStrategy.get( KEY, txTimestamp ) );
 
 					// Let node1 write
 					writeLatch1.countDown();
 					// Wait for node1 to finish
 					writeLatch2.await();
 
 					if ( useMinimalAPI ) {
 						remoteAccessStrategy.putFromLoad( KEY, VALUE1, txTimestamp, new Integer( 1 ), true );
 					}
 					else {
 						remoteAccessStrategy.putFromLoad( KEY, VALUE1, txTimestamp, new Integer( 1 ) );
 					}
 
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
                     log.error("node2 caught exception", e);
 					node2Exception = e;
 					rollback();
 				}
 				catch (AssertionFailedError e) {
 					node2Failure = e;
 					rollback();
 				}
 				finally {
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		node1.setDaemon( true );
 		node2.setDaemon( true );
 
 		node1.start();
 		node2.start();
 
 		assertTrue( "Threads completed", completionLatch.await( 2, TimeUnit.SECONDS ) );
 
 		assertThreadsRanCleanly();
 
 		long txTimestamp = System.currentTimeMillis();
 		assertEquals( "Correct node1 value", VALUE2, localAccessStrategy.get( KEY, txTimestamp ) );
 
 		if ( isUsingInvalidation() ) {
 			// no data version to prevent the PFER; we count on db locks preventing this
 			assertEquals( "Expected node2 value", VALUE1, remoteAccessStrategy.get( KEY, txTimestamp ) );
 		}
 		else {
 			// The node1 update is replicated, preventing the node2 PFER
 			assertEquals( "Correct node2 value", VALUE2, remoteAccessStrategy.get( KEY, txTimestamp ) );
 		}
 	}
 
 	@Test
 	public void testInsert() throws Exception {
 
 		final String KEY = KEY_BASE + testCount++;
 
 		final CountDownLatch readLatch = new CountDownLatch( 1 );
 		final CountDownLatch commitLatch = new CountDownLatch( 1 );
 		final CountDownLatch completionLatch = new CountDownLatch( 2 );
 
 		Thread inserter = new Thread() {
 
 			@Override
             public void run() {
 
 				try {
 					long txTimestamp = System.currentTimeMillis();
 					BatchModeTransactionManager.getInstance().begin();
 
 					assertNull( "Correct initial value", localAccessStrategy.get( KEY, txTimestamp ) );
 
 					localAccessStrategy.insert( KEY, VALUE1, new Integer( 1 ) );
 
 					readLatch.countDown();
 					commitLatch.await();
 
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
                     log.error("node1 caught exception", e);
 					node1Exception = e;
 					rollback();
 				}
 				catch (AssertionFailedError e) {
 					node1Failure = e;
 					rollback();
 				}
 				finally {
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		Thread reader = new Thread() {
 
 			@Override
             public void run() {
 
 				try {
 					long txTimestamp = System.currentTimeMillis();
 					BatchModeTransactionManager.getInstance().begin();
 
 					readLatch.await();
 //               Object expected = !isBlockingReads() ? null : VALUE1;
 					Object expected = null;
 
 					assertEquals(
 							"Correct initial value", expected, localAccessStrategy.get(
 							KEY,
 							txTimestamp
 					)
 					);
 
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
                     log.error("node1 caught exception", e);
 					node1Exception = e;
 					rollback();
 				}
 				catch (AssertionFailedError e) {
 					node1Failure = e;
 					rollback();
 				}
 				finally {
 					commitLatch.countDown();
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		inserter.setDaemon( true );
 		reader.setDaemon( true );
 		inserter.start();
 		reader.start();
 
 		assertTrue( "Threads completed", completionLatch.await( 1, TimeUnit.SECONDS ) );
 
 		assertThreadsRanCleanly();
 
 		long txTimestamp = System.currentTimeMillis();
 		assertEquals( "Correct node1 value", VALUE1, localAccessStrategy.get( KEY, txTimestamp ) );
 		Object expected = isUsingInvalidation() ? null : VALUE1;
 		assertEquals( "Correct node2 value", expected, remoteAccessStrategy.get( KEY, txTimestamp ) );
 	}
 
 	@Test
 	public void testUpdate() throws Exception {
 
 		final String KEY = KEY_BASE + testCount++;
 
 		// Set up initial state
 		localAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		remoteAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 
 		// Let the async put propagate
 		sleep( 250 );
 
 		final CountDownLatch readLatch = new CountDownLatch( 1 );
 		final CountDownLatch commitLatch = new CountDownLatch( 1 );
 		final CountDownLatch completionLatch = new CountDownLatch( 2 );
 
 		Thread updater = new Thread( "testUpdate-updater" ) {
 
 			@Override
             public void run() {
 				boolean readerUnlocked = false;
 				try {
 					long txTimestamp = System.currentTimeMillis();
 					BatchModeTransactionManager.getInstance().begin();
                     log.debug("Transaction began, get initial value");
 					assertEquals( "Correct initial value", VALUE1, localAccessStrategy.get( KEY, txTimestamp ) );
                     log.debug("Now update value");
 					localAccessStrategy.update( KEY, VALUE2, new Integer( 2 ), new Integer( 1 ) );
                     log.debug("Notify the read latch");
 					readLatch.countDown();
 					readerUnlocked = true;
                     log.debug("Await commit");
 					commitLatch.await();
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
                     log.error("node1 caught exception", e);
 					node1Exception = e;
 					rollback();
 				}
 				catch (AssertionFailedError e) {
 					node1Failure = e;
 					rollback();
 				}
 				finally {
 					if ( !readerUnlocked ) {
 						readLatch.countDown();
 					}
                     log.debug("Completion latch countdown");
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		Thread reader = new Thread( "testUpdate-reader" ) {
 
 			@Override
             public void run() {
 				try {
 					long txTimestamp = System.currentTimeMillis();
 					BatchModeTransactionManager.getInstance().begin();
                     log.debug("Transaction began, await read latch");
 					readLatch.await();
                     log.debug("Read latch acquired, verify local access strategy");
 
 					// This won't block w/ mvc and will read the old value
 					Object expected = VALUE1;
 					assertEquals( "Correct value", expected, localAccessStrategy.get( KEY, txTimestamp ) );
 
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
                     log.error("node1 caught exception", e);
 					node1Exception = e;
 					rollback();
 				}
 				catch (AssertionFailedError e) {
 					node1Failure = e;
 					rollback();
 				}
 				finally {
 					commitLatch.countDown();
                     log.debug("Completion latch countdown");
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		updater.setDaemon( true );
 		reader.setDaemon( true );
 		updater.start();
 		reader.start();
 
 		// Should complete promptly
 		assertTrue( completionLatch.await( 2, TimeUnit.SECONDS ) );
 
 		assertThreadsRanCleanly();
 
 		long txTimestamp = System.currentTimeMillis();
 		assertEquals( "Correct node1 value", VALUE2, localAccessStrategy.get( KEY, txTimestamp ) );
 		Object expected = isUsingInvalidation() ? null : VALUE2;
 		assertEquals( "Correct node2 value", expected, remoteAccessStrategy.get( KEY, txTimestamp ) );
 	}
 
 	@Test
 	public void testRemove() {
 		evictOrRemoveTest( false );
 	}
 
 	@Test
 	public void testRemoveAll() {
 		evictOrRemoveAllTest( false );
 	}
 
 	@Test
 	public void testEvict() {
 		evictOrRemoveTest( true );
 	}
 
 	@Test
 	public void testEvictAll() {
 		evictOrRemoveAllTest( true );
 	}
 
 	private void evictOrRemoveTest(boolean evict) {
 		final String KEY = KEY_BASE + testCount++;
 		assertEquals( 0, getValidKeyCount( localEntityRegion.getCacheAdapter().keySet() ) );
 		assertEquals( 0, getValidKeyCount( remoteEntityRegion.getCacheAdapter().keySet() ) );
 
 		assertNull( "local is clean", localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertNull( "remote is clean", remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		localAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		remoteAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		if ( evict ) {
 			localAccessStrategy.evict( KEY );
 		}
 		else {
 			localAccessStrategy.remove( KEY );
 		}
 
 		assertEquals( null, localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertEquals( 0, getValidKeyCount( localEntityRegion.getCacheAdapter().keySet() ) );
 		assertEquals( null, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertEquals( 0, getValidKeyCount( remoteEntityRegion.getCacheAdapter().keySet() ) );
 	}
 
 	private void evictOrRemoveAllTest(boolean evict) {
 		final String KEY = KEY_BASE + testCount++;
 		assertEquals( 0, getValidKeyCount( localEntityRegion.getCacheAdapter().keySet() ) );
 		assertEquals( 0, getValidKeyCount( remoteEntityRegion.getCacheAdapter().keySet() ) );
 		assertNull( "local is clean", localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertNull( "remote is clean", remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		localAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		// Wait for async propagation
 		sleep( 250 );
 
 		remoteAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 
 		// Wait for async propagation
 		sleep( 250 );
 
 		if ( evict ) {
             log.debug("Call evict all locally");
 			localAccessStrategy.evictAll();
 		}
 		else {
 			localAccessStrategy.removeAll();
 		}
 
 		// This should re-establish the region root node in the optimistic case
 		assertNull( localAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertEquals( 0, getValidKeyCount( localEntityRegion.getCacheAdapter().keySet() ) );
 
 		// Re-establishing the region root on the local node doesn't
 		// propagate it to other nodes. Do a get on the remote node to re-establish
 		assertEquals( null, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertEquals( 0, getValidKeyCount( remoteEntityRegion.getCacheAdapter().keySet() ) );
 
 		// Test whether the get above messes up the optimistic version
 		remoteAccessStrategy.putFromLoad( KEY, VALUE1, System.currentTimeMillis(), new Integer( 1 ) );
 		assertEquals( VALUE1, remoteAccessStrategy.get( KEY, System.currentTimeMillis() ) );
 		assertEquals( 1, getValidKeyCount( remoteEntityRegion.getCacheAdapter().keySet() ) );
 
 		// Wait for async propagation
 		sleep( 250 );
 
 		assertEquals(
 				"local is correct", (isUsingInvalidation() ? null : VALUE1), localAccessStrategy
 				.get( KEY, System.currentTimeMillis() )
 		);
 		assertEquals(
 				"remote is correct", VALUE1, remoteAccessStrategy.get(
 				KEY, System
 				.currentTimeMillis()
 		)
 		);
 	}
 
 	protected void rollback() {
 		try {
 			BatchModeTransactionManager.getInstance().rollback();
 		}
 		catch (Exception e) {
             log.error(e.getMessage(), e);
 		}
 	}
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractReadOnlyAccessTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractReadOnlyAccessTestCase.java
index 04da6bdaeb..79e27895e1 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractReadOnlyAccessTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractReadOnlyAccessTestCase.java
@@ -1,94 +1,94 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. ¬†All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.entity;
 
 import org.infinispan.transaction.tm.BatchModeTransactionManager;
 
-import org.hibernate.cache.access.AccessType;
+import org.hibernate.cache.spi.access.AccessType;
 
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.fail;
 
 /**
  * Base class for tests of TRANSACTIONAL access.
  * 
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public abstract class AbstractReadOnlyAccessTestCase extends AbstractEntityRegionAccessStrategyTestCase {
     @Override
     protected AccessType getAccessType() {
         return AccessType.READ_ONLY;
     }   
 
 	@Test
     @Override
     public void testPutFromLoad() throws Exception {
         putFromLoadTest(false);
     }
 
 	@Test
     @Override
     public void testPutFromLoadMinimal() throws Exception {
         putFromLoadTest(true);
     }
     
     private void putFromLoadTest(boolean minimal) throws Exception {
        
         final String KEY = KEY_BASE + testCount++;
         
         long txTimestamp = System.currentTimeMillis();
         BatchModeTransactionManager.getInstance().begin();
         assertNull(localAccessStrategy.get(KEY, System.currentTimeMillis()));
         if (minimal)
             localAccessStrategy.putFromLoad(KEY, VALUE1, txTimestamp, new Integer(1), true);
         else
             localAccessStrategy.putFromLoad(KEY, VALUE1, txTimestamp, new Integer(1));
         
         sleep(250);
         Object expected = isUsingInvalidation() ? null : VALUE1;
         assertEquals(expected, remoteAccessStrategy.get(KEY, System.currentTimeMillis()));
         
         BatchModeTransactionManager.getInstance().commit();
         assertEquals(VALUE1, localAccessStrategy.get(KEY, System.currentTimeMillis()));
         assertEquals(expected, remoteAccessStrategy.get(KEY, System.currentTimeMillis()));
     }
 
 	@Test
     @Override
     public void testUpdate() throws Exception {
        
         final String KEY = KEY_BASE + testCount++;
         
         try {
             localAccessStrategy.update(KEY, VALUE2, new Integer(2), new Integer(1));
             fail("Call to update did not throw exception");
         }
         catch (UnsupportedOperationException good) {}
     }
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractTransactionalAccessTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractTransactionalAccessTestCase.java
index 15f7d25f15..b53000b6bb 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractTransactionalAccessTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/AbstractTransactionalAccessTestCase.java
@@ -1,134 +1,134 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. ¬†All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.entity;
 
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 
 import org.infinispan.transaction.tm.BatchModeTransactionManager;
 import org.jboss.logging.Logger;
 
-import org.hibernate.cache.access.AccessType;
+import org.hibernate.cache.spi.access.AccessType;
 
 import junit.framework.AssertionFailedError;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 
 /**
  * Base class for tests of TRANSACTIONAL access.
  *
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public abstract class AbstractTransactionalAccessTestCase extends AbstractEntityRegionAccessStrategyTestCase {
 	private static final Logger log = Logger.getLogger( AbstractTransactionalAccessTestCase.class );
 
 	@Override
    protected AccessType getAccessType() {
       return AccessType.TRANSACTIONAL;
    }
 
     public void testContestedPutFromLoad() throws Exception {
 
         final String KEY = KEY_BASE + testCount++;
 
         localAccessStrategy.putFromLoad(KEY, VALUE1, System.currentTimeMillis(), new Integer(1));
 
         final CountDownLatch pferLatch = new CountDownLatch(1);
         final CountDownLatch pferCompletionLatch = new CountDownLatch(1);
         final CountDownLatch commitLatch = new CountDownLatch(1);
         final CountDownLatch completionLatch = new CountDownLatch(1);
 
         Thread blocker = new Thread("Blocker") {
 
             @Override
             public void run() {
 
                 try {
                     long txTimestamp = System.currentTimeMillis();
                     BatchModeTransactionManager.getInstance().begin();
 
                     assertEquals("Correct initial value", VALUE1, localAccessStrategy.get(KEY, txTimestamp));
 
                     localAccessStrategy.update(KEY, VALUE2, new Integer(2), new Integer(1));
 
                     pferLatch.countDown();
                     commitLatch.await();
 
                     BatchModeTransactionManager.getInstance().commit();
                 } catch (Exception e) {
                     log.error("node1 caught exception", e);
                     node1Exception = e;
                     rollback();
                 } catch (AssertionFailedError e) {
                     node1Failure = e;
                     rollback();
                 } finally {
                     completionLatch.countDown();
                 }
             }
         };
 
         Thread putter = new Thread("Putter") {
 
             @Override
             public void run() {
 
                 try {
                     long txTimestamp = System.currentTimeMillis();
                     BatchModeTransactionManager.getInstance().begin();
 
                     localAccessStrategy.putFromLoad(KEY, VALUE1, txTimestamp, new Integer(1));
 
                     BatchModeTransactionManager.getInstance().commit();
                 } catch (Exception e) {
                     log.error("node1 caught exception", e);
                     node1Exception = e;
                     rollback();
                 } catch (AssertionFailedError e) {
                     node1Failure = e;
                     rollback();
                 } finally {
                     pferCompletionLatch.countDown();
                 }
             }
         };
 
         blocker.start();
         assertTrue("Active tx has done an update", pferLatch.await(1, TimeUnit.SECONDS));
         putter.start();
         assertTrue("putFromLoadreturns promtly", pferCompletionLatch.await(10, TimeUnit.MILLISECONDS));
 
         commitLatch.countDown();
 
         assertTrue("Threads completed", completionLatch.await(1, TimeUnit.SECONDS));
 
         assertThreadsRanCleanly();
 
         long txTimestamp = System.currentTimeMillis();
         assertEquals("Correct node1 value", VALUE2, localAccessStrategy.get(KEY, txTimestamp));
     }
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/EntityRegionImplTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/EntityRegionImplTestCase.java
index 6b11b0be5c..558c136687 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/EntityRegionImplTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/EntityRegionImplTestCase.java
@@ -1,93 +1,93 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. ¬†All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.entity;
 import java.util.Properties;
-import org.hibernate.cache.CacheDataDescription;
+import org.hibernate.cache.spi.CacheDataDescription;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.EntityRegion;
-import org.hibernate.cache.Region;
-import org.hibernate.cache.RegionFactory;
-import org.hibernate.cache.access.AccessType;
+import org.hibernate.cache.spi.EntityRegion;
+import org.hibernate.cache.spi.Region;
+import org.hibernate.cache.spi.RegionFactory;
+import org.hibernate.cache.spi.access.AccessType;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.cache.infinispan.util.CacheAdapterImpl;
 
 import org.hibernate.test.cache.infinispan.AbstractEntityCollectionRegionTestCase;
 
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.fail;
 
 /**
  * Tests of EntityRegionImpl.
  * 
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public class EntityRegionImplTestCase extends AbstractEntityCollectionRegionTestCase {
 
    @Override
    protected void supportedAccessTypeTest(RegionFactory regionFactory, Properties properties) {
       EntityRegion region = regionFactory.buildEntityRegion("test", properties, null);
       assertNull("Got TRANSACTIONAL", region.buildAccessStrategy(AccessType.TRANSACTIONAL)
                .lockRegion());
       try {
          region.buildAccessStrategy(AccessType.READ_ONLY).lockRegion();
          fail("Did not get READ_ONLY");
       } catch (UnsupportedOperationException good) {
       }
 
       try {
          region.buildAccessStrategy(AccessType.NONSTRICT_READ_WRITE);
          fail("Incorrectly got NONSTRICT_READ_WRITE");
       } catch (CacheException good) {
       }
 
       try {
          region.buildAccessStrategy(AccessType.READ_WRITE);
          fail("Incorrectly got READ_WRITE");
       } catch (CacheException good) {
       }
    }
 
    @Override
    protected void putInRegion(Region region, Object key, Object value) {
       ((EntityRegion) region).buildAccessStrategy(AccessType.TRANSACTIONAL).insert(key, value, new Integer(1));
    }
 
    @Override
    protected void removeFromRegion(Region region, Object key) {
       ((EntityRegion) region).buildAccessStrategy(AccessType.TRANSACTIONAL).remove(key);
    }
 
    @Override
    protected Region createRegion(InfinispanRegionFactory regionFactory, String regionName, Properties properties, CacheDataDescription cdd) {
       return regionFactory.buildEntityRegion(regionName, properties, cdd);
    }
 
    @Override
    protected CacheAdapter getInfinispanCache(InfinispanRegionFactory regionFactory) {
       return CacheAdapterImpl.newInstance(regionFactory.getCacheManager().getCache(InfinispanRegionFactory.DEF_ENTITY_RESOURCE));
    }
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/ReadOnlyExtraAPITestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/ReadOnlyExtraAPITestCase.java
index f099d0d743..2b18376cd4 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/ReadOnlyExtraAPITestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/ReadOnlyExtraAPITestCase.java
@@ -1,79 +1,79 @@
 /*
  * JBoss, Home of Professional Open Source.
  * Copyright 2009, Red Hat, Inc. and/or it's affiliates, and individual contributors
  * as indicated by the @author tags. See the copyright.txt file in the
  * distribution for a full listing of individual contributors.
  *
  * This is free software; you can redistribute it and/or modify it
  * under the terms of the GNU Lesser General Public License as
  * published by the Free Software Foundation; either version 2.1 of
  * the License, or (at your option) any later version.
  *
  * This software is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * Lesser General Public License for more details.
  *
  * You should have received a copy of the GNU Lesser General Public
  * License along with this software; if not, write to the Free
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
 package org.hibernate.test.cache.infinispan.entity;
-import org.hibernate.cache.access.AccessType;
+import org.hibernate.cache.spi.access.AccessType;
 
 import static org.junit.Assert.fail;
 
 /**
  * Tests for the "extra API" in EntityRegionAccessStrategy;
  * <p/>
  * By "extra API" we mean those methods that are superfluous to the
  * function of the Infinispan integration, where the impl is a no-op or a static
  * false return value, UnsupportedOperationException, etc.
  *
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public class ReadOnlyExtraAPITestCase extends TransactionalExtraAPITestCase {
 	@Override
 	protected AccessType getAccessType() {
 		return AccessType.READ_ONLY;
 	}
 
 	@Override
 	public void testLockItem() {
 		try {
 			getEntityAccessStrategy().lockItem( KEY, Integer.valueOf( 1 ) );
 			fail( "Call to lockItem did not throw exception" );
 		}
 		catch (UnsupportedOperationException expected) {
 		}
 	}
 
 	@Override
 	public void testLockRegion() {
 		try {
 			getEntityAccessStrategy().lockRegion();
 			fail( "Call to lockRegion did not throw exception" );
 		}
 		catch (UnsupportedOperationException expected) {
 		}
 	}
 
 	@Override
 	public void testAfterUpdate() {
 		try {
 			getEntityAccessStrategy().afterUpdate(
 					KEY,
 					VALUE2,
 					Integer.valueOf( 1 ),
 					Integer.valueOf( 2 ),
 					new MockSoftLock()
 			);
 			fail( "Call to afterUpdate did not throw exception" );
 		}
 		catch (UnsupportedOperationException expected) {
 		}
 	}
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/TransactionalExtraAPITestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/TransactionalExtraAPITestCase.java
index f6f5ee7d9e..8e74868915 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/TransactionalExtraAPITestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/entity/TransactionalExtraAPITestCase.java
@@ -1,147 +1,147 @@
 /*
  * JBoss, Home of Professional Open Source.
  * Copyright 2009, Red Hat, Inc. and/or it's affiliates, and individual contributors
  * as indicated by the @author tags. See the copyright.txt file in the
  * distribution for a full listing of individual contributors.
  *
  * This is free software; you can redistribute it and/or modify it
  * under the terms of the GNU Lesser General Public License as
  * published by the Free Software Foundation; either version 2.1 of
  * the License, or (at your option) any later version.
  *
  * This software is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * Lesser General Public License for more details.
  *
  * You should have received a copy of the GNU Lesser General Public
  * License along with this software; if not, write to the Free
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
 package org.hibernate.test.cache.infinispan.entity;
 
-import org.hibernate.cache.access.AccessType;
-import org.hibernate.cache.access.EntityRegionAccessStrategy;
-import org.hibernate.cache.access.SoftLock;
+import org.hibernate.cache.spi.access.AccessType;
+import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
+import org.hibernate.cache.spi.access.SoftLock;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cfg.Configuration;
 
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 
 import org.hibernate.test.cache.infinispan.AbstractNonFunctionalTestCase;
 import org.hibernate.test.cache.infinispan.NodeEnvironment;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNull;
 
 /**
  * Tests for the "extra API" in EntityRegionAccessStrategy;.
  * <p>
  * By "extra API" we mean those methods that are superfluous to the 
  * function of the JBC integration, where the impl is a no-op or a static
  * false return value, UnsupportedOperationException, etc.
  * 
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public class TransactionalExtraAPITestCase extends AbstractNonFunctionalTestCase {
 	public static final String REGION_NAME = "test/com.foo.test";
 	public static final String KEY = "KEY";
 	public static final String VALUE1 = "VALUE1";
 	public static final String VALUE2 = "VALUE2";
 
 	private NodeEnvironment environment;
 	private EntityRegionAccessStrategy accessStrategy;
 
 	@Before
 	public final void prepareLocalAccessStrategy() throws Exception {
 		environment = new NodeEnvironment( createConfiguration() );
 		environment.prepare();
 
 		// Sleep a bit to avoid concurrent FLUSH problem
 		avoidConcurrentFlush();
 
 		accessStrategy = environment.getEntityRegion( REGION_NAME, null ).buildAccessStrategy( getAccessType() );
    }
 
 	protected Configuration createConfiguration() {
 		Configuration cfg = CacheTestUtil.buildConfiguration(REGION_PREFIX, InfinispanRegionFactory.class, true, false);
 		cfg.setProperty(InfinispanRegionFactory.ENTITY_CACHE_RESOURCE_PROP, getCacheConfigName());
 		return cfg;
 	}
 
 	@After
 	public final void releaseLocalAccessStrategy() throws Exception {
 		if ( environment != null ) {
 			environment.release();
 		}
 	}
 
 	protected final EntityRegionAccessStrategy getEntityAccessStrategy() {
 		return accessStrategy;
 	}
 
 	protected String getCacheConfigName() {
 		return "entity";
 	}
 
 	protected AccessType getAccessType() {
 		return AccessType.TRANSACTIONAL;
 	}
 
 	@Test
 	@SuppressWarnings( {"UnnecessaryBoxing"})
 	public void testLockItem() {
 		assertNull( getEntityAccessStrategy().lockItem( KEY, Integer.valueOf( 1 ) ) );
 	}
 
 	@Test
 	public void testLockRegion() {
 		assertNull( getEntityAccessStrategy().lockRegion() );
 	}
 
 	@Test
 	public void testUnlockItem() {
 		getEntityAccessStrategy().unlockItem( KEY, new MockSoftLock() );
 	}
 
 	@Test
 	public void testUnlockRegion() {
 		getEntityAccessStrategy().unlockItem( KEY, new MockSoftLock() );
 	}
 
 	@Test
 	@SuppressWarnings( {"UnnecessaryBoxing"})
 	public void testAfterInsert() {
 		assertFalse(
 				"afterInsert always returns false",
 				getEntityAccessStrategy().afterInsert(
 						KEY,
 						VALUE1,
 						Integer.valueOf( 1 )
 				)
 		);
 	}
 
 	@Test
 	@SuppressWarnings( {"UnnecessaryBoxing"})
 	public void testAfterUpdate() {
 		assertFalse(
 				"afterInsert always returns false",
 				getEntityAccessStrategy().afterUpdate(
 						KEY,
 						VALUE2,
 						Integer.valueOf( 1 ),
 						Integer.valueOf( 2 ),
 						new MockSoftLock()
 				)
 		);
 	}
 
 	public static class MockSoftLock implements SoftLock {
 	}
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/BasicTransactionalTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/BasicTransactionalTestCase.java
index 9fe0bece2d..e4f6b60ae9 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/BasicTransactionalTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/BasicTransactionalTestCase.java
@@ -1,446 +1,444 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.functional;
 
 import java.io.Serializable;
 import java.util.Map;
 
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 import org.hibernate.Session;
 import org.hibernate.Transaction;
-import org.hibernate.cache.entry.CacheEntry;
+import org.hibernate.cache.spi.entry.CacheEntry;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.stat.SecondLevelCacheStatistics;
 import org.hibernate.stat.Statistics;
 
 import org.junit.Test;
 
-import org.hibernate.testing.FailureExpected;
-
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 
 /**
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public class BasicTransactionalTestCase extends SingleNodeTestCase {
 	private static final Log log = LogFactory.getLog( BasicTransactionalTestCase.class );
 
 	@Override
 	public void configure(Configuration cfg) {
 		super.configure( cfg );
 	}
 
 	@Test
 	public void testEntityCache() throws Exception {
 		Statistics stats = sessionFactory().getStatistics();
 		stats.clear();
 
 		Item item = new Item( "chris", "Chris's Item" );
 		beginTx();
 		try {
 			Session s = openSession();
 			s.getTransaction().begin();
 			s.persist( item );
 			s.getTransaction().commit();
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 
 		log.info( "Entry persisted, let's load and delete it." );
 
 		beginTx();
 		try {
 			Session s = openSession();
 			Item found = (Item) s.load( Item.class, item.getId() );
 			log.info( stats.toString() );
 			assertEquals( item.getDescription(), found.getDescription() );
 			assertEquals( 0, stats.getSecondLevelCacheMissCount() );
 			assertEquals( 1, stats.getSecondLevelCacheHitCount() );
 			s.delete( found );
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 	}
 
 	@Test
 	public void testCollectionCache() throws Exception {
 		Statistics stats = sessionFactory().getStatistics();
 		stats.clear();
 
 		Item item = new Item( "chris", "Chris's Item" );
 		Item another = new Item( "another", "Owned Item" );
 		item.addItem( another );
 
 		beginTx();
 		try {
 			Session s = openSession();
 			s.getTransaction().begin();
 			s.persist( item );
 			s.persist( another );
 			s.getTransaction().commit();
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 
 		beginTx();
 		try {
 			Session s = openSession();
 			Item loaded = (Item) s.load( Item.class, item.getId() );
 			assertEquals( 1, loaded.getItems().size() );
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 
 		beginTx();
 		try {
 			Session s = openSession();
 			SecondLevelCacheStatistics cStats = stats.getSecondLevelCacheStatistics( Item.class.getName() + ".items" );
 			Item loadedWithCachedCollection = (Item) s.load( Item.class, item.getId() );
 			stats.logSummary();
 			assertEquals( item.getName(), loadedWithCachedCollection.getName() );
 			assertEquals( item.getItems().size(), loadedWithCachedCollection.getItems().size() );
 			assertEquals( 1, cStats.getHitCount() );
 			Map cacheEntries = cStats.getEntries();
 			assertEquals( 1, cacheEntries.size() );
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 	}
 
 	@Test
 	public void testStaleWritesLeaveCacheConsistent() throws Exception {
 		Statistics stats = sessionFactory().getStatistics();
 		stats.clear();
 
 		VersionedItem item = null;
 		Transaction txn = null;
 		Session s = null;
 		beginTx();
 		try {
 			s = openSession();
 			txn = s.beginTransaction();
 			item = new VersionedItem();
 			item.setName( "steve" );
 			item.setDescription( "steve's item" );
 			s.save( item );
 			txn.commit();
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 
 		Long initialVersion = item.getVersion();
 
 		// manually revert the version property
 		item.setVersion( new Long( item.getVersion().longValue() - 1 ) );
 
 		beginTx();
 		try {
 			s = openSession();
 			txn = s.beginTransaction();
 			s.update( item );
 			txn.commit();
 			fail( "expected stale write to fail" );
 		}
 		catch (Exception e) {
 			setRollbackOnlyTxExpected( e );
 		}
 		finally {
 			commitOrRollbackTx();
 			if ( s != null && s.isOpen() ) {
 				try {
 					s.close();
 				}
 				catch (Throwable ignore) {
 				}
 			}
 		}
 
 		// check the version value in the cache...
 		SecondLevelCacheStatistics slcs = stats.getSecondLevelCacheStatistics( VersionedItem.class.getName() );
 
 		Object entry = slcs.getEntries().get( item.getId() );
 		Long cachedVersionValue;
 		cachedVersionValue = (Long) ((CacheEntry) entry).getVersion();
 		assertEquals( initialVersion.longValue(), cachedVersionValue.longValue() );
 
 		beginTx();
 		try {
 			// cleanup
 			s = openSession();
 			txn = s.beginTransaction();
 			item = (VersionedItem) s.load( VersionedItem.class, item.getId() );
 			s.delete( item );
 			txn.commit();
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 	}
 
 	@Test
 	public void testQueryCacheInvalidation() throws Exception {
 		Statistics stats = sessionFactory().getStatistics();
 		stats.clear();
 
 		SecondLevelCacheStatistics slcs = stats.getSecondLevelCacheStatistics( Item.class.getName() );
 		sessionFactory().getCache().evictEntityRegion( Item.class.getName() );
 
 		assertEquals( 0, slcs.getPutCount() );
 		assertEquals( 0, slcs.getElementCountInMemory() );
 		assertEquals( 0, slcs.getEntries().size() );
 
 		Session s = null;
 		Transaction t = null;
 		Item i = null;
 
 		beginTx();
 		try {
 			s = openSession();
 			t = s.beginTransaction();
 			i = new Item();
 			i.setName( "widget" );
 			i.setDescription( "A really top-quality, full-featured widget." );
 			s.persist( i );
 			t.commit();
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 
 
 		assertEquals( 1, slcs.getPutCount() );
 		assertEquals( 1, slcs.getElementCountInMemory() );
 		assertEquals( 1, slcs.getEntries().size() );
 
 		beginTx();
 		try {
 			s = openSession();
 			t = s.beginTransaction();
 			i = (Item) s.get( Item.class, i.getId() );
 			assertEquals( slcs.getHitCount(), 1 );
 			assertEquals( slcs.getMissCount(), 0 );
 			i.setDescription( "A bog standard item" );
 			t.commit();
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 
 		assertEquals( slcs.getPutCount(), 2 );
 
 		CacheEntry entry = (CacheEntry) slcs.getEntries().get( i.getId() );
 		Serializable[] ser = entry.getDisassembledState();
 		assertTrue( ser[0].equals( "widget" ) );
 		assertTrue( ser[1].equals( "A bog standard item" ) );
 
 		beginTx();
 		try {
 			// cleanup
 			s = openSession();
 			t = s.beginTransaction();
 			s.delete( i );
 			t.commit();
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 	}
 
 	@Test
 	public void testQueryCache() throws Exception {
 		Statistics stats = sessionFactory().getStatistics();
 		stats.clear();
 
 		Session s;
 		Item item = new Item( "chris", "Chris's Item" );
 
 		beginTx();
 		try {
 			s = openSession();
 			s.getTransaction().begin();
 			s.persist( item );
 			s.getTransaction().commit();
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 
 		// Delay added to guarantee that query cache results won't be considered
 		// as not up to date due to persist session and query results from first
 		// query happening within same 100ms gap.
 		Thread.sleep( 100 );
 
 		beginTx();
 		try {
 			s = openSession();
 			s.createQuery( "from Item" ).setCacheable( true ).list();
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 
 		beginTx();
 		try {
 			s = openSession();
 			s.createQuery( "from Item" ).setCacheable( true ).list();
 			assertEquals( 1, stats.getQueryCacheHitCount() );
 			s.createQuery( "delete from Item" ).executeUpdate();
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 	}
 
 	@Test
 	public void testQueryCacheHitInSameTransaction() throws Exception {
 		Statistics stats = sessionFactory().getStatistics();
 		stats.clear();
 
 		Session s = null;
 		Item item = new Item( "galder", "Galder's Item" );
 
 		beginTx();
 		try {
 			s = openSession();
 			s.getTransaction().begin();
 			s.persist( item );
 			s.getTransaction().commit();
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 
 		// Delay added to guarantee that query cache results won't be considered
 		// as not up to date due to persist session and query results from first
 		// query happening within same 100ms gap.
 		Thread.sleep( 100 );
 
 		beginTx();
 		try {
 			s = openSession();
 			s.createQuery( "from Item" ).setCacheable( true ).list();
 			s.createQuery( "from Item" ).setCacheable( true ).list();
 			assertEquals( 1, stats.getQueryCacheHitCount() );
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 
 		beginTx();
 		try {
 			s = openSession();
 			s.createQuery( "delete from Item" ).executeUpdate();
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 	}
 
 	@Test
 	public void testEmptySecondLevelCacheEntry() throws Exception {
       sessionFactory().getCache().evictCollectionRegion( Item.class.getName() + ".items" );
 		Statistics stats = sessionFactory().getStatistics();
 		stats.clear();
 		SecondLevelCacheStatistics statistics = stats.getSecondLevelCacheStatistics( Item.class.getName() + ".items" );
 		Map cacheEntries = statistics.getEntries();
 		assertEquals( 0, cacheEntries.size() );
 	}
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/ConcurrentWriteTest.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/ConcurrentWriteTest.java
index 84fd092274..07d1fc0c00 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/ConcurrentWriteTest.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/ConcurrentWriteTest.java
@@ -1,558 +1,558 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.functional;
 
 import javax.transaction.TransactionManager;
 import java.io.PrintWriter;
 import java.io.StringWriter;
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Random;
 import java.util.Set;
 import java.util.concurrent.Callable;
 import java.util.concurrent.CyclicBarrier;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
 import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 import org.hibernate.FlushMode;
 import org.hibernate.Session;
-import org.hibernate.cache.RegionFactory;
+import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.service.jta.platform.spi.JtaPlatform;
 import org.hibernate.stat.SecondLevelCacheStatistics;
 
 import org.junit.Test;
 
 import org.hibernate.test.cache.infinispan.functional.cluster.DualNodeConnectionProviderImpl;
 import org.hibernate.test.cache.infinispan.functional.cluster.DualNodeJtaPlatformImpl;
 import org.hibernate.test.cache.infinispan.functional.cluster.DualNodeJtaTransactionManagerImpl;
 import org.hibernate.test.cache.infinispan.functional.cluster.DualNodeTestCase;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNull;
 
 /**
  * @author nikita_tovstoles@mba.berkeley.edu
  * @author Galder Zamarre√±o
  */
 public class ConcurrentWriteTest extends SingleNodeTestCase {
 	private static final Log log = LogFactory.getLog( ConcurrentWriteTest.class );
 	private static final boolean trace = log.isTraceEnabled();
 	/**
 	 * when USER_COUNT==1, tests pass, when >4 tests fail
 	 */
 	private static final int USER_COUNT = 5;
 	private static final int ITERATION_COUNT = 150;
 	private static final int THINK_TIME_MILLIS = 10;
 	private static final long LAUNCH_INTERVAL_MILLIS = 10;
 	private static final Random random = new Random();
 
 	/**
 	 * kill switch used to stop all users when one fails
 	 */
 	private static volatile boolean TERMINATE_ALL_USERS = false;
 
 	/**
 	 * collection of IDs of all customers participating in this test
 	 */
 	private Set<Integer> customerIDs = new HashSet<Integer>();
 
 	private TransactionManager tm;
 
 	@Override
 	public void configure(Configuration cfg) {
 		super.configure( cfg );
 		cfg.setProperty( DualNodeTestCase.NODE_ID_PROP, DualNodeTestCase.LOCAL );
 		cfg.setProperty( DualNodeTestCase.NODE_ID_FIELD, DualNodeTestCase.LOCAL );
 	}
 
 	@Override
 	protected boolean getUseQueryCache() {
 		return true;
 	}
 
 	@Override
 	protected TransactionManager getTransactionManager() {
 		return DualNodeJtaTransactionManagerImpl.getInstance( DualNodeTestCase.LOCAL );
 	}
 
 	@Override
 	protected Class<? extends RegionFactory> getCacheRegionFactory() {
 		return InfinispanRegionFactory.class;
 	}
 
 	@Override
 	protected Class<? extends ConnectionProvider> getConnectionProviderClass() {
 		return DualNodeConnectionProviderImpl.class;
 	}
 
 	@Override
 	protected Class<? extends JtaPlatform> getJtaPlatform() {
 		return DualNodeJtaPlatformImpl.class;
 	}
 
 	@Override
 	protected void prepareTest() throws Exception {
 		super.prepareTest();
 		TERMINATE_ALL_USERS = false;
 	}
 
 	@Override
 	protected void cleanupTest() throws Exception {
 		try {
 			super.cleanupTest();
 		}
 		finally {
 			cleanup();
 			// DualNodeJtaTransactionManagerImpl.cleanupTransactions();
 			// DualNodeJtaTransactionManagerImpl.cleanupTransactionManagers();
 		}
 	}
 
 	@Test
 	public void testPingDb() throws Exception {
 		try {
 			beginTx();
 			sessionFactory()
 					.getCurrentSession()
 					.createQuery( "from " + Customer.class.getName() )
 					.list();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 //         setRollbackOnly();
 //         fail("failed to query DB; exception=" + e);
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 	}
 
 	@Test
 	public void testSingleUser() throws Exception {
 		// setup
 		Customer customer = createCustomer( 0 );
 		final Integer customerId = customer.getId();
 		getCustomerIDs().add( customerId );
 
 		assertNull( "contact exists despite not being added", getFirstContact( customerId ) );
 
 		// check that cache was hit
 		SecondLevelCacheStatistics customerSlcs = sessionFactory()
 				.getStatistics()
 				.getSecondLevelCacheStatistics( Customer.class.getName() );
 		assertEquals( customerSlcs.getPutCount(), 1 );
 		assertEquals( customerSlcs.getElementCountInMemory(), 1 );
 		assertEquals( customerSlcs.getEntries().size(), 1 );
 
 		log.info( "Add contact to customer {0}", customerId );
 		SecondLevelCacheStatistics contactsCollectionSlcs = sessionFactory()
 				.getStatistics()
 				.getSecondLevelCacheStatistics( Customer.class.getName() + ".contacts" );
 		assertEquals( 1, contactsCollectionSlcs.getPutCount() );
 		assertEquals( 1, contactsCollectionSlcs.getElementCountInMemory() );
 		assertEquals( 1, contactsCollectionSlcs.getEntries().size() );
 
 		final Contact contact = addContact( customerId );
 		assertNotNull( "contact returned by addContact is null", contact );
 		assertEquals(
 				"Customer.contacts cache was not invalidated after addContact", 0,
 				contactsCollectionSlcs.getElementCountInMemory()
 		);
 
 		assertNotNull( "Contact missing after successful add call", getFirstContact( customerId ) );
 
 		// read everyone's contacts
 		readEveryonesFirstContact();
 
 		removeContact( customerId );
 		assertNull( "contact still exists after successful remove call", getFirstContact( customerId ) );
 
 	}
 
 	@Test
 	public void testManyUsers() throws Throwable {
 		try {
 			// setup - create users
 			for ( int i = 0; i < USER_COUNT; i++ ) {
 				Customer customer = createCustomer( 0 );
 				getCustomerIDs().add( customer.getId() );
 			}
 			assertEquals( "failed to create enough Customers", USER_COUNT, getCustomerIDs().size() );
 
 			final ExecutorService executor = Executors.newFixedThreadPool( USER_COUNT );
 
 			CyclicBarrier barrier = new CyclicBarrier( USER_COUNT + 1 );
 			List<Future<Void>> futures = new ArrayList<Future<Void>>( USER_COUNT );
 			for ( Integer customerId : getCustomerIDs() ) {
 				Future<Void> future = executor.submit( new UserRunner( customerId, barrier ) );
 				futures.add( future );
 				Thread.sleep( LAUNCH_INTERVAL_MILLIS ); // rampup
 			}
 //         barrier.await(); // wait for all threads to be ready
 			barrier.await( 45, TimeUnit.SECONDS ); // wait for all threads to finish
 			log.info( "All threads finished, let's shutdown the executor and check whether any exceptions were reported" );
 			for ( Future<Void> future : futures ) {
 				future.get();
 			}
 			log.info( "All future gets checked" );
 		}
 		catch (Throwable t) {
 			log.error( "Error running test", t );
 			throw t;
 		}
 	}
 
 	public void cleanup() throws Exception {
 		getCustomerIDs().clear();
 		String deleteContactHQL = "delete from Contact";
 		String deleteCustomerHQL = "delete from Customer";
 		beginTx();
 		try {
 			Session session = sessionFactory().getCurrentSession();
 			session.createQuery( deleteContactHQL ).setFlushMode( FlushMode.AUTO ).executeUpdate();
 			session.createQuery( deleteCustomerHQL ).setFlushMode( FlushMode.AUTO ).executeUpdate();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 	}
 
 	private Customer createCustomer(int nameSuffix) throws Exception {
 		Customer customer = null;
 		beginTx();
 		try {
 			customer = new Customer();
 			customer.setName( "customer_" + nameSuffix );
 			customer.setContacts( new HashSet<Contact>() );
 			sessionFactory().getCurrentSession().persist( customer );
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 		return customer;
 	}
 
 	/**
 	 * read first contact of every Customer participating in this test. this forces concurrent cache
 	 * writes of Customer.contacts Collection cache node
 	 *
 	 * @return who cares
 	 * @throws java.lang.Exception
 	 */
 	private void readEveryonesFirstContact() throws Exception {
 		beginTx();
 		try {
 			for ( Integer customerId : getCustomerIDs() ) {
 				if ( TERMINATE_ALL_USERS ) {
 					setRollbackOnlyTx();
 					return;
 				}
 				Customer customer = (Customer) sessionFactory()
 						.getCurrentSession()
 						.load( Customer.class, customerId );
 				Set<Contact> contacts = customer.getContacts();
 				if ( !contacts.isEmpty() ) {
 					contacts.iterator().next();
 				}
 			}
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 	}
 
    /**
     * -load existing Customer -get customer's contacts; return 1st one
     * 
     * @param customerId
     * @return first Contact or null if customer has none
     */
    private Contact getFirstContact(Integer customerId) throws Exception {
       assert customerId != null;
       Contact firstContact = null;
       beginTx();
       try {
          final Customer customer = (Customer) sessionFactory()
 				 .getCurrentSession()
 				 .load(Customer.class, customerId);
          Set<Contact> contacts = customer.getContacts();
          firstContact = contacts.isEmpty() ? null : contacts.iterator().next();
          if (TERMINATE_ALL_USERS)
             setRollbackOnlyTx();
       } catch (Exception e) {
          setRollbackOnlyTx(e);
       } finally {
          commitOrRollbackTx();
       }
       return firstContact;
    }
 
    /**
     * -load existing Customer -create a new Contact and add to customer's contacts
     *
     * @param customerId
     * @return added Contact
     */
    private Contact addContact(Integer customerId) throws Exception {
       assert customerId != null;
       Contact contact = null;
       beginTx();
       try {
          final Customer customer = (Customer) sessionFactory()
 				 .getCurrentSession()
 				 .load(Customer.class, customerId);
          contact = new Contact();
          contact.setName("contact name");
          contact.setTlf("wtf is tlf?");
          contact.setCustomer(customer);
          customer.getContacts().add(contact);
          // assuming contact is persisted via cascade from customer
          if (TERMINATE_ALL_USERS)
             setRollbackOnlyTx();
       } catch (Exception e) {
          setRollbackOnlyTx(e);
       } finally {
          commitOrRollbackTx();
       }
       return contact;
    }
 
    /**
     * remove existing 'contact' from customer's list of contacts
     *
     * @param customerId
     * @throws IllegalStateException
     *            if customer does not own a contact
     */
    private void removeContact(Integer customerId) throws Exception {
       assert customerId != null;
 
 		beginTx();
 		try {
 			Customer customer = (Customer) sessionFactory()
 					.getCurrentSession()
 					.load( Customer.class, customerId );
 			Set<Contact> contacts = customer.getContacts();
 			if ( contacts.size() != 1 ) {
 				throw new IllegalStateException(
 						"can't remove contact: customer id=" + customerId
 								+ " expected exactly 1 contact, " + "actual count=" + contacts.size()
 				);
 			}
 
 			Contact contact = contacts.iterator().next();
 			contacts.remove( contact );
 			contact.setCustomer( null );
 
 			// explicitly delete Contact because hbm has no 'DELETE_ORPHAN' cascade?
 			// getEnvironment().getSessionFactory().getCurrentSession().delete(contact); //appears to
 			// not be needed
 
 			// assuming contact is persisted via cascade from customer
 
 			if ( TERMINATE_ALL_USERS ) {
 				setRollbackOnlyTx();
 			}
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 	}
 
 	/**
 	 * @return the customerIDs
 	 */
 	public Set<Integer> getCustomerIDs() {
 		return customerIDs;
 	}
 
 	private String statusOfRunnersToString(Set<UserRunner> runners) {
 		assert runners != null;
 
 		StringBuilder sb = new StringBuilder(
 				"TEST CONFIG [userCount=" + USER_COUNT
 						+ ", iterationsPerUser=" + ITERATION_COUNT + ", thinkTimeMillis="
 						+ THINK_TIME_MILLIS + "] " + " STATE of UserRunners: "
 		);
 
 		for ( UserRunner r : runners ) {
 			sb.append( r.toString() + System.getProperty( "line.separator" ) );
 		}
 		return sb.toString();
 	}
 
 	class UserRunner implements Callable<Void> {
 		private final CyclicBarrier barrier;
 		final private Integer customerId;
 		private int completedIterations = 0;
 		private Throwable causeOfFailure;
 
 		public UserRunner(Integer cId, CyclicBarrier barrier) {
 			assert cId != null;
 			this.customerId = cId;
 			this.barrier = barrier;
 		}
 
 		private boolean contactExists() throws Exception {
 			return getFirstContact( customerId ) != null;
 		}
 
 		public Void call() throws Exception {
 			// name this thread for easier log tracing
 			Thread.currentThread().setName( "UserRunnerThread-" + getCustomerId() );
 			log.info( "Wait for all executions paths to be ready to perform calls" );
 			try {
 //            barrier.await();
 				for ( int i = 0; i < ITERATION_COUNT && !TERMINATE_ALL_USERS; i++ ) {
 					contactExists();
 					if ( trace ) {
 						log.trace( "Add contact for customer " + customerId );
 					}
 					addContact( customerId );
 					if ( trace ) {
 						log.trace( "Added contact" );
 					}
 					thinkRandomTime();
 					contactExists();
 					thinkRandomTime();
 					if ( trace ) {
 						log.trace( "Read all customers' first contact" );
 					}
 					// read everyone's contacts
 					readEveryonesFirstContact();
 					if ( trace ) {
 						log.trace( "Read completed" );
 					}
 					thinkRandomTime();
 					if ( trace ) {
 						log.trace( "Remove contact of customer" + customerId );
 					}
 					removeContact( customerId );
 					if ( trace ) {
 						log.trace( "Removed contact" );
 					}
 					contactExists();
 					thinkRandomTime();
 					++completedIterations;
 					if ( log.isTraceEnabled() ) {
 						log.trace( "Iteration completed {0}", completedIterations );
 					}
 				}
 			}
 			catch (Throwable t) {
 				TERMINATE_ALL_USERS = true;
 				log.error( "Error", t );
 				throw new Exception( t );
 				// rollback current transaction if any
 				// really should not happen since above methods all follow begin-commit-rollback pattern
 				// try {
 				// if
 				// (DualNodeJtaTransactionManagerImpl.getInstance(DualNodeTestUtil.LOCAL).getTransaction()
 				// != null) {
 				// DualNodeJtaTransactionManagerImpl.getInstance(DualNodeTestUtil.LOCAL).rollback();
 				// }
 				// } catch (SystemException ex) {
 				// throw new RuntimeException("failed to rollback tx", ex);
 				// }
 			}
 			finally {
 				log.info( "Wait for all execution paths to finish" );
 				barrier.await();
 			}
 			return null;
 		}
 
 		public boolean isSuccess() {
 			return ITERATION_COUNT == getCompletedIterations();
 		}
 
 		public int getCompletedIterations() {
 			return completedIterations;
 		}
 
 		public Throwable getCauseOfFailure() {
 			return causeOfFailure;
 		}
 
 		public Integer getCustomerId() {
 			return customerId;
 		}
 
 		@Override
 		public String toString() {
 			return super.toString() + "[customerId=" + getCustomerId() + " iterationsCompleted="
 					+ getCompletedIterations() + " completedAll=" + isSuccess() + " causeOfFailure="
 					+ (this.causeOfFailure != null ? getStackTrace( causeOfFailure ) : "") + "] ";
 		}
 	}
 
 	public static String getStackTrace(Throwable throwable) {
 		StringWriter sw = new StringWriter();
 		PrintWriter pw = new PrintWriter( sw, true );
 		throwable.printStackTrace( pw );
 		return sw.getBuffer().toString();
 	}
 
 	/**
 	 * sleep between 0 and THINK_TIME_MILLIS.
 	 *
 	 * @throws RuntimeException if sleep is interrupted or TERMINATE_ALL_USERS flag was set to true i n the
 	 * meantime
 	 */
 	private void thinkRandomTime() {
 		try {
 			Thread.sleep( random.nextInt( THINK_TIME_MILLIS ) );
 		}
 		catch (InterruptedException ex) {
 			throw new RuntimeException( "sleep interrupted", ex );
 		}
 
 		if ( TERMINATE_ALL_USERS ) {
 			throw new RuntimeException( "told to terminate (because a UserRunner had failed)" );
 		}
 	}
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/JndiRegionFactoryTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/JndiRegionFactoryTestCase.java
index 81b2f01c41..834aa2599b 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/JndiRegionFactoryTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/JndiRegionFactoryTestCase.java
@@ -1,208 +1,208 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.functional;
 
 import javax.naming.Context;
 import javax.naming.InitialContext;
 import javax.naming.Name;
 import javax.naming.NameNotFoundException;
 import javax.naming.Reference;
 import javax.naming.StringRefAddr;
 import java.util.Properties;
 
 import org.infinispan.Cache;
 import org.infinispan.lifecycle.ComponentStatus;
 import org.infinispan.manager.DefaultCacheManager;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 import org.jboss.util.naming.NonSerializableFactory;
 import org.jnp.server.Main;
 import org.jnp.server.SingletonNamingServer;
 
 import org.hibernate.Session;
-import org.hibernate.cache.RegionFactory;
+import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.JndiInfinispanRegionFactory;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Mappings;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.stat.Statistics;
 
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 
 /**
  * // TODO: Document this
  *
  * @author Galder Zamarre√±o
  * @since // TODO
  */
 public class JndiRegionFactoryTestCase extends SingleNodeTestCase {
 	private static final Log log = LogFactory.getLog( JndiRegionFactoryTestCase.class );
 	private static final String JNDI_NAME = "java:CacheManager";
 	private Main namingMain;
 	private SingletonNamingServer namingServer;
 	private Properties props;
 	private boolean bindToJndi = true;
 	private EmbeddedCacheManager manager;
 
 	@Override
 	protected void cleanupTest() throws Exception {
 		Context ctx = new InitialContext( props );
 		unbind( JNDI_NAME, ctx );
 		namingServer.destroy();
 		namingMain.stop();
 		manager.stop(); // Need to stop cos JNDI region factory does not stop it.
 	}
 
 	@Override
 	protected Class<? extends RegionFactory> getCacheRegionFactory() {
 		return JndiInfinispanRegionFactory.class;
 	}
 
 	@Override
 	public void afterConfigurationBuilt(Mappings mappings, Dialect dialect) {
 		if ( bindToJndi ) {
 			try {
 				// Create an in-memory jndi
 				namingServer = new SingletonNamingServer();
 				namingMain = new Main();
 				namingMain.setInstallGlobalService( true );
 				namingMain.setPort( -1 );
 				namingMain.start();
 				props = new Properties();
 				props.put( "java.naming.factory.initial", "org.jnp.interfaces.NamingContextFactory" );
 				props.put( "java.naming.factory.url.pkgs", "org.jboss.naming:org.jnp.interfaces" );
 
 				manager = new DefaultCacheManager( InfinispanRegionFactory.DEF_INFINISPAN_CONFIG_RESOURCE, false );
 				Context ctx = new InitialContext( props );
 				bind( JNDI_NAME, manager, EmbeddedCacheManager.class, ctx );
 			}
 			catch (Exception e) {
 				throw new RuntimeException( "Failure to set up JNDI", e );
 			}
 		}
 	}
 
 	@Override
 	public void configure(Configuration cfg) {
 		super.configure( cfg );
 		cfg.setProperty( JndiInfinispanRegionFactory.CACHE_MANAGER_RESOURCE_PROP, JNDI_NAME );
 		cfg.setProperty( Environment.JNDI_CLASS, "org.jnp.interfaces.NamingContextFactory" );
 		cfg.setProperty( "java.naming.factory.url.pkgs", "org.jboss.naming:org.jnp.interfaces" );
 	}
 
 	@Test
 	public void testRedeployment() throws Exception {
 		addEntityCheckCache( sessionFactory() );
 		sessionFactory().close();
 		bindToJndi = false;
 
 		SessionFactoryImplementor sessionFactory = (SessionFactoryImplementor) configuration().buildSessionFactory( serviceRegistry() );
 		addEntityCheckCache( sessionFactory );
 		JndiInfinispanRegionFactory regionFactory = (JndiInfinispanRegionFactory) sessionFactory.getSettings().getRegionFactory();
 		Cache cache = regionFactory.getCacheManager().getCache( "org.hibernate.test.cache.infinispan.functional.Item" );
 		assertEquals( ComponentStatus.RUNNING, cache.getStatus() );
 	}
 
 	private void addEntityCheckCache(SessionFactoryImplementor sessionFactory) throws Exception {
 		Item item = new Item( "chris", "Chris's Item" );
 		beginTx();
 		try {
 			Session s = sessionFactory.openSession();
 			s.getTransaction().begin();
 			s.persist( item );
 			s.getTransaction().commit();
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 
 		beginTx();
 		try {
 			Session s =	sessionFactory.openSession();
 			Item found = (Item) s.load( Item.class, item.getId() );
 			Statistics stats = sessionFactory.getStatistics();
 			log.info( stats.toString() );
 			assertEquals( item.getDescription(), found.getDescription() );
 			assertEquals( 0, stats.getSecondLevelCacheMissCount() );
 			assertEquals( 1, stats.getSecondLevelCacheHitCount() );
 			s.delete( found );
 			s.close();
 		}
 		catch (Exception e) {
 			setRollbackOnlyTx( e );
 		}
 		finally {
 			commitOrRollbackTx();
 		}
 
 	}
 
 	/**
 	 * Helper method that binds the a non serializable object to the JNDI tree.
 	 *
 	 * @param jndiName Name under which the object must be bound
 	 * @param who Object to bind in JNDI
 	 * @param classType Class type under which should appear the bound object
 	 * @param ctx Naming context under which we bind the object
 	 * @throws Exception Thrown if a naming exception occurs during binding
 	 */
 	private void bind(String jndiName, Object who, Class<?> classType, Context ctx) throws Exception {
 		// Ah ! This service isn't serializable, so we use a helper class
 		NonSerializableFactory.bind( jndiName, who );
 		Name n = ctx.getNameParser( "" ).parse( jndiName );
 		while ( n.size() > 1 ) {
 			String ctxName = n.get( 0 );
 			try {
 				ctx = (Context) ctx.lookup( ctxName );
 			}
 			catch (NameNotFoundException e) {
 				log.debug( "creating Subcontext " + ctxName );
 				ctx = ctx.createSubcontext( ctxName );
 			}
 			n = n.getSuffix( 1 );
 		}
 
 		// The helper class NonSerializableFactory uses address type nns, we go on to
 		// use the helper class to bind the service object in JNDI
 		StringRefAddr addr = new StringRefAddr( "nns", jndiName );
 		Reference ref = new Reference( classType.getName(), addr, NonSerializableFactory.class.getName(), null );
 		ctx.rebind( n.get( 0 ), ref );
 	}
 
 	private void unbind(String jndiName, Context ctx) throws Exception {
 		NonSerializableFactory.unbind( jndiName );
 //      ctx.unbind(jndiName);
 	}
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/SingleNodeTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/SingleNodeTestCase.java
index fa75e9c3a4..f848d940c0 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/SingleNodeTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/SingleNodeTestCase.java
@@ -1,153 +1,153 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.functional;
 
 import javax.transaction.Status;
 import javax.transaction.TransactionManager;
 
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import org.hibernate.cache.RegionFactory;
+import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.transaction.internal.jta.CMTTransactionFactory;
 import org.hibernate.engine.transaction.spi.TransactionFactory;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.service.jta.platform.spi.JtaPlatform;
 
 import org.junit.Before;
 
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.test.cache.infinispan.tm.JtaPlatformImpl;
 
 /**
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public abstract class SingleNodeTestCase extends BaseCoreFunctionalTestCase {
 	private static final Log log = LogFactory.getLog( SingleNodeTestCase.class );
 	private TransactionManager tm;
 
 	@Before
 	public void prepare() {
 		tm = getTransactionManager();
 	}
 
 	protected TransactionManager getTransactionManager() {
 		try {
 			Class<? extends JtaPlatform> jtaPlatformClass = getJtaPlatform();
 			if ( jtaPlatformClass == null ) {
 				return null;
 			}
 			else {
 				return jtaPlatformClass.newInstance().retrieveTransactionManager();
 			}
 		}
 		catch (Exception e) {
 			log.error( "Error", e );
 			throw new RuntimeException( e );
 		}
 	}
 
 	@Override
 	public String[] getMappings() {
 		return new String[] {
 				"cache/infinispan/functional/Item.hbm.xml",
 				"cache/infinispan/functional/Customer.hbm.xml",
 				"cache/infinispan/functional/Contact.hbm.xml"
 		};
 	}
 
 	@Override
 	public String getCacheConcurrencyStrategy() {
 		return "transactional";
 	}
 
 	protected Class<? extends RegionFactory> getCacheRegionFactory() {
 		return InfinispanRegionFactory.class;
 	}
 
 	protected Class<? extends TransactionFactory> getTransactionFactoryClass() {
 		return CMTTransactionFactory.class;
 	}
 
 	protected Class<? extends ConnectionProvider> getConnectionProviderClass() {
 		return org.hibernate.test.cache.infinispan.tm.XaConnectionProvider.class;
 	}
 
 	protected Class<? extends JtaPlatform> getJtaPlatform() {
 		return JtaPlatformImpl.class;
 	}
 
 	protected boolean getUseQueryCache() {
 		return true;
 	}
 
 	@Override
 	public void configure(Configuration cfg) {
 		super.configure( cfg );
 		cfg.setProperty( Environment.USE_SECOND_LEVEL_CACHE, "true" );
 		cfg.setProperty( Environment.GENERATE_STATISTICS, "true" );
 		cfg.setProperty( Environment.USE_QUERY_CACHE, String.valueOf( getUseQueryCache() ) );
 		cfg.setProperty( Environment.CACHE_REGION_FACTORY, getCacheRegionFactory().getName() );
 
 		if ( getJtaPlatform() != null ) {
 			cfg.getProperties().put( AvailableSettings.JTA_PLATFORM, getJtaPlatform() );
 		}
 		cfg.setProperty( Environment.TRANSACTION_STRATEGY, getTransactionFactoryClass().getName() );
 		cfg.setProperty( Environment.CONNECTION_PROVIDER, getConnectionProviderClass().getName() );
 	}
 
 	protected void beginTx() throws Exception {
 		tm.begin();
 	}
 
 	protected void setRollbackOnlyTx() throws Exception {
 		tm.setRollbackOnly();
 	}
 
 	protected void setRollbackOnlyTx(Exception e) throws Exception {
 		log.error( "Error", e );
 		tm.setRollbackOnly();
 		throw e;
 	}
 
 	protected void setRollbackOnlyTxExpected(Exception e) throws Exception {
 		log.debug( "Expected behaivour", e );
 		tm.setRollbackOnly();
 	}
 
 	protected void commitOrRollbackTx() throws Exception {
 		if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 			tm.commit();
 		}
 		else {
 			tm.rollback();
 		}
 	}
 
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/bulk/BulkOperationsTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/bulk/BulkOperationsTestCase.java
index 5ccfdbd725..b9a87c7668 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/bulk/BulkOperationsTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/bulk/BulkOperationsTestCase.java
@@ -1,421 +1,421 @@
 /*
  * JBoss, Home of Professional Open Source.
  * Copyright 2009, Red Hat, Inc. and/or it's affiliates, and individual contributors
  * as indicated by the @author tags. See the copyright.txt file in the
  * distribution for a full listing of individual contributors.
  *
  * This is free software; you can redistribute it and/or modify it
  * under the terms of the GNU Lesser General Public License as
  * published by the Free Software Foundation; either version 2.1 of
  * the License, or (at your option) any later version.
  *
  * This software is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * Lesser General Public License for more details.
  *
  * You should have received a copy of the GNU Lesser General Public
  * License along with this software; if not, write to the Free
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
 package org.hibernate.test.cache.infinispan.functional.bulk;
 
 import javax.transaction.Status;
 import javax.transaction.TransactionManager;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 
 import org.hibernate.FlushMode;
 import org.hibernate.Session;
-import org.hibernate.cache.RegionFactory;
+import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.transaction.internal.jta.CMTTransactionFactory;
 import org.hibernate.engine.transaction.spi.TransactionFactory;
 import org.hibernate.service.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.service.jta.platform.spi.JtaPlatform;
 import org.hibernate.stat.SecondLevelCacheStatistics;
 
 import org.junit.Test;
 
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.test.cache.infinispan.functional.Contact;
 import org.hibernate.test.cache.infinispan.functional.Customer;
 import org.hibernate.test.cache.infinispan.tm.JtaPlatformImpl;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNull;
 
 /**
  * BulkOperationsTestCase.
  *
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public class BulkOperationsTestCase extends BaseCoreFunctionalTestCase {
 	private TransactionManager tm;
 
 	@Override
 	public String[] getMappings() {
 		return new String[] {
 				"cache/infinispan/functional/Contact.hbm.xml",
 				"cache/infinispan/functional/Customer.hbm.xml"
 		};
 	}
 
 	@Override
 	public String getCacheConcurrencyStrategy() {
 		return "transactional";
 	}
 
 	protected Class<? extends RegionFactory> getCacheRegionFactory() {
 		return InfinispanRegionFactory.class;
 	}
 
 	protected Class<? extends TransactionFactory> getTransactionFactoryClass() {
 		return CMTTransactionFactory.class;
 	}
 
 	protected Class<? extends ConnectionProvider> getConnectionProviderClass() {
 		return org.hibernate.test.cache.infinispan.tm.XaConnectionProvider.class;
 	}
 
 	protected JtaPlatform getJtaPlatform() {
 		return new JtaPlatformImpl();
 	}
 
 	@Override
 	public void configure(Configuration cfg) {
 		super.configure( cfg );
 		cfg.setProperty( Environment.USE_SECOND_LEVEL_CACHE, "true" );
 		cfg.setProperty( Environment.GENERATE_STATISTICS, "true" );
 		cfg.setProperty( Environment.USE_QUERY_CACHE, "false" );
 		cfg.setProperty( Environment.CACHE_REGION_FACTORY, getCacheRegionFactory().getName() );
 		cfg.setProperty( Environment.TRANSACTION_STRATEGY, getTransactionFactoryClass().getName() );
 		cfg.getProperties().put( AvailableSettings.JTA_PLATFORM, getJtaPlatform() );
 		cfg.setProperty( Environment.CONNECTION_PROVIDER, getConnectionProviderClass().getName() );
 	}
 
 	@Test
 	public void testBulkOperations() throws Throwable {
 		boolean cleanedUp = false;
 		try {
 			tm = getJtaPlatform().retrieveTransactionManager();
 
 			createContacts();
 
 			List<Integer> rhContacts = getContactsByCustomer( "Red Hat" );
 			assertNotNull( "Red Hat contacts exist", rhContacts );
 			assertEquals( "Created expected number of Red Hat contacts", 10, rhContacts.size() );
 
 			SecondLevelCacheStatistics contactSlcs = sessionFactory()
 					.getStatistics()
 					.getSecondLevelCacheStatistics( Contact.class.getName() );
 			assertEquals( 20, contactSlcs.getElementCountInMemory() );
 
 			assertEquals( "Deleted all Red Hat contacts", 10, deleteContacts() );
 			assertEquals( 0, contactSlcs.getElementCountInMemory() );
 
 			List<Integer> jbContacts = getContactsByCustomer( "JBoss" );
 			assertNotNull( "JBoss contacts exist", jbContacts );
 			assertEquals( "JBoss contacts remain", 10, jbContacts.size() );
 
 			for ( Integer id : rhContacts ) {
 				assertNull( "Red Hat contact " + id + " cannot be retrieved", getContact( id ) );
 			}
 			rhContacts = getContactsByCustomer( "Red Hat" );
 			if ( rhContacts != null ) {
 				assertEquals( "No Red Hat contacts remain", 0, rhContacts.size() );
 			}
 
 			updateContacts( "Kabir", "Updated" );
 			assertEquals( 0, contactSlcs.getElementCountInMemory() );
 			for ( Integer id : jbContacts ) {
 				Contact contact = getContact( id );
 				assertNotNull( "JBoss contact " + id + " exists", contact );
 				String expected = ("Kabir".equals( contact.getName() )) ? "Updated" : "2222";
 				assertEquals( "JBoss contact " + id + " has correct TLF", expected, contact.getTlf() );
 			}
 
 			List<Integer> updated = getContactsByTLF( "Updated" );
 			assertNotNull( "Got updated contacts", updated );
 			assertEquals( "Updated contacts", 5, updated.size() );
 
 			updateContactsWithOneManual( "Kabir", "UpdatedAgain" );
 			assertEquals( contactSlcs.getElementCountInMemory(), 0 );
 			for ( Integer id : jbContacts ) {
 				Contact contact = getContact( id );
 				assertNotNull( "JBoss contact " + id + " exists", contact );
 				String expected = ("Kabir".equals( contact.getName() )) ? "UpdatedAgain" : "2222";
 				assertEquals( "JBoss contact " + id + " has correct TLF", expected, contact.getTlf() );
 			}
 
 			updated = getContactsByTLF( "UpdatedAgain" );
 			assertNotNull( "Got updated contacts", updated );
 			assertEquals( "Updated contacts", 5, updated.size() );
 		}
 		catch (Throwable t) {
 			cleanedUp = true;
 			cleanup( true );
 			throw t;
 		}
 		finally {
 			// cleanup the db so we can run this test multiple times w/o restarting the cluster
 			if ( !cleanedUp ) {
 				cleanup( false );
 			}
 		}
 	}
 
 	public void createContacts() throws Exception {
 		tm.begin();
 		try {
 			for ( int i = 0; i < 10; i++ ) {
 				createCustomer( i );
 			}
 		}
 		catch (Exception e) {
 			tm.setRollbackOnly();
 			throw e;
 		}
 		finally {
 			if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 				tm.commit();
 			}
 			else {
 				tm.rollback();
 			}
 		}
 	}
 
 	public int deleteContacts() throws Exception {
 		String deleteHQL = "delete Contact where customer in ";
 		deleteHQL += " (select customer FROM Customer as customer ";
 		deleteHQL += " where customer.name = :cName)";
 
 		tm.begin();
 		try {
 			Session session = sessionFactory().getCurrentSession();
 			int rowsAffected = session.createQuery( deleteHQL ).setFlushMode( FlushMode.AUTO )
 					.setParameter( "cName", "Red Hat" ).executeUpdate();
 			tm.commit();
 			return rowsAffected;
 		}
 		catch (Exception e) {
 			tm.setRollbackOnly();
 			throw e;
 		}
 		finally {
 			if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 				tm.commit();
 			}
 			else {
 				try {
 					tm.rollback();
 				}
 				catch (Exception ee) {
 					// ignored
 				}
 			}
 		}
 	}
 
 	@SuppressWarnings( {"unchecked"})
 	public List<Integer> getContactsByCustomer(String customerName) throws Exception {
 		String selectHQL = "select contact.id from Contact contact";
 		selectHQL += " where contact.customer.name = :cName";
 
 		tm.begin();
 		try {
 
 			Session session = sessionFactory().getCurrentSession();
 			return session.createQuery( selectHQL )
 					.setFlushMode( FlushMode.AUTO )
 					.setParameter( "cName", customerName )
 					.list();
 		}
 		catch (Exception e) {
 			tm.setRollbackOnly();
 			throw e;
 		}
 		finally {
 			if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 				tm.commit();
 			}
 			else {
 				tm.rollback();
 			}
 		}
 	}
 
 	@SuppressWarnings( {"unchecked"})
 	public List<Integer> getContactsByTLF(String tlf) throws Exception {
 		String selectHQL = "select contact.id from Contact contact";
 		selectHQL += " where contact.tlf = :cTLF";
 
 		tm.begin();
 		try {
 			Session session = sessionFactory().getCurrentSession();
 			return session.createQuery( selectHQL )
 					.setFlushMode( FlushMode.AUTO )
 					.setParameter( "cTLF", tlf )
 					.list();
 		}
 		catch (Exception e) {
 			tm.setRollbackOnly();
 			throw e;
 		}
 		finally {
 			if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 				tm.commit();
 			}
 			else {
 				tm.rollback();
 			}
 		}
 	}
 
 	public int updateContacts(String name, String newTLF) throws Exception {
 		String updateHQL = "update Contact set tlf = :cNewTLF where name = :cName";
 		tm.begin();
 		try {
 			Session session = sessionFactory().getCurrentSession();
 			return session.createQuery( updateHQL )
 					.setFlushMode( FlushMode.AUTO )
 					.setParameter( "cNewTLF", newTLF )
 					.setParameter( "cName", name )
 					.executeUpdate();
 		}
 		catch (Exception e) {
 			tm.setRollbackOnly();
 			throw e;
 		}
 		finally {
 			if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 				tm.commit();
 			}
 			else {
 				tm.rollback();
 			}
 		}
 	}
 
 	public int updateContactsWithOneManual(String name, String newTLF) throws Exception {
 		String queryHQL = "from Contact c where c.name = :cName";
 		String updateHQL = "update Contact set tlf = :cNewTLF where name = :cName";
 		tm.begin();
 		try {
 			Session session = sessionFactory().getCurrentSession();
 			@SuppressWarnings("unchecked")
 			List<Contact> list = session.createQuery( queryHQL ).setParameter( "cName", name ).list();
 			list.get( 0 ).setTlf( newTLF );
 			return session.createQuery( updateHQL )
 					.setFlushMode( FlushMode.AUTO )
 					.setParameter( "cNewTLF", newTLF )
 					.setParameter( "cName", name )
 					.executeUpdate();
 		}
 		catch (Exception e) {
 			tm.setRollbackOnly();
 			throw e;
 		}
 		finally {
 			if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 				tm.commit();
 			}
 			else {
 				tm.rollback();
 			}
 		}
 	}
 
 	public Contact getContact(Integer id) throws Exception {
 		tm.begin();
 		try {
 			Session session = sessionFactory().getCurrentSession();
 			return (Contact) session.get( Contact.class, id );
 		}
 		catch (Exception e) {
 			tm.setRollbackOnly();
 			throw e;
 		}
 		finally {
 			if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 				tm.commit();
 			}
 			else {
 				tm.rollback();
 			}
 		}
 	}
 
 	public void cleanup(boolean ignore) throws Exception {
 		String deleteContactHQL = "delete from Contact";
 		String deleteCustomerHQL = "delete from Customer";
 		tm.begin();
 		try {
 			Session session = sessionFactory().getCurrentSession();
 			session.createQuery( deleteContactHQL ).setFlushMode( FlushMode.AUTO ).executeUpdate();
 			session.createQuery( deleteCustomerHQL ).setFlushMode( FlushMode.AUTO ).executeUpdate();
 		}
 		catch (Exception e) {
 			tm.setRollbackOnly();
 			throw e;
 		}
 		finally {
 			if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 				tm.commit();
 			}
 			else {
 				if ( !ignore ) {
 					try {
 						tm.rollback();
 					}
 					catch (Exception ee) {
 						// ignored
 					}
 				}
 			}
 		}
 	}
 
 	private Customer createCustomer(int id) throws Exception {
 		System.out.println( "CREATE CUSTOMER " + id );
 		try {
 			Customer customer = new Customer();
 			customer.setName( (id % 2 == 0) ? "JBoss" : "Red Hat" );
 			Set<Contact> contacts = new HashSet<Contact>();
 
 			Contact kabir = new Contact();
 			kabir.setCustomer( customer );
 			kabir.setName( "Kabir" );
 			kabir.setTlf( "1111" );
 			contacts.add( kabir );
 
 			Contact bill = new Contact();
 			bill.setCustomer( customer );
 			bill.setName( "Bill" );
 			bill.setTlf( "2222" );
 			contacts.add( bill );
 
 			customer.setContacts( contacts );
 
 			Session s = openSession();
 			s.getTransaction().begin();
 			s.persist( customer );
 			s.getTransaction().commit();
 			s.close();
 
 			return customer;
 		}
 		finally {
 			System.out.println( "CREATE CUSTOMER " + id + " -  END" );
 		}
 	}
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/classloader/IsolatedClassLoaderTest.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/classloader/IsolatedClassLoaderTest.java
index 2ecb70707f..6cec847704 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/classloader/IsolatedClassLoaderTest.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/classloader/IsolatedClassLoaderTest.java
@@ -1,351 +1,351 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.functional.classloader;
 
 import javax.transaction.TransactionManager;
 
 import org.infinispan.Cache;
 import org.infinispan.manager.CacheContainer;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.jboss.logging.Logger;
 
 import org.hibernate.SessionFactory;
-import org.hibernate.cache.StandardQueryCache;
+import org.hibernate.cache.internal.StandardQueryCache;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cfg.Configuration;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.fail;
 
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
 import org.hibernate.test.cache.infinispan.functional.cluster.ClusterAwareRegionFactory;
 import org.hibernate.test.cache.infinispan.functional.cluster.DualNodeJtaTransactionManagerImpl;
 import org.hibernate.test.cache.infinispan.functional.cluster.DualNodeTestCase;
 
 /**
  * Tests entity and query caching when class of objects being cached are not visible to Infinispan's classloader. Also serves as a
  * general integration test.
  * <p/>
  * This test stores an object (AccountHolder) that isn't visible to the Infinispan classloader in the cache in two places: 1) As
  * part of the value tuple in an Account entity 2) As part of the FQN in a query cache entry (see query in
  * ClassLoaderTestDAO.getBranch())
  *
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public class IsolatedClassLoaderTest extends DualNodeTestCase {
 	private static final Logger log = Logger.getLogger( IsolatedClassLoaderTest.class );
 
 	protected static final long SLEEP_TIME = 300L;
 
 	private Cache localQueryCache;
 	private CacheAccessListener localQueryListener;
 
 	private Cache remoteQueryCache;
 	private CacheAccessListener remoteQueryListener;
 
    private static ClassLoader originalTCCL;
 
 	@BeforeClass
 	public static void prepareClassLoader() {
       final String packageName = IsolatedClassLoaderTest.class.getPackage().getName();
       final String[] classes = new String[] { packageName + ".Account", packageName + ".AccountHolder" };
       originalTCCL = Thread.currentThread().getContextClassLoader();
       // Most likely, it will point to system classloader
       ClassLoader parent = originalTCCL == null ? IsolatedClassLoaderTest.class.getClassLoader() : originalTCCL;
 
       // First, create a classloader where classes won't be found
       ClassLoader selectedTCCL = new SelectedClassnameClassLoader(null, null, classes, parent);
 
       // Now, make the class visible to the test driver
       SelectedClassnameClassLoader visible = new SelectedClassnameClassLoader(classes, null, null, selectedTCCL);
       Thread.currentThread().setContextClassLoader(visible);
 	}
 
 	@AfterClass
 	public static void resetClassLoader() {
 		ClusterAwareRegionFactory.clearCacheManagers();
 		DualNodeJtaTransactionManagerImpl.cleanupTransactions();
 		DualNodeJtaTransactionManagerImpl.cleanupTransactionManagers();
 		Thread.currentThread().setContextClassLoader( originalTCCL );
 	}
 
 	@Override
 	public String[] getMappings() {
 		return new String[] {"cache/infinispan/functional/classloader/Account.hbm.xml"};
 	}
 
 	@Override
 	protected void standardConfigure(Configuration cfg) {
 		super.standardConfigure( cfg );
 		cfg.setProperty( InfinispanRegionFactory.QUERY_CACHE_RESOURCE_PROP, "replicated-query" );
 		cfg.setProperty( "hibernate.cache.infinispan.AccountRegion.cfg", "replicated-query" );
 	}
 
 	@Override
 	protected void cleanupTransactionManagement() {
 		// Don't clean up the managers, just the transactions
 		// Managers are still needed by the long-lived caches
 		DualNodeJtaTransactionManagerImpl.cleanupTransactions();
 	}
 
 	@Override
 	protected void cleanupTest() throws Exception {
 		try {
          // Clear the local account cache
          sessionFactory().getCache().evictEntityRegion(Account.class.getName());
 			if ( localQueryCache != null && localQueryListener != null ) {
 				localQueryCache.removeListener( localQueryListener );
 			}
 			if ( remoteQueryCache != null && remoteQueryListener != null ) {
 				remoteQueryCache.removeListener( remoteQueryListener );
 			}
 		}
 		finally {
 			super.cleanupTest();
 		}
 	}
 
 	@Test
 	public void testIsolatedSetup() throws Exception {
 		// Bind a listener to the "local" cache
 		// Our region factory makes its CacheManager available to us
 		CacheContainer localManager = ClusterAwareRegionFactory.getCacheManager( DualNodeTestCase.LOCAL );
 		Cache localReplicatedCache = localManager.getCache( "replicated-entity" );
 
 		// Bind a listener to the "remote" cache
 		CacheContainer remoteManager = ClusterAwareRegionFactory.getCacheManager( DualNodeTestCase.REMOTE );
 		Cache remoteReplicatedCache = remoteManager.getCache( "replicated-entity" );
 
 		ClassLoader cl = Thread.currentThread().getContextClassLoader();
 		Thread.currentThread().setContextClassLoader( cl.getParent() );
 		log.info( "TCCL is " + cl.getParent() );
 
 		Account acct = new Account();
 		acct.setAccountHolder( new AccountHolder() );
 
 		try {
 			localReplicatedCache.put( "isolated1", acct );
 			// With lazy deserialization, retrieval in remote forces class resolution
 			remoteReplicatedCache.get( "isolated1" );
 			fail( "Should not have succeeded in putting acct -- classloader not isolated" );
 		}
 		catch (Exception e) {
 			if ( e.getCause() instanceof ClassNotFoundException ) {
 				log.info( "Caught exception as desired", e );
 			}
 			else {
 				throw new IllegalStateException( "Unexpected exception", e );
 			}
 		}
 
 		Thread.currentThread().setContextClassLoader( cl );
 		log.info( "TCCL is " + cl );
 		localReplicatedCache.put( "isolated2", acct );
 		assertEquals( acct.getClass().getName(), remoteReplicatedCache.get( "isolated2" ).getClass().getName() );
 	}
 
 	@Test
 	public void testClassLoaderHandlingNamedQueryRegion() throws Exception {
       rebuildSessionFactory();
 		queryTest( true );
 	}
 
 	@Test
 	public void testClassLoaderHandlingStandardQueryCache() throws Exception {
       rebuildSessionFactory();
 		queryTest( false );
 	}
 
 	protected void queryTest(boolean useNamedRegion) throws Exception {
 		// Bind a listener to the "local" cache
 		// Our region factory makes its CacheManager available to us
 		EmbeddedCacheManager localManager = ClusterAwareRegionFactory.getCacheManager( DualNodeTestCase.LOCAL );
 		// Bind a listener to the "remote" cache
 		EmbeddedCacheManager remoteManager = ClusterAwareRegionFactory.getCacheManager( DualNodeTestCase.REMOTE );
 		String cacheName;
 		if ( useNamedRegion ) {
 			cacheName = "AccountRegion"; // As defined by ClassLoaderTestDAO via calls to query.setCacheRegion
 			// Define cache configurations for region early to avoid ending up with local caches for this region
 			localManager.defineConfiguration(
 					cacheName, "replicated-query", new org.infinispan.config.Configuration()
 			);
 			remoteManager.defineConfiguration(
 					cacheName, "replicated-query", new org.infinispan.config.Configuration()
 			);
 		}
 		else {
 			cacheName = "replicated-query";
 		}
 
 		localQueryCache = localManager.getCache( cacheName );
 		localQueryListener = new CacheAccessListener();
 		localQueryCache.addListener( localQueryListener );
 
 		TransactionManager localTM = DualNodeJtaTransactionManagerImpl.getInstance( DualNodeTestCase.LOCAL );
 
 		remoteQueryCache = remoteManager.getCache( cacheName );
 		remoteQueryListener = new CacheAccessListener();
 		remoteQueryCache.addListener( remoteQueryListener );
 
 		TransactionManager remoteTM = DualNodeJtaTransactionManagerImpl.getInstance( DualNodeTestCase.REMOTE );
 
 		SessionFactory localFactory = sessionFactory();
 		SessionFactory remoteFactory = secondNodeEnvironment().getSessionFactory();
 
 		ClassLoaderTestDAO dao0 = new ClassLoaderTestDAO( localFactory, localTM );
 		ClassLoaderTestDAO dao1 = new ClassLoaderTestDAO( remoteFactory, remoteTM );
 
 		// Initial ops on node 0
 		setupEntities( dao0 );
 
 		String branch = "63088";
 		// Query on post code count
 		assertEquals( branch + " has correct # of accounts", 6, dao0.getCountForBranch( branch, useNamedRegion ) );
 
 		assertEquals( "Query cache used", 1, localQueryListener.getSawRegionModificationCount() );
 		localQueryListener.clearSawRegionModification();
 
 //      log.info("First query (get count for branch + " + branch + " ) on node0 done, contents of local query cache are: " + TestingUtil.printCache(localQueryCache));
 
 		// Sleep a bit to allow async repl to happen
 		sleep( SLEEP_TIME );
 
 		assertEquals( "Query cache used", 1, remoteQueryListener.getSawRegionModificationCount() );
 		remoteQueryListener.clearSawRegionModification();
 
 		// Do query again from node 1
 		log.info( "Repeat first query (get count for branch + " + branch + " ) on remote node" );
 		assertEquals( "63088 has correct # of accounts", 6, dao1.getCountForBranch( branch, useNamedRegion ) );
 		assertEquals( "Query cache used", 1, remoteQueryListener.getSawRegionModificationCount() );
 		remoteQueryListener.clearSawRegionModification();
 
 		sleep( SLEEP_TIME );
 
 		assertEquals( "Query cache used", 1, localQueryListener.getSawRegionModificationCount() );
 		localQueryListener.clearSawRegionModification();
 
 		log.info( "First query on node 1 done" );
 
 		// Sleep a bit to allow async repl to happen
 		sleep( SLEEP_TIME );
 
 		// Do some more queries on node 0
 		log.info( "Do query Smith's branch" );
 		assertEquals( "Correct branch for Smith", "94536", dao0.getBranch( dao0.getSmith(), useNamedRegion ) );
 		log.info( "Do query Jone's balance" );
 		assertEquals( "Correct high balances for Jones", 40, dao0.getTotalBalance( dao0.getJones(), useNamedRegion ) );
 
 		assertEquals( "Query cache used", 2, localQueryListener.getSawRegionModificationCount() );
 		localQueryListener.clearSawRegionModification();
 //      // Clear the access state
 //      localQueryListener.getSawRegionAccess("???");
 
 		log.info( "Second set of queries on node0 done" );
 
 		// Sleep a bit to allow async repl to happen
 		sleep( SLEEP_TIME );
 
 		// Check if the previous queries replicated
 		assertEquals( "Query cache remotely modified", 2, remoteQueryListener.getSawRegionModificationCount() );
 		remoteQueryListener.clearSawRegionModification();
 
 		log.info( "Repeat second set of queries on node1" );
 
 		// Do queries again from node 1
 		log.info( "Again query Smith's branch" );
 		assertEquals( "Correct branch for Smith", "94536", dao1.getBranch( dao1.getSmith(), useNamedRegion ) );
 		log.info( "Again query Jone's balance" );
 		assertEquals( "Correct high balances for Jones", 40, dao1.getTotalBalance( dao1.getJones(), useNamedRegion ) );
 
 		// Should be no change; query was already there
 		assertEquals( "Query cache modified", 0, remoteQueryListener.getSawRegionModificationCount() );
 		assertEquals( "Query cache accessed", 2, remoteQueryListener.getSawRegionAccessCount() );
 		remoteQueryListener.clearSawRegionAccess();
 
 		log.info( "Second set of queries on node1 done" );
 
 		// allow async to propagate
 		sleep( SLEEP_TIME );
 
 		// Modify underlying data on node 1
 		modifyEntities( dao1 );
 
 		// allow async timestamp change to propagate
 		sleep( SLEEP_TIME );
 
 		// Confirm query results are correct on node 0
 		assertEquals( "63088 has correct # of accounts", 7, dao0.getCountForBranch( "63088", useNamedRegion ) );
 		assertEquals( "Correct branch for Smith", "63088", dao0.getBranch( dao0.getSmith(), useNamedRegion ) );
 		assertEquals( "Correct high balances for Jones", 50, dao0.getTotalBalance( dao0.getJones(), useNamedRegion ) );
 		log.info( "Third set of queries on node0 done" );
 	}
 
 	protected void setupEntities(ClassLoaderTestDAO dao) throws Exception {
 		dao.cleanup();
 
 		dao.createAccount( dao.getSmith(), new Integer( 1001 ), new Integer( 5 ), "94536" );
 		dao.createAccount( dao.getSmith(), new Integer( 1002 ), new Integer( 15 ), "94536" );
 		dao.createAccount( dao.getSmith(), new Integer( 1003 ), new Integer( 20 ), "94536" );
 
 		dao.createAccount( dao.getJones(), new Integer( 2001 ), new Integer( 5 ), "63088" );
 		dao.createAccount( dao.getJones(), new Integer( 2002 ), new Integer( 15 ), "63088" );
 		dao.createAccount( dao.getJones(), new Integer( 2003 ), new Integer( 20 ), "63088" );
 
 		dao.createAccount( dao.getBarney(), new Integer( 3001 ), new Integer( 5 ), "63088" );
 		dao.createAccount( dao.getBarney(), new Integer( 3002 ), new Integer( 15 ), "63088" );
 		dao.createAccount( dao.getBarney(), new Integer( 3003 ), new Integer( 20 ), "63088" );
 
 		log.info( "Standard entities created" );
 	}
 
 	protected void resetRegionUsageState(CacheAccessListener localListener, CacheAccessListener remoteListener) {
 		String stdName = StandardQueryCache.class.getName();
 		String acctName = Account.class.getName();
 
 		localListener.getSawRegionModification( stdName );
 		localListener.getSawRegionModification( acctName );
 
 		localListener.getSawRegionAccess( stdName );
 		localListener.getSawRegionAccess( acctName );
 
 		remoteListener.getSawRegionModification( stdName );
 		remoteListener.getSawRegionModification( acctName );
 
 		remoteListener.getSawRegionAccess( stdName );
 		remoteListener.getSawRegionAccess( acctName );
 
 		log.info( "Region usage state cleared" );
 	}
 
 	protected void modifyEntities(ClassLoaderTestDAO dao) throws Exception {
 		dao.updateAccountBranch( 1001, "63088" );
 		dao.updateAccountBalance( 2001, 15 );
 
 		log.info( "Entities modified" );
 	}
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/ClusterAwareRegionFactory.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/ClusterAwareRegionFactory.java
index 7a413523a6..2f035d1746 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/ClusterAwareRegionFactory.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/ClusterAwareRegionFactory.java
@@ -1,127 +1,127 @@
 /*
  * JBoss, Home of Professional Open Source.
  * Copyright 2009, Red Hat, Inc. and/or it's affiliates, and individual contributors
  * as indicated by the @author tags. See the copyright.txt file in the
  * distribution for a full listing of individual contributors.
  *
  * This is free software; you can redistribute it and/or modify it
  * under the terms of the GNU Lesser General Public License as
  * published by the Free Software Foundation; either version 2.1 of
  * the License, or (at your option) any later version.
  *
  * This software is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * Lesser General Public License for more details.
  *
  * You should have received a copy of the GNU Lesser General Public
  * License along with this software; if not, write to the Free
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
 package org.hibernate.test.cache.infinispan.functional.cluster;
 import java.util.Hashtable;
 import java.util.Properties;
-import org.hibernate.cache.CacheDataDescription;
+import org.hibernate.cache.spi.CacheDataDescription;
 import org.hibernate.cache.CacheException;
-import org.hibernate.cache.CollectionRegion;
-import org.hibernate.cache.EntityRegion;
-import org.hibernate.cache.QueryResultsRegion;
-import org.hibernate.cache.RegionFactory;
-import org.hibernate.cache.TimestampsRegion;
-import org.hibernate.cache.access.AccessType;
+import org.hibernate.cache.spi.CollectionRegion;
+import org.hibernate.cache.spi.EntityRegion;
+import org.hibernate.cache.spi.QueryResultsRegion;
+import org.hibernate.cache.spi.RegionFactory;
+import org.hibernate.cache.spi.TimestampsRegion;
+import org.hibernate.cache.spi.access.AccessType;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cfg.Settings;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 /**
  * ClusterAwareRegionFactory.
  * 
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public class ClusterAwareRegionFactory implements RegionFactory {
    
    private static final Log log = LogFactory.getLog(ClusterAwareRegionFactory.class);
    private static final Hashtable<String, EmbeddedCacheManager> cacheManagers = new Hashtable<String, EmbeddedCacheManager>();
 
    private final InfinispanRegionFactory delegate = new InfinispanRegionFactory();
    private String cacheManagerName;
    private boolean locallyAdded;
    
    public ClusterAwareRegionFactory(Properties props) {
    }
    
    public static EmbeddedCacheManager getCacheManager(String name) {
       return cacheManagers.get(name);
    }
    
    public static void addCacheManager(String name, EmbeddedCacheManager manager) {
       cacheManagers.put(name, manager);
    }
    
    public static void clearCacheManagers() {
       for (EmbeddedCacheManager manager : cacheManagers.values()) {
          try {
             manager.stop();
          } catch (Exception e) {
             log.error("Exception cleaning up CacheManager " + manager, e);
          }
       }
       cacheManagers.clear();      
    }
 
    public void start(Settings settings, Properties properties) throws CacheException {
       cacheManagerName = properties.getProperty(DualNodeTestCase.NODE_ID_PROP);
       
       EmbeddedCacheManager existing = getCacheManager(cacheManagerName);
       locallyAdded = (existing == null);
       
       if (locallyAdded) {
          delegate.start(settings, properties);
          cacheManagers.put(cacheManagerName, delegate.getCacheManager());
       } else {
          delegate.setCacheManager(existing);
       }      
    }
 
    public void stop() {
       if (locallyAdded) cacheManagers.remove(cacheManagerName);     
       delegate.stop();
    }
 
    public CollectionRegion buildCollectionRegion(String regionName, Properties properties,
             CacheDataDescription metadata) throws CacheException {
       return delegate.buildCollectionRegion(regionName, properties, metadata);
    }
 
    public EntityRegion buildEntityRegion(String regionName, Properties properties,
             CacheDataDescription metadata) throws CacheException {
       return delegate.buildEntityRegion(regionName, properties, metadata);
    }
 
    public QueryResultsRegion buildQueryResultsRegion(String regionName, Properties properties)
             throws CacheException {
       return delegate.buildQueryResultsRegion(regionName, properties);
    }
 
    public TimestampsRegion buildTimestampsRegion(String regionName, Properties properties)
             throws CacheException {
       return delegate.buildTimestampsRegion(regionName, properties);
    }
 
    public boolean isMinimalPutsEnabledByDefault() {
       return delegate.isMinimalPutsEnabledByDefault();
    }
 
 	@Override
 	public AccessType getDefaultAccessType() {
 		return AccessType.TRANSACTIONAL;
 	}
 
 	public long nextTimestamp() {
       return delegate.nextTimestamp();
    }
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/EntityCollectionInvalidationTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/EntityCollectionInvalidationTestCase.java
index cf20eebede..c798f334be 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/EntityCollectionInvalidationTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/EntityCollectionInvalidationTestCase.java
@@ -1,396 +1,396 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.functional.cluster;
 
 import javax.transaction.TransactionManager;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Set;
 
 import org.infinispan.Cache;
 import org.infinispan.manager.CacheContainer;
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryVisited;
 import org.infinispan.notifications.cachelistener.event.CacheEntryVisitedEvent;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 import org.jboss.util.collection.ConcurrentSet;
 
 import org.hibernate.Session;
 import org.hibernate.SessionFactory;
-import org.hibernate.cache.CacheKey;
+import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.cache.infinispan.util.CacheHelper;
 
 import org.junit.Test;
 
 import org.hibernate.test.cache.infinispan.functional.Contact;
 import org.hibernate.test.cache.infinispan.functional.Customer;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 
 /**
  * EntityCollectionInvalidationTestCase.
  *
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public class EntityCollectionInvalidationTestCase extends DualNodeTestCase {
 	private static final Log log = LogFactory.getLog( EntityCollectionInvalidationTestCase.class );
 
 	private static final long SLEEP_TIME = 50l;
 	private static final Integer CUSTOMER_ID = new Integer( 1 );
 
 	static int test = 0;
 
 	@Test
 	public void testAll() throws Exception {
 		log.info( "*** testAll()" );
 
 		// Bind a listener to the "local" cache
 		// Our region factory makes its CacheManager available to us
 		CacheContainer localManager = ClusterAwareRegionFactory.getCacheManager( DualNodeTestCase.LOCAL );
 		// Cache localCache = localManager.getCache("entity");
 		Cache localCustomerCache = localManager.getCache( Customer.class.getName() );
 		Cache localContactCache = localManager.getCache( Contact.class.getName() );
 		Cache localCollectionCache = localManager.getCache( Customer.class.getName() + ".contacts" );
 		MyListener localListener = new MyListener( "local" );
 		localCustomerCache.addListener( localListener );
 		localContactCache.addListener( localListener );
 		localCollectionCache.addListener( localListener );
 		TransactionManager localTM = DualNodeJtaTransactionManagerImpl.getInstance( DualNodeTestCase.LOCAL );
 
 		// Bind a listener to the "remote" cache
 		CacheContainer remoteManager = ClusterAwareRegionFactory.getCacheManager( DualNodeTestCase.REMOTE );
 		Cache remoteCustomerCache = remoteManager.getCache( Customer.class.getName() );
 		Cache remoteContactCache = remoteManager.getCache( Contact.class.getName() );
 		Cache remoteCollectionCache = remoteManager.getCache( Customer.class.getName() + ".contacts" );
 		MyListener remoteListener = new MyListener( "remote" );
 		remoteCustomerCache.addListener( remoteListener );
 		remoteContactCache.addListener( remoteListener );
 		remoteCollectionCache.addListener( remoteListener );
 		TransactionManager remoteTM = DualNodeJtaTransactionManagerImpl.getInstance( DualNodeTestCase.REMOTE );
 
 		SessionFactory localFactory = sessionFactory();
 		SessionFactory remoteFactory = secondNodeEnvironment().getSessionFactory();
 
 		try {
 			assertTrue( remoteListener.isEmpty() );
 			assertTrue( localListener.isEmpty() );
 
 			log.debug( "Create node 0" );
 			IdContainer ids = createCustomer( localFactory, localTM );
 
 			assertTrue( remoteListener.isEmpty() );
 			assertTrue( localListener.isEmpty() );
 
 			// Sleep a bit to let async commit propagate. Really just to
 			// help keep the logs organized for debugging any issues
 			sleep( SLEEP_TIME );
 
 			log.debug( "Find node 0" );
 			// This actually brings the collection into the cache
 			getCustomer( ids.customerId, localFactory, localTM );
 
 			sleep( SLEEP_TIME );
 
 			// Now the collection is in the cache so, the 2nd "get"
 			// should read everything from the cache
 			log.debug( "Find(2) node 0" );
 			localListener.clear();
 			getCustomer( ids.customerId, localFactory, localTM );
 
 			// Check the read came from the cache
 			log.debug( "Check cache 0" );
 			assertLoadedFromCache( localListener, ids.customerId, ids.contactIds );
 
 			log.debug( "Find node 1" );
 			// This actually brings the collection into the cache since invalidation is in use
 			getCustomer( ids.customerId, remoteFactory, remoteTM );
 
 			// Now the collection is in the cache so, the 2nd "get"
 			// should read everything from the cache
 			log.debug( "Find(2) node 1" );
 			remoteListener.clear();
 			getCustomer( ids.customerId, remoteFactory, remoteTM );
 
 			// Check the read came from the cache
 			log.debug( "Check cache 1" );
 			assertLoadedFromCache( remoteListener, ids.customerId, ids.contactIds );
 
 			// Modify customer in remote
 			remoteListener.clear();
 			ids = modifyCustomer( ids.customerId, remoteFactory, remoteTM );
 			sleep( 250 );
 			assertLoadedFromCache( remoteListener, ids.customerId, ids.contactIds );
 
 			// After modification, local cache should have been invalidated and hence should be empty
 			assertEquals( 0, getValidKeyCount( localCollectionCache.keySet() ) );
 			assertEquals( 0, getValidKeyCount( localCustomerCache.keySet() ) );
 		}
 		catch (Exception e) {
 			log.error( "Error", e );
 			throw e;
 		}
 		finally {
 			// cleanup the db
 			log.debug( "Cleaning up" );
 			cleanup( localFactory, localTM );
 		}
 	}
 
 	private IdContainer createCustomer(SessionFactory sessionFactory, TransactionManager tm)
 			throws Exception {
 		log.debug( "CREATE CUSTOMER" );
 
 		tm.begin();
 
 		try {
 			Session session = sessionFactory.getCurrentSession();
 			Customer customer = new Customer();
 			customer.setName( "JBoss" );
 			Set<Contact> contacts = new HashSet<Contact>();
 
 			Contact kabir = new Contact();
 			kabir.setCustomer( customer );
 			kabir.setName( "Kabir" );
 			kabir.setTlf( "1111" );
 			contacts.add( kabir );
 
 			Contact bill = new Contact();
 			bill.setCustomer( customer );
 			bill.setName( "Bill" );
 			bill.setTlf( "2222" );
 			contacts.add( bill );
 
 			customer.setContacts( contacts );
 
 			session.save( customer );
 			tm.commit();
 
 			IdContainer ids = new IdContainer();
 			ids.customerId = customer.getId();
 			Set contactIds = new HashSet();
 			contactIds.add( kabir.getId() );
 			contactIds.add( bill.getId() );
 			ids.contactIds = contactIds;
 
 			return ids;
 		}
 		catch (Exception e) {
 			log.error( "Caught exception creating customer", e );
 			try {
 				tm.rollback();
 			}
 			catch (Exception e1) {
 				log.error( "Exception rolling back txn", e1 );
 			}
 			throw e;
 		}
 		finally {
 			log.debug( "CREATE CUSTOMER -  END" );
 		}
 	}
 
 	private Customer getCustomer(Integer id, SessionFactory sessionFactory, TransactionManager tm) throws Exception {
 		log.debug( "Find customer with id=" + id );
 		tm.begin();
 		try {
 			Session session = sessionFactory.getCurrentSession();
 			Customer customer = doGetCustomer( id, session, tm );
 			tm.commit();
 			return customer;
 		}
 		catch (Exception e) {
 			try {
 				tm.rollback();
 			}
 			catch (Exception e1) {
 				log.error( "Exception rolling back txn", e1 );
 			}
 			throw e;
 		}
 		finally {
 			log.debug( "Find customer ended." );
 		}
 	}
 
 	private Customer doGetCustomer(Integer id, Session session, TransactionManager tm) throws Exception {
 		Customer customer = (Customer) session.get( Customer.class, id );
 		// Access all the contacts
 		for ( Iterator it = customer.getContacts().iterator(); it.hasNext(); ) {
 			((Contact) it.next()).getName();
 		}
 		return customer;
 	}
 
 	private IdContainer modifyCustomer(Integer id, SessionFactory sessionFactory, TransactionManager tm)
 			throws Exception {
 		log.debug( "Modify customer with id=" + id );
 		tm.begin();
 		try {
 			Session session = sessionFactory.getCurrentSession();
 			IdContainer ids = new IdContainer();
 			Set contactIds = new HashSet();
 			Customer customer = doGetCustomer( id, session, tm );
 			customer.setName( "NewJBoss" );
 			ids.customerId = customer.getId();
 			Set<Contact> contacts = customer.getContacts();
 			for ( Contact c : contacts ) {
 				contactIds.add( c.getId() );
 			}
 			Contact contact = contacts.iterator().next();
 			contacts.remove( contact );
 			contactIds.remove( contact.getId() );
 			ids.contactIds = contactIds;
 			contact.setCustomer( null );
 
 			session.save( customer );
 			tm.commit();
 			return ids;
 		}
 		catch (Exception e) {
 			try {
 				tm.rollback();
 			}
 			catch (Exception e1) {
 				log.error( "Exception rolling back txn", e1 );
 			}
 			throw e;
 		}
 		finally {
 			log.debug( "Find customer ended." );
 		}
 	}
 
 	private void cleanup(SessionFactory sessionFactory, TransactionManager tm) throws Exception {
 		tm.begin();
 		try {
 			Session session = sessionFactory.getCurrentSession();
 			Customer c = (Customer) session.get( Customer.class, CUSTOMER_ID );
 			if ( c != null ) {
 				Set contacts = c.getContacts();
 				for ( Iterator it = contacts.iterator(); it.hasNext(); ) {
 					session.delete( it.next() );
 				}
 				c.setContacts( null );
 				session.delete( c );
 			}
 
 			tm.commit();
 		}
 		catch (Exception e) {
 			try {
 				tm.rollback();
 			}
 			catch (Exception e1) {
 				log.error( "Exception rolling back txn", e1 );
 			}
 			log.error( "Caught exception in cleanup", e );
 		}
 	}
 
 	private void assertLoadedFromCache(MyListener listener, Integer custId, Set contactIds) {
 		assertTrue(
 				"Customer#" + custId + " was in cache", listener.visited.contains(
 				"Customer#"
 						+ custId
 		)
 		);
 		for ( Iterator it = contactIds.iterator(); it.hasNext(); ) {
 			Integer contactId = (Integer) it.next();
 			assertTrue(
 					"Contact#" + contactId + " was in cache", listener.visited.contains(
 					"Contact#"
 							+ contactId
 			)
 			);
 			assertTrue(
 					"Contact#" + contactId + " was in cache", listener.visited.contains(
 					"Contact#"
 							+ contactId
 			)
 			);
 		}
 		assertTrue(
 				"Customer.contacts" + custId + " was in cache", listener.visited
 				.contains( "Customer.contacts#" + custId )
 		);
 	}
 
 	protected int getValidKeyCount(Set keys) {
 		int result = 0;
 		for ( Object key : keys ) {
 			if ( !(CacheHelper.isEvictAllNotification( key )) ) {
 				result++;
 			}
 		}
 		return result;
 	}
 
 	@Listener
 	public static class MyListener {
 		private static final Log log = LogFactory.getLog( MyListener.class );
 		private Set<String> visited = new ConcurrentSet<String>();
 		private final String name;
 
 		public MyListener(String name) {
 			this.name = name;
 		}
 
 		public void clear() {
 			visited.clear();
 		}
 
 		public boolean isEmpty() {
 			return visited.isEmpty();
 		}
 
 		@CacheEntryVisited
 		public void nodeVisited(CacheEntryVisitedEvent event) {
 			log.debug( event.toString() );
 			if ( !event.isPre() ) {
 				CacheKey cacheKey = (CacheKey) event.getKey();
 				Integer primKey = (Integer) cacheKey.getKey();
 				String key = (String) cacheKey.getEntityOrRoleName() + '#' + primKey;
 				log.debug( "MyListener[" + name + "] - Visiting key " + key );
 				// String name = fqn.toString();
 				String token = ".functional.";
 				int index = key.indexOf( token );
 				if ( index > -1 ) {
 					index += token.length();
 					key = key.substring( index );
 					log.debug( "MyListener[" + name + "] - recording visit to " + key );
 					visited.add( key );
 				}
 			}
 		}
 	}
 
 	private class IdContainer {
 		Integer customerId;
 		Set<Integer> contactIds;
 	}
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/query/QueryRegionImplTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/query/QueryRegionImplTestCase.java
index 9defaf1502..cc3954a01d 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/query/QueryRegionImplTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/query/QueryRegionImplTestCase.java
@@ -1,335 +1,334 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. ¬†All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.query;
 
 import java.util.Properties;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryVisited;
 import org.infinispan.notifications.cachelistener.event.CacheEntryVisitedEvent;
 import org.infinispan.transaction.tm.BatchModeTransactionManager;
 import org.infinispan.util.concurrent.IsolationLevel;
 import org.jboss.logging.Logger;
 
-import org.hibernate.cache.CacheDataDescription;
-import org.hibernate.cache.QueryResultsRegion;
-import org.hibernate.cache.Region;
-import org.hibernate.cache.StandardQueryCache;
+import org.hibernate.cache.spi.CacheDataDescription;
+import org.hibernate.cache.spi.QueryResultsRegion;
+import org.hibernate.cache.spi.Region;
+import org.hibernate.cache.internal.StandardQueryCache;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.cache.infinispan.util.CacheAdapterImpl;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.service.ServiceRegistryBuilder;
-import org.hibernate.service.internal.BasicServiceRegistryImpl;
 
 import junit.framework.AssertionFailedError;
 
 import org.hibernate.test.cache.infinispan.AbstractGeneralDataRegionTestCase;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 
 /**
  * Tests of QueryResultRegionImpl.
  *
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public class QueryRegionImplTestCase extends AbstractGeneralDataRegionTestCase {
 	private static final Logger log = Logger.getLogger( QueryRegionImplTestCase.class );
 
 	@Override
 	protected Region createRegion(
 			InfinispanRegionFactory regionFactory,
 			String regionName,
 			Properties properties,
 			CacheDataDescription cdd) {
 		return regionFactory.buildQueryResultsRegion( regionName, properties );
 	}
 
 	@Override
 	protected String getStandardRegionName(String regionPrefix) {
 		return regionPrefix + "/" + StandardQueryCache.class.getName();
 	}
 
 	@Override
 	protected CacheAdapter getInfinispanCache(InfinispanRegionFactory regionFactory) {
 		return CacheAdapterImpl.newInstance( regionFactory.getCacheManager().getCache( "local-query" ) );
 	}
 
 	@Override
 	protected Configuration createConfiguration() {
 		return CacheTestUtil.buildCustomQueryCacheConfiguration( "test", "replicated-query" );
 	}
 
 	private void putDoesNotBlockGetTest() throws Exception {
 		Configuration cfg = createConfiguration();
 		InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
 				new ServiceRegistryBuilder( cfg.getProperties() ).buildServiceRegistry(),
 				cfg,
 				getCacheTestSupport()
 		);
 
 		// Sleep a bit to avoid concurrent FLUSH problem
 		avoidConcurrentFlush();
 
 		final QueryResultsRegion region = regionFactory.buildQueryResultsRegion(
 				getStandardRegionName( REGION_PREFIX ),
 				cfg.getProperties()
 		);
 
 		region.put( KEY, VALUE1 );
 		assertEquals( VALUE1, region.get( KEY ) );
 
 		final CountDownLatch readerLatch = new CountDownLatch( 1 );
 		final CountDownLatch writerLatch = new CountDownLatch( 1 );
 		final CountDownLatch completionLatch = new CountDownLatch( 1 );
 		final ExceptionHolder holder = new ExceptionHolder();
 
 		Thread reader = new Thread() {
 			@Override
 			public void run() {
 				try {
 					BatchModeTransactionManager.getInstance().begin();
 					log.debug( "Transaction began, get value for key" );
 					assertTrue( VALUE2.equals( region.get( KEY ) ) == false );
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (AssertionFailedError e) {
 					holder.a1 = e;
 					rollback();
 				}
 				catch (Exception e) {
 					holder.e1 = e;
 					rollback();
 				}
 				finally {
 					readerLatch.countDown();
 				}
 			}
 		};
 
 		Thread writer = new Thread() {
 			@Override
 			public void run() {
 				try {
 					BatchModeTransactionManager.getInstance().begin();
 					log.debug( "Put value2" );
 					region.put( KEY, VALUE2 );
 					log.debug( "Put finished for value2, await writer latch" );
 					writerLatch.await();
 					log.debug( "Writer latch finished" );
 					BatchModeTransactionManager.getInstance().commit();
 					log.debug( "Transaction committed" );
 				}
 				catch (Exception e) {
 					holder.e2 = e;
 					rollback();
 				}
 				finally {
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		reader.setDaemon( true );
 		writer.setDaemon( true );
 
 		writer.start();
 		assertFalse( "Writer is blocking", completionLatch.await( 100, TimeUnit.MILLISECONDS ) );
 
 		// Start the reader
 		reader.start();
 		assertTrue( "Reader finished promptly", readerLatch.await( 1000000000, TimeUnit.MILLISECONDS ) );
 
 		writerLatch.countDown();
 		assertTrue( "Reader finished promptly", completionLatch.await( 100, TimeUnit.MILLISECONDS ) );
 
 		assertEquals( VALUE2, region.get( KEY ) );
 
 		if ( holder.a1 != null ) {
 			throw holder.a1;
 		}
 		else if ( holder.a2 != null ) {
 			throw holder.a2;
 		}
 
 		assertEquals( "writer saw no exceptions", null, holder.e1 );
 		assertEquals( "reader saw no exceptions", null, holder.e2 );
 	}
 
 	public void testGetDoesNotBlockPut() throws Exception {
 		getDoesNotBlockPutTest();
 	}
 
 	private void getDoesNotBlockPutTest() throws Exception {
 		Configuration cfg = createConfiguration();
 		InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
 				new ServiceRegistryBuilder( cfg.getProperties() ).buildServiceRegistry(),
 				cfg,
 				getCacheTestSupport()
 		);
 
 		// Sleep a bit to avoid concurrent FLUSH problem
 		avoidConcurrentFlush();
 
 		final QueryResultsRegion region = regionFactory.buildQueryResultsRegion(
 				getStandardRegionName( REGION_PREFIX ),
 				cfg.getProperties()
 		);
 
 		region.put( KEY, VALUE1 );
 		assertEquals( VALUE1, region.get( KEY ) );
 
 		// final Fqn rootFqn = getRegionFqn(getStandardRegionName(REGION_PREFIX), REGION_PREFIX);
 		final CacheAdapter jbc = getInfinispanCache( regionFactory );
 
 		final CountDownLatch blockerLatch = new CountDownLatch( 1 );
 		final CountDownLatch writerLatch = new CountDownLatch( 1 );
 		final CountDownLatch completionLatch = new CountDownLatch( 1 );
 		final ExceptionHolder holder = new ExceptionHolder();
 
 		Thread blocker = new Thread() {
 
 			@Override
 			public void run() {
 				// Fqn toBlock = new Fqn(rootFqn, KEY);
 				GetBlocker blocker = new GetBlocker( blockerLatch, KEY );
 				try {
 					jbc.addListener( blocker );
 
 					BatchModeTransactionManager.getInstance().begin();
 					region.get( KEY );
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
 					holder.e1 = e;
 					rollback();
 				}
 				finally {
 					jbc.removeListener( blocker );
 				}
 			}
 		};
 
 		Thread writer = new Thread() {
 
 			@Override
 			public void run() {
 				try {
 					writerLatch.await();
 
 					BatchModeTransactionManager.getInstance().begin();
 					region.put( KEY, VALUE2 );
 					BatchModeTransactionManager.getInstance().commit();
 				}
 				catch (Exception e) {
 					holder.e2 = e;
 					rollback();
 				}
 				finally {
 					completionLatch.countDown();
 				}
 			}
 		};
 
 		blocker.setDaemon( true );
 		writer.setDaemon( true );
 
 		boolean unblocked = false;
 		try {
 			blocker.start();
 			writer.start();
 
 			assertFalse( "Blocker is blocking", completionLatch.await( 100, TimeUnit.MILLISECONDS ) );
 			// Start the writer
 			writerLatch.countDown();
 			assertTrue( "Writer finished promptly", completionLatch.await( 100, TimeUnit.MILLISECONDS ) );
 
 			blockerLatch.countDown();
 			unblocked = true;
 
 			if ( IsolationLevel.REPEATABLE_READ.equals( jbc.getConfiguration().getIsolationLevel() ) ) {
 				assertEquals( VALUE1, region.get( KEY ) );
 			}
 			else {
 				assertEquals( VALUE2, region.get( KEY ) );
 			}
 
 			if ( holder.a1 != null ) {
 				throw holder.a1;
 			}
 			else if ( holder.a2 != null ) {
 				throw holder.a2;
 			}
 
 			assertEquals( "blocker saw no exceptions", null, holder.e1 );
 			assertEquals( "writer saw no exceptions", null, holder.e2 );
 		}
 		finally {
 			if ( !unblocked ) {
 				blockerLatch.countDown();
 			}
 		}
 	}
 
 	@Listener
 	public class GetBlocker {
 
 		private CountDownLatch latch;
 		// private Fqn fqn;
 		private Object key;
 
 		GetBlocker(
 				CountDownLatch latch,
 				Object key
 		) {
 			this.latch = latch;
 			this.key = key;
 		}
 
 		@CacheEntryVisited
 		public void nodeVisisted(CacheEntryVisitedEvent event) {
 			if ( event.isPre() && event.getKey().equals( key ) ) {
 				try {
 					latch.await();
 				}
 				catch (InterruptedException e) {
 					log.error( "Interrupted waiting for latch", e );
 				}
 			}
 		}
 	}
 
 	private class ExceptionHolder {
 		Exception e1;
 		Exception e2;
 		AssertionFailedError a1;
 		AssertionFailedError a2;
 	}
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/timestamp/TimestampsRegionImplTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/timestamp/TimestampsRegionImplTestCase.java
index 9a412ffa16..164d998dda 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/timestamp/TimestampsRegionImplTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/timestamp/TimestampsRegionImplTestCase.java
@@ -1,213 +1,212 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. ¬†All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.timestamp;
 
 import java.util.Properties;
 
 import org.infinispan.AdvancedCache;
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryActivated;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryCreated;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryEvicted;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryInvalidated;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryLoaded;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryModified;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryPassivated;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryRemoved;
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryVisited;
 import org.infinispan.notifications.cachelistener.event.Event;
 
-import org.hibernate.cache.CacheDataDescription;
-import org.hibernate.cache.Region;
-import org.hibernate.cache.UpdateTimestampsCache;
+import org.hibernate.cache.spi.CacheDataDescription;
+import org.hibernate.cache.spi.Region;
+import org.hibernate.cache.spi.UpdateTimestampsCache;
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.infinispan.impl.ClassLoaderAwareCache;
 import org.hibernate.cache.infinispan.timestamp.TimestampsRegionImpl;
 import org.hibernate.cache.infinispan.util.CacheAdapter;
 import org.hibernate.cache.infinispan.util.CacheAdapterImpl;
 import org.hibernate.cache.infinispan.util.FlagAdapter;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.service.ServiceRegistryBuilder;
-import org.hibernate.service.internal.BasicServiceRegistryImpl;
 
 import org.hibernate.test.cache.infinispan.AbstractGeneralDataRegionTestCase;
 import org.hibernate.test.cache.infinispan.functional.classloader.Account;
 import org.hibernate.test.cache.infinispan.functional.classloader.AccountHolder;
 import org.hibernate.test.cache.infinispan.functional.classloader.SelectedClassnameClassLoader;
 import org.hibernate.test.cache.infinispan.util.CacheTestUtil;
 
 /**
  * Tests of TimestampsRegionImpl.
  * 
  * @author Galder Zamarre√±o
  * @since 3.5
  */
 public class TimestampsRegionImplTestCase extends AbstractGeneralDataRegionTestCase {
 
     @Override
    protected String getStandardRegionName(String regionPrefix) {
       return regionPrefix + "/" + UpdateTimestampsCache.class.getName();
    }
 
    @Override
    protected Region createRegion(InfinispanRegionFactory regionFactory, String regionName, Properties properties, CacheDataDescription cdd) {
       return regionFactory.buildTimestampsRegion(regionName, properties);
    }
 
    @Override
    protected CacheAdapter getInfinispanCache(InfinispanRegionFactory regionFactory) {
       return CacheAdapterImpl.newInstance(regionFactory.getCacheManager().getCache("timestamps"));
    }
 
    public void testClearTimestampsRegionInIsolated() throws Exception {
       Configuration cfg = createConfiguration();
       InfinispanRegionFactory regionFactory = CacheTestUtil.startRegionFactory(
 				new ServiceRegistryBuilder( cfg.getProperties() ).buildServiceRegistry(),
 			  cfg,
 			  getCacheTestSupport()
 	  );
       // Sleep a bit to avoid concurrent FLUSH problem
       avoidConcurrentFlush();
 
       Configuration cfg2 = createConfiguration();
       InfinispanRegionFactory regionFactory2 = CacheTestUtil.startRegionFactory(
 				new ServiceRegistryBuilder( cfg.getProperties() ).buildServiceRegistry(),
 			  cfg2,
 			  getCacheTestSupport()
 	  );
       // Sleep a bit to avoid concurrent FLUSH problem
       avoidConcurrentFlush();
 
       TimestampsRegionImpl region = (TimestampsRegionImpl) regionFactory.buildTimestampsRegion(getStandardRegionName(REGION_PREFIX), cfg.getProperties());
       TimestampsRegionImpl region2 = (TimestampsRegionImpl) regionFactory2.buildTimestampsRegion(getStandardRegionName(REGION_PREFIX), cfg2.getProperties());
 //      QueryResultsRegion region2 = regionFactory2.buildQueryResultsRegion(getStandardRegionName(REGION_PREFIX), cfg2.getProperties());
 
 //      ClassLoader cl = Thread.currentThread().getContextClassLoader();
 //      Thread.currentThread().setContextClassLoader(cl.getParent());
 //      log.info("TCCL is " + cl.getParent());
 
       Account acct = new Account();
       acct.setAccountHolder(new AccountHolder());
       region.getCacheAdapter().withFlags(FlagAdapter.FORCE_SYNCHRONOUS).put(acct, "boo");
 
 //      region.put(acct, "boo");
 //
 //      region.evictAll();
 
 //      Account acct = new Account();
 //      acct.setAccountHolder(new AccountHolder());
 
 
 
    }
 
    @Override
    protected Configuration createConfiguration() {
       return CacheTestUtil.buildConfiguration("test", MockInfinispanRegionFactory.class, false, true);
    }
 
    public static class MockInfinispanRegionFactory extends InfinispanRegionFactory {
 
       public MockInfinispanRegionFactory() {
       }
 
       public MockInfinispanRegionFactory(Properties props) {
          super(props);
       }
 
 //      @Override
 //      protected TimestampsRegionImpl createTimestampsRegion(CacheAdapter cacheAdapter, String regionName) {
 //         return new MockTimestampsRegionImpl(cacheAdapter, regionName, getTransactionManager(), this);
 //      }
 
       @Override
       protected ClassLoaderAwareCache createCacheWrapper(AdvancedCache cache) {
          return new ClassLoaderAwareCache(cache, Thread.currentThread().getContextClassLoader()) {
             @Override
             public void addListener(Object listener) {
                super.addListener(new MockClassLoaderAwareListener(listener, this));
             }
          };
       }
 
       //      @Override
 //      protected EmbeddedCacheManager createCacheManager(Properties properties) throws CacheException {
 //         try {
 //            EmbeddedCacheManager manager = new DefaultCacheManager(InfinispanRegionFactory.DEF_INFINISPAN_CONFIG_RESOURCE);
 //            org.infinispan.config.Configuration ispnCfg = new org.infinispan.config.Configuration();
 //            ispnCfg.setCacheMode(org.infinispan.config.Configuration.CacheMode.REPL_SYNC);
 //            manager.defineConfiguration("timestamps", ispnCfg);
 //            return manager;
 //         } catch (IOException e) {
 //            throw new CacheException("Unable to create default cache manager", e);
 //         }
 //      }
 
       @Listener      
       public static class MockClassLoaderAwareListener extends ClassLoaderAwareCache.ClassLoaderAwareListener {
          MockClassLoaderAwareListener(Object listener, ClassLoaderAwareCache cache) {
             super(listener, cache);
          }
 
          @CacheEntryActivated
          @CacheEntryCreated
          @CacheEntryEvicted
          @CacheEntryInvalidated
          @CacheEntryLoaded
          @CacheEntryModified
          @CacheEntryPassivated
          @CacheEntryRemoved
          @CacheEntryVisited
          public void event(Event event) throws Throwable {
             ClassLoader cl = Thread.currentThread().getContextClassLoader();
             String notFoundPackage = "org.hibernate.test.cache.infinispan.functional.classloader";
             String[] notFoundClasses = { notFoundPackage + ".Account", notFoundPackage + ".AccountHolder" };
             SelectedClassnameClassLoader visible = new SelectedClassnameClassLoader(null, null, notFoundClasses, cl);
             Thread.currentThread().setContextClassLoader(visible);
             super.event(event);
             Thread.currentThread().setContextClassLoader(cl);            
          }
       }
    }
 
 //   @Listener
 //   public static class MockTimestampsRegionImpl extends TimestampsRegionImpl {
 //
 //      public MockTimestampsRegionImpl(CacheAdapter cacheAdapter, String name, TransactionManager transactionManager, RegionFactory factory) {
 //         super(cacheAdapter, name, transactionManager, factory);
 //      }
 //
 //      @CacheEntryModified
 //      public void nodeModified(CacheEntryModifiedEvent event) {
 ////         ClassLoader cl = Thread.currentThread().getContextClassLoader();
 ////         String notFoundPackage = "org.hibernate.test.cache.infinispan.functional.classloader";
 ////         String[] notFoundClasses = { notFoundPackage + ".Account", notFoundPackage + ".AccountHolder" };
 ////         SelectedClassnameClassLoader visible = new SelectedClassnameClassLoader(null, null, notFoundClasses, cl);
 ////         Thread.currentThread().setContextClassLoader(visible);
 //         super.nodeModified(event);
 ////         Thread.currentThread().setContextClassLoader(cl);
 //      }
 //   }
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/util/CacheTestSupport.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/util/CacheTestSupport.java
index 2634a62629..64f5577349 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/util/CacheTestSupport.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/util/CacheTestSupport.java
@@ -1,146 +1,146 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007, Red Hat, Inc. and/or it's affiliates or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. ¬†All third-party contributions are
  * distributed under license by Red Hat, Inc. and/or it's affiliates.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.util;
 
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Set;
 
 import org.infinispan.Cache;
 import org.jboss.logging.Logger;
 
-import org.hibernate.cache.RegionFactory;
+import org.hibernate.cache.spi.RegionFactory;
 
 /**
  * Support class for tracking and cleaning up objects used in tests.
  *
  * @author <a href="brian.stansberry@jboss.com">Brian Stansberry</a>
  */
 public class CacheTestSupport {
 	private static final Logger log = Logger.getLogger( CacheTestSupport.class );
 
 	private static final String PREFER_IPV4STACK = "java.net.preferIPv4Stack";
 
     private Set<Cache> caches = new HashSet();
     private Set<RegionFactory> factories = new HashSet();
     private Exception exception;
     private String preferIPv4Stack;
 
     public void registerCache(Cache cache) {
         caches.add(cache);
     }
 
     public void registerFactory(RegionFactory factory) {
         factories.add(factory);
     }
 
     public void unregisterCache(Cache cache) {
         caches.remove( cache );
     }
 
     public void unregisterFactory(RegionFactory factory) {
         factories.remove( factory );
     }
 
     public void setUp() throws Exception {
 
         // Try to ensure we use IPv4; otherwise cluster formation is very slow
         preferIPv4Stack = System.getProperty(PREFER_IPV4STACK);
         System.setProperty(PREFER_IPV4STACK, "true");
 
         cleanUp();
         throwStoredException();
     }
 
     public void tearDown() throws Exception {
 
         if (preferIPv4Stack == null)
             System.clearProperty(PREFER_IPV4STACK);
         else
             System.setProperty(PREFER_IPV4STACK, preferIPv4Stack);
 
         cleanUp();
         throwStoredException();
     }
 
     public void avoidConcurrentFlush() {
        // JG 2.6.1 has a problem where calling flush more than once too quickly
        // can result in several second delays
        sleep( 100 );
     }
 
     private void sleep(long ms) {
         try {
             Thread.sleep(ms);
         }
         catch (InterruptedException e) {
             log.warn("Interrupted during sleep", e);
         }
     }
 
     private void cleanUp() {
         for (Iterator it = factories.iterator(); it.hasNext(); ) {
             try {
                 ((RegionFactory) it.next()).stop();
             }
             catch (Exception e) {
                 storeException(e);
             }
             finally {
                 it.remove();
             }
         }
         factories.clear();
 
         for (Iterator it = caches.iterator(); it.hasNext(); ) {
             try {
                 Cache cache = (Cache) it.next();
                 cache.stop();
             }
             catch (Exception e) {
                 storeException(e);
             }
             finally {
                 it.remove();
             }
             avoidConcurrentFlush();
         }
         caches.clear();
     }
 
     private void storeException(Exception e) {
         if (this.exception == null) {
             this.exception = e;
         }
     }
 
     private void throwStoredException() throws Exception {
         if (exception != null) {
             Exception toThrow = exception;
             exception = null;
             throw toThrow;
         }
     }
 
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/BaseCoreFunctionalTestCase.java b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/BaseCoreFunctionalTestCase.java
index 03f16bb5df..c8669e3ab4 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/BaseCoreFunctionalTestCase.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/BaseCoreFunctionalTestCase.java
@@ -1,413 +1,413 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.junit4;
 
 import java.io.InputStream;
 import java.sql.Blob;
 import java.sql.Clob;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.Session;
-import org.hibernate.cache.HashtableCacheProvider;
+import org.hibernate.cache.internal.HashtableCacheProvider;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Mappings;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.SessionFactoryImplementor;
 import org.hibernate.engine.SessionImplementor;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.jdbc.AbstractReturningWork;
 import org.hibernate.jdbc.Work;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.SimpleValue;
 import org.hibernate.service.internal.BasicServiceRegistryImpl;
 
 import org.junit.After;
 import org.junit.Before;
 
 import org.hibernate.testing.AfterClassOnce;
 import org.hibernate.testing.BeforeClassOnce;
 import org.hibernate.testing.OnExpectedFailure;
 import org.hibernate.testing.OnFailure;
 import org.hibernate.testing.SkipLog;
 
 import static org.junit.Assert.fail;
 
 /**
  * Applies functional testing logic for core Hibernate testing on top of {@link BaseUnitTestCase}
  *
  * @author Steve Ebersole
  */
 public abstract class BaseCoreFunctionalTestCase extends BaseUnitTestCase {
 	public static final String VALIDATE_DATA_CLEANUP = "hibernate.test.validateDataCleanup";
 	public static final Dialect DIALECT = Dialect.getDialect();
 
 	private Configuration configuration;
 	private BasicServiceRegistryImpl serviceRegistry;
 	private SessionFactoryImplementor sessionFactory;
 
 	private Session session;
 
 	protected static Dialect getDialect() {
 		return DIALECT;
 	}
 
 	protected Configuration configuration() {
 		return configuration;
 	}
 
 	protected BasicServiceRegistryImpl serviceRegistry() {
 		return serviceRegistry;
 	}
 
 	protected SessionFactoryImplementor sessionFactory() {
 		return sessionFactory;
 	}
 
 	protected Session openSession() throws HibernateException {
 		session = sessionFactory().openSession();
 		return session;
 	}
 
 	protected Session openSession(Interceptor interceptor) throws HibernateException {
 		session = sessionFactory().withOptions().interceptor( interceptor ).openSession();
 		return session;
 	}
 
 
 	// before/after test class ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@BeforeClassOnce
 	@SuppressWarnings( {"UnusedDeclaration"})
 	private void buildSessionFactory() {
 		configuration = buildConfiguration();
 		serviceRegistry = buildServiceRegistry( configuration );
 		sessionFactory = (SessionFactoryImplementor) configuration.buildSessionFactory( serviceRegistry );
 		afterSessionFactoryBuilt();
 	}
 
 	protected Configuration buildConfiguration() {
 		Configuration cfg = constructConfiguration();
 		configure( cfg );
 		addMappings( cfg );
 		cfg.buildMappings();
 		applyCacheSettings( cfg );
 		afterConfigurationBuilt( cfg );
 		return cfg;
 	}
 
 	protected Configuration constructConfiguration() {
 		Configuration configuration = new Configuration()
 				.setProperty( Environment.CACHE_PROVIDER, HashtableCacheProvider.class.getName() );
 		configuration.setProperty( AvailableSettings.USE_NEW_ID_GENERATOR_MAPPINGS, "true" );
 		if ( createSchema() ) {
 			configuration.setProperty( Environment.HBM2DDL_AUTO, "create-drop" );
 		}
 		configuration.setProperty( Environment.DIALECT, getDialect().getClass().getName() );
 		return configuration;
 	}
 
 	protected void configure(Configuration configuration) {
 	}
 
 	protected void addMappings(Configuration configuration) {
 		String[] mappings = getMappings();
 		if ( mappings != null ) {
 			for ( String mapping : mappings ) {
 				configuration.addResource(
 						getBaseForMappings() + mapping,
 						getClass().getClassLoader()
 				);
 			}
 		}
 		Class<?>[] annotatedClasses = getAnnotatedClasses();
 		if ( annotatedClasses != null ) {
 			for ( Class<?> annotatedClass : annotatedClasses ) {
 				configuration.addAnnotatedClass( annotatedClass );
 			}
 		}
 		String[] annotatedPackages = getAnnotatedPackages();
 		if ( annotatedPackages != null ) {
 			for ( String annotatedPackage : annotatedPackages ) {
 				configuration.addPackage( annotatedPackage );
 			}
 		}
 		String[] xmlFiles = getXmlFiles();
 		if ( xmlFiles != null ) {
 			for ( String xmlFile : xmlFiles ) {
 				InputStream is = Thread.currentThread().getContextClassLoader().getResourceAsStream( xmlFile );
 				configuration.addInputStream( is );
 			}
 		}
 	}
 
 	protected static final String[] NO_MAPPINGS = new String[0];
 
 	protected String[] getMappings() {
 		return NO_MAPPINGS;
 	}
 
 	protected String getBaseForMappings() {
 		return "org/hibernate/test/";
 	}
 
 	protected static final Class<?>[] NO_CLASSES = new Class[0];
 
 	protected Class<?>[] getAnnotatedClasses() {
 		return NO_CLASSES;
 	}
 
 	protected String[] getAnnotatedPackages() {
 		return NO_MAPPINGS;
 	}
 
 	protected String[] getXmlFiles() {
 		// todo : rename to getOrmXmlFiles()
 		return NO_MAPPINGS;
 	}
 
 	protected void applyCacheSettings(Configuration configuration) {
 		if ( getCacheConcurrencyStrategy() != null ) {
 			Iterator itr = configuration.getClassMappings();
 			while ( itr.hasNext() ) {
 				PersistentClass clazz = (PersistentClass) itr.next();
 				Iterator props = clazz.getPropertyClosureIterator();
 				boolean hasLob = false;
 				while ( props.hasNext() ) {
 					Property prop = (Property) props.next();
 					if ( prop.getValue().isSimpleValue() ) {
 						String type = ( (SimpleValue) prop.getValue() ).getTypeName();
 						if ( "blob".equals(type) || "clob".equals(type) ) {
 							hasLob = true;
 						}
 						if ( Blob.class.getName().equals(type) || Clob.class.getName().equals(type) ) {
 							hasLob = true;
 						}
 					}
 				}
 				if ( !hasLob && !clazz.isInherited() && overrideCacheStrategy() ) {
 					configuration.setCacheConcurrencyStrategy( clazz.getEntityName(), getCacheConcurrencyStrategy() );
 				}
 			}
 			itr = configuration.getCollectionMappings();
 			while ( itr.hasNext() ) {
 				Collection coll = (Collection) itr.next();
 				configuration.setCollectionCacheConcurrencyStrategy( coll.getRole(), getCacheConcurrencyStrategy() );
 			}
 		}
 	}
 
 	protected boolean overrideCacheStrategy() {
 		return true;
 	}
 
 	protected String getCacheConcurrencyStrategy() {
 		return null;
 	}
 
 	protected void afterConfigurationBuilt(Configuration configuration) {
 		afterConfigurationBuilt( configuration.createMappings(), getDialect() );
 	}
 
 	protected void afterConfigurationBuilt(Mappings mappings, Dialect dialect) {
 	}
 
 	protected BasicServiceRegistryImpl buildServiceRegistry(Configuration configuration) {
 		Properties properties = new Properties();
 		properties.putAll( configuration.getProperties() );
 		Environment.verifyProperties( properties );
 		ConfigurationHelper.resolvePlaceHolders( properties );
 		BasicServiceRegistryImpl serviceRegistry = (BasicServiceRegistryImpl) new org.hibernate.service.ServiceRegistryBuilder( properties ).buildServiceRegistry();
 		applyServices( serviceRegistry );
 		return serviceRegistry;
 	}
 
 	protected void applyServices(BasicServiceRegistryImpl serviceRegistry) {
 	}
 
 	protected void afterSessionFactoryBuilt() {
 	}
 
 	protected boolean createSchema() {
 		return true;
 	}
 
 	protected boolean rebuildSessionFactoryOnError() {
 		return true;
 	}
 
 	@AfterClassOnce
 	@SuppressWarnings( {"UnusedDeclaration"})
 	private void releaseSessionFactory() {
 		if ( sessionFactory == null ) {
 			return;
 		}
 		sessionFactory.close();
 		sessionFactory = null;
 		configuration = null;
 	}
 
 	@OnFailure
 	@OnExpectedFailure
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public void onFailure() {
 		if ( rebuildSessionFactoryOnError() ) {
 			rebuildSessionFactory();
 		}
 	}
 
 	protected void rebuildSessionFactory() {
 		if ( sessionFactory == null ) {
 			return;
 		}
 		sessionFactory.close();
 		serviceRegistry.destroy();
 
 		serviceRegistry = buildServiceRegistry( configuration );
 		sessionFactory = (SessionFactoryImplementor) configuration.buildSessionFactory( serviceRegistry );
 		afterSessionFactoryBuilt();
 	}
 
 
 	// before/after each test ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Before
 	public final void beforeTest() throws Exception {
 		prepareTest();
 	}
 
 	protected void prepareTest() throws Exception {
 	}
 
 	@After
 	public final void afterTest() throws Exception {
 		cleanupTest();
 
 		cleanupSession();
 
 		assertAllDataRemoved();
 	}
 
 	private void cleanupSession() {
 		if ( session != null && ! ( (SessionImplementor) session ).isClosed() ) {
 			if ( session.isConnected() ) {
 				session.doWork( new RollbackWork() );
 			}
 			session.close();
 		}
 		session = null;
 	}
 
 	public class RollbackWork implements Work {
 		public void execute(Connection connection) throws SQLException {
 			connection.rollback();
 		}
 	}
 
 	protected void cleanupTest() throws Exception {
 	}
 
 	@SuppressWarnings( {"UnnecessaryBoxing", "UnnecessaryUnboxing"})
 	protected void assertAllDataRemoved() {
 		if ( !createSchema() ) {
 			return; // no tables were created...
 		}
 		if ( !Boolean.getBoolean( VALIDATE_DATA_CLEANUP ) ) {
 			return;
 		}
 
 		Session tmpSession = sessionFactory.openSession();
 		try {
 			List list = tmpSession.createQuery( "select o from java.lang.Object o" ).list();
 
 			Map<String,Integer> items = new HashMap<String,Integer>();
 			if ( !list.isEmpty() ) {
 				for ( Object element : list ) {
 					Integer l = items.get( tmpSession.getEntityName( element ) );
 					if ( l == null ) {
 						l = Integer.valueOf( 0 );
 					}
 					l = Integer.valueOf( l.intValue() + 1 ) ;
 					items.put( tmpSession.getEntityName( element ), l );
 					System.out.println( "Data left: " + element );
 				}
 				fail( "Data is left in the database: " + items.toString() );
 			}
 		}
 		finally {
 			try {
 				tmpSession.close();
 			}
 			catch( Throwable t ) {
 				// intentionally empty
 			}
 		}
 	}
 
 	protected boolean readCommittedIsolationMaintained(String scenario) {
 		int isolation = java.sql.Connection.TRANSACTION_READ_UNCOMMITTED;
 		Session testSession = null;
 		try {
 			testSession = openSession();
 			isolation = testSession.doReturningWork(
 					new AbstractReturningWork<Integer>() {
 						@Override
 						public Integer execute(Connection connection) throws SQLException {
 							return connection.getTransactionIsolation();
 						}
 					}
 			);
 		}
 		catch( Throwable ignore ) {
 		}
 		finally {
 			if ( testSession != null ) {
 				try {
 					testSession.close();
 				}
 				catch( Throwable ignore ) {
 				}
 			}
 		}
 		if ( isolation < java.sql.Connection.TRANSACTION_READ_COMMITTED ) {
 			SkipLog.reportSkip( "environment does not support at least read committed isolation", scenario );
 			return false;
 		}
 		else {
 			return true;
 		}
 	}
 
 }
