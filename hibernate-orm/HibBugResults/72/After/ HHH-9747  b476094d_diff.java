diff --git a/hibernate-core/src/main/java/org/hibernate/EmptyInterceptor.java b/hibernate-core/src/main/java/org/hibernate/EmptyInterceptor.java
index cc583c35cd..cf9d1710a3 100755
--- a/hibernate-core/src/main/java/org/hibernate/EmptyInterceptor.java
+++ b/hibernate-core/src/main/java/org/hibernate/EmptyInterceptor.java
@@ -1,152 +1,156 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate;
 
 import java.io.Serializable;
 import java.util.Iterator;
 
 import org.hibernate.type.Type;
 
 /**
  * An interceptor that does nothing.  May be used as a base class for application-defined custom interceptors.
  * 
  * @author Gavin King
  */
 public class EmptyInterceptor implements Interceptor, Serializable {
 	/**
 	 * The singleton reference.
 	 */
 	public static final Interceptor INSTANCE = new EmptyInterceptor();
 
 	protected EmptyInterceptor() {
 	}
 
 	@Override
 	public void onDelete(
 			Object entity, 
 			Serializable id, 
 			Object[] state, 
 			String[] propertyNames, 
 			Type[] types) {}
 
 	@Override
 	public boolean onFlushDirty(
 			Object entity, 
 			Serializable id, 
 			Object[] currentState, 
 			Object[] previousState, 
 			String[] propertyNames, 
 			Type[] types) {
 		return false;
 	}
 
 	@Override
 	public boolean onLoad(
 			Object entity, 
 			Serializable id, 
 			Object[] state, 
 			String[] propertyNames, 
 			Type[] types) {
 		return false;
 	}
 
 	@Override
 	public boolean onSave(
 			Object entity, 
 			Serializable id, 
 			Object[] state, 
 			String[] propertyNames, 
 			Type[] types) {
 		return false;
 	}
 
 	@Override
 	public void postFlush(Iterator entities) {
 	}
 
 	@Override
 	public void preFlush(Iterator entities) {
 	}
 
 	@Override
 	public Boolean isTransient(Object entity) {
 		return null;
 	}
 
 	@Override
 	public Object instantiate(String entityName, EntityMode entityMode, Serializable id) {
 		return null;
 	}
 
 	@Override
 	public int[] findDirty(
 			Object entity,
 			Serializable id,
 			Object[] currentState,
 			Object[] previousState,
 			String[] propertyNames,
 			Type[] types) {
 		return null;
 	}
 
 	@Override
 	public String getEntityName(Object object) {
 		return null;
 	}
 
 	@Override
 	public Object getEntity(String entityName, Serializable id) {
 		return null;
 	}
 
 	@Override
 	public void afterTransactionBegin(Transaction tx) {
 	}
 
 	@Override
 	public void afterTransactionCompletion(Transaction tx) {
 	}
 
 	@Override
 	public void beforeTransactionCompletion(Transaction tx) {
 	}
 
 	@Override
 	public String onPrepareStatement(String sql) {
 		return sql;
 	}
 
 	@Override
 	public void onCollectionRemove(Object collection, Serializable key) throws CallbackException {
 	}
 
 	@Override
 	public void onCollectionRecreate(Object collection, Serializable key) throws CallbackException {
 	}
 
 	@Override
 	public void onCollectionUpdate(Object collection, Serializable key) throws CallbackException {
 	}
-	
+
+	@Override
+	public String inspect(String sql) {
+		return this.onPrepareStatement( sql );
+	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/Interceptor.java b/hibernate-core/src/main/java/org/hibernate/Interceptor.java
index 29b5108387..0e4a1ab313 100644
--- a/hibernate-core/src/main/java/org/hibernate/Interceptor.java
+++ b/hibernate-core/src/main/java/org/hibernate/Interceptor.java
@@ -1,277 +1,278 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate;
 
 import java.io.Serializable;
 import java.util.Iterator;
 
+import org.hibernate.resource.jdbc.spi.StatementInspector;
 import org.hibernate.type.Type;
 
 /**
  * Allows user code to inspect and/or change property values.
  *
  * Inspection occurs before property values are written and after they are read
  * from the database.
  *
  * There might be a single instance of <tt>Interceptor</tt> for a <tt>SessionFactory</tt>, or a new instance
  * might be specified for each <tt>Session</tt>. Whichever approach is used, the interceptor must be
  * serializable if the <tt>Session</tt> is to be serializable. This means that <tt>SessionFactory</tt>-scoped
  * interceptors should implement <tt>readResolve()</tt>.
  *
  * The <tt>Session</tt> may not be invoked from a callback (nor may a callback cause a collection or proxy to
  * be lazily initialized).
  *
  * Instead of implementing this interface directly, it is usually better to extend <tt>EmptyInterceptor</tt>
  * and override only the callback methods of interest.
  *
  * @see SessionBuilder#interceptor(Interceptor)
  * @see SharedSessionBuilder#interceptor()
  * @see org.hibernate.cfg.Configuration#setInterceptor(Interceptor)
  * @see EmptyInterceptor
  *
  * @author Gavin King
  */
-public interface Interceptor {
+public interface Interceptor extends StatementInspector {
 	/**
 	 * Called just before an object is initialized. The interceptor may change the <tt>state</tt>, which will
 	 * be propagated to the persistent object. Note that when this method is called, <tt>entity</tt> will be
 	 * an empty uninitialized instance of the class.
 	 * <p/>
 	 * NOTE: The indexes across the <tt>state</tt>, <tt>propertyNames</tt> and <tt>types</tt> arrays match.
 	 *
 	 * @param entity The entity instance being loaded
 	 * @param id The identifier value being loaded
 	 * @param state The entity state (which will be pushed into the entity instance)
 	 * @param propertyNames The names of the entity properties, corresponding to the <tt>state</tt>.
 	 * @param types The types of the entity properties, corresponding to the <tt>state</tt>.
 	 *
 	 * @return {@code true} if the user modified the <tt>state</tt> in any way.
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
 	public boolean onLoad(Object entity, Serializable id, Object[] state, String[] propertyNames, Type[] types) throws CallbackException;
 
 	/**
 	 * Called when an object is detected to be dirty, during a flush. The interceptor may modify the detected
 	 * <tt>currentState</tt>, which will be propagated to both the database and the persistent object.
 	 * Note that not all flushes end in actual synchronization with the database, in which case the
 	 * new <tt>currentState</tt> will be propagated to the object, but not necessarily (immediately) to
 	 * the database. It is strongly recommended that the interceptor <b>not</b> modify the <tt>previousState</tt>.
 	 * <p/>
 	 * NOTE: The indexes across the <tt>currentState</tt>, <tt>previousState</tt>, <tt>propertyNames</tt> and
 	 * <tt>types</tt> arrays match.
 	 *
 	 * @param entity The entity instance detected as being dirty and being flushed
 	 * @param id The identifier of the entity
 	 * @param currentState The entity's current state
 	 * @param previousState The entity's previous (load time) state.
 	 * @param propertyNames The names of the entity properties
 	 * @param types The types of the entity properties
 	 *
 	 * @return {@code true} if the user modified the <tt>currentState</tt> in any way.
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
 	public boolean onFlushDirty(Object entity, Serializable id, Object[] currentState, Object[] previousState, String[] propertyNames, Type[] types) throws CallbackException;
 
 	/**
 	 * Called before an object is saved. The interceptor may modify the <tt>state</tt>, which will be used for
 	 * the SQL <tt>INSERT</tt> and propagated to the persistent object.
 	 *
 	 * @param entity The entity instance whose state is being inserted
 	 * @param id The identifier of the entity
 	 * @param state The state of the entity which will be inserted
 	 * @param propertyNames The names of the entity properties.
 	 * @param types The types of the entity properties
 	 *
 	 * @return <tt>true</tt> if the user modified the <tt>state</tt> in any way.
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
 	public boolean onSave(Object entity, Serializable id, Object[] state, String[] propertyNames, Type[] types) throws CallbackException;
 
 	/**
 	 *  Called before an object is deleted. It is not recommended that the interceptor modify the <tt>state</tt>.
 	 *
 	 * @param entity The entity instance being deleted
 	 * @param id The identifier of the entity
 	 * @param state The state of the entity
 	 * @param propertyNames The names of the entity properties.
 	 * @param types The types of the entity properties
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
 	public void onDelete(Object entity, Serializable id, Object[] state, String[] propertyNames, Type[] types) throws CallbackException;
 
 	/**
 	 * Called before a collection is (re)created.
 	 *
 	 * @param collection The collection instance.
 	 * @param key The collection key value.
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
 	public void onCollectionRecreate(Object collection, Serializable key) throws CallbackException;
 
 	/**
 	 * Called before a collection is deleted.
 	 *
 	 * @param collection The collection instance.
 	 * @param key The collection key value.
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
 	public void onCollectionRemove(Object collection, Serializable key) throws CallbackException;
 
 	/**
 	 * Called before a collection is updated.
 	 *
 	 * @param collection The collection instance.
 	 * @param key The collection key value.
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
 	public void onCollectionUpdate(Object collection, Serializable key) throws CallbackException;
 
 	/**
 	 * Called before a flush.
 	 *
 	 * @param entities The entities to be flushed.
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
 	public void preFlush(Iterator entities) throws CallbackException;
 
 	/**
 	 * Called after a flush that actually ends in execution of the SQL statements required to synchronize
 	 * in-memory state with the database.
 	 *
 	 * @param entities The entities that were flushed.
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
 	public void postFlush(Iterator entities) throws CallbackException;
 
 	/**
 	 * Called to distinguish between transient and detached entities. The return value determines the
 	 * state of the entity with respect to the current session.
 	 * <ul>
 	 * <li><tt>Boolean.TRUE</tt> - the entity is transient
 	 * <li><tt>Boolean.FALSE</tt> - the entity is detached
 	 * <li><tt>null</tt> - Hibernate uses the <tt>unsaved-value</tt> mapping and other heuristics to 
 	 * determine if the object is unsaved
 	 * </ul>
 	 * @param entity a transient or detached entity
 	 * @return Boolean or <tt>null</tt> to choose default behaviour
 	 */
 	public Boolean isTransient(Object entity);
 
 	/**
 	 * Called from <tt>flush()</tt>. The return value determines whether the entity is updated
 	 * <ul>
 	 * <li>an array of property indices - the entity is dirty
 	 * <li>an empty array - the entity is not dirty
 	 * <li><tt>null</tt> - use Hibernate's default dirty-checking algorithm
 	 * </ul>
 	 *
 	 * @param entity The entity for which to find dirty properties.
 	 * @param id The identifier of the entity
 	 * @param currentState The current entity state as taken from the entity instance
 	 * @param previousState The state of the entity when it was last synchronized (generally when it was loaded)
 	 * @param propertyNames The names of the entity properties.
 	 * @param types The types of the entity properties
 	 *
 	 * @return array of dirty property indices or {@code null} to indicate Hibernate should perform default behaviour
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
 	public int[] findDirty(Object entity, Serializable id, Object[] currentState, Object[] previousState, String[] propertyNames, Type[] types);
 	/**
 	 * Instantiate the entity class. Return <tt>null</tt> to indicate that Hibernate should use
 	 * the default constructor of the class. The identifier property of the returned instance
 	 * should be initialized with the given identifier.
 	 *
 	 * @param entityName the name of the entity
 	 * @param entityMode The type of entity instance to be returned.
 	 * @param id the identifier of the new instance
 	 *
 	 * @return an instance of the class, or <tt>null</tt> to choose default behaviour
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
 	public Object instantiate(String entityName, EntityMode entityMode, Serializable id) throws CallbackException;
 
 	/**
 	 * Get the entity name for a persistent or transient instance.
 	 *
 	 * @param object an entity instance
 	 *
 	 * @return the name of the entity
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
 	public String getEntityName(Object object) throws CallbackException;
 
 	/**
 	 * Get a fully loaded entity instance that is cached externally.
 	 *
 	 * @param entityName the name of the entity
 	 * @param id the instance identifier
 	 *
 	 * @return a fully initialized entity
 	 *
 	 * @throws CallbackException Thrown if the interceptor encounters any problems handling the callback.
 	 */
 	public Object getEntity(String entityName, Serializable id) throws CallbackException;
 	
 	/**
 	 * Called when a Hibernate transaction is begun via the Hibernate <tt>Transaction</tt> 
 	 * API. Will not be called if transactions are being controlled via some other 
 	 * mechanism (CMT, for example).
 	 *
 	 * @param tx The Hibernate transaction facade object
 	 */
 	public void afterTransactionBegin(Transaction tx);
 
 	/**
 	 * Called before a transaction is committed (but not before rollback).
 	 *
 	 * @param tx The Hibernate transaction facade object
 	 */
 	public void beforeTransactionCompletion(Transaction tx);
 
 	/**
 	 * Called after a transaction is committed or rolled back.
 	 *
 	 * @param tx The Hibernate transaction facade object
 	 */
 	public void afterTransactionCompletion(Transaction tx);
 
 	/**
 	 * Called when sql string is being prepared. 
 	 * @param sql sql to be prepared
 	 * @return original or modified sql
 	 */
 	public String onPrepareStatement(String sql);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/Transaction.java b/hibernate-core/src/main/java/org/hibernate/Transaction.java
index 6351603da0..c01a80b9b4 100644
--- a/hibernate-core/src/main/java/org/hibernate/Transaction.java
+++ b/hibernate-core/src/main/java/org/hibernate/Transaction.java
@@ -1,171 +1,122 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate;
 
 import javax.transaction.Synchronization;
 
+import org.hibernate.engine.transaction.spi.IsolationDelegate;
 import org.hibernate.engine.transaction.spi.LocalStatus;
+import org.hibernate.resource.transaction.spi.TransactionStatus;
 
 /**
  * Defines the contract for abstracting applications from the configured underlying means of transaction management.
  * Allows the application to define units of work, while maintaining abstraction from the underlying transaction
  * implementation (eg. JTA, JDBC).
  * <p/>
  * A transaction is associated with a {@link Session} and is usually initiated by a call to
  * {@link org.hibernate.Session#beginTransaction()}.  A single session might span multiple transactions since
  * the notion of a session (a conversation between the application and the datastore) is of coarser granularity than
  * the notion of a transaction.  However, it is intended that there be at most one uncommitted transaction associated
  * with a particular {@link Session} at any time.
  * <p/>
  * Implementers are not intended to be thread-safe.
  *
  * @author Anton van Straaten
  * @author Steve Ebersole
  */
 public interface Transaction {
-	/**
-	 * Is this transaction the initiator of any underlying transaction?
-	 *
-	 * @return {@code true} if this transaction initiated the underlying transaction; {@code false} otherwise.
-	 */
-	public boolean isInitiator();
 
 	/**
 	 * Begin this transaction.  No-op if the transaction has already been begun.  Note that this is not necessarily
 	 * symmetrical since usually multiple calls to {@link #commit} or {@link #rollback} will error.
 	 *
 	 * @throws HibernateException Indicates a problem beginning the transaction.
 	 */
 	public void begin();
 
 	/**
 	 * Commit this transaction.  This might entail a number of things depending on the context:<ul>
 	 *     <li>
 	 *         If this transaction is the {@link #isInitiator initiator}, {@link Session#flush} the {@link Session}
 	 *         with which it is associated (unless {@link Session} is in {@link FlushMode#MANUAL}).
 	 *     </li>
 	 *     <li>
 	 *         If this transaction is the {@link #isInitiator initiator}, commit the underlying transaction.
 	 *     </li>
 	 *     <li>
 	 *         Coordinate various callbacks
 	 *     </li>
 	 * </ul>
 	 *
 	 * @throws HibernateException Indicates a problem committing the transaction.
 	 */
 	public void commit();
 
 	/**
 	 * Rollback this transaction.  Either rolls back the underlying transaction or ensures it cannot later commit
 	 * (depending on the actual underlying strategy).
 	 *
 	 * @throws HibernateException Indicates a problem rolling back the transaction.
 	 */
 	public void rollback();
 
 	/**
 	 * Get the current local status of this transaction.
 	 * <p/>
 	 * This only accounts for the local view of the transaction status.  In other words it does not check the status
 	 * of the actual underlying transaction.
 	 *
 	 * @return The current local status.
 	 */
-	public LocalStatus getLocalStatus();
-
-	/**
-	 * Is this transaction still active?
-	 * <p/>
-	 * Answers on a best effort basis.  For example, in the case of JDBC based transactions we cannot know that a
-	 * transaction is active when it is initiated directly through the JDBC {@link java.sql.Connection}, only when
-	 * it is initiated from here.
-	 *
-	 * @return {@code true} if the transaction is still active; {@code false} otherwise.
-	 *
-	 * @throws HibernateException Indicates a problem checking the transaction status.
-	 */
-	public boolean isActive();
-
-	/**
-	 * Is Hibernate participating in the underlying transaction?
-	 * <p/>
-	 * Generally speaking this will be the same as {@link #isActive()}.
-	 * 
-	 * @return {@code true} if Hibernate is known to be participating in the underlying transaction; {@code false}
-	 * otherwise.
-	 */
-	public boolean isParticipating();
-
-	/**
-	 * Was this transaction committed?
-	 * <p/>
-	 * Answers on a best effort basis.  For example, in the case of JDBC based transactions we cannot know that a
-	 * transaction was committed when the commit was performed directly through the JDBC {@link java.sql.Connection},
-	 * only when the commit was done from this.
-	 *
-	 * @return {@code true} if the transaction is rolled back; {@code false} otherwise.
-	 *
-	 * @throws HibernateException Indicates a problem checking the transaction status.
-	 */
-	@SuppressWarnings( {"UnusedDeclaration"})
-	public boolean wasCommitted();
-
-	/**
-	 * Was this transaction rolled back or set to rollback only?
-	 * <p/>
-	 * Answers on a best effort basis.  For example, in the case of JDBC based transactions we cannot know that a
-	 * transaction was rolled back when rollback was performed directly through the JDBC {@link java.sql.Connection},
-	 * only when it was rolled back  from here.
-	 *
-	 * @return {@literal true} if the transaction is rolled back; {@literal false} otherwise.
-	 *
-	 * @throws HibernateException Indicates a problem checking the transaction status.
-	 */
-	@SuppressWarnings( {"UnusedDeclaration"})
-	public boolean wasRolledBack();
+	public TransactionStatus getStatus();
 
 	/**
 	 * Register a user synchronization callback for this transaction.
 	 *
 	 * @param synchronization The Synchronization callback to register.
 	 *
 	 * @throws HibernateException Indicates a problem registering the synchronization.
 	 */
 	public void registerSynchronization(Synchronization synchronization) throws HibernateException;
 
 	/**
 	 * Set the transaction timeout for any transaction started by a subsequent call to {@link #begin} on this instance.
 	 *
 	 * @param seconds The number of seconds before a timeout.
 	 */
 	public void setTimeout(int seconds);
 
 	/**
 	 * Retrieve the transaction timeout set for this transaction.  A negative indicates no timeout has been set.
 	 *
 	 * @return The timeout, in seconds.
 	 */
 	public int getTimeout();
+
+	/**
+	 * Make a best effort to mark the underlying transaction for rollback only.
+	 */
+	public void markRollbackOnly();
+
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/internal/SessionFactoryBuilderImpl.java b/hibernate-core/src/main/java/org/hibernate/boot/internal/SessionFactoryBuilderImpl.java
index 2f5db38c89..8452dbb00d 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/internal/SessionFactoryBuilderImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/internal/SessionFactoryBuilderImpl.java
@@ -1,1206 +1,1215 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.internal;
 
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.CustomEntityDirtinessStrategy;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.EntityMode;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.Interceptor;
 import org.hibernate.MultiTenancyStrategy;
 import org.hibernate.NullPrecedence;
 import org.hibernate.SessionEventListener;
 import org.hibernate.SessionFactory;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.boot.SchemaAutoTooling;
 import org.hibernate.boot.SessionFactoryBuilder;
 import org.hibernate.boot.TempTableDdlTransactionHandling;
 import org.hibernate.boot.registry.StandardServiceRegistry;
 import org.hibernate.boot.registry.selector.spi.StrategySelector;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.boot.spi.SessionFactoryBuilderImplementor;
 import org.hibernate.boot.spi.SessionFactoryOptions;
 import org.hibernate.cache.internal.StandardQueryCacheFactory;
 import org.hibernate.cache.spi.QueryCacheFactory;
 import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.BaselineSessionEventsListenerBuilder;
 import org.hibernate.context.spi.CurrentTenantIdentifierResolver;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.engine.config.internal.ConfigurationServiceImpl;
 import org.hibernate.engine.config.spi.ConfigurationService;
 import org.hibernate.engine.jdbc.env.spi.ExtractedDatabaseMetaData;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
-import org.hibernate.engine.transaction.spi.TransactionFactory;
 import org.hibernate.hql.spi.id.MultiTableBulkIdStrategy;
 import org.hibernate.internal.SessionFactoryImpl;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.loader.BatchFetchStyle;
 import org.hibernate.proxy.EntityNotFoundDelegate;
+import org.hibernate.resource.transaction.TransactionCoordinatorBuilder;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.tuple.entity.EntityTuplizer;
 import org.hibernate.tuple.entity.EntityTuplizerFactory;
 
 import org.jboss.logging.Logger;
 
 import static org.hibernate.cfg.AvailableSettings.AUTO_CLOSE_SESSION;
 import static org.hibernate.cfg.AvailableSettings.AUTO_EVICT_COLLECTION_CACHE;
 import static org.hibernate.cfg.AvailableSettings.AUTO_SESSION_EVENTS_LISTENER;
 import static org.hibernate.cfg.AvailableSettings.BATCH_FETCH_STYLE;
 import static org.hibernate.cfg.AvailableSettings.BATCH_VERSIONED_DATA;
 import static org.hibernate.cfg.AvailableSettings.CACHE_REGION_PREFIX;
 import static org.hibernate.cfg.AvailableSettings.CHECK_NULLABILITY;
 import static org.hibernate.cfg.AvailableSettings.CUSTOM_ENTITY_DIRTINESS_STRATEGY;
 import static org.hibernate.cfg.AvailableSettings.DEFAULT_BATCH_FETCH_SIZE;
 import static org.hibernate.cfg.AvailableSettings.DEFAULT_ENTITY_MODE;
 import static org.hibernate.cfg.AvailableSettings.ENABLE_LAZY_LOAD_NO_TRANS;
 import static org.hibernate.cfg.AvailableSettings.FLUSH_BEFORE_COMPLETION;
 import static org.hibernate.cfg.AvailableSettings.GENERATE_STATISTICS;
 import static org.hibernate.cfg.AvailableSettings.HQL_BULK_ID_STRATEGY;
 import static org.hibernate.cfg.AvailableSettings.INTERCEPTOR;
 import static org.hibernate.cfg.AvailableSettings.JPAQL_STRICT_COMPLIANCE;
 import static org.hibernate.cfg.AvailableSettings.JTA_TRACK_BY_THREAD;
 import static org.hibernate.cfg.AvailableSettings.LOG_SESSION_METRICS;
 import static org.hibernate.cfg.AvailableSettings.MAX_FETCH_DEPTH;
 import static org.hibernate.cfg.AvailableSettings.MULTI_TENANT_IDENTIFIER_RESOLVER;
 import static org.hibernate.cfg.AvailableSettings.ORDER_INSERTS;
 import static org.hibernate.cfg.AvailableSettings.ORDER_UPDATES;
 import static org.hibernate.cfg.AvailableSettings.QUERY_CACHE_FACTORY;
 import static org.hibernate.cfg.AvailableSettings.QUERY_STARTUP_CHECKING;
 import static org.hibernate.cfg.AvailableSettings.QUERY_SUBSTITUTIONS;
 import static org.hibernate.cfg.AvailableSettings.RELEASE_CONNECTIONS;
 import static org.hibernate.cfg.AvailableSettings.SESSION_FACTORY_NAME;
 import static org.hibernate.cfg.AvailableSettings.SESSION_FACTORY_NAME_IS_JNDI;
 import static org.hibernate.cfg.AvailableSettings.STATEMENT_BATCH_SIZE;
 import static org.hibernate.cfg.AvailableSettings.STATEMENT_FETCH_SIZE;
 import static org.hibernate.cfg.AvailableSettings.USE_DIRECT_REFERENCE_CACHE_ENTRIES;
 import static org.hibernate.cfg.AvailableSettings.USE_GET_GENERATED_KEYS;
 import static org.hibernate.cfg.AvailableSettings.USE_IDENTIFIER_ROLLBACK;
 import static org.hibernate.cfg.AvailableSettings.USE_MINIMAL_PUTS;
 import static org.hibernate.cfg.AvailableSettings.USE_QUERY_CACHE;
 import static org.hibernate.cfg.AvailableSettings.USE_SCROLLABLE_RESULTSET;
 import static org.hibernate.cfg.AvailableSettings.USE_SECOND_LEVEL_CACHE;
 import static org.hibernate.cfg.AvailableSettings.USE_SQL_COMMENTS;
 import static org.hibernate.cfg.AvailableSettings.USE_STRUCTURED_CACHE;
 import static org.hibernate.cfg.AvailableSettings.WRAP_RESULT_SETS;
 import static org.hibernate.engine.config.spi.StandardConverters.BOOLEAN;
+import static org.hibernate.cfg.AvailableSettings.PREFER_USER_TRANSACTION;
 
 /**
  * @author Gail Badner
  * @author Steve Ebersole
  */
 public class SessionFactoryBuilderImpl implements SessionFactoryBuilderImplementor, SessionFactoryOptionsState {
 	private static final Logger log = Logger.getLogger( SessionFactoryBuilderImpl.class );
 
 	private final MetadataImplementor metadata;
 	private final SessionFactoryOptionsStateStandardImpl options;
 
 	SessionFactoryBuilderImpl(MetadataImplementor metadata) {
 		this.metadata = metadata;
 		this.options = new SessionFactoryOptionsStateStandardImpl( metadata.getMetadataBuildingOptions().getServiceRegistry() );
 
 		if ( metadata.getSqlFunctionMap() != null ) {
 			for ( Map.Entry<String, SQLFunction> sqlFunctionEntry : metadata.getSqlFunctionMap().entrySet() ) {
 				applySqlFunction( sqlFunctionEntry.getKey(), sqlFunctionEntry.getValue() );
 			}
 		}
 	}
 
 	@Override
 	public SessionFactoryBuilder applyValidatorFactory(Object validatorFactory) {
 		this.options.validatorFactoryReference = validatorFactory;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyBeanManager(Object beanManager) {
 		this.options.beanManagerReference = beanManager;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyName(String sessionFactoryName) {
 		this.options.sessionFactoryName = sessionFactoryName;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyNameAsJndiName(boolean isJndiName) {
 		this.options.sessionFactoryNameAlsoJndiName = isJndiName;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyAutoClosing(boolean enabled) {
 		this.options.autoCloseSessionEnabled = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyAutoFlushing(boolean enabled) {
 		this.options.flushBeforeCompletionEnabled = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyStatisticsSupport(boolean enabled) {
 		this.options.statisticsEnabled = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder addSessionFactoryObservers(SessionFactoryObserver... observers) {
 		this.options.sessionFactoryObserverList.addAll( Arrays.asList( observers ) );
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyInterceptor(Interceptor interceptor) {
 		this.options.interceptor = interceptor;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyCustomEntityDirtinessStrategy(CustomEntityDirtinessStrategy strategy) {
 		this.options.customEntityDirtinessStrategy = strategy;
 		return this;
 	}
 
 
 	@Override
 	public SessionFactoryBuilder addEntityNameResolver(EntityNameResolver... entityNameResolvers) {
 		this.options.entityNameResolvers.addAll( Arrays.asList( entityNameResolvers ) );
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyEntityNotFoundDelegate(EntityNotFoundDelegate entityNotFoundDelegate) {
 		this.options.entityNotFoundDelegate = entityNotFoundDelegate;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyIdentifierRollbackSupport(boolean enabled) {
 		this.options.identifierRollbackEnabled = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyDefaultEntityMode(EntityMode entityMode) {
 		this.options.defaultEntityMode = entityMode;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyNullabilityChecking(boolean enabled) {
 		this.options.checkNullability = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyLazyInitializationOutsideTransaction(boolean enabled) {
 		this.options.initializeLazyStateOutsideTransactions = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyEntityTuplizerFactory(EntityTuplizerFactory entityTuplizerFactory) {
 		this.options.entityTuplizerFactory = entityTuplizerFactory;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyEntityTuplizer(
 			EntityMode entityMode,
 			Class<? extends EntityTuplizer> tuplizerClass) {
 		this.options.entityTuplizerFactory.registerDefaultTuplizerClass( entityMode, tuplizerClass );
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyMultiTableBulkIdStrategy(MultiTableBulkIdStrategy strategy) {
 		this.options.multiTableBulkIdStrategy = strategy;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyTempTableDdlTransactionHandling(TempTableDdlTransactionHandling handling) {
 		this.options.tempTableDdlTransactionHandling = handling;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyBatchFetchStyle(BatchFetchStyle style) {
 		this.options.batchFetchStyle = style;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyDefaultBatchFetchSize(int size) {
 		this.options.defaultBatchFetchSize = size;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyMaximumFetchDepth(int depth) {
 		this.options.maximumFetchDepth = depth;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyDefaultNullPrecedence(NullPrecedence nullPrecedence) {
 		this.options.defaultNullPrecedence = nullPrecedence;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyOrderingOfInserts(boolean enabled) {
 		this.options.orderInsertsEnabled = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyOrderingOfUpdates(boolean enabled) {
 		this.options.orderUpdatesEnabled = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyMultiTenancyStrategy(MultiTenancyStrategy strategy) {
 		this.options.multiTenancyStrategy = strategy;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyCurrentTenantIdentifierResolver(CurrentTenantIdentifierResolver resolver) {
 		this.options.currentTenantIdentifierResolver = resolver;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyJtaTrackingByThread(boolean enabled) {
 		this.options.jtaTrackByThread = enabled;
 		return this;
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public SessionFactoryBuilder applyQuerySubstitutions(Map substitutions) {
 		this.options.querySubstitutions.putAll( substitutions );
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyStrictJpaQueryLanguageCompliance(boolean enabled) {
 		this.options.strictJpaQueryLanguageCompliance = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyNamedQueryCheckingOnStartup(boolean enabled) {
 		this.options.namedQueryStartupCheckingEnabled = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applySecondLevelCacheSupport(boolean enabled) {
 		this.options.secondLevelCacheEnabled = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyQueryCacheSupport(boolean enabled) {
 		this.options.queryCacheEnabled = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyQueryCacheFactory(QueryCacheFactory factory) {
 		this.options.queryCacheFactory = factory;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyCacheRegionPrefix(String prefix) {
 		this.options.cacheRegionPrefix = prefix;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyMinimalPutsForCaching(boolean enabled) {
 		this.options.minimalPutsEnabled = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyStructuredCacheEntries(boolean enabled) {
 		this.options.structuredCacheEntriesEnabled = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyDirectReferenceCaching(boolean enabled) {
 		this.options.directReferenceCacheEntriesEnabled = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyAutomaticEvictionOfCollectionCaches(boolean enabled) {
 		this.options.autoEvictCollectionCache = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyJdbcBatchSize(int size) {
 		this.options.jdbcBatchSize = size;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyJdbcBatchingForVersionedEntities(boolean enabled) {
 		this.options.jdbcBatchVersionedData = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyScrollableResultsSupport(boolean enabled) {
 		this.options.scrollableResultSetsEnabled = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyResultSetsWrapping(boolean enabled) {
 		this.options.wrapResultSetsEnabled = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyGetGeneratedKeysSupport(boolean enabled) {
 		this.options.getGeneratedKeysEnabled = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyJdbcFetchSize(int size) {
 		this.options.jdbcFetchSize = size;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applyConnectionReleaseMode(ConnectionReleaseMode connectionReleaseMode) {
 		this.options.connectionReleaseMode = connectionReleaseMode;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applySqlComments(boolean enabled) {
 		this.options.commentsEnabled = enabled;
 		return this;
 	}
 
 	@Override
 	public SessionFactoryBuilder applySqlFunction(String registrationName, SQLFunction sqlFunction) {
 		if ( this.options.sqlFunctions == null ) {
 			this.options.sqlFunctions = new HashMap<String, SQLFunction>();
 		}
 		this.options.sqlFunctions.put( registrationName, sqlFunction );
 		return this;
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <T extends SessionFactoryBuilder> T unwrap(Class<T> type) {
 		return (T) this;
 	}
 
 	@Override
 	public SessionFactory build() {
 		metadata.validate();
 		return new SessionFactoryImpl( metadata, buildSessionFactoryOptions() );
 	}
 
 	@Override
 	public SessionFactoryOptions buildSessionFactoryOptions() {
 		return new SessionFactoryOptionsImpl( this );
 	}
 
 
 
 	// SessionFactoryOptionsState impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public static class SessionFactoryOptionsStateStandardImpl implements SessionFactoryOptionsState {
 		private final StandardServiceRegistry serviceRegistry;
 
 		// integration
 		private Object beanManagerReference;
 		private Object validatorFactoryReference;
 
 		// SessionFactory behavior
 		private String sessionFactoryName;
 		private boolean sessionFactoryNameAlsoJndiName;
 
 		// Session behavior
 		private boolean flushBeforeCompletionEnabled;
 		private boolean autoCloseSessionEnabled;
 
 		// Statistics/Interceptor/observers
 		private boolean statisticsEnabled;
 		private Interceptor interceptor;
 		private List<SessionFactoryObserver> sessionFactoryObserverList = new ArrayList<SessionFactoryObserver>();
 		private BaselineSessionEventsListenerBuilder baselineSessionEventsListenerBuilder;	// not exposed on builder atm
 
 		// persistence behavior
 		private CustomEntityDirtinessStrategy customEntityDirtinessStrategy;
 		private List<EntityNameResolver> entityNameResolvers = new ArrayList<EntityNameResolver>();
 		private EntityNotFoundDelegate entityNotFoundDelegate;
 		private boolean identifierRollbackEnabled;
 		private EntityMode defaultEntityMode;
 		private EntityTuplizerFactory entityTuplizerFactory = new EntityTuplizerFactory();
 		private boolean checkNullability;
 		private boolean initializeLazyStateOutsideTransactions;
 		private MultiTableBulkIdStrategy multiTableBulkIdStrategy;
 		private TempTableDdlTransactionHandling tempTableDdlTransactionHandling;
 		private BatchFetchStyle batchFetchStyle;
 		private int defaultBatchFetchSize;
 		private Integer maximumFetchDepth;
 		private NullPrecedence defaultNullPrecedence;
 		private boolean orderUpdatesEnabled;
 		private boolean orderInsertsEnabled;
 
 		// multi-tenancy
 		private MultiTenancyStrategy multiTenancyStrategy;
 		private CurrentTenantIdentifierResolver currentTenantIdentifierResolver;
 
 		// JTA timeout detection
 		private boolean jtaTrackByThread;
 
 		// Queries
 		private Map querySubstitutions;
 		private boolean strictJpaQueryLanguageCompliance;
 		private boolean namedQueryStartupCheckingEnabled;
 
 		// Caching
 		private boolean secondLevelCacheEnabled;
 		private boolean queryCacheEnabled;
 		private QueryCacheFactory queryCacheFactory;
 		private String cacheRegionPrefix;
 		private boolean minimalPutsEnabled;
 		private boolean structuredCacheEntriesEnabled;
 		private boolean directReferenceCacheEntriesEnabled;
 		private boolean autoEvictCollectionCache;
 
 		// Schema tooling
 		private SchemaAutoTooling schemaAutoTooling;
 
 		// JDBC Handling
 		private boolean getGeneratedKeysEnabled;
 		private int jdbcBatchSize;
 		private boolean jdbcBatchVersionedData;
 		private Integer jdbcFetchSize;
 		private boolean scrollableResultSetsEnabled;
 		private boolean commentsEnabled;
 		private ConnectionReleaseMode connectionReleaseMode;
 		private boolean wrapResultSetsEnabled;
 
 		private Map<String, SQLFunction> sqlFunctions;
+		private boolean preferUserTransaction;
 
 		public SessionFactoryOptionsStateStandardImpl(StandardServiceRegistry serviceRegistry) {
 			this.serviceRegistry = serviceRegistry;
 
 			final StrategySelector strategySelector = serviceRegistry.getService( StrategySelector.class );
 			ConfigurationService cfgService = serviceRegistry.getService( ConfigurationService.class );
 			final JdbcServices jdbcServices = serviceRegistry.getService( JdbcServices.class );
 
 			final Map configurationSettings = new HashMap();
 			//noinspection unchecked
 			configurationSettings.putAll( cfgService.getSettings() );
 			//noinspection unchecked
 			configurationSettings.putAll( jdbcServices.getJdbcEnvironment().getDialect().getDefaultProperties() );
 			cfgService = new ConfigurationServiceImpl( configurationSettings );
 			( (ConfigurationServiceImpl) cfgService ).injectServices( (ServiceRegistryImplementor) serviceRegistry );
 
 			this.beanManagerReference = configurationSettings.get( "javax.persistence.bean.manager" );
 			this.validatorFactoryReference = configurationSettings.get( "javax.persistence.validation.factory" );
 
 			this.sessionFactoryName = (String) configurationSettings.get( SESSION_FACTORY_NAME );
 			this.sessionFactoryNameAlsoJndiName = cfgService.getSetting(
 					SESSION_FACTORY_NAME_IS_JNDI,
 					BOOLEAN,
 					true
 			);
 
 			this.flushBeforeCompletionEnabled = cfgService.getSetting( FLUSH_BEFORE_COMPLETION, BOOLEAN, false );
 			this.autoCloseSessionEnabled = cfgService.getSetting( AUTO_CLOSE_SESSION, BOOLEAN, false );
 
 			this.statisticsEnabled = cfgService.getSetting( GENERATE_STATISTICS, BOOLEAN, false );
 			this.interceptor = strategySelector.resolveDefaultableStrategy(
 					Interceptor.class,
 					configurationSettings.get( INTERCEPTOR ),
 					EmptyInterceptor.INSTANCE
 			);
 			// todo : expose this from builder?
 			final String autoSessionEventsListenerName = (String) configurationSettings.get(
 					AUTO_SESSION_EVENTS_LISTENER
 			);
 			final Class<? extends SessionEventListener> autoSessionEventsListener = autoSessionEventsListenerName == null
 					? null
 					: strategySelector.selectStrategyImplementor( SessionEventListener.class, autoSessionEventsListenerName );
 
 			final boolean logSessionMetrics = cfgService.getSetting( LOG_SESSION_METRICS, BOOLEAN, statisticsEnabled );
 			this.baselineSessionEventsListenerBuilder = new BaselineSessionEventsListenerBuilder( logSessionMetrics, autoSessionEventsListener );
 
 			this.customEntityDirtinessStrategy = strategySelector.resolveDefaultableStrategy(
 					CustomEntityDirtinessStrategy.class,
 					configurationSettings.get( CUSTOM_ENTITY_DIRTINESS_STRATEGY ),
 					DefaultCustomEntityDirtinessStrategy.INSTANCE
 			);
 
 			this.entityNotFoundDelegate = StandardEntityNotFoundDelegate.INSTANCE;
 			this.identifierRollbackEnabled = cfgService.getSetting( USE_IDENTIFIER_ROLLBACK, BOOLEAN, false );
 			this.defaultEntityMode = EntityMode.parse( (String) configurationSettings.get( DEFAULT_ENTITY_MODE ) );
 			this.checkNullability = cfgService.getSetting( CHECK_NULLABILITY, BOOLEAN, true );
 			this.initializeLazyStateOutsideTransactions = cfgService.getSetting( ENABLE_LAZY_LOAD_NO_TRANS, BOOLEAN, false );
 
 			this.multiTenancyStrategy = MultiTenancyStrategy.determineMultiTenancyStrategy( configurationSettings );
 			this.currentTenantIdentifierResolver = strategySelector.resolveStrategy(
 					CurrentTenantIdentifierResolver.class,
 					configurationSettings.get( MULTI_TENANT_IDENTIFIER_RESOLVER )
 			);
 
 			this.multiTableBulkIdStrategy = strategySelector.resolveDefaultableStrategy(
 					MultiTableBulkIdStrategy.class,
 					configurationSettings.get( HQL_BULK_ID_STRATEGY ),
 					jdbcServices.getJdbcEnvironment().getDialect().getDefaultMultiTableBulkIdStrategy()
 			);
 
 			this.batchFetchStyle = BatchFetchStyle.interpret( configurationSettings.get( BATCH_FETCH_STYLE ) );
 			this.defaultBatchFetchSize = ConfigurationHelper.getInt( DEFAULT_BATCH_FETCH_SIZE, configurationSettings, -1 );
 			this.maximumFetchDepth = ConfigurationHelper.getInteger( MAX_FETCH_DEPTH, configurationSettings );
 			final String defaultNullPrecedence = ConfigurationHelper.getString(
 					AvailableSettings.DEFAULT_NULL_ORDERING, configurationSettings, "none", "first", "last"
 			);
 			this.defaultNullPrecedence = NullPrecedence.parse( defaultNullPrecedence );
 			this.orderUpdatesEnabled = ConfigurationHelper.getBoolean( ORDER_UPDATES, configurationSettings );
 			this.orderInsertsEnabled = ConfigurationHelper.getBoolean( ORDER_INSERTS, configurationSettings );
 
 			this.jtaTrackByThread = cfgService.getSetting( JTA_TRACK_BY_THREAD, BOOLEAN, true );
 
 			this.querySubstitutions = ConfigurationHelper.toMap( QUERY_SUBSTITUTIONS, " ,=;:\n\t\r\f", configurationSettings );
 			this.strictJpaQueryLanguageCompliance = cfgService.getSetting( JPAQL_STRICT_COMPLIANCE, BOOLEAN, false );
 			this.namedQueryStartupCheckingEnabled = cfgService.getSetting( QUERY_STARTUP_CHECKING, BOOLEAN, true );
 
 			this.secondLevelCacheEnabled = cfgService.getSetting( USE_SECOND_LEVEL_CACHE, BOOLEAN, true );
 			this.queryCacheEnabled = cfgService.getSetting( USE_QUERY_CACHE, BOOLEAN, false );
 			this.queryCacheFactory = strategySelector.resolveDefaultableStrategy(
 					QueryCacheFactory.class,
 					configurationSettings.get( QUERY_CACHE_FACTORY ),
 					StandardQueryCacheFactory.INSTANCE
 			);
 			this.cacheRegionPrefix = ConfigurationHelper.extractPropertyValue(
 					CACHE_REGION_PREFIX,
 					configurationSettings
 			);
 			this.minimalPutsEnabled = cfgService.getSetting(
 					USE_MINIMAL_PUTS,
 					BOOLEAN,
 					serviceRegistry.getService( RegionFactory.class ).isMinimalPutsEnabledByDefault()
 			);
 			this.structuredCacheEntriesEnabled = cfgService.getSetting( USE_STRUCTURED_CACHE, BOOLEAN, false );
 			this.directReferenceCacheEntriesEnabled = cfgService.getSetting( USE_DIRECT_REFERENCE_CACHE_ENTRIES,BOOLEAN, false );
 			this.autoEvictCollectionCache = cfgService.getSetting( AUTO_EVICT_COLLECTION_CACHE, BOOLEAN, false );
 
 			try {
 				this.schemaAutoTooling = SchemaAutoTooling.interpret( (String) configurationSettings.get( AvailableSettings.HBM2DDL_AUTO ) );
 			}
 			catch (Exception e) {
 				log.warn( e.getMessage() + "  Ignoring" );
 			}
 
 
 			final ExtractedDatabaseMetaData meta = jdbcServices.getExtractedMetaDataSupport();
 
 			this.tempTableDdlTransactionHandling = TempTableDdlTransactionHandling.NONE;
 			if ( meta.doesDataDefinitionCauseTransactionCommit() ) {
 				if ( meta.supportsDataDefinitionInTransaction() ) {
 					this.tempTableDdlTransactionHandling = TempTableDdlTransactionHandling.ISOLATE_AND_TRANSACT;
 				}
 				else {
 					this.tempTableDdlTransactionHandling = TempTableDdlTransactionHandling.ISOLATE;
 				}
 			}
 
 			this.jdbcBatchSize = ConfigurationHelper.getInt( STATEMENT_BATCH_SIZE, configurationSettings, 0 );
 			if ( !meta.supportsBatchUpdates() ) {
 				this.jdbcBatchSize = 0;
 			}
 
 			this.jdbcBatchVersionedData = ConfigurationHelper.getBoolean( BATCH_VERSIONED_DATA, configurationSettings, false );
 			this.scrollableResultSetsEnabled = ConfigurationHelper.getBoolean(
 					USE_SCROLLABLE_RESULTSET,
 					configurationSettings,
 					meta.supportsScrollableResults()
 			);
 			this.wrapResultSetsEnabled = ConfigurationHelper.getBoolean(
 					WRAP_RESULT_SETS,
 					configurationSettings,
 					false
 			);
 			this.getGeneratedKeysEnabled = ConfigurationHelper.getBoolean(
 					USE_GET_GENERATED_KEYS,
 					configurationSettings,
 					meta.supportsGetGeneratedKeys()
 			);
 			this.jdbcFetchSize = ConfigurationHelper.getInteger( STATEMENT_FETCH_SIZE, configurationSettings );
 
 			final String releaseModeName = ConfigurationHelper.getString( RELEASE_CONNECTIONS, configurationSettings, "auto" );
 			if ( "auto".equals( releaseModeName ) ) {
-				this.connectionReleaseMode = serviceRegistry.getService( TransactionFactory.class ).getDefaultReleaseMode();
+				this.connectionReleaseMode = serviceRegistry.getService( TransactionCoordinatorBuilder.class )
+						.getDefaultConnectionReleaseMode();
 			}
 			else {
 				connectionReleaseMode = ConnectionReleaseMode.parse( releaseModeName );
 			}
 
 			this.commentsEnabled = ConfigurationHelper.getBoolean( USE_SQL_COMMENTS, configurationSettings );
+
+			this.preferUserTransaction = ConfigurationHelper.getBoolean( PREFER_USER_TRANSACTION, configurationSettings, false  );
 		}
 
 		@Override
 		public StandardServiceRegistry getServiceRegistry() {
 			return serviceRegistry;
 		}
 
 		@Override
 		public Object getBeanManagerReference() {
 			return beanManagerReference;
 		}
 
 		@Override
 		public Object getValidatorFactoryReference() {
 			return validatorFactoryReference;
 		}
 
 		@Override
 		public String getSessionFactoryName() {
 			return sessionFactoryName;
 		}
 
 		@Override
 		public boolean isSessionFactoryNameAlsoJndiName() {
 			return sessionFactoryNameAlsoJndiName;
 		}
 
 		@Override
 		public boolean isFlushBeforeCompletionEnabled() {
 			return flushBeforeCompletionEnabled;
 		}
 
 		@Override
 		public boolean isAutoCloseSessionEnabled() {
 			return autoCloseSessionEnabled;
 		}
 
 		@Override
 		public boolean isStatisticsEnabled() {
 			return statisticsEnabled;
 		}
 
 		@Override
 		public Interceptor getInterceptor() {
 			return interceptor == null ? EmptyInterceptor.INSTANCE : interceptor;
 		}
 
 		@Override
 		public SessionFactoryObserver[] getSessionFactoryObservers() {
 			return sessionFactoryObserverList.toArray( new SessionFactoryObserver[ sessionFactoryObserverList.size() ] );
 		}
 
 		@Override
 		public BaselineSessionEventsListenerBuilder getBaselineSessionEventsListenerBuilder() {
 			return baselineSessionEventsListenerBuilder;
 		}
 
 		@Override
 		public boolean isIdentifierRollbackEnabled() {
 			return identifierRollbackEnabled;
 		}
 
 		@Override
 		public EntityMode getDefaultEntityMode() {
 			return defaultEntityMode;
 		}
 
 		@Override
 		public EntityTuplizerFactory getEntityTuplizerFactory() {
 			return entityTuplizerFactory;
 		}
 
 		@Override
 		public boolean isCheckNullability() {
 			return checkNullability;
 		}
 
 		@Override
 		public boolean isInitializeLazyStateOutsideTransactionsEnabled() {
 			return initializeLazyStateOutsideTransactions;
 		}
 
 		@Override
 		public MultiTableBulkIdStrategy getMultiTableBulkIdStrategy() {
 			return multiTableBulkIdStrategy;
 		}
 
 		@Override
 		public TempTableDdlTransactionHandling getTempTableDdlTransactionHandling() {
 			return tempTableDdlTransactionHandling;
 		}
 
 		@Override
 		public BatchFetchStyle getBatchFetchStyle() {
 			return batchFetchStyle;
 		}
 
 		@Override
 		public int getDefaultBatchFetchSize() {
 			return defaultBatchFetchSize;
 		}
 
 		@Override
 		public Integer getMaximumFetchDepth() {
 			return maximumFetchDepth;
 		}
 
 		@Override
 		public NullPrecedence getDefaultNullPrecedence() {
 			return defaultNullPrecedence;
 		}
 
 		@Override
 		public boolean isOrderUpdatesEnabled() {
 			return orderUpdatesEnabled;
 		}
 
 		@Override
 		public boolean isOrderInsertsEnabled() {
 			return orderInsertsEnabled;
 		}
 
 		@Override
 		public MultiTenancyStrategy getMultiTenancyStrategy() {
 			return multiTenancyStrategy;
 		}
 
 		@Override
 		public CurrentTenantIdentifierResolver getCurrentTenantIdentifierResolver() {
 			return currentTenantIdentifierResolver;
 		}
 
 		@Override
 		public boolean isJtaTrackByThread() {
 			return jtaTrackByThread;
 		}
 
 		@Override
 		public Map getQuerySubstitutions() {
 			return querySubstitutions;
 		}
 
 		@Override
 		public boolean isStrictJpaQueryLanguageCompliance() {
 			return strictJpaQueryLanguageCompliance;
 		}
 
 		@Override
 		public boolean isNamedQueryStartupCheckingEnabled() {
 			return namedQueryStartupCheckingEnabled;
 		}
 
 		@Override
 		public boolean isSecondLevelCacheEnabled() {
 			return secondLevelCacheEnabled;
 		}
 
 		@Override
 		public boolean isQueryCacheEnabled() {
 			return queryCacheEnabled;
 		}
 
 		@Override
 		public QueryCacheFactory getQueryCacheFactory() {
 			return queryCacheFactory;
 		}
 
 		@Override
 		public String getCacheRegionPrefix() {
 			return cacheRegionPrefix;
 		}
 
 		@Override
 		public boolean isMinimalPutsEnabled() {
 			return minimalPutsEnabled;
 		}
 
 		@Override
 		public boolean isStructuredCacheEntriesEnabled() {
 			return structuredCacheEntriesEnabled;
 		}
 
 		@Override
 		public boolean isDirectReferenceCacheEntriesEnabled() {
 			return directReferenceCacheEntriesEnabled;
 		}
 
 		@Override
 		public boolean isAutoEvictCollectionCache() {
 			return autoEvictCollectionCache;
 		}
 
 		@Override
 		public SchemaAutoTooling getSchemaAutoTooling() {
 			return schemaAutoTooling;
 		}
 
 		@Override
 		public int getJdbcBatchSize() {
 			return jdbcBatchSize;
 		}
 
 		@Override
 		public boolean isJdbcBatchVersionedData() {
 			return jdbcBatchVersionedData;
 		}
 
 		@Override
 		public boolean isScrollableResultSetsEnabled() {
 			return scrollableResultSetsEnabled;
 		}
 
 		@Override
 		public boolean isWrapResultSetsEnabled() {
 			return wrapResultSetsEnabled;
 		}
 
 		@Override
 		public boolean isGetGeneratedKeysEnabled() {
 			return getGeneratedKeysEnabled;
 		}
 
 		@Override
 		public Integer getJdbcFetchSize() {
 			return jdbcFetchSize;
 		}
 
 		@Override
 		public ConnectionReleaseMode getConnectionReleaseMode() {
 			return connectionReleaseMode;
 		}
 
 		@Override
 		public boolean isCommentsEnabled() {
 			return commentsEnabled;
 		}
 
 		@Override
 		public CustomEntityDirtinessStrategy getCustomEntityDirtinessStrategy() {
 			return customEntityDirtinessStrategy;
 		}
 
 		@Override
 		public EntityNameResolver[] getEntityNameResolvers() {
 			return entityNameResolvers.toArray( new EntityNameResolver[ entityNameResolvers.size() ] );
 		}
 
 		@Override
 		public EntityNotFoundDelegate getEntityNotFoundDelegate() {
 			return entityNotFoundDelegate;
 		}
 
 		@Override
 		public Map<String, SQLFunction> getCustomSqlFunctionMap() {
 			return sqlFunctions == null ? Collections.<String, SQLFunction>emptyMap() : sqlFunctions;
 		}
 
+		@Override
+		public boolean isPreferUserTransaction() {
+			return this.preferUserTransaction;
+		}
 	}
 
 	@Override
 	public StandardServiceRegistry getServiceRegistry() {
 		return options.getServiceRegistry();
 	}
 
 	@Override
 	public Object getBeanManagerReference() {
 		return options.getBeanManagerReference();
 	}
 
 	@Override
 	public Object getValidatorFactoryReference() {
 		return options.getValidatorFactoryReference();
 	}
 
 	@Override
 	public String getSessionFactoryName() {
 		return options.getSessionFactoryName();
 	}
 
 	@Override
 	public boolean isSessionFactoryNameAlsoJndiName() {
 		return options.isSessionFactoryNameAlsoJndiName();
 	}
 
 	@Override
 	public boolean isFlushBeforeCompletionEnabled() {
 		return options.isFlushBeforeCompletionEnabled();
 	}
 
 	@Override
 	public boolean isAutoCloseSessionEnabled() {
 		return options.isAutoCloseSessionEnabled();
 	}
 
 	@Override
 	public boolean isStatisticsEnabled() {
 		return options.isStatisticsEnabled();
 	}
 
 	@Override
 	public Interceptor getInterceptor() {
 		return options.getInterceptor();
 	}
 
 	@Override
 	public SessionFactoryObserver[] getSessionFactoryObservers() {
 		return options.getSessionFactoryObservers();
 	}
 
 	@Override
 	public BaselineSessionEventsListenerBuilder getBaselineSessionEventsListenerBuilder() {
 		return options.getBaselineSessionEventsListenerBuilder();
 	}
 
 	@Override
 	public boolean isIdentifierRollbackEnabled() {
 		return options.isIdentifierRollbackEnabled();
 	}
 
 	@Override
 	public EntityMode getDefaultEntityMode() {
 		return options.getDefaultEntityMode();
 	}
 
 	@Override
 	public EntityTuplizerFactory getEntityTuplizerFactory() {
 		return options.getEntityTuplizerFactory();
 	}
 
 	@Override
 	public boolean isCheckNullability() {
 		return options.isCheckNullability();
 	}
 
 	@Override
 	public boolean isInitializeLazyStateOutsideTransactionsEnabled() {
 		return options.isInitializeLazyStateOutsideTransactionsEnabled();
 	}
 
 	@Override
 	public MultiTableBulkIdStrategy getMultiTableBulkIdStrategy() {
 		return options.getMultiTableBulkIdStrategy();
 	}
 
 	@Override
 	public TempTableDdlTransactionHandling getTempTableDdlTransactionHandling() {
 		return options.getTempTableDdlTransactionHandling();
 	}
 
 	@Override
 	public BatchFetchStyle getBatchFetchStyle() {
 		return options.getBatchFetchStyle();
 	}
 
 	@Override
 	public int getDefaultBatchFetchSize() {
 		return options.getDefaultBatchFetchSize();
 	}
 
 	@Override
 	public Integer getMaximumFetchDepth() {
 		return options.getMaximumFetchDepth();
 	}
 
 	@Override
 	public NullPrecedence getDefaultNullPrecedence() {
 		return options.getDefaultNullPrecedence();
 	}
 
 	@Override
 	public boolean isOrderUpdatesEnabled() {
 		return options.isOrderUpdatesEnabled();
 	}
 
 	@Override
 	public boolean isOrderInsertsEnabled() {
 		return options.isOrderInsertsEnabled();
 	}
 
 	@Override
 	public MultiTenancyStrategy getMultiTenancyStrategy() {
 		return options.getMultiTenancyStrategy();
 	}
 
 	@Override
 	public CurrentTenantIdentifierResolver getCurrentTenantIdentifierResolver() {
 		return options.getCurrentTenantIdentifierResolver();
 	}
 
 	@Override
 	public boolean isJtaTrackByThread() {
 		return options.isJtaTrackByThread();
 	}
 
 	@Override
 	public Map getQuerySubstitutions() {
 		return options.getQuerySubstitutions();
 	}
 
 	@Override
 	public boolean isStrictJpaQueryLanguageCompliance() {
 		return options.isStrictJpaQueryLanguageCompliance();
 	}
 
 	@Override
 	public boolean isNamedQueryStartupCheckingEnabled() {
 		return options.isNamedQueryStartupCheckingEnabled();
 	}
 
 	@Override
 	public boolean isSecondLevelCacheEnabled() {
 		return options.isSecondLevelCacheEnabled();
 	}
 
 	@Override
 	public boolean isQueryCacheEnabled() {
 		return options.isQueryCacheEnabled();
 	}
 
 	@Override
 	public QueryCacheFactory getQueryCacheFactory() {
 		return options.getQueryCacheFactory();
 	}
 
 	@Override
 	public String getCacheRegionPrefix() {
 		return options.getCacheRegionPrefix();
 	}
 
 	@Override
 	public boolean isMinimalPutsEnabled() {
 		return options.isMinimalPutsEnabled();
 	}
 
 	@Override
 	public boolean isStructuredCacheEntriesEnabled() {
 		return options.isStructuredCacheEntriesEnabled();
 	}
 
 	@Override
 	public boolean isDirectReferenceCacheEntriesEnabled() {
 		return options.isDirectReferenceCacheEntriesEnabled();
 	}
 
 	@Override
 	public boolean isAutoEvictCollectionCache() {
 		return options.isAutoEvictCollectionCache();
 	}
 
 	@Override
 	public SchemaAutoTooling getSchemaAutoTooling() {
 		return options.getSchemaAutoTooling();
 	}
 
 	@Override
 	public int getJdbcBatchSize() {
 		return options.getJdbcBatchSize();
 	}
 
 	@Override
 	public boolean isJdbcBatchVersionedData() {
 		return options.isJdbcBatchVersionedData();
 	}
 
 	@Override
 	public boolean isScrollableResultSetsEnabled() {
 		return options.isScrollableResultSetsEnabled();
 	}
 
 	@Override
 	public boolean isWrapResultSetsEnabled() {
 		return options.isWrapResultSetsEnabled();
 	}
 
 	@Override
 	public boolean isGetGeneratedKeysEnabled() {
 		return options.isGetGeneratedKeysEnabled();
 	}
 
 	@Override
 	public Integer getJdbcFetchSize() {
 		return options.getJdbcFetchSize();
 	}
 
 	@Override
 	public ConnectionReleaseMode getConnectionReleaseMode() {
 		return options.getConnectionReleaseMode();
 	}
 
 	@Override
 	public boolean isCommentsEnabled() {
 		return options.isCommentsEnabled();
 	}
 
 	@Override
 	public CustomEntityDirtinessStrategy getCustomEntityDirtinessStrategy() {
 		return options.getCustomEntityDirtinessStrategy();
 	}
 
 	@Override
 	public EntityNameResolver[] getEntityNameResolvers() {
 		return options.getEntityNameResolvers();
 	}
 
 	@Override
 	public EntityNotFoundDelegate getEntityNotFoundDelegate() {
 		return options.getEntityNotFoundDelegate();
 	}
 
 	@Override
 	public Map<String, SQLFunction> getCustomSqlFunctionMap() {
 		return options.getCustomSqlFunctionMap();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/registry/selector/internal/StrategySelectorBuilder.java b/hibernate-core/src/main/java/org/hibernate/boot/registry/selector/internal/StrategySelectorBuilder.java
index df301da11c..a9dc423580 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/registry/selector/internal/StrategySelectorBuilder.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/registry/selector/internal/StrategySelectorBuilder.java
@@ -1,404 +1,400 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.registry.selector.internal;
 
 import java.util.ArrayList;
 import java.util.List;
 
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.boot.registry.selector.SimpleStrategyRegistrationImpl;
 import org.hibernate.boot.registry.selector.StrategyRegistration;
 import org.hibernate.boot.registry.selector.StrategyRegistrationProvider;
 import org.hibernate.boot.registry.selector.spi.StrategySelectionException;
 import org.hibernate.boot.registry.selector.spi.StrategySelector;
 import org.hibernate.dialect.CUBRIDDialect;
 import org.hibernate.dialect.Cache71Dialect;
 import org.hibernate.dialect.DB2390Dialect;
 import org.hibernate.dialect.DB2400Dialect;
 import org.hibernate.dialect.DB2Dialect;
 import org.hibernate.dialect.DerbyTenFiveDialect;
 import org.hibernate.dialect.DerbyTenSevenDialect;
 import org.hibernate.dialect.DerbyTenSixDialect;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.FirebirdDialect;
 import org.hibernate.dialect.FrontBaseDialect;
 import org.hibernate.dialect.H2Dialect;
 import org.hibernate.dialect.HSQLDialect;
 import org.hibernate.dialect.InformixDialect;
 import org.hibernate.dialect.Ingres10Dialect;
 import org.hibernate.dialect.Ingres9Dialect;
 import org.hibernate.dialect.IngresDialect;
 import org.hibernate.dialect.InterbaseDialect;
 import org.hibernate.dialect.JDataStoreDialect;
 import org.hibernate.dialect.MckoiDialect;
 import org.hibernate.dialect.MimerSQLDialect;
 import org.hibernate.dialect.MySQL5Dialect;
 import org.hibernate.dialect.MySQL5InnoDBDialect;
 import org.hibernate.dialect.Oracle10gDialect;
 import org.hibernate.dialect.Oracle8iDialect;
 import org.hibernate.dialect.Oracle9iDialect;
 import org.hibernate.dialect.PointbaseDialect;
 import org.hibernate.dialect.PostgreSQL81Dialect;
 import org.hibernate.dialect.PostgreSQL82Dialect;
 import org.hibernate.dialect.PostgreSQL9Dialect;
 import org.hibernate.dialect.PostgresPlusDialect;
 import org.hibernate.dialect.ProgressDialect;
 import org.hibernate.dialect.SAPDBDialect;
 import org.hibernate.dialect.SQLServer2005Dialect;
 import org.hibernate.dialect.SQLServer2008Dialect;
 import org.hibernate.dialect.SQLServerDialect;
 import org.hibernate.dialect.Sybase11Dialect;
 import org.hibernate.dialect.SybaseASE157Dialect;
 import org.hibernate.dialect.SybaseASE15Dialect;
 import org.hibernate.dialect.SybaseAnywhereDialect;
 import org.hibernate.dialect.TeradataDialect;
 import org.hibernate.dialect.TimesTenDialect;
-import org.hibernate.engine.transaction.internal.jdbc.JdbcTransactionFactory;
-import org.hibernate.engine.transaction.internal.jta.CMTTransactionFactory;
-import org.hibernate.engine.transaction.internal.jta.JtaTransactionFactory;
 import org.hibernate.engine.transaction.jta.platform.internal.BitronixJtaPlatform;
 import org.hibernate.engine.transaction.jta.platform.internal.BorlandEnterpriseServerJtaPlatform;
 import org.hibernate.engine.transaction.jta.platform.internal.JBossAppServerJtaPlatform;
 import org.hibernate.engine.transaction.jta.platform.internal.JBossStandAloneJtaPlatform;
 import org.hibernate.engine.transaction.jta.platform.internal.JOTMJtaPlatform;
 import org.hibernate.engine.transaction.jta.platform.internal.JOnASJtaPlatform;
 import org.hibernate.engine.transaction.jta.platform.internal.JRun4JtaPlatform;
 import org.hibernate.engine.transaction.jta.platform.internal.OC4JJtaPlatform;
 import org.hibernate.engine.transaction.jta.platform.internal.OrionJtaPlatform;
 import org.hibernate.engine.transaction.jta.platform.internal.ResinJtaPlatform;
 import org.hibernate.engine.transaction.jta.platform.internal.SunOneJtaPlatform;
 import org.hibernate.engine.transaction.jta.platform.internal.WebSphereExtendedJtaPlatform;
 import org.hibernate.engine.transaction.jta.platform.internal.WebSphereJtaPlatform;
 import org.hibernate.engine.transaction.jta.platform.internal.WeblogicJtaPlatform;
 import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
-import org.hibernate.engine.transaction.spi.TransactionFactory;
 import org.hibernate.event.internal.EntityCopyAllowedLoggedObserver;
 import org.hibernate.event.internal.EntityCopyAllowedObserver;
 import org.hibernate.event.internal.EntityCopyNotAllowedObserver;
 import org.hibernate.event.spi.EntityCopyObserver;
 import org.hibernate.hql.spi.id.global.GlobalTemporaryTableBulkIdStrategy;
 import org.hibernate.hql.spi.id.local.LocalTemporaryTableBulkIdStrategy;
 import org.hibernate.hql.spi.id.MultiTableBulkIdStrategy;
 import org.hibernate.hql.spi.id.persistent.PersistentTableBulkIdStrategy;
 
 import org.jboss.logging.Logger;
 
 /**
  * Builder for StrategySelector instances.
  *
  * @author Steve Ebersole
  */
 public class StrategySelectorBuilder {
 	private static final Logger log = Logger.getLogger( StrategySelectorBuilder.class );
 
 	private final List<StrategyRegistration> explicitStrategyRegistrations = new ArrayList<StrategyRegistration>();
 
 	/**
 	 * Adds an explicit (as opposed to discovered) strategy registration.
 	 *
 	 * @param strategy The strategy
 	 * @param implementation The strategy implementation
 	 * @param name The registered name
 	 * @param <T> The type of the strategy.  Used to make sure that the strategy and implementation are type
 	 * compatible.
 	 */
 	@SuppressWarnings("unchecked")
 	public <T> void addExplicitStrategyRegistration(Class<T> strategy, Class<? extends T> implementation, String name) {
 		addExplicitStrategyRegistration( new SimpleStrategyRegistrationImpl<T>( strategy, implementation, name ) );
 	}
 
 	/**
 	 * Adds an explicit (as opposed to discovered) strategy registration.
 	 *
 	 * @param strategyRegistration The strategy implementation registration.
 	 * @param <T> The type of the strategy.  Used to make sure that the strategy and implementation are type
 	 * compatible.
 	 */
 	public <T> void addExplicitStrategyRegistration(StrategyRegistration<T> strategyRegistration) {
 		if ( !strategyRegistration.getStrategyRole().isInterface() ) {
 			// not good form...
 			log.debug( "Registering non-interface strategy : " + strategyRegistration.getStrategyRole().getName()  );
 		}
 
 		if ( ! strategyRegistration.getStrategyRole().isAssignableFrom( strategyRegistration.getStrategyImplementation() ) ) {
 			throw new StrategySelectionException(
 					"Implementation class [" + strategyRegistration.getStrategyImplementation().getName()
 							+ "] does not implement strategy interface ["
 							+ strategyRegistration.getStrategyRole().getName() + "]"
 			);
 		}
 		explicitStrategyRegistrations.add( strategyRegistration );
 	}
 
 	/**
 	 * Builds the selector.
 	 *
 	 * @param classLoaderService The class loading service used to (attempt to) resolve any un-registered
 	 * strategy implementations.
 	 *
 	 * @return The selector.
 	 */
 	public StrategySelector buildSelector(ClassLoaderService classLoaderService) {
 		final StrategySelectorImpl strategySelector = new StrategySelectorImpl( classLoaderService );
 
 		// build the baseline...
 		addDialects( strategySelector );
 		addJtaPlatforms( strategySelector );
-		addTransactionFactories( strategySelector );
+//		addTransactionFactories( strategySelector );
 		addMultiTableBulkIdStrategies( strategySelector );
 		addEntityCopyObserverStrategies( strategySelector );
 
 		// apply auto-discovered registrations
 		for ( StrategyRegistrationProvider provider : classLoaderService.loadJavaServices( StrategyRegistrationProvider.class ) ) {
 			for ( StrategyRegistration discoveredStrategyRegistration : provider.getStrategyRegistrations() ) {
 				applyFromStrategyRegistration( strategySelector, discoveredStrategyRegistration );
 			}
 		}
 
 		// apply customizations
 		for ( StrategyRegistration explicitStrategyRegistration : explicitStrategyRegistrations ) {
 			applyFromStrategyRegistration( strategySelector, explicitStrategyRegistration );
 		}
 
 		return strategySelector;
 	}
 
 	@SuppressWarnings("unchecked")
 	private <T> void applyFromStrategyRegistration(StrategySelectorImpl strategySelector, StrategyRegistration<T> strategyRegistration) {
 		for ( String name : strategyRegistration.getSelectorNames() ) {
 			strategySelector.registerStrategyImplementor(
 					strategyRegistration.getStrategyRole(),
 					name,
 					strategyRegistration.getStrategyImplementation()
 			);
 		}
 	}
 
 	private void addDialects(StrategySelectorImpl strategySelector) {
 		addDialect( strategySelector, Cache71Dialect.class );
 		addDialect( strategySelector, CUBRIDDialect.class );
 		addDialect( strategySelector, DB2Dialect.class );
 		addDialect( strategySelector, DB2390Dialect.class );
 		addDialect( strategySelector, DB2400Dialect.class );
 		addDialect( strategySelector, DerbyTenFiveDialect.class );
 		addDialect( strategySelector, DerbyTenSixDialect.class );
 		addDialect( strategySelector, DerbyTenSevenDialect.class );
 		addDialect( strategySelector, FirebirdDialect.class );
 		addDialect( strategySelector, FrontBaseDialect.class );
 		addDialect( strategySelector, H2Dialect.class );
 		addDialect( strategySelector, HSQLDialect.class );
 		addDialect( strategySelector, InformixDialect.class );
 		addDialect( strategySelector, IngresDialect.class );
 		addDialect( strategySelector, Ingres9Dialect.class );
 		addDialect( strategySelector, Ingres10Dialect.class );
 		addDialect( strategySelector, InterbaseDialect.class );
 		addDialect( strategySelector, JDataStoreDialect.class );
 		addDialect( strategySelector, MckoiDialect.class );
 		addDialect( strategySelector, MimerSQLDialect.class );
 		addDialect( strategySelector, MySQL5Dialect.class );
 		addDialect( strategySelector, MySQL5InnoDBDialect.class );
 		addDialect( strategySelector, MySQL5Dialect.class );
 		addDialect( strategySelector, MySQL5InnoDBDialect.class );
 		addDialect( strategySelector, Oracle8iDialect.class );
 		addDialect( strategySelector, Oracle9iDialect.class );
 		addDialect( strategySelector, Oracle10gDialect.class );
 		addDialect( strategySelector, PointbaseDialect.class );
 		addDialect( strategySelector, PostgresPlusDialect.class );
 		addDialect( strategySelector, PostgreSQL81Dialect.class );
 		addDialect( strategySelector, PostgreSQL82Dialect.class );
 		addDialect( strategySelector, PostgreSQL9Dialect.class );
 		addDialect( strategySelector, ProgressDialect.class );
 		addDialect( strategySelector, SAPDBDialect.class );
 		addDialect( strategySelector, SQLServerDialect.class );
 		addDialect( strategySelector, SQLServer2005Dialect.class );
 		addDialect( strategySelector, SQLServer2008Dialect.class );
 		addDialect( strategySelector, Sybase11Dialect.class );
 		addDialect( strategySelector, SybaseAnywhereDialect.class );
 		addDialect( strategySelector, SybaseASE15Dialect.class );
 		addDialect( strategySelector, SybaseASE157Dialect.class );
 		addDialect( strategySelector, TeradataDialect.class );
 		addDialect( strategySelector, TimesTenDialect.class );
 	}
 
 	private void addDialect(StrategySelectorImpl strategySelector, Class<? extends Dialect> dialectClass) {
 		String simpleName = dialectClass.getSimpleName();
 		if ( simpleName.endsWith( "Dialect" ) ) {
 			simpleName = simpleName.substring( 0, simpleName.length() - "Dialect".length() );
 		}
 		strategySelector.registerStrategyImplementor( Dialect.class, simpleName, dialectClass );
 	}
 
 	private void addJtaPlatforms(StrategySelectorImpl strategySelector) {
 		addJtaPlatforms(
 				strategySelector,
 				BorlandEnterpriseServerJtaPlatform.class,
 				"Borland",
 				"org.hibernate.service.jta.platform.internal.BorlandEnterpriseServerJtaPlatform"
 		);
 
 		addJtaPlatforms(
 				strategySelector,
 				BitronixJtaPlatform.class,
 				"Bitronix",
 				"org.hibernate.service.jta.platform.internal.BitronixJtaPlatform"
 		);
 
 		addJtaPlatforms(
 				strategySelector,
 				JBossAppServerJtaPlatform.class,
 				"JBossAS",
 				"org.hibernate.service.jta.platform.internal.JBossAppServerJtaPlatform"
 		);
 
 		addJtaPlatforms(
 				strategySelector,
 				JBossStandAloneJtaPlatform.class,
 				"JBossTS",
 				"org.hibernate.service.jta.platform.internal.JBossStandAloneJtaPlatform"
 		);
 
 		addJtaPlatforms(
 				strategySelector,
 				JOnASJtaPlatform.class,
 				"JOnAS",
 				"org.hibernate.service.jta.platform.internal.JOnASJtaPlatform"
 		);
 
 		addJtaPlatforms(
 				strategySelector,
 				JOTMJtaPlatform.class,
 				"JOTM",
 				"org.hibernate.service.jta.platform.internal.JOTMJtaPlatform"
 		);
 
 		addJtaPlatforms(
 				strategySelector,
 				JRun4JtaPlatform.class,
 				"JRun4",
 				"org.hibernate.service.jta.platform.internal.JRun4JtaPlatform"
 		);
 
 		addJtaPlatforms(
 				strategySelector,
 				OC4JJtaPlatform.class,
 				"OC4J",
 				"org.hibernate.service.jta.platform.internal.OC4JJtaPlatform"
 		);
 
 		addJtaPlatforms(
 				strategySelector,
 				OrionJtaPlatform.class,
 				"Orion",
 				"org.hibernate.service.jta.platform.internal.OrionJtaPlatform"
 		);
 
 		addJtaPlatforms(
 				strategySelector,
 				ResinJtaPlatform.class,
 				"Resin",
 				"org.hibernate.service.jta.platform.internal.ResinJtaPlatform"
 		);
 
 		addJtaPlatforms(
 				strategySelector,
 				SunOneJtaPlatform.class,
 				"SunOne",
 				"org.hibernate.service.jta.platform.internal.SunOneJtaPlatform"
 		);
 
 		addJtaPlatforms(
 				strategySelector,
 				WeblogicJtaPlatform.class,
 				"Weblogic",
 				"org.hibernate.service.jta.platform.internal.WeblogicJtaPlatform"
 		);
 
 		addJtaPlatforms(
 				strategySelector,
 				WebSphereJtaPlatform.class,
 				"WebSphere",
 				"org.hibernate.service.jta.platform.internal.WebSphereJtaPlatform"
 		);
 
 		addJtaPlatforms(
 				strategySelector,
 				WebSphereExtendedJtaPlatform.class,
 				"WebSphereExtended",
 				"org.hibernate.service.jta.platform.internal.WebSphereExtendedJtaPlatform"
 		);
 	}
 
 	private void addJtaPlatforms(StrategySelectorImpl strategySelector, Class<? extends JtaPlatform> impl, String... names) {
 		for ( String name : names ) {
 			strategySelector.registerStrategyImplementor( JtaPlatform.class, name, impl );
 		}
 	}
 
-	private void addTransactionFactories(StrategySelectorImpl strategySelector) {
-		strategySelector.registerStrategyImplementor( TransactionFactory.class, JdbcTransactionFactory.SHORT_NAME, JdbcTransactionFactory.class );
-		strategySelector.registerStrategyImplementor( TransactionFactory.class, "org.hibernate.transaction.JDBCTransactionFactory", JdbcTransactionFactory.class );
-
-		strategySelector.registerStrategyImplementor( TransactionFactory.class, JtaTransactionFactory.SHORT_NAME, JtaTransactionFactory.class );
-		strategySelector.registerStrategyImplementor( TransactionFactory.class, "org.hibernate.transaction.JTATransactionFactory", JtaTransactionFactory.class );
-
-		strategySelector.registerStrategyImplementor( TransactionFactory.class, CMTTransactionFactory.SHORT_NAME, CMTTransactionFactory.class );
-		strategySelector.registerStrategyImplementor( TransactionFactory.class, "org.hibernate.transaction.CMTTransactionFactory", CMTTransactionFactory.class );
-	}
+//	private void addTransactionFactories(StrategySelectorImpl strategySelector) {
+//		strategySelector.registerStrategyImplementor( TransactionFactory.class, JdbcTransactionFactory.SHORT_NAME, JdbcTransactionFactory.class );
+//		strategySelector.registerStrategyImplementor( TransactionFactory.class, "org.hibernate.transaction.JDBCTransactionFactory", JdbcTransactionFactory.class );
+//
+//		strategySelector.registerStrategyImplementor( TransactionFactory.class, JtaTransactionFactory.SHORT_NAME, JtaTransactionFactory.class );
+//		strategySelector.registerStrategyImplementor( TransactionFactory.class, "org.hibernate.transaction.JTATransactionFactory", JtaTransactionFactory.class );
+//
+//		strategySelector.registerStrategyImplementor( TransactionFactory.class, CMTTransactionFactory.SHORT_NAME, CMTTransactionFactory.class );
+//		strategySelector.registerStrategyImplementor( TransactionFactory.class, "org.hibernate.transaction.CMTTransactionFactory", CMTTransactionFactory.class );
+//	}
 
 	private void addMultiTableBulkIdStrategies(StrategySelectorImpl strategySelector) {
 		strategySelector.registerStrategyImplementor(
 				MultiTableBulkIdStrategy.class,
 				PersistentTableBulkIdStrategy.SHORT_NAME,
 				PersistentTableBulkIdStrategy.class
 		);
 		strategySelector.registerStrategyImplementor(
 				MultiTableBulkIdStrategy.class,
 				GlobalTemporaryTableBulkIdStrategy.SHORT_NAME,
 				GlobalTemporaryTableBulkIdStrategy.class
 		);
 		strategySelector.registerStrategyImplementor(
 				MultiTableBulkIdStrategy.class,
 				LocalTemporaryTableBulkIdStrategy.SHORT_NAME,
 				LocalTemporaryTableBulkIdStrategy.class
 		);
 	}
 
 	private void addEntityCopyObserverStrategies(StrategySelectorImpl strategySelector) {
 		strategySelector.registerStrategyImplementor(
 				EntityCopyObserver.class,
 				EntityCopyNotAllowedObserver.SHORT_NAME,
 				EntityCopyNotAllowedObserver.class
 		);
 		strategySelector.registerStrategyImplementor(
 				EntityCopyObserver.class,
 				EntityCopyAllowedObserver.SHORT_NAME,
 				EntityCopyAllowedObserver.class
 		);
 		strategySelector.registerStrategyImplementor(
 				EntityCopyObserver.class,
 				EntityCopyAllowedLoggedObserver.SHORT_NAME,
 				EntityCopyAllowedLoggedObserver.class
 		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/boot/spi/SessionFactoryOptions.java b/hibernate-core/src/main/java/org/hibernate/boot/spi/SessionFactoryOptions.java
index 11d741e597..a8daf310a1 100644
--- a/hibernate-core/src/main/java/org/hibernate/boot/spi/SessionFactoryOptions.java
+++ b/hibernate-core/src/main/java/org/hibernate/boot/spi/SessionFactoryOptions.java
@@ -1,186 +1,188 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.boot.spi;
 
 import java.util.Map;
 
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.CustomEntityDirtinessStrategy;
 import org.hibernate.EntityMode;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.Interceptor;
 import org.hibernate.MultiTenancyStrategy;
 import org.hibernate.NullPrecedence;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.boot.SchemaAutoTooling;
 import org.hibernate.boot.TempTableDdlTransactionHandling;
 import org.hibernate.boot.registry.StandardServiceRegistry;
 import org.hibernate.cache.spi.QueryCacheFactory;
 import org.hibernate.cfg.BaselineSessionEventsListenerBuilder;
 import org.hibernate.context.spi.CurrentTenantIdentifierResolver;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.hql.spi.id.MultiTableBulkIdStrategy;
 import org.hibernate.loader.BatchFetchStyle;
 import org.hibernate.proxy.EntityNotFoundDelegate;
 import org.hibernate.tuple.entity.EntityTuplizerFactory;
 
 /**
  * Aggregator of special options used to build the SessionFactory.
  *
  * @since 5.0
  */
 public interface SessionFactoryOptions {
 	/**
 	 * The service registry to use in building the factory.
 	 *
 	 * @return The service registry to use.
 	 */
 	public StandardServiceRegistry getServiceRegistry();
 
 	public Object getBeanManagerReference();
 
 	public Object getValidatorFactoryReference();
 
 	/**
 	 * The name to be used for the SessionFactory.  This is use both in:<ul>
 	 *     <li>in-VM serialization</li>
 	 *     <li>JNDI binding, depending on {@link #isSessionFactoryNameAlsoJndiName}</li>
 	 * </ul>
 	 *
 	 * @return The SessionFactory name
 	 */
 	public String getSessionFactoryName();
 
 	/**
 	 * Is the {@link #getSessionFactoryName SesssionFactory name} also a JNDI name, indicating we
 	 * should bind it into JNDI?
 	 *
 	 * @return {@code true} if the SessionFactory name is also a JNDI name; {@code false} otherwise.
 	 */
 	public boolean isSessionFactoryNameAlsoJndiName();
 
 	public boolean isFlushBeforeCompletionEnabled();
 
 	public boolean isAutoCloseSessionEnabled();
 
 	public boolean isStatisticsEnabled();
 
 	/**
 	 * Get the interceptor to use by default for all sessions opened from this factory.
 	 *
 	 * @return The interceptor to use factory wide.  May be {@code null}
 	 */
 	public Interceptor getInterceptor();
 
 	public SessionFactoryObserver[] getSessionFactoryObservers();
 
 	public BaselineSessionEventsListenerBuilder getBaselineSessionEventsListenerBuilder();
 
 	public boolean isIdentifierRollbackEnabled();
 
 	public EntityMode getDefaultEntityMode();
 
 	public EntityTuplizerFactory getEntityTuplizerFactory();
 
 	public boolean isCheckNullability();
 
 	public boolean isInitializeLazyStateOutsideTransactionsEnabled();
 
 	public MultiTableBulkIdStrategy getMultiTableBulkIdStrategy();
 
 	public TempTableDdlTransactionHandling getTempTableDdlTransactionHandling();
 
 	public BatchFetchStyle getBatchFetchStyle();
 
 	public int getDefaultBatchFetchSize();
 
 	public Integer getMaximumFetchDepth();
 
 	public NullPrecedence getDefaultNullPrecedence();
 
 	public boolean isOrderUpdatesEnabled();
 
 	public boolean isOrderInsertsEnabled();
 
 	public MultiTenancyStrategy getMultiTenancyStrategy();
 
 	public CurrentTenantIdentifierResolver getCurrentTenantIdentifierResolver();
 
 	public boolean isJtaTrackByThread();
 
 	public Map getQuerySubstitutions();
 
 	public boolean isStrictJpaQueryLanguageCompliance();
 
 	public boolean isNamedQueryStartupCheckingEnabled();
 
 	public boolean isSecondLevelCacheEnabled();
 
 	public boolean isQueryCacheEnabled();
 
 	public QueryCacheFactory getQueryCacheFactory();
 
 	public String getCacheRegionPrefix();
 
 	public boolean isMinimalPutsEnabled();
 
 	public boolean isStructuredCacheEntriesEnabled();
 
 	public boolean isDirectReferenceCacheEntriesEnabled();
 
 	public boolean isAutoEvictCollectionCache();
 
 	public SchemaAutoTooling getSchemaAutoTooling();
 
 	public int getJdbcBatchSize();
 
 	public boolean isJdbcBatchVersionedData();
 
 	public boolean isScrollableResultSetsEnabled();
 
 	public boolean isWrapResultSetsEnabled();
 
 	public boolean isGetGeneratedKeysEnabled();
 
 	public Integer getJdbcFetchSize();
 
 	public ConnectionReleaseMode getConnectionReleaseMode();
 
 	public boolean isCommentsEnabled();
 
 
 	public CustomEntityDirtinessStrategy getCustomEntityDirtinessStrategy();
 	public EntityNameResolver[] getEntityNameResolvers();
 
 	/**
 	 * Get the delegate for handling entity-not-found exception conditions.
 	 *
 	 * @return The specific EntityNotFoundDelegate to use,  May be {@code null}
 	 */
 	public EntityNotFoundDelegate getEntityNotFoundDelegate();
 
 	public Map<String, SQLFunction> getCustomSqlFunctionMap();
 
 	void setCheckNullability(boolean enabled);
+
+	public boolean isPreferUserTransaction();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/AvailableSettings.java b/hibernate-core/src/main/java/org/hibernate/cfg/AvailableSettings.java
index 44e3a0266f..564b8c0018 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/AvailableSettings.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/AvailableSettings.java
@@ -1,810 +1,819 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 /**
  * @author Steve Ebersole
  */
 public interface AvailableSettings {
 	/**
 	 * Setting used to name the Hibernate {@link org.hibernate.SessionFactory}.
 	 *
 	 * Naming the SessionFactory allows for it to be properly serialized across JVMs as
 	 * long as the same name is used on each JVM.
 	 *
 	 * If {@link #SESSION_FACTORY_NAME_IS_JNDI} is set to {@code true}, this is also the
 	 * name under which the SessionFactory is bound into JNDI on startup and from which
 	 * it can be obtained from JNDI.
 	 *
 	 * @see #SESSION_FACTORY_NAME_IS_JNDI
 	 * @see org.hibernate.internal.SessionFactoryRegistry
 	 */
 	 String SESSION_FACTORY_NAME = "hibernate.session_factory_name";
 
 	/**
 	 * Does the value defined by {@link #SESSION_FACTORY_NAME} represent a JNDI namespace into which
 	 * the {@link org.hibernate.SessionFactory} should be bound and made accessible?
 	 *
 	 * Defaults to {@code true} for backwards compatibility.
 	 *
 	 * Set this to {@code false} if naming a SessionFactory is needed for serialization purposes, but
 	 * no writable JNDI context exists in the runtime environment or if the user simply does not want
 	 * JNDI to be used.
 	 *
 	 * @see #SESSION_FACTORY_NAME
 	 */
 	String SESSION_FACTORY_NAME_IS_JNDI = "hibernate.session_factory_name_is_jndi";
 
 	/**
 	 * Names the {@link org.hibernate.engine.jdbc.connections.spi.ConnectionProvider} to use for obtaining
 	 * JDBC connections.  Can either reference an instance of
 	 * {@link org.hibernate.engine.jdbc.connections.spi.ConnectionProvider} or a {@link Class} or {@link String}
 	 * reference to the {@link org.hibernate.engine.jdbc.connections.spi.ConnectionProvider} implementation
 	 * class.
 	 */
 	String CONNECTION_PROVIDER ="hibernate.connection.provider_class";
 
 	/**
 	 * Names the {@literal JDBC} driver class
 	 */
 	String DRIVER ="hibernate.connection.driver_class";
 
 	/**
 	 * Names the {@literal JDBC} connection url.
 	 */
 	String URL ="hibernate.connection.url";
 
 	/**
 	 * Names the connection user.  This might mean one of 2 things in out-of-the-box Hibernate
 	 * {@link org.hibernate.engine.jdbc.connections.spi.ConnectionProvider}: <ul>
 	 *     <li>The username used to pass along to creating the JDBC connection</li>
 	 *     <li>The username used to obtain a JDBC connection from a data source</li>
 	 * </ul>
 	 */
 	String USER ="hibernate.connection.username";
 
 	/**
 	 * Names the connection password.  See usage discussion on {@link #USER}
 	 */
 	String PASS ="hibernate.connection.password";
 
 	/**
 	 * Names the {@literal JDBC} transaction isolation level
 	 */
 	String ISOLATION ="hibernate.connection.isolation";
 
 	/**
 	 * Names the {@literal JDBC} autocommit mode
 	 */
 	String AUTOCOMMIT ="hibernate.connection.autocommit";
 
 	/**
 	 * Maximum number of inactive connections for the built-in Hibernate connection pool.
 	 */
 	String POOL_SIZE ="hibernate.connection.pool_size";
 
 	/**
 	 * Names a {@link javax.sql.DataSource}.  Can either reference a {@link javax.sql.DataSource} instance or
 	 * a {@literal JNDI} name under which to locate the {@link javax.sql.DataSource}.
 	 */
 	String DATASOURCE ="hibernate.connection.datasource";
 
 	/**
 	 * Names a prefix used to define arbitrary JDBC connection properties.  These properties are passed along to
 	 * the {@literal JDBC} provider when creating a connection.
 	 */
 	String CONNECTION_PREFIX = "hibernate.connection";
 
 	/**
 	 * Names the {@literal JNDI} {@link javax.naming.InitialContext} class.
 	 *
 	 * @see javax.naming.Context#INITIAL_CONTEXT_FACTORY
 	 */
 	String JNDI_CLASS ="hibernate.jndi.class";
 
 	/**
 	 * Names the {@literal JNDI} provider/connection url
 	 *
 	 * @see javax.naming.Context#PROVIDER_URL
 	 */
 	String JNDI_URL ="hibernate.jndi.url";
 
 	/**
 	 * Names a prefix used to define arbitrary {@literal JNDI} {@link javax.naming.InitialContext} properties.  These
 	 * properties are passed along to {@link javax.naming.InitialContext#InitialContext(java.util.Hashtable)}
 	 */
 	String JNDI_PREFIX = "hibernate.jndi";
 
 	/**
 	 * Names the Hibernate {@literal SQL} {@link org.hibernate.dialect.Dialect} class
 	 */
 	String DIALECT ="hibernate.dialect";
 
 	/**
 	 * Names any additional {@link org.hibernate.engine.jdbc.dialect.spi.DialectResolver} implementations to
 	 * register with the standard {@link org.hibernate.engine.jdbc.dialect.spi.DialectFactory}.
 	 */
 	String DIALECT_RESOLVERS = "hibernate.dialect_resolvers";
 
 
 	/**
 	 * A default database schema (owner) name to use for unqualified tablenames
 	 */
 	String DEFAULT_SCHEMA = "hibernate.default_schema";
 	/**
 	 * A default database catalog name to use for unqualified tablenames
 	 */
 	String DEFAULT_CATALOG = "hibernate.default_catalog";
 
 	/**
 	 * Enable logging of generated SQL to the console
 	 */
 	String SHOW_SQL ="hibernate.show_sql";
 	/**
 	 * Enable formatting of SQL logged to the console
 	 */
 	String FORMAT_SQL ="hibernate.format_sql";
 	/**
 	 * Add comments to the generated SQL
 	 */
 	String USE_SQL_COMMENTS ="hibernate.use_sql_comments";
 	/**
 	 * Maximum depth of outer join fetching
 	 */
 	String MAX_FETCH_DEPTH = "hibernate.max_fetch_depth";
 	/**
 	 * The default batch size for batch fetching
 	 */
 	String DEFAULT_BATCH_FETCH_SIZE = "hibernate.default_batch_fetch_size";
 	/**
 	 * Use <tt>java.io</tt> streams to read / write binary data from / to JDBC
 	 */
 	String USE_STREAMS_FOR_BINARY = "hibernate.jdbc.use_streams_for_binary";
 	/**
 	 * Use JDBC scrollable <tt>ResultSet</tt>s. This property is only necessary when there is
 	 * no <tt>ConnectionProvider</tt>, ie. the user is supplying JDBC connections.
 	 */
 	String USE_SCROLLABLE_RESULTSET = "hibernate.jdbc.use_scrollable_resultset";
 	/**
 	 * Tells the JDBC driver to attempt to retrieve row Id with the JDBC 3.0 PreparedStatement.getGeneratedKeys()
 	 * method. In general, performance will be better if this property is set to true and the underlying
 	 * JDBC driver supports getGeneratedKeys().
 	 */
 	String USE_GET_GENERATED_KEYS = "hibernate.jdbc.use_get_generated_keys";
 	/**
 	 * Gives the JDBC driver a hint as to the number of rows that should be fetched from the database
 	 * when more rows are needed. If <tt>0</tt>, JDBC driver default settings will be used.
 	 */
 	String STATEMENT_FETCH_SIZE = "hibernate.jdbc.fetch_size";
 	/**
 	 * Maximum JDBC batch size. A nonzero value enables batch updates.
 	 */
 	String STATEMENT_BATCH_SIZE = "hibernate.jdbc.batch_size";
 	/**
 	 * Select a custom batcher.
 	 */
 	String BATCH_STRATEGY = "hibernate.jdbc.factory_class";
 	/**
 	 * Should versioned data be included in batching?
 	 */
 	String BATCH_VERSIONED_DATA = "hibernate.jdbc.batch_versioned_data";
 	/**
 	 * An XSLT resource used to generate "custom" XML
 	 */
 	String OUTPUT_STYLESHEET ="hibernate.xml.output_stylesheet";
 
 	/**
 	 * Maximum size of C3P0 connection pool
 	 */
 	String C3P0_MAX_SIZE = "hibernate.c3p0.max_size";
 	/**
 	 * Minimum size of C3P0 connection pool
 	 */
 	String C3P0_MIN_SIZE = "hibernate.c3p0.min_size";
 
 	/**
 	 * Maximum idle time for C3P0 connection pool
 	 */
 	String C3P0_TIMEOUT = "hibernate.c3p0.timeout";
 	/**
 	 * Maximum size of C3P0 statement cache
 	 */
 	String C3P0_MAX_STATEMENTS = "hibernate.c3p0.max_statements";
 	/**
 	 * Number of connections acquired when pool is exhausted
 	 */
 	String C3P0_ACQUIRE_INCREMENT = "hibernate.c3p0.acquire_increment";
 	/**
 	 * Idle time before a C3P0 pooled connection is validated
 	 */
 	String C3P0_IDLE_TEST_PERIOD = "hibernate.c3p0.idle_test_period";
 
 	/**
 	 * Proxool/Hibernate property prefix
 	 * @deprecated Use {@link #PROXOOL_CONFIG_PREFIX} instead
 	 */
 	String PROXOOL_PREFIX = "hibernate.proxool";
 	/**
 	 * Proxool property to configure the Proxool Provider using an XML (<tt>/path/to/file.xml</tt>)
 	 */
 	String PROXOOL_XML = "hibernate.proxool.xml";
 	/**
 	 * Proxool property to configure the Proxool Provider  using a properties file (<tt>/path/to/proxool.properties</tt>)
 	 */
 	String PROXOOL_PROPERTIES = "hibernate.proxool.properties";
 	/**
 	 * Proxool property to configure the Proxool Provider from an already existing pool (<tt>true</tt> / <tt>false</tt>)
 	 */
 	String PROXOOL_EXISTING_POOL = "hibernate.proxool.existing_pool";
 	/**
 	 * Proxool property with the Proxool pool alias to use
 	 * (Required for <tt>PROXOOL_EXISTING_POOL</tt>, <tt>PROXOOL_PROPERTIES</tt>, or
 	 * <tt>PROXOOL_XML</tt>)
 	 */
 	String PROXOOL_POOL_ALIAS = "hibernate.proxool.pool_alias";
 
 	/**
 	 * Enable automatic session close at end of transaction
 	 */
 	String AUTO_CLOSE_SESSION = "hibernate.transaction.auto_close_session";
 	/**
 	 * Enable automatic flush during the JTA <tt>beforeCompletion()</tt> callback
 	 */
 	String FLUSH_BEFORE_COMPLETION = "hibernate.transaction.flush_before_completion";
 	/**
 	 * Specifies how Hibernate should release JDBC connections.
 	 */
 	String RELEASE_CONNECTIONS = "hibernate.connection.release_mode";
 	/**
 	 * Context scoping impl for {@link org.hibernate.SessionFactory#getCurrentSession()} processing.
 	 */
 	String CURRENT_SESSION_CONTEXT_CLASS = "hibernate.current_session_context_class";
 
 	/**
-	 * Names the implementation of {@link org.hibernate.engine.transaction.spi.TransactionFactory} to use for
-	 * creating {@link org.hibernate.Transaction} instances
+	 * Names the implementation of {@link org.hibernate.resource.transaction.TransactionCoordinatorBuilder} to use for
+	 * creating {@link org.hibernate.resource.transaction.TransactionCoordinator} instances
 	 */
-	String TRANSACTION_STRATEGY = "hibernate.transaction.factory_class";
+	String TRANSACTION_COORDINATOR_STRATEGY = "hibernate.transaction.coordinator_class";
 
 	/**
 	 * Names the {@link org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform} implementation to use for integrating
 	 * with {@literal JTA} systems.  Can reference either a {@link org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform}
 	 * instance or the name of the {@link org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform} implementation class
 	 * @since 4.0
 	 */
 	String JTA_PLATFORM = "hibernate.transaction.jta.platform";
 
 	/**
 	 * Names the {@link org.hibernate.engine.transaction.jta.platform.spi.JtaPlatformResolver} implementation to use.
 	 * @since 4.3
 	 */
 	String JTA_PLATFORM_RESOLVER = "hibernate.transaction.jta.platform_resolver";
 
 	/**
 	 * The {@link org.hibernate.cache.spi.RegionFactory} implementation class
 	 */
 	String CACHE_REGION_FACTORY = "hibernate.cache.region.factory_class";
 
 	/**
 	 * The <tt>CacheProvider</tt> implementation class
 	 */
 	String CACHE_PROVIDER_CONFIG = "hibernate.cache.provider_configuration_file_resource_path";
 	/**
 	 * The <tt>CacheProvider</tt> JNDI namespace, if pre-bound to JNDI.
 	 */
 	String CACHE_NAMESPACE = "hibernate.cache.jndi";
 	/**
 	 * Enable the query cache (disabled by default)
 	 */
 	String USE_QUERY_CACHE = "hibernate.cache.use_query_cache";
 	/**
 	 * The <tt>QueryCacheFactory</tt> implementation class.
 	 */
 	String QUERY_CACHE_FACTORY = "hibernate.cache.query_cache_factory";
 	/**
 	 * Enable the second-level cache (enabled by default)
 	 */
 	String USE_SECOND_LEVEL_CACHE = "hibernate.cache.use_second_level_cache";
 	/**
 	 * Optimize the cache for minimal puts instead of minimal gets
 	 */
 	String USE_MINIMAL_PUTS = "hibernate.cache.use_minimal_puts";
 	/**
 	 * The <tt>CacheProvider</tt> region name prefix
 	 */
 	String CACHE_REGION_PREFIX = "hibernate.cache.region_prefix";
 	/**
 	 * Enable use of structured second-level cache entries
 	 */
 	String USE_STRUCTURED_CACHE = "hibernate.cache.use_structured_entries";
 	/**
 	 * Enables the automatic eviction of a bi-directional association's collection cache when an element in the
 	 * ManyToOne collection is added/updated/removed without properly managing the change on the OneToMany side.
 	 */
 	String AUTO_EVICT_COLLECTION_CACHE = "hibernate.cache.auto_evict_collection_cache";
 	/**
 	 * Enable statistics collection
 	 */
 	String GENERATE_STATISTICS = "hibernate.generate_statistics";
 
 	String USE_IDENTIFIER_ROLLBACK = "hibernate.use_identifier_rollback";
 
 	/**
 	 * Use bytecode libraries optimized property access
 	 */
 	String USE_REFLECTION_OPTIMIZER = "hibernate.bytecode.use_reflection_optimizer";
 
 	/**
 	 * The classname of the HQL query parser factory
 	 */
 	String QUERY_TRANSLATOR = "hibernate.query.factory_class";
 
 	/**
 	 * A comma-separated list of token substitutions to use when translating a Hibernate
 	 * query to SQL
 	 */
 	String QUERY_SUBSTITUTIONS = "hibernate.query.substitutions";
 
 	/**
 	 * Should named queries be checked during startup (the default is enabled).
 	 * <p/>
 	 * Mainly intended for test environments.
 	 */
 	String QUERY_STARTUP_CHECKING = "hibernate.query.startup_check";
 
 	/**
 	 * Auto export/update schema using hbm2ddl tool. Valid values are <tt>update</tt>,
 	 * <tt>create</tt>, <tt>create-drop</tt> and <tt>validate</tt>.
 	 */
 	String HBM2DDL_AUTO = "hibernate.hbm2ddl.auto";
 
 	/**
 	 * Comma-separated names of the optional files containing SQL DML statements executed
 	 * during the SessionFactory creation.
 	 * File order matters, the statements of a give file are executed before the statements of the
 	 * following files.
 	 *
 	 * These statements are only executed if the schema is created ie if <tt>hibernate.hbm2ddl.auto</tt>
 	 * is set to <tt>create</tt> or <tt>create-drop</tt>.
 	 *
 	 * The default value is <tt>/import.sql</tt>
 	 */
 	String HBM2DDL_IMPORT_FILES = "hibernate.hbm2ddl.import_files";
 
 	/**
 	 * {@link String} reference to {@link org.hibernate.tool.hbm2ddl.ImportSqlCommandExtractor} implementation class.
 	 * Referenced implementation is required to provide non-argument constructor.
 	 *
 	 * The default value is <tt>org.hibernate.tool.hbm2ddl.SingleLineSqlCommandExtractor</tt>.
 	 */
 	String HBM2DDL_IMPORT_FILES_SQL_EXTRACTOR = "hibernate.hbm2ddl.import_files_sql_extractor";
 
 	/**
 	 * The {@link org.hibernate.exception.spi.SQLExceptionConverter} to use for converting SQLExceptions
 	 * to Hibernate's JDBCException hierarchy.  The default is to use the configured
 	 * {@link org.hibernate.dialect.Dialect}'s preferred SQLExceptionConverter.
 	 */
 	String SQL_EXCEPTION_CONVERTER = "hibernate.jdbc.sql_exception_converter";
 
 	/**
 	 * Enable wrapping of JDBC result sets in order to speed up column name lookups for
 	 * broken JDBC drivers
 	 */
 	String WRAP_RESULT_SETS = "hibernate.jdbc.wrap_result_sets";
 
 	/**
 	 * Enable ordering of update statements by primary key value
 	 */
 	String ORDER_UPDATES = "hibernate.order_updates";
 
 	/**
 	 * Enable ordering of insert statements for the purpose of more efficient JDBC batching.
 	 */
 	String ORDER_INSERTS = "hibernate.order_inserts";
 
 	/**
 	 * Default precedence of null values in {@code ORDER BY} clause.  Supported options: {@code none} (default),
 	 * {@code first}, {@code last}.
 	 */
 	String DEFAULT_NULL_ORDERING = "hibernate.order_by.default_null_ordering";
 
 	/**
 	 * The EntityMode in which set the Session opened from the SessionFactory.
 	 */
     String DEFAULT_ENTITY_MODE = "hibernate.default_entity_mode";
 
 	/**
 	 * Should all database identifiers be quoted.
 	 */
 	String GLOBALLY_QUOTED_IDENTIFIERS = "hibernate.globally_quoted_identifiers";
 
 	/**
 	 * Enable nullability checking.
 	 * Raises an exception if a property marked as not-null is null.
 	 * Default to false if Bean Validation is present in the classpath and Hibernate Annotations is used,
 	 * true otherwise.
 	 */
 	String CHECK_NULLABILITY = "hibernate.check_nullability";
 
 
 	String BYTECODE_PROVIDER = "hibernate.bytecode.provider";
 
 	String JPAQL_STRICT_COMPLIANCE= "hibernate.query.jpaql_strict_compliance";
 
 	/**
 	 * When using pooled {@link org.hibernate.id.enhanced.Optimizer optimizers}, prefer interpreting the
 	 * database value as the lower (lo) boundary.  The default is to interpret it as the high boundary.
 	 */
 	String PREFER_POOLED_VALUES_LO = "hibernate.id.optimizer.pooled.prefer_lo";
 
 	/**
 	 * The maximum number of strong references maintained by {@link org.hibernate.engine.query.spi.QueryPlanCache}. Default is 128.
 	 * @deprecated in favor of {@link #QUERY_PLAN_CACHE_PARAMETER_METADATA_MAX_SIZE}
 	 */
 	@Deprecated
 	String QUERY_PLAN_CACHE_MAX_STRONG_REFERENCES = "hibernate.query.plan_cache_max_strong_references";
 
 	/**
 	 * The maximum number of soft references maintained by {@link org.hibernate.engine.query.spi.QueryPlanCache}. Default is 2048.
 	 * @deprecated in favor of {@link #QUERY_PLAN_CACHE_MAX_SIZE}
 	 */
 	@Deprecated
 	String QUERY_PLAN_CACHE_MAX_SOFT_REFERENCES = "hibernate.query.plan_cache_max_soft_references";
 
 	/**
 	 * The maximum number of entries including:
 	 * <ul>
 	 *     <li>{@link org.hibernate.engine.query.spi.HQLQueryPlan}</li>
 	 *     <li>{@link org.hibernate.engine.query.spi.FilterQueryPlan}</li>
 	 *     <li>{@link org.hibernate.engine.query.spi.NativeSQLQueryPlan}</li>
 	 * </ul>
 	 * 
 	 * maintained by {@link org.hibernate.engine.query.spi.QueryPlanCache}. Default is 2048.
 	 */
 	String QUERY_PLAN_CACHE_MAX_SIZE = "hibernate.query.plan_cache_max_size";
 
 	/**
 	 * The maximum number of {@link org.hibernate.engine.query.spi.ParameterMetadata} maintained 
 	 * by {@link org.hibernate.engine.query.spi.QueryPlanCache}. Default is 128.
 	 */
 	String QUERY_PLAN_CACHE_PARAMETER_METADATA_MAX_SIZE = "hibernate.query.plan_parameter_metadata_max_size";
 
 	/**
 	 * Should we not use contextual LOB creation (aka based on {@link java.sql.Connection#createBlob()} et al).
 	 */
 	String NON_CONTEXTUAL_LOB_CREATION = "hibernate.jdbc.lob.non_contextual_creation";
 
 	/**
 	 * Used to define a {@link java.util.Collection} of the {@link ClassLoader} instances Hibernate should use for
 	 * class-loading and resource-lookups.
 	 *
 	 * @since 5.0
 	 */
 	String CLASSLOADERS = "hibernate.classLoaders";
 
 	/**
 	 * Names the {@link ClassLoader} used to load user application classes.
 	 * @since 4.0
 	 *
 	 * @deprecated Use {@link #CLASSLOADERS} instead
 	 */
 	@Deprecated
 	String APP_CLASSLOADER = "hibernate.classLoader.application";
 
 	/**
 	 * Names the {@link ClassLoader} Hibernate should use to perform resource loading.
 	 * @since 4.0
 	 * @deprecated Use {@link #CLASSLOADERS} instead
 	 */
 	@Deprecated
 	String RESOURCES_CLASSLOADER = "hibernate.classLoader.resources";
 
 	/**
 	 * Names the {@link ClassLoader} responsible for loading Hibernate classes.  By default this is
 	 * the {@link ClassLoader} that loaded this class.
 	 * @since 4.0
 	 * @deprecated Use {@link #CLASSLOADERS} instead
 	 */
 	@Deprecated
 	String HIBERNATE_CLASSLOADER = "hibernate.classLoader.hibernate";
 
 	/**
 	 * Names the {@link ClassLoader} used when Hibernate is unable to locates classes on the
 	 * {@link #APP_CLASSLOADER} or {@link #HIBERNATE_CLASSLOADER}.
 	 * @since 4.0
 	 * @deprecated Use {@link #CLASSLOADERS} instead
 	 */
 	@Deprecated
 	String ENVIRONMENT_CLASSLOADER = "hibernate.classLoader.environment";
 
 
 	String C3P0_CONFIG_PREFIX = "hibernate.c3p0";
 
 	String PROXOOL_CONFIG_PREFIX = "hibernate.proxool";
 
 
 	String JMX_ENABLED = "hibernate.jmx.enabled";
 	String JMX_PLATFORM_SERVER = "hibernate.jmx.usePlatformServer";
 	String JMX_AGENT_ID = "hibernate.jmx.agentId";
 	String JMX_DOMAIN_NAME = "hibernate.jmx.defaultDomain";
 	String JMX_SF_NAME = "hibernate.jmx.sessionFactoryName";
 	String JMX_DEFAULT_OBJ_NAME_DOMAIN = "org.hibernate.core";
 
 	/**
 	 * A configuration value key used to indicate that it is safe to cache
 	 * {@link javax.transaction.TransactionManager} references.
 	 * @since 4.0
 	 */
 	String JTA_CACHE_TM = "hibernate.jta.cacheTransactionManager";
 
 	/**
 	 * A configuration value key used to indicate that it is safe to cache
 	 * {@link javax.transaction.UserTransaction} references.
 	 * @since 4.0
 	 */
 	String JTA_CACHE_UT = "hibernate.jta.cacheUserTransaction";
 
 	/**
 	 * Setting used to give the name of the default {@link org.hibernate.annotations.CacheConcurrencyStrategy}
 	 * to use when either {@link javax.persistence.Cacheable @Cacheable} or
 	 * {@link org.hibernate.annotations.Cache @Cache} is used.  {@link org.hibernate.annotations.Cache @Cache(strategy="..")} is used to override.
 	 */
 	String DEFAULT_CACHE_CONCURRENCY_STRATEGY = "hibernate.cache.default_cache_concurrency_strategy";
 
 	/**
 	 * Setting which indicates whether or not the new {@link org.hibernate.id.IdentifierGenerator} are used
 	 * for AUTO, TABLE and SEQUENCE.
 	 * Default to false to keep backward compatibility.
 	 */
 	String USE_NEW_ID_GENERATOR_MAPPINGS = "hibernate.id.new_generator_mappings";
 
 	/**
 	 * Setting to identify a {@link org.hibernate.CustomEntityDirtinessStrategy} to use.  May point to
 	 * either a class name or instance.
 	 */
 	String CUSTOM_ENTITY_DIRTINESS_STRATEGY = "hibernate.entity_dirtiness_strategy";
 
 	/**
 	 * Strategy for multi-tenancy.
 
 	 * @see org.hibernate.MultiTenancyStrategy
 	 * @since 4.0
 	 */
 	String MULTI_TENANT = "hibernate.multiTenancy";
 
 	/**
 	 * Names a {@link org.hibernate.engine.jdbc.connections.spi.MultiTenantConnectionProvider} implementation to
 	 * use.  As MultiTenantConnectionProvider is also a service, can be configured directly through the
 	 * {@link org.hibernate.boot.registry.StandardServiceRegistryBuilder}
 	 *
 	 * @since 4.1
 	 */
 	String MULTI_TENANT_CONNECTION_PROVIDER = "hibernate.multi_tenant_connection_provider";
 
 	/**
 	 * Names a {@link org.hibernate.context.spi.CurrentTenantIdentifierResolver} implementation to use.
 	 * <p/>
 	 * Can be<ul>
 	 *     <li>CurrentTenantIdentifierResolver instance</li>
 	 *     <li>CurrentTenantIdentifierResolver implementation {@link Class} reference</li>
 	 *     <li>CurrentTenantIdentifierResolver implementation class name</li>
 	 * </ul>
 	 *
 	 * @since 4.1
 	 */
 	String MULTI_TENANT_IDENTIFIER_RESOLVER = "hibernate.tenant_identifier_resolver";
 
 	String FORCE_DISCRIMINATOR_IN_SELECTS_BY_DEFAULT = "hibernate.discriminator.force_in_select";
 
 	/**
 	 * The legacy behavior of Hibernate is to not use discriminators for joined inheritance (Hibernate does not need
 	 * the discriminator...).  However, some JPA providers do need the discriminator for handling joined inheritance.
 	 * In the interest of portability this capability has been added to Hibernate too.
 	 * <p/>
 	 * However, we want to make sure that legacy applications continue to work as well.  Which puts us in a bind in
 	 * terms of how to handle "implicit" discriminator mappings.  The solution is to assume that the absence of
 	 * discriminator metadata means to follow the legacy behavior *unless* this setting is enabled.  With this setting
 	 * enabled, Hibernate will interpret the absence of discriminator metadata as an indication to use the JPA
 	 * defined defaults for these absent annotations.
 	 * <p/>
 	 * See Hibernate Jira issue HHH-6911 for additional background info.
 	 *
 	 * @see #IGNORE_EXPLICIT_DISCRIMINATOR_COLUMNS_FOR_JOINED_SUBCLASS
 	 */
 	String IMPLICIT_DISCRIMINATOR_COLUMNS_FOR_JOINED_SUBCLASS = "hibernate.discriminator.implicit_for_joined";
 
 	/**
 	 * The legacy behavior of Hibernate is to not use discriminators for joined inheritance (Hibernate does not need
 	 * the discriminator...).  However, some JPA providers do need the discriminator for handling joined inheritance.
 	 * In the interest of portability this capability has been added to Hibernate too.
 	 * <p/>
 	 * Existing applications rely (implicitly or explicitly) on Hibernate ignoring any DiscriminatorColumn declarations
 	 * on joined inheritance hierarchies.  This setting allows these applications to maintain the legacy behavior
 	 * of DiscriminatorColumn annotations being ignored when paired with joined inheritance.
 	 * <p/>
 	 * See Hibernate Jira issue HHH-6911 for additional background info.
 	 *
 	 * @see #IMPLICIT_DISCRIMINATOR_COLUMNS_FOR_JOINED_SUBCLASS
 	 */
 	String IGNORE_EXPLICIT_DISCRIMINATOR_COLUMNS_FOR_JOINED_SUBCLASS = "hibernate.discriminator.ignore_explicit_for_joined";
 
 	/**
 	 * Names a {@link org.hibernate.Interceptor} implementation to be applied to the {@link org.hibernate.SessionFactory}
 	 * Can reference<ul>
 	 *     <li>Interceptor instance</li>
 	 *     <li>Interceptor implementation {@link Class} reference</li>
 	 *     <li>Interceptor implementation class name</li>
 	 * </ul>
 	 *
 	 * @since 5.0
 	 */
 	String INTERCEPTOR = "hibernate.session_factory.interceptor";
 
     String ENABLE_LAZY_LOAD_NO_TRANS = "hibernate.enable_lazy_load_no_trans";
 
 	String HQL_BULK_ID_STRATEGY = "hibernate.hql.bulk_id_strategy";
 
 	/**
 	 * Names the {@link org.hibernate.loader.BatchFetchStyle} to use.  Can specify either the
 	 * {@link org.hibernate.loader.BatchFetchStyle} name (insensitively), or a
 	 * {@link org.hibernate.loader.BatchFetchStyle} instance.
 	 */
 	String BATCH_FETCH_STYLE = "hibernate.batch_fetch_style";
 
 	/**
 	 * Enable direct storage of entity references into the second level cache when applicable (immutable data, etc).
 	 * Default is to not store direct references.
 	 */
 	String USE_DIRECT_REFERENCE_CACHE_ENTRIES = "hibernate.cache.use_reference_entries";
 
 	/**
 	 * Enable nationalized character support on all string / clob based attribute ( string, char, clob, text etc ).
 	 *
 	 * Default is <clode>false</clode>.
 	 */
 	String USE_NATIONALIZED_CHARACTER_DATA = "hibernate.use_nationalized_character_data";
 	
 	/**
 	 * A transaction can be rolled back by another thread ("tracking by thread")
 	 * -- not the original application. Examples of this include a JTA
 	 * transaction timeout handled by a background reaper thread.  The ability
 	 * to handle this situation requires checking the Thread ID every time
 	 * Session is called.  This can certainly have performance considerations.
 	 * 
 	 * Default is <code>true</code> (enabled).
 	 */
 	String JTA_TRACK_BY_THREAD = "hibernate.jta.track_by_thread";
 
 	String JACC_CONTEXT_ID = "hibernate.jacc_context_id";
 	String JACC_PREFIX = "hibernate.jacc";
 	String JACC_ENABLED = "hibernate.jacc.enabled";
 
 	/**
 	 * If enabled, allows schema update and validation to support synonyms.  Due
 	 * to the possibility that this would return duplicate tables (especially in
 	 * Oracle), this is disabled by default.
 	 */
 	String ENABLE_SYNONYMS = "hibernate.synonyms";
 	
 	/**
 	 * Unique columns and unique keys both use unique constraints in most dialects.
 	 * SchemaUpdate needs to create these constraints, but DB's
 	 * support for finding existing constraints is extremely inconsistent. Further,
 	 * non-explicitly-named unique constraints use randomly generated characters.
 	 * 
 	 * Therefore, select from these strategies.
 	 * {@link org.hibernate.tool.hbm2ddl.UniqueConstraintSchemaUpdateStrategy#DROP_RECREATE_QUIETLY} (DEFAULT):
 	 * 			Attempt to drop, then (re-)create each unique constraint.
 	 * 			Ignore any exceptions thrown.
 	 * {@link org.hibernate.tool.hbm2ddl.UniqueConstraintSchemaUpdateStrategy#RECREATE_QUIETLY}:
 	 * 			attempt to (re-)create unique constraints,
 	 * 			ignoring exceptions thrown if the constraint already existed
 	 * {@link org.hibernate.tool.hbm2ddl.UniqueConstraintSchemaUpdateStrategy#SKIP}:
 	 * 			do not attempt to create unique constraints on a schema update
 	 */
 	String UNIQUE_CONSTRAINT_SCHEMA_UPDATE_STRATEGY = "hibernate.schema_update.unique_constraint_strategy";
 
 	/**
 	 * A setting to control whether to {@link org.hibernate.engine.internal.StatisticalLoggingSessionEventListener} is
 	 * enabled on all Sessions (unless explicitly disabled for a given Session).  The default value of this
 	 * setting is determined by the value for {@link #GENERATE_STATISTICS}, meaning that if collection of statistics
 	 * is enabled logging of Session metrics is enabled by default too.
 	 */
 	String LOG_SESSION_METRICS = "hibernate.session.events.log";
 
 	String AUTO_SESSION_EVENTS_LISTENER = "hibernate.session.events.auto";
 
 
 	/**
 	 * The deprecated name.  Use {@link #SCANNER} or {@link #SCANNER_ARCHIVE_INTERPRETER} instead.
 	 */
 	String SCANNER_DEPRECATED = "hibernate.ejb.resource_scanner";
 
 	/**
 	 * Pass an implementation of {@link org.hibernate.boot.archive.scan.spi.Scanner}.
 	 * Accepts either:<ul>
 	 *     <li>an actual instance</li>
 	 *     <li>a reference to a Class that implements Scanner</li>
 	 *     <li>a fully qualified name (String) of a Class that implements Scanner</li>
 	 * </ul>
 	 */
 	String SCANNER = "hibernate.archive.scanner";
 
 	/**
 	 * Pass {@link org.hibernate.boot.archive.spi.ArchiveDescriptorFactory} to use
 	 * in the scanning process.  Accepts either:<ul>
 	 *     <li>an ArchiveDescriptorFactory instance</li>
 	 *     <li>a reference to a Class that implements ArchiveDescriptorFactory</li>
 	 *     <li>a fully qualified name (String) of a Class that implements ArchiveDescriptorFactory</li>
 	 * </ul>
 	 * <p/>
 	 * See information on {@link org.hibernate.boot.archive.scan.spi.Scanner}
 	 * about expected constructor forms.
 	 *
 	 * @see #SCANNER
 	 * @see org.hibernate.boot.archive.scan.spi.Scanner
 	 * @see org.hibernate.boot.archive.scan.spi.AbstractScannerImpl
 	 */
 	String SCANNER_ARCHIVE_INTERPRETER = "hibernate.archive.interpreter";
 
 	/**
 	 * Identifies a comma-separate list of values indicating the types of
 	 * things we should auto-detect during scanning.  Allowable values include:<ul>
 	 *     <li>"class" - discover classes - .class files are discovered as managed classes</li>
 	 *     <li>"hbm" - discover hbm mapping files - hbm.xml files are discovered as mapping files</li>
 	 * </ul>
 	 */
 	String SCANNER_DISCOVERY = "hibernate.archive.autodetection";
 
 	/**
 	 * Used to specify the {@link org.hibernate.tool.schema.spi.SchemaManagementTool} to use for performing
 	 * schema management.  The default is to use {@link org.hibernate.tool.schema.internal.HibernateSchemaManagementTool}
 	 *
 	 * @since 5.0
 	 */
 	String SCHEMA_MANAGEMENT_TOOL = "hibernate.schema_management_tool";
 
 	/**
 	 * Used to specify the {@link org.hibernate.boot.model.naming.ImplicitNamingStrategy} class to use.
 	 *
 	 * @since 5.0
 	 */
 	String IMPLICIT_NAMING_STRATEGY = "hibernate.implicit_naming_strategy";
 
 	/**
 	 * Used to specify the {@link org.hibernate.boot.model.naming.PhysicalNamingStrategy} class to use.
 	 *
 	 * @since 5.0
 	 */
 	String PHYSICAL_NAMING_STRATEGY = "hibernate.physical_naming_strategy";
 
 	/**
 	 * Used to specify the order in which metadata sources should be processed.  Value
 	 * is a delimited-list whose elements are defined by {@link org.hibernate.cfg.MetadataSourceType}.
 	 * <p/>
 	 * Default is {@code "hbm,class"} which indicates to process {@code hbm.xml} files followed by
 	 * annotations (combined with {@code orm.xml} mappings).
 	 */
 	String ARTIFACT_PROCESSING_ORDER = "hibernate.mapping.precedence";
+
+	/**
+	 * Used to specify if using {@link javax.transaction.UserTransaction}  class to use for JTA transaction management.
+	 *
+	 * Default is <code>false</code>
+	 *
+	 * @since 5.0
+	 */
+	String PREFER_USER_TRANSACTION = "hibernate.jta.prefer_user_transaction";
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/cfg/Settings.java b/hibernate-core/src/main/java/org/hibernate/cfg/Settings.java
index b194245c84..07076b8a31 100644
--- a/hibernate-core/src/main/java/org/hibernate/cfg/Settings.java
+++ b/hibernate-core/src/main/java/org/hibernate/cfg/Settings.java
@@ -1,332 +1,336 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.cfg;
 
 import java.util.Map;
 
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.EntityMode;
 import org.hibernate.MultiTenancyStrategy;
 import org.hibernate.NullPrecedence;
 import org.hibernate.boot.Metadata;
 import org.hibernate.boot.SchemaAutoTooling;
 import org.hibernate.boot.model.naming.Identifier;
 import org.hibernate.boot.spi.SessionFactoryOptions;
 import org.hibernate.cache.spi.QueryCacheFactory;
 import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
 import org.hibernate.hql.spi.id.MultiTableBulkIdStrategy;
 import org.hibernate.hql.spi.QueryTranslatorFactory;
 import org.hibernate.loader.BatchFetchStyle;
 import org.hibernate.tuple.entity.EntityTuplizerFactory;
 
 import org.jboss.logging.Logger;
 
 /**
  * Settings that affect the behaviour of Hibernate at runtime.
  *
  * @author Gavin King
  * @author Steve Ebersole
  *
  * @deprecated Use {@link org.hibernate.boot.spi.SessionFactoryOptions} instead.
  */
 @Deprecated
 public final class Settings {
 	private static final Logger LOG = Logger.getLogger( Settings.class );
 
 	private final SessionFactoryOptions sessionFactoryOptions;
 	private final String defaultCatalogName;
 	private final String defaultSchemaName;
 
 	public Settings(SessionFactoryOptions sessionFactoryOptions) {
 		this( sessionFactoryOptions, null, null );
 	}
 
 	public Settings(SessionFactoryOptions sessionFactoryOptions, Metadata metadata) {
 		this(
 				sessionFactoryOptions,
 				extractName( metadata.getDatabase().getDefaultSchema().getName().getCatalog() ),
 				extractName( metadata.getDatabase().getDefaultSchema().getName().getSchema() )
 		);
 	}
 
 	private static String extractName(Identifier identifier) {
 		return identifier == null ? null : identifier.render();
 	}
 
 	public Settings(SessionFactoryOptions sessionFactoryOptions, String defaultCatalogName, String defaultSchemaName) {
 		this.sessionFactoryOptions = sessionFactoryOptions;
 		this.defaultCatalogName = defaultCatalogName;
 		this.defaultSchemaName = defaultSchemaName;
 
 		final boolean debugEnabled =  LOG.isDebugEnabled();
 
 		if ( debugEnabled ) {
 			LOG.debugf( "SessionFactory name : %s", sessionFactoryOptions.getSessionFactoryName() );
 			LOG.debugf( "Automatic flush during beforeCompletion(): %s", enabledDisabled( sessionFactoryOptions.isFlushBeforeCompletionEnabled() ) );
 			LOG.debugf( "Automatic session close at end of transaction: %s", enabledDisabled( sessionFactoryOptions.isAutoCloseSessionEnabled() ) );
 
 			LOG.debugf( "Statistics: %s", enabledDisabled( sessionFactoryOptions.isStatisticsEnabled() ) );
 
 			LOG.debugf( "Deleted entity synthetic identifier rollback: %s", enabledDisabled( sessionFactoryOptions.isIdentifierRollbackEnabled() ) );
 			LOG.debugf( "Default entity-mode: %s", sessionFactoryOptions.getDefaultEntityMode() );
 			LOG.debugf( "Check Nullability in Core (should be disabled when Bean Validation is on): %s", enabledDisabled( sessionFactoryOptions.isCheckNullability() ) );
 			LOG.debugf( "Allow initialization of lazy state outside session : %s", enabledDisabled( sessionFactoryOptions.isInitializeLazyStateOutsideTransactionsEnabled() ) );
 
 			LOG.debugf( "Using BatchFetchStyle : " + sessionFactoryOptions.getBatchFetchStyle().name() );
 			LOG.debugf( "Default batch fetch size: %s", sessionFactoryOptions.getDefaultBatchFetchSize() );
 			LOG.debugf( "Maximum outer join fetch depth: %s", sessionFactoryOptions.getMaximumFetchDepth() );
 			LOG.debugf( "Default null ordering: %s", sessionFactoryOptions.getDefaultNullPrecedence() );
 			LOG.debugf( "Order SQL updates by primary key: %s", enabledDisabled( sessionFactoryOptions.isOrderUpdatesEnabled() ) );
 			LOG.debugf( "Order SQL inserts for batching: %s", enabledDisabled( sessionFactoryOptions.isOrderInsertsEnabled() ) );
 
 			LOG.debugf( "multi-tenancy strategy : %s", sessionFactoryOptions.getMultiTenancyStrategy() );
 
 			LOG.debugf( "JTA Track by Thread: %s", enabledDisabled( sessionFactoryOptions.isJtaTrackByThread() ) );
 
 			LOG.debugf( "Query language substitutions: %s", sessionFactoryOptions.getQuerySubstitutions() );
 			LOG.debugf( "JPA query language strict compliance: %s", enabledDisabled( sessionFactoryOptions.isStrictJpaQueryLanguageCompliance() ) );
 			LOG.debugf( "Named query checking : %s", enabledDisabled( sessionFactoryOptions.isNamedQueryStartupCheckingEnabled() ) );
 
 			LOG.debugf( "Second-level cache: %s", enabledDisabled( sessionFactoryOptions.isSecondLevelCacheEnabled() ) );
 			LOG.debugf( "Second-level query cache: %s", enabledDisabled( sessionFactoryOptions.isQueryCacheEnabled() ) );
 			LOG.debugf( "Second-level query cache factory: %s", sessionFactoryOptions.getQueryCacheFactory() );
 			LOG.debugf( "Second-level cache region prefix: %s", sessionFactoryOptions.getCacheRegionPrefix() );
 			LOG.debugf( "Optimize second-level cache for minimal puts: %s", enabledDisabled( sessionFactoryOptions.isMinimalPutsEnabled() ) );
 			LOG.debugf( "Structured second-level cache entries: %s", enabledDisabled( sessionFactoryOptions.isStructuredCacheEntriesEnabled() ) );
 			LOG.debugf( "Second-level cache direct-reference entries: %s", enabledDisabled( sessionFactoryOptions.isDirectReferenceCacheEntriesEnabled() ) );
 			LOG.debugf( "Automatic eviction of collection cache: %s", enabledDisabled( sessionFactoryOptions.isAutoEvictCollectionCache() ) );
 
 			LOG.debugf( "JDBC batch size: %s", sessionFactoryOptions.getJdbcBatchSize() );
 			LOG.debugf( "JDBC batch updates for versioned data: %s", enabledDisabled( sessionFactoryOptions.isJdbcBatchVersionedData() ) );
 			LOG.debugf( "Scrollable result sets: %s", enabledDisabled( sessionFactoryOptions.isScrollableResultSetsEnabled() ) );
 			LOG.debugf( "Wrap result sets: %s", enabledDisabled( sessionFactoryOptions.isWrapResultSetsEnabled() ) );
 			LOG.debugf( "JDBC3 getGeneratedKeys(): %s", enabledDisabled( sessionFactoryOptions.isGetGeneratedKeysEnabled() ) );
 			LOG.debugf( "JDBC result set fetch size: %s", sessionFactoryOptions.getJdbcFetchSize() );
 			LOG.debugf( "Connection release mode: %s", sessionFactoryOptions.getConnectionReleaseMode() );
 			LOG.debugf( "Generate SQL with comments: %s", enabledDisabled( sessionFactoryOptions.isCommentsEnabled() ) );
 		}
 	}
 
 	private static String enabledDisabled(boolean value) {
 		return value ? "enabled" : "disabled";
 	}
 
 	public String getDefaultSchemaName() {
 		return defaultSchemaName;
 	}
 
 	public String getDefaultCatalogName() {
 		return defaultCatalogName;
 	}
 
 	public String getSessionFactoryName() {
 		return sessionFactoryOptions.getSessionFactoryName();
 	}
 
 	public boolean isSessionFactoryNameAlsoJndiName() {
 		return sessionFactoryOptions.isSessionFactoryNameAlsoJndiName();
 	}
 
 	public boolean isFlushBeforeCompletionEnabled() {
 		return sessionFactoryOptions.isFlushBeforeCompletionEnabled();
 	}
 
 	public boolean isAutoCloseSessionEnabled() {
 		return sessionFactoryOptions.isAutoCloseSessionEnabled();
 	}
 
 	public boolean isStatisticsEnabled() {
 		return sessionFactoryOptions.isStatisticsEnabled();
 	}
 
 	public BaselineSessionEventsListenerBuilder getBaselineSessionEventsListenerBuilder() {
 		return sessionFactoryOptions.getBaselineSessionEventsListenerBuilder();
 	}
 
 	public boolean isIdentifierRollbackEnabled() {
 		return sessionFactoryOptions.isIdentifierRollbackEnabled();
 	}
 
 	public EntityMode getDefaultEntityMode() {
 		return sessionFactoryOptions.getDefaultEntityMode();
 	}
 
 	public EntityTuplizerFactory getEntityTuplizerFactory() {
 		return sessionFactoryOptions.getEntityTuplizerFactory();
 	}
 
 	public boolean isCheckNullability() {
 		return sessionFactoryOptions.isCheckNullability();
 	}
 
 	public boolean isInitializeLazyStateOutsideTransactionsEnabled() {
 		return sessionFactoryOptions.isInitializeLazyStateOutsideTransactionsEnabled();
 	}
 
 	public MultiTableBulkIdStrategy getMultiTableBulkIdStrategy() {
 		return sessionFactoryOptions.getMultiTableBulkIdStrategy();
 	}
 
 	public BatchFetchStyle getBatchFetchStyle() {
 		return sessionFactoryOptions.getBatchFetchStyle();
 	}
 
 	public int getDefaultBatchFetchSize() {
 		return sessionFactoryOptions.getDefaultBatchFetchSize();
 	}
 
 	public Integer getMaximumFetchDepth() {
 		return sessionFactoryOptions.getMaximumFetchDepth();
 	}
 
 	public NullPrecedence getDefaultNullPrecedence() {
 		return sessionFactoryOptions.getDefaultNullPrecedence();
 	}
 
 	public boolean isOrderUpdatesEnabled() {
 		return sessionFactoryOptions.isOrderUpdatesEnabled();
 	}
 
 	public boolean isOrderInsertsEnabled() {
 		return sessionFactoryOptions.isOrderInsertsEnabled();
 	}
 
 	public MultiTenancyStrategy getMultiTenancyStrategy() {
 		return sessionFactoryOptions.getMultiTenancyStrategy();
 	}
 	public boolean isJtaTrackByThread() {
 		return sessionFactoryOptions.isJtaTrackByThread();
 	}
 
 	public Map getQuerySubstitutions() {
 		return sessionFactoryOptions.getQuerySubstitutions();
 	}
 
 	public boolean isStrictJPAQLCompliance() {
 		return sessionFactoryOptions.isStrictJpaQueryLanguageCompliance();
 	}
 
 	public boolean isNamedQueryStartupCheckingEnabled() {
 		return sessionFactoryOptions.isNamedQueryStartupCheckingEnabled();
 	}
 
 	public boolean isSecondLevelCacheEnabled() {
 		return sessionFactoryOptions.isSecondLevelCacheEnabled();
 	}
 
 	public boolean isQueryCacheEnabled() {
 		return sessionFactoryOptions.isQueryCacheEnabled();
 	}
 
 	public QueryCacheFactory getQueryCacheFactory() {
 		return sessionFactoryOptions.getQueryCacheFactory();
 	}
 
 	public String getCacheRegionPrefix() {
 		return sessionFactoryOptions.getCacheRegionPrefix();
 	}
 
 	public boolean isMinimalPutsEnabled() {
 		return sessionFactoryOptions.isMinimalPutsEnabled();
 	}
 
 	public boolean isStructuredCacheEntriesEnabled() {
 		return sessionFactoryOptions.isStructuredCacheEntriesEnabled();
 	}
 
 	public boolean isDirectReferenceCacheEntriesEnabled() {
 		return sessionFactoryOptions.isDirectReferenceCacheEntriesEnabled();
 	}
 
 	public boolean isAutoEvictCollectionCache() {
 		return sessionFactoryOptions.isAutoEvictCollectionCache();
 	}
 
 	public boolean isAutoCreateSchema() {
 		return sessionFactoryOptions.getSchemaAutoTooling() == SchemaAutoTooling.CREATE
 				|| sessionFactoryOptions.getSchemaAutoTooling() == SchemaAutoTooling.CREATE_DROP;
 	}
 
 	public boolean isAutoDropSchema() {
 		return sessionFactoryOptions.getSchemaAutoTooling() == SchemaAutoTooling.CREATE_DROP;
 	}
 
 	public boolean isAutoUpdateSchema() {
 		return sessionFactoryOptions.getSchemaAutoTooling() == SchemaAutoTooling.UPDATE;
 	}
 
 	public boolean isAutoValidateSchema() {
 		return sessionFactoryOptions.getSchemaAutoTooling() == SchemaAutoTooling.VALIDATE;
 	}
 
 	public int getJdbcBatchSize() {
 		return sessionFactoryOptions.getJdbcBatchSize();
 	}
 
 	public boolean isJdbcBatchVersionedData() {
 		return sessionFactoryOptions.isJdbcBatchVersionedData();
 	}
 
 	public Integer getJdbcFetchSize() {
 		return sessionFactoryOptions.getJdbcFetchSize();
 	}
 
 	public boolean isScrollableResultSetsEnabled() {
 		return sessionFactoryOptions.isScrollableResultSetsEnabled();
 	}
 
 	public boolean isWrapResultSetsEnabled() {
 		return sessionFactoryOptions.isWrapResultSetsEnabled();
 	}
 
 	public boolean isGetGeneratedKeysEnabled() {
 		return sessionFactoryOptions.isGetGeneratedKeysEnabled();
 	}
 
 	public ConnectionReleaseMode getConnectionReleaseMode() {
 		return sessionFactoryOptions.getConnectionReleaseMode();
 	}
 
 	public boolean isCommentsEnabled() {
 		return sessionFactoryOptions.isCommentsEnabled();
 	}
 
 	public RegionFactory getRegionFactory() {
 		return sessionFactoryOptions.getServiceRegistry().getService( RegionFactory.class );
 	}
 
 	public JtaPlatform getJtaPlatform() {
 		return sessionFactoryOptions.getServiceRegistry().getService( JtaPlatform.class );
 	}
 
 	public QueryTranslatorFactory getQueryTranslatorFactory() {
 		return sessionFactoryOptions.getServiceRegistry().getService( QueryTranslatorFactory.class );
 	}
 
 	public void setCheckNullability(boolean enabled) {
 		// ugh, used by org.hibernate.cfg.beanvalidation.TypeSafeActivator as part of the BV integrator
 		sessionFactoryOptions.setCheckNullability( enabled );
 	}
+
+	public boolean isPreferUserTransaction() {
+		return sessionFactoryOptions.isPreferUserTransaction();
+	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/collection/internal/AbstractPersistentCollection.java b/hibernate-core/src/main/java/org/hibernate/collection/internal/AbstractPersistentCollection.java
index 4162a2b964..b2b044e5c1 100644
--- a/hibernate-core/src/main/java/org/hibernate/collection/internal/AbstractPersistentCollection.java
+++ b/hibernate-core/src/main/java/org/hibernate/collection/internal/AbstractPersistentCollection.java
@@ -1,1220 +1,1217 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.collection.internal;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.ListIterator;
 
 import javax.naming.NamingException;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LazyInitializationException;
 import org.hibernate.Session;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.internal.ForeignKeys;
 import org.hibernate.engine.spi.CollectionEntry;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.Status;
 import org.hibernate.engine.spi.TypedValue;
 import org.hibernate.internal.SessionFactoryRegistry;
 import org.hibernate.internal.util.MarkerObject;
 import org.hibernate.internal.util.collections.EmptyIterator;
 import org.hibernate.internal.util.collections.IdentitySet;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.ComponentType;
 import org.hibernate.type.IntegerType;
 import org.hibernate.type.LongType;
 import org.hibernate.type.PostgresUUIDType;
 import org.hibernate.type.StringType;
 import org.hibernate.type.Type;
 import org.hibernate.type.UUIDBinaryType;
 import org.hibernate.type.UUIDCharType;
 import org.jboss.logging.Logger;
 
 /**
  * Base class implementing {@link org.hibernate.collection.spi.PersistentCollection}
  *
  * @author Gavin King
  */
 public abstract class AbstractPersistentCollection implements Serializable, PersistentCollection {
 	private static final Logger log = Logger.getLogger( AbstractPersistentCollection.class );
 
 	private transient SessionImplementor session;
 	private boolean initialized;
 	private transient List<DelayedOperation> operationQueue;
 	private transient boolean directlyAccessible;
 	private transient boolean initializing;
 	private Object owner;
 	private int cachedSize = -1;
 
 	private String role;
 	private Serializable key;
 	// collections detect changes made via their public interface and mark
 	// themselves as dirty as a performance optimization
 	private boolean dirty;
 	private Serializable storedSnapshot;
 
 	private String sessionFactoryUuid;
 	private boolean allowLoadOutsideTransaction;
 
 	/**
 	 * Not called by Hibernate, but used by non-JDK serialization,
 	 * eg. SOAP libraries.
 	 */
 	public AbstractPersistentCollection() {
 	}
 
 	protected AbstractPersistentCollection(SessionImplementor session) {
 		this.session = session;
 	}
 
 	@Override
 	public final String getRole() {
 		return role;
 	}
 
 	@Override
 	public final Serializable getKey() {
 		return key;
 	}
 
 	@Override
 	public final boolean isUnreferenced() {
 		return role == null;
 	}
 
 	@Override
 	public final boolean isDirty() {
 		return dirty;
 	}
 
 	@Override
 	public final void clearDirty() {
 		dirty = false;
 	}
 
 	@Override
 	public final void dirty() {
 		dirty = true;
 	}
 
 	@Override
 	public final Serializable getStoredSnapshot() {
 		return storedSnapshot;
 	}
 
 	//Careful: these methods do not initialize the collection.
 
 	@Override
 	public abstract boolean empty();
 
 	/**
 	 * Called by any read-only method of the collection interface
 	 */
 	protected final void read() {
 		initialize( false );
 	}
 
 	/**
 	 * Called by the {@link Collection#size} method
 	 */
 	@SuppressWarnings({"JavaDoc"})
 	protected boolean readSize() {
 		if ( !initialized ) {
 			if ( cachedSize != -1 && !hasQueuedOperations() ) {
 				return true;
 			}
 			else {
 				final boolean isExtraLazy = withTemporarySessionIfNeeded(
 						new LazyInitializationWork<Boolean>() {
 							@Override
 							public Boolean doWork() {
 								final CollectionEntry entry = session.getPersistenceContext().getCollectionEntry( AbstractPersistentCollection.this );
 
 								if ( entry != null ) {
 									final CollectionPersister persister = entry.getLoadedPersister();
 									if ( persister.isExtraLazy() ) {
 										if ( hasQueuedOperations() ) {
 											session.flush();
 										}
 										cachedSize = persister.getSize( entry.getLoadedKey(), session );
 										return true;
 									}
 									else {
 										read();
 									}
 								}
 								else{
 									throwLazyInitializationExceptionIfNotConnected();
 								}
 								return false;
 							}
 						}
 				);
 				if ( isExtraLazy ) {
 					return true;
 				}
 			}
 		}
 		return false;
 	}
 
 	/**
 	 * TBH not sure why this is public
 	 *
 	 * @param <T> The java type of the return for this LazyInitializationWork
 	 */
 	public static interface LazyInitializationWork<T> {
 		/**
 		 * Do the represented work and return the result.
 		 *
 		 * @return The result
 		 */
 		public T doWork();
 	}
 
 	private <T> T withTemporarySessionIfNeeded(LazyInitializationWork<T> lazyInitializationWork) {
 		SessionImplementor originalSession = null;
 		boolean isTempSession = false;
 		boolean isJTA = false;
 
 		if ( session == null ) {
 			if ( allowLoadOutsideTransaction ) {
 				session = openTemporarySessionForLoading();
 				isTempSession = true;
 			}
 			else {
 				throwLazyInitializationException( "could not initialize proxy - no Session" );
 			}
 		}
 		else if ( !session.isOpen() ) {
 			if ( allowLoadOutsideTransaction ) {
 				originalSession = session;
 				session = openTemporarySessionForLoading();
 				isTempSession = true;
 			}
 			else {
 				throwLazyInitializationException( "could not initialize proxy - the owning Session was closed" );
 			}
 		}
 		else if ( !session.isConnected() ) {
 			if ( allowLoadOutsideTransaction ) {
 				originalSession = session;
 				session = openTemporarySessionForLoading();
 				isTempSession = true;
 			}
 			else {
 				throwLazyInitializationException( "could not initialize proxy - the owning Session is disconnected" );
 			}
 		}
 
 		if ( isTempSession ) {
-			isJTA = session.getTransactionCoordinator()
-					.getTransactionContext().getTransactionEnvironment()
-					.getTransactionFactory()
-					.compatibleWithJtaSynchronization();
+			isJTA = session.getTransactionCoordinator().getTransactionCoordinatorBuilder().isJta();
 			
 			if ( !isJTA ) {
 				// Explicitly handle the transactions only if we're not in
 				// a JTA environment.  A lazy loading temporary session can
 				// be created even if a current session and transaction are
 				// open (ex: session.clear() was used).  We must prevent
 				// multiple transactions.
 				( (Session) session ).beginTransaction();
 			}
 
 			session.getPersistenceContext().addUninitializedDetachedCollection(
 					session.getFactory().getCollectionPersister( getRole() ),
 					this
 			);
 		}
 
 		try {
 			return lazyInitializationWork.doWork();
 		}
 		finally {
 			if ( isTempSession ) {
 				// make sure the just opened temp session gets closed!
 				try {
 					if ( !isJTA ) {
 						( (Session) session ).getTransaction().commit();
 					}
 					( (Session) session ).close();
 				}
 				catch (Exception e) {
 					log.warn( "Unable to close temporary session used to load lazy collection associated to no session" );
 				}
 				session = originalSession;
 			}
 		}
 	}
 
 	private SessionImplementor openTemporarySessionForLoading() {
 		if ( sessionFactoryUuid == null ) {
 			throwLazyInitializationException( "SessionFactory UUID not known to create temporary Session for loading" );
 		}
 
 		final SessionFactoryImplementor sf = (SessionFactoryImplementor)
 				SessionFactoryRegistry.INSTANCE.getSessionFactory( sessionFactoryUuid );
 		final SessionImplementor session = (SessionImplementor) sf.openSession();
 		session.getPersistenceContext().setDefaultReadOnly( true );
 		session.setFlushMode( FlushMode.MANUAL );
 		return session;
 	}
 
 	protected Boolean readIndexExistence(final Object index) {
 		if ( !initialized ) {
 			final Boolean extraLazyExistenceCheck = withTemporarySessionIfNeeded(
 					new LazyInitializationWork<Boolean>() {
 						@Override
 						public Boolean doWork() {
 							final CollectionEntry entry = session.getPersistenceContext().getCollectionEntry( AbstractPersistentCollection.this );
 							final CollectionPersister persister = entry.getLoadedPersister();
 							if ( persister.isExtraLazy() ) {
 								if ( hasQueuedOperations() ) {
 									session.flush();
 								}
 								return persister.indexExists( entry.getLoadedKey(), index, session );
 							}
 							else {
 								read();
 							}
 							return null;
 						}
 					}
 			);
 			if ( extraLazyExistenceCheck != null ) {
 				return extraLazyExistenceCheck;
 			}
 		}
 		return null;
 	}
 
 	protected Boolean readElementExistence(final Object element) {
 		if ( !initialized ) {
 			final Boolean extraLazyExistenceCheck = withTemporarySessionIfNeeded(
 					new LazyInitializationWork<Boolean>() {
 						@Override
 						public Boolean doWork() {
 							final CollectionEntry entry = session.getPersistenceContext().getCollectionEntry( AbstractPersistentCollection.this );
 							final CollectionPersister persister = entry.getLoadedPersister();
 							if ( persister.isExtraLazy() ) {
 								if ( hasQueuedOperations() ) {
 									session.flush();
 								}
 								return persister.elementExists( entry.getLoadedKey(), element, session );
 							}
 							else {
 								read();
 							}
 							return null;
 						}
 					}
 			);
 			if ( extraLazyExistenceCheck != null ) {
 				return extraLazyExistenceCheck;
 			}
 		}
 		return null;
 	}
 
 	protected static final Object UNKNOWN = new MarkerObject( "UNKNOWN" );
 
 	protected Object readElementByIndex(final Object index) {
 		if ( !initialized ) {
 			class ExtraLazyElementByIndexReader implements LazyInitializationWork {
 				private boolean isExtraLazy;
 				private Object element;
 
 				@Override
 				public Object doWork() {
 					final CollectionEntry entry = session.getPersistenceContext().getCollectionEntry( AbstractPersistentCollection.this );
 					final CollectionPersister persister = entry.getLoadedPersister();
 					isExtraLazy = persister.isExtraLazy();
 					if ( isExtraLazy ) {
 						if ( hasQueuedOperations() ) {
 							session.flush();
 						}
 						element = persister.getElementByIndex( entry.getLoadedKey(), index, session, owner );
 					}
 					else {
 						read();
 					}
 					return null;
 				}
 			}
 
 			final ExtraLazyElementByIndexReader reader = new ExtraLazyElementByIndexReader();
 			//noinspection unchecked
 			withTemporarySessionIfNeeded( reader );
 			if ( reader.isExtraLazy ) {
 				return reader.element;
 			}
 		}
 		return UNKNOWN;
 
 	}
 
 	protected int getCachedSize() {
 		return cachedSize;
 	}
 
 	private boolean isConnectedToSession() {
 		return session != null
 				&& session.isOpen()
 				&& session.getPersistenceContext().containsCollection( this );
 	}
 
 	/**
 	 * Called by any writer method of the collection interface
 	 */
 	protected final void write() {
 		initialize( true );
 		dirty();
 	}
 
 	/**
 	 * Is this collection in a state that would allow us to
 	 * "queue" operations?
 	 */
 	@SuppressWarnings({"JavaDoc"})
 	protected boolean isOperationQueueEnabled() {
 		return !initialized
 				&& isConnectedToSession()
 				&& isInverseCollection();
 	}
 
 	/**
 	 * Is this collection in a state that would allow us to
 	 * "queue" puts? This is a special case, because of orphan
 	 * delete.
 	 */
 	@SuppressWarnings({"JavaDoc"})
 	protected boolean isPutQueueEnabled() {
 		return !initialized
 				&& isConnectedToSession()
 				&& isInverseOneToManyOrNoOrphanDelete();
 	}
 
 	/**
 	 * Is this collection in a state that would allow us to
 	 * "queue" clear? This is a special case, because of orphan
 	 * delete.
 	 */
 	@SuppressWarnings({"JavaDoc"})
 	protected boolean isClearQueueEnabled() {
 		return !initialized
 				&& isConnectedToSession()
 				&& isInverseCollectionNoOrphanDelete();
 	}
 
 	/**
 	 * Is this the "inverse" end of a bidirectional association?
 	 */
 	@SuppressWarnings({"JavaDoc"})
 	private boolean isInverseCollection() {
 		final CollectionEntry ce = session.getPersistenceContext().getCollectionEntry( this );
 		return ce != null && ce.getLoadedPersister().isInverse();
 	}
 
 	/**
 	 * Is this the "inverse" end of a bidirectional association with
 	 * no orphan delete enabled?
 	 */
 	@SuppressWarnings({"JavaDoc"})
 	private boolean isInverseCollectionNoOrphanDelete() {
 		final CollectionEntry ce = session.getPersistenceContext().getCollectionEntry( this );
 		return ce != null
 				&&
 				ce.getLoadedPersister().isInverse() &&
 				!ce.getLoadedPersister().hasOrphanDelete();
 	}
 
 	/**
 	 * Is this the "inverse" end of a bidirectional one-to-many, or
 	 * of a collection with no orphan delete?
 	 */
 	@SuppressWarnings({"JavaDoc"})
 	private boolean isInverseOneToManyOrNoOrphanDelete() {
 		final CollectionEntry ce = session.getPersistenceContext().getCollectionEntry( this );
 		return ce != null
 				&& ce.getLoadedPersister().isInverse()
 				&& ( ce.getLoadedPersister().isOneToMany() || !ce.getLoadedPersister().hasOrphanDelete() );
 	}
 
 	/**
 	 * Queue an addition
 	 */
 	@SuppressWarnings({"JavaDoc"})
 	protected final void queueOperation(DelayedOperation operation) {
 		if ( operationQueue == null ) {
 			operationQueue = new ArrayList<DelayedOperation>( 10 );
 		}
 		operationQueue.add( operation );
 		//needed so that we remove this collection from the second-level cache
 		dirty = true;
 	}
 
 	/**
 	 * After reading all existing elements from the database,
 	 * add the queued elements to the underlying collection.
 	 */
 	protected final void performQueuedOperations() {
 		for ( DelayedOperation operation : operationQueue ) {
 			operation.operate();
 		}
 	}
 
 	@Override
 	public void setSnapshot(Serializable key, String role, Serializable snapshot) {
 		this.key = key;
 		this.role = role;
 		this.storedSnapshot = snapshot;
 	}
 
 	@Override
 	public void postAction() {
 		operationQueue = null;
 		cachedSize = -1;
 		clearDirty();
 	}
 
 	@Override
 	public Object getValue() {
 		return this;
 	}
 
 	@Override
 	public void beginRead() {
 		// override on some subclasses
 		initializing = true;
 	}
 
 	@Override
 	public boolean endRead() {
 		//override on some subclasses
 		return afterInitialize();
 	}
 
 	@Override
 	public boolean afterInitialize() {
 		setInitialized();
 		//do this bit after setting initialized to true or it will recurse
 		if ( operationQueue != null ) {
 			performQueuedOperations();
 			operationQueue = null;
 			cachedSize = -1;
 			return false;
 		}
 		else {
 			return true;
 		}
 	}
 
 	/**
 	 * Initialize the collection, if possible, wrapping any exceptions
 	 * in a runtime exception
 	 *
 	 * @param writing currently obsolete
 	 *
 	 * @throws LazyInitializationException if we cannot initialize
 	 */
 	protected final void initialize(final boolean writing) {
 		if ( initialized ) {
 			return;
 		}
 
 		withTemporarySessionIfNeeded(
 				new LazyInitializationWork<Object>() {
 					@Override
 					public Object doWork() {
 						session.initializeCollection( AbstractPersistentCollection.this, writing );
 						return null;
 					}
 				}
 		);
 	}
 
 	private void throwLazyInitializationExceptionIfNotConnected() {
 		if ( !isConnectedToSession() ) {
 			throwLazyInitializationException( "no session or session was closed" );
 		}
 		if ( !session.isConnected() ) {
 			throwLazyInitializationException( "session is disconnected" );
 		}
 	}
 
 	private void throwLazyInitializationException(String message) {
 		throw new LazyInitializationException(
 				"failed to lazily initialize a collection" +
 						(role == null ? "" : " of role: " + role) +
 						", " + message
 		);
 	}
 
 	protected final void setInitialized() {
 		this.initializing = false;
 		this.initialized = true;
 	}
 
 	protected final void setDirectlyAccessible(boolean directlyAccessible) {
 		this.directlyAccessible = directlyAccessible;
 	}
 
 	@Override
 	public boolean isDirectlyAccessible() {
 		return directlyAccessible;
 	}
 
 	@Override
 	public final boolean unsetSession(SessionImplementor currentSession) {
 		prepareForPossibleLoadingOutsideTransaction();
 		if ( currentSession == this.session ) {
 			this.session = null;
 			return true;
 		}
 		else {
 			return false;
 		}
 	}
 
 	protected void prepareForPossibleLoadingOutsideTransaction() {
 		if ( session != null ) {
 			allowLoadOutsideTransaction = session.getFactory().getSettings().isInitializeLazyStateOutsideTransactionsEnabled();
 
 			if ( allowLoadOutsideTransaction && sessionFactoryUuid == null ) {
 				try {
 					sessionFactoryUuid = (String) session.getFactory().getReference().get( "uuid" ).getContent();
 				}
 				catch (NamingException e) {
 					//not much we can do if this fails...
 				}
 			}
 		}
 	}
 
 
 	@Override
 	public final boolean setCurrentSession(SessionImplementor session) throws HibernateException {
 		if ( session == this.session ) {
 			return false;
 		}
 		else {
 			if ( isConnectedToSession() ) {
 				final CollectionEntry ce = session.getPersistenceContext().getCollectionEntry( this );
 				if ( ce == null ) {
 					throw new HibernateException(
 							"Illegal attempt to associate a collection with two open sessions"
 					);
 				}
 				else {
 					throw new HibernateException(
 							"Illegal attempt to associate a collection with two open sessions: " +
 									MessageHelper.collectionInfoString(
 											ce.getLoadedPersister(), this,
 											ce.getLoadedKey(), session
 									)
 					);
 				}
 			}
 			else {
 				this.session = session;
 				return true;
 			}
 		}
 	}
 
 	@Override
 	public boolean needsRecreate(CollectionPersister persister) {
 		// Workaround for situations like HHH-7072.  If the collection element is a component that consists entirely
 		// of nullable properties, we currently have to forcefully recreate the entire collection.  See the use
 		// of hasNotNullableColumns in the AbstractCollectionPersister constructor for more info.  In order to delete
 		// row-by-row, that would require SQL like "WHERE ( COL = ? OR ( COL is null AND ? is null ) )", rather than
 		// the current "WHERE COL = ?" (fails for null for most DBs).  Note that
 		// the param would have to be bound twice.  Until we eventually add "parameter bind points" concepts to the
 		// AST in ORM 5+, handling this type of condition is either extremely difficult or impossible.  Forcing
 		// recreation isn't ideal, but not really any other option in ORM 4.
 		if (persister.getElementType() instanceof ComponentType) {
 			ComponentType componentType = (ComponentType) persister.getElementType();
 			return !componentType.hasNotNullProperty();
 		}
 		return false;
 	}
 
 	@Override
 	public final void forceInitialization() throws HibernateException {
 		if ( !initialized ) {
 			if ( initializing ) {
 				throw new AssertionFailure( "force initialize loading collection" );
 			}
 			if ( session == null ) {
 				throw new HibernateException( "collection is not associated with any session" );
 			}
 			if ( !session.isConnected() ) {
 				throw new HibernateException( "disconnected session" );
 			}
 			session.initializeCollection( this, false );
 		}
 	}
 
 
 	/**
 	 * Get the current snapshot from the session
 	 */
 	@SuppressWarnings({"JavaDoc"})
 	protected final Serializable getSnapshot() {
 		return session.getPersistenceContext().getSnapshot( this );
 	}
 
 	@Override
 	public final boolean wasInitialized() {
 		return initialized;
 	}
 
 	@Override
 	public boolean isRowUpdatePossible() {
 		return true;
 	}
 
 	@Override
 	public final boolean hasQueuedOperations() {
 		return operationQueue != null;
 	}
 
 	@Override
 	public final Iterator queuedAdditionIterator() {
 		if ( hasQueuedOperations() ) {
 			return new Iterator() {
 				private int index;
 
 				@Override
 				public Object next() {
 					return operationQueue.get( index++ ).getAddedInstance();
 				}
 
 				@Override
 				public boolean hasNext() {
 					return index < operationQueue.size();
 				}
 
 				@Override
 				public void remove() {
 					throw new UnsupportedOperationException();
 				}
 			};
 		}
 		else {
 			return EmptyIterator.INSTANCE;
 		}
 	}
 
 	@Override
 	@SuppressWarnings({"unchecked"})
 	public final Collection getQueuedOrphans(String entityName) {
 		if ( hasQueuedOperations() ) {
 			final Collection additions = new ArrayList( operationQueue.size() );
 			final Collection removals = new ArrayList( operationQueue.size() );
 			for ( DelayedOperation operation : operationQueue ) {
 				additions.add( operation.getAddedInstance() );
 				removals.add( operation.getOrphan() );
 			}
 			return getOrphans( removals, additions, entityName, session );
 		}
 		else {
 			return Collections.EMPTY_LIST;
 		}
 	}
 
 	@Override
 	public void preInsert(CollectionPersister persister) throws HibernateException {
 	}
 
 	@Override
 	public void afterRowInsert(CollectionPersister persister, Object entry, int i) throws HibernateException {
 	}
 
 	@Override
 	public abstract Collection getOrphans(Serializable snapshot, String entityName) throws HibernateException;
 
 	/**
 	 * Get the session currently associated with this collection.
 	 *
 	 * @return The session
 	 */
 	public final SessionImplementor getSession() {
 		return session;
 	}
 
 	protected final class IteratorProxy implements Iterator {
 		protected final Iterator itr;
 
 		public IteratorProxy(Iterator itr) {
 			this.itr = itr;
 		}
 
 		@Override
 		public boolean hasNext() {
 			return itr.hasNext();
 		}
 
 		@Override
 		public Object next() {
 			return itr.next();
 		}
 
 		@Override
 		public void remove() {
 			write();
 			itr.remove();
 		}
 	}
 
 	protected final class ListIteratorProxy implements ListIterator {
 		protected final ListIterator itr;
 
 		public ListIteratorProxy(ListIterator itr) {
 			this.itr = itr;
 		}
 
 		@Override
 		@SuppressWarnings({"unchecked"})
 		public void add(Object o) {
 			write();
 			itr.add( o );
 		}
 
 		@Override
 		public boolean hasNext() {
 			return itr.hasNext();
 		}
 
 		@Override
 		public boolean hasPrevious() {
 			return itr.hasPrevious();
 		}
 
 		@Override
 		public Object next() {
 			return itr.next();
 		}
 
 		@Override
 		public int nextIndex() {
 			return itr.nextIndex();
 		}
 
 		@Override
 		public Object previous() {
 			return itr.previous();
 		}
 
 		@Override
 		public int previousIndex() {
 			return itr.previousIndex();
 		}
 
 		@Override
 		public void remove() {
 			write();
 			itr.remove();
 		}
 
 		@Override
 		@SuppressWarnings({"unchecked"})
 		public void set(Object o) {
 			write();
 			itr.set( o );
 		}
 	}
 
 	protected class SetProxy implements java.util.Set {
 		protected final Collection set;
 
 		public SetProxy(Collection set) {
 			this.set = set;
 		}
 
 		@Override
 		@SuppressWarnings({"unchecked"})
 		public boolean add(Object o) {
 			write();
 			return set.add( o );
 		}
 
 		@Override
 		@SuppressWarnings({"unchecked"})
 		public boolean addAll(Collection c) {
 			write();
 			return set.addAll( c );
 		}
 
 		@Override
 		public void clear() {
 			write();
 			set.clear();
 		}
 
 		@Override
 		public boolean contains(Object o) {
 			return set.contains( o );
 		}
 
 		@Override
 		@SuppressWarnings("unchecked")
 		public boolean containsAll(Collection c) {
 			return set.containsAll( c );
 		}
 
 		@Override
 		public boolean isEmpty() {
 			return set.isEmpty();
 		}
 
 		@Override
 		public Iterator iterator() {
 			return new IteratorProxy( set.iterator() );
 		}
 
 		@Override
 		public boolean remove(Object o) {
 			write();
 			return set.remove( o );
 		}
 
 		@Override
 		@SuppressWarnings("unchecked")
 		public boolean removeAll(Collection c) {
 			write();
 			return set.removeAll( c );
 		}
 
 		@Override
 		@SuppressWarnings("unchecked")
 		public boolean retainAll(Collection c) {
 			write();
 			return set.retainAll( c );
 		}
 
 		@Override
 		public int size() {
 			return set.size();
 		}
 
 		@Override
 		public Object[] toArray() {
 			return set.toArray();
 		}
 
 		@Override
 		@SuppressWarnings({"unchecked"})
 		public Object[] toArray(Object[] array) {
 			return set.toArray( array );
 		}
 	}
 
 	protected final class ListProxy implements java.util.List {
 		protected final List list;
 
 		public ListProxy(List list) {
 			this.list = list;
 		}
 
 		@Override
 		@SuppressWarnings({"unchecked"})
 		public void add(int index, Object value) {
 			write();
 			list.add( index, value );
 		}
 
 		@Override
 		@SuppressWarnings({"unchecked"})
 		public boolean add(Object o) {
 			write();
 			return list.add( o );
 		}
 
 		@Override
 		@SuppressWarnings({"unchecked"})
 		public boolean addAll(Collection c) {
 			write();
 			return list.addAll( c );
 		}
 
 		@Override
 		@SuppressWarnings({"unchecked"})
 		public boolean addAll(int i, Collection c) {
 			write();
 			return list.addAll( i, c );
 		}
 
 		@Override
 		public void clear() {
 			write();
 			list.clear();
 		}
 
 		@Override
 		public boolean contains(Object o) {
 			return list.contains( o );
 		}
 
 		@Override
 		@SuppressWarnings("unchecked")
 		public boolean containsAll(Collection c) {
 			return list.containsAll( c );
 		}
 
 		@Override
 		public Object get(int i) {
 			return list.get( i );
 		}
 
 		@Override
 		public int indexOf(Object o) {
 			return list.indexOf( o );
 		}
 
 		@Override
 		public boolean isEmpty() {
 			return list.isEmpty();
 		}
 
 		@Override
 		public Iterator iterator() {
 			return new IteratorProxy( list.iterator() );
 		}
 
 		@Override
 		public int lastIndexOf(Object o) {
 			return list.lastIndexOf( o );
 		}
 
 		@Override
 		public ListIterator listIterator() {
 			return new ListIteratorProxy( list.listIterator() );
 		}
 
 		@Override
 		public ListIterator listIterator(int i) {
 			return new ListIteratorProxy( list.listIterator( i ) );
 		}
 
 		@Override
 		public Object remove(int i) {
 			write();
 			return list.remove( i );
 		}
 
 		@Override
 		public boolean remove(Object o) {
 			write();
 			return list.remove( o );
 		}
 
 		@Override
 		@SuppressWarnings("unchecked")
 		public boolean removeAll(Collection c) {
 			write();
 			return list.removeAll( c );
 		}
 
 		@Override
 		@SuppressWarnings("unchecked")
 		public boolean retainAll(Collection c) {
 			write();
 			return list.retainAll( c );
 		}
 
 		@Override
 		@SuppressWarnings({"unchecked"})
 		public Object set(int i, Object o) {
 			write();
 			return list.set( i, o );
 		}
 
 		@Override
 		public int size() {
 			return list.size();
 		}
 
 		@Override
 		public List subList(int i, int j) {
 			return list.subList( i, j );
 		}
 
 		@Override
 		public Object[] toArray() {
 			return list.toArray();
 		}
 
 		@Override
 		@SuppressWarnings({"unchecked"})
 		public Object[] toArray(Object[] array) {
 			return list.toArray( array );
 		}
 
 	}
 
 	/**
 	 * Contract for operations which are part of a collection's operation queue.
 	 */
 	protected interface DelayedOperation {
 		public void operate();
 
 		public Object getAddedInstance();
 
 		public Object getOrphan();
 	}
 
 	/**
 	 * Given a collection of entity instances that used to
 	 * belong to the collection, and a collection of instances
 	 * that currently belong, return a collection of orphans
 	 */
 	@SuppressWarnings({"JavaDoc", "unchecked"})
 	protected static Collection getOrphans(
 			Collection oldElements,
 			Collection currentElements,
 			String entityName,
 			SessionImplementor session) throws HibernateException {
 
 		// short-circuit(s)
 		if ( currentElements.size() == 0 ) {
 			// no new elements, the old list contains only Orphans
 			return oldElements;
 		}
 		if ( oldElements.size() == 0 ) {
 			// no old elements, so no Orphans neither
 			return oldElements;
 		}
 
 		final EntityPersister entityPersister = session.getFactory().getEntityPersister( entityName );
 		final Type idType = entityPersister.getIdentifierType();
 		final boolean useIdDirect = mayUseIdDirect( idType );
 
 		// create the collection holding the Orphans
 		final Collection res = new ArrayList();
 
 		// collect EntityIdentifier(s) of the *current* elements - add them into a HashSet for fast access
 		final java.util.Set currentIds = new HashSet();
 		final java.util.Set currentSaving = new IdentitySet();
 		for ( Object current : currentElements ) {
 			if ( current != null && ForeignKeys.isNotTransient( entityName, current, null, session ) ) {
 				final EntityEntry ee = session.getPersistenceContext().getEntry( current );
 				if ( ee != null && ee.getStatus() == Status.SAVING ) {
 					currentSaving.add( current );
 				}
 				else {
 					final Serializable currentId = ForeignKeys.getEntityIdentifierIfNotUnsaved(
 							entityName,
 							current,
 							session
 					);
 					currentIds.add( useIdDirect ? currentId : new TypedValue( idType, currentId ) );
 				}
 			}
 		}
 
 		// iterate over the *old* list
 		for ( Object old : oldElements ) {
 			if ( !currentSaving.contains( old ) ) {
 				final Serializable oldId = ForeignKeys.getEntityIdentifierIfNotUnsaved( entityName, old, session );
 				if ( !currentIds.contains( useIdDirect ? oldId : new TypedValue( idType, oldId ) ) ) {
 					res.add( old );
 				}
 			}
 		}
 
 		return res;
 	}
 
 	private static boolean mayUseIdDirect(Type idType) {
 		return idType == StringType.INSTANCE
 			|| idType == IntegerType.INSTANCE
 			|| idType == LongType.INSTANCE
 			|| idType == UUIDBinaryType.INSTANCE
 			|| idType == UUIDCharType.INSTANCE
 			|| idType == PostgresUUIDType.INSTANCE;
 	}
 
 	/**
 	 * Removes entity entries that have an equal identifier with the incoming entity instance
 	 *
 	 * @param list The list containing the entity instances
 	 * @param entityInstance The entity instance to match elements.
 	 * @param entityName The entity name
 	 * @param session The session
 	 */
 	public static void identityRemove(
 			Collection list,
 			Object entityInstance,
 			String entityName,
 			SessionImplementor session) {
 
 		if ( entityInstance != null && ForeignKeys.isNotTransient( entityName, entityInstance, null, session ) ) {
 			final EntityPersister entityPersister = session.getFactory().getEntityPersister( entityName );
 			final Type idType = entityPersister.getIdentifierType();
 
 			final Serializable idOfCurrent = ForeignKeys.getEntityIdentifierIfNotUnsaved( entityName, entityInstance, session );
 			final Iterator itr = list.iterator();
 			while ( itr.hasNext() ) {
 				final Serializable idOfOld = ForeignKeys.getEntityIdentifierIfNotUnsaved( entityName, itr.next(), session );
 				if ( idType.isEqual( idOfCurrent, idOfOld, session.getFactory() ) ) {
 					itr.remove();
 					break;
 				}
 			}
 
 		}
 	}
 
 	@Override
 	public Object getIdentifier(Object entry, int i) {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public Object getOwner() {
 		return owner;
 	}
 
 	@Override
 	public void setOwner(Object owner) {
 		this.owner = owner;
 	}
 
 }
 
diff --git a/hibernate-core/src/main/java/org/hibernate/context/internal/ThreadLocalSessionContext.java b/hibernate-core/src/main/java/org/hibernate/context/internal/ThreadLocalSessionContext.java
index a1b991c504..8902de93c5 100644
--- a/hibernate-core/src/main/java/org/hibernate/context/internal/ThreadLocalSessionContext.java
+++ b/hibernate-core/src/main/java/org/hibernate/context/internal/ThreadLocalSessionContext.java
@@ -1,397 +1,396 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.context.internal;
 
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.lang.reflect.InvocationHandler;
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Method;
 import java.lang.reflect.Proxy;
 import java.util.HashMap;
 import java.util.Map;
 import javax.transaction.Synchronization;
 
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.HibernateException;
 import org.hibernate.Session;
 import org.hibernate.SessionFactory;
 import org.hibernate.context.spi.AbstractCurrentSessionContext;
 import org.hibernate.engine.jdbc.LobCreationContext;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.engine.transaction.spi.TransactionContext;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.resource.transaction.spi.TransactionStatus;
 
 import org.jboss.logging.Logger;
 
 /**
  * A {@link org.hibernate.context.spi.CurrentSessionContext} impl which scopes the notion of current
  * session by the current thread of execution.  Unlike the JTA counterpart, threads do not give us a nice
  * hook to perform any type of cleanup making it questionable for this impl to actually generate Session
  * instances.  In the interest of usability, it was decided to have this default impl actually generate
  * a session upon first request and then clean it up after the {@link org.hibernate.Transaction}
  * associated with that session is committed/rolled-back.  In order for ensuring that happens, the
  * sessions generated here are unusable until after {@link Session#beginTransaction()} has been
  * called. If <tt>close()</tt> is called on a session managed by this class, it will be automatically
  * unbound.
  *
  * Additionally, the static {@link #bind} and {@link #unbind} methods are provided to allow application
  * code to explicitly control opening and closing of these sessions.  This, with some from of interception,
  * is the preferred approach.  It also allows easy framework integration and one possible approach for
  * implementing long-sessions.
  *
  * The {@link #buildOrObtainSession}, {@link #isAutoCloseEnabled}, {@link #isAutoFlushEnabled},
  * {@link #getConnectionReleaseMode}, and {@link #buildCleanupSynch} methods are all provided to allow easy
  * subclassing (for long-running session scenarios, for example).
  *
  * @author Steve Ebersole
  */
 public class ThreadLocalSessionContext extends AbstractCurrentSessionContext {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			ThreadLocalSessionContext.class.getName()
 	);
 
 	private static final Class[] SESSION_PROXY_INTERFACES = new Class[] {
 			Session.class,
 			SessionImplementor.class,
 			EventSource.class,
-			TransactionContext.class,
 			LobCreationContext.class
 	};
 
 	/**
 	 * A ThreadLocal maintaining current sessions for the given execution thread.
 	 * The actual ThreadLocal variable is a java.util.Map to account for
 	 * the possibility for multiple SessionFactory instances being used during execution
 	 * of the given thread.
 	 */
 	private static final ThreadLocal<Map> CONTEXT_TL = new ThreadLocal<Map>();
 
 	/**
 	 * Constructs a ThreadLocal
 	 *
 	 * @param factory The factory this context will service
 	 */
 	public ThreadLocalSessionContext(SessionFactoryImplementor factory) {
 		super( factory );
 	}
 
 	@Override
 	public final Session currentSession() throws HibernateException {
 		Session current = existingSession( factory() );
 		if ( current == null ) {
 			current = buildOrObtainSession();
 			// register a cleanup sync
 			current.getTransaction().registerSynchronization( buildCleanupSynch() );
 			// wrap the session in the transaction-protection proxy
 			if ( needsWrapping( current ) ) {
 				current = wrap( current );
 			}
 			// then bind it
 			doBind( current, factory() );
 		}
 		else {
 			validateExistingSession( current );
 		}
 		return current;
 	}
 
 	private boolean needsWrapping(Session session) {
 		// try to make sure we don't wrap and already wrapped session
 		if ( session != null ) {
 			if ( Proxy.isProxyClass( session.getClass() ) ) {
 				final InvocationHandler invocationHandler = Proxy.getInvocationHandler( session );
 				if ( invocationHandler != null && TransactionProtectionWrapper.class.isInstance( invocationHandler ) ) {
 					return false;
 				}
 			}
 		}
 		return true;
 	}
 
 	/**
 	 * Getter for property 'factory'.
 	 *
 	 * @return Value for property 'factory'.
 	 */
 	protected SessionFactoryImplementor getFactory() {
 		return factory();
 	}
 
 	/**
 	 * Strictly provided for sub-classing purposes; specifically to allow long-session
 	 * support.
 	 * <p/>
 	 * This implementation always just opens a new session.
 	 *
 	 * @return the built or (re)obtained session.
 	 */
 	@SuppressWarnings("deprecation")
 	protected Session buildOrObtainSession() {
 		return baseSessionBuilder()
 				.autoClose( isAutoCloseEnabled() )
 				.connectionReleaseMode( getConnectionReleaseMode() )
 				.flushBeforeCompletion( isAutoFlushEnabled() )
 				.openSession();
 	}
 
 	protected CleanupSync buildCleanupSynch() {
 		return new CleanupSync( factory() );
 	}
 
 	/**
 	 * Mainly for subclass usage.  This impl always returns true.
 	 *
 	 * @return Whether or not the the session should be closed by transaction completion.
 	 */
 	protected boolean isAutoCloseEnabled() {
 		return true;
 	}
 
 	/**
 	 * Mainly for subclass usage.  This impl always returns true.
 	 *
 	 * @return Whether or not the the session should be flushed prior transaction completion.
 	 */
 	protected boolean isAutoFlushEnabled() {
 		return true;
 	}
 
 	/**
 	 * Mainly for subclass usage.  This impl always returns after_transaction.
 	 *
 	 * @return The connection release mode for any built sessions.
 	 */
 	protected ConnectionReleaseMode getConnectionReleaseMode() {
 		return factory().getSettings().getConnectionReleaseMode();
 	}
 
 	protected Session wrap(Session session) {
 		final TransactionProtectionWrapper wrapper = new TransactionProtectionWrapper( session );
 		final Session wrapped = (Session) Proxy.newProxyInstance(
 				Session.class.getClassLoader(),
 				SESSION_PROXY_INTERFACES,
 				wrapper
 		);
 		// yick!  need this for proper serialization/deserialization handling...
 		wrapper.setWrapped( wrapped );
 		return wrapped;
 	}
 
 	/**
 	 * Associates the given session with the current thread of execution.
 	 *
 	 * @param session The session to bind.
 	 */
 	public static void bind(org.hibernate.Session session) {
 		final SessionFactory factory = session.getSessionFactory();
 		cleanupAnyOrphanedSession( factory );
 		doBind( session, factory );
 	}
 
 	private static void cleanupAnyOrphanedSession(SessionFactory factory) {
 		final Session orphan = doUnbind( factory, false );
 		if ( orphan != null ) {
 			LOG.alreadySessionBound();
 			try {
-				if ( orphan.getTransaction() != null && orphan.getTransaction().isActive() ) {
+				if ( orphan.getTransaction() != null && orphan.getTransaction().getStatus() == TransactionStatus.ACTIVE ) {
 					try {
 						orphan.getTransaction().rollback();
 					}
 					catch( Throwable t ) {
 						LOG.debug( "Unable to rollback transaction for orphaned session", t );
 					}
 				}
 				orphan.close();
 			}
 			catch( Throwable t ) {
 				LOG.debug( "Unable to close orphaned session", t );
 			}
 		}
 	}
 
 	/**
 	 * Disassociates a previously bound session from the current thread of execution.
 	 *
 	 * @param factory The factory for which the session should be unbound.
 	 * @return The session which was unbound.
 	 */
 	public static Session unbind(SessionFactory factory) {
 		return doUnbind( factory, true );
 	}
 
 	private static Session existingSession(SessionFactory factory) {
 		final Map sessionMap = sessionMap();
 		if ( sessionMap == null ) {
 			return null;
 		}
 		return (Session) sessionMap.get( factory );
 	}
 
 	protected static Map sessionMap() {
 		return CONTEXT_TL.get();
 	}
 
 	@SuppressWarnings({"unchecked"})
 	private static void doBind(org.hibernate.Session session, SessionFactory factory) {
 		Map sessionMap = sessionMap();
 		if ( sessionMap == null ) {
 			sessionMap = new HashMap();
 			CONTEXT_TL.set( sessionMap );
 		}
 		sessionMap.put( factory, session );
 	}
 
 	private static Session doUnbind(SessionFactory factory, boolean releaseMapIfEmpty) {
 		Session session = null;
 		final Map sessionMap = sessionMap();
 		if ( sessionMap != null ) {
 			session = (Session) sessionMap.remove( factory );
 			if ( releaseMapIfEmpty && sessionMap.isEmpty() ) {
 				CONTEXT_TL.set( null );
 			}
 		}
 		return session;
 	}
 
 	/**
 	 * Transaction sync used for cleanup of the internal session map.
 	 */
 	protected static class CleanupSync implements Synchronization, Serializable {
 		protected final SessionFactory factory;
 
 		public CleanupSync(SessionFactory factory) {
 			this.factory = factory;
 		}
 
 		@Override
 		public void beforeCompletion() {
 		}
 
 		@Override
 		public void afterCompletion(int i) {
 			unbind( factory );
 		}
 	}
 
 	private class TransactionProtectionWrapper implements InvocationHandler, Serializable {
 		private final Session realSession;
 		private Session wrappedSession;
 
 		public TransactionProtectionWrapper(Session realSession) {
 			this.realSession = realSession;
 		}
 
 		@Override
 		public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
 			final String methodName = method.getName(); 
 			try {
 				// If close() is called, guarantee unbind()
 				if ( "close".equals( methodName ) ) {
 					unbind( realSession.getSessionFactory() );
 				}
 				else if ( "toString".equals( methodName )
 						|| "equals".equals( methodName )
 						|| "hashCode".equals( methodName )
 						|| "getStatistics".equals( methodName )
 						|| "isOpen".equals( methodName )
 						|| "getListeners".equals( methodName ) ) {
 					// allow these to go through the the real session no matter what
 					LOG.tracef( "Allowing invocation [%s] to proceed to real session", methodName );
 				}
 				else if ( !realSession.isOpen() ) {
 					// essentially, if the real session is closed allow any
 					// method call to pass through since the real session
 					// will complain by throwing an appropriate exception;
 					// NOTE that allowing close() above has the same basic effect,
 					//   but we capture that there simply to doAfterTransactionCompletion the unbind...
 					LOG.tracef( "Allowing invocation [%s] to proceed to real (closed) session", methodName );
 				}
-				else if ( !realSession.getTransaction().isActive() ) {
+				else if ( realSession.getTransaction().getStatus() != TransactionStatus.ACTIVE ) {
 					// limit the methods available if no transaction is active
 					if ( "beginTransaction".equals( methodName )
 							|| "getTransaction".equals( methodName )
 							|| "isTransactionInProgress".equals( methodName )
 							|| "setFlushMode".equals( methodName )
 							|| "getFactory".equals( methodName )
 							|| "getSessionFactory".equals( methodName )
 							|| "getTenantIdentifier".equals( methodName ) ) {
 						LOG.tracef( "Allowing invocation [%s] to proceed to real (non-transacted) session", methodName );
 					}
 					else if ( "reconnect".equals( methodName ) || "disconnect".equals( methodName ) ) {
 						// allow these (deprecated) methods to pass through
 						LOG.tracef( "Allowing invocation [%s] to proceed to real (non-transacted) session - deprecated methods", methodName );
 					}
 					else {
 						throw new HibernateException( methodName + " is not valid without active transaction" );
 					}
 				}
 				LOG.tracef( "Allowing proxy invocation [%s] to proceed to real session", methodName );
 				return method.invoke( realSession, args );
 			}
 			catch ( InvocationTargetException e ) {
 				if (e.getTargetException() instanceof RuntimeException) {
 					throw (RuntimeException)e.getTargetException();
 				}
 				throw e;
 			}
 		}
 
 		/**
 		 * Setter for property 'wrapped'.
 		 *
 		 * @param wrapped Value to set for property 'wrapped'.
 		 */
 		public void setWrapped(Session wrapped) {
 			this.wrappedSession = wrapped;
 		}
 
 
 		// serialization ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		private void writeObject(ObjectOutputStream oos) throws IOException {
 			// if a ThreadLocalSessionContext-bound session happens to get
 			// serialized, to be completely correct, we need to make sure
 			// that unbinding of that session occurs.
 			oos.defaultWriteObject();
 			if ( existingSession( factory() ) == wrappedSession ) {
 				unbind( factory() );
 			}
 		}
 
 		private void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException {
 			// on the inverse, it makes sense that if a ThreadLocalSessionContext-
 			// bound session then gets deserialized to go ahead and re-bind it to
 			// the ThreadLocalSessionContext session map.
 			ois.defaultReadObject();
 			realSession.getTransaction().registerSynchronization( buildCleanupSynch() );
 			doBind( wrappedSession, factory() );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticReadSelectLockingStrategy.java b/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticReadSelectLockingStrategy.java
index 5f52a37ddb..09337215bc 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticReadSelectLockingStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticReadSelectLockingStrategy.java
@@ -1,137 +1,138 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect.lock;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.JDBCException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.SimpleSelect;
 
 /**
  * A pessimistic locking strategy where the locks are obtained through select statements.
  * <p/>
  * For non-read locks, this is achieved through the Dialect's specific
  * SELECT ... FOR UPDATE syntax.
  *
  * This strategy is valid for LockMode.PESSIMISTIC_READ
  *
  * This class is a clone of SelectLockingStrategy.
  *
  * @author Steve Ebersole
  * @author Scott Marlow
  *
  * @see org.hibernate.dialect.Dialect#getForUpdateString(org.hibernate.LockMode)
  * @see org.hibernate.dialect.Dialect#appendLockHint(org.hibernate.LockMode, String)
  *
  * @since 3.5
  */
 public class PessimisticReadSelectLockingStrategy extends AbstractSelectLockingStrategy {
 	/**
 	 * Construct a locking strategy based on SQL SELECT statements.
 	 *
 	 * @param lockable The metadata for the entity to be locked.
 	 * @param lockMode Indicates the type of lock to be acquired.
 	 */
 	public PessimisticReadSelectLockingStrategy(Lockable lockable, LockMode lockMode) {
 		super( lockable, lockMode );
 	}
 
 	@Override
 	public void lock(Serializable id, Object version, Object object, int timeout, SessionImplementor session) {
 		final String sql = determineSql( timeout );
 		final SessionFactoryImplementor factory = session.getFactory();
 		try {
 			try {
-				final PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
+				final PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 				try {
 					getLockable().getIdentifierType().nullSafeSet( st, id, 1, session );
 					if ( getLockable().isVersioned() ) {
 						getLockable().getVersionType().nullSafeSet(
 								st,
 								version,
 								getLockable().getIdentifierType().getColumnSpan( factory ) + 1,
 								session
 						);
 					}
 
-					final ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
+					final ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 					try {
 						if ( !rs.next() ) {
 							if ( factory.getStatistics().isStatisticsEnabled() ) {
 								factory.getStatisticsImplementor()
 										.optimisticFailure( getLockable().getEntityName() );
 							}
 							throw new StaleObjectStateException( getLockable().getEntityName(), id );
 						}
 					}
 					finally {
-						session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
+						session.getJdbcCoordinator().getResourceRegistry().release( rs, st );
 					}
 				}
 				finally {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+					session.getJdbcCoordinator().getResourceRegistry().release( st );
+					session.getJdbcCoordinator().afterStatementExecution();
 				}
 
 			}
 			catch ( SQLException e ) {
 				throw session.getFactory().getSQLExceptionHelper().convert(
 						e,
 						"could not lock: " + MessageHelper.infoString( getLockable(), id, session.getFactory() ),
 						sql
 				);
 			}
 		}
 		catch (JDBCException e) {
 			throw new PessimisticEntityLockException( object, "could not obtain pessimistic lock", e );
 		}
 	}
 
 	protected String generateLockString(int lockTimeout) {
 		final SessionFactoryImplementor factory = getLockable().getFactory();
 		final LockOptions lockOptions = new LockOptions( getLockMode() );
 		lockOptions.setTimeOut( lockTimeout );
 		final SimpleSelect select = new SimpleSelect( factory.getDialect() )
 				.setLockOptions( lockOptions )
 				.setTableName( getLockable().getRootTableName() )
 				.addColumn( getLockable().getRootTableIdentifierColumnNames()[0] )
 				.addCondition( getLockable().getRootTableIdentifierColumnNames(), "=?" );
 		if ( getLockable().isVersioned() ) {
 			select.addCondition( getLockable().getVersionColumnName(), "=?" );
 		}
 		if ( factory.getSettings().isCommentsEnabled() ) {
 			select.setComment( getLockMode() + " lock " + getLockable().getEntityName() );
 		}
 		return select.toStatementString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticReadUpdateLockingStrategy.java b/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticReadUpdateLockingStrategy.java
index ef84a8ac32..45ac9564d1 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticReadUpdateLockingStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticReadUpdateLockingStrategy.java
@@ -1,151 +1,152 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect.lock;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.JDBCException;
 import org.hibernate.LockMode;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Update;
 
 import org.jboss.logging.Logger;
 
 /**
  * A pessimistic locking strategy where the locks are obtained through update statements.
  * <p/>
  * This strategy is valid for LockMode.PESSIMISTIC_READ
  *
  * This class is a clone of UpdateLockingStrategy.
  *
  * @author Steve Ebersole
  * @author Scott Marlow
  * @since 3.5
  */
 public class PessimisticReadUpdateLockingStrategy implements LockingStrategy {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			PessimisticReadUpdateLockingStrategy.class.getName()
 	);
 
 	private final Lockable lockable;
 	private final LockMode lockMode;
 	private final String sql;
 
 	/**
 	 * Construct a locking strategy based on SQL UPDATE statements.
 	 *
 	 * @param lockable The metadata for the entity to be locked.
 	 * @param lockMode Indicates the type of lock to be acquired.  Note that
 	 * read-locks are not valid for this strategy.
 	 */
 	public PessimisticReadUpdateLockingStrategy(Lockable lockable, LockMode lockMode) {
 		this.lockable = lockable;
 		this.lockMode = lockMode;
 		if ( lockMode.lessThan( LockMode.PESSIMISTIC_READ ) ) {
 			throw new HibernateException( "[" + lockMode + "] not valid for update statement" );
 		}
 		if ( !lockable.isVersioned() ) {
 			LOG.writeLocksNotSupported( lockable.getEntityName() );
 			this.sql = null;
 		}
 		else {
 			this.sql = generateLockString();
 		}
 	}
 
 	@Override
 	public void lock(Serializable id, Object version, Object object, int timeout, SessionImplementor session) {
 		if ( !lockable.isVersioned() ) {
 			throw new HibernateException( "write locks via update not supported for non-versioned entities [" + lockable.getEntityName() + "]" );
 		}
 
 		final SessionFactoryImplementor factory = session.getFactory();
 		try {
 			try {
-				final PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
+				final PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 				try {
 					lockable.getVersionType().nullSafeSet( st, version, 1, session );
 					int offset = 2;
 
 					lockable.getIdentifierType().nullSafeSet( st, id, offset, session );
 					offset += lockable.getIdentifierType().getColumnSpan( factory );
 
 					if ( lockable.isVersioned() ) {
 						lockable.getVersionType().nullSafeSet( st, version, offset, session );
 					}
 
-					final int affected = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st );
+					final int affected = session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st );
 					// todo:  should this instead check for exactly one row modified?
 					if ( affected < 0 ) {
 						if (factory.getStatistics().isStatisticsEnabled()) {
 							factory.getStatisticsImplementor().optimisticFailure( lockable.getEntityName() );
 						}
 						throw new StaleObjectStateException( lockable.getEntityName(), id );
 					}
 
 				}
 				finally {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+					session.getJdbcCoordinator().getResourceRegistry().release( st );
+					session.getJdbcCoordinator().afterStatementExecution();
 				}
 
 			}
 			catch ( SQLException e ) {
 				throw session.getFactory().getSQLExceptionHelper().convert(
 						e,
 						"could not lock: " + MessageHelper.infoString( lockable, id, session.getFactory() ),
 						sql
 				);
 			}
 		}
 		catch (JDBCException e) {
 			throw new PessimisticEntityLockException( object, "could not obtain pessimistic lock", e );
 		}
 	}
 
 	protected String generateLockString() {
 		final SessionFactoryImplementor factory = lockable.getFactory();
 		final Update update = new Update( factory.getDialect() );
 		update.setTableName( lockable.getRootTableName() );
 		update.addPrimaryKeyColumns( lockable.getRootTableIdentifierColumnNames() );
 		update.setVersionColumnName( lockable.getVersionColumnName() );
 		update.addColumn( lockable.getVersionColumnName() );
 		if ( factory.getSettings().isCommentsEnabled() ) {
 			update.setComment( lockMode + " lock " + lockable.getEntityName() );
 		}
 		return update.toStatementString();
 	}
 
 	protected LockMode getLockMode() {
 		return lockMode;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticWriteSelectLockingStrategy.java b/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticWriteSelectLockingStrategy.java
index e5267a10f4..c6c729252c 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticWriteSelectLockingStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticWriteSelectLockingStrategy.java
@@ -1,135 +1,136 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect.lock;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.JDBCException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.SimpleSelect;
 
 /**
  * A pessimistic locking strategy where the locks are obtained through select statements.
  * <p/>
  * For non-read locks, this is achieved through the Dialect's specific
  * SELECT ... FOR UPDATE syntax.
  *
  * This strategy is valid for LockMode.PESSIMISTIC_WRITE
  *
  * This class is a clone of SelectLockingStrategy.
  *
  * @see org.hibernate.dialect.Dialect#getForUpdateString(org.hibernate.LockMode)
  * @see org.hibernate.dialect.Dialect#appendLockHint(org.hibernate.LockMode, String)
  *
  * @author Steve Ebersole
  * @author Scott Marlow
  * @since 3.5
  */
 public class PessimisticWriteSelectLockingStrategy extends AbstractSelectLockingStrategy {
 	/**
 	 * Construct a locking strategy based on SQL SELECT statements.
 	 *
 	 * @param lockable The metadata for the entity to be locked.
 	 * @param lockMode Indicates the type of lock to be acquired.
 	 */
 	public PessimisticWriteSelectLockingStrategy(Lockable lockable, LockMode lockMode) {
 		super( lockable, lockMode );
 	}
 
 	@Override
 	public void lock(Serializable id, Object version, Object object, int timeout, SessionImplementor session) {
 		final String sql = determineSql( timeout );
 		final SessionFactoryImplementor factory = session.getFactory();
 		try {
 			try {
-				final PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
+				final PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 				try {
 					getLockable().getIdentifierType().nullSafeSet( st, id, 1, session );
 					if ( getLockable().isVersioned() ) {
 						getLockable().getVersionType().nullSafeSet(
 								st,
 								version,
 								getLockable().getIdentifierType().getColumnSpan( factory ) + 1,
 								session
 						);
 					}
 
-					final ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
+					final ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 					try {
 						if ( !rs.next() ) {
 							if ( factory.getStatistics().isStatisticsEnabled() ) {
 								factory.getStatisticsImplementor()
 										.optimisticFailure( getLockable().getEntityName() );
 							}
 							throw new StaleObjectStateException( getLockable().getEntityName(), id );
 						}
 					}
 					finally {
-						session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
+						session.getJdbcCoordinator().getResourceRegistry().release( rs, st );
 					}
 				}
 				finally {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+					session.getJdbcCoordinator().getResourceRegistry().release( st );
+					session.getJdbcCoordinator().afterStatementExecution();
 				}
 			}
 			catch ( SQLException e ) {
 				throw session.getFactory().getSQLExceptionHelper().convert(
 						e,
 						"could not lock: " + MessageHelper.infoString( getLockable(), id, session.getFactory() ),
 						sql
 				);
 			}
 		}
 		catch (JDBCException e) {
 			throw new PessimisticEntityLockException( object, "could not obtain pessimistic lock", e );
 		}
 	}
 
 	protected String generateLockString(int lockTimeout) {
 		final SessionFactoryImplementor factory = getLockable().getFactory();
 		final LockOptions lockOptions = new LockOptions( getLockMode() );
 		lockOptions.setTimeOut( lockTimeout );
 		final SimpleSelect select = new SimpleSelect( factory.getDialect() )
 				.setLockOptions( lockOptions )
 				.setTableName( getLockable().getRootTableName() )
 				.addColumn( getLockable().getRootTableIdentifierColumnNames()[0] )
 				.addCondition( getLockable().getRootTableIdentifierColumnNames(), "=?" );
 		if ( getLockable().isVersioned() ) {
 			select.addCondition( getLockable().getVersionColumnName(), "=?" );
 		}
 		if ( factory.getSettings().isCommentsEnabled() ) {
 			select.setComment( getLockMode() + " lock " + getLockable().getEntityName() );
 		}
 		return select.toStatementString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticWriteUpdateLockingStrategy.java b/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticWriteUpdateLockingStrategy.java
index 797e003960..d386e9a03c 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticWriteUpdateLockingStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/lock/PessimisticWriteUpdateLockingStrategy.java
@@ -1,149 +1,150 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect.lock;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.JDBCException;
 import org.hibernate.LockMode;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Update;
 
 import org.jboss.logging.Logger;
 
 /**
  * A pessimistic locking strategy where the locks are obtained through update statements.
  * <p/>
  * This strategy is valid for LockMode.PESSIMISTIC_WRITE
  *
  * This class is a clone of UpdateLockingStrategy.
  *
  * @author Steve Ebersole
  * @author Scott Marlow
  * @since 3.5
  */
 public class PessimisticWriteUpdateLockingStrategy implements LockingStrategy {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			PessimisticWriteUpdateLockingStrategy.class.getName()
 	);
 
 	private final Lockable lockable;
 	private final LockMode lockMode;
 	private final String sql;
 
 	/**
 	 * Construct a locking strategy based on SQL UPDATE statements.
 	 *
 	 * @param lockable The metadata for the entity to be locked.
 	 * @param lockMode Indicates the type of lock to be acquired.  Note that read-locks are not valid for this strategy.
 	 */
 	public PessimisticWriteUpdateLockingStrategy(Lockable lockable, LockMode lockMode) {
 		this.lockable = lockable;
 		this.lockMode = lockMode;
 		if ( lockMode.lessThan( LockMode.PESSIMISTIC_READ ) ) {
 			throw new HibernateException( "[" + lockMode + "] not valid for update statement" );
 		}
 		if ( !lockable.isVersioned() ) {
 			LOG.writeLocksNotSupported( lockable.getEntityName() );
 			this.sql = null;
 		}
 		else {
 			this.sql = generateLockString();
 		}
 	}
 
 	@Override
 	public void lock(Serializable id, Object version, Object object, int timeout, SessionImplementor session) {
 		if ( !lockable.isVersioned() ) {
 			throw new HibernateException( "write locks via update not supported for non-versioned entities [" + lockable.getEntityName() + "]" );
 		}
 
 		final SessionFactoryImplementor factory = session.getFactory();
 		try {
 			try {
-				final PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
+				final PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 				try {
 					lockable.getVersionType().nullSafeSet( st, version, 1, session );
 					int offset = 2;
 
 					lockable.getIdentifierType().nullSafeSet( st, id, offset, session );
 					offset += lockable.getIdentifierType().getColumnSpan( factory );
 
 					if ( lockable.isVersioned() ) {
 						lockable.getVersionType().nullSafeSet( st, version, offset, session );
 					}
 
-					final int affected = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st );
+					final int affected = session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st );
 					// todo:  should this instead check for exactly one row modified?
 					if ( affected < 0 ) {
 						if (factory.getStatistics().isStatisticsEnabled()) {
 							factory.getStatisticsImplementor().optimisticFailure( lockable.getEntityName() );
 						}
 						throw new StaleObjectStateException( lockable.getEntityName(), id );
 					}
 
 				}
 				finally {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+					session.getJdbcCoordinator().getResourceRegistry().release( st );
+					session.getJdbcCoordinator().afterStatementExecution();
 				}
 			}
 			catch ( SQLException e ) {
 				throw session.getFactory().getSQLExceptionHelper().convert(
 						e,
 						"could not lock: " + MessageHelper.infoString( lockable, id, session.getFactory() ),
 						sql
 				);
 			}
 		}
 		catch (JDBCException e) {
 			throw new PessimisticEntityLockException( object, "could not obtain pessimistic lock", e );
 		}
 	}
 
 	protected String generateLockString() {
 		final SessionFactoryImplementor factory = lockable.getFactory();
 		final Update update = new Update( factory.getDialect() );
 		update.setTableName( lockable.getRootTableName() );
 		update.addPrimaryKeyColumns( lockable.getRootTableIdentifierColumnNames() );
 		update.setVersionColumnName( lockable.getVersionColumnName() );
 		update.addColumn( lockable.getVersionColumnName() );
 		if ( factory.getSettings().isCommentsEnabled() ) {
 			update.setComment( lockMode + " lock " + lockable.getEntityName() );
 		}
 		return update.toStatementString();
 	}
 
 	protected LockMode getLockMode() {
 		return lockMode;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/lock/SelectLockingStrategy.java b/hibernate-core/src/main/java/org/hibernate/dialect/lock/SelectLockingStrategy.java
index eaca2bca66..73a5fc3f32 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/lock/SelectLockingStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/lock/SelectLockingStrategy.java
@@ -1,131 +1,132 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect.lock;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.JDBCException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.SimpleSelect;
 
 /**
  * A locking strategy where the locks are obtained through select statements.
  * <p/>
  * For non-read locks, this is achieved through the Dialect's specific
  * SELECT ... FOR UPDATE syntax.
  *
  * @see org.hibernate.dialect.Dialect#getForUpdateString(org.hibernate.LockMode)
  * @see org.hibernate.dialect.Dialect#appendLockHint(org.hibernate.LockMode, String)
  *
  * @author Steve Ebersole
  * @since 3.2
  */
 public class SelectLockingStrategy extends AbstractSelectLockingStrategy {
 	/**
 	 * Construct a locking strategy based on SQL SELECT statements.
 	 *
 	 * @param lockable The metadata for the entity to be locked.
 	 * @param lockMode Indictates the type of lock to be acquired.
 	 */
 	public SelectLockingStrategy(Lockable lockable, LockMode lockMode) {
 		super( lockable, lockMode );
 	}
 
 	@Override
 	public void lock(
 			Serializable id,
 			Object version,
 			Object object,
 			int timeout,
 			SessionImplementor session) throws StaleObjectStateException, JDBCException {
 		final String sql = determineSql( timeout );
 		final SessionFactoryImplementor factory = session.getFactory();
 		try {
-			final PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
+			final PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 			try {
 				getLockable().getIdentifierType().nullSafeSet( st, id, 1, session );
 				if ( getLockable().isVersioned() ) {
 					getLockable().getVersionType().nullSafeSet(
 							st,
 							version,
 							getLockable().getIdentifierType().getColumnSpan( factory ) + 1,
 							session
 					);
 				}
 
-				final ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
+				final ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
 					if ( !rs.next() ) {
 						if ( factory.getStatistics().isStatisticsEnabled() ) {
 							factory.getStatisticsImplementor()
 									.optimisticFailure( getLockable().getEntityName() );
 						}
 						throw new StaleObjectStateException( getLockable().getEntityName(), id );
 					}
 				}
 				finally {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
+					session.getJdbcCoordinator().getResourceRegistry().release( rs, st );
 				}
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+				session.getJdbcCoordinator().getResourceRegistry().release( st );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 
 		}
 		catch ( SQLException sqle ) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not lock: " + MessageHelper.infoString( getLockable(), id, session.getFactory() ),
 					sql
 				);
 		}
 	}
 
 	protected String generateLockString(int timeout) {
 		final SessionFactoryImplementor factory = getLockable().getFactory();
 		final LockOptions lockOptions = new LockOptions( getLockMode() );
 		lockOptions.setTimeOut( timeout );
 		final SimpleSelect select = new SimpleSelect( factory.getDialect() )
 				.setLockOptions( lockOptions )
 				.setTableName( getLockable().getRootTableName() )
 				.addColumn( getLockable().getRootTableIdentifierColumnNames()[0] )
 				.addCondition( getLockable().getRootTableIdentifierColumnNames(), "=?" );
 		if ( getLockable().isVersioned() ) {
 			select.addCondition( getLockable().getVersionColumnName(), "=?" );
 		}
 		if ( factory.getSettings().isCommentsEnabled() ) {
 			select.setComment( getLockMode() + " lock " + getLockable().getEntityName() );
 		}
 		return select.toStatementString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/dialect/lock/UpdateLockingStrategy.java b/hibernate-core/src/main/java/org/hibernate/dialect/lock/UpdateLockingStrategy.java
index 6d371417b1..d250316698 100644
--- a/hibernate-core/src/main/java/org/hibernate/dialect/lock/UpdateLockingStrategy.java
+++ b/hibernate-core/src/main/java/org/hibernate/dialect/lock/UpdateLockingStrategy.java
@@ -1,148 +1,149 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.dialect.lock;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.JDBCException;
 import org.hibernate.LockMode;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.persister.entity.Lockable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Update;
 
 import org.jboss.logging.Logger;
 
 /**
  * A locking strategy where the locks are obtained through update statements.
  * <p/>
  * This strategy is not valid for read style locks.
  *
  * @author Steve Ebersole
  * @since 3.2
  */
 public class UpdateLockingStrategy implements LockingStrategy {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			UpdateLockingStrategy.class.getName()
 	);
 
 	private final Lockable lockable;
 	private final LockMode lockMode;
 	private final String sql;
 
 	/**
 	 * Construct a locking strategy based on SQL UPDATE statements.
 	 *
 	 * @param lockable The metadata for the entity to be locked.
 	 * @param lockMode Indictates the type of lock to be acquired.  Note that
 	 * read-locks are not valid for this strategy.
 	 */
 	public UpdateLockingStrategy(Lockable lockable, LockMode lockMode) {
 		this.lockable = lockable;
 		this.lockMode = lockMode;
 		if ( lockMode.lessThan( LockMode.UPGRADE ) ) {
 			throw new HibernateException( "[" + lockMode + "] not valid for update statement" );
 		}
 		if ( !lockable.isVersioned() ) {
 			LOG.writeLocksNotSupported( lockable.getEntityName() );
 			this.sql = null;
 		}
 		else {
 			this.sql = generateLockString();
 		}
 	}
 
 	@Override
 	public void lock(
 			Serializable id,
 			Object version,
 			Object object,
 			int timeout,
 			SessionImplementor session) throws StaleObjectStateException, JDBCException {
 		if ( !lockable.isVersioned() ) {
 			throw new HibernateException( "write locks via update not supported for non-versioned entities [" + lockable.getEntityName() + "]" );
 		}
 
 		// todo : should we additionally check the current isolation mode explicitly?
 		final SessionFactoryImplementor factory = session.getFactory();
 		try {
-			final PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
+			final PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 			try {
 				lockable.getVersionType().nullSafeSet( st, version, 1, session );
 				int offset = 2;
 
 				lockable.getIdentifierType().nullSafeSet( st, id, offset, session );
 				offset += lockable.getIdentifierType().getColumnSpan( factory );
 
 				if ( lockable.isVersioned() ) {
 					lockable.getVersionType().nullSafeSet( st, version, offset, session );
 				}
 
-				final int affected = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st );
+				final int affected = session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st );
 				if ( affected < 0 ) {
 					if (factory.getStatistics().isStatisticsEnabled()) {
 						factory.getStatisticsImplementor().optimisticFailure( lockable.getEntityName() );
 					}
 					throw new StaleObjectStateException( lockable.getEntityName(), id );
 				}
 
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+				session.getJdbcCoordinator().getResourceRegistry().release( st );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 
 		}
 		catch ( SQLException sqle ) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not lock: " + MessageHelper.infoString( lockable, id, session.getFactory() ),
 					sql
 			);
 		}
 	}
 
 	protected String generateLockString() {
 		final SessionFactoryImplementor factory = lockable.getFactory();
 		final Update update = new Update( factory.getDialect() );
 		update.setTableName( lockable.getRootTableName() );
 		update.addPrimaryKeyColumns( lockable.getRootTableIdentifierColumnNames() );
 		update.setVersionColumnName( lockable.getVersionColumnName() );
 		update.addColumn( lockable.getVersionColumnName() );
 		if ( factory.getSettings().isCommentsEnabled() ) {
 			update.setComment( lockMode + " lock " + lockable.getEntityName() );
 		}
 		return update.toStatementString();
 	}
 
 	protected LockMode getLockMode() {
 		return lockMode;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/AbstractBatchImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/AbstractBatchImpl.java
index 7e865a9bed..20d8c031e5 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/AbstractBatchImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/AbstractBatchImpl.java
@@ -1,213 +1,215 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.batch.internal;
 
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.LinkedHashMap;
 import java.util.LinkedHashSet;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.engine.jdbc.batch.spi.Batch;
 import org.hibernate.engine.jdbc.batch.spi.BatchKey;
 import org.hibernate.engine.jdbc.batch.spi.BatchObserver;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
-import org.hibernate.engine.transaction.spi.TransactionContext;
 import org.hibernate.internal.CoreMessageLogger;
 
-import org.jboss.logging.Logger;
-
 /**
  * Convenience base class for implementers of the Batch interface.
  *
  * @author Steve Ebersole
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public abstract class AbstractBatchImpl implements Batch {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			AbstractBatchImpl.class.getName()
 	);
 
 	private final BatchKey key;
 	private final JdbcCoordinator jdbcCoordinator;
 
-	private final TransactionContext transactionContext;
 	private final SqlStatementLogger sqlStatementLogger;
 	private final SqlExceptionHelper sqlExceptionHelper;
 
 	private LinkedHashMap<String,PreparedStatement> statements = new LinkedHashMap<String,PreparedStatement>();
 	private LinkedHashSet<BatchObserver> observers = new LinkedHashSet<BatchObserver>();
 
 	protected AbstractBatchImpl(BatchKey key, JdbcCoordinator jdbcCoordinator) {
 		if ( key == null ) {
 			throw new IllegalArgumentException( "batch key cannot be null" );
 		}
 		if ( jdbcCoordinator == null ) {
 			throw new IllegalArgumentException( "JDBC coordinator cannot be null" );
 		}
 		this.key = key;
 		this.jdbcCoordinator = jdbcCoordinator;
 
-		this.transactionContext = jdbcCoordinator.getTransactionCoordinator().getTransactionContext();
-		final JdbcServices jdbcServices = transactionContext.getTransactionEnvironment().getJdbcServices();
+		final JdbcServices jdbcServices = jdbcCoordinator.getJdbcSessionOwner()
+				.getJdbcSessionContext()
+				.getServiceRegistry()
+				.getService( JdbcServices.class );
+
 		this.sqlStatementLogger = jdbcServices.getSqlStatementLogger();
 		this.sqlExceptionHelper = jdbcServices.getSqlExceptionHelper();
 	}
 
+	protected JdbcCoordinator getJdbcCoordinator(){
+		return this.jdbcCoordinator;
+	}
+
 	/**
-	 * Perform batch execution.
+	 * Perform batch execution..
 	 * <p/>
 	 * This is called from the explicit {@link #execute() execution}, but may also be called from elsewhere
 	 * depending on the exact implementation.
 	 */
 	protected abstract void doExecuteBatch();
 
-	public TransactionContext transactionContext() {
-		return transactionContext;
-	}
-
 	/**
 	 * Convenience access to the SQLException helper.
 	 *
 	 * @return The underlying SQLException helper.
 	 */
 	protected SqlExceptionHelper sqlExceptionHelper() {
 		return sqlExceptionHelper;
 	}
 
 	/**
 	 * Convenience access to the SQL statement logger.
 	 *
 	 * @return The underlying JDBC services.
 	 */
 	protected SqlStatementLogger sqlStatementLogger() {
 		return sqlStatementLogger;
 	}
 
 	protected void abortBatch() {
 		jdbcCoordinator.abortBatch();
 	}
 
 	/**
 	 * Access to the batch's map of statements (keyed by SQL statement string).
 	 *
 	 * @return This batch's statements.
 	 */
 	protected LinkedHashMap<String,PreparedStatement> getStatements() {
 		return statements;
 	}
 
 	@Override
 	public final BatchKey getKey() {
 		return key;
 	}
 
 	@Override
 	public void addObserver(BatchObserver observer) {
 		observers.add( observer );
 	}
 
 	@Override
 	public PreparedStatement getBatchStatement(String sql, boolean callable) {
 		if ( sql == null ) {
 			throw new IllegalArgumentException( "sql must be non-null." );
 		}
 		PreparedStatement statement = statements.get( sql );
 		if ( statement == null ) {
 			statement = buildBatchStatement( sql, callable );
 			statements.put( sql, statement );
 		}
 		else {
 			LOG.debug( "Reusing batch statement" );
 			sqlStatementLogger().logStatement( sql );
 		}
 		return statement;
 	}
 
 	private PreparedStatement buildBatchStatement(String sql, boolean callable) {
 		return jdbcCoordinator.getStatementPreparer().prepareStatement( sql, callable );
 	}
 
 	@Override
 	public final void execute() {
 		notifyObserversExplicitExecution();
 		if ( getStatements().isEmpty() ) {
 			return;
 		}
 
 		try {
 			doExecuteBatch();
 		}
 		finally {
 			releaseStatements();
 		}
 	}
 
 	protected void releaseStatements() {
 		for ( PreparedStatement statement : getStatements().values() ) {
 			clearBatch( statement );
-			jdbcCoordinator.release( statement );
+			jdbcCoordinator.getResourceRegistry().release( statement );
+			jdbcCoordinator.afterStatementExecution();
 		}
 		getStatements().clear();
 	}
 
 	protected void clearBatch(PreparedStatement statement) {
 		try {
 			statement.clearBatch();
 		}
 		catch ( SQLException e ) {
 			LOG.unableToReleaseBatchStatement();
 		}
 	}
 
 	/**
 	 * Convenience method to notify registered observers of an explicit execution of this batch.
 	 */
 	protected final void notifyObserversExplicitExecution() {
 		for ( BatchObserver observer : observers ) {
 			observer.batchExplicitlyExecuted();
 		}
 	}
 
 	/**
 	 * Convenience method to notify registered observers of an implicit execution of this batch.
 	 */
 	protected final void notifyObserversImplicitExecution() {
 		for ( BatchObserver observer : observers ) {
 			observer.batchImplicitlyExecuted();
 		}
 	}
 
 	@Override
 	public void release() {
 		if ( getStatements() != null && !getStatements().isEmpty() ) {
 			LOG.batchContainedStatementsOnRelease();
 		}
 		releaseStatements();
 		observers.clear();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/BatchingBatch.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/BatchingBatch.java
index 08c524a367..56cd8b5d35 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/BatchingBatch.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/BatchingBatch.java
@@ -1,158 +1,158 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.batch.internal;
 
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.jdbc.batch.spi.BatchKey;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.Logger;
 
 /**
  * A {@link org.hibernate.engine.jdbc.batch.spi.Batch} implementation which does bathing based on a given size.  Once
  * the batch size is reached for a statement in the batch, the entire batch is implicitly executed.
  *
  * @author Steve Ebersole
  */
 public class BatchingBatch extends AbstractBatchImpl {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			BatchingBatch.class.getName()
 	);
 
 	// IMPL NOTE : Until HHH-5797 is fixed, there will only be 1 statement in a batch
 
 	private final int batchSize;
 	private int batchPosition;
 	private boolean batchExecuted;
 	private int statementPosition;
 
 	/**
 	 * Constructs a BatchingBatch
 	 *
 	 * @param key The batch key
 	 * @param jdbcCoordinator The JDBC jdbcCoordinator
 	 * @param batchSize The batch size.
 	 */
 	public BatchingBatch(
 			BatchKey key,
 			JdbcCoordinator jdbcCoordinator,
 			int batchSize) {
 		super( key, jdbcCoordinator );
 		if ( ! key.getExpectation().canBeBatched() ) {
 			throw new HibernateException( "attempting to batch an operation which cannot be batched" );
 		}
 		this.batchSize = batchSize;
 	}
 
 	private String currentStatementSql;
 	private PreparedStatement currentStatement;
 
 	@Override
 	public PreparedStatement getBatchStatement(String sql, boolean callable) {
 		currentStatementSql = sql;
 		currentStatement = super.getBatchStatement( sql, callable );
 		return currentStatement;
 	}
 
 	@Override
 	public void addToBatch() {
 		try {
 			currentStatement.addBatch();
 		}
 		catch ( SQLException e ) {
 			LOG.debugf( "SQLException escaped proxy", e );
 			throw sqlExceptionHelper().convert( e, "could not perform addBatch", currentStatementSql );
 		}
 		statementPosition++;
 		if ( statementPosition >= getKey().getBatchedStatementCount() ) {
 			batchPosition++;
 			if ( batchPosition == batchSize ) {
 				notifyObserversImplicitExecution();
 				performExecution();
 				batchPosition = 0;
                 batchExecuted = true;
 			}
 			statementPosition = 0;
 		}
 	}
 
 	@Override
 	protected void doExecuteBatch() {
 		if (batchPosition == 0 ) {
 			if(! batchExecuted) {
 				LOG.debug( "No batched statements to execute" );
 			}
 		}
 		else {
 			performExecution();
 		}
 	}
 
 	private void performExecution() {
 		LOG.debugf( "Executing batch size: %s", batchPosition );
 		try {
 			for ( Map.Entry<String,PreparedStatement> entry : getStatements().entrySet() ) {
 				try {
 					final PreparedStatement statement = entry.getValue();
 					final int[] rowCounts;
 					try {
-						transactionContext().startBatchExecution();
+						getJdbcCoordinator().getJdbcSessionOwner().getJdbcSessionContext().getObserver().jdbcExecuteBatchStart();
 						rowCounts = statement.executeBatch();
 					}
 					finally {
-						transactionContext().endBatchExecution();
+						getJdbcCoordinator().getJdbcSessionOwner().getJdbcSessionContext().getObserver().jdbcExecuteBatchEnd();
 					}
 					checkRowCounts( rowCounts, statement );
 				}
 				catch ( SQLException e ) {
 					abortBatch();
 					throw sqlExceptionHelper().convert( e, "could not execute batch", entry.getKey() );
 				}
 			}
 		}
 		catch ( RuntimeException re ) {
 			LOG.unableToExecuteBatch( re.getMessage() );
 			throw re;
 		}
 		finally {
 			batchPosition = 0;
 		}
 	}
 
 	private void checkRowCounts(int[] rowCounts, PreparedStatement ps) throws SQLException, HibernateException {
 		final int numberOfRowCounts = rowCounts.length;
 		if ( numberOfRowCounts != batchPosition ) {
 			LOG.unexpectedRowCounts();
 		}
 		for ( int i = 0; i < numberOfRowCounts; i++ ) {
 			getKey().getExpectation().verifyOutcome( rowCounts[i], ps, i );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/NonBatchingBatch.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/NonBatchingBatch.java
index d640bab003..f98ec444b3 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/NonBatchingBatch.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/batch/internal/NonBatchingBatch.java
@@ -1,88 +1,89 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.batch.internal;
 
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Map;
 
 import org.hibernate.JDBCException;
 import org.hibernate.engine.jdbc.batch.spi.BatchKey;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.Logger;
 
 /**
  * An implementation of {@link org.hibernate.engine.jdbc.batch.spi.Batch} which does not perform batching.  It simply
  * executes each statement as it is encountered.
  *
  * @author Steve Ebersole
  */
 public class NonBatchingBatch extends AbstractBatchImpl {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			NonBatchingBatch.class.getName()
 	);
 
 	private JdbcCoordinator jdbcCoordinator;
 	
 	protected NonBatchingBatch(BatchKey key, JdbcCoordinator jdbcCoordinator) {
 		super( key, jdbcCoordinator );
 		this.jdbcCoordinator = jdbcCoordinator;
 	}
 
 	@Override
 	public void addToBatch() {
 		notifyObserversImplicitExecution();
 		for ( Map.Entry<String,PreparedStatement> entry : getStatements().entrySet() ) {
 			try {
 				final PreparedStatement statement = entry.getValue();
 				final int rowCount = jdbcCoordinator.getResultSetReturn().executeUpdate( statement );
 				getKey().getExpectation().verifyOutcome( rowCount, statement, 0 );
-				jdbcCoordinator.release( statement );
+				jdbcCoordinator.getResourceRegistry().release( statement );
+				jdbcCoordinator.afterStatementExecution();
 			}
 			catch ( SQLException e ) {
 				abortBatch();
 				throw sqlExceptionHelper().convert( e, "could not execute non-batched batch statement", entry.getKey() );
 			}
 			catch (JDBCException e) {
 				abortBatch();
 				throw e;
 			}
 		}
 
 		getStatements().clear();
 	}
 
 	@Override
 	protected void clearBatch(PreparedStatement statement) {
 		// no need to call PreparedStatement#clearBatch here...
 	}
 
 	@Override
 	protected void doExecuteBatch() {
 		// nothing to do
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/JdbcCoordinatorImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/JdbcCoordinatorImpl.java
index a1f9483e62..f75818738e 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/JdbcCoordinatorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/JdbcCoordinatorImpl.java
@@ -1,593 +1,569 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.internal;
 
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.sql.Connection;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.HibernateException;
 import org.hibernate.TransactionException;
 import org.hibernate.engine.jdbc.batch.spi.Batch;
 import org.hibernate.engine.jdbc.batch.spi.BatchBuilder;
 import org.hibernate.engine.jdbc.batch.spi.BatchKey;
+import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
 import org.hibernate.engine.jdbc.spi.InvalidatableWrapper;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
+import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.JdbcWrapper;
-import org.hibernate.engine.jdbc.spi.LogicalConnectionImplementor;
 import org.hibernate.engine.jdbc.spi.ResultSetReturn;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jdbc.spi.StatementPreparer;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl;
-import org.hibernate.engine.transaction.spi.TransactionContext;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
-import org.hibernate.engine.transaction.spi.TransactionEnvironment;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.jdbc.WorkExecutor;
 import org.hibernate.jdbc.WorkExecutorVisitable;
-
-import org.jboss.logging.Logger;
+import org.hibernate.resource.jdbc.ResourceRegistry;
+import org.hibernate.resource.jdbc.internal.LogicalConnectionManagedImpl;
+import org.hibernate.resource.jdbc.internal.LogicalConnectionProvidedImpl;
+import org.hibernate.resource.jdbc.spi.JdbcSessionOwner;
+import org.hibernate.resource.jdbc.spi.LogicalConnectionImplementor;
+import org.hibernate.resource.transaction.backend.store.spi.DataStoreTransaction;
 
 /**
  * Standard Hibernate implementation of {@link JdbcCoordinator}
  * <p/>
  * IMPL NOTE : Custom serialization handling!
  *
  * @author Steve Ebersole
  * @author Brett Meyer
  * @author Sanne Grinovero
  */
 public class JdbcCoordinatorImpl implements JdbcCoordinator {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			JdbcCoordinatorImpl.class.getName()
 	);
 
-	private transient TransactionCoordinator transactionCoordinator;
-	private final transient LogicalConnectionImpl logicalConnection;
+	private boolean closed;
+
+	private transient LogicalConnectionImplementor logicalConnection;
+	private transient JdbcSessionOwner owner;
+	private final ConnectionReleaseMode connectionReleaseMode;
 
 	private transient Batch currentBatch;
 
 	private transient long transactionTimeOutInstant = -1;
 
 	/**
 	 * This is a marker value to insert instead of null values for when a Statement gets registered in xref
 	 * but has no associated ResultSets registered. This is useful to efficiently check against duplicate
 	 * registration but you'll have to check against instance equality rather than null before attempting
 	 * to add elements to this set.
 	 */
 	private static final Set<ResultSet> EMPTY_RESULTSET = Collections.emptySet();
 
 	private final HashMap<Statement,Set<ResultSet>> xref = new HashMap<Statement,Set<ResultSet>>();
 	private final Set<ResultSet> unassociatedResultSets = new HashSet<ResultSet>();
-	private final transient SqlExceptionHelper exceptionHelper;
+	private transient SqlExceptionHelper exceptionHelper;
 
 	private Statement lastQuery;
+	private final boolean isUserSuppliedConnection;
+
 
 	/**
 	 * If true, manually (and temporarily) circumvent aggressive release processing.
 	 */
 	private boolean releasesEnabled = true;
 
 	/**
 	 * Constructs a JdbcCoordinatorImpl
 	 *
 	 * @param userSuppliedConnection The user supplied connection (may be null)
-	 * @param transactionCoordinator The transaction coordinator
 	 */
 	public JdbcCoordinatorImpl(
 			Connection userSuppliedConnection,
-			TransactionCoordinator transactionCoordinator) {
-		this.transactionCoordinator = transactionCoordinator;
-		this.logicalConnection = new LogicalConnectionImpl(
-				userSuppliedConnection,
-				transactionCoordinator.getTransactionContext().getConnectionReleaseMode(),
-				transactionCoordinator.getTransactionContext().getTransactionEnvironment().getJdbcServices(),
-				transactionCoordinator.getTransactionContext().getJdbcConnectionAccess()
+			JdbcSessionOwner owner) {
+		if ( userSuppliedConnection != null ) {
+			this.logicalConnection = new LogicalConnectionProvidedImpl( userSuppliedConnection );
+			this.isUserSuppliedConnection = true;
+		}
+		else {
+			this.logicalConnection = new LogicalConnectionManagedImpl(
+					owner.getJdbcConnectionAccess(),
+					owner.getJdbcSessionContext()
+			);
+			this.isUserSuppliedConnection = false;
+		}
+		this.connectionReleaseMode = determineConnectionReleaseMode(
+				owner.getJdbcConnectionAccess(),
+				isUserSuppliedConnection,
+				owner.getJdbcSessionContext()
+						.getConnectionReleaseMode()
 		);
-		this.exceptionHelper = logicalConnection.getJdbcServices().getSqlExceptionHelper();
-	}
-
-	/**
-	 * Constructs a JdbcCoordinatorImpl
-	 *
-	 * @param logicalConnection The logical JDBC connection
-	 * @param transactionCoordinator The transaction coordinator
-	 */
-	public JdbcCoordinatorImpl(
-			LogicalConnectionImpl logicalConnection,
-			TransactionCoordinator transactionCoordinator) {
-		this.transactionCoordinator = transactionCoordinator;
+		this.owner = owner;
+		this.exceptionHelper = owner.getJdbcSessionContext()
+				.getServiceRegistry()
+				.getService( JdbcServices.class )
+				.getSqlExceptionHelper();
+	}
+
+	private JdbcCoordinatorImpl(
+			LogicalConnectionImplementor logicalConnection,
+			boolean isUserSuppliedConnection,
+			ConnectionReleaseMode connectionReleaseMode,
+			JdbcSessionOwner owner) {
 		this.logicalConnection = logicalConnection;
-		this.exceptionHelper = logicalConnection.getJdbcServices().getSqlExceptionHelper();
-	}
-
-	private JdbcCoordinatorImpl(LogicalConnectionImpl logicalConnection) {
-		this.logicalConnection = logicalConnection;
-		this.exceptionHelper = logicalConnection.getJdbcServices().getSqlExceptionHelper();
-	}
-
-	@Override
-	public TransactionCoordinator getTransactionCoordinator() {
-		return transactionCoordinator;
+		this.isUserSuppliedConnection = isUserSuppliedConnection;
+		this.connectionReleaseMode = connectionReleaseMode;
+		this.owner = owner;
+		this.exceptionHelper = owner.getJdbcSessionContext()
+				.getServiceRegistry()
+				.getService( JdbcServices.class )
+				.getSqlExceptionHelper();
 	}
 
 	@Override
 	public LogicalConnectionImplementor getLogicalConnection() {
 		return logicalConnection;
 	}
 
-	protected TransactionEnvironment transactionEnvironment() {
-		return getTransactionCoordinator().getTransactionContext().getTransactionEnvironment();
-	}
-
 	protected SessionFactoryImplementor sessionFactory() {
-		return transactionEnvironment().getSessionFactory();
+		return this.owner.getJdbcSessionContext().getSessionFactory();
 	}
 
 	protected BatchBuilder batchBuilder() {
 		return sessionFactory().getServiceRegistry().getService( BatchBuilder.class );
 	}
 
 	/**
 	 * Access to the SqlExceptionHelper
 	 *
 	 * @return The SqlExceptionHelper
 	 */
 	public SqlExceptionHelper sqlExceptionHelper() {
 		return exceptionHelper;
 	}
 
-
 	private int flushDepth;
 
 	@Override
 	public void flushBeginning() {
 		if ( flushDepth == 0 ) {
 			releasesEnabled = false;
 		}
 		flushDepth++;
 	}
 
 	@Override
 	public void flushEnding() {
 		flushDepth--;
 		if ( flushDepth < 0 ) {
 			throw new HibernateException( "Mismatched flush handling" );
 		}
 		if ( flushDepth == 0 ) {
 			releasesEnabled = true;
 		}
 		
 		afterStatementExecution();
 	}
 
 	@Override
 	public Connection close() {
 		LOG.tracev( "Closing JDBC container [{0}]", this );
 		if ( currentBatch != null ) {
 			LOG.closingUnreleasedBatch();
 			currentBatch.release();
 		}
 		cleanup();
+		closed = true;
 		return logicalConnection.close();
 	}
 
 	@Override
 	public Batch getBatch(BatchKey key) {
 		if ( currentBatch != null ) {
 			if ( currentBatch.getKey().equals( key ) ) {
 				return currentBatch;
 			}
 			else {
 				currentBatch.execute();
 				currentBatch.release();
 			}
 		}
 		currentBatch = batchBuilder().buildBatch( key, this );
 		return currentBatch;
 	}
 
 	@Override
 	public void executeBatch() {
 		if ( currentBatch != null ) {
 			currentBatch.execute();
 			// needed?
 			currentBatch.release();
 		}
 	}
 
 	@Override
 	public void abortBatch() {
 		if ( currentBatch != null ) {
 			currentBatch.release();
 		}
 	}
 
 	private transient StatementPreparer statementPreparer;
 
 	@Override
 	public StatementPreparer getStatementPreparer() {
 		if ( statementPreparer == null ) {
 			statementPreparer = new StatementPreparerImpl( this );
 		}
 		return statementPreparer;
 	}
 
 	private transient ResultSetReturn resultSetExtractor;
 
 	@Override
 	public ResultSetReturn getResultSetReturn() {
 		if ( resultSetExtractor == null ) {
 			resultSetExtractor = new ResultSetReturnImpl( this );
 		}
 		return resultSetExtractor;
 	}
 
 	@Override
 	public void setTransactionTimeOut(int seconds) {
 		transactionTimeOutInstant = System.currentTimeMillis() + ( seconds * 1000 );
 	}
 
 	@Override
+	public void flushBeforeTransactionCompletion() {
+		getJdbcSessionOwner().flushBeforeTransactionCompletion();
+	}
+
+	@Override
 	public int determineRemainingTransactionTimeOutPeriod() {
 		if ( transactionTimeOutInstant < 0 ) {
 			return -1;
 		}
 		final int secondsRemaining = (int) ((transactionTimeOutInstant - System.currentTimeMillis()) / 1000);
 		if ( secondsRemaining <= 0 ) {
 			throw new TransactionException( "transaction timeout expired" );
 		}
 		return secondsRemaining;
 	}
 
 	@Override
 	public void afterStatementExecution() {
-		LOG.tracev( "Starting after statement execution processing [{0}]", connectionReleaseMode() );
-		if ( connectionReleaseMode() == ConnectionReleaseMode.AFTER_STATEMENT ) {
+		LOG.tracev( "Starting after statement execution processing [{0}]", getConnectionReleaseMode() );
+		if ( getConnectionReleaseMode() == ConnectionReleaseMode.AFTER_STATEMENT ) {
 			if ( ! releasesEnabled ) {
 				LOG.debug( "Skipping aggressive release due to manual disabling" );
 				return;
 			}
 			if ( hasRegisteredResources() ) {
 				LOG.debug( "Skipping aggressive release due to registered resources" );
 				return;
 			}
-			getLogicalConnection().releaseConnection();
+			getLogicalConnection().afterStatement();
 		}
 	}
 
 	@Override
 	public void afterTransaction() {
 		transactionTimeOutInstant = -1;
-		if ( connectionReleaseMode() == ConnectionReleaseMode.AFTER_STATEMENT ||
-				connectionReleaseMode() == ConnectionReleaseMode.AFTER_TRANSACTION ) {
-			if ( hasRegisteredResources() ) {
-				LOG.forcingContainerResourceCleanup();
-				releaseResources();
-			}
-			getLogicalConnection().aggressiveRelease();
+		if ( getConnectionReleaseMode() == ConnectionReleaseMode.AFTER_STATEMENT ||
+				getConnectionReleaseMode() == ConnectionReleaseMode.AFTER_TRANSACTION ) {
+			this.logicalConnection.afterTransaction();
 		}
 	}
-	
-	private ConnectionReleaseMode connectionReleaseMode() {
-		return getLogicalConnection().getConnectionReleaseMode();
+
+	private void releaseResources() {
+		getResourceRegistry().releaseResources();
+	}
+
+	private boolean hasRegisteredResources() {
+		return getResourceRegistry().hasRegisteredResources();
 	}
 
 	@Override
+	public ResourceRegistry getResourceRegistry(){
+		return this.logicalConnection.getResourceRegistry();
+	}
+
+	@Override
+	public  ConnectionReleaseMode getConnectionReleaseMode() {
+		return this.connectionReleaseMode;
+	}
+
+	private ConnectionReleaseMode determineConnectionReleaseMode(
+			JdbcConnectionAccess jdbcConnectionAccess,
+			boolean isUserSuppliedConnection,
+			ConnectionReleaseMode connectionReleaseMode) {
+		if ( isUserSuppliedConnection ) {
+			return ConnectionReleaseMode.ON_CLOSE;
+		}
+		else if ( connectionReleaseMode == ConnectionReleaseMode.AFTER_STATEMENT &&
+				! jdbcConnectionAccess.supportsAggressiveRelease() ) {
+			LOG.debug( "Connection provider reports to not support aggressive release; overriding" );
+			return ConnectionReleaseMode.AFTER_TRANSACTION;
+		}
+		else {
+			return connectionReleaseMode;
+		}
+	}
+	@Override
 	public <T> T coordinateWork(WorkExecutorVisitable<T> work) {
-		final Connection connection = getLogicalConnection().getConnection();
+		final Connection connection = getLogicalConnection().getPhysicalConnection();
 		try {
 			final T result = work.accept( new WorkExecutor<T>(), connection );
 			afterStatementExecution();
 			return result;
 		}
 		catch ( SQLException e ) {
 			throw sqlExceptionHelper().convert( e, "error executing work" );
 		}
 	}
 
 	@Override
 	public boolean isReadyForSerialization() {
-		return getLogicalConnection().isUserSuppliedConnection()
+		return this.isUserSuppliedConnection
 				? ! getLogicalConnection().isPhysicallyConnected()
 				: ! hasRegisteredResources();
 	}
 
-	/**
-	 * JDK serialization hook
-	 *
-	 * @param oos The stream into which to write our state
-	 *
-	 * @throws IOException Trouble accessing the stream
-	 */
-	public void serialize(ObjectOutputStream oos) throws IOException {
-		if ( ! isReadyForSerialization() ) {
-			throw new HibernateException( "Cannot serialize Session while connected" );
-		}
-		logicalConnection.serialize( oos );
-	}
-
-	/**
-	 * JDK deserialization hook
-	 *
-	 * @param ois The stream into which to write our state
-	 * @param transactionContext The transaction context which owns the JdbcCoordinatorImpl to be deserialized.
-	 *
-	 * @return The deserialized JdbcCoordinatorImpl
-	 *
-	 * @throws IOException Trouble accessing the stream
-	 * @throws ClassNotFoundException Trouble reading the stream
-	 */
-	public static JdbcCoordinatorImpl deserialize(
-			ObjectInputStream ois,
-			TransactionContext transactionContext) throws IOException, ClassNotFoundException {
-		return new JdbcCoordinatorImpl( LogicalConnectionImpl.deserialize( ois, transactionContext ) );
-	}
-
-	/**
-	 * Callback after deserialization from Session is done
-	 *
-	 * @param transactionCoordinator The transaction coordinator
-	 */
-	public void afterDeserialize(TransactionCoordinatorImpl transactionCoordinator) {
-		this.transactionCoordinator = transactionCoordinator;
-	}
-
-	@Override
-	public void register(Statement statement) {
-		LOG.tracev( "Registering statement [{0}]", statement );
-		// Benchmarking has shown this to be a big hotspot.  Originally, most usages would call both
-		// #containsKey and #put.  Instead, we optimize for the most common path (no previous Statement was
-		// registered) by calling #put only once, but still handling the unlikely conflict and resulting exception.
-		final Set<ResultSet> previousValue = xref.put( statement, EMPTY_RESULTSET );
-		if ( previousValue != null ) {
-			// Put the previous value back to undo the put
-			xref.put( statement, previousValue );
-			throw new HibernateException( "statement already registered with JDBCContainer" );
-		}
-	}
-
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public void registerLastQuery(Statement statement) {
 		LOG.tracev( "Registering last query statement [{0}]", statement );
 		if ( statement instanceof JdbcWrapper ) {
 			final JdbcWrapper<Statement> wrapper = (JdbcWrapper<Statement>) statement;
 			registerLastQuery( wrapper.getWrappedObject() );
 			return;
 		}
 		lastQuery = statement;
 	}
 
 	@Override
 	public void cancelLastQuery() {
 		try {
 			if (lastQuery != null) {
 				lastQuery.cancel();
 			}
 		}
 		catch (SQLException sqle) {
 			throw exceptionHelper.convert( sqle, "Cannot cancel query" );
 		}
 		finally {
 			lastQuery = null;
 		}
 	}
 
 	@Override
-	public void release(Statement statement) {
-		LOG.tracev( "Releasing statement [{0}]", statement );
-		final Set<ResultSet> resultSets = xref.get( statement );
-		if ( resultSets != null ) {
-			for ( ResultSet resultSet : resultSets ) {
-				close( resultSet );
-			}
-			resultSets.clear();
-		}
-		xref.remove( statement );
-		close( statement );
-		
-		afterStatementExecution();
-	}
-
-	@Override
-	public void register(ResultSet resultSet, Statement statement) {
-		if ( statement == null ) {
-			try {
-				statement = resultSet.getStatement();
-			}
-			catch ( SQLException e ) {
-				throw exceptionHelper.convert( e, "unable to access statement from resultset" );
-			}
-		}
-		if ( statement != null ) {
-			LOG.tracev( "Registering result set [{0}]", resultSet );
-			Set<ResultSet> resultSets = xref.get( statement );
-			if ( resultSets == null ) {
-				LOG.unregisteredStatement();
-			}
-			if ( resultSets == null || resultSets == EMPTY_RESULTSET ) {
-				resultSets = new HashSet<ResultSet>();
-				xref.put( statement, resultSets );
-			}
-			resultSets.add( resultSet );
-		}
-		else {
-			unassociatedResultSets.add( resultSet );
-		}
-	}
-
-	@Override
-	public void release(ResultSet resultSet, Statement statement) {
-		LOG.tracev( "Releasing result set [{0}]", resultSet );
-		if ( statement == null ) {
-			try {
-				statement = resultSet.getStatement();
-			}
-			catch ( SQLException e ) {
-				throw exceptionHelper.convert( e, "unable to access statement from resultset" );
-			}
-		}
-		if ( statement != null ) {
-			final Set<ResultSet> resultSets = xref.get( statement );
-			if ( resultSets == null ) {
-				LOG.unregisteredStatement();
-			}
-			else {
-				resultSets.remove( resultSet );
-				if ( resultSets.isEmpty() ) {
-					xref.remove( statement );
-				}
-			}
-		}
-		else {
-			final boolean removed = unassociatedResultSets.remove( resultSet );
-			if ( !removed ) {
-				LOG.unregisteredResultSetWithoutStatement();
-			}
-		}
-		close( resultSet );
-	}
-
-	@Override
-	public boolean hasRegisteredResources() {
-		return ! xref.isEmpty() || ! unassociatedResultSets.isEmpty();
-	}
-
-	@Override
-	public void releaseResources() {
-		LOG.tracev( "Releasing JDBC container resources [{0}]", this );
-		cleanup();
-	}
-	
-	@Override
 	public void enableReleases() {
 		releasesEnabled = true;
 	}
 	
 	@Override
 	public void disableReleases() {
 		releasesEnabled = false;
 	}
 
 	private void cleanup() {
 		for ( Map.Entry<Statement,Set<ResultSet>> entry : xref.entrySet() ) {
 			closeAll( entry.getValue() );
 			close( entry.getKey() );
 		}
 		xref.clear();
 
 		closeAll( unassociatedResultSets );
 	}
 
 	protected void closeAll(Set<ResultSet> resultSets) {
 		for ( ResultSet resultSet : resultSets ) {
 			close( resultSet );
 		}
 		resultSets.clear();
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	protected void close(Statement statement) {
 		LOG.tracev( "Closing prepared statement [{0}]", statement );
 		
 		// Important for Statement caching -- some DBs (especially Sybase) log warnings on every Statement under
 		// certain situations.
 		sqlExceptionHelper().logAndClearWarnings( statement );
 
 		if ( statement instanceof InvalidatableWrapper ) {
 			final InvalidatableWrapper<Statement> wrapper = (InvalidatableWrapper<Statement>) statement;
 			close( wrapper.getWrappedObject() );
 			wrapper.invalidate();
 			return;
 		}
 
 		try {
 			// if we are unable to "clean" the prepared statement,
 			// we do not close it
 			try {
 				if ( statement.getMaxRows() != 0 ) {
 					statement.setMaxRows( 0 );
 				}
 				if ( statement.getQueryTimeout() != 0 ) {
 					statement.setQueryTimeout( 0 );
 				}
 			}
 			catch( SQLException sqle ) {
 				// there was a problem "cleaning" the prepared statement
 				if ( LOG.isDebugEnabled() ) {
 					LOG.debugf( "Exception clearing maxRows/queryTimeout [%s]", sqle.getMessage() );
 				}
 				// EARLY EXIT!!!
 				return;
 			}
 			statement.close();
 			if ( lastQuery == statement ) {
 				lastQuery = null;
 			}
 		}
 		catch( SQLException e ) {
 			LOG.debugf( "Unable to release JDBC statement [%s]", e.getMessage() );
 		}
 		catch ( Exception e ) {
 			// try to handle general errors more elegantly
 			LOG.debugf( "Unable to release JDBC statement [%s]", e.getMessage() );
 		}
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	protected void close(ResultSet resultSet) {
 		LOG.tracev( "Closing result set [{0}]", resultSet );
 
 		if ( resultSet instanceof InvalidatableWrapper ) {
 			final InvalidatableWrapper<ResultSet> wrapper = (InvalidatableWrapper<ResultSet>) resultSet;
 			close( wrapper.getWrappedObject() );
 			wrapper.invalidate();
 			return;
 		}
 
 		try {
 			resultSet.close();
 		}
 		catch( SQLException e ) {
 			LOG.debugf( "Unable to release JDBC result set [%s]", e.getMessage() );
 		}
 		catch ( Exception e ) {
 			// try to handle general errors more elegantly
 			LOG.debugf( "Unable to release JDBC result set [%s]", e.getMessage() );
 		}
 	}
+
+	@Override
+	public boolean isActive() {
+		return !closed;
+	}
+
+	@Override
+	public void afterTransactionBegin() {
+		owner.afterTransactionBegin();
+	}
+
+	@Override
+	public void beforeTransactionCompletion() {
+		owner.beforeTransactionCompletion();
+	}
+
+	@Override
+	public void afterTransactionCompletion(boolean successful) {
+		afterTransaction();
+		owner.afterTransactionCompletion( successful );
+	}
+
+	@Override
+	public JdbcSessionOwner getJdbcSessionOwner() {
+		return this.owner;
+	}
+
+	@Override
+	public DataStoreTransaction getResourceLocalTransaction() {
+		return logicalConnection.getPhysicalJdbcTransaction();
+	}
+
+	/**
+	 * JDK serialization hook
+	 *
+	 * @param oos The stream into which to write our state
+	 *
+	 * @throws IOException Trouble accessing the stream
+	 */
+	public void serialize(ObjectOutputStream oos) throws IOException {
+		if ( ! isReadyForSerialization() ) {
+			throw new HibernateException( "Cannot serialize Session while connected" );
+		}
+		oos.writeBoolean( isUserSuppliedConnection );
+		oos.writeObject( connectionReleaseMode );
+		logicalConnection.serialize( oos );
+	}
+
+	/**
+	 * JDK deserialization hook
+	 *
+	 * @param ois The stream into which to write our state
+	 * @param JdbcSessionOwner The Jdbc Session owner which owns the JdbcCoordinatorImpl to be deserialized.
+	 *
+	 * @return The deserialized JdbcCoordinatorImpl
+	 *
+	 * @throws IOException Trouble accessing the stream
+	 * @throws ClassNotFoundException Trouble reading the stream
+	 */
+	public static JdbcCoordinatorImpl deserialize(
+			ObjectInputStream ois,
+			JdbcSessionOwner owner) throws IOException, ClassNotFoundException {
+		final boolean isUserSuppliedConnection = ois.readBoolean();
+		final ConnectionReleaseMode connectionReleaseMode = (ConnectionReleaseMode) ois.readObject();
+		LogicalConnectionImplementor logicalConnection;
+		if ( isUserSuppliedConnection ) {
+			logicalConnection = LogicalConnectionProvidedImpl.deserialize( ois );
+		}
+		else {
+			logicalConnection = LogicalConnectionManagedImpl.deserialize(
+					ois,
+					owner.getJdbcConnectionAccess(),
+					owner.getJdbcSessionContext()
+			);
+		}
+		return new JdbcCoordinatorImpl( logicalConnection, isUserSuppliedConnection, connectionReleaseMode, owner );
+	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/LogicalConnectionImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/LogicalConnectionImpl.java
deleted file mode 100644
index 8fb17d43e3..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/LogicalConnectionImpl.java
+++ /dev/null
@@ -1,393 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.engine.jdbc.internal;
-
-import java.io.IOException;
-import java.io.ObjectInputStream;
-import java.io.ObjectOutputStream;
-import java.sql.Connection;
-import java.sql.SQLException;
-import java.util.ArrayList;
-import java.util.Iterator;
-import java.util.List;
-
-import org.hibernate.ConnectionReleaseMode;
-import org.hibernate.HibernateException;
-import org.hibernate.JDBCException;
-import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
-import org.hibernate.engine.jdbc.spi.ConnectionObserver;
-import org.hibernate.engine.jdbc.spi.JdbcServices;
-import org.hibernate.engine.jdbc.spi.LogicalConnectionImplementor;
-import org.hibernate.engine.jdbc.spi.NonDurableConnectionObserver;
-import org.hibernate.engine.transaction.spi.TransactionContext;
-import org.hibernate.internal.CoreMessageLogger;
-import org.hibernate.internal.util.collections.CollectionHelper;
-
-import org.jboss.logging.Logger;
-
-/**
- * Standard Hibernate {@link org.hibernate.engine.jdbc.spi.LogicalConnection} implementation
- * <p/>
- * IMPL NOTE : Custom serialization handling!
- *
- * @author Steve Ebersole
- * @author Brett Meyer
- */
-public class LogicalConnectionImpl implements LogicalConnectionImplementor {
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
-			CoreMessageLogger.class,
-			LogicalConnectionImpl.class.getName()
-	);
-
-	private transient Connection physicalConnection;
-
-	private final transient ConnectionReleaseMode connectionReleaseMode;
-	private final transient JdbcServices jdbcServices;
-	private final transient JdbcConnectionAccess jdbcConnectionAccess;
-	private final transient List<ConnectionObserver> observers;
-
-	private final boolean isUserSuppliedConnection;
-
-	private boolean isClosed;
-
-	/**
-	 * Constructs a LogicalConnectionImpl
-	 *
-	 * @param userSuppliedConnection The user-supplied connection
-	 * @param connectionReleaseMode The connection release mode to use
-	 * @param jdbcServices JdbcServices
-	 * @param jdbcConnectionAccess JDBC Connection access
-	 */
-	public LogicalConnectionImpl(
-			Connection userSuppliedConnection,
-			ConnectionReleaseMode connectionReleaseMode,
-			JdbcServices jdbcServices,
-			JdbcConnectionAccess jdbcConnectionAccess) {
-		this(
-				connectionReleaseMode,
-				jdbcServices,
-				jdbcConnectionAccess,
-				(userSuppliedConnection != null),
-				false,
-				new ArrayList<ConnectionObserver>()
-		);
-		this.physicalConnection = userSuppliedConnection;
-	}
-
-	/**
-	 * Constructs a LogicalConnectionImpl.  This for used from deserialization
-	 */
-	private LogicalConnectionImpl(
-			ConnectionReleaseMode connectionReleaseMode,
-			JdbcServices jdbcServices,
-			JdbcConnectionAccess jdbcConnectionAccess,
-			boolean isUserSuppliedConnection,
-			boolean isClosed,
-			List<ConnectionObserver> observers) {
-		this.connectionReleaseMode = determineConnectionReleaseMode(
-				jdbcConnectionAccess, isUserSuppliedConnection, connectionReleaseMode
-		);
-		this.jdbcServices = jdbcServices;
-		this.jdbcConnectionAccess = jdbcConnectionAccess;
-		this.observers = observers;
-
-		this.isUserSuppliedConnection = isUserSuppliedConnection;
-		this.isClosed = isClosed;
-	}
-
-	private static ConnectionReleaseMode determineConnectionReleaseMode(
-			JdbcConnectionAccess jdbcConnectionAccess,
-			boolean isUserSuppliedConnection,
-			ConnectionReleaseMode connectionReleaseMode) {
-		if ( isUserSuppliedConnection ) {
-			return ConnectionReleaseMode.ON_CLOSE;
-		}
-		else if ( connectionReleaseMode == ConnectionReleaseMode.AFTER_STATEMENT &&
-				! jdbcConnectionAccess.supportsAggressiveRelease() ) {
-			LOG.debug( "Connection provider reports to not support aggressive release; overriding" );
-			return ConnectionReleaseMode.AFTER_TRANSACTION;
-		}
-		else {
-			return connectionReleaseMode;
-		}
-	}
-
-	@Override
-	public JdbcServices getJdbcServices() {
-		return jdbcServices;
-	}
-
-	@Override
-	public void addObserver(ConnectionObserver observer) {
-		observers.add( observer );
-	}
-
-	@Override
-	public void removeObserver(ConnectionObserver connectionObserver) {
-		observers.remove( connectionObserver );
-	}
-
-	@Override
-	public boolean isOpen() {
-		return !isClosed;
-	}
-
-	@Override
-	public boolean isPhysicallyConnected() {
-		return physicalConnection != null;
-	}
-
-	@Override
-	public Connection getConnection() throws HibernateException {
-		if ( isClosed ) {
-			throw new HibernateException( "Logical connection is closed" );
-		}
-		if ( physicalConnection == null ) {
-			if ( isUserSuppliedConnection ) {
-				// should never happen
-				throw new HibernateException( "User-supplied connection was null" );
-			}
-			obtainConnection();
-		}
-		return physicalConnection;
-	}
-
-	@Override
-	public Connection close() {
-		LOG.trace( "Closing logical connection" );
-		final Connection c = isUserSuppliedConnection ? physicalConnection : null;
-		try {
-			if ( !isUserSuppliedConnection && physicalConnection != null ) {
-				releaseConnection();
-			}
-			return c;
-		}
-		finally {
-			// no matter what
-			physicalConnection = null;
-			isClosed = true;
-			LOG.trace( "Logical connection closed" );
-			for ( ConnectionObserver observer : observers ) {
-				observer.logicalConnectionClosed();
-			}
-			observers.clear();
-		}
-	}
-
-	@Override
-	public ConnectionReleaseMode getConnectionReleaseMode() {
-		return connectionReleaseMode;
-	}
-
-	/**
-	 * Force aggressive release of the underlying connection.
-	 */
-	@Override
-	public void aggressiveRelease() {
-		if ( isUserSuppliedConnection ) {
-			LOG.debug( "Cannot aggressively release user-supplied connection; skipping" );
-		}
-		else {
-			LOG.debug( "Aggressively releasing JDBC connection" );
-			if ( physicalConnection != null ) {
-				releaseConnection();
-			}
-		}
-	}
-
-
-	/**
-	 * Physically opens a JDBC Connection.
-	 *
-	 * @throws org.hibernate.JDBCException Indicates problem opening a connection
-	 */
-	private void obtainConnection() throws JDBCException {
-		LOG.debug( "Obtaining JDBC connection" );
-		try {
-			physicalConnection = jdbcConnectionAccess.obtainConnection();
-			for ( ConnectionObserver observer : observers ) {
-				observer.physicalConnectionObtained( physicalConnection );
-			}
-			LOG.debug( "Obtained JDBC connection" );
-		}
-		catch ( SQLException sqle) {
-			throw getJdbcServices().getSqlExceptionHelper().convert( sqle, "Could not open connection" );
-		}
-	}
-
-	/**
-	 * Physically closes the JDBC Connection.
-	 *
-	 * @throws JDBCException Indicates problem closing a connection
-	 */
-	@Override
-	public void releaseConnection() throws JDBCException {
-		LOG.debug( "Releasing JDBC connection" );
-		if ( physicalConnection == null ) {
-			return;
-		}
-		try {
-			if ( !physicalConnection.isClosed() ) {
-				getJdbcServices().getSqlExceptionHelper().logAndClearWarnings( physicalConnection );
-			}
-			if ( !isUserSuppliedConnection ) {
-				jdbcConnectionAccess.releaseConnection( physicalConnection );
-			}
-		}
-		catch (SQLException e) {
-			throw getJdbcServices().getSqlExceptionHelper().convert( e, "Could not close connection" );
-		}
-		finally {
-			physicalConnection = null;
-		}
-		LOG.debug( "Released JDBC connection" );
-		for ( ConnectionObserver observer : observers ) {
-			observer.physicalConnectionReleased();
-		}
-		releaseNonDurableObservers();
-	}
-
-	private void releaseNonDurableObservers() {
-		final Iterator observers = this.observers.iterator();
-		while ( observers.hasNext() ) {
-			if ( NonDurableConnectionObserver.class.isInstance( observers.next() ) ) {
-				observers.remove();
-			}
-		}
-	}
-
-	@Override
-	public Connection manualDisconnect() {
-		if ( isClosed ) {
-			throw new IllegalStateException( "cannot manually disconnect because logical connection is already closed" );
-		}
-		final Connection c = physicalConnection;
-		releaseConnection();
-		return c;
-	}
-
-	@Override
-	public void manualReconnect(Connection suppliedConnection) {
-		if ( isClosed ) {
-			throw new IllegalStateException( "cannot manually reconnect because logical connection is already closed" );
-		}
-		if ( !isUserSuppliedConnection ) {
-			throw new IllegalStateException( "cannot manually reconnect unless Connection was originally supplied" );
-		}
-		else {
-			if ( suppliedConnection == null ) {
-				throw new IllegalArgumentException( "cannot reconnect a null user-supplied connection" );
-			}
-			else if ( suppliedConnection == physicalConnection ) {
-				LOG.debug( "reconnecting the same connection that is already connected; should this connection have been disconnected?" );
-			}
-			else if ( physicalConnection != null ) {
-				throw new IllegalArgumentException(
-						"cannot reconnect to a new user-supplied connection because currently connected; must disconnect before reconnecting."
-				);
-			}
-			physicalConnection = suppliedConnection;
-			LOG.debug( "Reconnected JDBC connection" );
-		}
-	}
-
-	@Override
-	public boolean isAutoCommit() {
-		if ( !isOpen() || ! isPhysicallyConnected() ) {
-			return true;
-		}
-
-		try {
-			return getConnection().getAutoCommit();
-		}
-		catch (SQLException e) {
-			throw jdbcServices.getSqlExceptionHelper().convert( e, "could not inspect JDBC autocommit mode" );
-		}
-	}
-	
-	@Override
-	public boolean isUserSuppliedConnection() {
-		return isUserSuppliedConnection;
-	}
-
-	@Override
-	public void notifyObserversStatementPrepared() {
-		for ( ConnectionObserver observer : observers ) {
-			observer.statementPrepared();
-		}
-	}
-
-	/**
-	 * Serialization hook
-	 *
-	 * @param oos The stream to write out state to
-	 *
-	 * @throws IOException Problem accessing stream
-	 */
-	public void serialize(ObjectOutputStream oos) throws IOException {
-		oos.writeBoolean( isUserSuppliedConnection );
-		oos.writeBoolean( isClosed );
-		final List<ConnectionObserver> durableConnectionObservers = new ArrayList<ConnectionObserver>();
-		for ( ConnectionObserver observer : observers ) {
-			if ( ! NonDurableConnectionObserver.class.isInstance( observer ) ) {
-				durableConnectionObservers.add( observer );
-			}
-		}
-		oos.writeInt( durableConnectionObservers.size() );
-		for ( ConnectionObserver observer : durableConnectionObservers ) {
-			oos.writeObject( observer );
-		}
-	}
-
-	/**
-	 * Deserialization hook
-	 *
-	 * @param ois The stream to read our state from
-	 * @param transactionContext The transactionContext which owns this logical connection
-	 *
-	 * @return The deserialized LogicalConnectionImpl
-	 *
-	 * @throws IOException Trouble accessing the stream
-	 * @throws ClassNotFoundException Trouble reading the stream
-	 */
-	public static LogicalConnectionImpl deserialize(
-			ObjectInputStream ois,
-			TransactionContext transactionContext) throws IOException, ClassNotFoundException {
-		final boolean isUserSuppliedConnection = ois.readBoolean();
-		final boolean isClosed = ois.readBoolean();
-		final int observerCount = ois.readInt();
-		final List<ConnectionObserver> observers = CollectionHelper.arrayList( observerCount );
-		for ( int i = 0; i < observerCount; i++ ) {
-			observers.add( (ConnectionObserver) ois.readObject() );
-		}
-		return new LogicalConnectionImpl(
-				transactionContext.getConnectionReleaseMode(),
-				transactionContext.getTransactionEnvironment().getJdbcServices(),
-				transactionContext.getJdbcConnectionAccess(),
-				isUserSuppliedConnection,
-				isClosed,
-				observers
-		);
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/ResultSetReturnImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/ResultSetReturnImpl.java
index dc00391cc7..92403f6ee3 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/ResultSetReturnImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/ResultSetReturnImpl.java
@@ -1,239 +1,249 @@
 /* 
  * Hibernate, Relational Persistence for Idiomatic Java
  * 
  * JBoss, Home of Professional Open Source
  * Copyright 2013 Red Hat Inc. and/or its affiliates and other contributors
  * as indicated by the @authors tag. All rights reserved.
  * See the copyright.txt in the distribution for a
  * full listing of individual contributors.
  *
  * This copyrighted material is made available to anyone wishing to use,
  * modify, copy, or redistribute it subject to the terms and conditions
  * of the GNU Lesser General Public License, v. 2.1.
  * This program is distributed in the hope that it will be useful, but WITHOUT A
  * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
  * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
  * You should have received a copy of the GNU Lesser General Public License,
  * v.2.1 along with this distribution; if not, write to the Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
  * MA  02110-1301, USA.
  */
 package org.hibernate.engine.jdbc.internal;
 
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.ResultSetReturn;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
 
 /**
  * Standard implementation of the ResultSetReturn contract
  *
  * @author Brett Meyer
  */
 public class ResultSetReturnImpl implements ResultSetReturn {
 	private final JdbcCoordinator jdbcCoordinator;
 
 	private final Dialect dialect;
 	private final SqlStatementLogger sqlStatementLogger;
 	private final SqlExceptionHelper sqlExceptionHelper;
 	
 	private boolean isJdbc4 = true;
 
 	/**
 	 * Constructs a ResultSetReturnImpl
 	 *
 	 * @param jdbcCoordinator The JdbcCoordinator
 	 */
 	public ResultSetReturnImpl(JdbcCoordinator jdbcCoordinator) {
 		this.jdbcCoordinator = jdbcCoordinator;
 
-		final JdbcServices jdbcServices = jdbcCoordinator.getTransactionCoordinator().getTransactionContext()
-				.getTransactionEnvironment()
-				.getJdbcServices();
+		final JdbcServices jdbcServices = jdbcCoordinator.getJdbcSessionOwner()
+				.getJdbcSessionContext()
+				.getServiceRegistry()
+				.getService( JdbcServices.class );
 
 		this.dialect = jdbcServices.getDialect();
+
 		this.sqlStatementLogger = jdbcServices.getSqlStatementLogger();
 		this.sqlExceptionHelper = jdbcServices.getSqlExceptionHelper();
 	}
 
 	@Override
 	public ResultSet extract(PreparedStatement statement) {
 		// IMPL NOTE : SQL logged by caller
 		if (isTypeOf(statement, CallableStatement.class)) {
 			// We actually need to extract from Callable statement.  Although
 			// this seems needless, Oracle can return an
 			// OracleCallableStatementWrapper that finds its way to this method,
 			// rather than extract(CallableStatement).  See HHH-8022.
 			final CallableStatement callableStatement = (CallableStatement) statement;
 			return extract( callableStatement );
 		}
 		try {
 			final ResultSet rs;
 			try {
-				jdbcCoordinator.getTransactionCoordinator().getTransactionContext().startStatementExecution();
+				jdbcExecuteStatementStart();
 				rs = statement.executeQuery();
 			}
 			finally {
-				jdbcCoordinator.getTransactionCoordinator().getTransactionContext().endStatementExecution();
+				jdbcExecuteStatementEnd();
 			}
 			postExtract( rs, statement );
 			return rs;
 		}
 		catch (SQLException e) {
 			throw sqlExceptionHelper.convert( e, "could not extract ResultSet" );
 		}
 	}
 
+	private void jdbcExecuteStatementEnd() {
+		jdbcCoordinator.getJdbcSessionOwner().getJdbcSessionContext().getObserver().jdbcExecuteStatementEnd();
+	}
+
+	private void jdbcExecuteStatementStart() {
+		jdbcCoordinator.getJdbcSessionOwner().getJdbcSessionContext().getObserver().jdbcExecuteStatementStart();
+	}
+
 	private boolean isTypeOf(final Statement statement, final Class<? extends Statement> type) {
         if (isJdbc4) {
             try {
                 // This is "more correct" than #isInstance, but not always supported.
                 return statement.isWrapperFor( type );
             }
             catch (SQLException e) {
                 // No operation
             }
             catch (Throwable e) {
                 // No operation. Note that this catches more than just SQLException to
                 // cover edge cases where a driver might throw an UnsupportedOperationException, AbstractMethodError,
                 // etc.  If so, skip permanently.
                 isJdbc4 = false;
             }
         }
         return type.isInstance( statement );
     }
 
 	@Override
 	public ResultSet extract(CallableStatement callableStatement) {
 		// IMPL NOTE : SQL logged by caller
 		try {
 			final ResultSet rs;
 			try {
-				jdbcCoordinator.getTransactionCoordinator().getTransactionContext().startStatementExecution();
+				jdbcExecuteStatementStart();
 				rs = dialect.getResultSet( callableStatement );
 			}
 			finally {
-				jdbcCoordinator.getTransactionCoordinator().getTransactionContext().endStatementExecution();
+				jdbcExecuteStatementEnd();
 			}
 			postExtract( rs, callableStatement );
 			return rs;
 		}
 		catch (SQLException e) {
 			throw sqlExceptionHelper.convert( e, "could not extract ResultSet" );
 		}
 	}
 
 	@Override
 	public ResultSet extract(Statement statement, String sql) {
 		sqlStatementLogger.logStatement( sql );
 		try {
 			final ResultSet rs;
 			try {
-				jdbcCoordinator.getTransactionCoordinator().getTransactionContext().startStatementExecution();
+				jdbcExecuteStatementStart();
 				rs = statement.executeQuery( sql );
 			}
 			finally {
-				jdbcCoordinator.getTransactionCoordinator().getTransactionContext().endStatementExecution();
+				jdbcExecuteStatementEnd();
 			}
 			postExtract( rs, statement );
 			return rs;
 		}
 		catch (SQLException e) {
 			throw sqlExceptionHelper.convert( e, "could not extract ResultSet" );
 		}
 	}
 
 	@Override
 	public ResultSet execute(PreparedStatement statement) {
 		// sql logged by StatementPreparerImpl
 		try {
 			final ResultSet rs;
 			try {
-				jdbcCoordinator.getTransactionCoordinator().getTransactionContext().startStatementExecution();
+				jdbcExecuteStatementStart();
 				if ( !statement.execute() ) {
 					while ( !statement.getMoreResults() && statement.getUpdateCount() != -1 ) {
 						// do nothing until we hit the resultset
 					}
 				}
 				rs = statement.getResultSet();
 			}
 			finally {
-				jdbcCoordinator.getTransactionCoordinator().getTransactionContext().endStatementExecution();
+				jdbcExecuteStatementEnd();
 			}
 			postExtract( rs, statement );
 			return rs;
 		}
 		catch (SQLException e) {
 			throw sqlExceptionHelper.convert( e, "could not execute statement" );
 		}
 	}
 
 	@Override
 	public ResultSet execute(Statement statement, String sql) {
 		sqlStatementLogger.logStatement( sql );
 		try {
 			final ResultSet rs;
 			try {
-				jdbcCoordinator.getTransactionCoordinator().getTransactionContext().startStatementExecution();
+				jdbcExecuteStatementStart();
 				if ( !statement.execute( sql ) ) {
 					while ( !statement.getMoreResults() && statement.getUpdateCount() != -1 ) {
 						// do nothing until we hit the resultset
 					}
 				}
 				rs = statement.getResultSet();
 			}
 			finally {
-				jdbcCoordinator.getTransactionCoordinator().getTransactionContext().endStatementExecution();
+				jdbcExecuteStatementEnd();
 			}
 			postExtract( rs, statement );
 			return rs;
 		}
 		catch (SQLException e) {
 			throw sqlExceptionHelper.convert( e, "could not execute statement" );
 		}
 	}
 	
 	@Override
 	public int executeUpdate(PreparedStatement statement) {
 		try {
-			jdbcCoordinator.getTransactionCoordinator().getTransactionContext().startStatementExecution();
+			jdbcExecuteStatementStart();
 			return statement.executeUpdate();
 		}
 		catch (SQLException e) {
 			throw sqlExceptionHelper.convert( e, "could not execute statement" );
 		}
 		finally {
-			jdbcCoordinator.getTransactionCoordinator().getTransactionContext().endStatementExecution();
+			jdbcExecuteStatementEnd();
 		}
 	}
 	
 	@Override
 	public int executeUpdate(Statement statement, String sql) {
 		sqlStatementLogger.logStatement( sql );
 		try {
-			jdbcCoordinator.getTransactionCoordinator().getTransactionContext().startStatementExecution();
+			jdbcExecuteStatementStart();
 			return statement.executeUpdate( sql );
 		}
 		catch (SQLException e) {
 			throw sqlExceptionHelper.convert( e, "could not execute statement" );
 		}
 		finally {
-			jdbcCoordinator.getTransactionCoordinator().getTransactionContext().endStatementExecution();
+			jdbcExecuteStatementEnd();
 		}
 	}
 
 	private void postExtract(ResultSet rs, Statement st) {
 		if ( rs != null ) {
-			jdbcCoordinator.register( rs, st );
+			jdbcCoordinator.getResourceRegistry().register( rs, st );
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/StatementPreparerImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/StatementPreparerImpl.java
index 7f6a67c400..ea34d8e999 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/StatementPreparerImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/internal/StatementPreparerImpl.java
@@ -1,232 +1,241 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.internal;
 
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.ScrollMode;
 import org.hibernate.cfg.Settings;
-import org.hibernate.engine.jdbc.spi.LogicalConnectionImplementor;
+import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jdbc.spi.StatementPreparer;
+import org.hibernate.resource.jdbc.spi.LogicalConnectionImplementor;
 
 /**
  * Standard implementation of StatementPreparer
  *
  * @author Steve Ebersole
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  * @author Brett Meyer
 */
 class StatementPreparerImpl implements StatementPreparer {
 	private JdbcCoordinatorImpl jdbcCoordinator;
 
 	/**
 	 * Construct a StatementPreparerImpl
 	 *
 	 * @param jdbcCoordinator The JdbcCoordinatorImpl
 	 */
 	StatementPreparerImpl(JdbcCoordinatorImpl jdbcCoordinator) {
 		this.jdbcCoordinator = jdbcCoordinator;
 	}
 
 	protected final Settings settings() {
 		return jdbcCoordinator.sessionFactory().getSettings();
 	}
 
 	protected final Connection connection() {
-		return logicalConnection().getConnection();
+		return logicalConnection().getPhysicalConnection();
 	}
 
 	protected final LogicalConnectionImplementor logicalConnection() {
 		return jdbcCoordinator.getLogicalConnection();
 	}
 
 	protected final SqlExceptionHelper sqlExceptionHelper() {
-		return jdbcCoordinator.getTransactionCoordinator().getTransactionContext().getTransactionEnvironment()
-				.getJdbcServices()
-				.getSqlExceptionHelper();
+		return getJdbcService().getSqlExceptionHelper();
 	}
 	
 	@Override
 	public Statement createStatement() {
 		try {
 			final Statement statement = connection().createStatement();
-			jdbcCoordinator.register( statement );
+			jdbcCoordinator.getResourceRegistry().register( statement, true );
 			return statement;
 		}
 		catch ( SQLException e ) {
 			throw sqlExceptionHelper().convert( e, "could not create statement" );
 		}
 	}
 
 	@Override
 	public PreparedStatement prepareStatement(String sql) {
 		return buildPreparedStatementPreparationTemplate( sql, false ).prepareStatement();
 	}
 
 	@Override
 	public PreparedStatement prepareStatement(String sql, final boolean isCallable) {
 		jdbcCoordinator.executeBatch();
 		return buildPreparedStatementPreparationTemplate( sql, isCallable ).prepareStatement();
 	}
 
 	private StatementPreparationTemplate buildPreparedStatementPreparationTemplate(String sql, final boolean isCallable) {
 		return new StatementPreparationTemplate( sql ) {
 			@Override
 			protected PreparedStatement doPrepare() throws SQLException {
 				return isCallable
 						? connection().prepareCall( sql )
 						: connection().prepareStatement( sql );
 			}
 		};
 	}
 
 	private void checkAutoGeneratedKeysSupportEnabled() {
 		if ( ! settings().isGetGeneratedKeysEnabled() ) {
 			throw new AssertionFailure( "getGeneratedKeys() support is not enabled" );
 		}
 	}
 
 	@Override
 	public PreparedStatement prepareStatement(String sql, final int autoGeneratedKeys) {
 		if ( autoGeneratedKeys == PreparedStatement.RETURN_GENERATED_KEYS ) {
 			checkAutoGeneratedKeysSupportEnabled();
 		}
 		jdbcCoordinator.executeBatch();
 		return new StatementPreparationTemplate( sql ) {
 			public PreparedStatement doPrepare() throws SQLException {
 				return connection().prepareStatement( sql, autoGeneratedKeys );
 			}
 		}.prepareStatement();
 	}
 
 	@Override
 	public PreparedStatement prepareStatement(String sql, final String[] columnNames) {
 		checkAutoGeneratedKeysSupportEnabled();
 		jdbcCoordinator.executeBatch();
 		return new StatementPreparationTemplate( sql ) {
 			public PreparedStatement doPrepare() throws SQLException {
 				return connection().prepareStatement( sql, columnNames );
 			}
 		}.prepareStatement();
 	}
 
 	@Override
 	public PreparedStatement prepareQueryStatement(
 			String sql,
 			final boolean isCallable,
 			final ScrollMode scrollMode) {
 		if ( scrollMode != null && !scrollMode.equals( ScrollMode.FORWARD_ONLY ) ) {
 			if ( ! settings().isScrollableResultSetsEnabled() ) {
 				throw new AssertionFailure("scrollable result sets are not enabled");
 			}
 			final PreparedStatement ps = new QueryStatementPreparationTemplate( sql ) {
 				public PreparedStatement doPrepare() throws SQLException {
 						return isCallable
 								? connection().prepareCall( sql, scrollMode.toResultSetType(), ResultSet.CONCUR_READ_ONLY )
 								: connection().prepareStatement( sql, scrollMode.toResultSetType(), ResultSet.CONCUR_READ_ONLY );
 				}
 			}.prepareStatement();
 			jdbcCoordinator.registerLastQuery( ps );
 			return ps;
 		}
 		else {
 			final PreparedStatement ps = new QueryStatementPreparationTemplate( sql ) {
 				public PreparedStatement doPrepare() throws SQLException {
 						return isCallable
 								? connection().prepareCall( sql )
 								: connection().prepareStatement( sql );
 				}
 			}.prepareStatement();
 			jdbcCoordinator.registerLastQuery( ps );
 			return ps;
 		}
 	}
 
 	private abstract class StatementPreparationTemplate {
 		protected final String sql;
 
 		protected StatementPreparationTemplate(String sql) {
-			this.sql = jdbcCoordinator.getTransactionCoordinator().getTransactionContext().onPrepareStatement( sql );
+			this.sql = jdbcCoordinator.getJdbcSessionOwner().getJdbcSessionContext().getStatementInspector().inspect(
+					sql
+			);
 		}
 
 		public PreparedStatement prepareStatement() {
 			try {
-				jdbcCoordinator.getLogicalConnection().getJdbcServices().getSqlStatementLogger().logStatement( sql );
+				getJdbcService().getSqlStatementLogger().logStatement( sql );
 
 				final PreparedStatement preparedStatement;
 				try {
-					jdbcCoordinator.getTransactionCoordinator().getTransactionContext().startPrepareStatement();
+					jdbcCoordinator.getJdbcSessionOwner().getJdbcSessionContext().getObserver().jdbcPrepareStatementStart();
 					preparedStatement = doPrepare();
 					setStatementTimeout( preparedStatement );
 				}
 				finally {
-					jdbcCoordinator.getTransactionCoordinator().getTransactionContext().endPrepareStatement();
+					jdbcCoordinator.getJdbcSessionOwner().getJdbcSessionContext().getObserver().jdbcPrepareStatementEnd();
 				}
 				postProcess( preparedStatement );
 				return preparedStatement;
 			}
 			catch ( SQLException e ) {
 				throw sqlExceptionHelper().convert( e, "could not prepare statement", sql );
 			}
 		}
 
 		protected abstract PreparedStatement doPrepare() throws SQLException;
 
 		public void postProcess(PreparedStatement preparedStatement) throws SQLException {
-			jdbcCoordinator.register( preparedStatement );
-			logicalConnection().notifyObserversStatementPrepared();
+			jdbcCoordinator.getResourceRegistry().register( preparedStatement, true );
+//			logicalConnection().notifyObserversStatementPrepared();
 		}
 
 		private void setStatementTimeout(PreparedStatement preparedStatement) throws SQLException {
 			final int remainingTransactionTimeOutPeriod = jdbcCoordinator.determineRemainingTransactionTimeOutPeriod();
 			if ( remainingTransactionTimeOutPeriod > 0 ) {
 				preparedStatement.setQueryTimeout( remainingTransactionTimeOutPeriod );
 			}
 		}
 	}
 
+	private JdbcServices getJdbcService() {
+		return jdbcCoordinator
+				.getJdbcSessionOwner()
+				.getJdbcSessionContext()
+				.getServiceRegistry()
+				.getService( JdbcServices.class );
+	}
+
 	private abstract class QueryStatementPreparationTemplate extends StatementPreparationTemplate {
 		protected QueryStatementPreparationTemplate(String sql) {
 			super( sql );
 		}
 
 		public void postProcess(PreparedStatement preparedStatement) throws SQLException {
 			super.postProcess( preparedStatement );
 			setStatementFetchSize( preparedStatement );
 		}
 	}
 
 	private void setStatementFetchSize(PreparedStatement statement) throws SQLException {
 		if ( settings().getJdbcFetchSize() != null ) {
 			statement.setFetchSize( settings().getJdbcFetchSize() );
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/JdbcCoordinator.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/JdbcCoordinator.java
index fa0d16e6a9..c7c8a16b47 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/JdbcCoordinator.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/JdbcCoordinator.java
@@ -1,227 +1,187 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.spi;
 
 import java.io.Serializable;
 import java.sql.Connection;
-import java.sql.ResultSet;
 import java.sql.Statement;
 
+import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.engine.jdbc.batch.spi.Batch;
 import org.hibernate.engine.jdbc.batch.spi.BatchKey;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.jdbc.WorkExecutorVisitable;
+import org.hibernate.resource.jdbc.ResourceRegistry;
+import org.hibernate.resource.jdbc.spi.LogicalConnectionImplementor;
+import org.hibernate.resource.transaction.TransactionCoordinator;
+import org.hibernate.resource.transaction.backend.store.spi.DataStoreTransactionAccess;
+import org.hibernate.resource.transaction.spi.TransactionCoordinatorOwner;
 
 /**
  * Coordinates JDBC-related activities.
  *
  * @author Steve Ebersole
  * @author Brett Meyer
  */
-public interface JdbcCoordinator extends Serializable {
-	/**
-	 * Retrieve the transaction coordinator associated with this JDBC coordinator.
-	 *
-	 * @return The transaction coordinator
-	 */
-	public TransactionCoordinator getTransactionCoordinator();
+public interface JdbcCoordinator extends Serializable, TransactionCoordinatorOwner, DataStoreTransactionAccess {
+//	/**
+//	 * Retrieve the transaction coordinator associated with this JDBC coordinator.
+//	 *
+//	 * @return The transaction coordinator
+//	 */
+//	public TransactionCoordinator getTransactionCoordinator();
 
 	/**
 	 * Retrieves the logical connection associated with this JDBC coordinator.
 	 *
 	 * @return The logical connection
 	 */
 	public LogicalConnectionImplementor getLogicalConnection();
 
 	/**
 	 * Get a batch instance.
 	 *
 	 * @param key The unique batch key.
 	 *
 	 * @return The batch
 	 */
 	public Batch getBatch(BatchKey key);
 
 	/**
 	 * Execute the currently managed batch (if any)
 	 */
 	public void executeBatch();
 
 	/**
 	 * Abort the currently managed batch (if any)
 	 */
 	public void abortBatch();
 
 	/**
 	 * Obtain the statement preparer associated with this JDBC coordinator.
 	 *
 	 * @return This coordinator's statement preparer
 	 */
 	public StatementPreparer getStatementPreparer();
 
 	/**
 	 * Obtain the resultset extractor associated with this JDBC coordinator.
 	 *
 	 * @return This coordinator's resultset extractor
 	 */
 	public ResultSetReturn getResultSetReturn();
 
 	/**
 	 * Callback to let us know that a flush is beginning.  We use this fact
 	 * to temporarily circumvent aggressive connection releasing until after
 	 * the flush cycle is complete {@link #flushEnding()}
 	 */
 	public void flushBeginning();
 
 	/**
 	 * Callback to let us know that a flush is ending.  We use this fact to
 	 * stop circumventing aggressive releasing connections.
 	 */
 	public void flushEnding();
 
 	/**
 	 * Close this coordinator and release and resources.
 	 *
 	 * @return The {@link Connection} associated with the managed {@link #getLogicalConnection() logical connection}
 	 *
-	 * @see LogicalConnection#close
+	 * @see org.hibernate.resource.jdbc.spi.LogicalConnectionImplementor#close
 	 */
 	public Connection close();
 
 	/**
 	 * Signals the end of transaction.
 	 * <p/>
 	 * Intended for use from the transaction coordinator, after local transaction completion.  Used to conditionally
 	 * release the JDBC connection aggressively if the configured release mode indicates.
 	 */
 	public void afterTransaction();
 
 	/**
 	 * Used to signify that a statement has completed execution which may
 	 * indicate that this logical connection need to perform an
 	 * aggressive release of its physical connection.
 	 */
 	public void afterStatementExecution();
 
 	/**
 	 * Perform the requested work handling exceptions, coordinating and handling return processing.
 	 *
 	 * @param work The work to be performed.
 	 * @param <T> The result type.
 	 * @return The work result.
 	 */
 	public <T> T coordinateWork(WorkExecutorVisitable<T> work);
 
 	/**
 	 * Attempt to cancel the last query sent to the JDBC driver.
 	 */
 	public void cancelLastQuery();
 
-	/**
-	 * Set the effective transaction timeout period for the current transaction, in seconds.
-	 *
-	 * @param seconds The number of seconds before a time out should occur.
-	 */
-	public void setTransactionTimeOut(int seconds);
-
     /**
 	 * Calculate the amount of time, in seconds, still remaining before transaction timeout occurs.
 	 *
 	 * @return The number of seconds remaining until until a transaction timeout occurs.  A negative value indicates
 	 * no timeout was requested.
 	 *
 	 * @throws org.hibernate.TransactionException Indicates the time out period has already been exceeded.
 	 */
 	public int determineRemainingTransactionTimeOutPeriod();
 
 	/**
-	 * Register a JDBC statement.
-	 *
-	 * @param statement The statement to register.
-	 */
-	public void register(Statement statement);
-	
-	/**
-	 * Release a previously registered statement.
-	 *
-	 * @param statement The statement to release.
-	 */
-	public void release(Statement statement);
-
-	/**
-	 * Register a JDBC result set.
-	 * <p/>
-	 * Implementation note: Second parameter has been introduced to prevent
-	 * multiple registrations of the same statement in case {@link ResultSet#getStatement()}
-	 * does not return original {@link Statement} object.
-	 *
-	 * @param resultSet The result set to register.
-	 * @param statement Statement from which {@link ResultSet} has been generated.
-	 */
-	public void register(ResultSet resultSet, Statement statement);
-
-	/**
-	 * Release a previously registered result set.
-	 *
-	 * @param resultSet The result set to release.
-	 * @param statement Statement from which {@link ResultSet} has been generated.
-	 */
-	public void release(ResultSet resultSet, Statement statement);
-
-	/**
-	 * Does this registry currently have any registered resources?
-	 *
-	 * @return True if the registry does have registered resources; false otherwise.
-	 */
-	public boolean hasRegisteredResources();
-
-	/**
-	 * Release all registered resources.
-	 */
-	public void releaseResources();
-
-	/**
 	 * Enable connection releases
 	 */
 	public void enableReleases();
 
 	/**
 	 * Disable connection releases
 	 */
 	public void disableReleases();
 
 	/**
 	 * Register a query statement as being able to be cancelled.
 	 * 
 	 * @param statement The cancel-able query statement.
 	 */
 	public void registerLastQuery(Statement statement);
 
 	/**
 	 * Can this coordinator be serialized?
 	 *
 	 * @return {@code true} indicates the coordinator can be serialized.
 	 */
 	public boolean isReadyForSerialization();
+
+	/**
+	 * The release mode under which this logical connection is operating.
+	 *
+	 * @return the release mode.
+	 */
+	public ConnectionReleaseMode getConnectionReleaseMode();
+
+	public ResourceRegistry getResourceRegistry();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/LogicalConnection.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/LogicalConnection.java
deleted file mode 100644
index 6741e9a47c..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/LogicalConnection.java
+++ /dev/null
@@ -1,71 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.engine.jdbc.spi;
-
-import java.io.Serializable;
-import java.sql.Connection;
-
-/**
- * LogicalConnection contract
- *
- * @author Steve Ebersole
- */
-public interface LogicalConnection extends Serializable {
-	/**
-	 * Is this logical connection open?  Another phraseology sometimes used is: "are we
-	 * logically connected"?
-	 *
-	 * @return True if logically connected; false otherwise.
-	 */
-	public boolean isOpen();
-
-	/**
-	 * Is this logical connection instance "physically" connected.  Meaning
-	 * do we currently internally have a cached connection.
-	 *
-	 * @return True if physically connected; false otherwise.
-	 */
-	public boolean isPhysicallyConnected();
-
-	/**
-	 * Retrieves the connection currently "logically" managed by this LogicalConnectionImpl.
-	 * <p/>
-	 * Note, that we may need to obtain a connection to return here if a
-	 * connection has either not yet been obtained (non-UserSuppliedConnectionProvider)
-	 * or has previously been aggressively released.
-	 *
-	 * @return The current Connection.
-	 */
-	public Connection getConnection();
-
-	/**
-	 * Release the underlying connection and clean up any other resources associated
-	 * with this logical connection.
-	 * <p/>
-	 * This leaves the logical connection in a "no longer usable" state.
-	 *
-	 * @return The application-supplied connection, or {@code null} if Hibernate was managing connection.
-	 */
-	public Connection close();
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/query/spi/NativeSQLQueryPlan.java b/hibernate-core/src/main/java/org/hibernate/engine/query/spi/NativeSQLQueryPlan.java
index 27d331d434..e5d18c3a20 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/query/spi/NativeSQLQueryPlan.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/query/spi/NativeSQLQueryPlan.java
@@ -1,229 +1,230 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.query.spi;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.QueryException;
 import org.hibernate.action.internal.BulkOperationCleanupAction;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.TypedValue;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.custom.CustomQuery;
 import org.hibernate.type.Type;
 
 /**
  * Defines a query execution plan for a native-SQL query.
  *
  * @author Steve Ebersole
  */
 public class NativeSQLQueryPlan implements Serializable {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( NativeSQLQueryPlan.class );
 
 	private final String sourceQuery;
 	private final CustomQuery customQuery;
 
 	/**
 	  * Constructs a NativeSQLQueryPlan.
 	  *
 	  * @param sourceQuery The original native query to create a plan for
 	  * @param customQuery The query executed via this plan
 	  */
 	public NativeSQLQueryPlan(String sourceQuery, CustomQuery customQuery) {
 		this.sourceQuery = sourceQuery;
 		this.customQuery = customQuery;
 	}
 
 	public String getSourceQuery() {
 		return sourceQuery;
 	}
 
 	public CustomQuery getCustomQuery() {
 		return customQuery;
 	}
 
 	private int[] getNamedParameterLocs(String name) throws QueryException {
 		final Object loc = customQuery.getNamedParameterBindPoints().get( name );
 		if ( loc == null ) {
 			throw new QueryException(
 					"Named parameter does not appear in Query: " + name,
 					customQuery.getSQL() );
 		}
 		if ( loc instanceof Integer ) {
 			return new int[] { (Integer) loc };
 		}
 		else {
 			return ArrayHelper.toIntArray( (List) loc );
 		}
 	}
 
 	/**
 	 * Perform binding of all the JDBC bind parameter values based on the user-defined
 	 * positional query parameters (these are the '?'-style hibernate query
 	 * params) into the JDBC {@link PreparedStatement}.
 	 *
 	 * @param st The prepared statement to which to bind the parameter values.
 	 * @param queryParameters The query parameters specified by the application.
 	 * @param start JDBC paramer binds are positional, so this is the position
 	 * from which to start binding.
 	 * @param session The session from which the query originated.
 	 *
 	 * @return The number of JDBC bind positions accounted for during execution.
 	 *
 	 * @throws SQLException Some form of JDBC error binding the values.
 	 * @throws HibernateException Generally indicates a mapping problem or type mismatch.
 	 */
 	private int bindPositionalParameters(
 			final PreparedStatement st,
 			final QueryParameters queryParameters,
 			final int start,
 			final SessionImplementor session) throws SQLException {
 		final Object[] values = queryParameters.getFilteredPositionalParameterValues();
 		final Type[] types = queryParameters.getFilteredPositionalParameterTypes();
 		int span = 0;
 		for (int i = 0; i < values.length; i++) {
 			types[i].nullSafeSet( st, values[i], start + span, session );
 			span += types[i].getColumnSpan( session.getFactory() );
 		}
 		return span;
 	}
 
 	/**
 	 * Perform binding of all the JDBC bind parameter values based on the user-defined
 	 * named query parameters into the JDBC {@link PreparedStatement}.
 	 *
 	 * @param ps The prepared statement to which to bind the parameter values.
 	 * @param namedParams The named query parameters specified by the application.
 	 * @param start JDBC paramer binds are positional, so this is the position
 	 * from which to start binding.
 	 * @param session The session from which the query originated.
 	 *
 	 * @return The number of JDBC bind positions accounted for during execution.
 	 *
 	 * @throws SQLException Some form of JDBC error binding the values.
 	 * @throws HibernateException Generally indicates a mapping problem or type mismatch.
 	 */
 	private int bindNamedParameters(
 			final PreparedStatement ps,
 			final Map namedParams,
 			final int start,
 			final SessionImplementor session) throws SQLException {
 		if ( namedParams != null ) {
 			// assumes that types are all of span 1
 			final Iterator iter = namedParams.entrySet().iterator();
 			int result = 0;
 			while ( iter.hasNext() ) {
 				final Map.Entry e = (Map.Entry) iter.next();
 				final String name = (String) e.getKey();
 				final TypedValue typedval = (TypedValue) e.getValue();
 				final int[] locs = getNamedParameterLocs( name );
 				for ( int loc : locs ) {
 					LOG.debugf( "bindNamedParameters() %s -> %s [%s]", typedval.getValue(), name, loc + start );
 					typedval.getType().nullSafeSet(
 							ps,
 							typedval.getValue(),
 							loc + start,
 							session
 					);
 				}
 				result += locs.length;
 			}
 			return result;
 		}
 
 		return 0;
 	}
 
 	protected void coordinateSharedCacheCleanup(SessionImplementor session) {
 		final BulkOperationCleanupAction action = new BulkOperationCleanupAction( session, getCustomQuery().getQuerySpaces() );
 
 		if ( session.isEventSource() ) {
 			( (EventSource) session ).getActionQueue().addAction( action );
 		}
 		else {
 			action.getAfterTransactionCompletionProcess().doAfterTransactionCompletion( true, session );
 		}
 	}
 
 	/**
 	 * Performs the execute query
 	 *
 	 * @param queryParameters The query parameters
 	 * @param session The session
 	 *
 	 * @return The number of affected rows as returned by the JDBC driver
 	 *
 	 * @throws HibernateException Indicates a problem performing the query execution
 	 */
 	public int performExecuteUpdate(
 			QueryParameters queryParameters,
 			SessionImplementor session) throws HibernateException {
 
 		coordinateSharedCacheCleanup( session );
 
 		if ( queryParameters.isCallable() ) {
 			throw new IllegalArgumentException("callable not yet supported for native queries");
 		}
 
 		int result = 0;
 		PreparedStatement ps;
 		try {
 			queryParameters.processFilters( this.customQuery.getSQL(), session );
 			final String sql = queryParameters.getFilteredSQL();
 
-			ps = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql, false );
+			ps = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( sql, false );
 
 			try {
 				int col = 1;
 				col += bindPositionalParameters( ps, queryParameters, col, session );
 				col += bindNamedParameters( ps, queryParameters.getNamedParameters(), col, session );
-				result = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( ps );
+				result = session.getJdbcCoordinator().getResultSetReturn().executeUpdate( ps );
 			}
 			finally {
 				if ( ps != null ) {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
+					session.getJdbcCoordinator().getResourceRegistry().release( ps );
+					session.getJdbcCoordinator().afterStatementExecution();
 				}
 			}
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not execute native bulk manipulation query",
 					this.sourceQuery
 			);
 		}
 
 		return result;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/spi/ActionQueue.java b/hibernate-core/src/main/java/org/hibernate/engine/spi/ActionQueue.java
index 6ed62fd48b..a3793f3087 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/spi/ActionQueue.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/spi/ActionQueue.java
@@ -1,913 +1,913 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.spi;
 
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Map;
 import java.util.Queue;
 import java.util.Set;
 import java.util.concurrent.ConcurrentLinkedQueue;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.PropertyValueException;
 import org.hibernate.action.internal.AbstractEntityInsertAction;
 import org.hibernate.action.internal.BulkOperationCleanupAction;
 import org.hibernate.action.internal.CollectionRecreateAction;
 import org.hibernate.action.internal.CollectionRemoveAction;
 import org.hibernate.action.internal.CollectionUpdateAction;
 import org.hibernate.action.internal.EntityDeleteAction;
 import org.hibernate.action.internal.EntityIdentityInsertAction;
 import org.hibernate.action.internal.EntityInsertAction;
 import org.hibernate.action.internal.EntityUpdateAction;
 import org.hibernate.action.internal.OrphanRemovalAction;
 import org.hibernate.action.internal.QueuedOperationCollectionAction;
 import org.hibernate.action.internal.UnresolvedEntityInsertActions;
 import org.hibernate.action.spi.AfterTransactionCompletionProcess;
 import org.hibernate.action.spi.BeforeTransactionCompletionProcess;
 import org.hibernate.action.spi.Executable;
 import org.hibernate.cache.CacheException;
 import org.hibernate.engine.internal.NonNullableTransientDependencies;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.LazyInitializer;
 import org.hibernate.type.Type;
 
 /**
  * Responsible for maintaining the queue of actions related to events.
  *
  * The ActionQueue holds the DML operations queued as part of a session's transactional-write-behind semantics. The
  * DML operations are queued here until a flush forces them to be executed against the database.
  * 
  * @author Steve Ebersole
  * @author Gail Badner
  * @author Anton Marsden
  */
 public class ActionQueue {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( ActionQueue.class );
 
 	private SessionImplementor session;
 
 	private UnresolvedEntityInsertActions unresolvedInsertions;
 
 	// Object insertions, updates, and deletions have list semantics because
 	// they must happen in the right order so as to respect referential
 	// integrity
 	private final ExecutableList<AbstractEntityInsertAction> insertions;
 	private final ExecutableList<EntityDeleteAction> deletions;
 	private final ExecutableList<EntityUpdateAction> updates;
 
 	// Actually the semantics of the next three are really "Bag"
 	// Note that, unlike objects, collection insertions, updates,
 	// deletions are not really remembered between flushes. We
 	// just re-use the same Lists for convenience.
 	private final ExecutableList<CollectionRecreateAction> collectionCreations;
 	private final ExecutableList<CollectionUpdateAction> collectionUpdates;
 	private final ExecutableList<QueuedOperationCollectionAction> collectionQueuedOps;
 	private final ExecutableList<CollectionRemoveAction> collectionRemovals;
 	
 	// TODO: The removeOrphan concept is a temporary "hack" for HHH-6484.  This should be removed once action/task
 	// ordering is improved.
 	private final ExecutableList<OrphanRemovalAction> orphanRemovals;
 
 	// an immutable array holding all 7 ExecutionLists in execution order
 	private final List<ExecutableList<?>> executableLists;
 
 	private transient boolean isTransactionCoordinatorShared;
 	private AfterTransactionCompletionProcessQueue afterTransactionProcesses;
 	private BeforeTransactionCompletionProcessQueue beforeTransactionProcesses;
 
 	/**
 	 * Constructs an action queue bound to the given session.
 	 * 
 	 * @param session The session "owning" this queue.
 	 */
 	public ActionQueue(SessionImplementor session) {
 		this.session = session;
 
 		unresolvedInsertions = new UnresolvedEntityInsertActions();
 
 		insertions = new ExecutableList<AbstractEntityInsertAction>( new InsertActionSorter() );
 		deletions = new ExecutableList<EntityDeleteAction>();
 		updates = new ExecutableList<EntityUpdateAction>();
 
 		collectionCreations = new ExecutableList<CollectionRecreateAction>();
 		collectionRemovals = new ExecutableList<CollectionRemoveAction>();
 		collectionUpdates = new ExecutableList<CollectionUpdateAction>();
 		collectionQueuedOps = new ExecutableList<QueuedOperationCollectionAction>();
 		
 		orphanRemovals = new ExecutableList<OrphanRemovalAction>();
 
 		// Important: these lists are in execution order
 		List<ExecutableList<?>> tmp = Arrays.<ExecutableList<?>>asList(
 				orphanRemovals,
 				insertions,
 				updates,
 				// do before actions are handled in the other collection queues
 				collectionQueuedOps,
 				collectionRemovals,
 				collectionUpdates,
 				collectionCreations,
 				deletions
 		);
 
 		executableLists = Collections.unmodifiableList( tmp );
 
 		isTransactionCoordinatorShared = false;
 		afterTransactionProcesses = new AfterTransactionCompletionProcessQueue( session );
 		beforeTransactionProcesses = new BeforeTransactionCompletionProcessQueue( session );
 
 	}
 
 	public void clear() {
 		for ( ExecutableList<?> l : executableLists ) {
 			l.clear();
 		}
 		unresolvedInsertions.clear();
 	}
 
 	/**
 	 * Adds an entity insert action
 	 *
 	 * @param action The action representing the entity insertion
 	 */
 	public void addAction(EntityInsertAction action) {
 		LOG.tracev( "Adding an EntityInsertAction for [{0}] object", action.getEntityName() );
 		addInsertAction( action );
 	}
 
 	private void addInsertAction(AbstractEntityInsertAction insert) {
 		if ( insert.isEarlyInsert() ) {
 			// For early inserts, must execute inserts before finding non-nullable transient entities.
 			// TODO: find out why this is necessary
 			LOG.tracev( "Executing inserts before finding non-nullable transient entities for early insert: [{0}]", insert );
 			executeInserts();
 		}
 		NonNullableTransientDependencies nonNullableTransientDependencies = insert.findNonNullableTransientEntities();
 		if ( nonNullableTransientDependencies == null ) {
 			LOG.tracev( "Adding insert with no non-nullable, transient entities: [{0}]", insert );
 			addResolvedEntityInsertAction( insert );
 		}
 		else {
 			if ( LOG.isTraceEnabled() ) {
 				LOG.tracev( "Adding insert with non-nullable, transient entities; insert=[{0}], dependencies=[{1}]", insert,
 							nonNullableTransientDependencies.toLoggableString( insert.getSession() ) );
 			}
 			unresolvedInsertions.addUnresolvedEntityInsertAction( insert, nonNullableTransientDependencies );
 		}
 	}
 
 	private void addResolvedEntityInsertAction(AbstractEntityInsertAction insert) {
 		if ( insert.isEarlyInsert() ) {
 			LOG.trace( "Executing insertions before resolved early-insert" );
 			executeInserts();
 			LOG.debug( "Executing identity-insert immediately" );
 			execute( insert );
 		}
 		else {
 			LOG.trace( "Adding resolved non-early insert action." );
 			insertions.add( insert );
 		}
 		insert.makeEntityManaged();
 		for ( AbstractEntityInsertAction resolvedAction : unresolvedInsertions.resolveDependentActions( insert.getInstance(), session ) ) {
 			addResolvedEntityInsertAction( resolvedAction );
 		}
 	}
 
 	/**
 	 * Adds an entity (IDENTITY) insert action
 	 *
 	 * @param action The action representing the entity insertion
 	 */
 	public void addAction(EntityIdentityInsertAction action) {
 		LOG.tracev( "Adding an EntityIdentityInsertAction for [{0}] object", action.getEntityName() );
 		addInsertAction( action );
 	}
 
 	/**
 	 * Adds an entity delete action
 	 *
 	 * @param action The action representing the entity deletion
 	 */
 	public void addAction(EntityDeleteAction action) {
 		deletions.add( action );
 	}
 
 	/**
 	 * Adds an orphan removal action
 	 *
 	 * @param action The action representing the orphan removal
 	 */
 	public void addAction(OrphanRemovalAction action) {
 		orphanRemovals.add( action );
 	}
 
 	/**
 	 * Adds an entity update action
 	 *
 	 * @param action The action representing the entity update
 	 */
 	public void addAction(EntityUpdateAction action) {
 		updates.add( action );
 	}
 
 	/**
 	 * Adds a collection (re)create action
 	 *
 	 * @param action The action representing the (re)creation of a collection
 	 */
 	public void addAction(CollectionRecreateAction action) {
 		collectionCreations.add( action );
 	}
 
 	/**
 	 * Adds a collection remove action
 	 *
 	 * @param action The action representing the removal of a collection
 	 */
 	public void addAction(CollectionRemoveAction action) {
 		collectionRemovals.add( action );
 	}
 
 	/**
 	 * Adds a collection update action
 	 *
 	 * @param action The action representing the update of a collection
 	 */
 	public void addAction(CollectionUpdateAction action) {
 		collectionUpdates.add( action );
 	}
 
 	/**
 	 * Adds an action relating to a collection queued operation (extra lazy).
 	 *
 	 * @param action The action representing the queued operation
 	 */
 	public void addAction(QueuedOperationCollectionAction action) {
 		collectionQueuedOps.add( action );
 	}
 
 	/**
 	 * Adds an action defining a cleanup relating to a bulk operation (HQL/JPQL or Criteria based update/delete)
 	 *
 	 * @param action The action representing the queued operation
 	 */
 	public void addAction(BulkOperationCleanupAction action) {
 		registerCleanupActions( action );
 	}
 
 	private void registerCleanupActions(Executable executable) {
 		beforeTransactionProcesses.register( executable.getBeforeTransactionCompletionProcess() );
 		if ( session.getFactory().getSettings().isQueryCacheEnabled() ) {
 			invalidateSpaces( executable.getPropertySpaces() );
 		}
 		afterTransactionProcesses.register( executable.getAfterTransactionCompletionProcess() );
 	}
 
 	/**
 	 * Are there unresolved entity insert actions that depend on non-nullable associations with a transient entity?
 	 * 
 	 * @return true, if there are unresolved entity insert actions that depend on non-nullable associations with a
 	 * transient entity; false, otherwise
 	 */
 	public boolean hasUnresolvedEntityInsertActions() {
 		return !unresolvedInsertions.isEmpty();
 	}
 
 	/**
 	 * Throws {@link org.hibernate.PropertyValueException} if there are any unresolved entity insert actions that depend
 	 * on non-nullable associations with a transient entity. This method should be called on completion of an operation
 	 * (after all cascades are completed) that saves an entity.
 	 * 
 	 * @throws org.hibernate.PropertyValueException if there are any unresolved entity insert actions;
 	 * {@link org.hibernate.PropertyValueException#getEntityName()} and
 	 * {@link org.hibernate.PropertyValueException#getPropertyName()} will return the entity name and property value for
 	 * the first unresolved entity insert action.
 	 */
 	public void checkNoUnresolvedActionsAfterOperation() throws PropertyValueException {
 		unresolvedInsertions.checkNoUnresolvedActionsAfterOperation();
 	}
 
 	public void registerProcess(AfterTransactionCompletionProcess process) {
 		afterTransactionProcesses.register( process );
 	}
 
 	public void registerProcess(BeforeTransactionCompletionProcess process) {
 		beforeTransactionProcesses.register( process );
 	}
 
 	/**
 	 * Perform all currently queued entity-insertion actions.
 	 * 
 	 * @throws HibernateException error executing queued insertion actions.
 	 */
 	public void executeInserts() throws HibernateException {
 		executeActions( insertions );
 	}
 
 	/**
 	 * Perform all currently queued actions.
 	 * 
 	 * @throws HibernateException error executing queued actions.
 	 */
 	public void executeActions() throws HibernateException {
 		if ( !unresolvedInsertions.isEmpty() ) {
 			throw new IllegalStateException( "About to execute actions, but there are unresolved entity insert actions." );
 		}
 
 		for ( ExecutableList<?> l : executableLists ) {
 			executeActions( l );
 		}
 	}
 
 	/**
 	 * Prepares the internal action queues for execution.
 	 * 
 	 * @throws HibernateException error preparing actions.
 	 */
 	public void prepareActions() throws HibernateException {
 		prepareActions( collectionRemovals );
 		prepareActions( collectionUpdates );
 		prepareActions( collectionCreations );
 		prepareActions( collectionQueuedOps );
 	}
 
 	private void prepareActions(ExecutableList<?> queue) throws HibernateException {
 		for ( Executable executable : queue ) {
 			executable.beforeExecutions();
 		}
 	}
 
 	/**
 	 * Performs cleanup of any held cache softlocks.
 	 * 
 	 * @param success Was the transaction successful.
 	 */
 	public void afterTransactionCompletion(boolean success) {
 		if ( !isTransactionCoordinatorShared ) {
 			// Execute completion actions only in transaction owner (aka parent session).
 			afterTransactionProcesses.afterTransactionCompletion( success );
 		}
 	}
 
 	/**
 	 * Execute any registered {@link org.hibernate.action.spi.BeforeTransactionCompletionProcess}
 	 */
 	public void beforeTransactionCompletion() {
 		if ( !isTransactionCoordinatorShared ) {
 			// Execute completion actions only in transaction owner (aka parent session).
 			beforeTransactionProcesses.beforeTransactionCompletion();
 		}
 	}
 
 	/**
 	 * Check whether any insertion or deletion actions are currently queued.
 	 *
 	 * @return {@code true} if insertions or deletions are currently queued; {@code false} otherwise.
 	 */
 	public boolean areInsertionsOrDeletionsQueued() {
 		return !insertions.isEmpty() || !unresolvedInsertions.isEmpty() || !deletions.isEmpty() || !orphanRemovals.isEmpty();
 	}
 
 	/**
 	 * Check whether the given tables/query-spaces are to be executed against given the currently queued actions.
 	 * 
 	 * @param tables The table/query-spaces to check.
 	 *
 	 * @return {@code true} if we contain pending actions against any of the given tables; {@code false} otherwise.
 	 */
 	public boolean areTablesToBeUpdated(@SuppressWarnings("rawtypes") Set tables) {
 		if ( tables.isEmpty() ) {
 			return false;
 		}
 		for ( ExecutableList<?> l : executableLists ) {
 			if ( areTablesToBeUpdated( l, tables ) ) {
 				return true;
 			}
 		}
 		return areTablesToBeUpdated( unresolvedInsertions, tables );
 	}
 
 	private static boolean areTablesToBeUpdated(ExecutableList<?> actions, @SuppressWarnings("rawtypes") Set tableSpaces) {
 		if ( actions.isEmpty() ) {
 			return false;
 		}
 
 		for ( Serializable actionSpace : actions.getQuerySpaces() ) {
 			if ( tableSpaces.contains( actionSpace ) ) {
 				LOG.debugf( "Changes must be flushed to space: %s", actionSpace );
 				return true;
 			}
 		}
 
 		return false;
 	}
 
 	private static boolean areTablesToBeUpdated(UnresolvedEntityInsertActions actions, @SuppressWarnings("rawtypes") Set tableSpaces) {
 		for ( Executable action : actions.getDependentEntityInsertActions() ) {
 			final Serializable[] spaces = action.getPropertySpaces();
 			for ( Serializable space : spaces ) {
 				if ( tableSpaces.contains( space ) ) {
 					LOG.debugf( "Changes must be flushed to space: %s", space );
 					return true;
 				}
 			}
 		}
 		return false;
 	}
 
 	/**
 	 * Perform {@link org.hibernate.action.spi.Executable#execute()} on each element of the list
 	 * 
 	 * @param list The list of Executable elements to be performed
 	 *
 	 * @throws HibernateException
 	 */
 	private <E extends Executable & Comparable<?> & Serializable> void executeActions(ExecutableList<E> list) throws HibernateException {
 		// todo : consider ways to improve the double iteration of Executables here:
 		//		1) we explicitly iterate list here to perform Executable#execute()
 		//		2) ExecutableList#getQuerySpaces also iterates the Executables to collect query spaces.
 		try {
 			for ( E e : list ) {
 				try {
 					e.execute();
 				}
 				finally {
 					beforeTransactionProcesses.register( e.getBeforeTransactionCompletionProcess() );
 					afterTransactionProcesses.register( e.getAfterTransactionCompletionProcess() );
 				}
 			}
 		}
 		finally {
 			if ( session.getFactory().getSettings().isQueryCacheEnabled() ) {
 				// Strictly speaking, only a subset of the list may have been processed if a RuntimeException occurs.
 				// We still invalidate all spaces. I don't see this as a big deal - after all, RuntimeExceptions are
 				// unexpected.
 				Set<Serializable> propertySpaces = list.getQuerySpaces();
 				invalidateSpaces( propertySpaces.toArray( new Serializable[propertySpaces.size()] ) );
 			}
 		}
 
 		list.clear();
-		session.getTransactionCoordinator().getJdbcCoordinator().executeBatch();
+		session.getJdbcCoordinator().executeBatch();
 	}
 
 	/**
 	 * @param executable The action to execute
 	 */
 	public <E extends Executable & Comparable<?>> void execute(E executable) {
 		try {
 			executable.execute();
 		}
 		finally {
 			registerCleanupActions( executable );
 		}
 	}
 
 	/**
 	 * This method is now called once per execution of an ExecutableList or once for execution of an Execution.
 	 * 
 	 * @param spaces The spaces to invalidate
 	 */
 	private void invalidateSpaces(Serializable... spaces) {
 		if ( spaces != null && spaces.length > 0 ) {
 			for ( Serializable s : spaces ) {
 				afterTransactionProcesses.addSpaceToInvalidate( (String) s );
 			}
 			// Performance win: If we are processing an ExecutableList, this will only be called once
 			session.getFactory().getUpdateTimestampsCache().preInvalidate( spaces, session );
 		}
 	}
 
 	/**
 	 * Returns a string representation of the object.
 	 * 
 	 * @return a string representation of the object.
 	 */
 	@Override
 	public String toString() {
 		return "ActionQueue[insertions=" + insertions
 				+ " updates=" + updates
 				+ " deletions=" + deletions
 				+ " orphanRemovals=" + orphanRemovals
 				+ " collectionCreations=" + collectionCreations
 				+ " collectionRemovals=" + collectionRemovals
 				+ " collectionUpdates=" + collectionUpdates
 				+ " collectionQueuedOps=" + collectionQueuedOps
 				+ " unresolvedInsertDependencies=" + unresolvedInsertions
 				+ "]";
 	}
 
 	public int numberOfCollectionRemovals() {
 		return collectionRemovals.size();
 	}
 
 	public int numberOfCollectionUpdates() {
 		return collectionUpdates.size();
 	}
 
 	public int numberOfCollectionCreations() {
 		return collectionCreations.size();
 	}
 
 	public int numberOfDeletions() {
 		return deletions.size() + orphanRemovals.size();
 	}
 
 	public int numberOfUpdates() {
 		return updates.size();
 	}
 
 	public int numberOfInsertions() {
 		return insertions.size();
 	}
 
 	public TransactionCompletionProcesses getTransactionCompletionProcesses() {
 		return new TransactionCompletionProcesses( beforeTransactionProcesses, afterTransactionProcesses );
 	}
 
 	/**
 	 * Bind transaction completion processes to make them shared between primary and secondary session.
 	 * Transaction completion processes are always executed by transaction owner (primary session),
 	 * but can be registered using secondary session too.
 	 *
 	 * @param processes Transaction completion processes.
 	 * @param isTransactionCoordinatorShared Flag indicating shared transaction context.
 	 */
 	public void setTransactionCompletionProcesses(TransactionCompletionProcesses processes, boolean isTransactionCoordinatorShared) {
 		this.isTransactionCoordinatorShared = isTransactionCoordinatorShared;
 		this.beforeTransactionProcesses = processes.beforeTransactionCompletionProcesses;
 		this.afterTransactionProcesses = processes.afterTransactionCompletionProcesses;
 	}
 
 	public void sortCollectionActions() {
 		if ( session.getFactory().getSettings().isOrderUpdatesEnabled() ) {
 			// sort the updates by fk
 			collectionCreations.sort();
 			collectionUpdates.sort();
 			collectionQueuedOps.sort();
 			collectionRemovals.sort();
 		}
 	}
 
 	public void sortActions() {
 		if ( session.getFactory().getSettings().isOrderUpdatesEnabled() ) {
 			// sort the updates by pk
 			updates.sort();
 		}
 		if ( session.getFactory().getSettings().isOrderInsertsEnabled() ) {
 			insertions.sort();
 		}
 	}
 
 	public void clearFromFlushNeededCheck(int previousCollectionRemovalSize) {
 		collectionCreations.clear();
 		collectionUpdates.clear();
 		collectionQueuedOps.clear();
 		updates.clear();
 		// collection deletions are a special case since update() can add
 		// deletions of collections not loaded by the session.
 		if ( collectionRemovals.size() > previousCollectionRemovalSize ) {
 			collectionRemovals.removeLastN( collectionRemovals.size() - previousCollectionRemovalSize );
 		}
 	}
 
 	public boolean hasAfterTransactionActions() {
 		return isTransactionCoordinatorShared ? false : afterTransactionProcesses.hasActions();
 	}
 
 	public boolean hasBeforeTransactionActions() {
 		return isTransactionCoordinatorShared ? false : beforeTransactionProcesses.hasActions();
 	}
 
 	public boolean hasAnyQueuedActions() {
 		return !updates.isEmpty() || !insertions.isEmpty() || !unresolvedInsertions.isEmpty() || !deletions.isEmpty() || !collectionUpdates.isEmpty()
 				|| !collectionQueuedOps.isEmpty() || !collectionRemovals.isEmpty() || !collectionCreations.isEmpty();
 	}
 
 	public void unScheduleDeletion(EntityEntry entry, Object rescuedEntity) {
 		if ( rescuedEntity instanceof HibernateProxy ) {
 			LazyInitializer initializer = ( ( HibernateProxy ) rescuedEntity ).getHibernateLazyInitializer();
 			if ( !initializer.isUninitialized() ) {
 				rescuedEntity = initializer.getImplementation( session );
 			}
 		}
 		for ( int i = 0; i < deletions.size(); i++ ) {
 			EntityDeleteAction action = deletions.get( i );
 			if ( action.getInstance() == rescuedEntity ) {
 				deletions.remove( i );
 				return;
 			}
 		}
 		for ( int i = 0; i < orphanRemovals.size(); i++ ) {
 			EntityDeleteAction action = orphanRemovals.get( i );
 			if ( action.getInstance() == rescuedEntity ) {
 				orphanRemovals.remove( i );
 				return;
 			}
 		}
 		throw new AssertionFailure( "Unable to perform un-delete for instance " + entry.getEntityName() );
 	}
 
 	/**
 	 * Used by the owning session to explicitly control serialization of the action queue
 	 * 
 	 * @param oos The stream to which the action queue should get written
 	 * @throws IOException Indicates an error writing to the stream
 	 */
 	public void serialize(ObjectOutputStream oos) throws IOException {
 		LOG.trace( "Serializing action-queue" );
 
 		unresolvedInsertions.serialize( oos );
 
 		for ( ExecutableList<?> l : executableLists ) {
 			l.writeExternal( oos );
 		}
 	}
 
 	/**
 	 * Used by the owning session to explicitly control deserialization of the action queue.
 	 * 
 	 * @param ois The stream from which to read the action queue
 	 * @param session The session to which the action queue belongs
 	 * @return The deserialized action queue
 	 * @throws IOException indicates a problem reading from the stream
 	 * @throws ClassNotFoundException Generally means we were unable to locate user classes.
 	 */
 	public static ActionQueue deserialize(ObjectInputStream ois, SessionImplementor session) throws IOException, ClassNotFoundException {
 		final boolean traceEnabled = LOG.isTraceEnabled();
 		if ( traceEnabled ) {
 			LOG.trace( "Deserializing action-queue" );
 		}
 		ActionQueue rtn = new ActionQueue( session );
 
 		rtn.unresolvedInsertions = UnresolvedEntityInsertActions.deserialize( ois, session );
 
 		for ( ExecutableList<?> l : rtn.executableLists ) {
 			l.readExternal( ois );
 			if ( traceEnabled ) {
 				LOG.tracev( "Deserialized [{0}] entries", l.size() );
 			}
 			l.afterDeserialize( session );
 		}
 
 		return rtn;
 	}
 
 	private static abstract class AbstractTransactionCompletionProcessQueue<T> {
 		protected SessionImplementor session;
 		// Concurrency handling required when transaction completion process is dynamically registered
 		// inside event listener (HHH-7478).
 		protected Queue<T> processes = new ConcurrentLinkedQueue<T>();
 
 		private AbstractTransactionCompletionProcessQueue(SessionImplementor session) {
 			this.session = session;
 		}
 
 		public void register(T process) {
 			if ( process == null ) {
 				return;
 			}
 			processes.add( process );
 		}
 
 		public boolean hasActions() {
 			return !processes.isEmpty();
 		}
 	}
 
 	/**
 	 * Encapsulates behavior needed for before transaction processing
 	 */
 	private static class BeforeTransactionCompletionProcessQueue extends AbstractTransactionCompletionProcessQueue<BeforeTransactionCompletionProcess> {
 		private BeforeTransactionCompletionProcessQueue(SessionImplementor session) {
 			super( session );
 		}
 
 		public void beforeTransactionCompletion() {
 			while ( !processes.isEmpty() ) {
 				try {
 					processes.poll().doBeforeTransactionCompletion( session );
 				}
 				catch (HibernateException he) {
 					throw he;
 				}
 				catch (Exception e) {
 					throw new AssertionFailure( "Unable to perform beforeTransactionCompletion callback", e );
 				}
 			}
 		}
 	}
 
 	/**
 	 * Encapsulates behavior needed for after transaction processing
 	 */
 	private static class AfterTransactionCompletionProcessQueue extends AbstractTransactionCompletionProcessQueue<AfterTransactionCompletionProcess> {
 		private Set<String> querySpacesToInvalidate = new HashSet<String>();
 
 		private AfterTransactionCompletionProcessQueue(SessionImplementor session) {
 			super( session );
 		}
 
 		public void addSpaceToInvalidate(String space) {
 			querySpacesToInvalidate.add( space );
 		}
 
 		public void afterTransactionCompletion(boolean success) {
 			while ( !processes.isEmpty() ) {
 				try {
 					processes.poll().doAfterTransactionCompletion( success, session );
 				}
 				catch (CacheException ce) {
 					LOG.unableToReleaseCacheLock( ce );
 					// continue loop
 				}
 				catch (Exception e) {
 					throw new AssertionFailure( "Exception releasing cache locks", e );
 				}
 			}
 
 			if ( session.getFactory().getSettings().isQueryCacheEnabled() ) {
 				session.getFactory().getUpdateTimestampsCache().invalidate(
 						querySpacesToInvalidate.toArray( new String[querySpacesToInvalidate.size()] ),
 						session
 				);
 			}
 			querySpacesToInvalidate.clear();
 		}
 	}
 
 	/**
 	 * Wrapper class allowing to bind the same transaction completion process queues in different sessions.
 	 */
 	public static class TransactionCompletionProcesses {
 		private final BeforeTransactionCompletionProcessQueue beforeTransactionCompletionProcesses;
 		private final AfterTransactionCompletionProcessQueue afterTransactionCompletionProcesses;
 
 		private TransactionCompletionProcesses(
 				BeforeTransactionCompletionProcessQueue beforeTransactionCompletionProcessQueue,
 				AfterTransactionCompletionProcessQueue afterTransactionCompletionProcessQueue) {
 			this.beforeTransactionCompletionProcesses = beforeTransactionCompletionProcessQueue;
 			this.afterTransactionCompletionProcesses = afterTransactionCompletionProcessQueue;
 		}
 	}
 
 	/**
 	 * Order the {@link #insertions} queue such that we group inserts against the same entity together (without
 	 * violating constraints). The original order is generated by cascade order, which in turn is based on the
 	 * directionality of foreign-keys. So even though we will be changing the ordering here, we need to make absolutely
 	 * certain that we do not circumvent this FK ordering to the extent of causing constraint violations.
 	 * <p>
 	 * Sorts the insert actions using more hashes.
 	 * </p>
 	 * NOTE: this class is not thread-safe.
 	 * 
 	 * @author Jay Erb
 	 */
 	private static class InsertActionSorter implements ExecutableList.Sorter<AbstractEntityInsertAction> {
 		/**
 		 * Singleton access
 		 */
 		public static final InsertActionSorter INSTANCE = new InsertActionSorter();
 
 		// the mapping of entity names to their latest batch numbers.
 		private Map<String, Integer> latestBatches;
 		private Map<Object, Integer> entityBatchNumber;
 
 		// the map of batch numbers to EntityInsertAction lists
 		private Map<Integer, List<AbstractEntityInsertAction>> actionBatches;
 
 		public InsertActionSorter() {
 		}
 
 		/**
 		 * Sort the insert actions.
 		 */
 		public void sort(List<AbstractEntityInsertAction> insertions) {
 			// optimize the hash size to eliminate a rehash.
 			this.latestBatches = new HashMap<String, Integer>();
 			this.entityBatchNumber = new HashMap<Object, Integer>( insertions.size() + 1, 1.0f );
 			this.actionBatches = new HashMap<Integer, List<AbstractEntityInsertAction>>();
 
 			// the list of entity names that indicate the batch number
 			for ( AbstractEntityInsertAction action : insertions ) {
 				// remove the current element from insertions. It will be added back later.
 				String entityName = action.getEntityName();
 
 				// the entity associated with the current action.
 				Object currentEntity = action.getInstance();
 
 				Integer batchNumber;
 				if ( latestBatches.containsKey( entityName ) ) {
 					// There is already an existing batch for this type of entity.
 					// Check to see if the latest batch is acceptable.
 					batchNumber = findBatchNumber( action, entityName );
 				}
 				else {
 					// add an entry for this type of entity.
 					// we can be assured that all referenced entities have already
 					// been processed,
 					// so specify that this entity is with the latest batch.
 					// doing the batch number before adding the name to the list is
 					// a faster way to get an accurate number.
 
 					batchNumber = actionBatches.size();
 					latestBatches.put( entityName, batchNumber );
 				}
 				entityBatchNumber.put( currentEntity, batchNumber );
 				addToBatch( batchNumber, action );
 			}
 			insertions.clear();
 
 			// now rebuild the insertions list. There is a batch for each entry in the name list.
 			for ( int i = 0; i < actionBatches.size(); i++ ) {
 				List<AbstractEntityInsertAction> batch = actionBatches.get( i );
 				insertions.addAll( batch );
 			}
 		}
 
 		/**
 		 * Finds an acceptable batch for this entity to be a member as part of the {@link InsertActionSorter}
 		 * 
 		 * @param action The action being sorted
 		 * @param entityName The name of the entity affected by the action
 		 * @return An appropriate batch number; todo document this process better
 		 */
 		private Integer findBatchNumber(AbstractEntityInsertAction action, String entityName) {
 			// loop through all the associated entities and make sure they have been
 			// processed before the latest
 			// batch associated with this entity type.
 
 			// the current batch number is the latest batch for this entity type.
 			Integer latestBatchNumberForType = latestBatches.get( entityName );
 
 			// loop through all the associations of the current entity and make sure that they are processed
 			// before the current batch number
 			Object[] propertyValues = action.getState();
 			Type[] propertyTypes = action.getPersister().getClassMetadata().getPropertyTypes();
 
 			for ( int i = 0; i < propertyValues.length; i++ ) {
 				Object value = propertyValues[i];
 				Type type = propertyTypes[i];
 				if ( type.isEntityType() && value != null ) {
 					// find the batch number associated with the current association, if any.
 					Integer associationBatchNumber = entityBatchNumber.get( value );
 					if ( associationBatchNumber != null && associationBatchNumber.compareTo( latestBatchNumberForType ) > 0 ) {
 						// create a new batch for this type. The batch number is the number of current batches.
 						latestBatchNumberForType = actionBatches.size();
 						latestBatches.put( entityName, latestBatchNumberForType );
 						// since this entity will now be processed in the latest possible batch,
 						// we can be assured that it will come after all other associations,
 						// there's not need to continue checking.
 						break;
 					}
 				}
 			}
 			return latestBatchNumberForType;
 		}
 
 		private void addToBatch(Integer batchNumber, AbstractEntityInsertAction action) {
 			List<AbstractEntityInsertAction> actions = actionBatches.get( batchNumber );
 
 			if ( actions == null ) {
 				actions = new LinkedList<AbstractEntityInsertAction>();
 				actionBatches.put( batchNumber, actions );
 			}
 			actions.add( action );
 		}
 
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionDelegatorBaseImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionDelegatorBaseImpl.java
index 1dc33596e9..9cff127b75 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionDelegatorBaseImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionDelegatorBaseImpl.java
@@ -1,803 +1,819 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.spi;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.CacheMode;
 import org.hibernate.Criteria;
 import org.hibernate.Filter;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.IdentifierLoadAccess;
 import org.hibernate.Interceptor;
 import org.hibernate.LobHelper;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.NaturalIdLoadAccess;
 import org.hibernate.Query;
 import org.hibernate.ReplicationMode;
 import org.hibernate.SQLQuery;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.SessionEventListener;
 import org.hibernate.SessionFactory;
 import org.hibernate.SharedSessionBuilder;
 import org.hibernate.SimpleNaturalIdLoadAccess;
 import org.hibernate.Transaction;
 import org.hibernate.TypeHelper;
 import org.hibernate.UnknownProfileException;
 import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
+import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.engine.query.spi.sql.NativeSQLQuerySpecification;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.jdbc.ReturningWork;
 import org.hibernate.jdbc.Work;
 import org.hibernate.loader.custom.CustomQuery;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.procedure.ProcedureCall;
+import org.hibernate.resource.transaction.TransactionCoordinator;
 import org.hibernate.stat.SessionStatistics;
 import org.hibernate.type.Type;
 
 /**
  * This class is meant to be extended.
  * 
  * Wraps and delegates all methods to a {@link SessionImplementor} and
  * a {@link Session}. This is useful for custom implementations of this
  * API so that only some methods need to be overridden
  * (Used by Hibernate Search).
  * 
  * @author Sanne Grinovero <sanne@hibernate.org> (C) 2012 Red Hat Inc.
  */
 public class SessionDelegatorBaseImpl implements SessionImplementor, Session {
 
 	protected final SessionImplementor sessionImplementor;
 	protected final Session session;
 
 	public SessionDelegatorBaseImpl(SessionImplementor sessionImplementor, Session session) {
 		if ( sessionImplementor == null ) {
 			throw new IllegalArgumentException( "Unable to create a SessionDelegatorBaseImpl from a null sessionImplementor object" );
 		}
 		if ( session == null ) {
 			throw new IllegalArgumentException( "Unable to create a SessionDelegatorBaseImpl from a null session object" );
 		}
 		this.sessionImplementor = sessionImplementor;
 		this.session = session;
 	}
 
 	// Delegates to SessionImplementor
 
 	@Override
 	public <T> T execute(Callback<T> callback) {
 		return sessionImplementor.execute( callback );
 	}
 
 	@Override
 	public String getTenantIdentifier() {
 		return sessionImplementor.getTenantIdentifier();
 	}
 
 	@Override
 	public JdbcConnectionAccess getJdbcConnectionAccess() {
 		return sessionImplementor.getJdbcConnectionAccess();
 	}
 
 	@Override
 	public EntityKey generateEntityKey(Serializable id, EntityPersister persister) {
 		return sessionImplementor.generateEntityKey( id, persister );
 	}
 
 	@Override
 	public CacheKey generateCacheKey(Serializable id, Type type, String entityOrRoleName) {
 		return sessionImplementor.generateCacheKey( id, type, entityOrRoleName );
 	}
 
 	@Override
 	public Interceptor getInterceptor() {
 		return sessionImplementor.getInterceptor();
 	}
 
 	@Override
 	public void setAutoClear(boolean enabled) {
 		sessionImplementor.setAutoClear( enabled );
 	}
 
 	@Override
 	public void disableTransactionAutoJoin() {
 		sessionImplementor.disableTransactionAutoJoin();
 	}
 
 	@Override
 	public boolean isTransactionInProgress() {
 		return sessionImplementor.isTransactionInProgress();
 	}
 
 	@Override
 	public void initializeCollection(PersistentCollection collection, boolean writing) throws HibernateException {
 		sessionImplementor.initializeCollection( collection, writing );
 	}
 
 	@Override
 	public Object internalLoad(String entityName, Serializable id, boolean eager, boolean nullable) throws HibernateException {
 		return sessionImplementor.internalLoad( entityName, id, eager, nullable );
 	}
 
 	@Override
 	public Object immediateLoad(String entityName, Serializable id) throws HibernateException {
 		return sessionImplementor.immediateLoad( entityName, id );
 	}
 
 	@Override
 	public long getTimestamp() {
 		return sessionImplementor.getTimestamp();
 	}
 
 	@Override
 	public SessionFactoryImplementor getFactory() {
 		return sessionImplementor.getFactory();
 	}
 
 	@Override
 	public List list(String query, QueryParameters queryParameters) throws HibernateException {
 		return sessionImplementor.list( query, queryParameters );
 	}
 
 	@Override
 	public Iterator iterate(String query, QueryParameters queryParameters) throws HibernateException {
 		return sessionImplementor.iterate( query, queryParameters );
 	}
 
 	@Override
 	public ScrollableResults scroll(String query, QueryParameters queryParameters) throws HibernateException {
 		return sessionImplementor.scroll( query, queryParameters );
 	}
 
 	@Override
 	public ScrollableResults scroll(Criteria criteria, ScrollMode scrollMode) {
 		return sessionImplementor.scroll( criteria, scrollMode );
 	}
 
 	@Override
 	public List list(Criteria criteria) {
 		return sessionImplementor.list( criteria );
 	}
 
 	@Override
 	public List listFilter(Object collection, String filter, QueryParameters queryParameters) throws HibernateException {
 		return sessionImplementor.listFilter( collection, filter, queryParameters );
 	}
 
 	@Override
 	public Iterator iterateFilter(Object collection, String filter, QueryParameters queryParameters) throws HibernateException {
 		return sessionImplementor.iterateFilter( collection, filter, queryParameters );
 	}
 
 	@Override
 	public EntityPersister getEntityPersister(String entityName, Object object) throws HibernateException {
 		return sessionImplementor.getEntityPersister( entityName, object );
 	}
 
 	@Override
 	public Object getEntityUsingInterceptor(EntityKey key) throws HibernateException {
 		return sessionImplementor.getEntityUsingInterceptor( key );
 	}
 
 	@Override
 	public Serializable getContextEntityIdentifier(Object object) {
 		return sessionImplementor.getContextEntityIdentifier( object );
 	}
 
 	@Override
 	public String bestGuessEntityName(Object object) {
 		return sessionImplementor.bestGuessEntityName( object );
 	}
 
 	@Override
 	public String guessEntityName(Object entity) throws HibernateException {
 		return sessionImplementor.guessEntityName( entity );
 	}
 
 	@Override
 	public Object instantiate(String entityName, Serializable id) throws HibernateException {
 		return sessionImplementor.instantiate( entityName, id );
 	}
 
 	@Override
 	public List listCustomQuery(CustomQuery customQuery, QueryParameters queryParameters) throws HibernateException {
 		return sessionImplementor.listCustomQuery( customQuery, queryParameters );
 	}
 
 	@Override
 	public ScrollableResults scrollCustomQuery(CustomQuery customQuery, QueryParameters queryParameters) throws HibernateException {
 		return sessionImplementor.scrollCustomQuery( customQuery, queryParameters );
 	}
 
 	@Override
 	public List list(NativeSQLQuerySpecification spec, QueryParameters queryParameters) throws HibernateException {
 		return sessionImplementor.list( spec, queryParameters );
 	}
 
 	@Override
 	public ScrollableResults scroll(NativeSQLQuerySpecification spec, QueryParameters queryParameters) throws HibernateException {
 		return sessionImplementor.scroll( spec, queryParameters );
 	}
 
 	@Override
 	public Object getFilterParameterValue(String filterParameterName) {
 		return sessionImplementor.getFilterParameterValue( filterParameterName );
 	}
 
 	@Override
 	public Type getFilterParameterType(String filterParameterName) {
 		return sessionImplementor.getFilterParameterType( filterParameterName );
 	}
 
 	@Override
 	public Map getEnabledFilters() {
 		return sessionImplementor.getEnabledFilters();
 	}
 
 	@Override
 	public int getDontFlushFromFind() {
 		return sessionImplementor.getDontFlushFromFind();
 	}
 
 	@Override
 	public PersistenceContext getPersistenceContext() {
 		return sessionImplementor.getPersistenceContext();
 	}
 
 	@Override
 	public int executeUpdate(String query, QueryParameters queryParameters) throws HibernateException {
 		return sessionImplementor.executeUpdate( query, queryParameters );
 	}
 
 	@Override
 	public int executeNativeUpdate(NativeSQLQuerySpecification specification, QueryParameters queryParameters) throws HibernateException {
 		return sessionImplementor.executeNativeUpdate( specification, queryParameters );
 	}
 
 	@Override
 	public CacheMode getCacheMode() {
 		return sessionImplementor.getCacheMode();
 	}
 
 	@Override
 	public void setCacheMode(CacheMode cm) {
 		sessionImplementor.setCacheMode( cm );
 	}
 
 	@Override
 	public boolean isOpen() {
 		return sessionImplementor.isOpen();
 	}
 
 	@Override
 	public boolean isConnected() {
 		return sessionImplementor.isConnected();
 	}
 
 	@Override
 	public FlushMode getFlushMode() {
 		return sessionImplementor.getFlushMode();
 	}
 
 	@Override
 	public void setFlushMode(FlushMode fm) {
 		sessionImplementor.setFlushMode( fm );
 	}
 
 	@Override
 	public Connection connection() {
 		return sessionImplementor.connection();
 	}
 
 	@Override
 	public void flush() {
 		sessionImplementor.flush();
 	}
 
 	@Override
 	public Query getNamedQuery(String name) {
 		return sessionImplementor.getNamedQuery( name );
 	}
 
 	@Override
 	public Query getNamedSQLQuery(String name) {
 		return sessionImplementor.getNamedSQLQuery( name );
 	}
 
 	@Override
 	public boolean isEventSource() {
 		return sessionImplementor.isEventSource();
 	}
 
 	@Override
 	public void afterScrollOperation() {
 		sessionImplementor.afterScrollOperation();
 	}
 
 	@Override
 	public String getFetchProfile() {
 		return sessionImplementor.getFetchProfile();
 	}
 
 	@Override
 	public void setFetchProfile(String name) {
 		sessionImplementor.setFetchProfile( name );
 	}
 
 	@Override
 	public TransactionCoordinator getTransactionCoordinator() {
 		return sessionImplementor.getTransactionCoordinator();
 	}
 
 	@Override
+	public JdbcCoordinator getJdbcCoordinator() {
+		return sessionImplementor.getJdbcCoordinator();
+	}
+
+	@Override
 	public boolean isClosed() {
 		return sessionImplementor.isClosed();
 	}
 
 	@Override
+	public boolean shouldAutoClose() {
+		return sessionImplementor.shouldAutoClose();
+	}
+
+	@Override
+	public boolean isAutoCloseSessionEnabled() {
+		return sessionImplementor.isAutoCloseSessionEnabled();
+	}
+
+	@Override
 	public LoadQueryInfluencers getLoadQueryInfluencers() {
 		return sessionImplementor.getLoadQueryInfluencers();
 	}
 
 	@Override
 	public Query createQuery(NamedQueryDefinition namedQueryDefinition) {
 		return sessionImplementor.createQuery( namedQueryDefinition );
 	}
 
 	@Override
 	public SQLQuery createSQLQuery(NamedSQLQueryDefinition namedQueryDefinition) {
 		return sessionImplementor.createSQLQuery( namedQueryDefinition );
 	}
 
 	@Override
 	public SessionEventListenerManager getEventListenerManager() {
 		return sessionImplementor.getEventListenerManager();
 	}
 
 	// Delegates to Session
 
 	@Override
 	public Transaction beginTransaction() {
 		return session.beginTransaction();
 	}
 
 	@Override
 	public Transaction getTransaction() {
 		return session.getTransaction();
 	}
 
 	@Override
 	public Query createQuery(String queryString) {
 		return session.createQuery( queryString );
 	}
 
 	@Override
 	public SQLQuery createSQLQuery(String queryString) {
 		return session.createSQLQuery( queryString );
 	}
 
 	@Override
 	public ProcedureCall getNamedProcedureCall(String name) {
 		return session.getNamedProcedureCall( name );
 	}
 
 	@Override
 	public ProcedureCall createStoredProcedureCall(String procedureName) {
 		return session.createStoredProcedureCall( procedureName );
 	}
 
 	@Override
 	public ProcedureCall createStoredProcedureCall(String procedureName, Class... resultClasses) {
 		return session.createStoredProcedureCall( procedureName, resultClasses );
 	}
 
 	@Override
 	public ProcedureCall createStoredProcedureCall(String procedureName, String... resultSetMappings) {
 		return session.createStoredProcedureCall( procedureName, resultSetMappings );
 	}
 
 	@Override
 	public Criteria createCriteria(Class persistentClass) {
 		return session.createCriteria( persistentClass );
 	}
 
 	@Override
 	public Criteria createCriteria(Class persistentClass, String alias) {
 		return session.createCriteria( persistentClass, alias );
 	}
 
 	@Override
 	public Criteria createCriteria(String entityName) {
 		return session.createCriteria( entityName );
 	}
 
 	@Override
 	public Criteria createCriteria(String entityName, String alias) {
 		return session.createCriteria( entityName, alias );
 	}
 
 	@Override
 	public SharedSessionBuilder sessionWithOptions() {
 		return session.sessionWithOptions();
 	}
 
 	@Override
 	public SessionFactory getSessionFactory() {
 		return session.getSessionFactory();
 	}
 
 	@Override
 	public Connection close() throws HibernateException {
 		return session.close();
 	}
 
 	@Override
 	public void cancelQuery() throws HibernateException {
 		session.cancelQuery();
 	}
 
 	@Override
 	public boolean isDirty() throws HibernateException {
 		return session.isDirty();
 	}
 
 	@Override
 	public boolean isDefaultReadOnly() {
 		return session.isDefaultReadOnly();
 	}
 
 	@Override
 	public void setDefaultReadOnly(boolean readOnly) {
 		session.setDefaultReadOnly( readOnly );
 	}
 
 	@Override
 	public Serializable getIdentifier(Object object) {
 		return session.getIdentifier( object );
 	}
 
 	@Override
 	public boolean contains(Object object) {
 		return session.contains( object );
 	}
 
 	@Override
 	public void evict(Object object) {
 		session.evict( object );
 	}
 
 	@Override
 	public Object load(Class theClass, Serializable id, LockMode lockMode) {
 		return session.load( theClass, id, lockMode );
 	}
 
 	@Override
 	public Object load(Class theClass, Serializable id, LockOptions lockOptions) {
 		return session.load( theClass, id, lockOptions );
 	}
 
 	@Override
 	public Object load(String entityName, Serializable id, LockMode lockMode) {
 		return session.load( entityName, id, lockMode );
 	}
 
 	@Override
 	public Object load(String entityName, Serializable id, LockOptions lockOptions) {
 		return session.load( entityName, id, lockOptions );
 	}
 
 	@Override
 	public Object load(Class theClass, Serializable id) {
 		return session.load( theClass, id );
 	}
 
 	@Override
 	public Object load(String entityName, Serializable id) {
 		return session.load( entityName, id );
 	}
 
 	@Override
 	public void load(Object object, Serializable id) {
 		session.load( object, id );
 	}
 
 	@Override
 	public void replicate(Object object, ReplicationMode replicationMode) {
 		session.replicate( object, replicationMode );
 	}
 
 	@Override
 	public void replicate(String entityName, Object object, ReplicationMode replicationMode) {
 		session.replicate( entityName, object, replicationMode );
 	}
 
 	@Override
 	public Serializable save(Object object) {
 		return session.save( object );
 	}
 
 	@Override
 	public Serializable save(String entityName, Object object) {
 		return session.save( entityName, object );
 	}
 
 	@Override
 	public void saveOrUpdate(Object object) {
 		session.saveOrUpdate( object );
 	}
 
 	@Override
 	public void saveOrUpdate(String entityName, Object object) {
 		session.saveOrUpdate( entityName, object );
 	}
 
 	@Override
 	public void update(Object object) {
 		session.update( object );
 	}
 
 	@Override
 	public void update(String entityName, Object object) {
 		session.update( entityName, object );
 	}
 
 	@Override
 	public Object merge(Object object) {
 		return session.merge( object );
 	}
 
 	@Override
 	public Object merge(String entityName, Object object) {
 		return session.merge( entityName, object );
 	}
 
 	@Override
 	public void persist(Object object) {
 		session.persist( object );
 	}
 
 	@Override
 	public void persist(String entityName, Object object) {
 		session.persist( entityName, object );
 	}
 
 	@Override
 	public void delete(Object object) {
 		session.delete( object );
 	}
 
 	@Override
 	public void delete(String entityName, Object object) {
 		session.delete( entityName, object );
 	}
 
 	@Override
 	public void lock(Object object, LockMode lockMode) {
 		session.lock( object, lockMode );
 	}
 
 	@Override
 	public void lock(String entityName, Object object, LockMode lockMode) {
 		session.lock( entityName, object, lockMode );
 	}
 
 	@Override
 	public LockRequest buildLockRequest(LockOptions lockOptions) {
 		return session.buildLockRequest( lockOptions );
 	}
 
 	@Override
 	public void refresh(Object object) {
 		session.refresh( object );
 	}
 
 	@Override
 	public void refresh(String entityName, Object object) {
 		session.refresh( entityName, object );
 	}
 
 	@Override
 	public void refresh(Object object, LockMode lockMode) {
 		session.refresh( object, lockMode );
 	}
 
 	@Override
 	public void refresh(Object object, LockOptions lockOptions) {
 		session.refresh( object, lockOptions );
 	}
 
 	@Override
 	public void refresh(String entityName, Object object, LockOptions lockOptions) {
 		session.refresh( entityName, object, lockOptions );
 	}
 
 	@Override
 	public LockMode getCurrentLockMode(Object object) {
 		return session.getCurrentLockMode( object );
 	}
 
 	@Override
 	public Query createFilter(Object collection, String queryString) {
 		return session.createFilter( collection, queryString );
 	}
 
 	@Override
 	public void clear() {
 		session.clear();
 	}
 
 	@Override
 	public Object get(Class clazz, Serializable id) {
 		return session.get( clazz, id );
 	}
 
 	@Override
 	public Object get(Class clazz, Serializable id, LockMode lockMode) {
 		return session.get( clazz, id, lockMode );
 	}
 
 	@Override
 	public Object get(Class clazz, Serializable id, LockOptions lockOptions) {
 		return session.get( clazz, id, lockOptions );
 	}
 
 	@Override
 	public Object get(String entityName, Serializable id) {
 		return session.get( entityName, id );
 	}
 
 	@Override
 	public Object get(String entityName, Serializable id, LockMode lockMode) {
 		return session.get( entityName, id, lockMode );
 	}
 
 	@Override
 	public Object get(String entityName, Serializable id, LockOptions lockOptions) {
 		return session.get( entityName, id, lockOptions );
 	}
 
 	@Override
 	public String getEntityName(Object object) {
 		return session.getEntityName( object );
 	}
 
 	@Override
 	public IdentifierLoadAccess byId(String entityName) {
 		return session.byId( entityName );
 	}
 
 	@Override
 	public IdentifierLoadAccess byId(Class entityClass) {
 		return session.byId( entityClass );
 	}
 
 	@Override
 	public NaturalIdLoadAccess byNaturalId(String entityName) {
 		return session.byNaturalId( entityName );
 	}
 
 	@Override
 	public NaturalIdLoadAccess byNaturalId(Class entityClass) {
 		return session.byNaturalId( entityClass );
 	}
 
 	@Override
 	public SimpleNaturalIdLoadAccess bySimpleNaturalId(String entityName) {
 		return session.bySimpleNaturalId( entityName );
 	}
 
 	@Override
 	public SimpleNaturalIdLoadAccess bySimpleNaturalId(Class entityClass) {
 		return session.bySimpleNaturalId( entityClass );
 	}
 
 	@Override
 	public Filter enableFilter(String filterName) {
 		return session.enableFilter( filterName );
 	}
 
 	@Override
 	public Filter getEnabledFilter(String filterName) {
 		return session.getEnabledFilter( filterName );
 	}
 
 	@Override
 	public void disableFilter(String filterName) {
 		session.disableFilter( filterName );
 	}
 
 	@Override
 	public SessionStatistics getStatistics() {
 		return session.getStatistics();
 	}
 
 	@Override
 	public boolean isReadOnly(Object entityOrProxy) {
 		return session.isReadOnly( entityOrProxy );
 	}
 
 	@Override
 	public void setReadOnly(Object entityOrProxy, boolean readOnly) {
 		session.setReadOnly( entityOrProxy, readOnly );
 	}
 
 	@Override
 	public void doWork(Work work) throws HibernateException {
 		session.doWork( work );
 	}
 
 	@Override
 	public <T> T doReturningWork(ReturningWork<T> work) throws HibernateException {
 		return session.doReturningWork( work );
 	}
 
 	@Override
 	public Connection disconnect() {
 		return session.disconnect();
 	}
 
 	@Override
 	public void reconnect(Connection connection) {
 		session.reconnect( connection );
 	}
 
 	@Override
 	public boolean isFetchProfileEnabled(String name) throws UnknownProfileException {
 		return session.isFetchProfileEnabled( name );
 	}
 
 	@Override
 	public void enableFetchProfile(String name) throws UnknownProfileException {
 		session.enableFetchProfile( name );
 	}
 
 	@Override
 	public void disableFetchProfile(String name) throws UnknownProfileException {
 		session.disableFetchProfile( name );
 	}
 
 	@Override
 	public TypeHelper getTypeHelper() {
 		return session.getTypeHelper();
 	}
 
 	@Override
 	public LobHelper getLobHelper() {
 		return session.getLobHelper();
 	}
 
 	@Override
 	public void addEventListeners(SessionEventListener... listeners) {
 		session.addEventListeners( listeners );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionImplementor.java b/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionImplementor.java
index bec2bb6a28..cc44f51a19 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionImplementor.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/spi/SessionImplementor.java
@@ -1,424 +1,432 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.spi;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.CacheMode;
 import org.hibernate.Criteria;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.Query;
 import org.hibernate.SQLQuery;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
+import org.hibernate.Transaction;
 import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.jdbc.LobCreationContext;
 import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
+import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.engine.query.spi.sql.NativeSQLQuerySpecification;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.loader.custom.CustomQuery;
 import org.hibernate.persister.entity.EntityPersister;
+import org.hibernate.resource.transaction.TransactionCoordinator;
 import org.hibernate.type.Type;
 
 /**
  * Defines the internal contract between {@link org.hibernate.Session} / {@link org.hibernate.StatelessSession} and
  * other parts of Hibernate such as {@link Type}, {@link EntityPersister} and
  * {@link org.hibernate.persister.collection.CollectionPersister} implementors
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public interface SessionImplementor extends Serializable, LobCreationContext {
 	/**
 	 * Match te method on {@link org.hibernate.Session} and {@link org.hibernate.StatelessSession}
 	 *
 	 * @return The tenant identifier of this session
 	 */
 	public String getTenantIdentifier();
 
 	/**
 	 * Provides access to JDBC connections
 	 *
 	 * @return The contract for accessing JDBC connections.
 	 */
 	public JdbcConnectionAccess getJdbcConnectionAccess();
 
 	/**
 	 * Hide the changing requirements of entity key creation
 	 *
 	 * @param id The entity id
 	 * @param persister The entity persister
 	 *
 	 * @return The entity key
 	 */
 	public EntityKey generateEntityKey(Serializable id, EntityPersister persister);
 
 	/**
 	 * Hide the changing requirements of cache key creation.
 	 *
 	 * @param id The entity identifier or collection key.
 	 * @param type The type
 	 * @param entityOrRoleName The entity name or collection role.
 	 *
 	 * @return The cache key
 	 */
 	public CacheKey generateCacheKey(Serializable id, final Type type, final String entityOrRoleName);
 
 	/**
 	 * Retrieves the interceptor currently in use by this event source.
 	 *
 	 * @return The interceptor.
 	 */
 	public Interceptor getInterceptor();
 
 	/**
 	 * Enable/disable automatic cache clearing from after transaction
 	 * completion (for EJB3)
 	 */
 	public void setAutoClear(boolean enabled);
 
 	/**
 	 * Disable automatic transaction joining.  The really only has any effect for CMT transactions.  The default
 	 * Hibernate behavior is to auto join any active JTA transaction (register {@link javax.transaction.Synchronization}).
 	 * JPA however defines an explicit join transaction operation.
 	 * <p/>
 	 * See javax.persistence.EntityManager#joinTransaction
 	 */
 	public void disableTransactionAutoJoin();
 
 	/**
 	 * Does this <tt>Session</tt> have an active Hibernate transaction
 	 * or is there a JTA transaction in progress?
 	 */
 	public boolean isTransactionInProgress();
 
 	/**
 	 * Initialize the collection (if not already initialized)
 	 */
 	public void initializeCollection(PersistentCollection collection, boolean writing)
 			throws HibernateException;
 
 	/**
 	 * Load an instance without checking if it was deleted.
 	 * <p/>
 	 * When <tt>nullable</tt> is disabled this method may create a new proxy or
 	 * return an existing proxy; if it does not exist, throw an exception.
 	 * <p/>
 	 * When <tt>nullable</tt> is enabled, the method does not create new proxies
 	 * (but might return an existing proxy); if it does not exist, return
 	 * <tt>null</tt>.
 	 * <p/>
 	 * When <tt>eager</tt> is enabled, the object is eagerly fetched
 	 */
 	public Object internalLoad(String entityName, Serializable id, boolean eager, boolean nullable)
 			throws HibernateException;
 
 	/**
 	 * Load an instance immediately. This method is only called when lazily initializing a proxy.
 	 * Do not return the proxy.
 	 */
 	public Object immediateLoad(String entityName, Serializable id) throws HibernateException;
 
 	/**
 	 * System time before the start of the transaction
 	 */
 	public long getTimestamp();
 
 	/**
 	 * Get the creating <tt>SessionFactoryImplementor</tt>
 	 */
 	public SessionFactoryImplementor getFactory();
 
 	/**
 	 * Execute a <tt>find()</tt> query
 	 */
 	public List list(String query, QueryParameters queryParameters) throws HibernateException;
 
 	/**
 	 * Execute an <tt>iterate()</tt> query
 	 */
 	public Iterator iterate(String query, QueryParameters queryParameters) throws HibernateException;
 
 	/**
 	 * Execute a <tt>scroll()</tt> query
 	 */
 	public ScrollableResults scroll(String query, QueryParameters queryParameters) throws HibernateException;
 
 	/**
 	 * Execute a criteria query
 	 */
 	public ScrollableResults scroll(Criteria criteria, ScrollMode scrollMode);
 
 	/**
 	 * Execute a criteria query
 	 */
 	public List list(Criteria criteria);
 
 	/**
 	 * Execute a filter
 	 */
 	public List listFilter(Object collection, String filter, QueryParameters queryParameters) throws HibernateException;
 
 	/**
 	 * Iterate a filter
 	 */
 	public Iterator iterateFilter(Object collection, String filter, QueryParameters queryParameters)
 			throws HibernateException;
 
 	/**
 	 * Get the <tt>EntityPersister</tt> for any instance
 	 *
 	 * @param entityName optional entity name
 	 * @param object the entity instance
 	 */
 	public EntityPersister getEntityPersister(String entityName, Object object) throws HibernateException;
 
 	/**
 	 * Get the entity instance associated with the given <tt>Key</tt>,
 	 * calling the Interceptor if necessary
 	 */
 	public Object getEntityUsingInterceptor(EntityKey key) throws HibernateException;
 
 	/**
 	 * Return the identifier of the persistent object, or null if
 	 * not associated with the session
 	 */
 	public Serializable getContextEntityIdentifier(Object object);
 
 	/**
 	 * The best guess entity name for an entity not in an association
 	 */
 	public String bestGuessEntityName(Object object);
 
 	/**
 	 * The guessed entity name for an entity not in an association
 	 */
 	public String guessEntityName(Object entity) throws HibernateException;
 
 	/**
 	 * Instantiate the entity class, initializing with the given identifier
 	 */
 	public Object instantiate(String entityName, Serializable id) throws HibernateException;
 
 	/**
 	 * Execute an SQL Query
 	 */
 	public List listCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
 			throws HibernateException;
 
 	/**
 	 * Execute an SQL Query
 	 */
 	public ScrollableResults scrollCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
 			throws HibernateException;
 
 	/**
 	 * Execute a native SQL query, and return the results as a fully built list.
 	 *
 	 * @param spec The specification of the native SQL query to execute.
 	 * @param queryParameters The parameters by which to perform the execution.
 	 *
 	 * @return The result list.
 	 *
 	 * @throws HibernateException
 	 */
 	public List list(NativeSQLQuerySpecification spec, QueryParameters queryParameters)
 			throws HibernateException;
 
 	/**
 	 * Execute a native SQL query, and return the results as a scrollable result.
 	 *
 	 * @param spec The specification of the native SQL query to execute.
 	 * @param queryParameters The parameters by which to perform the execution.
 	 *
 	 * @return The resulting scrollable result.
 	 *
 	 * @throws HibernateException
 	 */
 	public ScrollableResults scroll(NativeSQLQuerySpecification spec, QueryParameters queryParameters)
 			throws HibernateException;
 
 	/**
 	 * Retreive the currently set value for a filter parameter.
 	 *
 	 * @param filterParameterName The filter parameter name in the format
 	 * {FILTER_NAME.PARAMETER_NAME}.
 	 *
 	 * @return The filter parameter value.
 	 *
 	 * @deprecated use #getLoadQueryInfluencers instead
 	 */
 	@Deprecated
 	public Object getFilterParameterValue(String filterParameterName);
 
 	/**
 	 * Retrieve the type for a given filter parameter.
 	 *
 	 * @param filterParameterName The filter parameter name in the format
 	 * {FILTER_NAME.PARAMETER_NAME}.
 	 *
 	 * @return The filter param type
 	 *
 	 * @deprecated use #getLoadQueryInfluencers instead
 	 */
 	@Deprecated
 	public Type getFilterParameterType(String filterParameterName);
 
 	/**
 	 * Return the currently enabled filters.  The filter map is keyed by filter
 	 * name, with values corresponding to the {@link org.hibernate.internal.FilterImpl}
 	 * instance.
 	 *
 	 * @return The currently enabled filters.
 	 *
 	 * @deprecated use #getLoadQueryInfluencers instead
 	 */
 	@Deprecated
 	public Map getEnabledFilters();
 
 	public int getDontFlushFromFind();
 
 	//TODO: temporary
 
 	/**
 	 * Get the persistence context for this session
 	 */
 	public PersistenceContext getPersistenceContext();
 
 	/**
 	 * Execute a HQL update or delete query
 	 */
 	int executeUpdate(String query, QueryParameters queryParameters) throws HibernateException;
 
 	/**
 	 * Execute a native SQL update or delete query
 	 */
 	int executeNativeUpdate(NativeSQLQuerySpecification specification, QueryParameters queryParameters)
 			throws HibernateException;
 
 
 	// copied from Session:
 
 	public CacheMode getCacheMode();
 
 	public void setCacheMode(CacheMode cm);
 
 	public boolean isOpen();
 
 	public boolean isConnected();
 
 	public FlushMode getFlushMode();
 
 	public void setFlushMode(FlushMode fm);
 
 	public Connection connection();
 
 	public void flush();
 
 	/**
 	 * Get a Query instance for a named query or named native SQL query
 	 */
 	public Query getNamedQuery(String name);
 
 	/**
 	 * Get a Query instance for a named native SQL query
 	 */
 	public Query getNamedSQLQuery(String name);
 
 	public boolean isEventSource();
 
 	public void afterScrollOperation();
 
 	/**
 	 * Get the <i>internal</i> fetch profile currently associated with this session.
 	 *
 	 * @return The current internal fetch profile, or null if none currently associated.
 	 *
 	 * @deprecated use #getLoadQueryInfluencers instead
 	 */
 	@Deprecated
 	public String getFetchProfile();
 
 	/**
 	 * Set the current <i>internal</i> fetch profile for this session.
 	 *
 	 * @param name The internal fetch profile name to use
 	 *
 	 * @deprecated use {@link #getLoadQueryInfluencers} instead
 	 */
 	@Deprecated
 	public void setFetchProfile(String name);
 
 	/**
 	 * Retrieve access to the session's transaction coordinator.
 	 *
 	 * @return The transaction coordinator.
 	 */
 	public TransactionCoordinator getTransactionCoordinator();
 
+	public JdbcCoordinator getJdbcCoordinator();
+
 	/**
 	 * Determine whether the session is closed.  Provided separately from
 	 * {@link #isOpen()} as this method does not attempt any JTA synchronization
 	 * registration, where as {@link #isOpen()} does; which makes this one
 	 * nicer to use for most internal purposes.
 	 *
 	 * @return True if the session is closed; false otherwise.
 	 */
 	public boolean isClosed();
 
+	public boolean shouldAutoClose();
+
+	public boolean isAutoCloseSessionEnabled();
+
 	/**
 	 * Get the load query influencers associated with this session.
 	 *
 	 * @return the load query influencers associated with this session;
 	 *         should never be null.
 	 */
 	public LoadQueryInfluencers getLoadQueryInfluencers();
 
 	/**
 	 * Used from EntityManager
 	 *
 	 * @param namedQueryDefinition The named query definition
 	 *
 	 * @return The basic HQL/JPQL query (without saved settings applied)
 	 */
 	Query createQuery(NamedQueryDefinition namedQueryDefinition);
 
 	/**
 	 * Used from EntityManager
 	 *
 	 * @param namedQueryDefinition The named query definition
 	 *
 	 * @return The basic SQL query (without saved settings applied)
 	 */
 	SQLQuery createSQLQuery(NamedSQLQueryDefinition namedQueryDefinition);
 
 	public SessionEventListenerManager getEventListenerManager();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/TransactionCoordinatorImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/TransactionCoordinatorImpl.java
deleted file mode 100644
index 36ad40d165..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/TransactionCoordinatorImpl.java
+++ /dev/null
@@ -1,398 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.engine.transaction.internal;
-
-import java.io.IOException;
-import java.io.ObjectInputStream;
-import java.io.ObjectOutputStream;
-import java.sql.Connection;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.hibernate.ConnectionReleaseMode;
-import org.hibernate.ResourceClosedException;
-import org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl;
-import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
-import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
-import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
-import org.hibernate.engine.transaction.spi.JoinStatus;
-import org.hibernate.engine.transaction.spi.SynchronizationRegistry;
-import org.hibernate.engine.transaction.spi.TransactionContext;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
-import org.hibernate.engine.transaction.spi.TransactionEnvironment;
-import org.hibernate.engine.transaction.spi.TransactionFactory;
-import org.hibernate.engine.transaction.spi.TransactionImplementor;
-import org.hibernate.engine.transaction.spi.TransactionObserver;
-import org.hibernate.engine.transaction.synchronization.internal.RegisteredSynchronization;
-import org.hibernate.engine.transaction.synchronization.internal.SynchronizationCallbackCoordinatorNonTrackingImpl;
-import org.hibernate.engine.transaction.synchronization.internal.SynchronizationCallbackCoordinatorTrackingImpl;
-import org.hibernate.engine.transaction.synchronization.spi.SynchronizationCallbackCoordinator;
-import org.hibernate.internal.CoreLogging;
-import org.hibernate.internal.CoreMessageLogger;
-import org.hibernate.internal.util.collections.CollectionHelper;
-
-/**
- * Standard implementation of the Hibernate {@link TransactionCoordinator}
- * <p/>
- * IMPL NOTE : Custom serialization handling!
- *
- * @author Steve Ebersole
- */
-public final class TransactionCoordinatorImpl implements TransactionCoordinator {
-	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( TransactionCoordinatorImpl.class );
-
-	private final transient TransactionContext transactionContext;
-	private final transient JdbcCoordinatorImpl jdbcCoordinator;
-	private final transient TransactionFactory transactionFactory;
-	private final transient TransactionEnvironment transactionEnvironment;
-
-	private final transient List<TransactionObserver> observers;
-	private final transient SynchronizationRegistryImpl synchronizationRegistry;
-
-	private transient TransactionImplementor currentHibernateTransaction;
-
-	private transient SynchronizationCallbackCoordinator callbackCoordinator;
-
-	private transient boolean open = true;
-	private transient boolean synchronizationRegistered;
-	private transient boolean ownershipTaken;
-	
-	private transient boolean isDebugging = LOG.isDebugEnabled();
-	private transient boolean isTracing = LOG.isTraceEnabled();
-
-	public TransactionCoordinatorImpl(
-			Connection userSuppliedConnection,
-			TransactionContext transactionContext) {
-		this.transactionContext = transactionContext;
-		this.jdbcCoordinator = new JdbcCoordinatorImpl( userSuppliedConnection, this );
-		this.transactionEnvironment = transactionContext.getTransactionEnvironment();
-		this.transactionFactory = this.transactionEnvironment.getTransactionFactory();
-		this.observers = new ArrayList<TransactionObserver>();
-		this.synchronizationRegistry = new SynchronizationRegistryImpl();
-		reset();
-
-		final boolean registerSynchronization = transactionContext.isAutoCloseSessionEnabled()
-				|| transactionContext.isFlushBeforeCompletionEnabled()
-				|| transactionContext.getConnectionReleaseMode() == ConnectionReleaseMode.AFTER_TRANSACTION;
-		if ( registerSynchronization ) {
-			pulse();
-		}
-	}
-
-	public TransactionCoordinatorImpl(
-			TransactionContext transactionContext,
-			JdbcCoordinatorImpl jdbcCoordinator,
-			List<TransactionObserver> observers) {
-		this.transactionContext = transactionContext;
-		this.jdbcCoordinator = jdbcCoordinator;
-		this.transactionEnvironment = transactionContext.getTransactionEnvironment();
-		this.transactionFactory = this.transactionEnvironment.getTransactionFactory();
-		this.observers = observers;
-		this.synchronizationRegistry = new SynchronizationRegistryImpl();
-		reset();
-	}
-
-	/**
-	 * Reset the internal state.
-	 */
-	public void reset() {
-		synchronizationRegistered = false;
-		ownershipTaken = false;
-
-		if ( currentHibernateTransaction != null ) {
-			currentHibernateTransaction.invalidate();
-		}
-		currentHibernateTransaction = transactionFactory().createTransaction( this );
-		if ( transactionContext.shouldAutoJoinTransaction() ) {
-			currentHibernateTransaction.markForJoin();
-			currentHibernateTransaction.join();
-		}
-
-		// IMPL NOTE : reset clears synchronizations (following jta spec), but not observers!
-		synchronizationRegistry.clearSynchronizations();
-	}
-
-	public void afterTransaction(TransactionImplementor hibernateTransaction, int status) {
-		if (isTracing) {
-			LOG.trace( "after transaction completion" );
-		}
-
-		final boolean success = JtaStatusHelper.isCommitted( status );
-
-		if ( sessionFactory().getStatistics().isStatisticsEnabled() ) {
-			transactionEnvironment.getStatisticsImplementor().endTransaction( success );
-		}
-
-		getJdbcCoordinator().afterTransaction();
-
-		getTransactionContext().afterTransactionCompletion( hibernateTransaction, success );
-		sendAfterTransactionCompletionNotifications( hibernateTransaction, status );
-		reset();
-	}
-
-	private SessionFactoryImplementor sessionFactory() {
-		return transactionEnvironment.getSessionFactory();
-	}
-
-	public boolean isSynchronizationRegistered() {
-		return synchronizationRegistered;
-	}
-
-	@Override
-	@SuppressWarnings({"unchecked"})
-	public boolean isTransactionInProgress() {
-		return open && getTransaction().isActive() && getTransaction().getJoinStatus() == JoinStatus.JOINED;
-	}
-
-	@Override
-	public TransactionContext getTransactionContext() {
-		return transactionContext;
-	}
-
-	@Override
-	public JdbcCoordinator getJdbcCoordinator() {
-		return jdbcCoordinator;
-	}
-
-	private TransactionFactory transactionFactory() {
-		return transactionFactory;
-	}
-
-	private TransactionEnvironment getTransactionEnvironment() {
-		return transactionEnvironment;
-	}
-
-	@Override
-	public TransactionImplementor getTransaction() {
-		if ( !open ) {
-			throw new ResourceClosedException( "This TransactionCoordinator has been closed" );
-		}
-		pulse();
-		return currentHibernateTransaction;
-	}
-
-	public void afterNonTransactionalQuery(boolean success) {
-		// check to see if the connection is in auto-commit mode (no connection means aggressive connection
-		// release outside a JTA transaction context, so MUST be autocommit mode)
-		boolean isAutocommit = getJdbcCoordinator().getLogicalConnection().isAutoCommit();
-		getJdbcCoordinator().afterTransaction();
-
-		if ( isAutocommit ) {
-			for ( TransactionObserver observer : observers ) {
-				observer.afterCompletion( success, this.getTransaction() );
-			}
-		}
-	}
-
-	@Override
-	public void resetJoinStatus() {
-		getTransaction().resetJoinStatus();
-	}
-
-	@SuppressWarnings({"unchecked"})
-	private void attemptToRegisterJtaSync() {
-		if ( synchronizationRegistered ) {
-			return;
-		}
-
-		final JtaPlatform jtaPlatform = getTransactionEnvironment().getJtaPlatform();
-		if ( jtaPlatform == null ) {
-			// if no jta platform was registered we wont be able to register a jta synchronization
-			return;
-		}
-
-		// Has the local transaction (Hibernate facade) taken on the responsibility of driving the transaction inflow?
-		if ( currentHibernateTransaction.isInitiator() ) {
-			return;
-		}
-
-		final JoinStatus joinStatus = currentHibernateTransaction.getJoinStatus();
-		if ( joinStatus != JoinStatus.JOINED ) {
-			// the transaction is not (yet) joined, see if we should join...
-			if ( !transactionContext.shouldAutoJoinTransaction() ) {
-				// we are supposed to not auto join transactions; if the transaction is not marked for join
-				// we cannot go any further in attempting to join (register sync).
-				if ( joinStatus != JoinStatus.MARKED_FOR_JOINED ) {
-					if (isDebugging) {
-						LOG.debug( "Skipping JTA sync registration due to auto join checking" );
-					}
-					return;
-				}
-			}
-		}
-
-		// IMPL NOTE : At this point the local callback is the "maybe" one.  The only time that needs to change is if
-		// we are able to successfully register the transaction synchronization in which case the local callback would become
-		// non driving.  To that end, the following checks are simply opt outs where we are unable to register the
-		// synchronization
-
-		// Can we resister a synchronization
-		if ( !jtaPlatform.canRegisterSynchronization() ) {
-			if (isTracing) {
-				LOG.trace( "registered JTA platform says we cannot currently register synchronization; skipping" );
-			}
-			return;
-		}
-
-		// Should we resister a synchronization
-		if ( !transactionFactory().isJoinableJtaTransaction( this, currentHibernateTransaction ) ) {
-			if (isTracing) {
-				LOG.trace( "TransactionFactory reported no JTA transaction to join; skipping Synchronization registration" );
-			}
-			return;
-		}
-
-		jtaPlatform.registerSynchronization( new RegisteredSynchronization( getSynchronizationCallbackCoordinator() ) );
-		getSynchronizationCallbackCoordinator().synchronizationRegistered();
-		synchronizationRegistered = true;
-		if (isDebugging) {
-			LOG.debug( "successfully registered Synchronization" );
-		}
-	}
-
-	@Override
-	public SynchronizationCallbackCoordinator getSynchronizationCallbackCoordinator() {
-		if ( callbackCoordinator == null ) {
-			callbackCoordinator = transactionEnvironment.getSessionFactory().getSettings().isJtaTrackByThread()
-					? new SynchronizationCallbackCoordinatorTrackingImpl( this )
-					: new SynchronizationCallbackCoordinatorNonTrackingImpl( this );
-		}
-		return callbackCoordinator;
-	}
-
-	public void pulse() {
-		if ( transactionFactory().compatibleWithJtaSynchronization() ) {
-			// the configured transaction strategy says it supports callbacks via JTA synchronization, so attempt to
-			// register JTA synchronization if possible
-			attemptToRegisterJtaSync();
-		}
-	}
-
-	public Connection close() {
-		open = false;
-		reset();
-		observers.clear();
-		return jdbcCoordinator.close();
-	}
-
-	public SynchronizationRegistry getSynchronizationRegistry() {
-		return synchronizationRegistry;
-	}
-
-	public void addObserver(TransactionObserver observer) {
-		observers.add( observer );
-	}
-
-	@Override
-	public void removeObserver(TransactionObserver observer) {
-		observers.remove( observer );
-	}
-
-	@Override
-	@SuppressWarnings({"unchecked"})
-	public boolean isTransactionJoinable() {
-		return transactionFactory().isJoinableJtaTransaction( this, currentHibernateTransaction );
-	}
-
-	@Override
-	@SuppressWarnings({"unchecked"})
-	public boolean isTransactionJoined() {
-		return currentHibernateTransaction != null && currentHibernateTransaction.getJoinStatus() == JoinStatus.JOINED;
-	}
-
-	public void setRollbackOnly() {
-		getTransaction().markRollbackOnly();
-	}
-
-	@Override
-	public boolean takeOwnership() {
-		if ( ownershipTaken ) {
-			return false;
-		}
-		else {
-			ownershipTaken = true;
-			return true;
-		}
-	}
-
-	@Override
-	public void sendAfterTransactionBeginNotifications(TransactionImplementor hibernateTransaction) {
-		for ( TransactionObserver observer : observers ) {
-			observer.afterBegin( currentHibernateTransaction );
-		}
-	}
-
-	@Override
-	public void sendBeforeTransactionCompletionNotifications(TransactionImplementor hibernateTransaction) {
-		synchronizationRegistry.notifySynchronizationsBeforeTransactionCompletion();
-		for ( TransactionObserver observer : observers ) {
-			observer.beforeCompletion( hibernateTransaction );
-		}
-	}
-
-	@Override
-	public void sendAfterTransactionCompletionNotifications(TransactionImplementor hibernateTransaction, int status) {
-		final boolean successful = JtaStatusHelper.isCommitted( status );
-		for ( TransactionObserver observer : new ArrayList<TransactionObserver>( observers ) ) {
-			observer.afterCompletion( successful, hibernateTransaction );
-		}
-		synchronizationRegistry.notifySynchronizationsAfterTransactionCompletion( status );
-	}
-
-	@Override
-	public boolean isActive() {
-		return !sessionFactory().isClosed();
-	}
-
-
-	// serialization ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-	public void serialize(ObjectOutputStream oos) throws IOException {
-		jdbcCoordinator.serialize( oos );
-		oos.writeInt( observers.size() );
-		for ( TransactionObserver observer : observers ) {
-			oos.writeObject( observer );
-		}
-	}
-
-	public static TransactionCoordinatorImpl deserialize(
-			ObjectInputStream ois,
-			TransactionContext transactionContext) throws ClassNotFoundException, IOException {
-		final JdbcCoordinatorImpl jdbcCoordinator = JdbcCoordinatorImpl.deserialize( ois, transactionContext );
-		final int observerCount = ois.readInt();
-		final List<TransactionObserver> observers = CollectionHelper.arrayList( observerCount );
-		for ( int i = 0; i < observerCount; i++ ) {
-			observers.add( (TransactionObserver) ois.readObject() );
-		}
-		final TransactionCoordinatorImpl transactionCoordinator = new TransactionCoordinatorImpl(
-				transactionContext,
-				jdbcCoordinator,
-				observers
-		);
-		jdbcCoordinator.afterDeserialize( transactionCoordinator );
-		return transactionCoordinator;
-	}
-
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/TransactionImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/TransactionImpl.java
new file mode 100644
index 0000000000..5480c98b44
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/TransactionImpl.java
@@ -0,0 +1,144 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) {DATE}, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.engine.transaction.internal;
+
+import javax.transaction.Synchronization;
+
+import org.jboss.logging.Logger;
+
+import org.hibernate.HibernateException;
+import org.hibernate.Transaction;
+import org.hibernate.TransactionException;
+import org.hibernate.internal.CoreLogging;
+import org.hibernate.resource.transaction.TransactionCoordinator;
+import org.hibernate.resource.transaction.spi.TransactionStatus;
+
+import static org.hibernate.resource.transaction.TransactionCoordinator.LocalInflow;
+
+/**
+ * @author Andrea Boriero
+ */
+public class TransactionImpl implements Transaction {
+	private static final Logger LOG = CoreLogging.logger( TransactionImpl.class );
+
+	private final TransactionCoordinator transactionCoordinator;
+	private final LocalInflow transactionDriverControl;
+
+	private boolean valid = true;
+
+	public TransactionImpl(TransactionCoordinator transactionCoordinator) {
+		this.transactionCoordinator = transactionCoordinator;
+		this.transactionDriverControl = transactionCoordinator.getTransactionDriverControl();
+	}
+
+	@Override
+	public void begin() {
+		TransactionStatus status = transactionDriverControl.getStatus();
+
+		if ( !valid ) {
+			throw new TransactionException( "Transaction instance is no longer valid" );
+		}
+		if ( status == TransactionStatus.ACTIVE ) {
+//			throw new TransactionException( "nested transactions not supported" );
+			return;
+		}
+
+		LOG.debug( "begin" );
+		this.transactionDriverControl.begin();
+	}
+
+	@Override
+	public void commit() {
+		TransactionStatus status = transactionDriverControl.getStatus();
+		if ( status != TransactionStatus.ACTIVE ) {
+			throw new TransactionException( "Transaction not successfully started" );
+		}
+
+		LOG.debug( "committing" );
+
+		try {
+			this.transactionDriverControl.commit();
+		}
+		catch (Exception e) {
+			throw new TransactionException( "commit failed", e );
+		}
+		finally {
+			invalidate();
+		}
+	}
+
+	@Override
+	public void rollback() {
+		TransactionStatus status = transactionDriverControl.getStatus();
+		if ( status != TransactionStatus.ACTIVE && status != TransactionStatus.FAILED_COMMIT ) {
+			throw new TransactionException( "Transaction not successfully started" );
+		}
+
+		LOG.debug( "rolling back" );
+		if ( status != TransactionStatus.FAILED_COMMIT || allowFailedCommitToPhysicallyRollback() ) {
+			try {
+				this.transactionDriverControl.rollback();
+			}
+			catch (Exception e) {
+				throw new TransactionException( "rollback failed", e );
+			}
+			finally {
+				invalidate();
+			}
+		}
+	}
+
+	@Override
+	public TransactionStatus getStatus() {
+		return transactionDriverControl.getStatus();
+	}
+
+	@Override
+	public void registerSynchronization(Synchronization synchronization) throws HibernateException {
+		this.transactionCoordinator.getLocalSynchronizations().registerSynchronization( synchronization );
+	}
+
+	@Override
+	public void setTimeout(int seconds) {
+		this.transactionCoordinator.setTimeOut( seconds );
+	}
+
+	@Override
+	public int getTimeout() {
+		return this.transactionCoordinator.getTimeOut();
+	}
+
+	@Override
+	public void markRollbackOnly() {
+		transactionDriverControl.markRollbackOnly();
+	}
+
+	public void invalidate() {
+		valid = false;
+	}
+
+	protected boolean allowFailedCommitToPhysicallyRollback() {
+		return false;
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jdbc/JdbcTransaction.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jdbc/JdbcTransaction.java
deleted file mode 100644
index 7ccf02e9a8..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jdbc/JdbcTransaction.java
+++ /dev/null
@@ -1,208 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.engine.transaction.internal.jdbc;
-
-import java.sql.Connection;
-import java.sql.SQLException;
-
-import org.hibernate.HibernateException;
-import org.hibernate.TransactionException;
-import org.hibernate.engine.transaction.spi.AbstractTransactionImpl;
-import org.hibernate.engine.transaction.spi.IsolationDelegate;
-import org.hibernate.engine.transaction.spi.JoinStatus;
-import org.hibernate.engine.transaction.spi.LocalStatus;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
-import org.hibernate.internal.CoreMessageLogger;
-
-import org.jboss.logging.Logger;
-
-/**
- * {@link org.hibernate.Transaction} implementation based on transaction management through a JDBC {@link java.sql.Connection}.
- * <p/>
- * This the default transaction strategy.
- *
- * @author Anton van Straaten
- * @author Gavin King
- * @author Steve Ebersole
- */
-public class JdbcTransaction extends AbstractTransactionImpl {
-
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, JdbcTransaction.class.getName() );
-
-	private Connection managedConnection;
-	private boolean wasInitiallyAutoCommit;
-	private boolean isDriver;
-
-	protected JdbcTransaction(TransactionCoordinator transactionCoordinator) {
-		super( transactionCoordinator );
-	}
-
-	@Override
-	protected void doBegin() {
-		try {
-			if ( managedConnection != null ) {
-				throw new TransactionException( "Already have an associated managed connection" );
-			}
-			managedConnection = transactionCoordinator().getJdbcCoordinator().getLogicalConnection().getConnection();
-			wasInitiallyAutoCommit = managedConnection.getAutoCommit();
-			LOG.debugv( "initial autocommit status: {0}", wasInitiallyAutoCommit );
-			if ( wasInitiallyAutoCommit ) {
-				LOG.debug( "disabling autocommit" );
-				managedConnection.setAutoCommit( false );
-			}
-		}
-		catch( SQLException e ) {
-			throw new TransactionException( "JDBC begin transaction failed: ", e );
-		}
-
-		isDriver = transactionCoordinator().takeOwnership();
-	}
-
-	@Override
-	protected void afterTransactionBegin() {
-		if ( getTimeout() > 0 ) {
-			transactionCoordinator().getJdbcCoordinator().setTransactionTimeOut( getTimeout() );
-		}
-		transactionCoordinator().sendAfterTransactionBeginNotifications( this );
-		if ( isDriver ) {
-			transactionCoordinator().getTransactionContext().afterTransactionBegin( this );
-		}
-	}
-
-	@Override
-	protected void beforeTransactionCommit() {
-		transactionCoordinator().sendBeforeTransactionCompletionNotifications( this );
-
-		// basically, if we are the driver of the transaction perform a managed flush prior to
-		// physically committing the transaction
-		if ( isDriver && !transactionCoordinator().getTransactionContext().isFlushModeNever() ) {
-			// if an exception occurs during flush, user must call rollback()
-			transactionCoordinator().getTransactionContext().managedFlush();
-		}
-
-		if ( isDriver ) {
-			transactionCoordinator().getTransactionContext().beforeTransactionCompletion( this );
-		}
-	}
-
-	@Override
-	protected void doCommit() throws TransactionException {
-		try {
-			managedConnection.commit();
-			LOG.debug( "committed JDBC Connection" );
-		}
-		catch( SQLException e ) {
-			throw new TransactionException( "unable to commit against JDBC connection", e );
-		}
-		finally {
-			releaseManagedConnection();
-		}
-	}
-
-	private void releaseManagedConnection() {
-		try {
-			if ( wasInitiallyAutoCommit ) {
-				LOG.debug( "re-enabling autocommit" );
-				managedConnection.setAutoCommit( true );
-			}
-			managedConnection = null;
-		}
-		catch ( Exception e ) {
-			LOG.debug( "Could not toggle autocommit", e );
-		}
-	}
-
-	@Override
-	protected void afterTransactionCompletion(int status) {
-		transactionCoordinator().afterTransaction( this, status );
-	}
-
-	@Override
-	protected void afterAfterCompletion() {
-		if ( isDriver
-				&& transactionCoordinator().getTransactionContext().shouldAutoClose()
-				&& !transactionCoordinator().getTransactionContext().isClosed() ) {
-			try {
-				transactionCoordinator().getTransactionContext().managedClose();
-			}
-			catch (HibernateException e) {
-				LOG.unableToCloseSessionButSwallowingError( e );
-			}
-		}
-	}
-
-	@Override
-	protected void beforeTransactionRollBack() {
-		// nothing to do here
-	}
-
-	@Override
-	protected void doRollback() throws TransactionException {
-		try {
-			managedConnection.rollback();
-			LOG.debug( "rolled JDBC Connection" );
-		}
-		catch( SQLException e ) {
-			throw new TransactionException( "unable to rollback against JDBC connection", e );
-		}
-		finally {
-			releaseManagedConnection();
-		}
-	}
-
-	@Override
-	public boolean isInitiator() {
-		return isActive();
-	}
-
-	@Override
-	public IsolationDelegate createIsolationDelegate() {
-		return new JdbcIsolationDelegate( transactionCoordinator() );
-	}
-
-	@Override
-	public JoinStatus getJoinStatus() {
-		return isActive() ? JoinStatus.JOINED : JoinStatus.NOT_JOINED;
-	}
-
-	@Override
-	public void markRollbackOnly() {
-		// nothing to do here
-	}
-
-	@Override
-	public void join() {
-		// nothing to do
-	}
-
-	@Override
-	public void resetJoinStatus() {
-		// nothing to do
-	}
-
-	@Override
-	public boolean isActive() throws HibernateException {
-		return getLocalStatus() == LocalStatus.ACTIVE;
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jdbc/JdbcTransactionFactory.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jdbc/JdbcTransactionFactory.java
deleted file mode 100644
index 163683db05..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jdbc/JdbcTransactionFactory.java
+++ /dev/null
@@ -1,63 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.engine.transaction.internal.jdbc;
-
-import org.hibernate.ConnectionReleaseMode;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
-import org.hibernate.engine.transaction.spi.TransactionFactory;
-
-/**
- * Factory for {@link org.hibernate.engine.transaction.internal.jdbc.JdbcTransaction} instances.
- *
- * @author Anton van Straaten
- * @author Steve Ebersole
- */
-public final class JdbcTransactionFactory implements TransactionFactory<JdbcTransaction> {
-	public static final String SHORT_NAME = "jdbc";
-
-	@Override
-	public JdbcTransaction createTransaction(TransactionCoordinator transactionCoordinator) {
-		return new JdbcTransaction( transactionCoordinator );
-	}
-
-	@Override
-	public boolean canBeDriver() {
-		return true;
-	}
-
-	@Override
-	public ConnectionReleaseMode getDefaultReleaseMode() {
-		return ConnectionReleaseMode.ON_CLOSE;
-	}
-
-	@Override
-	public boolean compatibleWithJtaSynchronization() {
-		return false;
-	}
-
-	@Override
-	public boolean isJoinableJtaTransaction(TransactionCoordinator transactionCoordinator, JdbcTransaction transaction) {
-		return false;
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/CMTTransaction.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/CMTTransaction.java
deleted file mode 100644
index a717567d86..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/CMTTransaction.java
+++ /dev/null
@@ -1,173 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.engine.transaction.internal.jta;
-
-import javax.transaction.SystemException;
-import javax.transaction.TransactionManager;
-
-import org.hibernate.TransactionException;
-import org.hibernate.engine.transaction.spi.AbstractTransactionImpl;
-import org.hibernate.engine.transaction.spi.IsolationDelegate;
-import org.hibernate.engine.transaction.spi.JoinStatus;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
-
-/**
- * Implements a transaction strategy for Container Managed Transaction (CMT) scenarios.  All work is done in
- * the context of the container managed transaction.
- * <p/>
- * The term 'CMT' is potentially misleading; the pertinent point simply being that the transactions are being
- * managed by something other than the Hibernate transaction mechanism.
- * <p/>
- * Additionally, this strategy does *not* attempt to access or use the {@link javax.transaction.UserTransaction} since
- * in the actual case CMT access to the {@link javax.transaction.UserTransaction} is explicitly disallowed.  Instead
- * we use the JTA {@link javax.transaction.Transaction} object obtained from the {@link TransactionManager}
- *
- * @author Gavin King
- * @author Steve Ebersole
- */
-public class CMTTransaction extends AbstractTransactionImpl {
-	private JoinStatus joinStatus = JoinStatus.NOT_JOINED;
-
-	protected CMTTransaction(TransactionCoordinator transactionCoordinator) {
-		super( transactionCoordinator );
-	}
-
-	protected TransactionManager transactionManager() {
-		return jtaPlatform().retrieveTransactionManager();
-	}
-
-	private TransactionManager getTransactionManager() {
-		return transactionManager();
-	}
-
-	@Override
-	protected void doBegin() {
-		transactionCoordinator().pulse();
-	}
-
-	@Override
-	protected void afterTransactionBegin() {
-		if ( ! transactionCoordinator().isSynchronizationRegistered() ) {
-			throw new TransactionException("Could not register synchronization for container transaction");
-		}
-		transactionCoordinator().sendAfterTransactionBeginNotifications( this );
-		transactionCoordinator().getTransactionContext().afterTransactionBegin( this );
-	}
-
-	@Override
-	protected void beforeTransactionCommit() {
-		boolean flush = ! transactionCoordinator().getTransactionContext().isFlushModeNever() &&
-				! transactionCoordinator().getTransactionContext().isFlushBeforeCompletionEnabled();
-		if ( flush ) {
-			// if an exception occurs during flush, user must call rollback()
-			transactionCoordinator().getTransactionContext().managedFlush();
-		}
-	}
-
-	@Override
-	protected void doCommit() {
-		// nothing to do
-	}
-
-	@Override
-	protected void beforeTransactionRollBack() {
-		// nothing to do
-	}
-
-	@Override
-	protected void doRollback() {
-		markRollbackOnly();
-	}
-
-	@Override
-	protected void afterTransactionCompletion(int status) {
-		// nothing to do
-	}
-
-	@Override
-	protected void afterAfterCompletion() {
-		// nothing to do
-	}
-
-	@Override
-	public boolean isActive() throws TransactionException {
-		return JtaStatusHelper.isActive( getTransactionManager() );
-	}
-
-	@Override
-	public IsolationDelegate createIsolationDelegate() {
-		return new JtaIsolationDelegate( transactionCoordinator() );
-	}
-
-	@Override
-	public boolean isInitiator() {
-		return false; // cannot be
-	}
-
-	@Override
-	public void markRollbackOnly() {
-		try {
-			getTransactionManager().setRollbackOnly();
-		}
-		catch ( SystemException se ) {
-			throw new TransactionException("Could not set transaction to rollback only", se);
-		}
-	}
-
-	@Override
-	public void markForJoin() {
-		joinStatus = JoinStatus.MARKED_FOR_JOINED;
-	}
-
-	@Override
-	public void join() {
-		if ( joinStatus != JoinStatus.MARKED_FOR_JOINED ) {
-			return;
-		}
-
-		if ( JtaStatusHelper.isActive( transactionManager() ) ) {
-			// register synchronization if needed
-			transactionCoordinator().pulse();
-			joinStatus = JoinStatus.JOINED;
-		}
-		else {
-			joinStatus = JoinStatus.NOT_JOINED;
-		}
-	}
-
-	@Override
-	public void resetJoinStatus() {
-		joinStatus = JoinStatus.NOT_JOINED;
-	}
-
-	boolean isJoinable() {
-		return ( joinStatus == JoinStatus.JOINED || joinStatus == JoinStatus.MARKED_FOR_JOINED ) &&
-				JtaStatusHelper.isActive( transactionManager() );
-	}
-
-	@Override
-	public JoinStatus getJoinStatus() {
-		return joinStatus;
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/CMTTransactionFactory.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/CMTTransactionFactory.java
deleted file mode 100644
index c211192d51..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/CMTTransactionFactory.java
+++ /dev/null
@@ -1,77 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.engine.transaction.internal.jta;
-
-import javax.transaction.SystemException;
-
-import org.hibernate.ConnectionReleaseMode;
-import org.hibernate.TransactionException;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
-import org.hibernate.engine.transaction.spi.TransactionFactory;
-
-/**
- * Factory for Container Managed Transaction (CMT) based transaction facades.
- *
- * @author Steve Ebersole
- * @author Gavin King
- */
-public class CMTTransactionFactory  implements TransactionFactory<CMTTransaction> {
-	public static final String SHORT_NAME = "cmt";
-
-	@Override
-	public CMTTransaction createTransaction(TransactionCoordinator transactionCoordinator) {
-		return new CMTTransaction( transactionCoordinator );
-	}
-
-	@Override
-	public boolean canBeDriver() {
-		return false;
-	}
-
-	@Override
-	public ConnectionReleaseMode getDefaultReleaseMode() {
-		return ConnectionReleaseMode.AFTER_STATEMENT;
-	}
-
-	@Override
-	public boolean compatibleWithJtaSynchronization() {
-		return true;
-	}
-
-	@Override
-	public boolean isJoinableJtaTransaction(TransactionCoordinator transactionCoordinator, CMTTransaction transaction) {
-		try {
-			final int status = transactionCoordinator
-					.getTransactionContext()
-					.getTransactionEnvironment()
-					.getJtaPlatform()
-					.getCurrentStatus();
-			return JtaStatusHelper.isActive( status );
-		}
-		catch( SystemException se ) {
-			throw new TransactionException( "Unable to check transaction status", se );
-		}
-	}
-
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaTransaction.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaTransaction.java
deleted file mode 100644
index ebfddf42a4..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaTransaction.java
+++ /dev/null
@@ -1,285 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.engine.transaction.internal.jta;
-
-import javax.transaction.Status;
-import javax.transaction.SystemException;
-import javax.transaction.TransactionManager;
-import javax.transaction.UserTransaction;
-
-import org.hibernate.HibernateException;
-import org.hibernate.TransactionException;
-import org.hibernate.engine.transaction.spi.AbstractTransactionImpl;
-import org.hibernate.engine.transaction.spi.IsolationDelegate;
-import org.hibernate.engine.transaction.spi.JoinStatus;
-import org.hibernate.engine.transaction.spi.LocalStatus;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
-import org.hibernate.internal.CoreLogging;
-import org.hibernate.internal.CoreMessageLogger;
-
-/**
- * Implements a transaction strategy based on transaction management through a JTA {@link UserTransaction}.
- *
- * @author Gavin King
- * @author Steve Ebersole
- * @author Les Hazlewood
- */
-public class JtaTransaction extends AbstractTransactionImpl {
-	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( JtaTransaction.class );
-
-	private UserTransaction userTransaction;
-
-	private boolean isInitiator;
-	private boolean isDriver;
-
-	protected JtaTransaction(TransactionCoordinator transactionCoordinator) {
-		super( transactionCoordinator );
-	}
-
-	@SuppressWarnings( {"UnusedDeclaration"})
-	public UserTransaction getUserTransaction() {
-		return userTransaction;
-	}
-
-	@Override
-	protected void doBegin() {
-		LOG.debug( "begin" );
-
-		userTransaction = locateUserTransaction();
-
-		try {
-			if ( userTransaction.getStatus() == Status.STATUS_NO_TRANSACTION ) {
-				userTransaction.begin();
-				isInitiator = true;
-				LOG.debug( "Began a new JTA transaction" );
-			}
-		}
-		catch ( Exception e ) {
-			throw new TransactionException( "JTA transaction begin failed", e );
-		}
-	}
-
-	private UserTransaction locateUserTransaction() {
-		final UserTransaction userTransaction = jtaPlatform().retrieveUserTransaction();
-		if ( userTransaction == null ) {
-			throw new TransactionException( "Unable to locate JTA UserTransaction" );
-		}
-		return userTransaction;
-	}
-
-	@Override
-	protected void afterTransactionBegin() {
-		transactionCoordinator().pulse();
-
-		if ( !transactionCoordinator().isSynchronizationRegistered() ) {
-			isDriver = transactionCoordinator().takeOwnership();
-		}
-
-		applyTimeout();
-		transactionCoordinator().sendAfterTransactionBeginNotifications( this );
-		transactionCoordinator().getTransactionContext().afterTransactionBegin( this );
-	}
-
-	private void applyTimeout() {
-		if ( getTimeout() > 0 ) {
-			if ( userTransaction != null ) {
-				try {
-					userTransaction.setTransactionTimeout( getTimeout() );
-				}
-				catch ( SystemException e ) {
-					throw new TransactionException( "Unable to apply requested transaction timeout", e );
-				}
-			}
-			else {
-				LOG.debug( "Unable to apply requested transaction timeout; no UserTransaction.  Will try later" );
-			}
-		}
-	}
-
-	@Override
-	protected void beforeTransactionCommit() {
-		transactionCoordinator().sendBeforeTransactionCompletionNotifications( this );
-
-		final boolean flush = ! transactionCoordinator().getTransactionContext().isFlushModeNever() &&
-				( isDriver || ! transactionCoordinator().getTransactionContext().isFlushBeforeCompletionEnabled() );
-
-		if ( flush ) {
-			// if an exception occurs during flush, user must call rollback()
-			transactionCoordinator().getTransactionContext().managedFlush();
-		}
-
-		if ( isDriver && isInitiator ) {
-			transactionCoordinator().getTransactionContext().beforeTransactionCompletion( this );
-		}
-
-		closeIfRequired();
-	}
-
-	private void closeIfRequired() throws HibernateException {
-		final boolean close = isDriver &&
-				transactionCoordinator().getTransactionContext().shouldAutoClose() &&
-				! transactionCoordinator().getTransactionContext().isClosed();
-		if ( close ) {
-			transactionCoordinator().getTransactionContext().managedClose();
-		}
-	}
-
-	@Override
-	protected void doCommit() {
-		try {
-			if ( isInitiator ) {
-				userTransaction.commit();
-				LOG.debug( "Committed JTA UserTransaction" );
-			}
-		}
-		catch ( Exception e ) {
-			throw new TransactionException( "JTA commit failed: ", e );
-		}
-	}
-
-	@Override
-	protected void afterTransactionCompletion(int status) {
-		// nothing to do
-	}
-
-	@Override
-	protected void afterAfterCompletion() {
-		// this method is a noop if there is a Synchronization!
-		try {
-			if ( isDriver ) {
-				if ( !isInitiator ) {
-					LOG.setManagerLookupClass();
-				}
-				try {
-					transactionCoordinator().afterTransaction( this, userTransaction.getStatus() );
-				}
-				catch (SystemException e) {
-					throw new TransactionException( "Unable to determine UserTransaction status", e );
-				}
-			}
-		}
-		finally {
-			isInitiator = false;
-		}
-	}
-
-	@Override
-	protected void beforeTransactionRollBack() {
-		// nothing to do
-	}
-
-	@Override
-	protected void doRollback() {
-		try {
-			if ( isInitiator ) {
-				// failed commits automatically rollback the transaction per JTA spec
-				if ( getLocalStatus() != LocalStatus.FAILED_COMMIT  ) {
-					userTransaction.rollback();
-					LOG.debug( "Rolled back JTA UserTransaction" );
-				}
-			}
-			else {
-				markRollbackOnly();
-			}
-		}
-		catch ( Exception e ) {
-			throw new TransactionException( "JTA rollback failed", e );
-		}
-	}
-
-	@Override
-	public void markRollbackOnly() {
-		LOG.trace( "Marking transaction for rollback only" );
-		try {
-			if ( userTransaction == null ) {
-				userTransaction = locateUserTransaction();
-			}
-			userTransaction.setRollbackOnly();
-			LOG.debug( "set JTA UserTransaction to rollback only" );
-		}
-		catch (SystemException e) {
-			LOG.debug( "Unable to mark transaction for rollback only", e );
-		}
-	}
-
-	@Override
-	public IsolationDelegate createIsolationDelegate() {
-		return new JtaIsolationDelegate( transactionCoordinator() );
-	}
-
-	@Override
-	public boolean isInitiator() {
-		return isInitiator;
-	}
-
-	@Override
-	public boolean isActive() throws HibernateException {
-		if ( getLocalStatus() != LocalStatus.ACTIVE ) {
-			return false;
-		}
-
-		final int status;
-		try {
-			status = userTransaction.getStatus();
-		}
-		catch ( SystemException se ) {
-			throw new TransactionException( "Could not determine transaction status: ", se );
-		}
-		return JtaStatusHelper.isActive( status );
-	}
-
-	@Override
-	public void setTimeout(int seconds) {
-		super.setTimeout( seconds );
-		applyTimeout();
-	}
-
-	@Override
-	public void join() {
-	}
-
-	@Override
-	public void resetJoinStatus() {
-	}
-
-	@Override
-	public JoinStatus getJoinStatus() {
-		// if we already have the UserTransaction cached locally, use it to avoid JNDI look ups
-		if ( this.userTransaction != null ) {
-			return JtaStatusHelper.isActive( this.userTransaction ) ? JoinStatus.JOINED : JoinStatus.NOT_JOINED;
-		}
-
-		// Otherwise, try to use the TransactionManager since it is generally cached
-		TransactionManager transactionManager = jtaPlatform().retrieveTransactionManager();
-		if ( transactionManager != null ) {
-			return JtaStatusHelper.isActive( transactionManager ) ? JoinStatus.JOINED : JoinStatus.NOT_JOINED;
-		}
-
-		// Finally, look up the UserTransaction
-		UserTransaction userTransaction = jtaPlatform().retrieveUserTransaction();
-		return userTransaction != null && JtaStatusHelper.isActive( userTransaction )
-				? JoinStatus.JOINED
-				: JoinStatus.NOT_JOINED;
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaTransactionFactory.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaTransactionFactory.java
deleted file mode 100644
index 1e6802d875..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaTransactionFactory.java
+++ /dev/null
@@ -1,104 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.engine.transaction.internal.jta;
-
-import javax.transaction.SystemException;
-import javax.transaction.UserTransaction;
-
-import org.hibernate.ConnectionReleaseMode;
-import org.hibernate.TransactionException;
-import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
-import org.hibernate.engine.transaction.spi.TransactionFactory;
-
-/**
- * Factory for {@link JtaTransaction} instances.
- *
- * @author Gavin King
- * @author Steve Ebersole
- * @author Les Hazlewood
- */
-public class JtaTransactionFactory implements TransactionFactory<JtaTransaction> {
-	public static final String SHORT_NAME = "jta";
-
-	@Override
-	public JtaTransaction createTransaction(TransactionCoordinator transactionCoordinator) {
-		return new JtaTransaction( transactionCoordinator );
-	}
-
-	@Override
-	public boolean canBeDriver() {
-		return true;
-	}
-
-	@Override
-	public ConnectionReleaseMode getDefaultReleaseMode() {
-		return ConnectionReleaseMode.AFTER_STATEMENT;
-	}
-
-	@Override
-	public boolean compatibleWithJtaSynchronization() {
-		return true;
-	}
-
-	@Override
-	public boolean isJoinableJtaTransaction(TransactionCoordinator transactionCoordinator, JtaTransaction transaction) {
-		try {
-			// Essentially:
-			// 1) If we have a local (Hibernate) transaction in progress
-			//      and it already has the UserTransaction cached, use that
-			//      UserTransaction to determine the status.
-			// 2) If a transaction manager has been located, use
-			//      that transaction manager to determine the status.
-			// 3) Finally, as the last resort, try to lookup the
-			//      UserTransaction via JNDI and use that to determine the
-			//      status.
-			if ( transaction != null ) {
-				UserTransaction ut = transaction.getUserTransaction();
-				if ( ut != null ) {
-					return JtaStatusHelper.isActive( ut );
-				}
-			}
-
-			final JtaPlatform jtaPlatform = transactionCoordinator
-					.getTransactionContext()
-					.getTransactionEnvironment()
-					.getJtaPlatform();
-			if ( jtaPlatform == null ) {
-				throw new TransactionException( "Unable to check transaction status" );
-			}
-			if ( jtaPlatform.retrieveTransactionManager() != null ) {
-				return JtaStatusHelper.isActive( jtaPlatform.retrieveTransactionManager().getStatus() );
-			}
-			else {
-				final UserTransaction ut = jtaPlatform.retrieveUserTransaction();
-				return ut != null && JtaStatusHelper.isActive( ut );
-			}
-		}
-		catch ( SystemException se ) {
-			throw new TransactionException( "Unable to check transaction status", se );
-		}
-	}
-
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/AbstractTransactionImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/AbstractTransactionImpl.java
deleted file mode 100644
index e493fdbef6..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/AbstractTransactionImpl.java
+++ /dev/null
@@ -1,251 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.engine.transaction.spi;
-
-import javax.transaction.Status;
-import javax.transaction.Synchronization;
-
-import org.hibernate.HibernateException;
-import org.hibernate.TransactionException;
-import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
-import org.hibernate.internal.CoreLogging;
-
-import org.jboss.logging.Logger;
-
-/**
- * Abstract support for creating {@link TransactionImplementor transaction} implementations
- *
- * @author Steve Ebersole
- */
-public abstract class AbstractTransactionImpl implements TransactionImplementor {
-	private static final Logger LOG = CoreLogging.logger( AbstractTransactionImpl.class );
-
-	private final TransactionCoordinator transactionCoordinator;
-
-	private boolean valid = true;
-
-	private LocalStatus localStatus = LocalStatus.NOT_ACTIVE;
-	private int timeout = -1;
-
-	protected AbstractTransactionImpl(TransactionCoordinator transactionCoordinator) {
-		this.transactionCoordinator = transactionCoordinator;
-	}
-
-	@Override
-	public void invalidate() {
-		valid = false;
-	}
-
-	/**
-	 * Perform the actual steps of beginning a transaction according to the strategy.
-	 *
-	 * @throws org.hibernate.TransactionException Indicates a problem beginning the transaction
-	 */
-	protected abstract void doBegin();
-
-	/**
-	 * Perform the actual steps of committing a transaction according to the strategy.
-	 *
-	 * @throws org.hibernate.TransactionException Indicates a problem committing the transaction
-	 */
-	protected abstract void doCommit();
-
-	/**
-	 * Perform the actual steps of rolling back a transaction according to the strategy.
-	 *
-	 * @throws org.hibernate.TransactionException Indicates a problem rolling back the transaction
-	 */
-	protected abstract void doRollback();
-
-	protected abstract void afterTransactionBegin();
-
-	protected abstract void beforeTransactionCommit();
-
-	protected abstract void beforeTransactionRollBack();
-
-	protected abstract void afterTransactionCompletion(int status);
-
-	protected abstract void afterAfterCompletion();
-
-	/**
-	 * Provide subclasses with access to the transaction coordinator.
-	 *
-	 * @return This transaction's context.
-	 */
-	protected TransactionCoordinator transactionCoordinator() {
-		return transactionCoordinator;
-	}
-
-	/**
-	 * Provide subclasses with convenient access to the configured {@link JtaPlatform}
-	 *
-	 * @return The {@link org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform}
-	 */
-	protected JtaPlatform jtaPlatform() {
-		return transactionCoordinator().getTransactionContext().getTransactionEnvironment().getJtaPlatform();
-	}
-
-	@Override
-	public void registerSynchronization(Synchronization synchronization) {
-		transactionCoordinator().getSynchronizationRegistry().registerSynchronization( synchronization );
-	}
-
-	@Override
-	public LocalStatus getLocalStatus() {
-		return localStatus;
-	}
-
-	@Override
-	public boolean isActive() {
-		return localStatus == LocalStatus.ACTIVE && doExtendedActiveCheck();
-	}
-
-	@Override
-	public boolean isParticipating() {
-		return getJoinStatus() == JoinStatus.JOINED && isActive();
-	}
-
-	@Override
-	public boolean wasCommitted() {
-		return localStatus == LocalStatus.COMMITTED;
-	}
-
-	@Override
-	public boolean wasRolledBack() throws HibernateException {
-		return localStatus == LocalStatus.ROLLED_BACK;
-	}
-
-	/**
-	 * Active has been checked against local state.  Perform any needed checks against resource transactions.
-	 *
-	 * @return {@code true} if the extended active check checks out as well; false otherwise.
-	 */
-	protected boolean doExtendedActiveCheck() {
-		return true;
-	}
-
-	@Override
-	public void begin() throws HibernateException {
-		if ( !valid ) {
-			throw new TransactionException( "Transaction instance is no longer valid" );
-		}
-		if ( localStatus == LocalStatus.ACTIVE ) {
-			throw new TransactionException( "nested transactions not supported" );
-		}
-		if ( localStatus != LocalStatus.NOT_ACTIVE ) {
-			throw new TransactionException( "reuse of Transaction instances not supported" );
-		}
-
-		LOG.debug( "begin" );
-
-		doBegin();
-
-		localStatus = LocalStatus.ACTIVE;
-
-		afterTransactionBegin();
-	}
-
-	@Override
-	public void commit() throws HibernateException {
-		if ( localStatus != LocalStatus.ACTIVE ) {
-			throw new TransactionException( "Transaction not successfully started" );
-		}
-
-		LOG.debug( "committing" );
-
-		beforeTransactionCommit();
-
-		try {
-			doCommit();
-			localStatus = LocalStatus.COMMITTED;
-			afterTransactionCompletion( Status.STATUS_COMMITTED );
-		}
-		catch (Exception e) {
-			localStatus = LocalStatus.FAILED_COMMIT;
-			afterTransactionCompletion( Status.STATUS_UNKNOWN );
-			throw new TransactionException( "commit failed", e );
-		}
-		finally {
-			invalidate();
-			afterAfterCompletion();
-		}
-	}
-
-	protected boolean allowFailedCommitToPhysicallyRollback() {
-		return false;
-	}
-
-	@Override
-	public void rollback() throws HibernateException {
-		if ( localStatus != LocalStatus.ACTIVE && localStatus != LocalStatus.FAILED_COMMIT ) {
-			throw new TransactionException( "Transaction not successfully started" );
-		}
-
-		LOG.debug( "rolling back" );
-
-		beforeTransactionRollBack();
-
-		if ( localStatus != LocalStatus.FAILED_COMMIT || allowFailedCommitToPhysicallyRollback() ) {
-			try {
-				doRollback();
-				localStatus = LocalStatus.ROLLED_BACK;
-				afterTransactionCompletion( Status.STATUS_ROLLEDBACK );
-			}
-			catch (Exception e) {
-				afterTransactionCompletion( Status.STATUS_UNKNOWN );
-				throw new TransactionException( "rollback failed", e );
-			}
-			finally {
-				invalidate();
-				afterAfterCompletion();
-			}
-		}
-
-	}
-
-	@Override
-	public void setTimeout(int seconds) {
-		timeout = seconds;
-	}
-
-	@Override
-	public int getTimeout() {
-		return timeout;
-	}
-
-	@Override
-	public void markForJoin() {
-		// generally speaking this is no-op
-	}
-
-	@Override
-	public void join() {
-		// generally speaking this is no-op
-	}
-
-	@Override
-	public void resetJoinStatus() {
-		// generally speaking this is no-op
-	}
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionContext.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionContext.java
deleted file mode 100644
index 396a84c19a..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionContext.java
+++ /dev/null
@@ -1,130 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.engine.transaction.spi;
-
-import java.io.Serializable;
-
-import org.hibernate.ConnectionReleaseMode;
-import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
-
-/**
- * Access to services needed in the context of processing transaction requests.
- * <p/>
- * The context is roughly speaking equivalent to the Hibernate session, as opposed to the {@link TransactionEnvironment}
- * which is roughly equivalent to the Hibernate session factory
- * 
- * @author Steve Ebersole
- */
-public interface TransactionContext extends Serializable {
-	/**
-	 * Obtain the {@link TransactionEnvironment} associated with this context.
-	 *
-	 * @return The transaction environment.
-	 */
-	public TransactionEnvironment getTransactionEnvironment();
-
-	/**
-	 * Get the mode for releasing JDBC connection in effect for ths context.
-	 *
-	 * @return The connection release mode.
-	 */
-	public ConnectionReleaseMode getConnectionReleaseMode();
-
-	/**
-	 * Should transactions be auto joined?  Generally this is only a concern for CMT transactions.  The default
-	 * should be to auto join.  JPA defines an explicit operation for joining a CMT transaction.
-	 *
-	 * @return Should we automatically join transactions
-	 */
-	public boolean shouldAutoJoinTransaction();
-
-	/**
-	 * Should session automatically be closed after transaction completion in this context?
-	 *
-	 * @return {@literal true}/{@literal false} appropriately.
-	 */
-	public boolean isAutoCloseSessionEnabled();
-
-	/**
-	 * Is this context already closed?
-	 *
-	 * @return {@literal true}/{@literal false} appropriately.
-	 */
-	public boolean isClosed();
-
-	/**
-	 * Should flushes only happen manually for this context?
-	 *
-	 * @return {@literal true}/{@literal false} appropriately.
-	 */
-	public boolean isFlushModeNever();
-
-	/**
-	 * Should before transaction completion processing perform a flush when initiated from JTA synchronization for this
-	 * context?
-	 *
-	 * @return {@literal true}/{@literal false} appropriately.
-	 */
-	public boolean isFlushBeforeCompletionEnabled();
-
-	/**
-	 * Perform a managed flush.
-	 */
-	public void managedFlush();
-
-	/**
-	 * Should JTA synchronization processing perform a automatic close (call to {@link #managedClose} for this
-	 * context?
-	 * 
-	 * @return {@literal true}/{@literal false} appropriately.
-	 */
-	public boolean shouldAutoClose();
-
-	/**
-	 * Perform a managed close.
-	 */
-	public void managedClose();
-
-	public void afterTransactionBegin(TransactionImplementor hibernateTransaction);
-
-	public void beforeTransactionCompletion(TransactionImplementor hibernateTransaction);
-
-	public void afterTransactionCompletion(TransactionImplementor hibernateTransaction, boolean successful);
-
-	public String onPrepareStatement(String sql);
-
-	public JdbcConnectionAccess getJdbcConnectionAccess();
-
-	public void startPrepareStatement();
-
-	public void endPrepareStatement();
-
-	public void startStatementExecution();
-
-	public void endStatementExecution();
-
-	public void startBatchExecution();
-
-	public void endBatchExecution();
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionCoordinator.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionCoordinator.java
deleted file mode 100644
index 0b06aff160..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionCoordinator.java
+++ /dev/null
@@ -1,146 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.engine.transaction.spi;
-
-import java.io.Serializable;
-import java.sql.Connection;
-
-import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
-import org.hibernate.engine.transaction.synchronization.spi.SynchronizationCallbackCoordinator;
-
-/**
- * Acts as the coordinator between the Hibernate engine and physical transactions.
- *
- * @author Steve Ebersole
- */
-public interface TransactionCoordinator extends Serializable {
-	/**
-	 * Retrieves the context in which this coordinator operates.
-	 *
-	 * @return The context of the coordinator
-	 */
-	public TransactionContext getTransactionContext();
-
-	/**
-	 * Retrieves the JDBC coordinator currently operating within this transaction coordinator.
-	 *
-	 * @return The JDBC coordinator.
-	 */
-	public JdbcCoordinator getJdbcCoordinator();
-
-	/**
-	 * Get the Hibernate transaction facade object currently associated with this coordinator.
-	 *
-	 * @return The current Hibernate transaction.
-	 */
-	public TransactionImplementor getTransaction();
-
-	/**
-	 * Obtain the {@link javax.transaction.Synchronization} registry associated with this coordinator.
-	 *
-	 * @return The registry
-	 */
-	public SynchronizationRegistry getSynchronizationRegistry();
-
-	/**
-	 * Adds an observer to the coordinator.
-	 * <p/>
-	 * Unlike synchronizations added to the {@link #getSynchronizationRegistry() registry}, observers are not to be
-	 * cleared on transaction completion.
-	 *
-	 * @param observer The observer to add.
-	 */
-	public void addObserver(TransactionObserver observer);
-
-	/**
-	 * Removed an observer from the coordinator.
-	 *
-	 * @param observer The observer to remove.
-	 */
-	public void removeObserver(TransactionObserver observer);
-	
-	/**
-	 * Can we join to the underlying transaction?
-	 *
-	 * @return {@literal true} if the underlying transaction can be joined or is already joined; {@literal false}
-	 * otherwise.
-	 *
-	 * @see TransactionFactory#isJoinableJtaTransaction(TransactionCoordinator, TransactionImplementor)
-	 */
-	public boolean isTransactionJoinable();
-
-	/**
-	 * Is the underlying transaction already joined?
-	 *
-	 * @return {@literal true} if the underlying transaction is already joined; {@literal false} otherwise.
-	 */
-	public boolean isTransactionJoined();
-
-	/**
-	 * Reset the transaction's join status.
-	 */
-	public void resetJoinStatus();
-
-	/**
-	 * Are we "in" an active and joined transaction
-	 *
-	 * @return {@literal true} if there is currently a transaction in progress; {@literal false} otherwise.
-	 */
-	public boolean isTransactionInProgress();
-
-	/**
-	 * Attempts to register JTA synchronization if possible and needed.
-	 */
-	public void pulse();
-
-	/**
-	 * Close the transaction context, returning any user supplied connection from the underlying JDBC coordinator.
-	 *
-	 * @return The user supplied connection (if one).
-	 */
-	public Connection close();
-
-	/**
-	 * Performs actions needed after execution of a non-transactional query.
-	 *
-	 * @param success Was the query successfully performed
-	 */
-	public void afterNonTransactionalQuery(boolean success);
-
-	public void setRollbackOnly();
-
-	public SynchronizationCallbackCoordinator getSynchronizationCallbackCoordinator();
-
-	public boolean isSynchronizationRegistered();
-	public boolean takeOwnership();
-
-	public void afterTransaction(TransactionImplementor hibernateTransaction, int status);
-
-	public void sendAfterTransactionBeginNotifications(TransactionImplementor hibernateTransaction);
-	public void sendBeforeTransactionCompletionNotifications(TransactionImplementor hibernateTransaction);
-	public void sendAfterTransactionCompletionNotifications(TransactionImplementor hibernateTransaction, int status);
-
-	public boolean isActive();
-
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionFactory.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionFactory.java
deleted file mode 100644
index 56276f3888..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionFactory.java
+++ /dev/null
@@ -1,83 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.engine.transaction.spi;
-
-import org.hibernate.ConnectionReleaseMode;
-import org.hibernate.service.Service;
-
-/**
- * Contract for transaction creation, as well as providing metadata and contextual information about that creation.
- *
- * @author Steve Ebersole
- */
-public interface TransactionFactory<T extends TransactionImplementor> extends Service {
-	/**
-	 * Construct a transaction instance compatible with this strategy.
-	 *
-	 * @param coordinator The coordinator for this transaction
-	 *
-	 * @return The appropriate transaction instance.
-	 *
-	 * @throws org.hibernate.HibernateException Indicates a problem constructing the transaction.
-	 */
-	public T createTransaction(TransactionCoordinator coordinator);
-
-	/**
-	 * Can the transactions created from this strategy act as the driver?  In other words can the user actually manage
-	 * transactions with this strategy?
-	 *
-	 * @return {@literal true} if the transaction strategy represented by this factory can act as the driver callback;
-	 * {@literal false} otherwise.
-	 */
-	public boolean canBeDriver();
-
-	/**
-	 * Should we attempt to register JTA transaction {@link javax.transaction.Synchronization synchronizations}.
-	 * <p/>
-	 * In other words, is this strategy JTA-based?
-	 *
-	 * @return {@literal true} if the transaction strategy represented by this factory is compatible with registering
-	 * {@link javax.transaction.Synchronization synchronizations}; {@literal false} otherwise.
-	 */
-	public boolean compatibleWithJtaSynchronization();
-
-	/**
-	 * Can the underlying transaction represented by the passed Hibernate {@link TransactionImplementor} be joined?
-	 *
-	 * @param transactionCoordinator The transaction coordinator
-	 * @param transaction The current Hibernate transaction
-	 *
-	 * @return {@literal true} is the transaction can be joined; {@literal false} otherwise.
-	 */
-	public boolean isJoinableJtaTransaction(TransactionCoordinator transactionCoordinator, T transaction);
-
-	/**
-	 * Get the default connection release mode.
-	 *
-	 * @return The default release mode associated with this strategy
-	 */
-	public ConnectionReleaseMode getDefaultReleaseMode();
-
-}
-
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionObserver.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionObserver.java
index 5a3472f046..217b956246 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionObserver.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionObserver.java
@@ -1,57 +1,52 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.transaction.spi;
 
 /**
  * Observer of internal transaction events.
  *
  * @author Steve Ebersole
  */
 public interface TransactionObserver {
 	/**
 	 * Callback for processing the beginning of a transaction.
-	 *
+	 * <p/>
 	 * Do not rely on this being called as the transaction mat be started in a manner other than through the
 	 * {@link org.hibernate.Transaction} API.
-	 *
-	 * @param transaction The Hibernate transaction
 	 */
-	public void afterBegin(TransactionImplementor transaction);
+	public void afterBegin();
 
 	/**
 	 * Callback for processing the initial phase of transaction completion.
-	 *
-	 * @param transaction The Hibernate transaction
 	 */
-	public void beforeCompletion(TransactionImplementor transaction);
+	public void beforeCompletion();
 
 	/**
 	 * Callback for processing the last phase of transaction completion.
 	 *
 	 * @param successful Was the transaction successful?
-	 * @param transaction The Hibernate transaction
 	 */
-	public void afterCompletion(boolean successful, TransactionImplementor transaction);
+	public void afterCompletion(boolean successful);
 }
 
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/internal/SynchronizationCallbackCoordinatorNonTrackingImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/internal/SynchronizationCallbackCoordinatorNonTrackingImpl.java
deleted file mode 100644
index da485ccdfb..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/internal/SynchronizationCallbackCoordinatorNonTrackingImpl.java
+++ /dev/null
@@ -1,194 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.engine.transaction.synchronization.internal;
-
-import javax.transaction.SystemException;
-
-import org.hibernate.TransactionException;
-import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
-import org.hibernate.engine.transaction.spi.TransactionContext;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
-import org.hibernate.engine.transaction.synchronization.spi.AfterCompletionAction;
-import org.hibernate.engine.transaction.synchronization.spi.ExceptionMapper;
-import org.hibernate.engine.transaction.synchronization.spi.ManagedFlushChecker;
-import org.hibernate.engine.transaction.synchronization.spi.SynchronizationCallbackCoordinator;
-import org.hibernate.internal.CoreLogging;
-import org.hibernate.internal.CoreMessageLogger;
-
-/**
- * Manages callbacks from the {@link javax.transaction.Synchronization} registered by Hibernate.
- * 
- * @author Steve Ebersole
- */
-public class SynchronizationCallbackCoordinatorNonTrackingImpl implements SynchronizationCallbackCoordinator {
-	private static final CoreMessageLogger LOG = CoreLogging.messageLogger(
-			SynchronizationCallbackCoordinatorNonTrackingImpl.class
-	);
-
-	private final TransactionCoordinator transactionCoordinator;
-
-	private ManagedFlushChecker managedFlushChecker;
-	private AfterCompletionAction afterCompletionAction;
-	private ExceptionMapper exceptionMapper;
-
-	public SynchronizationCallbackCoordinatorNonTrackingImpl(TransactionCoordinator transactionCoordinator) {
-		this.transactionCoordinator = transactionCoordinator;
-		reset();
-	}
-
-	public void reset() {
-		managedFlushChecker = STANDARD_MANAGED_FLUSH_CHECKER;
-		exceptionMapper = STANDARD_EXCEPTION_MAPPER;
-		afterCompletionAction = STANDARD_AFTER_COMPLETION_ACTION;
-	}
-
-	protected final TransactionCoordinator transactionCoordinator() {
-		return transactionCoordinator;
-	}
-
-	private TransactionContext transactionContext() {
-		return transactionCoordinator.getTransactionContext();
-	}
-
-	@Override
-	public void setManagedFlushChecker(ManagedFlushChecker managedFlushChecker) {
-		this.managedFlushChecker = managedFlushChecker;
-	}
-
-	@Override
-	public void setExceptionMapper(ExceptionMapper exceptionMapper) {
-		this.exceptionMapper = exceptionMapper;
-	}
-
-	@Override
-	public void setAfterCompletionAction(AfterCompletionAction afterCompletionAction) {
-		this.afterCompletionAction = afterCompletionAction;
-	}
-
-	// sync callbacks ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-	@Override
-	public void beforeCompletion() {
-		LOG.trace( "Transaction before completion callback" );
-
-		if ( !transactionCoordinator.isActive() ) {
-			return;
-		}
-
-		boolean flush;
-		try {
-			final int status = transactionCoordinator.getTransactionContext().getTransactionEnvironment()
-					.getJtaPlatform().getCurrentStatus();
-			flush = managedFlushChecker.shouldDoManagedFlush( transactionCoordinator, status );
-		}
-		catch ( SystemException se ) {
-			setRollbackOnly();
-			throw exceptionMapper.mapStatusCheckFailure(
-					"could not determine transaction status in beforeCompletion()", se );
-		}
-
-		try {
-			if ( flush ) {
-				LOG.trace( "Automatically flushing session" );
-				transactionCoordinator.getTransactionContext().managedFlush();
-			}
-		}
-		catch ( RuntimeException re ) {
-			setRollbackOnly();
-			throw exceptionMapper.mapManagedFlushFailure( "error during managed flush", re );
-		}
-		finally {
-			transactionCoordinator.sendBeforeTransactionCompletionNotifications( null );
-			transactionCoordinator.getTransactionContext().beforeTransactionCompletion( null );
-		}
-	}
-
-	private void setRollbackOnly() {
-		transactionCoordinator.setRollbackOnly();
-	}
-
-	@Override
-	public void afterCompletion(int status) {
-		doAfterCompletion( status );
-	}
-
-	protected void doAfterCompletion(int status) {
-		LOG.tracef( "Starting transaction afterCompletion callback [status=%s]", status );
-		if ( !transactionCoordinator.isActive() ) {
-			return;
-		}
-
-		try {
-			afterCompletionAction.doAction( transactionCoordinator, status );
-			transactionCoordinator.afterTransaction( null, status );
-		}
-		finally {
-			reset();
-			if ( transactionContext().shouldAutoClose() && !transactionContext().isClosed() ) {
-				LOG.trace( "Automatically closing session" );
-				transactionContext().managedClose();
-			}
-		}
-	}
-
-	@Override
-	public void synchronizationRegistered() {
-	}
-
-	@Override
-	public void processAnyDelayedAfterCompletion() {
-	}
-
-	private static final ManagedFlushChecker STANDARD_MANAGED_FLUSH_CHECKER = new ManagedFlushChecker() {
-		@Override
-		public boolean shouldDoManagedFlush(TransactionCoordinator coordinator, int jtaStatus) {
-			return !coordinator.getTransactionContext().isClosed()
-					&& !coordinator.getTransactionContext().isFlushModeNever()
-					&& coordinator.getTransactionContext().isFlushBeforeCompletionEnabled()
-					&& !JtaStatusHelper.isRollback( jtaStatus );
-		}
-	};
-
-	private static final ExceptionMapper STANDARD_EXCEPTION_MAPPER = new ExceptionMapper() {
-		@Override
-		public RuntimeException mapStatusCheckFailure(String message, SystemException systemException) {
-			LOG.error( LOG.unableToDetermineTransactionStatus(), systemException );
-			return new TransactionException( "could not determine transaction status in beforeCompletion()",
-					systemException );
-		}
-
-		@Override
-		public RuntimeException mapManagedFlushFailure(String message, RuntimeException failure) {
-			LOG.unableToPerformManagedFlush( failure.getMessage() );
-			return failure;
-		}
-	};
-
-	private static final AfterCompletionAction STANDARD_AFTER_COMPLETION_ACTION = new AfterCompletionAction() {
-		@Override
-		public void doAction(TransactionCoordinator transactionCoordinator, int status) {
-			// nothing to do by default.
-		}
-	};
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/spi/ExceptionMapper.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/spi/ExceptionMapper.java
deleted file mode 100644
index 2991d56a32..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/spi/ExceptionMapper.java
+++ /dev/null
@@ -1,55 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.engine.transaction.synchronization.spi;
-
-import java.io.Serializable;
-import javax.transaction.SystemException;
-
-/**
- * A pluggable strategy for defining how the {@link javax.transaction.Synchronization} registered by Hibernate handles
- * exceptions.
- *
- * @author Steve Ebersole
- */
-public interface ExceptionMapper extends Serializable {
-	/**
-	 * Map a JTA {@link javax.transaction.SystemException} to the appropriate runtime-based exception.
-	 *
-	 * @param message The message to use for the returned exception
-	 * @param systemException The causal exception
-	 *
-	 * @return The appropriate exception to throw
-	 */
-	public RuntimeException mapStatusCheckFailure(String message, SystemException systemException);
-
-	/**
-	 * Map an exception encountered during a managed flush to the appropriate runtime-based exception.
-	 *
-	 * @param message The message to use for the returned exception
-	 * @param failure The causal exception
-	 *
-	 * @return The appropriate exception to throw
-	 */
-	public RuntimeException mapManagedFlushFailure(String message, RuntimeException failure);
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractFlushingEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractFlushingEventListener.java
index 8a55feebc6..c99a3bb827 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractFlushingEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractFlushingEventListener.java
@@ -1,404 +1,404 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.internal;
 
 import java.io.Serializable;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.action.internal.CollectionRecreateAction;
 import org.hibernate.action.internal.CollectionRemoveAction;
 import org.hibernate.action.internal.CollectionUpdateAction;
 import org.hibernate.action.internal.QueuedOperationCollectionAction;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.internal.Cascade;
 import org.hibernate.engine.internal.CascadePoint;
 import org.hibernate.engine.internal.Collections;
 import org.hibernate.engine.spi.ActionQueue;
 import org.hibernate.engine.spi.CascadingAction;
 import org.hibernate.engine.spi.CascadingActions;
 import org.hibernate.engine.spi.CollectionEntry;
 import org.hibernate.engine.spi.CollectionKey;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.Status;
 import org.hibernate.event.service.spi.EventListenerRegistry;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.event.spi.EventType;
 import org.hibernate.event.spi.FlushEntityEvent;
 import org.hibernate.event.spi.FlushEntityEventListener;
 import org.hibernate.event.spi.FlushEvent;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.EntityPrinter;
 import org.hibernate.internal.util.collections.IdentityMap;
 import org.hibernate.internal.util.collections.LazyIterator;
 import org.hibernate.persister.entity.EntityPersister;
 
 import org.jboss.logging.Logger;
 
 /**
  * A convenience base class for listeners whose functionality results in flushing.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractFlushingEventListener implements Serializable {
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, AbstractFlushingEventListener.class.getName() );
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// Pre-flushing section
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Coordinates the processing necessary to get things ready for executions
 	 * as db calls by preping the session caches and moving the appropriate
 	 * entities and collections to their respective execution queues.
 	 *
 	 * @param event The flush event.
 	 * @throws HibernateException Error flushing caches to execution queues.
 	 */
 	protected void flushEverythingToExecutions(FlushEvent event) throws HibernateException {
 
 		LOG.trace( "Flushing session" );
 
 		EventSource session = event.getSession();
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		session.getInterceptor().preFlush( new LazyIterator( persistenceContext.getEntitiesByKey() ) );
 
 		prepareEntityFlushes( session, persistenceContext );
 		// we could move this inside if we wanted to
 		// tolerate collection initializations during
 		// collection dirty checking:
 		prepareCollectionFlushes( persistenceContext );
 		// now, any collections that are initialized
 		// inside this block do not get updated - they
 		// are ignored until the next flush
 
 		persistenceContext.setFlushing( true );
 		try {
 			int entityCount = flushEntities( event, persistenceContext );
 			int collectionCount = flushCollections( session, persistenceContext );
 
 			event.setNumberOfEntitiesProcessed( entityCount );
 			event.setNumberOfCollectionsProcessed( collectionCount );
 		}
 		finally {
 			persistenceContext.setFlushing(false);
 		}
 
 		//some statistics
 		logFlushResults( event );
 	}
 
 	@SuppressWarnings( value = {"unchecked"} )
 	private void logFlushResults(FlushEvent event) {
 		if ( !LOG.isDebugEnabled() ) {
 			return;
 		}
 		final EventSource session = event.getSession();
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		LOG.debugf(
 				"Flushed: %s insertions, %s updates, %s deletions to %s objects",
 				session.getActionQueue().numberOfInsertions(),
 				session.getActionQueue().numberOfUpdates(),
 				session.getActionQueue().numberOfDeletions(),
 				persistenceContext.getNumberOfManagedEntities()
 		);
 		LOG.debugf(
 				"Flushed: %s (re)creations, %s updates, %s removals to %s collections",
 				session.getActionQueue().numberOfCollectionCreations(),
 				session.getActionQueue().numberOfCollectionUpdates(),
 				session.getActionQueue().numberOfCollectionRemovals(),
 				persistenceContext.getCollectionEntries().size()
 		);
 		new EntityPrinter( session.getFactory() ).toString(
 				persistenceContext.getEntitiesByKey().entrySet()
 		);
 	}
 
 	/**
 	 * process cascade save/update at the start of a flush to discover
 	 * any newly referenced entity that must be passed to saveOrUpdate(),
 	 * and also apply orphan delete
 	 */
 	private void prepareEntityFlushes(EventSource session, PersistenceContext persistenceContext) throws HibernateException {
 
 		LOG.debug( "Processing flush-time cascades" );
 
 		final Object anything = getAnything();
 		//safe from concurrent modification because of how concurrentEntries() is implemented on IdentityMap
 		for ( Map.Entry<Object,EntityEntry> me : persistenceContext.reentrantSafeEntityEntries() ) {
 //		for ( Map.Entry me : IdentityMap.concurrentEntries( persistenceContext.getEntityEntries() ) ) {
 			EntityEntry entry = (EntityEntry) me.getValue();
 			Status status = entry.getStatus();
 			if ( status == Status.MANAGED || status == Status.SAVING || status == Status.READ_ONLY ) {
 				cascadeOnFlush( session, entry.getPersister(), me.getKey(), anything );
 			}
 		}
 	}
 
 	private void cascadeOnFlush(EventSource session, EntityPersister persister, Object object, Object anything)
 	throws HibernateException {
 		session.getPersistenceContext().incrementCascadeLevel();
 		try {
 			Cascade.cascade( getCascadingAction(), CascadePoint.BEFORE_FLUSH, session, persister, object, anything );
 		}
 		finally {
 			session.getPersistenceContext().decrementCascadeLevel();
 		}
 	}
 
 	protected Object getAnything() { return null; }
 
 	protected CascadingAction getCascadingAction() {
 		return CascadingActions.SAVE_UPDATE;
 	}
 
 	/**
 	 * Initialize the flags of the CollectionEntry, including the
 	 * dirty check.
 	 */
 	private void prepareCollectionFlushes(PersistenceContext persistenceContext) throws HibernateException {
 
 		// Initialize dirty flags for arrays + collections with composite elements
 		// and reset reached, doupdate, etc.
 
 		LOG.debug( "Dirty checking collections" );
 
 		for ( Map.Entry<PersistentCollection,CollectionEntry> entry :
 				IdentityMap.concurrentEntries( (Map<PersistentCollection,CollectionEntry>) persistenceContext.getCollectionEntries() )) {
 			entry.getValue().preFlush( entry.getKey() );
 		}
 	}
 
 	/**
 	 * 1. detect any dirty entities
 	 * 2. schedule any entity updates
 	 * 3. search out any reachable collections
 	 */
 	private int flushEntities(final FlushEvent event, final PersistenceContext persistenceContext) throws HibernateException {
 
 		LOG.trace( "Flushing entities and processing referenced collections" );
 
 		final EventSource source = event.getSession();
 		final Iterable<FlushEntityEventListener> flushListeners = source.getFactory().getServiceRegistry()
 				.getService( EventListenerRegistry.class )
 				.getEventListenerGroup( EventType.FLUSH_ENTITY )
 				.listeners();
 
 		// Among other things, updateReachables() will recursively load all
 		// collections that are moving roles. This might cause entities to
 		// be loaded.
 
 		// So this needs to be safe from concurrent modification problems.
 
 		final Map.Entry<Object,EntityEntry>[] entityEntries = persistenceContext.reentrantSafeEntityEntries();
 		final int count = entityEntries.length;
 
 		for ( Map.Entry<Object,EntityEntry> me : entityEntries ) {
 
 			// Update the status of the object and if necessary, schedule an update
 
 			EntityEntry entry = me.getValue();
 			Status status = entry.getStatus();
 
 			if ( status != Status.LOADING && status != Status.GONE ) {
 				final FlushEntityEvent entityEvent = new FlushEntityEvent( source, me.getKey(), entry );
 				for ( FlushEntityEventListener listener : flushListeners ) {
 					listener.onFlushEntity( entityEvent );
 				}
 			}
 		}
 
 		source.getActionQueue().sortActions();
 
 		return count;
 	}
 
 	/**
 	 * process any unreferenced collections and then inspect all known collections,
 	 * scheduling creates/removes/updates
 	 */
 	@SuppressWarnings("unchecked")
 	private int flushCollections(final EventSource session, final PersistenceContext persistenceContext) throws HibernateException {
 		LOG.trace( "Processing unreferenced collections" );
 
 		final Map.Entry<PersistentCollection,CollectionEntry>[] entries = IdentityMap.concurrentEntries(
 				(Map<PersistentCollection,CollectionEntry>) persistenceContext.getCollectionEntries()
 		);
 
 		final int count = entries.length;
 
 		for ( Map.Entry<PersistentCollection,CollectionEntry> me : entries ) {
 			CollectionEntry ce = me.getValue();
 			if ( !ce.isReached() && !ce.isIgnore() ) {
 				Collections.processUnreachableCollection( me.getKey(), session );
 			}
 		}
 
 		// Schedule updates to collections:
 
 		LOG.trace( "Scheduling collection removes/(re)creates/updates" );
 
 		ActionQueue actionQueue = session.getActionQueue();
 		for ( Map.Entry<PersistentCollection,CollectionEntry> me :
 			IdentityMap.concurrentEntries( (Map<PersistentCollection,CollectionEntry>) persistenceContext.getCollectionEntries() )) {
 			PersistentCollection coll = me.getKey();
 			CollectionEntry ce = me.getValue();
 
 			if ( ce.isDorecreate() ) {
 				session.getInterceptor().onCollectionRecreate( coll, ce.getCurrentKey() );
 				actionQueue.addAction(
 						new CollectionRecreateAction(
 								coll,
 								ce.getCurrentPersister(),
 								ce.getCurrentKey(),
 								session
 							)
 					);
 			}
 			if ( ce.isDoremove() ) {
 				session.getInterceptor().onCollectionRemove( coll, ce.getLoadedKey() );
 				actionQueue.addAction(
 						new CollectionRemoveAction(
 								coll,
 								ce.getLoadedPersister(),
 								ce.getLoadedKey(),
 								ce.isSnapshotEmpty(coll),
 								session
 							)
 					);
 			}
 			if ( ce.isDoupdate() ) {
 				session.getInterceptor().onCollectionUpdate( coll, ce.getLoadedKey() );
 				actionQueue.addAction(
 						new CollectionUpdateAction(
 								coll,
 								ce.getLoadedPersister(),
 								ce.getLoadedKey(),
 								ce.isSnapshotEmpty(coll),
 								session
 							)
 					);
 			}
 			if ( !coll.wasInitialized() && coll.hasQueuedOperations() ) {
 				actionQueue.addAction(
 						new QueuedOperationCollectionAction(
 								coll,
 								ce.getLoadedPersister(),
 								ce.getLoadedKey(),
 								session
 							)
 					);
 			}
 
 		}
 
 		actionQueue.sortCollectionActions();
 
 		return count;
 	}
 
 	/**
 	 * Execute all SQL (and second-level cache updates) in a special order so that foreign-key constraints cannot
 	 * be violated: <ol>
 	 * <li> Inserts, in the order they were performed
 	 * <li> Updates
 	 * <li> Deletion of collection elements
 	 * <li> Insertion of collection elements
 	 * <li> Deletes, in the order they were performed
 	 * </ol>
 	 *
 	 * @param session The session being flushed
 	 */
 	protected void performExecutions(EventSource session) {
 		LOG.trace( "Executing flush" );
 
 		// IMPL NOTE : here we alter the flushing flag of the persistence context to allow
 		//		during-flush callbacks more leniency in regards to initializing proxies and
 		//		lazy collections during their processing.
 		// For more information, see HHH-2763
 		try {
-			session.getTransactionCoordinator().getJdbcCoordinator().flushBeginning();
+			session.getJdbcCoordinator().flushBeginning();
 			session.getPersistenceContext().setFlushing( true );
 			// we need to lock the collection caches before executing entity inserts/updates in order to
 			// account for bi-directional associations
 			session.getActionQueue().prepareActions();
 			session.getActionQueue().executeActions();
 		}
 		finally {
 			session.getPersistenceContext().setFlushing( false );
-			session.getTransactionCoordinator().getJdbcCoordinator().flushEnding();
+			session.getJdbcCoordinator().flushEnding();
 		}
 	}
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// Post-flushing section
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * 1. Recreate the collection key -> collection map
 	 * 2. rebuild the collection entries
 	 * 3. call Interceptor.postFlush()
 	 */
 	protected void postFlush(SessionImplementor session) throws HibernateException {
 
 		LOG.trace( "Post flush" );
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		persistenceContext.getCollectionsByKey().clear();
 		
 		// the database has changed now, so the subselect results need to be invalidated
 		// the batch fetching queues should also be cleared - especially the collection batch fetching one
 		persistenceContext.getBatchFetchQueue().clear();
 
 		for ( Map.Entry<PersistentCollection, CollectionEntry> me : IdentityMap.concurrentEntries( persistenceContext.getCollectionEntries() ) ) {
 			CollectionEntry collectionEntry = me.getValue();
 			PersistentCollection persistentCollection = me.getKey();
 			collectionEntry.postFlush(persistentCollection);
 			if ( collectionEntry.getLoadedPersister() == null ) {
 				//if the collection is dereferenced, remove from the session cache
 				//iter.remove(); //does not work, since the entrySet is not backed by the set
 				persistenceContext.getCollectionEntries()
 						.remove(persistentCollection);
 			}
 			else {
 				//otherwise recreate the mapping between the collection and its key
 				CollectionKey collectionKey = new CollectionKey(
 						collectionEntry.getLoadedPersister(),
 						collectionEntry.getLoadedKey()
 				);
 				persistenceContext.getCollectionsByKey().put(collectionKey, persistentCollection);
 			}
 		}
 
 	}
 
 	protected void postPostFlush(SessionImplementor session) {
 		session.getInterceptor().postFlush( new LazyIterator( session.getPersistenceContext().getEntitiesByKey() ) );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractSaveEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractSaveEventListener.java
index b2e36a8577..1894cf20e2 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractSaveEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractSaveEventListener.java
@@ -1,546 +1,546 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.internal;
 
 import java.io.Serializable;
 import java.util.Map;
 
 import org.hibernate.LockMode;
 import org.hibernate.NonUniqueObjectException;
 import org.hibernate.action.internal.AbstractEntityInsertAction;
 import org.hibernate.action.internal.EntityIdentityInsertAction;
 import org.hibernate.action.internal.EntityInsertAction;
 import org.hibernate.bytecode.instrumentation.spi.FieldInterceptor;
 import org.hibernate.classic.Lifecycle;
 import org.hibernate.engine.internal.Cascade;
 import org.hibernate.engine.internal.CascadePoint;
 import org.hibernate.engine.internal.ForeignKeys;
 import org.hibernate.engine.internal.Versioning;
 import org.hibernate.engine.spi.CascadingAction;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.EntityEntryExtraState;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.Status;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.id.IdentifierGenerationException;
 import org.hibernate.id.IdentifierGeneratorHelper;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeHelper;
 
 /**
  * A convenience bas class for listeners responding to save events.
  *
  * @author Steve Ebersole.
  */
 public abstract class AbstractSaveEventListener extends AbstractReassociateEventListener {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( AbstractSaveEventListener.class );
 
 	public static enum EntityState {
 		PERSISTENT, TRANSIENT, DETACHED, DELETED
 	}
 
 	/**
 	 * Prepares the save call using the given requested id.
 	 *
 	 * @param entity The entity to be saved.
 	 * @param requestedId The id to which to associate the entity.
 	 * @param entityName The name of the entity being saved.
 	 * @param anything Generally cascade-specific information.
 	 * @param source The session which is the source of this save event.
 	 *
 	 * @return The id used to save the entity.
 	 */
 	protected Serializable saveWithRequestedId(
 			Object entity,
 			Serializable requestedId,
 			String entityName,
 			Object anything,
 			EventSource source) {
 		return performSave(
 				entity,
 				requestedId,
 				source.getEntityPersister( entityName, entity ),
 				false,
 				anything,
 				source,
 				true
 		);
 	}
 
 	/**
 	 * Prepares the save call using a newly generated id.
 	 *
 	 * @param entity The entity to be saved
 	 * @param entityName The entity-name for the entity to be saved
 	 * @param anything Generally cascade-specific information.
 	 * @param source The session which is the source of this save event.
 	 * @param requiresImmediateIdAccess does the event context require
 	 * access to the identifier immediately after execution of this method (if
 	 * not, post-insert style id generators may be postponed if we are outside
 	 * a transaction).
 	 *
 	 * @return The id used to save the entity; may be null depending on the
 	 *         type of id generator used and the requiresImmediateIdAccess value
 	 */
 	protected Serializable saveWithGeneratedId(
 			Object entity,
 			String entityName,
 			Object anything,
 			EventSource source,
 			boolean requiresImmediateIdAccess) {
 		EntityPersister persister = source.getEntityPersister( entityName, entity );
 		Serializable generatedId = persister.getIdentifierGenerator().generate( source, entity );
 		if ( generatedId == null ) {
 			throw new IdentifierGenerationException( "null id generated for:" + entity.getClass() );
 		}
 		else if ( generatedId == IdentifierGeneratorHelper.SHORT_CIRCUIT_INDICATOR ) {
 			return source.getIdentifier( entity );
 		}
 		else if ( generatedId == IdentifierGeneratorHelper.POST_INSERT_INDICATOR ) {
 			return performSave( entity, null, persister, true, anything, source, requiresImmediateIdAccess );
 		}
 		else {
 			// TODO: define toString()s for generators
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf(
 						"Generated identifier: %s, using strategy: %s",
 						persister.getIdentifierType().toLoggableString( generatedId, source.getFactory() ),
 						persister.getIdentifierGenerator().getClass().getName()
 				);
 			}
 
 			return performSave( entity, generatedId, persister, false, anything, source, true );
 		}
 	}
 
 	/**
 	 * Prepares the save call by checking the session caches for a pre-existing
 	 * entity and performing any lifecycle callbacks.
 	 *
 	 * @param entity The entity to be saved.
 	 * @param id The id by which to save the entity.
 	 * @param persister The entity's persister instance.
 	 * @param useIdentityColumn Is an identity column being used?
 	 * @param anything Generally cascade-specific information.
 	 * @param source The session from which the event originated.
 	 * @param requiresImmediateIdAccess does the event context require
 	 * access to the identifier immediately after execution of this method (if
 	 * not, post-insert style id generators may be postponed if we are outside
 	 * a transaction).
 	 *
 	 * @return The id used to save the entity; may be null depending on the
 	 *         type of id generator used and the requiresImmediateIdAccess value
 	 */
 	protected Serializable performSave(
 			Object entity,
 			Serializable id,
 			EntityPersister persister,
 			boolean useIdentityColumn,
 			Object anything,
 			EventSource source,
 			boolean requiresImmediateIdAccess) {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Saving {0}", MessageHelper.infoString( persister, id, source.getFactory() ) );
 		}
 
 		final EntityKey key;
 		if ( !useIdentityColumn ) {
 			key = source.generateEntityKey( id, persister );
 			Object old = source.getPersistenceContext().getEntity( key );
 			if ( old != null ) {
 				if ( source.getPersistenceContext().getEntry( old ).getStatus() == Status.DELETED ) {
 					source.forceFlush( source.getPersistenceContext().getEntry( old ) );
 				}
 				else {
 					throw new NonUniqueObjectException( id, persister.getEntityName() );
 				}
 			}
 			persister.setIdentifier( entity, id, source );
 		}
 		else {
 			key = null;
 		}
 
 		if ( invokeSaveLifecycle( entity, persister, source ) ) {
 			return id; //EARLY EXIT
 		}
 
 		return performSaveOrReplicate(
 				entity,
 				key,
 				persister,
 				useIdentityColumn,
 				anything,
 				source,
 				requiresImmediateIdAccess
 		);
 	}
 
 	protected boolean invokeSaveLifecycle(Object entity, EntityPersister persister, EventSource source) {
 		// Sub-insertions should occur before containing insertion so
 		// Try to do the callback now
 		if ( persister.implementsLifecycle() ) {
 			LOG.debug( "Calling onSave()" );
 			if ( ((Lifecycle) entity).onSave( source ) ) {
 				LOG.debug( "Insertion vetoed by onSave()" );
 				return true;
 			}
 		}
 		return false;
 	}
 
 	/**
 	 * Performs all the actual work needed to save an entity (well to get the save moved to
 	 * the execution queue).
 	 *
 	 * @param entity The entity to be saved
 	 * @param key The id to be used for saving the entity (or null, in the case of identity columns)
 	 * @param persister The entity's persister instance.
 	 * @param useIdentityColumn Should an identity column be used for id generation?
 	 * @param anything Generally cascade-specific information.
 	 * @param source The session which is the source of the current event.
 	 * @param requiresImmediateIdAccess Is access to the identifier required immediately
 	 * after the completion of the save?  persist(), for example, does not require this...
 	 *
 	 * @return The id used to save the entity; may be null depending on the
 	 *         type of id generator used and the requiresImmediateIdAccess value
 	 */
 	protected Serializable performSaveOrReplicate(
 			Object entity,
 			EntityKey key,
 			EntityPersister persister,
 			boolean useIdentityColumn,
 			Object anything,
 			EventSource source,
 			boolean requiresImmediateIdAccess) {
 
 		Serializable id = key == null ? null : key.getIdentifier();
 
-		boolean inTxn = source.getTransactionCoordinator().isTransactionInProgress();
+		boolean inTxn = source.isTransactionInProgress();
 		boolean shouldDelayIdentityInserts = !inTxn && !requiresImmediateIdAccess;
 
 		// Put a placeholder in entries, so we don't recurse back and try to save() the
 		// same object again. QUESTION: should this be done before onSave() is called?
 		// likewise, should it be done before onUpdate()?
 		EntityEntry original = source.getPersistenceContext().addEntry(
 				entity,
 				Status.SAVING,
 				null,
 				null,
 				id,
 				null,
 				LockMode.WRITE,
 				useIdentityColumn,
 				persister,
 				false,
 				false
 		);
 
 		cascadeBeforeSave( source, persister, entity, anything );
 
 		Object[] values = persister.getPropertyValuesToInsert( entity, getMergeMap( anything ), source );
 		Type[] types = persister.getPropertyTypes();
 
 		boolean substitute = substituteValuesIfNecessary( entity, id, values, persister, source );
 
 		if ( persister.hasCollections() ) {
 			substitute = substitute || visitCollectionsBeforeSave( entity, id, values, types, source );
 		}
 
 		if ( substitute ) {
 			persister.setPropertyValues( entity, values );
 		}
 
 		TypeHelper.deepCopy(
 				values,
 				types,
 				persister.getPropertyUpdateability(),
 				values,
 				source
 		);
 
 		AbstractEntityInsertAction insert = addInsertAction(
 				values, id, entity, persister, useIdentityColumn, source, shouldDelayIdentityInserts
 		);
 
 		// postpone initializing id in case the insert has non-nullable transient dependencies
 		// that are not resolved until cascadeAfterSave() is executed
 		cascadeAfterSave( source, persister, entity, anything );
 		if ( useIdentityColumn && insert.isEarlyInsert() ) {
 			if ( !EntityIdentityInsertAction.class.isInstance( insert ) ) {
 				throw new IllegalStateException(
 						"Insert should be using an identity column, but action is of unexpected type: " +
 								insert.getClass().getName()
 				);
 			}
 			id = ((EntityIdentityInsertAction) insert).getGeneratedId();
 
 			insert.handleNaturalIdPostSaveNotifications( id );
 		}
 
 		markInterceptorDirty( entity, persister, source );
 
 		EntityEntry newEntry = source.getPersistenceContext().getEntry( entity );
 
 		if ( newEntry != original ) {
 			EntityEntryExtraState extraState = newEntry.getExtraState( EntityEntryExtraState.class );
 			if ( extraState == null ) {
 				newEntry.addExtraState( original.getExtraState( EntityEntryExtraState.class ) );
 			}
 		}
 
 		return id;
 	}
 
 	private AbstractEntityInsertAction addInsertAction(
 			Object[] values,
 			Serializable id,
 			Object entity,
 			EntityPersister persister,
 			boolean useIdentityColumn,
 			EventSource source,
 			boolean shouldDelayIdentityInserts) {
 		if ( useIdentityColumn ) {
 			EntityIdentityInsertAction insert = new EntityIdentityInsertAction(
 					values, entity, persister, isVersionIncrementDisabled(), source, shouldDelayIdentityInserts
 			);
 			source.getActionQueue().addAction( insert );
 			return insert;
 		}
 		else {
 			Object version = Versioning.getVersion( values, persister );
 			EntityInsertAction insert = new EntityInsertAction(
 					id, values, entity, version, persister, isVersionIncrementDisabled(), source
 			);
 			source.getActionQueue().addAction( insert );
 			return insert;
 		}
 	}
 
 	private void markInterceptorDirty(Object entity, EntityPersister persister, EventSource source) {
 		if ( persister.getInstrumentationMetadata().isInstrumented() ) {
 			FieldInterceptor interceptor = persister.getInstrumentationMetadata().injectInterceptor(
 					entity,
 					persister.getEntityName(),
 					null,
 					source
 			);
 			interceptor.dirty();
 		}
 	}
 
 	protected Map getMergeMap(Object anything) {
 		return null;
 	}
 
 	/**
 	 * After the save, will te version number be incremented
 	 * if the instance is modified?
 	 *
 	 * @return True if the version will be incremented on an entity change after save;
 	 *         false otherwise.
 	 */
 	protected boolean isVersionIncrementDisabled() {
 		return false;
 	}
 
 	protected boolean visitCollectionsBeforeSave(
 			Object entity,
 			Serializable id,
 			Object[] values,
 			Type[] types,
 			EventSource source) {
 		WrapVisitor visitor = new WrapVisitor( source );
 		// substitutes into values by side-effect
 		visitor.processEntityPropertyValues( values, types );
 		return visitor.isSubstitutionRequired();
 	}
 
 	/**
 	 * Perform any property value substitution that is necessary
 	 * (interceptor callback, version initialization...)
 	 *
 	 * @param entity The entity
 	 * @param id The entity identifier
 	 * @param values The snapshot entity state
 	 * @param persister The entity persister
 	 * @param source The originating session
 	 *
 	 * @return True if the snapshot state changed such that
 	 *         reinjection of the values into the entity is required.
 	 */
 	protected boolean substituteValuesIfNecessary(
 			Object entity,
 			Serializable id,
 			Object[] values,
 			EntityPersister persister,
 			SessionImplementor source) {
 		boolean substitute = source.getInterceptor().onSave(
 				entity,
 				id,
 				values,
 				persister.getPropertyNames(),
 				persister.getPropertyTypes()
 		);
 
 		//keep the existing version number in the case of replicate!
 		if ( persister.isVersioned() ) {
 			substitute = Versioning.seedVersion(
 					values,
 					persister.getVersionProperty(),
 					persister.getVersionType(),
 					source
 			) || substitute;
 		}
 		return substitute;
 	}
 
 	/**
 	 * Handles the calls needed to perform pre-save cascades for the given entity.
 	 *
 	 * @param source The session from whcih the save event originated.
 	 * @param persister The entity's persister instance.
 	 * @param entity The entity to be saved.
 	 * @param anything Generally cascade-specific data
 	 */
 	protected void cascadeBeforeSave(
 			EventSource source,
 			EntityPersister persister,
 			Object entity,
 			Object anything) {
 
 		// cascade-save to many-to-one BEFORE the parent is saved
 		source.getPersistenceContext().incrementCascadeLevel();
 		try {
 			Cascade.cascade(
 					getCascadeAction(),
 					CascadePoint.BEFORE_INSERT_AFTER_DELETE,
 					source,
 					persister,
 					entity,
 					anything
 			);
 		}
 		finally {
 			source.getPersistenceContext().decrementCascadeLevel();
 		}
 	}
 
 	/**
 	 * Handles to calls needed to perform post-save cascades.
 	 *
 	 * @param source The session from which the event originated.
 	 * @param persister The entity's persister instance.
 	 * @param entity The entity beng saved.
 	 * @param anything Generally cascade-specific data
 	 */
 	protected void cascadeAfterSave(
 			EventSource source,
 			EntityPersister persister,
 			Object entity,
 			Object anything) {
 
 		// cascade-save to collections AFTER the collection owner was saved
 		source.getPersistenceContext().incrementCascadeLevel();
 		try {
 			Cascade.cascade(
 					getCascadeAction(),
 					CascadePoint.AFTER_INSERT_BEFORE_DELETE,
 					source,
 					persister,
 					entity,
 					anything
 			);
 		}
 		finally {
 			source.getPersistenceContext().decrementCascadeLevel();
 		}
 	}
 
 	protected abstract CascadingAction getCascadeAction();
 
 	/**
 	 * Determine whether the entity is persistent, detached, or transient
 	 *
 	 * @param entity The entity to check
 	 * @param entityName The name of the entity
 	 * @param entry The entity's entry in the persistence context
 	 * @param source The originating session.
 	 *
 	 * @return The state.
 	 */
 	protected EntityState getEntityState(
 			Object entity,
 			String entityName,
 			EntityEntry entry, //pass this as an argument only to avoid double looking
 			SessionImplementor source) {
 
 		final boolean traceEnabled = LOG.isTraceEnabled();
 		if ( entry != null ) { // the object is persistent
 
 			//the entity is associated with the session, so check its status
 			if ( entry.getStatus() != Status.DELETED ) {
 				// do nothing for persistent instances
 				if ( traceEnabled ) {
 					LOG.tracev( "Persistent instance of: {0}", getLoggableName( entityName, entity ) );
 				}
 				return EntityState.PERSISTENT;
 			}
 			// ie. e.status==DELETED
 			if ( traceEnabled ) {
 				LOG.tracev( "Deleted instance of: {0}", getLoggableName( entityName, entity ) );
 			}
 			return EntityState.DELETED;
 		}
 		// the object is transient or detached
 
 		// the entity is not associated with the session, so
 		// try interceptor and unsaved-value
 
 		if ( ForeignKeys.isTransient( entityName, entity, getAssumedUnsaved(), source ) ) {
 			if ( traceEnabled ) {
 				LOG.tracev( "Transient instance of: {0}", getLoggableName( entityName, entity ) );
 			}
 			return EntityState.TRANSIENT;
 		}
 		if ( traceEnabled ) {
 			LOG.tracev( "Detached instance of: {0}", getLoggableName( entityName, entity ) );
 		}
 		return EntityState.DETACHED;
 	}
 
 	protected String getLoggableName(String entityName, Object entity) {
 		return entityName == null ? entity.getClass().getName() : entityName;
 	}
 
 	protected Boolean getAssumedUnsaved() {
 		return null;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/exec/BasicExecutor.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/exec/BasicExecutor.java
index d8b574ae55..4bb2d3a434 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/exec/BasicExecutor.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/exec/BasicExecutor.java
@@ -1,121 +1,122 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.exec;
 
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Iterator;
 import java.util.List;
 
 import org.hibernate.HibernateException;
 import org.hibernate.action.internal.BulkOperationCleanupAction;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.hql.internal.ast.HqlSqlWalker;
 import org.hibernate.hql.internal.ast.QuerySyntaxException;
 import org.hibernate.hql.internal.ast.SqlGenerator;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.persister.entity.Queryable;
 
 import antlr.RecognitionException;
 
 /**
  * Implementation of BasicExecutor.
  *
  * @author Steve Ebersole
  */
 public class BasicExecutor implements StatementExecutor {
 	private final SessionFactoryImplementor factory;
 	private final Queryable persister;
 	private final String sql;
 	private final List parameterSpecifications;
 
 	public BasicExecutor(HqlSqlWalker walker, Queryable persister) {
 		this.factory = walker.getSessionFactoryHelper().getFactory();
 		this.persister = persister;
 		try {
 			SqlGenerator gen = new SqlGenerator( factory );
 			gen.statement( walker.getAST() );
 			sql = gen.getSQL();
 			gen.getParseErrorHandler().throwQueryException();
 			parameterSpecifications = gen.getCollectedParameters();
 		}
 		catch ( RecognitionException e ) {
 			throw QuerySyntaxException.convert( e );
 		}
 	}
 
 	public String[] getSqlStatements() {
 		return new String[] { sql };
 	}
 
 	public int execute(QueryParameters parameters, SessionImplementor session) throws HibernateException {
 		return doExecute( parameters, session, sql, parameterSpecifications );
 	}
 	
 	protected int doExecute(QueryParameters parameters, SessionImplementor session, String sql,
 			List parameterSpecifications) throws HibernateException {
 		BulkOperationCleanupAction action = new BulkOperationCleanupAction( session, persister );
 		if ( session.isEventSource() ) {
 			( (EventSource) session ).getActionQueue().addAction( action );
 		}
 		else {
 			action.getAfterTransactionCompletionProcess().doAfterTransactionCompletion( true, session );
 		}
 
 		PreparedStatement st = null;
 		RowSelection selection = parameters.getRowSelection();
 
 		try {
 			try {
-				st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql, false );
+				st = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( sql, false );
 				Iterator paramSpecItr = parameterSpecifications.iterator();
 				int pos = 1;
 				while ( paramSpecItr.hasNext() ) {
 					final ParameterSpecification paramSpec = (ParameterSpecification) paramSpecItr.next();
 					pos += paramSpec.bind( st, parameters, session, pos );
 				}
 				if ( selection != null ) {
 					if ( selection.getTimeout() != null ) {
 						st.setQueryTimeout( selection.getTimeout() );
 					}
 				}
 
-				return session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st );
+				return session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st );
 			}
 			finally {
 				if ( st != null ) {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+					session.getJdbcCoordinator().getResourceRegistry().release( st );
+					session.getJdbcCoordinator().afterStatementExecution();
 				}
 			}
 		}
 		catch( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert( sqle, "could not execute update query", sql );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/spi/id/TableBasedDeleteHandlerImpl.java b/hibernate-core/src/main/java/org/hibernate/hql/spi/id/TableBasedDeleteHandlerImpl.java
index a0c12ed817..b77283b466 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/spi/id/TableBasedDeleteHandlerImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/spi/id/TableBasedDeleteHandlerImpl.java
@@ -1,187 +1,189 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.spi.id;
 
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.List;
 
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.hql.internal.ast.HqlSqlWalker;
 import org.hibernate.hql.internal.ast.tree.DeleteStatement;
 import org.hibernate.hql.internal.ast.tree.FromElement;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.persister.collection.AbstractCollectionPersister;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.Delete;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
 * @author Steve Ebersole
 */
 public class TableBasedDeleteHandlerImpl
 		extends AbstractTableBasedBulkIdHandler
 		implements MultiTableBulkIdStrategy.DeleteHandler {
 	private static final Logger log = Logger.getLogger( TableBasedDeleteHandlerImpl.class );
 
 	private final Queryable targetedPersister;
 
 	private final String idInsertSelect;
 	private final List<ParameterSpecification> idSelectParameterSpecifications;
 	private final List<String> deletes;
 
 	public TableBasedDeleteHandlerImpl(
 			SessionFactoryImplementor factory,
 			HqlSqlWalker walker,
 			IdTableInfo idTableInfo) {
 		super( factory, walker );
 
 		DeleteStatement deleteStatement = ( DeleteStatement ) walker.getAST();
 		FromElement fromElement = deleteStatement.getFromClause().getFromElement();
 
 		this.targetedPersister = fromElement.getQueryable();
 		final String bulkTargetAlias = fromElement.getTableAlias();
 
 		final ProcessedWhereClause processedWhereClause = processWhereClause( deleteStatement.getWhereClause() );
 		this.idSelectParameterSpecifications = processedWhereClause.getIdSelectParameterSpecifications();
 		this.idInsertSelect = generateIdInsertSelect( bulkTargetAlias, idTableInfo, processedWhereClause );
 		log.tracev( "Generated ID-INSERT-SELECT SQL (multi-table delete) : {0}", idInsertSelect );
 		
 		final String idSubselect = generateIdSubselect( targetedPersister, idTableInfo );
 		deletes = new ArrayList<String>();
 		
 		// If many-to-many, delete the FK row in the collection table.
 		// This partially overlaps with DeleteExecutor, but it instead uses the temp table in the idSubselect.
 		for ( Type type : targetedPersister.getPropertyTypes() ) {
 			if ( type.isCollectionType() ) {
 				CollectionType cType = (CollectionType) type;
 				AbstractCollectionPersister cPersister = (AbstractCollectionPersister)factory.getCollectionPersister( cType.getRole() );
 				if ( cPersister.isManyToMany() ) {
 					deletes.add( generateDelete( cPersister.getTableName(),
 							cPersister.getKeyColumnNames(), idSubselect, "bulk delete - m2m join table cleanup"));
 				}
 			}
 		}
 
 		String[] tableNames = targetedPersister.getConstraintOrderedTableNameClosure();
 		String[][] columnNames = targetedPersister.getContraintOrderedTableKeyColumnClosure();
 		for ( int i = 0; i < tableNames.length; i++ ) {
 			// TODO : an optimization here would be to consider cascade deletes and not gen those delete statements;
 			//      the difficulty is the ordering of the tables here vs the cascade attributes on the persisters ->
 			//          the table info gotten here should really be self-contained (i.e., a class representation
 			//          defining all the needed attributes), then we could then get an array of those
 			deletes.add( generateDelete( tableNames[i], columnNames[i], idSubselect, "bulk delete"));
 		}
 	}
 	
 	private String generateDelete(String tableName, String[] columnNames, String idSubselect, String comment) {
 		final Delete delete = new Delete()
 				.setTableName( tableName )
 				.setWhere( "(" + StringHelper.join( ", ", columnNames ) + ") IN (" + idSubselect + ")" );
 		if ( factory().getSettings().isCommentsEnabled() ) {
 			delete.setComment( comment );
 		}
 		return delete.toStatementString();
 	}
 
 	@Override
 	public Queryable getTargetedQueryable() {
 		return targetedPersister;
 	}
 
 	@Override
 	public String[] getSqlStatements() {
 		return deletes.toArray( new String[deletes.size()] );
 	}
 
 	@Override
 	public int execute(SessionImplementor session, QueryParameters queryParameters) {
 		prepareForUse( targetedPersister, session );
 		try {
 			PreparedStatement ps = null;
 			int resultCount = 0;
 			try {
 				try {
-					ps = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( idInsertSelect, false );
+					ps = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( idInsertSelect, false );
 					int pos = 1;
 					pos += handlePrependedParametersOnIdSelection( ps, session, pos );
 					for ( ParameterSpecification parameterSpecification : idSelectParameterSpecifications ) {
 						pos += parameterSpecification.bind( ps, queryParameters, session, pos );
 					}
-					resultCount = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( ps );
+					resultCount = session.getJdbcCoordinator().getResultSetReturn().executeUpdate( ps );
 				}
 				finally {
 					if ( ps != null ) {
-						session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
+						session.getJdbcCoordinator().getResourceRegistry().release( ps );
+						session.getJdbcCoordinator().afterStatementExecution();
 					}
 				}
 			}
 			catch( SQLException e ) {
 				throw convert( e, "could not insert/select ids for bulk delete", idInsertSelect );
 			}
 
 			// Start performing the deletes
 			for ( String delete : deletes ) {
 				try {
 					try {
-						ps = session.getTransactionCoordinator()
+						ps = session
 								.getJdbcCoordinator()
 								.getStatementPreparer()
 								.prepareStatement( delete, false );
 						handleAddedParametersOnDelete( ps, session );
-						session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( ps );
+						session.getJdbcCoordinator().getResultSetReturn().executeUpdate( ps );
 					}
 					finally {
 						if ( ps != null ) {
-							session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
+							session.getJdbcCoordinator().getResourceRegistry().release( ps );
+							session.getJdbcCoordinator().afterStatementExecution();
 						}
 					}
 				}
 				catch (SQLException e) {
 					throw convert( e, "error performing bulk delete", delete );
 				}
 			}
 
 			return resultCount;
 
 		}
 		finally {
 			releaseFromUse( targetedPersister, session );
 		}
 	}
 
 	protected int handlePrependedParametersOnIdSelection(PreparedStatement ps, SessionImplementor session, int pos) throws SQLException {
 		return 0;
 	}
 
 	protected void handleAddedParametersOnDelete(PreparedStatement ps, SessionImplementor session) throws SQLException {
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/spi/id/TableBasedUpdateHandlerImpl.java b/hibernate-core/src/main/java/org/hibernate/hql/spi/id/TableBasedUpdateHandlerImpl.java
index 6f858d27c7..f42f58d01a 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/spi/id/TableBasedUpdateHandlerImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/spi/id/TableBasedUpdateHandlerImpl.java
@@ -1,192 +1,194 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.spi.id;
 
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
 
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.hql.internal.ast.HqlSqlWalker;
 import org.hibernate.hql.internal.ast.tree.AssignmentSpecification;
 import org.hibernate.hql.internal.ast.tree.FromElement;
 import org.hibernate.hql.internal.ast.tree.UpdateStatement;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.Update;
 
 import org.jboss.logging.Logger;
 
 /**
 * @author Steve Ebersole
 */
 public class TableBasedUpdateHandlerImpl
 		extends AbstractTableBasedBulkIdHandler
 		implements MultiTableBulkIdStrategy.UpdateHandler {
 
 	private static final Logger log = Logger.getLogger( TableBasedUpdateHandlerImpl.class );
 
 	private final Queryable targetedPersister;
 
 	private final String idInsertSelect;
 	private final List<ParameterSpecification> idSelectParameterSpecifications;
 
 	private final String[] updates;
 	private final ParameterSpecification[][] assignmentParameterSpecifications;
 
 	@SuppressWarnings("unchecked")
 	public TableBasedUpdateHandlerImpl(
 			SessionFactoryImplementor factory,
 			HqlSqlWalker walker,
 			IdTableInfo idTableInfo) {
 		super( factory, walker );
 
 		UpdateStatement updateStatement = ( UpdateStatement ) walker.getAST();
 		FromElement fromElement = updateStatement.getFromClause().getFromElement();
 
 		this.targetedPersister = fromElement.getQueryable();
 
 		final String bulkTargetAlias = fromElement.getTableAlias();
 
 		final ProcessedWhereClause processedWhereClause = processWhereClause( updateStatement.getWhereClause() );
 		this.idSelectParameterSpecifications = processedWhereClause.getIdSelectParameterSpecifications();
 		this.idInsertSelect = generateIdInsertSelect( bulkTargetAlias, idTableInfo, processedWhereClause );
 		log.tracev( "Generated ID-INSERT-SELECT SQL (multi-table update) : {0}", idInsertSelect );
 
 		String[] tableNames = targetedPersister.getConstraintOrderedTableNameClosure();
 		String[][] columnNames = targetedPersister.getContraintOrderedTableKeyColumnClosure();
 		String idSubselect = generateIdSubselect( targetedPersister, idTableInfo );
 
 		updates = new String[tableNames.length];
 		assignmentParameterSpecifications = new ParameterSpecification[tableNames.length][];
 		for ( int tableIndex = 0; tableIndex < tableNames.length; tableIndex++ ) {
 			boolean affected = false;
 			final List<ParameterSpecification> parameterList = new ArrayList<ParameterSpecification>();
 			final Update update = new Update( factory().getDialect() )
 					.setTableName( tableNames[tableIndex] )
 					.setWhere( "(" + StringHelper.join( ", ", columnNames[tableIndex] ) + ") IN (" + idSubselect + ")" );
 			if ( factory().getSettings().isCommentsEnabled() ) {
 				update.setComment( "bulk update" );
 			}
 			final List<AssignmentSpecification> assignmentSpecifications = walker.getAssignmentSpecifications();
 			for ( AssignmentSpecification assignmentSpecification : assignmentSpecifications ) {
 				if ( assignmentSpecification.affectsTable( tableNames[tableIndex] ) ) {
 					affected = true;
 					update.appendAssignmentFragment( assignmentSpecification.getSqlAssignmentFragment() );
 					if ( assignmentSpecification.getParameters() != null ) {
 						Collections.addAll( parameterList, assignmentSpecification.getParameters() );
 					}
 				}
 			}
 			if ( affected ) {
 				updates[tableIndex] = update.toStatementString();
 				assignmentParameterSpecifications[tableIndex] = parameterList.toArray( new ParameterSpecification[parameterList.size()] );
 			}
 		}
 	}
 
 	@Override
 	public Queryable getTargetedQueryable() {
 		return targetedPersister;
 	}
 
 	@Override
 	public String[] getSqlStatements() {
 		return updates;
 	}
 
 	@Override
 	public int execute(SessionImplementor session, QueryParameters queryParameters) {
 		prepareForUse( targetedPersister, session );
 		try {
 			// First, save off the pertinent ids, as the return value
 			PreparedStatement ps = null;
 			int resultCount = 0;
 			try {
 				try {
-					ps = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( idInsertSelect, false );
+					ps = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( idInsertSelect, false );
 					int sum = 1;
 					sum += handlePrependedParametersOnIdSelection( ps, session, sum );
 					for ( ParameterSpecification parameterSpecification : idSelectParameterSpecifications ) {
 						sum += parameterSpecification.bind( ps, queryParameters, session, sum );
 					}
-					resultCount = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( ps );
+					resultCount = session.getJdbcCoordinator().getResultSetReturn().executeUpdate( ps );
 				}
 				finally {
 					if ( ps != null ) {
-						session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
+						session.getJdbcCoordinator().getResourceRegistry().release( ps );
+						session.getJdbcCoordinator().afterStatementExecution();
 					}
 				}
 			}
 			catch( SQLException e ) {
 				throw convert( e, "could not insert/select ids for bulk update", idInsertSelect );
 			}
 
 			// Start performing the updates
 			for ( int i = 0; i < updates.length; i++ ) {
 				if ( updates[i] == null ) {
 					continue;
 				}
 				try {
 					try {
-						ps = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( updates[i], false );
+						ps = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( updates[i], false );
 						if ( assignmentParameterSpecifications[i] != null ) {
 							int position = 1; // jdbc params are 1-based
 							for ( int x = 0; x < assignmentParameterSpecifications[i].length; x++ ) {
 								position += assignmentParameterSpecifications[i][x].bind( ps, queryParameters, session, position );
 							}
 							handleAddedParametersOnUpdate( ps, session, position );
 						}
-						session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( ps );
+						session.getJdbcCoordinator().getResultSetReturn().executeUpdate( ps );
 					}
 					finally {
 						if ( ps != null ) {
-							session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
+							session.getJdbcCoordinator().getResourceRegistry().release( ps );
+							session.getJdbcCoordinator().afterStatementExecution();
 						}
 					}
 				}
 				catch( SQLException e ) {
 					throw convert( e, "error performing bulk update", updates[i] );
 				}
 			}
 
 			return resultCount;
 		}
 		finally {
 			releaseFromUse( targetedPersister, session );
 		}
 	}
 
 	protected int handlePrependedParametersOnIdSelection(PreparedStatement ps, SessionImplementor session, int pos) throws SQLException {
 		return 0;
 	}
 
 	protected void handleAddedParametersOnUpdate(PreparedStatement ps, SessionImplementor session, int position) throws SQLException {
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/spi/id/local/Helper.java b/hibernate-core/src/main/java/org/hibernate/hql/spi/id/local/Helper.java
index 0c2e505745..ae3a65818a 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/spi/id/local/Helper.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/spi/id/local/Helper.java
@@ -1,222 +1,214 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2015, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.spi.id.local;
 
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.SQLWarning;
 import java.sql.Statement;
 
 import org.hibernate.boot.TempTableDdlTransactionHandling;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.jdbc.AbstractWork;
 
 /**
  * @author Steve Ebersole
  */
 public class Helper {
 	/**
 	 * Singleton access
 	 */
 	public static final Helper INSTANCE = new Helper();
 
 	private static final CoreMessageLogger log = CoreLogging.messageLogger( Helper.class );
 
 	private Helper() {
 	}
 
 
 	public void createTempTable(
 			IdTableInfoImpl idTableInfo,
 			TempTableDdlTransactionHandling ddlTransactionHandling,
 			SessionImplementor session) {
 		// Don't really know all the codes required to adequately decipher returned jdbc exceptions here.
 		// simply allow the failure to be eaten and the subsequent insert-selects/deletes should fail
 		TemporaryTableCreationWork work = new TemporaryTableCreationWork( idTableInfo, session.getFactory() );
 
 		if ( ddlTransactionHandling == TempTableDdlTransactionHandling.NONE ) {
-			final Connection connection = session.getTransactionCoordinator()
-					.getJdbcCoordinator()
+			final Connection connection = session.getJdbcCoordinator()
 					.getLogicalConnection()
-					.getConnection();
+					.getPhysicalConnection();
 
 			work.execute( connection );
 
-			session.getTransactionCoordinator()
-					.getJdbcCoordinator()
-					.afterStatementExecution();
+			session.getJdbcCoordinator().afterStatementExecution();
 		}
 		else {
 			session.getTransactionCoordinator()
-					.getTransaction()
 					.createIsolationDelegate()
 					.delegateWork( work, ddlTransactionHandling == TempTableDdlTransactionHandling.ISOLATE_AND_TRANSACT );
 		}
 	}
 
 	private static class TemporaryTableCreationWork extends AbstractWork {
 		private final IdTableInfoImpl idTableInfo;
 		private final SessionFactoryImplementor factory;
 
 		private TemporaryTableCreationWork(IdTableInfoImpl idTableInfo, SessionFactoryImplementor factory) {
 			this.idTableInfo = idTableInfo;
 			this.factory = factory;
 		}
 
 		@Override
 		public void execute(Connection connection) {
 			try {
 				Statement statement = connection.createStatement();
 				try {
 					statement.executeUpdate( idTableInfo.getIdTableCreationStatement() );
 					factory.getServiceRegistry()
 							.getService( JdbcServices.class )
 							.getSqlExceptionHelper()
 							.handleAndClearWarnings( statement, WARNING_HANDLER );
 				}
 				finally {
 					try {
 						statement.close();
 					}
 					catch( Throwable ignore ) {
 						// ignore
 					}
 				}
 			}
 			catch( Exception e ) {
 				log.debug( "unable to create temporary id table [" + e.getMessage() + "]" );
 			}
 		}
 	}
 
 	private static SqlExceptionHelper.WarningHandler WARNING_HANDLER = new SqlExceptionHelper.WarningHandlerLoggingSupport() {
 		public boolean doProcess() {
 			return log.isDebugEnabled();
 		}
 
 		public void prepare(SQLWarning warning) {
 			log.warningsCreatingTempTable( warning );
 		}
 
 		@Override
 		protected void logWarning(String description, String message) {
 			log.debug( description );
 			log.debug( message );
 		}
 	};
 
 	protected void releaseTempTable(
 			IdTableInfoImpl idTableInfo,
 			AfterUseAction afterUseAction,
 			TempTableDdlTransactionHandling ddlTransactionHandling,
 			SessionImplementor session) {
 		if ( afterUseAction == AfterUseAction.NONE ) {
 			return;
 		}
 
 		if ( afterUseAction == AfterUseAction.DROP ) {
 			TemporaryTableDropWork work = new TemporaryTableDropWork( idTableInfo, session.getFactory() );
 			if ( ddlTransactionHandling == TempTableDdlTransactionHandling.NONE ) {
-				final Connection connection = session.getTransactionCoordinator()
-						.getJdbcCoordinator()
+				final Connection connection = session.getJdbcCoordinator()
 						.getLogicalConnection()
-						.getConnection();
+						.getPhysicalConnection();
 
 				work.execute( connection );
 
-				session.getTransactionCoordinator()
-						.getJdbcCoordinator()
-						.afterStatementExecution();
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 			else {
 				session.getTransactionCoordinator()
-						.getTransaction()
 						.createIsolationDelegate()
 						.delegateWork( work, ddlTransactionHandling == TempTableDdlTransactionHandling.ISOLATE_AND_TRANSACT );
 			}
 		}
 
 		if ( afterUseAction == AfterUseAction.CLEAN ) {
 			PreparedStatement ps = null;
 			try {
 				final String sql = "delete from " + idTableInfo.getQualifiedIdTableName();
-				ps = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql, false );
-				session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( ps );
+				ps = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( sql, false );
+				session.getJdbcCoordinator().getResultSetReturn().executeUpdate( ps );
 			}
 			catch( Throwable t ) {
 				log.unableToCleanupTemporaryIdTable(t);
 			}
 			finally {
 				if ( ps != null ) {
 					try {
-						session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
+						session.getJdbcCoordinator().getResourceRegistry().release( ps );
 					}
 					catch( Throwable ignore ) {
 						// ignore
 					}
 				}
 			}
 		}
 	}
 
 	private static class TemporaryTableDropWork extends AbstractWork {
 		private final IdTableInfoImpl idTableInfo;
 		private final SessionFactoryImplementor factory;
 
 		private TemporaryTableDropWork(IdTableInfoImpl idTableInfo, SessionFactoryImplementor factory) {
 			this.idTableInfo = idTableInfo;
 			this.factory = factory;
 		}
 
 		@Override
 		public void execute(Connection connection) {
 			try {
 				Statement statement = connection.createStatement();
 				try {
 					statement.executeUpdate( idTableInfo.getIdTableDropStatement() );
 					factory.getServiceRegistry()
 							.getService( JdbcServices.class )
 							.getSqlExceptionHelper()
 							.handleAndClearWarnings( statement, WARNING_HANDLER );
 				}
 				finally {
 					try {
 						statement.close();
 					}
 					catch( Throwable ignore ) {
 						// ignore
 					}
 				}
 			}
 			catch( Exception e ) {
 				log.warn( "unable to drop temporary id table after use [" + e.getMessage() + "]" );
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/GUIDGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/GUIDGenerator.java
index 6c1646d613..a072bd3ea8 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/GUIDGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/GUIDGenerator.java
@@ -1,84 +1,85 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 
 /**
  * Generates <tt>string</tt> values using the SQL Server NEWID() function.
  *
  * @author Joseph Fifield
  */
 public class GUIDGenerator implements IdentifierGenerator {
     private static final CoreMessageLogger LOG = CoreLogging.messageLogger( GUIDGenerator.class );
 
 	private static boolean WARNED;
 
 	public GUIDGenerator() {
 		if ( !WARNED ) {
 			WARNED = true;
             LOG.deprecatedUuidGenerator( UUIDGenerator.class.getName(), UUIDGenerationStrategy.class.getName() );
 		}
 	}
 
 	public Serializable generate(SessionImplementor session, Object obj) throws HibernateException {
 		final String sql = session.getFactory().getDialect().getSelectGUIDString();
 		try {
-			PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
+			PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 			try {
-				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
+				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 				final String result;
 				try {
 					if ( !rs.next() ) {
 						throw new HibernateException( "The database returned no GUID identity value" );
 					}
 					result = rs.getString(1);
 				}
 				finally {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
+					session.getJdbcCoordinator().getResourceRegistry().release( rs, st );
 				}
                 LOG.guidGenerated(result);
 				return result;
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+				session.getJdbcCoordinator().getResourceRegistry().release( st );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not retrieve GUID",
 					sql
 				);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/IdentityGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/IdentityGenerator.java
index 943fde8249..b47085a50d 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/IdentityGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/IdentityGenerator.java
@@ -1,196 +1,196 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.id;
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.id.insert.AbstractReturningDelegate;
 import org.hibernate.id.insert.AbstractSelectingDelegate;
 import org.hibernate.id.insert.IdentifierGeneratingInsert;
 import org.hibernate.id.insert.InsertGeneratedIdentifierDelegate;
 import org.hibernate.id.insert.InsertSelectIdentityInsert;
 
 /**
  * A generator for use with ANSI-SQL IDENTITY columns used as the primary key.
  * The IdentityGenerator for autoincrement/identity key generation.
  * <br><br>
  * Indicates to the <tt>Session</tt> that identity (ie. identity/autoincrement
  * column) key generation should be used.
  *
  * @author Christoph Sturm
  */
 public class IdentityGenerator extends AbstractPostInsertGenerator {
 
 	public InsertGeneratedIdentifierDelegate getInsertGeneratedIdentifierDelegate(
 			PostInsertIdentityPersister persister,
 	        Dialect dialect,
 	        boolean isGetGeneratedKeysEnabled) throws HibernateException {
 		if ( isGetGeneratedKeysEnabled ) {
 			return new GetGeneratedKeysDelegate( persister, dialect );
 		}
 		else if ( dialect.supportsInsertSelectIdentity() ) {
 			return new InsertSelectDelegate( persister, dialect );
 		}
 		else {
 			return new BasicDelegate( persister, dialect );
 		}
 	}
 
 	/**
 	 * Delegate for dealing with IDENTITY columns using JDBC3 getGeneratedKeys
 	 */
 	public static class GetGeneratedKeysDelegate
 			extends AbstractReturningDelegate
 			implements InsertGeneratedIdentifierDelegate {
 		private final PostInsertIdentityPersister persister;
 		private final Dialect dialect;
 
 		public GetGeneratedKeysDelegate(PostInsertIdentityPersister persister, Dialect dialect) {
 			super( persister );
 			this.persister = persister;
 			this.dialect = dialect;
 		}
 
 		public IdentifierGeneratingInsert prepareIdentifierGeneratingInsert() {
 			IdentifierGeneratingInsert insert = new IdentifierGeneratingInsert( dialect );
 			insert.addIdentityColumn( persister.getRootTableKeyColumnNames()[0] );
 			return insert;
 		}
 
 		protected PreparedStatement prepare(String insertSQL, SessionImplementor session) throws SQLException {
-			return session.getTransactionCoordinator()
+			return session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( insertSQL, PreparedStatement.RETURN_GENERATED_KEYS );
 		}
 
 		public Serializable executeAndExtract(PreparedStatement insert, SessionImplementor session) throws SQLException {
-			session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( insert );
+			session.getJdbcCoordinator().getResultSetReturn().executeUpdate( insert );
 			ResultSet rs = null;
 			try {
 				rs = insert.getGeneratedKeys();
 				return IdentifierGeneratorHelper.getGeneratedIdentity(
 						rs,
 						persister.getRootTableKeyColumnNames()[0],
 						persister.getIdentifierType()
 				);
 			}
 			finally {
 				if ( rs != null ) {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, insert );
+					session.getJdbcCoordinator().getResourceRegistry().release( rs, insert );
 				}
 			}
 		}
 	}
 
 	/**
 	 * Delegate for dealing with IDENTITY columns where the dialect supports returning
 	 * the generated IDENTITY value directly from the insert statement.
 	 */
 	public static class InsertSelectDelegate
 			extends AbstractReturningDelegate
 			implements InsertGeneratedIdentifierDelegate {
 		private final PostInsertIdentityPersister persister;
 		private final Dialect dialect;
 
 		public InsertSelectDelegate(PostInsertIdentityPersister persister, Dialect dialect) {
 			super( persister );
 			this.persister = persister;
 			this.dialect = dialect;
 		}
 
 		public IdentifierGeneratingInsert prepareIdentifierGeneratingInsert() {
 			InsertSelectIdentityInsert insert = new InsertSelectIdentityInsert( dialect );
 			insert.addIdentityColumn( persister.getRootTableKeyColumnNames()[0] );
 			return insert;
 		}
 
 		protected PreparedStatement prepare(String insertSQL, SessionImplementor session) throws SQLException {
-			return session.getTransactionCoordinator()
+			return session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( insertSQL, PreparedStatement.NO_GENERATED_KEYS );
 		}
 
 		public Serializable executeAndExtract(PreparedStatement insert, SessionImplementor session) throws SQLException {
-			ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().execute( insert );
+			ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().execute( insert );
 			try {
 				return IdentifierGeneratorHelper.getGeneratedIdentity(
 						rs,
 						persister.getRootTableKeyColumnNames()[0],
 						persister.getIdentifierType()
 				);
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( rs, insert );
+				session.getJdbcCoordinator().getResourceRegistry().release( rs, insert );
 			}
 		}
 
 		public Serializable determineGeneratedIdentifier(SessionImplementor session, Object entity) {
 			throw new AssertionFailure( "insert statement returns generated value" );
 		}
 	}
 
 	/**
 	 * Delegate for dealing with IDENTITY columns where the dialect requires an
 	 * additional command execution to retrieve the generated IDENTITY value
 	 */
 	public static class BasicDelegate
 			extends AbstractSelectingDelegate
 			implements InsertGeneratedIdentifierDelegate {
 		private final PostInsertIdentityPersister persister;
 		private final Dialect dialect;
 
 		public BasicDelegate(PostInsertIdentityPersister persister, Dialect dialect) {
 			super( persister );
 			this.persister = persister;
 			this.dialect = dialect;
 		}
 
 		public IdentifierGeneratingInsert prepareIdentifierGeneratingInsert() {
 			IdentifierGeneratingInsert insert = new IdentifierGeneratingInsert( dialect );
 			insert.addIdentityColumn( persister.getRootTableKeyColumnNames()[0] );
 			return insert;
 		}
 
 		protected String getSelectSQL() {
 			return persister.getIdentitySelectString();
 		}
 
 		protected Serializable getResult(
 				SessionImplementor session,
 		        ResultSet rs,
 		        Object object) throws SQLException {
 			return IdentifierGeneratorHelper.getGeneratedIdentity( rs, persister.getRootTableKeyColumnNames()[0], persister.getIdentifierType() );
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/IncrementGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/IncrementGenerator.java
index 26aa628c56..d3e78c0b76 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/IncrementGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/IncrementGenerator.java
@@ -1,154 +1,155 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.boot.model.naming.ObjectNameNormalizer;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.Table;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * <b>increment</b><br>
  * <br>
  * An <tt>IdentifierGenerator</tt> that returns a <tt>long</tt>, constructed by
  * counting from the maximum primary key value at startup. Not safe for use in a
  * cluster!<br>
  * <br>
  * Mapping parameters supported, but not usually needed: tables, column.
  * (The tables parameter specified a comma-separated list of table names.)
  *
  * @author Gavin King
  * @author Steve Ebersole
  * @author Brett Meyer
  */
 public class IncrementGenerator implements IdentifierGenerator, Configurable {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, IncrementGenerator.class.getName());
 
 	private Class returnClass;
 	private String sql;
 
 	private IntegralDataTypeHolder previousValueHolder;
 
 	public synchronized Serializable generate(SessionImplementor session, Object object) throws HibernateException {
 		if ( sql != null ) {
 			initializePreviousValueHolder( session );
 		}
 		return previousValueHolder.makeValueThenIncrement();
 	}
 
 	@Override
 	public void configure(Type type, Properties params, JdbcEnvironment jdbcEnv) throws MappingException {
 		returnClass = type.getReturnedClass();
 
 		ObjectNameNormalizer normalizer =
 				( ObjectNameNormalizer ) params.get( PersistentIdentifierGenerator.IDENTIFIER_NORMALIZER );
 
 		String column = params.getProperty( "column" );
 		if ( column == null ) {
 			column = params.getProperty( PersistentIdentifierGenerator.PK );
 		}
 		column = normalizer.normalizeIdentifierQuoting( column ).render( jdbcEnv.getDialect() );
 
 		String tableList = params.getProperty( "tables" );
 		if ( tableList == null ) {
 			tableList = params.getProperty( PersistentIdentifierGenerator.TABLES );
 		}
 		String[] tables = StringHelper.split( ", ", tableList );
 
 		final String schema = normalizer.toDatabaseIdentifierText(
 				params.getProperty( PersistentIdentifierGenerator.SCHEMA )
 		);
 		final String catalog = normalizer.toDatabaseIdentifierText(
 				params.getProperty( PersistentIdentifierGenerator.CATALOG )
 		);
 
 		StringBuilder buf = new StringBuilder();
 		for ( int i=0; i < tables.length; i++ ) {
 			final String tableName = normalizer.toDatabaseIdentifierText( tables[i] );
 			if ( tables.length > 1 ) {
 				buf.append( "select max(" ).append( column ).append( ") as mx from " );
 			}
 			buf.append( Table.qualify( catalog, schema, tableName ) );
 			if ( i < tables.length-1 ) {
 				buf.append( " union " );
 			}
 		}
 		if ( tables.length > 1 ) {
 			buf.insert( 0, "( " ).append( " ) ids_" );
 			column = "ids_.mx";
 		}
 
 		sql = "select max(" + column + ") from " + buf.toString();
 	}
 
 	private void initializePreviousValueHolder(SessionImplementor session) {
 		previousValueHolder = IdentifierGeneratorHelper.getIntegralDataTypeHolder( returnClass );
 
 		final boolean debugEnabled = LOG.isDebugEnabled();
 		if ( debugEnabled ) {
 			LOG.debugf( "Fetching initial value: %s", sql );
 		}
 		try {
-			PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
+			PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 			try {
-				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
+				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
                     if (rs.next()) previousValueHolder.initialize(rs, 0L).increment();
                     else previousValueHolder.initialize(1L);
 					sql = null;
 					if ( debugEnabled ) {
 						LOG.debugf( "First free id: %s", previousValueHolder.makeValue() );
 					}
 				}
 				finally {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
+					session.getJdbcCoordinator().getResourceRegistry().release( rs, st );
 				}
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+				session.getJdbcCoordinator().getResourceRegistry().release( st );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not fetch initial value for increment generator",
 					sql
 			);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/MultipleHiLoPerTableGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/MultipleHiLoPerTableGenerator.java
index c3de529696..46922444f4 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/MultipleHiLoPerTableGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/MultipleHiLoPerTableGenerator.java
@@ -1,356 +1,356 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.MappingException;
 import org.hibernate.boot.model.naming.ObjectNameNormalizer;
 import org.hibernate.boot.model.relational.Database;
 import org.hibernate.boot.model.relational.QualifiedName;
 import org.hibernate.boot.model.relational.QualifiedNameParser;
 import org.hibernate.boot.model.relational.Schema;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.jdbc.internal.FormatStyle;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
 import org.hibernate.engine.spi.SessionEventListenerManager;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.id.enhanced.AccessCallback;
 import org.hibernate.id.enhanced.LegacyHiLoAlgorithmOptimizer;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.jdbc.AbstractReturningWork;
 import org.hibernate.jdbc.WorkExecutorVisitable;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.PrimaryKey;
 import org.hibernate.mapping.Table;
 import org.hibernate.type.LongType;
 import org.hibernate.type.StringType;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  *
  * A hilo <tt>IdentifierGenerator</tt> that returns a <tt>Long</tt>, constructed using
  * a hi/lo algorithm. The hi value MUST be fetched in a seperate transaction
  * to the <tt>Session</tt> transaction so the generator must be able to obtain
  * a new connection and commit it. Hence this implementation may not
  * be used  when the user is supplying connections. In this
  * case a <tt>SequenceHiLoGenerator</tt> would be a better choice (where
  * supported).<br>
  * <br>
  *
  * A hilo <tt>IdentifierGenerator</tt> that uses a database
  * table to store the last generated values. A table can contains
  * several hi values. They are distinct from each other through a key
  * <p/>
  * <p>This implementation is not compliant with a user connection</p>
  * <p/>
  *
  * <p>Allowed parameters (all of them are optional):</p>
  * <ul>
  * <li>table: table name (default <tt>hibernate_sequences</tt>)</li>
  * <li>primary_key_column: key column name (default <tt>sequence_name</tt>)</li>
  * <li>value_column: hi value column name(default <tt>sequence_next_hi_value</tt>)</li>
  * <li>primary_key_value: key value for the current entity (default to the entity's primary table name)</li>
  * <li>primary_key_length: length of the key column in DB represented as a varchar (default to 255)</li>
  * <li>max_lo: max low value before increasing hi (default to Short.MAX_VALUE)</li>
  * </ul>
  *
  * @author Emmanuel Bernard
  * @author <a href="mailto:kr@hbt.de">Klaus Richarz</a>.
  */
 public class MultipleHiLoPerTableGenerator implements PersistentIdentifierGenerator, Configurable {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
                                                                        MultipleHiLoPerTableGenerator.class.getName());
 
 	public static final String ID_TABLE = "table";
 	public static final String PK_COLUMN_NAME = "primary_key_column";
 	public static final String PK_VALUE_NAME = "primary_key_value";
 	public static final String VALUE_COLUMN_NAME = "value_column";
 	public static final String PK_LENGTH_NAME = "primary_key_length";
 
 	private static final int DEFAULT_PK_LENGTH = 255;
 	public static final String DEFAULT_TABLE = "hibernate_sequences";
 	private static final String DEFAULT_PK_COLUMN = "sequence_name";
 	private static final String DEFAULT_VALUE_COLUMN = "sequence_next_hi_value";
 
 	private QualifiedName qualifiedTableName;
 	private String tableName;
 	private String pkColumnName;
 	private String valueColumnName;
 	private String query;
 	private String insert;
 	private String update;
 
 	//hilo params
 	public static final String MAX_LO = "max_lo";
 
 	private int maxLo;
 	private LegacyHiLoAlgorithmOptimizer hiloOptimizer;
 
 	private Class returnClass;
 	private int keySize;
 
 	public synchronized Serializable generate(final SessionImplementor session, Object obj) {
 		final SqlStatementLogger statementLogger = session.getFactory().getServiceRegistry()
 				.getService( JdbcServices.class )
 				.getSqlStatementLogger();
 		final SessionEventListenerManager statsCollector = session.getEventListenerManager();
 
 		final WorkExecutorVisitable<IntegralDataTypeHolder> work = new AbstractReturningWork<IntegralDataTypeHolder>() {
 			@Override
 			public IntegralDataTypeHolder execute(Connection connection) throws SQLException {
 				IntegralDataTypeHolder value = IdentifierGeneratorHelper.getIntegralDataTypeHolder( returnClass );
 
 				int rows;
 				do {
 					final PreparedStatement queryPreparedStatement = prepareStatement( connection, query, statementLogger, statsCollector );
 					try {
 						final ResultSet rs = executeQuery( queryPreparedStatement, statsCollector );
 						boolean isInitialized = rs.next();
 						if ( !isInitialized ) {
 							value.initialize( 0 );
 							final PreparedStatement insertPreparedStatement = prepareStatement( connection, insert, statementLogger, statsCollector );
 							try {
 								value.bind( insertPreparedStatement, 1 );
 								executeUpdate( insertPreparedStatement, statsCollector );
 							}
 							finally {
 								insertPreparedStatement.close();
 							}
 						}
 						else {
 							value.initialize( rs, 0 );
 						}
 						rs.close();
 					}
 					catch (SQLException sqle) {
 						LOG.unableToReadOrInitHiValue( sqle );
 						throw sqle;
 					}
 					finally {
 						queryPreparedStatement.close();
 					}
 
 
 					final PreparedStatement updatePreparedStatement = prepareStatement( connection, update, statementLogger, statsCollector );
 					try {
 						value.copy().increment().bind( updatePreparedStatement, 1 );
 						value.bind( updatePreparedStatement, 2 );
 
 						rows = executeUpdate( updatePreparedStatement, statsCollector );
 					}
 					catch (SQLException sqle) {
 						LOG.error( LOG.unableToUpdateHiValue( tableName ), sqle );
 						throw sqle;
 					}
 					finally {
 						updatePreparedStatement.close();
 					}
 				} while ( rows==0 );
 
 				return value;
 			}
 		};
 
 		// maxLo < 1 indicates a hilo generator with no hilo :?
 		if ( maxLo < 1 ) {
 			//keep the behavior consistent even for boundary usages
 			IntegralDataTypeHolder value = null;
 			while ( value == null || value.lt( 1 ) ) {
-				value = session.getTransactionCoordinator().getTransaction().createIsolationDelegate().delegateWork( work, true );
+				value = session.getTransactionCoordinator().createIsolationDelegate().delegateWork( work, true );
 			}
 			return value.makeValue();
 		}
 
 		return hiloOptimizer.generate(
 				new AccessCallback() {
 					public IntegralDataTypeHolder getNextValue() {
-						return session.getTransactionCoordinator().getTransaction().createIsolationDelegate().delegateWork(
+						return session.getTransactionCoordinator().createIsolationDelegate().delegateWork(
 								work,
 								true
 						);
 					}
 
 					@Override
 					public String getTenantIdentifier() {
 						return session.getTenantIdentifier();
 					}
 				}
 		);
 	}
 
 	private PreparedStatement prepareStatement(
 			Connection connection,
 			String sql,
 			SqlStatementLogger statementLogger,
 			SessionEventListenerManager statsCollector) throws SQLException {
 		statementLogger.logStatement( sql, FormatStyle.BASIC.getFormatter() );
 		try {
 			statsCollector.jdbcPrepareStatementStart();
 			return connection.prepareStatement( sql );
 		}
 		finally {
 			statsCollector.jdbcPrepareStatementEnd();
 		}
 	}
 
 	private int executeUpdate(PreparedStatement ps, SessionEventListenerManager statsCollector) throws SQLException {
 		try {
 			statsCollector.jdbcExecuteStatementStart();
 			return ps.executeUpdate();
 		}
 		finally {
 			statsCollector.jdbcExecuteStatementEnd();
 		}
 
 	}
 
 	private ResultSet executeQuery(PreparedStatement ps, SessionEventListenerManager statsCollector) throws SQLException {
 		try {
 			statsCollector.jdbcExecuteStatementStart();
 			return ps.executeQuery();
 		}
 		finally {
 			statsCollector.jdbcExecuteStatementEnd();
 		}
 	}
 
 	@SuppressWarnings({"StatementWithEmptyBody", "deprecation"})
 	public void configure(Type type, Properties params, JdbcEnvironment jdbcEnv) throws MappingException {
 		ObjectNameNormalizer normalizer = ( ObjectNameNormalizer ) params.get( IDENTIFIER_NORMALIZER );
 
 		qualifiedTableName = QualifiedNameParser.INSTANCE.parse(
 				ConfigurationHelper.getString( ID_TABLE, params, DEFAULT_TABLE ),
 				normalizer.normalizeIdentifierQuoting( params.getProperty( CATALOG ) ),
 				normalizer.normalizeIdentifierQuoting( params.getProperty( SCHEMA ) )
 		);
 
 		tableName = jdbcEnv.getQualifiedObjectNameFormatter().format(
 				qualifiedTableName,
 				jdbcEnv.getDialect()
 		);
 		pkColumnName = normalizer.toDatabaseIdentifierText(
 				ConfigurationHelper.getString( PK_COLUMN_NAME, params, DEFAULT_PK_COLUMN )
 		);
 		valueColumnName = normalizer.toDatabaseIdentifierText(
 				ConfigurationHelper.getString( VALUE_COLUMN_NAME, params, DEFAULT_VALUE_COLUMN )
 		);
 
 		keySize = ConfigurationHelper.getInt( PK_LENGTH_NAME, params, DEFAULT_PK_LENGTH );
 		String keyValue = ConfigurationHelper.getString( PK_VALUE_NAME, params, params.getProperty( TABLE ) );
 
 		query = "select " +
 			valueColumnName +
 			" from " +
 			jdbcEnv.getDialect().appendLockHint( LockMode.PESSIMISTIC_WRITE, tableName ) +
 			" where " + pkColumnName + " = '" + keyValue + "'" +
 				jdbcEnv.getDialect().getForUpdateString();
 
 		update = "update " +
 			tableName +
 			" set " +
 			valueColumnName +
 			" = ? where " +
 			valueColumnName +
 			" = ? and " +
 			pkColumnName +
 			" = '" +
 			keyValue
 			+ "'";
 
 		insert = "insert into " + tableName +
 			"(" + pkColumnName + ", " +	valueColumnName + ") " +
 			"values('"+ keyValue +"', ?)";
 
 
 		//hilo config
 		maxLo = ConfigurationHelper.getInt(MAX_LO, params, Short.MAX_VALUE);
 		returnClass = type.getReturnedClass();
 
 		if ( maxLo >= 1 ) {
 			hiloOptimizer = new LegacyHiLoAlgorithmOptimizer( returnClass, maxLo );
 		}
 	}
 
 	@Override
 	public void registerExportables(Database database) {
 		final Schema schema = database.locateSchema(
 				qualifiedTableName.getCatalogName(),
 				qualifiedTableName.getSchemaName()
 		);
 
 		final Table table = schema.createTable( qualifiedTableName.getObjectName(), false );
 		table.setPrimaryKey( new PrimaryKey() );
 
 		final Column pkColumn = new ExportableColumn(
 				database,
 				table,
 				pkColumnName,
 				StringType.INSTANCE,
 				database.getDialect().getTypeName( Types.VARCHAR, keySize, 0, 0 )
 		);
 		table.addColumn( pkColumn );
 		table.getPrimaryKey().addColumn( pkColumn );
 
 		final Column valueColumn = new ExportableColumn(
 				database,
 				table,
 				valueColumnName,
 				LongType.INSTANCE
 		);
 		table.addColumn( valueColumn );
 	}
 
 	public String[] sqlCreateStrings(Dialect dialect) throws HibernateException {
 		return new String[] {
 				dialect.getCreateTableString()
 						+ ' ' + tableName + " ( "
 						+ pkColumnName + ' ' + dialect.getTypeName( Types.VARCHAR, keySize, 0, 0 ) + ",  "
 						+ valueColumnName + ' ' + dialect.getTypeName( Types.INTEGER )
 						+ " )" + dialect.getTableTypeString()
 		};
 	}
 
 	public String[] sqlDropStrings(Dialect dialect) throws HibernateException {
 		return new String[] { dialect.getDropTableString( tableName ) };
 	}
 
 	public Object generatorKey() {
 		return tableName;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/SequenceGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/SequenceGenerator.java
index d44537a7ef..77637311d3 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/SequenceGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/SequenceGenerator.java
@@ -1,198 +1,199 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Collections;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.boot.model.naming.ObjectNameNormalizer;
 import org.hibernate.boot.model.relational.Database;
 import org.hibernate.boot.model.relational.QualifiedName;
 import org.hibernate.boot.model.relational.QualifiedNameParser;
 import org.hibernate.boot.model.relational.Schema;
 import org.hibernate.boot.model.relational.SimpleAuxiliaryDatabaseObject;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * <b>sequence</b><br>
  * <br>
  * Generates <tt>long</tt> values using an oracle-style sequence. A higher
  * performance algorithm is <tt>SequenceHiLoGenerator</tt>.<br>
  * <br>
  * Mapping parameters supported: sequence, parameters.
  *
  * @see SequenceHiLoGenerator
  * @author Gavin King
  *
  * @deprecated Use {@link org.hibernate.id.enhanced.SequenceStyleGenerator} instead
  */
 @Deprecated
 public class SequenceGenerator
 		implements PersistentIdentifierGenerator, BulkInsertionCapableIdentifierGenerator, Configurable {
 
     private static final Logger LOG = Logger.getLogger( SequenceGenerator.class.getName() );
 
 	/**
 	 * The sequence parameter
 	 */
 	public static final String SEQUENCE = "sequence";
 
 	/**
 	 * The parameters parameter, appended to the create sequence DDL.
 	 * For example (Oracle): <tt>INCREMENT BY 1 START WITH 1 MAXVALUE 100 NOCACHE</tt>.
 	 */
 	public static final String PARAMETERS = "parameters";
 
 	private QualifiedName qualifiedSequenceName;
 	private String sequenceName;
 	private String parameters;
 	private Type identifierType;
 	private String sql;
 
 	protected Type getIdentifierType() {
 		return identifierType;
 	}
 
 	public Object generatorKey() {
 		return getSequenceName();
 	}
 
 	public String getSequenceName() {
 		return sequenceName;
 	}
 
 	@Override
 	@SuppressWarnings("StatementWithEmptyBody")
 	public void configure(Type type, Properties params, JdbcEnvironment jdbcEnv) throws MappingException {
 		identifierType = type;
 		parameters = params.getProperty( PARAMETERS );
 
 		final Dialect dialect = jdbcEnv.getDialect();
 		final ObjectNameNormalizer normalizer = ( ObjectNameNormalizer ) params.get( IDENTIFIER_NORMALIZER );
 		qualifiedSequenceName = QualifiedNameParser.INSTANCE.parse(
 				ConfigurationHelper.getString( SEQUENCE, params, "hibernate_sequence" ),
 				normalizer.normalizeIdentifierQuoting( params.getProperty( CATALOG ) ),
 				normalizer.normalizeIdentifierQuoting( params.getProperty( SCHEMA ) )
 		);
 		sequenceName = jdbcEnv.getQualifiedObjectNameFormatter().format( qualifiedSequenceName, dialect );
 
 		sql = dialect.getSequenceNextValString( sequenceName );
 	}
 
 	@Override
 	public Serializable generate(SessionImplementor session, Object obj) {
 		return generateHolder( session ).makeValue();
 	}
 
 	protected IntegralDataTypeHolder generateHolder(SessionImplementor session) {
 		try {
-			PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
+			PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 			try {
-				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
+				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
 					rs.next();
 					IntegralDataTypeHolder result = buildHolder();
 					result.initialize( rs, 1 );
 					LOG.debugf( "Sequence identifier generated: %s", result );
 					return result;
 				}
 				finally {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
+					session.getJdbcCoordinator().getResourceRegistry().release( rs, st );
 				}
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+				session.getJdbcCoordinator().getResourceRegistry().release( st );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not get next sequence value",
 					sql
 			);
 		}
 	}
 
 	protected IntegralDataTypeHolder buildHolder() {
 		return IdentifierGeneratorHelper.getIntegralDataTypeHolder( identifierType.getReturnedClass() );
 	}
 
 	@Override
 	@SuppressWarnings( {"deprecation"})
 	public String[] sqlCreateStrings(Dialect dialect) throws HibernateException {
 		String[] ddl = dialect.getCreateSequenceStrings( sequenceName );
 		if ( parameters != null ) {
 			ddl[ddl.length - 1] += ' ' + parameters;
 		}
 		return ddl;
 	}
 
 	@Override
 	public String[] sqlDropStrings(Dialect dialect) throws HibernateException {
 		return dialect.getDropSequenceStrings(sequenceName);
 	}
 
 	@Override
 	public boolean supportsBulkInsertionIdentifierGeneration() {
 		return true;
 	}
 
 	@Override
 	public String determineBulkInsertionIdentifierGenerationSelectFragment(Dialect dialect) {
 		return dialect.getSelectSequenceNextValString( getSequenceName() );
 	}
 
 	@Override
 	public void registerExportables(Database database) {
 		// we cannot register a proper Sequence object here because of the free-form
 		//'parameters' as opposed to specific initialValue/increment values
 
 		final Schema schema = database.locateSchema(
 				qualifiedSequenceName.getCatalogName(),
 				qualifiedSequenceName.getSchemaName()
 		);
 
 		database.addAuxiliaryDatabaseObject(
 				new SimpleAuxiliaryDatabaseObject(
 						schema,
 						sqlCreateStrings( database.getDialect() ),
 						sqlDropStrings( database.getDialect() ),
 						Collections.<String>emptySet()
 				)
 		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/SequenceIdentityGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/SequenceIdentityGenerator.java
index ec7cc848ac..f6a2508b6d 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/SequenceIdentityGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/SequenceIdentityGenerator.java
@@ -1,138 +1,138 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.id.insert.AbstractReturningDelegate;
 import org.hibernate.id.insert.IdentifierGeneratingInsert;
 import org.hibernate.id.insert.InsertGeneratedIdentifierDelegate;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.sql.Insert;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * A generator which combines sequence generation with immediate retrieval
  * through JDBC3 {@link java.sql.Connection#prepareStatement(String, String[]) getGeneratedKeys}.
  * In this respect it works much like ANSI-SQL IDENTITY generation.
  * <p/>
  * This generator only known to work with newer Oracle drivers compiled for
  * JDK 1.4 (JDBC3).
  * <p/>
  * Note: Due to a bug in Oracle drivers, sql comments on these insert statements
  * are completely disabled.
  *
  * @author Steve Ebersole
  *
  * @deprecated See deprecation discussion on {@link SequenceGenerator}
  */
 @Deprecated
 public class SequenceIdentityGenerator
 		extends SequenceGenerator
 		implements PostInsertIdentifierGenerator {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			SequenceIdentityGenerator.class.getName()
 	);
 
 	@Override
     public Serializable generate(SessionImplementor s, Object obj) {
 		return IdentifierGeneratorHelper.POST_INSERT_INDICATOR;
 	}
 
 	@Override
 	public InsertGeneratedIdentifierDelegate getInsertGeneratedIdentifierDelegate(
 			PostInsertIdentityPersister persister,
 	        Dialect dialect,
 	        boolean isGetGeneratedKeysEnabled) throws HibernateException {
 		return new Delegate( persister, dialect, getSequenceName() );
 	}
 
 	@Override
     public void configure(Type type, Properties params, JdbcEnvironment env) throws MappingException {
 		super.configure( type, params, env );
 	}
 
 	public static class Delegate extends AbstractReturningDelegate {
 		private final Dialect dialect;
 		private final String sequenceNextValFragment;
 		private final String[] keyColumns;
 
 		public Delegate(PostInsertIdentityPersister persister, Dialect dialect, String sequenceName) {
 			super( persister );
 			this.dialect = dialect;
 			this.sequenceNextValFragment = dialect.getSelectSequenceNextValString( sequenceName );
 			this.keyColumns = getPersister().getRootTableKeyColumnNames();
 			if ( keyColumns.length > 1 ) {
 				throw new HibernateException( "sequence-identity generator cannot be used with with multi-column keys" );
 			}
 		}
 
 		public IdentifierGeneratingInsert prepareIdentifierGeneratingInsert() {
 			NoCommentsInsert insert = new NoCommentsInsert( dialect );
 			insert.addColumn( getPersister().getRootTableKeyColumnNames()[0], sequenceNextValFragment );
 			return insert;
 		}
 
 		@Override
         protected PreparedStatement prepare(String insertSQL, SessionImplementor session) throws SQLException {
-			return session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( insertSQL, keyColumns );
+			return session.getJdbcCoordinator().getStatementPreparer().prepareStatement( insertSQL, keyColumns );
 		}
 
 		@Override
 		protected Serializable executeAndExtract(PreparedStatement insert, SessionImplementor session) throws SQLException {
-						session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( insert );
+						session.getJdbcCoordinator().getResultSetReturn().executeUpdate( insert );
 			return IdentifierGeneratorHelper.getGeneratedIdentity(
 					insert.getGeneratedKeys(),
 					getPersister().getRootTableKeyColumnNames()[0],
 					getPersister().getIdentifierType()
 			);
 		}
 	}
 
 	public static class NoCommentsInsert extends IdentifierGeneratingInsert {
 		public NoCommentsInsert(Dialect dialect) {
 			super( dialect );
 		}
 
 		@Override
         public Insert setComment(String comment) {
 			// don't allow comments on these insert statements as comments totally
 			// blow up the Oracle getGeneratedKeys "support" :(
 			LOG.disallowingInsertStatementComment();
 			return this;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/enhanced/SequenceStructure.java b/hibernate-core/src/main/java/org/hibernate/id/enhanced/SequenceStructure.java
index 4c5f9f63de..705b385fa2 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/enhanced/SequenceStructure.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/enhanced/SequenceStructure.java
@@ -1,186 +1,187 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id.enhanced;
 
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.boot.model.relational.Database;
 import org.hibernate.boot.model.relational.QualifiedName;
 import org.hibernate.boot.model.relational.Schema;
 import org.hibernate.boot.model.relational.Sequence;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.id.IdentifierGeneratorHelper;
 import org.hibernate.id.IntegralDataTypeHolder;
 import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.Logger;
 
 /**
  * Describes a sequence.
  *
  * @author Steve Ebersole
  */
 public class SequenceStructure implements DatabaseStructure {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			SequenceStructure.class.getName()
 	);
 
 	private QualifiedName qualifiedSequenceName;
 	private final String sequenceName;
 	private final int initialValue;
 	private final int incrementSize;
 	private final Class numberType;
 	private final String sql;
 	private boolean applyIncrementSizeToSourceValues;
 	private int accessCounter;
 
 	public SequenceStructure(
 			JdbcEnvironment jdbcEnvironment,
 			QualifiedName qualifiedSequenceName,
 			int initialValue,
 			int incrementSize,
 			Class numberType) {
 		this.qualifiedSequenceName = qualifiedSequenceName;
 		this.sequenceName = jdbcEnvironment.getQualifiedObjectNameFormatter().format(
 				qualifiedSequenceName,
 				jdbcEnvironment.getDialect()
 		);
 		this.initialValue = initialValue;
 		this.incrementSize = incrementSize;
 		this.numberType = numberType;
 		sql = jdbcEnvironment.getDialect().getSequenceNextValString( sequenceName );
 	}
 
 	@Override
 	public String getName() {
 		return sequenceName;
 	}
 
 	@Override
 	public int getIncrementSize() {
 		return incrementSize;
 	}
 
 	@Override
 	public int getTimesAccessed() {
 		return accessCounter;
 	}
 
 	@Override
 	public int getInitialValue() {
 		return initialValue;
 	}
 
 	@Override
 	public AccessCallback buildCallback(final SessionImplementor session) {
 		return new AccessCallback() {
 			@Override
 			public IntegralDataTypeHolder getNextValue() {
 				accessCounter++;
 				try {
-					final PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
+					final PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 					try {
-						final ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
+						final ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 						try {
 							rs.next();
 							final IntegralDataTypeHolder value = IdentifierGeneratorHelper.getIntegralDataTypeHolder( numberType );
 							value.initialize( rs, 1 );
 							if ( LOG.isDebugEnabled() ) {
 								LOG.debugf( "Sequence value obtained: %s", value.makeValue() );
 							}
 							return value;
 						}
 						finally {
 							try {
-								session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
+								session.getJdbcCoordinator().getResourceRegistry().release( rs, st );
 							}
 							catch( Throwable ignore ) {
 								// intentionally empty
 							}
 						}
 					}
 					finally {
-						session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+						session.getJdbcCoordinator().getResourceRegistry().release( st );
+						session.getJdbcCoordinator().afterStatementExecution();
 					}
 
 				}
 				catch ( SQLException sqle) {
 					throw session.getFactory().getSQLExceptionHelper().convert(
 							sqle,
 							"could not get next sequence value",
 							sql
 					);
 				}
 			}
 
 			@Override
 			public String getTenantIdentifier() {
 				return session.getTenantIdentifier();
 			}
 		};
 	}
 
 	@Override
 	public void prepare(Optimizer optimizer) {
 		applyIncrementSizeToSourceValues = optimizer.applyIncrementSizeToSourceValues();
 	}
 
 	@Override
 	public void registerExportables(Database database) {
 		final int sourceIncrementSize = applyIncrementSizeToSourceValues ? incrementSize : 1;
 		final Schema schema = database.locateSchema(
 				qualifiedSequenceName.getCatalogName(),
 				qualifiedSequenceName.getSchemaName()
 		);
 		Sequence sequence = schema.locateSequence( qualifiedSequenceName.getObjectName() );
 		if ( sequence != null ) {
 			sequence.validate( initialValue, sourceIncrementSize );
 		}
 		else {
 			schema.createSequence( qualifiedSequenceName.getObjectName(), initialValue, sourceIncrementSize );
 		}
 	}
 
 	@Override
 	public String[] sqlCreateStrings(Dialect dialect) throws HibernateException {
 		final int sourceIncrementSize = applyIncrementSizeToSourceValues ? incrementSize : 1;
 		return dialect.getCreateSequenceStrings( sequenceName, initialValue, sourceIncrementSize );
 	}
 
 	@Override
 	public String[] sqlDropStrings(Dialect dialect) throws HibernateException {
 		return dialect.getDropSequenceStrings( sequenceName );
 	}
 
 	@Override
 	public boolean isPhysicalSequence() {
 		return true;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/enhanced/TableGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/enhanced/TableGenerator.java
index 665071b10c..5ff127dedb 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/enhanced/TableGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/enhanced/TableGenerator.java
@@ -1,710 +1,710 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id.enhanced;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 import java.util.Collections;
 import java.util.Map;
 import java.util.Properties;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.boot.model.naming.ObjectNameNormalizer;
 import org.hibernate.boot.model.relational.Database;
 import org.hibernate.boot.model.relational.QualifiedName;
 import org.hibernate.boot.model.relational.QualifiedNameParser;
 import org.hibernate.boot.model.relational.Schema;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.jdbc.internal.FormatStyle;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
 import org.hibernate.engine.spi.SessionEventListenerManager;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.id.Configurable;
 import org.hibernate.id.ExportableColumn;
 import org.hibernate.id.IdentifierGeneratorHelper;
 import org.hibernate.id.IntegralDataTypeHolder;
 import org.hibernate.id.PersistentIdentifierGenerator;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.jdbc.AbstractReturningWork;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.PrimaryKey;
 import org.hibernate.mapping.Table;
 import org.hibernate.type.LongType;
 import org.hibernate.type.StringType;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * An enhanced version of table-based id generation.
  * <p/>
  * Unlike the simplistic legacy one (which, btw, was only ever intended for subclassing
  * support) we "segment" the table into multiple values.  Thus a single table can
  * actually serve as the persistent storage for multiple independent generators.  One
  * approach would be to segment the values by the name of the entity for which we are
  * performing generation, which would mean that we would have a row in the generator
  * table for each entity name.  Or any configuration really; the setup is very flexible.
  * <p/>
  * In this respect it is very similar to the legacy
  * {@link org.hibernate.id.MultipleHiLoPerTableGenerator} in terms of the
  * underlying storage structure (namely a single table capable of holding
  * multiple generator values).  The differentiator is, as with
  * {@link SequenceStyleGenerator} as well, the externalized notion
  * of an optimizer.
  * <p/>
  * <b>NOTE</b> that by default we use a single row for all generators (based
  * on {@link #DEF_SEGMENT_VALUE}).  The configuration parameter
  * {@link #CONFIG_PREFER_SEGMENT_PER_ENTITY} can be used to change that to
  * instead default to using a row for each entity name.
  * <p/>
  * Configuration parameters:
  * <table>
  * 	 <tr>
  *     <td><b>NAME</b></td>
  *     <td><b>DEFAULT</b></td>
  *     <td><b>DESCRIPTION</b></td>
  *   </tr>
  *   <tr>
  *     <td>{@link #TABLE_PARAM}</td>
  *     <td>{@link #DEF_TABLE}</td>
  *     <td>The name of the table to use to store/retrieve values</td>
  *   </tr>
  *   <tr>
  *     <td>{@link #VALUE_COLUMN_PARAM}</td>
  *     <td>{@link #DEF_VALUE_COLUMN}</td>
  *     <td>The name of column which holds the sequence value for the given segment</td>
  *   </tr>
  *   <tr>
  *     <td>{@link #SEGMENT_COLUMN_PARAM}</td>
  *     <td>{@link #DEF_SEGMENT_COLUMN}</td>
  *     <td>The name of the column which holds the segment key</td>
  *   </tr>
  *   <tr>
  *     <td>{@link #SEGMENT_VALUE_PARAM}</td>
  *     <td>{@link #DEF_SEGMENT_VALUE}</td>
  *     <td>The value indicating which segment is used by this generator; refers to values in the {@link #SEGMENT_COLUMN_PARAM} column</td>
  *   </tr>
  *   <tr>
  *     <td>{@link #SEGMENT_LENGTH_PARAM}</td>
  *     <td>{@link #DEF_SEGMENT_LENGTH}</td>
  *     <td>The data length of the {@link #SEGMENT_COLUMN_PARAM} column; used for schema creation</td>
  *   </tr>
  *   <tr>
  *     <td>{@link #INITIAL_PARAM}</td>
  *     <td>{@link #DEFAULT_INITIAL_VALUE}</td>
  *     <td>The initial value to be stored for the given segment</td>
  *   </tr>
  *   <tr>
  *     <td>{@link #INCREMENT_PARAM}</td>
  *     <td>{@link #DEFAULT_INCREMENT_SIZE}</td>
  *     <td>The increment size for the underlying segment; see the discussion on {@link Optimizer} for more details.</td>
  *   </tr>
  *   <tr>
  *     <td>{@link #OPT_PARAM}</td>
  *     <td><i>depends on defined increment size</i></td>
  *     <td>Allows explicit definition of which optimization strategy to use</td>
  *   </tr>
  * </table>
  *
  * @author Steve Ebersole
  */
 public class TableGenerator implements PersistentIdentifierGenerator, Configurable {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			TableGenerator.class.getName()
 	);
 
 	/**
 	 * By default (in the absence of a {@link #SEGMENT_VALUE_PARAM} setting) we use a single row for all
 	 * generators.  This setting can be used to change that to instead default to using a row for each entity name.
 	 */
 	public static final String CONFIG_PREFER_SEGMENT_PER_ENTITY = "prefer_entity_table_as_segment_value";
 
 	/**
 	 * Configures the name of the table to use.  The default value is {@link #DEF_TABLE}
 	 */
 	public static final String TABLE_PARAM = "table_name";
 
 	/**
 	 * The default {@link #TABLE_PARAM} value
 	 */
 	public static final String DEF_TABLE = "hibernate_sequences";
 
 	/**
 	 * The name of column which holds the sequence value.  The default value is {@link #DEF_VALUE_COLUMN}
 	 */
 	public static final String VALUE_COLUMN_PARAM = "value_column_name";
 
 	/**
 	 * The default {@link #VALUE_COLUMN_PARAM} value
 	 */
 	public static final String DEF_VALUE_COLUMN = "next_val";
 
 	/**
 	 * The name of the column which holds the segment key.  The segment defines the different buckets (segments)
 	 * of values currently tracked in the table.  The default value is {@link #DEF_SEGMENT_COLUMN}
 	 */
 	public static final String SEGMENT_COLUMN_PARAM = "segment_column_name";
 
 	/**
 	 * The default {@link #SEGMENT_COLUMN_PARAM} value
 	 */
 	public static final String DEF_SEGMENT_COLUMN = "sequence_name";
 
 	/**
 	 * The value indicating which segment is used by this generator, as indicated by the actual value stored in the
 	 * column indicated by {@link #SEGMENT_COLUMN_PARAM}.  The default value for setting is {@link #DEF_SEGMENT_VALUE},
 	 * although {@link #CONFIG_PREFER_SEGMENT_PER_ENTITY} effects the default as well.
 	 */
 	public static final String SEGMENT_VALUE_PARAM = "segment_value";
 
 	/**
 	 * The default {@link #SEGMENT_VALUE_PARAM} value, unless {@link #CONFIG_PREFER_SEGMENT_PER_ENTITY} is specified
 	 */
 	public static final String DEF_SEGMENT_VALUE = "default";
 
 	/**
 	 * Indicates the length of the column defined by {@link #SEGMENT_COLUMN_PARAM}.  Used in schema export.  The
 	 * default value is {@link #DEF_SEGMENT_LENGTH}
 	 */
 	public static final String SEGMENT_LENGTH_PARAM = "segment_value_length";
 
 	/**
 	 * The default {@link #SEGMENT_LENGTH_PARAM} value
 	 */
 	public static final int DEF_SEGMENT_LENGTH = 255;
 
 	/**
 	 * Indicates the initial value to use.  The default value is {@link #DEFAULT_INITIAL_VALUE}
 	 */
 	public static final String INITIAL_PARAM = "initial_value";
 
 	/**
 	 * The default {@link #INITIAL_PARAM} value
 	 */
 	public static final int DEFAULT_INITIAL_VALUE = 1;
 
 	/**
 	 * Indicates the increment size to use.  The default value is {@link #DEFAULT_INCREMENT_SIZE}
 	 */
 	public static final String INCREMENT_PARAM = "increment_size";
 
 	/**
 	 * The default {@link #INCREMENT_PARAM} value
 	 */
 	public static final int DEFAULT_INCREMENT_SIZE = 1;
 
 	/**
 	 * Indicates the optimizer to use, either naming a {@link Optimizer} implementation class or by naming
 	 * a {@link StandardOptimizerDescriptor} by name
 	 */
 	public static final String OPT_PARAM = "optimizer";
 
 
 	private Type identifierType;
 
 	private QualifiedName qualifiedTableName;
 	private String renderedTableName;
 
 	private String segmentColumnName;
 	private String segmentValue;
 	private int segmentValueLength;
 
 	private String valueColumnName;
 	private int initialValue;
 	private int incrementSize;
 
 	private String selectQuery;
 	private String insertQuery;
 	private String updateQuery;
 
 	private Optimizer optimizer;
 	private long accessCount;
 
 	@Override
 	public Object generatorKey() {
 		return qualifiedTableName.render();
 	}
 
 	/**
 	 * Type mapping for the identifier.
 	 *
 	 * @return The identifier type mapping.
 	 */
 	public final Type getIdentifierType() {
 		return identifierType;
 	}
 
 	/**
 	 * The name of the table in which we store this generator's persistent state.
 	 *
 	 * @return The table name.
 	 */
 	public final String getTableName() {
 		return qualifiedTableName.render();
 	}
 
 	/**
 	 * The name of the column in which we store the segment to which each row
 	 * belongs.  The value here acts as PK.
 	 *
 	 * @return The segment column name
 	 */
 	public final String getSegmentColumnName() {
 		return segmentColumnName;
 	}
 
 	/**
 	 * The value in {@link #getSegmentColumnName segment column} which
 	 * corresponding to this generator instance.  In other words this value
 	 * indicates the row in which this generator instance will store values.
 	 *
 	 * @return The segment value for this generator instance.
 	 */
 	public final String getSegmentValue() {
 		return segmentValue;
 	}
 
 	/**
 	 * The size of the {@link #getSegmentColumnName segment column} in the
 	 * underlying table.
 	 * <p/>
 	 * <b>NOTE</b> : should really have been called 'segmentColumnLength' or
 	 * even better 'segmentColumnSize'
 	 *
 	 * @return the column size.
 	 */
 	@SuppressWarnings("UnusedDeclaration")
 	public final int getSegmentValueLength() {
 		return segmentValueLength;
 	}
 
 	/**
 	 * The name of the column in which we store our persistent generator value.
 	 *
 	 * @return The name of the value column.
 	 */
 	public final String getValueColumnName() {
 		return valueColumnName;
 	}
 
 	/**
 	 * The initial value to use when we find no previous state in the
 	 * generator table corresponding to our sequence.
 	 *
 	 * @return The initial value to use.
 	 */
 	public final int getInitialValue() {
 		return initialValue;
 	}
 
 	/**
 	 * The amount of increment to use.  The exact implications of this
 	 * depends on the {@link #getOptimizer() optimizer} being used.
 	 *
 	 * @return The increment amount.
 	 */
 	public final int getIncrementSize() {
 		return incrementSize;
 	}
 
 	/**
 	 * The optimizer being used by this generator.
 	 *
 	 * @return Out optimizer.
 	 */
 	public final Optimizer getOptimizer() {
 		return optimizer;
 	}
 
 	/**
 	 * Getter for property 'tableAccessCount'.  Only really useful for unit test
 	 * assertions.
 	 *
 	 * @return Value for property 'tableAccessCount'.
 	 */
 	public final long getTableAccessCount() {
 		return accessCount;
 	}
 
 	@Override
 	public void configure(Type type, Properties params, JdbcEnvironment jdbcEnv) throws MappingException {
 		identifierType = type;
 
 		final Dialect dialect = jdbcEnv.getDialect();
 
 		qualifiedTableName = determineGeneratorTableName( params, dialect );
 		renderedTableName = jdbcEnv.getQualifiedObjectNameFormatter().format( qualifiedTableName, dialect );
 		segmentColumnName = determineSegmentColumnName( params, dialect );
 		valueColumnName = determineValueColumnName( params, dialect );
 
 		segmentValue = determineSegmentValue( params );
 
 		segmentValueLength = determineSegmentColumnSize( params );
 		initialValue = determineInitialValue( params );
 		incrementSize = determineIncrementSize( params );
 
 		this.selectQuery = buildSelectQuery( dialect );
 		this.updateQuery = buildUpdateQuery();
 		this.insertQuery = buildInsertQuery();
 
 		// if the increment size is greater than one, we prefer pooled optimization; but we
 		// need to see if the user prefers POOL or POOL_LO...
 		final String defaultPooledOptimizerStrategy = ConfigurationHelper.getBoolean( Environment.PREFER_POOLED_VALUES_LO, params, false )
 				? StandardOptimizerDescriptor.POOLED_LO.getExternalName()
 				: StandardOptimizerDescriptor.POOLED.getExternalName();
 		final String defaultOptimizerStrategy = incrementSize <= 1
 				? StandardOptimizerDescriptor.NONE.getExternalName()
 				: defaultPooledOptimizerStrategy;
 		final String optimizationStrategy = ConfigurationHelper.getString( OPT_PARAM, params, defaultOptimizerStrategy );
 		optimizer = OptimizerFactory.buildOptimizer(
 				optimizationStrategy,
 				identifierType.getReturnedClass(),
 				incrementSize,
 				ConfigurationHelper.getInt( INITIAL_PARAM, params, -1 )
 		);
 	}
 
 	/**
 	 * Determine the table name to use for the generator values.
 	 * <p/>
 	 * Called during {@link #configure configuration}.
 	 *
 	 * @see #getTableName()
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @param dialect The dialect in effect
 	 * @return The table name to use.
 	 */
 	@SuppressWarnings("UnusedParameters")
 	protected QualifiedName determineGeneratorTableName(Properties params, Dialect dialect) {
 		final ObjectNameNormalizer normalizer = (ObjectNameNormalizer) params.get( IDENTIFIER_NORMALIZER );
 
 		return QualifiedNameParser.INSTANCE.parse(
 				ConfigurationHelper.getString( TABLE_PARAM, params, DEF_TABLE ),
 				normalizer.normalizeIdentifierQuoting( params.getProperty( CATALOG ) ),
 				normalizer.normalizeIdentifierQuoting( params.getProperty( SCHEMA ) )
 		);
 	}
 
 	/**
 	 * Determine the name of the column used to indicate the segment for each
 	 * row.  This column acts as the primary key.
 	 * <p/>
 	 * Called during {@link #configure configuration}.
 	 *
 	 * @see #getSegmentColumnName()
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @param dialect The dialect in effect
 	 * @return The name of the segment column
 	 */
 	@SuppressWarnings("UnusedParameters")
 	protected String determineSegmentColumnName(Properties params, Dialect dialect) {
 		final ObjectNameNormalizer normalizer = (ObjectNameNormalizer) params.get( IDENTIFIER_NORMALIZER );
 		final String name = ConfigurationHelper.getString( SEGMENT_COLUMN_PARAM, params, DEF_SEGMENT_COLUMN );
 		return normalizer.toDatabaseIdentifierText( name );
 	}
 
 	/**
 	 * Determine the name of the column in which we will store the generator persistent value.
 	 * <p/>
 	 * Called during {@link #configure configuration}.
 	 *
 	 * @see #getValueColumnName()
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @param dialect The dialect in effect
 	 * @return The name of the value column
 	 */
 	@SuppressWarnings("UnusedParameters")
 	protected String determineValueColumnName(Properties params, Dialect dialect) {
 		final ObjectNameNormalizer normalizer = (ObjectNameNormalizer) params.get( IDENTIFIER_NORMALIZER );
 		final String name = ConfigurationHelper.getString( VALUE_COLUMN_PARAM, params, DEF_VALUE_COLUMN );
 		return normalizer.toDatabaseIdentifierText( name );
 	}
 
 	/**
 	 * Determine the segment value corresponding to this generator instance.
 	 * <p/>
 	 * Called during {@link #configure configuration}.
 	 *
 	 * @see #getSegmentValue()
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @return The name of the value column
 	 */
 	protected String determineSegmentValue(Properties params) {
 		String segmentValue = params.getProperty( SEGMENT_VALUE_PARAM );
 		if ( StringHelper.isEmpty( segmentValue ) ) {
 			segmentValue = determineDefaultSegmentValue( params );
 		}
 		return segmentValue;
 	}
 
 	/**
 	 * Used in the cases where {@link #determineSegmentValue} is unable to
 	 * determine the value to use.
 	 *
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @return The default segment value to use.
 	 */
 	protected String determineDefaultSegmentValue(Properties params) {
 		final boolean preferSegmentPerEntity = ConfigurationHelper.getBoolean( CONFIG_PREFER_SEGMENT_PER_ENTITY, params, false );
 		final String defaultToUse = preferSegmentPerEntity ? params.getProperty( TABLE ) : DEF_SEGMENT_VALUE;
 		LOG.usingDefaultIdGeneratorSegmentValue( qualifiedTableName.render(), segmentColumnName, defaultToUse );
 		return defaultToUse;
 	}
 
 	/**
 	 * Determine the size of the {@link #getSegmentColumnName segment column}
 	 * <p/>
 	 * Called during {@link #configure configuration}.
 	 *
 	 * @see #getSegmentValueLength()
 	 * @param params The params supplied in the generator config (plus some standard useful extras).
 	 * @return The size of the segment column
 	 */
 	protected int determineSegmentColumnSize(Properties params) {
 		return ConfigurationHelper.getInt( SEGMENT_LENGTH_PARAM, params, DEF_SEGMENT_LENGTH );
 	}
 
 	protected int determineInitialValue(Properties params) {
 		return ConfigurationHelper.getInt( INITIAL_PARAM, params, DEFAULT_INITIAL_VALUE );
 	}
 
 	protected int determineIncrementSize(Properties params) {
 		return ConfigurationHelper.getInt( INCREMENT_PARAM, params, DEFAULT_INCREMENT_SIZE );
 	}
 
 	@SuppressWarnings("unchecked")
 	protected String buildSelectQuery(Dialect dialect) {
 		final String alias = "tbl";
 		final String query = "select " + StringHelper.qualify( alias, valueColumnName ) +
 				" from " + renderedTableName + ' ' + alias +
 				" where " + StringHelper.qualify( alias, segmentColumnName ) + "=?";
 		final LockOptions lockOptions = new LockOptions( LockMode.PESSIMISTIC_WRITE );
 		lockOptions.setAliasSpecificLockMode( alias, LockMode.PESSIMISTIC_WRITE );
 		final Map updateTargetColumnsMap = Collections.singletonMap( alias, new String[] { valueColumnName } );
 		return dialect.applyLocksToSql( query, lockOptions, updateTargetColumnsMap );
 	}
 
 	protected String buildUpdateQuery() {
 		return "update " + renderedTableName +
 				" set " + valueColumnName + "=? " +
 				" where " + valueColumnName + "=? and " + segmentColumnName + "=?";
 	}
 
 	protected String buildInsertQuery() {
 		return "insert into " + renderedTableName + " (" + segmentColumnName + ", " + valueColumnName + ") " + " values (?,?)";
 	}
 
 	private IntegralDataTypeHolder makeValue() {
 		return IdentifierGeneratorHelper.getIntegralDataTypeHolder( identifierType.getReturnedClass() );
 	}
 
 	@Override
 	public Serializable generate(final SessionImplementor session, final Object obj) {
 		final SqlStatementLogger statementLogger = session.getFactory().getServiceRegistry()
 				.getService( JdbcServices.class )
 				.getSqlStatementLogger();
 		final SessionEventListenerManager statsCollector = session.getEventListenerManager();
 
 		return optimizer.generate(
 				new AccessCallback() {
 					@Override
 					public IntegralDataTypeHolder getNextValue() {
-						return session.getTransactionCoordinator().getTransaction().createIsolationDelegate().delegateWork(
+						return session.getTransactionCoordinator().createIsolationDelegate().delegateWork(
 								new AbstractReturningWork<IntegralDataTypeHolder>() {
 									@Override
 									public IntegralDataTypeHolder execute(Connection connection) throws SQLException {
 										final IntegralDataTypeHolder value = makeValue();
 										int rows;
 										do {
 											final PreparedStatement selectPS = prepareStatement( connection, selectQuery, statementLogger, statsCollector );
 
 											try {
 												selectPS.setString( 1, segmentValue );
 												final ResultSet selectRS = executeQuery( selectPS, statsCollector );
 												if ( !selectRS.next() ) {
 													value.initialize( initialValue );
 
 													final PreparedStatement insertPS = prepareStatement( connection, insertQuery, statementLogger, statsCollector );
 													try {
 														insertPS.setString( 1, segmentValue );
 														value.bind( insertPS, 2 );
 														executeUpdate( insertPS, statsCollector );
 													}
 													finally {
 														insertPS.close();
 													}
 												}
 												else {
 													value.initialize( selectRS, 1 );
 												}
 												selectRS.close();
 											}
 											catch (SQLException e) {
 												LOG.unableToReadOrInitHiValue( e );
 												throw e;
 											}
 											finally {
 												selectPS.close();
 											}
 
 
 											final PreparedStatement updatePS = prepareStatement( connection, updateQuery, statementLogger, statsCollector );
 											try {
 												final IntegralDataTypeHolder updateValue = value.copy();
 												if ( optimizer.applyIncrementSizeToSourceValues() ) {
 													updateValue.add( incrementSize );
 												}
 												else {
 													updateValue.increment();
 												}
 												updateValue.bind( updatePS, 1 );
 												value.bind( updatePS, 2 );
 												updatePS.setString( 3, segmentValue );
 												rows = executeUpdate( updatePS, statsCollector );
 											}
 											catch (SQLException e) {
 												LOG.unableToUpdateQueryHiValue( renderedTableName, e );
 												throw e;
 											}
 											finally {
 												updatePS.close();
 											}
 										}
 										while ( rows == 0 );
 
 										accessCount++;
 
 										return value;
 									}
 								},
 								true
 						);
 					}
 
 					@Override
 					public String getTenantIdentifier() {
 						return session.getTenantIdentifier();
 					}
 				}
 		);
 	}
 
 	private PreparedStatement prepareStatement(
 			Connection connection,
 			String sql,
 			SqlStatementLogger statementLogger,
 			SessionEventListenerManager statsCollector) throws SQLException {
 		statementLogger.logStatement( sql, FormatStyle.BASIC.getFormatter() );
 		try {
 			statsCollector.jdbcPrepareStatementStart();
 			return connection.prepareStatement( sql );
 		}
 		finally {
 			statsCollector.jdbcPrepareStatementEnd();
 		}
 	}
 
 	private int executeUpdate(PreparedStatement ps, SessionEventListenerManager statsCollector) throws SQLException {
 		try {
 			statsCollector.jdbcExecuteStatementStart();
 			return ps.executeUpdate();
 		}
 		finally {
 			statsCollector.jdbcExecuteStatementEnd();
 		}
 
 	}
 
 	private ResultSet executeQuery(PreparedStatement ps, SessionEventListenerManager statsCollector) throws SQLException {
 		try {
 			statsCollector.jdbcExecuteStatementStart();
 			return ps.executeQuery();
 		}
 		finally {
 			statsCollector.jdbcExecuteStatementEnd();
 		}
 	}
 
 	@Override
 	public String[] sqlCreateStrings(Dialect dialect) throws HibernateException {
 		return new String[] {
 				dialect.getCreateTableString() + ' ' + renderedTableName + " ( "
 						+ segmentColumnName + ' ' + dialect.getTypeName( Types.VARCHAR, segmentValueLength, 0, 0 ) + " not null "
 						+ ", " + valueColumnName + ' ' + dialect.getTypeName( Types.BIGINT )
 						+ ", primary key ( " + segmentColumnName + " ) )" + dialect.getTableTypeString()
 		};
 	}
 
 	@Override
 	public String[] sqlDropStrings(Dialect dialect) throws HibernateException {
 		return new String[] { dialect.getDropTableString( renderedTableName ) };
 	}
 
 	@Override
 	public void registerExportables(Database database) {
 		final Dialect dialect = database.getJdbcEnvironment().getDialect();
 
 		final Schema schema = database.locateSchema(
 				qualifiedTableName.getCatalogName(),
 				qualifiedTableName.getSchemaName()
 		);
 		final Table table = schema.createTable( qualifiedTableName.getObjectName(), false );
 
 		final Column segmentColumn = new ExportableColumn(
 				database,
 				table,
 				segmentColumnName,
 				StringType.INSTANCE,
 				dialect.getTypeName( Types.VARCHAR, segmentValueLength, 0, 0 )
 		);
 		segmentColumn.setNullable( false );
 		table.addColumn( segmentColumn );
 
 		// lol
 		table.setPrimaryKey( new PrimaryKey() );
 		table.getPrimaryKey().setTable( table );
 		table.getPrimaryKey().addColumn( segmentColumn );
 
 		final Column valueColumn = new ExportableColumn(
 				database,
 				table,
 				valueColumnName,
 				LongType.INSTANCE
 		);
 		table.addColumn( valueColumn );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/enhanced/TableStructure.java b/hibernate-core/src/main/java/org/hibernate/id/enhanced/TableStructure.java
index 36c4dbf0d2..044db4a2b5 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/enhanced/TableStructure.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/enhanced/TableStructure.java
@@ -1,292 +1,292 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id.enhanced;
 
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Types;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.boot.model.naming.Identifier;
 import org.hibernate.boot.model.relational.Database;
 import org.hibernate.boot.model.relational.InitCommand;
 import org.hibernate.boot.model.relational.QualifiedName;
 import org.hibernate.boot.model.relational.Schema;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.jdbc.internal.FormatStyle;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
 import org.hibernate.engine.spi.SessionEventListenerManager;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.id.ExportableColumn;
 import org.hibernate.id.IdentifierGenerationException;
 import org.hibernate.id.IdentifierGeneratorHelper;
 import org.hibernate.id.IntegralDataTypeHolder;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.jdbc.AbstractReturningWork;
 import org.hibernate.mapping.Table;
 import org.hibernate.type.LongType;
 
 import org.jboss.logging.Logger;
 
 /**
  * Describes a table used to mimic sequence behavior
  *
  * @author Steve Ebersole
  */
 public class TableStructure implements DatabaseStructure {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			TableStructure.class.getName()
 	);
 
 	private final QualifiedName qualifiedTableName;
 
 	private final String tableNameText;
 	private final String valueColumnNameText;
 
 	private final int initialValue;
 	private final int incrementSize;
 	private final Class numberType;
 	private final String selectQuery;
 	private final String updateQuery;
 
 	private boolean applyIncrementSizeToSourceValues;
 	private int accessCounter;
 
 	public TableStructure(
 			JdbcEnvironment jdbcEnvironment,
 			QualifiedName qualifiedTableName,
 			Identifier valueColumnNameIdentifier,
 			int initialValue,
 			int incrementSize,
 			Class numberType) {
 		final Dialect dialect = jdbcEnvironment.getDialect();
 
 		this.qualifiedTableName = qualifiedTableName;
 		this.tableNameText = jdbcEnvironment.getQualifiedObjectNameFormatter().format(
 				qualifiedTableName,
 				dialect
 		);
 
 		this.valueColumnNameText = valueColumnNameIdentifier.render( jdbcEnvironment.getDialect() );
 
 		this.initialValue = initialValue;
 		this.incrementSize = incrementSize;
 		this.numberType = numberType;
 
 		selectQuery = "select " + valueColumnNameText + " as id_val" +
 				" from " + dialect.appendLockHint( LockMode.PESSIMISTIC_WRITE, tableNameText ) +
 				dialect.getForUpdateString();
 
 		updateQuery = "update " + tableNameText +
 				" set " + valueColumnNameText + "= ?" +
 				" where " + valueColumnNameText + "=?";
 	}
 
 	@Override
 	public String getName() {
 		return tableNameText;
 	}
 
 	@Override
 	public int getInitialValue() {
 		return initialValue;
 	}
 
 	@Override
 	public int getIncrementSize() {
 		return incrementSize;
 	}
 
 	@Override
 	public int getTimesAccessed() {
 		return accessCounter;
 	}
 
 	@Override
 	public void prepare(Optimizer optimizer) {
 		applyIncrementSizeToSourceValues = optimizer.applyIncrementSizeToSourceValues();
 	}
 
 	private IntegralDataTypeHolder makeValue() {
 		return IdentifierGeneratorHelper.getIntegralDataTypeHolder( numberType );
 	}
 
 	@Override
 	public AccessCallback buildCallback(final SessionImplementor session) {
 		final SqlStatementLogger statementLogger = session.getFactory().getServiceRegistry()
 				.getService( JdbcServices.class )
 				.getSqlStatementLogger();
 		final SessionEventListenerManager statsCollector = session.getEventListenerManager();
 
 		return new AccessCallback() {
 			@Override
 			public IntegralDataTypeHolder getNextValue() {
-				return session.getTransactionCoordinator().getTransaction().createIsolationDelegate().delegateWork(
+				return session.getTransactionCoordinator().createIsolationDelegate().delegateWork(
 						new AbstractReturningWork<IntegralDataTypeHolder>() {
 							@Override
 							public IntegralDataTypeHolder execute(Connection connection) throws SQLException {
 								final IntegralDataTypeHolder value = makeValue();
 								int rows;
 								do {
 									final PreparedStatement selectStatement = prepareStatement( connection, selectQuery, statementLogger, statsCollector );
 									try {
 										final ResultSet selectRS = executeQuery( selectStatement, statsCollector );
 										if ( !selectRS.next() ) {
 											final String err = "could not read a hi value - you need to populate the table: " + tableNameText;
 											LOG.error( err );
 											throw new IdentifierGenerationException( err );
 										}
 										value.initialize( selectRS, 1 );
 										selectRS.close();
 									}
 									catch (SQLException sqle) {
 										LOG.error( "could not read a hi value", sqle );
 										throw sqle;
 									}
 									finally {
 										selectStatement.close();
 									}
 
 
 									final PreparedStatement updatePS = prepareStatement( connection, updateQuery, statementLogger, statsCollector );
 									try {
 										final int increment = applyIncrementSizeToSourceValues ? incrementSize : 1;
 										final IntegralDataTypeHolder updateValue = value.copy().add( increment );
 										updateValue.bind( updatePS, 1 );
 										value.bind( updatePS, 2 );
 										rows = executeUpdate( updatePS, statsCollector );
 									}
 									catch (SQLException e) {
 										LOG.unableToUpdateQueryHiValue( tableNameText, e );
 										throw e;
 									}
 									finally {
 										updatePS.close();
 									}
 								} while ( rows == 0 );
 
 								accessCounter++;
 
 								return value;
 							}
 						},
 						true
 				);
 			}
 
 			@Override
 			public String getTenantIdentifier() {
 				return session.getTenantIdentifier();
 			}
 		};
 	}
 
 	private PreparedStatement prepareStatement(
 			Connection connection,
 			String sql,
 			SqlStatementLogger statementLogger,
 			SessionEventListenerManager statsCollector) throws SQLException {
 		statementLogger.logStatement( sql, FormatStyle.BASIC.getFormatter() );
 		try {
 			statsCollector.jdbcPrepareStatementStart();
 			return connection.prepareStatement( sql );
 		}
 		finally {
 			statsCollector.jdbcPrepareStatementEnd();
 		}
 	}
 
 	private int executeUpdate(PreparedStatement ps, SessionEventListenerManager statsCollector) throws SQLException {
 		try {
 			statsCollector.jdbcExecuteStatementStart();
 			return ps.executeUpdate();
 		}
 		finally {
 			statsCollector.jdbcExecuteStatementEnd();
 		}
 
 	}
 
 	private ResultSet executeQuery(PreparedStatement ps, SessionEventListenerManager statsCollector) throws SQLException {
 		try {
 			statsCollector.jdbcExecuteStatementStart();
 			return ps.executeQuery();
 		}
 		finally {
 			statsCollector.jdbcExecuteStatementEnd();
 		}
 	}
 
 	@Override
 	public String[] sqlCreateStrings(Dialect dialect) throws HibernateException {
 		return new String[] {
 				dialect.getCreateTableString() + " " + tableNameText + " ( " + valueColumnNameText + " " + dialect.getTypeName( Types.BIGINT ) + " )",
 				"insert into " + tableNameText + " values ( " + initialValue + " )"
 		};
 	}
 
 	@Override
 	public String[] sqlDropStrings(Dialect dialect) throws HibernateException {
 		return new String[] { dialect.getDropTableString( tableNameText ) };
 	}
 
 	@Override
 	public boolean isPhysicalSequence() {
 		return false;
 	}
 
 	@Override
 	public void registerExportables(Database database) {
 		final Dialect dialect = database.getJdbcEnvironment().getDialect();
 		final Schema schema = database.locateSchema(
 				qualifiedTableName.getCatalogName(),
 				qualifiedTableName.getSchemaName()
 		);
 
 		Table table = schema.locateTable( qualifiedTableName.getObjectName() );
 		if ( table != null ) {
 			return;
 		}
 
 		table = schema.createTable( qualifiedTableName.getObjectName(), false );
 
 		ExportableColumn valueColumn = new ExportableColumn(
 				database,
 				table,
 				valueColumnNameText,
 				LongType.INSTANCE
 		);
 		table.addColumn( valueColumn );
 
 		database.addInitCommand(
 				new InitCommand( "insert into " + tableNameText + " values ( " + initialValue + " )" )
 		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/insert/AbstractReturningDelegate.java b/hibernate-core/src/main/java/org/hibernate/id/insert/AbstractReturningDelegate.java
index aa8649ce9a..add0184582 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/insert/AbstractReturningDelegate.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/insert/AbstractReturningDelegate.java
@@ -1,84 +1,85 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.id.insert;
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.id.PostInsertIdentityPersister;
 import org.hibernate.pretty.MessageHelper;
 
 /**
  * Abstract InsertGeneratedIdentifierDelegate implementation where the
  * underlying strategy causes the enerated identitifer to be returned as an
  * effect of performing the insert statement.  Thus, there is no need for an
  * additional sql statement to determine the generated identitifer.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractReturningDelegate implements InsertGeneratedIdentifierDelegate {
 	private final PostInsertIdentityPersister persister;
 
 	public AbstractReturningDelegate(PostInsertIdentityPersister persister) {
 		this.persister = persister;
 	}
 
 	public final Serializable performInsert(
 			String insertSQL,
 			SessionImplementor session,
 			Binder binder) {
 		try {
 			// prepare and execute the insert
 			PreparedStatement insert = prepare( insertSQL, session );
 			try {
 				binder.bindValues( insert );
 				return executeAndExtract( insert, session );
 			}
 			finally {
 				releaseStatement( insert, session );
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not insert: " + MessageHelper.infoString( persister ),
 			        insertSQL
 				);
 		}
 	}
 
 	protected PostInsertIdentityPersister getPersister() {
 		return persister;
 	}
 
 	protected abstract PreparedStatement prepare(String insertSQL, SessionImplementor session) throws SQLException;
 
 	protected abstract Serializable executeAndExtract(PreparedStatement insert, SessionImplementor session) throws SQLException;
 
 	protected void releaseStatement(PreparedStatement insert, SessionImplementor session) throws SQLException {
-		session.getTransactionCoordinator().getJdbcCoordinator().release( insert );
+		session.getJdbcCoordinator().getResourceRegistry().release( insert );
+		session.getJdbcCoordinator().afterStatementExecution();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/insert/AbstractSelectingDelegate.java b/hibernate-core/src/main/java/org/hibernate/id/insert/AbstractSelectingDelegate.java
index f783721b77..dba353bff2 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/insert/AbstractSelectingDelegate.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/insert/AbstractSelectingDelegate.java
@@ -1,142 +1,144 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.id.insert;
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.id.PostInsertIdentityPersister;
 import org.hibernate.pretty.MessageHelper;
 
 /**
  * Abstract InsertGeneratedIdentifierDelegate implementation where the
  * underlying strategy requires an subsequent select after the insert
  * to determine the generated identifier.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractSelectingDelegate implements InsertGeneratedIdentifierDelegate {
 	private final PostInsertIdentityPersister persister;
 
 	protected AbstractSelectingDelegate(PostInsertIdentityPersister persister) {
 		this.persister = persister;
 	}
 
 	public final Serializable performInsert(
 			String insertSQL,
 			SessionImplementor session,
 			Binder binder) {
 		try {
 			// prepare and execute the insert
-			PreparedStatement insert = session.getTransactionCoordinator()
+			PreparedStatement insert = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( insertSQL, PreparedStatement.NO_GENERATED_KEYS );
 			try {
 				binder.bindValues( insert );
-				session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( insert );
+				session.getJdbcCoordinator().getResultSetReturn().executeUpdate( insert );
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( insert );
+				session.getJdbcCoordinator().getResourceRegistry().release( insert );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not insert: " + MessageHelper.infoString( persister ),
 			        insertSQL
 				);
 		}
 
 		final String selectSQL = getSelectSQL();
 
 		try {
 			//fetch the generated id in a separate query
-			PreparedStatement idSelect = session.getTransactionCoordinator()
+			PreparedStatement idSelect = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( selectSQL, false );
 			try {
 				bindParameters( session, idSelect, binder.getEntity() );
-				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( idSelect );
+				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( idSelect );
 				try {
 					return getResult( session, rs, binder.getEntity() );
 				}
 				finally {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, idSelect );
+					session.getJdbcCoordinator().getResourceRegistry().release( rs, idSelect );
 				}
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( idSelect );
+				session.getJdbcCoordinator().getResourceRegistry().release( idSelect );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 
 		}
 		catch ( SQLException sqle ) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not retrieve generated id after insert: " + MessageHelper.infoString( persister ),
 			        insertSQL
 			);
 		}
 	}
 
 	/**
 	 * Get the SQL statement to be used to retrieve generated key values.
 	 *
 	 * @return The SQL command string
 	 */
 	protected abstract String getSelectSQL();
 
 	/**
 	 * Bind any required parameter values into the SQL command {@link #getSelectSQL}.
 	 *
 	 * @param session The session
 	 * @param ps The prepared {@link #getSelectSQL SQL} command
 	 * @param entity The entity being saved.
 	 * @throws SQLException
 	 */
 	protected void bindParameters(
 			SessionImplementor session,
 	        PreparedStatement ps,
 	        Object entity) throws SQLException {
 	}
 
 	/**
 	 * Extract the generated key value from the given result set.
 	 *
 	 * @param session The session
 	 * @param rs The result set containing the generated primay key values.
 	 * @param entity The entity being saved.
 	 * @return The generated identifier
 	 * @throws SQLException
 	 */
 	protected abstract Serializable getResult(
 			SessionImplementor session,
 	        ResultSet rs,
 	        Object entity) throws SQLException;
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/AbstractScrollableResults.java b/hibernate-core/src/main/java/org/hibernate/internal/AbstractScrollableResults.java
index f17eaa71da..d77e49c25e 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/AbstractScrollableResults.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/AbstractScrollableResults.java
@@ -1,300 +1,301 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.math.BigDecimal;
 import java.math.BigInteger;
 import java.sql.Blob;
 import java.sql.Clob;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.util.Calendar;
 import java.util.Date;
 import java.util.Locale;
 import java.util.TimeZone;
 
 import org.hibernate.HibernateException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.hql.internal.HolderInstantiator;
 import org.hibernate.loader.Loader;
 import org.hibernate.type.StandardBasicTypes;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * Base implementation of the ScrollableResults interface.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractScrollableResults implements ScrollableResults {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			AbstractScrollableResults.class.getName()
 	);
 
 	private final ResultSet resultSet;
 	private final PreparedStatement ps;
 	private final SessionImplementor session;
 	private final Loader loader;
 	private final QueryParameters queryParameters;
 	private final Type[] types;
 	private HolderInstantiator holderInstantiator;
 
 	protected AbstractScrollableResults(
 	        ResultSet rs,
 	        PreparedStatement ps,
 	        SessionImplementor sess,
 			Loader loader,
 			QueryParameters queryParameters,
 	        Type[] types,
 	        HolderInstantiator holderInstantiator) {
 		this.resultSet=rs;
 		this.ps=ps;
 		this.session = sess;
 		this.loader = loader;
 		this.queryParameters = queryParameters;
 		this.types = types;
 		this.holderInstantiator = holderInstantiator!=null && holderInstantiator.isRequired()
 		        ? holderInstantiator
 		        : null;
 	}
 
 	protected abstract Object[] getCurrentRow();
 
 	protected ResultSet getResultSet() {
 		return resultSet;
 	}
 
 	protected PreparedStatement getPs() {
 		return ps;
 	}
 
 	protected SessionImplementor getSession() {
 		return session;
 	}
 
 	protected Loader getLoader() {
 		return loader;
 	}
 
 	protected QueryParameters getQueryParameters() {
 		return queryParameters;
 	}
 
 	protected Type[] getTypes() {
 		return types;
 	}
 
 	protected HolderInstantiator getHolderInstantiator() {
 		return holderInstantiator;
 	}
 
 	@Override
 	public final void close() {
 		// not absolutely necessary, but does help with aggressive release
 		//session.getJDBCContext().getConnectionManager().closeQueryStatement( ps, resultSet );
-		session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
+		session.getJdbcCoordinator().getResourceRegistry().release( ps );
+		session.getJdbcCoordinator().afterStatementExecution();
 		try {
 			session.getPersistenceContext().getLoadContexts().cleanup( resultSet );
 		}
 		catch( Throwable ignore ) {
 			// ignore this error for now
 			if ( LOG.isTraceEnabled() ) {
 				LOG.tracev( "Exception trying to cleanup load context : {0}", ignore.getMessage() );
 			}
 		}
 	}
 
 	@Override
 	public final Object[] get() throws HibernateException {
 		return getCurrentRow();
 	}
 
 	@Override
 	public final Object get(int col) throws HibernateException {
 		return getCurrentRow()[col];
 	}
 
 	/**
 	 * Check that the requested type is compatible with the result type, and
 	 * return the column value.  This version makes sure the the classes
 	 * are identical.
 	 *
 	 * @param col the column
 	 * @param returnType a "final" type
 	 */
 	protected final Object getFinal(int col, Type returnType) throws HibernateException {
 		if ( holderInstantiator!=null ) {
 			throw new HibernateException("query specifies a holder class");
 		}
 
 		if ( returnType.getReturnedClass()==types[col].getReturnedClass() ) {
 			return get(col);
 		}
 		else {
 			return throwInvalidColumnTypeException(col, types[col], returnType);
 		}
 	}
 
 	/**
 	 * Check that the requested type is compatible with the result type, and
 	 * return the column value.  This version makes sure the the classes
 	 * are "assignable".
 	 *
 	 * @param col the column
 	 * @param returnType any type
 	 */
 	protected final Object getNonFinal(int col, Type returnType) throws HibernateException {
 		if ( holderInstantiator!=null ) {
 			throw new HibernateException("query specifies a holder class");
 		}
 
 		if ( returnType.getReturnedClass().isAssignableFrom( types[col].getReturnedClass() ) ) {
 			return get(col);
 		}
 		else {
 			return throwInvalidColumnTypeException(col, types[col], returnType);
 		}
 	}
 
 	@Override
 	public final BigDecimal getBigDecimal(int col) throws HibernateException {
 		return (BigDecimal) getFinal(col, StandardBasicTypes.BIG_DECIMAL);
 	}
 
 	@Override
 	public final BigInteger getBigInteger(int col) throws HibernateException {
 		return (BigInteger) getFinal(col, StandardBasicTypes.BIG_INTEGER);
 	}
 
 	@Override
 	public final byte[] getBinary(int col) throws HibernateException {
 		return (byte[]) getFinal(col, StandardBasicTypes.BINARY);
 	}
 
 	@Override
 	public final String getText(int col) throws HibernateException {
 		return (String) getFinal(col, StandardBasicTypes.TEXT);
 	}
 
 	@Override
 	public final Blob getBlob(int col) throws HibernateException {
 		return (Blob) getNonFinal(col, StandardBasicTypes.BLOB);
 	}
 
 	@Override
 	public final Clob getClob(int col) throws HibernateException {
 		return (Clob) getNonFinal(col, StandardBasicTypes.CLOB);
 	}
 
 	@Override
 	public final Boolean getBoolean(int col) throws HibernateException {
 		return (Boolean) getFinal(col, StandardBasicTypes.BOOLEAN);
 	}
 
 	@Override
 	public final Byte getByte(int col) throws HibernateException {
 		return (Byte) getFinal(col, StandardBasicTypes.BYTE);
 	}
 
 	@Override
 	public final Character getCharacter(int col) throws HibernateException {
 		return (Character) getFinal(col, StandardBasicTypes.CHARACTER);
 	}
 
 	@Override
 	public final Date getDate(int col) throws HibernateException {
 		return (Date) getNonFinal(col, StandardBasicTypes.TIMESTAMP);
 	}
 
 	@Override
 	public final Calendar getCalendar(int col) throws HibernateException {
 		return (Calendar) getNonFinal(col, StandardBasicTypes.CALENDAR);
 	}
 
 	@Override
 	public final Double getDouble(int col) throws HibernateException {
 		return (Double) getFinal(col, StandardBasicTypes.DOUBLE);
 	}
 
 	@Override
 	public final Float getFloat(int col) throws HibernateException {
 		return (Float) getFinal(col, StandardBasicTypes.FLOAT);
 	}
 
 	@Override
 	public final Integer getInteger(int col) throws HibernateException {
 		return (Integer) getFinal(col, StandardBasicTypes.INTEGER);
 	}
 
 	@Override
 	public final Long getLong(int col) throws HibernateException {
 		return (Long) getFinal(col, StandardBasicTypes.LONG);
 	}
 
 	@Override
 	public final Short getShort(int col) throws HibernateException {
 		return (Short) getFinal(col, StandardBasicTypes.SHORT);
 	}
 
 	@Override
 	public final String getString(int col) throws HibernateException {
 		return (String) getFinal(col, StandardBasicTypes.STRING);
 	}
 
 	@Override
 	public final Locale getLocale(int col) throws HibernateException {
 		return (Locale) getFinal(col, StandardBasicTypes.LOCALE);
 	}
 
 	@Override
 	public final TimeZone getTimeZone(int col) throws HibernateException {
 		return (TimeZone) getNonFinal(col, StandardBasicTypes.TIMEZONE);
 	}
 
 	@Override
 	public final Type getType(int i) {
 		return types[i];
 	}
 
 	private Object throwInvalidColumnTypeException(
 	        int i,
 	        Type type,
 	        Type returnType) throws HibernateException {
 		throw new HibernateException(
 				"incompatible column types: " +
 				type.getName() +
 				", " +
 				returnType.getName()
 		);
 	}
 
 	protected void afterScrollOperation() {
 		session.afterScrollOperation();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/AbstractSessionImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/AbstractSessionImpl.java
index 425f4fc555..839e41a394 100755
--- a/hibernate-core/src/main/java/org/hibernate/internal/AbstractSessionImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/AbstractSessionImpl.java
@@ -1,450 +1,622 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.SQLException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.UUID;
 
+import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.MultiTenancyStrategy;
 import org.hibernate.Query;
 import org.hibernate.SQLQuery;
 import org.hibernate.ScrollableResults;
 import org.hibernate.SessionEventListener;
 import org.hibernate.SessionException;
 import org.hibernate.SharedSessionContract;
+import org.hibernate.Transaction;
 import org.hibernate.cache.spi.CacheKey;
+import org.hibernate.cfg.Settings;
 import org.hibernate.engine.jdbc.LobCreationContext;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
 import org.hibernate.engine.jdbc.connections.spi.MultiTenantConnectionProvider;
+import org.hibernate.engine.jdbc.spi.ConnectionObserver;
 import org.hibernate.engine.query.spi.HQLQueryPlan;
 import org.hibernate.engine.query.spi.NativeSQLQueryPlan;
 import org.hibernate.engine.query.spi.ParameterMetadata;
 import org.hibernate.engine.query.spi.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.NamedQueryDefinition;
 import org.hibernate.engine.spi.NamedSQLQueryDefinition;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.engine.transaction.spi.TransactionContext;
-import org.hibernate.engine.transaction.spi.TransactionEnvironment;
+import org.hibernate.engine.transaction.internal.TransactionImpl;
 import org.hibernate.id.uuid.StandardRandomStrategy;
 import org.hibernate.jdbc.WorkExecutor;
 import org.hibernate.jdbc.WorkExecutorVisitable;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.procedure.ProcedureCall;
 import org.hibernate.procedure.ProcedureCallMemento;
 import org.hibernate.procedure.internal.ProcedureCallImpl;
+import org.hibernate.resource.jdbc.spi.JdbcObserver;
+import org.hibernate.resource.jdbc.spi.JdbcSessionContext;
+import org.hibernate.resource.jdbc.spi.JdbcSessionOwner;
+import org.hibernate.resource.jdbc.spi.StatementInspector;
+import org.hibernate.resource.transaction.TransactionCoordinatorBuilder;
+import org.hibernate.resource.transaction.TransactionCoordinatorJtaBuilder;
+import org.hibernate.resource.transaction.spi.TransactionStatus;
+import org.hibernate.service.ServiceRegistry;
 import org.hibernate.type.Type;
 
 /**
  * Functionality common to stateless and stateful sessions
  *
  * @author Gavin King
  */
 public abstract class AbstractSessionImpl
-		implements Serializable, SharedSessionContract, SessionImplementor, TransactionContext {
+		implements Serializable, SharedSessionContract, SessionImplementor, JdbcSessionOwner {
 	protected transient SessionFactoryImpl factory;
 	private final String tenantIdentifier;
 	private boolean closed;
 
+	protected transient Transaction currentHibernateTransaction;
+
 	protected AbstractSessionImpl(SessionFactoryImpl factory, String tenantIdentifier) {
 		this.factory = factory;
 		this.tenantIdentifier = tenantIdentifier;
 		if ( MultiTenancyStrategy.NONE == factory.getSettings().getMultiTenancyStrategy() ) {
 			if ( tenantIdentifier != null ) {
 				throw new HibernateException( "SessionFactory was not configured for multi-tenancy" );
 			}
 		}
 		else {
 			if ( tenantIdentifier == null ) {
 				throw new HibernateException( "SessionFactory configured for multi-tenancy, but no tenant identifier specified" );
 			}
 		}
 	}
 
 	public SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
-	@Override
-	public TransactionEnvironment getTransactionEnvironment() {
-		return factory.getTransactionEnvironment();
-	}
+	public abstract boolean shouldAutoJoinTransaction();
 
 	@Override
 	public <T> T execute(final LobCreationContext.Callback<T> callback) {
-		return getTransactionCoordinator().getJdbcCoordinator().coordinateWork(
+		return getJdbcCoordinator().coordinateWork(
 				new WorkExecutorVisitable<T>() {
 					@Override
 					public T accept(WorkExecutor<T> workExecutor, Connection connection) throws SQLException {
 						try {
 							return callback.executeOnConnection( connection );
 						}
 						catch (SQLException e) {
 							throw getFactory().getSQLExceptionHelper().convert(
 									e,
 									"Error creating contextual LOB : " + e.getMessage()
 							);
 						}
 					}
 				}
 		);
 	}
 
 	@Override
 	public boolean isClosed() {
 		return closed || factory.isClosed();
 	}
 
 	protected void setClosed() {
 		closed = true;
 	}
 
 	protected void errorIfClosed() {
 		if ( isClosed() ) {
 			throw new SessionException( "Session is closed!" );
 		}
 	}
 
 	@Override
 	public Query createQuery(NamedQueryDefinition namedQueryDefinition) {
 		String queryString = namedQueryDefinition.getQueryString();
 		final Query query = new QueryImpl(
 				queryString,
 				namedQueryDefinition.getFlushMode(),
 				this,
 				getHQLQueryPlan( queryString, false ).getParameterMetadata()
 		);
 		query.setComment( "named HQL query " + namedQueryDefinition.getName() );
 		if ( namedQueryDefinition.getLockOptions() != null ) {
 			query.setLockOptions( namedQueryDefinition.getLockOptions() );
 		}
 
 		return query;
 	}
 
 	@Override
 	public SQLQuery createSQLQuery(NamedSQLQueryDefinition namedQueryDefinition) {
-		final ParameterMetadata parameterMetadata = factory.getQueryPlanCache().getSQLParameterMetadata( namedQueryDefinition.getQueryString() );
+		final ParameterMetadata parameterMetadata = factory.getQueryPlanCache().getSQLParameterMetadata(
+				namedQueryDefinition.getQueryString()
+		);
 		final SQLQuery query = new SQLQueryImpl(
 				namedQueryDefinition,
 				this,
 				parameterMetadata
 		);
 		query.setComment( "named native SQL query " + namedQueryDefinition.getName() );
 		return query;
 	}
 
 	@Override
 	public Query getNamedQuery(String queryName) throws MappingException {
 		errorIfClosed();
 		NamedQueryDefinition nqd = factory.getNamedQuery( queryName );
 		final Query query;
 		if ( nqd != null ) {
 			query = createQuery( nqd );
 		}
 		else {
 			NamedSQLQueryDefinition nsqlqd = factory.getNamedSQLQuery( queryName );
 			if ( nsqlqd==null ) {
 				throw new MappingException( "Named query not known: " + queryName );
 			}
 
 			query = createSQLQuery( nsqlqd );
 			nqd = nsqlqd;
 		}
 		initQuery( query, nqd );
 		return query;
 	}
 
 	@Override
 	public Query getNamedSQLQuery(String queryName) throws MappingException {
 		errorIfClosed();
 		NamedSQLQueryDefinition nsqlqd = factory.getNamedSQLQuery( queryName );
 		if ( nsqlqd==null ) {
 			throw new MappingException( "Named SQL query not known: " + queryName );
 		}
 		Query query = new SQLQueryImpl(
 				nsqlqd,
 		        this,
 		        factory.getQueryPlanCache().getSQLParameterMetadata( nsqlqd.getQueryString() )
 		);
 		query.setComment( "named native SQL query " + queryName );
 		initQuery( query, nsqlqd );
 		return query;
 	}
 
 	private void initQuery(Query query, NamedQueryDefinition nqd) {
 		// todo : cacheable and readonly should be Boolean rather than boolean...
 		query.setCacheable( nqd.isCacheable() );
 		query.setCacheRegion( nqd.getCacheRegion() );
 		query.setReadOnly( nqd.isReadOnly() );
 
 		if ( nqd.getTimeout() != null ) {
 			query.setTimeout( nqd.getTimeout() );
 		}
 		if ( nqd.getFetchSize() != null ) {
 			query.setFetchSize( nqd.getFetchSize() );
 		}
 		if ( nqd.getCacheMode() != null ) {
 			query.setCacheMode( nqd.getCacheMode() );
 		}
 		if ( nqd.getComment() != null ) {
 			query.setComment( nqd.getComment() );
 		}
 		if ( nqd.getFirstResult() != null ) {
 			query.setFirstResult( nqd.getFirstResult() );
 		}
 		if ( nqd.getMaxResults() != null ) {
 			query.setMaxResults( nqd.getMaxResults() );
 		}
 		if ( nqd.getFlushMode() != null ) {
 			query.setFlushMode( nqd.getFlushMode() );
 		}
 	}
 
 	@Override
 	public Query createQuery(String queryString) {
 		errorIfClosed();
 		final QueryImpl query = new QueryImpl(
 				queryString,
 				this,
 				getHQLQueryPlan( queryString, false ).getParameterMetadata()
 		);
 		query.setComment( queryString );
 		return query;
 	}
 
 	@Override
 	public SQLQuery createSQLQuery(String sql) {
 		errorIfClosed();
 		final SQLQueryImpl query = new SQLQueryImpl(
 				sql,
 				this,
 				factory.getQueryPlanCache().getSQLParameterMetadata( sql )
 		);
 		query.setComment( "dynamic native SQL query" );
 		return query;
 	}
 
 	@Override
 	@SuppressWarnings("UnnecessaryLocalVariable")
 	public ProcedureCall getNamedProcedureCall(String name) {
 		errorIfClosed();
 
 		final ProcedureCallMemento memento = factory.getNamedQueryRepository().getNamedProcedureCallMemento( name );
 		if ( memento == null ) {
 			throw new IllegalArgumentException(
 					"Could not find named stored procedure call with that registration name : " + name
 			);
 		}
 		final ProcedureCall procedureCall = memento.makeProcedureCall( this );
 //		procedureCall.setComment( "Named stored procedure call [" + name + "]" );
 		return procedureCall;
 	}
 
 	@Override
 	@SuppressWarnings("UnnecessaryLocalVariable")
 	public ProcedureCall createStoredProcedureCall(String procedureName) {
 		errorIfClosed();
 		final ProcedureCall procedureCall = new ProcedureCallImpl( this, procedureName );
 //		call.setComment( "Dynamic stored procedure call" );
 		return procedureCall;
 	}
 
 	@Override
 	@SuppressWarnings("UnnecessaryLocalVariable")
 	public ProcedureCall createStoredProcedureCall(String procedureName, Class... resultClasses) {
 		errorIfClosed();
 		final ProcedureCall procedureCall = new ProcedureCallImpl( this, procedureName, resultClasses );
 //		call.setComment( "Dynamic stored procedure call" );
 		return procedureCall;
 	}
 
 	@Override
 	@SuppressWarnings("UnnecessaryLocalVariable")
 	public ProcedureCall createStoredProcedureCall(String procedureName, String... resultSetMappings) {
 		errorIfClosed();
 		final ProcedureCall procedureCall = new ProcedureCallImpl( this, procedureName, resultSetMappings );
 //		call.setComment( "Dynamic stored procedure call" );
 		return procedureCall;
 	}
 
 	protected HQLQueryPlan getHQLQueryPlan(String query, boolean shallow) throws HibernateException {
 		return factory.getQueryPlanCache().getHQLQueryPlan( query, shallow, getEnabledFilters() );
 	}
 
 	protected NativeSQLQueryPlan getNativeSQLQueryPlan(NativeSQLQuerySpecification spec) throws HibernateException {
 		return factory.getQueryPlanCache().getNativeSQLQueryPlan( spec );
 	}
 
 	@Override
+	public Transaction getTransaction() throws HibernateException {
+		errorIfClosed();
+		if ( this.currentHibernateTransaction == null || this.currentHibernateTransaction.getStatus() != TransactionStatus.ACTIVE ) {
+			this.currentHibernateTransaction = new TransactionImpl( getTransactionCoordinator() );
+		}
+		getTransactionCoordinator().pulse();
+		return currentHibernateTransaction;
+	}
+
+	@Override
 	public List list(NativeSQLQuerySpecification spec, QueryParameters queryParameters)
 			throws HibernateException {
 		return listCustomQuery( getNativeSQLQueryPlan( spec ).getCustomQuery(), queryParameters );
 	}
 
 	@Override
 	public ScrollableResults scroll(NativeSQLQuerySpecification spec, QueryParameters queryParameters)
 			throws HibernateException {
 		return scrollCustomQuery( getNativeSQLQueryPlan( spec ).getCustomQuery(), queryParameters );
 	}
 
 	@Override
 	public String getTenantIdentifier() {
 		return tenantIdentifier;
 	}
 
 	@Override
 	public EntityKey generateEntityKey(Serializable id, EntityPersister persister) {
 		return new EntityKey( id, persister );
 	}
 
 	@Override
 	public CacheKey generateCacheKey(Serializable id, Type type, String entityOrRoleName) {
 		return new CacheKey( id, type, entityOrRoleName, getTenantIdentifier(), getFactory() );
 	}
 
 	private transient JdbcConnectionAccess jdbcConnectionAccess;
 
 	@Override
 	public JdbcConnectionAccess getJdbcConnectionAccess() {
 		if ( jdbcConnectionAccess == null ) {
 			if ( MultiTenancyStrategy.NONE == factory.getSettings().getMultiTenancyStrategy() ) {
 				jdbcConnectionAccess = new NonContextualJdbcConnectionAccess(
 						getEventListenerManager(),
 						factory.getServiceRegistry().getService( ConnectionProvider.class )
 				);
 			}
 			else {
 				jdbcConnectionAccess = new ContextualJdbcConnectionAccess(
 						getEventListenerManager(),
 						factory.getServiceRegistry().getService( MultiTenantConnectionProvider.class )
 				);
 			}
 		}
 		return jdbcConnectionAccess;
 	}
 
 	private UUID sessionIdentifier;
 
 	public UUID getSessionIdentifier() {
 		if ( sessionIdentifier == null ) {
 			sessionIdentifier = StandardRandomStrategy.INSTANCE.generateUUID( this );
 		}
 		return sessionIdentifier;
 	}
 
 	private static class NonContextualJdbcConnectionAccess implements JdbcConnectionAccess, Serializable {
 		private final SessionEventListener listener;
 		private final ConnectionProvider connectionProvider;
 
 		private NonContextualJdbcConnectionAccess(
 				SessionEventListener listener,
 				ConnectionProvider connectionProvider) {
 			this.listener = listener;
 			this.connectionProvider = connectionProvider;
 		}
 
 		@Override
 		public Connection obtainConnection() throws SQLException {
 			try {
 				listener.jdbcConnectionAcquisitionStart();
 				return connectionProvider.getConnection();
 			}
 			finally {
 				listener.jdbcConnectionAcquisitionEnd();
 			}
 		}
 
 		@Override
 		public void releaseConnection(Connection connection) throws SQLException {
 			try {
 				listener.jdbcConnectionReleaseStart();
 				connectionProvider.closeConnection( connection );
 			}
 			finally {
 				listener.jdbcConnectionReleaseEnd();
 			}
 		}
 
 		@Override
 		public boolean supportsAggressiveRelease() {
 			return connectionProvider.supportsAggressiveRelease();
 		}
 	}
 
 	private class ContextualJdbcConnectionAccess implements JdbcConnectionAccess, Serializable {
 		private final SessionEventListener listener;
 		private final MultiTenantConnectionProvider connectionProvider;
 
 		private ContextualJdbcConnectionAccess(
 				SessionEventListener listener,
 				MultiTenantConnectionProvider connectionProvider) {
 			this.listener = listener;
 			this.connectionProvider = connectionProvider;
 		}
 
 		@Override
 		public Connection obtainConnection() throws SQLException {
 			if ( tenantIdentifier == null ) {
 				throw new HibernateException( "Tenant identifier required!" );
 			}
 
 			try {
 				listener.jdbcConnectionAcquisitionStart();
 				return connectionProvider.getConnection( tenantIdentifier );
 			}
 			finally {
 				listener.jdbcConnectionAcquisitionEnd();
 			}
 		}
 
 		@Override
 		public void releaseConnection(Connection connection) throws SQLException {
 			if ( tenantIdentifier == null ) {
 				throw new HibernateException( "Tenant identifier required!" );
 			}
 
 			try {
 				listener.jdbcConnectionReleaseStart();
 				connectionProvider.releaseConnection( tenantIdentifier, connection );
 			}
 			finally {
 				listener.jdbcConnectionReleaseEnd();
 			}
 		}
 
 		@Override
 		public boolean supportsAggressiveRelease() {
 			return connectionProvider.supportsAggressiveRelease();
 		}
 	}
+
+	public class JdbcSessionContextImpl implements JdbcSessionContext {
+		private final SessionFactoryImpl sessionFactory;
+		private final StatementInspector inspector;
+		private final transient ServiceRegistry serviceRegistry;
+		private final transient JdbcObserver jdbcObserver;
+
+		public JdbcSessionContextImpl(SessionFactoryImpl sessionFactory, StatementInspector inspector) {
+			this.sessionFactory = sessionFactory;
+			this.inspector = inspector;
+			this.serviceRegistry = sessionFactory.getServiceRegistry();
+			this.jdbcObserver = new JdbcObserverImpl();
+		}
+
+		@Override
+		public boolean isScrollableResultSetsEnabled() {
+			return settings().isScrollableResultSetsEnabled();
+		}
+
+		@Override
+		public boolean isGetGeneratedKeysEnabled() {
+			return settings().isGetGeneratedKeysEnabled();
+		}
+
+		@Override
+		public int getFetchSize() {
+			return settings().getJdbcFetchSize();
+		}
+
+		@Override
+		public ConnectionReleaseMode getConnectionReleaseMode() {
+			return settings().getConnectionReleaseMode();
+		}
+
+		@Override
+		public ConnectionAcquisitionMode getConnectionAcquisitionMode() {
+			return null;
+		}
+
+		@Override
+		public StatementInspector getStatementInspector() {
+			return inspector;
+		}
+
+		@Override
+		public JdbcObserver getObserver() {
+			return this.jdbcObserver;
+		}
+
+		@Override
+		public SessionFactoryImplementor getSessionFactory() {
+			return this.sessionFactory;
+		}
+
+		@Override
+		public ServiceRegistry getServiceRegistry() {
+			return this.serviceRegistry;
+		}
+
+		private final Settings settings() {
+			return this.sessionFactory.getSettings();
+		}
+	}
+
+	public class JdbcObserverImpl implements JdbcObserver {
+
+		private final transient List<ConnectionObserver> observers;
+
+		public JdbcObserverImpl() {
+			this.observers = new ArrayList<ConnectionObserver>();
+			this.observers.add( new ConnectionObserverStatsBridge( factory ) );
+		}
+
+		@Override
+		public void jdbcConnectionAcquisitionStart() {
+
+		}
+
+		@Override
+		public void jdbcConnectionAcquisitionEnd(Connection connection) {
+			for ( ConnectionObserver observer : observers ) {
+				observer.physicalConnectionObtained( connection );
+			}
+		}
+
+		@Override
+		public void jdbcConnectionReleaseStart() {
+
+		}
+
+		@Override
+		public void jdbcConnectionReleaseEnd() {
+			for ( ConnectionObserver observer : observers ) {
+				observer.physicalConnectionReleased();
+			}
+		}
+
+		@Override
+		public void jdbcPrepareStatementStart() {
+			getEventListenerManager().jdbcPrepareStatementStart();
+		}
+
+		@Override
+		public void jdbcPrepareStatementEnd() {
+			for ( ConnectionObserver observer : observers ) {
+				observer.statementPrepared();
+			}
+			getEventListenerManager().jdbcPrepareStatementEnd();
+		}
+
+		@Override
+		public void jdbcExecuteStatementStart() {
+			getEventListenerManager().jdbcExecuteStatementStart();
+		}
+
+		@Override
+		public void jdbcExecuteStatementEnd() {
+			getEventListenerManager().jdbcExecuteStatementEnd();
+		}
+
+		@Override
+		public void jdbcExecuteBatchStart() {
+			getEventListenerManager().jdbcExecuteBatchStart();
+		}
+
+		@Override
+		public void jdbcExecuteBatchEnd() {
+			getEventListenerManager().jdbcExecuteBatchEnd();
+		}
+	}
+
+	@Override
+	public TransactionCoordinatorBuilder getTransactionCoordinatorBuilder() {
+		TransactionCoordinatorBuilder transactionCoordinatorBuilder = factory.getServiceRegistry()
+				.getService( TransactionCoordinatorBuilder.class );
+
+		if ( transactionCoordinatorBuilder instanceof TransactionCoordinatorJtaBuilder ) {
+			((TransactionCoordinatorJtaBuilder) transactionCoordinatorBuilder).setJtaPlatform(
+					factory.getSettings()
+							.getJtaPlatform()
+			).setAutoJoinTransactions( shouldAutoJoinTransaction() ).setPerformJtaThreadTracking(
+					factory.getSettings()
+							.isJtaTrackByThread()
+			).setPreferUserTransactions( factory.getSettings().isPreferUserTransaction() );
+		}
+
+		return transactionCoordinatorBuilder;
+	}
+
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/IteratorImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/IteratorImpl.java
index de0eba9a5a..67345978ba 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/IteratorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/IteratorImpl.java
@@ -1,173 +1,174 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal;
 
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.NoSuchElementException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.JDBCException;
 import org.hibernate.engine.HibernateIterator;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.hql.internal.HolderInstantiator;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * An implementation of <tt>java.util.Iterator</tt> that is
  * returned by <tt>iterate()</tt> query execution methods.
  * @author Gavin King
  */
 public final class IteratorImpl implements HibernateIterator {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, IteratorImpl.class.getName());
 
 	private ResultSet rs;
 	private final EventSource session;
 	private boolean readOnly;
 	private final Type[] types;
 	private final boolean single;
 	private Object currentResult;
 	private boolean hasNext;
 	private final String[][] names;
 	private PreparedStatement ps;
 	private HolderInstantiator holderInstantiator;
 
 	public IteratorImpl(
 	        ResultSet rs,
 	        PreparedStatement ps,
 	        EventSource sess,
 	        boolean readOnly,
 	        Type[] types,
 	        String[][] columnNames,
 	        HolderInstantiator holderInstantiator)
 	throws HibernateException, SQLException {
 
 		this.rs=rs;
 		this.ps=ps;
 		this.session = sess;
 		this.readOnly = readOnly;
 		this.types = types;
 		this.names = columnNames;
 		this.holderInstantiator = holderInstantiator;
 
 		single = types.length==1;
 
 		postNext();
 	}
 
 	public void close() throws JDBCException {
 		if (ps!=null) {
 			LOG.debug("Closing iterator");
-			session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
+			session.getJdbcCoordinator().getResourceRegistry().release( ps );
+			session.getJdbcCoordinator().afterStatementExecution();
 			ps = null;
 			rs = null;
 			hasNext = false;
 			try {
 				session.getPersistenceContext().getLoadContexts().cleanup( rs );
 			}
 			catch( Throwable ignore ) {
 				// ignore this error for now
                 LOG.debugf("Exception trying to cleanup load context : %s", ignore.getMessage());
 			}
 		}
 	}
 
 	private void postNext() throws SQLException {
 		LOG.debug("Attempting to retrieve next results");
 		this.hasNext = rs.next();
 		if (!hasNext) {
 			LOG.debug("Exhausted results");
 			close();
 		} else LOG.debug("Retrieved next results");
 	}
 
 	public boolean hasNext() {
 		return hasNext;
 	}
 
 	public Object next() throws HibernateException {
 		if ( !hasNext ) throw new NoSuchElementException("No more results");
 		boolean sessionDefaultReadOnlyOrig = session.isDefaultReadOnly();
 		session.setDefaultReadOnly( readOnly );
 		try {
 			boolean isHolder = holderInstantiator.isRequired();
 
 			LOG.debugf( "Assembling results" );
 			if ( single && !isHolder ) {
 				currentResult = types[0].nullSafeGet( rs, names[0], session, null );
 			}
 			else {
 				Object[] currentResults = new Object[types.length];
 				for (int i=0; i<types.length; i++) {
 					currentResults[i] = types[i].nullSafeGet( rs, names[i], session, null );
 				}
 
 				if (isHolder) {
 					currentResult = holderInstantiator.instantiate(currentResults);
 				}
 				else {
 					currentResult = currentResults;
 				}
 			}
 
 			postNext();
 			LOG.debugf( "Returning current results" );
 			return currentResult;
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not get next iterator result"
 				);
 		}
 		finally {
 			session.setDefaultReadOnly( sessionDefaultReadOnlyOrig );
 		}
 	}
 
 	public void remove() {
 		if (!single) {
 			throw new UnsupportedOperationException("Not a single column hibernate query result set");
 		}
 		if (currentResult==null) {
 			throw new IllegalStateException("Called Iterator.remove() before next()");
 		}
 		if ( !( types[0] instanceof EntityType ) ) {
 			throw new UnsupportedOperationException("Not an entity");
 		}
 
 		session.delete(
 				( (EntityType) types[0] ).getAssociatedEntityName(),
 				currentResult,
 				false,
 		        null
 			);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
index dbe332e2a3..cb1b090546 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
@@ -1,1466 +1,1469 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
+import javax.naming.Reference;
+import javax.naming.StringRefAddr;
 import java.io.IOException;
 import java.io.InvalidObjectException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
-import javax.naming.Reference;
-import javax.naming.StringRefAddr;
+
+import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.Cache;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.CustomEntityDirtinessStrategy;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.MappingException;
 import org.hibernate.MultiTenancyStrategy;
 import org.hibernate.Session;
 import org.hibernate.SessionBuilder;
 import org.hibernate.SessionEventListener;
 import org.hibernate.SessionFactory;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.StatelessSession;
 import org.hibernate.StatelessSessionBuilder;
+import org.hibernate.Transaction;
 import org.hibernate.TypeHelper;
 import org.hibernate.boot.cfgxml.spi.CfgXmlAccessService;
 import org.hibernate.boot.cfgxml.spi.LoadedConfig;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.boot.registry.classloading.spi.ClassLoadingException;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.boot.spi.SessionFactoryOptions;
 import org.hibernate.cache.internal.CacheDataDescriptionImpl;
 import org.hibernate.cache.spi.CollectionRegion;
 import org.hibernate.cache.spi.EntityRegion;
 import org.hibernate.cache.spi.NaturalIdRegion;
 import org.hibernate.cache.spi.QueryCache;
 import org.hibernate.cache.spi.Region;
 import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cache.spi.UpdateTimestampsCache;
 import org.hibernate.cache.spi.access.AccessType;
 import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Settings;
 import org.hibernate.context.internal.JTASessionContext;
 import org.hibernate.context.internal.ManagedSessionContext;
 import org.hibernate.context.internal.ThreadLocalSessionContext;
 import org.hibernate.context.spi.CurrentSessionContext;
 import org.hibernate.context.spi.CurrentTenantIdentifierResolver;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.config.spi.ConfigurationService;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
 import org.hibernate.engine.jdbc.connections.spi.MultiTenantConnectionProvider;
+import org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jndi.spi.JndiService;
 import org.hibernate.engine.profile.Association;
 import org.hibernate.engine.profile.Fetch;
 import org.hibernate.engine.profile.FetchProfile;
 import org.hibernate.engine.query.spi.QueryPlanCache;
 import org.hibernate.engine.query.spi.ReturnMetadata;
 import org.hibernate.engine.spi.ActionQueue;
 import org.hibernate.engine.spi.CacheImplementor;
 import org.hibernate.engine.spi.FilterDefinition;
 import org.hibernate.engine.spi.NamedQueryDefinition;
 import org.hibernate.engine.spi.NamedSQLQueryDefinition;
 import org.hibernate.engine.spi.SessionBuilderImplementor;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionOwner;
-import org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl;
 import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
-import org.hibernate.engine.transaction.spi.TransactionEnvironment;
-import org.hibernate.engine.transaction.spi.TransactionFactory;
 import org.hibernate.event.service.spi.EventListenerGroup;
 import org.hibernate.event.service.spi.EventListenerRegistry;
 import org.hibernate.event.spi.EventType;
 import org.hibernate.exception.spi.SQLExceptionConverter;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.UUIDGenerator;
 import org.hibernate.id.factory.IdentifierGeneratorFactory;
 import org.hibernate.integrator.spi.Integrator;
 import org.hibernate.integrator.spi.IntegratorService;
 import org.hibernate.internal.util.config.ConfigurationException;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.metadata.CollectionMetadata;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.persister.spi.PersisterFactory;
 import org.hibernate.proxy.EntityNotFoundDelegate;
+import org.hibernate.resource.transaction.TransactionCoordinator;
 import org.hibernate.secure.spi.GrantedPermission;
 import org.hibernate.secure.spi.JaccPermissionDeclarations;
 import org.hibernate.secure.spi.JaccService;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.spi.SessionFactoryServiceRegistry;
 import org.hibernate.service.spi.SessionFactoryServiceRegistryFactory;
 import org.hibernate.stat.Statistics;
 import org.hibernate.stat.spi.StatisticsImplementor;
 import org.hibernate.tool.hbm2ddl.ImportSqlCommandExtractor;
 import org.hibernate.tool.hbm2ddl.SchemaExport;
 import org.hibernate.tool.hbm2ddl.SchemaUpdate;
 import org.hibernate.tool.hbm2ddl.SchemaValidator;
 import org.hibernate.tuple.entity.EntityTuplizer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeResolver;
 
-import org.jboss.logging.Logger;
-
 
 /**
  * Concrete implementation of the <tt>SessionFactory</tt> interface. Has the following
  * responsibilities
  * <ul>
  * <li>caches configuration settings (immutably)
  * <li>caches "compiled" mappings ie. <tt>EntityPersister</tt>s and
  *     <tt>CollectionPersister</tt>s (immutable)
  * <li>caches "compiled" queries (memory sensitive cache)
  * <li>manages <tt>PreparedStatement</tt>s
  * <li> delegates JDBC <tt>Connection</tt> management to the <tt>ConnectionProvider</tt>
  * <li>factory for instances of <tt>SessionImpl</tt>
  * </ul>
  * This class must appear immutable to clients, even if it does all kinds of caching
  * and pooling under the covers. It is crucial that the class is not only thread
  * safe, but also highly concurrent. Synchronization must be used extremely sparingly.
  *
  * @see org.hibernate.engine.jdbc.connections.spi.ConnectionProvider
  * @see org.hibernate.Session
  * @see org.hibernate.hql.spi.QueryTranslator
  * @see org.hibernate.persister.entity.EntityPersister
  * @see org.hibernate.persister.collection.CollectionPersister
  * @author Gavin King
  */
 public final class SessionFactoryImpl
 		implements SessionFactoryImplementor {
 
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SessionFactoryImpl.class.getName());
+	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
+			CoreMessageLogger.class,
+			SessionFactoryImpl.class.getName()
+	);
 	private static final IdentifierGenerator UUID_GENERATOR = UUIDGenerator.buildSessionFactoryUniqueIdentifierGenerator();
 
 	private final String name;
 	private final String uuid;
 
 	private final transient Map<String,EntityPersister> entityPersisters;
 	private final transient Map<String,ClassMetadata> classMetadata;
 	private final transient Map<String,CollectionPersister> collectionPersisters;
 	private final transient Map<String,CollectionMetadata> collectionMetadata;
 	private final transient Map<String,Set<String>> collectionRolesByEntityParticipant;
 	private final transient Map<String,IdentifierGenerator> identifierGenerators;
 	private final transient NamedQueryRepository namedQueryRepository;
 	private final transient Map<String, FilterDefinition> filters;
 	private final transient Map<String, FetchProfile> fetchProfiles;
 	private final transient Map<String,String> imports;
 	private final transient SessionFactoryServiceRegistry serviceRegistry;
 	private final transient JdbcServices jdbcServices;
 	private final transient Dialect dialect;
 	private final transient Settings settings;
 	private final transient Properties properties;
 	private transient SchemaExport schemaExport;
 	private final transient CurrentSessionContext currentSessionContext;
 	private final transient SQLFunctionRegistry sqlFunctionRegistry;
 	private final transient SessionFactoryObserverChain observer = new SessionFactoryObserverChain();
 	private final transient ConcurrentMap<EntityNameResolver,Object> entityNameResolvers = new ConcurrentHashMap<EntityNameResolver, Object>();
 	private final transient QueryPlanCache queryPlanCache;
 	private final transient CacheImplementor cacheAccess;
 	private transient boolean isClosed;
 	private final transient TypeResolver typeResolver;
 	private final transient TypeHelper typeHelper;
-	private final transient TransactionEnvironment transactionEnvironment;
 	private final transient SessionFactoryOptions sessionFactoryOptions;
 
 	public SessionFactoryImpl(final MetadataImplementor metadata, SessionFactoryOptions options) {
 		LOG.debug( "Building session factory" );
 
 		this.sessionFactoryOptions = options;
 		this.settings = new Settings( options, metadata );
 
 		this.serviceRegistry = options.getServiceRegistry()
 				.getService( SessionFactoryServiceRegistryFactory.class )
 				.buildServiceRegistry( this, options );
 
 		final CfgXmlAccessService cfgXmlAccessService = serviceRegistry.getService( CfgXmlAccessService.class );
 
 		String sfName = settings.getSessionFactoryName();
 		if ( cfgXmlAccessService.getAggregatedConfig() != null ) {
 			if ( sfName == null ) {
 				sfName = cfgXmlAccessService.getAggregatedConfig().getSessionFactoryName();
 			}
 			applyCfgXmlValues( cfgXmlAccessService.getAggregatedConfig(), serviceRegistry );
 		}
 
 		this.name = sfName;
 		try {
 			uuid = (String) UUID_GENERATOR.generate(null, null);
 		}
 		catch (Exception e) {
 			throw new AssertionFailure("Could not generate UUID");
 		}
 
 		this.properties = new Properties();
 		this.properties.putAll( serviceRegistry.getService( ConfigurationService.class ).getSettings() );
 
 		this.jdbcServices = this.serviceRegistry.getService( JdbcServices.class );
 		this.dialect = this.jdbcServices.getDialect();
 		this.cacheAccess = this.serviceRegistry.getService( CacheImplementor.class );
 		this.sqlFunctionRegistry = new SQLFunctionRegistry( getDialect(), options.getCustomSqlFunctionMap() );
 
 		for ( SessionFactoryObserver sessionFactoryObserver : options.getSessionFactoryObservers() ) {
 			this.observer.addObserver( sessionFactoryObserver );
 		}
 
 		this.typeResolver = metadata.getTypeResolver().scope( this );
 		this.typeHelper = new TypeLocatorImpl( typeResolver );
 
 		this.filters = new HashMap<String, FilterDefinition>();
 		this.filters.putAll( metadata.getFilterDefinitions() );
 
 		LOG.debugf( "Session factory constructed with filter configurations : %s", filters );
 		LOG.debugf( "Instantiating session factory with properties: %s", properties );
 
 		this.queryPlanCache = new QueryPlanCache( this );
 
 		class IntegratorObserver implements SessionFactoryObserver {
 			private ArrayList<Integrator> integrators = new ArrayList<Integrator>();
 
 			@Override
 			public void sessionFactoryCreated(SessionFactory factory) {
 			}
 
 			@Override
 			public void sessionFactoryClosed(SessionFactory factory) {
 				for ( Integrator integrator : integrators ) {
 					integrator.disintegrate( SessionFactoryImpl.this, SessionFactoryImpl.this.serviceRegistry );
 				}
 				integrators.clear();
 			}
 		}
 		final IntegratorObserver integratorObserver = new IntegratorObserver();
 		this.observer.addObserver( integratorObserver );
 		for ( Integrator integrator : serviceRegistry.getService( IntegratorService.class ).getIntegrators() ) {
 			integrator.integrate( metadata, this, this.serviceRegistry );
 			integratorObserver.integrators.add( integrator );
 		}
 
 		//Generators:
 
 		this.identifierGenerators = new HashMap<String, IdentifierGenerator>();
 		for ( PersistentClass model : metadata.getEntityBindings() ) {
 			if ( !model.isInherited() ) {
 				IdentifierGenerator generator = model.getIdentifier().createIdentifierGenerator(
 						metadata.getIdentifierGeneratorFactory(),
 						getDialect(),
 						settings.getDefaultCatalogName(),
 						settings.getDefaultSchemaName(),
 						(RootClass) model
 				);
 				identifierGenerators.put( model.getEntityName(), generator );
 			}
 		}
 
 		this.imports = new HashMap<String,String>( metadata.getImports() );
 
 		///////////////////////////////////////////////////////////////////////
 		// Prepare persisters and link them up with their cache
 		// region/access-strategy
 
 		final PersisterCreationContext persisterCreationContext = new PersisterCreationContext() {
 			@Override
 			public SessionFactoryImplementor getSessionFactory() {
 				return SessionFactoryImpl.this;
 			}
 
 			@Override
 			public MetadataImplementor getMetadata() {
 				return metadata;
 			}
 		};
 
 		final RegionFactory regionFactory = cacheAccess.getRegionFactory();
 		final String cacheRegionPrefix = settings.getCacheRegionPrefix() == null ? "" : settings.getCacheRegionPrefix() + ".";
 		final PersisterFactory persisterFactory = serviceRegistry.getService( PersisterFactory.class );
 
 		// todo : consider removing this silliness and just have EntityPersister directly implement ClassMetadata
 		//		EntityPersister.getClassMetadata() for the internal impls simply "return this";
 		//		collapsing those would allow us to remove this "extra" Map
 		//
 		// todo : similar for CollectionPersister/CollectionMetadata
 
 		this.entityPersisters = new HashMap<String,EntityPersister>();
 		Map cacheAccessStrategiesMap = new HashMap();
 		Map<String,ClassMetadata> inFlightClassMetadataMap = new HashMap<String,ClassMetadata>();
 		for ( final PersistentClass model : metadata.getEntityBindings() ) {
 			final String cacheRegionName = cacheRegionPrefix + model.getRootClass().getCacheRegionName();
 			// cache region is defined by the root-class in the hierarchy...
 			final EntityRegionAccessStrategy accessStrategy = determineEntityRegionAccessStrategy(
 					regionFactory,
 					cacheAccessStrategiesMap,
 					model,
 					cacheRegionName
 			);
 
 			final NaturalIdRegionAccessStrategy naturalIdAccessStrategy = determineNaturalIdRegionAccessStrategy(
 					regionFactory,
 					cacheRegionPrefix,
 					cacheAccessStrategiesMap,
 					model
 			);
 
 			final EntityPersister cp = persisterFactory.createEntityPersister(
 					model,
 					accessStrategy,
 					naturalIdAccessStrategy,
 					persisterCreationContext
 			);
 			entityPersisters.put( model.getEntityName(), cp );
 			inFlightClassMetadataMap.put( model.getEntityName(), cp.getClassMetadata() );
 		}
 		this.classMetadata = Collections.unmodifiableMap( inFlightClassMetadataMap );
 
 		this.collectionPersisters = new HashMap<String,CollectionPersister>();
 		Map<String,Set<String>> inFlightEntityToCollectionRoleMap = new HashMap<String,Set<String>>();
 		Map<String,CollectionMetadata> tmpCollectionMetadata = new HashMap<String,CollectionMetadata>();
 		for ( final Collection model : metadata.getCollectionBindings() ) {
 			final String cacheRegionName = cacheRegionPrefix + model.getCacheRegionName();
 			final AccessType accessType = AccessType.fromExternalName( model.getCacheConcurrencyStrategy() );
 			final CollectionRegionAccessStrategy accessStrategy;
 			if ( accessType != null && settings.isSecondLevelCacheEnabled() ) {
 				LOG.tracev( "Building shared cache region for collection data [{0}]", model.getRole() );
 				CollectionRegion collectionRegion = regionFactory.buildCollectionRegion(
 						cacheRegionName,
 						properties,
 						CacheDataDescriptionImpl.decode( model )
 				);
 				accessStrategy = collectionRegion.buildAccessStrategy( accessType );
 				cacheAccessStrategiesMap.put( cacheRegionName, accessStrategy );
 				cacheAccess.addCacheRegion( cacheRegionName, collectionRegion );
 			}
 			else {
 				accessStrategy = null;
 			}
 
 			final CollectionPersister persister = persisterFactory.createCollectionPersister(
 					model,
 					accessStrategy,
 					persisterCreationContext
 			);
 			collectionPersisters.put( model.getRole(), persister );
 			tmpCollectionMetadata.put( model.getRole(), persister.getCollectionMetadata() );
 			Type indexType = persister.getIndexType();
 			if ( indexType != null && indexType.isAssociationType() && !indexType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) indexType ).getAssociatedEntityName( this );
 				Set<String> roles = inFlightEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet<String>();
 					inFlightEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 			Type elementType = persister.getElementType();
 			if ( elementType.isAssociationType() && !elementType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) elementType ).getAssociatedEntityName( this );
 				Set<String> roles = inFlightEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet<String>();
 					inFlightEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 		}
 		this.collectionMetadata = Collections.unmodifiableMap( tmpCollectionMetadata );
 
 		for ( Map.Entry<String,Set<String>> entityToCollectionRoleMapEntry : inFlightEntityToCollectionRoleMap.entrySet() ) {
 			entityToCollectionRoleMapEntry.setValue(
 					Collections.unmodifiableSet( entityToCollectionRoleMapEntry.getValue() )
 			);
 		}
 		this.collectionRolesByEntityParticipant = Collections.unmodifiableMap( inFlightEntityToCollectionRoleMap );
 
 		//Named Queries:
 		this.namedQueryRepository = metadata.buildNamedQueryRepository( this );
 
 		// after *all* persisters and named queries are registered
 		for ( EntityPersister persister : entityPersisters.values() ) {
 			persister.generateEntityDefinition();
 		}
 
 		for ( EntityPersister persister : entityPersisters.values() ) {
 			persister.postInstantiate();
 			registerEntityNameResolvers( persister );
 		}
 		for ( CollectionPersister persister : collectionPersisters.values() ) {
 			persister.postInstantiate();
 		}
 
 		LOG.debug( "Instantiated session factory" );
 
 		settings.getMultiTableBulkIdStrategy().prepare(
 				jdbcServices,
 				buildLocalConnectionAccess(),
 				metadata,
 				sessionFactoryOptions
 		);
 
 
 		if ( settings.isAutoCreateSchema() ) {
 			new SchemaExport( serviceRegistry, metadata )
 					.setImportSqlCommandExtractor( serviceRegistry.getService( ImportSqlCommandExtractor.class ) )
 					.create( false, true );
 		}
 		if ( settings.isAutoUpdateSchema() ) {
 			new SchemaUpdate( serviceRegistry, metadata ).execute( false, true );
 		}
 		if ( settings.isAutoValidateSchema() ) {
 			new SchemaValidator( serviceRegistry, metadata ).validate();
 		}
 		if ( settings.isAutoDropSchema() ) {
 			schemaExport = new SchemaExport( serviceRegistry, metadata )
 					.setImportSqlCommandExtractor( serviceRegistry.getService( ImportSqlCommandExtractor.class ) );
 		}
 
 		currentSessionContext = buildCurrentSessionContext();
 
 		//checking for named queries
 		if ( settings.isNamedQueryStartupCheckingEnabled() ) {
 			final Map<String,HibernateException> errors = checkNamedQueries();
 			if ( ! errors.isEmpty() ) {
 				StringBuilder failingQueries = new StringBuilder( "Errors in named queries: " );
 				String sep = "";
 				for ( Map.Entry<String,HibernateException> entry : errors.entrySet() ) {
 					LOG.namedQueryError( entry.getKey(), entry.getValue() );
 					failingQueries.append( sep ).append( entry.getKey() );
 					sep = ", ";
 				}
 				throw new HibernateException( failingQueries.toString() );
 			}
 		}
 
 		// this needs to happen after persisters are all ready to go...
 		this.fetchProfiles = new HashMap<String,FetchProfile>();
 		for ( org.hibernate.mapping.FetchProfile mappingProfile : metadata.getFetchProfiles() ) {
 			final FetchProfile fetchProfile = new FetchProfile( mappingProfile.getName() );
 			for ( org.hibernate.mapping.FetchProfile.Fetch mappingFetch : mappingProfile.getFetches() ) {
 				// resolve the persister owning the fetch
 				final String entityName = getImportedClassName( mappingFetch.getEntity() );
 				final EntityPersister owner = entityName == null
 						? null
 						: entityPersisters.get( entityName );
 				if ( owner == null ) {
 					throw new HibernateException(
 							"Unable to resolve entity reference [" + mappingFetch.getEntity()
 									+ "] in fetch profile [" + fetchProfile.getName() + "]"
 					);
 				}
 
 				// validate the specified association fetch
 				Type associationType = owner.getPropertyType( mappingFetch.getAssociation() );
 				if ( associationType == null || !associationType.isAssociationType() ) {
 					throw new HibernateException( "Fetch profile [" + fetchProfile.getName() + "] specified an invalid association" );
 				}
 
 				// resolve the style
 				final Fetch.Style fetchStyle = Fetch.Style.parse( mappingFetch.getStyle() );
 
 				// then construct the fetch instance...
 				fetchProfile.addFetch( new Association( owner, mappingFetch.getAssociation() ), fetchStyle );
 				((Loadable) owner).registerAffectingFetchProfile( fetchProfile.getName() );
 			}
 			fetchProfiles.put( fetchProfile.getName(), fetchProfile );
 		}
 
-		this.transactionEnvironment = new TransactionEnvironmentImpl( this );
 		this.observer.sessionFactoryCreated( this );
 
 		SessionFactoryRegistry.INSTANCE.addSessionFactory(
 				uuid,
 				name,
 				settings.isSessionFactoryNameAlsoJndiName(),
 				this,
 				serviceRegistry.getService( JndiService.class )
 		);
 	}
 
 	private void applyCfgXmlValues(LoadedConfig aggregatedConfig, SessionFactoryServiceRegistry serviceRegistry) {
 		final JaccService jaccService = serviceRegistry.getService( JaccService.class );
 		if ( jaccService.getContextId() != null ) {
 			final JaccPermissionDeclarations permissions = aggregatedConfig.getJaccPermissions( jaccService.getContextId() );
 			if ( permissions != null ) {
 				for ( GrantedPermission grantedPermission : permissions.getPermissionDeclarations() ) {
 					jaccService.addPermission( grantedPermission );
 				}
 			}
 		}
 
 		if ( aggregatedConfig.getEventListenerMap() != null ) {
 			final ClassLoaderService cls = serviceRegistry.getService( ClassLoaderService.class );
 			final EventListenerRegistry eventListenerRegistry = serviceRegistry.getService( EventListenerRegistry.class );
 			for ( Map.Entry<EventType, Set<String>> entry : aggregatedConfig.getEventListenerMap().entrySet() ) {
 				final EventListenerGroup group = eventListenerRegistry.getEventListenerGroup( entry.getKey() );
 				for ( String listenerClassName : entry.getValue() ) {
 					try {
 						group.appendListener( cls.classForName( listenerClassName ).newInstance() );
 					}
 					catch (Exception e) {
 						throw new ConfigurationException( "Unable to instantiate event listener class : " + listenerClassName, e );
 					}
 				}
 			}
 		}
 	}
 
 	private NaturalIdRegionAccessStrategy determineNaturalIdRegionAccessStrategy(
 			RegionFactory regionFactory,
 			String cacheRegionPrefix,
 			Map cacheAccessStrategiesMap,
 			PersistentClass model) {
 		NaturalIdRegionAccessStrategy naturalIdAccessStrategy = null;
 		if ( model.hasNaturalId() && model.getNaturalIdCacheRegionName() != null ) {
 			final String naturalIdCacheRegionName = cacheRegionPrefix + model.getNaturalIdCacheRegionName();
 			naturalIdAccessStrategy = ( NaturalIdRegionAccessStrategy ) cacheAccessStrategiesMap.get( naturalIdCacheRegionName );
 
 			if ( naturalIdAccessStrategy == null && settings.isSecondLevelCacheEnabled() ) {
 				final CacheDataDescriptionImpl cacheDataDescription = CacheDataDescriptionImpl.decode( model );
 
 				NaturalIdRegion naturalIdRegion = null;
 				try {
 					naturalIdRegion = regionFactory.buildNaturalIdRegion(
 							naturalIdCacheRegionName,
 							properties,
 							cacheDataDescription
 					);
 				}
 				catch ( UnsupportedOperationException e ) {
 					LOG.warnf(
 							"Shared cache region factory [%s] does not support natural id caching; " +
 									"shared NaturalId caching will be disabled for not be enabled for %s",
 							regionFactory.getClass().getName(),
 							model.getEntityName()
 					);
 				}
 
 				if (naturalIdRegion != null) {
 					naturalIdAccessStrategy = naturalIdRegion.buildAccessStrategy( regionFactory.getDefaultAccessType() );
 					cacheAccessStrategiesMap.put( naturalIdCacheRegionName, naturalIdAccessStrategy );
 					cacheAccess.addCacheRegion(  naturalIdCacheRegionName, naturalIdRegion );
 				}
 			}
 		}
 		return naturalIdAccessStrategy;
 	}
 
 	private EntityRegionAccessStrategy determineEntityRegionAccessStrategy(
 			RegionFactory regionFactory,
 			Map cacheAccessStrategiesMap,
 			PersistentClass model,
 			String cacheRegionName) {
 		EntityRegionAccessStrategy accessStrategy = ( EntityRegionAccessStrategy ) cacheAccessStrategiesMap.get( cacheRegionName );
 		if ( accessStrategy == null && settings.isSecondLevelCacheEnabled() ) {
 			final AccessType accessType = AccessType.fromExternalName( model.getCacheConcurrencyStrategy() );
 			if ( accessType != null ) {
 				LOG.tracef( "Building shared cache region for entity data [%s]", model.getEntityName() );
 				EntityRegion entityRegion = regionFactory.buildEntityRegion( cacheRegionName, properties, CacheDataDescriptionImpl
 																					 .decode( model ) );
 				accessStrategy = entityRegion.buildAccessStrategy( accessType );
 				cacheAccessStrategiesMap.put( cacheRegionName, accessStrategy );
 				cacheAccess.addCacheRegion( cacheRegionName, entityRegion );
 			}
 		}
 		return accessStrategy;
 	}
 
 	private JdbcConnectionAccess buildLocalConnectionAccess() {
 		return new JdbcConnectionAccess() {
 			@Override
 			public Connection obtainConnection() throws SQLException {
 				return settings.getMultiTenancyStrategy() == MultiTenancyStrategy.NONE
 						? serviceRegistry.getService( ConnectionProvider.class ).getConnection()
 						: serviceRegistry.getService( MultiTenantConnectionProvider.class ).getAnyConnection();
 			}
 
 			@Override
 			public void releaseConnection(Connection connection) throws SQLException {
 				if ( settings.getMultiTenancyStrategy() == MultiTenancyStrategy.NONE ) {
 					serviceRegistry.getService( ConnectionProvider.class ).closeConnection( connection );
 				}
 				else {
 					serviceRegistry.getService( MultiTenantConnectionProvider.class ).releaseAnyConnection( connection );
 				}
 			}
 
 			@Override
 			public boolean supportsAggressiveRelease() {
 				return false;
 			}
 		};
 	}
 
 	@SuppressWarnings( {"unchecked"} )
 	private static Properties createPropertiesFromMap(Map map) {
 		Properties properties = new Properties();
 		properties.putAll( map );
 		return properties;
 	}
 
 	public Session openSession() throws HibernateException {
 		return withOptions().openSession();
 	}
 
 	public Session openTemporarySession() throws HibernateException {
 		return withOptions()
 				.autoClose( false )
 				.flushBeforeCompletion( false )
 				.connectionReleaseMode( ConnectionReleaseMode.AFTER_STATEMENT )
 				.openSession();
 	}
 
 	public Session getCurrentSession() throws HibernateException {
 		if ( currentSessionContext == null ) {
 			throw new HibernateException( "No CurrentSessionContext configured!" );
 		}
 		return currentSessionContext.currentSession();
 	}
 
 	@Override
 	public SessionBuilderImplementor withOptions() {
 		return new SessionBuilderImpl( this );
 	}
 
 	@Override
 	public StatelessSessionBuilder withStatelessOptions() {
 		return new StatelessSessionBuilderImpl( this );
 	}
 
 	public StatelessSession openStatelessSession() {
 		return withStatelessOptions().openStatelessSession();
 	}
 
 	public StatelessSession openStatelessSession(Connection connection) {
 		return withStatelessOptions().connection( connection ).openStatelessSession();
 	}
 
 	@Override
 	public void addObserver(SessionFactoryObserver observer) {
 		this.observer.addObserver( observer );
 	}
 
-	public TransactionEnvironment getTransactionEnvironment() {
-		return transactionEnvironment;
-	}
-
 	public Properties getProperties() {
 		return properties;
 	}
 
 	public IdentifierGeneratorFactory getIdentifierGeneratorFactory() {
 		return null;
 	}
 
 	public TypeResolver getTypeResolver() {
 		return typeResolver;
 	}
 
 	private void registerEntityNameResolvers(EntityPersister persister) {
 		if ( persister.getEntityMetamodel() == null || persister.getEntityMetamodel().getTuplizer() == null ) {
 			return;
 		}
 		registerEntityNameResolvers( persister.getEntityMetamodel().getTuplizer() );
 	}
 
 	private void registerEntityNameResolvers(EntityTuplizer tuplizer) {
 		EntityNameResolver[] resolvers = tuplizer.getEntityNameResolvers();
 		if ( resolvers == null ) {
 			return;
 		}
 
 		for ( EntityNameResolver resolver : resolvers ) {
 			registerEntityNameResolver( resolver );
 		}
 	}
 
 	private static final Object ENTITY_NAME_RESOLVER_MAP_VALUE = new Object();
 
 	public void registerEntityNameResolver(EntityNameResolver resolver) {
 		entityNameResolvers.put( resolver, ENTITY_NAME_RESOLVER_MAP_VALUE );
 	}
 
 	@Override
 	public Iterable<EntityNameResolver> iterateEntityNameResolvers() {
 		return entityNameResolvers.keySet();
 	}
 
 	public QueryPlanCache getQueryPlanCache() {
 		return queryPlanCache;
 	}
 
 	private Map<String,HibernateException> checkNamedQueries() throws HibernateException {
 		return namedQueryRepository.checkNamedQueries( queryPlanCache );
 	}
 
 	public EntityPersister getEntityPersister(String entityName) throws MappingException {
 		EntityPersister result = entityPersisters.get(entityName);
 		if ( result == null ) {
 			throw new MappingException( "Unknown entity: " + entityName );
 		}
 		return result;
 	}
 
 	@Override
 	public Map<String, CollectionPersister> getCollectionPersisters() {
 		return collectionPersisters;
 	}
 
 	@Override
 	public Map<String, EntityPersister> getEntityPersisters() {
 		return entityPersisters;
 	}
 
 	public CollectionPersister getCollectionPersister(String role) throws MappingException {
 		CollectionPersister result = collectionPersisters.get(role);
 		if ( result == null ) {
 			throw new MappingException( "Unknown collection role: " + role );
 		}
 		return result;
 	}
 
 	public Settings getSettings() {
 		return settings;
 	}
 
 	@Override
 	public SessionFactoryOptions getSessionFactoryOptions() {
 		return sessionFactoryOptions;
 	}
 
 	public JdbcServices getJdbcServices() {
 		return jdbcServices;
 	}
 
 	public Dialect getDialect() {
 		if ( serviceRegistry == null ) {
 			throw new IllegalStateException( "Cannot determine dialect because serviceRegistry is null." );
 		}
 		return dialect;
 	}
 
 	public Interceptor getInterceptor() {
 		return sessionFactoryOptions.getInterceptor();
 	}
 
 	public SQLExceptionConverter getSQLExceptionConverter() {
 		return getSQLExceptionHelper().getSqlExceptionConverter();
 	}
 
 	public SqlExceptionHelper getSQLExceptionHelper() {
 		return getJdbcServices().getSqlExceptionHelper();
 	}
 
 	public Set<String> getCollectionRolesByEntityParticipant(String entityName) {
 		return collectionRolesByEntityParticipant.get( entityName );
 	}
 
 	@Override
 	public Reference getReference() {
 		// from javax.naming.Referenceable
         LOG.debug( "Returning a Reference to the SessionFactory" );
 		return new Reference(
 				SessionFactoryImpl.class.getName(),
 				new StringRefAddr("uuid", uuid),
 				SessionFactoryRegistry.ObjectFactoryImpl.class.getName(),
 				null
 		);
 	}
 
 	@Override
 	public NamedQueryRepository getNamedQueryRepository() {
 		return namedQueryRepository;
 	}
 
 	public void registerNamedQueryDefinition(String name, NamedQueryDefinition definition) {
 		namedQueryRepository.registerNamedQueryDefinition( name, definition );
 	}
 
 	public NamedQueryDefinition getNamedQuery(String queryName) {
 		return namedQueryRepository.getNamedQueryDefinition( queryName );
 	}
 
 	public void registerNamedSQLQueryDefinition(String name, NamedSQLQueryDefinition definition) {
 		namedQueryRepository.registerNamedSQLQueryDefinition( name, definition );
 	}
 
 	public NamedSQLQueryDefinition getNamedSQLQuery(String queryName) {
 		return namedQueryRepository.getNamedSQLQueryDefinition( queryName );
 	}
 
 	public ResultSetMappingDefinition getResultSetMapping(String mappingName) {
 		return namedQueryRepository.getResultSetMappingDefinition( mappingName );
 	}
 
 	public Type getIdentifierType(String className) throws MappingException {
 		return getEntityPersister(className).getIdentifierType();
 	}
 	public String getIdentifierPropertyName(String className) throws MappingException {
 		return getEntityPersister(className).getIdentifierPropertyName();
 	}
 
 	public Type[] getReturnTypes(String queryString) throws HibernateException {
 		final ReturnMetadata metadata = queryPlanCache.getHQLQueryPlan( queryString, false, Collections.EMPTY_MAP )
 				.getReturnMetadata();
 		return metadata == null ? null : metadata.getReturnTypes();
 	}
 
 	public String[] getReturnAliases(String queryString) throws HibernateException {
 		final ReturnMetadata metadata = queryPlanCache.getHQLQueryPlan( queryString, false, Collections.EMPTY_MAP )
 				.getReturnMetadata();
 		return metadata == null ? null : metadata.getReturnAliases();
 	}
 
 	public ClassMetadata getClassMetadata(Class persistentClass) throws HibernateException {
 		return getClassMetadata( persistentClass.getName() );
 	}
 
 	public CollectionMetadata getCollectionMetadata(String roleName) throws HibernateException {
 		return collectionMetadata.get(roleName);
 	}
 
 	public ClassMetadata getClassMetadata(String entityName) throws HibernateException {
 		return classMetadata.get( entityName );
 	}
 
 	/**
 	 * Given the name of an entity class, determine all the class and interface names by which it can be
 	 * referenced in an HQL query.
 	 *
      * @param className The name of the entity class
 	 *
 	 * @return the names of all persistent (mapped) classes that extend or implement the
 	 *     given class or interface, accounting for implicit/explicit polymorphism settings
 	 *     and excluding mapped subclasses/joined-subclasses of other classes in the result.
 	 * @throws MappingException
 	 */
 	public String[] getImplementors(String className) throws MappingException {
 
 		final Class clazz;
 		try {
 			clazz = serviceRegistry.getService( ClassLoaderService.class ).classForName( className );
 		}
 		catch (ClassLoadingException cnfe) {
 			return new String[] { className }; //for a dynamic-class
 		}
 
 		ArrayList<String> results = new ArrayList<String>();
 		for ( EntityPersister checkPersister : entityPersisters.values() ) {
 			if ( ! Queryable.class.isInstance( checkPersister ) ) {
 				continue;
 			}
 			final Queryable checkQueryable = Queryable.class.cast( checkPersister );
 			final String checkQueryableEntityName = checkQueryable.getEntityName();
 			final boolean isMappedClass = className.equals( checkQueryableEntityName );
 			if ( checkQueryable.isExplicitPolymorphism() ) {
 				if ( isMappedClass ) {
 					return new String[] { className }; //NOTE EARLY EXIT
 				}
 			}
 			else {
 				if ( isMappedClass ) {
 					results.add( checkQueryableEntityName );
 				}
 				else {
 					final Class mappedClass = checkQueryable.getMappedClass();
 					if ( mappedClass != null && clazz.isAssignableFrom( mappedClass ) ) {
 						final boolean assignableSuperclass;
 						if ( checkQueryable.isInherited() ) {
 							Class mappedSuperclass = getEntityPersister( checkQueryable.getMappedSuperclass() ).getMappedClass();
 							assignableSuperclass = clazz.isAssignableFrom( mappedSuperclass );
 						}
 						else {
 							assignableSuperclass = false;
 						}
 						if ( !assignableSuperclass ) {
 							results.add( checkQueryableEntityName );
 						}
 					}
 				}
 			}
 		}
 		return results.toArray( new String[results.size()] );
 	}
 
 	@Override
 	public String getImportedClassName(String className) {
 		String result = imports.get( className );
 		if ( result == null ) {
 			try {
 				serviceRegistry.getService( ClassLoaderService.class ).classForName( className );
 				imports.put( className, className );
 				return className;
 			}
 			catch ( ClassLoadingException cnfe ) {
 				return null;
 			}
 		}
 		else {
 			return result;
 		}
 	}
 
 	public Map<String,ClassMetadata> getAllClassMetadata() throws HibernateException {
 		return classMetadata;
 	}
 
 	public Map getAllCollectionMetadata() throws HibernateException {
 		return collectionMetadata;
 	}
 
 	public Type getReferencedPropertyType(String className, String propertyName)
 		throws MappingException {
 		return getEntityPersister( className ).getPropertyType( propertyName );
 	}
 
 	public ConnectionProvider getConnectionProvider() {
 		return jdbcServices.getConnectionProvider();
 	}
 
 	/**
 	 * Closes the session factory, releasing all held resources.
 	 *
 	 * <ol>
 	 * <li>cleans up used cache regions and "stops" the cache provider.
 	 * <li>close the JDBC connection
 	 * <li>remove the JNDI binding
 	 * </ol>
 	 *
 	 * Note: Be aware that the sessionFactory instance still can
 	 * be a "heavy" object memory wise after close() has been called.  Thus
 	 * it is important to not keep referencing the instance to let the garbage
 	 * collector release the memory.
 	 * @throws HibernateException
 	 */
 	public void close() throws HibernateException {
 
 		if ( isClosed ) {
 			LOG.trace( "Already closed" );
 			return;
 		}
 
 		LOG.closing();
 
 		isClosed = true;
 
 		settings.getMultiTableBulkIdStrategy().release( jdbcServices, buildLocalConnectionAccess() );
 
 		Iterator iter = entityPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			EntityPersister p = (EntityPersister) iter.next();
 			if ( p.hasCache() ) {
 				p.getCacheAccessStrategy().getRegion().destroy();
 			}
 		}
 
 		iter = collectionPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			CollectionPersister p = (CollectionPersister) iter.next();
 			if ( p.hasCache() ) {
 				p.getCacheAccessStrategy().getRegion().destroy();
 			}
 		}
 
 		cacheAccess.close();
 
 		queryPlanCache.cleanup();
 
 		if ( settings.isAutoDropSchema() ) {
 			schemaExport.drop( false, true );
 		}
 
 		SessionFactoryRegistry.INSTANCE.removeSessionFactory(
 				uuid,
 				name,
 				settings.isSessionFactoryNameAlsoJndiName(),
 				serviceRegistry.getService( JndiService.class )
 		);
 
 		observer.sessionFactoryClosed( this );
 		serviceRegistry.destroy();
 	}
 
 	public Cache getCache() {
 		return cacheAccess;
 	}
 
 	public void evictEntity(String entityName, Serializable id) throws HibernateException {
 		getCache().evictEntity( entityName, id );
 	}
 
 	public void evictEntity(String entityName) throws HibernateException {
 		getCache().evictEntityRegion( entityName );
 	}
 
 	public void evict(Class persistentClass, Serializable id) throws HibernateException {
 		getCache().evictEntity( persistentClass, id );
 	}
 
 	public void evict(Class persistentClass) throws HibernateException {
 		getCache().evictEntityRegion( persistentClass );
 	}
 
 	public void evictCollection(String roleName, Serializable id) throws HibernateException {
 		getCache().evictCollection( roleName, id );
 	}
 
 	public void evictCollection(String roleName) throws HibernateException {
 		getCache().evictCollectionRegion( roleName );
 	}
 
 	public void evictQueries() throws HibernateException {
 		cacheAccess.evictQueries();
 	}
 
 	public void evictQueries(String regionName) throws HibernateException {
 		getCache().evictQueryRegion( regionName );
 	}
 
 	public UpdateTimestampsCache getUpdateTimestampsCache() {
 		return cacheAccess.getUpdateTimestampsCache();
 	}
 
 	public QueryCache getQueryCache() {
 		return cacheAccess.getQueryCache();
 	}
 
 	public QueryCache getQueryCache(String regionName) throws HibernateException {
 		return cacheAccess.getQueryCache( regionName );
 	}
 
 	public Region getSecondLevelCacheRegion(String regionName) {
 		return cacheAccess.getSecondLevelCacheRegion( regionName );
 	}
 
 	public Region getNaturalIdCacheRegion(String regionName) {
 		return cacheAccess.getNaturalIdCacheRegion( regionName );
 	}
 
 	@SuppressWarnings( {"unchecked"})
 	public Map getAllSecondLevelCacheRegions() {
 		return cacheAccess.getAllSecondLevelCacheRegions();
 	}
 
 	public boolean isClosed() {
 		return isClosed;
 	}
 
 	public Statistics getStatistics() {
 		return getStatisticsImplementor();
 	}
 
 	public StatisticsImplementor getStatisticsImplementor() {
 		return serviceRegistry.getService( StatisticsImplementor.class );
 	}
 
 	public FilterDefinition getFilterDefinition(String filterName) throws HibernateException {
 		FilterDefinition def = filters.get( filterName );
 		if ( def == null ) {
 			throw new HibernateException( "No such filter configured [" + filterName + "]" );
 		}
 		return def;
 	}
 
 	public boolean containsFetchProfileDefinition(String name) {
 		return fetchProfiles.containsKey( name );
 	}
 
 	public Set getDefinedFilterNames() {
 		return filters.keySet();
 	}
 
 	public IdentifierGenerator getIdentifierGenerator(String rootEntityName) {
 		return identifierGenerators.get(rootEntityName);
 	}
 
-	private TransactionFactory transactionFactory() {
-		return serviceRegistry.getService( TransactionFactory.class );
-	}
-
 	private boolean canAccessTransactionManager() {
 		try {
 			return serviceRegistry.getService( JtaPlatform.class ).retrieveTransactionManager() != null;
 		}
 		catch (Exception e) {
 			return false;
 		}
 	}
 
 	private CurrentSessionContext buildCurrentSessionContext() {
 		String impl = properties.getProperty( Environment.CURRENT_SESSION_CONTEXT_CLASS );
 		// for backward-compatibility
 		if ( impl == null ) {
 			if ( canAccessTransactionManager() ) {
 				impl = "jta";
 			}
 			else {
 				return null;
 			}
 		}
 
 		if ( "jta".equals( impl ) ) {
-			if ( ! transactionFactory().compatibleWithJtaSynchronization() ) {
-				LOG.autoFlushWillNotWork();
-			}
+//			if ( ! transactionFactory().compatibleWithJtaSynchronization() ) {
+//				LOG.autoFlushWillNotWork();
+//			}
 			return new JTASessionContext( this );
 		}
 		else if ( "thread".equals( impl ) ) {
 			return new ThreadLocalSessionContext( this );
 		}
 		else if ( "managed".equals( impl ) ) {
 			return new ManagedSessionContext( this );
 		}
 		else {
 			try {
 				Class implClass = serviceRegistry.getService( ClassLoaderService.class ).classForName( impl );
 				return ( CurrentSessionContext ) implClass
 						.getConstructor( new Class[] { SessionFactoryImplementor.class } )
 						.newInstance( this );
 			}
 			catch( Throwable t ) {
 				LOG.unableToConstructCurrentSessionContext( impl, t );
 				return null;
 			}
 		}
 	}
 
 	@Override
 	public ServiceRegistryImplementor getServiceRegistry() {
 		return serviceRegistry;
 	}
 
 	@Override
 	public EntityNotFoundDelegate getEntityNotFoundDelegate() {
 		return sessionFactoryOptions.getEntityNotFoundDelegate();
 	}
 
 	public SQLFunctionRegistry getSqlFunctionRegistry() {
 		return sqlFunctionRegistry;
 	}
 
 	public FetchProfile getFetchProfile(String name) {
 		return fetchProfiles.get( name );
 	}
 
 	public TypeHelper getTypeHelper() {
 		return typeHelper;
 	}
 
 	static class SessionBuilderImpl implements SessionBuilderImplementor {
 		private static final Logger log = CoreLogging.logger( SessionBuilderImpl.class );
 
 		private final SessionFactoryImpl sessionFactory;
 		private SessionOwner sessionOwner;
 		private Interceptor interceptor;
 		private Connection connection;
 		private ConnectionReleaseMode connectionReleaseMode;
 		private boolean autoClose;
 		private boolean autoJoinTransactions = true;
 		private boolean flushBeforeCompletion;
 		private String tenantIdentifier;
 		private List<SessionEventListener> listeners;
 
 		SessionBuilderImpl(SessionFactoryImpl sessionFactory) {
 			this.sessionFactory = sessionFactory;
 			this.sessionOwner = null;
 			final Settings settings = sessionFactory.settings;
 
 			// set up default builder values...
 			this.interceptor = sessionFactory.getInterceptor();
 			this.connectionReleaseMode = settings.getConnectionReleaseMode();
 			this.autoClose = settings.isAutoCloseSessionEnabled();
 			this.flushBeforeCompletion = settings.isFlushBeforeCompletionEnabled();
 
 			if ( sessionFactory.getCurrentTenantIdentifierResolver() != null ) {
 				tenantIdentifier = sessionFactory.getCurrentTenantIdentifierResolver().resolveCurrentTenantIdentifier();
 			}
 
 			listeners = settings.getBaselineSessionEventsListenerBuilder().buildBaselineList();
 		}
 
-		protected TransactionCoordinatorImpl getTransactionCoordinator() {
+		protected TransactionCoordinator getTransactionCoordinator() {
+			return null;
+		}
+
+		protected JdbcCoordinatorImpl getJdbcCoordinator() {
+			return null;
+		}
+
+		protected Transaction getTransaction() {
 			return null;
 		}
 
 		protected ActionQueue.TransactionCompletionProcesses getTransactionCompletionProcesses() {
 			return null;
 		}
 
 		@Override
 		public Session openSession() {
 			log.tracef( "Opening Hibernate Session.  tenant=%s, owner=%s", tenantIdentifier, sessionOwner );
 			final SessionImpl session = new SessionImpl(
 					connection,
 					sessionFactory,
 					sessionOwner,
 					getTransactionCoordinator(),
+					getJdbcCoordinator(),
+					getTransaction(),
 					getTransactionCompletionProcesses(),
 					autoJoinTransactions,
 					sessionFactory.settings.getRegionFactory().nextTimestamp(),
 					interceptor,
 					flushBeforeCompletion,
 					autoClose,
 					connectionReleaseMode,
 					tenantIdentifier
 			);
 
 			for ( SessionEventListener listener : listeners ) {
 				session.getEventListenerManager().addListener( listener );
 			}
 
 			return session;
 		}
 
 		@Override
 		public SessionBuilder owner(SessionOwner sessionOwner) {
 			this.sessionOwner = sessionOwner;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder interceptor(Interceptor interceptor) {
 			this.interceptor = interceptor;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder noInterceptor() {
 			this.interceptor = EmptyInterceptor.INSTANCE;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder connection(Connection connection) {
 			this.connection = connection;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder connectionReleaseMode(ConnectionReleaseMode connectionReleaseMode) {
 			this.connectionReleaseMode = connectionReleaseMode;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder autoJoinTransactions(boolean autoJoinTransactions) {
 			this.autoJoinTransactions = autoJoinTransactions;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder autoClose(boolean autoClose) {
 			this.autoClose = autoClose;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder flushBeforeCompletion(boolean flushBeforeCompletion) {
 			this.flushBeforeCompletion = flushBeforeCompletion;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder tenantIdentifier(String tenantIdentifier) {
 			this.tenantIdentifier = tenantIdentifier;
 			return this;
 		}
 
 		@Override
 		public SessionBuilder eventListeners(SessionEventListener... listeners) {
 			Collections.addAll( this.listeners, listeners );
 			return this;
 		}
 
 		@Override
 		public SessionBuilder clearEventListeners() {
 			listeners.clear();
 			return this;
 		}
 	}
 
 	public static class StatelessSessionBuilderImpl implements StatelessSessionBuilder {
 		private final SessionFactoryImpl sessionFactory;
 		private Connection connection;
 		private String tenantIdentifier;
 
 		public StatelessSessionBuilderImpl(SessionFactoryImpl sessionFactory) {
 			this.sessionFactory = sessionFactory;
 
 			if ( sessionFactory.getCurrentTenantIdentifierResolver() != null ) {
 				tenantIdentifier = sessionFactory.getCurrentTenantIdentifierResolver().resolveCurrentTenantIdentifier();
 			}
 		}
 
 		@Override
 		public StatelessSession openStatelessSession() {
 			return new StatelessSessionImpl( connection, tenantIdentifier, sessionFactory,
 					sessionFactory.settings.getRegionFactory().nextTimestamp() );
 		}
 
 		@Override
 		public StatelessSessionBuilder connection(Connection connection) {
 			this.connection = connection;
 			return this;
 		}
 
 		@Override
 		public StatelessSessionBuilder tenantIdentifier(String tenantIdentifier) {
 			this.tenantIdentifier = tenantIdentifier;
 			return this;
 		}
 	}
 
 	@Override
 	public CustomEntityDirtinessStrategy getCustomEntityDirtinessStrategy() {
 		return getSessionFactoryOptions().getCustomEntityDirtinessStrategy();
 	}
 
 	@Override
 	public CurrentTenantIdentifierResolver getCurrentTenantIdentifierResolver() {
 		return getSessionFactoryOptions().getCurrentTenantIdentifierResolver();
 	}
 
 
 	// Serialization handling ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Custom serialization hook defined by Java spec.  Used when the factory is directly serialized
 	 *
 	 * @param out The stream into which the object is being serialized.
 	 *
 	 * @throws IOException Can be thrown by the stream
 	 */
 	private void writeObject(ObjectOutputStream out) throws IOException {
 		LOG.debugf( "Serializing: %s", uuid );
 		out.defaultWriteObject();
 		LOG.trace( "Serialized" );
 	}
 
 	/**
 	 * Custom serialization hook defined by Java spec.  Used when the factory is directly deserialized
 	 *
 	 * @param in The stream from which the object is being deserialized.
 	 *
 	 * @throws IOException Can be thrown by the stream
 	 * @throws ClassNotFoundException Again, can be thrown by the stream
 	 */
 	private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException {
 		LOG.trace( "Deserializing" );
 		in.defaultReadObject();
 		LOG.debugf( "Deserialized: %s", uuid );
 	}
 
 	/**
 	 * Custom serialization hook defined by Java spec.  Used when the factory is directly deserialized.
 	 * Here we resolve the uuid/name read from the stream previously to resolve the SessionFactory
 	 * instance to use based on the registrations with the {@link SessionFactoryRegistry}
 	 *
 	 * @return The resolved factory to use.
 	 *
 	 * @throws InvalidObjectException Thrown if we could not resolve the factory by uuid/name.
 	 */
 	private Object readResolve() throws InvalidObjectException {
 		LOG.trace( "Resolving serialized SessionFactory" );
 		return locateSessionFactoryOnDeserialization( uuid, name );
 	}
 
 	private static SessionFactory locateSessionFactoryOnDeserialization(String uuid, String name) throws InvalidObjectException{
 		final SessionFactory uuidResult = SessionFactoryRegistry.INSTANCE.getSessionFactory( uuid );
 		if ( uuidResult != null ) {
 			LOG.debugf( "Resolved SessionFactory by UUID [%s]", uuid );
 			return uuidResult;
 		}
 
 		// in case we were deserialized in a different JVM, look for an instance with the same name
 		// (provided we were given a name)
 		if ( name != null ) {
 			final SessionFactory namedResult = SessionFactoryRegistry.INSTANCE.getNamedSessionFactory( name );
 			if ( namedResult != null ) {
 				LOG.debugf( "Resolved SessionFactory by name [%s]", name );
 				return namedResult;
 			}
 		}
 
 		throw new InvalidObjectException( "Could not find a SessionFactory [uuid=" + uuid + ",name=" + name + "]" );
 	}
 
 	/**
 	 * Custom serialization hook used during Session serialization.
 	 *
 	 * @param oos The stream to which to write the factory
 	 * @throws IOException Indicates problems writing out the serial data stream
 	 */
 	void serialize(ObjectOutputStream oos) throws IOException {
 		oos.writeUTF( uuid );
 		oos.writeBoolean( name != null );
 		if ( name != null ) {
 			oos.writeUTF( name );
 		}
 	}
 
 	/**
 	 * Custom deserialization hook used during Session deserialization.
 	 *
 	 * @param ois The stream from which to "read" the factory
 	 * @return The deserialized factory
 	 * @throws IOException indicates problems reading back serial data stream
 	 * @throws ClassNotFoundException indicates problems reading back serial data stream
 	 */
 	static SessionFactoryImpl deserialize(ObjectInputStream ois) throws IOException, ClassNotFoundException {
 		LOG.trace( "Deserializing SessionFactory from Session" );
 		final String uuid = ois.readUTF();
 		boolean isNamed = ois.readBoolean();
 		final String name = isNamed ? ois.readUTF() : null;
 		return (SessionFactoryImpl) locateSessionFactoryOnDeserialization( uuid, name );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/SessionImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/SessionImpl.java
index 3e0a3f5d36..5ebcfe1447 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/SessionImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/SessionImpl.java
@@ -1,2847 +1,2867 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2005-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
+import javax.persistence.EntityNotFoundException;
+import javax.transaction.SystemException;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Reader;
 import java.io.Serializable;
 import java.sql.Blob;
 import java.sql.Clob;
 import java.sql.Connection;
 import java.sql.NClob;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
-import javax.persistence.EntityNotFoundException;
+
+import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.CacheMode;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.Criteria;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.Filter;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.IdentifierLoadAccess;
 import org.hibernate.Interceptor;
 import org.hibernate.LobHelper;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.NaturalIdLoadAccess;
 import org.hibernate.ObjectDeletedException;
 import org.hibernate.ObjectNotFoundException;
 import org.hibernate.Query;
 import org.hibernate.QueryException;
 import org.hibernate.ReplicationMode;
 import org.hibernate.SQLQuery;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.SessionBuilder;
 import org.hibernate.SessionEventListener;
 import org.hibernate.SessionException;
 import org.hibernate.SharedSessionBuilder;
 import org.hibernate.SimpleNaturalIdLoadAccess;
 import org.hibernate.Transaction;
 import org.hibernate.TransientObjectException;
 import org.hibernate.TypeHelper;
 import org.hibernate.UnknownProfileException;
 import org.hibernate.UnresolvableObjectException;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.criterion.NaturalIdentifier;
 import org.hibernate.engine.internal.SessionEventListenerManagerImpl;
 import org.hibernate.engine.internal.StatefulPersistenceContext;
 import org.hibernate.engine.jdbc.LobCreator;
 import org.hibernate.engine.jdbc.NonContextualLobCreator;
+import org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl;
+import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.engine.query.spi.FilterQueryPlan;
 import org.hibernate.engine.query.spi.HQLQueryPlan;
 import org.hibernate.engine.query.spi.NativeSQLQueryPlan;
 import org.hibernate.engine.query.spi.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.spi.ActionQueue;
 import org.hibernate.engine.spi.CollectionEntry;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionOwner;
 import org.hibernate.engine.spi.Status;
-import org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
-import org.hibernate.engine.transaction.spi.TransactionImplementor;
+import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
 import org.hibernate.engine.transaction.spi.TransactionObserver;
 import org.hibernate.event.service.spi.EventListenerGroup;
 import org.hibernate.event.service.spi.EventListenerRegistry;
 import org.hibernate.event.spi.AutoFlushEvent;
 import org.hibernate.event.spi.AutoFlushEventListener;
 import org.hibernate.event.spi.ClearEvent;
 import org.hibernate.event.spi.ClearEventListener;
 import org.hibernate.event.spi.DeleteEvent;
 import org.hibernate.event.spi.DeleteEventListener;
 import org.hibernate.event.spi.DirtyCheckEvent;
 import org.hibernate.event.spi.DirtyCheckEventListener;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.event.spi.EventType;
 import org.hibernate.event.spi.EvictEvent;
 import org.hibernate.event.spi.EvictEventListener;
 import org.hibernate.event.spi.FlushEvent;
 import org.hibernate.event.spi.FlushEventListener;
 import org.hibernate.event.spi.InitializeCollectionEvent;
 import org.hibernate.event.spi.InitializeCollectionEventListener;
 import org.hibernate.event.spi.LoadEvent;
 import org.hibernate.event.spi.LoadEventListener;
 import org.hibernate.event.spi.LoadEventListener.LoadType;
 import org.hibernate.event.spi.LockEvent;
 import org.hibernate.event.spi.LockEventListener;
 import org.hibernate.event.spi.MergeEvent;
 import org.hibernate.event.spi.MergeEventListener;
 import org.hibernate.event.spi.PersistEvent;
 import org.hibernate.event.spi.PersistEventListener;
 import org.hibernate.event.spi.RefreshEvent;
 import org.hibernate.event.spi.RefreshEventListener;
 import org.hibernate.event.spi.ReplicateEvent;
 import org.hibernate.event.spi.ReplicateEventListener;
 import org.hibernate.event.spi.ResolveNaturalIdEvent;
 import org.hibernate.event.spi.ResolveNaturalIdEventListener;
 import org.hibernate.event.spi.SaveOrUpdateEvent;
 import org.hibernate.event.spi.SaveOrUpdateEventListener;
 import org.hibernate.internal.CriteriaImpl.CriterionEntry;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.jdbc.ReturningWork;
 import org.hibernate.jdbc.Work;
 import org.hibernate.jdbc.WorkExecutor;
 import org.hibernate.jdbc.WorkExecutorVisitable;
 import org.hibernate.loader.criteria.CriteriaLoader;
 import org.hibernate.loader.custom.CustomLoader;
 import org.hibernate.loader.custom.CustomQuery;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.procedure.ProcedureCall;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.LazyInitializer;
+import org.hibernate.resource.jdbc.spi.JdbcSessionContext;
+import org.hibernate.resource.jdbc.spi.StatementInspector;
+import org.hibernate.resource.transaction.TransactionCoordinator;
+import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorImpl;
+import org.hibernate.resource.transaction.spi.TransactionStatus;
 import org.hibernate.stat.SessionStatistics;
 import org.hibernate.stat.internal.SessionStatisticsImpl;
 import org.hibernate.type.Type;
 
-import org.jboss.logging.Logger;
-
 /**
  * Concrete implementation of a Session.
  *
  * Exposes two interfaces:<ul>
  *     <li>{@link Session} to the application</li>
  *     <li>{@link org.hibernate.engine.spi.SessionImplementor} to other Hibernate components (SPI)</li>
  * </ul>
  *
  * This class is not thread-safe.
  *
  * @author Gavin King
  * @author Steve Ebersole
  * @author Brett Meyer
  */
 public final class SessionImpl extends AbstractSessionImpl implements EventSource {
 
 	// todo : need to find a clean way to handle the "event source" role
 	// a separate class responsible for generating/dispatching events just duplicates most of the Session methods...
 	// passing around separate interceptor, factory, actionQueue, and persistentContext is not manageable...
 
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SessionImpl.class.getName());
+	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
+			CoreMessageLogger.class,
+			SessionImpl.class.getName()
+	);
 
-   private static final boolean TRACE_ENABLED = LOG.isTraceEnabled();
+	private static final boolean TRACE_ENABLED = LOG.isTraceEnabled();
 
 	private transient long timestamp;
 
 	private transient SessionOwner sessionOwner;
 
 	private transient ActionQueue actionQueue;
 	private transient StatefulPersistenceContext persistenceContext;
-	private transient TransactionCoordinatorImpl transactionCoordinator;
+	private transient TransactionCoordinator transactionCoordinator;
+	private transient JdbcCoordinatorImpl jdbcCoordinator;
 	private transient Interceptor interceptor;
 	private transient EntityNameResolver entityNameResolver = new CoordinatingEntityNameResolver();
 
 	private transient ConnectionReleaseMode connectionReleaseMode;
 	private transient FlushMode flushMode = FlushMode.AUTO;
 	private transient CacheMode cacheMode = CacheMode.NORMAL;
 
 	private transient boolean autoClear; //for EJB3
 	private transient boolean autoJoinTransactions = true;
 	private transient boolean flushBeforeCompletionEnabled;
 	private transient boolean autoCloseSessionEnabled;
 
 	private transient int dontFlushFromFind;
 
 	private transient LoadQueryInfluencers loadQueryInfluencers;
 
 	private final transient boolean isTransactionCoordinatorShared;
 	private transient TransactionObserver transactionObserver;
 
 	private SessionEventListenerManagerImpl sessionEventsManager = new SessionEventListenerManagerImpl();
 
+	private transient JdbcSessionContext jdbcSessionContext;
+
 	/**
 	 * Constructor used for openSession(...) processing, as well as construction
 	 * of sessions for getCurrentSession().
 	 *
 	 * @param connection The user-supplied connection to use for this session.
 	 * @param factory The factory from which this session was obtained
 	 * @param transactionCoordinator The transaction coordinator to use, may be null to indicate that a new transaction
 	 * coordinator should get created.
 	 * @param autoJoinTransactions Should the session automatically join JTA transactions?
 	 * @param timestamp The timestamp for this session
 	 * @param interceptor The interceptor to be applied to this session
 	 * @param flushBeforeCompletionEnabled Should we auto flush before completion of transaction
 	 * @param autoCloseSessionEnabled Should we auto close after completion of transaction
 	 * @param connectionReleaseMode The mode by which we should release JDBC connections.
 	 * @param tenantIdentifier The tenant identifier to use.  May be null
 	 */
 	SessionImpl(
 			final Connection connection,
 			final SessionFactoryImpl factory,
 			final SessionOwner sessionOwner,
-			final TransactionCoordinatorImpl transactionCoordinator,
+			final TransactionCoordinator transactionCoordinator,
+			final JdbcCoordinatorImpl jdbcCoordinator,
+			final Transaction transaction,
 			final ActionQueue.TransactionCompletionProcesses transactionCompletionProcesses,
 			final boolean autoJoinTransactions,
 			final long timestamp,
 			final Interceptor interceptor,
 			final boolean flushBeforeCompletionEnabled,
 			final boolean autoCloseSessionEnabled,
 			final ConnectionReleaseMode connectionReleaseMode,
 			final String tenantIdentifier) {
 		super( factory, tenantIdentifier );
 		this.timestamp = timestamp;
 		this.sessionOwner = sessionOwner;
 		this.interceptor = interceptor == null ? EmptyInterceptor.INSTANCE : interceptor;
 		this.actionQueue = new ActionQueue( this );
 		this.persistenceContext = new StatefulPersistenceContext( this );
 
 		this.autoCloseSessionEnabled = autoCloseSessionEnabled;
 		this.flushBeforeCompletionEnabled = flushBeforeCompletionEnabled;
+		this.jdbcSessionContext = new JdbcSessionContextImpl( factory, getStatementInspector() );
 
 		if ( transactionCoordinator == null ) {
 			this.isTransactionCoordinatorShared = false;
 			this.connectionReleaseMode = connectionReleaseMode;
 			this.autoJoinTransactions = autoJoinTransactions;
 
-			this.transactionCoordinator = new TransactionCoordinatorImpl( connection, this );
-			this.transactionCoordinator.getJdbcCoordinator().getLogicalConnection().addObserver(
-					new ConnectionObserverStatsBridge( factory )
-			);
+			this.jdbcCoordinator = new JdbcCoordinatorImpl( connection, this );
+			this.transactionCoordinator = getTransactionCoordinatorBuilder().buildTransactionCoordinator( this.jdbcCoordinator );
+			this.currentHibernateTransaction = getTransaction();
 		}
 		else {
 			if ( connection != null ) {
 				throw new SessionException( "Cannot simultaneously share transaction context and specify connection" );
 			}
 			this.transactionCoordinator = transactionCoordinator;
+			this.jdbcCoordinator = jdbcCoordinator;
+			this.currentHibernateTransaction = transaction;
 			this.isTransactionCoordinatorShared = true;
 			this.autoJoinTransactions = false;
 			if ( transactionCompletionProcesses != null ) {
 				actionQueue.setTransactionCompletionProcesses( transactionCompletionProcesses, true );
 			}
 			if ( autoJoinTransactions ) {
 				LOG.debug(
 						"Session creation specified 'autoJoinTransactions', which is invalid in conjunction " +
 								"with sharing JDBC connection between sessions; ignoring"
 				);
 			}
-			if ( connectionReleaseMode != transactionCoordinator.getJdbcCoordinator().getLogicalConnection().getConnectionReleaseMode() ) {
+			if ( connectionReleaseMode != this.jdbcCoordinator.getConnectionReleaseMode() ) {
 				LOG.debug(
-						"Session creation specified 'connectionReleaseMode', which is invalid in conjunction " +
+						"Session creation specified 'getConnectionReleaseMode', which is invalid in conjunction " +
 								"with sharing JDBC connection between sessions; ignoring"
 				);
 			}
-			this.connectionReleaseMode = transactionCoordinator.getJdbcCoordinator().getLogicalConnection().getConnectionReleaseMode();
+			this.connectionReleaseMode = this.jdbcCoordinator.getConnectionReleaseMode();
 
-			// add a transaction observer so that we can handle delegating managed actions back to THIS session
-			// versus the session that created (and therefore "owns") the transaction coordinator
 			transactionObserver = new TransactionObserver() {
 				@Override
-				public void afterBegin(TransactionImplementor transaction) {
+				public void afterBegin() {
 				}
 
 				@Override
-				public void beforeCompletion(TransactionImplementor transaction) {
+				public void beforeCompletion() {
 					if ( isOpen() && flushBeforeCompletionEnabled ) {
 						SessionImpl.this.managedFlush();
 					}
-					beforeTransactionCompletion( transaction );
+					actionQueue.beforeTransactionCompletion();
+					try {
+						interceptor.beforeTransactionCompletion( currentHibernateTransaction );
+					}
+					catch (Throwable t) {
+						LOG.exceptionInBeforeTransactionCompletionInterceptor( t );
+					}
 				}
 
 				@Override
-				public void afterCompletion(boolean successful, TransactionImplementor transaction) {
-					afterTransactionCompletion( transaction, successful );
+				public void afterCompletion(boolean successful) {
+					afterTransactionCompletion( successful );
 					if ( isOpen() && autoCloseSessionEnabled ) {
 						managedClose();
 					}
-					transactionCoordinator.removeObserver( this );
 				}
 			};
 
 			transactionCoordinator.addObserver( transactionObserver );
 		}
 
 		loadQueryInfluencers = new LoadQueryInfluencers( factory );
 
-		if (factory.getStatistics().isStatisticsEnabled()) {
+		if ( factory.getStatistics().isStatisticsEnabled() ) {
 			factory.getStatisticsImplementor().openSession();
 		}
 
-      if ( TRACE_ENABLED )
-		   LOG.tracef( "Opened session at timestamp: %s", timestamp );
+		if ( TRACE_ENABLED ) {
+			LOG.tracef( "Opened session at timestamp: %s", timestamp );
+		}
+
 	}
 
 	@Override
 	public SharedSessionBuilder sessionWithOptions() {
 		return new SharedSessionBuilderImpl( this );
 	}
 
 	@Override
 	public void clear() {
 		errorIfClosed();
 		// Do not call checkTransactionSynchStatus() here -- if a delayed
 		// afterCompletion exists, it can cause an infinite loop.
 		pulseTransactionCoordinator();
 		internalClear();
 	}
 
 	private void internalClear() {
 		persistenceContext.clear();
 		actionQueue.clear();
 
 		final ClearEvent event = new ClearEvent( this );
 		for ( ClearEventListener listener : listeners( EventType.CLEAR ) ) {
 			listener.onClear( event );
 		}
 	}
 
 	@Override
 	public long getTimestamp() {
 		checkTransactionSynchStatus();
 		return timestamp;
 	}
 
 	@Override
 	public Connection close() throws HibernateException {
 		LOG.trace( "Closing session" );
 		if ( isClosed() ) {
 			throw new SessionException( "Session was already closed" );
 		}
 
 		if ( factory.getStatistics().isStatisticsEnabled() ) {
 			factory.getStatisticsImplementor().closeSession();
 		}
 		getEventListenerManager().end();
 
 		try {
 			if ( !isTransactionCoordinatorShared ) {
-				return transactionCoordinator.close();
+				return jdbcCoordinator.close();
 			}
 			else {
 				if ( getActionQueue().hasBeforeTransactionActions() || getActionQueue().hasAfterTransactionActions() ) {
-					LOG.warn( "On close, shared Session had before / after transaction actions that have not yet been processed" );
-				}
-				else {
-					transactionCoordinator.removeObserver( transactionObserver );
+					LOG.warn(
+							"On close, shared Session had before / after transaction actions that have not yet been processed"
+					);
 				}
 				return null;
 			}
 		}
 		finally {
 			setClosed();
 			cleanup();
 		}
 	}
 
 	@Override
-	public ConnectionReleaseMode getConnectionReleaseMode() {
-		return connectionReleaseMode;
+	public boolean isAutoCloseSessionEnabled() {
+		return autoCloseSessionEnabled;
 	}
 
 	@Override
 	public boolean shouldAutoJoinTransaction() {
 		return autoJoinTransactions;
 	}
 
 	@Override
-	public boolean isAutoCloseSessionEnabled() {
-		return autoCloseSessionEnabled;
-	}
-
-	@Override
 	public boolean isOpen() {
 		checkTransactionSynchStatus();
 		return !isClosed();
 	}
 
-	@Override
-	public boolean isFlushModeNever() {
+	private boolean isFlushModeNever() {
 		return FlushMode.isManualFlushMode( getFlushMode() );
 	}
 
-	@Override
-	public boolean isFlushBeforeCompletionEnabled() {
-		return flushBeforeCompletionEnabled;
-	}
-
-	@Override
-	public void managedFlush() {
+	private void managedFlush() {
 		if ( isClosed() ) {
 			LOG.trace( "Skipping auto-flush due to session closed" );
 			return;
 		}
 		LOG.trace( "Automatically flushing session" );
 		flush();
 	}
 
 	@Override
 	public boolean shouldAutoClose() {
 		if ( isClosed() ) {
 			return false;
 		}
 		else if ( sessionOwner != null ) {
 			return sessionOwner.shouldAutoCloseSession();
 		}
 		else {
 			return isAutoCloseSessionEnabled();
 		}
 	}
 
-	@Override
-	public void managedClose() {
+	private void managedClose() {
 		LOG.trace( "Automatically closing session" );
 		close();
 	}
 
 	@Override
 	public Connection connection() throws HibernateException {
 		errorIfClosed();
-		return transactionCoordinator.getJdbcCoordinator().getLogicalConnection().getConnection();
+		return this.jdbcCoordinator.getLogicalConnection().getPhysicalConnection();
 	}
 
 	@Override
 	public boolean isConnected() {
 		checkTransactionSynchStatus();
-		return !isClosed() && transactionCoordinator.getJdbcCoordinator().getLogicalConnection().isOpen();
+		return !isClosed() && this.jdbcCoordinator.getLogicalConnection().isOpen();
 	}
 
 	@Override
 	public boolean isTransactionInProgress() {
 		checkTransactionSynchStatus();
-		return !isClosed() && transactionCoordinator.isTransactionInProgress();
+		return !isClosed() && transactionCoordinator.getTransactionDriverControl()
+				.getStatus() == TransactionStatus.ACTIVE && transactionCoordinator.isJoined();
 	}
 
 	@Override
 	public Connection disconnect() throws HibernateException {
 		errorIfClosed();
 		LOG.debug( "Disconnecting session" );
-		transactionCoordinator.getJdbcCoordinator().releaseResources();
-		return transactionCoordinator.getJdbcCoordinator().getLogicalConnection().manualDisconnect();
+		return this.jdbcCoordinator.getLogicalConnection().manualDisconnect();
 	}
 
 	@Override
 	public void reconnect(Connection conn) throws HibernateException {
 		errorIfClosed();
 		LOG.debug( "Reconnecting session" );
 		checkTransactionSynchStatus();
-		transactionCoordinator.getJdbcCoordinator().getLogicalConnection().manualReconnect( conn );
+		this.jdbcCoordinator.getLogicalConnection().manualReconnect( conn );
 	}
 
 	@Override
 	public void setAutoClear(boolean enabled) {
 		errorIfClosed();
 		autoClear = enabled;
 	}
 
 	@Override
 	public void disableTransactionAutoJoin() {
 		errorIfClosed();
 		autoJoinTransactions = false;
 	}
 
 	/**
 	 * Check if there is a Hibernate or JTA transaction in progress and,
 	 * if there is not, flush if necessary, make sure the connection has
 	 * been committed (if it is not in autocommit mode) and run the after
 	 * completion processing
 	 *
 	 * @param success Was the operation a success
 	 */
 	public void afterOperation(boolean success) {
-		if ( ! transactionCoordinator.isTransactionInProgress() ) {
-			transactionCoordinator.afterNonTransactionalQuery( success );
-		}
-	}
-
-	@Override
-	public void afterTransactionBegin(TransactionImplementor hibernateTransaction) {
-		errorIfClosed();
-		interceptor.afterTransactionBegin( hibernateTransaction );
-	}
-
-	@Override
-	public void beforeTransactionCompletion(TransactionImplementor hibernateTransaction) {
-		LOG.trace( "before transaction completion" );
-		actionQueue.beforeTransactionCompletion();
-		try {
-			interceptor.beforeTransactionCompletion( hibernateTransaction );
-		}
-		catch (Throwable t) {
-			LOG.exceptionInBeforeTransactionCompletionInterceptor( t );
-		}
-	}
-
-	@Override
-	public void afterTransactionCompletion(TransactionImplementor hibernateTransaction, boolean successful) {
-		LOG.trace( "after transaction completion" );
-		persistenceContext.afterTransactionCompletion();
-		actionQueue.afterTransactionCompletion( successful );
-
-		getEventListenerManager().transactionCompletion( successful );
-
-		try {
-			interceptor.afterTransactionCompletion( hibernateTransaction );
-		}
-		catch (Throwable t) {
-			LOG.exceptionInAfterTransactionCompletionInterceptor( t );
-		}
-
-		if ( autoClear ) {
-			internalClear();
-		}
-	}
-
-	@Override
-	public String onPrepareStatement(String sql) {
-		errorIfClosed();
-		if ( StringHelper.isEmpty( sql ) ) {
-			throw new AssertionFailure( "SQL to prepare was null." );
-		}
-
-		sql = interceptor.onPrepareStatement( sql );
-
-		if ( StringHelper.isEmpty( sql ) ) {
-			throw new AssertionFailure( "Interceptor.onPrepareStatement() returned null or empty string." );
+		if ( ! isTransactionInProgress() ) {
+			jdbcCoordinator.afterTransaction();
 		}
-		return sql;
 	}
 
 	@Override
 	public SessionEventListenerManagerImpl getEventListenerManager() {
 		return sessionEventsManager;
 	}
 
 	@Override
 	public void addEventListeners(SessionEventListener... listeners) {
 		getEventListenerManager().addListener( listeners );
 	}
 
-	@Override
-	public void startPrepareStatement() {
-		getEventListenerManager().jdbcPrepareStatementStart();
-	}
-
-	@Override
-	public void endPrepareStatement() {
-		getEventListenerManager().jdbcPrepareStatementEnd();
-	}
-
-	@Override
-	public void startStatementExecution() {
-		getEventListenerManager().jdbcExecuteStatementStart();
-	}
-
-	@Override
-	public void endStatementExecution() {
-		getEventListenerManager().jdbcExecuteStatementEnd();
-	}
-
-	@Override
-	public void startBatchExecution() {
-		getEventListenerManager().jdbcExecuteBatchStart();
-	}
-
-	@Override
-	public void endBatchExecution() {
-		getEventListenerManager().jdbcExecuteBatchEnd();
-	}
-
 	/**
 	 * clear all the internal collections, just
 	 * to help the garbage collector, does not
 	 * clear anything that is needed during the
 	 * afterTransactionCompletion() phase
 	 */
 	private void cleanup() {
 		persistenceContext.clear();
 	}
 
 	@Override
 	public LockMode getCurrentLockMode(Object object) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		if ( object == null ) {
 			throw new NullPointerException( "null object passed to getCurrentLockMode()" );
 		}
 		if ( object instanceof HibernateProxy ) {
 			object = ( (HibernateProxy) object ).getHibernateLazyInitializer().getImplementation(this);
 			if ( object == null ) {
 				return LockMode.NONE;
 			}
 		}
 		EntityEntry e = persistenceContext.getEntry(object);
 		if ( e == null ) {
 			throw new TransientObjectException( "Given object not associated with the session" );
 		}
 		if ( e.getStatus() != Status.MANAGED ) {
 			throw new ObjectDeletedException(
 					"The given object was deleted",
 					e.getId(),
 					e.getPersister().getEntityName()
 				);
 		}
 		return e.getLockMode();
 	}
 
 	@Override
 	public Object getEntityUsingInterceptor(EntityKey key) throws HibernateException {
 		errorIfClosed();
 		// todo : should this get moved to PersistentContext?
 		// logically, is PersistentContext the "thing" to which an interceptor gets attached?
 		final Object result = persistenceContext.getEntity(key);
 		if ( result == null ) {
 			final Object newObject = interceptor.getEntity( key.getEntityName(), key.getIdentifier() );
 			if ( newObject != null ) {
 				lock( newObject, LockMode.NONE );
 			}
 			return newObject;
 		}
 		else {
 			return result;
 		}
 	}
 
 	private void checkNoUnresolvedActionsBeforeOperation() {
 		if ( persistenceContext.getCascadeLevel() == 0 && actionQueue.hasUnresolvedEntityInsertActions() ) {
 			throw new IllegalStateException( "There are delayed insert actions before operation as cascade level 0." );
 		}
 	}
 
 	private void checkNoUnresolvedActionsAfterOperation() {
 		if ( persistenceContext.getCascadeLevel() == 0 ) {
 			actionQueue.checkNoUnresolvedActionsAfterOperation();
 		}
 		delayedAfterCompletion();
 	}
-	
+
 	private void delayedAfterCompletion() {
-		transactionCoordinator.getSynchronizationCallbackCoordinator().processAnyDelayedAfterCompletion();
+		if(transactionCoordinator instanceof JtaTransactionCoordinatorImpl) {
+			((JtaTransactionCoordinatorImpl)transactionCoordinator).getSynchronizationCallbackCoordinator().processAnyDelayedAfterCompletion();
+		}
 	}
 
 	// saveOrUpdate() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void saveOrUpdate(Object object) throws HibernateException {
 		saveOrUpdate( null, object );
 	}
 
 	@Override
 	public void saveOrUpdate(String entityName, Object obj) throws HibernateException {
 		fireSaveOrUpdate( new SaveOrUpdateEvent( entityName, obj, this ) );
 	}
 
 	private void fireSaveOrUpdate(SaveOrUpdateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( SaveOrUpdateEventListener listener : listeners( EventType.SAVE_UPDATE ) ) {
 			listener.onSaveOrUpdate( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 	}
 
 	private <T> Iterable<T> listeners(EventType<T> type) {
 		return eventListenerGroup( type ).listeners();
 	}
 
 	private <T> EventListenerGroup<T> eventListenerGroup(EventType<T> type) {
 		return factory.getServiceRegistry().getService( EventListenerRegistry.class ).getEventListenerGroup( type );
 	}
 
 
 	// save() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public Serializable save(Object obj) throws HibernateException {
 		return save( null, obj );
 	}
 
 	@Override
 	public Serializable save(String entityName, Object object) throws HibernateException {
 		return fireSave( new SaveOrUpdateEvent( entityName, object, this ) );
 	}
 
 	private Serializable fireSave(SaveOrUpdateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( SaveOrUpdateEventListener listener : listeners( EventType.SAVE ) ) {
 			listener.onSaveOrUpdate( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 		return event.getResultId();
 	}
 
 
 	// update() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void update(Object obj) throws HibernateException {
 		update( null, obj );
 	}
 
 	@Override
 	public void update(String entityName, Object object) throws HibernateException {
 		fireUpdate( new SaveOrUpdateEvent( entityName, object, this ) );
 	}
 
 	private void fireUpdate(SaveOrUpdateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( SaveOrUpdateEventListener listener : listeners( EventType.UPDATE ) ) {
 			listener.onSaveOrUpdate( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 	}
 
 
 	// lock() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void lock(String entityName, Object object, LockMode lockMode) throws HibernateException {
 		fireLock( new LockEvent( entityName, object, lockMode, this ) );
 	}
 
 	@Override
 	public LockRequest buildLockRequest(LockOptions lockOptions) {
 		return new LockRequestImpl(lockOptions);
 	}
 
 	@Override
 	public void lock(Object object, LockMode lockMode) throws HibernateException {
 		fireLock( new LockEvent( object, lockMode, this ) );
 	}
 
 	private void fireLock(String entityName, Object object, LockOptions options) {
-		fireLock( new LockEvent( entityName, object, options, this) );
+		fireLock( new LockEvent( entityName, object, options, this ) );
 	}
 
 	private void fireLock( Object object, LockOptions options) {
 		fireLock( new LockEvent( object, options, this ) );
 	}
 
 	private void fireLock(LockEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( LockEventListener listener : listeners( EventType.LOCK ) ) {
 			listener.onLock( event );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// persist() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void persist(String entityName, Object object) throws HibernateException {
 		firePersist( new PersistEvent( entityName, object, this ) );
 	}
 
 	@Override
 	public void persist(Object object) throws HibernateException {
 		persist( null, object );
 	}
 
 	@Override
 	public void persist(String entityName, Object object, Map copiedAlready) throws HibernateException {
 		firePersist( copiedAlready, new PersistEvent( entityName, object, this ) );
 	}
 
 	private void firePersist(Map copiedAlready, PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST ) ) {
 			listener.onPersist( event, copiedAlready );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void firePersist(PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST ) ) {
 			listener.onPersist( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 	}
 
 
 	// persistOnFlush() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void persistOnFlush(String entityName, Object object)
 			throws HibernateException {
 		firePersistOnFlush( new PersistEvent( entityName, object, this ) );
 	}
 
 	public void persistOnFlush(Object object) throws HibernateException {
 		persist( null, object );
 	}
 
 	@Override
 	public void persistOnFlush(String entityName, Object object, Map copiedAlready)
 			throws HibernateException {
 		firePersistOnFlush( copiedAlready, new PersistEvent( entityName, object, this ) );
 	}
 
 	private void firePersistOnFlush(Map copiedAlready, PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST_ONFLUSH ) ) {
 			listener.onPersist( event, copiedAlready );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void firePersistOnFlush(PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST_ONFLUSH ) ) {
 			listener.onPersist( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 	}
 
 
 	// merge() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public Object merge(String entityName, Object object) throws HibernateException {
 		return fireMerge( new MergeEvent( entityName, object, this ) );
 	}
 
 	@Override
 	public Object merge(Object object) throws HibernateException {
 		return merge( null, object );
 	}
 
 	@Override
 	public void merge(String entityName, Object object, Map copiedAlready) throws HibernateException {
 		fireMerge( copiedAlready, new MergeEvent( entityName, object, this ) );
 	}
 
 	private Object fireMerge(MergeEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( MergeEventListener listener : listeners( EventType.MERGE ) ) {
 			listener.onMerge( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 		return event.getResult();
 	}
 
 	private void fireMerge(Map copiedAlready, MergeEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( MergeEventListener listener : listeners( EventType.MERGE ) ) {
 			listener.onMerge( event, copiedAlready );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// delete() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void delete(Object object) throws HibernateException {
 		fireDelete( new DeleteEvent( object, this ) );
 	}
 
 	@Override
 	public void delete(String entityName, Object object) throws HibernateException {
 		fireDelete( new DeleteEvent( entityName, object, this ) );
 	}
 
 	@Override
 	public void delete(String entityName, Object object, boolean isCascadeDeleteEnabled, Set transientEntities) throws HibernateException {
 		if ( TRACE_ENABLED && persistenceContext.isRemovingOrphanBeforeUpates() ) {
 			logRemoveOrphanBeforeUpdates( "before continuing", entityName, object );
 		}
 		fireDelete(
 				new DeleteEvent(
 						entityName,
 						object,
 						isCascadeDeleteEnabled,
 						persistenceContext.isRemovingOrphanBeforeUpates(),
 						this
 				),
 				transientEntities
 		);
 		if ( TRACE_ENABLED && persistenceContext.isRemovingOrphanBeforeUpates() ) {
 			logRemoveOrphanBeforeUpdates( "after continuing", entityName, object );
 		}
 	}
 
 	@Override
 	public void removeOrphanBeforeUpdates(String entityName, Object child) {
 		// TODO: The removeOrphan concept is a temporary "hack" for HHH-6484.  This should be removed once action/task
 		// ordering is improved.
 		if ( TRACE_ENABLED ) {
 			logRemoveOrphanBeforeUpdates( "begin", entityName, child );
 		}
 		persistenceContext.beginRemoveOrphanBeforeUpdates();
 		try {
 			fireDelete( new DeleteEvent( entityName, child, false, true, this ) );
 		}
 		finally {
 			persistenceContext.endRemoveOrphanBeforeUpdates();
 			if ( TRACE_ENABLED ) {
 				logRemoveOrphanBeforeUpdates( "end", entityName, child );
 			}
 		}
 	}
 
 	private void logRemoveOrphanBeforeUpdates(String timing, String entityName, Object entity) {
 		final EntityEntry entityEntry = persistenceContext.getEntry( entity );
 		LOG.tracef(
 				"%s remove orphan before updates: [%s]",
 				timing,
 				entityEntry == null ? entityName : MessageHelper.infoString( entityName, entityEntry.getId() )
 		);
 	}
 
 	private void fireDelete(DeleteEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( DeleteEventListener listener : listeners( EventType.DELETE ) ) {
 			listener.onDelete( event );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void fireDelete(DeleteEvent event, Set transientEntities) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( DeleteEventListener listener : listeners( EventType.DELETE ) ) {
 			listener.onDelete( event, transientEntities );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// load()/get() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void load(Object object, Serializable id) throws HibernateException {
 		LoadEvent event = new LoadEvent(id, object, this);
 		fireLoad( event, LoadEventListener.RELOAD );
 	}
 
 	@Override
 	public Object load(Class entityClass, Serializable id) throws HibernateException {
 		return this.byId( entityClass ).getReference( id );
 	}
 
 	@Override
 	public Object load(String entityName, Serializable id) throws HibernateException {
 		return this.byId( entityName ).getReference( id );
 	}
 
 	@Override
 	public Object get(Class entityClass, Serializable id) throws HibernateException {
 		return this.byId( entityClass ).load( id );
 	}
 
 	@Override
 	public Object get(String entityName, Serializable id) throws HibernateException {
 		return this.byId( entityName ).load( id );
 	}
 
 	/**	
 	 * Load the data for the object with the specified id into a newly created object.
 	 * This is only called when lazily initializing a proxy.
 	 * Do NOT return a proxy.
 	 */
 	@Override
 	public Object immediateLoad(String entityName, Serializable id) throws HibernateException {
 		if ( LOG.isDebugEnabled() ) {
 			EntityPersister persister = getFactory().getEntityPersister(entityName);
 			LOG.debugf( "Initializing proxy: %s", MessageHelper.infoString( persister, id, getFactory() ) );
 		}
 
 		LoadEvent event = new LoadEvent(id, entityName, true, this);
 		fireLoad(event, LoadEventListener.IMMEDIATE_LOAD);
 		return event.getResult();
 	}
 
 	@Override
 	public Object internalLoad(String entityName, Serializable id, boolean eager, boolean nullable) throws HibernateException {
 		// todo : remove
 		LoadEventListener.LoadType type = nullable
 				? LoadEventListener.INTERNAL_LOAD_NULLABLE
 				: eager
 						? LoadEventListener.INTERNAL_LOAD_EAGER
 						: LoadEventListener.INTERNAL_LOAD_LAZY;
 		LoadEvent event = new LoadEvent(id, entityName, true, this);
 		fireLoad( event, type );
 		if ( !nullable ) {
 			UnresolvableObjectException.throwIfNull( event.getResult(), id, entityName );
 		}
 		return event.getResult();
 	}
 
 	@Override
 	public Object load(Class entityClass, Serializable id, LockMode lockMode) throws HibernateException {
 		return this.byId( entityClass ).with( new LockOptions( lockMode ) ).getReference( id );
 	}
 
 	@Override
 	public Object load(Class entityClass, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return this.byId( entityClass ).with( lockOptions ).getReference( id );
 	}
 
 	@Override
 	public Object load(String entityName, Serializable id, LockMode lockMode) throws HibernateException {
 		return this.byId( entityName ).with( new LockOptions( lockMode ) ).getReference( id );
 	}
 
 	@Override
 	public Object load(String entityName, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return this.byId( entityName ).with( lockOptions ).getReference( id );
 	}
 
 	@Override
 	public Object get(Class entityClass, Serializable id, LockMode lockMode) throws HibernateException {
 		return this.byId( entityClass ).with( new LockOptions( lockMode ) ).load( id );
 	}
 
 	@Override
 	public Object get(Class entityClass, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return this.byId( entityClass ).with( lockOptions ).load( id );
 	}
 
 	@Override
 	public Object get(String entityName, Serializable id, LockMode lockMode) throws HibernateException {
 		return this.byId( entityName ).with( new LockOptions( lockMode ) ).load( id );
 	}
 
 	@Override
 	public Object get(String entityName, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return this.byId( entityName ).with( lockOptions ).load( id );
 	}
 	
 	@Override
 	public IdentifierLoadAccessImpl byId(String entityName) {
 		return new IdentifierLoadAccessImpl( entityName );
 	}
 
 	@Override
 	public IdentifierLoadAccessImpl byId(Class entityClass) {
 		return new IdentifierLoadAccessImpl( entityClass );
 	}
 
 	@Override
 	public NaturalIdLoadAccess byNaturalId(String entityName) {
 		return new NaturalIdLoadAccessImpl( entityName );
 	}
 
 	@Override
 	public NaturalIdLoadAccess byNaturalId(Class entityClass) {
 		return new NaturalIdLoadAccessImpl( entityClass );
 	}
 
 	@Override
 	public SimpleNaturalIdLoadAccess bySimpleNaturalId(String entityName) {
 		return new SimpleNaturalIdLoadAccessImpl( entityName );
 	}
 
 	@Override
 	public SimpleNaturalIdLoadAccess bySimpleNaturalId(Class entityClass) {
 		return new SimpleNaturalIdLoadAccessImpl( entityClass );
 	}
 
 	private void fireLoad(LoadEvent event, LoadType loadType) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( LoadEventListener listener : listeners( EventType.LOAD ) ) {
 			listener.onLoad( event, loadType );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void fireResolveNaturalId(ResolveNaturalIdEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( ResolveNaturalIdEventListener listener : listeners( EventType.RESOLVE_NATURAL_ID ) ) {
 			listener.onResolveNaturalId( event );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// refresh() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void refresh(Object object) throws HibernateException {
 		refresh( null, object );
 	}
 
 	@Override
 	public void refresh(String entityName, Object object) throws HibernateException {
 		fireRefresh( new RefreshEvent( entityName, object, this ) );
 	}
 
 	@Override
 	public void refresh(Object object, LockMode lockMode) throws HibernateException {
 		fireRefresh( new RefreshEvent( object, lockMode, this ) );
 	}
 
 	@Override
 	public void refresh(Object object, LockOptions lockOptions) throws HibernateException {
 		refresh( null, object, lockOptions );
 	}
 
 	@Override
 	public void refresh(String entityName, Object object, LockOptions lockOptions) throws HibernateException {
 		fireRefresh( new RefreshEvent( entityName, object, lockOptions, this ) );
 	}
 
 	@Override
 	public void refresh(String entityName, Object object, Map refreshedAlready) throws HibernateException {
 		fireRefresh( refreshedAlready, new RefreshEvent( entityName, object, this ) );
 	}
 
 	private void fireRefresh(RefreshEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( RefreshEventListener listener : listeners( EventType.REFRESH ) ) {
 			listener.onRefresh( event );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void fireRefresh(Map refreshedAlready, RefreshEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( RefreshEventListener listener : listeners( EventType.REFRESH ) ) {
 			listener.onRefresh( event, refreshedAlready );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// replicate() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void replicate(Object obj, ReplicationMode replicationMode) throws HibernateException {
 		fireReplicate( new ReplicateEvent( obj, replicationMode, this ) );
 	}
 
 	@Override
 	public void replicate(String entityName, Object obj, ReplicationMode replicationMode)
 	throws HibernateException {
 		fireReplicate( new ReplicateEvent( entityName, obj, replicationMode, this ) );
 	}
 
 	private void fireReplicate(ReplicateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( ReplicateEventListener listener : listeners( EventType.REPLICATE ) ) {
 			listener.onReplicate( event );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// evict() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * remove any hard references to the entity that are held by the infrastructure
 	 * (references held by application or other persistent instances are okay)
 	 */
 	@Override
 	public void evict(Object object) throws HibernateException {
 		fireEvict( new EvictEvent( object, this ) );
 	}
 
 	private void fireEvict(EvictEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( EvictEventListener listener : listeners( EventType.EVICT ) ) {
 			listener.onEvict( event );
 		}
 		delayedAfterCompletion();
 	}
 
 	/**
 	 * detect in-memory changes, determine if the changes are to tables
 	 * named in the query and, if so, complete execution the flush
 	 */
 	protected boolean autoFlushIfRequired(Set querySpaces) throws HibernateException {
 		errorIfClosed();
 		if ( ! isTransactionInProgress() ) {
 			// do not auto-flush while outside a transaction
 			return false;
 		}
 		AutoFlushEvent event = new AutoFlushEvent( querySpaces, this );
+		listeners( EventType.AUTO_FLUSH );
 		for ( AutoFlushEventListener listener : listeners( EventType.AUTO_FLUSH ) ) {
 			listener.onAutoFlush( event );
 		}
 		return event.isFlushRequired();
 	}
 
 	@Override
 	public boolean isDirty() throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		LOG.debug( "Checking session dirtiness" );
 		if ( actionQueue.areInsertionsOrDeletionsQueued() ) {
 			LOG.debug( "Session dirty (scheduled updates and insertions)" );
 			return true;
 		}
 		DirtyCheckEvent event = new DirtyCheckEvent( this );
 		for ( DirtyCheckEventListener listener : listeners( EventType.DIRTY_CHECK ) ) {
 			listener.onDirtyCheck( event );
 		}
 		delayedAfterCompletion();
 		return event.isDirty();
 	}
 
 	@Override
 	public void flush() throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		if ( persistenceContext.getCascadeLevel() > 0 ) {
 			throw new HibernateException("Flush during cascade is dangerous");
 		}
 		FlushEvent flushEvent = new FlushEvent( this );
 		for ( FlushEventListener listener : listeners( EventType.FLUSH ) ) {
 			listener.onFlush( flushEvent );
 		}
 		delayedAfterCompletion();
 	}
 
 	@Override
 	public void forceFlush(EntityEntry entityEntry) throws HibernateException {
 		errorIfClosed();
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "Flushing to force deletion of re-saved object: %s",
 					MessageHelper.infoString( entityEntry.getPersister(), entityEntry.getId(), getFactory() ) );
 		}
 
 		if ( persistenceContext.getCascadeLevel() > 0 ) {
 			throw new ObjectDeletedException(
 				"deleted object would be re-saved by cascade (remove deleted object from associations)",
 				entityEntry.getId(),
 				entityEntry.getPersister().getEntityName()
 			);
 		}
 
 		flush();
 	}
 
 	@Override
 	public List list(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		queryParameters.validateParameters();
 		
 		HQLQueryPlan plan = queryParameters.getQueryPlan();
 		if (plan == null) {
 			plan = getHQLQueryPlan( query, false );
 		}
 		
 		autoFlushIfRequired( plan.getQuerySpaces() );
 
 		List results = Collections.EMPTY_LIST;
 		boolean success = false;
 
 		dontFlushFromFind++;   //stops flush being called multiple times if this method is recursively called
 		try {
 			results = plan.performList( queryParameters, this );
 			success = true;
 		}
 		finally {
 			dontFlushFromFind--;
 			afterOperation(success);
 			delayedAfterCompletion();
 		}
 		return results;
 	}
 
 	@Override
 	public int executeUpdate(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		queryParameters.validateParameters();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		autoFlushIfRequired( plan.getQuerySpaces() );
 
 		boolean success = false;
 		int result = 0;
 		try {
 			result = plan.performExecuteUpdate( queryParameters, this );
 			success = true;
 		}
 		finally {
-			afterOperation(success);
+			afterOperation( success );
 			delayedAfterCompletion();
 		}
 		return result;
 	}
 
 	@Override
     public int executeNativeUpdate(NativeSQLQuerySpecification nativeQuerySpecification,
             QueryParameters queryParameters) throws HibernateException {
         errorIfClosed();
         checkTransactionSynchStatus();
         queryParameters.validateParameters();
         NativeSQLQueryPlan plan = getNativeSQLQueryPlan( nativeQuerySpecification );
 
 
         autoFlushIfRequired( plan.getCustomQuery().getQuerySpaces() );
 
         boolean success = false;
         int result = 0;
         try {
             result = plan.performExecuteUpdate(queryParameters, this);
             success = true;
         } finally {
-            afterOperation(success);
+            afterOperation( success );
     		delayedAfterCompletion();
         }
         return result;
     }
 
 	@Override
 	public Iterator iterate(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		queryParameters.validateParameters();
 		HQLQueryPlan plan = getHQLQueryPlan( query, true );
 		autoFlushIfRequired( plan.getQuerySpaces() );
 
 		dontFlushFromFind++; //stops flush being called multiple times if this method is recursively called
 		try {
 			return plan.performIterate( queryParameters, this );
 		}
 		finally {
 			delayedAfterCompletion();
 			dontFlushFromFind--;
 		}
 	}
 
 	@Override
 	public ScrollableResults scroll(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		autoFlushIfRequired( plan.getQuerySpaces() );
 		dontFlushFromFind++;
 		try {
 			return plan.performScroll( queryParameters, this );
 		}
 		finally {
 			delayedAfterCompletion();
 			dontFlushFromFind--;
 		}
 	}
 
 	@Override
 	public Query createFilter(Object collection, String queryString) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		CollectionFilterImpl filter = new CollectionFilterImpl(
 				queryString,
 		        collection,
 		        this,
 		        getFilterQueryPlan( collection, queryString, null, false ).getParameterMetadata()
 		);
 		filter.setComment( queryString );
 		delayedAfterCompletion();
 		return filter;
 	}
 
 	@Override
 	public Query getNamedQuery(String queryName) throws MappingException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		Query query = super.getNamedQuery( queryName );
 		delayedAfterCompletion();
 		return query;
 	}
 
 	@Override
 	public Object instantiate(String entityName, Serializable id) throws HibernateException {
 		return instantiate( factory.getEntityPersister( entityName ), id );
 	}
 
 	/**
 	 * give the interceptor an opportunity to override the default instantiation
 	 */
 	@Override
 	public Object instantiate(EntityPersister persister, Serializable id) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		Object result = interceptor.instantiate( persister.getEntityName(), persister.getEntityMetamodel().getEntityMode(), id );
 		if ( result == null ) {
 			result = persister.instantiate( id, this );
 		}
 		delayedAfterCompletion();
 		return result;
 	}
 
 	@Override
 	public void setFlushMode(FlushMode flushMode) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		LOG.tracev( "Setting flush mode to: {0}", flushMode );
 		this.flushMode = flushMode;
 	}
 
 	@Override
 	public FlushMode getFlushMode() {
 		checkTransactionSynchStatus();
 		return flushMode;
 	}
 
 	@Override
 	public CacheMode getCacheMode() {
 		checkTransactionSynchStatus();
 		return cacheMode;
 	}
 
 	@Override
 	public void setCacheMode(CacheMode cacheMode) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		LOG.tracev( "Setting cache mode to: {0}", cacheMode );
 		this.cacheMode= cacheMode;
 	}
 
 	@Override
-	public Transaction getTransaction() throws HibernateException {
-		errorIfClosed();
-		return transactionCoordinator.getTransaction();
-	}
-
-	@Override
 	public Transaction beginTransaction() throws HibernateException {
 		errorIfClosed();
 		Transaction result = getTransaction();
 		result.begin();
 		return result;
 	}
 
 	@Override
 	public EntityPersister getEntityPersister(final String entityName, final Object object) {
 		errorIfClosed();
 		if (entityName==null) {
 			return factory.getEntityPersister( guessEntityName( object ) );
 		}
 		else {
 			// try block is a hack around fact that currently tuplizers are not
 			// given the opportunity to resolve a subclass entity name.  this
 			// allows the (we assume custom) interceptor the ability to
 			// influence this decision if we were not able to based on the
 			// given entityName
 			try {
 				return factory.getEntityPersister( entityName ).getSubclassEntityPersister( object, getFactory() );
 			}
 			catch( HibernateException e ) {
 				try {
 					return getEntityPersister( null, object );
 				}
 				catch( HibernateException e2 ) {
 					throw e;
 				}
 			}
 		}
 	}
 
 	// not for internal use:
 	@Override
 	public Serializable getIdentifier(Object object) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		if ( object instanceof HibernateProxy ) {
 			LazyInitializer li = ( (HibernateProxy) object ).getHibernateLazyInitializer();
 			if ( li.getSession() != this ) {
 				throw new TransientObjectException( "The proxy was not associated with this session" );
 			}
 			return li.getIdentifier();
 		}
 		else {
 			EntityEntry entry = persistenceContext.getEntry(object);
 			if ( entry == null ) {
 				throw new TransientObjectException( "The instance was not associated with this session" );
 			}
 			return entry.getId();
 		}
 	}
 
 	/**
 	 * Get the id value for an object that is actually associated with the session. This
 	 * is a bit stricter than getEntityIdentifierIfNotUnsaved().
 	 */
 	@Override
 	public Serializable getContextEntityIdentifier(Object object) {
 		errorIfClosed();
 		if ( object instanceof HibernateProxy ) {
 			return getProxyIdentifier( object );
 		}
 		else {
 			EntityEntry entry = persistenceContext.getEntry(object);
 			return entry != null ? entry.getId() : null;
 		}
 	}
 
 	private Serializable getProxyIdentifier(Object proxy) {
 		return ( (HibernateProxy) proxy ).getHibernateLazyInitializer().getIdentifier();
 	}
 
 	private FilterQueryPlan getFilterQueryPlan(
 			Object collection,
 			String filter,
 			QueryParameters parameters,
 			boolean shallow) throws HibernateException {
 		if ( collection == null ) {
 			throw new NullPointerException( "null collection passed to filter" );
 		}
 
 		CollectionEntry entry = persistenceContext.getCollectionEntryOrNull( collection );
 		final CollectionPersister roleBeforeFlush = (entry == null) ? null : entry.getLoadedPersister();
 
 		FilterQueryPlan plan = null;
 		if ( roleBeforeFlush == null ) {
 			// if it was previously unreferenced, we need to flush in order to
 			// get its state into the database in order to execute query
 			flush();
 			entry = persistenceContext.getCollectionEntryOrNull( collection );
 			CollectionPersister roleAfterFlush = (entry == null) ? null : entry.getLoadedPersister();
 			if ( roleAfterFlush == null ) {
 				throw new QueryException( "The collection was unreferenced" );
 			}
 			plan = factory.getQueryPlanCache().getFilterQueryPlan( filter, roleAfterFlush.getRole(), shallow, getEnabledFilters() );
 		}
 		else {
 			// otherwise, we only need to flush if there are in-memory changes
 			// to the queried tables
 			plan = factory.getQueryPlanCache().getFilterQueryPlan( filter, roleBeforeFlush.getRole(), shallow, getEnabledFilters() );
 			if ( autoFlushIfRequired( plan.getQuerySpaces() ) ) {
 				// might need to run a different filter entirely after the flush
 				// because the collection role may have changed
 				entry = persistenceContext.getCollectionEntryOrNull( collection );
 				CollectionPersister roleAfterFlush = (entry == null) ? null : entry.getLoadedPersister();
 				if ( roleBeforeFlush != roleAfterFlush ) {
 					if ( roleAfterFlush == null ) {
 						throw new QueryException( "The collection was dereferenced" );
 					}
 					plan = factory.getQueryPlanCache().getFilterQueryPlan( filter, roleAfterFlush.getRole(), shallow, getEnabledFilters() );
 				}
 			}
 		}
 
 		if ( parameters != null ) {
 			parameters.getPositionalParameterValues()[0] = entry.getLoadedKey();
 			parameters.getPositionalParameterTypes()[0] = entry.getLoadedPersister().getKeyType();
 		}
 
 		return plan;
 	}
 
 	@Override
 	public List listFilter(Object collection, String filter, QueryParameters queryParameters)
 	throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		FilterQueryPlan plan = getFilterQueryPlan( collection, filter, queryParameters, false );
 		List results = Collections.EMPTY_LIST;
 
 		boolean success = false;
 		dontFlushFromFind++;   //stops flush being called multiple times if this method is recursively called
 		try {
 			results = plan.performList( queryParameters, this );
 			success = true;
 		}
 		finally {
 			dontFlushFromFind--;
 			afterOperation(success);
 			delayedAfterCompletion();
 		}
 		return results;
 	}
 
 	@Override
 	public Iterator iterateFilter(Object collection, String filter, QueryParameters queryParameters)
 	throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		FilterQueryPlan plan = getFilterQueryPlan( collection, filter, queryParameters, true );
 		Iterator itr = plan.performIterate( queryParameters, this );
 		delayedAfterCompletion();
 		return itr;
 	}
 
 	@Override
 	public Criteria createCriteria(Class persistentClass, String alias) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return new CriteriaImpl( persistentClass.getName(), alias, this );
 	}
 
 	@Override
 	public Criteria createCriteria(String entityName, String alias) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return new CriteriaImpl(entityName, alias, this);
 	}
 
 	@Override
 	public Criteria createCriteria(Class persistentClass) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return new CriteriaImpl( persistentClass.getName(), this );
 	}
 
 	@Override
 	public Criteria createCriteria(String entityName) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return new CriteriaImpl(entityName, this);
 	}
 
 	@Override
 	public ScrollableResults scroll(Criteria criteria, ScrollMode scrollMode) {
 		// TODO: Is this guaranteed to always be CriteriaImpl?
 		CriteriaImpl criteriaImpl = (CriteriaImpl) criteria;
 		
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		String entityName = criteriaImpl.getEntityOrClassName();
 		CriteriaLoader loader = new CriteriaLoader(
 				getOuterJoinLoadable(entityName),
 				factory,
 				criteriaImpl,
 				entityName,
 				getLoadQueryInfluencers()
 		);
 		autoFlushIfRequired( loader.getQuerySpaces() );
 		dontFlushFromFind++;
 		try {
 			return loader.scroll(this, scrollMode);
 		}
 		finally {
 			delayedAfterCompletion();
 			dontFlushFromFind--;
 		}
 	}
 
 	@Override
 	public List list(Criteria criteria) throws HibernateException {
 		// TODO: Is this guaranteed to always be CriteriaImpl?
 		CriteriaImpl criteriaImpl = (CriteriaImpl) criteria;
 				
 		final NaturalIdLoadAccess naturalIdLoadAccess = this.tryNaturalIdLoadAccess( criteriaImpl );
 		if ( naturalIdLoadAccess != null ) {
 			// EARLY EXIT!
 			return Arrays.asList( naturalIdLoadAccess.load() );
 		}
 
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		String[] implementors = factory.getImplementors( criteriaImpl.getEntityOrClassName() );
 		int size = implementors.length;
 
 		CriteriaLoader[] loaders = new CriteriaLoader[size];
 		Set spaces = new HashSet();
 		for( int i=0; i <size; i++ ) {
 
 			loaders[i] = new CriteriaLoader(
 					getOuterJoinLoadable( implementors[i] ),
 					factory,
 					criteriaImpl,
 					implementors[i],
 					getLoadQueryInfluencers()
 				);
 
 			spaces.addAll( loaders[i].getQuerySpaces() );
 
 		}
 
 		autoFlushIfRequired(spaces);
 
 		List results = Collections.EMPTY_LIST;
 		dontFlushFromFind++;
 		boolean success = false;
 		try {
 			for( int i=0; i<size; i++ ) {
 				final List currentResults = loaders[i].list(this);
 				currentResults.addAll(results);
 				results = currentResults;
 			}
 			success = true;
 		}
 		finally {
 			dontFlushFromFind--;
 			afterOperation(success);
 			delayedAfterCompletion();
 		}
 
 		return results;
 	}
 
 	/**
 	 * Checks to see if the CriteriaImpl is a naturalId lookup that can be done via
 	 * NaturalIdLoadAccess
 	 *
 	 * @param criteria The criteria to check as a complete natural identifier lookup.
 	 *
 	 * @return A fully configured NaturalIdLoadAccess or null, if null is returned the standard CriteriaImpl execution
 	 *         should be performed
 	 */
 	private NaturalIdLoadAccess tryNaturalIdLoadAccess(CriteriaImpl criteria) {
 		// See if the criteria lookup is by naturalId
 		if ( !criteria.isLookupByNaturalKey() ) {
 			return null;
 		}
 
 		final String entityName = criteria.getEntityOrClassName();
 		final EntityPersister entityPersister = factory.getEntityPersister( entityName );
 
 		// Verify the entity actually has a natural id, needed for legacy support as NaturalIdentifier criteria
 		// queries did no natural id validation
 		if ( !entityPersister.hasNaturalIdentifier() ) {
 			return null;
 		}
 
 		// Since isLookupByNaturalKey is true there can be only one CriterionEntry and getCriterion() will
 		// return an instanceof NaturalIdentifier
 		final CriterionEntry criterionEntry = (CriterionEntry) criteria.iterateExpressionEntries().next();
 		final NaturalIdentifier naturalIdentifier = (NaturalIdentifier) criterionEntry.getCriterion();
 
 		final Map<String, Object> naturalIdValues = naturalIdentifier.getNaturalIdValues();
 		final int[] naturalIdentifierProperties = entityPersister.getNaturalIdentifierProperties();
 
 		// Verify the NaturalIdentifier criterion includes all naturalId properties, first check that the property counts match
 		if ( naturalIdentifierProperties.length != naturalIdValues.size() ) {
 			return null;
 		}
 
 		final String[] propertyNames = entityPersister.getPropertyNames();
 		final NaturalIdLoadAccess naturalIdLoader = this.byNaturalId( entityName );
 
 		// Build NaturalIdLoadAccess and in the process verify all naturalId properties were specified
 		for ( int i = 0; i < naturalIdentifierProperties.length; i++ ) {
 			final String naturalIdProperty = propertyNames[naturalIdentifierProperties[i]];
 			final Object naturalIdValue = naturalIdValues.get( naturalIdProperty );
 
 			if ( naturalIdValue == null ) {
 				// A NaturalId property is missing from the critera query, can't use NaturalIdLoadAccess
 				return null;
 			}
 
 			naturalIdLoader.using( naturalIdProperty, naturalIdValue );
 		}
 
 		// Critera query contains a valid naturalId, use the new API
 		LOG.warn( "Session.byNaturalId(" + entityName
 				+ ") should be used for naturalId queries instead of Restrictions.naturalId() from a Criteria" );
 
 		return naturalIdLoader;
 	}
 
 	private OuterJoinLoadable getOuterJoinLoadable(String entityName) throws MappingException {
 		EntityPersister persister = factory.getEntityPersister(entityName);
 		if ( !(persister instanceof OuterJoinLoadable) ) {
 			throw new MappingException( "class persister is not OuterJoinLoadable: " + entityName );
 		}
 		return ( OuterJoinLoadable ) persister;
 	}
 
 	@Override
 	public boolean contains(Object object) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		if ( object instanceof HibernateProxy ) {
 			//do not use proxiesByKey, since not all
 			//proxies that point to this session's
 			//instances are in that collection!
 			LazyInitializer li = ( (HibernateProxy) object ).getHibernateLazyInitializer();
 			if ( li.isUninitialized() ) {
 				//if it is an uninitialized proxy, pointing
 				//with this session, then when it is accessed,
 				//the underlying instance will be "contained"
 				return li.getSession()==this;
 			}
 			else {
 				//if it is initialized, see if the underlying
 				//instance is contained, since we need to
 				//account for the fact that it might have been
 				//evicted
 				object = li.getImplementation();
 			}
 		}
 		// A session is considered to contain an entity only if the entity has
 		// an entry in the session's persistence context and the entry reports
 		// that the entity has not been removed
 		EntityEntry entry = persistenceContext.getEntry( object );
 		delayedAfterCompletion();
 		return entry != null && entry.getStatus() != Status.DELETED && entry.getStatus() != Status.GONE;
 	}
 
 	@Override
 	public Query createQuery(String queryString) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return super.createQuery( queryString );
 	}
 
 	@Override
 	public SQLQuery createSQLQuery(String sql) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return super.createSQLQuery( sql );
 	}
 
 	@Override
 	public ProcedureCall createStoredProcedureCall(String procedureName) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return super.createStoredProcedureCall( procedureName );
 	}
 
 	@Override
 	public ProcedureCall createStoredProcedureCall(String procedureName, String... resultSetMappings) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return super.createStoredProcedureCall( procedureName, resultSetMappings );
 	}
 
 	@Override
 	public ProcedureCall createStoredProcedureCall(String procedureName, Class... resultClasses) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return super.createStoredProcedureCall( procedureName, resultClasses );
 	}
 
 	@Override
 	public ScrollableResults scrollCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
 	throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Scroll SQL query: {0}", customQuery.getSQL() );
 		}
 
 		CustomLoader loader = new CustomLoader( customQuery, getFactory() );
 
 		autoFlushIfRequired( loader.getQuerySpaces() );
 
 		dontFlushFromFind++; //stops flush being called multiple times if this method is recursively called
 		try {
 			return loader.scroll(queryParameters, this);
 		}
 		finally {
 			delayedAfterCompletion();
 			dontFlushFromFind--;
 		}
 	}
 
 	// basically just an adapted copy of find(CriteriaImpl)
 	@Override
 	public List listCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
 	throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "SQL query: {0}", customQuery.getSQL() );
 		}
 
 		CustomLoader loader = new CustomLoader( customQuery, getFactory() );
 
 		autoFlushIfRequired( loader.getQuerySpaces() );
 
 		dontFlushFromFind++;
 		boolean success = false;
 		try {
 			List results = loader.list(this, queryParameters);
 			success = true;
 			return results;
 		}
 		finally {
 			dontFlushFromFind--;
 			delayedAfterCompletion();
 			afterOperation(success);
 		}
 	}
 
 	@Override
 	public SessionFactoryImplementor getSessionFactory() {
 		checkTransactionSynchStatus();
 		return factory;
 	}
 
 	@Override
 	public void initializeCollection(PersistentCollection collection, boolean writing)
 	throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		InitializeCollectionEvent event = new InitializeCollectionEvent( collection, this );
 		for ( InitializeCollectionEventListener listener : listeners( EventType.INIT_COLLECTION ) ) {
 			listener.onInitializeCollection( event );
 		}
 		delayedAfterCompletion();
 	}
 
 	@Override
 	public String bestGuessEntityName(Object object) {
 		if (object instanceof HibernateProxy) {
 			LazyInitializer initializer = ( ( HibernateProxy ) object ).getHibernateLazyInitializer();
 			// it is possible for this method to be called during flush processing,
 			// so make certain that we do not accidentally initialize an uninitialized proxy
 			if ( initializer.isUninitialized() ) {
 				return initializer.getEntityName();
 			}
 			object = initializer.getImplementation();
 		}
 		EntityEntry entry = persistenceContext.getEntry(object);
 		if (entry==null) {
 			return guessEntityName(object);
 		}
 		else {
 			return entry.getPersister().getEntityName();
 		}
 	}
 
 	@Override
 	public String getEntityName(Object object) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		if (object instanceof HibernateProxy) {
 			if ( !persistenceContext.containsProxy( object ) ) {
 				throw new TransientObjectException("proxy was not associated with the session");
 			}
 			object = ( (HibernateProxy) object ).getHibernateLazyInitializer().getImplementation();
 		}
 
 		EntityEntry entry = persistenceContext.getEntry(object);
 		if ( entry == null ) {
 			throwTransientObjectException( object );
 		}
 		return entry.getPersister().getEntityName();
 	}
 
 	private void throwTransientObjectException(Object object) throws HibernateException {
 		throw new TransientObjectException(
 				"object references an unsaved transient instance - save the transient instance before flushing: " +
 				guessEntityName(object)
 			);
 	}
 
 	@Override
 	public String guessEntityName(Object object) throws HibernateException {
 		errorIfClosed();
 		return entityNameResolver.resolveEntityName( object );
 	}
 
 	@Override
 	public void cancelQuery() throws HibernateException {
 		errorIfClosed();
-		getTransactionCoordinator().getJdbcCoordinator().cancelLastQuery();
+		this.jdbcCoordinator.cancelLastQuery();
 	}
 
 	@Override
 	public Interceptor getInterceptor() {
 		checkTransactionSynchStatus();
 		return interceptor;
 	}
 
 	@Override
 	public int getDontFlushFromFind() {
 		return dontFlushFromFind;
 	}
 
 	@Override
 	public String toString() {
 		StringBuilder buf = new StringBuilder(500)
 			.append( "SessionImpl(" );
 		if ( !isClosed() ) {
 			buf.append(persistenceContext)
 				.append(";")
 				.append(actionQueue);
 		}
 		else {
 			buf.append("<closed>");
 		}
 		return buf.append(')').toString();
 	}
 
 	@Override
 	public ActionQueue getActionQueue() {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return actionQueue;
 	}
 
 	@Override
 	public PersistenceContext getPersistenceContext() {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return persistenceContext;
 	}
 
 	@Override
 	public SessionStatistics getStatistics() {
 		checkTransactionSynchStatus();
 		return new SessionStatisticsImpl(this);
 	}
 
 	@Override
 	public boolean isEventSource() {
 		checkTransactionSynchStatus();
 		return true;
 	}
 
 	@Override
 	public boolean isDefaultReadOnly() {
 		return persistenceContext.isDefaultReadOnly();
 	}
 
 	@Override
 	public void setDefaultReadOnly(boolean defaultReadOnly) {
 		persistenceContext.setDefaultReadOnly( defaultReadOnly );
 	}
 
 	@Override
 	public boolean isReadOnly(Object entityOrProxy) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return persistenceContext.isReadOnly( entityOrProxy );
 	}
 
 	@Override
 	public void setReadOnly(Object entity, boolean readOnly) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		persistenceContext.setReadOnly( entity, readOnly );
 	}
 
 	@Override
 	public void doWork(final Work work) throws HibernateException {
 		WorkExecutorVisitable<Void> realWork = new WorkExecutorVisitable<Void>() {
 			@Override
 			public Void accept(WorkExecutor<Void> workExecutor, Connection connection) throws SQLException {
 				workExecutor.executeWork( work, connection );
 				return null;
 			}
 		};
 		doWork( realWork );
 	}
 
 	@Override
 	public <T> T doReturningWork(final ReturningWork<T> work) throws HibernateException {
 		WorkExecutorVisitable<T> realWork = new WorkExecutorVisitable<T>() {
 			@Override
 			public T accept(WorkExecutor<T> workExecutor, Connection connection) throws SQLException {
 				return workExecutor.executeReturningWork( work, connection );
 			}
 		};
 		return doWork( realWork );
 	}
 
 	private <T> T doWork(WorkExecutorVisitable<T> work) throws HibernateException {
-		return transactionCoordinator.getJdbcCoordinator().coordinateWork( work );
+		return this.jdbcCoordinator.coordinateWork( work );
 	}
 
 	@Override
 	public void afterScrollOperation() {
 		// nothing to do in a stateful session
 	}
 
 	@Override
 	public TransactionCoordinator getTransactionCoordinator() {
 		errorIfClosed();
 		return transactionCoordinator;
 	}
 
 	@Override
+	public JdbcCoordinator getJdbcCoordinator() {
+		return this.jdbcCoordinator;
+	}
+
+	@Override
 	public LoadQueryInfluencers getLoadQueryInfluencers() {
 		return loadQueryInfluencers;
 	}
 
 	// filter support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public Filter getEnabledFilter(String filterName) {
 		checkTransactionSynchStatus();
 		return loadQueryInfluencers.getEnabledFilter( filterName );
 	}
 
 	@Override
 	public Filter enableFilter(String filterName) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return loadQueryInfluencers.enableFilter( filterName );
 	}
 
 	@Override
 	public void disableFilter(String filterName) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		loadQueryInfluencers.disableFilter( filterName );
 	}
 
 	@Override
 	public Object getFilterParameterValue(String filterParameterName) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return loadQueryInfluencers.getFilterParameterValue( filterParameterName );
 	}
 
 	@Override
 	public Type getFilterParameterType(String filterParameterName) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return loadQueryInfluencers.getFilterParameterType( filterParameterName );
 	}
 
 	@Override
 	public Map getEnabledFilters() {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		return loadQueryInfluencers.getEnabledFilters();
 	}
 
 
 	// internal fetch profile support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public String getFetchProfile() {
 		checkTransactionSynchStatus();
 		return loadQueryInfluencers.getInternalFetchProfile();
 	}
 
 	@Override
 	public void setFetchProfile(String fetchProfile) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		loadQueryInfluencers.setInternalFetchProfile( fetchProfile );
 	}
 
 
 	// fetch profile support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public boolean isFetchProfileEnabled(String name) throws UnknownProfileException {
 		return loadQueryInfluencers.isFetchProfileEnabled( name );
 	}
 
 	@Override
 	public void enableFetchProfile(String name) throws UnknownProfileException {
 		loadQueryInfluencers.enableFetchProfile( name );
 	}
 
 	@Override
 	public void disableFetchProfile(String name) throws UnknownProfileException {
 		loadQueryInfluencers.disableFetchProfile( name );
 	}
 
 	private void checkTransactionSynchStatus() {
 		pulseTransactionCoordinator();
 		delayedAfterCompletion();
 	}
 
 	private void pulseTransactionCoordinator() {
 		if ( !isClosed() ) {
 			transactionCoordinator.pulse();
 		}
 	}
 
 	/**
 	 * Used by JDK serialization...
 	 *
 	 * @param ois The input stream from which we are being read...
 	 * @throws IOException Indicates a general IO stream exception
 	 * @throws ClassNotFoundException Indicates a class resolution issue
 	 */
-	private void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException {
+	private void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException, SQLException {
 		LOG.trace( "Deserializing session" );
 
 		ois.defaultReadObject();
 
 		entityNameResolver = new CoordinatingEntityNameResolver();
 
-		connectionReleaseMode = ConnectionReleaseMode.parse( ( String ) ois.readObject() );
+		connectionReleaseMode = ConnectionReleaseMode.parse( (String) ois.readObject() );
 		autoClear = ois.readBoolean();
 		autoJoinTransactions = ois.readBoolean();
-		flushMode = FlushMode.valueOf( ( String ) ois.readObject() );
-		cacheMode = CacheMode.valueOf( ( String ) ois.readObject() );
+		flushMode = FlushMode.valueOf( (String) ois.readObject() );
+		cacheMode = CacheMode.valueOf( (String) ois.readObject() );
 		flushBeforeCompletionEnabled = ois.readBoolean();
 		autoCloseSessionEnabled = ois.readBoolean();
-		interceptor = ( Interceptor ) ois.readObject();
+		interceptor = (Interceptor) ois.readObject();
 
 		factory = SessionFactoryImpl.deserialize( ois );
-		sessionOwner = ( SessionOwner ) ois.readObject();
+		this.jdbcSessionContext = new JdbcSessionContextImpl( factory, interceptor );
+		sessionOwner = (SessionOwner) ois.readObject();
+
+		jdbcCoordinator = JdbcCoordinatorImpl.deserialize( ois, this );
 
-		transactionCoordinator = TransactionCoordinatorImpl.deserialize( ois, this );
+		this.transactionCoordinator = getTransactionCoordinatorBuilder().buildTransactionCoordinator( jdbcCoordinator );
 
 		persistenceContext = StatefulPersistenceContext.deserialize( ois, this );
 		actionQueue = ActionQueue.deserialize( ois, this );
 
 		loadQueryInfluencers = (LoadQueryInfluencers) ois.readObject();
 
 		// LoadQueryInfluencers.getEnabledFilters() tries to validate each enabled
 		// filter, which will fail when called before FilterImpl.afterDeserialize( factory );
 		// Instead lookup the filter by name and then call FilterImpl.afterDeserialize( factory ).
 		for ( String filterName : loadQueryInfluencers.getEnabledFilterNames() ) {
 			((FilterImpl) loadQueryInfluencers.getEnabledFilter( filterName )).afterDeserialize( factory );
 		}
 	}
 
 	/**
 	 * Used by JDK serialization...
 	 *
 	 * @param oos The output stream to which we are being written...
 	 * @throws IOException Indicates a general IO stream exception
 	 */
 	private void writeObject(ObjectOutputStream oos) throws IOException {
-		if ( ! transactionCoordinator.getJdbcCoordinator().isReadyForSerialization() ) {
+		if ( !jdbcCoordinator.isReadyForSerialization() ) {
 			throw new IllegalStateException( "Cannot serialize a session while connected" );
 		}
 
 		LOG.trace( "Serializing session" );
 
 		oos.defaultWriteObject();
 
 		oos.writeObject( connectionReleaseMode.toString() );
 		oos.writeBoolean( autoClear );
 		oos.writeBoolean( autoJoinTransactions );
 		oos.writeObject( flushMode.toString() );
 		oos.writeObject( cacheMode.name() );
 		oos.writeBoolean( flushBeforeCompletionEnabled );
 		oos.writeBoolean( autoCloseSessionEnabled );
 		// we need to writeObject() on this since interceptor is user defined
 		oos.writeObject( interceptor );
 
 		factory.serialize( oos );
 		oos.writeObject( sessionOwner );
 
-		transactionCoordinator.serialize( oos );
+		jdbcCoordinator.serialize( oos );
 
 		persistenceContext.serialize( oos );
 		actionQueue.serialize( oos );
 
 		// todo : look at optimizing these...
 		oos.writeObject( loadQueryInfluencers );
 	}
 
 	@Override
 	public TypeHelper getTypeHelper() {
 		return getSessionFactory().getTypeHelper();
 	}
 
 	@Override
 	public LobHelper getLobHelper() {
 		if ( lobHelper == null ) {
 			lobHelper = new LobHelperImpl( this );
 		}
 		return lobHelper;
 	}
 
 	private transient LobHelperImpl lobHelper;
 
+	@Override
+	public JdbcSessionContext getJdbcSessionContext() {
+		return this.jdbcSessionContext;
+	}
+
+	private StatementInspector getStatementInspector() {
+		return this.interceptor;
+	}
+
+	@Override
+	public void beforeTransactionCompletion() {
+		LOG.trace( "before transaction completion" );
+		flushBeforeTransactionCompletion();
+		actionQueue.beforeTransactionCompletion();
+		try {
+			interceptor.beforeTransactionCompletion( currentHibernateTransaction );
+		}
+		catch (Throwable t) {
+			LOG.exceptionInBeforeTransactionCompletionInterceptor( t );
+		}
+	}
+
+	@Override
+	public void afterTransactionCompletion(boolean successful) {
+
+		LOG.trace( "after transaction completion" );
+
+		persistenceContext.afterTransactionCompletion();
+		actionQueue.afterTransactionCompletion( successful );
+
+		getEventListenerManager().transactionCompletion( successful );
+
+		if ( factory.getStatistics().isStatisticsEnabled() ) {
+			factory.getStatisticsImplementor().endTransaction( successful );
+		}
+
+		try {
+			interceptor.afterTransactionCompletion( currentHibernateTransaction );
+		}
+		catch (Throwable t) {
+			LOG.exceptionInAfterTransactionCompletionInterceptor( t );
+		}
+
+		if ( shouldAutoClose() && !isClosed() ) {
+			managedClose();
+		}
+
+		if ( autoClear ) {
+			internalClear();
+		}
+	}
+
 	private static class LobHelperImpl implements LobHelper {
 		private final SessionImpl session;
 
 		private LobHelperImpl(SessionImpl session) {
 			this.session = session;
 		}
 
 		@Override
 		public Blob createBlob(byte[] bytes) {
 			return lobCreator().createBlob( bytes );
 		}
 
 		private LobCreator lobCreator() {
 			// Always use NonContextualLobCreator.  If ContextualLobCreator is
 			// used both here and in WrapperOptions, 
 			return NonContextualLobCreator.INSTANCE;
 		}
 
 		@Override
 		public Blob createBlob(InputStream stream, long length) {
 			return lobCreator().createBlob( stream, length );
 		}
 
 		@Override
 		public Clob createClob(String string) {
 			return lobCreator().createClob( string );
 		}
 
 		@Override
 		public Clob createClob(Reader reader, long length) {
 			return lobCreator().createClob( reader, length );
 		}
 
 		@Override
 		public NClob createNClob(String string) {
 			return lobCreator().createNClob( string );
 		}
 
 		@Override
 		public NClob createNClob(Reader reader, long length) {
 			return lobCreator().createNClob( reader, length );
 		}
 	}
 
 	private static class SharedSessionBuilderImpl extends SessionFactoryImpl.SessionBuilderImpl implements SharedSessionBuilder {
 		private final SessionImpl session;
 		private boolean shareTransactionContext;
 
 		private SharedSessionBuilderImpl(SessionImpl session) {
 			super( session.factory );
 			this.session = session;
 			super.owner( session.sessionOwner );
 			super.tenantIdentifier( session.getTenantIdentifier() );
 		}
 
 		@Override
 		public SessionBuilder tenantIdentifier(String tenantIdentifier) {
 			// todo : is this always true?  Or just in the case of sharing JDBC resources?
 			throw new SessionException( "Cannot redefine tenant identifier on child session" );
 		}
 
 		@Override
-		protected TransactionCoordinatorImpl getTransactionCoordinator() {
+		protected TransactionCoordinator getTransactionCoordinator() {
 			return shareTransactionContext ? session.transactionCoordinator : super.getTransactionCoordinator();
 		}
 
 		@Override
+		protected JdbcCoordinatorImpl getJdbcCoordinator() {
+			return shareTransactionContext ? session.jdbcCoordinator : super.getJdbcCoordinator();
+		}
+
+		@Override
+		protected Transaction getTransaction() {
+			return shareTransactionContext ? session.currentHibernateTransaction : super.getTransaction();
+		}
+
+		@Override
 		protected ActionQueue.TransactionCompletionProcesses getTransactionCompletionProcesses() {
 			return shareTransactionContext ?
 					session.getActionQueue().getTransactionCompletionProcesses() :
 					super.getTransactionCompletionProcesses();
 		}
 
 		@Override
 		public SharedSessionBuilder interceptor() {
 			return interceptor( session.interceptor );
 		}
 
 		@Override
 		public SharedSessionBuilder connection() {
 			this.shareTransactionContext = true;
 			return this;
 		}
 
 		@Override
 		public SharedSessionBuilder connectionReleaseMode() {
 			return connectionReleaseMode( session.connectionReleaseMode );
 		}
 
 		@Override
 		public SharedSessionBuilder autoJoinTransactions() {
 			return autoJoinTransactions( session.autoJoinTransactions );
 		}
 
 		@Override
 		public SharedSessionBuilder autoClose() {
 			return autoClose( session.autoCloseSessionEnabled );
 		}
 
 		@Override
 		public SharedSessionBuilder flushBeforeCompletion() {
 			return flushBeforeCompletion( session.flushBeforeCompletionEnabled );
 		}
 
 		/**
 		 * @deprecated Use {@link #connection()} instead
 		 */
 		@Override
 		@Deprecated
 		public SharedSessionBuilder transactionContext() {
 			return connection();
 		}
 
 		@Override
 		public SharedSessionBuilder interceptor(Interceptor interceptor) {
 			return (SharedSessionBuilder) super.interceptor( interceptor );
 		}
 
 		@Override
 		public SharedSessionBuilder noInterceptor() {
 			return (SharedSessionBuilder) super.noInterceptor();
 		}
 
 		@Override
 		public SharedSessionBuilder connection(Connection connection) {
 			return (SharedSessionBuilder) super.connection( connection );
 		}
 
 		@Override
 		public SharedSessionBuilder connectionReleaseMode(ConnectionReleaseMode connectionReleaseMode) {
 			return (SharedSessionBuilder) super.connectionReleaseMode( connectionReleaseMode );
 		}
 
 		@Override
 		public SharedSessionBuilder autoJoinTransactions(boolean autoJoinTransactions) {
 			return (SharedSessionBuilder) super.autoJoinTransactions( autoJoinTransactions );
 		}
 
 		@Override
 		public SharedSessionBuilder autoClose(boolean autoClose) {
 			return (SharedSessionBuilder) super.autoClose( autoClose );
 		}
 
 		@Override
 		public SharedSessionBuilder flushBeforeCompletion(boolean flushBeforeCompletion) {
 			return (SharedSessionBuilder) super.flushBeforeCompletion( flushBeforeCompletion );
 		}
 
 		@Override
 		public SharedSessionBuilder eventListeners(SessionEventListener... listeners) {
 			super.eventListeners( listeners );
 			return this;
 		}
 
 		@Override
 		public SessionBuilder clearEventListeners() {
 			super.clearEventListeners();
 			return this;
 		}
 	}
 
 	private class CoordinatingEntityNameResolver implements EntityNameResolver {
 		@Override
 		public String resolveEntityName(Object entity) {
 			String entityName = interceptor.getEntityName( entity );
 			if ( entityName != null ) {
 				return entityName;
 			}
 
 			for ( EntityNameResolver resolver : factory.iterateEntityNameResolvers() ) {
 				entityName = resolver.resolveEntityName( entity );
 				if ( entityName != null ) {
 					break;
 				}
 			}
 
 			if ( entityName != null ) {
 				return entityName;
 			}
 
 			// the old-time stand-by...
 			return entity.getClass().getName();
 		}
 	}
 
 	private class LockRequestImpl implements LockRequest {
 		private final LockOptions lockOptions;
 		private LockRequestImpl(LockOptions lo) {
 			lockOptions = new LockOptions();
 			LockOptions.copy(lo, lockOptions);
 		}
 
 		@Override
 		public LockMode getLockMode() {
 			return lockOptions.getLockMode();
 		}
 
 		@Override
 		public LockRequest setLockMode(LockMode lockMode) {
 			lockOptions.setLockMode(lockMode);
 			return this;
 		}
 
 		@Override
 		public int getTimeOut() {
 			return lockOptions.getTimeOut();
 		}
 
 		@Override
 		public LockRequest setTimeOut(int timeout) {
 			lockOptions.setTimeOut(timeout);
 			return this;
 		}
 
 		@Override
 		public boolean getScope() {
 			return lockOptions.getScope();
 		}
 
 		@Override
 		public LockRequest setScope(boolean scope) {
 			lockOptions.setScope(scope);
 			return this;
 		}
 
 		@Override
 		public void lock(String entityName, Object object) throws HibernateException {
 			fireLock( entityName, object, lockOptions );
 		}
 
 		@Override
 		public void lock(Object object) throws HibernateException {
 			fireLock( object, lockOptions );
 		}
 	}
 
 	private class IdentifierLoadAccessImpl implements IdentifierLoadAccess {
 		private final EntityPersister entityPersister;
 		private LockOptions lockOptions;
 
 		private IdentifierLoadAccessImpl(EntityPersister entityPersister) {
 			this.entityPersister = entityPersister;
 		}
 
 		private IdentifierLoadAccessImpl(String entityName) {
 			this( locateEntityPersister( entityName ) );
 		}
 
 		private IdentifierLoadAccessImpl(Class entityClass) {
 			this( entityClass.getName() );
 		}
 
 		@Override
 		public final IdentifierLoadAccessImpl with(LockOptions lockOptions) {
 			this.lockOptions = lockOptions;
 			return this;
 		}
 
 		@Override
 		public final Object getReference(Serializable id) {
 			if ( this.lockOptions != null ) {
 				LoadEvent event = new LoadEvent( id, entityPersister.getEntityName(), lockOptions, SessionImpl.this );
 				fireLoad( event, LoadEventListener.LOAD );
 				return event.getResult();
 			}
 
 			LoadEvent event = new LoadEvent( id, entityPersister.getEntityName(), false, SessionImpl.this );
 			boolean success = false;
 			try {
 				fireLoad( event, LoadEventListener.LOAD );
 				if ( event.getResult() == null ) {
 					getFactory().getEntityNotFoundDelegate().handleEntityNotFound( entityPersister.getEntityName(), id );
 				}
 				success = true;
 				return event.getResult();
 			}
 			finally {
 				afterOperation( success );
 			}
 		}
 
 		@Override
 		public final Object load(Serializable id) {
 			if ( this.lockOptions != null ) {
 				LoadEvent event = new LoadEvent( id, entityPersister.getEntityName(), lockOptions, SessionImpl.this );
 				fireLoad( event, LoadEventListener.GET );
 				return event.getResult();
 			}
 
 			LoadEvent event = new LoadEvent( id, entityPersister.getEntityName(), false, SessionImpl.this );
 			boolean success = false;
 			try {
 				fireLoad( event, LoadEventListener.GET );
 				success = true;
 			}
 			catch (ObjectNotFoundException e) {
 				// if session cache contains proxy for non-existing object
 			}
 			finally {
 				afterOperation( success );
 			}
 			return event.getResult();
 		}
 	}
 
 	private EntityPersister locateEntityPersister(String entityName) {
 		final EntityPersister entityPersister = factory.getEntityPersister( entityName );
 		if ( entityPersister == null ) {
 			throw new HibernateException( "Unable to locate persister: " + entityName );
 		}
 		return entityPersister;
 	}
 
 	private abstract class BaseNaturalIdLoadAccessImpl  {
 		private final EntityPersister entityPersister;
 		private LockOptions lockOptions;
 		private boolean synchronizationEnabled = true;
 
 		private BaseNaturalIdLoadAccessImpl(EntityPersister entityPersister) {
 			this.entityPersister = entityPersister;
 
 			if ( ! entityPersister.hasNaturalIdentifier() ) {
 				throw new HibernateException(
 						String.format( "Entity [%s] did not define a natural id", entityPersister.getEntityName() )
 				);
 			}
 		}
 
 		private BaseNaturalIdLoadAccessImpl(String entityName) {
 			this( locateEntityPersister( entityName ) );
 		}
 
 		private BaseNaturalIdLoadAccessImpl(Class entityClass) {
 			this( entityClass.getName() );
 		}
 
 		public BaseNaturalIdLoadAccessImpl with(LockOptions lockOptions) {
 			this.lockOptions = lockOptions;
 			return this;
 		}
 
 		protected void synchronizationEnabled(boolean synchronizationEnabled) {
 			this.synchronizationEnabled = synchronizationEnabled;
 		}
 
 		protected final Serializable resolveNaturalId(Map<String, Object> naturalIdParameters) {
 			performAnyNeededCrossReferenceSynchronizations();
 
 			final ResolveNaturalIdEvent event =
 					new ResolveNaturalIdEvent( naturalIdParameters, entityPersister, SessionImpl.this );
 			fireResolveNaturalId( event );
 
 			if ( event.getEntityId() == PersistenceContext.NaturalIdHelper.INVALID_NATURAL_ID_REFERENCE ) {
 				return null;
 			}
 			else {
 				return event.getEntityId();
 			}
 		}
 
 		protected void performAnyNeededCrossReferenceSynchronizations() {
 			if ( ! synchronizationEnabled ) {
 				// synchronization (this process) was disabled
 				return;
 			}
 			if ( entityPersister.getEntityMetamodel().hasImmutableNaturalId() ) {
 				// only mutable natural-ids need this processing
 				return;
 			}
 			if ( ! isTransactionInProgress() ) {
 				// not in a transaction so skip synchronization
 				return;
 			}
 
 			final boolean debugEnabled = LOG.isDebugEnabled();
 			for ( Serializable pk : getPersistenceContext().getNaturalIdHelper().getCachedPkResolutions( entityPersister ) ) {
 				final EntityKey entityKey = generateEntityKey( pk, entityPersister );
 				final Object entity = getPersistenceContext().getEntity( entityKey );
 				final EntityEntry entry = getPersistenceContext().getEntry( entity );
 
 				if ( entry == null ) {
 					if ( debugEnabled ) {
 						LOG.debug(
 								"Cached natural-id/pk resolution linked to null EntityEntry in persistence context : "
 										+ MessageHelper.infoString( entityPersister, pk, getFactory() )
 						);
 					}
 					continue;
 				}
 
 				if ( !entry.requiresDirtyCheck( entity ) ) {
 					continue;
 				}
 
 				// MANAGED is the only status we care about here...
 				if ( entry.getStatus() != Status.MANAGED ) {
 					continue;
 				}
 
 				getPersistenceContext().getNaturalIdHelper().handleSynchronization(
 						entityPersister,
 						pk,
 						entity
 				);
 			}
 		}
 
 		protected final IdentifierLoadAccess getIdentifierLoadAccess() {
 			final IdentifierLoadAccessImpl identifierLoadAccess = new IdentifierLoadAccessImpl( entityPersister );
 			if ( this.lockOptions != null ) {
 				identifierLoadAccess.with( lockOptions );
 			}
 			return identifierLoadAccess;
 		}
 
 		protected EntityPersister entityPersister() {
 			return entityPersister;
 		}
 	}
 
 	private class NaturalIdLoadAccessImpl extends BaseNaturalIdLoadAccessImpl implements NaturalIdLoadAccess {
 		private final Map<String, Object> naturalIdParameters = new LinkedHashMap<String, Object>();
 
 		private NaturalIdLoadAccessImpl(EntityPersister entityPersister) {
 			super(entityPersister);
 		}
 
 		private NaturalIdLoadAccessImpl(String entityName) {
 			this( locateEntityPersister( entityName ) );
 		}
 
 		private NaturalIdLoadAccessImpl(Class entityClass) {
 			this( entityClass.getName() );
 		}
 		
 		@Override
 		public NaturalIdLoadAccessImpl with(LockOptions lockOptions) {
 			return (NaturalIdLoadAccessImpl) super.with( lockOptions );
 		}
 
 		@Override
 		public NaturalIdLoadAccess using(String attributeName, Object value) {
 			naturalIdParameters.put( attributeName, value );
 			return this;
 		}
 
 		@Override
 		public NaturalIdLoadAccessImpl setSynchronizationEnabled(boolean synchronizationEnabled) {
 			super.synchronizationEnabled( synchronizationEnabled );
 			return this;
 		}
 
 		@Override
 		public final Object getReference() {
 			final Serializable entityId = resolveNaturalId( this.naturalIdParameters );
 			if ( entityId == null ) {
 				return null;
 			}
 			return this.getIdentifierLoadAccess().getReference( entityId );
 		}
 
 		@Override
 		public final Object load() {
 			final Serializable entityId = resolveNaturalId( this.naturalIdParameters );
 			if ( entityId == null ) {
 				return null;
 			}
 			try {
 				return this.getIdentifierLoadAccess().load( entityId );
 			}
 			catch (EntityNotFoundException enf) {
 				// OK
 			}
 			catch (ObjectNotFoundException nf) {
 				// OK
 			}
 			return null;
 		}
 	}
 
 	private class SimpleNaturalIdLoadAccessImpl extends BaseNaturalIdLoadAccessImpl implements SimpleNaturalIdLoadAccess {
 		private final String naturalIdAttributeName;
 
 		private SimpleNaturalIdLoadAccessImpl(EntityPersister entityPersister) {
 			super(entityPersister);
 
 			if ( entityPersister.getNaturalIdentifierProperties().length != 1 ) {
 				throw new HibernateException(
 						String.format( "Entity [%s] did not define a simple natural id", entityPersister.getEntityName() )
 				);
 			}
 
 			final int naturalIdAttributePosition = entityPersister.getNaturalIdentifierProperties()[0];
 			this.naturalIdAttributeName = entityPersister.getPropertyNames()[ naturalIdAttributePosition ];
 		}
 
 		private SimpleNaturalIdLoadAccessImpl(String entityName) {
 			this( locateEntityPersister( entityName ) );
 		}
 
 		private SimpleNaturalIdLoadAccessImpl(Class entityClass) {
 			this( entityClass.getName() );
 		}
 
 		@Override
 		public final SimpleNaturalIdLoadAccessImpl with(LockOptions lockOptions) {
 			return (SimpleNaturalIdLoadAccessImpl) super.with( lockOptions );
 		}
 		
 		private Map<String, Object> getNaturalIdParameters(Object naturalIdValue) {
 			return Collections.singletonMap( naturalIdAttributeName, naturalIdValue );
 		}
 
 		@Override
 		public SimpleNaturalIdLoadAccessImpl setSynchronizationEnabled(boolean synchronizationEnabled) {
 			super.synchronizationEnabled( synchronizationEnabled );
 			return this;
 		}
 
 		@Override
 		public Object getReference(Object naturalIdValue) {
 			final Serializable entityId = resolveNaturalId( getNaturalIdParameters( naturalIdValue ) );
 			if ( entityId == null ) {
 				return null;
 			}
 			return this.getIdentifierLoadAccess().getReference( entityId );
 		}
 
 		@Override
 		public Object load(Object naturalIdValue) {
 			final Serializable entityId = resolveNaturalId( getNaturalIdParameters( naturalIdValue ) );
 			if ( entityId == null ) {
 				return null;
 			}
 			try {
 				return this.getIdentifierLoadAccess().load( entityId );
 			}
 			catch (EntityNotFoundException enf) {
 				// OK
 			}
 			catch (ObjectNotFoundException nf) {
 				// OK
 			}
 			return null;
 		}
 	}
+
+	@Override
+	public void afterTransactionBegin() {
+		errorIfClosed();
+		interceptor.afterTransactionBegin( currentHibernateTransaction );
+	}
+
+	@Override
+	public void flushBeforeTransactionCompletion() {
+		boolean flush = false;
+		try {
+			flush = (!isFlushModeNever() &&
+					!flushBeforeCompletionEnabled) || (
+					!isClosed()
+							&& !isFlushModeNever()
+							&& flushBeforeCompletionEnabled
+							&& !JtaStatusHelper.isRollback(
+							getSessionFactory().getSettings()
+									.getJtaPlatform()
+									.getCurrentStatus()
+					));
+		}
+		catch (SystemException se) {
+			throw new HibernateException( "could not determine transaction status in beforeCompletion()", se );
+		}
+		if ( flush ) {
+			managedFlush();
+		}
+	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/StatelessSessionImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/StatelessSessionImpl.java
index 3157f162ae..218836435c 100755
--- a/hibernate-core/src/main/java/org/hibernate/internal/StatelessSessionImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/StatelessSessionImpl.java
@@ -1,807 +1,797 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
+import javax.transaction.SystemException;
 import java.io.Serializable;
 import java.sql.Connection;
 import java.util.Collections;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
+import org.jboss.logging.Logger;
+
 import org.hibernate.CacheMode;
-import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.Criteria;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.EntityMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.LockMode;
 import org.hibernate.MappingException;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.SessionException;
 import org.hibernate.StatelessSession;
 import org.hibernate.Transaction;
 import org.hibernate.UnresolvableObjectException;
 import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.internal.SessionEventListenerManagerImpl;
 import org.hibernate.engine.internal.StatefulPersistenceContext;
 import org.hibernate.engine.internal.Versioning;
+import org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl;
+import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.engine.query.spi.HQLQueryPlan;
 import org.hibernate.engine.query.spi.NativeSQLQueryPlan;
 import org.hibernate.engine.query.spi.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionEventListenerManager;
-import org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
-import org.hibernate.engine.transaction.spi.TransactionEnvironment;
-import org.hibernate.engine.transaction.spi.TransactionImplementor;
+import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
 import org.hibernate.id.IdentifierGeneratorHelper;
 import org.hibernate.loader.criteria.CriteriaLoader;
 import org.hibernate.loader.custom.CustomLoader;
 import org.hibernate.loader.custom.CustomQuery;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.HibernateProxy;
+import org.hibernate.resource.jdbc.spi.JdbcSessionContext;
+import org.hibernate.resource.transaction.TransactionCoordinator;
+import org.hibernate.resource.transaction.spi.TransactionStatus;
 import org.hibernate.type.Type;
 
-import org.jboss.logging.Logger;
-
 /**
  * @author Gavin King
  */
 public class StatelessSessionImpl extends AbstractSessionImpl implements StatelessSession {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, StatelessSessionImpl.class.getName());
 
 	private TransactionCoordinator transactionCoordinator;
+
+	private transient JdbcCoordinator jdbcCoordinator;
 	private PersistenceContext temporaryPersistenceContext = new StatefulPersistenceContext( this );
 	private long timestamp;
-	
+	private JdbcSessionContext jdbcSessionContext;
+
 	StatelessSessionImpl(
 			Connection connection,
 			String tenantIdentifier,
 			SessionFactoryImpl factory) {
 		this( connection, tenantIdentifier, factory, factory.getSettings().getRegionFactory().nextTimestamp() );
 	}
 
 	StatelessSessionImpl(
 			Connection connection,
 			String tenantIdentifier,
 			SessionFactoryImpl factory,
 			long timestamp) {
 		super( factory, tenantIdentifier );
-		this.transactionCoordinator = new TransactionCoordinatorImpl( connection, this );
+		this.jdbcSessionContext = new JdbcSessionContextImpl( factory, EmptyInterceptor.INSTANCE );
+		this.jdbcCoordinator = new JdbcCoordinatorImpl( connection, this );
+
+		this.transactionCoordinator = getTransactionCoordinatorBuilder().buildTransactionCoordinator( jdbcCoordinator );
+		this.currentHibernateTransaction = getTransaction();
 		this.timestamp = timestamp;
 	}
 
-	// TransactionContext ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
 	@Override
 	public TransactionCoordinator getTransactionCoordinator() {
 		return transactionCoordinator;
 	}
 
 	@Override
-	public TransactionEnvironment getTransactionEnvironment() {
-		return factory.getTransactionEnvironment();
+	public JdbcCoordinator getJdbcCoordinator() {
+		return this.jdbcCoordinator;
+	}
+
+	@Override
+	public boolean shouldAutoJoinTransaction() {
+		return true;
 	}
 
 	// inserts ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public Serializable insert(Object entity) {
 		errorIfClosed();
 		return insert(null, entity);
 	}
 
 	@Override
 	public Serializable insert(String entityName, Object entity) {
 		errorIfClosed();
 		EntityPersister persister = getEntityPersister( entityName, entity );
 		Serializable id = persister.getIdentifierGenerator().generate( this, entity );
 		Object[] state = persister.getPropertyValues( entity );
 		if ( persister.isVersioned() ) {
 			boolean substitute = Versioning.seedVersion(
 					state, persister.getVersionProperty(), persister.getVersionType(), this
 			);
 			if ( substitute ) {
 				persister.setPropertyValues( entity, state );
 			}
 		}
 		if ( id == IdentifierGeneratorHelper.POST_INSERT_INDICATOR ) {
 			id = persister.insert(state, entity, this);
 		}
 		else {
 			persister.insert(id, state, entity, this);
 		}
 		persister.setIdentifier( entity, id, this );
 		return id;
 	}
 
 
 	// deletes ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void delete(Object entity) {
 		errorIfClosed();
-		delete(null, entity);
+		delete( null, entity );
 	}
 
 	@Override
 	public void delete(String entityName, Object entity) {
 		errorIfClosed();
-		EntityPersister persister = getEntityPersister(entityName, entity);
+		EntityPersister persister = getEntityPersister( entityName, entity );
 		Serializable id = persister.getIdentifier( entity, this );
 		Object version = persister.getVersion( entity );
-		persister.delete(id, version, entity, this);
+		persister.delete( id, version, entity, this );
 	}
 
 
 	// updates ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void update(Object entity) {
 		errorIfClosed();
 		update(null, entity);
 	}
 
 	@Override
 	public void update(String entityName, Object entity) {
 		errorIfClosed();
 		EntityPersister persister = getEntityPersister(entityName, entity);
 		Serializable id = persister.getIdentifier( entity, this );
 		Object[] state = persister.getPropertyValues( entity );
 		Object oldVersion;
 		if ( persister.isVersioned() ) {
 			oldVersion = persister.getVersion( entity );
 			Object newVersion = Versioning.increment( oldVersion, persister.getVersionType(), this );
 			Versioning.setVersion(state, newVersion, persister);
 			persister.setPropertyValues( entity, state );
 		}
 		else {
 			oldVersion = null;
 		}
 		persister.update(id, state, null, false, null, oldVersion, entity, null, this);
 	}
 
 
 	// loading ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public Object get(Class entityClass, Serializable id) {
 		return get( entityClass.getName(), id );
 	}
 
 	@Override
 	public Object get(Class entityClass, Serializable id, LockMode lockMode) {
 		return get( entityClass.getName(), id, lockMode );
 	}
 
 	@Override
 	public Object get(String entityName, Serializable id) {
 		return get(entityName, id, LockMode.NONE);
 	}
 
 	@Override
 	public Object get(String entityName, Serializable id, LockMode lockMode) {
 		errorIfClosed();
 		Object result = getFactory().getEntityPersister(entityName)
 				.load(id, null, lockMode, this);
 		if ( temporaryPersistenceContext.isLoadFinished() ) {
 			temporaryPersistenceContext.clear();
 		}
 		return result;
 	}
 
 	@Override
 	public void refresh(Object entity) {
 		refresh( bestGuessEntityName( entity ), entity, LockMode.NONE );
 	}
 
 	@Override
 	public void refresh(String entityName, Object entity) {
 		refresh( entityName, entity, LockMode.NONE );
 	}
 
 	@Override
 	public void refresh(Object entity, LockMode lockMode) {
 		refresh( bestGuessEntityName( entity ), entity, lockMode );
 	}
 
 	@Override
 	public void refresh(String entityName, Object entity, LockMode lockMode) {
 		final EntityPersister persister = this.getEntityPersister( entityName, entity );
 		final Serializable id = persister.getIdentifier( entity, this );
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Refreshing transient {0}", MessageHelper.infoString( persister, id, this.getFactory() ) );
 		}
 		// TODO : can this ever happen???
 //		EntityKey key = new EntityKey( id, persister, source.getEntityMode() );
 //		if ( source.getPersistenceContext().getEntry( key ) != null ) {
 //			throw new PersistentObjectException(
 //					"attempted to refresh transient instance when persistent " +
 //					"instance was already associated with the Session: " +
 //					MessageHelper.infoString( persister, id, source.getFactory() )
 //			);
 //		}
 
 		if ( persister.hasCache() ) {
 			final CacheKey ck = generateCacheKey( id, persister.getIdentifierType(), persister.getRootEntityName() );
 			persister.getCacheAccessStrategy().evict( ck );
 		}
 
 		String previousFetchProfile = this.getFetchProfile();
 		Object result = null;
 		try {
 			this.setFetchProfile( "refresh" );
 			result = persister.load( id, entity, lockMode, this );
 		}
 		finally {
 			this.setFetchProfile( previousFetchProfile );
 		}
 		UnresolvableObjectException.throwIfNull( result, id, persister.getEntityName() );
 	}
 
 	@Override
 	public Object immediateLoad(String entityName, Serializable id)
 			throws HibernateException {
 		throw new SessionException("proxies cannot be fetched by a stateless session");
 	}
 
 	@Override
 	public void initializeCollection(
 			PersistentCollection collection,
 	        boolean writing) throws HibernateException {
 		throw new SessionException("collections cannot be fetched by a stateless session");
 	}
 
 	@Override
 	public Object instantiate(
 			String entityName,
 	        Serializable id) throws HibernateException {
 		errorIfClosed();
 		return getFactory().getEntityPersister( entityName ).instantiate( id, this );
 	}
 
 	@Override
 	public Object internalLoad(
 			String entityName,
 	        Serializable id,
 	        boolean eager,
 	        boolean nullable) throws HibernateException {
 		errorIfClosed();
 		EntityPersister persister = getFactory().getEntityPersister( entityName );
 		// first, try to load it from the temp PC associated to this SS
 		Object loaded = temporaryPersistenceContext.getEntity( generateEntityKey( id, persister ) );
 		if ( loaded != null ) {
 			// we found it in the temp PC.  Should indicate we are in the midst of processing a result set
 			// containing eager fetches via join fetch
 			return loaded;
 		}
 		if ( !eager && persister.hasProxy() ) {
 			// if the metadata allowed proxy creation and caller did not request forceful eager loading,
 			// generate a proxy
 			return persister.createProxy( id, this );
 		}
 		// otherwise immediately materialize it
 		return get( entityName, id );
 	}
 
 	@Override
 	public Iterator iterate(String query, QueryParameters queryParameters) throws HibernateException {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public Iterator iterateFilter(Object collection, String filter, QueryParameters queryParameters)
 	throws HibernateException {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public List listFilter(Object collection, String filter, QueryParameters queryParameters)
 	throws HibernateException {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public boolean isOpen() {
 		return !isClosed();
 	}
 
 	@Override
 	public void close() {
 		managedClose();
 	}
 
 	@Override
-	public ConnectionReleaseMode getConnectionReleaseMode() {
-		return factory.getSettings().getConnectionReleaseMode();
-	}
-
-	@Override
-	public boolean shouldAutoJoinTransaction() {
-		return true;
-	}
-
-	@Override
 	public boolean isAutoCloseSessionEnabled() {
 		return factory.getSettings().isAutoCloseSessionEnabled();
 	}
 
 	@Override
-	public boolean isFlushBeforeCompletionEnabled() {
-		return true;
+	public boolean shouldAutoClose() {
+		return isAutoCloseSessionEnabled() && !isClosed();
 	}
 
-	@Override
-	public boolean isFlushModeNever() {
+
+	private boolean isFlushModeNever() {
 		return false;
 	}
 
-	@Override
-	public void managedClose() {
+	private void managedClose() {
 		if ( isClosed() ) {
 			throw new SessionException( "Session was already closed!" );
 		}
-		transactionCoordinator.close();
+		jdbcCoordinator.close();
 		setClosed();
 	}
 
-	@Override
-	public void managedFlush() {
+	private void managedFlush() {
 		errorIfClosed();
-		getTransactionCoordinator().getJdbcCoordinator().executeBatch();
-	}
-
-	@Override
-	public boolean shouldAutoClose() {
-		return isAutoCloseSessionEnabled() && !isClosed();
-	}
-
-	@Override
-	public void afterTransactionBegin(TransactionImplementor hibernateTransaction) {
-		// nothing to do here
-	}
-
-	@Override
-	public void beforeTransactionCompletion(TransactionImplementor hibernateTransaction) {
-		// nothing to do here
-	}
-
-	@Override
-	public void afterTransactionCompletion(TransactionImplementor hibernateTransaction, boolean successful) {
-		// nothing to do here
-	}
-
-	@Override
-	public String onPrepareStatement(String sql) {
-		return sql;
+		jdbcCoordinator.executeBatch();
 	}
 
 	private SessionEventListenerManagerImpl sessionEventsManager;
 
 	@Override
 	public SessionEventListenerManager getEventListenerManager() {
 		if ( sessionEventsManager == null ) {
 			sessionEventsManager = new SessionEventListenerManagerImpl();
 		}
 		return sessionEventsManager;
 	}
 
 	@Override
-	public void startPrepareStatement() {
-	}
-
-	@Override
-	public void endPrepareStatement() {
-	}
-
-	@Override
-	public void startStatementExecution() {
-	}
-
-	@Override
-	public void endStatementExecution() {
-	}
-
-	@Override
-	public void startBatchExecution() {
-	}
-
-	@Override
-	public void endBatchExecution() {
-	}
-
-	@Override
 	public String bestGuessEntityName(Object object) {
 		if (object instanceof HibernateProxy) {
 			object = ( (HibernateProxy) object ).getHibernateLazyInitializer().getImplementation();
 		}
 		return guessEntityName(object);
 	}
 
 	@Override
 	public Connection connection() {
 		errorIfClosed();
-		return transactionCoordinator.getJdbcCoordinator().getLogicalConnection().getConnection();
+		return jdbcCoordinator.getLogicalConnection().getPhysicalConnection();
 	}
 
 	@Override
 	public int executeUpdate(String query, QueryParameters queryParameters)
 			throws HibernateException {
 		errorIfClosed();
 		queryParameters.validateParameters();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		boolean success = false;
 		int result = 0;
 		try {
 			result = plan.performExecuteUpdate( queryParameters, this );
 			success = true;
 		}
 		finally {
 			afterOperation(success);
 		}
 		temporaryPersistenceContext.clear();
 		return result;
 	}
 
 	@Override
 	public CacheMode getCacheMode() {
 		return CacheMode.IGNORE;
 	}
 
 	@Override
 	public int getDontFlushFromFind() {
 		return 0;
 	}
 
 	@Override
 	public Map getEnabledFilters() {
 		return Collections.EMPTY_MAP;
 	}
 
 	@Override
 	public Serializable getContextEntityIdentifier(Object object) {
 		errorIfClosed();
 		return null;
 	}
 
 	public EntityMode getEntityMode() {
 		return EntityMode.POJO;
 	}
 
 	@Override
 	public EntityPersister getEntityPersister(String entityName, Object object)
 			throws HibernateException {
 		errorIfClosed();
 		if ( entityName==null ) {
 			return factory.getEntityPersister( guessEntityName( object ) );
 		}
 		else {
 			return factory.getEntityPersister( entityName ).getSubclassEntityPersister( object, getFactory() );
 		}
 	}
 
 	@Override
 	public Object getEntityUsingInterceptor(EntityKey key) throws HibernateException {
 		errorIfClosed();
 		return null;
 	}
 
 	@Override
 	public Type getFilterParameterType(String filterParameterName) {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public Object getFilterParameterValue(String filterParameterName) {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public FlushMode getFlushMode() {
 		return FlushMode.COMMIT;
 	}
 
 	@Override
 	public Interceptor getInterceptor() {
 		return EmptyInterceptor.INSTANCE;
 	}
 
 	@Override
 	public PersistenceContext getPersistenceContext() {
 		return temporaryPersistenceContext;
 	}
 
 	@Override
 	public long getTimestamp() {
 		return timestamp;
 	}
 
 	@Override
 	public String guessEntityName(Object entity) throws HibernateException {
 		errorIfClosed();
 		return entity.getClass().getName();
 	}
 
 	@Override
 	public boolean isConnected() {
-		return transactionCoordinator.getJdbcCoordinator().getLogicalConnection().isPhysicallyConnected();
+		return jdbcCoordinator.getLogicalConnection().isPhysicallyConnected();
 	}
 
 	@Override
 	public boolean isTransactionInProgress() {
-		return transactionCoordinator.isTransactionInProgress();
+		return !isClosed() && transactionCoordinator.isJoined() && transactionCoordinator.getTransactionDriverControl()
+				.getStatus() == TransactionStatus.ACTIVE;
 	}
 
 	@Override
 	public void setAutoClear(boolean enabled) {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public void disableTransactionAutoJoin() {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public void setCacheMode(CacheMode cm) {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public void setFlushMode(FlushMode fm) {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
-	public Transaction getTransaction() throws HibernateException {
-		errorIfClosed();
-		return transactionCoordinator.getTransaction();
-	}
-
-	@Override
 	public Transaction beginTransaction() throws HibernateException {
 		errorIfClosed();
 		Transaction result = getTransaction();
 		result.begin();
 		return result;
 	}
 
 	@Override
 	public boolean isEventSource() {
 		return false;
 	}
 
 	public boolean isDefaultReadOnly() {
 		return false;
 	}
 
 	public void setDefaultReadOnly(boolean readOnly) throws HibernateException {
 		if ( readOnly ) {
 			throw new UnsupportedOperationException();
 		}
 	}
 
 /////////////////////////////////////////////////////////////////////////////////////////////////////
 
 	//TODO: COPY/PASTE FROM SessionImpl, pull up!
 
 	@Override
 	public List list(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		queryParameters.validateParameters();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		boolean success = false;
 		List results = Collections.EMPTY_LIST;
 		try {
 			results = plan.performList( queryParameters, this );
 			success = true;
 		}
 		finally {
 			afterOperation(success);
 		}
 		temporaryPersistenceContext.clear();
 		return results;
 	}
 
 	public void afterOperation(boolean success) {
-		if ( ! transactionCoordinator.isTransactionInProgress() ) {
-			transactionCoordinator.afterNonTransactionalQuery( success );
+		if ( ! isTransactionInProgress() ) {
+			jdbcCoordinator.afterTransaction();
 		}
 	}
 
 	@Override
 	public Criteria createCriteria(Class persistentClass, String alias) {
 		errorIfClosed();
 		return new CriteriaImpl( persistentClass.getName(), alias, this );
 	}
 
 	@Override
 	public Criteria createCriteria(String entityName, String alias) {
 		errorIfClosed();
 		return new CriteriaImpl(entityName, alias, this);
 	}
 
 	@Override
 	public Criteria createCriteria(Class persistentClass) {
 		errorIfClosed();
 		return new CriteriaImpl( persistentClass.getName(), this );
 	}
 
 	@Override
 	public Criteria createCriteria(String entityName) {
 		errorIfClosed();
 		return new CriteriaImpl(entityName, this);
 	}
 
 	@Override
 	public ScrollableResults scroll(Criteria criteria, ScrollMode scrollMode) {
 		// TODO: Is this guaranteed to always be CriteriaImpl?
 		CriteriaImpl criteriaImpl = (CriteriaImpl) criteria;
 		
 		errorIfClosed();
 		String entityName = criteriaImpl.getEntityOrClassName();
 		CriteriaLoader loader = new CriteriaLoader(
 				getOuterJoinLoadable( entityName ),
 		        factory,
 		        criteriaImpl,
 		        entityName,
 		        getLoadQueryInfluencers()
 		);
 		return loader.scroll(this, scrollMode);
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public List list(Criteria criteria) throws HibernateException {
 		// TODO: Is this guaranteed to always be CriteriaImpl?
 		CriteriaImpl criteriaImpl = (CriteriaImpl) criteria;
 		
 		errorIfClosed();
 		String[] implementors = factory.getImplementors( criteriaImpl.getEntityOrClassName() );
 		int size = implementors.length;
 
 		CriteriaLoader[] loaders = new CriteriaLoader[size];
 		for( int i=0; i <size; i++ ) {
 			loaders[i] = new CriteriaLoader(
 					getOuterJoinLoadable( implementors[i] ),
 			        factory,
 			        criteriaImpl,
 			        implementors[i],
 			        getLoadQueryInfluencers()
 			);
 		}
 
 
 		List results = Collections.EMPTY_LIST;
 		boolean success = false;
 		try {
 			for( int i=0; i<size; i++ ) {
 				final List currentResults = loaders[i].list(this);
 				currentResults.addAll(results);
 				results = currentResults;
 			}
 			success = true;
 		}
 		finally {
 			afterOperation(success);
 		}
 		temporaryPersistenceContext.clear();
 		return results;
 	}
 
 	private OuterJoinLoadable getOuterJoinLoadable(String entityName) throws MappingException {
 		EntityPersister persister = factory.getEntityPersister(entityName);
 		if ( !(persister instanceof OuterJoinLoadable) ) {
 			throw new MappingException( "class persister is not OuterJoinLoadable: " + entityName );
 		}
 		return ( OuterJoinLoadable ) persister;
 	}
 
 	@Override
 	public List listCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
 	throws HibernateException {
 		errorIfClosed();
 		CustomLoader loader = new CustomLoader( customQuery, getFactory() );
 
 		boolean success = false;
 		List results;
 		try {
 			results = loader.list(this, queryParameters);
 			success = true;
 		}
 		finally {
 			afterOperation(success);
 		}
 		temporaryPersistenceContext.clear();
 		return results;
 	}
 
 	@Override
 	public ScrollableResults scrollCustomQuery(CustomQuery customQuery, QueryParameters queryParameters)
 	throws HibernateException {
 		errorIfClosed();
 		CustomLoader loader = new CustomLoader( customQuery, getFactory() );
 		return loader.scroll( queryParameters, this );
 	}
 
 	@Override
 	public ScrollableResults scroll(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		return plan.performScroll( queryParameters, this );
 	}
 
 	@Override
 	public void afterScrollOperation() {
 		temporaryPersistenceContext.clear();
 	}
 
 	@Override
 	public void flush() {
 	}
 
 	@Override
 	public String getFetchProfile() {
 		return null;
 	}
 
 	@Override
 	public LoadQueryInfluencers getLoadQueryInfluencers() {
 		return LoadQueryInfluencers.NONE;
 	}
 
 	@Override
 	public void setFetchProfile(String name) {
 	}
 
 	@Override
 	public int executeNativeUpdate(NativeSQLQuerySpecification nativeSQLQuerySpecification,
 			QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		queryParameters.validateParameters();
 		NativeSQLQueryPlan plan = getNativeSQLQueryPlan(nativeSQLQuerySpecification);
 
 		boolean success = false;
 		int result = 0;
 		try {
 			result = plan.performExecuteUpdate(queryParameters, this);
 			success = true;
 		} finally {
 			afterOperation(success);
 		}
 		temporaryPersistenceContext.clear();
 		return result;
 	}
+
+	@Override
+	public JdbcSessionContext getJdbcSessionContext() {
+		return this.jdbcSessionContext;
+	}
+
+	@Override
+	public void afterTransactionBegin() {
+
+	}
+
+	@Override
+	public void beforeTransactionCompletion() {
+		flushBeforeTransactionCompletion();
+	}
+
+	@Override
+	public void afterTransactionCompletion(boolean successful) {
+		if ( shouldAutoClose()
+				&& !isClosed() ) {
+			managedClose();
+		}
+	}
+
+	@Override
+	public void flushBeforeTransactionCompletion() {
+		boolean flush = false;
+		try {
+			flush = (
+					!isClosed()
+							&& !isFlushModeNever()
+							&& !JtaStatusHelper.isRollback(
+							factory.getSettings()
+									.getJtaPlatform()
+									.getCurrentStatus()
+					));
+		}
+		catch (SystemException se) {
+			throw new HibernateException( "could not determine transaction status in beforeCompletion()", se );
+		}
+		if ( flush ) {
+			managedFlush();
+		}
+	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/TransactionEnvironmentImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/TransactionEnvironmentImpl.java
deleted file mode 100644
index 1a37103cf0..0000000000
--- a/hibernate-core/src/main/java/org/hibernate/internal/TransactionEnvironmentImpl.java
+++ /dev/null
@@ -1,82 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.internal;
-
-import org.hibernate.engine.jdbc.spi.JdbcServices;
-import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
-import org.hibernate.engine.transaction.spi.TransactionEnvironment;
-import org.hibernate.engine.transaction.spi.TransactionFactory;
-import org.hibernate.service.ServiceRegistry;
-import org.hibernate.stat.spi.StatisticsImplementor;
-
-/**
- * @author Steve Ebersole
- */
-public class TransactionEnvironmentImpl implements TransactionEnvironment {
-    private final SessionFactoryImpl sessionFactory;
-    private final transient StatisticsImplementor statisticsImplementor;
-    private final transient ServiceRegistry serviceRegistry;
-    private final transient JdbcServices jdbcServices;
-    private final transient JtaPlatform jtaPlatform;
-    private final transient TransactionFactory transactionFactory;
-
-    public TransactionEnvironmentImpl(SessionFactoryImpl sessionFactory) {
-        this.sessionFactory = sessionFactory;
-        this.statisticsImplementor = sessionFactory.getStatisticsImplementor();
-        this.serviceRegistry = sessionFactory.getServiceRegistry();
-        this.jdbcServices = serviceRegistry.getService( JdbcServices.class );
-        this.jtaPlatform = serviceRegistry.getService( JtaPlatform.class );
-        this.transactionFactory = serviceRegistry.getService( TransactionFactory.class );
-    }
-
-    @Override
-    public SessionFactoryImplementor getSessionFactory() {
-        return sessionFactory;
-    }
-
-    protected ServiceRegistry serviceRegistry() {
-        return serviceRegistry;
-    }
-
-    @Override
-    public JdbcServices getJdbcServices() {
-        return jdbcServices;
-    }
-
-    @Override
-    public JtaPlatform getJtaPlatform() {
-        return jtaPlatform;
-    }
-
-    @Override
-    public TransactionFactory getTransactionFactory() {
-        return transactionFactory;
-    }
-
-    @Override
-    public StatisticsImplementor getStatisticsImplementor() {
-        return statisticsImplementor;
-    }
-}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/Loader.java b/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
index d1d8ff00e0..05f9e34062 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/Loader.java
@@ -1,2723 +1,2727 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader;
 
 import java.io.Serializable;
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.WrongClassException;
 import org.hibernate.cache.spi.FilterKey;
 import org.hibernate.cache.spi.QueryCache;
 import org.hibernate.cache.spi.QueryKey;
 import org.hibernate.cache.spi.entry.CacheEntry;
 import org.hibernate.cache.spi.entry.ReferenceCacheEntryImpl;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.dialect.pagination.NoopLimitHandler;
 import org.hibernate.engine.internal.CacheHelper;
 import org.hibernate.engine.internal.TwoPhaseLoad;
 import org.hibernate.engine.jdbc.ColumnNameCache;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.EntityUniqueKey;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.SubselectFetch;
 import org.hibernate.engine.spi.TypedValue;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.event.spi.PostLoadEvent;
 import org.hibernate.event.spi.PreLoadEvent;
 import org.hibernate.hql.internal.HolderInstantiator;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.FetchingScrollableResultsImpl;
 import org.hibernate.internal.ScrollableResultsImpl;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.loader.spi.AfterLoadAction;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.UniqueKeyLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.transform.CacheableResultTransformer;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 
 import org.jboss.logging.Logger;
 
 /**
  * Abstract superclass of object loading (and querying) strategies. This class implements
  * useful common functionality that concrete loaders delegate to. It is not intended that this
  * functionality would be directly accessed by client code. (Hence, all methods of this class
  * are declared <tt>protected</tt> or <tt>private</tt>.) This class relies heavily upon the
  * <tt>Loadable</tt> interface, which is the contract between this class and
  * <tt>EntityPersister</tt>s that may be loaded by it.<br>
  * <br>
  * The present implementation is able to load any number of columns of entities and at most
  * one collection role per query.
  *
  * @author Gavin King
  * @see org.hibernate.persister.entity.Loadable
  */
 public abstract class Loader {
 
 	protected static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, Loader.class.getName());
 	protected static final boolean DEBUG_ENABLED = LOG.isDebugEnabled();
 	private final SessionFactoryImplementor factory;
 	private volatile ColumnNameCache columnNameCache;
 
 	private final boolean referenceCachingEnabled;
 
 	public Loader(SessionFactoryImplementor factory) {
 		this.factory = factory;
 		this.referenceCachingEnabled = factory.getSettings().isDirectReferenceCacheEntriesEnabled();
 	}
 
 	/**
 	 * The SQL query string to be called; implemented by all subclasses
 	 *
 	 * @return The sql command this loader should use to get its {@link ResultSet}.
 	 */
 	public abstract String getSQLString();
 
 	/**
 	 * An array of persisters of entity classes contained in each row of results;
 	 * implemented by all subclasses
 	 *
 	 * @return The entity persisters.
 	 */
 	protected abstract Loadable[] getEntityPersisters();
 
 	/**
 	 * An array indicating whether the entities have eager property fetching
 	 * enabled.
 	 *
 	 * @return Eager property fetching indicators.
 	 */
 	protected boolean[] getEntityEagerPropertyFetches() {
 		return null;
 	}
 
 	/**
 	 * An array of indexes of the entity that owns a one-to-one association
 	 * to the entity at the given index (-1 if there is no "owner").  The
 	 * indexes contained here are relative to the result of
 	 * {@link #getEntityPersisters}.
 	 *
 	 * @return The owner indicators (see discussion above).
 	 */
 	protected int[] getOwners() {
 		return null;
 	}
 
 	/**
 	 * An array of the owner types corresponding to the {@link #getOwners()}
 	 * returns.  Indices indicating no owner would be null here.
 	 *
 	 * @return The types for the owners.
 	 */
 	protected EntityType[] getOwnerAssociationTypes() {
 		return null;
 	}
 
 	/**
 	 * An (optional) persister for a collection to be initialized; only
 	 * collection loaders return a non-null value
 	 */
 	protected CollectionPersister[] getCollectionPersisters() {
 		return null;
 	}
 
 	/**
 	 * Get the index of the entity that owns the collection, or -1
 	 * if there is no owner in the query results (ie. in the case of a
 	 * collection initializer) or no collection.
 	 */
 	protected int[] getCollectionOwners() {
 		return null;
 	}
 
 	protected int[][] getCompositeKeyManyToOneTargetIndices() {
 		return null;
 	}
 
 	/**
 	 * What lock options does this load entities with?
 	 *
 	 * @param lockOptions a collection of lock options specified dynamically via the Query interface
 	 */
 	//protected abstract LockOptions[] getLockOptions(Map lockOptions);
 	protected abstract LockMode[] getLockModes(LockOptions lockOptions);
 
 	/**
 	 * Append <tt>FOR UPDATE OF</tt> clause, if necessary. This
 	 * empty superclass implementation merely returns its first
 	 * argument.
 	 */
 	protected String applyLocks(
 			String sql,
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) throws HibernateException {
 		return sql;
 	}
 
 	/**
 	 * Does this query return objects that might be already cached
 	 * by the session, whose lock mode may need upgrading
 	 */
 	protected boolean upgradeLocks() {
 		return false;
 	}
 
 	/**
 	 * Return false is this loader is a batch entity loader
 	 */
 	protected boolean isSingleRowLoader() {
 		return false;
 	}
 
 	/**
 	 * Get the SQL table aliases of entities whose
 	 * associations are subselect-loadable, returning
 	 * null if this loader does not support subselect
 	 * loading
 	 */
 	protected String[] getAliases() {
 		return null;
 	}
 
 	/**
 	 * Modify the SQL, adding lock hints and comments, if necessary
 	 */
 	protected String preprocessSQL(
 			String sql,
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) throws HibernateException {
 		sql = applyLocks( sql, parameters, dialect, afterLoadActions );
 		
 		// Keep this here, rather than moving to Select.  Some Dialects may need the hint to be appended to the very
 		// end or beginning of the finalized SQL statement, so wait until everything is processed.
 		if ( parameters.getQueryHints() != null && parameters.getQueryHints().size() > 0 ) {
 			sql = dialect.getQueryHintString( sql, parameters.getQueryHints() );
 		}
 		
 		return getFactory().getSettings().isCommentsEnabled()
 				? prependComment( sql, parameters )
 				: sql;
 	}
 
 	protected boolean shouldUseFollowOnLocking(
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) {
 		if ( dialect.useFollowOnLocking() ) {
 			// currently only one lock mode is allowed in follow-on locking
 			final LockMode lockMode = determineFollowOnLockMode( parameters.getLockOptions() );
 			final LockOptions lockOptions = new LockOptions( lockMode );
 			if ( lockOptions.getLockMode() != LockMode.UPGRADE_SKIPLOCKED ) {
 				LOG.usingFollowOnLocking();
 				lockOptions.setTimeOut( parameters.getLockOptions().getTimeOut() );
 				lockOptions.setScope( parameters.getLockOptions().getScope() );
 				afterLoadActions.add(
 						new AfterLoadAction() {
 							@Override
 							public void afterLoad(SessionImplementor session, Object entity, Loadable persister) {
 								( (Session) session ).buildLockRequest( lockOptions ).lock( persister.getEntityName(), entity );
 							}
 						}
 				);
 				parameters.setLockOptions( new LockOptions() );
 				return true;
 			}
 		}
 		return false;
 	}
 
 	protected LockMode determineFollowOnLockMode(LockOptions lockOptions) {
 		final LockMode lockModeToUse = lockOptions.findGreatestLockMode();
 
 		if ( lockOptions.hasAliasSpecificLockModes() ) {
 			LOG.aliasSpecificLockingWithFollowOnLocking( lockModeToUse );
 		}
 
 		return lockModeToUse;
 	}
 
 	private String prependComment(String sql, QueryParameters parameters) {
 		String comment = parameters.getComment();
 		if ( comment == null ) {
 			return sql;
 		}
 		else {
 			return new StringBuilder( comment.length() + sql.length() + 5 )
 					.append( "/* " )
 					.append( comment )
 					.append( " */ " )
 					.append( sql )
 					.toString();
 		}
 	}
 
 	/**
 	 * Execute an SQL query and attempt to instantiate instances of the class mapped by the given
 	 * persister from each row of the <tt>ResultSet</tt>. If an object is supplied, will attempt to
 	 * initialize that object. If a collection is supplied, attempt to initialize that collection.
 	 */
 	public List doQueryAndInitializeNonLazyCollections(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies) throws HibernateException, SQLException {
 		return doQueryAndInitializeNonLazyCollections(
 				session,
 				queryParameters,
 				returnProxies,
 				null
 		);
 	}
 
 	public List doQueryAndInitializeNonLazyCollections(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final ResultTransformer forcedResultTransformer)
 			throws HibernateException, SQLException {
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		boolean defaultReadOnlyOrig = persistenceContext.isDefaultReadOnly();
 		if ( queryParameters.isReadOnlyInitialized() ) {
 			// The read-only/modifiable mode for the query was explicitly set.
 			// Temporarily set the default read-only/modifiable setting to the query's setting.
 			persistenceContext.setDefaultReadOnly( queryParameters.isReadOnly() );
 		}
 		else {
 			// The read-only/modifiable setting for the query was not initialized.
 			// Use the default read-only/modifiable from the persistence context instead.
 			queryParameters.setReadOnly( persistenceContext.isDefaultReadOnly() );
 		}
 		persistenceContext.beforeLoad();
 		List result;
 		try {
 			try {
 				result = doQuery( session, queryParameters, returnProxies, forcedResultTransformer );
 			}
 			finally {
 				persistenceContext.afterLoad();
 			}
 			persistenceContext.initializeNonLazyCollections();
 		}
 		finally {
 			// Restore the original default
 			persistenceContext.setDefaultReadOnly( defaultReadOnlyOrig );
 		}
 		return result;
 	}
 
 	/**
 	 * Loads a single row from the result set.  This is the processing used from the
 	 * ScrollableResults where no collection fetches were encountered.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
 	 * @return The loaded "row".
 	 * @throws HibernateException
 	 */
 	public Object loadSingleRow(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies) throws HibernateException {
 
 		final int entitySpan = getEntityPersisters().length;
 		final List hydratedObjects = entitySpan == 0 ?
 				null : new ArrayList( entitySpan );
 
 		final Object result;
 		try {
 			result = getRowFromResultSet(
 					resultSet,
 					session,
 					queryParameters,
 					getLockModes( queryParameters.getLockOptions() ),
 					null,
 					hydratedObjects,
 					new EntityKey[entitySpan],
 					returnProxies
 				);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not read next row of results",
 					getSQLString()
 				);
 		}
 
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				resultSet,
 				session,
 				queryParameters.isReadOnly( session )
 		);
 		session.getPersistenceContext().initializeNonLazyCollections();
 		return result;
 	}
 
 	private Object sequentialLoad(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final EntityKey keyToRead) throws HibernateException {
 
 		final int entitySpan = getEntityPersisters().length;
 		final List hydratedObjects = entitySpan == 0 ?
 				null : new ArrayList( entitySpan );
 
 		Object result = null;
 		final EntityKey[] loadedKeys = new EntityKey[entitySpan];
 
 		try {
 			do {
 				Object loaded = getRowFromResultSet(
 						resultSet,
 						session,
 						queryParameters,
 						getLockModes( queryParameters.getLockOptions() ),
 						null,
 						hydratedObjects,
 						loadedKeys,
 						returnProxies
 				);
 				if ( ! keyToRead.equals( loadedKeys[0] ) ) {
 					throw new AssertionFailure(
 							String.format(
 									"Unexpected key read for row; expected [%s]; actual [%s]",
 									keyToRead,
 									loadedKeys[0] )
 					);
 				}
 				if ( result == null ) {
 					result = loaded;
 				}
 			}
 			while ( resultSet.next() &&
 					isCurrentRowForSameEntity( keyToRead, 0, resultSet, session ) );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not doAfterTransactionCompletion sequential read of results (forward)",
 					getSQLString()
 				);
 		}
 
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				resultSet,
 				session,
 				queryParameters.isReadOnly( session )
 		);
 		session.getPersistenceContext().initializeNonLazyCollections();
 		return result;
 	}
 
 	private boolean isCurrentRowForSameEntity(
 			final EntityKey keyToRead,
 			final int persisterIndex,
 			final ResultSet resultSet,
 			final SessionImplementor session) throws SQLException {
 		EntityKey currentRowKey = getKeyFromResultSet(
 				persisterIndex, getEntityPersisters()[persisterIndex], null, resultSet, session
 		);
 		return keyToRead.equals( currentRowKey );
 	}
 
 	/**
 	 * Loads a single logical row from the result set moving forward.  This is the
 	 * processing used from the ScrollableResults where there were collection fetches
 	 * encountered; thus a single logical row may have multiple rows in the underlying
 	 * result set.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
 	 * @return The loaded "row".
 	 * @throws HibernateException
 	 */
 	public Object loadSequentialRowsForward(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies) throws HibernateException {
 
 		// note that for sequential scrolling, we make the assumption that
 		// the first persister element is the "root entity"
 
 		try {
 			if ( resultSet.isAfterLast() ) {
 				// don't even bother trying to read further
 				return null;
 			}
 
 			if ( resultSet.isBeforeFirst() ) {
 				resultSet.next();
 			}
 
 			// We call getKeyFromResultSet() here so that we can know the
 			// key value upon which to perform the breaking logic.  However,
 			// it is also then called from getRowFromResultSet() which is certainly
 			// not the most efficient.  But the call here is needed, and there
 			// currently is no other way without refactoring of the doQuery()/getRowFromResultSet()
 			// methods
 			final EntityKey currentKey = getKeyFromResultSet(
 					0,
 					getEntityPersisters()[0],
 					null,
 					resultSet,
 					session
 				);
 
 			return sequentialLoad( resultSet, session, queryParameters, returnProxies, currentKey );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not perform sequential read of results (forward)",
 					getSQLString()
 				);
 		}
 	}
 
 	/**
 	 * Loads a single logical row from the result set moving forward.  This is the
 	 * processing used from the ScrollableResults where there were collection fetches
 	 * encountered; thus a single logical row may have multiple rows in the underlying
 	 * result set.
 	 *
 	 * @param resultSet The result set from which to do the load.
 	 * @param session The session from which the request originated.
 	 * @param queryParameters The query parameters specified by the user.
 	 * @param returnProxies Should proxies be generated
 	 * @return The loaded "row".
 	 * @throws HibernateException
 	 */
 	public Object loadSequentialRowsReverse(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final boolean isLogicallyAfterLast) throws HibernateException {
 
 		// note that for sequential scrolling, we make the assumption that
 		// the first persister element is the "root entity"
 
 		try {
 			if ( resultSet.isFirst() ) {
 				// don't even bother trying to read any further
 				return null;
 			}
 
 			EntityKey keyToRead = null;
 			// This check is needed since processing leaves the cursor
 			// after the last physical row for the current logical row;
 			// thus if we are after the last physical row, this might be
 			// caused by either:
 			//      1) scrolling to the last logical row
 			//      2) scrolling past the last logical row
 			// In the latter scenario, the previous logical row
 			// really is the last logical row.
 			//
 			// In all other cases, we should process back two
 			// logical records (the current logic row, plus the
 			// previous logical row).
 			if ( resultSet.isAfterLast() && isLogicallyAfterLast ) {
 				// position cursor to the last row
 				resultSet.last();
 				keyToRead = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
 					);
 			}
 			else {
 				// Since the result set cursor is always left at the first
 				// physical row after the "last processed", we need to jump
 				// back one position to get the key value we are interested
 				// in skipping
 				resultSet.previous();
 
 				// sequentially read the result set in reverse until we recognize
 				// a change in the key value.  At that point, we are pointed at
 				// the last physical sequential row for the logical row in which
 				// we are interested in processing
 				boolean firstPass = true;
 				final EntityKey lastKey = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
 					);
 				while ( resultSet.previous() ) {
 					EntityKey checkKey = getKeyFromResultSet(
 							0,
 							getEntityPersisters()[0],
 							null,
 							resultSet,
 							session
 						);
 
 					if ( firstPass ) {
 						firstPass = false;
 						keyToRead = checkKey;
 					}
 
 					if ( !lastKey.equals( checkKey ) ) {
 						break;
 					}
 				}
 
 			}
 
 			// Read backwards until we read past the first physical sequential
 			// row with the key we are interested in loading
 			while ( resultSet.previous() ) {
 				EntityKey checkKey = getKeyFromResultSet(
 						0,
 						getEntityPersisters()[0],
 						null,
 						resultSet,
 						session
 					);
 
 				if ( !keyToRead.equals( checkKey ) ) {
 					break;
 				}
 			}
 
 			// Finally, read ahead one row to position result set cursor
 			// at the first physical row we are interested in loading
 			resultSet.next();
 
 			// and doAfterTransactionCompletion the load
 			return sequentialLoad( resultSet, session, queryParameters, returnProxies, keyToRead );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not doAfterTransactionCompletion sequential read of results (forward)",
 					getSQLString()
 				);
 		}
 	}
 
 	private static EntityKey getOptionalObjectKey(QueryParameters queryParameters, SessionImplementor session) {
 		final Object optionalObject = queryParameters.getOptionalObject();
 		final Serializable optionalId = queryParameters.getOptionalId();
 		final String optionalEntityName = queryParameters.getOptionalEntityName();
 
 		if ( optionalObject != null && optionalEntityName != null ) {
 			return session.generateEntityKey( optionalId, session.getEntityPersister( optionalEntityName, optionalObject ) );
 		}
 		else {
 			return null;
 		}
 
 	}
 
 	private Object getRowFromResultSet(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final LockMode[] lockModesArray,
 			final EntityKey optionalObjectKey,
 			final List hydratedObjects,
 			final EntityKey[] keys,
 			boolean returnProxies) throws SQLException, HibernateException {
 		return getRowFromResultSet(
 				resultSet,
 				session,
 				queryParameters,
 				lockModesArray,
 				optionalObjectKey,
 				hydratedObjects,
 				keys,
 				returnProxies,
 				null
 		);
 	}
 
 	private Object getRowFromResultSet(
 			final ResultSet resultSet,
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final LockMode[] lockModesArray,
 			final EntityKey optionalObjectKey,
 			final List hydratedObjects,
 			final EntityKey[] keys,
 			boolean returnProxies,
 			ResultTransformer forcedResultTransformer) throws SQLException, HibernateException {
 		final Loadable[] persisters = getEntityPersisters();
 		final int entitySpan = persisters.length;
 		extractKeysFromResultSet( persisters, queryParameters, resultSet, session, keys, lockModesArray, hydratedObjects );
 
 		registerNonExists( keys, persisters, session );
 
 		// this call is side-effecty
 		Object[] row = getRow(
 				resultSet,
 				persisters,
 				keys,
 				queryParameters.getOptionalObject(),
 				optionalObjectKey,
 				lockModesArray,
 				hydratedObjects,
 				session
 		);
 
 		readCollectionElements( row, resultSet, session );
 
 		if ( returnProxies ) {
 			// now get an existing proxy for each row element (if there is one)
 			for ( int i = 0; i < entitySpan; i++ ) {
 				Object entity = row[i];
 				Object proxy = session.getPersistenceContext().proxyFor( persisters[i], keys[i], entity );
 				if ( entity != proxy ) {
 					// force the proxy to resolve itself
 					( (HibernateProxy) proxy ).getHibernateLazyInitializer().setImplementation(entity);
 					row[i] = proxy;
 				}
 			}
 		}
 
 		applyPostLoadLocks( row, lockModesArray, session );
 
 		return forcedResultTransformer == null
 				? getResultColumnOrRow( row, queryParameters.getResultTransformer(), resultSet, session )
 				: forcedResultTransformer.transformTuple( getResultRow( row, resultSet, session ), getResultRowAliases() )
 		;
 	}
 
 	protected void extractKeysFromResultSet(
 			Loadable[] persisters,
 			QueryParameters queryParameters,
 			ResultSet resultSet,
 			SessionImplementor session,
 			EntityKey[] keys,
 			LockMode[] lockModes,
 			List hydratedObjects) throws SQLException {
 		final int entitySpan = persisters.length;
 
 		final int numberOfPersistersToProcess;
 		final Serializable optionalId = queryParameters.getOptionalId();
 		if ( isSingleRowLoader() && optionalId != null ) {
 			keys[ entitySpan - 1 ] = session.generateEntityKey( optionalId, persisters[ entitySpan - 1 ] );
 			// skip the last persister below...
 			numberOfPersistersToProcess = entitySpan - 1;
 		}
 		else {
 			numberOfPersistersToProcess = entitySpan;
 		}
 
 		final Object[] hydratedKeyState = new Object[numberOfPersistersToProcess];
 
 		for ( int i = 0; i < numberOfPersistersToProcess; i++ ) {
 			final Type idType = persisters[i].getIdentifierType();
 			hydratedKeyState[i] = idType.hydrate( resultSet, getEntityAliases()[i].getSuffixedKeyAliases(), session, null );
 		}
 
 		for ( int i = 0; i < numberOfPersistersToProcess; i++ ) {
 			final Type idType = persisters[i].getIdentifierType();
 			if ( idType.isComponentType() && getCompositeKeyManyToOneTargetIndices() != null ) {
 				// we may need to force resolve any key-many-to-one(s)
 				int[] keyManyToOneTargetIndices = getCompositeKeyManyToOneTargetIndices()[i];
 				// todo : better solution is to order the index processing based on target indices
 				//		that would account for multiple levels whereas this scheme does not
 				if ( keyManyToOneTargetIndices != null ) {
 					for ( int targetIndex : keyManyToOneTargetIndices ) {
 						if ( targetIndex < numberOfPersistersToProcess ) {
 							final Type targetIdType = persisters[targetIndex].getIdentifierType();
 							final Serializable targetId = (Serializable) targetIdType.resolve(
 									hydratedKeyState[targetIndex],
 									session,
 									null
 							);
 							// todo : need a way to signal that this key is resolved and its data resolved
 							keys[targetIndex] = session.generateEntityKey( targetId, persisters[targetIndex] );
 						}
 
 						// this part copied from #getRow, this section could be refactored out
 						Object object = session.getEntityUsingInterceptor( keys[targetIndex] );
 						if ( object != null ) {
 							//its already loaded so don't need to hydrate it
 							instanceAlreadyLoaded(
 									resultSet,
 									targetIndex,
 									persisters[targetIndex],
 									keys[targetIndex],
 									object,
 									lockModes[targetIndex],
 									session
 							);
 						}
 						else {
 							instanceNotYetLoaded(
 									resultSet,
 									targetIndex,
 									persisters[targetIndex],
 									getEntityAliases()[targetIndex].getRowIdAlias(),
 									keys[targetIndex],
 									lockModes[targetIndex],
 									getOptionalObjectKey( queryParameters, session ),
 									queryParameters.getOptionalObject(),
 									hydratedObjects,
 									session
 							);
 						}
 					}
 				}
 			}
 			final Serializable resolvedId = (Serializable) idType.resolve( hydratedKeyState[i], session, null );
 			keys[i] = resolvedId == null ? null : session.generateEntityKey( resolvedId, persisters[i] );
 		}
 	}
 
 	protected void applyPostLoadLocks(Object[] row, LockMode[] lockModesArray, SessionImplementor session) {
 	}
 
 	/**
 	 * Read any collection elements contained in a single row of the result set
 	 */
 	private void readCollectionElements(Object[] row, ResultSet resultSet, SessionImplementor session)
 			throws SQLException, HibernateException {
 
 		//TODO: make this handle multiple collection roles!
 
 		final CollectionPersister[] collectionPersisters = getCollectionPersisters();
 		if ( collectionPersisters != null ) {
 
 			final CollectionAliases[] descriptors = getCollectionAliases();
 			final int[] collectionOwners = getCollectionOwners();
 
 			for ( int i=0; i<collectionPersisters.length; i++ ) {
 
 				final boolean hasCollectionOwners = collectionOwners !=null &&
 						collectionOwners[i] > -1;
 				//true if this is a query and we are loading multiple instances of the same collection role
 				//otherwise this is a CollectionInitializer and we are loading up a single collection or batch
 
 				final Object owner = hasCollectionOwners ?
 						row[ collectionOwners[i] ] :
 						null; //if null, owner will be retrieved from session
 
 				final CollectionPersister collectionPersister = collectionPersisters[i];
 				final Serializable key;
 				if ( owner == null ) {
 					key = null;
 				}
 				else {
 					key = collectionPersister.getCollectionType().getKeyOfOwner( owner, session );
 					//TODO: old version did not require hashmap lookup:
 					//keys[collectionOwner].getIdentifier()
 				}
 
 				readCollectionElement(
 						owner,
 						key,
 						collectionPersister,
 						descriptors[i],
 						resultSet,
 						session
 					);
 
 			}
 
 		}
 	}
 
 	private List doQuery(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final boolean returnProxies,
 			final ResultTransformer forcedResultTransformer) throws SQLException, HibernateException {
 
 		final RowSelection selection = queryParameters.getRowSelection();
 		final int maxRows = LimitHelper.hasMaxRows( selection ) ?
 				selection.getMaxRows() :
 				Integer.MAX_VALUE;
 
 		final List<AfterLoadAction> afterLoadActions = new ArrayList<AfterLoadAction>();
 
 		final SqlStatementWrapper wrapper = executeQueryStatement( queryParameters, false, afterLoadActions, session );
 		final ResultSet rs = wrapper.getResultSet();
 		final Statement st = wrapper.getStatement();
 
 // would be great to move all this below here into another method that could also be used
 // from the new scrolling stuff.
 //
 // Would need to change the way the max-row stuff is handled (i.e. behind an interface) so
 // that I could do the control breaking at the means to know when to stop
 
 		try {
 			return processResultSet( rs, queryParameters, session, returnProxies, forcedResultTransformer, maxRows, afterLoadActions );
 		}
 		finally {
-			session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+			session.getJdbcCoordinator().getResourceRegistry().release( st );
+			session.getJdbcCoordinator().afterStatementExecution();
 		}
 
 	}
 
 	protected List processResultSet(
 			ResultSet rs,
 			QueryParameters queryParameters,
 			SessionImplementor session,
 			boolean returnProxies,
 			ResultTransformer forcedResultTransformer,
 			int maxRows,
 			List<AfterLoadAction> afterLoadActions) throws SQLException {
 		final int entitySpan = getEntityPersisters().length;
 		final EntityKey optionalObjectKey = getOptionalObjectKey( queryParameters, session );
 		final LockMode[] lockModesArray = getLockModes( queryParameters.getLockOptions() );
 		final boolean createSubselects = isSubselectLoadingEnabled();
 		final List subselectResultKeys = createSubselects ? new ArrayList() : null;
 		final ArrayList hydratedObjects = entitySpan == 0 ? null : new ArrayList( entitySpan * 10 );
 		final List results = new ArrayList();
 
 		handleEmptyCollections( queryParameters.getCollectionKeys(), rs, session );
 		EntityKey[] keys = new EntityKey[entitySpan]; //we can reuse it for each row
 		LOG.trace( "Processing result set" );
 		int count;
 
 		for ( count = 0; count < maxRows && rs.next(); count++ ) {
 			if ( DEBUG_ENABLED )
 				LOG.debugf( "Result set row: %s", count );
 			Object result = getRowFromResultSet(
 					rs,
 					session,
 					queryParameters,
 					lockModesArray,
 					optionalObjectKey,
 					hydratedObjects,
 					keys,
 					returnProxies,
 					forcedResultTransformer
 			);
 			results.add( result );
 			if ( createSubselects ) {
 				subselectResultKeys.add(keys);
 				keys = new EntityKey[entitySpan]; //can't reuse in this case
 			}
 		}
 
 		LOG.tracev( "Done processing result set ({0} rows)", count );
 
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				rs,
 				session,
 				queryParameters.isReadOnly( session ),
 				afterLoadActions
 		);
 		if ( createSubselects ) {
 			createSubselects( subselectResultKeys, queryParameters, session );
 		}
 		return results;
 	}
 
 	protected boolean isSubselectLoadingEnabled() {
 		return false;
 	}
 
 	protected boolean hasSubselectLoadableCollections() {
 		final Loadable[] loadables = getEntityPersisters();
 		for ( Loadable loadable : loadables ) {
 			if ( loadable.hasSubselectLoadableCollections() ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	private static Set[] transpose( List keys ) {
 		Set[] result = new Set[ ( ( EntityKey[] ) keys.get(0) ).length ];
 		for ( int j=0; j<result.length; j++ ) {
 			result[j] = new HashSet( keys.size() );
 			for ( Object key : keys ) {
 				result[j].add( ( (EntityKey[]) key )[j] );
 			}
 		}
 		return result;
 	}
 
 	private void createSubselects(List keys, QueryParameters queryParameters, SessionImplementor session) {
 		if ( keys.size() > 1 ) { //if we only returned one entity, query by key is more efficient
 
 			Set[] keySets = transpose(keys);
 
 			Map namedParameterLocMap = buildNamedParameterLocMap( queryParameters );
 
 			final Loadable[] loadables = getEntityPersisters();
 			final String[] aliases = getAliases();
 			final Iterator iter = keys.iterator();
 			while ( iter.hasNext() ) {
 
 				final EntityKey[] rowKeys = (EntityKey[]) iter.next();
 				for ( int i=0; i<rowKeys.length; i++ ) {
 
 					if ( rowKeys[i]!=null && loadables[i].hasSubselectLoadableCollections() ) {
 
 						SubselectFetch subselectFetch = new SubselectFetch(
 								//getSQLString(),
 								aliases[i],
 								loadables[i],
 								queryParameters,
 								keySets[i],
 								namedParameterLocMap
 							);
 
 						session.getPersistenceContext()
 								.getBatchFetchQueue()
 								.addSubselect( rowKeys[i], subselectFetch );
 					}
 
 				}
 
 			}
 		}
 	}
 
 	private Map buildNamedParameterLocMap(QueryParameters queryParameters) {
 		if ( queryParameters.getNamedParameters()!=null ) {
 			final Map namedParameterLocMap = new HashMap();
 			for(String name : queryParameters.getNamedParameters().keySet()){
 				namedParameterLocMap.put(
 						name,
 						getNamedParameterLocs(name)
 				);
 			}
 			return namedParameterLocMap;
 		}
 		else {
 			return null;
 		}
 	}
 
 	private void initializeEntitiesAndCollections(
 			final List hydratedObjects,
 			final Object resultSetId,
 			final SessionImplementor session,
 			final boolean readOnly) throws HibernateException {
 		initializeEntitiesAndCollections(
 				hydratedObjects,
 				resultSetId,
 				session,
 				readOnly,
 				Collections.<AfterLoadAction>emptyList()
 		);
 	}
 
 	private void initializeEntitiesAndCollections(
 			final List hydratedObjects,
 			final Object resultSetId,
 			final SessionImplementor session,
 			final boolean readOnly,
 			List<AfterLoadAction> afterLoadActions) throws HibernateException {
 
 		final CollectionPersister[] collectionPersisters = getCollectionPersisters();
 		if ( collectionPersisters != null ) {
 			for ( int i=0; i<collectionPersisters.length; i++ ) {
 				if ( collectionPersisters[i].isArray() ) {
 					//for arrays, we should end the collection load before resolving
 					//the entities, since the actual array instances are not instantiated
 					//during loading
 					//TODO: or we could do this polymorphically, and have two
 					//      different operations implemented differently for arrays
 					endCollectionLoad( resultSetId, session, collectionPersisters[i] );
 				}
 			}
 		}
 
 		//important: reuse the same event instances for performance!
 		final PreLoadEvent pre;
 		final PostLoadEvent post;
 		if ( session.isEventSource() ) {
 			pre = new PreLoadEvent( (EventSource) session );
 			post = new PostLoadEvent( (EventSource) session );
 		}
 		else {
 			pre = null;
 			post = null;
 		}
 
 		if ( hydratedObjects!=null ) {
 			int hydratedObjectsSize = hydratedObjects.size();
 			LOG.tracev( "Total objects hydrated: {0}", hydratedObjectsSize );
 			for ( int i = 0; i < hydratedObjectsSize; i++ ) {
 				TwoPhaseLoad.initializeEntity( hydratedObjects.get(i), readOnly, session, pre );
 			}
 		}
 
 		if ( collectionPersisters != null ) {
 			for ( int i=0; i<collectionPersisters.length; i++ ) {
 				if ( !collectionPersisters[i].isArray() ) {
 					//for sets, we should end the collection load after resolving
 					//the entities, since we might call hashCode() on the elements
 					//TODO: or we could do this polymorphically, and have two
 					//      different operations implemented differently for arrays
 					endCollectionLoad( resultSetId, session, collectionPersisters[i] );
 				}
 			}
 		}
 		
 		// Until this entire method is refactored w/ polymorphism, postLoad was
 		// split off from initializeEntity.  It *must* occur after
 		// endCollectionLoad to ensure the collection is in the
 		// persistence context.
 		if ( hydratedObjects != null ) {
 			for ( Object hydratedObject : hydratedObjects ) {
 				TwoPhaseLoad.postLoad( hydratedObject, session, post );
 				if ( afterLoadActions != null ) {
 					for ( AfterLoadAction afterLoadAction : afterLoadActions ) {
 						final EntityEntry entityEntry = session.getPersistenceContext().getEntry( hydratedObject );
 						if ( entityEntry == null ) {
 							// big problem
 							throw new HibernateException( "Could not locate EntityEntry immediately after two-phase load" );
 						}
 						afterLoadAction.afterLoad( session, hydratedObject, (Loadable) entityEntry.getPersister() );
 					}
 				}
 			}
 		}
 	}
 
 	private void endCollectionLoad(
 			final Object resultSetId,
 			final SessionImplementor session,
 			final CollectionPersister collectionPersister) {
 		//this is a query and we are loading multiple instances of the same collection role
 		session.getPersistenceContext()
 				.getLoadContexts()
 				.getCollectionLoadContext( ( ResultSet ) resultSetId )
 				.endLoadingCollections( collectionPersister );
 	}
 
 	/**
 	 * Determine the actual ResultTransformer that will be used to
 	 * transform query results.
 	 *
 	 * @param resultTransformer the specified result transformer
 	 * @return the actual result transformer
 	 */
 	protected ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer) {
 		return resultTransformer;
 	}
 
 	protected List getResultList(List results, ResultTransformer resultTransformer) throws QueryException {
 		return results;
 	}
 
 	/**
 	 * Are rows transformed immediately after being read from the ResultSet?
 	 * @return true, if getResultColumnOrRow() transforms the results; false, otherwise
 	 */
 	protected boolean areResultSetRowsTransformedImmediately() {
 		return false;
 	}
 
 	/**
 	 * Returns the aliases that corresponding to a result row.
 	 * @return Returns the aliases that corresponding to a result row.
 	 */
 	protected String[] getResultRowAliases() {
 		 return null;
 	}
 
 	/**
 	 * Get the actual object that is returned in the user-visible result list.
 	 * This empty implementation merely returns its first argument. This is
 	 * overridden by some subclasses.
 	 */
 	protected Object getResultColumnOrRow(
 			Object[] row,
 			ResultTransformer transformer,
 			ResultSet rs,
 			SessionImplementor session) throws SQLException, HibernateException {
 		return row;
 	}
 
 	protected boolean[] includeInResultRow() {
 		return null;
 	}
 
 	protected Object[] getResultRow(
 			Object[] row,
 			ResultSet rs,
 			SessionImplementor session) throws SQLException, HibernateException {
 		return row;
 	}
 
 	/**
 	 * For missing objects associated by one-to-one with another object in the
 	 * result set, register the fact that the the object is missing with the
 	 * session.
 	 */
 	private void registerNonExists(
 			final EntityKey[] keys,
 			final Loadable[] persisters,
 			final SessionImplementor session) {
 
 		final int[] owners = getOwners();
 		if ( owners != null ) {
 
 			EntityType[] ownerAssociationTypes = getOwnerAssociationTypes();
 			for ( int i = 0; i < keys.length; i++ ) {
 
 				int owner = owners[i];
 				if ( owner > -1 ) {
 					EntityKey ownerKey = keys[owner];
 					if ( keys[i] == null && ownerKey != null ) {
 
 						final PersistenceContext persistenceContext = session.getPersistenceContext();
 
 						/*final boolean isPrimaryKey;
 						final boolean isSpecialOneToOne;
 						if ( ownerAssociationTypes == null || ownerAssociationTypes[i] == null ) {
 							isPrimaryKey = true;
 							isSpecialOneToOne = false;
 						}
 						else {
 							isPrimaryKey = ownerAssociationTypes[i].getRHSUniqueKeyPropertyName()==null;
 							isSpecialOneToOne = ownerAssociationTypes[i].getLHSPropertyName()!=null;
 						}*/
 
 						//TODO: can we *always* use the "null property" approach for everything?
 						/*if ( isPrimaryKey && !isSpecialOneToOne ) {
 							persistenceContext.addNonExistantEntityKey(
 									new EntityKey( ownerKey.getIdentifier(), persisters[i], session.getEntityMode() )
 							);
 						}
 						else if ( isSpecialOneToOne ) {*/
 						boolean isOneToOneAssociation = ownerAssociationTypes!=null &&
 								ownerAssociationTypes[i]!=null &&
 								ownerAssociationTypes[i].isOneToOne();
 						if ( isOneToOneAssociation ) {
 							persistenceContext.addNullProperty( ownerKey,
 									ownerAssociationTypes[i].getPropertyName() );
 						}
 						/*}
 						else {
 							persistenceContext.addNonExistantEntityUniqueKey( new EntityUniqueKey(
 									persisters[i].getEntityName(),
 									ownerAssociationTypes[i].getRHSUniqueKeyPropertyName(),
 									ownerKey.getIdentifier(),
 									persisters[owner].getIdentifierType(),
 									session.getEntityMode()
 							) );
 						}*/
 					}
 				}
 			}
 		}
 	}
 
 	/**
 	 * Read one collection element from the current row of the JDBC result set
 	 */
 	private void readCollectionElement(
 			final Object optionalOwner,
 			final Serializable optionalKey,
 			final CollectionPersister persister,
 			final CollectionAliases descriptor,
 			final ResultSet rs,
 			final SessionImplementor session)
 	throws HibernateException, SQLException {
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 
 		final Serializable collectionRowKey = (Serializable) persister.readKey(
 				rs,
 				descriptor.getSuffixedKeyAliases(),
 				session
 			);
 
 		if ( collectionRowKey != null ) {
 			// we found a collection element in the result set
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Found row of collection: %s",
 						MessageHelper.collectionInfoString( persister, collectionRowKey, getFactory() ) );
 			}
 
 			Object owner = optionalOwner;
 			if ( owner == null ) {
 				owner = persistenceContext.getCollectionOwner( collectionRowKey, persister );
 				if ( owner == null ) {
 					//TODO: This is assertion is disabled because there is a bug that means the
 					//	  original owner of a transient, uninitialized collection is not known
 					//	  if the collection is re-referenced by a different object associated
 					//	  with the current Session
 					//throw new AssertionFailure("bug loading unowned collection");
 				}
 			}
 
 			PersistentCollection rowCollection = persistenceContext.getLoadContexts()
 					.getCollectionLoadContext( rs )
 					.getLoadingCollection( persister, collectionRowKey );
 
 			if ( rowCollection != null ) {
 				rowCollection.readFrom( rs, persister, descriptor, owner );
 			}
 
 		}
 		else if ( optionalKey != null ) {
 			// we did not find a collection element in the result set, so we
 			// ensure that a collection is created with the owner's identifier,
 			// since what we have is an empty collection
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Result set contains (possibly empty) collection: %s",
 						MessageHelper.collectionInfoString( persister, optionalKey, getFactory() ) );
 			}
 
 			persistenceContext.getLoadContexts()
 					.getCollectionLoadContext( rs )
 					.getLoadingCollection( persister, optionalKey ); // handle empty collection
 
 		}
 
 		// else no collection element, but also no owner
 
 	}
 
 	/**
 	 * If this is a collection initializer, we need to tell the session that a collection
 	 * is being initialized, to account for the possibility of the collection having
 	 * no elements (hence no rows in the result set).
 	 */
 	private void handleEmptyCollections(
 			final Serializable[] keys,
 			final Object resultSetId,
 			final SessionImplementor session) {
 
 		if ( keys != null ) {
 			final boolean debugEnabled = LOG.isDebugEnabled();
 			// this is a collection initializer, so we must create a collection
 			// for each of the passed-in keys, to account for the possibility
 			// that the collection is empty and has no rows in the result set
 			CollectionPersister[] collectionPersisters = getCollectionPersisters();
 			for ( int j=0; j<collectionPersisters.length; j++ ) {
 				for ( int i = 0; i < keys.length; i++ ) {
 					//handle empty collections
 
 					if ( debugEnabled ) {
 						LOG.debugf( "Result set contains (possibly empty) collection: %s",
 								MessageHelper.collectionInfoString( collectionPersisters[j], keys[i], getFactory() ) );
 					}
 
 					session.getPersistenceContext()
 							.getLoadContexts()
 							.getCollectionLoadContext( ( ResultSet ) resultSetId )
 							.getLoadingCollection( collectionPersisters[j], keys[i] );
 				}
 			}
 		}
 
 		// else this is not a collection initializer (and empty collections will
 		// be detected by looking for the owner's identifier in the result set)
 	}
 
 	/**
 	 * Read a row of <tt>Key</tt>s from the <tt>ResultSet</tt> into the given array.
 	 * Warning: this method is side-effecty.
 	 * <p/>
 	 * If an <tt>id</tt> is given, don't bother going to the <tt>ResultSet</tt>.
 	 */
 	private EntityKey getKeyFromResultSet(
 			final int i,
 			final Loadable persister,
 			final Serializable id,
 			final ResultSet rs,
 			final SessionImplementor session) throws HibernateException, SQLException {
 
 		Serializable resultId;
 
 		// if we know there is exactly 1 row, we can skip.
 		// it would be great if we could _always_ skip this;
 		// it is a problem for <key-many-to-one>
 
 		if ( isSingleRowLoader() && id != null ) {
 			resultId = id;
 		}
 		else {
 
 			Type idType = persister.getIdentifierType();
 			resultId = (Serializable) idType.nullSafeGet(
 					rs,
 					getEntityAliases()[i].getSuffixedKeyAliases(),
 					session,
 					null //problematic for <key-many-to-one>!
 				);
 
 			final boolean idIsResultId = id != null &&
 					resultId != null &&
 					idType.isEqual( id, resultId, factory );
 
 			if ( idIsResultId ) resultId = id; //use the id passed in
 		}
 
 		return resultId == null ? null : session.generateEntityKey( resultId, persister );
 	}
 
 	/**
 	 * Check the version of the object in the <tt>ResultSet</tt> against
 	 * the object version in the session cache, throwing an exception
 	 * if the version numbers are different
 	 */
 	private void checkVersion(
 			final int i,
 			final Loadable persister,
 			final Serializable id,
 			final Object entity,
 			final ResultSet rs,
 			final SessionImplementor session)
 	throws HibernateException, SQLException {
 
 		Object version = session.getPersistenceContext().getEntry( entity ).getVersion();
 
 		if ( version != null ) { //null version means the object is in the process of being loaded somewhere else in the ResultSet
 			VersionType versionType = persister.getVersionType();
 			Object currentVersion = versionType.nullSafeGet(
 					rs,
 					getEntityAliases()[i].getSuffixedVersionAliases(),
 					session,
 					null
 				);
 			if ( !versionType.isEqual(version, currentVersion) ) {
 				if ( session.getFactory().getStatistics().isStatisticsEnabled() ) {
 					session.getFactory().getStatisticsImplementor()
 							.optimisticFailure( persister.getEntityName() );
 				}
 				throw new StaleObjectStateException( persister.getEntityName(), id );
 			}
 		}
 
 	}
 
 	/**
 	 * Resolve any IDs for currently loaded objects, duplications within the
 	 * <tt>ResultSet</tt>, etc. Instantiate empty objects to be initialized from the
 	 * <tt>ResultSet</tt>. Return an array of objects (a row of results) and an
 	 * array of booleans (by side-effect) that determine whether the corresponding
 	 * object should be initialized.
 	 */
 	private Object[] getRow(
 			final ResultSet rs,
 			final Loadable[] persisters,
 			final EntityKey[] keys,
 			final Object optionalObject,
 			final EntityKey optionalObjectKey,
 			final LockMode[] lockModes,
 			final List hydratedObjects,
 			final SessionImplementor session)
 	throws HibernateException, SQLException {
 
 		final int cols = persisters.length;
 		final EntityAliases[] descriptors = getEntityAliases();
 
 		if ( LOG.isDebugEnabled() ) LOG.debugf( "Result row: %s", StringHelper.toString( keys ) );
 
 		final Object[] rowResults = new Object[cols];
 
 		for ( int i = 0; i < cols; i++ ) {
 
 			Object object = null;
 			EntityKey key = keys[i];
 
 			if ( keys[i] == null ) {
 				//do nothing
 			}
 			else {
 
 				//If the object is already loaded, return the loaded one
 				object = session.getEntityUsingInterceptor( key );
 				if ( object != null ) {
 					//its already loaded so don't need to hydrate it
 					instanceAlreadyLoaded(
 							rs,
 							i,
 							persisters[i],
 							key,
 							object,
 							lockModes[i],
 							session
 						);
 				}
 				else {
 					object = instanceNotYetLoaded(
 							rs,
 							i,
 							persisters[i],
 							descriptors[i].getRowIdAlias(),
 							key,
 							lockModes[i],
 							optionalObjectKey,
 							optionalObject,
 							hydratedObjects,
 							session
 						);
 				}
 
 			}
 
 			rowResults[i] = object;
 
 		}
 
 		return rowResults;
 	}
 
 	/**
 	 * The entity instance is already in the session cache
 	 */
 	private void instanceAlreadyLoaded(
 			final ResultSet rs,
 			final int i,
 			final Loadable persister,
 			final EntityKey key,
 			final Object object,
 			final LockMode requestedLockMode,
 			final SessionImplementor session)
 			throws HibernateException, SQLException {
 		if ( !persister.isInstance( object ) ) {
 			throw new WrongClassException(
 					"loaded object was of wrong class " + object.getClass(),
 					key.getIdentifier(),
 					persister.getEntityName()
 			);
 		}
 
 		if ( LockMode.NONE != requestedLockMode && upgradeLocks() ) { //no point doing this if NONE was requested
 			final EntityEntry entry = session.getPersistenceContext().getEntry( object );
 			if ( entry.getLockMode().lessThan( requestedLockMode ) ) {
 				//we only check the version when _upgrading_ lock modes
 				if ( persister.isVersioned() ) {
 					checkVersion( i, persister, key.getIdentifier(), object, rs, session );
 				}
 				//we need to upgrade the lock mode to the mode requested
 				entry.setLockMode( requestedLockMode );
 			}
 		}
 	}
 
 
 	/**
 	 * The entity instance is not in the session cache
 	 */
 	private Object instanceNotYetLoaded(
 			final ResultSet rs,
 			final int i,
 			final Loadable persister,
 			final String rowIdAlias,
 			final EntityKey key,
 			final LockMode lockMode,
 			final EntityKey optionalObjectKey,
 			final Object optionalObject,
 			final List hydratedObjects,
 			final SessionImplementor session)
 	throws HibernateException, SQLException {
 		final String instanceClass = getInstanceClass(
 				rs,
 				i,
 				persister,
 				key.getIdentifier(),
 				session
 		);
 
 		// see if the entity defines reference caching, and if so use the cached reference (if one).
 		if ( session.getCacheMode().isGetEnabled() && persister.canUseReferenceCacheEntries() ) {
 			final Object cachedEntry = CacheHelper.fromSharedCache(
 					session,
 					session.generateCacheKey(
 							key.getIdentifier(),
 							persister.getEntityMetamodel().getEntityType(),
 							key.getEntityName()
 					),
 					persister.getCacheAccessStrategy()
 			);
 			if ( cachedEntry != null ) {
 				CacheEntry entry = (CacheEntry) persister.getCacheEntryStructure().destructure( cachedEntry, factory );
 				return ( (ReferenceCacheEntryImpl) entry ).getReference();
 			}
 		}
 
 		final Object object;
 		if ( optionalObjectKey != null && key.equals( optionalObjectKey ) ) {
 			//its the given optional object
 			object = optionalObject;
 		}
 		else {
 			// instantiate a new instance
 			object = session.instantiate( instanceClass, key.getIdentifier() );
 		}
 
 		//need to hydrate it.
 
 		// grab its state from the ResultSet and keep it in the Session
 		// (but don't yet initialize the object itself)
 		// note that we acquire LockMode.READ even if it was not requested
 		LockMode acquiredLockMode = lockMode == LockMode.NONE ? LockMode.READ : lockMode;
 		loadFromResultSet(
 				rs,
 				i,
 				object,
 				instanceClass,
 				key,
 				rowIdAlias,
 				acquiredLockMode,
 				persister,
 				session
 			);
 
 		//materialize associations (and initialize the object) later
 		hydratedObjects.add( object );
 
 		return object;
 	}
 
 	private boolean isEagerPropertyFetchEnabled(int i) {
 		boolean[] array = getEntityEagerPropertyFetches();
 		return array!=null && array[i];
 	}
 
 
 	/**
 	 * Hydrate the state an object from the SQL <tt>ResultSet</tt>, into
 	 * an array or "hydrated" values (do not resolve associations yet),
 	 * and pass the hydrates state to the session.
 	 */
 	private void loadFromResultSet(
 			final ResultSet rs,
 			final int i,
 			final Object object,
 			final String instanceEntityName,
 			final EntityKey key,
 			final String rowIdAlias,
 			final LockMode lockMode,
 			final Loadable rootPersister,
 			final SessionImplementor session)
 	throws SQLException, HibernateException {
 
 		final Serializable id = key.getIdentifier();
 
 		// Get the persister for the _subclass_
 		final Loadable persister = (Loadable) getFactory().getEntityPersister( instanceEntityName );
 
 		if ( LOG.isTraceEnabled() )
 			LOG.tracev( "Initializing object from ResultSet: {0}", MessageHelper.infoString( persister, id, getFactory() ) );
 
 		boolean eagerPropertyFetch = isEagerPropertyFetchEnabled(i);
 
 		// add temp entry so that the next step is circular-reference
 		// safe - only needed because some types don't take proper
 		// advantage of two-phase-load (esp. components)
 		TwoPhaseLoad.addUninitializedEntity(
 				key,
 				object,
 				persister,
 				lockMode,
 				!eagerPropertyFetch,
 				session
 			);
 
 		//This is not very nice (and quite slow):
 		final String[][] cols = persister == rootPersister ?
 				getEntityAliases()[i].getSuffixedPropertyAliases() :
 				getEntityAliases()[i].getSuffixedPropertyAliases(persister);
 
 		final Object[] values = persister.hydrate(
 				rs,
 				id,
 				object,
 				rootPersister,
 				cols,
 				eagerPropertyFetch,
 				session
 			);
 
 		final Object rowId = persister.hasRowId() ? rs.getObject(rowIdAlias) : null;
 
 		final AssociationType[] ownerAssociationTypes = getOwnerAssociationTypes();
 		if ( ownerAssociationTypes != null && ownerAssociationTypes[i] != null ) {
 			String ukName = ownerAssociationTypes[i].getRHSUniqueKeyPropertyName();
 			if (ukName!=null) {
 				final int index = ( (UniqueKeyLoadable) persister ).getPropertyIndex(ukName);
 				final Type type = persister.getPropertyTypes()[index];
 
 				// polymorphism not really handled completely correctly,
 				// perhaps...well, actually its ok, assuming that the
 				// entity name used in the lookup is the same as the
 				// the one used here, which it will be
 
 				EntityUniqueKey euk = new EntityUniqueKey(
 						rootPersister.getEntityName(), //polymorphism comment above
 						ukName,
 						type.semiResolve( values[index], session, object ),
 						type,
 						persister.getEntityMode(),
 						session.getFactory()
 				);
 				session.getPersistenceContext().addEntity( euk, object );
 			}
 		}
 
 		TwoPhaseLoad.postHydrate(
 				persister,
 				id,
 				values,
 				rowId,
 				object,
 				lockMode,
 				!eagerPropertyFetch,
 				session
 		);
 
 	}
 
 	/**
 	 * Determine the concrete class of an instance in the <tt>ResultSet</tt>
 	 */
 	private String getInstanceClass(
 	        final ResultSet rs,
 	        final int i,
 	        final Loadable persister,
 	        final Serializable id,
 	        final SessionImplementor session)
 	throws HibernateException, SQLException {
 
 		if ( persister.hasSubclasses() ) {
 
 			// Code to handle subclasses of topClass
 			Object discriminatorValue = persister.getDiscriminatorType().nullSafeGet(
 					rs,
 					getEntityAliases()[i].getSuffixedDiscriminatorAlias(),
 					session,
 					null
 				);
 
 			final String result = persister.getSubclassForDiscriminatorValue( discriminatorValue );
 
 			if ( result == null ) {
 				//woops we got an instance of another class hierarchy branch
 				throw new WrongClassException(
 						"Discriminator: " + discriminatorValue,
 						id,
 						persister.getEntityName()
 					);
 			}
 
 			return result;
 
 		}
 		else {
 			return persister.getEntityName();
 		}
 	}
 
 	/**
 	 * Advance the cursor to the first required row of the <tt>ResultSet</tt>
 	 */
 	private void advance(final ResultSet rs, final RowSelection selection)
 			throws SQLException {
 
 		final int firstRow = LimitHelper.getFirstRow( selection );
 		if ( firstRow != 0 ) {
 			if ( getFactory().getSettings().isScrollableResultSetsEnabled() ) {
 				// we can go straight to the first required row
 				rs.absolute( firstRow );
 			}
 			else {
 				// we need to step through the rows one row at a time (slow)
 				for ( int m = 0; m < firstRow; m++ ) rs.next();
 			}
 		}
 	}
 
 	/**
 	 * Build LIMIT clause handler applicable for given selection criteria. Returns {@link NoopLimitHandler} delegate
 	 * if dialect does not support LIMIT expression or processed query does not use pagination.
 	 *
 	 * @param selection Selection criteria.
 	 * @return LIMIT clause delegate.
 	 */
 	protected LimitHandler getLimitHandler(RowSelection selection) {
 		final LimitHandler limitHandler = getFactory().getDialect().getLimitHandler();
 		return LimitHelper.useLimit( limitHandler, selection ) ? limitHandler : NoopLimitHandler.INSTANCE;
 	}
 
 	private ScrollMode getScrollMode(boolean scroll, boolean hasFirstRow, boolean useLimitOffSet, QueryParameters queryParameters) {
 		final boolean canScroll = getFactory().getSettings().isScrollableResultSetsEnabled();
 		if ( canScroll ) {
 			if ( scroll ) {
 				return queryParameters.getScrollMode();
 			}
 			if ( hasFirstRow && !useLimitOffSet ) {
 				return ScrollMode.SCROLL_INSENSITIVE;
 			}
 		}
 		return null;
 	}
 
 	/**
 	 * Process query string by applying filters, LIMIT clause, locks and comments if necessary.
 	 * Finally execute SQL statement and advance to the first row.
 	 */
 	protected SqlStatementWrapper executeQueryStatement(
 			final QueryParameters queryParameters,
 			final boolean scroll,
 			List<AfterLoadAction> afterLoadActions,
 			final SessionImplementor session) throws SQLException {
 		return executeQueryStatement( getSQLString(), queryParameters, scroll, afterLoadActions, session );
 	}
 
 	protected SqlStatementWrapper executeQueryStatement(
 			String sqlStatement,
 			QueryParameters queryParameters,
 			boolean scroll,
 			List<AfterLoadAction> afterLoadActions,
 			SessionImplementor session) throws SQLException {
 
 		// Processing query filters.
 		queryParameters.processFilters( sqlStatement, session );
 
 		// Applying LIMIT clause.
 		final LimitHandler limitHandler = getLimitHandler(
 				queryParameters.getRowSelection()
 		);
 		String sql = limitHandler.processSql( queryParameters.getFilteredSQL(), queryParameters.getRowSelection() );
 
 		// Adding locks and comments.
 		sql = preprocessSQL( sql, queryParameters, getFactory().getDialect(), afterLoadActions );
 
 		final PreparedStatement st = prepareQueryStatement( sql, queryParameters, limitHandler, scroll, session );
 		return new SqlStatementWrapper( st, getResultSet( st, queryParameters.getRowSelection(), limitHandler, queryParameters.hasAutoDiscoverScalarTypes(), session ) );
 	}
 
 	/**
 	 * Obtain a <tt>PreparedStatement</tt> with all parameters pre-bound.
 	 * Bind JDBC-style <tt>?</tt> parameters, named parameters, and
 	 * limit parameters.
 	 */
 	protected final PreparedStatement prepareQueryStatement(
 	        String sql,
 	        final QueryParameters queryParameters,
 	        final LimitHandler limitHandler,
 	        final boolean scroll,
 	        final SessionImplementor session) throws SQLException, HibernateException {
 		final Dialect dialect = getFactory().getDialect();
 		final RowSelection selection = queryParameters.getRowSelection();
 		boolean useLimit = LimitHelper.useLimit( limitHandler, selection );
 		boolean hasFirstRow = LimitHelper.hasFirstRow( selection );
 		boolean useLimitOffset = hasFirstRow && useLimit && limitHandler.supportsLimitOffset();
 		boolean callable = queryParameters.isCallable();
 		final ScrollMode scrollMode = getScrollMode( scroll, hasFirstRow, useLimitOffset, queryParameters );
 		
-		PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareQueryStatement(
+		PreparedStatement st = session.getJdbcCoordinator().getStatementPreparer().prepareQueryStatement(
 				sql,
 				callable,
 				scrollMode
 		);
 
 		try {
 
 			int col = 1;
 			//TODO: can we limit stored procedures ?!
 			col += limitHandler.bindLimitParametersAtStartOfQuery( selection, st, col );
 
 			if (callable) {
 				col = dialect.registerResultSetOutParameter( (CallableStatement)st, col );
 			}
 
 			col += bindParameterValues( st, queryParameters, col, session );
 
 			col += limitHandler.bindLimitParametersAtEndOfQuery( selection, st, col );
 
 			limitHandler.setMaxRows( selection, st );
 
 			if ( selection != null ) {
 				if ( selection.getTimeout() != null ) {
 					st.setQueryTimeout( selection.getTimeout() );
 				}
 				if ( selection.getFetchSize() != null ) {
 					st.setFetchSize( selection.getFetchSize() );
 				}
 			}
 
 			// handle lock timeout...
 			LockOptions lockOptions = queryParameters.getLockOptions();
 			if ( lockOptions != null ) {
 				if ( lockOptions.getTimeOut() != LockOptions.WAIT_FOREVER ) {
 					if ( !dialect.supportsLockTimeouts() ) {
 						if ( LOG.isDebugEnabled() ) {
 							LOG.debugf(
 									"Lock timeout [%s] requested but dialect reported to not support lock timeouts",
 									lockOptions.getTimeOut()
 							);
 						}
 					}
 					else if ( dialect.isLockTimeoutParameterized() ) {
 						st.setInt( col++, lockOptions.getTimeOut() );
 					}
 				}
 			}
 
 			if ( LOG.isTraceEnabled() )
 			   LOG.tracev( "Bound [{0}] parameters total", col );
 		}
 		catch ( SQLException sqle ) {
-			session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+			session.getJdbcCoordinator().getResourceRegistry().release( st );
+			session.getJdbcCoordinator().afterStatementExecution();
 			throw sqle;
 		}
 		catch ( HibernateException he ) {
-			session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+			session.getJdbcCoordinator().getResourceRegistry().release( st );
+			session.getJdbcCoordinator().afterStatementExecution();
 			throw he;
 		}
 
 		return st;
 	}
 
 	/**
 	 * Bind all parameter values into the prepared statement in preparation
 	 * for execution.
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param queryParameters The encapsulation of the parameter values to be bound.
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
 	 * @return The number of JDBC bind positions actually bound during this method execution.
 	 * @throws SQLException Indicates problems performing the binding.
 	 */
 	protected int bindParameterValues(
 			PreparedStatement statement,
 			QueryParameters queryParameters,
 			int startIndex,
 			SessionImplementor session) throws SQLException {
 		int span = 0;
 		span += bindPositionalParameters( statement, queryParameters, startIndex, session );
 		span += bindNamedParameters( statement, queryParameters.getNamedParameters(), startIndex + span, session );
 		return span;
 	}
 
 	/**
 	 * Bind positional parameter values to the JDBC prepared statement.
 	 * <p/>
 	 * Positional parameters are those specified by JDBC-style ? parameters
 	 * in the source query.  It is (currently) expected that these come
 	 * before any named parameters in the source query.
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param queryParameters The encapsulation of the parameter values to be bound.
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
 	 * @return The number of JDBC bind positions actually bound during this method execution.
 	 * @throws SQLException Indicates problems performing the binding.
 	 * @throws org.hibernate.HibernateException Indicates problems delegating binding to the types.
 	 */
 	protected int bindPositionalParameters(
 			final PreparedStatement statement,
 			final QueryParameters queryParameters,
 			final int startIndex,
 			final SessionImplementor session) throws SQLException, HibernateException {
 		final Object[] values = queryParameters.getFilteredPositionalParameterValues();
 		final Type[] types = queryParameters.getFilteredPositionalParameterTypes();
 		int span = 0;
 		for ( int i = 0; i < values.length; i++ ) {
 			types[i].nullSafeSet( statement, values[i], startIndex + span, session );
 			span += types[i].getColumnSpan( getFactory() );
 		}
 		return span;
 	}
 
 	/**
 	 * Bind named parameters to the JDBC prepared statement.
 	 * <p/>
 	 * This is a generic implementation, the problem being that in the
 	 * general case we do not know enough information about the named
 	 * parameters to perform this in a complete manner here.  Thus this
 	 * is generally overridden on subclasses allowing named parameters to
 	 * apply the specific behavior.  The most usual limitation here is that
 	 * we need to assume the type span is always one...
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param namedParams A map of parameter names to values
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
 	 * @return The number of JDBC bind positions actually bound during this method execution.
 	 * @throws SQLException Indicates problems performing the binding.
 	 * @throws org.hibernate.HibernateException Indicates problems delegating binding to the types.
 	 */
 	protected int bindNamedParameters(
 			final PreparedStatement statement,
 			final Map<String, TypedValue> namedParams,
 			final int startIndex,
 			final SessionImplementor session) throws SQLException, HibernateException {
 		int result = 0;
 		if ( CollectionHelper.isEmpty( namedParams ) ) {
 			return result;
 		}
 
 		for ( String name : namedParams.keySet() ) {
 			TypedValue typedValue = namedParams.get( name );
 			int columnSpan = typedValue.getType().getColumnSpan( getFactory() );
 			int[] locs = getNamedParameterLocs( name );
 			for ( int loc : locs ) {
 				if ( DEBUG_ENABLED ) {
 					LOG.debugf(
 							"bindNamedParameters() %s -> %s [%s]",
 							typedValue.getValue(),
 							name,
 							loc + startIndex
 					);
 				}
 				int start = loc * columnSpan + startIndex;
 				typedValue.getType().nullSafeSet( statement, typedValue.getValue(), start, session );
 			}
 			result += locs.length;
 		}
 		return result;
 	}
 
 	public int[] getNamedParameterLocs(String name) {
 		throw new AssertionFailure("no named parameters");
 	}
 
 	/**
 	 * Execute given <tt>PreparedStatement</tt>, advance to the first result and return SQL <tt>ResultSet</tt>.
 	 */
 	protected final ResultSet getResultSet(
 			final PreparedStatement st,
 			final RowSelection selection,
 			final LimitHandler limitHandler,
 			final boolean autodiscovertypes,
 			final SessionImplementor session)
 	throws SQLException, HibernateException {
 
 		try {
-			ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
+			ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 			rs = wrapResultSetIfEnabled( rs , session );
 
 			if ( !limitHandler.supportsLimitOffset() || !LimitHelper.useLimit( limitHandler, selection ) ) {
 				advance( rs, selection );
 			}
 
 			if ( autodiscovertypes ) {
 				autoDiscoverTypes( rs );
 			}
 			return rs;
 		}
 		catch ( SQLException sqle ) {
-			session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+			session.getJdbcCoordinator().getResourceRegistry().release( st );
+			session.getJdbcCoordinator().afterStatementExecution();
 			throw sqle;
 		}
 	}
 
 	protected void autoDiscoverTypes(ResultSet rs) {
 		throw new AssertionFailure("Auto discover types not supported in this loader");
 
 	}
 
 	private ResultSet wrapResultSetIfEnabled(final ResultSet rs, final SessionImplementor session) {
 		if ( session.getFactory().getSettings().isWrapResultSetsEnabled() ) {
 			try {
 				LOG.debugf( "Wrapping result set [%s]", rs );
 				return session.getFactory()
 						.getJdbcServices()
 						.getResultSetWrapper().wrap( rs, retreiveColumnNameToIndexCache( rs ) );
 			}
 			catch(SQLException e) {
 				LOG.unableToWrapResultSet( e );
 				return rs;
 			}
 		}
 		else {
 			return rs;
 		}
 	}
 
 	private ColumnNameCache retreiveColumnNameToIndexCache(final ResultSet rs) throws SQLException {
 		final ColumnNameCache cache = columnNameCache;
 		if ( cache == null ) {
 			//there is no need for a synchronized second check, as in worst case
 			//we'll have allocated an unnecessary ColumnNameCache
 			LOG.trace( "Building columnName -> columnIndex cache" );
 			columnNameCache = new ColumnNameCache( rs.getMetaData().getColumnCount() );
 			return columnNameCache;
 		}
 		else {
 			return cache;
 		}
 	}
 
 	/**
 	 * Called by subclasses that load entities
 	 * @param persister only needed for logging
 	 * @param lockOptions
 	 */
 	protected final List loadEntity(
 			final SessionImplementor session,
 			final Object id,
 			final Type identifierType,
 			final Object optionalObject,
 			final String optionalEntityName,
 			final Serializable optionalIdentifier,
 			final EntityPersister persister,
 			LockOptions lockOptions) throws HibernateException {
 
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "Loading entity: %s", MessageHelper.infoString( persister, id, identifierType, getFactory() ) );
 		}
 
 		List result;
 		try {
 			QueryParameters qp = new QueryParameters();
 			qp.setPositionalParameterTypes( new Type[] { identifierType } );
 			qp.setPositionalParameterValues( new Object[] { id } );
 			qp.setOptionalObject( optionalObject );
 			qp.setOptionalEntityName( optionalEntityName );
 			qp.setOptionalId( optionalIdentifier );
 			qp.setLockOptions( lockOptions );
 			result = doQueryAndInitializeNonLazyCollections( session, qp, false );
 		}
 		catch ( SQLException sqle ) {
 			final Loadable[] persisters = getEntityPersisters();
 			throw factory.getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not load an entity: " +
 			        MessageHelper.infoString( persisters[persisters.length-1], id, identifierType, getFactory() ),
 			        getSQLString()
 				);
 		}
 
 		LOG.debug( "Done entity load" );
 
 		return result;
 
 	}
 
 	/**
 	 * Called by subclasses that load entities
 	 * @param persister only needed for logging
 	 */
 	protected final List loadEntity(
 	        final SessionImplementor session,
 	        final Object key,
 	        final Object index,
 	        final Type keyType,
 	        final Type indexType,
 	        final EntityPersister persister) throws HibernateException {
 
 		LOG.debug( "Loading collection element by index" );
 
 		List result;
 		try {
 			result = doQueryAndInitializeNonLazyCollections(
 					session,
 					new QueryParameters(
 							new Type[] { keyType, indexType },
 							new Object[] { key, index }
 					),
 					false
 			);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not load collection element by index",
 			        getSQLString()
 				);
 		}
 
 		LOG.debug( "Done entity load" );
 
 		return result;
 
 	}
 
 	/**
 	 * Called by wrappers that batch load entities
 	 * @param persister only needed for logging
 	 * @param lockOptions
 	 */
 	public final List loadEntityBatch(
 			final SessionImplementor session,
 			final Serializable[] ids,
 			final Type idType,
 			final Object optionalObject,
 			final String optionalEntityName,
 			final Serializable optionalId,
 			final EntityPersister persister,
 			LockOptions lockOptions) throws HibernateException {
 
 		if ( LOG.isDebugEnabled() )
 			LOG.debugf( "Batch loading entity: %s", MessageHelper.infoString( persister, ids, getFactory() ) );
 
 		Type[] types = new Type[ids.length];
 		Arrays.fill( types, idType );
 		List result;
 		try {
 			QueryParameters qp = new QueryParameters();
 			qp.setPositionalParameterTypes( types );
 			qp.setPositionalParameterValues( ids );
 			qp.setOptionalObject( optionalObject );
 			qp.setOptionalEntityName( optionalEntityName );
 			qp.setOptionalId( optionalId );
 			qp.setLockOptions( lockOptions );
 			result = doQueryAndInitializeNonLazyCollections( session, qp, false );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 			        sqle,
 			        "could not load an entity batch: " +
 			        MessageHelper.infoString( getEntityPersisters()[0], ids, getFactory() ),
 			        getSQLString()
 				);
 		}
 
 		LOG.debug( "Done entity batch load" );
 
 		return result;
 
 	}
 
 	/**
 	 * Called by subclasses that initialize collections
 	 */
 	public final void loadCollection(
 	        final SessionImplementor session,
 	        final Serializable id,
 	        final Type type) throws HibernateException {
 
 		if ( LOG.isDebugEnabled() )
 			LOG.debugf( "Loading collection: %s",
 					MessageHelper.collectionInfoString( getCollectionPersisters()[0], id, getFactory() ) );
 
 		Serializable[] ids = new Serializable[]{id};
 		try {
 			doQueryAndInitializeNonLazyCollections(
 					session,
 					new QueryParameters( new Type[]{type}, ids, ids ),
 					true
 				);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not initialize a collection: " +
 					MessageHelper.collectionInfoString( getCollectionPersisters()[0], id, getFactory() ),
 					getSQLString()
 				);
 		}
 
 		LOG.debug( "Done loading collection" );
 
 	}
 
 	/**
 	 * Called by wrappers that batch initialize collections
 	 */
 	public final void loadCollectionBatch(
 			final SessionImplementor session,
 			final Serializable[] ids,
 			final Type type) throws HibernateException {
 
 		if ( LOG.isDebugEnabled() )
 			LOG.debugf( "Batch loading collection: %s",
 					MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() ) );
 
 		Type[] idTypes = new Type[ids.length];
 		Arrays.fill( idTypes, type );
 		try {
 			doQueryAndInitializeNonLazyCollections(
 					session,
 					new QueryParameters( idTypes, ids, ids ),
 					true
 				);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not initialize a collection batch: " +
 					MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() ),
 					getSQLString()
 				);
 		}
 
 		LOG.debug( "Done batch load" );
 
 	}
 
 	/**
 	 * Called by subclasses that batch initialize collections
 	 */
 	protected final void loadCollectionSubselect(
 			final SessionImplementor session,
 			final Serializable[] ids,
 			final Object[] parameterValues,
 			final Type[] parameterTypes,
 			final Map<String, TypedValue> namedParameters,
 			final Type type) throws HibernateException {
 
 		Type[] idTypes = new Type[ids.length];
 		Arrays.fill( idTypes, type );
 		try {
 			doQueryAndInitializeNonLazyCollections( session,
 					new QueryParameters( parameterTypes, parameterValues, namedParameters, ids ),
 					true
 				);
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not load collection by subselect: " +
 					MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() ),
 					getSQLString()
 				);
 		}
 	}
 
 	/**
 	 * Return the query results, using the query cache, called
 	 * by subclasses that implement cacheable queries
 	 */
 	protected List list(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final Set<Serializable> querySpaces,
 			final Type[] resultTypes) throws HibernateException {
 
 		final boolean cacheable = factory.getSettings().isQueryCacheEnabled() &&
 			queryParameters.isCacheable();
 
 		if ( cacheable ) {
 			return listUsingQueryCache( session, queryParameters, querySpaces, resultTypes );
 		}
 		else {
 			return listIgnoreQueryCache( session, queryParameters );
 		}
 	}
 
 	private List listIgnoreQueryCache(SessionImplementor session, QueryParameters queryParameters) {
 		return getResultList( doList( session, queryParameters ), queryParameters.getResultTransformer() );
 	}
 
 	private List listUsingQueryCache(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final Set<Serializable> querySpaces,
 			final Type[] resultTypes) {
 
 		QueryCache queryCache = factory.getQueryCache( queryParameters.getCacheRegion() );
 
 		QueryKey key = generateQueryKey( session, queryParameters );
 
 		if ( querySpaces == null || querySpaces.size() == 0 )
 			LOG.tracev( "Unexpected querySpaces is {0}", ( querySpaces == null ? querySpaces : "empty" ) );
 		else {
 			LOG.tracev( "querySpaces is {0}", querySpaces );
 		}
 
 		List result = getResultFromQueryCache(
 				session,
 				queryParameters,
 				querySpaces,
 				resultTypes,
 				queryCache,
 				key
 			);
 
 		if ( result == null ) {
 			result = doList( session, queryParameters, key.getResultTransformer() );
 
 			putResultInQueryCache(
 					session,
 					queryParameters,
 					resultTypes,
 					queryCache,
 					key,
 					result
 			);
 		}
 
 		ResultTransformer resolvedTransformer = resolveResultTransformer( queryParameters.getResultTransformer() );
 		if ( resolvedTransformer != null ) {
 			result = (
 					areResultSetRowsTransformedImmediately() ?
 							key.getResultTransformer().retransformResults(
 									result,
 									getResultRowAliases(),
 									queryParameters.getResultTransformer(),
 									includeInResultRow()
 							) :
 							key.getResultTransformer().untransformToTuples(
 									result
 							)
 			);
 		}
 
 		return getResultList( result, queryParameters.getResultTransformer() );
 	}
 
 	private QueryKey generateQueryKey(
 			SessionImplementor session,
 			QueryParameters queryParameters) {
 		return QueryKey.generateQueryKey(
 				getSQLString(),
 				queryParameters,
 				FilterKey.createFilterKeys( session.getLoadQueryInfluencers().getEnabledFilters() ),
 				session,
 				createCacheableResultTransformer( queryParameters )
 		);
 	}
 
 	private CacheableResultTransformer createCacheableResultTransformer(QueryParameters queryParameters) {
 		return CacheableResultTransformer.create(
 				queryParameters.getResultTransformer(),
 				getResultRowAliases(),
 				includeInResultRow()
 		);
 	}
 
 	private List getResultFromQueryCache(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final Set<Serializable> querySpaces,
 			final Type[] resultTypes,
 			final QueryCache queryCache,
 			final QueryKey key) {
 		List result = null;
 
 		if ( session.getCacheMode().isGetEnabled() ) {
 			boolean isImmutableNaturalKeyLookup =
 					queryParameters.isNaturalKeyLookup() &&
 							resultTypes.length == 1 &&
 							resultTypes[0].isEntityType() &&
 							getEntityPersister( EntityType.class.cast( resultTypes[0] ) )
 									.getEntityMetamodel()
 									.hasImmutableNaturalId();
 
 			final PersistenceContext persistenceContext = session.getPersistenceContext();
 			boolean defaultReadOnlyOrig = persistenceContext.isDefaultReadOnly();
 			if ( queryParameters.isReadOnlyInitialized() ) {
 				// The read-only/modifiable mode for the query was explicitly set.
 				// Temporarily set the default read-only/modifiable setting to the query's setting.
 				persistenceContext.setDefaultReadOnly( queryParameters.isReadOnly() );
 			}
 			else {
 				// The read-only/modifiable setting for the query was not initialized.
 				// Use the default read-only/modifiable from the persistence context instead.
 				queryParameters.setReadOnly( persistenceContext.isDefaultReadOnly() );
 			}
 			try {
 				result = queryCache.get(
 						key,
 						key.getResultTransformer().getCachedResultTypes( resultTypes ),
 						isImmutableNaturalKeyLookup,
 						querySpaces,
 						session
 				);
 			}
 			finally {
 				persistenceContext.setDefaultReadOnly( defaultReadOnlyOrig );
 			}
 
 			if ( factory.getStatistics().isStatisticsEnabled() ) {
 				if ( result == null ) {
 					factory.getStatisticsImplementor()
 							.queryCacheMiss( getQueryIdentifier(), queryCache.getRegion().getName() );
 				}
 				else {
 					factory.getStatisticsImplementor()
 							.queryCacheHit( getQueryIdentifier(), queryCache.getRegion().getName() );
 				}
 			}
 		}
 
 		return result;
 	}
 
 	private EntityPersister getEntityPersister(EntityType entityType) {
 		return factory.getEntityPersister( entityType.getAssociatedEntityName() );
 	}
 
 	protected void putResultInQueryCache(
 			final SessionImplementor session,
 			final QueryParameters queryParameters,
 			final Type[] resultTypes,
 			final QueryCache queryCache,
 			final QueryKey key,
 			final List result) {
 		if ( session.getCacheMode().isPutEnabled() ) {
 			boolean put = queryCache.put(
 					key,
 					key.getResultTransformer().getCachedResultTypes( resultTypes ),
 					result,
 					queryParameters.isNaturalKeyLookup(),
 					session
 			);
 			if ( put && factory.getStatistics().isStatisticsEnabled() ) {
 				factory.getStatisticsImplementor()
 						.queryCachePut( getQueryIdentifier(), queryCache.getRegion().getName() );
 			}
 		}
 	}
 
 	/**
 	 * Actually execute a query, ignoring the query cache
 	 */
 
 	protected List doList(final SessionImplementor session, final QueryParameters queryParameters)
 			throws HibernateException {
 		return doList( session, queryParameters, null);
 	}
 
 	private List doList(final SessionImplementor session,
 						final QueryParameters queryParameters,
 						final ResultTransformer forcedResultTransformer)
 			throws HibernateException {
 
 		final boolean stats = getFactory().getStatistics().isStatisticsEnabled();
 		long startTime = 0;
 		if ( stats ) startTime = System.nanoTime();
 
 		List result;
 		try {
 			result = doQueryAndInitializeNonLazyCollections( session, queryParameters, true, forcedResultTransformer );
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not execute query",
 					getSQLString()
 				);
 		}
 
 		if ( stats ) {
 			final long endTime = System.nanoTime();
 			final long milliseconds = TimeUnit.MILLISECONDS.convert( endTime - startTime, TimeUnit.NANOSECONDS );
 			getFactory().getStatisticsImplementor().queryExecuted(
 					getQueryIdentifier(),
 					result.size(),
 					milliseconds
 				);
 		}
 
 		return result;
 	}
 
 	/**
 	 * Check whether the current loader can support returning ScrollableResults.
 	 *
 	 * @throws HibernateException
 	 */
 	protected void checkScrollability() throws HibernateException {
 		// Allows various loaders (ok mainly the QueryLoader :) to check
 		// whether scrolling of their result set should be allowed.
 		//
 		// By default it is allowed.
 	}
 
 	/**
 	 * Does the result set to be scrolled contain collection fetches?
 	 *
 	 * @return True if it does, and thus needs the special fetching scroll
 	 * functionality; false otherwise.
 	 */
 	protected boolean needsFetchingScroll() {
 		return false;
 	}
 
 	/**
 	 * Return the query results, as an instance of <tt>ScrollableResults</tt>
 	 *
 	 * @param queryParameters The parameters with which the query should be executed.
 	 * @param returnTypes The expected return types of the query
 	 * @param holderInstantiator If the return values are expected to be wrapped
 	 * in a holder, this is the thing that knows how to wrap them.
 	 * @param session The session from which the scroll request originated.
 	 * @return The ScrollableResults instance.
 	 * @throws HibernateException Indicates an error executing the query, or constructing
 	 * the ScrollableResults.
 	 */
 	protected ScrollableResults scroll(
 			final QueryParameters queryParameters,
 			final Type[] returnTypes,
 			final HolderInstantiator holderInstantiator,
 			final SessionImplementor session) throws HibernateException {
 
 		checkScrollability();
 
 		final boolean stats = getQueryIdentifier() != null &&
 				getFactory().getStatistics().isStatisticsEnabled();
 		long startTime = 0;
 		if ( stats ) startTime = System.nanoTime();
 
 		try {
 			// Don't use Collections#emptyList() here -- follow on locking potentially adds AfterLoadActions,
 			// so the list cannot be immutable.
 			final SqlStatementWrapper wrapper = executeQueryStatement( queryParameters, true, new ArrayList<AfterLoadAction>(), session );
 			final ResultSet rs = wrapper.getResultSet();
 			final PreparedStatement st = (PreparedStatement) wrapper.getStatement();
 
 			if ( stats ) {
 				final long endTime = System.nanoTime();
 				final long milliseconds = TimeUnit.MILLISECONDS.convert( endTime - startTime, TimeUnit.NANOSECONDS );
 				getFactory().getStatisticsImplementor().queryExecuted(
 						getQueryIdentifier(),
 						0,
 						milliseconds
 					);
 			}
 
 			if ( needsFetchingScroll() ) {
 				return new FetchingScrollableResultsImpl(
 						rs,
 						st,
 						session,
 						this,
 						queryParameters,
 						returnTypes,
 						holderInstantiator
 					);
 			}
 			else {
 				return new ScrollableResultsImpl(
 						rs,
 						st,
 						session,
 						this,
 						queryParameters,
 						returnTypes,
 						holderInstantiator
 					);
 			}
 
 		}
 		catch ( SQLException sqle ) {
 			throw factory.getSQLExceptionHelper().convert(
 					sqle,
 					"could not execute query using scroll",
 					getSQLString()
 				);
 		}
 
 	}
 
 	/**
 	 * Calculate and cache select-clause suffixes. Must be
 	 * called by subclasses after instantiation.
 	 */
 	protected void postInstantiate() {}
 
 	/**
 	 * Get the result set descriptor
 	 */
 	protected abstract EntityAliases[] getEntityAliases();
 
 	protected abstract CollectionAliases[] getCollectionAliases();
 
 	/**
 	 * Identifies the query for statistics reporting, if null,
 	 * no statistics will be reported
 	 */
 	protected String getQueryIdentifier() {
 		return null;
 	}
 
 	public final SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	@Override
 	public String toString() {
 		return getClass().getName() + '(' + getSQLString() + ')';
 	}
 
 	/**
 	 * Wrapper class for {@link Statement} and associated {@link ResultSet}.
 	 */
 	protected static class SqlStatementWrapper {
 		private final Statement statement;
 		private final ResultSet resultSet;
 
 		private SqlStatementWrapper(Statement statement, ResultSet resultSet) {
 			this.resultSet = resultSet;
 			this.statement = statement;
 		}
 
 		public ResultSet getResultSet() {
 			return resultSet;
 		}
 
 		public Statement getStatement() {
 			return statement;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/collection/DynamicBatchingCollectionInitializerBuilder.java b/hibernate-core/src/main/java/org/hibernate/loader/collection/DynamicBatchingCollectionInitializerBuilder.java
index 8f470ca1e1..27259f806b 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/collection/DynamicBatchingCollectionInitializerBuilder.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/collection/DynamicBatchingCollectionInitializerBuilder.java
@@ -1,270 +1,271 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.collection;
 
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.List;
 
 import org.hibernate.HibernateException;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.JoinWalker;
 import org.hibernate.loader.Loader;
 import org.hibernate.loader.spi.AfterLoadAction;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.Type;
 
 /**
  * A BatchingCollectionInitializerBuilder that builds CollectionInitializer instances capable of dynamically building
  * its batch-fetch SQL based on the actual number of collections keys waiting to be fetched.
  *
  * @author Steve Ebersole
  */
 public class DynamicBatchingCollectionInitializerBuilder extends BatchingCollectionInitializerBuilder {
 	public static final DynamicBatchingCollectionInitializerBuilder INSTANCE = new DynamicBatchingCollectionInitializerBuilder();
 
 	@Override
 	protected CollectionInitializer createRealBatchingCollectionInitializer(
 			QueryableCollection persister,
 			int maxBatchSize,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers influencers) {
 		return new DynamicBatchingCollectionInitializer( persister, maxBatchSize, factory, influencers );
 	}
 
 	@Override
 	protected CollectionInitializer createRealBatchingOneToManyInitializer(
 			QueryableCollection persister,
 			int maxBatchSize,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers influencers) {
 		return new DynamicBatchingCollectionInitializer( persister, maxBatchSize, factory, influencers );
 	}
 
 	public static class DynamicBatchingCollectionInitializer extends BatchingCollectionInitializer {
 		private final int maxBatchSize;
 		private final Loader singleKeyLoader;
 		private final DynamicBatchingCollectionLoader batchLoader;
 
 		public DynamicBatchingCollectionInitializer(
 				QueryableCollection collectionPersister,
 				int maxBatchSize,
 				SessionFactoryImplementor factory,
 				LoadQueryInfluencers influencers) {
 			super( collectionPersister );
 			this.maxBatchSize = maxBatchSize;
 
 			if ( collectionPersister.isOneToMany() ) {
 				this.singleKeyLoader = new OneToManyLoader( collectionPersister, 1, factory, influencers );
 			}
 			else {
 				this.singleKeyLoader = new BasicCollectionLoader( collectionPersister, 1, factory, influencers );
 			}
 
 			this.batchLoader = new DynamicBatchingCollectionLoader( collectionPersister, factory, influencers );
 		}
 
 		@Override
 		public void initialize(Serializable id, SessionImplementor session) throws HibernateException {
 			// first, figure out how many batchable ids we have...
 			final Serializable[] batch = session.getPersistenceContext()
 					.getBatchFetchQueue()
 					.getCollectionBatch( collectionPersister(), id, maxBatchSize );
 			final int numberOfIds = ArrayHelper.countNonNull( batch );
 			if ( numberOfIds <= 1 ) {
 				singleKeyLoader.loadCollection( session, id, collectionPersister().getKeyType() );
 				return;
 			}
 
 			final Serializable[] idsToLoad = new Serializable[numberOfIds];
 			System.arraycopy( batch, 0, idsToLoad, 0, numberOfIds );
 
 			batchLoader.doBatchedCollectionLoad( session, idsToLoad, collectionPersister().getKeyType() );
 		}
 	}
 
 	private static class DynamicBatchingCollectionLoader extends CollectionLoader {
 		// todo : this represents another case where the current Loader contract is unhelpful
 		//		the other recent case was stored procedure support.  Really any place where the SQL
 		//		generation is dynamic but the "loading plan" remains constant.  The long term plan
 		//		is to split Loader into (a) PreparedStatement generation/execution and (b) ResultSet
 		// 		processing.
 		//
 		// Same holds true for org.hibernate.loader.entity.DynamicBatchingEntityLoaderBuilder.DynamicBatchingEntityLoader
 		//
 		// for now I will essentially semi-re-implement the collection loader contract here to be able to alter
 		// 		the SQL (specifically to be able to dynamically build the WHERE-clause IN-condition) later, when
 		//		we actually know the ids to batch fetch
 
 		private final String sqlTemplate;
 		private final String alias;
 
 		public DynamicBatchingCollectionLoader(
 				QueryableCollection collectionPersister,
 				SessionFactoryImplementor factory,
 				LoadQueryInfluencers influencers) {
 			super( collectionPersister, factory, influencers );
 
 			JoinWalker walker = buildJoinWalker( collectionPersister, factory, influencers );
 			initFromWalker( walker );
 			this.sqlTemplate = walker.getSQLString();
 			this.alias = StringHelper.generateAlias( collectionPersister.getRole(), 0 );
 			postInstantiate();
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf(
 						"SQL-template for dynamic collection [%s] batch-fetching : %s",
 						collectionPersister.getRole(),
 						sqlTemplate
 				);
 			}
 		}
 
 		private JoinWalker buildJoinWalker(
 				QueryableCollection collectionPersister,
 				SessionFactoryImplementor factory,
 				LoadQueryInfluencers influencers) {
 
 			if ( collectionPersister.isOneToMany() ) {
 				return new OneToManyJoinWalker( collectionPersister, -1, null, factory, influencers ) {
 					@Override
 					protected StringBuilder whereString(String alias, String[] columnNames, String subselect, int batchSize) {
 						if ( subselect != null ) {
 							return super.whereString( alias, columnNames, subselect, batchSize );
 						}
 
 						return StringHelper.buildBatchFetchRestrictionFragment( alias, columnNames, getFactory().getDialect() );
 					}
 				};
 			}
 			else {
 				return new BasicCollectionJoinWalker( collectionPersister, -1, null, factory, influencers ) {
 					@Override
 					protected StringBuilder whereString(String alias, String[] columnNames, String subselect, int batchSize) {
 						if ( subselect != null ) {
 							return super.whereString( alias, columnNames, subselect, batchSize );
 						}
 
 						return StringHelper.buildBatchFetchRestrictionFragment( alias, columnNames, getFactory().getDialect() );
 					}
 				};
 			}
 		}
 
 		public final void doBatchedCollectionLoad(
 				final SessionImplementor session,
 				final Serializable[] ids,
 				final Type type) throws HibernateException {
 
 			if ( LOG.isDebugEnabled() )
 				LOG.debugf( "Batch loading collection: %s",
 							MessageHelper.collectionInfoString( getCollectionPersisters()[0], ids, getFactory() ) );
 
 			final Type[] idTypes = new Type[ids.length];
 			Arrays.fill( idTypes, type );
 			final QueryParameters queryParameters = new QueryParameters( idTypes, ids, ids );
 
 			final String sql = StringHelper.expandBatchIdPlaceholder(
 					sqlTemplate,
 					ids,
 					alias,
 					collectionPersister().getKeyColumnNames(),
 					getFactory().getDialect()
 			);
 
 			try {
 				final PersistenceContext persistenceContext = session.getPersistenceContext();
 				boolean defaultReadOnlyOrig = persistenceContext.isDefaultReadOnly();
 				if ( queryParameters.isReadOnlyInitialized() ) {
 					// The read-only/modifiable mode for the query was explicitly set.
 					// Temporarily set the default read-only/modifiable setting to the query's setting.
 					persistenceContext.setDefaultReadOnly( queryParameters.isReadOnly() );
 				}
 				else {
 					// The read-only/modifiable setting for the query was not initialized.
 					// Use the default read-only/modifiable from the persistence context instead.
 					queryParameters.setReadOnly( persistenceContext.isDefaultReadOnly() );
 				}
 				persistenceContext.beforeLoad();
 				try {
 					try {
 						doTheLoad( sql, queryParameters, session );
 					}
 					finally {
 						persistenceContext.afterLoad();
 					}
 					persistenceContext.initializeNonLazyCollections();
 				}
 				finally {
 					// Restore the original default
 					persistenceContext.setDefaultReadOnly( defaultReadOnlyOrig );
 				}
 			}
 			catch ( SQLException e ) {
 				throw getFactory().getSQLExceptionHelper().convert(
 						e,
 						"could not initialize a collection batch: " +
 								MessageHelper.collectionInfoString( collectionPersister(), ids, getFactory() ),
 						sql
 				);
 			}
 
 			LOG.debug( "Done batch load" );
 
 		}
 
 		private void doTheLoad(String sql, QueryParameters queryParameters, SessionImplementor session) throws SQLException {
 			final RowSelection selection = queryParameters.getRowSelection();
 			final int maxRows = LimitHelper.hasMaxRows( selection ) ?
 					selection.getMaxRows() :
 					Integer.MAX_VALUE;
 
 			final List<AfterLoadAction> afterLoadActions = Collections.emptyList();
 			final SqlStatementWrapper wrapper = executeQueryStatement( sql, queryParameters, false, afterLoadActions, session );
 			final ResultSet rs = wrapper.getResultSet();
 			final Statement st = wrapper.getStatement();
 			try {
 				processResultSet( rs, queryParameters, session, true, null, maxRows, afterLoadActions );
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+				session.getJdbcCoordinator().getResourceRegistry().release( st );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/entity/DynamicBatchingEntityLoaderBuilder.java b/hibernate-core/src/main/java/org/hibernate/loader/entity/DynamicBatchingEntityLoaderBuilder.java
index bd6de49682..dd35e4ff22 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/entity/DynamicBatchingEntityLoaderBuilder.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/entity/DynamicBatchingEntityLoaderBuilder.java
@@ -1,270 +1,271 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.entity;
 
 import java.io.Serializable;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.ArrayList;
 import java.util.List;
 
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.spi.AfterLoadAction;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.pretty.MessageHelper;
 
 import org.jboss.logging.Logger;
 
 /**
  * A BatchingEntityLoaderBuilder that builds UniqueEntityLoader instances capable of dynamically building
  * its batch-fetch SQL based on the actual number of entity ids waiting to be fetched.
  *
  * @author Steve Ebersole
  */
 public class DynamicBatchingEntityLoaderBuilder extends BatchingEntityLoaderBuilder {
 	private static final Logger log = Logger.getLogger( DynamicBatchingEntityLoaderBuilder.class );
 
 	public static final DynamicBatchingEntityLoaderBuilder INSTANCE = new DynamicBatchingEntityLoaderBuilder();
 
 	@Override
 	protected UniqueEntityLoader buildBatchingLoader(
 			OuterJoinLoadable persister,
 			int batchSize,
 			LockMode lockMode,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers influencers) {
 		return new DynamicBatchingEntityLoader( persister, batchSize, lockMode, factory, influencers );
 	}
 
 	@Override
 	protected UniqueEntityLoader buildBatchingLoader(
 			OuterJoinLoadable persister,
 			int batchSize,
 			LockOptions lockOptions,
 			SessionFactoryImplementor factory,
 			LoadQueryInfluencers influencers) {
 		return new DynamicBatchingEntityLoader( persister, batchSize, lockOptions, factory, influencers );
 	}
 
 	public static class DynamicBatchingEntityLoader extends BatchingEntityLoader {
 		private final int maxBatchSize;
 		private final UniqueEntityLoader singleKeyLoader;
 		private final DynamicEntityLoader dynamicLoader;
 
 		public DynamicBatchingEntityLoader(
 				OuterJoinLoadable persister,
 				int maxBatchSize,
 				LockMode lockMode,
 				SessionFactoryImplementor factory,
 				LoadQueryInfluencers loadQueryInfluencers) {
 			super( persister );
 			this.maxBatchSize = maxBatchSize;
 			this.singleKeyLoader = new EntityLoader( persister, 1, lockMode, factory, loadQueryInfluencers );
 			this.dynamicLoader = new DynamicEntityLoader( persister, maxBatchSize, lockMode, factory, loadQueryInfluencers );
 		}
 
 		public DynamicBatchingEntityLoader(
 				OuterJoinLoadable persister,
 				int maxBatchSize,
 				LockOptions lockOptions,
 				SessionFactoryImplementor factory,
 				LoadQueryInfluencers loadQueryInfluencers) {
 			super( persister );
 			this.maxBatchSize = maxBatchSize;
 			this.singleKeyLoader = new EntityLoader( persister, 1, lockOptions, factory, loadQueryInfluencers );
 			this.dynamicLoader = new DynamicEntityLoader( persister, maxBatchSize, lockOptions, factory, loadQueryInfluencers );
 		}
 
 		@Override
 		public Object load(
 				Serializable id,
 				Object optionalObject,
 				SessionImplementor session,
 				LockOptions lockOptions) {
 			final Serializable[] batch = session.getPersistenceContext()
 					.getBatchFetchQueue()
 					.getEntityBatch( persister(), id, maxBatchSize, persister().getEntityMode() );
 
 			final int numberOfIds = ArrayHelper.countNonNull( batch );
 			if ( numberOfIds <= 1 ) {
 				return singleKeyLoader.load( id, optionalObject, session );
 			}
 
 			final Serializable[] idsToLoad = new Serializable[numberOfIds];
 			System.arraycopy( batch, 0, idsToLoad, 0, numberOfIds );
 
 			if ( log.isDebugEnabled() ) {
 				log.debugf( "Batch loading entity: %s", MessageHelper.infoString( persister(), idsToLoad, session.getFactory() ) );
 			}
 
 			QueryParameters qp = buildQueryParameters( id, idsToLoad, optionalObject, lockOptions );
 			List results = dynamicLoader.doEntityBatchFetch( session, qp, idsToLoad );
 			return getObjectFromList( results, id, session );
 		}
 	}
 
 
 	private static class DynamicEntityLoader extends EntityLoader {
 		// todo : see the discussion on org.hibernate.loader.collection.DynamicBatchingCollectionInitializerBuilder.DynamicBatchingCollectionLoader
 
 		private final String sqlTemplate;
 		private final String alias;
 
 		public DynamicEntityLoader(
 				OuterJoinLoadable persister,
 				int maxBatchSize,
 				LockOptions lockOptions,
 				SessionFactoryImplementor factory,
 				LoadQueryInfluencers loadQueryInfluencers) {
 			this( persister, maxBatchSize, lockOptions.getLockMode(), factory, loadQueryInfluencers );
 		}
 
 		public DynamicEntityLoader(
 				OuterJoinLoadable persister,
 				int maxBatchSize,
 				LockMode lockMode,
 				SessionFactoryImplementor factory,
 				LoadQueryInfluencers loadQueryInfluencers) {
 			super( persister, -1, lockMode, factory, loadQueryInfluencers );
 
 			EntityJoinWalker walker = new EntityJoinWalker(
 					persister,
 					persister.getIdentifierColumnNames(),
 					-1,
 					lockMode,
 					factory,
 					loadQueryInfluencers
 			) {
 				@Override
 				protected StringBuilder whereString(String alias, String[] columnNames, int batchSize) {
 					return StringHelper.buildBatchFetchRestrictionFragment( alias, columnNames, getFactory().getDialect() );
 				}
 			};
 
 			initFromWalker( walker );
 			this.sqlTemplate = walker.getSQLString();
 			this.alias = walker.getAlias();
 			postInstantiate();
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf(
 						"SQL-template for dynamic entity [%s] batch-fetching [%s] : %s",
 						entityName,
 						lockMode,
 						sqlTemplate
 				);
 			}
 		}
 
 		@Override
 		protected boolean isSingleRowLoader() {
 			return false;
 		}
 
 		public List doEntityBatchFetch(
 				SessionImplementor session,
 				QueryParameters queryParameters,
 				Serializable[] ids) {
 			final String sql = StringHelper.expandBatchIdPlaceholder(
 					sqlTemplate,
 					ids,
 					alias,
 					persister.getKeyColumnNames(),
 					getFactory().getDialect()
 			);
 
 			try {
 				final PersistenceContext persistenceContext = session.getPersistenceContext();
 				boolean defaultReadOnlyOrig = persistenceContext.isDefaultReadOnly();
 				if ( queryParameters.isReadOnlyInitialized() ) {
 					// The read-only/modifiable mode for the query was explicitly set.
 					// Temporarily set the default read-only/modifiable setting to the query's setting.
 					persistenceContext.setDefaultReadOnly( queryParameters.isReadOnly() );
 				}
 				else {
 					// The read-only/modifiable setting for the query was not initialized.
 					// Use the default read-only/modifiable from the persistence context instead.
 					queryParameters.setReadOnly( persistenceContext.isDefaultReadOnly() );
 				}
 				persistenceContext.beforeLoad();
 				List results;
 				try {
 					try {
 						results = doTheLoad( sql, queryParameters, session );
 					}
 					finally {
 						persistenceContext.afterLoad();
 					}
 					persistenceContext.initializeNonLazyCollections();
 					log.debug( "Done batch load" );
 					return results;
 				}
 				finally {
 					// Restore the original default
 					persistenceContext.setDefaultReadOnly( defaultReadOnlyOrig );
 				}
 			}
 			catch ( SQLException sqle ) {
 				throw session.getFactory().getSQLExceptionHelper().convert(
 						sqle,
 						"could not load an entity batch: " + MessageHelper.infoString(
 								getEntityPersisters()[0],
 								ids,
 								session.getFactory()
 						),
 						sql
 				);
 			}
 		}
 
 		private List doTheLoad(String sql, QueryParameters queryParameters, SessionImplementor session) throws SQLException {
 			final RowSelection selection = queryParameters.getRowSelection();
 			final int maxRows = LimitHelper.hasMaxRows( selection ) ?
 					selection.getMaxRows() :
 					Integer.MAX_VALUE;
 
 			final List<AfterLoadAction> afterLoadActions = new ArrayList<AfterLoadAction>();
 			final SqlStatementWrapper wrapper = executeQueryStatement( sql, queryParameters, false, afterLoadActions, session );
 			final ResultSet rs = wrapper.getResultSet();
 			final Statement st = wrapper.getStatement();
 			try {
 				return processResultSet( rs, queryParameters, session, false, null, maxRows, afterLoadActions );
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+				session.getJdbcCoordinator().getResourceRegistry().release( st );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/AbstractLoadPlanBasedLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/AbstractLoadPlanBasedLoader.java
index 96721a4073..9e4160ffc5 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/AbstractLoadPlanBasedLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/exec/internal/AbstractLoadPlanBasedLoader.java
@@ -1,535 +1,539 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.plan.exec.internal;
 
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockOptions;
 import org.hibernate.ScrollMode;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.pagination.LimitHandler;
 import org.hibernate.dialect.pagination.LimitHelper;
 import org.hibernate.dialect.pagination.NoopLimitHandler;
 import org.hibernate.engine.jdbc.ColumnNameCache;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.RowSelection;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.TypedValue;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.loader.plan.exec.query.spi.NamedParameterContext;
 import org.hibernate.loader.plan.exec.spi.LoadQueryDetails;
 import org.hibernate.loader.spi.AfterLoadAction;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.Type;
 
 /**
  * A superclass for loader implementations based on using LoadPlans.
  *
  * @see org.hibernate.loader.entity.plan.EntityLoader
  * @see org.hibernate.loader.collection.plan.CollectionLoader
 
  * @author Gail Badner
  */
 public abstract class AbstractLoadPlanBasedLoader {
 	private static final CoreMessageLogger log = CoreLogging.messageLogger( AbstractLoadPlanBasedLoader.class );
 
 	private final SessionFactoryImplementor factory;
 
 	private ColumnNameCache columnNameCache;
 
 	/**
 	 * Constructs a {@link AbstractLoadPlanBasedLoader}.
 	 *
 	 * @param factory The session factory
 	 * @see SessionFactoryImplementor
 	 */
 	public AbstractLoadPlanBasedLoader(
 			SessionFactoryImplementor factory) {
 		this.factory = factory;
 	}
 
 	protected SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	protected abstract LoadQueryDetails getStaticLoadQuery();
 
 	protected abstract int[] getNamedParameterLocs(String name);
 
 	protected abstract void autoDiscoverTypes(ResultSet rs);
 
 	protected List executeLoad(
 			SessionImplementor session,
 			QueryParameters queryParameters,
 			LoadQueryDetails loadQueryDetails,
 			boolean returnProxies,
 			ResultTransformer forcedResultTransformer) throws SQLException {
 		final List<AfterLoadAction> afterLoadActions = new ArrayList<AfterLoadAction>();
 		return executeLoad(
 				session,
 				queryParameters,
 				loadQueryDetails,
 				returnProxies,
 				forcedResultTransformer,
 				afterLoadActions
 		);
 	}
 
 	protected List executeLoad(
 			SessionImplementor session,
 			QueryParameters queryParameters,
 			LoadQueryDetails loadQueryDetails,
 			boolean returnProxies,
 			ResultTransformer forcedResultTransformer,
 			List<AfterLoadAction> afterLoadActions) throws SQLException {
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 		final boolean defaultReadOnlyOrig = persistenceContext.isDefaultReadOnly();
 		if ( queryParameters.isReadOnlyInitialized() ) {
 			// The read-only/modifiable mode for the query was explicitly set.
 			// Temporarily set the default read-only/modifiable setting to the query's setting.
 			persistenceContext.setDefaultReadOnly( queryParameters.isReadOnly() );
 		}
 		else {
 			// The read-only/modifiable setting for the query was not initialized.
 			// Use the default read-only/modifiable from the persistence context instead.
 			queryParameters.setReadOnly( persistenceContext.isDefaultReadOnly() );
 		}
 		persistenceContext.beforeLoad();
 		try {
 			List results = null;
 			final String sql = loadQueryDetails.getSqlStatement();
 			SqlStatementWrapper wrapper = null;
 			try {
 				wrapper = executeQueryStatement( sql, queryParameters, false, afterLoadActions, session );
 				results = loadQueryDetails.getResultSetProcessor().extractResults(
 						wrapper.getResultSet(),
 						session,
 						queryParameters,
 						new NamedParameterContext() {
 							@Override
 							public int[] getNamedParameterLocations(String name) {
 								return AbstractLoadPlanBasedLoader.this.getNamedParameterLocs( name );
 							}
 						},
 						returnProxies,
 						queryParameters.isReadOnly(),
 						forcedResultTransformer,
 						afterLoadActions
 				);
 			}
 			finally {
 				if ( wrapper != null ) {
-					session.getTransactionCoordinator().getJdbcCoordinator().release(
+					session.getJdbcCoordinator().getResourceRegistry().release(
 							wrapper.getResultSet(),
 							wrapper.getStatement()
 					);
-					session.getTransactionCoordinator().getJdbcCoordinator().release( wrapper.getStatement() );
+					session.getJdbcCoordinator().getResourceRegistry().release( wrapper.getStatement() );
+					session.getJdbcCoordinator().afterStatementExecution();
 				}
 				persistenceContext.afterLoad();
 			}
 			persistenceContext.initializeNonLazyCollections();
 			return results;
 		}
 		finally {
 			// Restore the original default
 			persistenceContext.setDefaultReadOnly( defaultReadOnlyOrig );
 		}
 	}
 
 	protected SqlStatementWrapper executeQueryStatement(
 			final QueryParameters queryParameters,
 			final boolean scroll,
 			List<AfterLoadAction> afterLoadActions,
 			final SessionImplementor session) throws SQLException {
 		return executeQueryStatement( getStaticLoadQuery().getSqlStatement(), queryParameters, scroll, afterLoadActions, session );
 	}
 
 	protected SqlStatementWrapper executeQueryStatement(
 			String sqlStatement,
 			QueryParameters queryParameters,
 			boolean scroll,
 			List<AfterLoadAction> afterLoadActions,
 			SessionImplementor session) throws SQLException {
 
 		// Processing query filters.
 		queryParameters.processFilters( sqlStatement, session );
 
 		// Applying LIMIT clause.
 		final LimitHandler limitHandler = getLimitHandler(
 				queryParameters.getRowSelection()
 		);
 		String sql = limitHandler.processSql( queryParameters.getFilteredSQL(), queryParameters.getRowSelection() );
 
 		// Adding locks and comments.
 		sql = preprocessSQL( sql, queryParameters, getFactory().getDialect(), afterLoadActions );
 
 		final PreparedStatement st = prepareQueryStatement( sql, queryParameters, limitHandler, scroll, session );
 		return new SqlStatementWrapper( st, getResultSet( st, queryParameters.getRowSelection(), limitHandler, queryParameters.hasAutoDiscoverScalarTypes(), session ) );
 	}
 
 	/**
 	 * Build LIMIT clause handler applicable for given selection criteria. Returns {@link org.hibernate.dialect.pagination.NoopLimitHandler} delegate
 	 * if dialect does not support LIMIT expression or processed query does not use pagination.
 	 *
 	 * @param selection Selection criteria.
 	 * @return LIMIT clause delegate.
 	 */
 	protected LimitHandler getLimitHandler(RowSelection selection) {
 		final LimitHandler limitHandler = getFactory().getDialect().getLimitHandler();
 		return LimitHelper.useLimit( limitHandler, selection ) ? limitHandler : NoopLimitHandler.INSTANCE;
 	}
 
 	private String preprocessSQL(
 			String sql,
 			QueryParameters queryParameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) {
 		return getFactory().getSettings().isCommentsEnabled()
 				? prependComment( sql, queryParameters )
 				: sql;
 	}
 
 	private String prependComment(String sql, QueryParameters parameters) {
 		final String comment = parameters.getComment();
 		if ( comment == null ) {
 			return sql;
 		}
 		else {
 			return "/* " + comment + " */ " + sql;
 		}
 	}
 
 	/**
 	 * Obtain a <tt>PreparedStatement</tt> with all parameters pre-bound.
 	 * Bind JDBC-style <tt>?</tt> parameters, named parameters, and
 	 * limit parameters.
 	 */
 	protected final PreparedStatement prepareQueryStatement(
 			final String sql,
 			final QueryParameters queryParameters,
 			final LimitHandler limitHandler,
 			final boolean scroll,
 			final SessionImplementor session) throws SQLException, HibernateException {
 		final Dialect dialect = getFactory().getDialect();
 		final RowSelection selection = queryParameters.getRowSelection();
 		final boolean useLimit = LimitHelper.useLimit( limitHandler, selection );
 		final boolean hasFirstRow = LimitHelper.hasFirstRow( selection );
 		final boolean useLimitOffset = hasFirstRow && useLimit && limitHandler.supportsLimitOffset();
 		final boolean callable = queryParameters.isCallable();
 		final ScrollMode scrollMode = getScrollMode( scroll, hasFirstRow, useLimitOffset, queryParameters );
 
-		final PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator()
+		final PreparedStatement st = session.getJdbcCoordinator()
 				.getStatementPreparer().prepareQueryStatement( sql, callable, scrollMode );
 
 		try {
 
 			int col = 1;
 			//TODO: can we limit stored procedures ?!
 			col += limitHandler.bindLimitParametersAtStartOfQuery( selection, st, col );
 
 			if (callable) {
 				col = dialect.registerResultSetOutParameter( (CallableStatement)st, col );
 			}
 
 			col += bindParameterValues( st, queryParameters, col, session );
 
 			col += limitHandler.bindLimitParametersAtEndOfQuery( selection, st, col );
 
 			limitHandler.setMaxRows( selection, st );
 
 			if ( selection != null ) {
 				if ( selection.getTimeout() != null ) {
 					st.setQueryTimeout( selection.getTimeout() );
 				}
 				if ( selection.getFetchSize() != null ) {
 					st.setFetchSize( selection.getFetchSize() );
 				}
 			}
 
 			// handle lock timeout...
 			final LockOptions lockOptions = queryParameters.getLockOptions();
 			if ( lockOptions != null ) {
 				if ( lockOptions.getTimeOut() != LockOptions.WAIT_FOREVER ) {
 					if ( !dialect.supportsLockTimeouts() ) {
 						if ( log.isDebugEnabled() ) {
 							log.debugf(
 									"Lock timeout [%s] requested but dialect reported to not support lock timeouts",
 									lockOptions.getTimeOut()
 							);
 						}
 					}
 					else if ( dialect.isLockTimeoutParameterized() ) {
 						st.setInt( col++, lockOptions.getTimeOut() );
 					}
 				}
 			}
 
 			if ( log.isTraceEnabled() ) {
 				log.tracev( "Bound [{0}] parameters total", col );
 			}
 		}
 		catch ( SQLException sqle ) {
-			session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+			session.getJdbcCoordinator().getResourceRegistry().release( st );
+			session.getJdbcCoordinator().afterStatementExecution();
 			throw sqle;
 		}
 		catch ( HibernateException he ) {
-			session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+			session.getJdbcCoordinator().getResourceRegistry().release( st );
+			session.getJdbcCoordinator().afterStatementExecution();
 			throw he;
 		}
 
 		return st;
 	}
 
 	protected ScrollMode getScrollMode(boolean scroll, boolean hasFirstRow, boolean useLimitOffSet, QueryParameters queryParameters) {
 		final boolean canScroll = getFactory().getSettings().isScrollableResultSetsEnabled();
 		if ( canScroll ) {
 			if ( scroll ) {
 				return queryParameters.getScrollMode();
 			}
 			if ( hasFirstRow && !useLimitOffSet ) {
 				return ScrollMode.SCROLL_INSENSITIVE;
 			}
 		}
 		return null;
 	}
 
 	/**
 	 * Bind all parameter values into the prepared statement in preparation
 	 * for execution.
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param queryParameters The encapsulation of the parameter values to be bound.
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
 	 * @return The number of JDBC bind positions actually bound during this method execution.
 	 * @throws SQLException Indicates problems performing the binding.
 	 */
 	protected int bindParameterValues(
 			PreparedStatement statement,
 			QueryParameters queryParameters,
 			int startIndex,
 			SessionImplementor session) throws SQLException {
 		int span = 0;
 		span += bindPositionalParameters( statement, queryParameters, startIndex, session );
 		span += bindNamedParameters( statement, queryParameters.getNamedParameters(), startIndex + span, session );
 		return span;
 	}
 
 	/**
 	 * Bind positional parameter values to the JDBC prepared statement.
 	 * <p/>
 	 * Positional parameters are those specified by JDBC-style ? parameters
 	 * in the source query.  It is (currently) expected that these come
 	 * before any named parameters in the source query.
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param queryParameters The encapsulation of the parameter values to be bound.
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
 	 * @return The number of JDBC bind positions actually bound during this method execution.
 	 * @throws SQLException Indicates problems performing the binding.
 	 * @throws org.hibernate.HibernateException Indicates problems delegating binding to the types.
 	 */
 	protected int bindPositionalParameters(
 			final PreparedStatement statement,
 			final QueryParameters queryParameters,
 			final int startIndex,
 			final SessionImplementor session) throws SQLException, HibernateException {
 		final Object[] values = queryParameters.getFilteredPositionalParameterValues();
 		final Type[] types = queryParameters.getFilteredPositionalParameterTypes();
 		int span = 0;
 		for ( int i = 0; i < values.length; i++ ) {
 			types[i].nullSafeSet( statement, values[i], startIndex + span, session );
 			span += types[i].getColumnSpan( getFactory() );
 		}
 		return span;
 	}
 
 	/**
 	 * Bind named parameters to the JDBC prepared statement.
 	 * <p/>
 	 * This is a generic implementation, the problem being that in the
 	 * general case we do not know enough information about the named
 	 * parameters to perform this in a complete manner here.  Thus this
 	 * is generally overridden on subclasses allowing named parameters to
 	 * apply the specific behavior.  The most usual limitation here is that
 	 * we need to assume the type span is always one...
 	 *
 	 * @param statement The JDBC prepared statement
 	 * @param namedParams A map of parameter names to values
 	 * @param startIndex The position from which to start binding parameter values.
 	 * @param session The originating session.
 	 * @return The number of JDBC bind positions actually bound during this method execution.
 	 * @throws SQLException Indicates problems performing the binding.
 	 * @throws org.hibernate.HibernateException Indicates problems delegating binding to the types.
 	 */
 	protected int bindNamedParameters(
 			final PreparedStatement statement,
 			final Map namedParams,
 			final int startIndex,
 			final SessionImplementor session) throws SQLException, HibernateException {
 		if ( namedParams != null ) {
 			// assumes that types are all of span 1
 			final Iterator itr = namedParams.entrySet().iterator();
 			final boolean debugEnabled = log.isDebugEnabled();
 			int result = 0;
 			while ( itr.hasNext() ) {
 				final Map.Entry e = (Map.Entry) itr.next();
 				final String name = (String) e.getKey();
 				final TypedValue typedval = (TypedValue) e.getValue();
 				final int[] locs = getNamedParameterLocs( name );
 				for ( int loc : locs ) {
 					if ( debugEnabled ) {
 						log.debugf(
 								"bindNamedParameters() %s -> %s [%s]",
 								typedval.getValue(),
 								name,
 								loc + startIndex
 						);
 					}
 					typedval.getType().nullSafeSet( statement, typedval.getValue(), loc + startIndex, session );
 				}
 				result += locs.length;
 			}
 			return result;
 		}
 		else {
 			return 0;
 		}
 	}
 
 	/**
 	 * Execute given <tt>PreparedStatement</tt>, advance to the first result and return SQL <tt>ResultSet</tt>.
 	 */
 	protected final ResultSet getResultSet(
 			final PreparedStatement st,
 			final RowSelection selection,
 			final LimitHandler limitHandler,
 			final boolean autodiscovertypes,
 			final SessionImplementor session)
 			throws SQLException, HibernateException {
 
 		try {
-			ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
+			ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 			rs = wrapResultSetIfEnabled( rs , session );
 
 			if ( !limitHandler.supportsLimitOffset() || !LimitHelper.useLimit( limitHandler, selection ) ) {
 				advance( rs, selection );
 			}
 
 			if ( autodiscovertypes ) {
 				autoDiscoverTypes( rs );
 			}
 			return rs;
 		}
 		catch ( SQLException sqle ) {
-			session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+			session.getJdbcCoordinator().getResourceRegistry().release( st );
+			session.getJdbcCoordinator().afterStatementExecution();
 			throw sqle;
 		}
 	}
 
 	/**
 	 * Advance the cursor to the first required row of the <tt>ResultSet</tt>
 	 */
 	protected void advance(final ResultSet rs, final RowSelection selection) throws SQLException {
 		final int firstRow = LimitHelper.getFirstRow( selection );
 		if ( firstRow != 0 ) {
 			if ( getFactory().getSettings().isScrollableResultSetsEnabled() ) {
 				// we can go straight to the first required row
 				rs.absolute( firstRow );
 			}
 			else {
 				// we need to step through the rows one row at a time (slow)
 				for ( int m = 0; m < firstRow; m++ ) {
 					rs.next();
 				}
 			}
 		}
 	}
 
 	private synchronized ResultSet wrapResultSetIfEnabled(final ResultSet rs, final SessionImplementor session) {
 		// synchronized to avoid multi-thread access issues; defined as method synch to avoid
 		// potential deadlock issues due to nature of code.
 		if ( session.getFactory().getSettings().isWrapResultSetsEnabled() ) {
 			try {
 				if ( log.isDebugEnabled() ) {
 					log.debugf( "Wrapping result set [%s]", rs );
 				}
 				return session.getFactory()
 						.getJdbcServices()
 						.getResultSetWrapper().wrap( rs, retreiveColumnNameToIndexCache( rs ) );
 			}
 			catch(SQLException e) {
 				log.unableToWrapResultSet( e );
 				return rs;
 			}
 		}
 		else {
 			return rs;
 		}
 	}
 
 	private ColumnNameCache retreiveColumnNameToIndexCache(ResultSet rs) throws SQLException {
 		if ( columnNameCache == null ) {
 			log.trace( "Building columnName->columnIndex cache" );
 			columnNameCache = new ColumnNameCache( rs.getMetaData().getColumnCount() );
 		}
 
 		return columnNameCache;
 	}
 
 	/**
 	 * Wrapper class for {@link java.sql.Statement} and associated {@link java.sql.ResultSet}.
 	 */
 	protected static class SqlStatementWrapper {
 		private final Statement statement;
 		private final ResultSet resultSet;
 
 		private SqlStatementWrapper(Statement statement, ResultSet resultSet) {
 			this.resultSet = resultSet;
 			this.statement = statement;
 		}
 
 		public ResultSet getResultSet() {
 			return resultSet;
 		}
 
 		public Statement getStatement() {
 			return statement;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
index a17567c3ce..802f944980 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
@@ -193,2061 +193,2068 @@ public abstract class AbstractCollectionPersister
 	private final boolean isPrimitiveArray;
 	private final boolean isArray;
 	protected final boolean hasIndex;
 	protected final boolean hasIdentifier;
 	private final boolean isLazy;
 	private final boolean isExtraLazy;
 	protected final boolean isInverse;
 	private final boolean isMutable;
 	private final boolean isVersioned;
 	protected final int batchSize;
 	private final FetchMode fetchMode;
 	private final boolean hasOrphanDelete;
 	private final boolean subselectLoadable;
 
 	// extra information about the element type
 	private final Class elementClass;
 	private final String entityName;
 
 	private final Dialect dialect;
 	protected final SqlExceptionHelper sqlExceptionHelper;
 	private final SessionFactoryImplementor factory;
 	private final EntityPersister ownerPersister;
 	private final IdentifierGenerator identifierGenerator;
 	private final PropertyMapping elementPropertyMapping;
 	private final EntityPersister elementPersister;
 	private final CollectionRegionAccessStrategy cacheAccessStrategy;
 	private final CollectionType collectionType;
 	private CollectionInitializer initializer;
 
 	private final CacheEntryStructure cacheEntryStructure;
 
 	// dynamic filters for the collection
 	private final FilterHelper filterHelper;
 
 	// dynamic filters specifically for many-to-many inside the collection
 	private final FilterHelper manyToManyFilterHelper;
 
 	private final String manyToManyWhereString;
 	private final String manyToManyWhereTemplate;
 
 	// custom sql
 	private final boolean insertCallable;
 	private final boolean updateCallable;
 	private final boolean deleteCallable;
 	private final boolean deleteAllCallable;
 	private ExecuteUpdateResultCheckStyle insertCheckStyle;
 	private ExecuteUpdateResultCheckStyle updateCheckStyle;
 	private ExecuteUpdateResultCheckStyle deleteCheckStyle;
 	private ExecuteUpdateResultCheckStyle deleteAllCheckStyle;
 
 	private final Serializable[] spaces;
 
 	private Map collectionPropertyColumnAliases = new HashMap();
 	private Map collectionPropertyColumnNames = new HashMap();
 
 	public AbstractCollectionPersister(
 			Collection collectionBinding,
 			CollectionRegionAccessStrategy cacheAccessStrategy,
 			PersisterCreationContext creationContext) throws MappingException, CacheException {
 
 		this.factory = creationContext.getSessionFactory();
 		this.cacheAccessStrategy = cacheAccessStrategy;
 		if ( factory.getSettings().isStructuredCacheEntriesEnabled() ) {
 			cacheEntryStructure = collectionBinding.isMap()
 					? StructuredMapCacheEntry.INSTANCE
 					: StructuredCollectionCacheEntry.INSTANCE;
 		}
 		else {
 			cacheEntryStructure = UnstructuredCacheEntry.INSTANCE;
 		}
 
 		dialect = factory.getDialect();
 		sqlExceptionHelper = factory.getSQLExceptionHelper();
 		collectionType = collectionBinding.getCollectionType();
 		role = collectionBinding.getRole();
 		entityName = collectionBinding.getOwnerEntityName();
 		ownerPersister = factory.getEntityPersister( entityName );
 		queryLoaderName = collectionBinding.getLoaderName();
 		nodeName = collectionBinding.getNodeName();
 		isMutable = collectionBinding.isMutable();
 		mappedByProperty = collectionBinding.getMappedByProperty();
 
 		Table table = collectionBinding.getCollectionTable();
 		fetchMode = collectionBinding.getElement().getFetchMode();
 		elementType = collectionBinding.getElement().getType();
 		// isSet = collectionBinding.isSet();
 		// isSorted = collectionBinding.isSorted();
 		isPrimitiveArray = collectionBinding.isPrimitiveArray();
 		isArray = collectionBinding.isArray();
 		subselectLoadable = collectionBinding.isSubselectLoadable();
 
 		qualifiedTableName = table.getQualifiedName(
 				dialect,
 				factory.getSettings().getDefaultCatalogName(),
 				factory.getSettings().getDefaultSchemaName()
 				);
 
 		int spacesSize = 1 + collectionBinding.getSynchronizedTables().size();
 		spaces = new String[spacesSize];
 		spaces[0] = qualifiedTableName;
 		Iterator iter = collectionBinding.getSynchronizedTables().iterator();
 		for ( int i = 1; i < spacesSize; i++ ) {
 			spaces[i] = (String) iter.next();
 		}
 
 		sqlWhereString = StringHelper.isNotEmpty( collectionBinding.getWhere() ) ? "( " + collectionBinding.getWhere() + ") " : null;
 		hasWhere = sqlWhereString != null;
 		sqlWhereStringTemplate = hasWhere ?
 				Template.renderWhereStringTemplate( sqlWhereString, dialect, factory.getSqlFunctionRegistry() ) :
 				null;
 
 		hasOrphanDelete = collectionBinding.hasOrphanDelete();
 
 		int batch = collectionBinding.getBatchSize();
 		if ( batch == -1 ) {
 			batch = factory.getSettings().getDefaultBatchFetchSize();
 		}
 		batchSize = batch;
 
 		isVersioned = collectionBinding.isOptimisticLocked();
 
 		// KEY
 
 		keyType = collectionBinding.getKey().getType();
 		iter = collectionBinding.getKey().getColumnIterator();
 		int keySpan = collectionBinding.getKey().getColumnSpan();
 		keyColumnNames = new String[keySpan];
 		keyColumnAliases = new String[keySpan];
 		int k = 0;
 		while ( iter.hasNext() ) {
 			// NativeSQL: collect key column and auto-aliases
 			Column col = ( (Column) iter.next() );
 			keyColumnNames[k] = col.getQuotedName( dialect );
 			keyColumnAliases[k] = col.getAlias( dialect, collectionBinding.getOwner().getRootTable() );
 			k++;
 		}
 
 		// unquotedKeyColumnNames = StringHelper.unQuote(keyColumnAliases);
 
 		// ELEMENT
 
 		String elemNode = collectionBinding.getElementNodeName();
 		if ( elementType.isEntityType() ) {
 			String entityName = ( (EntityType) elementType ).getAssociatedEntityName();
 			elementPersister = factory.getEntityPersister( entityName );
 			if ( elemNode == null ) {
 				elemNode = creationContext.getMetadata().getEntityBinding( entityName ).getNodeName();
 			}
 			// NativeSQL: collect element column and auto-aliases
 
 		}
 		else {
 			elementPersister = null;
 		}
 		elementNodeName = elemNode;
 
 		int elementSpan = collectionBinding.getElement().getColumnSpan();
 		elementColumnAliases = new String[elementSpan];
 		elementColumnNames = new String[elementSpan];
 		elementColumnWriters = new String[elementSpan];
 		elementColumnReaders = new String[elementSpan];
 		elementColumnReaderTemplates = new String[elementSpan];
 		elementFormulaTemplates = new String[elementSpan];
 		elementFormulas = new String[elementSpan];
 		elementColumnIsSettable = new boolean[elementSpan];
 		elementColumnIsInPrimaryKey = new boolean[elementSpan];
 		boolean isPureFormula = true;
 		boolean hasNotNullableColumns = false;
 		int j = 0;
 		iter = collectionBinding.getElement().getColumnIterator();
 		while ( iter.hasNext() ) {
 			Selectable selectable = (Selectable) iter.next();
 			elementColumnAliases[j] = selectable.getAlias( dialect, table );
 			if ( selectable.isFormula() ) {
 				Formula form = (Formula) selectable;
 				elementFormulaTemplates[j] = form.getTemplate( dialect, factory.getSqlFunctionRegistry() );
 				elementFormulas[j] = form.getFormula();
 			}
 			else {
 				Column col = (Column) selectable;
 				elementColumnNames[j] = col.getQuotedName( dialect );
 				elementColumnWriters[j] = col.getWriteExpr();
 				elementColumnReaders[j] = col.getReadExpr( dialect );
 				elementColumnReaderTemplates[j] = col.getTemplate( dialect, factory.getSqlFunctionRegistry() );
 				elementColumnIsSettable[j] = true;
 				elementColumnIsInPrimaryKey[j] = !col.isNullable();
 				if ( !col.isNullable() ) {
 					hasNotNullableColumns = true;
 				}
 				isPureFormula = false;
 			}
 			j++;
 		}
 		elementIsPureFormula = isPureFormula;
 
 		// workaround, for backward compatibility of sets with no
 		// not-null columns, assume all columns are used in the
 		// row locator SQL
 		if ( !hasNotNullableColumns ) {
 			Arrays.fill( elementColumnIsInPrimaryKey, true );
 		}
 
 		// INDEX AND ROW SELECT
 
 		hasIndex = collectionBinding.isIndexed();
 		if ( hasIndex ) {
 			// NativeSQL: collect index column and auto-aliases
 			IndexedCollection indexedCollection = (IndexedCollection) collectionBinding;
 			indexType = indexedCollection.getIndex().getType();
 			int indexSpan = indexedCollection.getIndex().getColumnSpan();
 			iter = indexedCollection.getIndex().getColumnIterator();
 			indexColumnNames = new String[indexSpan];
 			indexFormulaTemplates = new String[indexSpan];
 			indexFormulas = new String[indexSpan];
 			indexColumnIsSettable = new boolean[indexSpan];
 			indexColumnAliases = new String[indexSpan];
 			int i = 0;
 			boolean hasFormula = false;
 			while ( iter.hasNext() ) {
 				Selectable s = (Selectable) iter.next();
 				indexColumnAliases[i] = s.getAlias( dialect );
 				if ( s.isFormula() ) {
 					Formula indexForm = (Formula) s;
 					indexFormulaTemplates[i] = indexForm.getTemplate( dialect, factory.getSqlFunctionRegistry() );
 					indexFormulas[i] = indexForm.getFormula();
 					hasFormula = true;
 				}
 				else {
 					Column indexCol = (Column) s;
 					indexColumnNames[i] = indexCol.getQuotedName( dialect );
 					indexColumnIsSettable[i] = true;
 				}
 				i++;
 			}
 			indexContainsFormula = hasFormula;
 			baseIndex = indexedCollection.isList() ?
 					( (List) indexedCollection ).getBaseIndex() : 0;
 
 			indexNodeName = indexedCollection.getIndexNodeName();
 
 		}
 		else {
 			indexContainsFormula = false;
 			indexColumnIsSettable = null;
 			indexFormulaTemplates = null;
 			indexFormulas = null;
 			indexType = null;
 			indexColumnNames = null;
 			indexColumnAliases = null;
 			baseIndex = 0;
 			indexNodeName = null;
 		}
 
 		hasIdentifier = collectionBinding.isIdentified();
 		if ( hasIdentifier ) {
 			if ( collectionBinding.isOneToMany() ) {
 				throw new MappingException( "one-to-many collections with identifiers are not supported" );
 			}
 			IdentifierCollection idColl = (IdentifierCollection) collectionBinding;
 			identifierType = idColl.getIdentifier().getType();
 			iter = idColl.getIdentifier().getColumnIterator();
 			Column col = (Column) iter.next();
 			identifierColumnName = col.getQuotedName( dialect );
 			identifierColumnAlias = col.getAlias( dialect );
 			// unquotedIdentifierColumnName = identifierColumnAlias;
 			identifierGenerator = idColl.getIdentifier().createIdentifierGenerator(
 					creationContext.getMetadata().getIdentifierGeneratorFactory(),
 					factory.getDialect(),
 					factory.getSettings().getDefaultCatalogName(),
 					factory.getSettings().getDefaultSchemaName(),
 					null
 					);
 		}
 		else {
 			identifierType = null;
 			identifierColumnName = null;
 			identifierColumnAlias = null;
 			// unquotedIdentifierColumnName = null;
 			identifierGenerator = null;
 		}
 
 		// GENERATE THE SQL:
 
 		// sqlSelectString = sqlSelectString();
 		// sqlSelectRowString = sqlSelectRowString();
 
 		if ( collectionBinding.getCustomSQLInsert() == null ) {
 			sqlInsertRowString = generateInsertRowString();
 			insertCallable = false;
 			insertCheckStyle = ExecuteUpdateResultCheckStyle.COUNT;
 		}
 		else {
 			sqlInsertRowString = collectionBinding.getCustomSQLInsert();
 			insertCallable = collectionBinding.isCustomInsertCallable();
 			insertCheckStyle = collectionBinding.getCustomSQLInsertCheckStyle() == null
 					? ExecuteUpdateResultCheckStyle.determineDefault( collectionBinding.getCustomSQLInsert(), insertCallable )
 					: collectionBinding.getCustomSQLInsertCheckStyle();
 		}
 
 		if ( collectionBinding.getCustomSQLUpdate() == null ) {
 			sqlUpdateRowString = generateUpdateRowString();
 			updateCallable = false;
 			updateCheckStyle = ExecuteUpdateResultCheckStyle.COUNT;
 		}
 		else {
 			sqlUpdateRowString = collectionBinding.getCustomSQLUpdate();
 			updateCallable = collectionBinding.isCustomUpdateCallable();
 			updateCheckStyle = collectionBinding.getCustomSQLUpdateCheckStyle() == null
 					? ExecuteUpdateResultCheckStyle.determineDefault( collectionBinding.getCustomSQLUpdate(), insertCallable )
 					: collectionBinding.getCustomSQLUpdateCheckStyle();
 		}
 
 		if ( collectionBinding.getCustomSQLDelete() == null ) {
 			sqlDeleteRowString = generateDeleteRowString();
 			deleteCallable = false;
 			deleteCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 		else {
 			sqlDeleteRowString = collectionBinding.getCustomSQLDelete();
 			deleteCallable = collectionBinding.isCustomDeleteCallable();
 			deleteCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 
 		if ( collectionBinding.getCustomSQLDeleteAll() == null ) {
 			sqlDeleteString = generateDeleteString();
 			deleteAllCallable = false;
 			deleteAllCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 		else {
 			sqlDeleteString = collectionBinding.getCustomSQLDeleteAll();
 			deleteAllCallable = collectionBinding.isCustomDeleteAllCallable();
 			deleteAllCheckStyle = ExecuteUpdateResultCheckStyle.NONE;
 		}
 
 		sqlSelectSizeString = generateSelectSizeString( collectionBinding.isIndexed() && !collectionBinding.isMap() );
 		sqlDetectRowByIndexString = generateDetectRowByIndexString();
 		sqlDetectRowByElementString = generateDetectRowByElementString();
 		sqlSelectRowByIndexString = generateSelectRowByIndexString();
 
 		logStaticSQL();
 
 		isLazy = collectionBinding.isLazy();
 		isExtraLazy = collectionBinding.isExtraLazy();
 
 		isInverse = collectionBinding.isInverse();
 
 		if ( collectionBinding.isArray() ) {
 			elementClass = ( (org.hibernate.mapping.Array) collectionBinding ).getElementClass();
 		}
 		else {
 			// for non-arrays, we don't need to know the element class
 			elementClass = null; // elementType.returnedClass();
 		}
 
 		if ( elementType.isComponentType() ) {
 			elementPropertyMapping = new CompositeElementPropertyMapping(
 					elementColumnNames,
 					elementColumnReaders,
 					elementColumnReaderTemplates,
 					elementFormulaTemplates,
 					(CompositeType) elementType,
 					factory
 					);
 		}
 		else if ( !elementType.isEntityType() ) {
 			elementPropertyMapping = new ElementPropertyMapping(
 					elementColumnNames,
 					elementType
 					);
 		}
 		else {
 			if ( elementPersister instanceof PropertyMapping ) { // not all classpersisters implement PropertyMapping!
 				elementPropertyMapping = (PropertyMapping) elementPersister;
 			}
 			else {
 				elementPropertyMapping = new ElementPropertyMapping(
 						elementColumnNames,
 						elementType
 						);
 			}
 		}
 
 		hasOrder = collectionBinding.getOrderBy() != null;
 		if ( hasOrder ) {
 			orderByTranslation = Template.translateOrderBy(
 					collectionBinding.getOrderBy(),
 					new ColumnMapperImpl(),
 					factory,
 					dialect,
 					factory.getSqlFunctionRegistry()
 			);
 		}
 		else {
 			orderByTranslation = null;
 		}
 
 		// Handle any filters applied to this collectionBinding
 		filterHelper = new FilterHelper( collectionBinding.getFilters(), factory);
 
 		// Handle any filters applied to this collectionBinding for many-to-many
 		manyToManyFilterHelper = new FilterHelper( collectionBinding.getManyToManyFilters(), factory);
 		manyToManyWhereString = StringHelper.isNotEmpty( collectionBinding.getManyToManyWhere() ) ?
 				"( " + collectionBinding.getManyToManyWhere() + ")" :
 				null;
 		manyToManyWhereTemplate = manyToManyWhereString == null ?
 				null :
 				Template.renderWhereStringTemplate( manyToManyWhereString, factory.getDialect(), factory.getSqlFunctionRegistry() );
 
 		hasManyToManyOrder = collectionBinding.getManyToManyOrdering() != null;
 		if ( hasManyToManyOrder ) {
 			manyToManyOrderByTranslation = Template.translateOrderBy(
 					collectionBinding.getManyToManyOrdering(),
 					new ColumnMapperImpl(),
 					factory,
 					dialect,
 					factory.getSqlFunctionRegistry()
 			);
 		}
 		else {
 			manyToManyOrderByTranslation = null;
 		}
 
 		initCollectionPropertyMap();
 	}
 
 	private class ColumnMapperImpl implements ColumnMapper {
 		@Override
 		public SqlValueReference[] map(String reference) {
 			final String[] columnNames;
 			final String[] formulaTemplates;
 
 			// handle the special "$element$" property name...
 			if ( "$element$".equals( reference ) ) {
 				columnNames = elementColumnNames;
 				formulaTemplates = elementFormulaTemplates;
 			}
 			else {
 				columnNames = elementPropertyMapping.toColumns( reference );
 				formulaTemplates = formulaTemplates( reference, columnNames.length );
 			}
 
 			final SqlValueReference[] result = new SqlValueReference[ columnNames.length ];
 			int i = 0;
 			for ( final String columnName : columnNames ) {
 				if ( columnName == null ) {
 					// if the column name is null, it indicates that this index in the property value mapping is
 					// actually represented by a formula.
 //					final int propertyIndex = elementPersister.getEntityMetamodel().getPropertyIndex( reference );
 					final String formulaTemplate = formulaTemplates[i];
 					result[i] = new FormulaReference() {
 						@Override
 						public String getFormulaFragment() {
 							return formulaTemplate;
 						}
 					};
 				}
 				else {
 					result[i] = new ColumnReference() {
 						@Override
 						public String getColumnName() {
 							return columnName;
 						}
 					};
 				}
 				i++;
 			}
 			return result;
 		}
 	}
 
 	private String[] formulaTemplates(String reference, int expectedSize) {
 		try {
 			final int propertyIndex = elementPersister.getEntityMetamodel().getPropertyIndex( reference );
 			return  ( (Queryable) elementPersister ).getSubclassPropertyFormulaTemplateClosure()[propertyIndex];
 		}
 		catch (Exception e) {
 			return new String[expectedSize];
 		}
 	}
 
 	@Override
 	public void postInstantiate() throws MappingException {
 		initializer = queryLoaderName == null ?
 				createCollectionInitializer( LoadQueryInfluencers.NONE ) :
 				new NamedQueryCollectionInitializer( queryLoaderName, this );
 	}
 
 	protected void logStaticSQL() {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "Static SQL for collection: %s", getRole() );
 			if ( getSQLInsertRowString() != null ) LOG.debugf( " Row insert: %s", getSQLInsertRowString() );
 			if ( getSQLUpdateRowString() != null ) LOG.debugf( " Row update: %s", getSQLUpdateRowString() );
 			if ( getSQLDeleteRowString() != null ) LOG.debugf( " Row delete: %s", getSQLDeleteRowString() );
 			if ( getSQLDeleteString() != null ) LOG.debugf( " One-shot delete: %s", getSQLDeleteString() );
 		}
 	}
 
 	@Override
 	public void initialize(Serializable key, SessionImplementor session) throws HibernateException {
 		getAppropriateInitializer( key, session ).initialize( key, session );
 	}
 
 	protected CollectionInitializer getAppropriateInitializer(Serializable key, SessionImplementor session) {
 		if ( queryLoaderName != null ) {
 			// if there is a user-specified loader, return that
 			// TODO: filters!?
 			return initializer;
 		}
 		CollectionInitializer subselectInitializer = getSubselectInitializer( key, session );
 		if ( subselectInitializer != null ) {
 			return subselectInitializer;
 		}
 		else if ( session.getEnabledFilters().isEmpty() ) {
 			return initializer;
 		}
 		else {
 			return createCollectionInitializer( session.getLoadQueryInfluencers() );
 		}
 	}
 
 	private CollectionInitializer getSubselectInitializer(Serializable key, SessionImplementor session) {
 
 		if ( !isSubselectLoadable() ) {
 			return null;
 		}
 
 		final PersistenceContext persistenceContext = session.getPersistenceContext();
 
 		SubselectFetch subselect = persistenceContext.getBatchFetchQueue()
 				.getSubselect( session.generateEntityKey( key, getOwnerEntityPersister() ) );
 
 		if ( subselect == null ) {
 			return null;
 		}
 		else {
 
 			// Take care of any entities that might have
 			// been evicted!
 			Iterator iter = subselect.getResult().iterator();
 			while ( iter.hasNext() ) {
 				if ( !persistenceContext.containsEntity( (EntityKey) iter.next() ) ) {
 					iter.remove();
 				}
 			}
 
 			// Run a subquery loader
 			return createSubselectInitializer( subselect, session );
 		}
 	}
 
 	protected abstract CollectionInitializer createSubselectInitializer(SubselectFetch subselect, SessionImplementor session);
 
 	protected abstract CollectionInitializer createCollectionInitializer(LoadQueryInfluencers loadQueryInfluencers)
 			throws MappingException;
 
 	@Override
 	public CollectionRegionAccessStrategy getCacheAccessStrategy() {
 		return cacheAccessStrategy;
 	}
 
 	@Override
 	public boolean hasCache() {
 		return cacheAccessStrategy != null;
 	}
 
 	@Override
 	public CollectionType getCollectionType() {
 		return collectionType;
 	}
 
 	protected String getSQLWhereString(String alias) {
 		return StringHelper.replace( sqlWhereStringTemplate, Template.TEMPLATE, alias );
 	}
 
 	@Override
 	public String getSQLOrderByString(String alias) {
 		return hasOrdering()
 				? orderByTranslation.injectAliases( new StandardOrderByAliasResolver( alias ) )
 				: "";
 	}
 
 	@Override
 	public String getManyToManyOrderByString(String alias) {
 		return hasManyToManyOrdering()
 				? manyToManyOrderByTranslation.injectAliases( new StandardOrderByAliasResolver( alias ) )
 				: "";
 	}
 
 	@Override
 	public FetchMode getFetchMode() {
 		return fetchMode;
 	}
 
 	@Override
 	public boolean hasOrdering() {
 		return hasOrder;
 	}
 
 	@Override
 	public boolean hasManyToManyOrdering() {
 		return isManyToMany() && hasManyToManyOrder;
 	}
 
 	@Override
 	public boolean hasWhere() {
 		return hasWhere;
 	}
 
 	protected String getSQLDeleteString() {
 		return sqlDeleteString;
 	}
 
 	protected String getSQLInsertRowString() {
 		return sqlInsertRowString;
 	}
 
 	protected String getSQLUpdateRowString() {
 		return sqlUpdateRowString;
 	}
 
 	protected String getSQLDeleteRowString() {
 		return sqlDeleteRowString;
 	}
 
 	@Override
 	public Type getKeyType() {
 		return keyType;
 	}
 
 	@Override
 	public Type getIndexType() {
 		return indexType;
 	}
 
 	@Override
 	public Type getElementType() {
 		return elementType;
 	}
 
 	/**
 	 * Return the element class of an array, or null otherwise.  needed by arrays
 	 */
 	@Override
 	public Class getElementClass() {
 		return elementClass;
 	}
 
 	@Override
 	public Object readElement(ResultSet rs, Object owner, String[] aliases, SessionImplementor session)
 			throws HibernateException, SQLException {
 		return getElementType().nullSafeGet( rs, aliases, session, owner );
 	}
 
 	@Override
 	public Object readIndex(ResultSet rs, String[] aliases, SessionImplementor session)
 			throws HibernateException, SQLException {
 		Object index = getIndexType().nullSafeGet( rs, aliases, session, null );
 		if ( index == null ) {
 			throw new HibernateException( "null index column for collection: " + role );
 		}
 		index = decrementIndexByBase( index );
 		return index;
 	}
 
 	protected Object decrementIndexByBase(Object index) {
 		if ( baseIndex != 0 ) {
             index = (Integer)index - baseIndex;
 		}
 		return index;
 	}
 
 	@Override
 	public Object readIdentifier(ResultSet rs, String alias, SessionImplementor session)
 			throws HibernateException, SQLException {
 		Object id = getIdentifierType().nullSafeGet( rs, alias, session, null );
 		if ( id == null ) {
 			throw new HibernateException( "null identifier column for collection: " + role );
 		}
 		return id;
 	}
 
 	@Override
 	public Object readKey(ResultSet rs, String[] aliases, SessionImplementor session)
 			throws HibernateException, SQLException {
 		return getKeyType().nullSafeGet( rs, aliases, session, null );
 	}
 
 	/**
 	 * Write the key to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeKey(PreparedStatement st, Serializable key, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 
 		if ( key == null ) {
 			throw new NullPointerException( "null key for collection: " + role ); // an assertion
 		}
 		getKeyType().nullSafeSet( st, key, i, session );
 		return i + keyColumnAliases.length;
 	}
 
 	/**
 	 * Write the element to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeElement(PreparedStatement st, Object elt, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		getElementType().nullSafeSet( st, elt, i, elementColumnIsSettable, session );
 		return i + ArrayHelper.countTrue( elementColumnIsSettable );
 
 	}
 
 	/**
 	 * Write the index to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeIndex(PreparedStatement st, Object index, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		getIndexType().nullSafeSet( st, incrementIndexByBase( index ), i, indexColumnIsSettable, session );
 		return i + ArrayHelper.countTrue( indexColumnIsSettable );
 	}
 
 	protected Object incrementIndexByBase(Object index) {
 		if ( baseIndex != 0 ) {
             index = (Integer)index + baseIndex;
 		}
 		return index;
 	}
 
 	/**
 	 * Write the element to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeElementToWhere(PreparedStatement st, Object elt, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		if ( elementIsPureFormula ) {
 			throw new AssertionFailure( "cannot use a formula-based element in the where condition" );
 		}
 		getElementType().nullSafeSet( st, elt, i, elementColumnIsInPrimaryKey, session );
 		return i + elementColumnAliases.length;
 
 	}
 
 	/**
 	 * Write the index to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeIndexToWhere(PreparedStatement st, Object index, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		if ( indexContainsFormula ) {
 			throw new AssertionFailure( "cannot use a formula-based index in the where condition" );
 		}
 		getIndexType().nullSafeSet( st, incrementIndexByBase( index ), i, session );
 		return i + indexColumnAliases.length;
 	}
 
 	/**
 	 * Write the identifier to a JDBC <tt>PreparedStatement</tt>
 	 */
 	public int writeIdentifier(PreparedStatement st, Object id, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 
 		getIdentifierType().nullSafeSet( st, id, i, session );
 		return i + 1;
 	}
 
 	@Override
 	public boolean isPrimitiveArray() {
 		return isPrimitiveArray;
 	}
 
 	@Override
 	public boolean isArray() {
 		return isArray;
 	}
 
 	@Override
 	public String[] getKeyColumnAliases(String suffix) {
 		return new Alias( suffix ).toAliasStrings( keyColumnAliases );
 	}
 
 	@Override
 	public String[] getElementColumnAliases(String suffix) {
 		return new Alias( suffix ).toAliasStrings( elementColumnAliases );
 	}
 
 	@Override
 	public String[] getIndexColumnAliases(String suffix) {
 		if ( hasIndex ) {
 			return new Alias( suffix ).toAliasStrings( indexColumnAliases );
 		}
 		else {
 			return null;
 		}
 	}
 
 	@Override
 	public String getIdentifierColumnAlias(String suffix) {
 		if ( hasIdentifier ) {
 			return new Alias( suffix ).toAliasString( identifierColumnAlias );
 		}
 		else {
 			return null;
 		}
 	}
 
 	@Override
 	public String getIdentifierColumnName() {
 		if ( hasIdentifier ) {
 			return identifierColumnName;
 		}
 		else {
 			return null;
 		}
 	}
 
 	/**
 	 * Generate a list of collection index, key and element columns
 	 */
 	@Override
 	public String selectFragment(String alias, String columnSuffix) {
 		SelectFragment frag = generateSelectFragment( alias, columnSuffix );
 		appendElementColumns( frag, alias );
 		appendIndexColumns( frag, alias );
 		appendIdentifierColumns( frag, alias );
 
 		return frag.toFragmentString()
 				.substring( 2 ); // strip leading ','
 	}
 
 	protected String generateSelectSizeString(boolean isIntegerIndexed) {
 		String selectValue = isIntegerIndexed ?
 				"max(" + getIndexColumnNames()[0] + ") + 1" : // lists, arrays
 				"count(" + getElementColumnNames()[0] + ")"; // sets, maps, bags
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addColumn( selectValue )
 				.toStatementString();
 	}
 
 	protected String generateDetectRowByIndexString() {
 		if ( !hasIndex() ) {
 			return null;
 		}
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getIndexColumnNames(), "=?" )
 				.addCondition( indexFormulas, "=?" )
 				.addColumn( "1" )
 				.toStatementString();
 	}
 
 	protected String generateSelectRowByIndexString() {
 		if ( !hasIndex() ) {
 			return null;
 		}
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getIndexColumnNames(), "=?" )
 				.addCondition( indexFormulas, "=?" )
 				.addColumns( getElementColumnNames(), elementColumnAliases )
 				.addColumns( indexFormulas, indexColumnAliases )
 				.toStatementString();
 	}
 
 	protected String generateDetectRowByElementString() {
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getElementColumnNames(), "=?" )
 				.addCondition( elementFormulas, "=?" )
 				.addColumn( "1" )
 				.toStatementString();
 	}
 
 	protected SelectFragment generateSelectFragment(String alias, String columnSuffix) {
 		return new SelectFragment()
 				.setSuffix( columnSuffix )
 				.addColumns( alias, keyColumnNames, keyColumnAliases );
 	}
 
 	protected void appendElementColumns(SelectFragment frag, String elemAlias) {
 		for ( int i = 0; i < elementColumnIsSettable.length; i++ ) {
 			if ( elementColumnIsSettable[i] ) {
 				frag.addColumnTemplate( elemAlias, elementColumnReaderTemplates[i], elementColumnAliases[i] );
 			}
 			else {
 				frag.addFormula( elemAlias, elementFormulaTemplates[i], elementColumnAliases[i] );
 			}
 		}
 	}
 
 	protected void appendIndexColumns(SelectFragment frag, String alias) {
 		if ( hasIndex ) {
 			for ( int i = 0; i < indexColumnIsSettable.length; i++ ) {
 				if ( indexColumnIsSettable[i] ) {
 					frag.addColumn( alias, indexColumnNames[i], indexColumnAliases[i] );
 				}
 				else {
 					frag.addFormula( alias, indexFormulaTemplates[i], indexColumnAliases[i] );
 				}
 			}
 		}
 	}
 
 	protected void appendIdentifierColumns(SelectFragment frag, String alias) {
 		if ( hasIdentifier ) {
 			frag.addColumn( alias, identifierColumnName, identifierColumnAlias );
 		}
 	}
 
 	@Override
 	public String[] getIndexColumnNames() {
 		return indexColumnNames;
 	}
 
 	@Override
 	public String[] getIndexFormulas() {
 		return indexFormulas;
 	}
 
 	@Override
 	public String[] getIndexColumnNames(String alias) {
 		return qualify( alias, indexColumnNames, indexFormulaTemplates );
 	}
 
 	@Override
 	public String[] getElementColumnNames(String alias) {
 		return qualify( alias, elementColumnNames, elementFormulaTemplates );
 	}
 
 	private static String[] qualify(String alias, String[] columnNames, String[] formulaTemplates) {
 		int span = columnNames.length;
 		String[] result = new String[span];
 		for ( int i = 0; i < span; i++ ) {
 			if ( columnNames[i] == null ) {
 				result[i] = StringHelper.replace( formulaTemplates[i], Template.TEMPLATE, alias );
 			}
 			else {
 				result[i] = StringHelper.qualify( alias, columnNames[i] );
 			}
 		}
 		return result;
 	}
 
 	@Override
 	public String[] getElementColumnNames() {
 		return elementColumnNames; // TODO: something with formulas...
 	}
 
 	@Override
 	public String[] getKeyColumnNames() {
 		return keyColumnNames;
 	}
 
 	@Override
 	public boolean hasIndex() {
 		return hasIndex;
 	}
 
 	@Override
 	public boolean isLazy() {
 		return isLazy;
 	}
 
 	@Override
 	public boolean isInverse() {
 		return isInverse;
 	}
 
 	@Override
 	public String getTableName() {
 		return qualifiedTableName;
 	}
 
 	private BasicBatchKey removeBatchKey;
 
 	@Override
 	public void remove(Serializable id, SessionImplementor session) throws HibernateException {
 		if ( !isInverse && isRowDeleteEnabled() ) {
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Deleting collection: %s",
 						MessageHelper.collectionInfoString( this, id, getFactory() ) );
 			}
 
 			// Remove all the old entries
 
 			try {
 				int offset = 1;
 				PreparedStatement st = null;
 				Expectation expectation = Expectations.appropriateExpectation( getDeleteAllCheckStyle() );
 				boolean callable = isDeleteAllCallable();
 				boolean useBatch = expectation.canBeBatched();
 				String sql = getSQLDeleteString();
 				if ( useBatch ) {
 					if ( removeBatchKey == null ) {
 						removeBatchKey = new BasicBatchKey(
 								getRole() + "#REMOVE",
 								expectation
 								);
 					}
-					st = session.getTransactionCoordinator()
+					st = session
 							.getJdbcCoordinator()
 							.getBatch( removeBatchKey )
 							.getBatchStatement( sql, callable );
 				}
 				else {
-					st = session.getTransactionCoordinator()
+					st = session
 							.getJdbcCoordinator()
 							.getStatementPreparer()
 							.prepareStatement( sql, callable );
 				}
 
 				try {
 					offset += expectation.prepare( st );
 
 					writeKey( st, id, offset, session );
 					if ( useBatch ) {
-						session.getTransactionCoordinator()
+						session
 								.getJdbcCoordinator()
 								.getBatch( removeBatchKey )
 								.addToBatch();
 					}
 					else {
-						expectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
+						expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 					}
 				}
 				catch ( SQLException sqle ) {
 					if ( useBatch ) {
-						session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
+						session.getJdbcCoordinator().abortBatch();
 					}
 					throw sqle;
 				}
 				finally {
 					if ( !useBatch ) {
-						session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+						session.getJdbcCoordinator().getResourceRegistry().release( st );
+						session.getJdbcCoordinator().afterStatementExecution();
 					}
 				}
 
 				LOG.debug( "Done deleting collection" );
 			}
 			catch ( SQLException sqle ) {
 				throw sqlExceptionHelper.convert(
 						sqle,
 						"could not delete collection: " +
 								MessageHelper.collectionInfoString( this, id, getFactory() ),
 						getSQLDeleteString()
 						);
 			}
 
 		}
 
 	}
 
 	protected BasicBatchKey recreateBatchKey;
 
 	@Override
 	public void recreate(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( isInverse ) {
 			return;
 		}
 
 		if ( !isRowInsertEnabled() ) {
 			return;
 		}
 
 
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"Inserting collection: %s",
 					MessageHelper.collectionInfoString( this, collection, id, session )
 			);
 		}
 
 		try {
 			// create all the new entries
 			Iterator entries = collection.entries( this );
 			if ( entries.hasNext() ) {
 				Expectation expectation = Expectations.appropriateExpectation( getInsertCheckStyle() );
 				collection.preInsert( this );
 				int i = 0;
 				int count = 0;
 				while ( entries.hasNext() ) {
 
 					final Object entry = entries.next();
 					if ( collection.entryExists( entry, i ) ) {
 						int offset = 1;
 						PreparedStatement st = null;
 						boolean callable = isInsertCallable();
 						boolean useBatch = expectation.canBeBatched();
 						String sql = getSQLInsertRowString();
 
 						if ( useBatch ) {
 							if ( recreateBatchKey == null ) {
 								recreateBatchKey = new BasicBatchKey(
 										getRole() + "#RECREATE",
 										expectation
 								);
 							}
-							st = session.getTransactionCoordinator()
+							st = session
 									.getJdbcCoordinator()
 									.getBatch( recreateBatchKey )
 									.getBatchStatement( sql, callable );
 						}
 						else {
-							st = session.getTransactionCoordinator()
+							st = session
 									.getJdbcCoordinator()
 									.getStatementPreparer()
 									.prepareStatement( sql, callable );
 						}
 
 						try {
 							offset += expectation.prepare( st );
 
 							// TODO: copy/paste from insertRows()
 							int loc = writeKey( st, id, offset, session );
 							if ( hasIdentifier ) {
 								loc = writeIdentifier( st, collection.getIdentifier( entry, i ), loc, session );
 							}
 							if ( hasIndex /* && !indexIsFormula */) {
 								loc = writeIndex( st, collection.getIndex( entry, i, this ), loc, session );
 							}
 							loc = writeElement( st, collection.getElement( entry ), loc, session );
 
 							if ( useBatch ) {
-								session.getTransactionCoordinator()
+								session
 										.getJdbcCoordinator()
 										.getBatch( recreateBatchKey )
 										.addToBatch();
 							}
 							else {
-								expectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
+								expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 							}
 
 							collection.afterRowInsert( this, entry, i );
 							count++;
 						}
 						catch ( SQLException sqle ) {
 							if ( useBatch ) {
-								session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
+								session.getJdbcCoordinator().abortBatch();
 							}
 							throw sqle;
 						}
 						finally {
 							if ( !useBatch ) {
-								session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+								session.getJdbcCoordinator().getResourceRegistry().release( st );
+								session.getJdbcCoordinator().afterStatementExecution();
 							}
 						}
 
 					}
 					i++;
 				}
 
 				LOG.debugf( "Done inserting collection: %s rows inserted", count );
 
 			}
 			else {
 				LOG.debug( "Collection was empty" );
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw sqlExceptionHelper.convert(
 					sqle,
 					"could not insert collection: " +
 							MessageHelper.collectionInfoString( this, collection, id, session ),
 					getSQLInsertRowString()
 			);
 		}
 	}
 
 	protected boolean isRowDeleteEnabled() {
 		return true;
 	}
 
 	private BasicBatchKey deleteBatchKey;
 
 	@Override
 	public void deleteRows(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( isInverse ) {
 			return;
 		}
 
 		if ( !isRowDeleteEnabled() ) {
 			return;
 		}
 
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"Deleting rows of collection: %s",
 					MessageHelper.collectionInfoString( this, collection, id, session )
 			);
 		}
 
 		boolean deleteByIndex = !isOneToMany() && hasIndex && !indexContainsFormula;
 		final Expectation expectation = Expectations.appropriateExpectation( getDeleteCheckStyle() );
 		try {
 			// delete all the deleted entries
 			Iterator deletes = collection.getDeletes( this, !deleteByIndex );
 			if ( deletes.hasNext() ) {
 				int offset = 1;
 				int count = 0;
 				while ( deletes.hasNext() ) {
 					PreparedStatement st = null;
 					boolean callable = isDeleteCallable();
 					boolean useBatch = expectation.canBeBatched();
 					String sql = getSQLDeleteRowString();
 
 					if ( useBatch ) {
 						if ( deleteBatchKey == null ) {
 							deleteBatchKey = new BasicBatchKey(
 									getRole() + "#DELETE",
 									expectation
 									);
 						}
-						st = session.getTransactionCoordinator()
+						st = session
 								.getJdbcCoordinator()
 								.getBatch( deleteBatchKey )
 								.getBatchStatement( sql, callable );
 					}
 					else {
-						st = session.getTransactionCoordinator()
+						st = session
 								.getJdbcCoordinator()
 								.getStatementPreparer()
 								.prepareStatement( sql, callable );
 					}
 
 					try {
 						expectation.prepare( st );
 
 						Object entry = deletes.next();
 						int loc = offset;
 						if ( hasIdentifier ) {
 							writeIdentifier( st, entry, loc, session );
 						}
 						else {
 							loc = writeKey( st, id, loc, session );
 							if ( deleteByIndex ) {
 								writeIndexToWhere( st, entry, loc, session );
 							}
 							else {
 								writeElementToWhere( st, entry, loc, session );
 							}
 						}
 
 						if ( useBatch ) {
-							session.getTransactionCoordinator()
+							session
 									.getJdbcCoordinator()
 									.getBatch( deleteBatchKey )
 									.addToBatch();
 						}
 						else {
-							expectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
+							expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 						}
 						count++;
 					}
 					catch ( SQLException sqle ) {
 						if ( useBatch ) {
-							session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
+							session.getJdbcCoordinator().abortBatch();
 						}
 						throw sqle;
 					}
 					finally {
 						if ( !useBatch ) {
-							session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+							session.getJdbcCoordinator().getResourceRegistry().release( st );
+							session.getJdbcCoordinator().afterStatementExecution();
 						}
 					}
 
 					LOG.debugf( "Done deleting collection rows: %s deleted", count );
 				}
 			}
 			else {
 				LOG.debug( "No rows to delete" );
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw sqlExceptionHelper.convert(
 					sqle,
 					"could not delete collection rows: " +
 							MessageHelper.collectionInfoString( this, collection, id, session ),
 					getSQLDeleteRowString()
 			);
 		}
 	}
 
 	protected boolean isRowInsertEnabled() {
 		return true;
 	}
 
 	private BasicBatchKey insertBatchKey;
 
 	@Override
 	public void insertRows(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( isInverse ) {
 			return;
 		}
 
 		if ( !isRowInsertEnabled() ) {
 			return;
 		}
 
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf(
 					"Inserting rows of collection: %s",
 					MessageHelper.collectionInfoString( this, collection, id, session )
 			);
 		}
 
 		try {
 			// insert all the new entries
 			collection.preInsert( this );
 			Iterator entries = collection.entries( this );
 			Expectation expectation = Expectations.appropriateExpectation( getInsertCheckStyle() );
 			boolean callable = isInsertCallable();
 			boolean useBatch = expectation.canBeBatched();
 			String sql = getSQLInsertRowString();
 			int i = 0;
 			int count = 0;
 			while ( entries.hasNext() ) {
 				int offset = 1;
 				Object entry = entries.next();
 				PreparedStatement st = null;
 				if ( collection.needsInserting( entry, i, elementType ) ) {
 
 					if ( useBatch ) {
 						if ( insertBatchKey == null ) {
 							insertBatchKey = new BasicBatchKey(
 									getRole() + "#INSERT",
 									expectation
 									);
 						}
 						if ( st == null ) {
-							st = session.getTransactionCoordinator()
+							st = session
 									.getJdbcCoordinator()
 									.getBatch( insertBatchKey )
 									.getBatchStatement( sql, callable );
 						}
 					}
 					else {
-						st = session.getTransactionCoordinator()
+						st = session
 								.getJdbcCoordinator()
 								.getStatementPreparer()
 								.prepareStatement( sql, callable );
 					}
 
 					try {
 						offset += expectation.prepare( st );
 						// TODO: copy/paste from recreate()
 						offset = writeKey( st, id, offset, session );
 						if ( hasIdentifier ) {
 							offset = writeIdentifier( st, collection.getIdentifier( entry, i ), offset, session );
 						}
 						if ( hasIndex /* && !indexIsFormula */) {
 							offset = writeIndex( st, collection.getIndex( entry, i, this ), offset, session );
 						}
 						writeElement( st, collection.getElement( entry ), offset, session );
 
 						if ( useBatch ) {
-							session.getTransactionCoordinator().getJdbcCoordinator().getBatch( insertBatchKey ).addToBatch();
+							session.getJdbcCoordinator().getBatch( insertBatchKey ).addToBatch();
 						}
 						else {
-							expectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
+							expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 						}
 						collection.afterRowInsert( this, entry, i );
 						count++;
 					}
 					catch ( SQLException sqle ) {
 						if ( useBatch ) {
-							session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
+							session.getJdbcCoordinator().abortBatch();
 						}
 						throw sqle;
 					}
 					finally {
 						if ( !useBatch ) {
-							session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+							session.getJdbcCoordinator().getResourceRegistry().release( st );
+							session.getJdbcCoordinator().afterStatementExecution();
 						}
 					}
 				}
 				i++;
 			}
 			LOG.debugf( "Done inserting rows: %s inserted", count );
 		}
 		catch ( SQLException sqle ) {
 			throw sqlExceptionHelper.convert(
 					sqle,
 					"could not insert collection rows: " +
 							MessageHelper.collectionInfoString( this, collection, id, session ),
 					getSQLInsertRowString()
 			);
 		}
 	}
 
 	@Override
 	public String getRole() {
 		return role;
 	}
 
 	public String getOwnerEntityName() {
 		return entityName;
 	}
 
 	@Override
 	public EntityPersister getOwnerEntityPersister() {
 		return ownerPersister;
 	}
 
 	@Override
 	public IdentifierGenerator getIdentifierGenerator() {
 		return identifierGenerator;
 	}
 
 	@Override
 	public Type getIdentifierType() {
 		return identifierType;
 	}
 
 	@Override
 	public boolean hasOrphanDelete() {
 		return hasOrphanDelete;
 	}
 
 	@Override
 	public Type toType(String propertyName) throws QueryException {
 		if ( "index".equals( propertyName ) ) {
 			return indexType;
 		}
 		return elementPropertyMapping.toType( propertyName );
 	}
 
 	@Override
 	public abstract boolean isManyToMany();
 
 	@Override
 	public String getManyToManyFilterFragment(String alias, Map enabledFilters) {
 		StringBuilder buffer = new StringBuilder();
 		manyToManyFilterHelper.render( buffer, elementPersister.getFilterAliasGenerator(alias), enabledFilters );
 
 		if ( manyToManyWhereString != null ) {
 			buffer.append( " and " )
 					.append( StringHelper.replace( manyToManyWhereTemplate, Template.TEMPLATE, alias ) );
 		}
 
 		return buffer.toString();
 	}
 
 	@Override
 	public String[] toColumns(String alias, String propertyName) throws QueryException {
 		if ( "index".equals( propertyName ) ) {
 			return qualify( alias, indexColumnNames, indexFormulaTemplates );
 		}
 		return elementPropertyMapping.toColumns( alias, propertyName );
 	}
 
 	private String[] indexFragments;
 
 	@Override
 	public String[] toColumns(String propertyName) throws QueryException {
 		if ( "index".equals( propertyName ) ) {
 			if ( indexFragments == null ) {
 				String[] tmp = new String[indexColumnNames.length];
 				for ( int i = 0; i < indexColumnNames.length; i++ ) {
 					tmp[i] = indexColumnNames[i] == null
 							? indexFormulas[i]
 							: indexColumnNames[i];
 					indexFragments = tmp;
 				}
 			}
 			return indexFragments;
 		}
 
 		return elementPropertyMapping.toColumns( propertyName );
 	}
 
 	@Override
 	public Type getType() {
 		return elementPropertyMapping.getType(); // ==elementType ??
 	}
 
 	@Override
 	public String getName() {
 		return getRole();
 	}
 
 	@Override
 	public EntityPersister getElementPersister() {
 		if ( elementPersister == null ) {
 			throw new AssertionFailure( "not an association" );
 		}
 		return elementPersister;
 	}
 
 	@Override
 	public boolean isCollection() {
 		return true;
 	}
 
 	@Override
 	public Serializable[] getCollectionSpaces() {
 		return spaces;
 	}
 
 	protected abstract String generateDeleteString();
 
 	protected abstract String generateDeleteRowString();
 
 	protected abstract String generateUpdateRowString();
 
 	protected abstract String generateInsertRowString();
 
 	@Override
 	public void updateRows(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( !isInverse && collection.isRowUpdatePossible() ) {
 
 			LOG.debugf( "Updating rows of collection: %s#%s", role, id );
 
 			// update all the modified entries
 			int count = doUpdateRows( id, collection, session );
 
 			LOG.debugf( "Done updating rows: %s updated", count );
 		}
 	}
 
 	protected abstract int doUpdateRows(Serializable key, PersistentCollection collection, SessionImplementor session)
 			throws HibernateException;
 
 	@Override
 	public void processQueuedOps(PersistentCollection collection, Serializable key, SessionImplementor session)
 			throws HibernateException {
 		if ( collection.hasQueuedOperations() ) {
 			doProcessQueuedOps( collection, key, session );
 		}
 	}
 
 	/**
 	 * Process queued operations within the PersistentCollection.
 	 *
 	 * @param collection The collection
 	 * @param key The collection key
 	 * @param nextIndex The next index to write
 	 * @param session The session
 	 * @throws HibernateException
 	 *
 	 * @deprecated Use {@link #doProcessQueuedOps(org.hibernate.collection.spi.PersistentCollection, java.io.Serializable, org.hibernate.engine.spi.SessionImplementor)}
 	 */
 	@Deprecated
 	protected void doProcessQueuedOps(PersistentCollection collection, Serializable key,
 			int nextIndex, SessionImplementor session)
 			throws HibernateException {
 		doProcessQueuedOps( collection, key, session );
 	}
 
 	protected abstract void doProcessQueuedOps(PersistentCollection collection, Serializable key, SessionImplementor session)
 			throws HibernateException;
 
 	@Override
 	public CollectionMetadata getCollectionMetadata() {
 		return this;
 	}
 
 	@Override
 	public SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	protected String filterFragment(String alias) throws MappingException {
 		return hasWhere() ? " and " + getSQLWhereString( alias ) : "";
 	}
 
 	protected String filterFragment(String alias, Set<String> treatAsDeclarations) throws MappingException {
 		return hasWhere() ? " and " + getSQLWhereString( alias ) : "";
 	}
 
 	@Override
 	public String filterFragment(String alias, Map enabledFilters) throws MappingException {
 		StringBuilder sessionFilterFragment = new StringBuilder();
 		filterHelper.render( sessionFilterFragment, getFilterAliasGenerator(alias), enabledFilters );
 
 		return sessionFilterFragment.append( filterFragment( alias ) ).toString();
 	}
 
 	@Override
 	public String filterFragment(
 			String alias,
 			Map enabledFilters,
 			Set<String> treatAsDeclarations) {
 		StringBuilder sessionFilterFragment = new StringBuilder();
 		filterHelper.render( sessionFilterFragment, getFilterAliasGenerator(alias), enabledFilters );
 
 		return sessionFilterFragment.append( filterFragment( alias, treatAsDeclarations ) ).toString();
 	}
 
 	@Override
 	public String oneToManyFilterFragment(String alias) throws MappingException {
 		return "";
 	}
 
 	@Override
 	public String oneToManyFilterFragment(String alias, Set<String> treatAsDeclarations) {
 		return oneToManyFilterFragment( alias );
 	}
 
 	protected boolean isInsertCallable() {
 		return insertCallable;
 	}
 
 	protected ExecuteUpdateResultCheckStyle getInsertCheckStyle() {
 		return insertCheckStyle;
 	}
 
 	protected boolean isUpdateCallable() {
 		return updateCallable;
 	}
 
 	protected ExecuteUpdateResultCheckStyle getUpdateCheckStyle() {
 		return updateCheckStyle;
 	}
 
 	protected boolean isDeleteCallable() {
 		return deleteCallable;
 	}
 
 	protected ExecuteUpdateResultCheckStyle getDeleteCheckStyle() {
 		return deleteCheckStyle;
 	}
 
 	protected boolean isDeleteAllCallable() {
 		return deleteAllCallable;
 	}
 
 	protected ExecuteUpdateResultCheckStyle getDeleteAllCheckStyle() {
 		return deleteAllCheckStyle;
 	}
 
 	@Override
 	public String toString() {
 		return StringHelper.unqualify( getClass().getName() ) + '(' + role + ')';
 	}
 
 	@Override
 	public boolean isVersioned() {
 		return isVersioned && getOwnerEntityPersister().isVersioned();
 	}
 
 	@Override
 	public String getNodeName() {
 		return nodeName;
 	}
 
 	@Override
 	public String getElementNodeName() {
 		return elementNodeName;
 	}
 
 	@Override
 	public String getIndexNodeName() {
 		return indexNodeName;
 	}
 
 	// TODO: deprecate???
 	protected SQLExceptionConverter getSQLExceptionConverter() {
 		return getSQLExceptionHelper().getSqlExceptionConverter();
 	}
 
 	// TODO: needed???
 	protected SqlExceptionHelper getSQLExceptionHelper() {
 		return sqlExceptionHelper;
 	}
 
 	@Override
 	public CacheEntryStructure getCacheEntryStructure() {
 		return cacheEntryStructure;
 	}
 
 	@Override
 	public boolean isAffectedByEnabledFilters(SessionImplementor session) {
 		return filterHelper.isAffectedBy( session.getEnabledFilters() ) ||
 				( isManyToMany() && manyToManyFilterHelper.isAffectedBy( session.getEnabledFilters() ) );
 	}
 
 	public boolean isSubselectLoadable() {
 		return subselectLoadable;
 	}
 
 	@Override
 	public boolean isMutable() {
 		return isMutable;
 	}
 
 	@Override
 	public String[] getCollectionPropertyColumnAliases(String propertyName, String suffix) {
 		String[] rawAliases = (String[]) collectionPropertyColumnAliases.get( propertyName );
 
 		if ( rawAliases == null ) {
 			return null;
 		}
 
 		String[] result = new String[rawAliases.length];
 		for ( int i = 0; i < rawAliases.length; i++ ) {
 			result[i] = new Alias( suffix ).toUnquotedAliasString( rawAliases[i] );
 		}
 		return result;
 	}
 
 	// TODO: formulas ?
 	public void initCollectionPropertyMap() {
 
 		initCollectionPropertyMap( "key", keyType, keyColumnAliases, keyColumnNames );
 		initCollectionPropertyMap( "element", elementType, elementColumnAliases, elementColumnNames );
 		if ( hasIndex ) {
 			initCollectionPropertyMap( "index", indexType, indexColumnAliases, indexColumnNames );
 		}
 		if ( hasIdentifier ) {
 			initCollectionPropertyMap(
 					"id",
 					identifierType,
 					new String[] { identifierColumnAlias },
 					new String[] { identifierColumnName } );
 		}
 	}
 
 	private void initCollectionPropertyMap(String aliasName, Type type, String[] columnAliases, String[] columnNames) {
 
 		collectionPropertyColumnAliases.put( aliasName, columnAliases );
 		collectionPropertyColumnNames.put( aliasName, columnNames );
 
 		if ( type.isComponentType() ) {
 			CompositeType ct = (CompositeType) type;
 			String[] propertyNames = ct.getPropertyNames();
 			for ( int i = 0; i < propertyNames.length; i++ ) {
 				String name = propertyNames[i];
 				collectionPropertyColumnAliases.put( aliasName + "." + name, columnAliases[i] );
 				collectionPropertyColumnNames.put( aliasName + "." + name, columnNames[i] );
 			}
 		}
 
 	}
 
 	@Override
 	public int getSize(Serializable key, SessionImplementor session) {
 		try {
-			PreparedStatement st = session.getTransactionCoordinator()
+			PreparedStatement st = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( sqlSelectSizeString );
 			try {
 				getKeyType().nullSafeSet( st, key, 1, session );
-				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
+				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
 					return rs.next() ? rs.getInt( 1 ) - baseIndex : 0;
 				}
 				finally {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
+					session.getJdbcCoordinator().getResourceRegistry().release( rs, st );
 				}
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+				session.getJdbcCoordinator().getResourceRegistry().release( st );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw getSQLExceptionHelper().convert(
 					sqle,
 					"could not retrieve collection size: " +
 							MessageHelper.collectionInfoString( this, key, getFactory() ),
 					sqlSelectSizeString
 			);
 		}
 	}
 
 	@Override
 	public boolean indexExists(Serializable key, Object index, SessionImplementor session) {
 		return exists( key, incrementIndexByBase( index ), getIndexType(), sqlDetectRowByIndexString, session );
 	}
 
 	@Override
 	public boolean elementExists(Serializable key, Object element, SessionImplementor session) {
 		return exists( key, element, getElementType(), sqlDetectRowByElementString, session );
 	}
 
 	private boolean exists(Serializable key, Object indexOrElement, Type indexOrElementType, String sql, SessionImplementor session) {
 		try {
-			PreparedStatement st = session.getTransactionCoordinator()
+			PreparedStatement st = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( sql );
 			try {
 				getKeyType().nullSafeSet( st, key, 1, session );
 				indexOrElementType.nullSafeSet( st, indexOrElement, keyColumnNames.length + 1, session );
-				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
+				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
 					return rs.next();
 				}
 				finally {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
+					session.getJdbcCoordinator().getResourceRegistry().release( rs, st );
 				}
 			}
 			catch ( TransientObjectException e ) {
 				return false;
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+				session.getJdbcCoordinator().getResourceRegistry().release( st );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw getSQLExceptionHelper().convert(
 					sqle,
 					"could not check row existence: " +
 							MessageHelper.collectionInfoString( this, key, getFactory() ),
 					sqlSelectSizeString
 			);
 		}
 	}
 
 	@Override
 	public Object getElementByIndex(Serializable key, Object index, SessionImplementor session, Object owner) {
 		try {
-			PreparedStatement st = session.getTransactionCoordinator()
+			PreparedStatement st = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( sqlSelectRowByIndexString );
 			try {
 				getKeyType().nullSafeSet( st, key, 1, session );
 				getIndexType().nullSafeSet( st, incrementIndexByBase( index ), keyColumnNames.length + 1, session );
-				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
+				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
 					if ( rs.next() ) {
 						return getElementType().nullSafeGet( rs, elementColumnAliases, session, owner );
 					}
 					else {
 						return null;
 					}
 				}
 				finally {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
+					session.getJdbcCoordinator().getResourceRegistry().release( rs, st );
 				}
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+				session.getJdbcCoordinator().getResourceRegistry().release( st );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw getSQLExceptionHelper().convert(
 					sqle,
 					"could not read row: " +
 							MessageHelper.collectionInfoString( this, key, getFactory() ),
 					sqlSelectSizeString
 			);
 		}
 	}
 
 	@Override
 	public boolean isExtraLazy() {
 		return isExtraLazy;
 	}
 
 	protected Dialect getDialect() {
 		return dialect;
 	}
 
 	/**
 	 * Intended for internal use only. In fact really only currently used from
 	 * test suite for assertion purposes.
 	 *
 	 * @return The default collection initializer for this persister/collection.
 	 */
 	public CollectionInitializer getInitializer() {
 		return initializer;
 	}
 
 	@Override
 	public int getBatchSize() {
 		return batchSize;
 	}
 
 	@Override
 	public String getMappedByProperty() {
 		return mappedByProperty;
 	}
 
 	private class StandardOrderByAliasResolver implements OrderByAliasResolver {
 		private final String rootAlias;
 
 		private StandardOrderByAliasResolver(String rootAlias) {
 			this.rootAlias = rootAlias;
 		}
 
 		@Override
 		public String resolveTableAlias(String columnReference) {
 			if ( elementPersister == null ) {
 				// we have collection of non-entity elements...
 				return rootAlias;
 			}
 			else {
 				return ( (Loadable) elementPersister ).getTableAliasForColumn( columnReference, rootAlias );
 			}
 		}
 	}
 
 	public abstract FilterAliasGenerator getFilterAliasGenerator(final String rootAlias);
 
 	// ColectionDefinition impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public CollectionPersister getCollectionPersister() {
 		return this;
 	}
 
 	@Override
 	public CollectionIndexDefinition getIndexDefinition() {
 		if ( ! hasIndex() ) {
 			return null;
 		}
 
 		return new CollectionIndexDefinition() {
 			@Override
 			public CollectionDefinition getCollectionDefinition() {
 				return AbstractCollectionPersister.this;
 			}
 
 			@Override
 			public Type getType() {
 				return getIndexType();
 			}
 
 			@Override
 			public EntityDefinition toEntityDefinition() {
 				if ( !getType().isEntityType() ) {
 					throw new IllegalStateException( "Cannot treat collection index type as entity" );
 				}
 				return (EntityPersister) ( (AssociationType) getIndexType() ).getAssociatedJoinable( getFactory() );
 			}
 
 			@Override
 			public CompositionDefinition toCompositeDefinition() {
 				if ( ! getType().isComponentType() ) {
 					throw new IllegalStateException( "Cannot treat collection index type as composite" );
 				}
 				return new CompositeCollectionElementDefinition() {
 					@Override
 					public String getName() {
 						return "index";
 					}
 
 					@Override
 					public CompositeType getType() {
 						return (CompositeType) getIndexType();
 					}
 
 					@Override
 					public boolean isNullable() {
 						return false;
 					}
 
 					@Override
 					public AttributeSource getSource() {
 						// TODO: what if this is a collection w/in an encapsulated composition attribute?
 						// should return the encapsulated composition attribute instead???
 						return getOwnerEntityPersister();
 					}
 
 					@Override
 					public Iterable<AttributeDefinition> getAttributes() {
 						return CompositionSingularSubAttributesHelper.getCompositeCollectionIndexSubAttributes( this );
 					}
 					@Override
 					public CollectionDefinition getCollectionDefinition() {
 						return AbstractCollectionPersister.this;
 					}
 				};
 			}
 
 			@Override
 			public AnyMappingDefinition toAnyMappingDefinition() {
 				final Type type = getType();
 				if ( ! type.isAnyType() ) {
 					throw new IllegalStateException( "Cannot treat collection index type as ManyToAny" );
 				}
 				return new StandardAnyTypeDefinition( (AnyType) type, isLazy() || isExtraLazy() );
 			}
 		};
 	}
 
 	@Override
 	public CollectionElementDefinition getElementDefinition() {
 		return new CollectionElementDefinition() {
 			@Override
 			public CollectionDefinition getCollectionDefinition() {
 				return AbstractCollectionPersister.this;
 			}
 
 			@Override
 			public Type getType() {
 				return getElementType();
 			}
 
 			@Override
 			public AnyMappingDefinition toAnyMappingDefinition() {
 				final Type type = getType();
 				if ( ! type.isAnyType() ) {
 					throw new IllegalStateException( "Cannot treat collection element type as ManyToAny" );
 				}
 				return new StandardAnyTypeDefinition( (AnyType) type, isLazy() || isExtraLazy() );
 			}
 
 			@Override
 			public EntityDefinition toEntityDefinition() {
 				if ( !getType().isEntityType() ) {
 					throw new IllegalStateException( "Cannot treat collection element type as entity" );
 				}
 				return getElementPersister();
 			}
 
 			@Override
 			public CompositeCollectionElementDefinition toCompositeElementDefinition() {
 
 				if ( ! getType().isComponentType() ) {
 					throw new IllegalStateException( "Cannot treat entity collection element type as composite" );
 				}
 
 				return new CompositeCollectionElementDefinition() {
 					@Override
 					public String getName() {
 						return "";
 					}
 
 					@Override
 					public CompositeType getType() {
 						return (CompositeType) getElementType();
 					}
 
 					@Override
 					public boolean isNullable() {
 						return false;
 					}
 
 					@Override
 					public AttributeSource getSource() {
 						// TODO: what if this is a collection w/in an encapsulated composition attribute?
 						// should return the encapsulated composition attribute instead???
 						return getOwnerEntityPersister();
 					}
 
 					@Override
 					public Iterable<AttributeDefinition> getAttributes() {
 						return CompositionSingularSubAttributesHelper.getCompositeCollectionElementSubAttributes( this );
 					}
 
 					@Override
 					public CollectionDefinition getCollectionDefinition() {
 						return AbstractCollectionPersister.this;
 					}
 				};
 			}
 		};
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/BasicCollectionPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/BasicCollectionPersister.java
index 6cbeadf9cc..396a111558 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/BasicCollectionPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/BasicCollectionPersister.java
@@ -1,383 +1,384 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.collection;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Iterator;
 import java.util.Set;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.SubselectFetch;
 import org.hibernate.internal.FilterAliasGenerator;
 import org.hibernate.internal.StaticFilterAliasGenerator;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.loader.collection.BatchingCollectionInitializerBuilder;
 import org.hibernate.loader.collection.CollectionInitializer;
 import org.hibernate.loader.collection.SubselectCollectionLoader;
 import org.hibernate.mapping.Collection;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Delete;
 import org.hibernate.sql.Insert;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.Update;
 import org.hibernate.type.AssociationType;
 
 /**
  * Collection persister for collections of values and many-to-many associations.
  *
  * @author Gavin King
  */
 public class BasicCollectionPersister extends AbstractCollectionPersister {
 
 	public boolean isCascadeDeleteEnabled() {
 		return false;
 	}
 
 	public BasicCollectionPersister(
 			Collection collectionBinding,
 			CollectionRegionAccessStrategy cacheAccessStrategy,
 			PersisterCreationContext creationContext) throws MappingException, CacheException {
 		super( collectionBinding, cacheAccessStrategy, creationContext );
 	}
 
 	/**
 	 * Generate the SQL DELETE that deletes all rows
 	 */
 	@Override
     protected String generateDeleteString() {
 		
 		Delete delete = new Delete()
 				.setTableName( qualifiedTableName )
 				.addPrimaryKeyColumns( keyColumnNames );
 		
 		if ( hasWhere ) delete.setWhere( sqlWhereString );
 		
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			delete.setComment( "delete collection " + getRole() );
 		}
 		
 		return delete.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL INSERT that creates a new row
 	 */
 	@Override
     protected String generateInsertRowString() {
 		
 		Insert insert = new Insert( getDialect() )
 				.setTableName( qualifiedTableName )
 				.addColumns( keyColumnNames );
 		
 		if ( hasIdentifier) insert.addColumn( identifierColumnName );
 		
 		if ( hasIndex /*&& !indexIsFormula*/ ) {
 			insert.addColumns( indexColumnNames, indexColumnIsSettable );
 		}
 		
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			insert.setComment( "insert collection row " + getRole() );
 		}
 		
 		//if ( !elementIsFormula ) {
 			insert.addColumns( elementColumnNames, elementColumnIsSettable, elementColumnWriters );
 		//}
 		
 		return insert.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that updates a row
 	 */
 	@Override
     protected String generateUpdateRowString() {
 		
 		Update update = new Update( getDialect() )
 			.setTableName( qualifiedTableName );
 		
 		//if ( !elementIsFormula ) {
 			update.addColumns( elementColumnNames, elementColumnIsSettable, elementColumnWriters );
 		//}
 		
 		if ( hasIdentifier ) {
 			update.addPrimaryKeyColumns( new String[]{ identifierColumnName } );
 		}
 		else if ( hasIndex && !indexContainsFormula ) {
 			update.addPrimaryKeyColumns( ArrayHelper.join( keyColumnNames, indexColumnNames ) );
 		}
 		else {
 			update.addPrimaryKeyColumns( keyColumnNames );
 			update.addPrimaryKeyColumns( elementColumnNames, elementColumnIsInPrimaryKey, elementColumnWriters );
 		}
 		
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			update.setComment( "update collection row " + getRole() );
 		}
 		
 		return update.toStatementString();
 	}
 	
 	@Override
 	protected void doProcessQueuedOps(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 		// nothing to do
 	}
 
 	/**
 	 * Generate the SQL DELETE that deletes a particular row
 	 */
 	@Override
     protected String generateDeleteRowString() {
 		
 		Delete delete = new Delete()
 			.setTableName( qualifiedTableName );
 		
 		if ( hasIdentifier ) {
 			delete.addPrimaryKeyColumns( new String[]{ identifierColumnName } );
 		}
 		else if ( hasIndex && !indexContainsFormula ) {
 			delete.addPrimaryKeyColumns( ArrayHelper.join( keyColumnNames, indexColumnNames ) );
 		}
 		else {
 			delete.addPrimaryKeyColumns( keyColumnNames );
 			delete.addPrimaryKeyColumns( elementColumnNames, elementColumnIsInPrimaryKey, elementColumnWriters );
 		}
 		
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			delete.setComment( "delete collection row " + getRole() );
 		}
 		
 		return delete.toStatementString();
 	}
 
 	public boolean consumesEntityAlias() {
 		return false;
 	}
 
 	public boolean consumesCollectionAlias() {
 //		return !isOneToMany();
 		return true;
 	}
 
 	public boolean isOneToMany() {
 		return false;
 	}
 
 	@Override
     public boolean isManyToMany() {
 		return elementType.isEntityType(); //instanceof AssociationType;
 	}
 
 	private BasicBatchKey updateBatchKey;
 
 	@Override
     protected int doUpdateRows(Serializable id, PersistentCollection collection, SessionImplementor session)
 			throws HibernateException {
 		
 		if ( ArrayHelper.isAllFalse(elementColumnIsSettable) ) return 0;
 
 		try {
 			PreparedStatement st = null;
 			Expectation expectation = Expectations.appropriateExpectation( getUpdateCheckStyle() );
 			boolean callable = isUpdateCallable();
 			boolean useBatch = expectation.canBeBatched();
 			Iterator entries = collection.entries( this );
 			String sql = getSQLUpdateRowString();
 			int i = 0;
 			int count = 0;
 			while ( entries.hasNext() ) {
 				Object entry = entries.next();
 				if ( collection.needsUpdating( entry, i, elementType ) ) {
 					int offset = 1;
 
 					if ( useBatch ) {
 						if ( updateBatchKey == null ) {
 							updateBatchKey = new BasicBatchKey(
 									getRole() + "#UPDATE",
 									expectation
 							);
 						}
-						st = session.getTransactionCoordinator()
+						st = session
 								.getJdbcCoordinator()
 								.getBatch( updateBatchKey )
 								.getBatchStatement( sql, callable );
 					}
 					else {
-						st = session.getTransactionCoordinator()
+						st = session
 								.getJdbcCoordinator()
 								.getStatementPreparer()
 								.prepareStatement( sql, callable );
 					}
 
 					try {
 						offset+= expectation.prepare( st );
 						int loc = writeElement( st, collection.getElement( entry ), offset, session );
 						if ( hasIdentifier ) {
 							writeIdentifier( st, collection.getIdentifier( entry, i ), loc, session );
 						}
 						else {
 							loc = writeKey( st, id, loc, session );
 							if ( hasIndex && !indexContainsFormula ) {
 								writeIndexToWhere( st, collection.getIndex( entry, i, this ), loc, session );
 							}
 							else {
 								writeElementToWhere( st, collection.getSnapshotElement( entry, i ), loc, session );
 							}
 						}
 
 						if ( useBatch ) {
-							session.getTransactionCoordinator()
+							session
 									.getJdbcCoordinator()
 									.getBatch( updateBatchKey )
 									.addToBatch();
 						}
 						else {
-							expectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
+							expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 						}
 					}
 					catch ( SQLException sqle ) {
 						if ( useBatch ) {
-							session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
+							session.getJdbcCoordinator().abortBatch();
 						}
 						throw sqle;
 					}
 					finally {
 						if ( !useBatch ) {
-							session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+							session.getJdbcCoordinator().getResourceRegistry().release( st );
+							session.getJdbcCoordinator().afterStatementExecution();
 						}
 					}
 					count++;
 				}
 				i++;
 			}
 			return count;
 		}
 		catch ( SQLException sqle ) {
 			throw getSQLExceptionHelper().convert(
 					sqle,
 					"could not update collection rows: " + MessageHelper.collectionInfoString( this, collection, id, session ),
 					getSQLUpdateRowString()
 				);
 		}
 	}
 
 	public String selectFragment(
 	        Joinable rhs,
 	        String rhsAlias,
 	        String lhsAlias,
 	        String entitySuffix,
 	        String collectionSuffix,
 	        boolean includeCollectionColumns) {
 		// we need to determine the best way to know that two joinables
 		// represent a single many-to-many...
 		if ( rhs != null && isManyToMany() && !rhs.isCollection() ) {
 			AssociationType elementType = ( ( AssociationType ) getElementType() );
 			if ( rhs.equals( elementType.getAssociatedJoinable( getFactory() ) ) ) {
 				return manyToManySelectFragment( rhs, rhsAlias, lhsAlias, collectionSuffix );
 			}
 		}
 		return includeCollectionColumns ? selectFragment( lhsAlias, collectionSuffix ) : "";
 	}
 
 	private String manyToManySelectFragment(
 	        Joinable rhs,
 	        String rhsAlias,
 	        String lhsAlias,
 	        String collectionSuffix) {
 		SelectFragment frag = generateSelectFragment( lhsAlias, collectionSuffix );
 
 		String[] elementColumnNames = rhs.getKeyColumnNames();
 		frag.addColumns( rhsAlias, elementColumnNames, elementColumnAliases );
 		appendIndexColumns( frag, lhsAlias );
 		appendIdentifierColumns( frag, lhsAlias );
 
 		return frag.toFragmentString()
 				.substring( 2 ); //strip leading ','
 	}
 
 	/**
 	 * Create the <tt>CollectionLoader</tt>
 	 *
 	 * @see org.hibernate.loader.collection.BasicCollectionLoader
 	 */
 	@Override
     protected CollectionInitializer createCollectionInitializer(LoadQueryInfluencers loadQueryInfluencers)
 			throws MappingException {
 		return BatchingCollectionInitializerBuilder.getBuilder( getFactory() )
 				.createBatchingCollectionInitializer( this, batchSize, getFactory(), loadQueryInfluencers );
 	}
 
 	@Override
 	public String fromJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		return "";
 	}
 
 	@Override
 	public String fromJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses, Set<String> treatAsDeclarations) {
 		return "";
 	}
 
 	@Override
 	public String whereJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		return "";
 	}
 
 	@Override
 	public String whereJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses, Set<String> treatAsDeclarations) {
 		return "";
 	}
 
 	@Override
     protected CollectionInitializer createSubselectInitializer(SubselectFetch subselect, SessionImplementor session) {
 		return new SubselectCollectionLoader( 
 				this,
 				subselect.toSubselectString( getCollectionType().getLHSPropertyName() ),
 				subselect.getResult(),
 				subselect.getQueryParameters(),
 				subselect.getNamedParameterLocMap(),
 				session.getFactory(),
 				session.getLoadQueryInfluencers() 
 		);
 	}
 
 	@Override
 	public FilterAliasGenerator getFilterAliasGenerator(String rootAlias) {
 		return new StaticFilterAliasGenerator(rootAlias);
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/OneToManyPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/OneToManyPersister.java
index f26a4e7694..9532169fe1 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/OneToManyPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/OneToManyPersister.java
@@ -1,559 +1,562 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.persister.collection;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Iterator;
 import java.util.Set;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.cache.CacheException;
 import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.SubselectFetch;
 import org.hibernate.internal.FilterAliasGenerator;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.loader.collection.BatchingCollectionInitializerBuilder;
 import org.hibernate.loader.collection.CollectionInitializer;
 import org.hibernate.loader.collection.SubselectOneToManyLoader;
 import org.hibernate.loader.entity.CollectionElementLoader;
 import org.hibernate.mapping.Collection;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.sql.Update;
 
 /**
  * Collection persister for one-to-many associations.
  *
  * @author Gavin King
  * @author Brett Meyer
  */
 public class OneToManyPersister extends AbstractCollectionPersister {
 
 	private final boolean cascadeDeleteEnabled;
 	private final boolean keyIsNullable;
 	private final boolean keyIsUpdateable;
 
 	@Override
     protected boolean isRowDeleteEnabled() {
 		return keyIsUpdateable && keyIsNullable;
 	}
 
 	@Override
     protected boolean isRowInsertEnabled() {
 		return keyIsUpdateable;
 	}
 
 	public boolean isCascadeDeleteEnabled() {
 		return cascadeDeleteEnabled;
 	}
 
 	public OneToManyPersister(
 			Collection collectionBinding,
 			CollectionRegionAccessStrategy cacheAccessStrategy,
 			PersisterCreationContext creationContext) throws MappingException, CacheException {
 		super( collectionBinding, cacheAccessStrategy, creationContext );
 		cascadeDeleteEnabled = collectionBinding.getKey().isCascadeDeleteEnabled()
 				&& creationContext.getSessionFactory().getDialect().supportsCascadeDelete();
 		keyIsNullable = collectionBinding.getKey().isNullable();
 		keyIsUpdateable = collectionBinding.getKey().isUpdateable();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that updates all the foreign keys to null
 	 */
 	@Override
     protected String generateDeleteString() {
 		
 		Update update = new Update( getDialect() )
 				.setTableName( qualifiedTableName )
 				.addColumns( keyColumnNames, "null" )
 				.addPrimaryKeyColumns( keyColumnNames );
 		
 		if ( hasIndex && !indexContainsFormula ) update.addColumns( indexColumnNames, "null" );
 		
 		if ( hasWhere ) update.setWhere( sqlWhereString );
 		
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			update.setComment( "delete one-to-many " + getRole() );
 		}
 		
 		return update.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that updates a foreign key to a value
 	 */
 	@Override
     protected String generateInsertRowString() {
 		
 		Update update = new Update( getDialect() )
 				.setTableName( qualifiedTableName )
 				.addColumns( keyColumnNames );
 		
 		if ( hasIndex && !indexContainsFormula ) update.addColumns( indexColumnNames );
 		
 		//identifier collections not supported for 1-to-many
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			update.setComment( "create one-to-many row " + getRole() );
 		}
 		
 		return update.addPrimaryKeyColumns( elementColumnNames, elementColumnWriters )
 				.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that inserts a collection index
 	 */
 	@Override
     protected String generateUpdateRowString() {
 		Update update = new Update( getDialect() ).setTableName( qualifiedTableName );
 		update.addPrimaryKeyColumns( elementColumnNames, elementColumnIsSettable, elementColumnWriters );
 		if ( hasIdentifier ) {
 			update.addPrimaryKeyColumns( new String[]{ identifierColumnName } );
 		}
 		if ( hasIndex && !indexContainsFormula ) {
 			update.addColumns( indexColumnNames );
 		}
 		
 		return update.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL UPDATE that updates a particular row's foreign
 	 * key to null
 	 */
 	@Override
     protected String generateDeleteRowString() {
 		
 		Update update = new Update( getDialect() )
 				.setTableName( qualifiedTableName )
 				.addColumns( keyColumnNames, "null" );
 		
 		if ( hasIndex && !indexContainsFormula ) update.addColumns( indexColumnNames, "null" );
 		
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			update.setComment( "delete one-to-many row " + getRole() );
 		}
 		
 		//use a combination of foreign key columns and pk columns, since
 		//the ordering of removal and addition is not guaranteed when
 		//a child moves from one parent to another
 		String[] rowSelectColumnNames = ArrayHelper.join( keyColumnNames, elementColumnNames );
 		return update.addPrimaryKeyColumns( rowSelectColumnNames )
 				.toStatementString();
 	}
 	
 	@Override
 	public void recreate(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 		super.recreate( collection, id, session );
 		writeIndex( collection, collection.entries( this ), id, true, session );
 	}
 	
 	@Override
 	public void insertRows(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 		super.insertRows( collection, id, session );
 		writeIndex( collection, collection.entries( this ), id, true, session );
 	}
 	
 	@Override
 	protected void doProcessQueuedOps(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 		writeIndex( collection, collection.queuedAdditionIterator(), id, false, session );
 	}
 
 	private void writeIndex(
 			PersistentCollection collection,
 			Iterator entries,
 			Serializable id,
 			boolean resetIndex,
 			SessionImplementor session) {
 		// If one-to-many and inverse, still need to create the index.  See HHH-5732.
 		if ( isInverse && hasIndex && !indexContainsFormula ) {
 			try {
 				if ( entries.hasNext() ) {
 					int nextIndex = resetIndex ? 0 : getSize( id, session );
 					Expectation expectation = Expectations.appropriateExpectation( getUpdateCheckStyle() );
 					while ( entries.hasNext() ) {
 
 						final Object entry = entries.next();
 						if ( entry != null && collection.entryExists( entry, nextIndex ) ) {
 							int offset = 1;
 							PreparedStatement st = null;
 							boolean callable = isUpdateCallable();
 							boolean useBatch = expectation.canBeBatched();
 							String sql = getSQLUpdateRowString();
 
 							if ( useBatch ) {
 								if ( recreateBatchKey == null ) {
 									recreateBatchKey = new BasicBatchKey(
 											getRole() + "#RECREATE",
 											expectation
 											);
 								}
-								st = session.getTransactionCoordinator()
+								st = session
 										.getJdbcCoordinator()
 										.getBatch( recreateBatchKey )
 										.getBatchStatement( sql, callable );
 							}
 							else {
-								st = session.getTransactionCoordinator()
+								st = session
 										.getJdbcCoordinator()
 										.getStatementPreparer()
 										.prepareStatement( sql, callable );
 							}
 
 							try {
 								offset += expectation.prepare( st );
 								if ( hasIdentifier ) {
 									offset = writeIdentifier( st, collection.getIdentifier( entry, nextIndex ), offset, session );
 								}
 								offset = writeIndex( st, collection.getIndex( entry, nextIndex, this ), offset, session );
 								offset = writeElement( st, collection.getElement( entry ), offset, session );
 
 								if ( useBatch ) {
-									session.getTransactionCoordinator()
+									session
 											.getJdbcCoordinator()
 											.getBatch( recreateBatchKey )
 											.addToBatch();
 								}
 								else {
-									expectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
+									expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 								}
 							}
 							catch ( SQLException sqle ) {
 								if ( useBatch ) {
-									session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
+									session.getJdbcCoordinator().abortBatch();
 								}
 								throw sqle;
 							}
 							finally {
 								if ( !useBatch ) {
-									session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+									session.getJdbcCoordinator().getResourceRegistry().release( st );
+									session.getJdbcCoordinator().afterStatementExecution();
 								}
 							}
 
 						}
 						nextIndex++;
 					}
 				}
 			}
 			catch ( SQLException sqle ) {
 				throw sqlExceptionHelper.convert(
 						sqle,
 						"could not update collection: " +
 								MessageHelper.collectionInfoString( this, collection, id, session ),
 						getSQLUpdateRowString()
 						);
 			}
 		}
 	}
 
 	public boolean consumesEntityAlias() {
 		return true;
 	}
 	public boolean consumesCollectionAlias() {
 		return true;
 	}
 
 	public boolean isOneToMany() {
 		return true;
 	}
 
 	@Override
     public boolean isManyToMany() {
 		return false;
 	}
 
 	private BasicBatchKey deleteRowBatchKey;
 	private BasicBatchKey insertRowBatchKey;
 
 	@Override
     protected int doUpdateRows(Serializable id, PersistentCollection collection, SessionImplementor session) {
 
 		// we finish all the "removes" first to take care of possible unique
 		// constraints and so that we can take better advantage of batching
 		
 		try {
 			int count = 0;
 			if ( isRowDeleteEnabled() ) {
 				final Expectation deleteExpectation = Expectations.appropriateExpectation( getDeleteCheckStyle() );
 				final boolean useBatch = deleteExpectation.canBeBatched();
 				if ( useBatch && deleteRowBatchKey == null ) {
 					deleteRowBatchKey = new BasicBatchKey(
 							getRole() + "#DELETEROW",
 							deleteExpectation
 					);
 				}
 				final String sql = getSQLDeleteRowString();
 
 				PreparedStatement st = null;
 				// update removed rows fks to null
 				try {
 					int i = 0;
 					Iterator entries = collection.entries( this );
 					int offset = 1;
 					while ( entries.hasNext() ) {
 						Object entry = entries.next();
 						if ( collection.needsUpdating( entry, i, elementType ) ) {  // will still be issued when it used to be null
 							if ( useBatch ) {
-								st = session.getTransactionCoordinator()
+								st = session
 										.getJdbcCoordinator()
 										.getBatch( deleteRowBatchKey )
 										.getBatchStatement( sql, isDeleteCallable() );
 							}
 							else {
-								st = session.getTransactionCoordinator()
+								st = session
 										.getJdbcCoordinator()
 										.getStatementPreparer()
 										.prepareStatement( sql, isDeleteCallable() );
 							}
 							int loc = writeKey( st, id, offset, session );
 							writeElementToWhere( st, collection.getSnapshotElement(entry, i), loc, session );
 							if ( useBatch ) {
-								session.getTransactionCoordinator()
+								session
 										.getJdbcCoordinator()
 										.getBatch( deleteRowBatchKey )
 										.addToBatch();
 							}
 							else {
-								deleteExpectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
+								deleteExpectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 							}
 							count++;
 						}
 						i++;
 					}
 				}
 				catch ( SQLException e ) {
 					if ( useBatch ) {
-						session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
+						session.getJdbcCoordinator().abortBatch();
 					}
 					throw e;
 				}
 				finally {
 					if ( !useBatch ) {
-						session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+						session.getJdbcCoordinator().getResourceRegistry().release( st );
+						session.getJdbcCoordinator().afterStatementExecution();
 					}
 				}
 			}
 			
 			if ( isRowInsertEnabled() ) {
 				final Expectation insertExpectation = Expectations.appropriateExpectation( getInsertCheckStyle() );
 				boolean useBatch = insertExpectation.canBeBatched();
 				boolean callable = isInsertCallable();
 				if ( useBatch && insertRowBatchKey == null ) {
 					insertRowBatchKey = new BasicBatchKey(
 							getRole() + "#INSERTROW",
 							insertExpectation
 					);
 				}
 				final String sql = getSQLInsertRowString();
 
 				PreparedStatement st = null;
 				// now update all changed or added rows fks
 				try {
 					int i = 0;
 					Iterator entries = collection.entries( this );
 					while ( entries.hasNext() ) {
 						Object entry = entries.next();
 						int offset = 1;
 						if ( collection.needsUpdating( entry, i, elementType ) ) {
 							if ( useBatch ) {
-								st = session.getTransactionCoordinator()
+								st = session
 										.getJdbcCoordinator()
 										.getBatch( insertRowBatchKey )
 										.getBatchStatement( sql, callable );
 							}
 							else {
-								st = session.getTransactionCoordinator()
+								st = session
 										.getJdbcCoordinator()
 										.getStatementPreparer()
 										.prepareStatement( sql, callable );
 							}
 
 							offset += insertExpectation.prepare( st );
 
 							int loc = writeKey( st, id, offset, session );
 							if ( hasIndex && !indexContainsFormula ) {
 								loc = writeIndexToWhere( st, collection.getIndex( entry, i, this ), loc, session );
 							}
 
 							writeElementToWhere( st, collection.getElement( entry ), loc, session );
 
 							if ( useBatch ) {
-								session.getTransactionCoordinator().getJdbcCoordinator().getBatch( insertRowBatchKey ).addToBatch();
+								session.getJdbcCoordinator().getBatch( insertRowBatchKey ).addToBatch();
 							}
 							else {
-								insertExpectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
+								insertExpectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 							}
 							count++;
 						}
 						i++;
 					}
 				}
 				catch ( SQLException sqle ) {
 					if ( useBatch ) {
-						session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
+						session.getJdbcCoordinator().abortBatch();
 					}
 					throw sqle;
 				}
 				finally {
 					if ( !useBatch ) {
-						session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+						session.getJdbcCoordinator().getResourceRegistry().release( st );
+						session.getJdbcCoordinator().afterStatementExecution();
 					}
 				}
 			}
 
 			return count;
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not update collection rows: " + 
 					MessageHelper.collectionInfoString( this, collection, id, session ),
 					getSQLInsertRowString()
 			);
 		}
 	}
 
 	public String selectFragment(
 	        Joinable rhs,
 	        String rhsAlias,
 	        String lhsAlias,
 	        String entitySuffix,
 	        String collectionSuffix,
 	        boolean includeCollectionColumns) {
 		StringBuilder buf = new StringBuilder();
 		if ( includeCollectionColumns ) {
 //			buf.append( selectFragment( lhsAlias, "" ) )//ignore suffix for collection columns!
 			buf.append( selectFragment( lhsAlias, collectionSuffix ) )
 					.append( ", " );
 		}
 		OuterJoinLoadable ojl = ( OuterJoinLoadable ) getElementPersister();
 		return buf.append( ojl.selectFragment( lhsAlias, entitySuffix ) )//use suffix for the entity columns
 				.toString();
 	}
 
 	/**
 	 * Create the <tt>OneToManyLoader</tt>
 	 *
 	 * @see org.hibernate.loader.collection.OneToManyLoader
 	 */
 	@Override
     protected CollectionInitializer createCollectionInitializer(LoadQueryInfluencers loadQueryInfluencers)
 			throws MappingException {
 		return BatchingCollectionInitializerBuilder.getBuilder( getFactory() )
 				.createBatchingOneToManyInitializer( this, batchSize, getFactory(), loadQueryInfluencers );
 	}
 
 	@Override
 	public String fromJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		return ( (Joinable) getElementPersister() ).fromJoinFragment( alias, innerJoin, includeSubclasses );
 	}
 
 	@Override
 	public String fromJoinFragment(
 			String alias,
 			boolean innerJoin,
 			boolean includeSubclasses,
 			Set<String> treatAsDeclarations) {
 		return ( (Joinable) getElementPersister() ).fromJoinFragment( alias, innerJoin, includeSubclasses, treatAsDeclarations );
 	}
 
 	@Override
 	public String whereJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		return ( (Joinable) getElementPersister() ).whereJoinFragment( alias, innerJoin, includeSubclasses );
 	}
 
 	@Override
 	public String whereJoinFragment(
 			String alias,
 			boolean innerJoin,
 			boolean includeSubclasses,
 			Set<String> treatAsDeclarations) {
 		return ( (Joinable) getElementPersister() ).whereJoinFragment( alias, innerJoin, includeSubclasses, treatAsDeclarations );
 	}
 
 	@Override
     public String getTableName() {
 		return ( (Joinable) getElementPersister() ).getTableName();
 	}
 
 	@Override
     public String filterFragment(String alias) throws MappingException {
 		String result = super.filterFragment( alias );
 		if ( getElementPersister() instanceof Joinable ) {
 			result += ( ( Joinable ) getElementPersister() ).oneToManyFilterFragment( alias );
 		}
 		return result;
 
 	}
 
 	@Override
 	protected String filterFragment(String alias, Set<String> treatAsDeclarations) throws MappingException {
 		String result = super.filterFragment( alias );
 		if ( getElementPersister() instanceof Joinable ) {
 			result += ( ( Joinable ) getElementPersister() ).oneToManyFilterFragment( alias, treatAsDeclarations );
 		}
 		return result;
 	}
 
 	@Override
     protected CollectionInitializer createSubselectInitializer(SubselectFetch subselect, SessionImplementor session) {
 		return new SubselectOneToManyLoader( 
 				this,
 				subselect.toSubselectString( getCollectionType().getLHSPropertyName() ),
 				subselect.getResult(),
 				subselect.getQueryParameters(),
 				subselect.getNamedParameterLocMap(),
 				session.getFactory(),
 				session.getLoadQueryInfluencers()
 			);
 	}
 
 	@Override
     public Object getElementByIndex(Serializable key, Object index, SessionImplementor session, Object owner) {
 		return new CollectionElementLoader( this, getFactory(), session.getLoadQueryInfluencers() )
 				.loadElement( session, key, incrementIndexByBase(index) );
 	}
 
 	@Override
 	public FilterAliasGenerator getFilterAliasGenerator(String rootAlias) {
 		return getElementPersister().getFilterAliasGenerator(rootAlias);
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
index c98f5e2f83..d2062ee53c 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
@@ -1,5102 +1,5113 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.entity;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.EntityMode;
 import org.hibernate.FetchMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.Session;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.StaleStateException;
 import org.hibernate.bytecode.instrumentation.spi.FieldInterceptor;
 import org.hibernate.bytecode.instrumentation.spi.LazyPropertyInitializer;
 import org.hibernate.bytecode.spi.EntityInstrumentationMetadata;
 import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.cache.spi.entry.CacheEntry;
 import org.hibernate.cache.spi.entry.CacheEntryStructure;
 import org.hibernate.cache.spi.entry.ReferenceCacheEntryImpl;
 import org.hibernate.cache.spi.entry.StandardCacheEntryImpl;
 import org.hibernate.cache.spi.entry.StructuredCacheEntry;
 import org.hibernate.cache.spi.entry.UnstructuredCacheEntry;
 import org.hibernate.dialect.lock.LockingStrategy;
 import org.hibernate.engine.OptimisticLockStyle;
 import org.hibernate.engine.internal.CacheHelper;
 import org.hibernate.engine.internal.MutableEntityEntryFactory;
 import org.hibernate.engine.internal.ImmutableEntityEntryFactory;
 import org.hibernate.engine.internal.StatefulPersistenceContext;
 import org.hibernate.engine.internal.Versioning;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.engine.spi.CachedNaturalIdValueSource;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.CascadingActions;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.EntityEntryFactory;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.ExecuteUpdateResultCheckStyle;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.PersistenceContext.NaturalIdHelper;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.ValueInclusion;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.PostInsertIdentifierGenerator;
 import org.hibernate.id.PostInsertIdentityPersister;
 import org.hibernate.id.insert.Binder;
 import org.hibernate.id.insert.InsertGeneratedIdentifierDelegate;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.FilterHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
 import org.hibernate.jdbc.TooManyRowsAffectedException;
 import org.hibernate.loader.entity.BatchingEntityLoaderBuilder;
 import org.hibernate.loader.entity.CascadeEntityLoader;
 import org.hibernate.loader.entity.EntityLoader;
 import org.hibernate.loader.entity.UniqueEntityLoader;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Component;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.mapping.Selectable;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.persister.spi.PersisterCreationContext;
 import org.hibernate.persister.walking.internal.EntityIdentifierDefinitionHelper;
 import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.EntityIdentifierDefinition;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.property.BackrefPropertyAccessor;
 import org.hibernate.sql.Alias;
 import org.hibernate.sql.Delete;
 import org.hibernate.sql.Insert;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.JoinType;
 import org.hibernate.sql.Select;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.sql.SimpleSelect;
 import org.hibernate.sql.Template;
 import org.hibernate.sql.Update;
 import org.hibernate.tuple.GenerationTiming;
 import org.hibernate.tuple.InDatabaseValueGenerationStrategy;
 import org.hibernate.tuple.InMemoryValueGenerationStrategy;
 import org.hibernate.tuple.NonIdentifierAttribute;
 import org.hibernate.tuple.ValueGeneration;
 import org.hibernate.tuple.entity.EntityMetamodel;
 import org.hibernate.tuple.entity.EntityTuplizer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeHelper;
 import org.hibernate.type.VersionType;
 import org.jboss.logging.Logger;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.Comparator;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 /**
  * Basic functionality for persisting an entity via JDBC
  * through either generated or custom SQL
  *
  * @author Gavin King
  */
 public abstract class AbstractEntityPersister
 		implements OuterJoinLoadable, Queryable, ClassMetadata, UniqueKeyLoadable,
 		SQLLoadable, LazyPropertyInitializer, PostInsertIdentityPersister, Lockable {
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, AbstractEntityPersister.class.getName() );
 
 	public static final String ENTITY_CLASS = "class";
 
 	// moved up from AbstractEntityPersister ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	private final SessionFactoryImplementor factory;
 	private final EntityRegionAccessStrategy cacheAccessStrategy;
 	private final NaturalIdRegionAccessStrategy naturalIdRegionAccessStrategy;
 	private final boolean isLazyPropertiesCacheable;
 	private final CacheEntryHelper cacheEntryHelper;
 	private final EntityMetamodel entityMetamodel;
 	private final EntityTuplizer entityTuplizer;
 	private final EntityEntryFactory entityEntryFactory;
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private final String[] rootTableKeyColumnNames;
 	private final String[] rootTableKeyColumnReaders;
 	private final String[] rootTableKeyColumnReaderTemplates;
 	private final String[] identifierAliases;
 	private final int identifierColumnSpan;
 	private final String versionColumnName;
 	private final boolean hasFormulaProperties;
 	private final int batchSize;
 	private final boolean hasSubselectLoadableCollections;
 	protected final String rowIdName;
 
 	private final Set lazyProperties;
 
 	// The optional SQL string defined in the where attribute
 	private final String sqlWhereString;
 	private final String sqlWhereStringTemplate;
 
 	//information about properties of this class,
 	//including inherited properties
 	//(only really needed for updatable/insertable properties)
 	private final int[] propertyColumnSpans;
 	private final String[] propertySubclassNames;
 	private final String[][] propertyColumnAliases;
 	private final String[][] propertyColumnNames;
 	private final String[][] propertyColumnFormulaTemplates;
 	private final String[][] propertyColumnReaderTemplates;
 	private final String[][] propertyColumnWriters;
 	private final boolean[][] propertyColumnUpdateable;
 	private final boolean[][] propertyColumnInsertable;
 	private final boolean[] propertyUniqueness;
 	private final boolean[] propertySelectable;
 	
 	private final List<Integer> lobProperties = new ArrayList<Integer>();
 
 	//information about lazy properties of this class
 	private final String[] lazyPropertyNames;
 	private final int[] lazyPropertyNumbers;
 	private final Type[] lazyPropertyTypes;
 	private final String[][] lazyPropertyColumnAliases;
 
 	//information about all properties in class hierarchy
 	private final String[] subclassPropertyNameClosure;
 	private final String[] subclassPropertySubclassNameClosure;
 	private final Type[] subclassPropertyTypeClosure;
 	private final String[][] subclassPropertyFormulaTemplateClosure;
 	private final String[][] subclassPropertyColumnNameClosure;
 	private final String[][] subclassPropertyColumnReaderClosure;
 	private final String[][] subclassPropertyColumnReaderTemplateClosure;
 	private final FetchMode[] subclassPropertyFetchModeClosure;
 	private final boolean[] subclassPropertyNullabilityClosure;
 	private final boolean[] propertyDefinedOnSubclass;
 	private final int[][] subclassPropertyColumnNumberClosure;
 	private final int[][] subclassPropertyFormulaNumberClosure;
 	private final CascadeStyle[] subclassPropertyCascadeStyleClosure;
 
 	//information about all columns/formulas in class hierarchy
 	private final String[] subclassColumnClosure;
 	private final boolean[] subclassColumnLazyClosure;
 	private final String[] subclassColumnAliasClosure;
 	private final boolean[] subclassColumnSelectableClosure;
 	private final String[] subclassColumnReaderTemplateClosure;
 	private final String[] subclassFormulaClosure;
 	private final String[] subclassFormulaTemplateClosure;
 	private final String[] subclassFormulaAliasClosure;
 	private final boolean[] subclassFormulaLazyClosure;
 
 	// dynamic filters attached to the class-level
 	private final FilterHelper filterHelper;
 
 	private final Set<String> affectingFetchProfileNames = new HashSet<String>();
 
 	private final Map uniqueKeyLoaders = new HashMap();
 	private final Map lockers = new HashMap();
 	private final Map loaders = new HashMap();
 
 	// SQL strings
 	private String sqlVersionSelectString;
 	private String sqlSnapshotSelectString;
 	private String sqlLazySelectString;
 
 	private String sqlIdentityInsertString;
 	private String sqlUpdateByRowIdString;
 	private String sqlLazyUpdateByRowIdString;
 
 	private String[] sqlDeleteStrings;
 	private String[] sqlInsertStrings;
 	private String[] sqlUpdateStrings;
 	private String[] sqlLazyUpdateStrings;
 
 	private String sqlInsertGeneratedValuesSelectString;
 	private String sqlUpdateGeneratedValuesSelectString;
 
 	//Custom SQL (would be better if these were private)
 	protected boolean[] insertCallable;
 	protected boolean[] updateCallable;
 	protected boolean[] deleteCallable;
 	protected String[] customSQLInsert;
 	protected String[] customSQLUpdate;
 	protected String[] customSQLDelete;
 	protected ExecuteUpdateResultCheckStyle[] insertResultCheckStyles;
 	protected ExecuteUpdateResultCheckStyle[] updateResultCheckStyles;
 	protected ExecuteUpdateResultCheckStyle[] deleteResultCheckStyles;
 
 	private InsertGeneratedIdentifierDelegate identityDelegate;
 
 	private boolean[] tableHasColumns;
 
 	private final String loaderName;
 
 	private UniqueEntityLoader queryLoader;
 
 	private final Map subclassPropertyAliases = new HashMap();
 	private final Map subclassPropertyColumnNames = new HashMap();
 
 	protected final BasicEntityPropertyMapping propertyMapping;
 
 	private final boolean useReferenceCacheEntries;
 
 	protected void addDiscriminatorToInsert(Insert insert) {}
 
 	protected void addDiscriminatorToSelect(SelectFragment select, String name, String suffix) {}
 
 	protected abstract int[] getSubclassColumnTableNumberClosure();
 
 	protected abstract int[] getSubclassFormulaTableNumberClosure();
 
 	public abstract String getSubclassTableName(int j);
 
 	protected abstract String[] getSubclassTableKeyColumns(int j);
 
 	protected abstract boolean isClassOrSuperclassTable(int j);
 
 	protected abstract int getSubclassTableSpan();
 
 	protected abstract int getTableSpan();
 
 	protected abstract boolean isTableCascadeDeleteEnabled(int j);
 
 	protected abstract String getTableName(int j);
 
 	protected abstract String[] getKeyColumns(int j);
 
 	protected abstract boolean isPropertyOfTable(int property, int j);
 
 	protected abstract int[] getPropertyTableNumbersInSelect();
 
 	protected abstract int[] getPropertyTableNumbers();
 
 	protected abstract int getSubclassPropertyTableNumber(int i);
 
 	protected abstract String filterFragment(String alias) throws MappingException;
 
 	protected abstract String filterFragment(String alias, Set<String> treatAsDeclarations);
 
 	private static final String DISCRIMINATOR_ALIAS = "clazz_";
 
 	public String getDiscriminatorColumnName() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	public String getDiscriminatorColumnReaders() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	public String getDiscriminatorColumnReaderTemplate() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	protected String getDiscriminatorAlias() {
 		return DISCRIMINATOR_ALIAS;
 	}
 
 	protected String getDiscriminatorFormulaTemplate() {
 		return null;
 	}
 
 	protected boolean isInverseTable(int j) {
 		return false;
 	}
 
 	protected boolean isNullableTable(int j) {
 		return false;
 	}
 
 	protected boolean isNullableSubclassTable(int j) {
 		return false;
 	}
 
 	protected boolean isInverseSubclassTable(int j) {
 		return false;
 	}
 
 	public boolean isSubclassEntityName(String entityName) {
 		return entityMetamodel.getSubclassEntityNames().contains(entityName);
 	}
 
 	private boolean[] getTableHasColumns() {
 		return tableHasColumns;
 	}
 
 	public String[] getRootTableKeyColumnNames() {
 		return rootTableKeyColumnNames;
 	}
 
 	protected String[] getSQLUpdateByRowIdStrings() {
 		if ( sqlUpdateByRowIdString == null ) {
 			throw new AssertionFailure( "no update by row id" );
 		}
 		String[] result = new String[getTableSpan() + 1];
 		result[0] = sqlUpdateByRowIdString;
 		System.arraycopy( sqlUpdateStrings, 0, result, 1, getTableSpan() );
 		return result;
 	}
 
 	protected String[] getSQLLazyUpdateByRowIdStrings() {
 		if ( sqlLazyUpdateByRowIdString == null ) {
 			throw new AssertionFailure( "no update by row id" );
 		}
 		String[] result = new String[getTableSpan()];
 		result[0] = sqlLazyUpdateByRowIdString;
 		for ( int i = 1; i < getTableSpan(); i++ ) {
 			result[i] = sqlLazyUpdateStrings[i];
 		}
 		return result;
 	}
 
 	protected String getSQLSnapshotSelectString() {
 		return sqlSnapshotSelectString;
 	}
 
 	protected String getSQLLazySelectString() {
 		return sqlLazySelectString;
 	}
 
 	protected String[] getSQLDeleteStrings() {
 		return sqlDeleteStrings;
 	}
 
 	protected String[] getSQLInsertStrings() {
 		return sqlInsertStrings;
 	}
 
 	protected String[] getSQLUpdateStrings() {
 		return sqlUpdateStrings;
 	}
 
 	protected String[] getSQLLazyUpdateStrings() {
 		return sqlLazyUpdateStrings;
 	}
 
 	/**
 	 * The query that inserts a row, letting the database generate an id
 	 *
 	 * @return The IDENTITY-based insertion query.
 	 */
 	protected String getSQLIdentityInsertString() {
 		return sqlIdentityInsertString;
 	}
 
 	protected String getVersionSelectString() {
 		return sqlVersionSelectString;
 	}
 
 	protected boolean isInsertCallable(int j) {
 		return insertCallable[j];
 	}
 
 	protected boolean isUpdateCallable(int j) {
 		return updateCallable[j];
 	}
 
 	protected boolean isDeleteCallable(int j) {
 		return deleteCallable[j];
 	}
 
 	protected boolean isSubclassPropertyDeferred(String propertyName, String entityName) {
 		return false;
 	}
 
 	protected boolean isSubclassTableSequentialSelect(int j) {
 		return false;
 	}
 
 	public boolean hasSequentialSelect() {
 		return false;
 	}
 
 	/**
 	 * Decide which tables need to be updated.
 	 * <p/>
 	 * The return here is an array of boolean values with each index corresponding
 	 * to a given table in the scope of this persister.
 	 *
 	 * @param dirtyProperties The indices of all the entity properties considered dirty.
 	 * @param hasDirtyCollection Whether any collections owned by the entity which were considered dirty.
 	 *
 	 * @return Array of booleans indicating which table require updating.
 	 */
 	protected boolean[] getTableUpdateNeeded(final int[] dirtyProperties, boolean hasDirtyCollection) {
 
 		if ( dirtyProperties == null ) {
 			return getTableHasColumns(); // for objects that came in via update()
 		}
 		else {
 			boolean[] updateability = getPropertyUpdateability();
 			int[] propertyTableNumbers = getPropertyTableNumbers();
 			boolean[] tableUpdateNeeded = new boolean[ getTableSpan() ];
 			for ( int i = 0; i < dirtyProperties.length; i++ ) {
 				int property = dirtyProperties[i];
 				int table = propertyTableNumbers[property];
 				tableUpdateNeeded[table] = tableUpdateNeeded[table] ||
 						( getPropertyColumnSpan(property) > 0 && updateability[property] );
 			}
 			if ( isVersioned() ) {
 				tableUpdateNeeded[0] = tableUpdateNeeded[0] ||
 					Versioning.isVersionIncrementRequired( dirtyProperties, hasDirtyCollection, getPropertyVersionability() );
 			}
 			return tableUpdateNeeded;
 		}
 	}
 
 	public boolean hasRowId() {
 		return rowIdName != null;
 	}
 
 	protected boolean[][] getPropertyColumnUpdateable() {
 		return propertyColumnUpdateable;
 	}
 
 	protected boolean[][] getPropertyColumnInsertable() {
 		return propertyColumnInsertable;
 	}
 
 	protected boolean[] getPropertySelectable() {
 		return propertySelectable;
 	}
 
 	public AbstractEntityPersister(
 			final PersistentClass persistentClass,
 			final EntityRegionAccessStrategy cacheAccessStrategy,
 			final NaturalIdRegionAccessStrategy naturalIdRegionAccessStrategy,
 			final PersisterCreationContext creationContext) throws HibernateException {
 
 		// moved up from AbstractEntityPersister ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		this.factory = creationContext.getSessionFactory();
 		this.cacheAccessStrategy = cacheAccessStrategy;
 		this.naturalIdRegionAccessStrategy = naturalIdRegionAccessStrategy;
 		isLazyPropertiesCacheable = persistentClass.isLazyPropertiesCacheable();
 
 		this.entityMetamodel = new EntityMetamodel( persistentClass, this, factory );
 		this.entityTuplizer = this.entityMetamodel.getTuplizer();
 
 		if( entityMetamodel.isMutable() ) {
 			this.entityEntryFactory = MutableEntityEntryFactory.INSTANCE;
 		}
 		else {
 			this.entityEntryFactory = ImmutableEntityEntryFactory.INSTANCE;
 		}
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		int batch = persistentClass.getBatchSize();
 		if ( batch == -1 ) {
 			batch = factory.getSettings().getDefaultBatchFetchSize();
 		}
 		batchSize = batch;
 		hasSubselectLoadableCollections = persistentClass.hasSubselectLoadableCollections();
 
 		propertyMapping = new BasicEntityPropertyMapping( this );
 
 		// IDENTIFIER
 
 		identifierColumnSpan = persistentClass.getIdentifier().getColumnSpan();
 		rootTableKeyColumnNames = new String[identifierColumnSpan];
 		rootTableKeyColumnReaders = new String[identifierColumnSpan];
 		rootTableKeyColumnReaderTemplates = new String[identifierColumnSpan];
 		identifierAliases = new String[identifierColumnSpan];
 
 		rowIdName = persistentClass.getRootTable().getRowId();
 
 		loaderName = persistentClass.getLoaderName();
 
 		Iterator iter = persistentClass.getIdentifier().getColumnIterator();
 		int i = 0;
 		while ( iter.hasNext() ) {
 			Column col = ( Column ) iter.next();
 			rootTableKeyColumnNames[i] = col.getQuotedName( factory.getDialect() );
 			rootTableKeyColumnReaders[i] = col.getReadExpr( factory.getDialect() );
 			rootTableKeyColumnReaderTemplates[i] = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 			identifierAliases[i] = col.getAlias( factory.getDialect(), persistentClass.getRootTable() );
 			i++;
 		}
 
 		// VERSION
 
 		if ( persistentClass.isVersioned() ) {
 			versionColumnName = ( ( Column ) persistentClass.getVersion().getColumnIterator().next() ).getQuotedName( factory.getDialect() );
 		}
 		else {
 			versionColumnName = null;
 		}
 
 		//WHERE STRING
 
 		sqlWhereString = StringHelper.isNotEmpty( persistentClass.getWhere() ) ? "( " + persistentClass.getWhere() + ") " : null;
 		sqlWhereStringTemplate = sqlWhereString == null ?
 				null :
 				Template.renderWhereStringTemplate( sqlWhereString, factory.getDialect(), factory.getSqlFunctionRegistry() );
 
 		// PROPERTIES
 
 		final boolean lazyAvailable = isInstrumented();
 
 		int hydrateSpan = entityMetamodel.getPropertySpan();
 		propertyColumnSpans = new int[hydrateSpan];
 		propertySubclassNames = new String[hydrateSpan];
 		propertyColumnAliases = new String[hydrateSpan][];
 		propertyColumnNames = new String[hydrateSpan][];
 		propertyColumnFormulaTemplates = new String[hydrateSpan][];
 		propertyColumnReaderTemplates = new String[hydrateSpan][];
 		propertyColumnWriters = new String[hydrateSpan][];
 		propertyUniqueness = new boolean[hydrateSpan];
 		propertySelectable = new boolean[hydrateSpan];
 		propertyColumnUpdateable = new boolean[hydrateSpan][];
 		propertyColumnInsertable = new boolean[hydrateSpan][];
 		HashSet thisClassProperties = new HashSet();
 
 		lazyProperties = new HashSet();
 		ArrayList lazyNames = new ArrayList();
 		ArrayList lazyNumbers = new ArrayList();
 		ArrayList lazyTypes = new ArrayList();
 		ArrayList lazyColAliases = new ArrayList();
 
 		iter = persistentClass.getPropertyClosureIterator();
 		i = 0;
 		boolean foundFormula = false;
 		while ( iter.hasNext() ) {
 			Property prop = ( Property ) iter.next();
 			thisClassProperties.add( prop );
 
 			int span = prop.getColumnSpan();
 			propertyColumnSpans[i] = span;
 			propertySubclassNames[i] = prop.getPersistentClass().getEntityName();
 			String[] colNames = new String[span];
 			String[] colAliases = new String[span];
 			String[] colReaderTemplates = new String[span];
 			String[] colWriters = new String[span];
 			String[] formulaTemplates = new String[span];
 			Iterator colIter = prop.getColumnIterator();
 			int k = 0;
 			while ( colIter.hasNext() ) {
 				Selectable thing = ( Selectable ) colIter.next();
 				colAliases[k] = thing.getAlias( factory.getDialect() , prop.getValue().getTable() );
 				if ( thing.isFormula() ) {
 					foundFormula = true;
 					formulaTemplates[k] = thing.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 				}
 				else {
 					Column col = (Column)thing;
 					colNames[k] = col.getQuotedName( factory.getDialect() );
 					colReaderTemplates[k] = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					colWriters[k] = col.getWriteExpr();
 				}
 				k++;
 			}
 			propertyColumnNames[i] = colNames;
 			propertyColumnFormulaTemplates[i] = formulaTemplates;
 			propertyColumnReaderTemplates[i] = colReaderTemplates;
 			propertyColumnWriters[i] = colWriters;
 			propertyColumnAliases[i] = colAliases;
 
 			if ( lazyAvailable && prop.isLazy() ) {
 				lazyProperties.add( prop.getName() );
 				lazyNames.add( prop.getName() );
 				lazyNumbers.add( i );
 				lazyTypes.add( prop.getValue().getType() );
 				lazyColAliases.add( colAliases );
 			}
 
 			propertyColumnUpdateable[i] = prop.getValue().getColumnUpdateability();
 			propertyColumnInsertable[i] = prop.getValue().getColumnInsertability();
 
 			propertySelectable[i] = prop.isSelectable();
 
 			propertyUniqueness[i] = prop.getValue().isAlternateUniqueKey();
 			
 			if (prop.isLob() && getFactory().getDialect().forceLobAsLastValue() ) {
 				lobProperties.add( i );
 			}
 
 			i++;
 
 		}
 		hasFormulaProperties = foundFormula;
 		lazyPropertyColumnAliases = ArrayHelper.to2DStringArray( lazyColAliases );
 		lazyPropertyNames = ArrayHelper.toStringArray( lazyNames );
 		lazyPropertyNumbers = ArrayHelper.toIntArray( lazyNumbers );
 		lazyPropertyTypes = ArrayHelper.toTypeArray( lazyTypes );
 
 		// SUBCLASS PROPERTY CLOSURE
 
 		ArrayList columns = new ArrayList();
 		ArrayList columnsLazy = new ArrayList();
 		ArrayList columnReaderTemplates = new ArrayList();
 		ArrayList aliases = new ArrayList();
 		ArrayList formulas = new ArrayList();
 		ArrayList formulaAliases = new ArrayList();
 		ArrayList formulaTemplates = new ArrayList();
 		ArrayList formulasLazy = new ArrayList();
 		ArrayList types = new ArrayList();
 		ArrayList names = new ArrayList();
 		ArrayList classes = new ArrayList();
 		ArrayList templates = new ArrayList();
 		ArrayList propColumns = new ArrayList();
 		ArrayList propColumnReaders = new ArrayList();
 		ArrayList propColumnReaderTemplates = new ArrayList();
 		ArrayList joinedFetchesList = new ArrayList();
 		ArrayList cascades = new ArrayList();
 		ArrayList definedBySubclass = new ArrayList();
 		ArrayList propColumnNumbers = new ArrayList();
 		ArrayList propFormulaNumbers = new ArrayList();
 		ArrayList columnSelectables = new ArrayList();
 		ArrayList propNullables = new ArrayList();
 
 		iter = persistentClass.getSubclassPropertyClosureIterator();
 		while ( iter.hasNext() ) {
 			Property prop = ( Property ) iter.next();
 			names.add( prop.getName() );
 			classes.add( prop.getPersistentClass().getEntityName() );
 			boolean isDefinedBySubclass = !thisClassProperties.contains( prop );
 			definedBySubclass.add( Boolean.valueOf( isDefinedBySubclass ) );
 			propNullables.add( Boolean.valueOf( prop.isOptional() || isDefinedBySubclass ) ); //TODO: is this completely correct?
 			types.add( prop.getType() );
 
 			Iterator colIter = prop.getColumnIterator();
 			String[] cols = new String[prop.getColumnSpan()];
 			String[] readers = new String[prop.getColumnSpan()];
 			String[] readerTemplates = new String[prop.getColumnSpan()];
 			String[] forms = new String[prop.getColumnSpan()];
 			int[] colnos = new int[prop.getColumnSpan()];
 			int[] formnos = new int[prop.getColumnSpan()];
 			int l = 0;
 			Boolean lazy = Boolean.valueOf( prop.isLazy() && lazyAvailable );
 			while ( colIter.hasNext() ) {
 				Selectable thing = ( Selectable ) colIter.next();
 				if ( thing.isFormula() ) {
 					String template = thing.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					formnos[l] = formulaTemplates.size();
 					colnos[l] = -1;
 					formulaTemplates.add( template );
 					forms[l] = template;
 					formulas.add( thing.getText( factory.getDialect() ) );
 					formulaAliases.add( thing.getAlias( factory.getDialect() ) );
 					formulasLazy.add( lazy );
 				}
 				else {
 					Column col = (Column)thing;
 					String colName = col.getQuotedName( factory.getDialect() );
 					colnos[l] = columns.size(); //before add :-)
 					formnos[l] = -1;
 					columns.add( colName );
 					cols[l] = colName;
 					aliases.add( thing.getAlias( factory.getDialect(), prop.getValue().getTable() ) );
 					columnsLazy.add( lazy );
 					columnSelectables.add( Boolean.valueOf( prop.isSelectable() ) );
 
 					readers[l] = col.getReadExpr( factory.getDialect() );
 					String readerTemplate = col.getTemplate( factory.getDialect(), factory.getSqlFunctionRegistry() );
 					readerTemplates[l] = readerTemplate;
 					columnReaderTemplates.add( readerTemplate );
 				}
 				l++;
 			}
 			propColumns.add( cols );
 			propColumnReaders.add( readers );
 			propColumnReaderTemplates.add( readerTemplates );
 			templates.add( forms );
 			propColumnNumbers.add( colnos );
 			propFormulaNumbers.add( formnos );
 
 			joinedFetchesList.add( prop.getValue().getFetchMode() );
 			cascades.add( prop.getCascadeStyle() );
 		}
 		subclassColumnClosure = ArrayHelper.toStringArray( columns );
 		subclassColumnAliasClosure = ArrayHelper.toStringArray( aliases );
 		subclassColumnLazyClosure = ArrayHelper.toBooleanArray( columnsLazy );
 		subclassColumnSelectableClosure = ArrayHelper.toBooleanArray( columnSelectables );
 		subclassColumnReaderTemplateClosure = ArrayHelper.toStringArray( columnReaderTemplates );
 
 		subclassFormulaClosure = ArrayHelper.toStringArray( formulas );
 		subclassFormulaTemplateClosure = ArrayHelper.toStringArray( formulaTemplates );
 		subclassFormulaAliasClosure = ArrayHelper.toStringArray( formulaAliases );
 		subclassFormulaLazyClosure = ArrayHelper.toBooleanArray( formulasLazy );
 
 		subclassPropertyNameClosure = ArrayHelper.toStringArray( names );
 		subclassPropertySubclassNameClosure = ArrayHelper.toStringArray( classes );
 		subclassPropertyTypeClosure = ArrayHelper.toTypeArray( types );
 		subclassPropertyNullabilityClosure = ArrayHelper.toBooleanArray( propNullables );
 		subclassPropertyFormulaTemplateClosure = ArrayHelper.to2DStringArray( templates );
 		subclassPropertyColumnNameClosure = ArrayHelper.to2DStringArray( propColumns );
 		subclassPropertyColumnReaderClosure = ArrayHelper.to2DStringArray( propColumnReaders );
 		subclassPropertyColumnReaderTemplateClosure = ArrayHelper.to2DStringArray( propColumnReaderTemplates );
 		subclassPropertyColumnNumberClosure = ArrayHelper.to2DIntArray( propColumnNumbers );
 		subclassPropertyFormulaNumberClosure = ArrayHelper.to2DIntArray( propFormulaNumbers );
 
 		subclassPropertyCascadeStyleClosure = new CascadeStyle[cascades.size()];
 		iter = cascades.iterator();
 		int j = 0;
 		while ( iter.hasNext() ) {
 			subclassPropertyCascadeStyleClosure[j++] = ( CascadeStyle ) iter.next();
 		}
 		subclassPropertyFetchModeClosure = new FetchMode[joinedFetchesList.size()];
 		iter = joinedFetchesList.iterator();
 		j = 0;
 		while ( iter.hasNext() ) {
 			subclassPropertyFetchModeClosure[j++] = ( FetchMode ) iter.next();
 		}
 
 		propertyDefinedOnSubclass = new boolean[definedBySubclass.size()];
 		iter = definedBySubclass.iterator();
 		j = 0;
 		while ( iter.hasNext() ) {
 			propertyDefinedOnSubclass[j++] = (Boolean) iter.next();
 		}
 
 		// Handle any filters applied to the class level
 		filterHelper = new FilterHelper( persistentClass.getFilters(), factory );
 
 		// Check if we can use Reference Cached entities in 2lc
 		// todo : should really validate that the cache access type is read-only
 		boolean refCacheEntries = true;
 		if ( ! factory.getSettings().isDirectReferenceCacheEntriesEnabled() ) {
 			refCacheEntries = false;
 		}
 
 		// for now, limit this to just entities that:
 		// 		1) are immutable
 		if ( entityMetamodel.isMutable() ) {
 			refCacheEntries =  false;
 		}
 
 		//		2)  have no associations.  Eventually we want to be a little more lenient with associations.
 		for ( Type type : getSubclassPropertyTypeClosure() ) {
 			if ( type.isAssociationType() ) {
 				refCacheEntries =  false;
 			}
 		}
 
 		useReferenceCacheEntries = refCacheEntries;
 
 		this.cacheEntryHelper = buildCacheEntryHelper();
 
 	}
 
 	protected CacheEntryHelper buildCacheEntryHelper() {
 		if ( cacheAccessStrategy == null ) {
 			// the entity defined no caching...
 			return NoopCacheEntryHelper.INSTANCE;
 		}
 
 		if ( canUseReferenceCacheEntries() ) {
 			entityMetamodel.setLazy( false );
 			// todo : do we also need to unset proxy factory?
 			return new ReferenceCacheEntryHelper( this );
 		}
 
 		return factory.getSettings().isStructuredCacheEntriesEnabled()
 				? new StructuredCacheEntryHelper( this )
 				: new StandardCacheEntryHelper( this );
 	}
 
 	public boolean canUseReferenceCacheEntries() {
 		return useReferenceCacheEntries;
 	}
 
 	protected static String getTemplateFromString(String string, SessionFactoryImplementor factory) {
 		return string == null ?
 				null :
 				Template.renderWhereStringTemplate( string, factory.getDialect(), factory.getSqlFunctionRegistry() );
 	}
 
 	protected String generateLazySelectString() {
 
 		if ( !entityMetamodel.hasLazyProperties() ) {
 			return null;
 		}
 
 		HashSet tableNumbers = new HashSet();
 		ArrayList columnNumbers = new ArrayList();
 		ArrayList formulaNumbers = new ArrayList();
 		for ( int i = 0; i < lazyPropertyNames.length; i++ ) {
 			// all this only really needs to consider properties
 			// of this class, not its subclasses, but since we
 			// are reusing code used for sequential selects, we
 			// use the subclass closure
 			int propertyNumber = getSubclassPropertyIndex( lazyPropertyNames[i] );
 
 			int tableNumber = getSubclassPropertyTableNumber( propertyNumber );
 			tableNumbers.add(  tableNumber );
 
 			int[] colNumbers = subclassPropertyColumnNumberClosure[propertyNumber];
 			for ( int j = 0; j < colNumbers.length; j++ ) {
 				if ( colNumbers[j]!=-1 ) {
 					columnNumbers.add( colNumbers[j] );
 				}
 			}
 			int[] formNumbers = subclassPropertyFormulaNumberClosure[propertyNumber];
 			for ( int j = 0; j < formNumbers.length; j++ ) {
 				if ( formNumbers[j]!=-1 ) {
 					formulaNumbers.add( formNumbers[j] );
 				}
 			}
 		}
 
 		if ( columnNumbers.size()==0 && formulaNumbers.size()==0 ) {
 			// only one-to-one is lazy fetched
 			return null;
 		}
 
 		return renderSelect( ArrayHelper.toIntArray( tableNumbers ),
 				ArrayHelper.toIntArray( columnNumbers ),
 				ArrayHelper.toIntArray( formulaNumbers ) );
 
 	}
 
 	public Object initializeLazyProperty(String fieldName, Object entity, SessionImplementor session)
 			throws HibernateException {
 
 		final Serializable id = session.getContextEntityIdentifier( entity );
 
 		final EntityEntry entry = session.getPersistenceContext().getEntry( entity );
 		if ( entry == null ) {
 			throw new HibernateException( "entity is not associated with the session: " + id );
 		}
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Initializing lazy properties of: {0}, field access: {1}", MessageHelper.infoString( this, id, getFactory() ), fieldName );
 		}
 
 		if ( session.getCacheMode().isGetEnabled() && hasCache() ) {
 			final CacheKey cacheKey = session.generateCacheKey( id, getIdentifierType(), getEntityName() );
 			final Object ce = CacheHelper.fromSharedCache( session, cacheKey, getCacheAccessStrategy() );
 			if ( ce != null ) {
 				final CacheEntry cacheEntry = (CacheEntry) getCacheEntryStructure().destructure(ce, factory);
 				if ( !cacheEntry.areLazyPropertiesUnfetched() ) {
 					//note early exit here:
 					return initializeLazyPropertiesFromCache( fieldName, entity, session, entry, cacheEntry );
 				}
 			}
 		}
 
 		return initializeLazyPropertiesFromDatastore( fieldName, entity, session, id, entry );
 
 	}
 
 	private Object initializeLazyPropertiesFromDatastore(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final Serializable id,
 			final EntityEntry entry) {
 
 		if ( !hasLazyProperties() ) throw new AssertionFailure( "no lazy properties" );
 
 		LOG.trace( "Initializing lazy properties from datastore" );
 
 		try {
 
 			Object result = null;
 			PreparedStatement ps = null;
 			try {
 				final String lazySelect = getSQLLazySelectString();
 				ResultSet rs = null;
 				try {
 					if ( lazySelect != null ) {
 						// null sql means that the only lazy properties
 						// are shared PK one-to-one associations which are
 						// handled differently in the Type#nullSafeGet code...
-						ps = session.getTransactionCoordinator()
-								.getJdbcCoordinator()
+						ps = session.getJdbcCoordinator()
 								.getStatementPreparer()
 								.prepareStatement( lazySelect );
 						getIdentifierType().nullSafeSet( ps, id, 1, session );
-						rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( ps );
+						rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 						rs.next();
 					}
 					final Object[] snapshot = entry.getLoadedState();
 					for ( int j = 0; j < lazyPropertyNames.length; j++ ) {
 						Object propValue = lazyPropertyTypes[j].nullSafeGet( rs, lazyPropertyColumnAliases[j], session, entity );
 						if ( initializeLazyProperty( fieldName, entity, session, snapshot, j, propValue ) ) {
 							result = propValue;
 						}
 					}
 				}
 				finally {
 					if ( rs != null ) {
-						session.getTransactionCoordinator().getJdbcCoordinator().release( rs, ps );
+						session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 					}
 				}
 			}
 			finally {
 				if ( ps != null ) {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
+					session.getJdbcCoordinator().getResourceRegistry().release( ps );
+					session.getJdbcCoordinator().afterStatementExecution();
 				}
 			}
 
 			LOG.trace( "Done initializing lazy properties" );
 
 			return result;
 
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not initialize lazy properties: " +
 					MessageHelper.infoString( this, id, getFactory() ),
 					getSQLLazySelectString()
 				);
 		}
 	}
 
 	private Object initializeLazyPropertiesFromCache(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final EntityEntry entry,
 			final CacheEntry cacheEntry
 	) {
 
 		LOG.trace( "Initializing lazy properties from second-level cache" );
 
 		Object result = null;
 		Serializable[] disassembledValues = cacheEntry.getDisassembledState();
 		final Object[] snapshot = entry.getLoadedState();
 		for ( int j = 0; j < lazyPropertyNames.length; j++ ) {
 			final Object propValue = lazyPropertyTypes[j].assemble(
 					disassembledValues[ lazyPropertyNumbers[j] ],
 					session,
 					entity
 				);
 			if ( initializeLazyProperty( fieldName, entity, session, snapshot, j, propValue ) ) {
 				result = propValue;
 			}
 		}
 
 		LOG.trace( "Done initializing lazy properties" );
 
 		return result;
 	}
 
 	private boolean initializeLazyProperty(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final Object[] snapshot,
 			final int j,
 			final Object propValue) {
 		setPropertyValue( entity, lazyPropertyNumbers[j], propValue );
 		if ( snapshot != null ) {
 			// object have been loaded with setReadOnly(true); HHH-2236
 			snapshot[ lazyPropertyNumbers[j] ] = lazyPropertyTypes[j].deepCopy( propValue, factory );
 		}
 		return fieldName.equals( lazyPropertyNames[j] );
 	}
 
 	public boolean isBatchable() {
 		return optimisticLockStyle() == OptimisticLockStyle.NONE
 				|| ( !isVersioned() && optimisticLockStyle() == OptimisticLockStyle.VERSION )
 				|| getFactory().getSettings().isJdbcBatchVersionedData();
 	}
 
 	public Serializable[] getQuerySpaces() {
 		return getPropertySpaces();
 	}
 
 	protected Set getLazyProperties() {
 		return lazyProperties;
 	}
 
 	public boolean isBatchLoadable() {
 		return batchSize > 1;
 	}
 
 	public String[] getIdentifierColumnNames() {
 		return rootTableKeyColumnNames;
 	}
 
 	public String[] getIdentifierColumnReaders() {
 		return rootTableKeyColumnReaders;
 	}
 
 	public String[] getIdentifierColumnReaderTemplates() {
 		return rootTableKeyColumnReaderTemplates;
 	}
 
 	protected int getIdentifierColumnSpan() {
 		return identifierColumnSpan;
 	}
 
 	protected String[] getIdentifierAliases() {
 		return identifierAliases;
 	}
 
 	public String getVersionColumnName() {
 		return versionColumnName;
 	}
 
 	protected String getVersionedTableName() {
 		return getTableName( 0 );
 	}
 
 	protected boolean[] getSubclassColumnLazyiness() {
 		return subclassColumnLazyClosure;
 	}
 
 	protected boolean[] getSubclassFormulaLazyiness() {
 		return subclassFormulaLazyClosure;
 	}
 
 	/**
 	 * We can't immediately add to the cache if we have formulas
 	 * which must be evaluated, or if we have the possibility of
 	 * two concurrent updates to the same item being merged on
 	 * the database. This can happen if (a) the item is not
 	 * versioned and either (b) we have dynamic update enabled
 	 * or (c) we have multiple tables holding the state of the
 	 * item.
 	 */
 	public boolean isCacheInvalidationRequired() {
 		return hasFormulaProperties() ||
 				( !isVersioned() && ( entityMetamodel.isDynamicUpdate() || getTableSpan() > 1 ) );
 	}
 
 	public boolean isLazyPropertiesCacheable() {
 		return isLazyPropertiesCacheable;
 	}
 
 	public String selectFragment(String alias, String suffix) {
 		return identifierSelectFragment( alias, suffix ) +
 				propertySelectFragment( alias, suffix, false );
 	}
 
 	public String[] getIdentifierAliases(String suffix) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		// was toUnqotedAliasStrings( getIdentiferColumnNames() ) before - now tried
 		// to remove that unqoting and missing aliases..
 		return new Alias( suffix ).toAliasStrings( getIdentifierAliases() );
 	}
 
 	public String[] getPropertyAliases(String suffix, int i) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		return new Alias( suffix ).toUnquotedAliasStrings( propertyColumnAliases[i] );
 	}
 
 	public String getDiscriminatorAlias(String suffix) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		// was toUnqotedAliasStrings( getdiscriminatorColumnName() ) before - now tried
 		// to remove that unqoting and missing aliases..
 		return entityMetamodel.hasSubclasses() ?
 				new Alias( suffix ).toAliasString( getDiscriminatorAlias() ) :
 				null;
 	}
 
 	public String identifierSelectFragment(String name, String suffix) {
 		return new SelectFragment()
 				.setSuffix( suffix )
 				.addColumns( name, getIdentifierColumnNames(), getIdentifierAliases() )
 				.toFragmentString()
 				.substring( 2 ); //strip leading ", "
 	}
 
 
 	public String propertySelectFragment(String tableAlias, String suffix, boolean allProperties) {
 		return propertySelectFragmentFragment( tableAlias, suffix, allProperties ).toFragmentString();
 	}
 
 	public SelectFragment propertySelectFragmentFragment(
 			String tableAlias,
 			String suffix,
 			boolean allProperties) {
 		SelectFragment select = new SelectFragment()
 				.setSuffix( suffix )
 				.setUsedAliases( getIdentifierAliases() );
 
 		int[] columnTableNumbers = getSubclassColumnTableNumberClosure();
 		String[] columnAliases = getSubclassColumnAliasClosure();
 		String[] columnReaderTemplates = getSubclassColumnReaderTemplateClosure();
 		for ( int i = 0; i < getSubclassColumnClosure().length; i++ ) {
 			boolean selectable = ( allProperties || !subclassColumnLazyClosure[i] ) &&
 				!isSubclassTableSequentialSelect( columnTableNumbers[i] ) &&
 				subclassColumnSelectableClosure[i];
 			if ( selectable ) {
 				String subalias = generateTableAlias( tableAlias, columnTableNumbers[i] );
 				select.addColumnTemplate( subalias, columnReaderTemplates[i], columnAliases[i] );
 			}
 		}
 
 		int[] formulaTableNumbers = getSubclassFormulaTableNumberClosure();
 		String[] formulaTemplates = getSubclassFormulaTemplateClosure();
 		String[] formulaAliases = getSubclassFormulaAliasClosure();
 		for ( int i = 0; i < getSubclassFormulaTemplateClosure().length; i++ ) {
 			boolean selectable = ( allProperties || !subclassFormulaLazyClosure[i] )
 				&& !isSubclassTableSequentialSelect( formulaTableNumbers[i] );
 			if ( selectable ) {
 				String subalias = generateTableAlias( tableAlias, formulaTableNumbers[i] );
 				select.addFormula( subalias, formulaTemplates[i], formulaAliases[i] );
 			}
 		}
 
 		if ( entityMetamodel.hasSubclasses() ) {
 			addDiscriminatorToSelect( select, tableAlias, suffix );
 		}
 
 		if ( hasRowId() ) {
 			select.addColumn( tableAlias, rowIdName, ROWID_ALIAS );
 		}
 
 		return select;
 	}
 
 	public Object[] getDatabaseSnapshot(Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Getting current persistent state for: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		try {
-			PreparedStatement ps = session.getTransactionCoordinator()
+			PreparedStatement ps = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( getSQLSnapshotSelectString() );
 			try {
 				getIdentifierType().nullSafeSet( ps, id, 1, session );
 				//if ( isVersioned() ) getVersionType().nullSafeSet( ps, version, getIdentifierColumnSpan()+1, session );
-				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( ps );
+				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					//if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 					//otherwise return the "hydrated" state (ie. associations are not resolved)
 					Type[] types = getPropertyTypes();
 					Object[] values = new Object[types.length];
 					boolean[] includeProperty = getPropertyUpdateability();
 					for ( int i = 0; i < types.length; i++ ) {
 						if ( includeProperty[i] ) {
 							values[i] = types[i].hydrate( rs, getPropertyAliases( "", i ), session, null ); //null owner ok??
 						}
 					}
 					return values;
 				}
 				finally {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, ps );
+					session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 				}
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
+				session.getJdbcCoordinator().getResourceRegistry().release( ps );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not retrieve snapshot: " + MessageHelper.infoString( this, id, getFactory() ),
 			        getSQLSnapshotSelectString()
 			);
 		}
 
 	}
 
 	@Override
 	public Serializable getIdByUniqueKey(Serializable key, String uniquePropertyName, SessionImplementor session) throws HibernateException {
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracef(
 					"resolving unique key [%s] to identifier for entity [%s]",
 					key,
 					getEntityName()
 			);
 		}
 
 		int propertyIndex = getSubclassPropertyIndex( uniquePropertyName );
 		if ( propertyIndex < 0 ) {
 			throw new HibernateException(
 					"Could not determine Type for property [" + uniquePropertyName + "] on entity [" + getEntityName() + "]"
 			);
 		}
 		Type propertyType = getSubclassPropertyType( propertyIndex );
 
 		try {
-			PreparedStatement ps = session.getTransactionCoordinator()
+			PreparedStatement ps = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( generateIdByUniqueKeySelectString( uniquePropertyName ) );
 			try {
 				propertyType.nullSafeSet( ps, key, 1, session );
-				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( ps );
+				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					//if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 					return (Serializable) getIdentifierType().nullSafeGet( rs, getIdentifierAliases(), session, null );
 				}
 				finally {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, ps );
+					session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 				}
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
+				session.getJdbcCoordinator().getResourceRegistry().release( ps );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					String.format(
 							"could not resolve unique property [%s] to identifier for entity [%s]",
 							uniquePropertyName,
 							getEntityName()
 					),
 					getSQLSnapshotSelectString()
 			);
 		}
 
 	}
 
 	protected String generateIdByUniqueKeySelectString(String uniquePropertyName) {
 		Select select = new Select( getFactory().getDialect() );
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "resolve id by unique property [" + getEntityName() + "." + uniquePropertyName + "]" );
 		}
 
 		final String rooAlias = getRootAlias();
 
 		select.setFromClause( fromTableFragment( rooAlias ) + fromJoinFragment( rooAlias, true, false ) );
 
 		SelectFragment selectFragment = new SelectFragment();
 		selectFragment.addColumns( rooAlias, getIdentifierColumnNames(), getIdentifierAliases() );
 		select.setSelectClause( selectFragment );
 
 		StringBuilder whereClauseBuffer = new StringBuilder();
 		final int uniquePropertyIndex = getSubclassPropertyIndex( uniquePropertyName );
 		final String uniquePropertyTableAlias = generateTableAlias(
 				rooAlias,
 				getSubclassPropertyTableNumber( uniquePropertyIndex )
 		);
 		String sep = "";
 		for ( String columnTemplate : getSubclassPropertyColumnReaderTemplateClosure()[uniquePropertyIndex] ) {
 			if ( columnTemplate == null ) {
 				continue;
 			}
 			final String columnReference = StringHelper.replace( columnTemplate, Template.TEMPLATE, uniquePropertyTableAlias );
 			whereClauseBuffer.append( sep ).append( columnReference ).append( "=?" );
 			sep = " and ";
 		}
 		for ( String formulaTemplate : getSubclassPropertyFormulaTemplateClosure()[uniquePropertyIndex] ) {
 			if ( formulaTemplate == null ) {
 				continue;
 			}
 			final String formulaReference = StringHelper.replace( formulaTemplate, Template.TEMPLATE, uniquePropertyTableAlias );
 			whereClauseBuffer.append( sep ).append( formulaReference ).append( "=?" );
 			sep = " and ";
 		}
 		whereClauseBuffer.append( whereJoinFragment( rooAlias, true, false ) );
 
 		select.setWhereClause( whereClauseBuffer.toString() );
 
 		return select.setOuterJoins( "", "" ).toStatementString();
 	}
 
 
 	/**
 	 * Generate the SQL that selects the version number by id
 	 */
 	protected String generateSelectVersionString() {
 		SimpleSelect select = new SimpleSelect( getFactory().getDialect() )
 				.setTableName( getVersionedTableName() );
 		if ( isVersioned() ) {
 			select.addColumn( versionColumnName );
 		}
 		else {
 			select.addColumns( rootTableKeyColumnNames );
 		}
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "get version " + getEntityName() );
 		}
 		return select.addCondition( rootTableKeyColumnNames, "=?" ).toStatementString();
 	}
 
 	public boolean[] getPropertyUniqueness() {
 		return propertyUniqueness;
 	}
 
 	protected String generateInsertGeneratedValuesSelectString() {
 		return generateGeneratedValuesSelectString( GenerationTiming.INSERT );
 	}
 
 	protected String generateUpdateGeneratedValuesSelectString() {
 		return generateGeneratedValuesSelectString( GenerationTiming.ALWAYS );
 	}
 
 	private String generateGeneratedValuesSelectString(final GenerationTiming generationTimingToMatch) {
 		Select select = new Select( getFactory().getDialect() );
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "get generated state " + getEntityName() );
 		}
 
 		String[] aliasedIdColumns = StringHelper.qualify( getRootAlias(), getIdentifierColumnNames() );
 
 		// Here we render the select column list based on the properties defined as being generated.
 		// For partial component generation, we currently just re-select the whole component
 		// rather than trying to handle the individual generated portions.
 		String selectClause = concretePropertySelectFragment(
 				getRootAlias(),
 				new InclusionChecker() {
 					@Override
 					public boolean includeProperty(int propertyNumber) {
 						final InDatabaseValueGenerationStrategy generationStrategy
 								= entityMetamodel.getInDatabaseValueGenerationStrategies()[propertyNumber];
 						return generationStrategy != null
 								&& timingsMatch( generationStrategy.getGenerationTiming(), generationTimingToMatch );
 					}
 				}
 		);
 		selectClause = selectClause.substring( 2 );
 
 		String fromClause = fromTableFragment( getRootAlias() ) +
 				fromJoinFragment( getRootAlias(), true, false );
 
 		String whereClause = new StringBuilder()
 				.append( StringHelper.join( "=? and ", aliasedIdColumns ) )
 				.append( "=?" )
 				.append( whereJoinFragment( getRootAlias(), true, false ) )
 				.toString();
 
 		return select.setSelectClause( selectClause )
 				.setFromClause( fromClause )
 				.setOuterJoins( "", "" )
 				.setWhereClause( whereClause )
 				.toStatementString();
 	}
 
 	protected static interface InclusionChecker {
 		public boolean includeProperty(int propertyNumber);
 	}
 
 	protected String concretePropertySelectFragment(String alias, final boolean[] includeProperty) {
 		return concretePropertySelectFragment(
 				alias,
 				new InclusionChecker() {
 					public boolean includeProperty(int propertyNumber) {
 						return includeProperty[propertyNumber];
 					}
 				}
 		);
 	}
 
 	protected String concretePropertySelectFragment(String alias, InclusionChecker inclusionChecker) {
 		int propertyCount = getPropertyNames().length;
 		int[] propertyTableNumbers = getPropertyTableNumbersInSelect();
 		SelectFragment frag = new SelectFragment();
 		for ( int i = 0; i < propertyCount; i++ ) {
 			if ( inclusionChecker.includeProperty( i ) ) {
 				frag.addColumnTemplates(
 						generateTableAlias( alias, propertyTableNumbers[i] ),
 						propertyColumnReaderTemplates[i],
 						propertyColumnAliases[i]
 				);
 				frag.addFormulas(
 						generateTableAlias( alias, propertyTableNumbers[i] ),
 						propertyColumnFormulaTemplates[i],
 						propertyColumnAliases[i]
 				);
 			}
 		}
 		return frag.toFragmentString();
 	}
 
 	protected String generateSnapshotSelectString() {
 
 		//TODO: should we use SELECT .. FOR UPDATE?
 
 		Select select = new Select( getFactory().getDialect() );
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "get current state " + getEntityName() );
 		}
 
 		String[] aliasedIdColumns = StringHelper.qualify( getRootAlias(), getIdentifierColumnNames() );
 		String selectClause = StringHelper.join( ", ", aliasedIdColumns ) +
 				concretePropertySelectFragment( getRootAlias(), getPropertyUpdateability() );
 
 		String fromClause = fromTableFragment( getRootAlias() ) +
 				fromJoinFragment( getRootAlias(), true, false );
 
 		String whereClause = new StringBuilder()
 			.append( StringHelper.join( "=? and ",
 					aliasedIdColumns ) )
 			.append( "=?" )
 			.append( whereJoinFragment( getRootAlias(), true, false ) )
 			.toString();
 
 		/*if ( isVersioned() ) {
 			where.append(" and ")
 				.append( getVersionColumnName() )
 				.append("=?");
 		}*/
 
 		return select.setSelectClause( selectClause )
 				.setFromClause( fromClause )
 				.setOuterJoins( "", "" )
 				.setWhereClause( whereClause )
 				.toStatementString();
 	}
 
 	public Object forceVersionIncrement(Serializable id, Object currentVersion, SessionImplementor session) {
 		if ( !isVersioned() ) {
 			throw new AssertionFailure( "cannot force version increment on non-versioned entity" );
 		}
 
 		if ( isVersionPropertyGenerated() ) {
 			// the difficulty here is exactly what do we update in order to
 			// force the version to be incremented in the db...
 			throw new HibernateException( "LockMode.FORCE is currently not supported for generated version properties" );
 		}
 
 		Object nextVersion = getVersionType().next( currentVersion, session );
         if (LOG.isTraceEnabled()) LOG.trace("Forcing version increment [" + MessageHelper.infoString(this, id, getFactory()) + "; "
                                             + getVersionType().toLoggableString(currentVersion, getFactory()) + " -> "
                                             + getVersionType().toLoggableString(nextVersion, getFactory()) + "]");
 
 		// todo : cache this sql...
 		String versionIncrementString = generateVersionIncrementUpdateString();
 		PreparedStatement st = null;
 		try {
-			st = session.getTransactionCoordinator()
+			st = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( versionIncrementString, false );
 			try {
 				getVersionType().nullSafeSet( st, nextVersion, 1, session );
 				getIdentifierType().nullSafeSet( st, id, 2, session );
 				getVersionType().nullSafeSet( st, currentVersion, 2 + getIdentifierColumnSpan(), session );
-				int rows = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st );
+				int rows = session.getJdbcCoordinator().getResultSetReturn().executeUpdate( st );
 				if ( rows != 1 ) {
 					throw new StaleObjectStateException( getEntityName(), id );
 				}
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+				session.getJdbcCoordinator().getResourceRegistry().release( st );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not retrieve version: " +
 					MessageHelper.infoString( this, id, getFactory() ),
 					getVersionSelectString()
 				);
 		}
 
 		return nextVersion;
 	}
 
 	private String generateVersionIncrementUpdateString() {
 		Update update = new Update( getFactory().getDialect() );
 		update.setTableName( getTableName( 0 ) );
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			update.setComment( "forced version increment" );
 		}
 		update.addColumn( getVersionColumnName() );
 		update.addPrimaryKeyColumns( getIdentifierColumnNames() );
 		update.setVersionColumnName( getVersionColumnName() );
 		return update.toStatementString();
 	}
 
 	/**
 	 * Retrieve the version number
 	 */
 	public Object getCurrentVersion(Serializable id, SessionImplementor session) throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Getting version: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		try {
-			PreparedStatement st = session.getTransactionCoordinator()
+			PreparedStatement st = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( getVersionSelectString() );
 			try {
 				getIdentifierType().nullSafeSet( st, id, 1, session );
-				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
+				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
 					if ( !rs.next() ) {
 						return null;
 					}
 					if ( !isVersioned() ) {
 						return this;
 					}
 					return getVersionType().nullSafeGet( rs, getVersionColumnName(), session, null );
 				}
 				finally {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
+					session.getJdbcCoordinator().getResourceRegistry().release( rs, st );
 				}
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
+				session.getJdbcCoordinator().getResourceRegistry().release( st );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not retrieve version: " + MessageHelper.infoString( this, id, getFactory() ),
 					getVersionSelectString()
 			);
 		}
 	}
 
 	protected void initLockers() {
 		lockers.put( LockMode.READ, generateLocker( LockMode.READ ) );
 		lockers.put( LockMode.UPGRADE, generateLocker( LockMode.UPGRADE ) );
 		lockers.put( LockMode.UPGRADE_NOWAIT, generateLocker( LockMode.UPGRADE_NOWAIT ) );
 		lockers.put( LockMode.UPGRADE_SKIPLOCKED, generateLocker( LockMode.UPGRADE_SKIPLOCKED ) );
 		lockers.put( LockMode.FORCE, generateLocker( LockMode.FORCE ) );
 		lockers.put( LockMode.PESSIMISTIC_READ, generateLocker( LockMode.PESSIMISTIC_READ ) );
 		lockers.put( LockMode.PESSIMISTIC_WRITE, generateLocker( LockMode.PESSIMISTIC_WRITE ) );
 		lockers.put( LockMode.PESSIMISTIC_FORCE_INCREMENT, generateLocker( LockMode.PESSIMISTIC_FORCE_INCREMENT ) );
 		lockers.put( LockMode.OPTIMISTIC, generateLocker( LockMode.OPTIMISTIC ) );
 		lockers.put( LockMode.OPTIMISTIC_FORCE_INCREMENT, generateLocker( LockMode.OPTIMISTIC_FORCE_INCREMENT ) );
 	}
 
 	protected LockingStrategy generateLocker(LockMode lockMode) {
 		return factory.getDialect().getLockingStrategy( this, lockMode );
 	}
 
 	private LockingStrategy getLocker(LockMode lockMode) {
 		return ( LockingStrategy ) lockers.get( lockMode );
 	}
 
 	public void lock(
 			Serializable id,
 	        Object version,
 	        Object object,
 	        LockMode lockMode,
 	        SessionImplementor session) throws HibernateException {
 		getLocker( lockMode ).lock( id, version, object, LockOptions.WAIT_FOREVER, session );
 	}
 
 	public void lock(
 			Serializable id,
 	        Object version,
 	        Object object,
 	        LockOptions lockOptions,
 	        SessionImplementor session) throws HibernateException {
 		getLocker( lockOptions.getLockMode() ).lock( id, version, object, lockOptions.getTimeOut(), session );
 	}
 
 	public String getRootTableName() {
 		return getSubclassTableName( 0 );
 	}
 
 	public String getRootTableAlias(String drivingAlias) {
 		return drivingAlias;
 	}
 
 	public String[] getRootTableIdentifierColumnNames() {
 		return getRootTableKeyColumnNames();
 	}
 
 	public String[] toColumns(String alias, String propertyName) throws QueryException {
 		return propertyMapping.toColumns( alias, propertyName );
 	}
 
 	public String[] toColumns(String propertyName) throws QueryException {
 		return propertyMapping.getColumnNames( propertyName );
 	}
 
 	public Type toType(String propertyName) throws QueryException {
 		return propertyMapping.toType( propertyName );
 	}
 
 	public String[] getPropertyColumnNames(String propertyName) {
 		return propertyMapping.getColumnNames( propertyName );
 	}
 
 	/**
 	 * Warning:
 	 * When there are duplicated property names in the subclasses
 	 * of the class, this method may return the wrong table
 	 * number for the duplicated subclass property (note that
 	 * SingleTableEntityPersister defines an overloaded form
 	 * which takes the entity name.
 	 */
 	public int getSubclassPropertyTableNumber(String propertyPath) {
 		String rootPropertyName = StringHelper.root(propertyPath);
 		Type type = propertyMapping.toType(rootPropertyName);
 		if ( type.isAssociationType() ) {
 			AssociationType assocType = ( AssociationType ) type;
 			if ( assocType.useLHSPrimaryKey() ) {
 				// performance op to avoid the array search
 				return 0;
 			}
 			else if ( type.isCollectionType() ) {
 				// properly handle property-ref-based associations
 				rootPropertyName = assocType.getLHSPropertyName();
 			}
 		}
 		//Enable for HHH-440, which we don't like:
 		/*if ( type.isComponentType() && !propertyName.equals(rootPropertyName) ) {
 			String unrooted = StringHelper.unroot(propertyName);
 			int idx = ArrayHelper.indexOf( getSubclassColumnClosure(), unrooted );
 			if ( idx != -1 ) {
 				return getSubclassColumnTableNumberClosure()[idx];
 			}
 		}*/
 		int index = ArrayHelper.indexOf( getSubclassPropertyNameClosure(), rootPropertyName); //TODO: optimize this better!
 		return index==-1 ? 0 : getSubclassPropertyTableNumber(index);
 	}
 
 	public Declarer getSubclassPropertyDeclarer(String propertyPath) {
 		int tableIndex = getSubclassPropertyTableNumber( propertyPath );
 		if ( tableIndex == 0 ) {
 			return Declarer.CLASS;
 		}
 		else if ( isClassOrSuperclassTable( tableIndex ) ) {
 			return Declarer.SUPERCLASS;
 		}
 		else {
 			return Declarer.SUBCLASS;
 		}
 	}
 
 	private DiscriminatorMetadata discriminatorMetadata;
 
 	public DiscriminatorMetadata getTypeDiscriminatorMetadata() {
 		if ( discriminatorMetadata == null ) {
 			discriminatorMetadata = buildTypeDiscriminatorMetadata();
 		}
 		return discriminatorMetadata;
 	}
 
 	private DiscriminatorMetadata buildTypeDiscriminatorMetadata() {
 		return new DiscriminatorMetadata() {
 			public String getSqlFragment(String sqlQualificationAlias) {
 				return toColumns( sqlQualificationAlias, ENTITY_CLASS )[0];
 			}
 
 			public Type getResolutionType() {
 				return new DiscriminatorType( getDiscriminatorType(), AbstractEntityPersister.this );
 			}
 		};
 	}
 
 	public static String generateTableAlias(String rootAlias, int tableNumber) {
 		if ( tableNumber == 0 ) {
 			return rootAlias;
 		}
 		StringBuilder buf = new StringBuilder().append( rootAlias );
 		if ( !rootAlias.endsWith( "_" ) ) {
 			buf.append( '_' );
 		}
 		return buf.append( tableNumber ).append( '_' ).toString();
 	}
 
 	public String[] toColumns(String name, final int i) {
 		final String alias = generateTableAlias( name, getSubclassPropertyTableNumber( i ) );
 		String[] cols = getSubclassPropertyColumnNames( i );
 		String[] templates = getSubclassPropertyFormulaTemplateClosure()[i];
 		String[] result = new String[cols.length];
 		for ( int j = 0; j < cols.length; j++ ) {
 			if ( cols[j] == null ) {
 				result[j] = StringHelper.replace( templates[j], Template.TEMPLATE, alias );
 			}
 			else {
 				result[j] = StringHelper.qualify( alias, cols[j] );
 			}
 		}
 		return result;
 	}
 
 	private int getSubclassPropertyIndex(String propertyName) {
 		return ArrayHelper.indexOf(subclassPropertyNameClosure, propertyName);
 	}
 
 	protected String[] getPropertySubclassNames() {
 		return propertySubclassNames;
 	}
 
 	public String[] getPropertyColumnNames(int i) {
 		return propertyColumnNames[i];
 	}
 
 	public String[] getPropertyColumnWriters(int i) {
 		return propertyColumnWriters[i];
 	}
 
 	protected int getPropertyColumnSpan(int i) {
 		return propertyColumnSpans[i];
 	}
 
 	protected boolean hasFormulaProperties() {
 		return hasFormulaProperties;
 	}
 
 	public FetchMode getFetchMode(int i) {
 		return subclassPropertyFetchModeClosure[i];
 	}
 
 	public CascadeStyle getCascadeStyle(int i) {
 		return subclassPropertyCascadeStyleClosure[i];
 	}
 
 	public Type getSubclassPropertyType(int i) {
 		return subclassPropertyTypeClosure[i];
 	}
 
 	public String getSubclassPropertyName(int i) {
 		return subclassPropertyNameClosure[i];
 	}
 
 	public int countSubclassProperties() {
 		return subclassPropertyTypeClosure.length;
 	}
 
 	public String[] getSubclassPropertyColumnNames(int i) {
 		return subclassPropertyColumnNameClosure[i];
 	}
 
 	public boolean isDefinedOnSubclass(int i) {
 		return propertyDefinedOnSubclass[i];
 	}
 
 	@Override
 	public String[][] getSubclassPropertyFormulaTemplateClosure() {
 		return subclassPropertyFormulaTemplateClosure;
 	}
 
 	protected Type[] getSubclassPropertyTypeClosure() {
 		return subclassPropertyTypeClosure;
 	}
 
 	protected String[][] getSubclassPropertyColumnNameClosure() {
 		return subclassPropertyColumnNameClosure;
 	}
 
 	public String[][] getSubclassPropertyColumnReaderClosure() {
 		return subclassPropertyColumnReaderClosure;
 	}
 
 	public String[][] getSubclassPropertyColumnReaderTemplateClosure() {
 		return subclassPropertyColumnReaderTemplateClosure;
 	}
 
 	protected String[] getSubclassPropertyNameClosure() {
 		return subclassPropertyNameClosure;
 	}
 
 	@Override
 	public int[] resolveAttributeIndexes(Set<String> properties) {
 		Iterator<String> iter = properties.iterator();
 		int[] fields = new int[properties.size()];
 		int counter = 0;
 		while(iter.hasNext()) {
 			Integer index = entityMetamodel.getPropertyIndexOrNull( iter.next() );
 			if ( index != null )
 				fields[counter++] = index;
 		}
 		return fields;
 	}
 
 	protected String[] getSubclassPropertySubclassNameClosure() {
 		return subclassPropertySubclassNameClosure;
 	}
 
 	protected String[] getSubclassColumnClosure() {
 		return subclassColumnClosure;
 	}
 
 	protected String[] getSubclassColumnAliasClosure() {
 		return subclassColumnAliasClosure;
 	}
 
 	public String[] getSubclassColumnReaderTemplateClosure() {
 		return subclassColumnReaderTemplateClosure;
 	}
 
 	protected String[] getSubclassFormulaClosure() {
 		return subclassFormulaClosure;
 	}
 
 	protected String[] getSubclassFormulaTemplateClosure() {
 		return subclassFormulaTemplateClosure;
 	}
 
 	protected String[] getSubclassFormulaAliasClosure() {
 		return subclassFormulaAliasClosure;
 	}
 
 	public String[] getSubclassPropertyColumnAliases(String propertyName, String suffix) {
 		String[] rawAliases = ( String[] ) subclassPropertyAliases.get( propertyName );
 
 		if ( rawAliases == null ) {
 			return null;
 		}
 
 		String[] result = new String[rawAliases.length];
 		for ( int i = 0; i < rawAliases.length; i++ ) {
 			result[i] = new Alias( suffix ).toUnquotedAliasString( rawAliases[i] );
 		}
 		return result;
 	}
 
 	public String[] getSubclassPropertyColumnNames(String propertyName) {
 		//TODO: should we allow suffixes on these ?
 		return ( String[] ) subclassPropertyColumnNames.get( propertyName );
 	}
 
 
 
 	//This is really ugly, but necessary:
 	/**
 	 * Must be called by subclasses, at the end of their constructors
 	 */
 	protected void initSubclassPropertyAliasesMap(PersistentClass model) throws MappingException {
 
 		// ALIASES
 		internalInitSubclassPropertyAliasesMap( null, model.getSubclassPropertyClosureIterator() );
 
 		// aliases for identifier ( alias.id ); skip if the entity defines a non-id property named 'id'
 		if ( ! entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 			subclassPropertyAliases.put( ENTITY_ID, getIdentifierAliases() );
 			subclassPropertyColumnNames.put( ENTITY_ID, getIdentifierColumnNames() );
 		}
 
 		// aliases named identifier ( alias.idname )
 		if ( hasIdentifierProperty() ) {
 			subclassPropertyAliases.put( getIdentifierPropertyName(), getIdentifierAliases() );
 			subclassPropertyColumnNames.put( getIdentifierPropertyName(), getIdentifierColumnNames() );
 		}
 
 		// aliases for composite-id's
 		if ( getIdentifierType().isComponentType() ) {
 			// Fetch embedded identifiers propertynames from the "virtual" identifier component
 			CompositeType componentId = ( CompositeType ) getIdentifierType();
 			String[] idPropertyNames = componentId.getPropertyNames();
 			String[] idAliases = getIdentifierAliases();
 			String[] idColumnNames = getIdentifierColumnNames();
 
 			for ( int i = 0; i < idPropertyNames.length; i++ ) {
 				if ( entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 					subclassPropertyAliases.put(
 							ENTITY_ID + "." + idPropertyNames[i],
 							new String[] { idAliases[i] }
 					);
 					subclassPropertyColumnNames.put(
 							ENTITY_ID + "." + getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idColumnNames[i] }
 					);
 				}
 //				if (hasIdentifierProperty() && !ENTITY_ID.equals( getIdentifierPropertyName() ) ) {
 				if ( hasIdentifierProperty() ) {
 					subclassPropertyAliases.put(
 							getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idAliases[i] }
 					);
 					subclassPropertyColumnNames.put(
 							getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idColumnNames[i] }
 					);
 				}
 				else {
 					// embedded composite ids ( alias.idname1, alias.idname2 )
 					subclassPropertyAliases.put( idPropertyNames[i], new String[] { idAliases[i] } );
 					subclassPropertyColumnNames.put( idPropertyNames[i],  new String[] { idColumnNames[i] } );
 				}
 			}
 		}
 
 		if ( entityMetamodel.isPolymorphic() ) {
 			subclassPropertyAliases.put( ENTITY_CLASS, new String[] { getDiscriminatorAlias() } );
 			subclassPropertyColumnNames.put( ENTITY_CLASS, new String[] { getDiscriminatorColumnName() } );
 		}
 
 	}
 
 	private void internalInitSubclassPropertyAliasesMap(String path, Iterator propertyIterator) {
 		while ( propertyIterator.hasNext() ) {
 
 			Property prop = ( Property ) propertyIterator.next();
 			String propname = path == null ? prop.getName() : path + "." + prop.getName();
 			if ( prop.isComposite() ) {
 				Component component = ( Component ) prop.getValue();
 				Iterator compProps = component.getPropertyIterator();
 				internalInitSubclassPropertyAliasesMap( propname, compProps );
 			}
 			else {
 				String[] aliases = new String[prop.getColumnSpan()];
 				String[] cols = new String[prop.getColumnSpan()];
 				Iterator colIter = prop.getColumnIterator();
 				int l = 0;
 				while ( colIter.hasNext() ) {
 					Selectable thing = ( Selectable ) colIter.next();
 					aliases[l] = thing.getAlias( getFactory().getDialect(), prop.getValue().getTable() );
 					cols[l] = thing.getText( getFactory().getDialect() ); // TODO: skip formulas?
 					l++;
 				}
 
 				subclassPropertyAliases.put( propname, aliases );
 				subclassPropertyColumnNames.put( propname, cols );
 			}
 		}
 
 	}
 
 	public Object loadByUniqueKey(
 			String propertyName,
 			Object uniqueKey,
 			SessionImplementor session) throws HibernateException {
 		return getAppropriateUniqueKeyLoader( propertyName, session ).loadByUniqueKey( session, uniqueKey );
 	}
 
 	private EntityLoader getAppropriateUniqueKeyLoader(String propertyName, SessionImplementor session) {
 		final boolean useStaticLoader = !session.getLoadQueryInfluencers().hasEnabledFilters()
 				&& !session.getLoadQueryInfluencers().hasEnabledFetchProfiles()
 				&& propertyName.indexOf('.')<0; //ugly little workaround for fact that createUniqueKeyLoaders() does not handle component properties
 
 		if ( useStaticLoader ) {
 			return ( EntityLoader ) uniqueKeyLoaders.get( propertyName );
 		}
 		else {
 			return createUniqueKeyLoader(
 					propertyMapping.toType( propertyName ),
 					propertyMapping.toColumns( propertyName ),
 					session.getLoadQueryInfluencers()
 			);
 		}
 	}
 
 	public int getPropertyIndex(String propertyName) {
 		return entityMetamodel.getPropertyIndex(propertyName);
 	}
 
 	protected void createUniqueKeyLoaders() throws MappingException {
 		Type[] propertyTypes = getPropertyTypes();
 		String[] propertyNames = getPropertyNames();
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( propertyUniqueness[i] ) {
 				//don't need filters for the static loaders
 				uniqueKeyLoaders.put(
 						propertyNames[i],
 						createUniqueKeyLoader(
 								propertyTypes[i],
 								getPropertyColumnNames( i ),
 								LoadQueryInfluencers.NONE
 						)
 				);
 				//TODO: create uk loaders for component properties
 			}
 		}
 	}
 
 	private EntityLoader createUniqueKeyLoader(
 			Type uniqueKeyType,
 			String[] columns,
 			LoadQueryInfluencers loadQueryInfluencers) {
 		if ( uniqueKeyType.isEntityType() ) {
 			String className = ( ( EntityType ) uniqueKeyType ).getAssociatedEntityName();
 			uniqueKeyType = getFactory().getEntityPersister( className ).getIdentifierType();
 		}
 		return new EntityLoader(
 				this,
 				columns,
 				uniqueKeyType,
 				1,
 				LockMode.NONE,
 				getFactory(),
 				loadQueryInfluencers
 		);
 	}
 
 	protected String getSQLWhereString(String alias) {
 		return StringHelper.replace( sqlWhereStringTemplate, Template.TEMPLATE, alias );
 	}
 
 	protected boolean hasWhere() {
 		return sqlWhereString != null;
 	}
 
 	private void initOrdinaryPropertyPaths(Mapping mapping) throws MappingException {
 		for ( int i = 0; i < getSubclassPropertyNameClosure().length; i++ ) {
 			propertyMapping.initPropertyPaths(
 					getSubclassPropertyNameClosure()[i],
 					getSubclassPropertyTypeClosure()[i],
 					getSubclassPropertyColumnNameClosure()[i],
 					getSubclassPropertyColumnReaderClosure()[i],
 					getSubclassPropertyColumnReaderTemplateClosure()[i],
 					getSubclassPropertyFormulaTemplateClosure()[i],
 					mapping
 			);
 		}
 	}
 
 	private void initIdentifierPropertyPaths(Mapping mapping) throws MappingException {
 		String idProp = getIdentifierPropertyName();
 		if ( idProp != null ) {
 			propertyMapping.initPropertyPaths( idProp, getIdentifierType(), getIdentifierColumnNames(),
 					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping );
 		}
 		if ( entityMetamodel.getIdentifierProperty().isEmbedded() ) {
 			propertyMapping.initPropertyPaths( null, getIdentifierType(), getIdentifierColumnNames(),
 					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping );
 		}
 		if ( ! entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 			propertyMapping.initPropertyPaths( ENTITY_ID, getIdentifierType(), getIdentifierColumnNames(),
 					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping );
 		}
 	}
 
 	private void initDiscriminatorPropertyPath(Mapping mapping) throws MappingException {
 		propertyMapping.initPropertyPaths( ENTITY_CLASS,
 				getDiscriminatorType(),
 				new String[]{getDiscriminatorColumnName()},
 				new String[]{getDiscriminatorColumnReaders()},
 				new String[]{getDiscriminatorColumnReaderTemplate()},
 				new String[]{getDiscriminatorFormulaTemplate()},
 				getFactory() );
 	}
 
 	protected void initPropertyPaths(Mapping mapping) throws MappingException {
 		initOrdinaryPropertyPaths(mapping);
 		initOrdinaryPropertyPaths(mapping); //do two passes, for collection property-ref!
 		initIdentifierPropertyPaths(mapping);
 		if ( entityMetamodel.isPolymorphic() ) {
 			initDiscriminatorPropertyPath( mapping );
 		}
 	}
 
 	protected UniqueEntityLoader createEntityLoader(
 			LockMode lockMode,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		//TODO: disable batch loading if lockMode > READ?
 		return BatchingEntityLoaderBuilder.getBuilder( getFactory() )
 				.buildLoader( this, batchSize, lockMode, getFactory(), loadQueryInfluencers );
 	}
 
 	protected UniqueEntityLoader createEntityLoader(
 			LockOptions lockOptions,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		//TODO: disable batch loading if lockMode > READ?
 		return BatchingEntityLoaderBuilder.getBuilder( getFactory() )
 				.buildLoader( this, batchSize, lockOptions, getFactory(), loadQueryInfluencers );
 	}
 
 	/**
 	 * Used internally to create static loaders.  These are the default set of loaders used to handle get()/load()
 	 * processing.  lock() handling is done by the LockingStrategy instances (see {@link #getLocker})
 	 *
 	 * @param lockMode The lock mode to apply to the thing being loaded.
 	 * @return
 	 *
 	 * @throws MappingException
 	 */
 	protected UniqueEntityLoader createEntityLoader(LockMode lockMode) throws MappingException {
 		return createEntityLoader( lockMode, LoadQueryInfluencers.NONE );
 	}
 
 	protected boolean check(int rows, Serializable id, int tableNumber, Expectation expectation, PreparedStatement statement) throws HibernateException {
 		try {
 			expectation.verifyOutcome( rows, statement, -1 );
 		}
 		catch( StaleStateException e ) {
 			if ( !isNullableTable( tableNumber ) ) {
 				if ( getFactory().getStatistics().isStatisticsEnabled() ) {
 					getFactory().getStatisticsImplementor()
 							.optimisticFailure( getEntityName() );
 				}
 				throw new StaleObjectStateException( getEntityName(), id );
 			}
 			return false;
 		}
 		catch( TooManyRowsAffectedException e ) {
 			throw new HibernateException(
 					"Duplicate identifier in table for: " +
 					MessageHelper.infoString( this, id, getFactory() )
 			);
 		}
 		catch ( Throwable t ) {
 			return false;
 		}
 		return true;
 	}
 
 	protected String generateUpdateString(boolean[] includeProperty, int j, boolean useRowId) {
 		return generateUpdateString( includeProperty, j, null, useRowId );
 	}
 
 	/**
 	 * Generate the SQL that updates a row by id (and version)
 	 */
 	protected String generateUpdateString(final boolean[] includeProperty,
 										  final int j,
 										  final Object[] oldFields,
 										  final boolean useRowId) {
 
 		Update update = new Update( getFactory().getDialect() ).setTableName( getTableName( j ) );
 
 		// select the correct row by either pk or rowid
 		if ( useRowId ) {
 			update.addPrimaryKeyColumns( new String[]{rowIdName} ); //TODO: eventually, rowIdName[j]
 		}
 		else {
 			update.addPrimaryKeyColumns( getKeyColumns( j ) );
 		}
 
 		boolean hasColumns = false;
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) 
 					&& !lobProperties.contains( i ) ) {
 				// this is a property of the table, which we are updating
 				update.addColumns( getPropertyColumnNames(i),
 						propertyColumnUpdateable[i], propertyColumnWriters[i] );
 				hasColumns = hasColumns || getPropertyColumnSpan( i ) > 0;
 			}
 		}
 		
 		// HHH-4635
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) ) {
 				// this property belongs on the table and is to be inserted
 				update.addColumns( getPropertyColumnNames(i),
 						propertyColumnUpdateable[i], propertyColumnWriters[i] );
 				hasColumns = true;
 			}
 		}
 
 		if ( j == 0 && isVersioned() && entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.VERSION ) {
 			// this is the root (versioned) table, and we are using version-based
 			// optimistic locking;  if we are not updating the version, also don't
 			// check it (unless this is a "generated" version column)!
 			if ( checkVersion( includeProperty ) ) {
 				update.setVersionColumnName( getVersionColumnName() );
 				hasColumns = true;
 			}
 		}
 		else if ( isAllOrDirtyOptLocking() && oldFields != null ) {
 			// we are using "all" or "dirty" property-based optimistic locking
 
 			boolean[] includeInWhere = entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.ALL
 					? getPropertyUpdateability() //optimistic-lock="all", include all updatable properties
 					: includeProperty; 			 //optimistic-lock="dirty", include all properties we are updating this time
 
 			boolean[] versionability = getPropertyVersionability();
 			Type[] types = getPropertyTypes();
 			for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 				boolean include = includeInWhere[i] &&
 						isPropertyOfTable( i, j ) &&
 						versionability[i];
 				if ( include ) {
 					// this property belongs to the table, and it is not specifically
 					// excluded from optimistic locking by optimistic-lock="false"
 					String[] propertyColumnNames = getPropertyColumnNames( i );
 					String[] propertyColumnWriters = getPropertyColumnWriters( i );
 					boolean[] propertyNullness = types[i].toColumnNullness( oldFields[i], getFactory() );
 					for ( int k=0; k<propertyNullness.length; k++ ) {
 						if ( propertyNullness[k] ) {
 							update.addWhereColumn( propertyColumnNames[k], "=" + propertyColumnWriters[k] );
 						}
 						else {
 							update.addWhereColumn( propertyColumnNames[k], " is null" );
 						}
 					}
 				}
 			}
 
 		}
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			update.setComment( "update " + getEntityName() );
 		}
 
 		return hasColumns ? update.toStatementString() : null;
 	}
 
 	private boolean checkVersion(final boolean[] includeProperty) {
 		return includeProperty[ getVersionProperty() ]
 				|| entityMetamodel.isVersionGenerated();
 	}
 
 	protected String generateInsertString(boolean[] includeProperty, int j) {
 		return generateInsertString( false, includeProperty, j );
 	}
 
 	protected String generateInsertString(boolean identityInsert, boolean[] includeProperty) {
 		return generateInsertString( identityInsert, includeProperty, 0 );
 	}
 
 	/**
 	 * Generate the SQL that inserts a row
 	 */
 	protected String generateInsertString(boolean identityInsert, boolean[] includeProperty, int j) {
 
 		// todo : remove the identityInsert param and variations;
 		//   identity-insert strings are now generated from generateIdentityInsertString()
 
 		Insert insert = new Insert( getFactory().getDialect() )
 				.setTableName( getTableName( j ) );
 
 		// add normal properties
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			// the incoming 'includeProperty' array only accounts for insertable defined at the root level, it
 			// does not account for partially generated composites etc.  We also need to account for generation
 			// values
 			if ( isPropertyOfTable( i, j ) ) {
 				if ( !lobProperties.contains( i ) ) {
 					final InDatabaseValueGenerationStrategy generationStrategy = entityMetamodel.getInDatabaseValueGenerationStrategies()[i];
 					if ( generationStrategy != null && generationStrategy.getGenerationTiming().includesInsert() ) {
 						if ( generationStrategy.referenceColumnsInSql() ) {
 							final String[] values;
 							if ( generationStrategy.getReferencedColumnValues() == null ) {
 								values = propertyColumnWriters[i];
 							}
 							else {
 								final int numberOfColumns = propertyColumnWriters[i].length;
 								values = new String[ numberOfColumns ];
 								for ( int x = 0; x < numberOfColumns; x++ ) {
 									if ( generationStrategy.getReferencedColumnValues()[x] != null ) {
 										values[x] = generationStrategy.getReferencedColumnValues()[x];
 									}
 									else {
 										values[x] = propertyColumnWriters[i][x];
 									}
 								}
 							}
 							insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], values );
 						}
 					}
 					else if ( includeProperty[i] ) {
 						insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], propertyColumnWriters[i] );
 					}
 				}
 			}
 		}
 
 		// add the discriminator
 		if ( j == 0 ) {
 			addDiscriminatorToInsert( insert );
 		}
 
 		// add the primary key
 		if ( j == 0 && identityInsert ) {
 			insert.addIdentityColumn( getKeyColumns( 0 )[0] );
 		}
 		else {
 			insert.addColumns( getKeyColumns( j ) );
 		}
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			insert.setComment( "insert " + getEntityName() );
 		}
 		
 		// HHH-4635
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) ) {
 				// this property belongs on the table and is to be inserted
 				insert.addColumns(
 						getPropertyColumnNames(i),
 						propertyColumnInsertable[i],
 						propertyColumnWriters[i]
 				);
 			}
 		}
 
 		String result = insert.toStatementString();
 
 		// append the SQL to return the generated identifier
 		if ( j == 0 && identityInsert && useInsertSelectIdentity() ) { //TODO: suck into Insert
 			result = getFactory().getDialect().appendIdentitySelectToInsert( result );
 		}
 
 		return result;
 	}
 
 	/**
 	 * Used to generate an insery statement against the root table in the
 	 * case of identifier generation strategies where the insert statement
 	 * executions actually generates the identifier value.
 	 *
 	 * @param includeProperty indices of the properties to include in the
 	 * insert statement.
 	 * @return The insert SQL statement string
 	 */
 	protected String generateIdentityInsertString(boolean[] includeProperty) {
 		Insert insert = identityDelegate.prepareIdentifierGeneratingInsert();
 		insert.setTableName( getTableName( 0 ) );
 
 		// add normal properties except lobs
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, 0 ) && !lobProperties.contains( i ) ) {
 				// this property belongs on the table and is to be inserted
 				insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], propertyColumnWriters[i] );
 			}
 		}
 
 		// HHH-4635 & HHH-8103
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, 0 ) ) {
 				insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], propertyColumnWriters[i] );
 			}
 		}
 
 		// add the discriminator
 		addDiscriminatorToInsert( insert );
 
 		// delegate already handles PK columns
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			insert.setComment( "insert " + getEntityName() );
 		}
 
 		return insert.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL that deletes a row by id (and version)
 	 */
 	protected String generateDeleteString(int j) {
 		Delete delete = new Delete()
 				.setTableName( getTableName( j ) )
 				.addPrimaryKeyColumns( getKeyColumns( j ) );
 		if ( j == 0 ) {
 			delete.setVersionColumnName( getVersionColumnName() );
 		}
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			delete.setComment( "delete " + getEntityName() );
 		}
 		return delete.toStatementString();
 	}
 
 	protected int dehydrate(
 			Serializable id,
 			Object[] fields,
 			boolean[] includeProperty,
 			boolean[][] includeColumns,
 			int j,
 			PreparedStatement st,
 			SessionImplementor session,
 			boolean isUpdate) throws HibernateException, SQLException {
 		return dehydrate( id, fields, null, includeProperty, includeColumns, j, st, session, 1, isUpdate );
 	}
 
 	/**
 	 * Marshall the fields of a persistent instance to a prepared statement
 	 */
 	protected int dehydrate(
 			final Serializable id,
 			final Object[] fields,
 			final Object rowId,
 			final boolean[] includeProperty,
 			final boolean[][] includeColumns,
 			final int j,
 			final PreparedStatement ps,
 			final SessionImplementor session,
 			int index,
 			boolean isUpdate ) throws SQLException, HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Dehydrating entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j )
 					&& !lobProperties.contains( i )) {
 				getPropertyTypes()[i].nullSafeSet( ps, fields[i], index, includeColumns[i], session );
 				index += ArrayHelper.countTrue( includeColumns[i] ); //TODO:  this is kinda slow...
 			}
 		}
 		
 		if ( !isUpdate ) {
 			index += dehydrateId( id, rowId, ps, session, index );
 		}
 		
 		// HHH-4635
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) ) {
 				getPropertyTypes()[i].nullSafeSet( ps, fields[i], index, includeColumns[i], session );
 				index += ArrayHelper.countTrue( includeColumns[i] ); //TODO:  this is kinda slow...
 			}
 		}
 		
 		if ( isUpdate ) {
 			index += dehydrateId( id, rowId, ps, session, index );
 		}
 
 		return index;
 
 	}
 	
 	private int dehydrateId( 
 			final Serializable id,
 			final Object rowId,
 			final PreparedStatement ps,
 			final SessionImplementor session,
 			int index ) throws SQLException {
 		if ( rowId != null ) {
 			ps.setObject( index, rowId );
 			return 1;
 		}
 		else if ( id != null ) {
 			getIdentifierType().nullSafeSet( ps, id, index, session );
 			return getIdentifierColumnSpan();
 		}
 		return 0;
 	}
 
 	/**
 	 * Unmarshall the fields of a persistent instance from a result set,
 	 * without resolving associations or collections. Question: should
 	 * this really be here, or should it be sent back to Loader?
 	 */
 	public Object[] hydrate(
 			final ResultSet rs,
 			final Serializable id,
 			final Object object,
 			final Loadable rootLoadable,
 			final String[][] suffixedPropertyColumns,
 			final boolean allProperties,
 			final SessionImplementor session) throws SQLException, HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Hydrating entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		final AbstractEntityPersister rootPersister = (AbstractEntityPersister) rootLoadable;
 
 		final boolean hasDeferred = rootPersister.hasSequentialSelect();
 		PreparedStatement sequentialSelect = null;
 		ResultSet sequentialResultSet = null;
 		boolean sequentialSelectEmpty = false;
 		try {
 
 			if ( hasDeferred ) {
 				final String sql = rootPersister.getSequentialSelect( getEntityName() );
 				if ( sql != null ) {
 					//TODO: I am not so sure about the exception handling in this bit!
-					sequentialSelect = session.getTransactionCoordinator()
+					sequentialSelect = session
 							.getJdbcCoordinator()
 							.getStatementPreparer()
 							.prepareStatement( sql );
 					rootPersister.getIdentifierType().nullSafeSet( sequentialSelect, id, 1, session );
-					sequentialResultSet = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( sequentialSelect );
+					sequentialResultSet = session.getJdbcCoordinator().getResultSetReturn().extract( sequentialSelect );
 					if ( !sequentialResultSet.next() ) {
 						// TODO: Deal with the "optional" attribute in the <join> mapping;
 						// this code assumes that optional defaults to "true" because it
 						// doesn't actually seem to work in the fetch="join" code
 						//
 						// Note that actual proper handling of optional-ality here is actually
 						// more involved than this patch assumes.  Remember that we might have
 						// multiple <join/> mappings associated with a single entity.  Really
 						// a couple of things need to happen to properly handle optional here:
 						//  1) First and foremost, when handling multiple <join/>s, we really
 						//      should be using the entity root table as the driving table;
 						//      another option here would be to choose some non-optional joined
 						//      table to use as the driving table.  In all likelihood, just using
 						//      the root table is much simplier
 						//  2) Need to add the FK columns corresponding to each joined table
 						//      to the generated select list; these would then be used when
 						//      iterating the result set to determine whether all non-optional
 						//      data is present
 						// My initial thoughts on the best way to deal with this would be
 						// to introduce a new SequentialSelect abstraction that actually gets
 						// generated in the persisters (ok, SingleTable...) and utilized here.
 						// It would encapsulated all this required optional-ality checking...
 						sequentialSelectEmpty = true;
 					}
 				}
 			}
 
 			final String[] propNames = getPropertyNames();
 			final Type[] types = getPropertyTypes();
 			final Object[] values = new Object[types.length];
 			final boolean[] laziness = getPropertyLaziness();
 			final String[] propSubclassNames = getSubclassPropertySubclassNameClosure();
 
 			for ( int i = 0; i < types.length; i++ ) {
 				if ( !propertySelectable[i] ) {
 					values[i] = BackrefPropertyAccessor.UNKNOWN;
 				}
 				else if ( allProperties || !laziness[i] ) {
 					//decide which ResultSet to get the property value from:
 					final boolean propertyIsDeferred = hasDeferred &&
 							rootPersister.isSubclassPropertyDeferred( propNames[i], propSubclassNames[i] );
 					if ( propertyIsDeferred && sequentialSelectEmpty ) {
 						values[i] = null;
 					}
 					else {
 						final ResultSet propertyResultSet = propertyIsDeferred ? sequentialResultSet : rs;
 						final String[] cols = propertyIsDeferred ? propertyColumnAliases[i] : suffixedPropertyColumns[i];
 						values[i] = types[i].hydrate( propertyResultSet, cols, session, object );
 					}
 				}
 				else {
 					values[i] = LazyPropertyInitializer.UNFETCHED_PROPERTY;
 				}
 			}
 
 			if ( sequentialResultSet != null ) {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( sequentialResultSet, sequentialSelect );
+				session.getJdbcCoordinator().getResourceRegistry().release( sequentialResultSet, sequentialSelect );
 			}
 
 			return values;
 
 		}
 		finally {
 			if ( sequentialSelect != null ) {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( sequentialSelect );
+				session.getJdbcCoordinator().getResourceRegistry().release( sequentialSelect );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 	}
 
 	protected boolean useInsertSelectIdentity() {
 		return !useGetGeneratedKeys() && getFactory().getDialect().supportsInsertSelectIdentity();
 	}
 
 	protected boolean useGetGeneratedKeys() {
 		return getFactory().getSettings().isGetGeneratedKeysEnabled();
 	}
 
 	protected String getSequentialSelect(String entityName) {
 		throw new UnsupportedOperationException("no sequential selects");
 	}
 
 	/**
 	 * Perform an SQL INSERT, and then retrieve a generated identifier.
 	 * <p/>
 	 * This form is used for PostInsertIdentifierGenerator-style ids (IDENTITY,
 	 * select, etc).
 	 */
 	protected Serializable insert(
 			final Object[] fields,
 			final boolean[] notNull,
 			String sql,
 			final Object object,
 			final SessionImplementor session) throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Inserting entity: {0} (native id)", getEntityName() );
 			if ( isVersioned() ) {
 				LOG.tracev( "Version: {0}", Versioning.getVersion( fields, this ) );
 			}
 		}
 
 		Binder binder = new Binder() {
 			public void bindValues(PreparedStatement ps) throws SQLException {
 				dehydrate( null, fields, notNull, propertyColumnInsertable, 0, ps, session, false );
 			}
 			public Object getEntity() {
 				return object;
 			}
 		};
 
 		return identityDelegate.performInsert( sql, session, binder );
 	}
 
 	public String getIdentitySelectString() {
 		//TODO: cache this in an instvar
 		return getFactory().getDialect().getIdentitySelectString(
 				getTableName(0),
 				getKeyColumns(0)[0],
 				getIdentifierType().sqlTypes( getFactory() )[0]
 		);
 	}
 
 	public String getSelectByUniqueKeyString(String propertyName) {
 		return new SimpleSelect( getFactory().getDialect() )
 			.setTableName( getTableName(0) )
 			.addColumns( getKeyColumns(0) )
 			.addCondition( getPropertyColumnNames(propertyName), "=?" )
 			.toStatementString();
 	}
 
 	private BasicBatchKey inserBatchKey;
 
 	/**
 	 * Perform an SQL INSERT.
 	 * <p/>
 	 * This for is used for all non-root tables as well as the root table
 	 * in cases where the identifier value is known before the insert occurs.
 	 */
 	protected void insert(
 			final Serializable id,
 			final Object[] fields,
 			final boolean[] notNull,
 			final int j,
 			final String sql,
 			final Object object,
 			final SessionImplementor session) throws HibernateException {
 
 		if ( isInverseTable( j ) ) {
 			return;
 		}
 
 		//note: it is conceptually possible that a UserType could map null to
 		//	  a non-null value, so the following is arguable:
 		if ( isNullableTable( j ) && isAllNull( fields, j ) ) {
 			return;
 		}
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Inserting entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 			if ( j == 0 && isVersioned() )
 				LOG.tracev( "Version: {0}", Versioning.getVersion( fields, this ) );
 		}
 
 		// TODO : shouldn't inserts be Expectations.NONE?
 		final Expectation expectation = Expectations.appropriateExpectation( insertResultCheckStyles[j] );
 		// we can't batch joined inserts, *especially* not if it is an identity insert;
 		// nor can we batch statements where the expectation is based on an output param
 		final boolean useBatch = j == 0 && expectation.canBeBatched();
 		if ( useBatch && inserBatchKey == null ) {
 			inserBatchKey = new BasicBatchKey(
 					getEntityName() + "#INSERT",
 					expectation
 			);
 		}
 		final boolean callable = isInsertCallable( j );
 
 		try {
 			// Render the SQL query
 			final PreparedStatement insert;
 			if ( useBatch ) {
-				insert = session.getTransactionCoordinator()
+				insert = session
 						.getJdbcCoordinator()
 						.getBatch( inserBatchKey )
 						.getBatchStatement( sql, callable );
 			}
 			else {
-				insert = session.getTransactionCoordinator()
+				insert = session
 						.getJdbcCoordinator()
 						.getStatementPreparer()
 						.prepareStatement( sql, callable );
 			}
 
 			try {
 				int index = 1;
 				index += expectation.prepare( insert );
 
 				// Write the values of fields onto the prepared statement - we MUST use the state at the time the
 				// insert was issued (cos of foreign key constraints). Not necessarily the object's current state
 
 				dehydrate( id, fields, null, notNull, propertyColumnInsertable, j, insert, session, index, false );
 
 				if ( useBatch ) {
-					session.getTransactionCoordinator().getJdbcCoordinator().getBatch( inserBatchKey ).addToBatch();
+					session.getJdbcCoordinator().getBatch( inserBatchKey ).addToBatch();
 				}
 				else {
-					expectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( insert ), insert, -1 );
+					expectation.verifyOutcome( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( insert ), insert, -1 );
 				}
 
 			}
 			catch ( SQLException e ) {
 				if ( useBatch ) {
-					session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
+					session.getJdbcCoordinator().abortBatch();
 				}
 				throw e;
 			}
 			finally {
 				if ( !useBatch ) {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( insert );
+					session.getJdbcCoordinator().getResourceRegistry().release( insert );
+					session.getJdbcCoordinator().afterStatementExecution();
 				}
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not insert: " + MessageHelper.infoString( this ),
 					sql
 			);
 		}
 
 	}
 
 	/**
 	 * Perform an SQL UPDATE or SQL INSERT
 	 */
 	protected void updateOrInsert(
 			final Serializable id,
 			final Object[] fields,
 			final Object[] oldFields,
 			final Object rowId,
 			final boolean[] includeProperty,
 			final int j,
 			final Object oldVersion,
 			final Object object,
 			final String sql,
 			final SessionImplementor session) throws HibernateException {
 
 		if ( !isInverseTable( j ) ) {
 
 			final boolean isRowToUpdate;
 			if ( isNullableTable( j ) && oldFields != null && isAllNull( oldFields, j ) ) {
 				//don't bother trying to update, we know there is no row there yet
 				isRowToUpdate = false;
 			}
 			else if ( isNullableTable( j ) && isAllNull( fields, j ) ) {
 				//if all fields are null, we might need to delete existing row
 				isRowToUpdate = true;
 				delete( id, oldVersion, j, object, getSQLDeleteStrings()[j], session, null );
 			}
 			else {
 				//there is probably a row there, so try to update
 				//if no rows were updated, we will find out
 				isRowToUpdate = update( id, fields, oldFields, rowId, includeProperty, j, oldVersion, object, sql, session );
 			}
 
 			if ( !isRowToUpdate && !isAllNull( fields, j ) ) {
 				// assume that the row was not there since it previously had only null
 				// values, so do an INSERT instead
 				//TODO: does not respect dynamic-insert
 				insert( id, fields, getPropertyInsertability(), j, getSQLInsertStrings()[j], object, session );
 			}
 
 		}
 
 	}
 
 	private BasicBatchKey updateBatchKey;
 
 	protected boolean update(
 			final Serializable id,
 			final Object[] fields,
 			final Object[] oldFields,
 			final Object rowId,
 			final boolean[] includeProperty,
 			final int j,
 			final Object oldVersion,
 			final Object object,
 			final String sql,
 			final SessionImplementor session) throws HibernateException {
 
 		final Expectation expectation = Expectations.appropriateExpectation( updateResultCheckStyles[j] );
 		final boolean useBatch = j == 0 && expectation.canBeBatched() && isBatchable(); //note: updates to joined tables can't be batched...
 		if ( useBatch && updateBatchKey == null ) {
 			updateBatchKey = new BasicBatchKey(
 					getEntityName() + "#UPDATE",
 					expectation
 			);
 		}
 		final boolean callable = isUpdateCallable( j );
 		final boolean useVersion = j == 0 && isVersioned();
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Updating entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 			if ( useVersion )
 				LOG.tracev( "Existing version: {0} -> New version:{1}", oldVersion, fields[getVersionProperty()] );
 		}
 
 		try {
 			int index = 1; // starting index
 			final PreparedStatement update;
 			if ( useBatch ) {
-				update = session.getTransactionCoordinator()
+				update = session
 						.getJdbcCoordinator()
 						.getBatch( updateBatchKey )
 						.getBatchStatement( sql, callable );
 			}
 			else {
-				update = session.getTransactionCoordinator()
+				update = session
 						.getJdbcCoordinator()
 						.getStatementPreparer()
 						.prepareStatement( sql, callable );
 			}
 
 			try {
 				index+= expectation.prepare( update );
 
 				//Now write the values of fields onto the prepared statement
 				index = dehydrate( id, fields, rowId, includeProperty, propertyColumnUpdateable, j, update, session, index, true );
 
 				// Write any appropriate versioning conditional parameters
 				if ( useVersion && entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.VERSION ) {
 					if ( checkVersion( includeProperty ) ) {
 						getVersionType().nullSafeSet( update, oldVersion, index, session );
 					}
 				}
 				else if ( isAllOrDirtyOptLocking() && oldFields != null ) {
 					boolean[] versionability = getPropertyVersionability(); //TODO: is this really necessary????
 					boolean[] includeOldField = entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.ALL
 							? getPropertyUpdateability()
 							: includeProperty;
 					Type[] types = getPropertyTypes();
 					for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 						boolean include = includeOldField[i] &&
 								isPropertyOfTable( i, j ) &&
 								versionability[i]; //TODO: is this really necessary????
 						if ( include ) {
 							boolean[] settable = types[i].toColumnNullness( oldFields[i], getFactory() );
 							types[i].nullSafeSet(
 									update,
 									oldFields[i],
 									index,
 									settable,
 									session
 								);
 							index += ArrayHelper.countTrue(settable);
 						}
 					}
 				}
 
 				if ( useBatch ) {
-					session.getTransactionCoordinator().getJdbcCoordinator().getBatch( updateBatchKey ).addToBatch();
+					session.getJdbcCoordinator().getBatch( updateBatchKey ).addToBatch();
 					return true;
 				}
 				else {
-					return check( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( update ), id, j, expectation, update );
+					return check( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( update ), id, j, expectation, update );
 				}
 
 			}
 			catch ( SQLException e ) {
 				if ( useBatch ) {
-					session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
+					session.getJdbcCoordinator().abortBatch();
 				}
 				throw e;
 			}
 			finally {
 				if ( !useBatch ) {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( update );
+					session.getJdbcCoordinator().getResourceRegistry().release( update );
+					session.getJdbcCoordinator().afterStatementExecution();
 				}
 			}
 
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not update: " + MessageHelper.infoString( this, id, getFactory() ),
 					sql
 				);
 		}
 	}
 
 	private BasicBatchKey deleteBatchKey;
 
 	/**
 	 * Perform an SQL DELETE
 	 */
 	protected void delete(
 			final Serializable id,
 			final Object version,
 			final int j,
 			final Object object,
 			final String sql,
 			final SessionImplementor session,
 			final Object[] loadedState) throws HibernateException {
 
 		if ( isInverseTable( j ) ) {
 			return;
 		}
 
 		final boolean useVersion = j == 0 && isVersioned();
 		final boolean callable = isDeleteCallable( j );
 		final Expectation expectation = Expectations.appropriateExpectation( deleteResultCheckStyles[j] );
 		final boolean useBatch = j == 0 && isBatchable() && expectation.canBeBatched();
 		if ( useBatch && deleteBatchKey == null ) {
 			deleteBatchKey = new BasicBatchKey(
 					getEntityName() + "#DELETE",
 					expectation
 			);
 		}
 
 		final boolean traceEnabled = LOG.isTraceEnabled();
 		if ( traceEnabled ) {
 			LOG.tracev( "Deleting entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 			if ( useVersion )
 				LOG.tracev( "Version: {0}", version );
 		}
 
 		if ( isTableCascadeDeleteEnabled( j ) ) {
 			if ( traceEnabled ) {
 				LOG.tracev( "Delete handled by foreign key constraint: {0}", getTableName( j ) );
 			}
 			return; //EARLY EXIT!
 		}
 
 		try {
 			//Render the SQL query
 			PreparedStatement delete;
 			int index = 1;
 			if ( useBatch ) {
-				delete = session.getTransactionCoordinator()
+				delete = session
 						.getJdbcCoordinator()
 						.getBatch( deleteBatchKey )
 						.getBatchStatement( sql, callable );
 			}
 			else {
-				delete = session.getTransactionCoordinator()
+				delete = session
 						.getJdbcCoordinator()
 						.getStatementPreparer()
 						.prepareStatement( sql, callable );
 			}
 
 			try {
 
 				index += expectation.prepare( delete );
 
 				// Do the key. The key is immutable so we can use the _current_ object state - not necessarily
 				// the state at the time the delete was issued
 				getIdentifierType().nullSafeSet( delete, id, index, session );
 				index += getIdentifierColumnSpan();
 
 				// We should use the _current_ object state (ie. after any updates that occurred during flush)
 
 				if ( useVersion ) {
 					getVersionType().nullSafeSet( delete, version, index, session );
 				}
 				else if ( isAllOrDirtyOptLocking() && loadedState != null ) {
 					boolean[] versionability = getPropertyVersionability();
 					Type[] types = getPropertyTypes();
 					for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 						if ( isPropertyOfTable( i, j ) && versionability[i] ) {
 							// this property belongs to the table and it is not specifically
 							// excluded from optimistic locking by optimistic-lock="false"
 							boolean[] settable = types[i].toColumnNullness( loadedState[i], getFactory() );
 							types[i].nullSafeSet( delete, loadedState[i], index, settable, session );
 							index += ArrayHelper.countTrue( settable );
 						}
 					}
 				}
 
 				if ( useBatch ) {
-					session.getTransactionCoordinator().getJdbcCoordinator().getBatch( deleteBatchKey ).addToBatch();
+					session.getJdbcCoordinator().getBatch( deleteBatchKey ).addToBatch();
 				}
 				else {
-					check( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( delete ), id, j, expectation, delete );
+					check( session.getJdbcCoordinator().getResultSetReturn().executeUpdate( delete ), id, j, expectation, delete );
 				}
 
 			}
 			catch ( SQLException sqle ) {
 				if ( useBatch ) {
-					session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
+					session.getJdbcCoordinator().abortBatch();
 				}
 				throw sqle;
 			}
 			finally {
 				if ( !useBatch ) {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( delete );
+					session.getJdbcCoordinator().getResourceRegistry().release( delete );
+					session.getJdbcCoordinator().afterStatementExecution();
 				}
 			}
 
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not delete: " +
 					MessageHelper.infoString( this, id, getFactory() ),
 					sql
 				);
 
 		}
 
 	}
 
 	private String[] getUpdateStrings(boolean byRowId, boolean lazy) {
 		if ( byRowId ) {
 			return lazy ? getSQLLazyUpdateByRowIdStrings() : getSQLUpdateByRowIdStrings();
 		}
 		else {
 			return lazy ? getSQLLazyUpdateStrings() : getSQLUpdateStrings();
 		}
 	}
 
 	/**
 	 * Update an object
 	 */
 	public void update(
 			final Serializable id,
 			final Object[] fields,
 			final int[] dirtyFields,
 			final boolean hasDirtyCollection,
 			final Object[] oldFields,
 			final Object oldVersion,
 			final Object object,
 			final Object rowId,
 			final SessionImplementor session) throws HibernateException {
 
 		// apply any pre-update in-memory value generation
 		if ( getEntityMetamodel().hasPreUpdateGeneratedValues() ) {
 			final InMemoryValueGenerationStrategy[] strategies = getEntityMetamodel().getInMemoryValueGenerationStrategies();
 			for ( int i = 0; i < strategies.length; i++ ) {
 				if ( strategies[i] != null && strategies[i].getGenerationTiming().includesUpdate() ) {
 					fields[i] = strategies[i].getValueGenerator().generateValue( (Session) session, object );
 					setPropertyValue( object, i, fields[i] );
 					// todo : probably best to add to dirtyFields if not-null
 				}
 			}
 		}
 
 		//note: dirtyFields==null means we had no snapshot, and we couldn't get one using select-before-update
 		//	  oldFields==null just means we had no snapshot to begin with (we might have used select-before-update to get the dirtyFields)
 
 		final boolean[] tableUpdateNeeded = getTableUpdateNeeded( dirtyFields, hasDirtyCollection );
 		final int span = getTableSpan();
 
 		final boolean[] propsToUpdate;
 		final String[] updateStrings;
 		EntityEntry entry = session.getPersistenceContext().getEntry( object );
 
 		// Ensure that an immutable or non-modifiable entity is not being updated unless it is
 		// in the process of being deleted.
 		if ( entry == null && ! isMutable() ) {
 			throw new IllegalStateException( "Updating immutable entity that is not in session yet!" );
 		}
 		if ( ( entityMetamodel.isDynamicUpdate() && dirtyFields != null ) ) {
 			// We need to generate the UPDATE SQL when dynamic-update="true"
 			propsToUpdate = getPropertiesToUpdate( dirtyFields, hasDirtyCollection );
 			// don't need to check laziness (dirty checking algorithm handles that)
 			updateStrings = new String[span];
 			for ( int j = 0; j < span; j++ ) {
 				updateStrings[j] = tableUpdateNeeded[j] ?
 						generateUpdateString( propsToUpdate, j, oldFields, j == 0 && rowId != null ) :
 						null;
 			}
 		}
 		else if ( ! isModifiableEntity( entry ) ) {
 			// We need to generate UPDATE SQL when a non-modifiable entity (e.g., read-only or immutable)
 			// needs:
 			// - to have references to transient entities set to null before being deleted
 			// - to have version incremented do to a "dirty" association
 			// If dirtyFields == null, then that means that there are no dirty properties to
 			// to be updated; an empty array for the dirty fields needs to be passed to
 			// getPropertiesToUpdate() instead of null.
 			propsToUpdate = getPropertiesToUpdate(
 					( dirtyFields == null ? ArrayHelper.EMPTY_INT_ARRAY : dirtyFields ),
 					hasDirtyCollection
 			);
 			// don't need to check laziness (dirty checking algorithm handles that)
 			updateStrings = new String[span];
 			for ( int j = 0; j < span; j++ ) {
 				updateStrings[j] = tableUpdateNeeded[j] ?
 						generateUpdateString( propsToUpdate, j, oldFields, j == 0 && rowId != null ) :
 						null;
 			}
 		}
 		else {
 			// For the case of dynamic-update="false", or no snapshot, we use the static SQL
 			updateStrings = getUpdateStrings(
 					rowId != null,
 					hasUninitializedLazyProperties( object )
 			);
 			propsToUpdate = getPropertyUpdateability( object );
 		}
 
 		for ( int j = 0; j < span; j++ ) {
 			// Now update only the tables with dirty properties (and the table with the version number)
 			if ( tableUpdateNeeded[j] ) {
 				updateOrInsert(
 						id,
 						fields,
 						oldFields,
 						j == 0 ? rowId : null,
 						propsToUpdate,
 						j,
 						oldVersion,
 						object,
 						updateStrings[j],
 						session
 					);
 			}
 		}
 	}
 
 	public Serializable insert(Object[] fields, Object object, SessionImplementor session)
 			throws HibernateException {
 		// apply any pre-insert in-memory value generation
 		preInsertInMemoryValueGeneration( fields, object, session );
 		
 		final int span = getTableSpan();
 		final Serializable id;
 		if ( entityMetamodel.isDynamicInsert() ) {
 			// For the case of dynamic-insert="true", we need to generate the INSERT SQL
 			boolean[] notNull = getPropertiesToInsert( fields );
 			id = insert( fields, notNull, generateInsertString( true, notNull ), object, session );
 			for ( int j = 1; j < span; j++ ) {
 				insert( id, fields, notNull, j, generateInsertString( notNull, j ), object, session );
 			}
 		}
 		else {
 			// For the case of dynamic-insert="false", use the static SQL
 			id = insert( fields, getPropertyInsertability(), getSQLIdentityInsertString(), object, session );
 			for ( int j = 1; j < span; j++ ) {
 				insert( id, fields, getPropertyInsertability(), j, getSQLInsertStrings()[j], object, session );
 			}
 		}
 		return id;
 	}
 
 	public void insert(Serializable id, Object[] fields, Object object, SessionImplementor session) {
 		// apply any pre-insert in-memory value generation
 		preInsertInMemoryValueGeneration( fields, object, session );
 
 		final int span = getTableSpan();
 		if ( entityMetamodel.isDynamicInsert() ) {
 			// For the case of dynamic-insert="true", we need to generate the INSERT SQL
 			boolean[] notNull = getPropertiesToInsert( fields );
 			for ( int j = 0; j < span; j++ ) {
 				insert( id, fields, notNull, j, generateInsertString( notNull, j ), object, session );
 			}
 		}
 		else {
 			// For the case of dynamic-insert="false", use the static SQL
 			for ( int j = 0; j < span; j++ ) {
 				insert( id, fields, getPropertyInsertability(), j, getSQLInsertStrings()[j], object, session );
 			}
 		}
 	}
 	
 	private void preInsertInMemoryValueGeneration(Object[] fields, Object object, SessionImplementor session) {
 		if ( getEntityMetamodel().hasPreInsertGeneratedValues() ) {
 			final InMemoryValueGenerationStrategy[] strategies = getEntityMetamodel().getInMemoryValueGenerationStrategies();
 			for ( int i = 0; i < strategies.length; i++ ) {
 				if ( strategies[i] != null && strategies[i].getGenerationTiming().includesInsert() ) {
 					fields[i] = strategies[i].getValueGenerator().generateValue( (Session) session, object );
 					setPropertyValue( object, i, fields[i] );
 				}
 			}
 		}
 	}
 
 	/**
 	 * Delete an object
 	 */
 	public void delete(Serializable id, Object version, Object object, SessionImplementor session)
 			throws HibernateException {
 		final int span = getTableSpan();
 		boolean isImpliedOptimisticLocking = !entityMetamodel.isVersioned() && isAllOrDirtyOptLocking();
 		Object[] loadedState = null;
 		if ( isImpliedOptimisticLocking ) {
 			// need to treat this as if it where optimistic-lock="all" (dirty does *not* make sense);
 			// first we need to locate the "loaded" state
 			//
 			// Note, it potentially could be a proxy, so doAfterTransactionCompletion the location the safe way...
 			final EntityKey key = session.generateEntityKey( id, this );
 			Object entity = session.getPersistenceContext().getEntity( key );
 			if ( entity != null ) {
 				EntityEntry entry = session.getPersistenceContext().getEntry( entity );
 				loadedState = entry.getLoadedState();
 			}
 		}
 
 		final String[] deleteStrings;
 		if ( isImpliedOptimisticLocking && loadedState != null ) {
 			// we need to utilize dynamic delete statements
 			deleteStrings = generateSQLDeletStrings( loadedState );
 		}
 		else {
 			// otherwise, utilize the static delete statements
 			deleteStrings = getSQLDeleteStrings();
 		}
 
 		for ( int j = span - 1; j >= 0; j-- ) {
 			delete( id, version, j, object, deleteStrings[j], session, loadedState );
 		}
 
 	}
 
 	private boolean isAllOrDirtyOptLocking() {
 		return entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.DIRTY
 				|| entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.ALL;
 	}
 
 	private String[] generateSQLDeletStrings(Object[] loadedState) {
 		int span = getTableSpan();
 		String[] deleteStrings = new String[span];
 		for ( int j = span - 1; j >= 0; j-- ) {
 			Delete delete = new Delete()
 					.setTableName( getTableName( j ) )
 					.addPrimaryKeyColumns( getKeyColumns( j ) );
 			if ( getFactory().getSettings().isCommentsEnabled() ) {
 				delete.setComment( "delete " + getEntityName() + " [" + j + "]" );
 			}
 
 			boolean[] versionability = getPropertyVersionability();
 			Type[] types = getPropertyTypes();
 			for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 				if ( isPropertyOfTable( i, j ) && versionability[i] ) {
 					// this property belongs to the table and it is not specifically
 					// excluded from optimistic locking by optimistic-lock="false"
 					String[] propertyColumnNames = getPropertyColumnNames( i );
 					boolean[] propertyNullness = types[i].toColumnNullness( loadedState[i], getFactory() );
 					for ( int k = 0; k < propertyNullness.length; k++ ) {
 						if ( propertyNullness[k] ) {
 							delete.addWhereFragment( propertyColumnNames[k] + " = ?" );
 						}
 						else {
 							delete.addWhereFragment( propertyColumnNames[k] + " is null" );
 						}
 					}
 				}
 			}
 			deleteStrings[j] = delete.toStatementString();
 		}
 		return deleteStrings;
 	}
 
 	protected void logStaticSQL() {
         if ( LOG.isDebugEnabled() ) {
             LOG.debugf( "Static SQL for entity: %s", getEntityName() );
             if ( sqlLazySelectString != null ) {
 				LOG.debugf( " Lazy select: %s", sqlLazySelectString );
 			}
             if ( sqlVersionSelectString != null ) {
 				LOG.debugf( " Version select: %s", sqlVersionSelectString );
 			}
             if ( sqlSnapshotSelectString != null ) {
 				LOG.debugf( " Snapshot select: %s", sqlSnapshotSelectString );
 			}
 			for ( int j = 0; j < getTableSpan(); j++ ) {
                 LOG.debugf( " Insert %s: %s", j, getSQLInsertStrings()[j] );
                 LOG.debugf( " Update %s: %s", j, getSQLUpdateStrings()[j] );
                 LOG.debugf( " Delete %s: %s", j, getSQLDeleteStrings()[j] );
 			}
             if ( sqlIdentityInsertString != null ) {
 				LOG.debugf( " Identity insert: %s", sqlIdentityInsertString );
 			}
             if ( sqlUpdateByRowIdString != null ) {
 				LOG.debugf( " Update by row id (all fields): %s", sqlUpdateByRowIdString );
 			}
             if ( sqlLazyUpdateByRowIdString != null ) {
 				LOG.debugf( " Update by row id (non-lazy fields): %s", sqlLazyUpdateByRowIdString );
 			}
             if ( sqlInsertGeneratedValuesSelectString != null ) {
 				LOG.debugf( " Insert-generated property select: %s", sqlInsertGeneratedValuesSelectString );
 			}
             if ( sqlUpdateGeneratedValuesSelectString != null ) {
 				LOG.debugf( " Update-generated property select: %s", sqlUpdateGeneratedValuesSelectString );
 			}
 		}
 	}
 
 	@Override
 	public String filterFragment(String alias, Map enabledFilters) throws MappingException {
 		final StringBuilder sessionFilterFragment = new StringBuilder();
 		filterHelper.render( sessionFilterFragment, getFilterAliasGenerator(alias), enabledFilters );
 		return sessionFilterFragment.append( filterFragment( alias ) ).toString();
 	}
 
 	@Override
 	public String filterFragment(String alias, Map enabledFilters, Set<String> treatAsDeclarations) {
 		final StringBuilder sessionFilterFragment = new StringBuilder();
 		filterHelper.render( sessionFilterFragment, getFilterAliasGenerator(alias), enabledFilters );
 		return sessionFilterFragment.append( filterFragment( alias, treatAsDeclarations ) ).toString();
 	}
 
 	public String generateFilterConditionAlias(String rootAlias) {
 		return rootAlias;
 	}
 
 	public String oneToManyFilterFragment(String alias) throws MappingException {
 		return "";
 	}
 
 	@Override
 	public String oneToManyFilterFragment(String alias, Set<String> treatAsDeclarations) {
 		return oneToManyFilterFragment( alias );
 	}
 
 	@Override
 	public String fromJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		// NOTE : Not calling createJoin here is just a performance optimization
 		return getSubclassTableSpan() == 1
 				? ""
 				: createJoin( alias, innerJoin, includeSubclasses, Collections.<String>emptySet() ).toFromFragmentString();
 	}
 
 	@Override
 	public String fromJoinFragment(
 			String alias,
 			boolean innerJoin,
 			boolean includeSubclasses,
 			Set<String> treatAsDeclarations) {
 		// NOTE : Not calling createJoin here is just a performance optimization
 		return getSubclassTableSpan() == 1
 				? ""
 				: createJoin( alias, innerJoin, includeSubclasses, treatAsDeclarations ).toFromFragmentString();
 	}
 
 	@Override
 	public String whereJoinFragment(String alias, boolean innerJoin, boolean includeSubclasses) {
 		// NOTE : Not calling createJoin here is just a performance optimization
 		return getSubclassTableSpan() == 1
 				? ""
 				: createJoin( alias, innerJoin, includeSubclasses, Collections.<String>emptySet() ).toWhereFragmentString();
 	}
 
 	@Override
 	public String whereJoinFragment(
 			String alias,
 			boolean innerJoin,
 			boolean includeSubclasses,
 			Set<String> treatAsDeclarations) {
 		// NOTE : Not calling createJoin here is just a performance optimization
 		return getSubclassTableSpan() == 1
 				? ""
 				: createJoin( alias, innerJoin, includeSubclasses, treatAsDeclarations ).toWhereFragmentString();
 	}
 
 	protected boolean isSubclassTableLazy(int j) {
 		return false;
 	}
 
 	protected JoinFragment createJoin(String name, boolean innerJoin, boolean includeSubclasses, Set<String> treatAsDeclarations) {
 		// IMPL NOTE : all joins join to the pk of the driving table
 		final String[] idCols = StringHelper.qualify( name, getIdentifierColumnNames() );
 		final JoinFragment join = getFactory().getDialect().createOuterJoinFragment();
 		final int tableSpan = getSubclassTableSpan();
 		// IMPL NOTE : notice that we skip the first table; it is the driving table!
 		for ( int j = 1; j < tableSpan; j++ ) {
 			final JoinType joinType = determineSubclassTableJoinType(
 					j,
 					innerJoin,
 					includeSubclasses,
 					treatAsDeclarations
 			);
 
 			if ( joinType != null && joinType != JoinType.NONE ) {
 				join.addJoin(
 						getSubclassTableName( j ),
 						generateTableAlias( name, j ),
 						idCols,
 						getSubclassTableKeyColumns( j ),
 						joinType
 				);
 			}
 		}
 		return join;
 	}
 
 	protected JoinType determineSubclassTableJoinType(
 			int subclassTableNumber,
 			boolean canInnerJoin,
 			boolean includeSubclasses,
 			Set<String> treatAsDeclarations) {
 
 		if ( isClassOrSuperclassTable( subclassTableNumber ) ) {
 			final boolean shouldInnerJoin = canInnerJoin
 					&& !isInverseTable( subclassTableNumber )
 					&& !isNullableTable( subclassTableNumber );
 			// the table is either this persister's driving table or (one of) its super class persister's driving
 			// tables which can be inner joined as long as the `shouldInnerJoin` condition resolves to true
 			return shouldInnerJoin ? JoinType.INNER_JOIN : JoinType.LEFT_OUTER_JOIN;
 		}
 
 		// otherwise we have a subclass table and need to look a little deeper...
 
 		// IMPL NOTE : By default includeSubclasses indicates that all subclasses should be joined and that each
 		// subclass ought to be joined by outer-join.  However, TREAT-AS always requires that an inner-join be used
 		// so we give TREAT-AS higher precedence...
 
 		if ( isSubclassTableIndicatedByTreatAsDeclarations( subclassTableNumber, treatAsDeclarations ) ) {
 			return JoinType.INNER_JOIN;
 		}
 
 		if ( includeSubclasses
 				&& !isSubclassTableSequentialSelect( subclassTableNumber )
 				&& !isSubclassTableLazy( subclassTableNumber ) ) {
 			return JoinType.LEFT_OUTER_JOIN;
 		}
 
 		return JoinType.NONE;
 	}
 
 	protected boolean isSubclassTableIndicatedByTreatAsDeclarations(
 			int subclassTableNumber,
 			Set<String> treatAsDeclarations) {
 		return false;
 	}
 
 
 	protected JoinFragment createJoin(int[] tableNumbers, String drivingAlias) {
 		final String[] keyCols = StringHelper.qualify( drivingAlias, getSubclassTableKeyColumns( tableNumbers[0] ) );
 		final JoinFragment jf = getFactory().getDialect().createOuterJoinFragment();
 		// IMPL NOTE : notice that we skip the first table; it is the driving table!
 		for ( int i = 1; i < tableNumbers.length; i++ ) {
 			final int j = tableNumbers[i];
 			jf.addJoin( getSubclassTableName( j ),
 					generateTableAlias( getRootAlias(), j ),
 					keyCols,
 					getSubclassTableKeyColumns( j ),
 					isInverseSubclassTable( j ) || isNullableSubclassTable( j )
 							? JoinType.LEFT_OUTER_JOIN
 							: JoinType.INNER_JOIN
 			);
 		}
 		return jf;
 	}
 
 	protected SelectFragment createSelect(final int[] subclassColumnNumbers,
 										  final int[] subclassFormulaNumbers) {
 
 		SelectFragment selectFragment = new SelectFragment();
 
 		int[] columnTableNumbers = getSubclassColumnTableNumberClosure();
 		String[] columnAliases = getSubclassColumnAliasClosure();
 		String[] columnReaderTemplates = getSubclassColumnReaderTemplateClosure();
 		for ( int i = 0; i < subclassColumnNumbers.length; i++ ) {
 			int columnNumber = subclassColumnNumbers[i];
 			if ( subclassColumnSelectableClosure[columnNumber] ) {
 				final String subalias = generateTableAlias( getRootAlias(), columnTableNumbers[columnNumber] );
 				selectFragment.addColumnTemplate( subalias, columnReaderTemplates[columnNumber], columnAliases[columnNumber] );
 			}
 		}
 
 		int[] formulaTableNumbers = getSubclassFormulaTableNumberClosure();
 		String[] formulaTemplates = getSubclassFormulaTemplateClosure();
 		String[] formulaAliases = getSubclassFormulaAliasClosure();
 		for ( int i = 0; i < subclassFormulaNumbers.length; i++ ) {
 			int formulaNumber = subclassFormulaNumbers[i];
 			final String subalias = generateTableAlias( getRootAlias(), formulaTableNumbers[formulaNumber] );
 			selectFragment.addFormula( subalias, formulaTemplates[formulaNumber], formulaAliases[formulaNumber] );
 		}
 
 		return selectFragment;
 	}
 
 	protected String createFrom(int tableNumber, String alias) {
 		return getSubclassTableName( tableNumber ) + ' ' + alias;
 	}
 
 	protected String createWhereByKey(int tableNumber, String alias) {
 		//TODO: move to .sql package, and refactor with similar things!
 		return StringHelper.join( "=? and ",
 				StringHelper.qualify( alias, getSubclassTableKeyColumns( tableNumber ) ) ) + "=?";
 	}
 
 	protected String renderSelect(
 			final int[] tableNumbers,
 	        final int[] columnNumbers,
 	        final int[] formulaNumbers) {
 
 		Arrays.sort( tableNumbers ); //get 'em in the right order (not that it really matters)
 
 		//render the where and from parts
 		int drivingTable = tableNumbers[0];
 		final String drivingAlias = generateTableAlias( getRootAlias(), drivingTable ); //we *could* regerate this inside each called method!
 		final String where = createWhereByKey( drivingTable, drivingAlias );
 		final String from = createFrom( drivingTable, drivingAlias );
 
 		//now render the joins
 		JoinFragment jf = createJoin( tableNumbers, drivingAlias );
 
 		//now render the select clause
 		SelectFragment selectFragment = createSelect( columnNumbers, formulaNumbers );
 
 		//now tie it all together
 		Select select = new Select( getFactory().getDialect() );
 		select.setSelectClause( selectFragment.toFragmentString().substring( 2 ) );
 		select.setFromClause( from );
 		select.setWhereClause( where );
 		select.setOuterJoins( jf.toFromFragmentString(), jf.toWhereFragmentString() );
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "sequential select " + getEntityName() );
 		}
 		return select.toStatementString();
 	}
 
 	private String getRootAlias() {
 		return StringHelper.generateAlias( getEntityName() );
 	}
 
 	/**
 	 * Post-construct is a callback for AbstractEntityPersister subclasses to call after they are all done with their
 	 * constructor processing.  It allows AbstractEntityPersister to extend its construction after all subclass-specific
 	 * details have been handled.
 	 *
 	 * @param mapping The mapping
 	 *
 	 * @throws MappingException Indicates a problem accessing the Mapping
 	 */
 	protected void postConstruct(Mapping mapping) throws MappingException {
 		initPropertyPaths( mapping );
 
 		//doLateInit();
 		prepareEntityIdentifierDefinition();
 	}
 
 	private void doLateInit() {
 		//insert/update/delete SQL
 		final int joinSpan = getTableSpan();
 		sqlDeleteStrings = new String[joinSpan];
 		sqlInsertStrings = new String[joinSpan];
 		sqlUpdateStrings = new String[joinSpan];
 		sqlLazyUpdateStrings = new String[joinSpan];
 
 		sqlUpdateByRowIdString = rowIdName == null ?
 				null :
 				generateUpdateString( getPropertyUpdateability(), 0, true );
 		sqlLazyUpdateByRowIdString = rowIdName == null ?
 				null :
 				generateUpdateString( getNonLazyPropertyUpdateability(), 0, true );
 
 		for ( int j = 0; j < joinSpan; j++ ) {
 			sqlInsertStrings[j] = customSQLInsert[j] == null ?
 					generateInsertString( getPropertyInsertability(), j ) :
 					customSQLInsert[j];
 			sqlUpdateStrings[j] = customSQLUpdate[j] == null ?
 					generateUpdateString( getPropertyUpdateability(), j, false ) :
 					customSQLUpdate[j];
 			sqlLazyUpdateStrings[j] = customSQLUpdate[j] == null ?
 					generateUpdateString( getNonLazyPropertyUpdateability(), j, false ) :
 					customSQLUpdate[j];
 			sqlDeleteStrings[j] = customSQLDelete[j] == null ?
 					generateDeleteString( j ) :
 					customSQLDelete[j];
 		}
 
 		tableHasColumns = new boolean[joinSpan];
 		for ( int j = 0; j < joinSpan; j++ ) {
 			tableHasColumns[j] = sqlUpdateStrings[j] != null;
 		}
 
 		//select SQL
 		sqlSnapshotSelectString = generateSnapshotSelectString();
 		sqlLazySelectString = generateLazySelectString();
 		sqlVersionSelectString = generateSelectVersionString();
 		if ( hasInsertGeneratedProperties() ) {
 			sqlInsertGeneratedValuesSelectString = generateInsertGeneratedValuesSelectString();
 		}
 		if ( hasUpdateGeneratedProperties() ) {
 			sqlUpdateGeneratedValuesSelectString = generateUpdateGeneratedValuesSelectString();
 		}
 		if ( isIdentifierAssignedByInsert() ) {
 			identityDelegate = ( ( PostInsertIdentifierGenerator ) getIdentifierGenerator() )
 					.getInsertGeneratedIdentifierDelegate( this, getFactory().getDialect(), useGetGeneratedKeys() );
 			sqlIdentityInsertString = customSQLInsert[0] == null
 					? generateIdentityInsertString( getPropertyInsertability() )
 					: customSQLInsert[0];
 		}
 		else {
 			sqlIdentityInsertString = null;
 		}
 
 		logStaticSQL();
 	}
 
 	public final void postInstantiate() throws MappingException {
 		doLateInit();
 
 		createLoaders();
 		createUniqueKeyLoaders();
 		createQueryLoader();
 
 		doPostInstantiate();
 	}
 
 	protected void doPostInstantiate() {
 	}
 
 	//needed by subclasses to override the createLoader strategy
 	protected Map getLoaders() {
 		return loaders;
 	}
 
 	//Relational based Persisters should be content with this implementation
 	protected void createLoaders() {
 		final Map loaders = getLoaders();
 		loaders.put( LockMode.NONE, createEntityLoader( LockMode.NONE ) );
 
 		UniqueEntityLoader readLoader = createEntityLoader( LockMode.READ );
 		loaders.put( LockMode.READ, readLoader );
 
 		//TODO: inexact, what we really need to know is: are any outer joins used?
 		boolean disableForUpdate = getSubclassTableSpan() > 1 &&
 				hasSubclasses() &&
 				!getFactory().getDialect().supportsOuterJoinForUpdate();
 
 		loaders.put(
 				LockMode.UPGRADE,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.UPGRADE )
 			);
 		loaders.put(
 				LockMode.UPGRADE_NOWAIT,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.UPGRADE_NOWAIT )
 			);
 		loaders.put(
 				LockMode.UPGRADE_SKIPLOCKED,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.UPGRADE_SKIPLOCKED )
 			);
 		loaders.put(
 				LockMode.FORCE,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.FORCE )
 			);
 		loaders.put(
 				LockMode.PESSIMISTIC_READ,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.PESSIMISTIC_READ )
 			);
 		loaders.put(
 				LockMode.PESSIMISTIC_WRITE,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.PESSIMISTIC_WRITE )
 			);
 		loaders.put(
 				LockMode.PESSIMISTIC_FORCE_INCREMENT,
 				disableForUpdate ?
 						readLoader :
 						createEntityLoader( LockMode.PESSIMISTIC_FORCE_INCREMENT )
 			);
 		loaders.put( LockMode.OPTIMISTIC, createEntityLoader( LockMode.OPTIMISTIC) );
 		loaders.put( LockMode.OPTIMISTIC_FORCE_INCREMENT, createEntityLoader(LockMode.OPTIMISTIC_FORCE_INCREMENT) );
 
 		loaders.put(
 				"merge",
 				new CascadeEntityLoader( this, CascadingActions.MERGE, getFactory() )
 			);
 		loaders.put(
 				"refresh",
 				new CascadeEntityLoader( this, CascadingActions.REFRESH, getFactory() )
 			);
 	}
 
 	protected void createQueryLoader() {
 		if ( loaderName != null ) {
 			queryLoader = new NamedQueryLoader( loaderName, this );
 		}
 	}
 
 	/**
 	 * Load an instance using either the <tt>forUpdateLoader</tt> or the outer joining <tt>loader</tt>,
 	 * depending upon the value of the <tt>lock</tt> parameter
 	 */
 	public Object load(Serializable id, Object optionalObject, LockMode lockMode, SessionImplementor session) {
 		return load( id, optionalObject, new LockOptions().setLockMode(lockMode), session );
 	}
 
 	/**
 	 * Load an instance using either the <tt>forUpdateLoader</tt> or the outer joining <tt>loader</tt>,
 	 * depending upon the value of the <tt>lock</tt> parameter
 	 */
 	public Object load(Serializable id, Object optionalObject, LockOptions lockOptions, SessionImplementor session)
 			throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Fetching entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		final UniqueEntityLoader loader = getAppropriateLoader(lockOptions, session );
 		return loader.load( id, optionalObject, session, lockOptions );
 	}
 
 	public void registerAffectingFetchProfile(String fetchProfileName) {
 		affectingFetchProfileNames.add( fetchProfileName );
 	}
 
 	private boolean isAffectedByEntityGraph(SessionImplementor session) {
 		return session.getLoadQueryInfluencers().getFetchGraph() != null || session.getLoadQueryInfluencers()
 				.getLoadGraph() != null;
 	}
 
 	private boolean isAffectedByEnabledFetchProfiles(SessionImplementor session) {
 		for ( String s : session.getLoadQueryInfluencers().getEnabledFetchProfileNames() ) {
 			if ( affectingFetchProfileNames.contains( s ) ) {
 				return true;
 			}
 		}
 		return false;
 	}
 
 	private boolean isAffectedByEnabledFilters(SessionImplementor session) {
 		return session.getLoadQueryInfluencers().hasEnabledFilters()
 				&& filterHelper.isAffectedBy( session.getLoadQueryInfluencers().getEnabledFilters() );
 	}
 
 	private UniqueEntityLoader getAppropriateLoader(LockOptions lockOptions, SessionImplementor session) {
 		if ( queryLoader != null ) {
 			// if the user specified a custom query loader we need to that
 			// regardless of any other consideration
 			return queryLoader;
 		}
 		else if ( isAffectedByEnabledFilters( session ) ) {
 			// because filters affect the rows returned (because they add
 			// restrictions) these need to be next in precedence
 			return createEntityLoader(lockOptions, session.getLoadQueryInfluencers() );
 		}
 		else if ( session.getLoadQueryInfluencers().getInternalFetchProfile() != null && LockMode.UPGRADE.greaterThan( lockOptions.getLockMode() ) ) {
 			// Next, we consider whether an 'internal' fetch profile has been set.
 			// This indicates a special fetch profile Hibernate needs applied
 			// (for its merge loading process e.g.).
 			return ( UniqueEntityLoader ) getLoaders().get( session.getLoadQueryInfluencers().getInternalFetchProfile() );
 		}
 		else if ( isAffectedByEnabledFetchProfiles( session ) ) {
 			// If the session has associated influencers we need to adjust the
 			// SQL query used for loading based on those influencers
 			return createEntityLoader(lockOptions, session.getLoadQueryInfluencers() );
 		}
 		else if ( isAffectedByEntityGraph( session ) ) {
 			return createEntityLoader( lockOptions, session.getLoadQueryInfluencers() );
 		}
 		else if ( lockOptions.getTimeOut() != LockOptions.WAIT_FOREVER ) {
 			return createEntityLoader( lockOptions, session.getLoadQueryInfluencers() );
 		}
 		else {
 			return ( UniqueEntityLoader ) getLoaders().get( lockOptions.getLockMode() );
 		}
 	}
 
 	private boolean isAllNull(Object[] array, int tableNumber) {
 		for ( int i = 0; i < array.length; i++ ) {
 			if ( isPropertyOfTable( i, tableNumber ) && array[i] != null ) {
 				return false;
 			}
 		}
 		return true;
 	}
 
 	public boolean isSubclassPropertyNullable(int i) {
 		return subclassPropertyNullabilityClosure[i];
 	}
 
 	/**
 	 * Transform the array of property indexes to an array of booleans,
 	 * true when the property is dirty
 	 */
 	protected final boolean[] getPropertiesToUpdate(final int[] dirtyProperties, final boolean hasDirtyCollection) {
 		final boolean[] propsToUpdate = new boolean[ entityMetamodel.getPropertySpan() ];
 		final boolean[] updateability = getPropertyUpdateability(); //no need to check laziness, dirty checking handles that
 		for ( int j = 0; j < dirtyProperties.length; j++ ) {
 			int property = dirtyProperties[j];
 			if ( updateability[property] ) {
 				propsToUpdate[property] = true;
 			}
 		}
 		if ( isVersioned() && updateability[getVersionProperty() ]) {
 			propsToUpdate[ getVersionProperty() ] =
 				Versioning.isVersionIncrementRequired( dirtyProperties, hasDirtyCollection, getPropertyVersionability() );
 		}
 		return propsToUpdate;
 	}
 
 	/**
 	 * Transform the array of property indexes to an array of booleans,
 	 * true when the property is insertable and non-null
 	 */
 	protected boolean[] getPropertiesToInsert(Object[] fields) {
 		boolean[] notNull = new boolean[fields.length];
 		boolean[] insertable = getPropertyInsertability();
 		for ( int i = 0; i < fields.length; i++ ) {
 			notNull[i] = insertable[i] && fields[i] != null;
 		}
 		return notNull;
 	}
 
 	/**
 	 * Locate the property-indices of all properties considered to be dirty.
 	 *
 	 * @param currentState The current state of the entity (the state to be checked).
 	 * @param previousState The previous state of the entity (the state to be checked against).
 	 * @param entity The entity for which we are checking state dirtiness.
 	 * @param session The session in which the check is occurring.
 	 * @return <tt>null</tt> or the indices of the dirty properties
 	 * @throws HibernateException
 	 */
 	public int[] findDirty(Object[] currentState, Object[] previousState, Object entity, SessionImplementor session)
 	throws HibernateException {
 		int[] props = TypeHelper.findDirty(
 				entityMetamodel.getProperties(),
 				currentState,
 				previousState,
 				propertyColumnUpdateable,
 				hasUninitializedLazyProperties( entity ),
 				session
 			);
 		if ( props == null ) {
 			return null;
 		}
 		else {
 			logDirtyProperties( props );
 			return props;
 		}
 	}
 
 	/**
 	 * Locate the property-indices of all properties considered to be dirty.
 	 *
 	 * @param old The old state of the entity.
 	 * @param current The current state of the entity.
 	 * @param entity The entity for which we are checking state modification.
 	 * @param session The session in which the check is occurring.
 	 * @return <tt>null</tt> or the indices of the modified properties
 	 * @throws HibernateException
 	 */
 	public int[] findModified(Object[] old, Object[] current, Object entity, SessionImplementor session)
 	throws HibernateException {
 		int[] props = TypeHelper.findModified(
 				entityMetamodel.getProperties(),
 				current,
 				old,
 				propertyColumnUpdateable,
 				hasUninitializedLazyProperties( entity ),
 				session
 			);
 		if ( props == null ) {
 			return null;
 		}
 		else {
 			logDirtyProperties( props );
 			return props;
 		}
 	}
 
 	/**
 	 * Which properties appear in the SQL update?
 	 * (Initialized, updateable ones!)
 	 */
 	protected boolean[] getPropertyUpdateability(Object entity) {
 		return hasUninitializedLazyProperties( entity )
 				? getNonLazyPropertyUpdateability()
 				: getPropertyUpdateability();
 	}
 
 	private void logDirtyProperties(int[] props) {
 		if ( LOG.isTraceEnabled() ) {
 			for ( int i = 0; i < props.length; i++ ) {
 				String propertyName = entityMetamodel.getProperties()[ props[i] ].getName();
 				LOG.trace( StringHelper.qualify( getEntityName(), propertyName ) + " is dirty" );
 			}
 		}
 	}
 
 	public SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	public EntityMetamodel getEntityMetamodel() {
 		return entityMetamodel;
 	}
 
 	public boolean hasCache() {
 		return cacheAccessStrategy != null;
 	}
 
 	public EntityRegionAccessStrategy getCacheAccessStrategy() {
 		return cacheAccessStrategy;
 	}
 
 	@Override
 	public CacheEntryStructure getCacheEntryStructure() {
 		return cacheEntryHelper.getCacheEntryStructure();
 	}
 
 	@Override
 	public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 		return cacheEntryHelper.buildCacheEntry( entity, state, version, session );
 	}
 
 	public boolean hasNaturalIdCache() {
 		return naturalIdRegionAccessStrategy != null;
 	}
 	
 	public NaturalIdRegionAccessStrategy getNaturalIdCacheAccessStrategy() {
 		return naturalIdRegionAccessStrategy;
 	}
 
 	public Comparator getVersionComparator() {
 		return isVersioned() ? getVersionType().getComparator() : null;
 	}
 
 	// temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	public final String getEntityName() {
 		return entityMetamodel.getName();
 	}
 
 	public EntityType getEntityType() {
 		return entityMetamodel.getEntityType();
 	}
 
 	public boolean isPolymorphic() {
 		return entityMetamodel.isPolymorphic();
 	}
 
 	public boolean isInherited() {
 		return entityMetamodel.isInherited();
 	}
 
 	public boolean hasCascades() {
 		return entityMetamodel.hasCascades();
 	}
 
 	public boolean hasIdentifierProperty() {
 		return !entityMetamodel.getIdentifierProperty().isVirtual();
 	}
 
 	public VersionType getVersionType() {
 		return ( VersionType ) locateVersionType();
 	}
 
 	private Type locateVersionType() {
 		return entityMetamodel.getVersionProperty() == null ?
 				null :
 				entityMetamodel.getVersionProperty().getType();
 	}
 
 	public int getVersionProperty() {
 		return entityMetamodel.getVersionPropertyIndex();
 	}
 
 	public boolean isVersioned() {
 		return entityMetamodel.isVersioned();
 	}
 
 	public boolean isIdentifierAssignedByInsert() {
 		return entityMetamodel.getIdentifierProperty().isIdentifierAssignedByInsert();
 	}
 
 	public boolean hasLazyProperties() {
 		return entityMetamodel.hasLazyProperties();
 	}
 
 //	public boolean hasUninitializedLazyProperties(Object entity) {
 //		if ( hasLazyProperties() ) {
 //			InterceptFieldCallback callback = ( ( InterceptFieldEnabled ) entity ).getInterceptFieldCallback();
 //			return callback != null && !( ( FieldInterceptor ) callback ).isInitialized();
 //		}
 //		else {
 //			return false;
 //		}
 //	}
 
 	public void afterReassociate(Object entity, SessionImplementor session) {
 		if ( getEntityMetamodel().getInstrumentationMetadata().isInstrumented() ) {
 			FieldInterceptor interceptor = getEntityMetamodel().getInstrumentationMetadata().extractInterceptor( entity );
 			if ( interceptor != null ) {
 				interceptor.setSession( session );
 			}
 			else {
 				FieldInterceptor fieldInterceptor = getEntityMetamodel().getInstrumentationMetadata().injectInterceptor(
 						entity,
 						getEntityName(),
 						null,
 						session
 				);
 				fieldInterceptor.dirty();
 			}
 		}
 
 		handleNaturalIdReattachment( entity, session );
 	}
 
 	private void handleNaturalIdReattachment(Object entity, SessionImplementor session) {
 		if ( ! hasNaturalIdentifier() ) {
 			return;
 		}
 
 		if ( getEntityMetamodel().hasImmutableNaturalId() ) {
 			// we assume there were no changes to natural id during detachment for now, that is validated later
 			// during flush.
 			return;
 		}
 
 		final NaturalIdHelper naturalIdHelper = session.getPersistenceContext().getNaturalIdHelper();
 		final Serializable id = getIdentifier( entity, session );
 
 		// for reattachment of mutable natural-ids, we absolutely positively have to grab the snapshot from the
 		// database, because we have no other way to know if the state changed while detached.
 		final Object[] naturalIdSnapshot;
 		final Object[] entitySnapshot = session.getPersistenceContext().getDatabaseSnapshot( id, this );
 		if ( entitySnapshot == StatefulPersistenceContext.NO_ROW ) {
 			naturalIdSnapshot = null;
 		}
 		else {
 			naturalIdSnapshot = naturalIdHelper.extractNaturalIdValues( entitySnapshot, this );
 		}
 
 		naturalIdHelper.removeSharedNaturalIdCrossReference( this, id, naturalIdSnapshot );
 		naturalIdHelper.manageLocalNaturalIdCrossReference(
 				this,
 				id,
 				naturalIdHelper.extractNaturalIdValues( entity, this ),
 				naturalIdSnapshot,
 				CachedNaturalIdValueSource.UPDATE
 		);
 	}
 
 	public Boolean isTransient(Object entity, SessionImplementor session) throws HibernateException {
 		final Serializable id;
 		if ( canExtractIdOutOfEntity() ) {
 			id = getIdentifier( entity, session );
 		}
 		else {
 			id = null;
 		}
 		// we *always* assume an instance with a null
 		// identifier or no identifier property is unsaved!
 		if ( id == null ) {
 			return Boolean.TRUE;
 		}
 
 		// check the version unsaved-value, if appropriate
 		final Object version = getVersion( entity );
 		if ( isVersioned() ) {
 			// let this take precedence if defined, since it works for
 			// assigned identifiers
 			Boolean result = entityMetamodel.getVersionProperty()
 					.getUnsavedValue().isUnsaved( version );
 			if ( result != null ) {
 				return result;
 			}
 		}
 
 		// check the id unsaved-value
 		Boolean result = entityMetamodel.getIdentifierProperty()
 				.getUnsavedValue().isUnsaved( id );
 		if ( result != null ) {
 			return result;
 		}
 
 		// check to see if it is in the second-level cache
 		if ( session.getCacheMode().isGetEnabled() && hasCache() ) {
 			final CacheKey ck = session.generateCacheKey( id, getIdentifierType(), getRootEntityName() );
 			final Object ce = CacheHelper.fromSharedCache( session, ck, getCacheAccessStrategy() );
 			if ( ce != null ) {
 				return Boolean.FALSE;
 			}
 		}
 
 		return null;
 	}
 
 	public boolean hasCollections() {
 		return entityMetamodel.hasCollections();
 	}
 
 	public boolean hasMutableProperties() {
 		return entityMetamodel.hasMutableProperties();
 	}
 
 	public boolean isMutable() {
 		return entityMetamodel.isMutable();
 	}
 
 	private boolean isModifiableEntity(EntityEntry entry) {
 
 		return ( entry == null ? isMutable() : entry.isModifiableEntity() );
 	}
 
 	public boolean isAbstract() {
 		return entityMetamodel.isAbstract();
 	}
 
 	public boolean hasSubclasses() {
 		return entityMetamodel.hasSubclasses();
 	}
 
 	public boolean hasProxy() {
 		return entityMetamodel.isLazy();
 	}
 
 	public IdentifierGenerator getIdentifierGenerator() throws HibernateException {
 		return entityMetamodel.getIdentifierProperty().getIdentifierGenerator();
 	}
 
 	public String getRootEntityName() {
 		return entityMetamodel.getRootName();
 	}
 
 	public ClassMetadata getClassMetadata() {
 		return this;
 	}
 
 	public String getMappedSuperclass() {
 		return entityMetamodel.getSuperclass();
 	}
 
 	public boolean isExplicitPolymorphism() {
 		return entityMetamodel.isExplicitPolymorphism();
 	}
 
 	protected boolean useDynamicUpdate() {
 		return entityMetamodel.isDynamicUpdate();
 	}
 
 	protected boolean useDynamicInsert() {
 		return entityMetamodel.isDynamicInsert();
 	}
 
 	protected boolean hasEmbeddedCompositeIdentifier() {
 		return entityMetamodel.getIdentifierProperty().isEmbedded();
 	}
 
 	public boolean canExtractIdOutOfEntity() {
 		return hasIdentifierProperty() || hasEmbeddedCompositeIdentifier() || hasIdentifierMapper();
 	}
 
 	private boolean hasIdentifierMapper() {
 		return entityMetamodel.getIdentifierProperty().hasIdentifierMapper();
 	}
 
 	public String[] getKeyColumnNames() {
 		return getIdentifierColumnNames();
 	}
 
 	public String getName() {
 		return getEntityName();
 	}
 
 	public boolean isCollection() {
 		return false;
 	}
 
 	public boolean consumesEntityAlias() {
 		return true;
 	}
 
 	public boolean consumesCollectionAlias() {
 		return false;
 	}
 
 	public Type getPropertyType(String propertyName) throws MappingException {
 		return propertyMapping.toType( propertyName );
 	}
 
 	public Type getType() {
 		return entityMetamodel.getEntityType();
 	}
 
 	public boolean isSelectBeforeUpdateRequired() {
 		return entityMetamodel.isSelectBeforeUpdate();
 	}
 
 	protected final OptimisticLockStyle optimisticLockStyle() {
 		return entityMetamodel.getOptimisticLockStyle();
 	}
 
 	public Object createProxy(Serializable id, SessionImplementor session) throws HibernateException {
 		return entityMetamodel.getTuplizer().createProxy( id, session );
 	}
 
 	public String toString() {
 		return StringHelper.unqualify( getClass().getName() ) +
 				'(' + entityMetamodel.getName() + ')';
 	}
 
 	public final String selectFragment(
 			Joinable rhs,
 			String rhsAlias,
 			String lhsAlias,
 			String entitySuffix,
 			String collectionSuffix,
 			boolean includeCollectionColumns) {
 		return selectFragment( lhsAlias, entitySuffix );
 	}
 
 	public boolean isInstrumented() {
 		return entityMetamodel.isInstrumented();
 	}
 
 	public boolean hasInsertGeneratedProperties() {
 		return entityMetamodel.hasInsertGeneratedValues();
 	}
 
 	public boolean hasUpdateGeneratedProperties() {
 		return entityMetamodel.hasUpdateGeneratedValues();
 	}
 
 	public boolean isVersionPropertyGenerated() {
 		return isVersioned() && getEntityMetamodel().isVersionGenerated();
 	}
 
 	public boolean isVersionPropertyInsertable() {
 		return isVersioned() && getPropertyInsertability() [ getVersionProperty() ];
 	}
 
 	public void afterInitialize(Object entity, boolean lazyPropertiesAreUnfetched, SessionImplementor session) {
 		getEntityTuplizer().afterInitialize( entity, lazyPropertiesAreUnfetched, session );
 	}
 
 	public String[] getPropertyNames() {
 		return entityMetamodel.getPropertyNames();
 	}
 
 	public Type[] getPropertyTypes() {
 		return entityMetamodel.getPropertyTypes();
 	}
 
 	public boolean[] getPropertyLaziness() {
 		return entityMetamodel.getPropertyLaziness();
 	}
 
 	public boolean[] getPropertyUpdateability() {
 		return entityMetamodel.getPropertyUpdateability();
 	}
 
 	public boolean[] getPropertyCheckability() {
 		return entityMetamodel.getPropertyCheckability();
 	}
 
 	public boolean[] getNonLazyPropertyUpdateability() {
 		return entityMetamodel.getNonlazyPropertyUpdateability();
 	}
 
 	public boolean[] getPropertyInsertability() {
 		return entityMetamodel.getPropertyInsertability();
 	}
 
 	@Deprecated
 	public ValueInclusion[] getPropertyInsertGenerationInclusions() {
 		return null;
 	}
 
 	@Deprecated
 	public ValueInclusion[] getPropertyUpdateGenerationInclusions() {
 		return null;
 	}
 
 	public boolean[] getPropertyNullability() {
 		return entityMetamodel.getPropertyNullability();
 	}
 
 	public boolean[] getPropertyVersionability() {
 		return entityMetamodel.getPropertyVersionability();
 	}
 
 	public CascadeStyle[] getPropertyCascadeStyles() {
 		return entityMetamodel.getCascadeStyles();
 	}
 
 	public final Class getMappedClass() {
 		return getEntityTuplizer().getMappedClass();
 	}
 
 	public boolean implementsLifecycle() {
 		return getEntityTuplizer().isLifecycleImplementor();
 	}
 
 	public Class getConcreteProxyClass() {
 		return getEntityTuplizer().getConcreteProxyClass();
 	}
 
 	public void setPropertyValues(Object object, Object[] values) {
 		getEntityTuplizer().setPropertyValues( object, values );
 	}
 
 	public void setPropertyValue(Object object, int i, Object value) {
 		getEntityTuplizer().setPropertyValue( object, i, value );
 	}
 
 	public Object[] getPropertyValues(Object object) {
 		return getEntityTuplizer().getPropertyValues( object );
 	}
 
 	@Override
 	public Object getPropertyValue(Object object, int i) {
 		return getEntityTuplizer().getPropertyValue( object, i );
 	}
 
 	@Override
 	public Object getPropertyValue(Object object, String propertyName) {
 		return getEntityTuplizer().getPropertyValue( object, propertyName );
 	}
 
 	@Override
 	public Serializable getIdentifier(Object object) {
 		return getEntityTuplizer().getIdentifier( object, null );
 	}
 
 	@Override
 	public Serializable getIdentifier(Object entity, SessionImplementor session) {
 		return getEntityTuplizer().getIdentifier( entity, session );
 	}
 
 	@Override
 	public void setIdentifier(Object entity, Serializable id, SessionImplementor session) {
 		getEntityTuplizer().setIdentifier( entity, id, session );
 	}
 
 	@Override
 	public Object getVersion(Object object) {
 		return getEntityTuplizer().getVersion( object );
 	}
 
 	@Override
 	public Object instantiate(Serializable id, SessionImplementor session) {
 		return getEntityTuplizer().instantiate( id, session );
 	}
 
 	@Override
 	public boolean isInstance(Object object) {
 		return getEntityTuplizer().isInstance( object );
 	}
 
 	@Override
 	public boolean hasUninitializedLazyProperties(Object object) {
 		return getEntityTuplizer().hasUninitializedLazyProperties( object );
 	}
 
 	@Override
 	public void resetIdentifier(Object entity, Serializable currentId, Object currentVersion, SessionImplementor session) {
 		getEntityTuplizer().resetIdentifier( entity, currentId, currentVersion, session );
 	}
 
 	@Override
 	public EntityPersister getSubclassEntityPersister(Object instance, SessionFactoryImplementor factory) {
 		if ( !hasSubclasses() ) {
 			return this;
 		}
 		else {
 			final String concreteEntityName = getEntityTuplizer().determineConcreteSubclassEntityName(
 					instance,
 					factory
 			);
 			if ( concreteEntityName == null || getEntityName().equals( concreteEntityName ) ) {
 				// the contract of EntityTuplizer.determineConcreteSubclassEntityName says that returning null
 				// is an indication that the specified entity-name (this.getEntityName) should be used.
 				return this;
 			}
 			else {
 				return factory.getEntityPersister( concreteEntityName );
 			}
 		}
 	}
 
 	public boolean isMultiTable() {
 		return false;
 	}
 
 	protected int getPropertySpan() {
 		return entityMetamodel.getPropertySpan();
 	}
 
 	public Object[] getPropertyValuesToInsert(Object object, Map mergeMap, SessionImplementor session) throws HibernateException {
 		return getEntityTuplizer().getPropertyValuesToInsert( object, mergeMap, session );
 	}
 
 	public void processInsertGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session) {
 		if ( !hasInsertGeneratedProperties() ) {
 			throw new AssertionFailure("no insert-generated properties");
 		}
 		processGeneratedProperties( id, entity, state, session, sqlInsertGeneratedValuesSelectString, GenerationTiming.INSERT );
 	}
 
 	public void processUpdateGeneratedProperties(Serializable id, Object entity, Object[] state, SessionImplementor session) {
 		if ( !hasUpdateGeneratedProperties() ) {
 			throw new AssertionFailure("no update-generated properties");
 		}
 		processGeneratedProperties( id, entity, state, session, sqlUpdateGeneratedValuesSelectString, GenerationTiming.ALWAYS );
 	}
 
 	private void processGeneratedProperties(
 			Serializable id,
 	        Object entity,
 	        Object[] state,
 	        SessionImplementor session,
 	        String selectionSQL,
 			GenerationTiming matchTiming) {
 		// force immediate execution of the insert batch (if one)
-		session.getTransactionCoordinator().getJdbcCoordinator().executeBatch();
+		session.getJdbcCoordinator().executeBatch();
 
 		try {
-			PreparedStatement ps = session.getTransactionCoordinator()
+			PreparedStatement ps = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( selectionSQL );
 			try {
 				getIdentifierType().nullSafeSet( ps, id, 1, session );
-				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( ps );
+				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					if ( !rs.next() ) {
 						throw new HibernateException(
 								"Unable to locate row for retrieval of generated properties: " +
 								MessageHelper.infoString( this, id, getFactory() )
 							);
 					}
 					int propertyIndex = -1;
 					for ( NonIdentifierAttribute attribute : entityMetamodel.getProperties() ) {
 						propertyIndex++;
 						final ValueGeneration valueGeneration = attribute.getValueGenerationStrategy();
 						if ( isReadRequired( valueGeneration, matchTiming ) ) {
 							final Object hydratedState = attribute.getType().hydrate(
 									rs, getPropertyAliases(
 									"",
 									propertyIndex
 							), session, entity
 							);
 							state[propertyIndex] = attribute.getType().resolve( hydratedState, session, entity );
 							setPropertyValue( entity, propertyIndex, state[propertyIndex] );
 						}
 					}
 //					for ( int i = 0; i < getPropertySpan(); i++ ) {
 //						if ( includeds[i] != ValueInclusion.NONE ) {
 //							Object hydratedState = getPropertyTypes()[i].hydrate( rs, getPropertyAliases( "", i ), session, entity );
 //							state[i] = getPropertyTypes()[i].resolve( hydratedState, session, entity );
 //							setPropertyValue( entity, i, state[i] );
 //						}
 //					}
 				}
 				finally {
 					if ( rs != null ) {
-						session.getTransactionCoordinator().getJdbcCoordinator().release( rs, ps );
+						session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 					}
 				}
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
+				session.getJdbcCoordinator().getResourceRegistry().release( ps );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"unable to select generated column values",
 					selectionSQL
 			);
 		}
 
 	}
 
 	/**
 	 * Whether the given value generation strategy requires to read the value from the database or not.
 	 */
 	private boolean isReadRequired(ValueGeneration valueGeneration, GenerationTiming matchTiming) {
 		return valueGeneration != null &&
 				valueGeneration.getValueGenerator() == null &&
 				timingsMatch( valueGeneration.getGenerationTiming(), matchTiming );
 	}
 
 	private boolean timingsMatch(GenerationTiming timing, GenerationTiming matchTiming) {
 		return
 				(matchTiming == GenerationTiming.INSERT && timing.includesInsert()) ||
 						(matchTiming == GenerationTiming.ALWAYS && timing.includesUpdate());
 	}
 
 	public String getIdentifierPropertyName() {
 		return entityMetamodel.getIdentifierProperty().getName();
 	}
 
 	public Type getIdentifierType() {
 		return entityMetamodel.getIdentifierProperty().getType();
 	}
 
 	public boolean hasSubselectLoadableCollections() {
 		return hasSubselectLoadableCollections;
 	}
 
 	public int[] getNaturalIdentifierProperties() {
 		return entityMetamodel.getNaturalIdentifierProperties();
 	}
 
 	public Object[] getNaturalIdentifierSnapshot(Serializable id, SessionImplementor session) throws HibernateException {
 		if ( !hasNaturalIdentifier() ) {
 			throw new MappingException( "persistent class did not define a natural-id : " + MessageHelper.infoString( this ) );
 		}
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Getting current natural-id snapshot state for: {0}",
 					MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		int[] naturalIdPropertyIndexes = getNaturalIdentifierProperties();
 		int naturalIdPropertyCount = naturalIdPropertyIndexes.length;
 		boolean[] naturalIdMarkers = new boolean[ getPropertySpan() ];
 		Type[] extractionTypes = new Type[ naturalIdPropertyCount ];
 		for ( int i = 0; i < naturalIdPropertyCount; i++ ) {
 			extractionTypes[i] = getPropertyTypes()[ naturalIdPropertyIndexes[i] ];
 			naturalIdMarkers[ naturalIdPropertyIndexes[i] ] = true;
 		}
 
 		///////////////////////////////////////////////////////////////////////
 		// TODO : look at perhaps caching this...
 		Select select = new Select( getFactory().getDialect() );
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "get current natural-id state " + getEntityName() );
 		}
 		select.setSelectClause( concretePropertySelectFragmentSansLeadingComma( getRootAlias(), naturalIdMarkers ) );
 		select.setFromClause( fromTableFragment( getRootAlias() ) + fromJoinFragment( getRootAlias(), true, false ) );
 
 		String[] aliasedIdColumns = StringHelper.qualify( getRootAlias(), getIdentifierColumnNames() );
 		String whereClause = new StringBuilder()
 			.append( StringHelper.join( "=? and ",
 					aliasedIdColumns ) )
 			.append( "=?" )
 			.append( whereJoinFragment( getRootAlias(), true, false ) )
 			.toString();
 
 		String sql = select.setOuterJoins( "", "" )
 				.setWhereClause( whereClause )
 				.toStatementString();
 		///////////////////////////////////////////////////////////////////////
 
 		Object[] snapshot = new Object[ naturalIdPropertyCount ];
 		try {
-			PreparedStatement ps = session.getTransactionCoordinator()
+			PreparedStatement ps = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( sql );
 			try {
 				getIdentifierType().nullSafeSet( ps, id, 1, session );
-				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( ps );
+				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					//if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 					final EntityKey key = session.generateEntityKey( id, this );
 					Object owner = session.getPersistenceContext().getEntity( key );
 					for ( int i = 0; i < naturalIdPropertyCount; i++ ) {
 						snapshot[i] = extractionTypes[i].hydrate( rs, getPropertyAliases( "", naturalIdPropertyIndexes[i] ), session, null );
 						if (extractionTypes[i].isEntityType()) {
 							snapshot[i] = extractionTypes[i].resolve(snapshot[i], session, owner);
 						}
 					}
 					return snapshot;
 				}
 				finally {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, ps );
+					session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 				}
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
+				session.getJdbcCoordinator().getResourceRegistry().release( ps );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not retrieve snapshot: " + MessageHelper.infoString( this, id, getFactory() ),
 			        sql
 			);
 		}
 	}
 
 	@Override
 	public Serializable loadEntityIdByNaturalId(
 			Object[] naturalIdValues,
 			LockOptions lockOptions,
 			SessionImplementor session) {
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracef(
 					"Resolving natural-id [%s] to id : %s ",
 					naturalIdValues,
 					MessageHelper.infoString( this )
 			);
 		}
 
 		final boolean[] valueNullness = determineValueNullness( naturalIdValues );
 		final String sqlEntityIdByNaturalIdString = determinePkByNaturalIdQuery( valueNullness );
 
 		try {
-			PreparedStatement ps = session.getTransactionCoordinator()
+			PreparedStatement ps = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( sqlEntityIdByNaturalIdString );
 			try {
 				int positions = 1;
 				int loop = 0;
 				for ( int idPosition : getNaturalIdentifierProperties() ) {
 					final Object naturalIdValue = naturalIdValues[loop++];
 					if ( naturalIdValue != null ) {
 						final Type type = getPropertyTypes()[idPosition];
 						type.nullSafeSet( ps, naturalIdValue, positions, session );
 						positions += type.getColumnSpan( session.getFactory() );
 					}
 				}
-				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( ps );
+				ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					// if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 
 					final Object hydratedId = getIdentifierType().hydrate( rs, getIdentifierAliases(), session, null );
 					return (Serializable) getIdentifierType().resolve( hydratedId, session, null );
 				}
 				finally {
-					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, ps );
+					session.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
 				}
 			}
 			finally {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
+				session.getJdbcCoordinator().getResourceRegistry().release( ps );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					String.format(
 							"could not resolve natural-id [%s] to id : %s",
 							naturalIdValues,
 							MessageHelper.infoString( this )
 					),
 					sqlEntityIdByNaturalIdString
 			);
 		}
 	}
 
 	private boolean[] determineValueNullness(Object[] naturalIdValues) {
 		boolean[] nullness = new boolean[ naturalIdValues.length ];
 		for ( int i = 0; i < naturalIdValues.length; i++ ) {
 			nullness[i] = naturalIdValues[i] == null;
 		}
 		return nullness;
 	}
 
 	private Boolean naturalIdIsNonNullable;
 	private String cachedPkByNonNullableNaturalIdQuery;
 
 	private String determinePkByNaturalIdQuery(boolean[] valueNullness) {
 		if ( ! hasNaturalIdentifier() ) {
 			throw new HibernateException( "Attempt to build natural-id -> PK resolution query for entity that does not define natural id" );
 		}
 
 		// performance shortcut for cases where the natural-id is defined as completely non-nullable
 		if ( isNaturalIdNonNullable() ) {
 			if ( valueNullness != null && ! ArrayHelper.isAllFalse( valueNullness ) ) {
 				throw new HibernateException( "Null value(s) passed to lookup by non-nullable natural-id" );
 			}
 			if ( cachedPkByNonNullableNaturalIdQuery == null ) {
 				cachedPkByNonNullableNaturalIdQuery = generateEntityIdByNaturalIdSql( null );
 			}
 			return cachedPkByNonNullableNaturalIdQuery;
 		}
 
 		// Otherwise, regenerate it each time
 		return generateEntityIdByNaturalIdSql( valueNullness );
 	}
 
 	protected boolean isNaturalIdNonNullable() {
 		if ( naturalIdIsNonNullable == null ) {
 			naturalIdIsNonNullable = determineNaturalIdNullability();
 		}
 		return naturalIdIsNonNullable;
 	}
 
 	private boolean determineNaturalIdNullability() {
 		boolean[] nullability = getPropertyNullability();
 		for ( int position : getNaturalIdentifierProperties() ) {
 			// if any individual property is nullable, return false
 			if ( nullability[position] ) {
 				return false;
 			}
 		}
 		// return true if we found no individually nullable properties
 		return true;
 	}
 
 	private String generateEntityIdByNaturalIdSql(boolean[] valueNullness) {
 		EntityPersister rootPersister = getFactory().getEntityPersister( getRootEntityName() );
 		if ( rootPersister != this ) {
 			if ( rootPersister instanceof AbstractEntityPersister ) {
 				return ( (AbstractEntityPersister) rootPersister ).generateEntityIdByNaturalIdSql( valueNullness );
 			}
 		}
 
 		Select select = new Select( getFactory().getDialect() );
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "get current natural-id->entity-id state " + getEntityName() );
 		}
 
 		final String rootAlias = getRootAlias();
 
 		select.setSelectClause( identifierSelectFragment( rootAlias, "" ) );
 		select.setFromClause( fromTableFragment( rootAlias ) + fromJoinFragment( rootAlias, true, false ) );
 
 		final StringBuilder whereClause = new StringBuilder();
 		final int[] propertyTableNumbers = getPropertyTableNumbers();
 		final int[] naturalIdPropertyIndexes = this.getNaturalIdentifierProperties();
 		int valuesIndex = -1;
 		for ( int propIdx = 0; propIdx < naturalIdPropertyIndexes.length; propIdx++ ) {
 			valuesIndex++;
 			if ( propIdx > 0 ) {
 				whereClause.append( " and " );
 			}
 
 			final int naturalIdIdx = naturalIdPropertyIndexes[propIdx];
 			final String tableAlias = generateTableAlias( rootAlias, propertyTableNumbers[naturalIdIdx] );
 			final String[] propertyColumnNames = getPropertyColumnNames( naturalIdIdx );
 			final String[] aliasedPropertyColumns = StringHelper.qualify( tableAlias, propertyColumnNames );
 
 			if ( valueNullness != null && valueNullness[valuesIndex] ) {
 				whereClause.append( StringHelper.join( " is null and ", aliasedPropertyColumns ) ).append( " is null" );
 			}
 			else {
 				whereClause.append( StringHelper.join( "=? and ", aliasedPropertyColumns ) ).append( "=?" );
 			}
 		}
 
 		whereClause.append( whereJoinFragment( getRootAlias(), true, false ) );
 
 		return select.setOuterJoins( "", "" ).setWhereClause( whereClause.toString() ).toStatementString();
 	}
 
 	protected String concretePropertySelectFragmentSansLeadingComma(String alias, boolean[] include) {
 		String concretePropertySelectFragment = concretePropertySelectFragment( alias, include );
 		int firstComma = concretePropertySelectFragment.indexOf( ", " );
 		if ( firstComma == 0 ) {
 			concretePropertySelectFragment = concretePropertySelectFragment.substring( 2 );
 		}
 		return concretePropertySelectFragment;
 	}
 
 	public boolean hasNaturalIdentifier() {
 		return entityMetamodel.hasNaturalIdentifier();
 	}
 
 	public void setPropertyValue(Object object, String propertyName, Object value) {
 		getEntityTuplizer().setPropertyValue( object, propertyName, value );
 	}
 	
 	public static int getTableId(String tableName, String[] tables) {
 		for ( int j = 0; j < tables.length; j++ ) {
 			if ( tableName.equalsIgnoreCase( tables[j] ) ) {
 				return j;
 			}
 		}
 		throw new AssertionFailure( "Table " + tableName + " not found" );
 	}
 	
 	@Override
 	public EntityMode getEntityMode() {
 		return entityMetamodel.getEntityMode();
 	}
 
 	@Override
 	public EntityTuplizer getEntityTuplizer() {
 		return entityTuplizer;
 	}
 
 	@Override
 	public EntityInstrumentationMetadata getInstrumentationMetadata() {
 		return entityMetamodel.getInstrumentationMetadata();
 	}
 
 	@Override
 	public String getTableAliasForColumn(String columnName, String rootAlias) {
 		return generateTableAlias( rootAlias, determineTableNumberForColumn( columnName ) );
 	}
 
 	public int determineTableNumberForColumn(String columnName) {
 		return 0;
 	}
 
 	@Override
 	public EntityEntryFactory getEntityEntryFactory() {
 		return this.entityEntryFactory;
 	}
 
 	/**
 	 * Consolidated these onto a single helper because the 2 pieces work in tandem.
 	 */
 	public static interface CacheEntryHelper {
 		public CacheEntryStructure getCacheEntryStructure();
 
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session);
 	}
 
 	private static class StandardCacheEntryHelper implements CacheEntryHelper {
 		private final EntityPersister persister;
 
 		private StandardCacheEntryHelper(EntityPersister persister) {
 			this.persister = persister;
 		}
 
 		@Override
 		public CacheEntryStructure getCacheEntryStructure() {
 			return UnstructuredCacheEntry.INSTANCE;
 		}
 
 		@Override
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 			return new StandardCacheEntryImpl(
 					state,
 					persister,
 					persister.hasUninitializedLazyProperties( entity ),
 					version,
 					session,
 					entity
 			);
 		}
 	}
 
 	private static class ReferenceCacheEntryHelper implements CacheEntryHelper {
 		private final EntityPersister persister;
 
 		private ReferenceCacheEntryHelper(EntityPersister persister) {
 			this.persister = persister;
 		}
 
 		@Override
 		public CacheEntryStructure getCacheEntryStructure() {
 			return UnstructuredCacheEntry.INSTANCE;
 		}
 
 		@Override
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 			return new ReferenceCacheEntryImpl( entity, persister );
 		}
 	}
 
 	private static class StructuredCacheEntryHelper implements CacheEntryHelper {
 		private final EntityPersister persister;
 		private final StructuredCacheEntry structure;
 
 		private StructuredCacheEntryHelper(EntityPersister persister) {
 			this.persister = persister;
 			this.structure = new StructuredCacheEntry( persister );
 		}
 
 		@Override
 		public CacheEntryStructure getCacheEntryStructure() {
 			return structure;
 		}
 
 		@Override
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 			return new StandardCacheEntryImpl(
 					state,
 					persister,
 					persister.hasUninitializedLazyProperties( entity ),
 					version,
 					session,
 					entity
 			);
 		}
 	}
 
 	private static class NoopCacheEntryHelper implements CacheEntryHelper {
 		public static final NoopCacheEntryHelper INSTANCE = new NoopCacheEntryHelper();
 
 		@Override
 		public CacheEntryStructure getCacheEntryStructure() {
 			return UnstructuredCacheEntry.INSTANCE;
 		}
 
 		@Override
 		public CacheEntry buildCacheEntry(Object entity, Object[] state, Object version, SessionImplementor session) {
 			throw new HibernateException( "Illegal attempt to build cache entry for non-cached entity" );
 		}
 	}
 
 
 	// EntityDefinition impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private EntityIdentifierDefinition entityIdentifierDefinition;
 	private Iterable<AttributeDefinition> embeddedCompositeIdentifierAttributes;
 	private Iterable<AttributeDefinition> attributeDefinitions;
 
 	@Override
 	public void generateEntityDefinition() {
 		prepareEntityIdentifierDefinition();
 		collectAttributeDefinitions();
 	}
 
 	@Override
 	public EntityPersister getEntityPersister() {
 		return this;
 	}
 
 	@Override
 	public EntityIdentifierDefinition getEntityKeyDefinition() {
 		return entityIdentifierDefinition;
 	}
 
 	@Override
 	public Iterable<AttributeDefinition> getAttributes() {
 		return attributeDefinitions;
 	}
 
 
 	private void prepareEntityIdentifierDefinition() {
 		if ( entityIdentifierDefinition != null ) {
 			return;
 		}
 		final Type idType = getIdentifierType();
 
 		if ( !idType.isComponentType() ) {
 			entityIdentifierDefinition =
 					EntityIdentifierDefinitionHelper.buildSimpleEncapsulatedIdentifierDefinition( this );
 			return;
 		}
 
 		final CompositeType cidType = (CompositeType) idType;
 		if ( !cidType.isEmbedded() ) {
 			entityIdentifierDefinition =
 					EntityIdentifierDefinitionHelper.buildEncapsulatedCompositeIdentifierDefinition( this );
 			return;
 		}
 
 		entityIdentifierDefinition =
 				EntityIdentifierDefinitionHelper.buildNonEncapsulatedCompositeIdentifierDefinition( this );
 	}
 
 	private void collectAttributeDefinitions(
 			Map<String,AttributeDefinition> attributeDefinitionsByName,
 			EntityMetamodel metamodel) {
 		for ( int i = 0; i < metamodel.getPropertySpan(); i++ ) {
 			final AttributeDefinition attributeDefinition = metamodel.getProperties()[i];
 			// Don't replace an attribute definition if it is already in attributeDefinitionsByName
 			// because the new value will be from a subclass.
 			final AttributeDefinition oldAttributeDefinition = attributeDefinitionsByName.get(
 					attributeDefinition.getName()
 			);
 			if ( oldAttributeDefinition != null ) {
 				if ( LOG.isTraceEnabled() ) {
 						LOG.tracef(
 								"Ignoring subclass attribute definition [%s.%s] because it is defined in a superclass ",
 								entityMetamodel.getName(),
 								attributeDefinition.getName()
 						);
 				}
 			}
 			else {
 				attributeDefinitionsByName.put( attributeDefinition.getName(), attributeDefinition );
 			}
 		}
 
 		// see if there are any subclass persisters...
 		final Set<String> subClassEntityNames = metamodel.getSubclassEntityNames();
 		if ( subClassEntityNames == null ) {
 			return;
 		}
 
 		// see if we can find the persisters...
 		for ( String subClassEntityName : subClassEntityNames ) {
 			if ( metamodel.getName().equals( subClassEntityName ) ) {
 				// skip it
 				continue;
 			}
 			try {
 				final EntityPersister subClassEntityPersister = factory.getEntityPersister( subClassEntityName );
 				collectAttributeDefinitions( attributeDefinitionsByName, subClassEntityPersister.getEntityMetamodel() );
 			}
 			catch (MappingException e) {
 				throw new IllegalStateException(
 						String.format(
 								"Could not locate subclass EntityPersister [%s] while processing EntityPersister [%s]",
 								subClassEntityName,
 								metamodel.getName()
 						),
 						e
 				);
 			}
 		}
 	}
 
 	private void collectAttributeDefinitions() {
 		// todo : I think this works purely based on luck atm
 		// 		specifically in terms of the sub/super class entity persister(s) being available.  Bit of chicken-egg
 		// 		problem there:
 		//			* If I do this during postConstruct (as it is now), it works as long as the
 		//			super entity persister is already registered, but I don't think that is necessarily true.
 		//			* If I do this during postInstantiate then lots of stuff in postConstruct breaks if we want
 		//			to try and drive SQL generation on these (which we do ultimately).  A possible solution there
 		//			would be to delay all SQL generation until postInstantiate
 
 		Map<String,AttributeDefinition> attributeDefinitionsByName = new LinkedHashMap<String,AttributeDefinition>();
 		collectAttributeDefinitions( attributeDefinitionsByName, getEntityMetamodel() );
 
 
 //		EntityMetamodel currentEntityMetamodel = this.getEntityMetamodel();
 //		while ( currentEntityMetamodel != null ) {
 //			for ( int i = 0; i < currentEntityMetamodel.getPropertySpan(); i++ ) {
 //				attributeDefinitions.add( currentEntityMetamodel.getProperties()[i] );
 //			}
 //			// see if there is a super class EntityMetamodel
 //			final String superEntityName = currentEntityMetamodel.getSuperclass();
 //			if ( superEntityName != null ) {
 //				currentEntityMetamodel = factory.getEntityPersister( superEntityName ).getEntityMetamodel();
 //			}
 //			else {
 //				currentEntityMetamodel = null;
 //			}
 //		}
 
 		this.attributeDefinitions = Collections.unmodifiableList(
 				new ArrayList<AttributeDefinition>( attributeDefinitionsByName.values() )
 		);
 //		// todo : leverage the attribute definitions housed on EntityMetamodel
 //		// 		for that to work, we'd have to be able to walk our super entity persister(s)
 //		this.attributeDefinitions = new Iterable<AttributeDefinition>() {
 //			@Override
 //			public Iterator<AttributeDefinition> iterator() {
 //				return new Iterator<AttributeDefinition>() {
 ////					private final int numberOfAttributes = countSubclassProperties();
 ////					private final int numberOfAttributes = entityMetamodel.getPropertySpan();
 //
 //					EntityMetamodel currentEntityMetamodel = entityMetamodel;
 //					int numberOfAttributesInCurrentEntityMetamodel = currentEntityMetamodel.getPropertySpan();
 //
 //					private int currentAttributeNumber;
 //
 //					@Override
 //					public boolean hasNext() {
 //						return currentEntityMetamodel != null
 //								&& currentAttributeNumber < numberOfAttributesInCurrentEntityMetamodel;
 //					}
 //
 //					@Override
 //					public AttributeDefinition next() {
 //						final int attributeNumber = currentAttributeNumber;
 //						currentAttributeNumber++;
 //						final AttributeDefinition next = currentEntityMetamodel.getProperties()[ attributeNumber ];
 //
 //						if ( currentAttributeNumber >= numberOfAttributesInCurrentEntityMetamodel ) {
 //							// see if there is a super class EntityMetamodel
 //							final String superEntityName = currentEntityMetamodel.getSuperclass();
 //							if ( superEntityName != null ) {
 //								currentEntityMetamodel = factory.getEntityPersister( superEntityName ).getEntityMetamodel();
 //								if ( currentEntityMetamodel != null ) {
 //									numberOfAttributesInCurrentEntityMetamodel = currentEntityMetamodel.getPropertySpan();
 //									currentAttributeNumber = 0;
 //								}
 //							}
 //						}
 //
 //						return next;
 //					}
 //
 //					@Override
 //					public void remove() {
 //						throw new UnsupportedOperationException( "Remove operation not supported here" );
 //					}
 //				};
 //			}
 //		};
 	}
 
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/procedure/internal/ProcedureCallImpl.java b/hibernate-core/src/main/java/org/hibernate/procedure/internal/ProcedureCallImpl.java
index f2f144f228..531d49e2d3 100644
--- a/hibernate-core/src/main/java/org/hibernate/procedure/internal/ProcedureCallImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/procedure/internal/ProcedureCallImpl.java
@@ -1,541 +1,543 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.procedure.internal;
 
 import java.sql.CallableStatement;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import javax.persistence.ParameterMode;
 
 import org.hibernate.HibernateException;
 import org.hibernate.QueryException;
 import org.hibernate.cfg.NotYetImplementedException;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.jdbc.env.spi.ExtractedDatabaseMetaData;
+import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryReturn;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.AbstractBasicQueryContractImpl;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.procedure.NoSuchParameterException;
 import org.hibernate.procedure.ParameterRegistration;
 import org.hibernate.procedure.ParameterStrategyException;
 import org.hibernate.procedure.ProcedureCall;
 import org.hibernate.procedure.ProcedureCallMemento;
 import org.hibernate.procedure.ProcedureOutputs;
 import org.hibernate.procedure.spi.ParameterRegistrationImplementor;
 import org.hibernate.procedure.spi.ParameterStrategy;
 import org.hibernate.result.spi.ResultContext;
 import org.hibernate.type.Type;
 
 import org.jboss.logging.Logger;
 
 /**
  * Standard implementation of {@link org.hibernate.procedure.ProcedureCall}
  *
  * @author Steve Ebersole
  */
 public class ProcedureCallImpl extends AbstractBasicQueryContractImpl implements ProcedureCall, ResultContext {
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
 			CoreMessageLogger.class,
 			ProcedureCallImpl.class.getName()
 	);
 
 	private static final NativeSQLQueryReturn[] NO_RETURNS = new NativeSQLQueryReturn[0];
 
 	private final String procedureName;
 	private final NativeSQLQueryReturn[] queryReturns;
 
 	private ParameterStrategy parameterStrategy = ParameterStrategy.UNKNOWN;
 	private List<ParameterRegistrationImplementor<?>> registeredParameters = new ArrayList<ParameterRegistrationImplementor<?>>();
 
 	private Set<String> synchronizedQuerySpaces;
 
 	private ProcedureOutputsImpl outputs;
 
 	/**
 	 * The no-returns form.
 	 *
 	 * @param session The session
 	 * @param procedureName The name of the procedure to call
 	 */
 	public ProcedureCallImpl(SessionImplementor session, String procedureName) {
 		super( session );
 		this.procedureName = procedureName;
 		this.queryReturns = NO_RETURNS;
 	}
 
 	/**
 	 * The result Class(es) return form
 	 *
 	 * @param session The session
 	 * @param procedureName The name of the procedure to call
 	 * @param resultClasses The classes making up the result
 	 */
 	public ProcedureCallImpl(final SessionImplementor session, String procedureName, Class... resultClasses) {
 		super( session );
 		this.procedureName = procedureName;
 
 		final List<NativeSQLQueryReturn> collectedQueryReturns = new ArrayList<NativeSQLQueryReturn>();
 		final Set<String> collectedQuerySpaces = new HashSet<String>();
 
 		Util.resolveResultClasses(
 				new Util.ResultClassesResolutionContext() {
 					@Override
 					public SessionFactoryImplementor getSessionFactory() {
 						return session.getFactory();
 					}
 
 					@Override
 					public void addQueryReturns(NativeSQLQueryReturn... queryReturns) {
 						Collections.addAll( collectedQueryReturns, queryReturns );
 					}
 
 					@Override
 					public void addQuerySpaces(String... spaces) {
 						Collections.addAll( collectedQuerySpaces, spaces );
 					}
 				},
 				resultClasses
 		);
 
 		this.queryReturns = collectedQueryReturns.toArray( new NativeSQLQueryReturn[ collectedQueryReturns.size() ] );
 		this.synchronizedQuerySpaces = collectedQuerySpaces;
 	}
 
 	/**
 	 * The result-set-mapping(s) return form
 	 *
 	 * @param session The session
 	 * @param procedureName The name of the procedure to call
 	 * @param resultSetMappings The names of the result set mappings making up the result
 	 */
 	public ProcedureCallImpl(final SessionImplementor session, String procedureName, String... resultSetMappings) {
 		super( session );
 		this.procedureName = procedureName;
 
 		final List<NativeSQLQueryReturn> collectedQueryReturns = new ArrayList<NativeSQLQueryReturn>();
 		final Set<String> collectedQuerySpaces = new HashSet<String>();
 
 		Util.resolveResultSetMappings(
 				new Util.ResultSetMappingResolutionContext() {
 					@Override
 					public SessionFactoryImplementor getSessionFactory() {
 						return session.getFactory();
 					}
 
 					@Override
 					public ResultSetMappingDefinition findResultSetMapping(String name) {
 						return session.getFactory().getResultSetMapping( name );
 					}
 
 					@Override
 					public void addQueryReturns(NativeSQLQueryReturn... queryReturns) {
 						Collections.addAll( collectedQueryReturns, queryReturns );
 					}
 
 					@Override
 					public void addQuerySpaces(String... spaces) {
 						Collections.addAll( collectedQuerySpaces, spaces );
 					}
 				},
 				resultSetMappings
 		);
 
 		this.queryReturns = collectedQueryReturns.toArray( new NativeSQLQueryReturn[ collectedQueryReturns.size() ] );
 		this.synchronizedQuerySpaces = collectedQuerySpaces;
 	}
 
 	/**
 	 * The named/stored copy constructor
 	 *
 	 * @param session The session
 	 * @param memento The named/stored memento
 	 */
 	@SuppressWarnings("unchecked")
 	ProcedureCallImpl(SessionImplementor session, ProcedureCallMementoImpl memento) {
 		super( session );
 		this.procedureName = memento.getProcedureName();
 
 		this.queryReturns = memento.getQueryReturns();
 		this.synchronizedQuerySpaces = Util.copy( memento.getSynchronizedQuerySpaces() );
 		this.parameterStrategy = memento.getParameterStrategy();
 		if ( parameterStrategy == ParameterStrategy.UNKNOWN ) {
 			// nothing else to do in this case
 			return;
 		}
 
 		final List<ProcedureCallMementoImpl.ParameterMemento> storedRegistrations = memento.getParameterDeclarations();
 		if ( storedRegistrations == null ) {
 			// most likely a problem if ParameterStrategy is not UNKNOWN...
 			LOG.debugf(
 					"ParameterStrategy was [%s] on named copy [%s], but no parameters stored",
 					parameterStrategy,
 					procedureName
 			);
 			return;
 		}
 
 		final List<ParameterRegistrationImplementor<?>> parameterRegistrations =
 				CollectionHelper.arrayList( storedRegistrations.size() );
 
 		for ( ProcedureCallMementoImpl.ParameterMemento storedRegistration : storedRegistrations ) {
 			final ParameterRegistrationImplementor<?> registration;
 			if ( StringHelper.isNotEmpty( storedRegistration.getName() ) ) {
 				if ( parameterStrategy != ParameterStrategy.NAMED ) {
 					throw new IllegalStateException(
 							"Found named stored procedure parameter associated with positional parameters"
 					);
 				}
 				registration = new NamedParameterRegistration(
 						this,
 						storedRegistration.getName(),
 						storedRegistration.getMode(),
 						storedRegistration.getType(),
 						storedRegistration.getHibernateType()
 				);
 			}
 			else {
 				if ( parameterStrategy != ParameterStrategy.POSITIONAL ) {
 					throw new IllegalStateException(
 							"Found named stored procedure parameter associated with positional parameters"
 					);
 				}
 				registration = new PositionalParameterRegistration(
 						this,
 						storedRegistration.getPosition(),
 						storedRegistration.getMode(),
 						storedRegistration.getType(),
 						storedRegistration.getHibernateType()
 				);
 			}
 			parameterRegistrations.add( registration );
 		}
 		this.registeredParameters = parameterRegistrations;
 	}
 
 	@Override
 	public SessionImplementor getSession() {
 		return super.session();
 	}
 
 	public ParameterStrategy getParameterStrategy() {
 		return parameterStrategy;
 	}
 
 	@Override
 	public String getProcedureName() {
 		return procedureName;
 	}
 
 	@Override
 	public String getSql() {
 		return getProcedureName();
 	}
 
 	@Override
 	public NativeSQLQueryReturn[] getQueryReturns() {
 		return queryReturns;
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <T> ParameterRegistration<T> registerParameter(int position, Class<T> type, ParameterMode mode) {
 		final PositionalParameterRegistration parameterRegistration =
 				new PositionalParameterRegistration( this, position, mode, type );
 		registerParameter( parameterRegistration );
 		return parameterRegistration;
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public ProcedureCall registerParameter0(int position, Class type, ParameterMode mode) {
 		registerParameter( position, type, mode );
 		return this;
 	}
 
 	private void registerParameter(ParameterRegistrationImplementor parameter) {
 		if ( StringHelper.isNotEmpty( parameter.getName() ) ) {
 			prepareForNamedParameters();
 		}
 		else if ( parameter.getPosition() != null ) {
 			prepareForPositionalParameters();
 		}
 		else {
 			throw new IllegalArgumentException( "Given parameter did not define name or position [" + parameter + "]" );
 		}
 		registeredParameters.add( parameter );
 	}
 
 	private void prepareForPositionalParameters() {
 		if ( parameterStrategy == ParameterStrategy.NAMED ) {
 			throw new QueryException( "Cannot mix named and positional parameters" );
 		}
 		parameterStrategy = ParameterStrategy.POSITIONAL;
 	}
 
 	private void prepareForNamedParameters() {
 		if ( parameterStrategy == ParameterStrategy.POSITIONAL ) {
 			throw new QueryException( "Cannot mix named and positional parameters" );
 		}
 		if ( parameterStrategy == ParameterStrategy.UNKNOWN ) {
 			// protect to only do this check once
-			final ExtractedDatabaseMetaData databaseMetaData = getSession().getTransactionCoordinator()
+			final ExtractedDatabaseMetaData databaseMetaData = getSession()
 					.getJdbcCoordinator()
-					.getLogicalConnection()
-					.getJdbcServices()
-					.getExtractedMetaDataSupport();
+					.getJdbcSessionOwner()
+					.getJdbcSessionContext()
+					.getServiceRegistry().getService( JdbcEnvironment.class )
+					.getExtractedDatabaseMetaData();
 			if ( ! databaseMetaData.supportsNamedParameters() ) {
 				LOG.unsupportedNamedParameters();
 			}
 			parameterStrategy = ParameterStrategy.NAMED;
 		}
 	}
 
 	@Override
 	public ParameterRegistrationImplementor getParameterRegistration(int position) {
 		if ( parameterStrategy != ParameterStrategy.POSITIONAL ) {
 			throw new ParameterStrategyException(
 					"Attempt to access positional parameter [" + position + "] but ProcedureCall using named parameters"
 			);
 		}
 		for ( ParameterRegistrationImplementor parameter : registeredParameters ) {
 			if ( position == parameter.getPosition() ) {
 				return parameter;
 			}
 		}
 		throw new NoSuchParameterException( "Could not locate parameter registered using that position [" + position + "]" );
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <T> ParameterRegistration<T> registerParameter(String name, Class<T> type, ParameterMode mode) {
 		final NamedParameterRegistration parameterRegistration = new NamedParameterRegistration( this, name, mode, type );
 		registerParameter( parameterRegistration );
 		return parameterRegistration;
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public ProcedureCall registerParameter0(String name, Class type, ParameterMode mode) {
 		registerParameter( name, type, mode );
 		return this;
 	}
 
 	@Override
 	public ParameterRegistrationImplementor getParameterRegistration(String name) {
 		if ( parameterStrategy != ParameterStrategy.NAMED ) {
 			throw new ParameterStrategyException( "Names were not used to register parameters with this stored procedure call" );
 		}
 		for ( ParameterRegistrationImplementor parameter : registeredParameters ) {
 			if ( name.equals( parameter.getName() ) ) {
 				return parameter;
 			}
 		}
 		throw new NoSuchParameterException( "Could not locate parameter registered under that name [" + name + "]" );
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public List<ParameterRegistration> getRegisteredParameters() {
 		return new ArrayList<ParameterRegistration>( registeredParameters );
 	}
 
 	@Override
 	public ProcedureOutputs getOutputs() {
 		if ( outputs == null ) {
 			outputs = buildOutputs();
 		}
 
 		return outputs;
 	}
 
 	private ProcedureOutputsImpl buildOutputs() {
 		// todo : going to need a very specialized Loader for this.
 		// or, might be a good time to look at splitting Loader up into:
 		//		1) building statement objects
 		//		2) executing statement objects
 		//		3) processing result sets
 
 		// for now assume there are no resultClasses nor mappings defined..
 		// 	TOTAL PROOF-OF-CONCEPT!!!!!!
 
 		// todo : how to identify calls which should be in the form `{? = call procName...}` ??? (note leading param marker)
 		// 		more than likely this will need to be a method on the native API.  I can see this as a trigger to
 		//		both: (1) add the `? = ` part and also (2) register a REFCURSOR parameter for DBs (Oracle, PGSQL) that
 		//		need it.
 
 		final String call = session().getFactory().getDialect().getCallableStatementSupport().renderCallableStatement(
 				procedureName,
 				parameterStrategy,
 				registeredParameters,
 				session()
 		);
 
 		try {
-			final CallableStatement statement = (CallableStatement) getSession().getTransactionCoordinator()
+			final CallableStatement statement = (CallableStatement) getSession()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( call, true );
 
 
 			// prepare parameters
 			int i = 1;
 
 			for ( ParameterRegistrationImplementor parameter : registeredParameters ) {
 				parameter.prepare( statement, i );
 				if ( parameter.getMode() == ParameterMode.REF_CURSOR ) {
 					i++;
 				}
 				else {
 					i += parameter.getSqlTypes().length;
 				}
 			}
 
 			return new ProcedureOutputsImpl( this, statement );
 		}
 		catch (SQLException e) {
 			throw getSession().getFactory().getSQLExceptionHelper().convert(
 					e,
 					"Error preparing CallableStatement",
 					getProcedureName()
 			);
 		}
 	}
 
 	@Override
 	public Type[] getReturnTypes() throws HibernateException {
 		throw new NotYetImplementedException();
 	}
 
 	/**
 	 * Use this form instead of {@link #getSynchronizedQuerySpaces()} when you want to make sure the
 	 * underlying Set is instantiated (aka, on add)
 	 *
 	 * @return The spaces
 	 */
 	protected Set<String> synchronizedQuerySpaces() {
 		if ( synchronizedQuerySpaces == null ) {
 			synchronizedQuerySpaces = new HashSet<String>();
 		}
 		return synchronizedQuerySpaces;
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public Set<String> getSynchronizedQuerySpaces() {
 		if ( synchronizedQuerySpaces == null ) {
 			return Collections.emptySet();
 		}
 		else {
 			return Collections.unmodifiableSet( synchronizedQuerySpaces );
 		}
 	}
 
 	@Override
 	public ProcedureCallImpl addSynchronizedQuerySpace(String querySpace) {
 		synchronizedQuerySpaces().add( querySpace );
 		return this;
 	}
 
 	@Override
 	public ProcedureCallImpl addSynchronizedEntityName(String entityName) {
 		addSynchronizedQuerySpaces( getSession().getFactory().getEntityPersister( entityName ) );
 		return this;
 	}
 
 	protected void addSynchronizedQuerySpaces(EntityPersister persister) {
 		synchronizedQuerySpaces().addAll( Arrays.asList( (String[]) persister.getQuerySpaces() ) );
 	}
 
 	@Override
 	public ProcedureCallImpl addSynchronizedEntityClass(Class entityClass) {
 		addSynchronizedQuerySpaces( getSession().getFactory().getEntityPersister( entityClass.getName() ) );
 		return this;
 	}
 
 	@Override
 	public QueryParameters getQueryParameters() {
 		return buildQueryParametersObject();
 	}
 
 	@Override
 	public QueryParameters buildQueryParametersObject() {
 		final QueryParameters qp = super.buildQueryParametersObject();
 		// both of these are for documentation purposes, they are actually handled directly...
 		qp.setAutoDiscoverScalarTypes( true );
 		qp.setCallable( true );
 		return qp;
 	}
 
 	/**
 	 * Collects any parameter registrations which indicate a REF_CURSOR parameter type/mode.
 	 *
 	 * @return The collected REF_CURSOR type parameters.
 	 */
 	public ParameterRegistrationImplementor[] collectRefCursorParameters() {
 		final List<ParameterRegistrationImplementor> refCursorParams = new ArrayList<ParameterRegistrationImplementor>();
 		for ( ParameterRegistrationImplementor param : registeredParameters ) {
 			if ( param.getMode() == ParameterMode.REF_CURSOR ) {
 				refCursorParams.add( param );
 			}
 		}
 		return refCursorParams.toArray( new ParameterRegistrationImplementor[refCursorParams.size()] );
 	}
 
 	@Override
 	public ProcedureCallMemento extractMemento(Map<String, Object> hints) {
 		return new ProcedureCallMementoImpl(
 				procedureName,
 				Util.copy( queryReturns ),
 				parameterStrategy,
 				toParameterMementos( registeredParameters ),
 				Util.copy( synchronizedQuerySpaces ),
 				Util.copy( hints )
 		);
 	}
 
 
 	private static List<ProcedureCallMementoImpl.ParameterMemento> toParameterMementos(List<ParameterRegistrationImplementor<?>> registeredParameters) {
 		if ( registeredParameters == null ) {
 			return null;
 		}
 
 		final List<ProcedureCallMementoImpl.ParameterMemento> copy = CollectionHelper.arrayList( registeredParameters.size() );
 		for ( ParameterRegistrationImplementor registration : registeredParameters ) {
 			copy.add( ProcedureCallMementoImpl.ParameterMemento.fromRegistration( registration ) );
 		}
 		return copy;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/proxy/AbstractLazyInitializer.java b/hibernate-core/src/main/java/org/hibernate/proxy/AbstractLazyInitializer.java
index e79b802165..3fe67b0cf8 100755
--- a/hibernate-core/src/main/java/org/hibernate/proxy/AbstractLazyInitializer.java
+++ b/hibernate-core/src/main/java/org/hibernate/proxy/AbstractLazyInitializer.java
@@ -1,409 +1,406 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.proxy;
 
 import java.io.Serializable;
 import javax.naming.NamingException;
 
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LazyInitializationException;
 import org.hibernate.Session;
 import org.hibernate.SessionException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.SessionFactoryRegistry;
 import org.hibernate.persister.entity.EntityPersister;
 
 import org.jboss.logging.Logger;
 
 /**
  * Convenience base class for lazy initialization handlers.  Centralizes the basic plumbing of doing lazy
  * initialization freeing subclasses to acts as essentially adapters to their intended entity mode and/or
  * proxy generation strategy.
  *
  * @author Gavin King
  */
 public abstract class AbstractLazyInitializer implements LazyInitializer {
 	private static final Logger log = Logger.getLogger( AbstractLazyInitializer.class );
 
 	private String entityName;
 	private Serializable id;
 	private Object target;
 	private boolean initialized;
 	private boolean readOnly;
 	private boolean unwrap;
 	private transient SessionImplementor session;
 	private Boolean readOnlyBeforeAttachedToSession;
 
 	private String sessionFactoryUuid;
 	private boolean allowLoadOutsideTransaction;
 
 	/**
 	 * For serialization from the non-pojo initializers (HHH-3309)
 	 */
 	protected AbstractLazyInitializer() {
 	}
 
 	/**
 	 * Main constructor.
 	 *
 	 * @param entityName The name of the entity being proxied.
 	 * @param id The identifier of the entity being proxied.
 	 * @param session The session owning the proxy.
 	 */
 	protected AbstractLazyInitializer(String entityName, Serializable id, SessionImplementor session) {
 		this.entityName = entityName;
 		this.id = id;
 		// initialize other fields depending on session state
 		if ( session == null ) {
 			unsetSession();
 		}
 		else {
 			setSession( session );
 		}
 	}
 
 	@Override
 	public final String getEntityName() {
 		return entityName;
 	}
 
 	@Override
 	public final Serializable getIdentifier() {
 		return id;
 	}
 
 	@Override
 	public final void setIdentifier(Serializable id) {
 		this.id = id;
 	}
 
 	@Override
 	public final boolean isUninitialized() {
 		return !initialized;
 	}
 
 	@Override
 	public final SessionImplementor getSession() {
 		return session;
 	}
 
 	@Override
 	public final void setSession(SessionImplementor s) throws HibernateException {
 		if ( s != session ) {
 			// check for s == null first, since it is least expensive
 			if ( s == null ) {
 				unsetSession();
 			}
 			else if ( isConnectedToSession() ) {
 				//TODO: perhaps this should be some other RuntimeException...
 				throw new HibernateException( "illegally attempted to associate a proxy with two open Sessions" );
 			}
 			else {
 				// s != null
 				session = s;
 				if ( readOnlyBeforeAttachedToSession == null ) {
 					// use the default read-only/modifiable setting
 					final EntityPersister persister = s.getFactory().getEntityPersister( entityName );
 					setReadOnly( s.getPersistenceContext().isDefaultReadOnly() || !persister.isMutable() );
 				}
 				else {
 					// use the read-only/modifiable setting indicated during deserialization
 					setReadOnly( readOnlyBeforeAttachedToSession );
 					readOnlyBeforeAttachedToSession = null;
 				}
 			}
 		}
 	}
 
 	private static EntityKey generateEntityKeyOrNull(Serializable id, SessionImplementor s, String entityName) {
 		if ( id == null || s == null || entityName == null ) {
 			return null;
 		}
 		return s.generateEntityKey( id, s.getFactory().getEntityPersister( entityName ) );
 	}
 
 	@Override
 	public final void unsetSession() {
 		prepareForPossibleLoadingOutsideTransaction();
 		session = null;
 		readOnly = false;
 		readOnlyBeforeAttachedToSession = null;
 	}
 
 	@Override
 	public final void initialize() throws HibernateException {
 		if ( !initialized ) {
 			if ( allowLoadOutsideTransaction ) {
 				permissiveInitialization();
 			}
 			else if ( session == null ) {
 				throw new LazyInitializationException( "could not initialize proxy - no Session" );
 			}
 			else if ( !session.isOpen() ) {
 				throw new LazyInitializationException( "could not initialize proxy - the owning Session was closed" );
 			}
 			else if ( !session.isConnected() ) {
 				throw new LazyInitializationException( "could not initialize proxy - the owning Session is disconnected" );
 			}
 			else {
 				target = session.immediateLoad( entityName, id );
 				initialized = true;
 				checkTargetState();
 			}
 		}
 		else {
 			checkTargetState();
 		}
 	}
 
 	protected void permissiveInitialization() {
 		if ( session == null ) {
 			//we have a detached collection thats set to null, reattach
 			if ( sessionFactoryUuid == null ) {
 				throw new LazyInitializationException( "could not initialize proxy - no Session" );
 			}
 			try {
 				SessionFactoryImplementor sf = (SessionFactoryImplementor)
 						SessionFactoryRegistry.INSTANCE.getSessionFactory( sessionFactoryUuid );
 				SessionImplementor session = (SessionImplementor) sf.openSession();
 				session.getPersistenceContext().setDefaultReadOnly( true );
 				session.setFlushMode( FlushMode.MANUAL );
 
-				boolean isJTA = session.getTransactionCoordinator()
-						.getTransactionContext().getTransactionEnvironment()
-						.getTransactionFactory()
-						.compatibleWithJtaSynchronization();
-				
+				boolean isJTA = session.getTransactionCoordinator().getTransactionCoordinatorBuilder().isJta();
+
 				if ( !isJTA ) {
 					// Explicitly handle the transactions only if we're not in
 					// a JTA environment.  A lazy loading temporary session can
 					// be created even if a current session and transaction are
 					// open (ex: session.clear() was used).  We must prevent
 					// multiple transactions.
 					( ( Session) session ).beginTransaction();
 				}
 
 				try {
 					target = session.immediateLoad( entityName, id );
 				}
 				finally {
 					// make sure the just opened temp session gets closed!
 					try {
 						if ( !isJTA ) {
 							( ( Session) session ).getTransaction().commit();
 						}
 						( (Session) session ).close();
 					}
 					catch (Exception e) {
 						log.warn( "Unable to close temporary session used to load lazy proxy associated to no session" );
 					}
 				}
 				initialized = true;
 				checkTargetState();
 			}
 			catch (Exception e) {
 				e.printStackTrace();
 				throw new LazyInitializationException( e.getMessage() );
 			}
 		}
 		else if ( session.isOpen() && session.isConnected() ) {
 			target = session.immediateLoad( entityName, id );
 			initialized = true;
 			checkTargetState();
 		}
 		else {
 			throw new LazyInitializationException( "could not initialize proxy - Session was closed or disced" );
 		}
 	}
 
 	protected void prepareForPossibleLoadingOutsideTransaction() {
 		if ( session != null ) {
 			allowLoadOutsideTransaction = session.getFactory().getSettings().isInitializeLazyStateOutsideTransactionsEnabled();
 
 			if ( allowLoadOutsideTransaction && sessionFactoryUuid == null ) {
 				try {
 					sessionFactoryUuid = (String) session.getFactory().getReference().get( "uuid" ).getContent();
 				}
 				catch (NamingException e) {
 					//not much we can do if this fails...
 				}
 			}
 		}
 	}
 
 	private void checkTargetState() {
 		if ( !unwrap ) {
 			if ( target == null ) {
 				getSession().getFactory().getEntityNotFoundDelegate().handleEntityNotFound( entityName, id );
 			}
 		}
 	}
 
 	/**
 	 * Getter for property 'connectedToSession'.
 	 *
 	 * @return Value for property 'connectedToSession'.
 	 */
 	protected final boolean isConnectedToSession() {
 		return getProxyOrNull() != null;
 	}
 
 	private Object getProxyOrNull() {
 		final EntityKey entityKey = generateEntityKeyOrNull( getIdentifier(), session, getEntityName() );
 		if ( entityKey != null && session != null && session.isOpen() ) {
 			return session.getPersistenceContext().getProxy( entityKey );
 		}
 		return null;
 	}
 
 	@Override
 	public final Object getImplementation() {
 		initialize();
 		return target;
 	}
 
 	@Override
 	public final void setImplementation(Object target) {
 		this.target = target;
 		initialized = true;
 	}
 
 	@Override
 	public final Object getImplementation(SessionImplementor s) throws HibernateException {
 		final EntityKey entityKey = generateEntityKeyOrNull( getIdentifier(), s, getEntityName() );
 		return (entityKey == null ? null : s.getPersistenceContext().getEntity( entityKey ));
 	}
 
 	/**
 	 * Getter for property 'target'.
 	 * <p/>
 	 * Same as {@link #getImplementation()} except that this method will not force initialization.
 	 *
 	 * @return Value for property 'target'.
 	 */
 	protected final Object getTarget() {
 		return target;
 	}
 
 	@Override
 	public final boolean isReadOnlySettingAvailable() {
 		return (session != null && !session.isClosed());
 	}
 
 	private void errorIfReadOnlySettingNotAvailable() {
 		if ( session == null ) {
 			throw new TransientObjectException(
 					"Proxy is detached (i.e, session is null). The read-only/modifiable setting is only accessible when the proxy is associated with an open session."
 			);
 		}
 		if ( session.isClosed() ) {
 			throw new SessionException(
 					"Session is closed. The read-only/modifiable setting is only accessible when the proxy is associated with an open session."
 			);
 		}
 	}
 
 	@Override
 	public final boolean isReadOnly() {
 		errorIfReadOnlySettingNotAvailable();
 		return readOnly;
 	}
 
 	@Override
 	public final void setReadOnly(boolean readOnly) {
 		errorIfReadOnlySettingNotAvailable();
 		// only update if readOnly is different from current setting
 		if ( this.readOnly != readOnly ) {
 			final EntityPersister persister = session.getFactory().getEntityPersister( entityName );
 			if ( !persister.isMutable() && !readOnly ) {
 				throw new IllegalStateException( "cannot make proxies for immutable entities modifiable" );
 			}
 			this.readOnly = readOnly;
 			if ( initialized ) {
 				EntityKey key = generateEntityKeyOrNull( getIdentifier(), session, getEntityName() );
 				if ( key != null && session.getPersistenceContext().containsEntity( key ) ) {
 					session.getPersistenceContext().setReadOnly( target, readOnly );
 				}
 			}
 		}
 	}
 
 	/**
 	 * Get the read-only/modifiable setting that should be put in affect when it is
 	 * attached to a session.
 	 * <p/>
 	 * This method should only be called during serialization when read-only/modifiable setting
 	 * is not available (i.e., isReadOnlySettingAvailable() == false)
 	 *
 	 * @return null, if the default setting should be used;
 	 *         true, for read-only;
 	 *         false, for modifiable
 	 *
 	 * @throws IllegalStateException if isReadOnlySettingAvailable() == true
 	 */
 	protected final Boolean isReadOnlyBeforeAttachedToSession() {
 		if ( isReadOnlySettingAvailable() ) {
 			throw new IllegalStateException(
 					"Cannot call isReadOnlyBeforeAttachedToSession when isReadOnlySettingAvailable == true"
 			);
 		}
 		return readOnlyBeforeAttachedToSession;
 	}
 
 	/**
 	 * Set the read-only/modifiable setting that should be put in affect when it is
 	 * attached to a session.
 	 * <p/>
 	 * This method should only be called during deserialization, before associating
 	 * the proxy with a session.
 	 *
 	 * @param readOnlyBeforeAttachedToSession, the read-only/modifiable setting to use when
 	 * associated with a session; null indicates that the default should be used.
 	 *
 	 * @throws IllegalStateException if isReadOnlySettingAvailable() == true
 	 */
 	/* package-private */
 	final void setReadOnlyBeforeAttachedToSession(Boolean readOnlyBeforeAttachedToSession) {
 		if ( isReadOnlySettingAvailable() ) {
 			throw new IllegalStateException(
 					"Cannot call setReadOnlyBeforeAttachedToSession when isReadOnlySettingAvailable == true"
 			);
 		}
 		this.readOnlyBeforeAttachedToSession = readOnlyBeforeAttachedToSession;
 	}
 
 	@Override
 	public boolean isUnwrap() {
 		return unwrap;
 	}
 
 	@Override
 	public void setUnwrap(boolean unwrap) {
 		this.unwrap = unwrap;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/jdbc/LogicalConnection.java b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/LogicalConnection.java
new file mode 100644
index 0000000000..a9d8f10185
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/LogicalConnection.java
@@ -0,0 +1,66 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.jdbc;
+
+import java.sql.Connection;
+
+/**
+ * Models the logical notion of a JDBC Connection.  We may release/re-acquire physical JDBC connections under the
+ * covers, but this logically represents the overall access to the JDBC Connection.
+ *
+ * @author Steve Ebersole
+ */
+public interface LogicalConnection {
+	/**
+	 * Is this (logical) JDBC Connection still open/active.  In other words, has {@link #close} not been called yet?
+	 *
+	 * @return {@code true} if still open ({@link #close} has not been called yet); {@code false} if not open
+	 * (({@link #close} has been called).
+	 */
+	public boolean isOpen();
+
+	/**
+	 * Closes the JdbcSession, making it inactive and forcing release of any held resources
+	 *
+	 * @return Legacy :(  Returns the JDBC Connection *if* the user passed in a Connection originally.
+	 */
+	public Connection close();
+
+	/**
+	 * Is this JdbcSession currently physically connected (meaning does it currently hold a JDBC Connection)?
+	 *
+	 * @return {@code true} if the JdbcSession currently hold a JDBC Connection; {@code false} if it does not.
+	 */
+	public boolean isPhysicallyConnected();
+
+	/**
+	 * Provides access to the registry of JDBC resources associated with this LogicalConnection.
+	 *
+	 * @return The JDBC resource registry.
+	 *
+	 * @throws org.hibernate.ResourceClosedException if the LogicalConnection is closed
+	 */
+	public ResourceRegistry getResourceRegistry();
+
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/jdbc/ResourceRegistry.java b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/ResourceRegistry.java
new file mode 100644
index 0000000000..1c12a68d6e
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/ResourceRegistry.java
@@ -0,0 +1,94 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.jdbc;
+
+import java.sql.Blob;
+import java.sql.Clob;
+import java.sql.NClob;
+import java.sql.ResultSet;
+import java.sql.Statement;
+
+/**
+ * A registry for tracking JDBC resources
+ *
+ * @author Steve Ebersole
+ */
+public interface ResourceRegistry {
+	/**
+	 * Does this registry currently have any registered resources?
+	 *
+	 * @return True if the registry does have registered resources; false otherwise.
+	 */
+	public boolean hasRegisteredResources();
+
+	public void releaseResources();
+
+	/**
+	 * Register a JDBC statement.
+	 *
+	 * @param statement The statement to register.
+	 * @param cancelable Is the statement being registered capable of being cancelled?  In other words,
+	 * should we register it to be the target of subsequent {@link #cancelLastQuery()} calls?
+	 */
+	public void register(Statement statement, boolean cancelable);
+
+	/**
+	 * Release a previously registered statement.
+	 *
+	 * @param statement The statement to release.
+	 */
+	public void release(Statement statement);
+
+	/**
+	 * Register a JDBC result set.
+	 * <p/>
+	 * Implementation note: Second parameter has been introduced to prevent
+	 * multiple registrations of the same statement in case {@link java.sql.ResultSet#getStatement()}
+	 * does not return original {@link java.sql.Statement} object.
+	 *
+	 * @param resultSet The result set to register.
+	 * @param statement Statement from which {@link java.sql.ResultSet} has been generated.
+	 */
+	public void register(ResultSet resultSet, Statement statement);
+
+	/**
+	 * Release a previously registered result set.
+	 *
+	 * @param resultSet The result set to release.
+	 * @param statement Statement from which {@link java.sql.ResultSet} has been generated.
+	 */
+	public void release(ResultSet resultSet, Statement statement);
+
+	public void register(Blob blob);
+	public void release(Blob blob);
+
+	public void register(Clob clob);
+	public void release(Clob clob);
+
+	public void register(NClob nclob);
+	public void release(NClob nclob);
+
+	public void cancelLastQuery();
+
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/jdbc/internal/AbstractLogicalConnectionImplementor.java b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/internal/AbstractLogicalConnectionImplementor.java
new file mode 100644
index 0000000000..62c4e91d51
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/internal/AbstractLogicalConnectionImplementor.java
@@ -0,0 +1,134 @@
+package org.hibernate.resource.jdbc.internal;
+
+import java.sql.Connection;
+import java.sql.SQLException;
+
+import org.hibernate.ResourceClosedException;
+import org.hibernate.TransactionException;
+import org.hibernate.resource.jdbc.ResourceRegistry;
+import org.hibernate.resource.jdbc.spi.LogicalConnectionImplementor;
+import org.hibernate.resource.jdbc.spi.PhysicalJdbcTransaction;
+import org.hibernate.resource.transaction.spi.TransactionStatus;
+
+import org.jboss.logging.Logger;
+
+/**
+ * @author Steve Ebersole
+ */
+public abstract class AbstractLogicalConnectionImplementor implements LogicalConnectionImplementor, PhysicalJdbcTransaction {
+	private static final Logger log = Logger.getLogger( AbstractLogicalConnectionImplementor.class );
+
+	private TransactionStatus status = TransactionStatus.NOT_ACTIVE;
+	protected ResourceRegistry resourceRegistry;
+
+	@Override
+	public PhysicalJdbcTransaction getPhysicalJdbcTransaction() {
+		errorIfClosed();
+		return this;
+	}
+
+	protected void errorIfClosed() {
+		if ( !isOpen() ) {
+			throw new ResourceClosedException( this.toString() + " is closed" );
+		}
+	}
+
+	@Override
+	public ResourceRegistry getResourceRegistry() {
+		return resourceRegistry;
+	}
+
+	@Override
+	public void afterStatement() {
+		log.trace( "LogicalConnection#afterStatement" );
+	}
+
+	@Override
+	public void afterTransaction() {
+		log.trace( "LogicalConnection#afterTransaction" );
+
+		resourceRegistry.releaseResources();
+	}
+
+	// PhysicalJdbcTransaction impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+	protected abstract Connection getConnectionForTransactionManagement();
+
+	@Override
+	public void begin() {
+		try {
+			log.trace( "Preparing to begin transaction via JDBC Connection.setAutoCommit(false)" );
+			getConnectionForTransactionManagement().setAutoCommit( false );
+			status = TransactionStatus.ACTIVE;
+			log.trace( "Transaction begun via JDBC Connection.setAutoCommit(false)" );
+		}
+		catch( SQLException e ) {
+			throw new TransactionException( "JDBC begin transaction failed: ", e );
+		}
+	}
+
+	@Override
+	public void commit() {
+		try {
+			log.trace( "Preparing to commit transaction via JDBC Connection.commit()" );
+			getConnectionForTransactionManagement().commit();
+			status = TransactionStatus.COMMITTED;
+			log.trace( "Transaction committed via JDBC Connection.commit()" );
+		}
+		catch( SQLException e ) {
+			status = TransactionStatus.FAILED_COMMIT;
+			throw new TransactionException( "Unable to commit against JDBC Connection", e );
+		}
+
+		afterCompletion();
+	}
+
+	protected void afterCompletion() {
+		// by default, nothing to do
+	}
+
+	protected void resetConnection(boolean initiallyAutoCommit) {
+		try {
+			if ( initiallyAutoCommit ) {
+				log.trace( "re-enabling auto-commit on JDBC Connection after completion of JDBC-based transaction" );
+				getConnectionForTransactionManagement().setAutoCommit( true );
+				status = TransactionStatus.NOT_ACTIVE;
+			}
+		}
+		catch ( Exception e ) {
+			log.debug(
+					"Could not re-enable auto-commit on JDBC Connection after completion of JDBC-based transaction : " + e
+			);
+		}
+	}
+
+	@Override
+	public void rollback() {
+		try {
+			log.trace( "Preparing to rollback transaction via JDBC Connection.rollback()" );
+			getConnectionForTransactionManagement().rollback();
+			status = TransactionStatus.ROLLED_BACK;
+			log.trace( "Transaction rolled-back via JDBC Connection.rollback()" );
+		}
+		catch( SQLException e ) {
+			throw new TransactionException( "Unable to rollback against JDBC Connection", e );
+		}
+
+		afterCompletion();
+	}
+
+	protected static boolean determineInitialAutoCommitMode(Connection providedConnection) {
+		try {
+			return providedConnection.getAutoCommit();
+		}
+		catch (SQLException e) {
+			log.debug( "Unable to ascertain initial auto-commit state of provided connection; assuming auto-commit" );
+			return true;
+		}
+	}
+
+	@Override
+	public TransactionStatus getStatus(){
+		return status;
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/jdbc/internal/LogicalConnectionManagedImpl.java b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/internal/LogicalConnectionManagedImpl.java
new file mode 100644
index 0000000000..4a2b0bef31
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/internal/LogicalConnectionManagedImpl.java
@@ -0,0 +1,241 @@
+package org.hibernate.resource.jdbc.internal;
+
+import java.io.IOException;
+import java.io.ObjectInputStream;
+import java.io.ObjectOutputStream;
+import java.sql.Connection;
+import java.sql.SQLException;
+
+import org.jboss.logging.Logger;
+
+import org.hibernate.ConnectionReleaseMode;
+import org.hibernate.ResourceClosedException;
+import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
+import org.hibernate.engine.jdbc.spi.JdbcServices;
+import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
+import org.hibernate.resource.jdbc.ResourceRegistry;
+import org.hibernate.resource.jdbc.spi.JdbcObserver;
+import org.hibernate.resource.jdbc.spi.JdbcSessionContext;
+import org.hibernate.resource.jdbc.spi.LogicalConnectionImplementor;
+
+/**
+ * Represents a LogicalConnection where we manage obtaining and releasing the Connection as needed.
+ *
+ * @author Steve Ebersole
+ */
+public class LogicalConnectionManagedImpl extends AbstractLogicalConnectionImplementor {
+	private static final Logger log = Logger.getLogger( LogicalConnectionManagedImpl.class );
+
+	private final transient JdbcConnectionAccess jdbcConnectionAccess;
+	private final transient JdbcObserver observer;
+	private final transient SqlExceptionHelper sqlExceptionHelper;
+	private final transient ConnectionReleaseMode connectionReleaseMode;
+
+	private transient Connection physicalConnection;
+	private boolean closed;
+
+	public LogicalConnectionManagedImpl(
+			JdbcConnectionAccess jdbcConnectionAccess,
+			JdbcSessionContext jdbcSessionContext) {
+		this( jdbcConnectionAccess, jdbcSessionContext, new ResourceRegistryStandardImpl() );
+	}
+
+	public LogicalConnectionManagedImpl(
+			JdbcConnectionAccess jdbcConnectionAccess,
+			JdbcSessionContext jdbcSessionContext,
+			ResourceRegistry resourceRegistry) {
+		this.jdbcConnectionAccess = jdbcConnectionAccess;
+		this.observer = jdbcSessionContext.getObserver();
+
+		this.sqlExceptionHelper = jdbcSessionContext.getServiceRegistry()
+				.getService( JdbcServices.class )
+				.getSqlExceptionHelper();
+		this.connectionReleaseMode = jdbcSessionContext.getConnectionReleaseMode();
+		this.resourceRegistry = resourceRegistry;
+
+		if ( jdbcSessionContext.getConnectionAcquisitionMode() == JdbcSessionContext.ConnectionAcquisitionMode.IMMEDIATELY ) {
+			if ( jdbcSessionContext.getConnectionReleaseMode() != ConnectionReleaseMode.ON_CLOSE ) {
+				throw new IllegalStateException(
+						"Illegal combination of ConnectionAcquisitionMode#IMMEDIATELY with !ConnectionReleaseMode.ON_CLOSE"
+				);
+			}
+			acquireConnectionIfNeeded();
+		}
+	}
+
+	private LogicalConnectionManagedImpl(
+			JdbcConnectionAccess jdbcConnectionAccess,
+			JdbcSessionContext jdbcSessionContext,
+			boolean closed) {
+		this( jdbcConnectionAccess, jdbcSessionContext, new ResourceRegistryStandardImpl() );
+		this.closed = closed;
+	}
+
+
+	private Connection acquireConnectionIfNeeded() {
+		if ( physicalConnection == null ) {
+			// todo : is this the right place for these observer calls?
+			observer.jdbcConnectionAcquisitionStart();
+			try {
+				physicalConnection = jdbcConnectionAccess.obtainConnection();
+			}
+			catch (SQLException e) {
+				throw sqlExceptionHelper.convert( e, "Unable to acquire JDBC Connection" );
+			}
+			finally {
+				observer.jdbcConnectionAcquisitionEnd( physicalConnection );
+			}
+		}
+		return physicalConnection;
+	}
+
+	@Override
+	public boolean isOpen() {
+		return !closed;
+	}
+
+	@Override
+	public boolean isPhysicallyConnected() {
+		return physicalConnection != null;
+	}
+
+	@Override
+	public Connection getPhysicalConnection() {
+		errorIfClosed();
+		return acquireConnectionIfNeeded();
+	}
+
+	@Override
+	public void afterStatement() {
+		super.afterStatement();
+
+		if ( connectionReleaseMode == ConnectionReleaseMode.AFTER_STATEMENT ) {
+			if ( getResourceRegistry().hasRegisteredResources() ) {
+				log.debug( "Skipping aggressive release of JDBC Connection after-statement due to held resources" );
+			}
+			else {
+				log.debug( "Initiating JDBC connection release from afterStatement" );
+				releaseConnection();
+			}
+		}
+	}
+
+	@Override
+	public void afterTransaction() {
+		super.afterTransaction();
+
+		if ( connectionReleaseMode != ConnectionReleaseMode.ON_CLOSE ) {
+			// NOTE : we check for !ON_CLOSE here (rather than AFTER_TRANSACTION) to also catch AFTER_STATEMENT cases
+			// that were circumvented due to held resources
+			log.debug( "Initiating JDBC connection release from afterTransaction" );
+			releaseConnection();
+		}
+	}
+
+	@Override
+	public Connection manualDisconnect() {
+		if ( closed ) {
+			throw new ResourceClosedException( "Logical connection is closed" );
+		}
+		final Connection c = physicalConnection;
+		releaseConnection();
+		return c;
+	}
+
+	@Override
+	public void manualReconnect(Connection suppliedConnection) {
+		if ( closed ) {
+			throw new ResourceClosedException( "Logical connection is closed" );
+		}
+
+		throw new IllegalStateException( "Cannot manually reconnect unless Connection was originally supplied by user" );
+	}
+
+	private void releaseConnection() {
+		if ( physicalConnection == null ) {
+			return;
+		}
+
+		// todo : is this the right place for these observer calls?
+		observer.jdbcConnectionReleaseStart();
+		try {
+			if ( !physicalConnection.isClosed() ) {
+				sqlExceptionHelper.logAndClearWarnings( physicalConnection );
+			}
+			jdbcConnectionAccess.releaseConnection( physicalConnection );
+		}
+		catch (SQLException e) {
+			throw sqlExceptionHelper.convert( e, "Unable to release JDBC Connection" );
+		}
+		finally {
+			observer.jdbcConnectionReleaseEnd();
+			physicalConnection = null;
+			getResourceRegistry().releaseResources();
+		}
+	}
+
+	@Override
+	public LogicalConnectionImplementor makeShareableCopy() {
+		errorIfClosed();
+
+		// todo : implement
+		return null;
+	}
+
+	@Override
+	public void serialize(ObjectOutputStream oos) throws IOException {
+		oos.writeBoolean( closed );
+	}
+
+	public static LogicalConnectionManagedImpl deserialize(
+			ObjectInputStream ois,
+			JdbcConnectionAccess jdbcConnectionAccess,
+			JdbcSessionContext jdbcSessionContext) throws IOException, ClassNotFoundException {
+		final boolean isClosed = ois.readBoolean();
+		return new LogicalConnectionManagedImpl( jdbcConnectionAccess, jdbcSessionContext, isClosed );
+	}
+
+	@Override
+	public Connection close() {
+		if ( closed ) {
+			return null;
+		}
+
+		getResourceRegistry().releaseResources();
+
+		log.trace( "Closing logical connection" );
+		try {
+			releaseConnection();
+		}
+		finally {
+			// no matter what
+			closed = true;
+			log.trace( "Logical connection closed" );
+		}
+		return null;
+	}
+
+
+	// PhysicalJdbcTransaction impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+	@Override
+	protected Connection getConnectionForTransactionManagement() {
+		return getPhysicalConnection();
+	}
+
+	boolean initiallyAutoCommit;
+
+	@Override
+	public void begin() {
+		initiallyAutoCommit = determineInitialAutoCommitMode( getConnectionForTransactionManagement() );
+		super.begin();
+	}
+
+	@Override
+	protected void afterCompletion() {
+		afterTransaction();
+
+		resetConnection( initiallyAutoCommit );
+		initiallyAutoCommit = false;
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/jdbc/internal/LogicalConnectionProvidedImpl.java b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/internal/LogicalConnectionProvidedImpl.java
new file mode 100644
index 0000000000..32251ffda8
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/internal/LogicalConnectionProvidedImpl.java
@@ -0,0 +1,164 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.jdbc.internal;
+
+import java.io.IOException;
+import java.io.ObjectInputStream;
+import java.io.ObjectOutputStream;
+import java.sql.Connection;
+
+import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
+import org.hibernate.resource.jdbc.LogicalConnection;
+import org.hibernate.resource.jdbc.ResourceRegistry;
+import org.hibernate.resource.jdbc.spi.JdbcSessionContext;
+import org.hibernate.resource.jdbc.spi.LogicalConnectionImplementor;
+
+import org.jboss.logging.Logger;
+
+/**
+ * @author Steve Ebersole
+ */
+public class LogicalConnectionProvidedImpl extends AbstractLogicalConnectionImplementor {
+	private static final Logger log = Logger.getLogger( LogicalConnection.class );
+
+	private transient Connection providedConnection;
+	private final boolean initiallyAutoCommit;
+	private boolean closed;
+
+	public LogicalConnectionProvidedImpl(Connection providedConnection) {
+		this( providedConnection, new ResourceRegistryStandardImpl() );
+	}
+
+	public LogicalConnectionProvidedImpl(Connection providedConnection, ResourceRegistry resourceRegistry) {
+		this.resourceRegistry = resourceRegistry;
+		if ( providedConnection == null ) {
+			throw new IllegalArgumentException( "Provided Connection cannot be null" );
+		}
+
+		this.providedConnection = providedConnection;
+		this.initiallyAutoCommit = determineInitialAutoCommitMode( providedConnection );
+	}
+
+	private LogicalConnectionProvidedImpl(boolean closed, boolean initiallyAutoCommit) {
+		this.resourceRegistry = new ResourceRegistryStandardImpl();
+		this.closed = closed;
+		this.initiallyAutoCommit = initiallyAutoCommit;
+	}
+
+	@Override
+	public boolean isOpen() {
+		return !closed;
+	}
+
+	@Override
+	public Connection close() {
+		log.trace( "Closing logical connection" );
+
+		getResourceRegistry().releaseResources();
+
+		try {
+			return providedConnection;
+		}
+		finally {
+			providedConnection = null;
+			closed = true;
+			log.trace( "Logical connection closed" );
+		}
+	}
+
+	@Override
+	public boolean isPhysicallyConnected() {
+		return providedConnection != null;
+	}
+
+	@Override
+	public Connection getPhysicalConnection() {
+		errorIfClosed();
+		return providedConnection;
+	}
+
+	@Override
+	public LogicalConnectionImplementor makeShareableCopy() {
+		errorIfClosed();
+
+		return new LogicalConnectionProvidedImpl( providedConnection );
+	}
+
+	@Override
+	public void serialize(ObjectOutputStream oos) throws IOException {
+		oos.writeBoolean( closed );
+		oos.writeBoolean( initiallyAutoCommit );
+	}
+
+	public static LogicalConnectionProvidedImpl deserialize(
+			ObjectInputStream ois) throws IOException, ClassNotFoundException {
+		final boolean isClosed = ois.readBoolean();
+		final boolean initiallyAutoCommit = ois.readBoolean();
+		return new LogicalConnectionProvidedImpl( isClosed, initiallyAutoCommit );
+	}
+
+	@Override
+	public Connection manualDisconnect() {
+		errorIfClosed();
+		try {
+			resourceRegistry.releaseResources();
+			return providedConnection;
+		}
+		finally {
+			this.providedConnection = null;
+		}
+	}
+
+	@Override
+	public void manualReconnect(Connection connection) {
+		errorIfClosed();
+
+		if ( connection == null ) {
+			throw new IllegalArgumentException( "cannot reconnect using a null connection" );
+		}
+		else if ( connection == providedConnection ) {
+			// likely an unmatched reconnect call (no matching disconnect call)
+			log.debug( "reconnecting the same connection that is already connected; should this connection have been disconnected?" );
+		}
+		else if ( providedConnection != null ) {
+			throw new IllegalArgumentException(
+					"cannot reconnect to a new user-supplied connection because currently connected; must disconnect before reconnecting."
+			);
+		}
+		providedConnection = connection;
+		log.debug( "Manually reconnected logical connection" );
+	}
+
+	@Override
+	protected Connection getConnectionForTransactionManagement() {
+		return providedConnection;
+	}
+
+	@Override
+	protected void afterCompletion() {
+		afterTransaction();
+
+		resetConnection( initiallyAutoCommit );
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/jdbc/internal/ResourceRegistryStandardImpl.java b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/internal/ResourceRegistryStandardImpl.java
new file mode 100644
index 0000000000..86e0ecd4b1
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/internal/ResourceRegistryStandardImpl.java
@@ -0,0 +1,337 @@
+package org.hibernate.resource.jdbc.internal;
+
+import java.sql.Blob;
+import java.sql.Clob;
+import java.sql.NClob;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.sql.Statement;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.hibernate.HibernateException;
+import org.hibernate.JDBCException;
+import org.hibernate.internal.CoreLogging;
+import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.resource.jdbc.ResourceRegistry;
+
+/**
+ * @author Steve Ebersole
+ */
+public class ResourceRegistryStandardImpl implements ResourceRegistry {
+	private static final CoreMessageLogger log = CoreLogging.messageLogger( ResourceRegistryStandardImpl.class );
+
+	private final Map<Statement, Set<ResultSet>> xref = new HashMap<Statement, Set<ResultSet>>();
+	private final Set<ResultSet> unassociatedResultSets = new HashSet<ResultSet>();
+
+	private List<Blob> blobs;
+	private List<Clob> clobs;
+	private List<NClob> nclobs;
+
+	private Statement lastQuery;
+
+	@Override
+	public boolean hasRegisteredResources() {
+		return hasRegistered( xref )
+				|| hasRegistered( unassociatedResultSets )
+				|| hasRegistered( blobs )
+				|| hasRegistered( clobs )
+				|| hasRegistered( nclobs );
+	}
+
+	@Override
+	public void register(Statement statement, boolean cancelable) {
+		log.tracef( "Registering statement [%s]", statement );
+		if ( xref.containsKey( statement ) ) {
+			throw new HibernateException( "JDBC Statement already registered" );
+		}
+		xref.put( statement, null );
+
+		if ( cancelable ) {
+			lastQuery = statement;
+		}
+	}
+
+	@Override
+	public void release(Statement statement) {
+		log.tracev( "Releasing statement [{0}]", statement );
+
+		// Keep this at DEBUG level, rather than warn.  Numerous connection pool implementations can return a
+		// proxy/wrapper around the JDBC Statement, causing excessive logging here.  See HHH-8210.
+		if ( log.isDebugEnabled() && !xref.containsKey( statement ) ) {
+			log.unregisteredStatement();
+		}
+		else {
+			final Set<ResultSet> resultSets = xref.get( statement );
+			if ( resultSets != null ) {
+				closeAll( resultSets );
+			}
+			xref.remove( statement );
+		}
+		close( statement );
+
+		if ( lastQuery == statement ) {
+			lastQuery = null;
+		}
+	}
+
+	@Override
+	public void release(ResultSet resultSet, Statement statement) {
+		log.tracef( "Releasing result set [%s]", resultSet );
+
+		if ( statement == null ) {
+			try {
+				statement = resultSet.getStatement();
+			}
+			catch (SQLException e) {
+				throw convert( e, "unable to access Statement from ResultSet" );
+			}
+		}
+		if ( statement != null ) {
+			final Set<ResultSet> resultSets = xref.get( statement );
+			if ( resultSets == null ) {
+				log.unregisteredStatement();
+			}
+			else {
+				resultSets.remove( resultSet );
+				if ( resultSets.isEmpty() ) {
+					xref.remove( statement );
+				}
+			}
+		}
+		else {
+			final boolean removed = unassociatedResultSets.remove( resultSet );
+			if ( !removed ) {
+				log.unregisteredResultSetWithoutStatement();
+			}
+
+		}
+		close( resultSet );
+	}
+
+	protected void closeAll(Set<ResultSet> resultSets) {
+		for ( ResultSet resultSet : resultSets ) {
+			close( resultSet );
+		}
+		resultSets.clear();
+	}
+
+	@SuppressWarnings({"unchecked"})
+	public static void close(ResultSet resultSet) {
+		log.tracef( "Closing result set [%s]", resultSet );
+
+		try {
+			resultSet.close();
+		}
+		catch (SQLException e) {
+			log.debugf( "Unable to release JDBC result set [%s]", e.getMessage() );
+		}
+		catch (Exception e) {
+			// try to handle general errors more elegantly
+			log.debugf( "Unable to release JDBC result set [%s]", e.getMessage() );
+		}
+	}
+
+	@SuppressWarnings({"unchecked"})
+	public static void close(Statement statement) {
+		log.tracef( "Closing prepared statement [%s]", statement );
+
+		try {
+			// if we are unable to "clean" the prepared statement,
+			// we do not close it
+			try {
+				if ( statement.getMaxRows() != 0 ) {
+					statement.setMaxRows( 0 );
+				}
+				if ( statement.getQueryTimeout() != 0 ) {
+					statement.setQueryTimeout( 0 );
+				}
+			}
+			catch (SQLException sqle) {
+				// there was a problem "cleaning" the prepared statement
+				if ( log.isDebugEnabled() ) {
+					log.debugf( "Exception clearing maxRows/queryTimeout [%s]", sqle.getMessage() );
+				}
+				// EARLY EXIT!!!
+				return;
+			}
+			statement.close();
+		}
+		catch (SQLException e) {
+			log.debugf( "Unable to release JDBC statement [%s]", e.getMessage() );
+		}
+		catch (Exception e) {
+			// try to handle general errors more elegantly
+			log.debugf( "Unable to release JDBC statement [%s]", e.getMessage() );
+		}
+	}
+
+	@Override
+	public void register(ResultSet resultSet, Statement statement) {
+		log.tracef( "Registering result set [%s]", resultSet );
+
+		if ( statement == null ) {
+			try {
+				statement = resultSet.getStatement();
+			}
+			catch (SQLException e) {
+				throw convert( e, "unable to access Statement from ResultSet" );
+			}
+		}
+		if ( statement != null ) {
+			// Keep this at DEBUG level, rather than warn.  Numerous connection pool implementations can return a
+			// proxy/wrapper around the JDBC Statement, causing excessive logging here.  See HHH-8210.
+			if ( log.isDebugEnabled() && !xref.containsKey( statement ) ) {
+				log.debug( "ResultSet statement was not registered (on register)" );
+			}
+			Set<ResultSet> resultSets = xref.get( statement );
+			if ( resultSets == null ) {
+				resultSets = new HashSet<ResultSet>();
+				xref.put( statement, resultSets );
+			}
+			resultSets.add( resultSet );
+		}
+		else {
+			unassociatedResultSets.add( resultSet );
+		}
+	}
+
+	private JDBCException convert(SQLException e, String s) {
+		// todo : implement
+		return null;
+	}
+
+	@Override
+	public void register(Blob blob) {
+		if ( blobs == null ) {
+			blobs = new ArrayList<Blob>();
+		}
+
+		blobs.add( blob );
+	}
+
+	@Override
+	public void release(Blob blob) {
+		if ( blobs == null ) {
+			log.debug( "Request to release Blob, but appears no Blobs have ever been registered" );
+			return;
+		}
+		blobs.remove( blob );
+	}
+
+	@Override
+	public void register(Clob clob) {
+		if ( clobs == null ) {
+			clobs = new ArrayList<Clob>();
+		}
+		clobs.add( clob );
+	}
+
+	@Override
+	public void release(Clob clob) {
+		if ( clobs == null ) {
+			log.debug( "Request to release Clob, but appears no Clobs have ever been registered" );
+			return;
+		}
+		clobs.remove( clob );
+	}
+
+	@Override
+	public void register(NClob nclob) {
+		// todo : just store them in clobs?
+		if ( nclobs == null ) {
+			nclobs = new ArrayList<NClob>();
+		}
+		nclobs.add( nclob );
+	}
+
+	@Override
+	public void release(NClob nclob) {
+		// todo : just store them in clobs?
+		if ( nclobs == null ) {
+			log.debug( "Request to release NClob, but appears no NClobs have ever been registered" );
+			return;
+		}
+		nclobs.remove( nclob );
+	}
+
+	@Override
+	public void cancelLastQuery() {
+		try {
+			if ( lastQuery != null ) {
+				lastQuery.cancel();
+			}
+		}
+		catch (SQLException e) {
+			throw convert( e, "Cannot cancel query" );
+		}
+		finally {
+			lastQuery = null;
+		}
+	}
+
+	@Override
+	public void releaseResources() {
+		log.trace( "Releasing JDBC resources" );
+
+		for ( Map.Entry<Statement, Set<ResultSet>> entry : xref.entrySet() ) {
+			if ( entry.getValue() != null ) {
+				closeAll( entry.getValue() );
+			}
+			close( entry.getKey() );
+		}
+		xref.clear();
+
+		closeAll( unassociatedResultSets );
+
+		if ( blobs != null ) {
+			for ( Blob blob : blobs ) {
+				try {
+					blob.free();
+				}
+				catch (SQLException e) {
+					log.debugf( "Unable to free JDBC Blob reference [%s]", e.getMessage() );
+				}
+			}
+			blobs.clear();
+		}
+
+		if ( clobs != null ) {
+			for ( Clob clob : clobs ) {
+				try {
+					clob.free();
+				}
+				catch (SQLException e) {
+					log.debugf( "Unable to free JDBC Clob reference [%s]", e.getMessage() );
+				}
+			}
+			clobs.clear();
+		}
+
+		if ( nclobs != null ) {
+			for ( NClob nclob : nclobs ) {
+				try {
+					nclob.free();
+				}
+				catch (SQLException e) {
+					log.debugf( "Unable to free JDBC NClob reference [%s]", e.getMessage() );
+				}
+			}
+			nclobs.clear();
+		}
+
+	}
+
+	private boolean hasRegistered(Map resource) {
+		return resource != null && !resource.isEmpty();
+	}
+
+	private boolean hasRegistered(Collection resource) {
+		return resource != null && !resource.isEmpty();
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/JdbcObserver.java b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/JdbcObserver.java
new file mode 100644
index 0000000000..8ca84abaf5
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/JdbcObserver.java
@@ -0,0 +1,47 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.jdbc.spi;
+
+import java.sql.Connection;
+
+/**
+ * @author Steve Ebersole
+ */
+public interface JdbcObserver {
+	public void jdbcConnectionAcquisitionStart();
+	public void jdbcConnectionAcquisitionEnd(Connection connection);
+
+	public void jdbcConnectionReleaseStart();
+	public void jdbcConnectionReleaseEnd();
+
+	public void jdbcPrepareStatementStart();
+	public void jdbcPrepareStatementEnd();
+
+	public void jdbcExecuteStatementStart();
+	public void jdbcExecuteStatementEnd();
+
+	public void jdbcExecuteBatchStart();
+	public void jdbcExecuteBatchEnd();
+
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionEnvironment.java b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/JdbcSessionContext.java
similarity index 54%
rename from hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionEnvironment.java
rename to hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/JdbcSessionContext.java
index e3e9e19f5a..3aa2fabe22 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionEnvironment.java
+++ b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/JdbcSessionContext.java
@@ -1,71 +1,64 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.engine.transaction.spi;
+package org.hibernate.resource.jdbc.spi;
 
+import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
+import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
+import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
-import org.hibernate.stat.spi.StatisticsImplementor;
+import org.hibernate.service.ServiceRegistry;
 
 /**
- * Provides access to transactional services.
+ * Provides the JdbcSession implementation with contextual information it needs during its lifecycle.
  *
  * @author Steve Ebersole
  */
-public interface TransactionEnvironment {
-	/**
-	 * Retrieve the session factory for this environment.
-	 *
-	 * @return The session factory
-	 */
-	public SessionFactoryImplementor getSessionFactory();
+public interface JdbcSessionContext {
+	public boolean isScrollableResultSetsEnabled();
+	public boolean isGetGeneratedKeysEnabled();
+	public int getFetchSize();
 
-	/**
-	 * Retrieve the JDBC services for this environment.
-	 *
-	 * @return The JDBC services
-	 */
-	public JdbcServices getJdbcServices();
+	public ConnectionReleaseMode getConnectionReleaseMode();
+	public ConnectionAcquisitionMode getConnectionAcquisitionMode();
 
-	/**
-	 * Retrieve the JTA platform for this environment.
-	 *
-	 * @return The JTA platform
-	 */
-	public JtaPlatform getJtaPlatform();
+	public StatementInspector getStatementInspector();
 
-	/**
-	 * Retrieve the transaction factory for this environment.
-	 *
-	 * @return The transaction factory
-	 */
-	public TransactionFactory getTransactionFactory();
+	public JdbcObserver getObserver();
 
 	/**
-	 * Get access to the statistics collector
-	 *
-	 * @return The statistics collector
-	 */
-	public StatisticsImplementor getStatisticsImplementor();
+	* Retrieve the session factory for this environment.
+	*
+	* @return The session factory
+	*/
+	public SessionFactoryImplementor getSessionFactory();
+
+	public ServiceRegistry getServiceRegistry();
+
+	public static enum ConnectionAcquisitionMode {
+		IMMEDIATELY,
+		AS_NEEDED,
+		DEFAULT
+	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/JdbcSessionOwner.java b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/JdbcSessionOwner.java
new file mode 100644
index 0000000000..1af5a30120
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/JdbcSessionOwner.java
@@ -0,0 +1,62 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.jdbc.spi;
+
+import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
+import org.hibernate.resource.transaction.TransactionCoordinatorBuilder;
+
+/**
+ * @author Steve Ebersole
+ */
+public interface JdbcSessionOwner {
+	/**
+	 * Obtain the builder for TransactionCoordinator instances
+	 *
+	 * @return The TransactionCoordinatorBuilder
+	 */
+	public TransactionCoordinatorBuilder getTransactionCoordinatorBuilder();
+
+	public JdbcSessionContext getJdbcSessionContext();
+
+	public JdbcConnectionAccess getJdbcConnectionAccess();
+
+	/**
+	 * A after-begin callback from the coordinator to its owner.
+	 */
+	public void afterTransactionBegin();
+
+	/**
+	 * A before-completion callback to the owner.
+	 */
+	public void beforeTransactionCompletion();
+
+	/**
+	 * An after-completion callback to the owner.
+	 *
+	 * @param successful Was the transaction successful?
+	 */
+	public void afterTransactionCompletion(boolean successful);
+
+	public void flushBeforeTransactionCompletion();
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/LogicalConnectionImplementor.java b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/LogicalConnectionImplementor.java
similarity index 53%
rename from hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/LogicalConnectionImplementor.java
rename to hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/LogicalConnectionImplementor.java
index 6d7695503f..e83709307f 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/spi/LogicalConnectionImplementor.java
+++ b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/LogicalConnectionImplementor.java
@@ -1,112 +1,86 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.engine.jdbc.spi;
+package org.hibernate.resource.jdbc.spi;
+
+import java.io.IOException;
+import java.io.ObjectOutputStream;
 import java.sql.Connection;
 
-import org.hibernate.ConnectionReleaseMode;
-import org.hibernate.JDBCException;
+import org.hibernate.engine.jdbc.spi.ConnectionObserver;
+import org.hibernate.resource.jdbc.LogicalConnection;
 
 /**
- * The "internal" contract for LogicalConnection
- *
  * @author Steve Ebersole
- * @author Brett Meyer
  */
 public interface LogicalConnectionImplementor extends LogicalConnection {
-	/**
-	 * Obtains the JDBC services associated with this logical connection.
-	 *
-	 * @return JDBC services
-	 */
-	public JdbcServices getJdbcServices();
+	// todo : expose the Connection as below?  or accept(WorkInConnection) where WorkInConnection is given access to Connection?
+	public Connection getPhysicalConnection();
 
 	/**
-	 * Add an observer interested in notification of connection events.
-	 *
-	 * @param observer The observer.
+	 * Notification indicating a JDBC statement has been executed to trigger
+	 * {@link org.hibernate.ConnectionReleaseMode#AFTER_STATEMENT} releasing if needed
 	 */
-	public void addObserver(ConnectionObserver observer);
+	public void afterStatement();
 
 	/**
-	 * Remove an observer
-	 *
-	 * @param connectionObserver The observer to remove.
-	 */
-	public void removeObserver(ConnectionObserver connectionObserver);
-
-	/**
-	 * The release mode under which this logical connection is operating.
-	 *
-	 * @return the release mode.
+	 * Notification indicating a transaction has completed to trigger
+	 * {@link org.hibernate.ConnectionReleaseMode#AFTER_TRANSACTION} releasing if needed
 	 */
-	public ConnectionReleaseMode getConnectionReleaseMode();
+	public void afterTransaction();
 
 	/**
 	 * Manually disconnect the underlying JDBC Connection.  The assumption here
 	 * is that the manager will be reconnected at a later point in time.
 	 *
-	 * @return The connection maintained here at time of disconnect.  Null if
+	 * @return The connection maintained here at time of disconnect.  {@code null} if
 	 * there was no connection cached internally.
 	 */
 	public Connection manualDisconnect();
 
 	/**
 	 * Manually reconnect the underlying JDBC Connection.  Should be called at some point after manualDisconnect().
 	 *
 	 * @param suppliedConnection For user supplied connection strategy the user needs to hand us the connection
 	 * with which to reconnect.  It is an error to pass a connection in the other strategies.
 	 */
 	public void manualReconnect(Connection suppliedConnection);
 
 	/**
-	 * Perform an aggressive release
-	 */
-	public void aggressiveRelease();
-
-	/**
-	 * Release any held connection.
-	 *
-	 * @throws JDBCException Indicates a problem releasing the connection
-	 */
-	public void releaseConnection() throws JDBCException;
-
-	/**
-	 * Is this logical connection in auto-commit mode?
+	 * Creates a shareable copy of itself for use in "shared sessions"
 	 *
-	 * @return {@code true} if auto-commit
+	 * @return The shareable copy.
 	 */
-	public boolean isAutoCommit();
+	public LogicalConnectionImplementor makeShareableCopy();
 
-	/**
-	 * Callback to notify all registered observers of a connection being prepared.
-	 */
-	public void notifyObserversStatementPrepared();
+	public PhysicalJdbcTransaction getPhysicalJdbcTransaction();
 
 	/**
-	 * Does this logical connection wrap a user/application supplied connection?
+	 * Serialization hook
+	 *
+	 * @param oos The stream to write out state to
 	 *
-	 * @return {@code true} if the underlying connection was user supplied.
+	 * @throws java.io.IOException Problem accessing stream
 	 */
-	public boolean isUserSuppliedConnection();
+	public void serialize(ObjectOutputStream oos) throws IOException;
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/PhysicalJdbcTransaction.java b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/PhysicalJdbcTransaction.java
new file mode 100644
index 0000000000..a94e565b8c
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/PhysicalJdbcTransaction.java
@@ -0,0 +1,34 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.jdbc.spi;
+
+import org.hibernate.resource.transaction.backend.store.spi.DataStoreTransaction;
+
+/**
+ * Provides access to manage "transactionality" via the JDBC Connection
+ *
+ * @author Steve Ebersole
+ */
+public interface PhysicalJdbcTransaction extends DataStoreTransaction {
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/spi/ManagedFlushChecker.java b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/StatementInspector.java
similarity index 53%
rename from hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/spi/ManagedFlushChecker.java
rename to hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/StatementInspector.java
index 5a9fc78b0c..5fea8e3183 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/spi/ManagedFlushChecker.java
+++ b/hibernate-core/src/main/java/org/hibernate/resource/jdbc/spi/StatementInspector.java
@@ -1,47 +1,41 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.engine.transaction.synchronization.spi;
-
-import java.io.Serializable;
-
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
+package org.hibernate.resource.jdbc.spi;
 
 /**
- * A pluggable strategy for defining how the {@link javax.transaction.Synchronization} registered by Hibernate determines
- * whether to perform a managed flush.  An exceptions from either this delegate or the subsequent flush are routed
- * through the sister strategy {@link ExceptionMapper}.
+ * Contract to allow inspection (and swapping) of SQL to be prepared
  *
  * @author Steve Ebersole
  */
-public interface ManagedFlushChecker  extends Serializable {
+public interface StatementInspector {
 	/**
-	 * Check whether we should perform the managed flush
+	 * Inspect the given SQL, possibly returning a different SQL to be used instead.  Note that returning {@code null}
+	 * is interpreted as returning the same SQL as was passed.
 	 *
-	 * @param coordinator The transaction coordinator
-	 * @param jtaStatus The status of the current JTA transaction.
+	 * @param sql The SQL to inspect
 	 *
-	 * @return True to indicate to perform the managed flush; false otherwise.
+	 * @return The SQL to use; may be {@code null}
 	 */
-	public boolean shouldDoManagedFlush(TransactionCoordinator coordinator, int jtaStatus);
+	public String inspect(String sql);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/LocalSynchronizationException.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/LocalSynchronizationException.java
new file mode 100644
index 0000000000..0876f10fb9
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/LocalSynchronizationException.java
@@ -0,0 +1,37 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction;
+
+import org.hibernate.HibernateException;
+
+/**
+ * Wraps an exception thrown from a "local synchronization" (one registered in the SynchronizationRegistry).
+ *
+ * @author Steve Ebersole
+ */
+public class LocalSynchronizationException extends HibernateException {
+	public LocalSynchronizationException(String message, Throwable cause) {
+		super( message, cause );
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/NullSynchronizationException.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/NullSynchronizationException.java
new file mode 100644
index 0000000000..4d0d06058d
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/NullSynchronizationException.java
@@ -0,0 +1,41 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction;
+
+import org.hibernate.HibernateException;
+
+/**
+ * Indicates an attempt to register a null synchronization.  Basically a glorified {@link NullPointerException}
+ *
+ * @author Steve Ebersole
+ */
+public class NullSynchronizationException extends HibernateException {
+	public NullSynchronizationException() {
+		this( "Synchronization to register cannot be null" );
+	}
+
+	public NullSynchronizationException(String s) {
+		super( s );
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/spi/AfterCompletionAction.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/SynchronizationRegistry.java
similarity index 66%
rename from hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/spi/AfterCompletionAction.java
rename to hibernate-core/src/main/java/org/hibernate/resource/transaction/SynchronizationRegistry.java
index c4e0298451..ac5edd15a3 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/spi/AfterCompletionAction.java
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/SynchronizationRegistry.java
@@ -1,38 +1,43 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.engine.transaction.synchronization.spi;
+package org.hibernate.resource.transaction;
 
-
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
+import java.io.Serializable;
+import javax.transaction.Synchronization;
 
 /**
- * A pluggable strategy for defining any actions to be performed during
- * {@link javax.transaction.Synchronization#afterCompletion} processing from the the
- * {@link javax.transaction.Synchronization} registered by Hibernate with the underlying JTA platform.
+ * Manages a registry of (local) JTA {@link Synchronization} instances
  *
  * @author Steve Ebersole
  */
-public interface AfterCompletionAction {
-	public void doAction(TransactionCoordinator transactionCoordinator, int status);
+public interface SynchronizationRegistry extends Serializable {
+	/**
+	 * Register a {@link Synchronization} callback for this transaction.
+	 *
+	 * @param synchronization The synchronization callback to register.
+	 *
+	 * @throws NullSynchronizationException if the synchronization is {@code null}
+	 */
+	void registerSynchronization(Synchronization synchronization);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/TransactionCoordinator.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/TransactionCoordinator.java
new file mode 100644
index 0000000000..32f988ba72
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/TransactionCoordinator.java
@@ -0,0 +1,150 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction;
+
+import org.hibernate.engine.transaction.spi.IsolationDelegate;
+import org.hibernate.engine.transaction.spi.TransactionObserver;
+import org.hibernate.resource.transaction.spi.TransactionStatus;
+
+/**
+ * Models the coordination of all transaction related flows.
+ *
+ * @author Steve Ebersole
+ */
+public interface TransactionCoordinator {
+	/**
+	 * Indicates an explicit request to join a transaction.  This is mainly intended to handle the JPA requirement
+	 * around {@link javax.persistence.EntityManager#joinTransaction()}, and generally speaking only has an impact in
+	 * JTA environments
+	 */
+	public void explicitJoin();
+
+	/**
+	 * Determine if there is an active transaction that this coordinator is already joined to.
+	 *
+	 * @return {@code true} if there is an active transaction this coordinator is already joined to; {@code false}
+	 * otherwise.
+	 */
+	public boolean isJoined();
+
+	/**
+	 * Used by owner of the JdbcSession as a means to indicate that implicit joining should be done if needed.
+	 */
+	public void pulse();
+
+	/**
+	 * Get the delegate used by the local transaction driver to control the underlying transaction
+	 *
+	 * @return The control delegate.
+	 */
+	public LocalInflow getTransactionDriverControl();
+
+	/**
+	 * Get access to the local registry of Synchronization instances
+	 *
+	 * @return The local Synchronization registry
+	 */
+	public SynchronizationRegistry getLocalSynchronizations();
+
+	/**
+	 * Is this transaction still active?
+	 * <p/>
+	 * Answers on a best effort basis.  For example, in the case of JDBC based transactions we cannot know that a
+	 * transaction is active when it is initiated directly through the JDBC {@link java.sql.Connection}, only when
+	 * it is initiated from here.
+	 *
+	 * @return {@code true} if the transaction is still active; {@code false} otherwise.
+	 *
+	 * @throws org.hibernate.HibernateException Indicates a problem checking the transaction status.
+	 */
+	public boolean isActive();
+
+	/**
+	 * Retrieve an isolation delegate appropriate for this transaction strategy.
+	 *
+	 * @return An isolation delegate.
+	 */
+	public IsolationDelegate createIsolationDelegate();
+
+	/**
+	 * Adds an observer to the coordinator.
+	 * <p/>
+	 * observers are not to be cleared on transaction completion.
+	 *
+	 * @param observer The observer to add.
+	 */
+	public void addObserver(TransactionObserver observer);
+
+	/**
+	 * Removed an observer from the coordinator.
+	 *
+	 * @param observer The observer to remove.
+	 */
+	public void removeObserver(TransactionObserver observer);
+
+	/**
+	 *
+	 * @return
+	 */
+	public TransactionCoordinatorBuilder getTransactionCoordinatorBuilder();
+
+	public void setTimeOut(int seconds);
+
+	public int getTimeOut();
+
+	/**
+	 * Provides the means for "local transactions" (as transaction drivers) to control the
+	 * underlying "physical transaction" currently associated with the TransactionCoordinator.
+	 *
+	 * @author Steve Ebersole
+	 */
+	public interface LocalInflow {
+		/**
+		 * Begin the physical transaction
+		 */
+		public void begin();
+
+		/**
+		 * Commit the physical transaction
+		 */
+		public void commit();
+
+		/**
+		 * Rollback the physical transaction
+		 */
+		public void rollback();
+
+		public TransactionStatus getStatus();
+
+		public void markRollbackOnly();
+
+		// todo : org.hibernate.Transaction will need access to register local Synchronizations.
+		//		depending on how we integrate TransactionCoordinator/TransactionDriverControl with
+		//		org.hibernate.Transaction that might be best done by:
+		//			1) exposing registerSynchronization here (if the Transaction is just passed this)
+		//			2) using the exposed TransactionCoordinator#getLocalSynchronizations (if the Transaction is passed the TransactionCoordinator)
+		//
+		//		if
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/TransactionCoordinatorBuilder.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/TransactionCoordinatorBuilder.java
new file mode 100644
index 0000000000..133b252ee1
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/TransactionCoordinatorBuilder.java
@@ -0,0 +1,47 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction;
+
+import org.hibernate.ConnectionReleaseMode;
+import org.hibernate.resource.jdbc.spi.JdbcSessionContext;
+import org.hibernate.resource.transaction.TransactionCoordinator;
+import org.hibernate.resource.transaction.spi.TransactionCoordinatorOwner;
+import org.hibernate.service.Service;
+
+import static org.hibernate.resource.jdbc.spi.JdbcSessionContext.ConnectionAcquisitionMode;
+
+/**
+ * Builder for TransactionCoordinator instances
+ *
+ * @author Steve Ebersole
+ */
+public interface TransactionCoordinatorBuilder extends Service {
+	public TransactionCoordinator buildTransactionCoordinator(TransactionCoordinatorOwner owner);
+
+	public boolean isJta();
+
+	public ConnectionReleaseMode getDefaultConnectionReleaseMode();
+
+	public ConnectionAcquisitionMode getDefaultConnectionAcquisitionMode();
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/TransactionCoordinatorBuilderFactory.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/TransactionCoordinatorBuilderFactory.java
new file mode 100644
index 0000000000..66dfb44412
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/TransactionCoordinatorBuilderFactory.java
@@ -0,0 +1,64 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction;
+
+import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorBuilderImpl;
+import org.hibernate.resource.transaction.backend.store.internal.ResourceLocalTransactionCoordinatorBuilderImpl;
+
+/**
+ * Factory for obtaining instances of standard TransactionCoordinatorBuilder implementations
+ *
+ * @author Steve Ebersole
+ */
+public class TransactionCoordinatorBuilderFactory {
+	/**
+	 * Singleton access
+	 */
+	public static final TransactionCoordinatorBuilderFactory INSTANCE = new TransactionCoordinatorBuilderFactory();
+
+	/**
+	 * Private constructor for the factory
+	 */
+	private TransactionCoordinatorBuilderFactory() {
+	}
+
+	/**
+	 * Obtain a TransactionCoordinatorBuilder specific to resource-local environments
+	 *
+	 * @return The resource-local specific TransactionCoordinatorBuilder
+	 */
+	public TransactionCoordinatorResourceLocalBuilder forResourceLocal() {
+		return new ResourceLocalTransactionCoordinatorBuilderImpl();
+	}
+
+	/**
+	 * Obtain a TransactionCoordinatorBuilder specific to JTA environments
+	 *
+	 * @return The JTA specific TransactionCoordinatorBuilder
+	 */
+	public TransactionCoordinatorJtaBuilder forJta() {
+		return new JtaTransactionCoordinatorBuilderImpl();
+	}
+
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/TransactionCoordinatorJtaBuilder.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/TransactionCoordinatorJtaBuilder.java
new file mode 100644
index 0000000000..7e35236df1
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/TransactionCoordinatorJtaBuilder.java
@@ -0,0 +1,77 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction;
+
+import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
+
+/**
+ * A builder of TransactionCoordinator instances intended for use in JTA environments.
+ *
+ * @author Steve Ebersole
+ */
+public interface TransactionCoordinatorJtaBuilder extends TransactionCoordinatorBuilder {
+	/**
+	 * Specifies the JtaPlatform to use.
+	 *
+	 * @param jtaPlatform The JtaPlatform to use.
+	 *
+	 * @return {@code this}, for method chaining
+	 */
+	public TransactionCoordinatorJtaBuilder setJtaPlatform(JtaPlatform jtaPlatform);
+
+	/**
+	 * Should JTA transactions be automatically joined?  Or should we wait for (JPA-style) explicit joining?  The
+	 * default is to auto-join ({@code true}).
+	 *
+	 * @param autoJoinTransactions {@code true} (default) indicates that JTA transactions should be auto joined;
+	 * {@code false} indicated we should wait for an explicit join
+	 *
+	 * @return {@code this}, for method chaining
+	 */
+	public TransactionCoordinatorJtaBuilder setAutoJoinTransactions(boolean autoJoinTransactions);
+
+	/**
+	 * Should we prefer to use UserTransactions (over TransactionManager) for managing transactions (mainly for calling
+	 * begin, commit, rollback)?  We will try both, this controls which to check first.  The default is to prefer
+	 * accessing the TransactionManager
+	 *
+	 * @param preferUserTransactions {@code true} indicates to look for UserTransactions first; {@code false} (the
+	 * default) indicates to looks for the TransactionManager first,
+	 *
+	 * @return {@code this}, for method chaining
+	 */
+	public TransactionCoordinatorJtaBuilder setPreferUserTransactions(boolean preferUserTransactions);
+
+	/**
+	 * Should we track threads in order to protect against the JTA system calling us from a different thread?  This
+	 * might often be the case for JTA systems which implement timeout rollbacks from separate "reaper" threads.  The
+	 * default is to track threads.
+	 *
+	 * @param performJtaThreadTracking {@code true} (the default) indicates that the thread should be tracked;
+	 * {@code false} indicates it should not.
+	 *
+	 * @return {@code this}, for method chaining
+	 */
+	public TransactionCoordinatorJtaBuilder setPerformJtaThreadTracking(boolean performJtaThreadTracking);
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/TransactionCoordinatorResourceLocalBuilder.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/TransactionCoordinatorResourceLocalBuilder.java
new file mode 100644
index 0000000000..7d84711bed
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/TransactionCoordinatorResourceLocalBuilder.java
@@ -0,0 +1,51 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction;
+
+import org.hibernate.resource.transaction.backend.store.spi.DataStoreTransactionAccess;
+
+/**
+ * A builder of TransactionCoordinator instances intended for use in resource-local mode (non-JTA transactions local
+ * to the underlying  data store).
+ * <p/>
+ * NOTE : Ideally I'd love to specialize the {@link #buildTransactionCoordinator(org.hibernate.resource.transaction.spi.TransactionCoordinatorOwner)}
+ * method here to only accept TransactionCoordinatorOwner arguments that are specifically
+ * {@link org.hibernate.resource.transaction.backend.store.spi.DataStoreTransactionAccess} instances.  Not sure how to
+ * best achieve that.  For now we just cast and let the exception happen, but directing the user via the contract
+ * would be MUCH preferable.
+ *
+ * @author Steve Ebersole
+ */
+public interface TransactionCoordinatorResourceLocalBuilder extends TransactionCoordinatorBuilder {
+	/**
+	 * Provides the TransactionCoordinator we are building with access to the ResourceLocalTransaction used to control
+	 * transactions.
+	 * <p/>
+	 * An alternative is for the owner passed to {@link #buildTransactionCoordinator} to implement the
+	 * ResourceLocalTransactionAccess contract.
+	 *
+	 * @param dataStoreTransactionAccess Access
+	 */
+	public void setResourceLocalTransactionAccess(DataStoreTransactionAccess dataStoreTransactionAccess);
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaIsolationDelegate.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaIsolationDelegate.java
similarity index 78%
rename from hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaIsolationDelegate.java
rename to hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaIsolationDelegate.java
index 25891ec55a..8fb23efeb5 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaIsolationDelegate.java
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaIsolationDelegate.java
@@ -1,179 +1,172 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
+ * Copyright (c) {DATE}, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.engine.transaction.internal.jta;
+package org.hibernate.resource.transaction.backend.jta.internal;
 
-import java.sql.Connection;
-import java.sql.SQLException;
 import javax.transaction.NotSupportedException;
 import javax.transaction.SystemException;
 import javax.transaction.Transaction;
 import javax.transaction.TransactionManager;
+import java.sql.Connection;
+import java.sql.SQLException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.transaction.spi.IsolationDelegate;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.jdbc.WorkExecutor;
 import org.hibernate.jdbc.WorkExecutorVisitable;
 
 /**
  * An isolation delegate for JTA environments.
  *
- * @author Steve Ebersole
+ * @author Andrea Boriero
  */
 public class JtaIsolationDelegate implements IsolationDelegate {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( JtaIsolationDelegate.class );
 
-	private final TransactionCoordinator transactionCoordinator;
-
-	public JtaIsolationDelegate(TransactionCoordinator transactionCoordinator) {
-		this.transactionCoordinator = transactionCoordinator;
-	}
-
-	protected TransactionManager transactionManager() {
-		return transactionCoordinator.getTransactionContext()
-				.getTransactionEnvironment()
-				.getJtaPlatform()
-				.retrieveTransactionManager();
+	private final JdbcConnectionAccess connectionAccess;
+	private final SqlExceptionHelper sqlExceptionHelper;
+	private final TransactionManager transactionManager;
+
+	public JtaIsolationDelegate(
+			JdbcConnectionAccess connectionAccess,
+			SqlExceptionHelper sqlExceptionHelper,
+			TransactionManager transactionManager) {
+		this.connectionAccess = connectionAccess;
+		this.sqlExceptionHelper = sqlExceptionHelper;
+		this.transactionManager = transactionManager;
 	}
 
 	protected JdbcConnectionAccess jdbcConnectionAccess() {
-		return transactionCoordinator.getTransactionContext().getJdbcConnectionAccess();
+		return this.connectionAccess;
 	}
 
 	protected SqlExceptionHelper sqlExceptionHelper() {
-		return transactionCoordinator.getTransactionContext()
-				.getTransactionEnvironment()
-				.getJdbcServices()
-				.getSqlExceptionHelper();
+		return this.sqlExceptionHelper;
 	}
 
 	@Override
 	public <T> T delegateWork(WorkExecutorVisitable<T> work, boolean transacted) throws HibernateException {
-		TransactionManager transactionManager = transactionManager();
-
 		try {
 			// First we suspend any current JTA transaction
 			Transaction surroundingTransaction = transactionManager.suspend();
 			LOG.debugf( "Surrounding JTA transaction suspended [%s]", surroundingTransaction );
 
 			boolean hadProblems = false;
 			try {
 				// then perform the requested work
 				if ( transacted ) {
 					return doTheWorkInNewTransaction( work, transactionManager );
 				}
 				else {
 					return doTheWorkInNoTransaction( work );
 				}
 			}
-			catch ( HibernateException e ) {
+			catch (HibernateException e) {
 				hadProblems = true;
 				throw e;
 			}
 			finally {
 				try {
 					transactionManager.resume( surroundingTransaction );
 					LOG.debugf( "Surrounding JTA transaction resumed [%s]", surroundingTransaction );
 				}
-				catch( Throwable t ) {
+				catch (Throwable t) {
 					// if the actually work had an error use that, otherwise error based on t
 					if ( !hadProblems ) {
 						//noinspection ThrowFromFinallyBlock
 						throw new HibernateException( "Unable to resume previously suspended transaction", t );
 					}
 				}
 			}
 		}
-		catch ( SystemException e ) {
+		catch (SystemException e) {
 			throw new HibernateException( "Unable to suspend current JTA transaction", e );
 		}
 	}
 
 	private <T> T doTheWorkInNewTransaction(WorkExecutorVisitable<T> work, TransactionManager transactionManager) {
 		try {
 			// start the new isolated transaction
 			transactionManager.begin();
 
 			try {
 				T result = doTheWork( work );
 				// if everything went ok, commit the isolated transaction
 				transactionManager.commit();
 				return result;
 			}
-			catch ( Exception e ) {
+			catch (Exception e) {
 				try {
 					transactionManager.rollback();
 				}
-				catch ( Exception ignore ) {
+				catch (Exception ignore) {
 					LOG.unableToRollbackIsolatedTransaction( e, ignore );
 				}
 				throw new HibernateException( "Could not apply work", e );
 			}
 		}
-		catch ( SystemException e ) {
+		catch (SystemException e) {
 			throw new HibernateException( "Unable to start isolated transaction", e );
 		}
-		catch ( NotSupportedException e ) {
+		catch (NotSupportedException e) {
 			throw new HibernateException( "Unable to start isolated transaction", e );
 		}
 	}
 
 	private <T> T doTheWorkInNoTransaction(WorkExecutorVisitable<T> work) {
 		return doTheWork( work );
 	}
 
 	private <T> T doTheWork(WorkExecutorVisitable<T> work) {
 		try {
 			// obtain our isolated connection
 			Connection connection = jdbcConnectionAccess().obtainConnection();
 			try {
 				// do the actual work
 				return work.accept( new WorkExecutor<T>(), connection );
 			}
-			catch ( HibernateException e ) {
+			catch (HibernateException e) {
 				throw e;
 			}
-			catch ( Exception e ) {
+			catch (Exception e) {
 				throw new HibernateException( "Unable to perform isolated work", e );
 			}
 			finally {
 				try {
 					// no matter what, release the connection (handle)
 					jdbcConnectionAccess().releaseConnection( connection );
 				}
-				catch ( Throwable ignore ) {
+				catch (Throwable ignore) {
 					LOG.unableToReleaseIsolatedConnection( ignore );
 				}
 			}
 		}
-		catch ( SQLException e ) {
+		catch (SQLException e) {
 			throw sqlExceptionHelper().convert( e, "unable to obtain isolated JDBC connection" );
 		}
 	}
 }
-
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaMessageLogger.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaMessageLogger.java
new file mode 100644
index 0000000000..4f50254e7e
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaMessageLogger.java
@@ -0,0 +1,45 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction.backend.jta.internal;
+
+import org.jboss.logging.Logger;
+import org.jboss.logging.annotations.MessageLogger;
+import org.jboss.logging.annotations.ValidIdRange;
+
+/**
+ * Acts as the {@link org.jboss.logging.annotations.MessageLogger} related to
+ * JTA transaction processing
+ *
+ * @author Steve Ebersole
+ */
+@MessageLogger( projectCode = "HHH" )
+@ValidIdRange( min = 10001001, max = 10002000 )
+public interface JtaMessageLogger {
+	public static final JtaMessageLogger INSTANCE = Logger.getMessageLogger(
+			JtaMessageLogger.class,
+			"org.hibernate.orm.txn.backend.jta"
+	);
+
+
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaPlatformInaccessibleException.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaPlatformInaccessibleException.java
new file mode 100644
index 0000000000..2fb3eefd9a
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaPlatformInaccessibleException.java
@@ -0,0 +1,41 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction.backend.jta.internal;
+
+import org.hibernate.HibernateException;
+
+/**
+ * Indicates problems accessing TransactionManager or UserTransaction through the JtaPlatform
+ *
+ * @author Steve Ebersole
+ */
+public class JtaPlatformInaccessibleException extends HibernateException {
+	public JtaPlatformInaccessibleException(String message) {
+		super( message );
+	}
+
+	public JtaPlatformInaccessibleException(String message, Throwable cause) {
+		super( message, cause );
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionImplementor.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaTransactionAdapter.java
similarity index 50%
rename from hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionImplementor.java
rename to hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaTransactionAdapter.java
index 64a5397bf4..c75a7e9a6d 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/spi/TransactionImplementor.java
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaTransactionAdapter.java
@@ -1,72 +1,58 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
+ * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.engine.transaction.spi;
+package org.hibernate.resource.transaction.backend.jta.internal;
 
-import org.hibernate.Transaction;
+import org.hibernate.resource.transaction.spi.TransactionStatus;
 
 /**
- * Additional contract for implementors of the Hibernate {@link Transaction} API.
- * 
+ * Adapter for abstracting the physical means of interacting with JTA transactions.
+ * <p/>
+ * JTA transactions can concretely be interacted with through {@link javax.transaction.UserTransaction}
+ * or {@link javax.transaction.Transaction} depending on environment and situation.  This adapter hides
+ * this difference.
+ *
  * @author Steve Ebersole
  */
-public interface TransactionImplementor extends Transaction {
+public interface JtaTransactionAdapter {
 	/**
-	 * Retrieve an isolation delegate appropriate for this transaction strategy.
-	 *
-	 * @return An isolation delegate.
+	 * Call begin on the underlying transaction object
 	 */
-	public IsolationDelegate createIsolationDelegate();
+	public void begin();
 
 	/**
-	 * Get the current state of this transaction's join status.
-	 *
-	 * @return The current join status
+	 * Call commit on the underlying transaction object
 	 */
-	public JoinStatus getJoinStatus();
+	public void commit();
 
 	/**
-	 * Mark a transaction as joinable
+	 * Call rollback on the underlying transaction object
 	 */
-	public void markForJoin();
+	public void rollback();
 
-	/**
-	 * Perform a join to the underlying transaction
-	 */
-	public void join();
-
-	/**
-	 * Reset this transaction's join status.
-	 */
-	public void resetJoinStatus();
+	public TransactionStatus getStatus();
 
-	/**
-	 * Make a best effort to mark the underlying transaction for rollback only.
-	 */
 	public void markRollbackOnly();
 
-	/**
-	 * Called after completion of the underlying transaction to signify the facade is no longer valid.
-	 */
-	public void invalidate();
+	public void setTimeOut(int seconds);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaTransactionAdapterTransactionManagerImpl.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaTransactionAdapterTransactionManagerImpl.java
new file mode 100644
index 0000000000..b9e1f8f1ca
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaTransactionAdapterTransactionManagerImpl.java
@@ -0,0 +1,135 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction.backend.jta.internal;
+
+import javax.transaction.Status;
+import javax.transaction.SystemException;
+import javax.transaction.TransactionManager;
+
+import org.jboss.logging.Logger;
+
+import org.hibernate.TransactionException;
+import org.hibernate.resource.transaction.spi.TransactionStatus;
+
+/**
+ * JtaTransactionAdapter for coordinating with the JTA TransactionManager
+ *
+ * @author Steve Ebersole
+ */
+public class JtaTransactionAdapterTransactionManagerImpl implements JtaTransactionAdapter {
+	private static final Logger log = Logger.getLogger( JtaTransactionAdapterTransactionManagerImpl.class );
+
+	private final TransactionManager transactionManager;
+	private final JtaTransactionCoordinatorImpl transactionCoordinator;
+
+	private boolean initiator;
+
+	public JtaTransactionAdapterTransactionManagerImpl(
+			TransactionManager transactionManager,
+			JtaTransactionCoordinatorImpl transactionCoordinator) throws SystemException {
+		this.transactionManager = transactionManager;
+		this.transactionCoordinator = transactionCoordinator;
+	}
+
+	@Override
+	public void begin() {
+		try {
+			if ( getStatus() == TransactionStatus.NOT_ACTIVE ) {
+				log.trace( "Calling TransactionManager#begin" );
+				transactionManager.begin();
+				initiator = true;
+				log.trace( "Called TransactionManager#begin" );
+			}
+			else {
+				log.trace( "Skipping TransactionManager#begin due to already active transaction" );
+			}
+		}
+		catch (Exception e) {
+			throw new TransactionException( "JTA TransactionManager#begin failed", e );
+		}
+	}
+
+	@Override
+	public void commit() {
+		try {
+			this.transactionCoordinator.getTransactionCoordinatorOwner().flushBeforeTransactionCompletion();
+
+			if ( initiator ) {
+				initiator = false;
+				log.trace( "Calling TransactionManager#commit" );
+				transactionManager.commit();
+				log.trace( "Called TransactionManager#commit" );
+			}
+			else {
+				log.trace( "Skipping TransactionManager#commit due to not being initiator" );
+			}
+		}
+		catch (Exception e) {
+			throw new TransactionException( "JTA TransactionManager#commit failed", e );
+		}
+	}
+
+	@Override
+	public void rollback() {
+		try {
+			if ( initiator ) {
+				initiator = false;
+				log.trace( "Calling TransactionManager#rollback" );
+				transactionManager.rollback();
+				log.trace( "Called TransactionManager#rollback" );
+			}
+			else {
+				markRollbackOnly();
+			}
+		}
+		catch (Exception e) {
+			throw new TransactionException( "JTA TransactionManager#rollback failed", e );
+		}
+	}
+
+	@Override
+	public TransactionStatus getStatus() {
+		try {
+			return StatusTranslator.translate( transactionManager.getStatus() );
+		}
+		catch (SystemException e) {
+			throw new TransactionException( "JTA TransactionManager#getStatus failed", e );
+		}
+	}
+
+	@Override
+	public void markRollbackOnly() {
+		try {
+			transactionManager.setRollbackOnly();
+		}
+		catch (SystemException e) {
+			throw new TransactionException( "Could not set transaction to rollback only", e );
+		}
+	}
+
+	@Override
+	public void setTimeOut(int seconds) {
+
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaTransactionAdapterUserTransactionImpl.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaTransactionAdapterUserTransactionImpl.java
new file mode 100644
index 0000000000..3cde3cab12
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaTransactionAdapterUserTransactionImpl.java
@@ -0,0 +1,143 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction.backend.jta.internal;
+
+import javax.transaction.SystemException;
+import javax.transaction.UserTransaction;
+
+import org.hibernate.TransactionException;
+import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
+import org.hibernate.resource.transaction.spi.TransactionStatus;
+
+import org.jboss.logging.Logger;
+
+/**
+ * JtaTransactionAdapter for coordinating with the JTA UserTransaction
+ *
+ * @author Steve Ebersole
+ */
+public class JtaTransactionAdapterUserTransactionImpl implements JtaTransactionAdapter {
+	private static final Logger log = Logger.getLogger( JtaTransactionAdapterUserTransactionImpl.class );
+
+	private final UserTransaction userTransaction;
+	private final JtaTransactionCoordinatorImpl transactionCoordinator;
+
+
+	private boolean initiator;
+
+	public JtaTransactionAdapterUserTransactionImpl(
+			UserTransaction userTransaction,
+			JtaTransactionCoordinatorImpl transactionCoordinator) {
+		this.userTransaction = userTransaction;
+		this.transactionCoordinator = transactionCoordinator;
+	}
+
+	@Override
+	public void begin() {
+		try {
+			if ( getStatus() == TransactionStatus.NOT_ACTIVE ) {
+				log.trace( "Calling UserTransaction#begin" );
+				userTransaction.begin();
+				initiator = true;
+				log.trace( "Called UserTransaction#begin" );
+			}
+			else {
+				log.trace( "Skipping TransactionManager#begin due to already active transaction" );
+			}
+		}
+		catch (Exception e) {
+			throw new TransactionException( "JTA UserTransaction#begin failed", e );
+		}
+	}
+
+	@Override
+	public void commit() {
+		try {
+			this.transactionCoordinator.getTransactionCoordinatorOwner().flushBeforeTransactionCompletion();
+
+			if ( initiator ) {
+				initiator = false;
+				log.trace( "Calling UserTransaction#commit" );
+				userTransaction.commit();
+				log.trace( "Called UserTransaction#commit" );
+			}
+			else {
+				log.trace( "Skipping TransactionManager#commit due to not being initiator" );
+			}
+		}
+		catch (Exception e) {
+			throw new TransactionException( "JTA UserTransaction#commit failed", e );
+		}
+	}
+
+	@Override
+	public void rollback() {
+		try {
+			if ( initiator ) {
+				initiator = false;
+				log.trace( "Calling UserTransaction#rollback" );
+				userTransaction.rollback();
+				log.trace( "Called UserTransaction#rollback" );
+			}
+			else {
+				markRollbackOnly();
+			}
+		}
+		catch (Exception e) {
+			throw new TransactionException( "JTA UserTransaction#rollback failed", e );
+		}
+	}
+
+	@Override
+	public TransactionStatus getStatus() {
+		try {
+			return StatusTranslator.translate( userTransaction.getStatus() );
+		}
+		catch (SystemException e) {
+			throw new TransactionException( "JTA TransactionManager#getStatus failed", e );
+		}
+	}
+
+	@Override
+	public void markRollbackOnly(){
+		try {
+			userTransaction.setRollbackOnly();
+		}
+		catch (SystemException e) {
+			throw new TransactionException( "Unable to mark transaction for rollback only", e );
+		}
+	}
+
+	@Override
+	public void setTimeOut(int seconds) {
+		if ( seconds > 0 ) {
+			try {
+				userTransaction.setTransactionTimeout( seconds );
+			}
+			catch (SystemException e) {
+				throw new TransactionException( "Unable to apply requested transaction timeout", e );
+			}
+		}
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaTransactionCoordinatorBuilderImpl.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaTransactionCoordinatorBuilderImpl.java
new file mode 100644
index 0000000000..abb3ce9526
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaTransactionCoordinatorBuilderImpl.java
@@ -0,0 +1,98 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction.backend.jta.internal;
+
+import org.hibernate.ConnectionReleaseMode;
+import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
+import org.hibernate.resource.jdbc.spi.JdbcSessionContext;
+import org.hibernate.resource.jdbc.spi.JdbcSessionOwner;
+import org.hibernate.resource.transaction.TransactionCoordinatorJtaBuilder;
+import org.hibernate.resource.transaction.TransactionCoordinator;
+import org.hibernate.resource.transaction.spi.TransactionCoordinatorOwner;
+
+import static org.hibernate.resource.jdbc.spi.JdbcSessionContext.*;
+
+/**
+ * Concrete builder for JTA-based TransactionCoordinator instances.
+ *
+ * @author Steve Ebersole
+ */
+public class JtaTransactionCoordinatorBuilderImpl implements TransactionCoordinatorJtaBuilder {
+	private JtaPlatform jtaPlatform;
+	private boolean autoJoinTransactions = true;
+	private boolean preferUserTransactions;
+	private boolean performJtaThreadTracking = true;
+	private JdbcSessionOwner sessionOwner;
+
+	@Override
+	public TransactionCoordinatorJtaBuilder setJtaPlatform(JtaPlatform jtaPlatform) {
+		this.jtaPlatform = jtaPlatform;
+		return this;
+	}
+
+	@Override
+	public TransactionCoordinatorJtaBuilder setAutoJoinTransactions(boolean autoJoinTransactions) {
+		this.autoJoinTransactions = autoJoinTransactions;
+		return this;
+	}
+
+	@Override
+	public TransactionCoordinatorJtaBuilder setPreferUserTransactions(boolean preferUserTransactions) {
+		this.preferUserTransactions = preferUserTransactions;
+		return this;
+	}
+
+	@Override
+	public TransactionCoordinatorJtaBuilder setPerformJtaThreadTracking(boolean performJtaThreadTracking) {
+		this.performJtaThreadTracking = performJtaThreadTracking;
+		return this;
+	}
+
+	@Override
+	public TransactionCoordinator buildTransactionCoordinator(TransactionCoordinatorOwner owner) {
+		return new JtaTransactionCoordinatorImpl(
+				this,
+				owner,
+				jtaPlatform,
+				autoJoinTransactions,
+				preferUserTransactions,
+				performJtaThreadTracking
+		);
+	}
+
+	@Override
+	public boolean isJta() {
+		return true;
+	}
+
+	@Override
+	public ConnectionReleaseMode getDefaultConnectionReleaseMode() {
+		return ConnectionReleaseMode.AFTER_STATEMENT;
+	}
+
+	@Override
+	public ConnectionAcquisitionMode getDefaultConnectionAcquisitionMode() {
+		return ConnectionAcquisitionMode.DEFAULT;
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaTransactionCoordinatorImpl.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaTransactionCoordinatorImpl.java
new file mode 100644
index 0000000000..702af8eee1
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/JtaTransactionCoordinatorImpl.java
@@ -0,0 +1,371 @@
+package org.hibernate.resource.transaction.backend.jta.internal;
+
+import javax.transaction.Status;
+import javax.transaction.TransactionManager;
+import javax.transaction.UserTransaction;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import org.jboss.logging.Logger;
+
+import org.hibernate.TransactionException;
+import org.hibernate.engine.jdbc.spi.JdbcServices;
+import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
+import org.hibernate.engine.transaction.spi.IsolationDelegate;
+import org.hibernate.engine.transaction.spi.TransactionObserver;
+import org.hibernate.resource.jdbc.spi.JdbcSessionOwner;
+import org.hibernate.resource.transaction.SynchronizationRegistry;
+import org.hibernate.resource.transaction.TransactionCoordinator;
+import org.hibernate.resource.transaction.TransactionCoordinatorBuilder;
+import org.hibernate.resource.transaction.backend.jta.internal.synchronization.RegisteredSynchronization;
+import org.hibernate.resource.transaction.backend.jta.internal.synchronization.SynchronizationCallbackCoordinator;
+import org.hibernate.resource.transaction.backend.jta.internal.synchronization.SynchronizationCallbackCoordinatorNonTrackingImpl;
+import org.hibernate.resource.transaction.backend.jta.internal.synchronization.SynchronizationCallbackCoordinatorTrackingImpl;
+import org.hibernate.resource.transaction.backend.jta.internal.synchronization.SynchronizationCallbackTarget;
+import org.hibernate.resource.transaction.internal.SynchronizationRegistryStandardImpl;
+import org.hibernate.resource.transaction.spi.TransactionCoordinatorOwner;
+import org.hibernate.resource.transaction.spi.TransactionStatus;
+
+import static org.hibernate.internal.CoreLogging.logger;
+
+/**
+ * An implementation of TransactionCoordinator based on managing a transaction through the JTA API (either TM or UT)
+ *
+ * @author Steve Ebersole
+ */
+public class JtaTransactionCoordinatorImpl implements TransactionCoordinator, SynchronizationCallbackTarget {
+	private static final Logger log = logger( JtaTransactionCoordinatorImpl.class );
+
+	private final TransactionCoordinatorBuilder transactionCoordinatorBuilder;
+	private final TransactionCoordinatorOwner transactionCoordinatorOwner;
+	private final JtaPlatform jtaPlatform;
+	private final boolean autoJoinTransactions;
+	private final boolean preferUserTransactions;
+	private final boolean performJtaThreadTracking;
+
+	private boolean synchronizationRegistered;
+	private SynchronizationCallbackCoordinator callbackCoordinator;
+	private TransactionDriverControlImpl physicalTransactionDelegate;
+
+	private final SynchronizationRegistryStandardImpl synchronizationRegistry = new SynchronizationRegistryStandardImpl();
+
+	private int timeOut = -1;
+
+	private final transient List<TransactionObserver> observers;
+
+	/**
+	 * Construct a JtaTransactionCoordinatorImpl instance.  package-protected to ensure access goes through
+	 * builder.
+	 *
+	 * @param owner The transactionCoordinatorOwner
+	 * @param jtaPlatform The JtaPlatform to use
+	 * @param autoJoinTransactions Should JTA transactions be auto-joined?  Or should we wait for explicit join calls?
+	 * @param preferUserTransactions Should we prefer using UserTransaction, as opposed to TransactionManager?
+	 * @param performJtaThreadTracking Should we perform thread tracking?
+	 */
+	JtaTransactionCoordinatorImpl(
+			TransactionCoordinatorBuilder transactionCoordinatorBuilder,
+			TransactionCoordinatorOwner owner,
+			JtaPlatform jtaPlatform,
+			boolean autoJoinTransactions,
+			boolean preferUserTransactions,
+			boolean performJtaThreadTracking) {
+		this.observers = new ArrayList<TransactionObserver>();
+		this.transactionCoordinatorBuilder = transactionCoordinatorBuilder;
+		this.transactionCoordinatorOwner = owner;
+		this.jtaPlatform = jtaPlatform;
+		this.autoJoinTransactions = autoJoinTransactions;
+		this.preferUserTransactions = preferUserTransactions;
+		this.performJtaThreadTracking = performJtaThreadTracking;
+
+		synchronizationRegistered = false;
+
+		pulse();
+	}
+
+	public SynchronizationCallbackCoordinator getSynchronizationCallbackCoordinator() {
+		if ( callbackCoordinator == null ) {
+			callbackCoordinator = performJtaThreadTracking
+					? new SynchronizationCallbackCoordinatorTrackingImpl( this )
+					: new SynchronizationCallbackCoordinatorNonTrackingImpl( this );
+		}
+		return callbackCoordinator;
+	}
+
+	@Override
+	public void pulse() {
+		if ( !autoJoinTransactions ) {
+			return;
+		}
+
+		if ( synchronizationRegistered ) {
+			return;
+		}
+
+		// Can we resister a synchronization according to the JtaPlatform?
+		if ( !jtaPlatform.canRegisterSynchronization() ) {
+			log.trace( "JTA platform says we cannot currently resister synchronization; skipping" );
+			return;
+		}
+
+		joinJtaTransaction();
+	}
+
+	/**
+	 * Join to the JTA transaction.  Note that the underlying meaning of joining in JTA environments is to register the
+	 * RegisteredSynchronization with the JTA system
+	 */
+	private void joinJtaTransaction() {
+		if ( synchronizationRegistered ) {
+			return;
+		}
+
+		jtaPlatform.registerSynchronization( new RegisteredSynchronization( getSynchronizationCallbackCoordinator() ) );
+		getSynchronizationCallbackCoordinator().synchronizationRegistered();
+		synchronizationRegistered = true;
+		log.debug( "Hibernate RegisteredSynchronization successfully registered with JTA platform" );
+	}
+
+	@Override
+	public void explicitJoin() {
+		if ( synchronizationRegistered ) {
+			log.debug( "JTA transaction was already joined (RegisteredSynchronization already registered)" );
+			return;
+		}
+
+		if ( physicalTransactionDelegate.getStatus() != TransactionStatus.ACTIVE ) {
+			return;
+		}
+
+		joinJtaTransaction();
+	}
+
+	@Override
+	public boolean isJoined() {
+		return synchronizationRegistered;
+	}
+
+	/**
+	 * Is the RegisteredSynchronization used by Hibernate for unified JTA Synchronization callbacks registered for this
+	 * coordinator?
+	 *
+	 * @return {@code true} indicates that a RegisteredSynchronization is currently registered for this coordinator;
+	 * {@code false} indicates it is not (yet) registered.
+	 */
+	public boolean isSynchronizationRegistered() {
+		return synchronizationRegistered;
+	}
+
+	public TransactionCoordinatorOwner getTransactionCoordinatorOwner(){
+		return this.transactionCoordinatorOwner;
+	}
+
+	@Override
+	public LocalInflow getTransactionDriverControl() {
+		if ( physicalTransactionDelegate == null ) {
+			physicalTransactionDelegate = makePhysicalTransactionDelegate();
+		}
+		return physicalTransactionDelegate;
+	}
+
+	private TransactionDriverControlImpl makePhysicalTransactionDelegate() {
+		JtaTransactionAdapter adapter;
+
+		if ( preferUserTransactions ) {
+			adapter = makeUserTransactionAdapter();
+
+			if ( adapter == null ) {
+				log.debug( "Unable to access UserTransaction, attempting to use TransactionManager instead" );
+				adapter = makeTransactionManagerAdapter();
+			}
+		}
+		else {
+			adapter = makeTransactionManagerAdapter();
+
+			if ( adapter == null ) {
+				log.debug( "Unable to access TransactionManager, attempting to use UserTransaction instead" );
+				adapter = makeUserTransactionAdapter();
+			}
+		}
+
+		if ( adapter == null ) {
+			throw new JtaPlatformInaccessibleException(
+					"Unable to access TransactionManager or UserTransaction to make physical transaction delegate"
+			);
+		}
+
+		return new TransactionDriverControlImpl( adapter );
+	}
+
+	private JtaTransactionAdapter makeUserTransactionAdapter() {
+		try {
+			final UserTransaction userTransaction = jtaPlatform.retrieveUserTransaction();
+			if ( userTransaction == null ) {
+				log.debug( "JtaPlatform#retrieveUserTransaction returned null" );
+			}
+			else {
+				return new JtaTransactionAdapterUserTransactionImpl( userTransaction, this );
+			}
+		}
+		catch (Exception ignore) {
+			log.debugf( "JtaPlatform#retrieveUserTransaction threw an exception [%s]", ignore.getMessage() );
+		}
+
+		return null;
+	}
+
+	private JtaTransactionAdapter makeTransactionManagerAdapter() {
+		try {
+			final TransactionManager transactionManager = jtaPlatform.retrieveTransactionManager();
+			if ( transactionManager == null ) {
+				log.debug( "JtaPlatform#retrieveTransactionManager returned null" );
+			}
+			else {
+				return new JtaTransactionAdapterTransactionManagerImpl( transactionManager, this );
+			}
+		}
+		catch (Exception ignore) {
+			log.debugf( "JtaPlatform#retrieveTransactionManager threw an exception [%s]", ignore.getMessage() );
+		}
+
+		return null;
+	}
+
+	@Override
+	public SynchronizationRegistry getLocalSynchronizations() {
+		return synchronizationRegistry;
+	}
+
+	@Override
+	public boolean isActive() {
+		return getTransactionDriverControl().getStatus() == TransactionStatus.ACTIVE;
+	}
+
+	@Override
+	public IsolationDelegate createIsolationDelegate() {
+		final JdbcSessionOwner jdbcSessionOwner = transactionCoordinatorOwner.getJdbcSessionOwner();
+
+		return new JtaIsolationDelegate(
+				jdbcSessionOwner.getJdbcConnectionAccess(),
+				jdbcSessionOwner.getJdbcSessionContext()
+						.getServiceRegistry()
+						.getService( JdbcServices.class )
+						.getSqlExceptionHelper(),
+				jtaPlatform.retrieveTransactionManager()
+		);
+	}
+
+	@Override
+	public TransactionCoordinatorBuilder getTransactionCoordinatorBuilder() {
+		return this.transactionCoordinatorBuilder;
+	}
+
+	@Override
+	public void setTimeOut(int seconds) {
+		this.timeOut = seconds;
+		physicalTransactionDelegate.jtaTransactionAdapter.setTimeOut( seconds );
+	}
+
+	@Override
+	public int getTimeOut() {
+		return this.timeOut;
+	}
+
+	// SynchronizationCallbackTarget ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+	@Override
+	public void beforeCompletion() {
+		try {
+			transactionCoordinatorOwner.beforeTransactionCompletion();
+		}catch (Exception e){
+			physicalTransactionDelegate.markRollbackOnly();
+		}
+		synchronizationRegistry.notifySynchronizationsBeforeTransactionCompletion();
+	}
+
+	@Override
+	public void afterCompletion(boolean successful) {
+		final int statusToSend =  successful ? Status.STATUS_COMMITTED : Status.STATUS_UNKNOWN;
+		synchronizationRegistry.notifySynchronizationsAfterTransactionCompletion( statusToSend );
+
+		transactionCoordinatorOwner.afterTransactionCompletion( successful );
+
+		if ( physicalTransactionDelegate != null ) {
+			physicalTransactionDelegate.invalidate();
+		}
+		physicalTransactionDelegate = null;
+		synchronizationRegistered = false;
+	}
+
+	public void addObserver(TransactionObserver observer) {
+		observers.add( observer );
+	}
+
+	@Override
+	public void removeObserver(TransactionObserver observer) {
+		observers.remove( observer );
+	}
+
+
+	/**
+	 * Implementation of the LocalInflow for this TransactionCoordinator.  Allows the
+	 * local transaction ({@link org.hibernate.Transaction} to callback into this
+	 * TransactionCoordinator for the purpose of driving the underlying JTA transaction.
+	 */
+	public class TransactionDriverControlImpl implements LocalInflow {
+		private final JtaTransactionAdapter jtaTransactionAdapter;
+		private boolean invalid;
+
+		public TransactionDriverControlImpl(JtaTransactionAdapter jtaTransactionAdapter) {
+			this.jtaTransactionAdapter = jtaTransactionAdapter;
+		}
+
+		protected void invalidate() {
+			invalid = true;
+		}
+
+		@Override
+		public void begin() {
+			errorIfInvalid();
+
+			jtaTransactionAdapter.begin();
+			JtaTransactionCoordinatorImpl.this.joinJtaTransaction();
+		}
+
+		protected void errorIfInvalid() {
+			if ( invalid ) {
+				throw new IllegalStateException( "Physical-transaction delegate is no longer valid" );
+			}
+		}
+
+		@Override
+		public void commit() {
+			errorIfInvalid();
+
+			// we don't have to perform any before/after completion processing here.  We leave that for
+			// the Synchronization callbacks
+			jtaTransactionAdapter.commit();
+		}
+
+		@Override
+		public void rollback() {
+			errorIfInvalid();
+
+			// we don't have to perform any after completion processing here.  We leave that for
+			// the Synchronization callbacks
+			jtaTransactionAdapter.rollback();
+		}
+
+		@Override
+		public TransactionStatus getStatus() {
+			return jtaTransactionAdapter.getStatus();
+		}
+
+		@Override
+		public void markRollbackOnly() {
+			jtaTransactionAdapter.markRollbackOnly();
+		}
+	}
+
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/StatusTranslator.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/StatusTranslator.java
new file mode 100644
index 0000000000..25c83c2495
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/StatusTranslator.java
@@ -0,0 +1,75 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) {DATE}, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction.backend.jta.internal;
+
+import javax.transaction.Status;
+
+import org.hibernate.TransactionException;
+import org.hibernate.resource.transaction.spi.TransactionStatus;
+
+/**
+ * @author Andrea Boriero
+ */
+public class StatusTranslator {
+
+	public static TransactionStatus translate(int status) {
+		TransactionStatus transactionStatus = null;
+		switch ( status ) {
+			case Status.STATUS_ACTIVE:
+				transactionStatus = TransactionStatus.ACTIVE;
+				break;
+			case Status.STATUS_PREPARED:
+				transactionStatus = TransactionStatus.ACTIVE;
+				break;
+			case Status.STATUS_PREPARING:
+				transactionStatus = TransactionStatus.ACTIVE;
+				break;
+			case Status.STATUS_COMMITTING:
+				transactionStatus = TransactionStatus.COMMITTING;
+				break;
+			case Status.STATUS_ROLLING_BACK:
+				transactionStatus = TransactionStatus.ROLLING_BACK;
+				break;
+			case Status.STATUS_NO_TRANSACTION:
+				transactionStatus = TransactionStatus.NOT_ACTIVE;
+				break;
+			case Status.STATUS_COMMITTED:
+				transactionStatus = TransactionStatus.COMMITTED;
+				break;
+			case Status.STATUS_ROLLEDBACK:
+				transactionStatus = TransactionStatus.ROLLED_BACK;
+				break;
+			case Status.STATUS_MARKED_ROLLBACK:
+				transactionStatus = TransactionStatus.MARKED_ROLLBACK;
+				break;
+			default:
+				break;
+		}
+		if ( transactionStatus == null ) {
+			throw new TransactionException( "TransactionManager reported transaction status as unknwon" );
+		}
+		return transactionStatus;
+	}
+
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/internal/RegisteredSynchronization.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/RegisteredSynchronization.java
similarity index 68%
rename from hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/internal/RegisteredSynchronization.java
rename to hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/RegisteredSynchronization.java
index b00c00a836..c70afd9d72 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/internal/RegisteredSynchronization.java
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/RegisteredSynchronization.java
@@ -1,58 +1,63 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.engine.transaction.synchronization.internal;
+package org.hibernate.resource.transaction.backend.jta.internal.synchronization;
 
 import javax.transaction.Synchronization;
 
-import org.hibernate.engine.transaction.synchronization.spi.SynchronizationCallbackCoordinator;
-import org.hibernate.internal.CoreLogging;
-
 import org.jboss.logging.Logger;
 
+import static org.hibernate.internal.CoreLogging.logger;
+
 /**
- * The JTA {@link javax.transaction.Synchronization} Hibernate registers when needed for JTA callbacks
+ * The JTA {@link javax.transaction.Synchronization} Hibernate registers when needed for JTA callbacks.
+ * <p/>
+ * Note that we split the notion of the registered Synchronization and the processing of the Synchronization callbacks
+ * mainly to account for "separation of concerns", but also so that the transaction engine does not have to hold
+ * reference to the actual Synchronization that gets registered with the JTA system.
  *
  * @author Steve Ebersole
  */
 public class RegisteredSynchronization implements Synchronization {
-	private static final Logger log = CoreLogging.logger( RegisteredSynchronization.class.getName() );
+	private static final Logger log = logger( RegisteredSynchronization.class );
 
 	private final SynchronizationCallbackCoordinator synchronizationCallbackCoordinator;
 
 	public RegisteredSynchronization(SynchronizationCallbackCoordinator synchronizationCallbackCoordinator) {
 		this.synchronizationCallbackCoordinator = synchronizationCallbackCoordinator;
 	}
 
 	@Override
 	public void beforeCompletion() {
-		log.trace( "JTA sync : beforeCompletion()" );
+		log.trace( "Registered JTA Synchronization : beforeCompletion()" );
+
 		synchronizationCallbackCoordinator.beforeCompletion();
 	}
 
 	@Override
 	public void afterCompletion(int status) {
-		log.tracef( "JTA sync : afterCompletion(%s)", status );
+		log.tracef( "Registered JTA Synchronization : afterCompletion(%s)", status );
+
 		synchronizationCallbackCoordinator.afterCompletion( status );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/spi/SynchronizationCallbackCoordinator.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/SynchronizationCallbackCoordinator.java
similarity index 70%
rename from hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/spi/SynchronizationCallbackCoordinator.java
rename to hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/SynchronizationCallbackCoordinator.java
index aea06482c0..596fdbec0c 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/spi/SynchronizationCallbackCoordinator.java
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/SynchronizationCallbackCoordinator.java
@@ -1,45 +1,44 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.engine.transaction.synchronization.spi;
+package org.hibernate.resource.transaction.backend.jta.internal.synchronization;
 
 import javax.transaction.Synchronization;
 
 /**
+ * Manages funneling JTA Synchronization callbacks back into the Hibernate transaction engine.
+ *
  * @author Steve Ebersole
  */
 public interface SynchronizationCallbackCoordinator extends Synchronization {
-	public void setExceptionMapper(ExceptionMapper exceptionMapper);
-	public void setManagedFlushChecker(ManagedFlushChecker managedFlushChecker);
-	public void setAfterCompletionAction(AfterCompletionAction afterCompletionAction);
-
 	/**
-	 * A callback whenever a JTA Synchronization is registered
+	 * Called by the TransactionCoordinator when it registers the Synchronization with the JTA system
 	 */
 	public void synchronizationRegistered();
 
 	/**
-	 * A callback to perform any delayed afterCompletion processes
+	 * Called by the TransactionCoordinator to allow the SynchronizationCallbackCoordinator to process any
+	 * after-completion handling that it may have delayed due to thread affinity
 	 */
 	public void processAnyDelayedAfterCompletion();
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/SynchronizationCallbackCoordinatorNonTrackingImpl.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/SynchronizationCallbackCoordinatorNonTrackingImpl.java
new file mode 100644
index 0000000000..2a578f9a17
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/SynchronizationCallbackCoordinatorNonTrackingImpl.java
@@ -0,0 +1,85 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction.backend.jta.internal.synchronization;
+
+import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
+
+import org.jboss.logging.Logger;
+
+import static org.hibernate.internal.CoreLogging.logger;
+
+/**
+ * Manages callbacks from the {@link javax.transaction.Synchronization} registered by Hibernate.
+ * 
+ * @author Steve Ebersole
+ */
+public class SynchronizationCallbackCoordinatorNonTrackingImpl implements SynchronizationCallbackCoordinator {
+	private static final Logger log = logger( SynchronizationCallbackCoordinatorNonTrackingImpl.class );
+
+	private final SynchronizationCallbackTarget target;
+
+	public SynchronizationCallbackCoordinatorNonTrackingImpl(SynchronizationCallbackTarget target) {
+		this.target = target;
+		reset();
+	}
+
+	public void reset() {
+	}
+
+	@Override
+	public void synchronizationRegistered() {
+		// Nothing to do here
+	}
+
+	// sync callbacks ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+	@Override
+	public void beforeCompletion() {
+		log.trace( "Synchronization coordinator: beforeCompletion()" );
+
+		if ( !target.isActive() ) {
+			return;
+		}
+
+		target.beforeCompletion();
+	}
+
+
+	@Override
+	public void afterCompletion(int status) {
+		doAfterCompletion( JtaStatusHelper.isCommitted( status ) );
+	}
+
+	protected void doAfterCompletion(boolean successful) {
+		try {
+			target.afterCompletion( successful );
+		}finally {
+			reset();
+		}
+	}
+
+	@Override
+	public void processAnyDelayedAfterCompletion() {
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/internal/SynchronizationCallbackCoordinatorTrackingImpl.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/SynchronizationCallbackCoordinatorTrackingImpl.java
similarity index 64%
rename from hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/internal/SynchronizationCallbackCoordinatorTrackingImpl.java
rename to hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/SynchronizationCallbackCoordinatorTrackingImpl.java
index 2fd804b962..f7bcd51500 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/synchronization/internal/SynchronizationCallbackCoordinatorTrackingImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/SynchronizationCallbackCoordinatorTrackingImpl.java
@@ -1,107 +1,110 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.engine.transaction.synchronization.internal;
+package org.hibernate.resource.transaction.backend.jta.internal.synchronization;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
-import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 
+import static org.hibernate.internal.CoreLogging.messageLogger;
+
 /**
  * Extension of SynchronizationCallbackCoordinatorNonTrackingImpl that adds checking of whether a rollback comes from
  * a thread other than the application thread (thread used to register the Synchronization)
- * 
+ *
  * @author Steve Ebersole
  * @author Brett Meyer
  */
 public class SynchronizationCallbackCoordinatorTrackingImpl extends SynchronizationCallbackCoordinatorNonTrackingImpl {
-	private static final CoreMessageLogger log = CoreLogging.messageLogger( SynchronizationCallbackCoordinatorTrackingImpl.class );
+	private static final CoreMessageLogger log = messageLogger( SynchronizationCallbackCoordinatorTrackingImpl.class );
 
-	// magic numbers :(
-	private static final int NO_STATUS = -1;
+	// magic number :(
+	private static final long NO_THREAD_ID = Long.MIN_VALUE;
 
-	private volatile long registrationThreadId;
-	private volatile int delayedCompletionHandlingStatus;
+	private volatile long registrationThreadId = NO_THREAD_ID;
+	private volatile boolean delayedCompletionHandling;
 
-	public SynchronizationCallbackCoordinatorTrackingImpl(TransactionCoordinator transactionCoordinator) {
-		// super ctor calls reset() followed by pulse()
-		super( transactionCoordinator );
+	public SynchronizationCallbackCoordinatorTrackingImpl(SynchronizationCallbackTarget target) {
+		super( target );
 	}
 
 	@Override
 	public void reset() {
 		super.reset();
 		// NOTE : reset is typically called:
 		// 		1) on initialization, and
 		// 		2) after "after completion" handling is finished.
 		//
-		// Here we use that to "clear out" all 'delayed after-completion" state.
-		delayedCompletionHandlingStatus = NO_STATUS;
+		// Here we use that to "clear out" all 'delayed after-completion" state.  The registrationThreadId will
+		// "lazily" be re-populated on the next synchronizationRegistered call to allow for the potential of the next Session transaction
+		// occurring on a different thread (though that transaction would need to completely operate on that thread).
+		delayedCompletionHandling = false;
 	}
 
 	@Override
 	public void afterCompletion(int status) {
 		// The whole concept of "tracking" comes down to this code block..
 		// Essentially we need to see if we can process the callback immediately.  So here we check whether the
 		// current call is happening on the same thread as the thread under which we registered the Synchronization.
 		// As far as we know, this can only ever happen in the rollback case where the transaction had been rolled
 		// back on a separate "reaper" thread.  Since we know the transaction status and that check is not as heavy
 		// as accessing the current thread, we check that first
 		if ( JtaStatusHelper.isRollback( status ) ) {
 			// we are processing a rollback, see if it is the same thread
 			final long currentThreadId = Thread.currentThread().getId();
 			final boolean isRegistrationThread = currentThreadId == registrationThreadId;
 			if ( ! isRegistrationThread ) {
 				// so we do have the condition of a rollback initiated from a separate thread.  Set the flag here and
 				// check for it in SessionImpl. See HHH-7910.
-				delayedCompletionHandlingStatus = status;
+				delayedCompletionHandling = true;
 
-				// no matter what we need to release the Connection.  Not releasing
-				// the Connection here can lead to leaked Connections.
-				transactionCoordinator().getJdbcCoordinator().getLogicalConnection().close();
-
-				log.rollbackFromBackgroundThread( status );
+				// todo : update code to use message logger
+				//log.rollbackFromBackgroundThread( status );
+				log.warn( "Rollback from background thread (update code to use message logger)" );
 				return;
 			}
 		}
 
 		// otherwise, do the callback immediately
-		doAfterCompletion( status );
+		doAfterCompletion( JtaStatusHelper.isCommitted( status ) );
 	}
 
 	@Override
 	public void synchronizationRegistered() {
-		registrationThreadId = Thread.currentThread().getId();
+		if ( registrationThreadId == NO_THREAD_ID ) {
+			registrationThreadId = Thread.currentThread().getId();
+		}
 	}
 
 	@Override
 	public void processAnyDelayedAfterCompletion() {
-		if ( delayedCompletionHandlingStatus != NO_STATUS ) {
-			doAfterCompletion( delayedCompletionHandlingStatus );
-			delayedCompletionHandlingStatus = NO_STATUS;
-			throw new HibernateException("Transaction was rolled back in a different thread!");
+		if ( delayedCompletionHandling ) {
+			// false here because, as discussed above, the delayed logic should only ever occur during rollback
+			delayedCompletionHandling = false;
+			doAfterCompletion( false );
+			// NOTE : doAfterCompletion calls reset
+			throw new HibernateException( "Transaction was rolled back in a different thread!" );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/SynchronizationCallbackTarget.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/SynchronizationCallbackTarget.java
new file mode 100644
index 0000000000..6843017620
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/SynchronizationCallbackTarget.java
@@ -0,0 +1,76 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction.backend.jta.internal.synchronization;
+
+/**
+ * Defines "inflow" for JTA transactions from the perspective of Hibernate's registered JTA Synchronization
+ * back into the TransactionCoordinator by means of the SynchronizationCallbackCoordinator.
+ * <p/>
+ * That's a mouthful :)  The way it works is like this...<ul>
+ *     <li>
+ *         Hibernate will register a JTA {@link javax.transaction.Synchronization} implementation
+ *         ({@link RegisteredSynchronization}) which allows
+ *         it to listen for completion of the JTA transaction.
+ *     </li>
+ *     <li>
+ *         That RegisteredSynchronization is given a SynchronizationCallbackCoordinator which it uses
+ *         to route the transaction completion calls back into Hibernate.  The SynchronizationCallbackCoordinator
+ *         contract applies various behaviors around this process.  See the impls for details.
+ *     </li>
+ *     <li>
+ *         The SynchronizationCallbackCoordinator is handed a SynchronizationCallbackTarget which is the specific
+ *         means for it to "route the transaction completion calls back into Hibernate".  The SynchronizationCallbackTarget
+ *         is most often the TransactionCoordinator impl or a direct delegate of the TransactionCoordinator impl.  In
+ *         that sense, SynchronizationCallbackTarget is the contract between the SynchronizationCallbackCoordinator
+ *         and the TransactionCoordinator.
+ *     </li>
+ * </ul>
+ *
+ * @author Steve Ebersole
+ */
+public interface SynchronizationCallbackTarget {
+	/**
+	 * Is the callback target still active?  Generally this is checked by the caller prior to calling
+	 * {@link #beforeCompletion()} or {@link #afterCompletion(boolean)}
+	 *
+	 * @return {@code true} indicates the target is active; {@code false} indicates it is not.
+	 */
+	boolean isActive();
+
+	/**
+	 * Callback of before-completion.
+	 *
+	 * @see javax.transaction.Synchronization#beforeCompletion
+	 */
+	void beforeCompletion();
+
+	/**
+	 * Callback of after-completion.
+	 *
+	 * @param successful Was the transaction successful?
+	 *
+	 * @see javax.transaction.Synchronization#afterCompletion
+	 */
+	void afterCompletion(boolean successful);
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/package-info.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/package-info.java
new file mode 100644
index 0000000000..a698c6e5b1
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/jta/internal/synchronization/package-info.java
@@ -0,0 +1,29 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+
+/**
+ * Internal implementation details for reacting to JTA transaction completion via {@link javax.transaction.Synchronization}
+ * callbacks
+ */
+package org.hibernate.resource.transaction.backend.jta.internal.synchronization;
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jdbc/JdbcIsolationDelegate.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/internal/JdbcIsolationDelegate.java
similarity index 79%
rename from hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jdbc/JdbcIsolationDelegate.java
rename to hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/internal/JdbcIsolationDelegate.java
index 495df4afde..11d1830cb0 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jdbc/JdbcIsolationDelegate.java
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/internal/JdbcIsolationDelegate.java
@@ -1,123 +1,122 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
+ * Copyright (c) {DATE}, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.engine.transaction.internal.jdbc;
+package org.hibernate.resource.transaction.backend.store.internal;
 
 import java.sql.Connection;
 import java.sql.SQLException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.transaction.spi.IsolationDelegate;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.jdbc.WorkExecutor;
 import org.hibernate.jdbc.WorkExecutorVisitable;
 
 /**
- * The isolation delegate for JDBC {@link Connection} based transactions
- *
- * @author Steve Ebersole
+ * @author Andrea Boriero
  */
 public class JdbcIsolationDelegate implements IsolationDelegate {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( JdbcIsolationDelegate.class );
 
-	private final TransactionCoordinator transactionCoordinator;
+	private final JdbcConnectionAccess connectionAccess;
+	private final SqlExceptionHelper sqlExceptionHelper;
 
-	public JdbcIsolationDelegate(TransactionCoordinator transactionCoordinator) {
-		this.transactionCoordinator = transactionCoordinator;
+	public JdbcIsolationDelegate(JdbcConnectionAccess connectionAccess, SqlExceptionHelper sqlExceptionHelper) {
+		this.connectionAccess = connectionAccess;
+		this.sqlExceptionHelper = sqlExceptionHelper;
 	}
 
 	protected JdbcConnectionAccess jdbcConnectionAccess() {
-		return transactionCoordinator.getTransactionContext().getJdbcConnectionAccess();
+		return this.connectionAccess;
 	}
 
 	protected SqlExceptionHelper sqlExceptionHelper() {
-		return transactionCoordinator.getJdbcCoordinator().getLogicalConnection().getJdbcServices().getSqlExceptionHelper();
+		return this.sqlExceptionHelper;
 	}
 
 	@Override
 	public <T> T delegateWork(WorkExecutorVisitable<T> work, boolean transacted) throws HibernateException {
 		boolean wasAutoCommit = false;
 		try {
 			Connection connection = jdbcConnectionAccess().obtainConnection();
 			try {
 				if ( transacted ) {
 					if ( connection.getAutoCommit() ) {
 						wasAutoCommit = true;
 						connection.setAutoCommit( false );
 					}
 				}
 
 				T result = work.accept( new WorkExecutor<T>(), connection );
 
 				if ( transacted ) {
 					connection.commit();
 				}
 
 				return result;
 			}
-			catch ( Exception e ) {
+			catch (Exception e) {
 				try {
 					if ( transacted && !connection.isClosed() ) {
 						connection.rollback();
 					}
 				}
-				catch ( Exception ignore ) {
+				catch (Exception ignore) {
 					LOG.unableToRollbackConnection( ignore );
 				}
 
 				if ( e instanceof HibernateException ) {
 					throw (HibernateException) e;
 				}
 				else if ( e instanceof SQLException ) {
 					throw sqlExceptionHelper().convert( (SQLException) e, "error performing isolated work" );
 				}
 				else {
 					throw new HibernateException( "error performing isolated work", e );
 				}
 			}
 			finally {
 				if ( transacted && wasAutoCommit ) {
 					try {
 						connection.setAutoCommit( true );
 					}
-					catch ( Exception ignore ) {
+					catch (Exception ignore) {
 						LOG.trace( "was unable to reset connection back to auto-commit" );
 					}
 				}
 				try {
 					jdbcConnectionAccess().releaseConnection( connection );
 				}
-				catch ( Exception ignore ) {
+				catch (Exception ignore) {
 					LOG.unableToReleaseIsolatedConnection( ignore );
 				}
 			}
 		}
-		catch ( SQLException sqle ) {
+		catch (SQLException sqle) {
 			throw sqlExceptionHelper().convert( sqle, "unable to obtain isolated JDBC connection" );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/internal/ResourceLocalTransactionCoordinatorBuilderImpl.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/internal/ResourceLocalTransactionCoordinatorBuilderImpl.java
new file mode 100644
index 0000000000..506a5700a6
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/internal/ResourceLocalTransactionCoordinatorBuilderImpl.java
@@ -0,0 +1,79 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction.backend.store.internal;
+
+import org.hibernate.ConnectionReleaseMode;
+import org.hibernate.HibernateException;
+import org.hibernate.resource.jdbc.spi.JdbcSessionContext;
+import org.hibernate.resource.transaction.TransactionCoordinator;
+import org.hibernate.resource.transaction.backend.store.spi.DataStoreTransactionAccess;
+import org.hibernate.resource.transaction.spi.TransactionCoordinatorOwner;
+import org.hibernate.resource.transaction.TransactionCoordinatorResourceLocalBuilder;
+
+import static org.hibernate.resource.jdbc.spi.JdbcSessionContext.ConnectionAcquisitionMode;
+
+/**
+ * Concrete builder for resource-local TransactionCoordinator instances.
+ *
+ * @author Steve Ebersole
+ */
+public class ResourceLocalTransactionCoordinatorBuilderImpl implements TransactionCoordinatorResourceLocalBuilder {
+	private DataStoreTransactionAccess providedDataStoreTransactionAccess;
+
+	@Override
+	public void setResourceLocalTransactionAccess(DataStoreTransactionAccess dataStoreTransactionAccess) {
+		this.providedDataStoreTransactionAccess = dataStoreTransactionAccess;
+	}
+
+	@Override
+	public TransactionCoordinator buildTransactionCoordinator(TransactionCoordinatorOwner owner) {
+		if ( providedDataStoreTransactionAccess != null ) {
+			return new ResourceLocalTransactionCoordinatorImpl( this, owner, providedDataStoreTransactionAccess );
+		}
+		else {
+			if ( owner instanceof DataStoreTransactionAccess ) {
+				return new ResourceLocalTransactionCoordinatorImpl( this, owner, (DataStoreTransactionAccess) owner );
+			}
+		}
+
+		throw new HibernateException(
+				"Could not determine ResourceLocalTransactionAccess to use in building TransactionCoordinator"
+		);
+	}
+
+	@Override
+	public boolean isJta() {
+		return false;
+	}
+
+	@Override
+	public ConnectionReleaseMode getDefaultConnectionReleaseMode() {
+		return ConnectionReleaseMode.ON_CLOSE;
+	}
+
+	@Override
+	public ConnectionAcquisitionMode getDefaultConnectionAcquisitionMode() {
+		return null;
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/internal/ResourceLocalTransactionCoordinatorImpl.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/internal/ResourceLocalTransactionCoordinatorImpl.java
new file mode 100644
index 0000000000..7d873e004b
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/internal/ResourceLocalTransactionCoordinatorImpl.java
@@ -0,0 +1,252 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction.backend.store.internal;
+
+import javax.transaction.Status;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import org.hibernate.engine.jdbc.spi.JdbcServices;
+import org.hibernate.engine.transaction.spi.IsolationDelegate;
+import org.hibernate.engine.transaction.spi.TransactionObserver;
+import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.resource.jdbc.spi.JdbcSessionOwner;
+import org.hibernate.resource.transaction.SynchronizationRegistry;
+import org.hibernate.resource.transaction.TransactionCoordinator;
+import org.hibernate.resource.transaction.TransactionCoordinatorBuilder;
+import org.hibernate.resource.transaction.backend.store.spi.DataStoreTransaction;
+import org.hibernate.resource.transaction.backend.store.spi.DataStoreTransactionAccess;
+import org.hibernate.resource.transaction.internal.SynchronizationRegistryStandardImpl;
+import org.hibernate.resource.transaction.spi.TransactionCoordinatorOwner;
+import org.hibernate.resource.transaction.spi.TransactionStatus;
+
+import static org.hibernate.internal.CoreLogging.messageLogger;
+
+/**
+ * An implementation of TransactionCoordinator based on managing a transaction through the data-store
+ * specific ResourceLocalTransaction.
+ *
+ * @author Steve Ebersole
+ * @see org.hibernate.resource.transaction.backend.store.spi.DataStoreTransaction
+ */
+public class ResourceLocalTransactionCoordinatorImpl implements TransactionCoordinator {
+	private static final CoreMessageLogger log = messageLogger( ResourceLocalTransactionCoordinatorImpl.class );
+
+	private final TransactionCoordinatorBuilder transactionCoordinatorBuilder;
+	private final DataStoreTransactionAccess dataStoreTransactionAccess;
+	private final TransactionCoordinatorOwner transactionCoordinatorOwner;
+	private final SynchronizationRegistryStandardImpl synchronizationRegistry = new SynchronizationRegistryStandardImpl();
+
+	private TransactionDriverControlImpl physicalTransactionDelegate;
+
+	private int timeOut = -1;
+
+	private final transient List<TransactionObserver> observers;
+
+	/**
+	 * Construct a ResourceLocalTransactionCoordinatorImpl instance.  package-protected to ensure access goes through
+	 * builder.
+	 *
+	 * @param owner The transactionCoordinatorOwner
+	 */
+	ResourceLocalTransactionCoordinatorImpl(
+			TransactionCoordinatorBuilder transactionCoordinatorBuilder,
+			TransactionCoordinatorOwner owner,
+			DataStoreTransactionAccess dataStoreTransactionAccess) {
+		this.observers = new ArrayList<TransactionObserver>();
+		this.transactionCoordinatorBuilder = transactionCoordinatorBuilder;
+		this.dataStoreTransactionAccess = dataStoreTransactionAccess;
+		this.transactionCoordinatorOwner = owner;
+	}
+
+	@Override
+	public LocalInflow getTransactionDriverControl() {
+		// Again, this PhysicalTransactionDelegate will act as the bridge from the local transaction back into the
+		// coordinator.  We lazily build it as we invalidate each delegate after each transaction (a delegate is
+		// valid for just one transaction)
+		if ( physicalTransactionDelegate == null ) {
+			physicalTransactionDelegate = new TransactionDriverControlImpl( dataStoreTransactionAccess.getResourceLocalTransaction() );
+		}
+		return physicalTransactionDelegate;
+	}
+
+	@Override
+	public void explicitJoin() {
+		// nothing to do here, but log a warning
+		log.callingJoinTransactionOnNonJtaEntityManager();
+	}
+
+	@Override
+	public boolean isJoined() {
+		log.debug( "Calling TransactionCoordinator#isJoined in resource-local mode always returns false" );
+		return isActive();
+	}
+
+	@Override
+	public void pulse() {
+		// nothing to do here
+	}
+
+	@Override
+	public SynchronizationRegistry getLocalSynchronizations() {
+		return synchronizationRegistry;
+	}
+
+	@Override
+	public boolean isActive() {
+		return transactionCoordinatorOwner.isActive();
+	}
+
+	@Override
+	public IsolationDelegate createIsolationDelegate() {
+		final JdbcSessionOwner jdbcSessionOwner = transactionCoordinatorOwner.getJdbcSessionOwner();
+
+		return new JdbcIsolationDelegate(
+				jdbcSessionOwner.getJdbcConnectionAccess(),
+				jdbcSessionOwner.getJdbcSessionContext().getServiceRegistry().getService( JdbcServices.class ).getSqlExceptionHelper()
+		);
+	}
+
+	@Override
+	public TransactionCoordinatorBuilder getTransactionCoordinatorBuilder() {
+		return this.transactionCoordinatorBuilder;
+	}
+
+	@Override
+	public void setTimeOut(int seconds) {
+		this.timeOut = seconds;
+	}
+
+	@Override
+	public int getTimeOut() {
+		return this.timeOut;
+	}
+
+	// PhysicalTransactionDelegate ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+	private void afterBeginCallback() {
+		if(this.timeOut > 0) {
+			transactionCoordinatorOwner.setTransactionTimeOut( this.timeOut );
+		}
+		for ( TransactionObserver observer : observers ) {
+			observer.afterBegin();
+		}
+		log.trace( "ResourceLocalTransactionCoordinatorImpl#afterBeginCallback" );
+	}
+
+	private void beforeCompletionCallback() {
+		log.trace( "ResourceLocalTransactionCoordinatorImpl#beforeCompletionCallback" );
+		transactionCoordinatorOwner.beforeTransactionCompletion();
+		synchronizationRegistry.notifySynchronizationsBeforeTransactionCompletion();
+		for ( TransactionObserver observer : observers ) {
+			observer.beforeCompletion();
+		}
+	}
+
+	private void afterCompletionCallback(boolean successful) {
+		log.tracef( "ResourceLocalTransactionCoordinatorImpl#afterCompletionCallback(%s)", successful );
+		final int statusToSend = successful ? Status.STATUS_COMMITTED : Status.STATUS_UNKNOWN;
+		synchronizationRegistry.notifySynchronizationsAfterTransactionCompletion( statusToSend );
+
+		transactionCoordinatorOwner.afterTransactionCompletion( successful );
+		for ( TransactionObserver observer : observers ) {
+			observer.afterCompletion( successful );
+		}
+		invalidateDelegate();
+	}
+
+	private void invalidateDelegate() {
+		if ( physicalTransactionDelegate == null ) {
+			throw new IllegalStateException( "Physical-transaction delegate not known on attempt to invalidate" );
+		}
+
+		physicalTransactionDelegate.invalidate();
+		physicalTransactionDelegate = null;
+	}
+
+	public void addObserver(TransactionObserver observer) {
+		observers.add( observer );
+	}
+
+	@Override
+	public void removeObserver(TransactionObserver observer) {
+		observers.remove( observer );
+	}
+
+	/**
+	 * The delegate bridging between the local (application facing) transaction and the "physical" notion of a
+	 * transaction via the JDBC Connection.
+	 */
+	public class TransactionDriverControlImpl implements LocalInflow {
+		private final DataStoreTransaction dataStoreTransaction;
+		private boolean invalid;
+
+		public TransactionDriverControlImpl(DataStoreTransaction dataStoreTransaction) {
+			super();
+			this.dataStoreTransaction = dataStoreTransaction;
+		}
+
+		protected void invalidate() {
+			invalid = true;
+		}
+
+		@Override
+		public void begin() {
+			errorIfInvalid();
+
+			dataStoreTransaction.begin();
+			ResourceLocalTransactionCoordinatorImpl.this.afterBeginCallback();
+		}
+
+		protected void errorIfInvalid() {
+			if ( invalid ) {
+				throw new IllegalStateException( "Physical-transaction delegate is no longer valid" );
+			}
+		}
+
+		@Override
+		public void commit() {
+			ResourceLocalTransactionCoordinatorImpl.this.beforeCompletionCallback();
+			dataStoreTransaction.commit();
+			ResourceLocalTransactionCoordinatorImpl.this.afterCompletionCallback( true );
+		}
+
+		@Override
+		public void rollback() {
+			dataStoreTransaction.rollback();
+			ResourceLocalTransactionCoordinatorImpl.this.afterCompletionCallback( false );
+		}
+
+		@Override
+		public TransactionStatus getStatus() {
+			return dataStoreTransaction.getStatus();
+		}
+
+		@Override
+		public void markRollbackOnly() {
+
+		}
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/package-info.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/package-info.java
new file mode 100644
index 0000000000..98c6d0562f
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/package-info.java
@@ -0,0 +1,38 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+
+/**
+ * Collectively models the concept of transaction coordination through the
+ * "data store" specific notion of a transaction.  In Hibernate ORM uses this
+ * correlates to the JDBC notion of a transaction, which (unfortunately) is
+ * not modeled by an actual contract.  Instead JDBC models transaction control
+ * via its Connection contract.  Here we use
+ * {@link org.hibernate.resource.transaction.backend.store.spi.DataStoreTransaction}
+ * as the encapsulation for conceptual JDBC transaction.  It also helps isolate the
+ * {@link org.hibernate.resource.transaction} and {@link org.hibernate.resource.jdbc}
+ * packages from circularity.  Lastly it does somewhat allow for potentially abstracting
+ * non-JDBC data stores into this transaction handling utilizing its data store specific
+ * transaction mechanism.
+ */
+package org.hibernate.resource.transaction.backend.store;
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/spi/DataStoreTransaction.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/spi/DataStoreTransaction.java
new file mode 100644
index 0000000000..dfe6ec6fd7
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/spi/DataStoreTransaction.java
@@ -0,0 +1,50 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction.backend.store.spi;
+
+import org.hibernate.resource.transaction.spi.TransactionStatus;
+
+/**
+ * Models access to the resource transaction of the underlying data store (JDBC).
+ *
+ * @author Steve Ebersole
+ */
+public interface DataStoreTransaction {
+	/**
+	 * Begin the resource transaction
+	 */
+	public void begin();
+
+	/**
+	 * Commit the resource transaction
+	 */
+	public void commit();
+
+	/**
+	 * Rollback the resource transaction
+	 */
+	public void rollback();
+
+	public TransactionStatus getStatus();
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/spi/DataStoreTransactionAccess.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/spi/DataStoreTransactionAccess.java
new file mode 100644
index 0000000000..809d971283
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/backend/store/spi/DataStoreTransactionAccess.java
@@ -0,0 +1,40 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction.backend.store.spi;
+
+/**
+ * Provides access to DataStoreTransaction (JDBC transaction stand-in) for use in building resource-local
+ * TransactionCoordinator instances.
+ *
+ * @author Steve Ebersole
+ */
+public interface DataStoreTransactionAccess {
+	/**
+	 * Provides access to the resource local transaction of this data store, which is used by the TransactionCoordinator
+	 * to manage transactions against the data store when not using JTA.
+	 *
+	 * @return The resource-local transaction
+	 */
+	public DataStoreTransaction getResourceLocalTransaction();
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/internal/SynchronizationRegistryStandardImpl.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/internal/SynchronizationRegistryStandardImpl.java
new file mode 100644
index 0000000000..3563e9db51
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/internal/SynchronizationRegistryStandardImpl.java
@@ -0,0 +1,126 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction.internal;
+
+import java.util.LinkedHashSet;
+import javax.transaction.Synchronization;
+
+import org.hibernate.internal.CoreLogging;
+import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.resource.transaction.LocalSynchronizationException;
+import org.hibernate.resource.transaction.NullSynchronizationException;
+import org.hibernate.resource.transaction.spi.SynchronizationRegistryImplementor;
+
+/**
+ * The standard implementation of the SynchronizationRegistry contract
+ *
+ * @author Steve Ebersole
+ */
+public class SynchronizationRegistryStandardImpl implements SynchronizationRegistryImplementor {
+	private static final CoreMessageLogger log = CoreLogging.messageLogger( SynchronizationRegistryStandardImpl.class );
+
+	private LinkedHashSet<Synchronization> synchronizations;
+
+	/**
+	 * Intended for test access
+	 *
+	 * @return The number of Synchronizations registered
+	 */
+	public int getNumberOfRegisteredSynchronizations() {
+		return synchronizations == null ? 0 : synchronizations.size();
+	}
+
+	@Override
+	public void registerSynchronization(Synchronization synchronization) {
+		if ( synchronization == null ) {
+			throw new NullSynchronizationException();
+		}
+
+		if ( synchronizations == null ) {
+			synchronizations = new LinkedHashSet<Synchronization>();
+		}
+
+		final boolean added = synchronizations.add( synchronization );
+		if ( !added ) {
+			log.synchronizationAlreadyRegistered( synchronization );
+		}
+	}
+
+	@Override
+	public void notifySynchronizationsBeforeTransactionCompletion() {
+		log.trace( "SynchronizationRegistryStandardImpl.notifySynchronizationsBeforeTransactionCompletion" );
+
+		if ( synchronizations != null ) {
+			for ( Synchronization synchronization : synchronizations ) {
+				try {
+					synchronization.beforeCompletion();
+				}
+				catch (Throwable t) {
+					log.synchronizationFailed( synchronization, t );
+					throw new LocalSynchronizationException(
+							"Exception calling user Synchronization (beforeCompletion): " + synchronization.getClass().getName(),
+							t
+					);
+				}
+			}
+		}
+	}
+
+	@Override
+	public void notifySynchronizationsAfterTransactionCompletion(int status) {
+		log.tracef(
+				"SynchronizationRegistryStandardImpl.notifySynchronizationsAfterTransactionCompletion(%s)",
+				status
+		);
+
+		if ( synchronizations != null ) {
+			try {
+				for ( Synchronization synchronization : synchronizations ) {
+					try {
+						synchronization.afterCompletion( status );
+					}
+					catch (Throwable t) {
+						log.synchronizationFailed( synchronization, t );
+						throw new LocalSynchronizationException(
+								"Exception calling user Synchronization (afterCompletion): " + synchronization.getClass().getName(),
+								t
+						);
+					}
+				}
+			}
+			finally {
+				clearSynchronizations();
+			}
+		}
+	}
+
+	@Override
+	public void clearSynchronizations() {
+		log.debug( "Clearing local Synchronizations" );
+
+		if ( synchronizations != null ) {
+			synchronizations.clear();
+		}
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/TransactionFactoryInitiator.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/internal/TransactionCoordinatorBuilderInitiator.java
similarity index 50%
rename from hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/TransactionFactoryInitiator.java
rename to hibernate-core/src/main/java/org/hibernate/resource/transaction/internal/TransactionCoordinatorBuilderInitiator.java
index 798cf303bd..b9aaa1d2ad 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/TransactionFactoryInitiator.java
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/internal/TransactionCoordinatorBuilderInitiator.java
@@ -1,69 +1,68 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
+ * Copyright (c) {DATE}, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
-package org.hibernate.engine.transaction.internal;
+package org.hibernate.resource.transaction.internal;
 
 import java.util.Map;
 
 import org.hibernate.boot.registry.StandardServiceInitiator;
 import org.hibernate.boot.registry.selector.spi.StrategySelector;
 import org.hibernate.cfg.AvailableSettings;
-import org.hibernate.engine.transaction.internal.jdbc.JdbcTransactionFactory;
-import org.hibernate.engine.transaction.spi.TransactionFactory;
-import org.hibernate.engine.transaction.spi.TransactionImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.resource.transaction.TransactionCoordinatorBuilder;
+import org.hibernate.resource.transaction.TransactionCoordinatorBuilderFactory;
+import org.hibernate.resource.transaction.TransactionCoordinatorJtaBuilder;
+import org.hibernate.resource.transaction.backend.store.internal.ResourceLocalTransactionCoordinatorBuilderImpl;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 
 /**
- * Standard initiator for {@link TransactionFactory} service.
- *
- * @author Steve Ebersole
+ * @author Andrea Boriero
  */
-public class TransactionFactoryInitiator<T extends TransactionImplementor>
-		implements StandardServiceInitiator<TransactionFactory> {
-
-	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( TransactionFactoryInitiator.class );
+public class TransactionCoordinatorBuilderInitiator implements StandardServiceInitiator<TransactionCoordinatorBuilder> {
 
-	public static final TransactionFactoryInitiator INSTANCE = new TransactionFactoryInitiator();
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger(TransactionCoordinatorBuilderInitiator.class);
 
-	@Override
-	@SuppressWarnings({"unchecked"})
-	public Class<TransactionFactory> getServiceInitiated() {
-		return TransactionFactory.class;
-	}
+	public static final TransactionCoordinatorBuilderInitiator INSTANCE = 	new TransactionCoordinatorBuilderInitiator();
 
 	@Override
-	@SuppressWarnings({"unchecked"})
-	public TransactionFactory initiateService(Map configurationValues, ServiceRegistryImplementor registry) {
-		final Object strategy = configurationValues.get( AvailableSettings.TRANSACTION_STRATEGY );
+	public TransactionCoordinatorBuilder initiateService(
+			Map configurationValues, ServiceRegistryImplementor registry) {
+		final Object strategy = configurationValues.get( AvailableSettings.TRANSACTION_COORDINATOR_STRATEGY );
 
 		if ( strategy == null ) {
-			LOG.usingDefaultTransactionStrategy();
-			return new JdbcTransactionFactory();
+			return new ResourceLocalTransactionCoordinatorBuilderImpl() ;
 		}
+//		TransactionCoordinatorJtaBuilder transactionCoordinatorJtaBuilder = TransactionCoordinatorBuilderFactory.INSTANCE
+//				.forJta();
 
-		return registry.getService( StrategySelector.class ).resolveStrategy( TransactionFactory.class, strategy );
+		TransactionCoordinatorBuilder transactionCoordinatorBuilder = registry.getService( StrategySelector.class )
+				.resolveStrategy( TransactionCoordinatorBuilder.class, strategy );
+		return transactionCoordinatorBuilder;
 	}
-}
 
+	@Override
+	public Class<TransactionCoordinatorBuilder> getServiceInitiated() {
+		return TransactionCoordinatorBuilder.class;
+	}
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/internal/package-info.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/internal/package-info.java
new file mode 100644
index 0000000000..8cf314059a
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/internal/package-info.java
@@ -0,0 +1,28 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+
+/**
+ * Internal implementation details for the resource-level transaction capabilities of Hibernate.
+ */
+package org.hibernate.resource.transaction.internal;
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/package-info.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/package-info.java
new file mode 100644
index 0000000000..56778f6bb4
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/package-info.java
@@ -0,0 +1,66 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+
+/**
+ * Defines the resource-level transaction capabilities of Hibernate, which revolves around the
+ * {@link org.hibernate.resource.transaction.TransactionCoordinator} contract.  See
+ * {@link org.hibernate.resource.transaction.TransactionCoordinatorBuilder} and
+ * {@link org.hibernate.resource.transaction.TransactionCoordinatorBuilderFactory}
+ * for information on obtaining TransactionCoordinator instances.
+ *
+ * <p/>
+ *
+ * A few terms/concepts to keep in mind here...
+ *
+ * <h2>Local transaction</h2>
+ *
+ * The local transaction is the idea of transactionality exposed to the application (as
+ * {@link org.hibernate.Transaction}) as a means to control the underlying transaction.  That
+ * control flows from the {@link org.hibernate.Transaction} into the TransactionCoordinator
+ * through the {@link org.hibernate.resource.transaction.TransactionCoordinator.LocalInflow} it exposes.
+ *
+ * <h2>Physical transaction</h2>
+ *
+ * This is the physical underlying transaction that ultimately controls the database transaction.  This
+ * can be:<ul>
+ *     <li>
+ *       a JTA transaction, as expressed by {@link javax.transaction.UserTransaction} or
+ *       {@link javax.transaction.Transaction})
+ *     </li>
+ *     <li>
+ *         a "JDBC transaction", as expressed through the JDBC {@link java.sql.Connection} object
+ *     </li>
+ * </ul>
+ *
+ * The corresponding concrete TransactionCoordinator implementations manage that bridging internally.
+ *
+ * <h2>Local Synchronization</h2>
+ *
+ * The Hibernate transaction api allows the application itself to register JTA Synchronization
+ * objects with the TransactionCoordinator.  These local Synchronizations work in all transaction
+ * environments.  See {@link org.hibernate.Transaction#registerSynchronization} and
+ * {@link org.hibernate.resource.transaction.SynchronizationRegistry} for additional details.
+ *
+ */
+package org.hibernate.resource.transaction;
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/spi/SynchronizationRegistryImplementor.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/spi/SynchronizationRegistryImplementor.java
new file mode 100644
index 0000000000..afe7b7379a
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/spi/SynchronizationRegistryImplementor.java
@@ -0,0 +1,52 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction.spi;
+
+import org.hibernate.resource.transaction.SynchronizationRegistry;
+
+/**
+ * SPI contract for SynchronizationRegistry implementors.
+ *
+ * @author Steve Ebersole
+ */
+public interface SynchronizationRegistryImplementor extends SynchronizationRegistry {
+	/**
+	 * Delegates the {@link javax.transaction.Synchronization#beforeCompletion} call to each registered Synchronization
+	 */
+	void notifySynchronizationsBeforeTransactionCompletion();
+
+	/**
+	 * Delegates the {@link javax.transaction.Synchronization#afterCompletion} call to each registered Synchronization.  Will also
+	 * clear the registered Synchronizations after all have been notified.
+	 *
+	 * @param status The transaction status, per {@link javax.transaction.Status} constants
+	 */
+	void notifySynchronizationsAfterTransactionCompletion(int status);
+
+	/**
+	 * Clears all synchronizations from this registry.  Note that synchronizations are automatically cleared during
+	 * after-completion handling; see {@link #notifySynchronizationsAfterTransactionCompletion}
+	 */
+	void clearSynchronizations();
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/spi/TransactionCoordinatorOwner.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/spi/TransactionCoordinatorOwner.java
new file mode 100644
index 0000000000..b7607d35d9
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/spi/TransactionCoordinatorOwner.java
@@ -0,0 +1,75 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction.spi;
+
+import org.hibernate.resource.jdbc.spi.JdbcSessionOwner;
+
+/**
+ * Models an owner of a TransactionCoordinator.  Mainly used in 2 ways:<ul>
+ *     <li>
+ *         First to allow the coordinator to determine if its owner is still active (open, etc).
+ *     </li>
+ *     <li>
+ *         Second is to allow the coordinator to dispatch before and after completion events to the owner
+ *     </li>
+ * </ul>
+ *
+ * @author Steve Ebersole
+ */
+public interface TransactionCoordinatorOwner {
+	/**
+	 * Is the TransactionCoordinator owner considered active?
+	 *
+	 * @return {@code true} indicates the owner is still active; {@code false} indicates it is not.
+	 */
+	public boolean isActive();
+
+	/**
+	 * A after-begin callback from the coordinator to its owner.
+	 */
+	public void afterTransactionBegin();
+
+	/**
+	 * A before-completion callback from the coordinator to its owner.
+	 */
+	public void beforeTransactionCompletion();
+
+	/**
+	 * An after-completion callback from the coordinator to its owner.
+	 *
+	 * @param successful Was the transaction successful?
+	 */
+	public void afterTransactionCompletion(boolean successful);
+
+	public JdbcSessionOwner getJdbcSessionOwner();
+
+	/**
+	 * Set the effective transaction timeout period for the current transaction, in seconds.
+	 *
+	 * @param seconds The number of seconds before a time out should occur.
+	 */
+	public void setTransactionTimeOut(int seconds);
+
+	public void flushBeforeTransactionCompletion();
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/spi/TransactionStatus.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/spi/TransactionStatus.java
new file mode 100644
index 0000000000..db4f419927
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/spi/TransactionStatus.java
@@ -0,0 +1,67 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) {DATE}, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+package org.hibernate.resource.transaction.spi;
+
+/**
+ * Enumeration of statuses in which a transaction facade ({@link org.hibernate.Transaction}) might be.
+ *
+ * @author Andrea Boriero
+ */
+public enum TransactionStatus {
+	/**
+	 * The transaction has not yet been begun
+	 */
+	NOT_ACTIVE,
+	/**
+	 * The transaction has been begun, but not yet completed.
+	 */
+	ACTIVE,
+	/**
+	 * The transaction has been competed successfully.
+	 */
+	COMMITTED,
+	/**
+	 * The transaction has been rolled back.
+	 */
+	ROLLED_BACK,
+	/**
+	 * The transaction  has been marked for  rollback only.
+	 */
+	MARKED_ROLLBACK,
+	/**
+	 * The transaction attempted to commit, but failed.
+	 */
+	FAILED_COMMIT,
+	/**
+	 * Status code indicating a transaction that has begun the second
+	 * phase of the two-phase commit protocol, but not yet completed
+	 * this phase
+	 */
+	COMMITTING,
+	/**
+	 *  Status code indicating a transaction that is in the process of
+	 *  rolling back.
+	 */
+	 ROLLING_BACK
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/resource/transaction/spi/package-info.java b/hibernate-core/src/main/java/org/hibernate/resource/transaction/spi/package-info.java
new file mode 100644
index 0000000000..08ac3656d4
--- /dev/null
+++ b/hibernate-core/src/main/java/org/hibernate/resource/transaction/spi/package-info.java
@@ -0,0 +1,28 @@
+/*
+ * Hibernate, Relational Persistence for Idiomatic Java
+ *
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+ * indicated by the @author tags or express copyright attribution
+ * statements applied by the authors.  All third-party contributions are
+ * distributed under license by Red Hat Inc.
+ *
+ * This copyrighted material is made available to anyone wishing to use, modify,
+ * copy, or redistribute it subject to the terms and conditions of the GNU
+ * Lesser General Public License, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public License
+ * along with this distribution; if not, write to:
+ * Free Software Foundation, Inc.
+ * 51 Franklin Street, Fifth Floor
+ * Boston, MA  02110-1301  USA
+ */
+
+/**
+ * Extended SPI contracts for the resource-level transaction capabilities of Hibernate.
+ */
+package org.hibernate.resource.transaction.spi;
diff --git a/hibernate-core/src/main/java/org/hibernate/service/StandardServiceInitiators.java b/hibernate-core/src/main/java/org/hibernate/service/StandardServiceInitiators.java
index 264814661b..2c6b0d13c6 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/StandardServiceInitiators.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/StandardServiceInitiators.java
@@ -1,103 +1,104 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service;
 
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
 
 import org.hibernate.boot.cfgxml.internal.CfgXmlAccessServiceInitiator;
 import org.hibernate.boot.registry.StandardServiceInitiator;
 import org.hibernate.cache.internal.RegionFactoryInitiator;
 import org.hibernate.engine.config.internal.ConfigurationServiceInitiator;
 import org.hibernate.engine.jdbc.batch.internal.BatchBuilderInitiator;
 import org.hibernate.engine.jdbc.connections.internal.ConnectionProviderInitiator;
 import org.hibernate.engine.jdbc.connections.internal.MultiTenantConnectionProviderInitiator;
 import org.hibernate.engine.jdbc.cursor.internal.RefCursorSupportInitiator;
 import org.hibernate.engine.jdbc.dialect.internal.DialectFactoryInitiator;
 import org.hibernate.engine.jdbc.dialect.internal.DialectResolverInitiator;
 import org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator;
 import org.hibernate.engine.jdbc.internal.JdbcServicesInitiator;
 import org.hibernate.engine.jndi.internal.JndiServiceInitiator;
-import org.hibernate.engine.transaction.internal.TransactionFactoryInitiator;
 import org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator;
 import org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformResolverInitiator;
 import org.hibernate.hql.internal.QueryTranslatorFactoryInitiator;
 import org.hibernate.id.factory.internal.MutableIdentifierGeneratorFactoryInitiator;
 import org.hibernate.jmx.internal.JmxServiceInitiator;
 import org.hibernate.persister.internal.PersisterClassResolverInitiator;
 import org.hibernate.persister.internal.PersisterFactoryInitiator;
+import org.hibernate.resource.transaction.internal.TransactionCoordinatorBuilderInitiator;
 import org.hibernate.service.internal.SessionFactoryServiceRegistryFactoryInitiator;
 import org.hibernate.tool.hbm2ddl.ImportSqlCommandExtractorInitiator;
 import org.hibernate.tool.schema.internal.SchemaManagementToolInitiator;
 
 /**
  * Central definition of the standard set of service initiators defined by Hibernate.
  * 
  * @author Steve Ebersole
  */
 public final class StandardServiceInitiators {
 	private StandardServiceInitiators() {
 	}
 
 	public static List<StandardServiceInitiator> LIST = buildStandardServiceInitiatorList();
 
 	private static List<StandardServiceInitiator> buildStandardServiceInitiatorList() {
 		final List<StandardServiceInitiator> serviceInitiators = new ArrayList<StandardServiceInitiator>();
 
 		serviceInitiators.add( CfgXmlAccessServiceInitiator.INSTANCE );
 		serviceInitiators.add( ConfigurationServiceInitiator.INSTANCE );
 
 		serviceInitiators.add( ImportSqlCommandExtractorInitiator.INSTANCE );
 		serviceInitiators.add( SchemaManagementToolInitiator.INSTANCE );
 
 		serviceInitiators.add( JdbcEnvironmentInitiator.INSTANCE );
 		serviceInitiators.add( JndiServiceInitiator.INSTANCE );
 		serviceInitiators.add( JmxServiceInitiator.INSTANCE );
 
 		serviceInitiators.add( PersisterClassResolverInitiator.INSTANCE );
 		serviceInitiators.add( PersisterFactoryInitiator.INSTANCE );
 
 		serviceInitiators.add( ConnectionProviderInitiator.INSTANCE );
 		serviceInitiators.add( MultiTenantConnectionProviderInitiator.INSTANCE );
 		serviceInitiators.add( DialectResolverInitiator.INSTANCE );
 		serviceInitiators.add( DialectFactoryInitiator.INSTANCE );
 		serviceInitiators.add( BatchBuilderInitiator.INSTANCE );
 		serviceInitiators.add( JdbcServicesInitiator.INSTANCE );
 		serviceInitiators.add( RefCursorSupportInitiator.INSTANCE );
 
 		serviceInitiators.add( QueryTranslatorFactoryInitiator.INSTANCE );
 		serviceInitiators.add( MutableIdentifierGeneratorFactoryInitiator.INSTANCE);
 
 		serviceInitiators.add( JtaPlatformResolverInitiator.INSTANCE );
 		serviceInitiators.add( JtaPlatformInitiator.INSTANCE );
-		serviceInitiators.add( TransactionFactoryInitiator.INSTANCE );
 
 		serviceInitiators.add( SessionFactoryServiceRegistryFactoryInitiator.INSTANCE );
 
 		serviceInitiators.add( RegionFactoryInitiator.INSTANCE );
 
+		serviceInitiators.add( TransactionCoordinatorBuilderInitiator.INSTANCE );
+
 		return Collections.unmodifiableList( serviceInitiators );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/DbTimestampType.java b/hibernate-core/src/main/java/org/hibernate/type/DbTimestampType.java
index 80ad9db39d..8263427bf3 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/DbTimestampType.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/DbTimestampType.java
@@ -1,144 +1,146 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.sql.CallableStatement;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Timestamp;
 import java.util.Date;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreMessageLogger;
 
 import org.jboss.logging.Logger;
 
 /**
  * <tt>dbtimestamp</tt>: An extension of {@link TimestampType} which
  * maps to the database's current timestamp, rather than the jvm's
  * current timestamp.
  * <p/>
  * Note: May/may-not cause issues on dialects which do not properly support
  * a true notion of timestamp (Oracle < 8, for example, where only its DATE
  * datatype is supported).  Depends on the frequency of DML operations...
  *
  * @author Steve Ebersole
  */
 public class DbTimestampType extends TimestampType {
 	public static final DbTimestampType INSTANCE = new DbTimestampType();
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, DbTimestampType.class.getName() );
 
 	@Override
 	public String getName() {
 		return "dbtimestamp";
 	}
 
 	@Override
 	public String[] getRegistrationKeys() {
 		return new String[] { getName() };
 	}
 
 	@Override
 	public Date seed(SessionImplementor session) {
 		if ( session == null ) {
 			LOG.trace( "Incoming session was null; using current jvm time" );
 			return super.seed( session );
 		}
 		else if ( !session.getFactory().getDialect().supportsCurrentTimestampSelection() ) {
 			LOG.debug( "Falling back to vm-based timestamp, as dialect does not support current timestamp selection" );
 			return super.seed( session );
 		}
 		else {
 			return getCurrentTimestamp( session );
 		}
 	}
 
 	private Date getCurrentTimestamp(SessionImplementor session) {
 		Dialect dialect = session.getFactory().getDialect();
 		String timestampSelectString = dialect.getCurrentTimestampSelectString();
         if (dialect.isCurrentTimestampSelectStringCallable()) return useCallableStatement(timestampSelectString, session);
         return usePreparedStatement(timestampSelectString, session);
 	}
 
 	private Timestamp usePreparedStatement(String timestampSelectString, SessionImplementor session) {
 		PreparedStatement ps = null;
 		try {
-			ps = session.getTransactionCoordinator()
+			ps = session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( timestampSelectString, false );
-			ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( ps );
+			ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract( ps );
 			rs.next();
 			Timestamp ts = rs.getTimestamp( 1 );
 			if ( LOG.isTraceEnabled() ) {
 				LOG.tracev( "Current timestamp retreived from db : {0} (nanos={1}, time={2})", ts, ts.getNanos(), ts.getTime() );
 			}
 			return ts;
 		}
 		catch( SQLException e ) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 			        e,
 			        "could not select current db timestamp",
 			        timestampSelectString
 			);
 		}
 		finally {
 			if ( ps != null ) {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
+				session.getJdbcCoordinator().getResourceRegistry().release( ps );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 	}
 
 	private Timestamp useCallableStatement(String callString, SessionImplementor session) {
 		CallableStatement cs = null;
 		try {
-			cs = (CallableStatement) session.getTransactionCoordinator()
+			cs = (CallableStatement) session
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( callString, true );
 			cs.registerOutParameter( 1, java.sql.Types.TIMESTAMP );
-			session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().execute( cs );
+			session.getJdbcCoordinator().getResultSetReturn().execute( cs );
 			Timestamp ts = cs.getTimestamp( 1 );
 			if ( LOG.isTraceEnabled() ) {
 				LOG.tracev( "Current timestamp retreived from db : {0} (nanos={1}, time={2})", ts, ts.getNanos(), ts.getTime() );
 			}
 			return ts;
 		}
 		catch( SQLException e ) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 			        e,
 			        "could not call current db timestamp function",
 			        callString
 			);
 		}
 		finally {
 			if ( cs != null ) {
-				session.getTransactionCoordinator().getJdbcCoordinator().release( cs );
+				session.getJdbcCoordinator().getResourceRegistry().release( cs );
+				session.getJdbcCoordinator().afterStatementExecution();
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/id/SequenceHiLoGeneratorNoIncrementTest.java b/hibernate-core/src/test/java/org/hibernate/id/SequenceHiLoGeneratorNoIncrementTest.java
index 40446d9cbb..c88c32dfe3 100644
--- a/hibernate-core/src/test/java/org/hibernate/id/SequenceHiLoGeneratorNoIncrementTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/id/SequenceHiLoGeneratorNoIncrementTest.java
@@ -1,187 +1,187 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Collections;
 import java.util.Properties;
 
 import org.hibernate.Session;
 import org.hibernate.boot.Metadata;
 import org.hibernate.boot.MetadataSources;
 import org.hibernate.boot.model.naming.ObjectNameNormalizer;
 import org.hibernate.boot.model.relational.SimpleAuxiliaryDatabaseObject;
 import org.hibernate.boot.registry.StandardServiceRegistry;
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.boot.spi.MetadataBuildingContext;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.SessionImpl;
 import org.hibernate.jdbc.Work;
 import org.hibernate.type.StandardBasicTypes;
 
 import org.hibernate.testing.env.TestingDatabaseInfo;
 import org.hibernate.testing.junit4.BaseUnitTestCase;
 import org.hibernate.test.common.BasicTestingJdbcServiceImpl;
 import org.hibernate.test.common.MetadataBuildingContextTestingImpl;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 
 /**
  * I went back to 3.3 source and grabbed the code/logic as it existed back then and crafted this
  * unit test so that we can make sure the value keep being generated in the expected manner
  *
  * @author Steve Ebersole
  */
 @SuppressWarnings({ "deprecation" })
 public class SequenceHiLoGeneratorNoIncrementTest extends BaseUnitTestCase {
 	private static final String TEST_SEQUENCE = "test_sequence";
 
 	private StandardServiceRegistry serviceRegistry;
 	private SessionFactoryImplementor sessionFactory;
 	private SequenceHiLoGenerator generator;
     private SessionImplementor session;
 
 	@Before
 	public void setUp() throws Exception {
 		BasicTestingJdbcServiceImpl jdbcServices = new BasicTestingJdbcServiceImpl();
 		jdbcServices.prepare( false );
 
 		serviceRegistry = new StandardServiceRegistryBuilder()
 				.enableAutoClose()
 				.addService( JdbcEnvironment.class, jdbcServices.getJdbcEnvironment() )
 				.addService( JdbcServices.class, jdbcServices )
 				.applySetting( AvailableSettings.HBM2DDL_AUTO, "create-drop" )
 				.build();
 
 		generator = new SequenceHiLoGenerator();
 
 		// Build the properties used to configure the id generator
 		Properties properties = new Properties();
 		properties.setProperty( SequenceGenerator.SEQUENCE, TEST_SEQUENCE );
 		properties.setProperty( SequenceHiLoGenerator.MAX_LO, "0" ); // JPA allocationSize of 1
 		properties.put(
 				PersistentIdentifierGenerator.IDENTIFIER_NORMALIZER,
 				new ObjectNameNormalizer() {
 					@Override
 					protected MetadataBuildingContext getBuildingContext() {
 						return new MetadataBuildingContextTestingImpl( serviceRegistry );
 					}
 				}
 		);
 		generator.configure( StandardBasicTypes.LONG, properties, jdbcServices.getJdbcEnvironment() );
 
 		final Metadata metadata = new MetadataSources( serviceRegistry ).buildMetadata();
 		metadata.getDatabase().addAuxiliaryDatabaseObject(
 				new SimpleAuxiliaryDatabaseObject(
 						Collections.<String>emptySet(),
 						null,
 						null,
 						generator.sqlCreateStrings( TestingDatabaseInfo.DIALECT ),
 						generator.sqlDropStrings( TestingDatabaseInfo.DIALECT )
 				)
 		);
 
 		sessionFactory = (SessionFactoryImplementor) metadata.buildSessionFactory();
 	}
 
 	@After
 	public void tearDown() throws Exception {
         if(session != null && !session.isClosed()) {
             ((Session)session).close();
         }
 		if ( sessionFactory != null ) {
 			sessionFactory.close();
 		}
 		if ( serviceRegistry != null ) {
 			StandardServiceRegistryBuilder.destroy( serviceRegistry );
 		}
 	}
 
 	@Test
 	public void testHiLoAlgorithm() {
 		session = (SessionImpl) sessionFactory.openSession();
 		((Session)session).beginTransaction();
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// initially sequence should be uninitialized
 		assertEquals( 0L, extractSequenceValue( (session) ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// historically the hilo generators skipped the initial block of values;
 		// 		so the first generated id value is maxlo + 1, here be 4
 		Long generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 1L, generatedValue.longValue() );
 		// which should also perform the first read on the sequence which should set it to its "start with" value (1)
 		assertEquals( 1L, extractSequenceValue( (session) ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 2L, generatedValue.longValue() );
 		assertEquals( 2L, extractSequenceValue( (session) ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 3L, generatedValue.longValue() );
 		assertEquals( 3L, extractSequenceValue( (session) ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 4L, generatedValue.longValue() );
 		assertEquals( 4L, extractSequenceValue( (session) ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 5L, generatedValue.longValue() );
 		assertEquals( 5L, extractSequenceValue( (session) ) );
 
 		((Session)session).getTransaction().commit();
 		((Session)session).close();
 	}
 
 	private long extractSequenceValue(final SessionImplementor session) {
 		class WorkImpl implements Work {
 			private long value;
 			public void execute(Connection connection) throws SQLException {
 				
-				PreparedStatement query = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( "select currval('" + TEST_SEQUENCE + "');" );
-				ResultSet resultSet = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( query );
+				PreparedStatement query = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( "select currval('" + TEST_SEQUENCE + "');" );
+				ResultSet resultSet = session.getJdbcCoordinator().getResultSetReturn().extract( query );
 				resultSet.next();
 				value = resultSet.getLong( 1 );
 			}
 		}
 		WorkImpl work = new WorkImpl();
 		( (Session) session ).doWork( work );
 		return work.value;
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/id/SequenceHiLoGeneratorTest.java b/hibernate-core/src/test/java/org/hibernate/id/SequenceHiLoGeneratorTest.java
index f3ac143852..02b6da1834 100644
--- a/hibernate-core/src/test/java/org/hibernate/id/SequenceHiLoGeneratorTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/id/SequenceHiLoGeneratorTest.java
@@ -1,160 +1,160 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Properties;
 
 import org.hibernate.Session;
 import org.hibernate.boot.Metadata;
 import org.hibernate.boot.MetadataSources;
 import org.hibernate.boot.registry.StandardServiceRegistry;
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.boot.spi.MetadataBuildingContext;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.SessionImpl;
 import org.hibernate.jdbc.Work;
 import org.hibernate.type.StandardBasicTypes;
 
 import org.hibernate.testing.junit4.BaseUnitTestCase;
 import org.hibernate.test.common.MetadataBuildingContextTestingImpl;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 
 /**
  * I went back to 3.3 source and grabbed the code/logic as it existed back then and crafted this
  * unit test so that we can make sure the value keep being generated in the expected manner
  * 
  * @author Steve Ebersole
  */
 @SuppressWarnings({ "deprecation" })
 public class SequenceHiLoGeneratorTest extends BaseUnitTestCase {
 	private static final String TEST_SEQUENCE = "test_sequence";
 
 	private StandardServiceRegistry serviceRegistry;
 	private SessionFactoryImplementor sessionFactory;
 	private SequenceHiLoGenerator generator;
 
 	@Before
 	public void setUp() throws Exception {
 		serviceRegistry = new StandardServiceRegistryBuilder()
 				.enableAutoClose()
 				.applySetting( AvailableSettings.HBM2DDL_AUTO, "create-drop" )
 				.build();
 
 		MetadataBuildingContext buildingContext = new MetadataBuildingContextTestingImpl( serviceRegistry );
 
 		Properties properties = new Properties();
 		properties.setProperty( SequenceGenerator.SEQUENCE, TEST_SEQUENCE );
 		properties.setProperty( SequenceHiLoGenerator.MAX_LO, "3" );
 		properties.put( PersistentIdentifierGenerator.IDENTIFIER_NORMALIZER, buildingContext.getObjectNameNormalizer() );
 
 		generator = new SequenceHiLoGenerator();
 		generator.configure( StandardBasicTypes.LONG, properties, serviceRegistry.getService( JdbcEnvironment.class ) );
 
 		Metadata metadata = new MetadataSources( serviceRegistry ).buildMetadata();
 		generator.registerExportables( metadata.getDatabase() );
 
 		sessionFactory = (SessionFactoryImplementor) metadata.buildSessionFactory();
 	}
 
 	@After
 	public void tearDown() throws Exception {
 		if ( sessionFactory != null ) {
 			sessionFactory.close();
 		}
 		if ( serviceRegistry != null ) {
 			StandardServiceRegistryBuilder.destroy( serviceRegistry );
 		}
 	}
 
 	@Test
 	public void testHiLoAlgorithm() {
 		SessionImpl session = (SessionImpl) sessionFactory.openSession();
 		session.beginTransaction();
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// initially sequence should be uninitialized
 		assertEquals( 0L, extractSequenceValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// historically the hilo generators skipped the initial block of values;
 		// so the first generated id value is maxlo + 1, here be 4
 		Long generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 4L, generatedValue.longValue() );
 		// which should also perform the first read on the sequence which should set it to its "start with" value (1)
 		assertEquals( 1L, extractSequenceValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 5L, generatedValue.longValue() );
 		assertEquals( 1L, extractSequenceValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 6L, generatedValue.longValue() );
 		assertEquals( 1L, extractSequenceValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 7L, generatedValue.longValue() );
 		// unlike the newer strategies, the db value will not get update here. It gets updated on the next invocation
 		// after a clock over
 		assertEquals( 1L, extractSequenceValue( session ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		generatedValue = (Long) generator.generate( session, null );
 		assertEquals( 8L, generatedValue.longValue() );
 		// this should force an increment in the sequence value
 		assertEquals( 2L, extractSequenceValue( session ) );
 
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	private long extractSequenceValue(final SessionImplementor session) {
 		class WorkImpl implements Work {
 			private long value;
 
 			public void execute(Connection connection) throws SQLException {
-				PreparedStatement query = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( "select currval('" + TEST_SEQUENCE + "');" );
-				ResultSet resultSet = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( query );
+				PreparedStatement query = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( "select currval('" + TEST_SEQUENCE + "');" );
+				ResultSet resultSet = session.getJdbcCoordinator().getResultSetReturn().extract( query );
 				resultSet.next();
 				value = resultSet.getLong( 1 );
 			}
 		}
 		WorkImpl work = new WorkImpl();
 		( (Session) session ).doWork( work );
 		return work.value;
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/sharedSession/SessionWithSharedConnectionTest.java b/hibernate-core/src/test/java/org/hibernate/sharedSession/SessionWithSharedConnectionTest.java
index 08e359b9ad..1cecb935c1 100644
--- a/hibernate-core/src/test/java/org/hibernate/sharedSession/SessionWithSharedConnectionTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/sharedSession/SessionWithSharedConnectionTest.java
@@ -1,314 +1,268 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.sharedSession;
 
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.assertSame;
-import static org.junit.Assert.assertTrue;
-
-import java.lang.reflect.Field;
-import java.util.List;
-
 import org.hibernate.IrrelevantEntity;
 import org.hibernate.Session;
 import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl;
-import org.hibernate.engine.transaction.spi.TransactionContext;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.event.service.spi.EventListenerRegistry;
 import org.hibernate.event.spi.EventType;
 import org.hibernate.event.spi.PostInsertEvent;
 import org.hibernate.event.spi.PostInsertEventListener;
 import org.hibernate.persister.entity.EntityPersister;
+
+import org.junit.Test;
+
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
-import org.junit.Test;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertSame;
+import static org.junit.Assert.assertTrue;
 
 /**
  * @author Steve Ebersole
  */
 public class SessionWithSharedConnectionTest extends BaseCoreFunctionalTestCase {
 	@Test
 	@TestForIssue( jiraKey = "HHH-7090" )
 	public void testSharedTransactionContextSessionClosing() {
 		Session session = sessionFactory().openSession();
 		session.getTransaction().begin();
 
 		Session secondSession = session.sessionWithOptions()
 				.transactionContext()
 				.openSession();
 		secondSession.createCriteria( IrrelevantEntity.class ).list();
 
 		//the list should have registered and then released a JDBC resource
 		assertFalse(
-				((SessionImplementor) secondSession).getTransactionCoordinator()
+				((SessionImplementor) secondSession)
 						.getJdbcCoordinator()
+						.getResourceRegistry()
 						.hasRegisteredResources()
 		);
 
 		assertTrue( session.isOpen() );
 		assertTrue( secondSession.isOpen() );
 
 		assertSame( session.getTransaction(), secondSession.getTransaction() );
 
 		session.getTransaction().commit();
 
 		assertTrue( session.isOpen() );
 		assertTrue( secondSession.isOpen() );
 
 		secondSession.close();
 		assertTrue( session.isOpen() );
 		assertFalse( secondSession.isOpen() );
 
 		session.close();
 		assertFalse( session.isOpen() );
 		assertFalse( secondSession.isOpen() );
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-7090" )
 	public void testSharedTransactionContextAutoClosing() {
 		Session session = sessionFactory().openSession();
 		session.getTransaction().begin();
 
 		// COMMIT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		Session secondSession = session.sessionWithOptions()
 				.transactionContext()
 				.autoClose( true )
 				.openSession();
 
 		// directly assert state of the second session
-		assertTrue( ((TransactionContext) secondSession).isAutoCloseSessionEnabled() );
-		assertTrue( ((TransactionContext) secondSession).shouldAutoClose() );
+		assertTrue( ((SessionImplementor) secondSession).isAutoCloseSessionEnabled() );
+		assertTrue( ((SessionImplementor) secondSession).shouldAutoClose() );
 
 		// now commit the transaction and make sure that does not close the sessions
 		session.getTransaction().commit();
 		assertFalse( ((SessionImplementor) session).isClosed() );
 		assertTrue( ((SessionImplementor) secondSession).isClosed() );
 
 		session.close();
 		assertTrue( ((SessionImplementor) session).isClosed() );
 		assertTrue( ((SessionImplementor) secondSession).isClosed() );
 
 
 		// ROLLBACK ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		session = sessionFactory().openSession();
 		session.getTransaction().begin();
 
 		secondSession = session.sessionWithOptions()
 				.transactionContext()
 				.autoClose( true )
 				.openSession();
 
 		// directly assert state of the second session
-		assertTrue( ((TransactionContext) secondSession).isAutoCloseSessionEnabled() );
-		assertTrue( ((TransactionContext) secondSession).shouldAutoClose() );
+		assertTrue( ((SessionImplementor) secondSession).isAutoCloseSessionEnabled() );
+		assertTrue( ((SessionImplementor) secondSession).shouldAutoClose() );
 
 		// now rollback the transaction and make sure that does not close the sessions
 		session.getTransaction().rollback();
 		assertFalse( ((SessionImplementor) session).isClosed() );
 		assertTrue( ((SessionImplementor) secondSession).isClosed() );
 
 		session.close();
 		assertTrue( ((SessionImplementor) session).isClosed() );
 		assertTrue( ((SessionImplementor) secondSession).isClosed() );
 
 	}
 
-	@Test
-	@TestForIssue( jiraKey = "HHH-7090" )
-	public void testSharedTransactionContextAutoJoining() {
-		Session session = sessionFactory().openSession();
-		session.getTransaction().begin();
-
-		Session secondSession = session.sessionWithOptions()
-				.transactionContext()
-				.autoJoinTransactions( true )
-				.openSession();
-
-		// directly assert state of the second session
-		assertFalse( ((TransactionContext) secondSession).shouldAutoJoinTransaction() );
-
-		secondSession.close();
-		session.close();
-	}
+//	@Test
+//	@TestForIssue( jiraKey = "HHH-7090" )
+//	public void testSharedTransactionContextAutoJoining() {
+//		Session session = sessionFactory().openSession();
+//		session.getTransaction().begin();
+//
+//		Session secondSession = session.sessionWithOptions()
+//				.transactionContext()
+//				.autoJoinTransactions( true )
+//				.openSession();
+//
+//		// directly assert state of the second session
+//		assertFalse( ((SessionImplementor) secondSession).shouldAutoJoinTransaction() );
+//
+//		secondSession.close();
+//		session.close();
+//	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-7090" )
 	public void testSharedTransactionContextFlushBeforeCompletion() {
 		Session session = sessionFactory().openSession();
 		session.getTransaction().begin();
 
 		Session secondSession = session.sessionWithOptions()
 				.transactionContext()
 				.flushBeforeCompletion( true )
 				.autoClose( true )
 				.openSession();
 
 		// directly assert state of the second session
-		assertTrue( ((TransactionContext) secondSession).isFlushBeforeCompletionEnabled() );
+//		assertTrue( ((SessionImplementor) secondSession).isFlushBeforeCompletionEnabled() );
 
 		// now try it out
 		Integer id = (Integer) secondSession.save( new IrrelevantEntity() );
 		session.getTransaction().commit();
 		assertFalse( ((SessionImplementor) session).isClosed() );
 		assertTrue( ((SessionImplementor) secondSession).isClosed() );
 
 		session.close();
 		assertTrue( ((SessionImplementor) session).isClosed() );
 		assertTrue( ((SessionImplementor) secondSession).isClosed() );
 
 		session = sessionFactory().openSession();
 		session.getTransaction().begin();
 		IrrelevantEntity it = (IrrelevantEntity) session.byId( IrrelevantEntity.class ).load( id );
 		assertNotNull( it );
 		session.delete( it );
 		session.getTransaction().commit();
 		session.close();
 	}
 	
 	@Test
 	@TestForIssue( jiraKey = "HHH-7239" )
-	public void testSessionRemovedFromObserversOnClose() throws Exception {
-		Session session = sessionFactory().openSession();
-		session.getTransaction().begin();
-
-		//get the initial count of observers (use reflection as the observers property isn't exposed) 
-		Field field = TransactionCoordinatorImpl.class.getDeclaredField( "observers" );
-		field.setAccessible(true);
-		List observers = (List) field.get( ( ( SessionImplementor ) session ).getTransactionCoordinator() );
-		int originalObserverSize = observers.size();
-		
-		//opening 2nd session registers it with the TransactionCoordinator currently as an observer
-		Session secondSession = session.sessionWithOptions()
-				.connection()
-				.flushBeforeCompletion( false )
-				.autoClose( false )
-				.openSession();
-		
-		observers = (List) field.get( ( ( SessionImplementor ) session ).getTransactionCoordinator() );
-		//the observer size should be larger
-		final int observerSizeWithSecondSession = observers.size();
-		assertTrue( observerSizeWithSecondSession > originalObserverSize);
-
-		//don't need to actually even do anything with the 2nd session
-		secondSession.close();
-		
-		//the second session should be released from the observers on close since it didn't have any after transaction actions
-		observers = (List) field.get( ( ( SessionImplementor ) session ).getTransactionCoordinator() );
-
-		assertEquals( originalObserverSize, observers.size() );
-
-		//store the transaction coordinator here since it's not available after session close
-		TransactionCoordinator transactionCoordinator = ((SessionImplementor) session).getTransactionCoordinator();
-		
-		session.getTransaction().commit();
-		session.close();
-		
-		//on original session close all observers should be released
-		observers = (List) field.get( transactionCoordinator );
-		assertEquals( 0, observers.size() );
-	}
-
-	@Test
-	@TestForIssue( jiraKey = "HHH-7239" )
 	public void testChildSessionCallsAfterTransactionAction() throws Exception {
 		Session session = openSession();
 
 		final String postCommitMessage = "post commit was called";
 		
 		EventListenerRegistry eventListenerRegistry = sessionFactory().getServiceRegistry().getService(EventListenerRegistry.class);
 		//register a post commit listener
 		eventListenerRegistry.appendListeners(
 				EventType.POST_COMMIT_INSERT,
 				new PostInsertEventListener() {
 					@Override
 					public void onPostInsert(PostInsertEvent event) {
 						((IrrelevantEntity) event.getEntity()).setName( postCommitMessage );
 					}
 
 					@Override
 					public boolean requiresPostCommitHanding(EntityPersister persister) {
 						return true;
 					}
 				}
 		);
 		
 		session.getTransaction().begin();
 		
 		IrrelevantEntity irrelevantEntityMainSession = new IrrelevantEntity();
 		irrelevantEntityMainSession.setName( "main session" );
 		session.save( irrelevantEntityMainSession );
 		
 		//open secondary session to also insert an entity
 		Session secondSession = session.sessionWithOptions()
 				.connection()
 				.flushBeforeCompletion( true )
 				.autoClose( true )
 				.openSession();
 
 		IrrelevantEntity irrelevantEntitySecondarySession = new IrrelevantEntity();
 		irrelevantEntitySecondarySession.setName( "secondary session" );
 		secondSession.save( irrelevantEntitySecondarySession );
 
 		session.getTransaction().commit();
 		
 		//both entities should have their names updated to the postCommitMessage value
 		assertEquals(postCommitMessage, irrelevantEntityMainSession.getName());
 		assertEquals(postCommitMessage, irrelevantEntitySecondarySession.getName());
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-7239" )
 	public void testChildSessionTwoTransactions() throws Exception {
 		Session session = openSession();
 		
 		session.getTransaction().begin();
 		
 		//open secondary session with managed options
 		Session secondarySession = session.sessionWithOptions()
 				.connection()
 				.flushBeforeCompletion( true )
 				.autoClose( true )
 				.openSession();
 		
 		//the secondary session should be automatically closed after the commit
 		session.getTransaction().commit();
 		
 		assertFalse( secondarySession.isOpen() );
 
 		//should be able to create a new transaction and carry on using the original session
 		session.getTransaction().begin();
 		session.getTransaction().commit();
 	}
 	
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[] { IrrelevantEntity.class };
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/EntityTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/EntityTest.java
index c4e8a8444e..f9f5291bc1 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/EntityTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/EntityTest.java
@@ -1,458 +1,467 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations;
 
 import java.text.DateFormat;
 import java.text.SimpleDateFormat;
 import java.util.Date;
 import java.util.GregorianCalendar;
 import java.util.List;
 import java.util.TimeZone;
 
 import org.hibernate.HibernateException;
 import org.hibernate.Query;
 import org.hibernate.Session;
 import org.hibernate.StaleStateException;
 import org.hibernate.Transaction;
+import org.hibernate.TransactionException;
 import org.hibernate.boot.MetadataBuilder;
 import org.hibernate.boot.model.naming.ImplicitNamingStrategyJpaCompliantImpl;
 import org.hibernate.dialect.Oracle10gDialect;
 import org.hibernate.tool.hbm2ddl.SchemaExport;
 import org.hibernate.type.StandardBasicTypes;
 
 import org.hibernate.testing.SkipForDialect;
 import org.hibernate.testing.junit4.BaseNonConfigCoreFunctionalTestCase;
+
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author Emmanuel Bernard
  */
 public class EntityTest extends BaseNonConfigCoreFunctionalTestCase {
-	private DateFormat df = SimpleDateFormat.getDateTimeInstance(DateFormat.LONG, DateFormat.LONG);
+	private DateFormat df = SimpleDateFormat.getDateTimeInstance( DateFormat.LONG, DateFormat.LONG );
 
 	@Override
 	protected void configureMetadataBuilder(MetadataBuilder metadataBuilder) {
 		super.configureMetadataBuilder( metadataBuilder );
 		metadataBuilder.applyImplicitNamingStrategy( ImplicitNamingStrategyJpaCompliantImpl.INSTANCE );
 	}
 
 	@Test
 	public void testLoad() throws Exception {
 		//put an object in DB
 		assertEquals( "Flight", metadata().getEntityBinding( Flight.class.getName() ).getTable().getName() );
 
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Flight firstOne = new Flight();
 		firstOne.setId( Long.valueOf( 1 ) );
 		firstOne.setName( "AF3202" );
 		firstOne.setDuration( new Long( 1000000 ) );
 		firstOne.setDurationInSec( 2000 );
 		s.save( firstOne );
 		s.flush();
 		tx.commit();
 		s.close();
 
 		//read it
 		s = openSession();
 		tx = s.beginTransaction();
 		firstOne = (Flight) s.get( Flight.class, Long.valueOf( 1 ) );
 		assertNotNull( firstOne );
 		assertEquals( Long.valueOf( 1 ), firstOne.getId() );
 		assertEquals( "AF3202", firstOne.getName() );
 		assertEquals( Long.valueOf( 1000000 ), firstOne.getDuration() );
 		assertFalse( "Transient is not working", 2000l == firstOne.getDurationInSec() );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testColumn() throws Exception {
 		//put an object in DB
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Flight firstOne = new Flight();
 		firstOne.setId( Long.valueOf( 1 ) );
 		firstOne.setName( "AF3202" );
 		firstOne.setDuration( Long.valueOf( 1000000 ) );
 		firstOne.setDurationInSec( 2000 );
 		s.save( firstOne );
 		s.flush();
 		tx.commit();
 		s.close();
-		
+
 
 		s = openSession();
 		tx = s.beginTransaction();
 		firstOne = new Flight();
 		firstOne.setId( Long.valueOf( 1 ) );
 		firstOne.setName( null );
 
 		try {
 			s.save( firstOne );
 			tx.commit();
 			fail( "Name column should be not null" );
 		}
 		catch (HibernateException e) {
 			//fine
 		}
 		finally {
 			s.close();
 		}
 
 		//insert an object and check that name is not updatable
 		s = openSession();
 		tx = s.beginTransaction();
 		firstOne = new Flight();
 		firstOne.setId( Long.valueOf( 1 ) );
 		firstOne.setName( "AF3202" );
 		firstOne.setTriggeredData( "should not be insertable" );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		firstOne = (Flight) s.get( Flight.class, Long.valueOf( 1 ) );
 		assertNotNull( firstOne );
 		assertEquals( Long.valueOf( 1 ), firstOne.getId() );
 		assertEquals( "AF3202", firstOne.getName() );
 		assertFalse( "should not be insertable".equals( firstOne.getTriggeredData() ) );
 		firstOne.setName( "BA1234" );
 		firstOne.setTriggeredData( "should not be updatable" );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		firstOne = (Flight) s.get( Flight.class, Long.valueOf( 1 ) );
 		assertNotNull( firstOne );
 		assertEquals( Long.valueOf( 1 ), firstOne.getId() );
 		assertEquals( "AF3202", firstOne.getName() );
 		assertFalse( "should not be updatable".equals( firstOne.getTriggeredData() ) );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testColumnUnique() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Sky sky = new Sky();
 		sky.id = Long.valueOf( 2 );
 		sky.color = "blue";
 		sky.day = "monday";
 		sky.month = "January";
 
 		Sky sameSky = new Sky();
 		sameSky.id = Long.valueOf( 3 );
 		sameSky.color = "blue";
 		sky.day = "tuesday";
 		sky.month = "January";
 
 		try {
 			s.save( sky );
 			s.flush();
 			s.save( sameSky );
 			tx.commit();
 			fail( "unique constraints not respected" );
 		}
 		catch (HibernateException e) {
 			//success
 		}
 		finally {
-			if ( tx != null ) tx.rollback();
+			if ( tx != null ) {
+				tx.rollback();
+			}
 			s.close();
 		}
 	}
 
 	@Test
 	public void testUniqueConstraint() throws Exception {
 		int id = 5;
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Sky sky = new Sky();
 		sky.id = Long.valueOf( id++ );
 		sky.color = "green";
 		sky.day = "monday";
 		sky.month = "March";
 
 		Sky otherSky = new Sky();
 		otherSky.id = Long.valueOf( id++ );
 		otherSky.color = "red";
 		otherSky.day = "friday";
 		otherSky.month = "March";
 
 		Sky sameSky = new Sky();
 		sameSky.id = Long.valueOf( id++ );
 		sameSky.color = "green";
 		sameSky.day = "monday";
 		sameSky.month = "March";
 
 		s.save( sky );
 		s.flush();
 
 		s.save( otherSky );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		try {
 			s.save( sameSky );
 			tx.commit();
 			fail( "unique constraints not respected" );
 		}
 		catch (HibernateException e) {
 			//success
 			if ( tx != null ) {
 				tx.rollback();
 			}
 		}
 		finally {
 			s.close();
 		}
 	}
 
 	@Test
 	public void testVersion() throws Exception {
 //		put an object in DB
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Flight firstOne = new Flight();
 		firstOne.setId( Long.valueOf( 2 ) );
 		firstOne.setName( "AF3202" );
 		firstOne.setDuration( Long.valueOf( 500 ) );
 		s.save( firstOne );
 		s.flush();
 		tx.commit();
 		s.close();
 
 		//read it
 		s = openSession();
 		tx = s.beginTransaction();
 		firstOne = (Flight) s.get( Flight.class, Long.valueOf( 2 ) );
 		tx.commit();
 		s.close();
 
 		//read it again
 		s = openSession();
 		tx = s.beginTransaction();
 		Flight concurrentOne = (Flight) s.get( Flight.class, Long.valueOf( 2 ) );
 		concurrentOne.setDuration( Long.valueOf( 1000 ) );
 		s.update( concurrentOne );
 		tx.commit();
 		s.close();
 		assertFalse( firstOne == concurrentOne );
 		assertFalse( firstOne.getVersion().equals( concurrentOne.getVersion() ) );
 
 		//reattach the first one
 		s = openSession();
 		tx = s.beginTransaction();
 		firstOne.setName( "Second access" );
 		s.update( firstOne );
 		try {
 			tx.commit();
 			fail( "Optimistic locking should work" );
 		}
-		catch (StaleStateException e) {
-			//fine
+		catch (TransactionException e) {
+			assertTrue( e.getCause() instanceof StaleStateException );
 		}
 		finally {
-			if ( tx != null ) tx.rollback();
+			if ( tx != null ) {
+				tx.rollback();
+			}
 			s.close();
 		}
 	}
 
 	@Test
 	public void testFieldAccess() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Sky sky = new Sky();
 		sky.id = Long.valueOf( 1 );
 		sky.color = "black";
 		sky.area = "Paris";
 		sky.day = "23";
 		sky.month = "1";
 		s.save( sky );
 		tx.commit();
 		s.close();
 		sky.area = "London";
 
 		s = openSession();
 		tx = s.beginTransaction();
 		sky = (Sky) s.get( Sky.class, sky.id );
 		assertNotNull( sky );
 		assertEquals( "black", sky.color );
 		assertFalse( "Paris".equals( sky.area ) );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testEntityName() throws Exception {
 		assertEquals( "Corporation", metadata().getEntityBinding( Company.class.getName() ).getTable().getName() );
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Company comp = new Company();
 		s.persist( comp );
 		comp.setName( "JBoss Inc" );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		List result = s.createQuery( "from Corporation" ).list();
 		assertNotNull( result );
 		assertEquals( 1, result.size() );
 		tx.commit();
 		s.close();
 
 	}
 
 	@Test
 	public void testNonGetter() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Flight airFrance = new Flight();
 		airFrance.setId( Long.valueOf( 747 ) );
 		airFrance.setName( "Paris-Amsterdam" );
 		airFrance.setDuration( Long.valueOf( 10 ) );
 		airFrance.setFactor( 25 );
 		s.persist( airFrance );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		airFrance = (Flight) s.get( Flight.class, airFrance.getId() );
 		assertNotNull( airFrance );
 		assertEquals( Long.valueOf( 10 ), airFrance.getDuration() );
 		assertFalse( 25 == airFrance.getFactor( false ) );
 		s.delete( airFrance );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	@SkipForDialect(value = Oracle10gDialect.class, comment = "oracle12c returns time in getDate.  For now, skip.")
 	public void testTemporalType() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Flight airFrance = new Flight();
 		airFrance.setId( Long.valueOf( 747 ) );
 		airFrance.setName( "Paris-Amsterdam" );
 		airFrance.setDuration( Long.valueOf( 10 ) );
 		airFrance.setDepartureDate( new Date( 05, 06, 21, 10, 0, 0 ) );
 		airFrance.setAlternativeDepartureDate( new GregorianCalendar( 2006, 02, 03, 10, 00 ) );
 		airFrance.getAlternativeDepartureDate().setTimeZone( TimeZone.getTimeZone( "GMT" ) );
-		airFrance.setBuyDate( new java.sql.Timestamp(122367443) );
+		airFrance.setBuyDate( new java.sql.Timestamp( 122367443 ) );
 		airFrance.setFactor( 25 );
 		s.persist( airFrance );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		Query q = s.createQuery( "from Flight f where f.departureDate = :departureDate" );
 		q.setParameter( "departureDate", airFrance.getDepartureDate(), StandardBasicTypes.DATE );
 		Flight copyAirFrance = (Flight) q.uniqueResult();
 		assertNotNull( copyAirFrance );
 		assertEquals(
-				df.format(new Date( 05, 06, 21 )).toString(),
-				df.format(copyAirFrance.getDepartureDate()).toString()
+				df.format( new Date( 05, 06, 21 ) ).toString(),
+				df.format( copyAirFrance.getDepartureDate() ).toString()
 		);
-		assertEquals( df.format(airFrance.getBuyDate()), df.format(copyAirFrance.getBuyDate()));
+		assertEquals( df.format( airFrance.getBuyDate() ), df.format( copyAirFrance.getBuyDate() ) );
 
 		s.delete( copyAirFrance );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testBasic() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Flight airFrance = new Flight();
 		airFrance.setId( Long.valueOf( 747 ) );
 		airFrance.setName( "Paris-Amsterdam" );
 		airFrance.setDuration( null );
 		try {
 			s.persist( airFrance );
 			tx.commit();
 			fail( "Basic(optional=false) fails" );
 		}
 		catch (Exception e) {
 			//success
-			if ( tx != null ) tx.rollback();
+			if ( tx != null ) {
+				tx.rollback();
+			}
 		}
 		finally {
 			s.close();
 		}
 	}
 
 	@Override
 	protected Class[] getAnnotatedClasses() {
-		return new Class[]{
+		return new Class[] {
 				Flight.class,
 				Company.class,
 				Sky.class
 		};
 	}
 
 	// tests are leaving data around, so drop/recreate schema for now.  this is wha the old tests did
 
 	@Override
 	protected boolean createSchema() {
 		return false;
 	}
 
 	@Before
 	public void runCreateSchema() {
 		schemaExport().create( false, true );
 	}
 
 	private SchemaExport schemaExport() {
 		return new SchemaExport( serviceRegistry(), metadata() );
 	}
 
 	@After
 	public void runDropSchema() {
 		schemaExport().drop( false, true );
 	}
 
 }
 
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/dataTypes/BasicOperationsTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/dataTypes/BasicOperationsTest.java
index ae871bddc7..7221afc1bf 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/dataTypes/BasicOperationsTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/dataTypes/BasicOperationsTest.java
@@ -1,177 +1,177 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations.dataTypes;
 
 import java.sql.Connection;
 import java.sql.DatabaseMetaData;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.Date;
 import java.util.Locale;
 
 import org.junit.Test;
 
 import org.hibernate.Session;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.Oracle8iDialect;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
 import org.hibernate.testing.DialectCheck;
 import org.hibernate.testing.DialectChecks;
 import org.hibernate.testing.RequiresDialectFeature;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.type.descriptor.JdbcTypeNameMapper;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 
 /**
  * @author Steve Ebersole
  */
 @RequiresDialectFeature(value = {DialectChecks.SupportsExpectedLobUsagePattern.class, BasicOperationsTest.OracleDialectChecker.class}, jiraKey = "HHH-6834")
 public class BasicOperationsTest extends BaseCoreFunctionalTestCase {
 
 	private static final String SOME_ENTITY_TABLE_NAME = "SOMEENTITY";
 	private static final String SOME_OTHER_ENTITY_TABLE_NAME = "SOMEOTHERENTITY";
 
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[] { SomeEntity.class, SomeOtherEntity.class };
 	}
 	public static class OracleDialectChecker implements DialectCheck{
 		@Override
 		public boolean isMatch(Dialect dialect) {
 			return ! (dialect instanceof Oracle8iDialect);
 		}
 	}
 
 	@Test
 	public void testCreateAndDelete() {
 		Date now = new Date();
 
 		Session s = openSession();
 
 		s.doWork( new ValidateSomeEntityColumns( (SessionImplementor) s ) );
 		s.doWork( new ValidateRowCount( (SessionImplementor) s, SOME_ENTITY_TABLE_NAME, 0 ) );
 		s.doWork( new ValidateRowCount( (SessionImplementor) s, SOME_OTHER_ENTITY_TABLE_NAME, 0 ) );
 
 		s.beginTransaction();
 		SomeEntity someEntity = new SomeEntity( now );
 		SomeOtherEntity someOtherEntity = new SomeOtherEntity( 1 );
 		s.save( someEntity );
 		s.save( someOtherEntity );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 
 		s.doWork( new ValidateRowCount( (SessionImplementor) s, SOME_ENTITY_TABLE_NAME, 1 ) );
 		s.doWork( new ValidateRowCount( (SessionImplementor) s, SOME_OTHER_ENTITY_TABLE_NAME, 1 ) );
 
 		s.beginTransaction();
 		s.delete( someEntity );
 		s.delete( someOtherEntity );
 		s.getTransaction().commit();
 
 		s.doWork( new ValidateRowCount( (SessionImplementor) s, SOME_ENTITY_TABLE_NAME, 0 ) );
 		s.doWork( new ValidateRowCount( (SessionImplementor) s, SOME_OTHER_ENTITY_TABLE_NAME, 0 ) );
 
 		s.close();
 	}
 
 	// verify all the expected columns are created
 	class ValidateSomeEntityColumns implements Work {
 		private SessionImplementor s;
 		
 		public ValidateSomeEntityColumns( SessionImplementor s ) {
 			this.s = s;
 		}
 		
 		public void execute(Connection connection) throws SQLException {
 			// id -> java.util.Date (DATE - becase of explicit TemporalType)
 			validateColumn( connection, "ID", java.sql.Types.DATE );
 
 			// timeData -> java.sql.Time (TIME)
 			validateColumn( connection, "TIMEDATA", java.sql.Types.TIME );
 
 			// tsData -> java.sql.Timestamp (TIMESTAMP)
 			validateColumn( connection, "TSDATA", java.sql.Types.TIMESTAMP );
 		}
 
 		private void validateColumn(Connection connection, String columnName, int expectedJdbcTypeCode)
 				throws SQLException {
 			DatabaseMetaData meta = connection.getMetaData();
 
 			// DBs treat the meta information differently, in particular case sensitivity.
 			// We need to use the meta information to find out how to treat names
 			String tableNamePattern = generateFinalNamePattern( meta, SOME_ENTITY_TABLE_NAME );
 			String columnNamePattern = generateFinalNamePattern( meta, columnName );
 
 			ResultSet columnInfo = meta.getColumns( null, null, tableNamePattern, columnNamePattern );
-			s.getTransactionCoordinator().getJdbcCoordinator().register(columnInfo, columnInfo.getStatement());
+			s.getJdbcCoordinator().getResourceRegistry().register(columnInfo, columnInfo.getStatement());
 			assertTrue( columnInfo.next() );
 			int dataType = columnInfo.getInt( "DATA_TYPE" );
-			s.getTransactionCoordinator().getJdbcCoordinator().release( columnInfo, columnInfo.getStatement() );
+			s.getJdbcCoordinator().getResourceRegistry().release( columnInfo, columnInfo.getStatement() );
 			assertEquals(
 					columnName,
 					JdbcTypeNameMapper.getTypeName( expectedJdbcTypeCode ),
 					JdbcTypeNameMapper.getTypeName( dataType )
 			);
 		}
 
 		private String generateFinalNamePattern(DatabaseMetaData meta, String name) throws SQLException {
 			if ( meta.storesLowerCaseIdentifiers() ) {
 				return name.toLowerCase(Locale.ROOT);
 			}
 			else {
 				return name;
 			}
 		}
 	}
 
 	// verify we have the right amount of columns
 	class ValidateRowCount implements Work {
 		private final int expectedRowCount;
 		private final String table;
 
 		private SessionImplementor s;
 		
 		public ValidateRowCount(SessionImplementor s, String table, int count) {
 			this.s = s;
 			this.expectedRowCount = count;
 			this.table = table;
 		}
 
 		public void execute(Connection connection) throws SQLException {
-			Statement st = s.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().createStatement();
-			s.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st, "SELECT COUNT(*) FROM " + table );
-			ResultSet result = s.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st, "SELECT COUNT(*) FROM " + table );
+			Statement st = s.getJdbcCoordinator().getStatementPreparer().createStatement();
+			s.getJdbcCoordinator().getResultSetReturn().extract( st, "SELECT COUNT(*) FROM " + table );
+			ResultSet result = s.getJdbcCoordinator().getResultSetReturn().extract( st, "SELECT COUNT(*) FROM " + table );
 			result.next();
 			int rowCount = result.getInt( 1 );
 			assertEquals( "Unexpected row count", expectedRowCount, rowCount );
 		}
 	}
 }
 
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/immutable/ImmutableTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/immutable/ImmutableTest.java
index b386002dc1..4415c5c868 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/immutable/ImmutableTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/immutable/ImmutableTest.java
@@ -1,168 +1,168 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations.immutable;
 
 import java.util.ArrayList;
 import java.util.List;
 
 import org.hibernate.AnnotationException;
 import org.hibernate.HibernateException;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.boot.MetadataSources;
 
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.junit.Test;
 
 import org.jboss.logging.Logger;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * Tests for <code>Immutable</code> annotation.
  *
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public class ImmutableTest extends BaseCoreFunctionalTestCase {
 	private static final Logger log = Logger.getLogger( ImmutableTest.class );
 
 	@Test
 	public void testImmutableEntity() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Country country = new Country();
 		country.setName("Germany");
 		s.persist(country);
 		tx.commit();
 		s.close();
 
 		// try changing the entity
 		s = openSession();
 		tx = s.beginTransaction();
 		Country germany = (Country) s.get(Country.class, country.getId());
 		assertNotNull(germany);
 		germany.setName("France");
 		assertEquals("Local name can be changed", "France", germany.getName());
 		s.save(germany);
 		tx.commit();
 		s.close();
 
 		// retrieving the country again - it should be unmodified
 		s = openSession();
 		tx = s.beginTransaction();
 		germany = (Country) s.get(Country.class, country.getId());
 		assertNotNull(germany);
 		assertEquals("Name should not have changed", "Germany", germany.getName());
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testImmutableCollection() {
 		Country country = new Country();
 		country.setName("Germany");
 		List states = new ArrayList<State>();
 		State bayern = new State();
 		bayern.setName("Bayern");
 		State hessen = new State();
 		hessen.setName("Hessen");
 		State sachsen = new State();
 		sachsen.setName("Sachsen");
 		states.add(bayern);
 		states.add(hessen);
 		states.add(sachsen);
 		country.setStates(states);
 
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		s.persist(country);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		Country germany = (Country) s.get(Country.class, country.getId());
 		assertNotNull(germany);
 		assertEquals("Wrong number of states", 3, germany.getStates().size());
 
 		// try adding a state
 		State foobar = new State();
 		foobar.setName("foobar");
 		s.save(foobar);
 		germany.getStates().add(foobar);
 		try {
 			tx.commit();
 			fail();
 		}
 		catch (HibernateException e) {
-			assertTrue(e.getMessage().contains("changed an immutable collection instance"));
+			assertTrue(e.getCause().getMessage().contains("changed an immutable collection instance"));
             log.debug("success");
 		}
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		germany = (Country) s.get(Country.class, country.getId());
 		assertNotNull(germany);
 		assertEquals("Wrong number of states", 3, germany.getStates().size());
 
 		// try deleting a state
 		germany.getStates().remove(0);
 		try {
 			tx.commit();
 			fail();
 		} catch (HibernateException e) {
-			assertTrue(e.getMessage().contains("changed an immutable collection instance"));
+			assertTrue(e.getCause().getMessage().contains("changed an immutable collection instance"));
             log.debug("success");
 		}
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		germany = (Country) s.get(Country.class, country.getId());
 		assertNotNull(germany);
 		assertEquals("Wrong number of states", 3, germany.getStates().size());
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testMisplacedImmutableAnnotation() {
 		try {
 			new MetadataSources().addAnnotatedClass( Foobar.class ).buildMetadata();
 			fail( "Expecting exception due to misplaced @Immutable annotation");
 		}
 		catch (AnnotationException ignore) {
 		}
 	}
 
 	@Override
     protected Class[] getAnnotatedClasses() {
 		return new Class[] { Country.class, State.class};
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/manytomany/ManyToManyTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/manytomany/ManyToManyTest.java
index 72765caa82..e82cf4bfc6 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/manytomany/ManyToManyTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/manytomany/ManyToManyTest.java
@@ -1,794 +1,794 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations.manytomany;
 
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Date;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
 
 import org.hibernate.Hibernate;
 import org.hibernate.JDBCException;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.criterion.Restrictions;
 
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * Many to many tests
  *
  * @author Emmanuel Bernard
  */
 @SuppressWarnings("unchecked")
 public class ManyToManyTest extends BaseCoreFunctionalTestCase {
 	@Override
 	protected void configure(Configuration configuration) {
 		super.configure( configuration );
 //		configuration.setImplicitNamingStrategy( ImplicitNamingStrategyJpaCompliantImpl.INSTANCE );
 	}
 
 	@Test
 	public void testDefault() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Store fnac = new Store();
 		fnac.setName( "Fnac" );
 		KnownClient emmanuel = new KnownClient();
 		emmanuel.setName( "Emmanuel" );
 		emmanuel.setStores( new HashSet<Store>() );
 		fnac.setCustomers( new HashSet<KnownClient>() );
 		fnac.getCustomers().add( emmanuel );
 		emmanuel.getStores().add( fnac );
 		fnac.setImplantedIn( new HashSet<City>() );
 		City paris = new City();
 		fnac.getImplantedIn().add( paris );
 		paris.setName( "Paris" );
 		s.persist( fnac );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		Store store;
 		KnownClient knownClient;
 		City city;
 		store = (Store) s.get( Store.class, fnac.getId() );
 		assertNotNull( store );
 		assertNotNull( store.getCustomers() );
 		assertEquals( 1, store.getCustomers().size() );
 		knownClient = store.getCustomers().iterator().next();
 		assertEquals( emmanuel.getName(), knownClient.getName() );
 		assertNotNull( store.getImplantedIn() );
 		assertEquals( 1, store.getImplantedIn().size() );
 		city = store.getImplantedIn().iterator().next();
 		assertEquals( paris.getName(), city.getName() );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		knownClient = (KnownClient) s.get( KnownClient.class, emmanuel.getId() );
 		assertNotNull( knownClient );
 		assertNotNull( knownClient.getStores() );
 		assertEquals( 1, knownClient.getStores().size() );
 		store = knownClient.getStores().iterator().next();
 		assertEquals( fnac.getName(), store.getName() );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCanUseCriteriaQuery() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Store fnac = new Store();
 		fnac.setName( "Fnac" );
 		Supplier emi = new Supplier();
 		emi.setName( "Emmanuel" );
 		emi.setSuppStores( new HashSet<Store>() );
 		fnac.setSuppliers( new HashSet<Supplier>() );
 		fnac.getSuppliers().add( emi );
 		emi.getSuppStores().add( fnac );
 		s.persist( fnac );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		List result = s.createCriteria( Supplier.class ).createAlias( "suppStores", "s" ).add(
 				Restrictions.eq( "s.name", "Fnac" ) ).list();
 		assertEquals( 1, result.size() );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testDefaultCompositePk() throws Exception {
 		Session s;
 		Transaction tx;
 
 		s = openSession();
 		tx = s.beginTransaction();
 		CatPk catPk = new CatPk();
 		catPk.setName( "Minou" );
 		catPk.setThoroughbred( "Persan" );
 		Cat cat = new Cat();
 		cat.setId( catPk );
 		cat.setAge( 32 );
 		Woman woman = new Woman();
 		WomanPk womanPk = new WomanPk();
 		womanPk.setFirstName( "Emma" );
 		womanPk.setLastName( "Peel" );
 		woman.setId( womanPk );
 		woman.setCats( new HashSet<Cat>() );
 		woman.getCats().add( cat );
 		cat.setHumanContacts( new HashSet<Woman>() );
 		cat.getHumanContacts().add( woman );
 		s.persist( woman );
 		s.persist( cat );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		Cat sameCat = (Cat) s.get( Cat.class, cat.getId() );
 		assertNotNull( sameCat );
 		assertNotNull( sameCat.getHumanContacts() );
 		assertEquals( 1, sameCat.getHumanContacts().size() );
 		Woman sameWoman = sameCat.getHumanContacts().iterator().next();
 		assertEquals( sameWoman.getId().getLastName(), woman.getId().getLastName() );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		sameWoman = (Woman) s.get( Woman.class, woman.getId() );
 		assertNotNull( sameWoman );
 		assertNotNull( sameWoman.getCats() );
 		assertEquals( 1, sameWoman.getCats().size() );
 		sameCat = sameWoman.getCats().iterator().next();
 		assertEquals( cat.getAge(), sameCat.getAge() );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testMappedBy() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Store fnac = new Store();
 		fnac.setName( "Fnac" );
 		Supplier emi = new Supplier();
 		emi.setName( "Emmanuel" );
 		emi.setSuppStores( new HashSet<Store>() );
 		fnac.setSuppliers( new HashSet<Supplier>() );
 		fnac.getSuppliers().add( emi );
 		emi.getSuppStores().add( fnac );
 		s.persist( fnac );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		Store store;
 		Supplier supplier;
 		store = (Store) s.get( Store.class, fnac.getId() );
 		assertNotNull( store );
 		assertNotNull( store.getSuppliers() );
 		assertEquals( 1, store.getSuppliers().size() );
 		supplier = store.getSuppliers().iterator().next();
 		assertEquals( emi.getName(), supplier.getName() );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		supplier = (Supplier) s.get( Supplier.class, emi.getId() );
 		assertNotNull( supplier );
 		assertNotNull( supplier.getSuppStores() );
 		assertEquals( 1, supplier.getSuppStores().size() );
 		store = supplier.getSuppStores().iterator().next();
 		assertEquals( fnac.getName(), store.getName() );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testBasic() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Employer er = new Employer();
 		Employee ee = new Employee();
 		s.persist( ee );
 		Set erColl = new HashSet();
 		Collection eeColl = new ArrayList();
 		erColl.add( ee );
 		eeColl.add( er );
 		er.setEmployees( erColl );
 		ee.setEmployers( eeColl );
 		//s.persist(ee);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		er = (Employer) s.load( Employer.class, er.getId() );
 		assertNotNull( er );
 		assertNotNull( er.getEmployees() );
 		assertEquals( 1, er.getEmployees().size() );
 		Employee eeFromDb = (Employee) er.getEmployees().iterator().next();
 		assertEquals( ee.getId(), eeFromDb.getId() );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		ee = (Employee) s.get( Employee.class, ee.getId() );
 		assertNotNull( ee );
 		assertFalse( "ManyToMany mappedBy lazyness", Hibernate.isInitialized( ee.getEmployers() ) );
 		tx.commit();
 		assertFalse( "ManyToMany mappedBy lazyness", Hibernate.isInitialized( ee.getEmployers() ) );
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		ee = (Employee) s.get( Employee.class, ee.getId() );
 		assertNotNull( ee );
 		er = ee.getEmployers().iterator().next();
 		assertTrue( "second join non lazy", Hibernate.isInitialized( er ) );
 		s.delete( er );
 		s.delete( ee );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testOrderByEmployee() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Employer employer = new Employer();
 		Employee employee1 = new Employee();
 		employee1.setName( "Emmanuel" );
 		Employee employee2 = new Employee();
 		employee2.setName( "Alice" );
 		s.persist( employee1 );
 		s.persist( employee2 );
 		Set erColl = new HashSet();
 		Collection eeColl = new ArrayList();
 		Collection eeColl2 = new ArrayList();
 		erColl.add( employee1 );
 		erColl.add( employee2 );
 		eeColl.add( employer );
 		eeColl2.add( employer );
 		employer.setEmployees( erColl );
 		employee1.setEmployers( eeColl );
 		employee2.setEmployers( eeColl2 );
 
 		s.flush();
 		s.clear();
 
 		employer = (Employer) s.get( Employer.class, employer.getId() );
 		assertNotNull( employer );
 		assertNotNull( employer.getEmployees() );
 		assertEquals( 2, employer.getEmployees().size() );
 		Employee eeFromDb = (Employee) employer.getEmployees().iterator().next();
 		assertEquals( employee2.getName(), eeFromDb.getName() );
 		tx.rollback();
 		s.close();
 	}
 	
 	// HHH-4394
 	@Test
 	public void testOrderByContractor() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 
 		// create some test entities
 		Employer employer = new Employer();
 		Contractor contractor1 = new Contractor();
 		contractor1.setName( "Emmanuel" );
 		contractor1.setHourlyRate(100.0f);
 		Contractor contractor2 = new Contractor();
 		contractor2.setName( "Hardy" );
 		contractor2.setHourlyRate(99.99f);
 		s.persist( contractor1 );
 		s.persist( contractor2 );
 
 		// add contractors to employer
 		List setOfContractors = new ArrayList();
 		setOfContractors.add( contractor1 );
 		setOfContractors.add( contractor2 );
 		employer.setContractors( setOfContractors );
 
 		// add employer to contractors
 		Collection employerListContractor1 = new ArrayList();
 		employerListContractor1.add( employer );
 		contractor1.setEmployers( employerListContractor1 );
 
 		Collection employerListContractor2 = new ArrayList();
 		employerListContractor2.add( employer );
 		contractor2.setEmployers( employerListContractor2 );
 
 		s.flush();
 		s.clear();
 
 		// assertions
 		employer = (Employer) s.get( Employer.class, employer.getId() );
 		assertNotNull( employer );
 		assertNotNull( employer.getContractors() );
 		assertEquals( 2, employer.getContractors().size() );
 		Contractor firstContractorFromDb = (Contractor) employer.getContractors().iterator().next();
 		assertEquals( contractor2.getName(), firstContractorFromDb.getName() );
 		tx.rollback();
 		s.close();
 	}
 	
 	@Test
 	public void testRemoveInBetween() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Employer er = new Employer();
 		Employee ee = new Employee();
 		Employee ee2 = new Employee();
 		s.persist( ee );
 		s.persist( ee2 );
 		Set erColl = new HashSet();
 		Collection eeColl = new ArrayList();
 		erColl.add( ee );
 		erColl.add( ee2 );
 		eeColl.add( er );
 		er.setEmployees( erColl );
 		ee.setEmployers( eeColl );
 		//s.persist(ee);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		er = (Employer) s.load( Employer.class, er.getId() );
 		assertNotNull( er );
 		assertNotNull( er.getEmployees() );
 		assertEquals( 2, er.getEmployees().size() );
 		Iterator iterator = er.getEmployees().iterator();
 		Employee eeFromDb = (Employee) iterator.next();
 		if ( eeFromDb.getId().equals( ee.getId() ) ) {
 			eeFromDb = (Employee) iterator.next();
 		}
 		assertEquals( ee2.getId(), eeFromDb.getId() );
 		er.getEmployees().remove( eeFromDb );
 		eeFromDb.getEmployers().remove( er );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		ee = (Employee) s.get( Employee.class, ee.getId() );
 		assertNotNull( ee );
 		assertFalse( "ManyToMany mappedBy lazyness", Hibernate.isInitialized( ee.getEmployers() ) );
 		tx.commit();
 		assertFalse( "ManyToMany mappedBy lazyness", Hibernate.isInitialized( ee.getEmployers() ) );
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		ee = (Employee) s.get( Employee.class, ee.getId() );
 		assertNotNull( ee );
 		er = ee.getEmployers().iterator().next();
 		assertTrue( "second join non lazy", Hibernate.isInitialized( er ) );
 		assertEquals( 1, er.getEmployees().size() );
 		s.delete( er );
 		s.delete( ee );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testSelf() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Friend f = new Friend();
 		Friend sndF = new Friend();
 		f.setName( "Starsky" );
 		sndF.setName( "Hutch" );
 		Set frnds = new HashSet();
 		frnds.add( sndF );
 		f.setFriends( frnds );
 		//Starsky is a friend of Hutch but hutch is not
 		s.persist( f );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		f = (Friend) s.load( Friend.class, f.getId() );
 		assertNotNull( f );
 		assertNotNull( f.getFriends() );
 		assertEquals( 1, f.getFriends().size() );
 		Friend fromDb2ndFrnd = f.getFriends().iterator().next();
 		assertEquals( fromDb2ndFrnd.getId(), sndF.getId() );
 		assertEquals( 0, fromDb2ndFrnd.getFriends().size() );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCompositePk() throws Exception {
 		Session s;
 		Transaction tx;
 
 		ManPk m1pk = new ManPk();
 		m1pk.setElder( true );
 		m1pk.setFirstName( "Lucky" );
 		m1pk.setLastName( "Luke" );
 		ManPk m2pk = new ManPk();
 		m2pk.setElder( false );
 		m2pk.setFirstName( "Joe" );
 		m2pk.setLastName( "Dalton" );
 
 		Man m1 = new Man();
 		m1.setId( m1pk );
 		m1.setCarName( "Jolly Jumper" );
 		Man m2 = new Man();
 		m2.setId( m2pk );
 
 		WomanPk w1pk = new WomanPk();
 		w1pk.setFirstName( "Ma" );
 		w1pk.setLastName( "Dalton" );
 		WomanPk w2pk = new WomanPk();
 		w2pk.setFirstName( "Carla" );
 		w2pk.setLastName( "Bruni" );
 
 		Woman w1 = new Woman();
 		w1.setId( w1pk );
 		Woman w2 = new Woman();
 		w2.setId( w2pk );
 
 		Set<Woman> womens = new HashSet<Woman>();
 		womens.add( w1 );
 		m1.setWomens( womens );
 		Set<Woman> womens2 = new HashSet<Woman>();
 		womens2.add( w1 );
 		womens2.add( w2 );
 		m2.setWomens( womens2 );
 
 		Set<Man> mens = new HashSet<Man>();
 		mens.add( m1 );
 		mens.add( m2 );
 		w1.setMens( mens );
 		Set<Man> mens2 = new HashSet<Man>();
 		mens2.add( m2 );
 		w2.setMens( mens2 );
 
 		s = openSession();
 		tx = s.beginTransaction();
 		s.persist( m1 );
 		s.persist( m2 );
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		m1 = (Man) s.load( Man.class, m1pk );
 		assertFalse( m1.getWomens().isEmpty() );
 		assertEquals( 1, m1.getWomens().size() );
 		w1 = (Woman) s.load( Woman.class, w1pk );
 		assertFalse( w1.getMens().isEmpty() );
 		assertEquals( 2, w1.getMens().size() );
 
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testAssociationTableUniqueConstraints() throws Exception {
 		Session s = openSession();
 		Permission readAccess = new Permission();
 		readAccess.setPermission( "read" );
 		readAccess.setExpirationDate( new Date() );
 		Collection<Permission> coll = new ArrayList<Permission>( 2 );
 		coll.add( readAccess );
 		coll.add( readAccess );
 		Group group = new Group();
 		group.setId( new Integer( 1 ) );
 		group.setPermissions( coll );
 		s.getTransaction().begin();
 		try {
 			s.persist( group );
 			s.getTransaction().commit();
 			fail( "Unique constraints not applied on association table" );
 		}
-		catch (JDBCException e) {
+		catch (Exception e) {
 			//success
 			s.getTransaction().rollback();
 		}
 		finally {
 			s.close();
 		}
 	}
 
 	@Test
 	public void testAssociationTableAndOrderBy() throws Exception {
 		Session s = openSession();
 		s.enableFilter( "Groupfilter" );
 		Permission readAccess = new Permission();
 		readAccess.setPermission( "read" );
 		readAccess.setExpirationDate( new Date() );
 		Permission writeAccess = new Permission();
 		writeAccess.setPermission( "write" );
 		writeAccess.setExpirationDate( new Date( new Date().getTime() - 10*60*1000 ) );
 		Collection<Permission> coll = new ArrayList<Permission>( 2 );
 		coll.add( readAccess );
 		coll.add( writeAccess );
 		Group group = new Group();
 		group.setId( new Integer( 1 ) );
 		group.setPermissions( coll );
 		s.getTransaction().begin();
 		s.persist( group );
 		s.flush();
 		s.clear();
 		group = (Group) s.get( Group.class, group.getId() );
 		s.createQuery( "select g from Group g join fetch g.permissions").list();
 		assertEquals( "write", group.getPermissions().iterator().next().getPermission() );
 		s.getTransaction().rollback();
 		s.close();
 	}
 
 	@Test
 	public void testAssociationTableAndOrderByWithSet() throws Exception {
 		Session s = openSession();
 		s.enableFilter( "Groupfilter" );
 
 		Permission readAccess = new Permission();
 		readAccess.setPermission( "read" );
 		readAccess.setExpirationDate( new Date() );
 		
 		Permission writeAccess = new Permission();
 		writeAccess.setPermission( "write" );
 		writeAccess.setExpirationDate( new Date( new Date().getTime() - 10*60*1000 ) );
 		
 		Permission executeAccess = new Permission();
 		executeAccess.setPermission( "execute" );
 		executeAccess.setExpirationDate( new Date( new Date().getTime() - 5*60*1000 ) );
 		
 		Set<Permission> coll = new HashSet<Permission>( 3 );
 		coll.add( readAccess );
 		coll.add( writeAccess );
 		coll.add( executeAccess );
 
 		GroupWithSet group = new GroupWithSet();
 		group.setId( new Integer( 1 ) );
 		group.setPermissions( coll );
 		s.getTransaction().begin();
 		s.persist( group );
 		s.flush();
 		s.clear();
 
 		group = (GroupWithSet) s.get( GroupWithSet.class, group.getId() );
 		s.createQuery( "select g from Group g join fetch g.permissions").list();
 		Iterator<Permission> permIter = group.getPermissions().iterator();
 		assertEquals( "write", permIter.next().getPermission() );
 		assertEquals( "execute", permIter.next().getPermission() );
 		assertEquals( "read", permIter.next().getPermission() );
 		s.getTransaction().rollback();
 		s.close();
 	}
 	
 	@Test
 	public void testJoinedSubclassManyToMany() throws Exception {
 		Session s = openSession();
 		Zone a = new Zone();
 		InspectorPrefixes ip = new InspectorPrefixes( "dgi" );
 		Transaction tx = s.beginTransaction();
 		s.save( a );
 		s.save( ip );
 		ip.getAreas().add( a );
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		ip = (InspectorPrefixes) s.get( InspectorPrefixes.class, ip.getId() );
 		assertNotNull( ip );
 		assertEquals( 1, ip.getAreas().size() );
 		assertEquals( a.getId(), ip.getAreas().get( 0 ).getId() );
 		s.delete( ip );
 		s.delete( ip.getAreas().get( 0 ) );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testJoinedSubclassManyToManyWithNonPkReference() throws Exception {
 		Session s = openSession();
 		Zone a = new Zone();
 		InspectorPrefixes ip = new InspectorPrefixes( "dgi" );
 		ip.setName( "Inspector" );
 		Transaction tx = s.beginTransaction();
 		s.save( a );
 		s.save( ip );
 		ip.getDesertedAreas().add( a );
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		ip = (InspectorPrefixes) s.get( InspectorPrefixes.class, ip.getId() );
 		assertNotNull( ip );
 		assertEquals( 1, ip.getDesertedAreas().size() );
 		assertEquals( a.getId(), ip.getDesertedAreas().get( 0 ).getId() );
 		s.delete( ip );
 		s.delete( ip.getDesertedAreas().get( 0 ) );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testReferencedColumnNameToSuperclass() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		BuildingCompany comp = new BuildingCompany();
 		comp.setFoundedIn( new Date() );
 		comp.setName( "Builder century corp.");
 		s.persist( comp );
 		Building building = new Building();
 		building.setCompany( comp );
 		s.persist( building );
 		s.flush();
 		s.clear();
 		building = (Building) s.get( Building.class, building.getId() );
 		assertEquals( comp.getName(), building.getCompany().getName() );
 		tx.rollback();
 		s.close();
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-4685" )
 	public void testManyToManyEmbeddableBiDirectionalDotNotationInMappedBy() throws Exception {
 		// Section 11.1.25
 		// The ManyToMany annotation may be used within an embeddable class contained within an entity class to specify a
 		// relationship to a collection of entities[101]. If the relationship is bidirectional and the entity containing
 		// the embeddable class is the owner of the relationship, the non-owning side must use the mappedBy element of the
 		// ManyToMany annotation to specify the relationship field or property of the embeddable class. The dot (".")
 		// notation syntax must be used in the mappedBy element to indicate the relationship attribute within the embedded
 		// attribute. The value of each identifier used with the dot notation is the name of the respective embedded field
 		// or property.
 		Session s;
 		s = openSession();
 		s.getTransaction().begin();
 		Employee e = new Employee();
 		e.setName( "Sharon" );
 		List<PhoneNumber> phoneNumbers = new ArrayList<PhoneNumber>();
 		Collection<Employee> employees = new ArrayList<Employee>();
 		employees.add( e );
 		ContactInfo contactInfo = new ContactInfo();
 		PhoneNumber number = new PhoneNumber();
 		number.setEmployees( employees );
 		phoneNumbers.add( number );
 		contactInfo.setPhoneNumbers( phoneNumbers );
 		e.setContactInfo( contactInfo );
 		s.persist( e );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.getTransaction().begin();
 		e = (Employee)s.get( e.getClass(),e.getId() );
 		// follow both directions of many to many association 
 		assertEquals("same employee", e.getName(), e.getContactInfo().getPhoneNumbers().get(0).getEmployees().iterator().next().getName());
 		s.getTransaction().commit();
 
 		s.close();
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-4685" )
 	public void testOneToManyEmbeddableBiDirectionalDotNotationInMappedBy() throws Exception {
 		// Section 11.1.26
 		// The ManyToOne annotation may be used within an embeddable class to specify a relationship from the embeddable
 		// class to an entity class. If the relationship is bidirectional, the non-owning OneToMany entity side must use the
 		// mappedBy element of the OneToMany annotation to specify the relationship field or property of the embeddable field
 		// or property on the owning side of the relationship. The dot (".") notation syntax must be used in the mappedBy
 		// element to indicate the relationship attribute within the embedded attribute. The value of each identifier used
 		// with the dot notation is the name of the respective embedded field or property.
 		Session s;
 		s = openSession();
 		s.getTransaction().begin();
 		Employee e = new Employee();
 		JobInfo job = new JobInfo();
 		job.setJobDescription( "Sushi Chef" );
 		ProgramManager pm = new ProgramManager();
 		Collection<Employee> employees = new ArrayList<Employee>();
 		employees.add(e);
 		pm.setManages( employees );
 		job.setPm(pm);
 		e.setJobInfo( job );
 		s.persist( e );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.getTransaction().begin();
 		e = (Employee) s.get( e.getClass(), e.getId() );
 		assertEquals( "same job in both directions", 
 			e.getJobInfo().getJobDescription(),
 			e.getJobInfo().getPm().getManages().iterator().next().getJobInfo().getJobDescription()  );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Override
     protected Class[] getAnnotatedClasses() {
 		return new Class[]{
 				Friend.class,
 				Employer.class,
 				Employee.class,
 				Contractor.class,
 				Man.class,
 				Woman.class,
 				Store.class,
 				KnownClient.class,
 				Supplier.class,
 				City.class,
 				Cat.class,
 				Group.class,
 				GroupWithSet.class,
 				Permission.class,
 				Zone.class,
 				Inspector.class,
 				InspectorPrefixes.class,
 				BuildingCompany.class,
 				Building.class,
 				PhoneNumber.class,
 				ProgramManager.class
 		};
 	}
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/annotations/onetomany/OrderByTest.java b/hibernate-core/src/test/java/org/hibernate/test/annotations/onetomany/OrderByTest.java
index c30fef4081..bbda8d5c31 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/annotations/onetomany/OrderByTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/annotations/onetomany/OrderByTest.java
@@ -1,538 +1,538 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.annotations.onetomany;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.Criteria;
 import org.hibernate.NullPrecedence;
 import org.hibernate.Session;
 import org.hibernate.dialect.H2Dialect;
 import org.hibernate.dialect.MySQLDialect;
 import org.hibernate.dialect.Oracle8iDialect;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.sql.SimpleSelect;
 import org.hibernate.testing.RequiresDialect;
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.junit.Assert;
 import org.junit.Test;
 
 /**
  * @author Emmanuel Bernard
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  * @author Brett Meyer
  */
 public class OrderByTest extends BaseCoreFunctionalTestCase {
 	@Test
 	public void testOrderByOnIdClassProperties() throws Exception {
 		Session s = openSession( );
 		s.getTransaction().begin();
 		Order o = new Order();
 		o.setAcademicYear( 2000 );
 		o.setSchoolId( "Supelec" );
 		o.setSchoolIdSort( 1 );
 		s.persist( o );
 		OrderItem oi1 = new OrderItem();
 		oi1.setAcademicYear( 2000 );
 		oi1.setDayName( "Monday" );
 		oi1.setSchoolId( "Supelec" );
 		oi1.setOrder( o );
 		oi1.setDayNo( 23 );
 		s.persist( oi1 );
 		OrderItem oi2 = new OrderItem();
 		oi2.setAcademicYear( 2000 );
 		oi2.setDayName( "Tuesday" );
 		oi2.setSchoolId( "Supelec" );
 		oi2.setOrder( o );
 		oi2.setDayNo( 30 );
 		s.persist( oi2 );
 		s.flush();
 		s.clear();
 
 		OrderID oid = new OrderID();
 		oid.setAcademicYear( 2000 );
 		oid.setSchoolId( "Supelec" );
 		o = (Order) s.get( Order.class, oid );
 		assertEquals( 30, o.getItemList().get( 0 ).getDayNo().intValue() );
 
 		s.getTransaction().rollback();
 		s.close();
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-465")
 	@RequiresDialect(value = { H2Dialect.class, MySQLDialect.class },
 			comment = "By default H2 places NULL values first, so testing 'NULLS LAST' expression. " +
 					"For MySQL testing overridden Dialect#renderOrderByElement(String, String, String, NullPrecedence) method. " +
 					"MySQL does not support NULLS FIRST / LAST syntax at the moment, so transforming the expression to 'CASE WHEN ...'.")
 	public void testAnnotationNullsFirstLast() {
 		Session session = openSession();
 
 		// Populating database with test data.
 		session.getTransaction().begin();
 		Tiger tiger1 = new Tiger();
 		tiger1.setName( null ); // Explicitly setting null value.
 		Tiger tiger2 = new Tiger();
 		tiger2.setName( "Max" );
 		Monkey monkey1 = new Monkey();
 		monkey1.setName( "Michael" );
 		Monkey monkey2 = new Monkey();
 		monkey2.setName( null );  // Explicitly setting null value.
 		Zoo zoo = new Zoo( "Warsaw ZOO" );
 		zoo.getTigers().add( tiger1 );
 		zoo.getTigers().add( tiger2 );
 		zoo.getMonkeys().add( monkey1 );
 		zoo.getMonkeys().add( monkey2 );
 		session.persist( zoo );
 		session.persist( tiger1 );
 		session.persist( tiger2 );
 		session.persist( monkey1 );
 		session.persist( monkey2 );
 		session.getTransaction().commit();
 
 		session.clear();
 
 		session.getTransaction().begin();
 		zoo = (Zoo) session.get( Zoo.class, zoo.getId() );
 		// Testing @org.hibernate.annotations.OrderBy.
 		Iterator<Tiger> iterator1 = zoo.getTigers().iterator();
 		Assert.assertEquals( tiger2.getName(), iterator1.next().getName() );
 		Assert.assertNull( iterator1.next().getName() );
 		// Testing @javax.persistence.OrderBy.
 		Iterator<Monkey> iterator2 = zoo.getMonkeys().iterator();
 		Assert.assertEquals( monkey1.getName(), iterator2.next().getName() );
 		Assert.assertNull( iterator2.next().getName() );
 		session.getTransaction().commit();
 
 		session.clear();
 
 		// Cleanup data.
 		session.getTransaction().begin();
 		session.delete( tiger1 );
 		session.delete( tiger2 );
 		session.delete( monkey1 );
 		session.delete( monkey2 );
 		session.delete( zoo );
 		session.getTransaction().commit();
 
 		session.close();
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-465")
 	@RequiresDialect(value = { H2Dialect.class, MySQLDialect.class },
 			comment = "By default H2 places NULL values first, so testing 'NULLS LAST' expression. " +
 					"For MySQL testing overridden Dialect#renderOrderByElement(String, String, String, NullPrecedence) method. " +
 					"MySQL does not support NULLS FIRST / LAST syntax at the moment, so transforming the expression to 'CASE WHEN ...'.")
 	public void testCriteriaNullsFirstLast() {
 		Session session = openSession();
 
 		// Populating database with test data.
 		session.getTransaction().begin();
 		Zoo zoo1 = new Zoo( null );
 		Zoo zoo2 = new Zoo( "Warsaw ZOO" );
 		session.persist( zoo1 );
 		session.persist( zoo2 );
 		session.getTransaction().commit();
 
 		session.clear();
 
 		session.getTransaction().begin();
 		Criteria criteria = session.createCriteria( Zoo.class );
 		criteria.addOrder( org.hibernate.criterion.Order.asc( "name" ).nulls( NullPrecedence.LAST ) );
 		Iterator<Zoo> iterator = (Iterator<Zoo>) criteria.list().iterator();
 		Assert.assertEquals( zoo2.getName(), iterator.next().getName() );
 		Assert.assertNull( iterator.next().getName() );
 		session.getTransaction().commit();
 
 		session.clear();
 
 		// Cleanup data.
 		session.getTransaction().begin();
 		session.delete( zoo1 );
 		session.delete( zoo2 );
 		session.getTransaction().commit();
 
 		session.close();
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-465")
 	@RequiresDialect(value = { H2Dialect.class, MySQLDialect.class },
 			comment = "By default H2 places NULL values first, so testing 'NULLS LAST' expression. " +
 					"For MySQL testing overridden Dialect#renderOrderByElement(String, String, String, NullPrecedence) method. " +
 					"MySQL does not support NULLS FIRST / LAST syntax at the moment, so transforming the expression to 'CASE WHEN ...'.")
 	public void testNullsFirstLastSpawnMultipleColumns() {
 		Session session = openSession();
 
 		// Populating database with test data.
 		session.getTransaction().begin();
 		Zoo zoo = new Zoo();
 		zoo.setName( "Berlin ZOO" );
 		Visitor visitor1 = new Visitor( null, null );
 		Visitor visitor2 = new Visitor( null, "Antoniak" );
 		Visitor visitor3 = new Visitor( "Lukasz", "Antoniak" );
 		zoo.getVisitors().add( visitor1 );
 		zoo.getVisitors().add( visitor2 );
 		zoo.getVisitors().add( visitor3 );
 		session.save( zoo );
 		session.save( visitor1 );
 		session.save( visitor2 );
 		session.save( visitor3 );
 		session.getTransaction().commit();
 
 		session.clear();
 
 		session.getTransaction().begin();
 		zoo = (Zoo) session.get( Zoo.class, zoo.getId() );
 		Iterator<Visitor> iterator = zoo.getVisitors().iterator();
 		Assert.assertEquals( 3, zoo.getVisitors().size() );
 		Assert.assertEquals( visitor3, iterator.next() );
 		Assert.assertEquals( visitor2, iterator.next() );
 		Assert.assertEquals( visitor1, iterator.next() );
 		session.getTransaction().commit();
 
 		session.clear();
 
 		// Cleanup data.
 		session.getTransaction().begin();
 		session.delete( visitor1 );
 		session.delete( visitor2 );
 		session.delete( visitor3 );
 		session.delete( zoo );
 		session.getTransaction().commit();
 
 		session.close();
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-465")
 	@RequiresDialect(value = { H2Dialect.class, MySQLDialect.class },
 			comment = "By default H2 places NULL values first, so testing 'NULLS LAST' expression. " +
 					"For MySQL testing overridden Dialect#renderOrderByElement(String, String, String, NullPrecedence) method. " +
 					"MySQL does not support NULLS FIRST / LAST syntax at the moment, so transforming the expression to 'CASE WHEN ...'.")
 	public void testHqlNullsFirstLast() {
 		Session session = openSession();
 
 		// Populating database with test data.
 		session.getTransaction().begin();
 		Zoo zoo1 = new Zoo();
 		zoo1.setName( null );
 		Zoo zoo2 = new Zoo();
 		zoo2.setName( "Warsaw ZOO" );
 		session.persist( zoo1 );
 		session.persist( zoo2 );
 		session.getTransaction().commit();
 
 		session.getTransaction().begin();
 		List<Zoo> orderedResults = (List<Zoo>) session.createQuery( "from Zoo z order by z.name nulls lAsT" ).list();
 		Assert.assertEquals( Arrays.asList( zoo2, zoo1 ), orderedResults );
 		session.getTransaction().commit();
 
 		session.clear();
 
 		// Cleanup data.
 		session.getTransaction().begin();
 		session.delete( zoo1 );
 		session.delete( zoo2 );
 		session.getTransaction().commit();
 
 		session.close();
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-7608" )
 	@RequiresDialect({ H2Dialect.class, Oracle8iDialect.class })
 	public void testOrderByReferencingFormulaColumn() {
 		Session session = openSession();
 
 		// Populating database with test data.
 		session.getTransaction().begin();
 		Box box1 = new Box( 1 );
 		Item item1 = new Item( 1, "1", box1 );
 		Item item2 = new Item( 2, "22", box1 );
 		Item item3 = new Item( 3, "2", box1 );
 		session.persist( box1 );
 		session.persist( item1 );
 		session.persist( item2 );
 		session.persist( item3 );
 		session.flush();
 		session.refresh( item1 );
 		session.refresh( item2 );
 		session.refresh( item3 );
 		session.getTransaction().commit();
 
 		session.clear();
 
 		session.getTransaction().begin();
 		box1 = (Box) session.get( Box.class, box1.getId() );
 		Assert.assertEquals( Arrays.asList( item2, item1, item3 ), box1.getItems() );
 		session.getTransaction().commit();
 
 		session.clear();
 
 		// Cleanup data.
 		session.getTransaction().begin();
 		session.delete( item1 );
 		session.delete( item2 );
 		session.delete( item3 );
 		session.delete( box1 );
 		session.getTransaction().commit();
 
 		session.close();
 	}
 	
 	@Test
 	@TestForIssue(jiraKey = "HHH-5732")
 	public void testInverseIndex() {
 		final CollectionPersister transactionsPersister = sessionFactory().getCollectionPersister(
 				BankAccount.class.getName() + ".transactions" );
 		assertTrue( transactionsPersister.isInverse() );
 
 		Session s = openSession();
 		s.getTransaction().begin();
 
 		BankAccount account = new BankAccount();
 		account.addTransaction( "zzzzz" );
 		account.addTransaction( "aaaaa" );
 		account.addTransaction( "mmmmm" );
 		s.save( account );
 		s.getTransaction().commit();
 
 		s.close();
 
 		s = openSession();
 		s.getTransaction().begin();
 		
 		try {
 			final QueryableCollection queryableCollection = (QueryableCollection) transactionsPersister;
 			SimpleSelect select = new SimpleSelect( getDialect() )
 					.setTableName( queryableCollection.getTableName() )
 					.addColumn( "code" )
 					.addColumn( "transactions_index" );
-			PreparedStatement preparedStatement = ((SessionImplementor)s).getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( select.toStatementString() );
-			ResultSet resultSet = ((SessionImplementor)s).getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( preparedStatement );
+			PreparedStatement preparedStatement = ((SessionImplementor)s).getJdbcCoordinator().getStatementPreparer().prepareStatement( select.toStatementString() );
+			ResultSet resultSet = ((SessionImplementor)s).getJdbcCoordinator().getResultSetReturn().extract( preparedStatement );
 			Map<Integer, String> valueMap = new HashMap<Integer, String>();
 			while ( resultSet.next() ) {
 				final String code = resultSet.getString( 1 );
 				assertFalse( "code column was null", resultSet.wasNull() );
 				final int indx = resultSet.getInt( 2 );
 				assertFalse( "List index column was null", resultSet.wasNull() );
 				valueMap.put( indx, code );
 			}
 			assertEquals( 3, valueMap.size() );
 			assertEquals( "zzzzz", valueMap.get( 0 ) );
 			assertEquals( "aaaaa", valueMap.get( 1 ) );
 			assertEquals( "mmmmm", valueMap.get( 2 ) );
 		}
 		catch ( SQLException e ) {
 			fail(e.getMessage());
 		}
 		finally {
 			s.getTransaction().rollback();
 			s.close();
 		}
 	}
 	
 	@Test
 	@TestForIssue( jiraKey = "HHH-8083" )
 	public void testInverseIndexCascaded() {
 		final Session s = openSession();
 		s.getTransaction().begin();
 
 		Forum forum = new Forum();
 		forum.setName( "forum1" );
 		forum = (Forum) s.merge( forum );
 
 		s.flush();
 		s.clear();
 		sessionFactory().getCache().evictEntityRegions();
 
 		forum = (Forum) s.get( Forum.class, forum.getId() );
 
 		final Post post = new Post();
 		post.setName( "post1" );
 		post.setForum( forum );
 		forum.getPosts().add( post );
 
 		final User user = new User();
 		user.setName( "john" );
 		user.setForum( forum );
 		forum.getUsers().add( user );
 
 		forum = (Forum) s.merge( forum );
 
 		s.flush();
 		s.clear();
 		sessionFactory().getCache().evictEntityRegions();
 
 		forum = (Forum) s.get( Forum.class, forum.getId() );
 
 		final Post post2 = new Post();
 		post2.setName( "post2" );
 		post2.setForum( forum );
 		forum.getPosts().add( post2 );
 
 		forum = (Forum) s.merge( forum );
 
 		s.flush();
 		s.clear();
 		sessionFactory().getCache().evictEntityRegions();
 
 		forum = (Forum) s.get( Forum.class, forum.getId() );
 
 		assertEquals( 2, forum.getPosts().size() );
 		assertEquals( "post1", forum.getPosts().get( 0 ).getName() );
 		assertEquals( "post2", forum.getPosts().get( 1 ).getName() );
 		assertEquals( 1, forum.getUsers().size() );
 		assertEquals( "john", forum.getUsers().get( 0 ).getName() );
 	}
   
 	@Test
 	@TestForIssue(jiraKey = "HHH-8794")
 	public void testOrderByNoElement() {
 
 		final Session s = openSession();
 		s.getTransaction().begin();
 
 		Employee employee = new Employee( 1 );
 
 		Computer computer = new Computer( 1 );
 		computer.setComputerName( "Bob's computer" );
 		computer.setEmployee( employee );
 
 		Computer computer2 = new Computer( 2 );
 		computer2.setComputerName( "Alice's computer" );
 		computer2.setEmployee( employee );
 
 		s.save( employee );
 		s.save( computer2 );
 		s.save( computer );
 
 		s.flush();
 		s.clear();
 		sessionFactory().getCache().evictEntityRegions();
 
 		employee = (Employee) s.get( Employee.class, employee.getId() );
 
 		assertEquals( 2, employee.getAssets().size() );
 		assertEquals( 1, employee.getAssets().get( 0 ).getIdAsset().intValue() );
 		assertEquals( 2, employee.getAssets().get( 1 ).getIdAsset().intValue() );
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-9002" )
 	public void testOrderByOneToManyWithJoinTable() {
 		A a = new A();
 		a.setName( "a" );
 		B b1 = new B();
 		b1.setName( "b1" );
 		B b2 = new B();
 		b2.setName( "b2" );
 		C c11 = new C();
 		c11.setName( "c11" );
 		C c12 = new C();
 		c12.setName( "c12" );
 		C c21 = new C();
 		c21.setName( "c21" );
 		C c22 = new C();
 		c22.setName( "c22" );
 
 		a.getBs().add( b1 );
 		a.getBs().add( b2 );
 		b1.getCs().add( c11 );
 		b1.getCs().add( c12 );
 		b2.getCs().add( c21 );
 		b2.getCs().add( c22 );
 
 		Session s = openSession();
 		s.getTransaction().begin();
 		s.persist( a );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.getTransaction().begin();
 
 		b1 =  (B) s.get( B.class, b1.getId() );
 		assertEquals( "b1", b1.getName() );
 		List<C> cs = b1.getCs();
 		assertEquals( 2, cs.size() );
 		assertEquals( "c11", cs.get( 0 ).getName() );
 		assertEquals( "c12", cs.get( 1 ).getName() );
 
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.getTransaction().begin();
 
 		a = (A) s.get( A.class, a.getId() );
 		assertEquals( "a", a.getName() );
 		assertEquals( 2, a.getBs().size() );
 		List<B> bs = a.getBs();
 		assertEquals( "b1", bs.get( 0 ).getName() );
 		assertEquals( "b2", bs.get( 1 ).getName() );
 		List<C> b1cs = bs.get( 0 ).getCs();
 		assertEquals( 2, b1cs.size() );
 		assertEquals( "c11", b1cs.get( 0 ).getName() );
 		assertEquals( "c12", b1cs.get( 1 ).getName() );
 		List<C> b2cs = bs.get( 1 ).getCs();
 		assertEquals( 2, b2cs.size() );
 		assertEquals( "c21", b2cs.get( 0 ).getName() );
 		assertEquals( "c22", b2cs.get( 1 ).getName() );
 
 		s.delete( a );
 
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Override
 	protected Class[] getAnnotatedClasses() {
 		return new Class[] {
 				Order.class, OrderItem.class, Zoo.class, Tiger.class,
 				Monkey.class, Visitor.class, Box.class, Item.class,
 				BankAccount.class, Transaction.class,
 				Comment.class, Forum.class, Post.class, User.class,
 				Asset.class, Computer.class, Employee.class,
 				A.class, B.class, C.class
 		};
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/batch/BatchingBatchFailureTest.java b/hibernate-core/src/test/java/org/hibernate/test/batch/BatchingBatchFailureTest.java
index f05899cd95..1277553900 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/batch/BatchingBatchFailureTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/batch/BatchingBatchFailureTest.java
@@ -1,150 +1,150 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.batch;
 
 import javax.persistence.Column;
 import javax.persistence.Entity;
 import javax.persistence.Id;
 import javax.persistence.Table;
 
 import java.lang.reflect.Field;
 import java.util.Map;
 
 import org.hibernate.Session;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.engine.jdbc.batch.internal.AbstractBatchImpl;
 import org.hibernate.engine.jdbc.batch.internal.BatchingBatch;
 import org.hibernate.engine.jdbc.batch.spi.Batch;
 import org.hibernate.engine.spi.SessionImplementor;
 
 import org.junit.Test;
 
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.fail;
 
 /**
  * @author Shawn Clowater
  * @author Steve Ebersole
  */
 @TestForIssue( jiraKey = "HHH-7689" )
 public class BatchingBatchFailureTest extends BaseCoreFunctionalTestCase {
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[] { User.class };
 	}
 
 	@Override
 	protected void configure(Configuration configuration) {
 		super.configure( configuration );
 		// explicitly enable batching
 		configuration.setProperty( AvailableSettings.STATEMENT_BATCH_SIZE, "5" );
 		// and disable in-vm nullability checking (so we can force in-db not-null constraint violations)
 		configuration.setProperty( AvailableSettings.CHECK_NULLABILITY, "false" );
 	}
 
 	@Test
 	public void testBasicInsertion() {
 		Session session = openSession();
 		session.getTransaction().begin();
 
 		try {
 			session.persist( new User( 1, "ok" ) );
 			session.persist( new User( 2, null ) );
 			session.persist( new User( 3, "ok" ) );
 			session.persist( new User( 4, "ok" ) );
 			session.persist( new User( 5, "ok" ) );
 			session.persist( new User( 6, "ok" ) );
 			// the flush should fail
 			session.flush();
 			fail( "Expecting failed flush" );
 		}
 		catch (Exception expected) {
 			System.out.println( "Caught expected exception : " + expected );
 			expected.printStackTrace( System.out );
 
 			try {
 				//at this point the transaction is still active but the batch should have been aborted (have to use reflection to get at the field)
 				SessionImplementor sessionImplementor = (SessionImplementor) session;
-				Field field = sessionImplementor.getTransactionCoordinator().getJdbcCoordinator().getClass().getDeclaredField( "currentBatch" );
+				Field field = sessionImplementor.getJdbcCoordinator().getClass().getDeclaredField( "currentBatch" );
 				field.setAccessible( true );
-				Batch batch = (Batch) field.get( sessionImplementor.getTransactionCoordinator().getJdbcCoordinator() );
+				Batch batch = (Batch) field.get( sessionImplementor.getJdbcCoordinator() );
 				if ( batch == null ) {
 					throw new Exception( "Current batch was null" );
 				}
 				else {
 					//make sure it's actually a batching impl
 					assertEquals( BatchingBatch.class, batch.getClass() );
 					field = AbstractBatchImpl.class.getDeclaredField( "statements" );
 					field.setAccessible( true );
 					//check to see that there aren't any statements queued up (this can be an issue if using SavePoints)
 					assertEquals( 0, ((Map) field.get( batch )).size() );
 				}
 			}
 			catch (Exception fieldException) {
 				fail( "Couldn't inspect field " + fieldException.getMessage() );
 			}
 		}
 		finally {
 			session.getTransaction().rollback();
 			session.close();
 		}
 	}
 
 	@Entity( name = "User" )
 	@Table( name = "`USER`" )
 	public static class User {
 		private Integer id;
 		private String name;
 
 		public User() {
 		}
 
 		public User(Integer id, String name) {
 			this.id = id;
 			this.name = name;
 		}
 
 		@Id
 		public Integer getId() {
 			return id;
 		}
 
 		public void setId(Integer id) {
 			this.id = id;
 		}
 
 		@Column( nullable = false )
 		public String getName() {
 			return name;
 		}
 
 		public void setName(String name) {
 			this.name = name;
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/batch/NonBatchingBatchFailureTest.java b/hibernate-core/src/test/java/org/hibernate/test/batch/NonBatchingBatchFailureTest.java
index 212e9724f4..73bae090a3 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/batch/NonBatchingBatchFailureTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/batch/NonBatchingBatchFailureTest.java
@@ -1,146 +1,146 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.batch;
 
 import javax.persistence.Column;
 import javax.persistence.Entity;
 import javax.persistence.Id;
 import javax.persistence.Table;
 import java.lang.reflect.Field;
 import java.util.Map;
 
 import org.hibernate.Session;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.engine.jdbc.batch.internal.AbstractBatchImpl;
 import org.hibernate.engine.jdbc.batch.internal.NonBatchingBatch;
 import org.hibernate.engine.jdbc.batch.spi.Batch;
 import org.hibernate.engine.spi.SessionImplementor;
 
 import org.junit.Test;
 
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.fail;
 
 /**
  * @author Shawn Clowater
  * @author Steve Ebersole
  */
 @TestForIssue( jiraKey = "HHH-7689" )
 public class NonBatchingBatchFailureTest extends BaseCoreFunctionalTestCase {
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[] { User.class };
 	}
 
 	@Override
 	protected void configure(Configuration configuration) {
 		super.configure( configuration );
 		// explicitly disable batching
 		configuration.setProperty( AvailableSettings.STATEMENT_BATCH_SIZE, "-1" );
 		// and disable in-vm nullability checking (so we can force in-db not-null constraint violations)
 		configuration.setProperty( AvailableSettings.CHECK_NULLABILITY, "false" );
 	}
 
 	@Test
 	public void testBasicInsertion() {
 		Session session = openSession();
 		session.getTransaction().begin();
 
 		try {
 			session.persist( new User( 1, "ok" ) );
 			session.persist( new User( 2, null ) );
 			session.persist( new User( 3, "ok" ) );
 			// the flush should fail
 			session.flush();
 			fail( "Expecting failed flush" );
 		}
 		catch (Exception expected) {
 			System.out.println( "Caught expected exception : " + expected );
 			expected.printStackTrace( System.out );
 
 			try {
 				//at this point the transaction is still active but the batch should have been aborted (have to use reflection to get at the field)
 				SessionImplementor sessionImplementor = (SessionImplementor) session;
-				Field field = sessionImplementor.getTransactionCoordinator().getJdbcCoordinator().getClass().getDeclaredField( "currentBatch" );
+				Field field = sessionImplementor.getJdbcCoordinator().getClass().getDeclaredField( "currentBatch" );
 				field.setAccessible( true );
-				Batch batch = (Batch) field.get( sessionImplementor.getTransactionCoordinator().getJdbcCoordinator() );
+				Batch batch = (Batch) field.get( sessionImplementor.getJdbcCoordinator() );
 				if ( batch == null ) {
 					throw new Exception( "Current batch was null" );
 				}
 				else {
 					//make sure it's actually a batching impl
 					assertEquals( NonBatchingBatch.class, batch.getClass() );
 					field = AbstractBatchImpl.class.getDeclaredField( "statements" );
 					field.setAccessible( true );
 					//check to see that there aren't any statements queued up (this can be an issue if using SavePoints)
 					assertEquals( 0, ((Map) field.get( batch )).size() );
 				}
 			}
 			catch (Exception fieldException) {
 				fail( "Couldn't inspect field " + fieldException.getMessage() );
 			}
 		}
 		finally {
 			session.getTransaction().rollback();
 			session.close();
 		}
 	}
 
 	@Entity( name = "User" )
 	@Table( name = "`USER`" )
 	public static class User {
 		private Integer id;
 		private String name;
 
 		public User() {
 		}
 
 		public User(Integer id, String name) {
 			this.id = id;
 			this.name = name;
 		}
 
 		@Id
 		public Integer getId() {
 			return id;
 		}
 
 		public void setId(Integer id) {
 			this.id = id;
 		}
 
 		@Column( nullable = false )
 		public String getName() {
 			return name;
 		}
 
 		public void setName(String name) {
 			this.name = name;
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/cascade/MultiPathCascadeTest.java b/hibernate-core/src/test/java/org/hibernate/test/cascade/MultiPathCascadeTest.java
index f426c030bc..389d8d3c67 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/cascade/MultiPathCascadeTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/cascade/MultiPathCascadeTest.java
@@ -1,357 +1,358 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cascade;
 
 import org.junit.Test;
 
 import org.hibernate.Session;
+import org.hibernate.TransactionException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertSame;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author <a href="mailto:ovidiu@feodorov.com">Ovidiu Feodorov</a>
  * @author Gail Badner
  */
 public class MultiPathCascadeTest extends BaseCoreFunctionalTestCase {
 	@Override
 	public String[] getMappings() {
 		return new String[] {
 				"cascade/MultiPathCascade.hbm.xml"
 		};
 	}
 
 	@Override
 	protected void cleanupTest() {
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "delete from A" );
 		s.createQuery( "delete from G" );
 		s.createQuery( "delete from H" );
 	}
 
 	@Test
 	public void testMultiPathMergeModifiedDetached() throws Exception {
 		// persist a simple A in the database
 
 		Session s = openSession();
 		s.beginTransaction();
 		A a = new A();
 		a.setData( "Anna" );
 		s.save( a );
 		s.getTransaction().commit();
 		s.close();
 
 		// modify detached entity
 		modifyEntity( a );
 
 		s = openSession();
 		s.beginTransaction();
 		a = (A) s.merge( a );
 		s.getTransaction().commit();
 		s.close();
 
 		verifyModifications( a.getId() );
 	}
 
 	@Test
 	public void testMultiPathMergeModifiedDetachedIntoProxy() throws Exception {
 		// persist a simple A in the database
 
 		Session s = openSession();
 		s.beginTransaction();
 		A a = new A();
 		a.setData( "Anna" );
 		s.save( a );
 		s.getTransaction().commit();
 		s.close();
 
 		// modify detached entity
 		modifyEntity( a );
 
 		s = openSession();
 		s.beginTransaction();
 		A aLoaded = (A) s.load( A.class, new Long( a.getId() ) );
 		assertTrue( aLoaded instanceof HibernateProxy );
 		assertSame( aLoaded, s.merge( a ) );
 		s.getTransaction().commit();
 		s.close();
 
 		verifyModifications( a.getId() );
 	}
 
 	@Test
 	public void testMultiPathUpdateModifiedDetached() throws Exception {
 		// persist a simple A in the database
 
 		Session s = openSession();
 		s.beginTransaction();
 		A a = new A();
 		a.setData( "Anna" );
 		s.save( a );
 		s.getTransaction().commit();
 		s.close();
 
 		// modify detached entity
 		modifyEntity( a );
 
 		s = openSession();
 		s.beginTransaction();
 		s.update( a );
 		s.getTransaction().commit();
 		s.close();
 
 		verifyModifications( a.getId() );
 	}
 
 	@Test
 	public void testMultiPathGetAndModify() throws Exception {
 		// persist a simple A in the database
 
 		Session s = openSession();
 		s.beginTransaction();
 		A a = new A();
 		a.setData( "Anna" );
 		s.save( a );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		// retrieve the previously saved instance from the database, and update it
 		a = (A) s.get( A.class, new Long( a.getId() ) );
 		modifyEntity( a );
 		s.getTransaction().commit();
 		s.close();
 
 		verifyModifications( a.getId() );
 	}
 
 	@Test
 	public void testMultiPathMergeNonCascadedTransientEntityInCollection() throws Exception {
 		// persist a simple A in the database
 
 		Session s = openSession();
 		s.beginTransaction();
 		A a = new A();
 		a.setData( "Anna" );
 		s.save( a );
 		s.getTransaction().commit();
 		s.close();
 
 		// modify detached entity
 		modifyEntity( a );
 
 		s = openSession();
 		s.beginTransaction();
 		a = (A) s.merge( a );
 		s.getTransaction().commit();
 		s.close();
 
 		verifyModifications( a.getId() );
 
 		// add a new (transient) G to collection in h
 		// there is no cascade from H to the collection, so this should fail when merged
 		assertEquals( 1, a.getHs().size() );
 		H h = (H) a.getHs().iterator().next();
 		G gNew = new G();
 		gNew.setData( "Gail" );
 		gNew.getHs().add( h );
 		h.getGs().add( gNew );
 
 		s = openSession();
 		s.beginTransaction();
 		try {
 			s.merge( a );
 			s.merge( h );
 			s.getTransaction().commit();
 			fail( "should have thrown TransientObjectException" );
 		}
-		catch (TransientObjectException ex) {
-			// expected
+		catch (TransactionException e) {
+			assertTrue( e.getCause() instanceof TransientObjectException );
 		}
 		finally {
 			s.getTransaction().rollback();
 		}
 		s.close();
 	}
 
 	@Test
 	public void testMultiPathMergeNonCascadedTransientEntityInOneToOne() throws Exception {
 		// persist a simple A in the database
 
 		Session s = openSession();
 		s.beginTransaction();
 		A a = new A();
 		a.setData( "Anna" );
 		s.save( a );
 		s.getTransaction().commit();
 		s.close();
 
 		// modify detached entity
 		modifyEntity( a );
 
 		s = openSession();
 		s.beginTransaction();
 		a = (A) s.merge( a );
 		s.getTransaction().commit();
 		s.close();
 
 		verifyModifications( a.getId() );
 
 		// change the one-to-one association from g to be a new (transient) A
 		// there is no cascade from G to A, so this should fail when merged
 		G g = a.getG();
 		a.setG( null );
 		A aNew = new A();
 		aNew.setData( "Alice" );
 		g.setA( aNew );
 		aNew.setG( g );
 
 		s = openSession();
 		s.beginTransaction();
 		try {
 			s.merge( a );
 			s.merge( g );
 			s.getTransaction().commit();
 			fail( "should have thrown TransientObjectException" );
 		}
-		catch (TransientObjectException ex) {
-			// expected
+		catch (TransactionException e) {
+			assertTrue( e.getCause() instanceof TransientObjectException );
 		}
 		finally {
 			s.getTransaction().rollback();
 		}
 		s.close();
 	}
 
 	@Test
 	public void testMultiPathMergeNonCascadedTransientEntityInManyToOne() throws Exception {
 		// persist a simple A in the database
 
 		Session s = openSession();
 		s.beginTransaction();
 		A a = new A();
 		a.setData( "Anna" );
 		s.save( a );
 		s.getTransaction().commit();
 		s.close();
 
 		// modify detached entity
 		modifyEntity( a );
 
 		s = openSession();
 		s.beginTransaction();
 		a = (A) s.merge( a );
 		s.getTransaction().commit();
 		s.close();
 
 		verifyModifications( a.getId() );
 
 		// change the many-to-one association from h to be a new (transient) A
 		// there is no cascade from H to A, so this should fail when merged
 		assertEquals( 1, a.getHs().size() );
 		H h = (H) a.getHs().iterator().next();
 		a.getHs().remove( h );
 		A aNew = new A();
 		aNew.setData( "Alice" );
 		aNew.addH( h );
 
 		s = openSession();
 		s.beginTransaction();
 		try {
 			s.merge( a );
 			s.merge( h );
 			s.getTransaction().commit();
 			fail( "should have thrown TransientObjectException" );
 		}
-		catch (TransientObjectException ex) {
-			// expected
+		catch (TransactionException e) {
+			assertTrue( e.getCause() instanceof TransientObjectException );
 		}
 		finally {
 			s.getTransaction().rollback();
 		}
 		s.close();
 	}
 
 	private void modifyEntity(A a) {
 		// create a *circular* graph in detached entity
 		a.setData( "Anthony" );
 
 		G g = new G();
 		g.setData( "Giovanni" );
 
 		H h = new H();
 		h.setData( "Hellen" );
 
 		a.setG( g );
 		g.setA( a );
 
 		a.getHs().add( h );
 		h.setA( a );
 
 		g.getHs().add( h );
 		h.getGs().add( g );
 	}
 
 	private void verifyModifications(long aId) {
 		Session s = openSession();
 		s.beginTransaction();
 
 		// retrieve the A object and check it
 		A a = (A) s.get( A.class, new Long( aId ) );
 		assertEquals( aId, a.getId() );
 		assertEquals( "Anthony", a.getData() );
 		assertNotNull( a.getG() );
 		assertNotNull( a.getHs() );
 		assertEquals( 1, a.getHs().size() );
 
 		G gFromA = a.getG();
 		H hFromA = (H) a.getHs().iterator().next();
 
 		// check the G object
 		assertEquals( "Giovanni", gFromA.getData() );
 		assertSame( a, gFromA.getA() );
 		assertNotNull( gFromA.getHs() );
 		assertEquals( a.getHs(), gFromA.getHs() );
 		assertSame( hFromA, gFromA.getHs().iterator().next() );
 
 		// check the H object
 		assertEquals( "Hellen", hFromA.getData() );
 		assertSame( a, hFromA.getA() );
 		assertNotNull( hFromA.getGs() );
 		assertEquals( 1, hFromA.getGs().size() );
 		assertSame( gFromA, hFromA.getGs().iterator().next() );
 
 		s.getTransaction().commit();
 		s.close();
 	}
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/cascade/RefreshTest.java b/hibernate-core/src/test/java/org/hibernate/test/cascade/RefreshTest.java
index ba73ce98c1..10d0dfe6f2 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/cascade/RefreshTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/cascade/RefreshTest.java
@@ -1,103 +1,103 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2006-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cascade;
 import static org.junit.Assert.assertEquals;
 
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Date;
 import java.util.Iterator;
 
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.junit.Test;
 
 /**
  * Implementation of RefreshTest.
  *
  * @author Steve Ebersole
  */
 public class RefreshTest extends BaseCoreFunctionalTestCase {
 	@Override
 	public String[] getMappings() {
 		return new String[] { "cascade/Job.hbm.xml", "cascade/JobBatch.hbm.xml" };
 	}
 
 	@Test
 	public void testRefreshCascade() throws Throwable {
 		Session session = openSession();
 		Transaction txn = session.beginTransaction();
 
 		JobBatch batch = new JobBatch( new Date() );
 		batch.createJob().setProcessingInstructions( "Just do it!" );
 		batch.createJob().setProcessingInstructions( "I know you can do it!" );
 
 		// write the stuff to the database; at this stage all job.status values are zero
 		session.persist( batch );
 		session.flush();
 
 		// behind the session's back, let's modify the statuses
 		updateStatuses( (SessionImplementor)session );
 
 		// Now lets refresh the persistent batch, and see if the refresh cascaded to the jobs collection elements
 		session.refresh( batch );
 
 		Iterator itr = batch.getJobs().iterator();
 		while( itr.hasNext() ) {
 			Job job = ( Job ) itr.next();
 			assertEquals( "Jobs not refreshed!", 1, job.getStatus() );
 		}
 
 		txn.rollback();
 		session.close();
 	}
 
 	private void updateStatuses(final SessionImplementor session) throws Throwable {
 		((Session)session).doWork(
 				new Work() {
 					@Override
 					public void execute(Connection connection) throws SQLException {
 						PreparedStatement stmnt = null;
 						try {
-							stmnt = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( "UPDATE T_JOB SET JOB_STATUS = 1" );
-							session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( stmnt );
+							stmnt = session.getJdbcCoordinator().getStatementPreparer().prepareStatement( "UPDATE T_JOB SET JOB_STATUS = 1" );
+							session.getJdbcCoordinator().getResultSetReturn().executeUpdate( stmnt );
 						}
 						finally {
 							if ( stmnt != null ) {
 								try {
-									session.getTransactionCoordinator().getJdbcCoordinator().release( stmnt );
+									session.getJdbcCoordinator().getResourceRegistry().release( stmnt );
 								}
 								catch( Throwable ignore ) {
 								}
 							}
 						}
 					}
 				}
 		);
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/cascade/circle/MultiPathCircleCascadeTest.java b/hibernate-core/src/test/java/org/hibernate/test/cascade/circle/MultiPathCircleCascadeTest.java
index 902b66d997..f06b341c65 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/cascade/circle/MultiPathCircleCascadeTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/cascade/circle/MultiPathCircleCascadeTest.java
@@ -1,706 +1,713 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cascade.circle;
 
 import java.util.Iterator;
 
 import org.junit.Test;
 
 import org.hibernate.JDBCException;
 import org.hibernate.PropertyValueException;
 import org.hibernate.Session;
 import org.hibernate.TransientPropertyValueException;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertSame;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * The test case uses the following model:
  *
  *                          <-    ->
  *                      -- (N : 0,1) -- Tour
  *                      |    <-   ->
  *                      | -- (1 : N) -- (pickup) ----
  *               ->     | |                          |
  * Route -- (1 : N) -- Node                      Transport
  *                      |  <-   ->                |
  *                      -- (1 : N) -- (delivery) --
  *
  *  Arrows indicate the direction of cascade-merge, cascade-save, and cascade-save-or-update
  *
  * It reproduced the following issues:
  * http://opensource.atlassian.com/projects/hibernate/browse/HHH-3046
  * http://opensource.atlassian.com/projects/hibernate/browse/HHH-3810
  * <p/>
  * This tests that cascades are done properly from each entity.
  *
  * @author Pavol Zibrita, Gail Badner
  */
 public class MultiPathCircleCascadeTest extends BaseCoreFunctionalTestCase {
 	private static interface EntityOperation {
 		Object doEntityOperation(Object entity, Session s);
 	}
 	private static EntityOperation MERGE_OPERATION =
 			new EntityOperation() {
 				@Override
 				public Object doEntityOperation(Object entity, Session s) {
 					return s.merge( entity );
 				}
 			};
 	private static EntityOperation SAVE_OPERATION =
 			new EntityOperation() {
 				@Override
 				public Object doEntityOperation(Object entity, Session s) {
 					s.save( entity );
 					return entity;
 				}
 			};
 	private static EntityOperation SAVE_UPDATE_OPERATION =
 			new EntityOperation() {
 				@Override
 				public Object doEntityOperation(Object entity, Session s) {
 					s.saveOrUpdate( entity );
 					return entity;
 				}
 			};
 
 	@Override
 	public void configure(Configuration cfg) {
 		cfg.setProperty( Environment.GENERATE_STATISTICS, "true" );
 		cfg.setProperty( Environment.STATEMENT_BATCH_SIZE, "0" );
 	}
 
 	@Override
 	public String[] getMappings() {
 		return new String[] {
 				"cascade/circle/MultiPathCircleCascade.hbm.xml"
 		};
 	}
 
 	@Test
 	public void testMergeEntityWithNonNullableTransientEntity() {
 		testEntityWithNonNullableTransientEntity( MERGE_OPERATION );
 	}
 	@Test
 	public void testSaveEntityWithNonNullableTransientEntity() {
 		testEntityWithNonNullableTransientEntity( SAVE_OPERATION );
 	}
 	@Test
 	public void testSaveUpdateEntityWithNonNullableTransientEntity() {
 		testEntityWithNonNullableTransientEntity( SAVE_UPDATE_OPERATION );
 	}
 	private void testEntityWithNonNullableTransientEntity(EntityOperation operation) {
 
 		Route route = getUpdatedDetachedEntity();
 
 		Node node = (Node) route.getNodes().iterator().next();
 		route.getNodes().remove( node );
 
 		Route routeNew = new Route();
 		routeNew.setName( "new route" );
 		routeNew.getNodes().add( node );
 		node.setRoute( routeNew );
 
 		Session s = openSession();
 		s.beginTransaction();
 
 		try {
 			operation.doEntityOperation( node, s );
 			s.getTransaction().commit();
 			fail( "should have thrown an exception" );
 		}
 		catch (Exception ex) {
 			checkExceptionFromNullValueForNonNullable(
 					ex,
 					((SessionImplementor) s).getFactory().getSettings().isCheckNullability(),
 					false
 			);
 		}
 		finally {
 			s.getTransaction().rollback();
 			s.close();
 			cleanup();
 		}
 	}
 
 	@Test
 	public void testMergeEntityWithNonNullableEntityNull() {
 		testEntityWithNonNullableEntityNull( MERGE_OPERATION );
 	}
 	@Test
 	public void testSaveEntityWithNonNullableEntityNull() {
 		testEntityWithNonNullableEntityNull( SAVE_OPERATION );
 	}
 	@Test
 	public void testSaveUpdateEntityWithNonNullableEntityNull() {
 		testEntityWithNonNullableEntityNull( SAVE_UPDATE_OPERATION );
 	}
 	private void testEntityWithNonNullableEntityNull(EntityOperation operation) {
 		Route route = getUpdatedDetachedEntity();
 
 		Node node = (Node) route.getNodes().iterator().next();
 		route.getNodes().remove( node );
 		node.setRoute( null );
 
 		Session s = openSession();
 		s.beginTransaction();
 
 		try {
 			operation.doEntityOperation( node, s );
 			s.getTransaction().commit();
 			fail( "should have thrown an exception" );
 		}
 		catch (Exception ex) {
 			checkExceptionFromNullValueForNonNullable(
 					ex,
 					((SessionImplementor) s).getFactory().getSettings().isCheckNullability(),
 					true
 			);
 		}
 		finally {
 			s.getTransaction().rollback();
 			s.close();
 			cleanup();
 		}
 	}
 
 	@Test
 	public void testMergeEntityWithNonNullablePropSetToNull() {
 		testEntityWithNonNullablePropSetToNull( MERGE_OPERATION );
 	}
 	@Test
 	public void testSaveEntityWithNonNullablePropSetToNull() {
 		testEntityWithNonNullablePropSetToNull( SAVE_OPERATION );
 	}
 	@Test
 	public void testSaveUpdateEntityWithNonNullablePropSetToNull() {
 		testEntityWithNonNullablePropSetToNull( SAVE_UPDATE_OPERATION );
 	}
 	private void testEntityWithNonNullablePropSetToNull(EntityOperation operation) {
 		Route route = getUpdatedDetachedEntity();
 		Node node = (Node) route.getNodes().iterator().next();
 		node.setName( null );
 
 		Session s = openSession();
 		s.beginTransaction();
 
 		try {
 			operation.doEntityOperation( route, s );
 			s.getTransaction().commit();
 			fail( "should have thrown an exception" );
 		}
 		catch (Exception ex) {
 			checkExceptionFromNullValueForNonNullable(
 					ex,
 					((SessionImplementor) s).getFactory().getSettings().isCheckNullability(),
 					true
 			);
 		}
 		finally {
 			s.getTransaction().rollback();
 			s.close();
 			cleanup();
 		}
 	}
 
 	@Test
 	public void testMergeRoute() {
 		testRoute( MERGE_OPERATION );
 	}
 	// skip SAVE_OPERATION since Route is not transient
 	@Test
 	public void testSaveUpdateRoute() {
 		testRoute( SAVE_UPDATE_OPERATION );
 	}
 	private void testRoute(EntityOperation operation) {
 
 		Route route = getUpdatedDetachedEntity();
 
 		clearCounts();
 
 		Session s = openSession();
 		s.beginTransaction();
 
 		operation.doEntityOperation( route, s );
 
 		s.getTransaction().commit();
 		s.close();
 
 		assertInsertCount( 4 );
 		assertUpdateCount( 1 );
 
 		s = openSession();
 		s.beginTransaction();
 		route = (Route) s.get( Route.class, route.getRouteID() );
 		checkResults( route, true );
 		s.getTransaction().commit();
 		s.close();
 
 		cleanup();
 	}
 
 	@Test
 	public void testMergePickupNode() {
 		testPickupNode( MERGE_OPERATION );
 	}
 	@Test
 	public void testSavePickupNode() {
 		testPickupNode( SAVE_OPERATION );
 	}
 	@Test
 	public void testSaveUpdatePickupNode() {
 		testPickupNode( SAVE_UPDATE_OPERATION );
 	}
 	private void testPickupNode(EntityOperation operation) {
 
 		Route route = getUpdatedDetachedEntity();
 
 		clearCounts();
 
 		Session s = openSession();
 		s.beginTransaction();
 
 		Iterator it = route.getNodes().iterator();
 		Node node = (Node) it.next();
 		Node pickupNode;
 		if ( node.getName().equals( "pickupNodeB" ) ) {
 			pickupNode = node;
 		}
 		else {
 			node = (Node) it.next();
 			assertEquals( "pickupNodeB", node.getName() );
 			pickupNode = node;
 		}
 
 		pickupNode = (Node) operation.doEntityOperation( pickupNode, s );
 
 		s.getTransaction().commit();
 		s.close();
 
 		assertInsertCount( 4 );
 		assertUpdateCount( 0 );
 
 		s = openSession();
 		s.beginTransaction();
 		route = (Route) s.get( Route.class, route.getRouteID() );
 		checkResults( route, false );
 		s.getTransaction().commit();
 		s.close();
 
 		cleanup();
 	}
 
 	@Test
 	public void testMergeDeliveryNode() {
 		testDeliveryNode( MERGE_OPERATION );
 	}
 	@Test
 	public void testSaveDeliveryNode() {
 		testDeliveryNode( SAVE_OPERATION );
 	}
 	@Test
 	public void testSaveUpdateDeliveryNode() {
 		testDeliveryNode( SAVE_UPDATE_OPERATION );
 	}
 	private void testDeliveryNode(EntityOperation operation) {
 
 		Route route = getUpdatedDetachedEntity();
 
 		clearCounts();
 
 		Session s = openSession();
 		s.beginTransaction();
 
 		Iterator it = route.getNodes().iterator();
 		Node node = (Node) it.next();
 		Node deliveryNode;
 		if ( node.getName().equals( "deliveryNodeB" ) ) {
 			deliveryNode = node;
 		}
 		else {
 			node = (Node) it.next();
 			assertEquals( "deliveryNodeB", node.getName() );
 			deliveryNode = node;
 		}
 
 		deliveryNode = (Node) operation.doEntityOperation( deliveryNode, s );
 
 		s.getTransaction().commit();
 		s.close();
 
 		assertInsertCount( 4 );
 		assertUpdateCount( 0 );
 
 		s = openSession();
 		s.beginTransaction();
 		route = (Route) s.get( Route.class, route.getRouteID() );
 		checkResults( route, false );
 		s.getTransaction().commit();
 		s.close();
 
 		cleanup();
 	}
 
 	@Test
 	public void testMergeTour() {
 		testTour( MERGE_OPERATION );
 	}
 	@Test
 	public void testSaveTour() {
 		testTour( SAVE_OPERATION );
 	}
 	@Test
 	public void testSaveUpdateTour() {
 		testTour( SAVE_UPDATE_OPERATION );
 	}
 	private void testTour(EntityOperation operation) {
 
 		Route route = getUpdatedDetachedEntity();
 
 		clearCounts();
 
 		Session s = openSession();
 		s.beginTransaction();
 
 		Tour tour = (Tour) operation.doEntityOperation( ((Node) route.getNodes().toArray()[0]).getTour(), s );
 
 		s.getTransaction().commit();
 		s.close();
 
 		assertInsertCount( 4 );
 		assertUpdateCount( 0 );
 
 		s = openSession();
 		s.beginTransaction();
 		route = (Route) s.get( Route.class, route.getRouteID() );
 		checkResults( route, false );
 		s.getTransaction().commit();
 		s.close();
 
 		cleanup();
 	}
 
 	@Test
 	public void testMergeTransport() {
 		testTransport( MERGE_OPERATION );
 	}
 	@Test
 	public void testSaveTransport() {
 		testTransport( SAVE_OPERATION );
 	}
 	@Test
 	public void testSaveUpdateTransport() {
 		testTransport( SAVE_UPDATE_OPERATION );
 	}
 	private void testTransport(EntityOperation operation) {
 
 		Route route = getUpdatedDetachedEntity();
 
 		clearCounts();
 
 		Session s = openSession();
 		s.beginTransaction();
 
 		Node node = ((Node) route.getNodes().toArray()[0]);
 		Transport transport;
 		if ( node.getPickupTransports().size() == 1 ) {
 			transport = (Transport) node.getPickupTransports().toArray()[0];
 		}
 		else {
 			transport = (Transport) node.getDeliveryTransports().toArray()[0];
 		}
 
 		transport = (Transport) operation.doEntityOperation( transport, s );
 
 		s.getTransaction().commit();
 		s.close();
 
 		assertInsertCount( 4 );
 		assertUpdateCount( 0 );
 
 		s = openSession();
 		s.beginTransaction();
 		route = (Route) s.get( Route.class, route.getRouteID() );
 		checkResults( route, false );
 		s.getTransaction().commit();
 		s.close();
 
 		cleanup();
 	}
 
+	private Node getSimpleUpdatedDetachedEntity(){
+
+		Node deliveryNode = new Node();
+		deliveryNode.setName( "deliveryNodeB" );
+		return deliveryNode;
+	}
+
 	private Route getUpdatedDetachedEntity() {
 
 		Session s = openSession();
 		s.beginTransaction();
 
 		Route route = new Route();
 		route.setName( "routeA" );
 
 		s.save( route );
 		s.getTransaction().commit();
 		s.close();
 
 		route.setName( "new routeA" );
 		route.setTransientField( new String( "sfnaouisrbn" ) );
 
 		Tour tour = new Tour();
 		tour.setName( "tourB" );
 
 		Transport transport = new Transport();
 		transport.setName( "transportB" );
 
 		Node pickupNode = new Node();
 		pickupNode.setName( "pickupNodeB" );
 
 		Node deliveryNode = new Node();
 		deliveryNode.setName( "deliveryNodeB" );
 
 		pickupNode.setRoute( route );
 		pickupNode.setTour( tour );
 		pickupNode.getPickupTransports().add( transport );
 		pickupNode.setTransientField( "pickup node aaaaaaaaaaa" );
 
 		deliveryNode.setRoute( route );
 		deliveryNode.setTour( tour );
 		deliveryNode.getDeliveryTransports().add( transport );
 		deliveryNode.setTransientField( "delivery node aaaaaaaaa" );
 
 		tour.getNodes().add( pickupNode );
 		tour.getNodes().add( deliveryNode );
 
 		route.getNodes().add( pickupNode );
 		route.getNodes().add( deliveryNode );
 
 		transport.setPickupNode( pickupNode );
 		transport.setDeliveryNode( deliveryNode );
 		transport.setTransientField( "aaaaaaaaaaaaaa" );
 
 		return route;
 	}
 
 	private void cleanup() {
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "delete from Transport" );
 		s.createQuery( "delete from Tour" );
 		s.createQuery( "delete from Node" );
 		s.createQuery( "delete from Route" );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	private void checkResults(Route route, boolean isRouteUpdated) {
 		// since no cascaded to route, this method needs to
 		// know whether route is expected to be updated
 		if ( isRouteUpdated ) {
 			assertEquals( "new routeA", route.getName() );
 		}
 		assertEquals( 2, route.getNodes().size() );
 		Node deliveryNode = null;
 		Node pickupNode = null;
 		for ( Iterator it = route.getNodes().iterator(); it.hasNext(); ) {
 			Node node = (Node) it.next();
 			if ( "deliveryNodeB".equals( node.getName() ) ) {
 				deliveryNode = node;
 			}
 			else if ( "pickupNodeB".equals( node.getName() ) ) {
 				pickupNode = node;
 			}
 			else {
 				fail( "unknown node" );
 			}
 		}
 		assertNotNull( deliveryNode );
 		assertSame( route, deliveryNode.getRoute() );
 		assertEquals( 1, deliveryNode.getDeliveryTransports().size() );
 		assertEquals( 0, deliveryNode.getPickupTransports().size() );
 		assertNotNull( deliveryNode.getTour() );
 		assertEquals( "node original value", deliveryNode.getTransientField() );
 
 		assertNotNull( pickupNode );
 		assertSame( route, pickupNode.getRoute() );
 		assertEquals( 0, pickupNode.getDeliveryTransports().size() );
 		assertEquals( 1, pickupNode.getPickupTransports().size() );
 		assertNotNull( pickupNode.getTour() );
 		assertEquals( "node original value", pickupNode.getTransientField() );
 
 		assertTrue( !deliveryNode.getNodeID().equals( pickupNode.getNodeID() ) );
 		assertSame( deliveryNode.getTour(), pickupNode.getTour() );
 		assertSame(
 				deliveryNode.getDeliveryTransports().iterator().next(),
 				pickupNode.getPickupTransports().iterator().next()
 		);
 
 		Tour tour = deliveryNode.getTour();
 		Transport transport = (Transport) deliveryNode.getDeliveryTransports().iterator().next();
 
 		assertEquals( "tourB", tour.getName() );
 		assertEquals( 2, tour.getNodes().size() );
 		assertTrue( tour.getNodes().contains( deliveryNode ) );
 		assertTrue( tour.getNodes().contains( pickupNode ) );
 
 		assertEquals( "transportB", transport.getName() );
 		assertSame( deliveryNode, transport.getDeliveryNode() );
 		assertSame( pickupNode, transport.getPickupNode() );
 		assertEquals( "transport original value", transport.getTransientField() );
 	}
 
 	@Test
 	public void testMergeData3Nodes() {
 		testData3Nodes( MERGE_OPERATION );
 	}
 	@Test
 	public void testSaveData3Nodes() {
 		testData3Nodes( SAVE_OPERATION );
 	}
 	@Test
 	public void testSaveUpdateData3Nodes() {
 		testData3Nodes( SAVE_UPDATE_OPERATION );
 	}
 	private void testData3Nodes(EntityOperation operation) {
 
 		Session s = openSession();
 		s.beginTransaction();
 
 		Route route = new Route();
 		route.setName( "routeA" );
 
 		s.save( route );
 		s.getTransaction().commit();
 		s.close();
 
 		clearCounts();
 
 		s = openSession();
 		s.beginTransaction();
 
 		route = (Route) s.get( Route.class, route.getRouteID() );
 		//System.out.println(route);
 		route.setName( "new routA" );
 
 		route.setTransientField( new String( "sfnaouisrbn" ) );
 
 		Tour tour = new Tour();
 		tour.setName( "tourB" );
 
 		Transport transport1 = new Transport();
 		transport1.setName( "TRANSPORT1" );
 
 		Transport transport2 = new Transport();
 		transport2.setName( "TRANSPORT2" );
 
 		Node node1 = new Node();
 		node1.setName( "NODE1" );
 
 		Node node2 = new Node();
 		node2.setName( "NODE2" );
 
 		Node node3 = new Node();
 		node3.setName( "NODE3" );
 
 		node1.setRoute( route );
 		node1.setTour( tour );
 		node1.getPickupTransports().add( transport1 );
 		node1.setTransientField( "node 1" );
 
 		node2.setRoute( route );
 		node2.setTour( tour );
 		node2.getDeliveryTransports().add( transport1 );
 		node2.getPickupTransports().add( transport2 );
 		node2.setTransientField( "node 2" );
 
 		node3.setRoute( route );
 		node3.setTour( tour );
 		node3.getDeliveryTransports().add( transport2 );
 		node3.setTransientField( "node 3" );
 
 		tour.getNodes().add( node1 );
 		tour.getNodes().add( node2 );
 		tour.getNodes().add( node3 );
 
 		route.getNodes().add( node1 );
 		route.getNodes().add( node2 );
 		route.getNodes().add( node3 );
 
 		transport1.setPickupNode( node1 );
 		transport1.setDeliveryNode( node2 );
 		transport1.setTransientField( "aaaaaaaaaaaaaa" );
 
 		transport2.setPickupNode( node2 );
 		transport2.setDeliveryNode( node3 );
 		transport2.setTransientField( "bbbbbbbbbbbbb" );
 
 		operation.doEntityOperation( route, s );
 
 		s.getTransaction().commit();
 		s.close();
 
 		assertInsertCount( 6 );
 		assertUpdateCount( 1 );
 
 		cleanup();
 	}
 
 	protected void checkExceptionFromNullValueForNonNullable(
 			Exception ex, boolean checkNullability, boolean isNullValue
 	) {
 		if ( isNullValue ) {
 			if ( checkNullability ) {
 				assertTrue( ex instanceof PropertyValueException );
 			}
 			else {
-				assertTrue( ex instanceof JDBCException );
+				assertTrue( (ex instanceof JDBCException) || (ex.getCause() instanceof JDBCException) );
 			}
 		}
 		else {
 			assertTrue( ex instanceof TransientPropertyValueException );
 		}
 	}
 
 	protected void clearCounts() {
 		sessionFactory().getStatistics().clear();
 	}
 
 	protected void assertInsertCount(int expected) {
 		int inserts = (int) sessionFactory().getStatistics().getEntityInsertCount();
 		assertEquals( "unexpected insert count", expected, inserts );
 	}
 
 	protected void assertUpdateCount(int expected) {
 		int updates = (int) sessionFactory().getStatistics().getEntityUpdateCount();
 		assertEquals( "unexpected update counts", expected, updates );
 	}
 
 	protected void assertDeleteCount(int expected) {
 		int deletes = (int) sessionFactory().getStatistics().getEntityDeleteCount();
 		assertEquals( "unexpected delete counts", expected, deletes );
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/collection/list/PersistentListTest.java b/hibernate-core/src/test/java/org/hibernate/test/collection/list/PersistentListTest.java
index 2650769820..d77bd92772 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/collection/list/PersistentListTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/collection/list/PersistentListTest.java
@@ -1,219 +1,219 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.collection.list;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.Session;
 import org.hibernate.collection.internal.PersistentList;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.sql.SimpleSelect;
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.junit.Test;
 
 /**
  * Tests related to operations on a PersistentList
  *
  * @author Steve Ebersole
  */
 public class PersistentListTest extends BaseCoreFunctionalTestCase {
 	
 	@Override
 	public String[] getMappings() {
 		return new String[] { "collection/list/Mappings.hbm.xml" };
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-5732"  )
 	public void testInverseListIndex() {
 		// make sure no one changes the mapping
 		final CollectionPersister collectionPersister = sessionFactory().getCollectionPersister( ListOwner.class.getName() + ".children" );
 		assertTrue( collectionPersister.isInverse() );
 
 		// do some creations...
 		Session session = openSession();
 		session.beginTransaction();
 
 		ListOwner root = new ListOwner( "root" );
 		ListOwner child1 = new ListOwner( "c1" );
 		root.getChildren().add( child1 );
 		child1.setParent( root );
 		ListOwner child2 = new ListOwner( "c2" );
 		root.getChildren().add( child2 );
 		child2.setParent( root );
 
 		session.save( root );
 		session.getTransaction().commit();
 		session.close();
 
 		// now, make sure the list-index column gotten written...
 		final Session session2 = openSession();
 		session2.beginTransaction();
 		session2.doWork(
 				new Work() {
 					@Override
 					public void execute(Connection connection) throws SQLException {
 						final QueryableCollection queryableCollection = (QueryableCollection) collectionPersister;
 						SimpleSelect select = new SimpleSelect( getDialect() )
 								.setTableName( queryableCollection.getTableName() )
 								.addColumn( "NAME" )
 								.addColumn( "LIST_INDEX" )
 								.addCondition( "NAME", "<>", "?" );
-						PreparedStatement preparedStatement = ((SessionImplementor)session2).getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( select.toStatementString() );
+						PreparedStatement preparedStatement = ((SessionImplementor)session2).getJdbcCoordinator().getStatementPreparer().prepareStatement( select.toStatementString() );
 						preparedStatement.setString( 1, "root" );
-						ResultSet resultSet = ((SessionImplementor)session2).getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( preparedStatement );
+						ResultSet resultSet = ((SessionImplementor)session2).getJdbcCoordinator().getResultSetReturn().extract( preparedStatement );
 						Map<String, Integer> valueMap = new HashMap<String, Integer>();
 						while ( resultSet.next() ) {
 							final String name = resultSet.getString( 1 );
 							assertFalse( "NAME column was null", resultSet.wasNull() );
 							final int position = resultSet.getInt( 2 );
 							assertFalse( "LIST_INDEX column was null", resultSet.wasNull() );
 							valueMap.put( name, position );
 						}
 						assertEquals( 2, valueMap.size() );
 
 						// c1 should be list index 0
 						assertEquals( Integer.valueOf( 0 ), valueMap.get( "c1" ) );
 						// c2 should be list index 1
 						assertEquals( Integer.valueOf( 1 ), valueMap.get( "c2" ) );
 					}
 				}
 		);
 		session2.delete( root );
 		session2.getTransaction().commit();
 		session2.close();
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-5732"  )
 	public void testInverseListIndex2() {
 		// make sure no one changes the mapping
 		final CollectionPersister collectionPersister = sessionFactory().getCollectionPersister( Order.class.getName() + ".lineItems" );
 		assertTrue( collectionPersister.isInverse() );
 
 		// do some creations...
 		Session session = openSession();
 		session.beginTransaction();
 
 		Order order = new Order( "acme-1" );
 		order.addLineItem( "abc", 2 );
 		order.addLineItem( "def", 200 );
 		order.addLineItem( "ghi", 13 );
 		session.save( order );
 		session.getTransaction().commit();
 		session.close();
 
 		// now, make sure the list-index column gotten written...
 		final Session session2 = openSession();
 		session2.beginTransaction();
 		session2.doWork(
 				new Work() {
 					@Override
 					public void execute(Connection connection) throws SQLException {
 						final QueryableCollection queryableCollection = (QueryableCollection) collectionPersister;
 						SimpleSelect select = new SimpleSelect( getDialect() )
 								.setTableName( queryableCollection.getTableName() )
 								.addColumn( "ORDER_ID" )
 								.addColumn( "INDX" )
 								.addColumn( "PRD_CODE" );
-						PreparedStatement preparedStatement = ((SessionImplementor)session2).getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( select.toStatementString() );
-						ResultSet resultSet = ((SessionImplementor)session2).getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( preparedStatement );
+						PreparedStatement preparedStatement = ((SessionImplementor)session2).getJdbcCoordinator().getStatementPreparer().prepareStatement( select.toStatementString() );
+						ResultSet resultSet = ((SessionImplementor)session2).getJdbcCoordinator().getResultSetReturn().extract( preparedStatement );
 						Map<String, Integer> valueMap = new HashMap<String, Integer>();
 						while ( resultSet.next() ) {
 							final int fk = resultSet.getInt( 1 );
 							assertFalse( "Collection key (FK) column was null", resultSet.wasNull() );
 							final int indx = resultSet.getInt( 2 );
 							assertFalse( "List index column was null", resultSet.wasNull() );
 							final String prodCode = resultSet.getString( 3 );
 							assertFalse( "Prod code column was null", resultSet.wasNull() );
 							valueMap.put( prodCode, indx );
 						}
 						assertEquals( 3, valueMap.size() );
 						assertEquals( Integer.valueOf( 0 ), valueMap.get( "abc" ) );
 						assertEquals( Integer.valueOf( 1 ), valueMap.get( "def" ) );
 						assertEquals( Integer.valueOf( 2 ), valueMap.get( "ghi" ) );
 					}
 				}
 		);
 		session2.delete( order );
 		session2.getTransaction().commit();
 		session2.close();
 	}
 
 	@Test
 	public void testWriteMethodDirtying() {
 		ListOwner parent = new ListOwner( "root" );
 		ListOwner child = new ListOwner( "c1" );
 		parent.getChildren().add( child );
 		child.setParent( parent );
 		ListOwner otherChild = new ListOwner( "c2" );
 
 		Session session = openSession();
 		session.beginTransaction();
 		session.save( parent );
 		session.flush();
 		// at this point, the list on parent has now been replaced with a PersistentList...
 		PersistentList children = (PersistentList) parent.getChildren();
 
 		assertFalse( children.remove( otherChild ) );
 		assertFalse( children.isDirty() );
 
 		ArrayList otherCollection = new ArrayList();
 		otherCollection.add( child );
 		assertFalse( children.retainAll( otherCollection ) );
 		assertFalse( children.isDirty() );
 
 		otherCollection = new ArrayList();
 		otherCollection.add( otherChild );
 		assertFalse( children.removeAll( otherCollection ) );
 		assertFalse( children.isDirty() );
 
 		children.clear();
 		session.delete( child );
 		assertTrue( children.isDirty() );
 
 		session.flush();
 
 		children.clear();
 		assertFalse( children.isDirty() );
 
 		session.delete( parent );
 		session.getTransaction().commit();
 		session.close();
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/common/JdbcConnectionAccessImpl.java b/hibernate-core/src/test/java/org/hibernate/test/common/JdbcConnectionAccessImpl.java
index e05b2341cb..8525c2f64d 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/common/JdbcConnectionAccessImpl.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/common/JdbcConnectionAccessImpl.java
@@ -1,66 +1,61 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.common;
 
 import java.sql.Connection;
 import java.sql.SQLException;
 
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
-import org.hibernate.engine.transaction.spi.TransactionEnvironment;
 import org.hibernate.service.ServiceRegistry;
 
 /**
  * @author Steve Ebersole
  */
 public class JdbcConnectionAccessImpl implements JdbcConnectionAccess {
 	private final ConnectionProvider connectionProvider;
 
-	public JdbcConnectionAccessImpl(TransactionEnvironment transactionEnvironment) {
-		this( transactionEnvironment.getSessionFactory().getServiceRegistry() );
-	}
-
 	public JdbcConnectionAccessImpl(ConnectionProvider connectionProvider) {
 		this.connectionProvider = connectionProvider;
 	}
 
 	public JdbcConnectionAccessImpl(ServiceRegistry serviceRegistry) {
 		this( serviceRegistry.getService( ConnectionProvider.class ) );
 	}
 
 	@Override
 	public Connection obtainConnection() throws SQLException {
 		return connectionProvider.getConnection();
 	}
 
 	@Override
 	public void releaseConnection(Connection connection) throws SQLException {
 		connectionProvider.closeConnection( connection );
 	}
 
 	@Override
 	public boolean supportsAggressiveRelease() {
 		return connectionProvider.supportsAggressiveRelease();
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/common/JournalingTransactionObserver.java b/hibernate-core/src/test/java/org/hibernate/test/common/JournalingTransactionObserver.java
index 68dd256e87..d4f6c9b262 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/common/JournalingTransactionObserver.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/common/JournalingTransactionObserver.java
@@ -1,60 +1,59 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.common;
 
-import org.hibernate.engine.transaction.spi.TransactionImplementor;
 import org.hibernate.engine.transaction.spi.TransactionObserver;
 
 /**
 * @author Steve Ebersole
 */
 public class JournalingTransactionObserver implements TransactionObserver {
 	private int begins = 0;
 	private int beforeCompletions = 0;
 	private int afterCompletions = 0;
 
-	public void afterBegin(TransactionImplementor transaction) {
+	public void afterBegin() {
 		begins++;
 	}
 
-	public void beforeCompletion(TransactionImplementor transaction) {
+	public void beforeCompletion() {
 		beforeCompletions++;
 	}
 
-	public void afterCompletion(boolean successful, TransactionImplementor transaction) {
+	public void afterCompletion(boolean successful) {
 		afterCompletions++;
 	}
 
 	public int getBegins() {
 		return begins;
 	}
 
 	public int getBeforeCompletions() {
 		return beforeCompletions;
 	}
 
 	public int getAfterCompletions() {
 		return afterCompletions;
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/common/TransactionContextImpl.java b/hibernate-core/src/test/java/org/hibernate/test/common/TransactionContextImpl.java
deleted file mode 100644
index b7a8c8de62..0000000000
--- a/hibernate-core/src/test/java/org/hibernate/test/common/TransactionContextImpl.java
+++ /dev/null
@@ -1,146 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.test.common;
-
-import org.hibernate.ConnectionReleaseMode;
-import org.hibernate.engine.jdbc.connections.spi.JdbcConnectionAccess;
-import org.hibernate.engine.transaction.spi.TransactionContext;
-import org.hibernate.engine.transaction.spi.TransactionEnvironment;
-import org.hibernate.engine.transaction.spi.TransactionImplementor;
-import org.hibernate.service.ServiceRegistry;
-
-/**
- * @author Steve Ebersole
- */
-public class TransactionContextImpl implements TransactionContext {
-	private final TransactionEnvironment transactionEnvironment;
-	private final JdbcConnectionAccess jdbcConnectionAccess;
-
-	public TransactionContextImpl(TransactionEnvironment transactionEnvironment, JdbcConnectionAccess jdbcConnectionAccess) {
-		this.transactionEnvironment = transactionEnvironment;
-		this.jdbcConnectionAccess = jdbcConnectionAccess;
-	}
-
-	public TransactionContextImpl(TransactionEnvironment transactionEnvironment, ServiceRegistry serviceRegistry) {
-		this( transactionEnvironment, new JdbcConnectionAccessImpl( serviceRegistry ) );
-	}
-
-	public TransactionContextImpl(TransactionEnvironment transactionEnvironment) {
-		this( transactionEnvironment, new JdbcConnectionAccessImpl( transactionEnvironment.getJdbcServices().getConnectionProvider() ) );
-	}
-
-	@Override
-	public TransactionEnvironment getTransactionEnvironment() {
-		return transactionEnvironment;
-	}
-
-	@Override
-	public ConnectionReleaseMode getConnectionReleaseMode() {
-		return transactionEnvironment.getTransactionFactory().getDefaultReleaseMode();
-	}
-
-	@Override
-	public JdbcConnectionAccess getJdbcConnectionAccess() {
-		return jdbcConnectionAccess;
-	}
-
-	@Override
-	public boolean shouldAutoJoinTransaction() {
-		return true;
-	}
-
-	@Override
-	public boolean isAutoCloseSessionEnabled() {
-		return false;
-	}
-
-	@Override
-	public boolean isClosed() {
-		return false;
-	}
-
-	@Override
-	public boolean isFlushModeNever() {
-		return false;
-	}
-
-	@Override
-	public boolean isFlushBeforeCompletionEnabled() {
-		return true;
-	}
-
-	@Override
-	public void managedFlush() {
-	}
-
-	@Override
-	public boolean shouldAutoClose() {
-		return false;
-	}
-
-	@Override
-	public void managedClose() {
-	}
-
-	@Override
-	public void afterTransactionBegin(TransactionImplementor hibernateTransaction) {
-	}
-
-	@Override
-	public void beforeTransactionCompletion(TransactionImplementor hibernateTransaction) {
-	}
-
-	@Override
-	public void afterTransactionCompletion(TransactionImplementor hibernateTransaction, boolean successful) {
-	}
-
-	@Override
-	public String onPrepareStatement(String sql) {
-		return sql;
-	}
-
-	@Override
-	public void startPrepareStatement() {
-	}
-
-	@Override
-	public void endPrepareStatement() {
-	}
-
-	@Override
-	public void startStatementExecution() {
-	}
-
-	@Override
-	public void endStatementExecution() {
-	}
-
-	@Override
-	public void startBatchExecution() {
-	}
-
-	@Override
-	public void endBatchExecution() {
-	}
-}
diff --git a/hibernate-core/src/test/java/org/hibernate/test/common/TransactionEnvironmentImpl.java b/hibernate-core/src/test/java/org/hibernate/test/common/TransactionEnvironmentImpl.java
deleted file mode 100644
index be0ed8f3a5..0000000000
--- a/hibernate-core/src/test/java/org/hibernate/test/common/TransactionEnvironmentImpl.java
+++ /dev/null
@@ -1,80 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.test.common;
-
-import org.hibernate.cfg.AvailableSettings;
-import org.hibernate.cfg.Configuration;
-import org.hibernate.engine.jdbc.spi.JdbcServices;
-import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.engine.transaction.spi.TransactionEnvironment;
-import org.hibernate.engine.transaction.spi.TransactionFactory;
-import org.hibernate.service.ServiceRegistry;
-import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
-import org.hibernate.stat.internal.ConcurrentStatisticsImpl;
-import org.hibernate.stat.spi.StatisticsImplementor;
-
-/**
- * @author Steve Ebersole
- */
-public class TransactionEnvironmentImpl implements TransactionEnvironment {
-	private final ServiceRegistry serviceRegistry;
-	private final ConcurrentStatisticsImpl statistics = new ConcurrentStatisticsImpl();
-	private final SessionFactoryImplementor sessionFactory;
-
-	public static final String NAME = "TransactionEnvironmentImpl_testSF";
-
-	public TransactionEnvironmentImpl(ServiceRegistry serviceRegistry) {
-		this.serviceRegistry = serviceRegistry;
-
-		Configuration cfg = new Configuration()
-				.setProperty( AvailableSettings.SESSION_FACTORY_NAME, NAME )
-				.setProperty( AvailableSettings.SESSION_FACTORY_NAME_IS_JNDI, "false" ); // default is true
-		sessionFactory = (SessionFactoryImplementor) cfg.buildSessionFactory(serviceRegistry);
-	}
-
-	@Override
-	public SessionFactoryImplementor getSessionFactory() {
-		return sessionFactory;
-	}
-
-	@Override
-	public JdbcServices getJdbcServices() {
-		return serviceRegistry.getService( JdbcServices.class );
-	}
-
-	@Override
-	public JtaPlatform getJtaPlatform() {
-		return serviceRegistry.getService( JtaPlatform.class );
-	}
-
-	@Override
-	public TransactionFactory getTransactionFactory() {
-		return serviceRegistry.getService( TransactionFactory.class );
-	}
-
-	@Override
-	public StatisticsImplementor getStatisticsImplementor() {
-		return statistics;
-	}
-}
diff --git a/hibernate-core/src/test/java/org/hibernate/test/connections/AggressiveReleaseTest.java b/hibernate-core/src/test/java/org/hibernate/test/connections/AggressiveReleaseTest.java
index 0b27677973..fdbe8ad572 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/connections/AggressiveReleaseTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/connections/AggressiveReleaseTest.java
@@ -1,250 +1,255 @@
 // $Id: AggressiveReleaseTest.java 10977 2006-12-12 23:28:04Z steve.ebersole@jboss.com $
 package org.hibernate.test.connections;
 
 import java.sql.Connection;
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.Hibernate;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
+import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.H2Dialect;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
-import org.hibernate.engine.transaction.internal.jta.CMTTransactionFactory;
 import org.hibernate.internal.util.SerializationHelper;
+import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorBuilderImpl;
+import org.hibernate.stat.Statistics;
 
 import org.hibernate.testing.RequiresDialect;
 import org.hibernate.testing.jta.TestingJtaBootstrap;
 import org.hibernate.testing.jta.TestingJtaPlatformImpl;
+
+import org.junit.Ignore;
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * Implementation of AggressiveReleaseTest.
  *
  * @author Steve Ebersole
  */
 @RequiresDialect(H2Dialect.class)
 public class AggressiveReleaseTest extends ConnectionManagementTestCase {
 	@Override
 	@SuppressWarnings("unchecked")
 	protected void addSettings(Map settings) {
 		super.addSettings( settings );
 
 		TestingJtaBootstrap.prepare( settings );
-		settings.put( Environment.TRANSACTION_STRATEGY, CMTTransactionFactory.class.getName() );
+//		settings.put( Environment.TRANSACTION_STRATEGY, CMTTransactionFactory.class.getName() );
+		settings.put( AvailableSettings.TRANSACTION_COORDINATOR_STRATEGY, JtaTransactionCoordinatorBuilderImpl.class.getName() );
 		settings.put( Environment.RELEASE_CONNECTIONS, ConnectionReleaseMode.AFTER_STATEMENT.toString() );
 		settings.put( Environment.GENERATE_STATISTICS, "true" );
 		settings.put( Environment.STATEMENT_BATCH_SIZE, "0" );
 	}
 
 	@Override
 	protected Session getSessionUnderTest() throws Throwable {
 		return openSession();
 	}
 
 	@Override
 	protected void reconnect(Session session) {
 	}
 
 	@Override
 	protected void prepare() throws Throwable {
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 	}
 
 	@Override
 	protected void done() throws Throwable {
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 	}
 
 	// Some additional tests specifically for the aggressive-release functionality...
 
 	@Test
 	public void testSerializationOnAfterStatementAggressiveRelease() throws Throwable {
 		prepare();
 		try {
 			Session s = getSessionUnderTest();
 			Silly silly = new Silly( "silly" );
 			s.save( silly );
 
 			// this should cause the CM to obtain a connection, and then release it
 			s.flush();
 
 			// We should be able to serialize the session at this point...
 			SerializationHelper.serialize( s );
 
 			s.delete( silly );
 			s.flush();
 
 			release( s );
 		}
 		finally {
 			done();
 		}
 	}
 
 	@Test
 	public void testSerializationFailsOnAfterStatementAggressiveReleaseWithOpenResources() throws Throwable {
 		prepare();
 		Session s = getSessionUnderTest();
 
 		Silly silly = new Silly( "silly" );
 		s.save( silly );
 
 		// this should cause the CM to obtain a connection, and then release it
 		s.flush();
 
 		// both scroll() and iterate() cause batching to hold on
 		// to resources, which should make aggressive-release not release
 		// the connection (and thus cause serialization to fail)
 		ScrollableResults sr = s.createQuery( "from Silly" ).scroll();
 
 		try {
 			SerializationHelper.serialize( s );
 			fail( "Serialization allowed on connected session; or aggressive release released connection with open resources" );
 		}
 		catch( IllegalStateException e ) {
 			// expected behavior
 		}
 
 		// getting the first row only because SybaseASE15Dialect throws NullPointerException
 		// if data is not read before closing the ResultSet
 		sr.next();
 
 		// Closing the ScrollableResults does currently force batching to
 		// aggressively release the connection
 		sr.close();
 		SerializationHelper.serialize( s );
 
 		s.delete( silly );
 		s.flush();
 
 		release( s );
 		done();
 	}
 
 	@Test
 	public void testQueryIteration() throws Throwable {
 		prepare();
 		Session s = getSessionUnderTest();
 		Silly silly = new Silly( "silly" );
 		s.save( silly );
 		s.flush();
 
 		Iterator itr = s.createQuery( "from Silly" ).iterate();
 		assertTrue( itr.hasNext() );
 		Silly silly2 = ( Silly ) itr.next();
 		assertEquals( silly, silly2 );
 		Hibernate.close( itr );
 
 		itr = s.createQuery( "from Silly" ).iterate();
 		Iterator itr2 = s.createQuery( "from Silly where name = 'silly'" ).iterate();
 
 		assertTrue( itr.hasNext() );
 		assertEquals( silly, itr.next() );
 		assertTrue( itr2.hasNext() );
 		assertEquals( silly, itr2.next() );
 
 		Hibernate.close( itr );
 		Hibernate.close( itr2 );
 
 		s.delete( silly );
 		s.flush();
 
 		release( s );
 		done();
 	}
 
 	@Test
 	public void testQueryScrolling() throws Throwable {
 		prepare();
 		Session s = getSessionUnderTest();
 		Silly silly = new Silly( "silly" );
 		s.save( silly );
 		s.flush();
 
 		ScrollableResults sr = s.createQuery( "from Silly" ).scroll();
 		assertTrue( sr.next() );
 		Silly silly2 = ( Silly ) sr.get( 0 );
 		assertEquals( silly, silly2 );
 		sr.close();
 
 		sr = s.createQuery( "from Silly" ).scroll();
 		ScrollableResults sr2 = s.createQuery( "from Silly where name = 'silly'" ).scroll();
 
 		assertTrue( sr.next() );
 		assertEquals( silly, sr.get( 0 ) );
 		assertTrue( sr2.next() );
 		assertEquals( silly, sr2.get( 0 ) );
 
 		sr.close();
 		sr2.close();
 
 		s.delete( silly );
 		s.flush();
 
 		release( s );
 		done();
 	}
 
 	@Test
 	public void testSuppliedConnection() throws Throwable {
 		prepare();
 
 		Connection originalConnection = sessionFactory().getServiceRegistry().getService( ConnectionProvider.class ).getConnection();
 		Session session = sessionFactory().withOptions().connection( originalConnection ).openSession();
 
 		Silly silly = new Silly( "silly" );
 		session.save( silly );
 
 		// this will cause the connection manager to cycle through the aggressive release logic;
 		// it should not release the connection since we explicitly suplied it ourselves.
 		session.flush();
 		assertTrue( session.isConnected() );
 
 		session.delete( silly );
 		session.flush();
 
 		release( session );
 		done();
 
 		sessionFactory().getServiceRegistry().getService( ConnectionProvider.class ).closeConnection( originalConnection );
 	}
 
 	@Test
 	public void testConnectionMaintanenceDuringFlush() throws Throwable {
+		final Statistics statistics = sessionFactory().getStatistics();
 		prepare();
 		Session s = getSessionUnderTest();
-		s.beginTransaction();
 
 		List<Silly> entities = new ArrayList<Silly>();
 		for ( int i = 0; i < 10; i++ ) {
 			Other other = new Other( "other-" + i );
 			Silly silly = new Silly( "silly-" + i, other );
 			entities.add( silly );
 			s.save( silly );
 		}
 		s.flush();
 
 		for ( Silly silly : entities ) {
 			silly.setName( "new-" + silly.getName() );
 			silly.getOther().setName( "new-" + silly.getOther().getName() );
 		}
-		long initialCount = sessionFactory().getStatistics().getConnectCount();
+		long initialCount = statistics.getConnectCount();
 		s.flush();
-		assertEquals( "connection not maintained through flush", initialCount + 1, sessionFactory().getStatistics().getConnectCount() );
+		assertEquals( "connection not maintained through flush", initialCount + 1, statistics.getConnectCount() );
 
 		s.createQuery( "delete from Silly" ).executeUpdate();
 		s.createQuery( "delete from Other" ).executeUpdate();
 		s.getTransaction().commit();
 		release( s );
 		done();
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/connections/ThreadLocalCurrentSessionTest.java b/hibernate-core/src/test/java/org/hibernate/test/connections/ThreadLocalCurrentSessionTest.java
index 66159ec1c1..321ca7eda8 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/connections/ThreadLocalCurrentSessionTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/connections/ThreadLocalCurrentSessionTest.java
@@ -1,137 +1,138 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.connections;
 
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.Session;
 import org.hibernate.cfg.Environment;
 import org.hibernate.context.internal.ThreadLocalSessionContext;
 import org.hibernate.dialect.H2Dialect;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.transaction.spi.LocalStatus;
+import org.hibernate.resource.transaction.spi.TransactionStatus;
 
 import org.hibernate.testing.RequiresDialect;
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author Steve Ebersole
  */
 @RequiresDialect(H2Dialect.class)
 public class ThreadLocalCurrentSessionTest extends ConnectionManagementTestCase {
 	@Override
 	@SuppressWarnings("unchecked")
 	protected void addSettings(Map settings) {
 		super.addSettings( settings );
 
 		settings.put( Environment.CURRENT_SESSION_CONTEXT_CLASS, TestableThreadLocalContext.class.getName() );
 		settings.put( Environment.GENERATE_STATISTICS, "true" );
 	}
 
 	@Override
 	protected Session getSessionUnderTest() throws Throwable {
 		Session session = sessionFactory().getCurrentSession();
 		session.beginTransaction();
 		return session;
 	}
 
 	@Override
 	protected void release(Session session) {
-		if ( session.getTransaction().getLocalStatus() != LocalStatus.ACTIVE ) {
+		if ( session.getTransaction().getStatus() != TransactionStatus.ACTIVE ) {
 			TestableThreadLocalContext.unbind( sessionFactory() );
 			return;
 		}
 		long initialCount = sessionFactory().getStatistics().getSessionCloseCount();
 		session.getTransaction().commit();
 		long subsequentCount = sessionFactory().getStatistics().getSessionCloseCount();
 		assertEquals( "Session still open after commit", initialCount + 1, subsequentCount );
 		// also make sure it was cleaned up from the internal ThreadLocal...
 		assertFalse( "session still bound to internal ThreadLocal", TestableThreadLocalContext.hasBind() );
 	}
 
 	@Override
 	protected void reconnect(Session session) throws Throwable {
 	}
 
 	@Override
 	protected void checkSerializedState(Session session) {
 		assertFalse( "session still bound after serialize", TestableThreadLocalContext.isSessionBound( session ) );
 	}
 
 	@Override
 	protected void checkDeserializedState(Session session) {
 		assertTrue( "session not bound after deserialize", TestableThreadLocalContext.isSessionBound( session ) );
 	}
 
 	@Test
 	public void testTransactionProtection() {
 		Session session = sessionFactory().getCurrentSession();
 		try {
 			session.createQuery( "from Silly" );
 			fail( "method other than beginTransaction{} allowed" );
 		}
 		catch ( HibernateException e ) {
 			// ok
 		}
 	}
 
 	@Test
 	public void testContextCleanup() {
 		Session session = sessionFactory().getCurrentSession();
 		session.beginTransaction();
 		session.getTransaction().commit();
 		assertFalse( "session open after txn completion", session.isOpen() );
 		assertFalse( "session still bound after txn completion", TestableThreadLocalContext.isSessionBound( session ) );
 
 		Session session2 = sessionFactory().getCurrentSession();
 		assertFalse( "same session returned after txn completion", session == session2 );
 		session2.close();
 		assertFalse( "session open after closing", session2.isOpen() );
 		assertFalse( "session still bound after closing", TestableThreadLocalContext.isSessionBound( session2 ) );
 	}
 
 	public static class TestableThreadLocalContext extends ThreadLocalSessionContext {
 		private static TestableThreadLocalContext me;
 
 		public TestableThreadLocalContext(SessionFactoryImplementor factory) {
 			super( factory );
 			me = this;
 		}
 
 		public static boolean isSessionBound(Session session) {
 			return sessionMap() != null && sessionMap().containsKey( me.factory() )
 					&& sessionMap().get( me.factory() ) == session;
 		}
 
 		public static boolean hasBind() {
 			return sessionMap() != null && sessionMap().containsKey( me.factory() );
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/dialect/functional/SQLServerDialectTest.java b/hibernate-core/src/test/java/org/hibernate/test/dialect/functional/SQLServerDialectTest.java
index 18a7426fd1..9c643a1181 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/dialect/functional/SQLServerDialectTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/dialect/functional/SQLServerDialectTest.java
@@ -1,389 +1,389 @@
 /*
   * Hibernate, Relational Persistence for Idiomatic Java
   *
   * Copyright (c) 2009, Red Hat, Inc. and/or its affiliates or third-
   * party contributors as indicated by the @author tags or express
   * copyright attribution statements applied by the authors.
   * All third-party contributions are distributed under license by
   * Red Hat, Inc.
   *
   * This copyrighted material is made available to anyone wishing to
   * use, modify, copy, or redistribute it subject to the terms and
   * conditions of the GNU Lesser General Public License, as published
   * by the Free Software Foundation.
   *
   * This program is distributed in the hope that it will be useful,
   * but WITHOUT ANY WARRANTY; without even the implied warranty of
   * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
   * Lesser General Public License for more details.
   *
   * You should have received a copy of the GNU Lesser General Public
   * License along with this distribution; if not, write to:
   *
   * Free Software Foundation, Inc.
   * 51 Franklin Street, Fifth Floor
   * Boston, MA  02110-1301  USA
   */
 package org.hibernate.test.dialect.functional;
 
 import static org.junit.Assert.assertArrayEquals;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 
 import java.sql.Connection;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.Arrays;
 import java.util.List;
 
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.criterion.Order;
 import org.hibernate.criterion.Projections;
 import org.hibernate.dialect.SQLServer2005Dialect;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.exception.LockTimeoutException;
 import org.hibernate.jdbc.ReturningWork;
 import org.hibernate.testing.RequiresDialect;
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.junit.Test;
 
 /**
  * used driver hibernate.connection.driver_class com.microsoft.sqlserver.jdbc.SQLServerDriver
  *
  * @author Guenther Demetz
  */
 @RequiresDialect(value = { SQLServer2005Dialect.class })
 public class SQLServerDialectTest extends BaseCoreFunctionalTestCase {
 	@Test
 	@TestForIssue(jiraKey = "HHH-7198")
 	public void testMaxResultsSqlServerWithCaseSensitiveCollation() throws Exception {
 
 		final Session s = openSession();
 		s.beginTransaction();
 		String defaultCollationName = s.doReturningWork( new ReturningWork<String>() {
 			@Override
 			public String execute(Connection connection) throws SQLException {
 				String databaseName = connection.getCatalog();
-				Statement st = ((SessionImplementor)s).getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().createStatement();
-				ResultSet rs =  ((SessionImplementor)s).getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st, "SELECT collation_name FROM sys.databases WHERE name = '"+databaseName+ "';" );
+				Statement st = ((SessionImplementor)s).getJdbcCoordinator().getStatementPreparer().createStatement();
+				ResultSet rs =  ((SessionImplementor)s).getJdbcCoordinator().getResultSetReturn().extract( st, "SELECT collation_name FROM sys.databases WHERE name = '"+databaseName+ "';" );
 				while(rs.next()){
 					return rs.getString( "collation_name" );
 				}
 				throw new AssertionError( "can't get collation name of database "+databaseName );
 
 			}
 		} );
 		s.getTransaction().commit();
 		s.close();
 
 		Session s2 = openSession();
 		String databaseName = s2.doReturningWork( new ReturningWork<String>() {
 			@Override
 			public String execute(Connection connection) throws SQLException {
 				return connection.getCatalog();
 			}
 		} );
 		s2.createSQLQuery( "ALTER DATABASE " + databaseName + " set single_user with rollback immediate" )
 				.executeUpdate();
 		s2.createSQLQuery( "ALTER DATABASE " + databaseName + " COLLATE Latin1_General_CS_AS" ).executeUpdate();
 		s2.createSQLQuery( "ALTER DATABASE " + databaseName + " set multi_user" ).executeUpdate();
 
 		Transaction tx = s2.beginTransaction();
 
 		for ( int i = 1; i <= 20; i++ ) {
 			s2.persist( new Product2( i, "Kit" + i ) );
 		}
 		s2.flush();
 		s2.clear();
 
 		List list = s2.createQuery( "from Product2 where description like 'Kit%'" )
 				.setFirstResult( 2 )
 				.setMaxResults( 2 )
 				.list();
 		assertEquals( 2, list.size() );
 		tx.rollback();
 		s2.close();
 
 		s2 = openSession();
 		s2.createSQLQuery( "ALTER DATABASE " + databaseName + " set single_user with rollback immediate" )
 				.executeUpdate();
 		s2.createSQLQuery( "ALTER DATABASE " + databaseName + " COLLATE " + defaultCollationName ).executeUpdate();
 		s2.createSQLQuery( "ALTER DATABASE " + databaseName + " set multi_user" ).executeUpdate();
 		s2.close();
 	}
 	
 	private void doWork(Session s) {
 		
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-7369")
 	public void testPaginationWithScalarQuery() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 
 		for ( int i = 0; i < 10; i++ ) {
 			s.persist( new Product2( i, "Kit" + i ) );
 		}
 		s.flush();
 		s.clear();
 
 		List list = s.createSQLQuery( "select id from Product2 where description like 'Kit%' order by id" ).list();
 		assertEquals(Integer.class, list.get(0).getClass()); // scalar result is an Integer
 
 		list = s.createSQLQuery( "select id from Product2 where description like 'Kit%' order by id" ).setFirstResult( 2 ).setMaxResults( 2 ).list();
 		assertEquals(Integer.class, list.get(0).getClass()); // this fails without patch, as result suddenly has become an array
 
 		// same once again with alias
 		list = s.createSQLQuery( "select id as myint from Product2 where description like 'Kit%' order by id asc" ).setFirstResult( 2 ).setMaxResults( 2 ).list();
 		assertEquals(Integer.class, list.get(0).getClass());
 
 		tx.rollback();
 		s.close();
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-7368")
 	public void testPaginationWithTrailingSemicolon() throws Exception {
 		Session s = openSession();
 		s.createSQLQuery( "select id from Product2 where description like 'Kit%' order by id;" )
 				.setFirstResult( 2 ).setMaxResults( 2 ).list();
 		s.close();
 	}
 
 	@Test
 	public void testPaginationWithHQLProjection() {
 		Session session = openSession();
 		Transaction tx = session.beginTransaction();
 
 		for ( int i = 10; i < 20; i++ ) {
 			session.persist( new Product2( i, "Kit" + i ) );
 		}
 		session.flush();
 		session.clear();
 
 		List list = session.createQuery(
 				"select id, description as descr, (select max(id) from Product2) as maximum from Product2"
 		).setFirstResult( 2 ).setMaxResults( 2 ).list();
 		assertEquals( 19, ( (Object[]) list.get( 1 ) )[2] );
 
 		list = session.createQuery( "select id, description, (select max(id) from Product2) from Product2 order by id" )
 				.setFirstResult( 2 ).setMaxResults( 2 ).list();
 		assertEquals( 2, list.size() );
 		assertArrayEquals( new Object[] {12, "Kit12", 19}, (Object[]) list.get( 0 ));
 		assertArrayEquals( new Object[] {13, "Kit13", 19}, (Object[]) list.get( 1 ));
 
 		tx.rollback();
 		session.close();
 	}
 
 	@Test
 	public void testPaginationWithHQL() {
 		Session session = openSession();
 		Transaction tx = session.beginTransaction();
 
 		for ( int i = 20; i < 30; i++ ) {
 			session.persist( new Product2( i, "Kit" + i ) );
 		}
 		session.flush();
 		session.clear();
 
 		List list = session.createQuery( "from Product2 order by id" ).setFirstResult( 3 ).setMaxResults( 2 ).list();
 		assertEquals( Arrays.asList( new Product2( 23, "Kit23" ), new Product2( 24, "Kit24" ) ), list );
 
 		tx.rollback();
 		session.close();
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-7370")
 	public void testPaginationWithMaxOnly() {
 		Session session = openSession();
 		Transaction tx = session.beginTransaction();
 
 		for ( int i = 30; i < 40; i++ ) {
 			session.persist( new Product2( i, "Kit" + i ) );
 		}
 		session.flush();
 		session.clear();
 
 		List list = session.createQuery( "from Product2 order by id" ).setFirstResult( 0 ).setMaxResults( 2 ).list();
 		assertEquals( Arrays.asList( new Product2( 30, "Kit30" ), new Product2( 31, "Kit31" ) ), list );
 
 		list = session.createQuery( "select distinct p from Product2 p order by p.id" ).setMaxResults( 1 ).list();
 		assertEquals( Arrays.asList( new Product2( 30, "Kit30" ) ), list );
 
 		tx.rollback();
 		session.close();
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-6627")
 	public void testPaginationWithAggregation() {
 		Session session = openSession();
 		Transaction tx = session.beginTransaction();
 
 		// populating test data
 		Category category1 = new Category( 1, "Category1" );
 		Category category2 = new Category( 2, "Category2" );
 		Category category3 = new Category( 3, "Category3" );
 		session.persist( category1 );
 		session.persist( category2 );
 		session.persist( category3 );
 		session.flush();
 		session.persist( new Product2( 1, "Kit1", category1 ) );
 		session.persist( new Product2( 2, "Kit2", category1 ) );
 		session.persist( new Product2( 3, "Kit3", category1 ) );
 		session.persist( new Product2( 4, "Kit4", category2 ) );
 		session.persist( new Product2( 5, "Kit5", category2 ) );
 		session.persist( new Product2( 6, "Kit6", category3 ) );
 		session.flush();
 		session.clear();
 
 		// count number of products in each category
 		List<Object[]> result = session.createCriteria( Category.class, "c" ).createAlias( "products", "p" )
 				.setProjection(
 						Projections.projectionList()
 								.add( Projections.groupProperty( "c.id" ) )
 								.add( Projections.countDistinct( "p.id" ) )
 				)
 				.addOrder( Order.asc( "c.id" ) )
 				.setFirstResult( 1 ).setMaxResults( 3 ).list();
 
 		assertEquals( 2, result.size() );
 		assertArrayEquals( new Object[] { 2, 2L }, result.get( 0 ) ); // two products of second category
 		assertArrayEquals( new Object[] { 3, 1L }, result.get( 1 ) ); // one products of third category
 
 		tx.rollback();
 		session.close();
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-7752")
 	public void testPaginationWithFormulaSubquery() {
 		Session session = openSession();
 		Transaction tx = session.beginTransaction();
 
 		// populating test data
 		Folder folder1 = new Folder( 1L, "Folder1" );
 		Folder folder2 = new Folder( 2L, "Folder2" );
 		Folder folder3 = new Folder( 3L, "Folder3" );
 		session.persist( folder1 );
 		session.persist( folder2 );
 		session.persist( folder3 );
 		session.flush();
 		session.persist( new Contact( 1L, "Lukasz", "Antoniak", "owner", folder1 ) );
 		session.persist( new Contact( 2L, "Kinga", "Mroz", "co-owner", folder2 ) );
 		session.flush();
 		session.clear();
 		session.refresh( folder1 );
 		session.refresh( folder2 );
 		session.clear();
 
 		List<Long> folderCount = session.createQuery( "select count(distinct f) from Folder f" ).setMaxResults( 1 ).list();
 		assertEquals( Arrays.asList( 3L ), folderCount );
 
 		List<Folder> distinctFolders = session.createQuery( "select distinct f from Folder f order by f.id desc" )
 				.setFirstResult( 1 ).setMaxResults( 2 ).list();
 		assertEquals( Arrays.asList( folder2, folder1 ), distinctFolders );
 
 		tx.rollback();
 		session.close();
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-7781")
 	public void testPaginationWithCastOperator() {
 		Session session = openSession();
 		Transaction tx = session.beginTransaction();
 
 		for ( int i = 40; i < 50; i++ ) {
 			session.persist( new Product2( i, "Kit" + i ) );
 		}
 		session.flush();
 		session.clear();
 
 		List<Object[]> list = session.createQuery( "select p.id, cast(p.id as string) as string_id from Product2 p order by p.id" )
 				.setFirstResult( 1 ).setMaxResults( 2 ).list();
 		assertEquals( 2, list.size() );
 		assertArrayEquals( new Object[] { 41, "41" }, list.get( 0 ) );
 		assertArrayEquals( new Object[] { 42, "42" }, list.get( 1 ) );
 
 		tx.rollback();
 		session.close();
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-3961")
 	public void testLockNowaitSqlServer() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 
 		final Product2 kit = new Product2();
 		kit.id = 4000;
 		kit.description = "m";
 		s.persist( kit );
 		s.getTransaction().commit();
 		final Transaction tx = s.beginTransaction();
 
 
 		Session s2 = openSession();
 
 		Transaction tx2 = s2.beginTransaction();
 
 		Product2 kit2 = (Product2) s2.byId( Product2.class ).load( kit.id );
 
 		kit.description = "change!";
 		s.flush(); // creates write lock on kit until we end the transaction
 
 		Thread thread = new Thread(
 				new Runnable() {
 					@Override
 					public void run() {
 						try {
 							Thread.sleep( 3000 );
 						}
 						catch ( InterruptedException e ) {
 							e.printStackTrace();
 						}
 						tx.commit();
 					}
 				}
 		);
 
 		LockOptions opt = new LockOptions( LockMode.UPGRADE_NOWAIT );
 		opt.setTimeOut( 0 ); // seems useless
 		long start = System.currentTimeMillis();
 		thread.start();
 		try {
 			s2.buildLockRequest( opt ).lock( kit2 );
 		}
 		catch ( LockTimeoutException e ) {
 			// OK
 		}
 		long end = System.currentTimeMillis();
 		thread.join();
 		long differenceInMillisecs = end - start;
 		assertTrue(
 				"Lock NoWait blocked for " + differenceInMillisecs + " ms, this is definitely to much for Nowait",
 				differenceInMillisecs < 2000
 		);
 
 		s2.getTransaction().rollback();
 		s.getTransaction().begin();
 		s.delete( kit );
 		s.getTransaction().commit();
 	}
 
 	@Override
 	protected java.lang.Class<?>[] getAnnotatedClasses() {
 		return new java.lang.Class[] {
 				Product2.class, Category.class, Folder.class, Contact.class
 		};
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/dialect/functional/cache/SQLFunctionsInterSystemsTest.java b/hibernate-core/src/test/java/org/hibernate/test/dialect/functional/cache/SQLFunctionsInterSystemsTest.java
index 4e54f28b6f..cf5bbd8481 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/dialect/functional/cache/SQLFunctionsInterSystemsTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/dialect/functional/cache/SQLFunctionsInterSystemsTest.java
@@ -1,760 +1,760 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.dialect.functional.cache;
 
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.ArrayList;
 import java.util.Calendar;
 import java.util.Date;
 import java.util.GregorianCalendar;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 import org.junit.Test;
 
 import org.hibernate.LockMode;
 import org.hibernate.Query;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.dialect.Cache71Dialect;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
 import org.hibernate.test.legacy.Blobber;
 import org.hibernate.test.legacy.Broken;
 import org.hibernate.test.legacy.Fixed;
 import org.hibernate.test.legacy.Simple;
 import org.hibernate.test.legacy.Single;
 import org.hibernate.testing.RequiresDialect;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertTrue;
 
 /**
  * Tests for function support on CacheSQL...
  *
  * @author Jonathan Levinson
  */
 @RequiresDialect( value = Cache71Dialect.class )
 public class SQLFunctionsInterSystemsTest extends BaseCoreFunctionalTestCase {
 	private static final Logger log = Logger.getLogger( SQLFunctionsInterSystemsTest.class );
 
 	public String[] getMappings() {
 		return new String[] {
 				"legacy/AltSimple.hbm.xml",
 				"legacy/Broken.hbm.xml",
 				"legacy/Blobber.hbm.xml",
 				"dialect/functional/cache/TestInterSystemsFunctionsClass.hbm.xml"
 		};
 	}
 
 	@Test
 	public void testDialectSQLFunctions() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 
 		Simple simple = new Simple( Long.valueOf( 10 ) );
 		simple.setName("Simple Dialect Function Test");
 		simple.setAddress("Simple Address");
 		simple.setPay(new Float(45.8));
 		simple.setCount(2);
 		s.save( simple );
 
 		// Test to make sure allocating an specified object operates correctly.
 		assertTrue(
 				s.createQuery( "select new org.hibernate.test.legacy.S(s.count, s.address) from Simple s" ).list().size() == 1
 		);
 
 		// Quick check the base dialect functions operate correctly
 		assertTrue(
 				s.createQuery( "select max(s.count) from Simple s" ).list().size() == 1
 		);
 		assertTrue(
 				s.createQuery( "select count(*) from Simple s" ).list().size() == 1
 		);
 
 		List rset = s.createQuery( "select s.name, sysdate, floor(s.pay), round(s.pay,0) from Simple s" ).list();
 		assertNotNull("Name string should have been returned",(((Object[])rset.get(0))[0]));
 		assertNotNull("Todays Date should have been returned",(((Object[])rset.get(0))[1]));
 		assertEquals("floor(45.8) result was incorrect ", new Integer(45), ( (Object[]) rset.get(0) )[2] );
 		assertEquals("round(45.8) result was incorrect ", new Float(46), ( (Object[]) rset.get(0) )[3] );
 
 		simple.setPay(new Float(-45.8));
 		s.update(simple);
 
 		// Test type conversions while using nested functions (Float to Int).
 		rset = s.createQuery( "select abs(round(s.pay,0)) from Simple s" ).list();
 		assertEquals("abs(round(-45.8)) result was incorrect ", new Float(46), rset.get(0));
 
 		// Test a larger depth 3 function example - Not a useful combo other than for testing
 		assertTrue(
 				s.createQuery( "select floor(round(sysdate,1)) from Simple s" ).list().size() == 1
 		);
 
 		// Test the oracle standard NVL funtion as a test of multi-param functions...
 		simple.setPay(null);
 		s.update(simple);
 		Double value = (Double) s.createQuery("select mod( nvl(s.pay, 5000), 2 ) from Simple as s where s.id = 10").list().get(0);
 		assertTrue( 0 == value.intValue() );
 
 		// Test the hsql standard MOD funtion as a test of multi-param functions...
 		value = (Double) s.createQuery( "select MOD(s.count, 2) from Simple as s where s.id = 10" )
 				.list()
 				.get(0);
 		assertTrue( 0 == value.intValue() );
 
         s.delete(simple);
 		t.commit();
 		s.close();
 	}
 
 	public void testSetProperties() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf( 10 ) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		Query q = s.createQuery("from Simple s where s.name=:name and s.count=:count");
 		q.setProperties(simple);
 		assertTrue( q.list().get(0)==simple );
 		//misuse of "Single" as a propertyobject, but it was the first testclass i found with a collection ;)
 		Single single = new Single() { // trivial hack to test properties with arrays.
 			@SuppressWarnings( {"unchecked"})
 			String[] getStuff() { 
 				return (String[]) getSeveral().toArray(new String[getSeveral().size()]);
 			}
 		};
 
 		List l = new ArrayList();
 		l.add("Simple 1");
 		l.add("Slimeball");
 		single.setSeveral(l);
 		q = s.createQuery("from Simple s where s.name in (:several)");
 		q.setProperties(single);
 		assertTrue( q.list().get(0)==simple );
 
 
 		q = s.createQuery("from Simple s where s.name in (:stuff)");
 		q.setProperties(single);
 		assertTrue( q.list().get(0)==simple );
 		s.delete(simple);
 		t.commit();
 		s.close();
 	}
 
 	public void testBroken() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Broken b = new Fixed();
 		b.setId( Long.valueOf( 123 ));
 		b.setOtherId("foobar");
 		s.save(b);
 		s.flush();
 		b.setTimestamp( new Date() );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update(b);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		b = (Broken) s.load( Broken.class, b );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.delete(b);
 		t.commit();
 		s.close();
 	}
 
 	public void testNothinToUpdate() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( simple );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( simple );
 		s.delete(simple);
 		t.commit();
 		s.close();
 	}
 
 	public void testCachedQuery() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Query q = s.createQuery("from Simple s where s.name=?");
 		q.setCacheable(true);
 		q.setString(0, "Simple 1");
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		q = s.createQuery("from Simple s where s.name=:name");
 		q.setCacheable(true);
 		q.setString("name", "Simple 1");
 		assertTrue( q.list().size()==1 );
 		simple = (Simple) q.list().get(0);
 
 		q.setString("name", "Simple 2");
 		assertTrue( q.list().size()==0 );
 		assertTrue( q.list().size()==0 );
 		simple.setName("Simple 2");
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s where s.name=:name");
 		q.setString("name", "Simple 2");
 		q.setCacheable(true);
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( simple );
 		s.delete(simple);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s where s.name=?");
 		q.setCacheable(true);
 		q.setString(0, "Simple 1");
 		assertTrue( q.list().size()==0 );
 		assertTrue( q.list().size()==0 );
 		t.commit();
 		s.close();
 	}
 
 	public void testCachedQueryRegion() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Query q = s.createQuery("from Simple s where s.name=?");
 		q.setCacheRegion("foo");
 		q.setCacheable(true);
 		q.setString(0, "Simple 1");
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		q = s.createQuery("from Simple s where s.name=:name");
 		q.setCacheRegion("foo");
 		q.setCacheable(true);
 		q.setString("name", "Simple 1");
 		assertTrue( q.list().size()==1 );
 		simple = (Simple) q.list().get(0);
 
 		q.setString("name", "Simple 2");
 		assertTrue( q.list().size()==0 );
 		assertTrue( q.list().size()==0 );
 		simple.setName("Simple 2");
 		assertTrue( q.list().size()==1 );
 		assertTrue( q.list().size()==1 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( simple );
 		s.delete(simple);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s where s.name=?");
 		q.setCacheRegion("foo");
 		q.setCacheable(true);
 		q.setString(0, "Simple 1");
 		assertTrue( q.list().size()==0 );
 		assertTrue( q.list().size()==0 );
 		t.commit();
 		s.close();
 	}
 
 	public void testSQLFunctions() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save(simple );
 
 		s.createQuery( "from Simple s where repeat('foo', 3) = 'foofoofoo'" ).list();
 		s.createQuery( "from Simple s where repeat(s.name, 3) = 'foofoofoo'" ).list();
 		s.createQuery( "from Simple s where repeat( lower(s.name), (3 + (1-1)) / 2) = 'foofoofoo'" ).list();
 
 		assertTrue(
 				s.createQuery( "from Simple s where upper( s.name ) ='SIMPLE 1'" ).list().size()==1
 		);
 		assertTrue(
 				s.createQuery(
 						"from Simple s where not( upper( s.name ) ='yada' or 1=2 or 'foo'='bar' or not('foo'='foo') or 'foo' like 'bar' )"
 				).list()
 						.size()==1
 		);
 
 		assertTrue(
 				s.createQuery( "from Simple s where lower( s.name || ' foo' ) ='simple 1 foo'" ).list().size()==1
 		);
 		assertTrue(
 				s.createQuery( "from Simple s where lower( concat(s.name, ' foo') ) ='simple 1 foo'" ).list().size()==1
 		);
 
 		Simple other = new Simple( Long.valueOf(20) );
 		other.setName( "Simple 2" );
 		other.setCount( 12 );
 		simple.setOther( other );
 		s.save( other );
 		//s.find("from Simple s where s.name ## 'cat|rat|bag'");
 		assertTrue(
 				s.createQuery( "from Simple s where upper( s.other.name ) ='SIMPLE 2'" ).list().size()==1
 		);
 		assertTrue(
 				s.createQuery( "from Simple s where not ( upper( s.other.name ) ='SIMPLE 2' )" ).list().size()==0
 		);
 		assertTrue(
 				s.createQuery(
 						"select distinct s from Simple s where ( ( s.other.count + 3 ) = (15*2)/2 and s.count = 69) or ( ( s.other.count + 2 ) / 7 ) = 2"
 				).list()
 						.size()==1
 		);
 		assertTrue(
 				s.createQuery(
 						"select s from Simple s where ( ( s.other.count + 3 ) = (15*2)/2 and s.count = 69) or ( ( s.other.count + 2 ) / 7 ) = 2 order by s.other.count"
 				).list()
 						.size()==1
 		);
 		Simple min = new Simple( Long.valueOf(30) );
 		min.setCount( -1 );
 		s.save(min );
 
 		assertTrue(
 				s.createQuery( "from Simple s where s.count > ( select min(sim.count) from Simple sim )" )
 						.list()
 						.size()==2
 		);
 		t.commit();
 		t = s.beginTransaction();
 		assertTrue(
 				s.createQuery(
 						"from Simple s where s = some( select sim from Simple sim where sim.count>=0 ) and s.count >= 0"
 				).list()
 						.size()==2
 		);
 		assertTrue(
 				s.createQuery(
 						"from Simple s where s = some( select sim from Simple sim where sim.other.count=s.other.count ) and s.other.count > 0"
 				).list()
 						.size()==1
 		);
 
 		Iterator iter = s.createQuery( "select sum(s.count) from Simple s group by s.count having sum(s.count) > 10" )
 				.iterate();
 		assertTrue( iter.hasNext() );
 		assertEquals( Long.valueOf( 12 ), iter.next() );
 		assertTrue( !iter.hasNext() );
 		iter = s.createQuery( "select s.count from Simple s group by s.count having s.count = 12" ).iterate();
 		assertTrue( iter.hasNext() );
 
 		s.createQuery(
 				"select s.id, s.count, count(t), max(t.date) from Simple s, Simple t where s.count = t.count group by s.id, s.count order by s.count"
 		).iterate();
 
 		Query q = s.createQuery("from Simple s");
 		q.setMaxResults( 10 );
 		assertTrue( q.list().size()==3 );
 		q = s.createQuery("from Simple s");
 		q.setMaxResults( 1 );
 		assertTrue( q.list().size()==1 );
 		q = s.createQuery("from Simple s");
 		assertTrue( q.list().size() == 3 );
 		q = s.createQuery("from Simple s where s.name = ?");
 		q.setString( 0, "Simple 1" );
 		assertTrue( q.list().size()==1 );
 		q = s.createQuery("from Simple s where s.name = ? and upper(s.name) = ?");
 		q.setString(1, "SIMPLE 1");
 		q.setString( 0, "Simple 1" );
 		q.setFirstResult(0);
 		assertTrue( q.iterate().hasNext() );
 		q = s.createQuery("from Simple s where s.name = :foo and upper(s.name) = :bar or s.count=:count or s.count=:count + 1");
 		q.setParameter( "bar", "SIMPLE 1" );
 		q.setString( "foo", "Simple 1" );
 		q.setInteger("count", 69);
 		q.setFirstResult(0);
 		assertTrue( q.iterate().hasNext() );
 		q = s.createQuery("select s.id from Simple s");
 		q.setFirstResult(1);
 		q.setMaxResults( 2 );
 		iter = q.iterate();
 		int i=0;
 		while ( iter.hasNext() ) {
 			assertTrue( iter.next() instanceof Long );
 			i++;
 		}
 		assertTrue( i == 2 );
 		q = s.createQuery("select all s, s.other from Simple s where s = :s");
 		q.setParameter("s", simple);
 		assertTrue( q.list().size()==1 );
 
 
 		q = s.createQuery("from Simple s where s.name in (:name_list) and s.count > :count");
 		HashSet set = new HashSet();
 		set.add("Simple 1");
 		set.add("foo");
 		q.setParameterList( "name_list", set );
 		q.setParameter("count", new Integer(-1) );
 		assertTrue( q.list().size()==1 );
 
 		ScrollableResults sr = s.createQuery("from Simple s").scroll();
 		sr.next();
 		sr.get(0);
 		sr.close();
 
 		s.delete( other );
 		s.delete( simple );
 		s.delete( min );
 		t.commit();
 		s.close();
 
 	}
 
 	public void testBlobClob() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Blobber b = new Blobber();
 		b.setBlob( s.getLobHelper().createBlob( "foo/bar/baz".getBytes() ) );
 		b.setClob( s.getLobHelper().createClob("foo/bar/baz") );
 		s.save(b);
 		//s.refresh(b);
 		//assertTrue( b.getClob() instanceof ClobImpl );
 		s.flush();
 		s.refresh(b);
 		//b.getBlob().setBytes( 2, "abc".getBytes() );
         log.debug("levinson: just bfore b.getClob()");
         b.getClob().getSubString(2, 3);
 		//b.getClob().setString(2, "abc");
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		b = (Blobber) s.load( Blobber.class, new Integer( b.getId() ) );
 		Blobber b2 = new Blobber();
 		s.save(b2);
 		b2.setBlob( b.getBlob() );
 		b.setBlob(null);
 		//assertTrue( b.getClob().getSubString(1, 3).equals("fab") );
 		b.getClob().getSubString(1, 6);
 		//b.getClob().setString(1, "qwerty");
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		b = (Blobber) s.load( Blobber.class, new Integer( b.getId() ) );
 		b.setClob( s.getLobHelper().createClob("xcvfxvc xcvbx cvbx cvbx cvbxcvbxcvbxcvb") );
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		b = (Blobber) s.load( Blobber.class, new Integer( b.getId() ) );
 		assertTrue( b.getClob().getSubString(1, 7).equals("xcvfxvc") );
 		//b.getClob().setString(5, "1234567890");
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	public void testSqlFunctionAsAlias() throws Exception {
 		String functionName = locateAppropriateDialectFunctionNameForAliasTest();
 		if (functionName == null) {
             log.info("Dialect does not list any no-arg functions");
 			return;
 		}
 
         log.info("Using function named [" + functionName + "] for 'function as alias' test");
 		String query = "select " + functionName + " from Simple as " + functionName + " where " + functionName + ".id = 10";
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		List result = s.createQuery( query ).list();
 		assertTrue( result.size() == 1 );
 		assertTrue(result.get(0) instanceof Simple);
 		s.delete( result.get(0) );
 		t.commit();
 		s.close();
 	}
 
 	@SuppressWarnings( {"ForLoopReplaceableByForEach"})
 	private String locateAppropriateDialectFunctionNameForAliasTest() {
 		for (Iterator itr = getDialect().getFunctions().entrySet().iterator(); itr.hasNext(); ) {
 			final Map.Entry entry = (Map.Entry) itr.next();
 			final SQLFunction function = (SQLFunction) entry.getValue();
 			if ( !function.hasArguments() && !function.hasParenthesesIfNoArguments() ) {
 				return (String) entry.getKey();
 			}
 		}
 		return null;
 	}
 
 	public void testCachedQueryOnInsert() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Simple simple = new Simple( Long.valueOf(10) );
 		simple.setName("Simple 1");
 		s.save( simple );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Query q = s.createQuery("from Simple s");
 		List list = q.setCacheable(true).list();
 		assertTrue( list.size()==1 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s");
 		list = q.setCacheable(true).list();
 		assertTrue( list.size()==1 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Simple simple2 = new Simple( Long.valueOf(12) );
 		simple2.setCount(133);
 		s.save( simple2 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s");
 		list = q.setCacheable(true).list();
 		assertTrue( list.size()==2 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		q = s.createQuery("from Simple s");
 		list = q.setCacheable(true).list();
 		assertTrue( list.size()==2 );
 		for ( Object o : list ) {
 			s.delete( o );
 		}
 		t.commit();
 		s.close();
 
 	}
 
 	public void testInterSystemsFunctions() throws Exception {
         Calendar cal = new GregorianCalendar();
         cal.set(1977,6,3,0,0,0);
         java.sql.Timestamp testvalue = new java.sql.Timestamp(cal.getTimeInMillis());
         testvalue.setNanos(0);
         Calendar cal3 = new GregorianCalendar();
         cal3.set(1976,2,3,0,0,0);
         java.sql.Timestamp testvalue3 = new java.sql.Timestamp(cal3.getTimeInMillis());
         testvalue3.setNanos(0);
 
         final Session s = openSession();
         s.beginTransaction();
         try {
 			s.doWork(
 					new Work() {
 						@Override
 						public void execute(Connection connection) throws SQLException {
-							Statement stmt = ((SessionImplementor)s).getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().createStatement();
-							((SessionImplementor)s).getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( stmt, "DROP FUNCTION spLock FROM TestInterSystemsFunctionsClass" );
+							Statement stmt = ((SessionImplementor)s).getJdbcCoordinator().getStatementPreparer().createStatement();
+							((SessionImplementor)s).getJdbcCoordinator().getResultSetReturn().executeUpdate( stmt, "DROP FUNCTION spLock FROM TestInterSystemsFunctionsClass" );
 						}
 					}
 			);
         }
         catch (Exception ex) {
             System.out.println("as we expected stored procedure sp does not exist when we drop it");
 
         }
 		s.getTransaction().commit();
 
         s.beginTransaction();
 		s.doWork(
 				new Work() {
 					@Override
 					public void execute(Connection connection) throws SQLException {
-						Statement stmt = ((SessionImplementor)s).getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().createStatement();
+						Statement stmt = ((SessionImplementor)s).getJdbcCoordinator().getStatementPreparer().createStatement();
 						String create_function = "CREATE FUNCTION SQLUser.TestInterSystemsFunctionsClass_spLock\n" +
 								"     ( INOUT pHandle %SQLProcContext, \n" +
 								"       ROWID INTEGER \n" +
 								" )\n" +
 								" FOR User.TestInterSystemsFunctionsClass " +
 								"    PROCEDURE\n" +
 								"    RETURNS INTEGER\n" +
 								"    LANGUAGE OBJECTSCRIPT\n" +
 								"    {\n" +
 								"        q 0\n" +
 								"     }";
-						((SessionImplementor)s).getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( stmt, create_function );
+						((SessionImplementor)s).getJdbcCoordinator().getResultSetReturn().executeUpdate( stmt, create_function );
 					}
 				}
 		);
         s.getTransaction().commit();
 
         s.beginTransaction();
 
         TestInterSystemsFunctionsClass object = new TestInterSystemsFunctionsClass( Long.valueOf( 10 ) );
         object.setDateText("1977-07-03");
         object.setDate1( testvalue );
         object.setDate3( testvalue3 );
         s.save( object );
         s.getTransaction().commit();
         s.close();
 
         Session s2 = openSession();
         s2.beginTransaction();
         TestInterSystemsFunctionsClass test = (TestInterSystemsFunctionsClass) s2.get(TestInterSystemsFunctionsClass.class, Long.valueOf(10));
         assertTrue( test.getDate1().equals(testvalue));
         test = (TestInterSystemsFunctionsClass) s2.get(TestInterSystemsFunctionsClass.class, Long.valueOf(10), LockMode.UPGRADE);
         assertTrue( test.getDate1().equals(testvalue));
         Date value = (Date) s2.createQuery( "select nvl(o.date,o.dateText) from TestInterSystemsFunctionsClass as o" )
 				.list()
 				.get(0);
         assertTrue( value.equals(testvalue));
         Object nv = s2.createQuery( "select nullif(o.dateText,o.dateText) from TestInterSystemsFunctionsClass as o" )
 				.list()
 				.get(0);
         assertTrue( nv == null);
         String dateText = (String) s2.createQuery(
 				"select nvl(o.dateText,o.date) from TestInterSystemsFunctionsClass as o"
 		).list()
 				.get(0);
         assertTrue( dateText.equals("1977-07-03"));
         value = (Date) s2.createQuery( "select ifnull(o.date,o.date1) from TestInterSystemsFunctionsClass as o" )
 				.list()
 				.get(0);
         assertTrue( value.equals(testvalue));
         value = (Date) s2.createQuery( "select ifnull(o.date3,o.date,o.date1) from TestInterSystemsFunctionsClass as o" )
 				.list()
 				.get(0);
         assertTrue( value.equals(testvalue));
         Integer pos = (Integer) s2.createQuery(
 				"select position('07', o.dateText) from TestInterSystemsFunctionsClass as o"
 		).list()
 				.get(0);
         assertTrue(pos.intValue() == 6);
         String st = (String) s2.createQuery( "select convert(o.date1, SQL_TIME) from TestInterSystemsFunctionsClass as o" )
 				.list()
 				.get(0);
         assertTrue( st.equals("00:00:00"));
         java.sql.Time tm = (java.sql.Time) s2.createQuery(
 				"select cast(o.date1, time) from TestInterSystemsFunctionsClass as o"
 		).list()
 				.get(0);
         assertTrue( tm.toString().equals("00:00:00"));
         Double diff = (Double) s2.createQuery(
 				"select timestampdiff(SQL_TSI_FRAC_SECOND, o.date3, o.date1) from TestInterSystemsFunctionsClass as o"
 		).list()
 				.get(0);
         assertTrue(diff.doubleValue() != 0.0);
         diff = (Double) s2.createQuery(
 				"select timestampdiff(SQL_TSI_MONTH, o.date3, o.date1) from TestInterSystemsFunctionsClass as o"
 		).list()
 				.get(0);
         assertTrue(diff.doubleValue() == 16.0);
         diff = (Double) s2.createQuery(
 				"select timestampdiff(SQL_TSI_WEEK, o.date3, o.date1) from TestInterSystemsFunctionsClass as o"
 		).list()
 				.get(0);
         assertTrue(diff.doubleValue() >= 16*4);
         diff = (Double) s2.createQuery(
 				"select timestampdiff(SQL_TSI_YEAR, o.date3, o.date1) from TestInterSystemsFunctionsClass as o"
 		).list()
 				.get(0);
         assertTrue(diff.doubleValue() == 1.0);
 
         s2.getTransaction().commit();
         s2.close();
     }
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/exception/SQLExceptionConversionTest.java b/hibernate-core/src/test/java/org/hibernate/test/exception/SQLExceptionConversionTest.java
index 7635565c4c..7e250c7ac5 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/exception/SQLExceptionConversionTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/exception/SQLExceptionConversionTest.java
@@ -1,179 +1,179 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.exception;
 
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.sql.Types;
 
 import org.junit.Test;
 
 import org.hibernate.Session;
 import org.hibernate.dialect.AbstractHANADialect;
 import org.hibernate.dialect.MySQLMyISAMDialect;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.engine.jdbc.spi.ResultSetReturn;
 import org.hibernate.engine.jdbc.spi.StatementPreparer;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.exception.ConstraintViolationException;
 import org.hibernate.exception.SQLGrammarException;
 import org.hibernate.jdbc.Work;
 import org.hibernate.testing.SkipForDialect;
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 import static org.junit.Assert.fail;
 
 /**
  * Implementation of SQLExceptionConversionTest.
  *
  * @author Steve Ebersole
  */
 public class SQLExceptionConversionTest extends BaseCoreFunctionalTestCase {
 	public String[] getMappings() {
 		return new String[] {"exception/User.hbm.xml", "exception/Group.hbm.xml"};
 	}
 
 	@Test
 	@SkipForDialect(
 			value = { MySQLMyISAMDialect.class, AbstractHANADialect.class },
 			comment = "MySQL (MyISAM) / Hana do not support FK violation checking"
 	)
 	public void testIntegrityViolation() throws Exception {
 		final Session session = openSession();
 		session.beginTransaction();
 
 		session.doWork(
 				new Work() {
 					@Override
 					public void execute(Connection connection) throws SQLException {
 						// Attempt to insert some bad values into the T_MEMBERSHIP table that should
 						// result in a constraint violation
 						PreparedStatement ps = null;
 						try {
-							ps = ((SessionImplementor)session).getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( "INSERT INTO T_MEMBERSHIP (user_id, group_id) VALUES (?, ?)" );
+							ps = ((SessionImplementor)session).getJdbcCoordinator().getStatementPreparer().prepareStatement( "INSERT INTO T_MEMBERSHIP (user_id, group_id) VALUES (?, ?)" );
 							ps.setLong(1, 52134241);    // Non-existent user_id
 							ps.setLong(2, 5342);        // Non-existent group_id
-							((SessionImplementor)session).getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( ps );
+							((SessionImplementor)session).getJdbcCoordinator().getResultSetReturn().executeUpdate( ps );
 
 							fail("INSERT should have failed");
 						}
 						catch (ConstraintViolationException ignore) {
 							// expected outcome
 						}
 						finally {
 							releaseStatement( session, ps );
 						}
 					}
 				}
 		);
 
 		session.getTransaction().rollback();
 		session.close();
 	}
 
 	@Test
 	public void testBadGrammar() throws Exception {
 		final Session session = openSession();
 		session.beginTransaction();
 
 		session.doWork(
 				new Work() {
 					@Override
 					public void execute(Connection connection) throws SQLException {
 						// prepare/execute a query against a non-existent table
 						PreparedStatement ps = null;
 						try {
-							ps = ((SessionImplementor)session).getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( "SELECT user_id, user_name FROM tbl_no_there" );
-							((SessionImplementor)session).getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( ps );
+							ps = ((SessionImplementor)session).getJdbcCoordinator().getStatementPreparer().prepareStatement( "SELECT user_id, user_name FROM tbl_no_there" );
+							((SessionImplementor)session).getJdbcCoordinator().getResultSetReturn().extract( ps );
 
 							fail("SQL compilation should have failed");
 						}
 						catch (SQLGrammarException ignored) {
 							// expected outcome
 						}
 						finally {
 							releaseStatement( session, ps );
 						}
 					}
 				}
 		);
 
 		session.getTransaction().rollback();
 		session.close();
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-7357")
 	public void testNotNullConstraint() {
 		final Session session = openSession();
 		session.beginTransaction();
 
 		final User user = new User();
 		user.setUsername( "Lukasz" );
 		session.save( user );
 		session.flush();
 
 		session.doWork(
 				new Work() {
 					@Override
 					public void execute(Connection connection) throws SQLException {
-						final JdbcCoordinator jdbcCoordinator = ( (SessionImplementor) session ).getTransactionCoordinator().getJdbcCoordinator();
+						final JdbcCoordinator jdbcCoordinator = ( (SessionImplementor) session ).getJdbcCoordinator();
 						final StatementPreparer statementPreparer = jdbcCoordinator.getStatementPreparer();
 						final ResultSetReturn resultSetReturn = jdbcCoordinator.getResultSetReturn();
 						PreparedStatement ps = null;
 						try {
 							ps = statementPreparer.prepareStatement( "UPDATE T_USER SET user_name = ? WHERE user_id = ?" );
 							ps.setNull( 1, Types.VARCHAR ); // Attempt to update user name to NULL (NOT NULL constraint defined).
 							ps.setLong( 2, user.getId() );
 							resultSetReturn.executeUpdate( ps );
 
 							fail( "UPDATE should have failed because of not NULL constraint." );
 						}
 						catch ( ConstraintViolationException ignore ) {
 							// expected outcome
 						}
 						finally {
 							releaseStatement( session, ps );
 						}
 					}
 				}
 		);
 
 		session.getTransaction().rollback();
 		session.close();
 	}
 
 	private void releaseStatement(Session session, PreparedStatement ps) {
 		if ( ps != null ) {
 			try {
-				( (SessionImplementor) session ).getTransactionCoordinator().getJdbcCoordinator().release( ps );
+				( (SessionImplementor) session ).getJdbcCoordinator().getResourceRegistry().release( ps );
 			}
 			catch ( Throwable ignore ) {
 				// ignore...
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/immutable/entitywithmutablecollection/AbstractEntityWithManyToManyTest.java b/hibernate-core/src/test/java/org/hibernate/test/immutable/entitywithmutablecollection/AbstractEntityWithManyToManyTest.java
index 3f79b0b476..4bf932d752 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/immutable/entitywithmutablecollection/AbstractEntityWithManyToManyTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/immutable/entitywithmutablecollection/AbstractEntityWithManyToManyTest.java
@@ -1,1128 +1,1129 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.immutable.entitywithmutablecollection;
 import java.util.Iterator;
 
 import org.junit.Test;
 
 import org.hibernate.MappingException;
 import org.hibernate.Session;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.StaleStateException;
 import org.hibernate.Transaction;
+import org.hibernate.TransactionException;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.criterion.Projections;
 import org.hibernate.criterion.Restrictions;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertSame;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author Gail Badner
  */
 public abstract class AbstractEntityWithManyToManyTest extends BaseCoreFunctionalTestCase {
 	private boolean isPlanContractsInverse;
 	private boolean isPlanContractsBidirectional;
 	private boolean isPlanVersioned;
 	private boolean isContractVersioned;
 
 	@Override
 	public void configure(Configuration cfg) {
 		cfg.setProperty( Environment.GENERATE_STATISTICS, "true");
 	}
 
 	@Override
 	protected void prepareTest() throws Exception {
 		super.prepareTest();
 		isPlanContractsInverse = sessionFactory().getCollectionPersister( Plan.class.getName() + ".contracts" ).isInverse();
 		try {
 			sessionFactory().getCollectionPersister( Contract.class.getName() + ".plans" );
 			isPlanContractsBidirectional = true;
 		}
 		catch ( MappingException ex) {
 			isPlanContractsBidirectional = false;	
 		}
 		isPlanVersioned = sessionFactory().getEntityPersister( Plan.class.getName() ).isVersioned();
 		isContractVersioned = sessionFactory().getEntityPersister( Contract.class.getName() ).isVersioned();
 		sessionFactory().getStatistics().clear();
 	}
 
 	@Test
 	public void testUpdateProperty() {
 		clearCounts();
 
 		Plan p = new Plan( "plan" );
 		p.addContract( new Contract( null, "gail", "phone") );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist(p);
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = (Plan) s.createCriteria( Plan.class ).uniqueResult();
 		p.setDescription( "new plan" );
 		assertEquals( 1, p.getContracts().size() );
 		Contract c = ( Contract ) p.getContracts().iterator().next();
 		c.setCustomerName( "yogi" );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = (Plan) s.createCriteria( Plan.class ).uniqueResult();
 		assertEquals( 1, p.getContracts().size() );
 		c = ( Contract ) p.getContracts().iterator().next();
 		assertEquals( "gail", c.getCustomerName() );
 		if ( isPlanContractsBidirectional ) {
 			assertEquals( 1, c.getPlans().size() );
 			assertSame( p, c.getPlans().iterator().next() );
 		}
 		s.delete( p );
 		assertEquals( new Long( 0 ), s.createCriteria( Contract.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria( Plan.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testCreateWithNonEmptyManyToManyCollectionOfNew() {
 		clearCounts();
 
 		Plan p = new Plan( "plan" );
 		p.addContract( new Contract( null, "gail", "phone") );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist(p);
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.createCriteria( Plan.class ).uniqueResult();
 		assertEquals( 1, p.getContracts().size() );
 		Contract c = ( Contract ) p.getContracts().iterator().next();
 		assertEquals( "gail", c.getCustomerName() );
 		if ( isPlanContractsBidirectional ) {
 			assertEquals( 1, c.getPlans().size() );
 			assertSame( p, c.getPlans().iterator().next() );
 		}
 		s.delete(p);
 		assertEquals( new Long( 0 ), s.createCriteria( Contract.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria( Plan.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testCreateWithNonEmptyManyToManyCollectionOfExisting() {
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone");
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist(c);
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		Plan p = new Plan( "plan" );
 		p.addContract( c );
 		s = openSession();
 		t = s.beginTransaction();
 		s.save(p);
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.createCriteria( Plan.class ).uniqueResult();
 		assertEquals( 1, p.getContracts().size() );
 		c = ( Contract ) p.getContracts().iterator().next();
 		assertEquals( "gail", c.getCustomerName() );
 		if ( isPlanContractsBidirectional ) {
 			assertEquals( 1, c.getPlans().size() );
 			assertSame( p, c.getPlans().iterator().next() );
 		}
 		s.delete(p);
 		assertEquals( new Long( 0 ), s.createCriteria( Contract.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria( Plan.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testAddNewManyToManyElementToPersistentEntity() {
 		clearCounts();
 
 		Plan p = new Plan( "plan" );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( p );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.get( Plan.class, p.getId() );
 		assertEquals( 0, p.getContracts().size() );
 		p.addContract( new Contract( null, "gail", "phone") );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan) s.createCriteria( Plan.class ).uniqueResult();
 		assertEquals( 1, p.getContracts().size() );
 		Contract c = ( Contract ) p.getContracts().iterator().next();
 		assertEquals( "gail", c.getCustomerName() );
 		if ( isPlanContractsBidirectional ) {
 			assertEquals( 1, c.getPlans().size() );
 			assertSame( p, c.getPlans().iterator().next() );
 		}
 		s.delete( p );
 		assertEquals( new Long( 0 ), s.createCriteria( Contract.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria( Plan.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testAddExistingManyToManyElementToPersistentEntity() {
 		clearCounts();
 
 		Plan p = new Plan( "plan" );
 		Contract c = new Contract( null, "gail", "phone" );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( p );
 		s.persist( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.get( Plan.class, p.getId() );
 		assertEquals( 0, p.getContracts().size() );
 		c = ( Contract ) s.get( Contract.class, c.getId() );
 		if ( isPlanContractsBidirectional ) {
 			assertEquals( 0, c.getPlans().size() );
 		}
 		p.addContract( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 0 );
 		assertUpdateCount( isContractVersioned && isPlanVersioned ? 2 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.createCriteria( Plan.class ).uniqueResult();
 		assertEquals( 1, p.getContracts().size() );
 		c = ( Contract ) p.getContracts().iterator().next();
 		assertEquals( "gail", c.getCustomerName() );
 		if ( isPlanContractsBidirectional ) {
 			assertSame( p, c.getPlans().iterator().next() );
 		}
 		s.delete( p );
 		assertEquals( new Long( 0 ), s.createCriteria( Plan.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria( Contract.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testCreateWithEmptyManyToManyCollectionUpdateWithExistingElement() {
 		clearCounts();
 
 		Plan p = new Plan( "plan" );
 		Contract c = new Contract( null, "gail", "phone");
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( p );
 		s.persist( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		p.addContract( c );
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( p );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 0 );
 		assertUpdateCount( isContractVersioned && isPlanVersioned ? 2 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.createCriteria( Plan.class ).uniqueResult();
 		assertEquals( 1, p.getContracts().size() );
 		c = ( Contract ) p.getContracts().iterator().next();
 		assertEquals( "gail", c.getCustomerName() );
 		if ( isPlanContractsBidirectional ) {
 			assertSame( p, c.getPlans().iterator().next() );
 		}
 		s.delete( p );
 		assertEquals( new Long( 0 ), s.createCriteria( Contract.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria( Plan.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testCreateWithNonEmptyManyToManyCollectionUpdateWithNewElement() {
 		clearCounts();
 
 		Plan p = new Plan( "plan" );
 		Contract c = new Contract( null, "gail", "phone");
 		p.addContract( c );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist(p);
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		Contract newC = new Contract( null, "sherman", "telepathy" );
 		p.addContract( newC );
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( p );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.createCriteria( Plan.class ).uniqueResult();
 		assertEquals( 2, p.getContracts().size() );
 		for ( Iterator it=p.getContracts().iterator(); it.hasNext(); ) {
 			Contract aContract = ( Contract ) it.next();
 			if ( aContract.getId() == c.getId() ) {
 				assertEquals( "gail", aContract.getCustomerName() );
 			}
 			else if ( aContract.getId() == newC.getId() ) {
 				assertEquals( "sherman", aContract.getCustomerName() );
 			}
 			else {
 				fail( "unknown contract" );
 			}
 			if ( isPlanContractsBidirectional ) {
 				assertSame( p, aContract.getPlans().iterator().next() );
 			}
 		}
 		s.delete( p );
 		assertEquals( new Long( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria(Plan.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 3 );
 	}
 
 	@Test
 	public void testCreateWithEmptyManyToManyCollectionMergeWithExistingElement() {
 		clearCounts();
 
 		Plan p = new Plan( "plan" );
 		Contract c = new Contract( null, "gail", "phone");
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( p );
 		s.persist( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		p.addContract( c );
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.merge( p );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 0 );
 		assertUpdateCount( isContractVersioned && isPlanVersioned ? 2 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.createCriteria( Plan.class ).uniqueResult();
 		assertEquals( 1, p.getContracts().size() );
 		c = ( Contract ) p.getContracts().iterator().next();
 		assertEquals( "gail", c.getCustomerName() );
 		if ( isPlanContractsBidirectional ) {
 			assertSame( p, c.getPlans().iterator().next() );
 		}
 		s.delete( p );
 		assertEquals( new Long( 0 ), s.createCriteria(Plan.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testCreateWithNonEmptyManyToManyCollectionMergeWithNewElement() {
 		clearCounts();
 
 		Plan p = new Plan( "plan" );
 		Contract c = new Contract( null, "gail", "phone");
 		p.addContract( c );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( p );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		Contract newC = new Contract( null, "yogi", "mail" );
 		p.addContract( newC );
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.merge( p );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		assertUpdateCount( isContractVersioned && isPlanVersioned ? 2 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.createCriteria( Plan.class ).uniqueResult();
 		assertEquals( 2, p.getContracts().size() );
 		for ( Iterator it=p.getContracts().iterator(); it.hasNext(); ) {
 			Contract aContract = ( Contract ) it.next();
 			if ( aContract.getId() == c.getId() ) {
 				assertEquals( "gail", aContract.getCustomerName() );
 			}
 			else if ( ! aContract.getCustomerName().equals( newC.getCustomerName() ) ) {
 				fail( "unknown contract:" + aContract.getCustomerName() );
 			}
 			if ( isPlanContractsBidirectional ) {
 				assertSame( p, aContract.getPlans().iterator().next() );
 			}
 		}
 		s.delete( p );
 		assertEquals( new Long( 0 ), s.createCriteria( Plan.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria( Contract.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 3 );
 	}
 
 	@Test
 	public void testRemoveManyToManyElementUsingUpdate() {
 		clearCounts();
 
 		Plan p = new Plan( "plan" );
 		Contract c = new Contract( null, "gail", "phone");
 		p.addContract( c );
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( p );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		p.removeContract( c );
 		assertEquals( 0, p.getContracts().size() );
 		if ( isPlanContractsBidirectional ) {
 			assertEquals( 0, c.getPlans().size() );
 		}
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( p );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		assertDeleteCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.createCriteria( Plan.class ).uniqueResult();
 		if ( isPlanContractsInverse ) {
 			assertEquals( 1, p.getContracts().size() );
 			c = ( Contract ) p.getContracts().iterator().next();
 			assertEquals( "gail", c.getCustomerName() );
 			assertSame( p, c.getPlans().iterator().next() );
 		}
 		else {
 			assertEquals( 0, p.getContracts().size() );
 			c = ( Contract ) s.createCriteria( Contract.class ).uniqueResult();
 			if ( isPlanContractsBidirectional ) {
 				assertEquals( 0, c.getPlans().size() );
 			}
 			s.delete( c );
 		}
 		s.delete( p );
 		assertEquals( new Long( 0 ), s.createCriteria(Plan.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testRemoveManyToManyElementUsingUpdateBothSides() {
 		clearCounts();
 
 		Plan p = new Plan( "plan" );
 		Contract c = new Contract( null, "gail", "phone");
 		p.addContract( c );
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( p );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		p.removeContract( c );
 		assertEquals( 0, p.getContracts().size() );
 		if ( isPlanContractsBidirectional ) {
 			assertEquals( 0, c.getPlans().size() );
 		}
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( p );
 		s.update( c );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( isContractVersioned && isPlanVersioned ? 2 : 0 );
 		assertDeleteCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.createCriteria( Plan.class ).uniqueResult();
 		assertEquals( 0, p.getContracts().size() );
 		c = ( Contract ) s.createCriteria( Contract.class ).uniqueResult();
 		if ( isPlanContractsBidirectional ) {
 			assertEquals( 0, c.getPlans().size() );
 		}
 		s.delete( c );
 		s.delete( p );
 		assertEquals( new Long( 0 ), s.createCriteria(Plan.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testRemoveManyToManyElementUsingMerge() {
 		clearCounts();
 
 		Plan p = new Plan( "plan" );
 		Contract c = new Contract( null, "gail", "phone");
 		p.addContract( c );
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( p );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		p.removeContract( c );
 		assertEquals( 0, p.getContracts().size() );
 		if ( isPlanContractsBidirectional ) {
 			assertEquals( 0, c.getPlans().size() );
 		}
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.merge( p );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		assertDeleteCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.createCriteria( Plan.class ).uniqueResult();
 		if ( isPlanContractsInverse ) {
 			assertEquals( 1, p.getContracts().size() );
 			c = ( Contract ) p.getContracts().iterator().next();
 			assertEquals( "gail", c.getCustomerName() );
 			assertSame( p, c.getPlans().iterator().next() );
 		}
 		else {
 			assertEquals( 0, p.getContracts().size() );
 			c = ( Contract ) s.createCriteria( Contract.class ).uniqueResult();
 			if ( isPlanContractsBidirectional ) {
 				assertEquals( 0, c.getPlans().size() );
 			}
 			s.delete( c );
 		}
 		s.delete( p );
 		assertEquals( new Long( 0 ), s.createCriteria(Plan.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testRemoveManyToManyElementUsingMergeBothSides() {
 		clearCounts();
 
 		Plan p = new Plan( "plan" );
 		Contract c = new Contract( null, "gail", "phone");
 		p.addContract( c );
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( p );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		p.removeContract( c );
 		assertEquals( 0, p.getContracts().size() );
 		if ( isPlanContractsBidirectional ) {
 			assertEquals( 0, c.getPlans().size() );
 		}
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.merge( p );
 		c = ( Contract ) s.merge( c );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( isContractVersioned  && isPlanVersioned ? 2 : 0 );
 		assertDeleteCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.createCriteria( Plan.class ).uniqueResult();
 		assertEquals( 0, p.getContracts().size() );
 		c = ( Contract ) s.createCriteria( Contract.class ).uniqueResult();
 		if ( isPlanContractsBidirectional ) {
 			assertEquals( 0, c.getPlans().size() );
 		}
 		s.delete( c );
 		s.delete( p );
 		assertEquals( new Long( 0 ), s.createCriteria(Plan.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testDeleteManyToManyElement() {
 		clearCounts();
 
 		Plan p = new Plan( "plan" );
 		Contract c = new Contract( null, "gail", "phone");
 		p.addContract( c );
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( p );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( p );
 		p.removeContract( c );
 		s.delete( c );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		assertDeleteCount( 1 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.createCriteria( Plan.class ).uniqueResult();
 		assertEquals( 0, p.getContracts().size() );
 		c = ( Contract ) s.createCriteria( Contract.class ).uniqueResult();
 		assertNull( c );
 		s.delete( p );
 		assertEquals( new Long( 0 ), s.createCriteria(Plan.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 1 );
 	}
 
 	@Test
 	public void testRemoveManyToManyElementByDelete() {
 		clearCounts();
 
 		Plan p = new Plan( "plan" );
 		Contract c = new Contract( null, "gail", "phone");
 		p.addContract( c );
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( p );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		p.removeContract( c );
 		assertEquals( 0, p.getContracts().size() );
 		if ( isPlanContractsBidirectional ) {
 			assertEquals( 0, c.getPlans().size() );
 		}
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( p );
 		s.delete( c );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( isPlanVersioned ? 1 : 0 );
 		assertDeleteCount( 1 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.createCriteria( Plan.class ).uniqueResult();
 		assertEquals( 0, p.getContracts().size() );
 		s.delete( p );
 		assertEquals( new Long( 0 ), s.createCriteria(Plan.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 1 );
 	}
 
 	@Test
 	public void testManyToManyCollectionOptimisticLockingWithMerge() {
 		clearCounts();
 
 		Plan pOrig = new Plan( "plan" );
 		Contract cOrig = new Contract( null, "gail", "phone");
 		pOrig.addContract( cOrig );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( pOrig );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Plan p = ( Plan ) s.get( Plan.class, pOrig.getId() );
 		Contract newC = new Contract( null, "sherman", "note" );
 		p.addContract( newC );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		pOrig.removeContract( cOrig );
 		try {
 			s.merge( pOrig );
 			assertFalse( isContractVersioned );
 		}
 		catch (StaleObjectStateException ex) {
 			assertTrue( isContractVersioned);
 		}
 		finally {
 			t.rollback();
 		}
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.createCriteria( Plan.class ).uniqueResult();
 		s.delete( p );
 		assertEquals( new Long( 0 ), s.createCriteria(Plan.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 3 );
 	}
 
 	@Test
 	public void testManyToManyCollectionOptimisticLockingWithUpdate() {
 		clearCounts();
 
 		Plan pOrig = new Plan( "plan" );
 		Contract cOrig = new Contract( null, "gail", "phone");
 		pOrig.addContract( cOrig );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist(pOrig);
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Plan p = ( Plan ) s.get( Plan.class, pOrig.getId() );
 		Contract newC = new Contract( null, "yogi", "pawprint" );
 		p.addContract( newC );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		pOrig.removeContract( cOrig );
 		s.update( pOrig );
 		try {
 			t.commit();
 			assertFalse( isContractVersioned );
 		}
-		catch (StaleStateException ex) {
+		catch (TransactionException e){
 			t.rollback();
 			assertTrue( isContractVersioned );
 			if ( ! sessionFactory().getSettings().isJdbcBatchVersionedData() ) {
-				assertTrue( StaleObjectStateException.class.isInstance( ex ) );
+				assertTrue( StaleObjectStateException.class.isInstance( e.getCause() ) );
 			}
 		}
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = ( Plan ) s.createCriteria( Plan.class ).uniqueResult();
 		s.delete( p );
 		s.createQuery( "delete from Contract" ).executeUpdate();
 		assertEquals( new Long( 0 ), s.createCriteria(Plan.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testMoveManyToManyElementToNewEntityCollection() {
 		clearCounts();
 
 		Plan p = new Plan( "plan" );
 		p.addContract( new Contract( null, "gail", "phone" ) );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( p );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = (Plan) s.createCriteria( Plan.class ).uniqueResult();
 		assertEquals( 1, p.getContracts().size() );
 		Contract c = ( Contract ) p.getContracts().iterator().next();
 		assertEquals( "gail", c.getCustomerName() );
 		if ( isPlanContractsBidirectional ) {
 			assertSame( p, c.getPlans().iterator().next() );
 		}
 		p.removeContract( c );
 		Plan p2 = new Plan( "new plan" );
 		p2.addContract( c );
 		s.save( p2 );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		assertUpdateCount( isPlanVersioned && isContractVersioned ? 2 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = (Plan) s.createCriteria( Plan.class ).add( Restrictions.idEq( new Long( p.getId() ) )).uniqueResult();
 		p2 = (Plan) s.createCriteria( Plan.class ).add( Restrictions.idEq( new Long( p2.getId() ) )).uniqueResult();
 		/*
 		if ( isPlanContractsInverse ) {
 			assertEquals( 1, p.getContracts().size() );
 			c = ( Contract ) p.getContracts().iterator().next();
 			assertEquals( "gail", c.getCustomerName() );
 			if ( isPlanContractsBidirectional ) {
 				assertSame( p, c.getPlans().iterator().next() );
 			}
 			assertEquals( 0, p2.getContracts().size() );
 		}
 		else {
 		*/
 			assertEquals( 0, p.getContracts().size() );
 			assertEquals( 1, p2.getContracts().size() );
 			c = ( Contract ) p2.getContracts().iterator().next();
 			assertEquals( "gail", c.getCustomerName() );
 			if ( isPlanContractsBidirectional ) {
 				assertSame( p2, c.getPlans().iterator().next() );
 			}
 		//}
 		s.delete( p );
 		s.delete( p2 );
 		assertEquals( new Long( 0 ), s.createCriteria( Plan.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria( Contract.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 3 );
 	}
 
 	@Test
 	public void testMoveManyToManyElementToExistingEntityCollection() {
 		clearCounts();
 
 		Plan p = new Plan( "plan" );
 		p.addContract( new Contract( null, "gail", "phone" ) );
 		Plan p2 = new Plan( "plan2" );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( p );
 		s.persist( p2 );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 3 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = (Plan) s.createCriteria( Plan.class ).add( Restrictions.idEq( new Long( p.getId() ) )).uniqueResult();
 		assertEquals( 1, p.getContracts().size() );
 		Contract c = ( Contract ) p.getContracts().iterator().next();
 		assertEquals( "gail", c.getCustomerName() );
 		if ( isPlanContractsBidirectional ) {
 			assertSame( p, c.getPlans().iterator().next() );
 		}
 		p.removeContract( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 0 );
 		assertUpdateCount( isPlanVersioned && isContractVersioned ? 2 : 0 );
 		clearCounts();
 		
 		s = openSession();
 		t = s.beginTransaction();
 		p2 = (Plan) s.createCriteria( Plan.class ).add( Restrictions.idEq( new Long( p2.getId() ) )).uniqueResult();
 		c = (Contract) s.createCriteria( Contract.class ).add( Restrictions.idEq( new Long( c.getId() ) )).uniqueResult();
 		p2.addContract( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 0 );
 		assertUpdateCount( isPlanVersioned && isContractVersioned ? 2 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		p = (Plan) s.createCriteria( Plan.class ).add( Restrictions.idEq( new Long( p.getId() ) )).uniqueResult();
 		p2 = (Plan) s.createCriteria( Plan.class ).add( Restrictions.idEq( new Long( p2.getId() ) )).uniqueResult();
 		/*
 		if ( isPlanContractsInverse ) {
 			assertEquals( 1, p.getContracts().size() );
 			c = ( Contract ) p.getContracts().iterator().next();
 			assertEquals( "gail", c.getCustomerName() );
 			if ( isPlanContractsBidirectional ) {
 				assertSame( p, c.getPlans().iterator().next() );
 			}
 			assertEquals( 0, p2.getContracts().size() );
 		}
 		else {
 		*/
 			assertEquals( 0, p.getContracts().size() );
 			assertEquals( 1, p2.getContracts().size() );
 			c = ( Contract ) p2.getContracts().iterator().next();
 			assertEquals( "gail", c.getCustomerName() );
 			if ( isPlanContractsBidirectional ) {
 				assertSame( p2, c.getPlans().iterator().next() );
 			}
 		//}
 		s.delete( p );
 		s.delete( p2 );
 		assertEquals( new Long( 0 ), s.createCriteria( Plan.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria( Contract.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 3 );
 	}
 
 	protected void clearCounts() {
 		sessionFactory().getStatistics().clear();
 	}
 
 	protected void assertInsertCount(int expected) {
 		int inserts = ( int ) sessionFactory().getStatistics().getEntityInsertCount();
 		assertEquals( "unexpected insert count", expected, inserts );
 	}
 
 	protected void assertUpdateCount(int expected) {
 		int updates = ( int ) sessionFactory().getStatistics().getEntityUpdateCount();
 		assertEquals( "unexpected update counts", expected, updates );
 	}
 
 	protected void assertDeleteCount(int expected) {
 		int deletes = ( int ) sessionFactory().getStatistics().getEntityDeleteCount();
 		assertEquals( "unexpected delete counts", expected, deletes );
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/immutable/entitywithmutablecollection/AbstractEntityWithOneToManyTest.java b/hibernate-core/src/test/java/org/hibernate/test/immutable/entitywithmutablecollection/AbstractEntityWithOneToManyTest.java
index e5133e65e9..c115f72f51 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/immutable/entitywithmutablecollection/AbstractEntityWithOneToManyTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/immutable/entitywithmutablecollection/AbstractEntityWithOneToManyTest.java
@@ -1,1202 +1,1203 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.immutable.entitywithmutablecollection;
 import org.junit.Test;
 
 import org.hibernate.QueryException;
 import org.hibernate.Session;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.StaleStateException;
 import org.hibernate.Transaction;
+import org.hibernate.TransactionException;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.criterion.Projections;
 import org.hibernate.criterion.Restrictions;
 import org.hibernate.internal.SessionFactoryImpl;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertSame;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author Gail Badner
  */
 @SuppressWarnings( {"UnusedDeclaration"})
 public abstract class AbstractEntityWithOneToManyTest extends BaseCoreFunctionalTestCase {
 	private boolean isContractPartiesInverse;
 	private boolean isContractPartiesBidirectional;
 	private boolean isContractVariationsBidirectional;
 	private boolean isContractVersioned;
 	public void configure(Configuration cfg) {
 		cfg.setProperty( Environment.GENERATE_STATISTICS, "true");
 	}
 
 	protected boolean checkUpdateCountsAfterAddingExistingElement() {
 		return true;
 	}
 
 	protected boolean checkUpdateCountsAfterRemovingElementWithoutDelete() {
 		return true;
 	}
 
 	protected void prepareTest() throws Exception {
 		super.prepareTest();
 		isContractPartiesInverse = sessionFactory().getCollectionPersister( Contract.class.getName() + ".parties" ).isInverse();
 		try {
 			 sessionFactory().getEntityPersister( Party.class.getName() ).getPropertyType( "contract" );
 			isContractPartiesBidirectional = true;
 		}
 		catch ( QueryException ex) {
 			isContractPartiesBidirectional = false;
 		}
 		try {
 			 sessionFactory().getEntityPersister( ContractVariation.class.getName() ).getPropertyType( "contract" );
 			isContractVariationsBidirectional = true;
 		}
 		catch ( QueryException ex) {
 			isContractVariationsBidirectional = false;
 		}
 
 		isContractVersioned = sessionFactory().getEntityPersister( Contract.class.getName() ).isVersioned();
 	}
 
 	@Test
 	public void testUpdateProperty() {
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone");
 		c.addParty( new Party( "party" ) );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist(c);
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = (Contract) s.createCriteria( Contract.class ).uniqueResult();
 		c.setCustomerName( "yogi" );
 		assertEquals( 1, c.getParties().size() );
 		Party party = ( Party ) c.getParties().iterator().next();
 		party.setName( "new party" );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = (Contract) s.createCriteria( Contract.class ).uniqueResult();
 		assertEquals( 1, c.getParties().size() );
 		party = ( Party ) c.getParties().iterator().next();
 		assertEquals( "party", party.getName() );
 		if ( isContractPartiesBidirectional ) {
 			assertSame( c, party.getContract() );
 		}
 		s.delete(c);
 		assertEquals( Long.valueOf( 0 ), s.createCriteria( Contract.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria( Party.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testCreateWithNonEmptyOneToManyCollectionOfNew() {
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone");
 		c.addParty( new Party( "party" ) );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist(c);
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = (Contract) s.createCriteria( Contract.class ).uniqueResult();
 		assertEquals( 1, c.getParties().size() );
 		Party party = ( Party ) c.getParties().iterator().next();
 		assertEquals( "party", party.getName() );
 		if ( isContractPartiesBidirectional ) {
 			assertSame( c, party.getContract() );
 		}
 		s.delete(c);
 		assertEquals( Long.valueOf( 0 ), s.createCriteria( Contract.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria( Party.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testCreateWithNonEmptyOneToManyCollectionOfExisting() {
 		clearCounts();
 
 		Party party = new Party( "party" );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( party );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone");
 		c.addParty( party );
 		s = openSession();
 		t = s.beginTransaction();
 		s.save( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		// BUG, should be assertUpdateCount( ! isContractPartiesInverse && isPartyVersioned ? 1 : 0 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = (Contract) s.createCriteria( Contract.class ).uniqueResult();
 		if ( isContractPartiesInverse ) {
 			assertEquals( 0 , c.getParties().size() );
 			party = ( Party ) s.createCriteria( Party.class ).uniqueResult();
 			assertNull( party.getContract() );
 			s.delete( party );
 		}
 		else {
 			assertEquals( 1 , c.getParties().size() );
 			party = ( Party ) c.getParties().iterator().next();
 			assertEquals( "party", party.getName() );
 			if ( isContractPartiesBidirectional ) {
 				assertSame( c, party.getContract() );
 			}
 		}
 		s.delete(c);
 		assertEquals( Long.valueOf( 0 ), s.createCriteria( Contract.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria( Party.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testAddNewOneToManyElementToPersistentEntity() {
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone" );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = ( Contract ) s.get( Contract.class, c.getId() );
 		assertEquals( 0, c.getParties().size() );
 		c.addParty( new Party( "party" ) );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = (Contract) s.createCriteria( Contract.class ).uniqueResult();
 		assertEquals( 1, c.getParties().size() );
 		Party party = ( Party ) c.getParties().iterator().next();
 		assertEquals( "party", party.getName() );
 		if ( isContractPartiesBidirectional ) {
 			assertSame( c, party.getContract() );
 		}
 		s.delete(c);
 		assertEquals( Long.valueOf( 0 ), s.createCriteria( Contract.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria( Party.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testAddExistingOneToManyElementToPersistentEntity() {
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone" );
 		Party party = new Party( "party" );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( c );
 		s.persist( party );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = ( Contract ) s.get( Contract.class, c.getId() );
 		assertEquals( 0, c.getParties().size() );
 		party = ( Party ) s.get( Party.class, party.getId() );
 		if ( isContractPartiesBidirectional ) {
 			assertNull( party.getContract() );
 		}
 		c.addParty( party );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 0 );
 		if ( checkUpdateCountsAfterAddingExistingElement() ) {
 			assertUpdateCount( isContractVersioned && ! isContractPartiesInverse ? 1 : 0 );
 		}
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = (Contract) s.createCriteria( Contract.class ).uniqueResult();
 		if ( isContractPartiesInverse ) {
 			assertEquals( 0, c.getParties().size() );
 			s.delete( party );
 		}
 		else {
 			assertEquals( 1, c.getParties().size() );
 			party = ( Party ) c.getParties().iterator().next();
 			assertEquals( "party", party.getName() );
 			if ( isContractPartiesBidirectional ) {
 				assertSame( c, party.getContract() );
 			}
 		}
 		s.delete(c);
 		assertEquals( Long.valueOf( 0 ), s.createCriteria( Contract.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria( Party.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testCreateWithEmptyOneToManyCollectionUpdateWithExistingElement() {
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone");
 		Party party = new Party( "party" );
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( c );
 		s.persist( party );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		c.addParty( party );
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 0 );
 		if ( checkUpdateCountsAfterAddingExistingElement() ) {
 			assertUpdateCount( isContractVersioned && ! isContractPartiesInverse ? 1 : 0 );
 		}
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = (Contract) s.createCriteria(Contract.class).uniqueResult();
 		if ( isContractPartiesInverse ) {
 			assertEquals( 0, c.getParties().size() );
 			s.delete( party );
 		}
 		else {
 			assertEquals( 1, c.getParties().size() );
 			party = ( Party ) c.getParties().iterator().next();
 			assertEquals( "party", party.getName() );
 			if ( isContractPartiesBidirectional ) {
 				assertSame( c, party.getContract() );
 			}
 		}
 		s.delete(c);
 		assertEquals( Long.valueOf( 0 ), s.createCriteria( Contract.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria( Party.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testCreateWithNonEmptyOneToManyCollectionUpdateWithNewElement() {
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone");
 		Party party = new Party( "party" );
 		c.addParty( party );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist(c);
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		Party newParty = new Party( "new party" );
 		c.addParty( newParty );
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = (Contract) s.createCriteria(Contract.class).uniqueResult();
 		assertEquals( 2, c.getParties().size() );
 		for ( Object o : c.getParties() ) {
 			Party aParty = (Party) o;
 			if ( aParty.getId() == party.getId() ) {
 				assertEquals( "party", aParty.getName() );
 			}
 			else if ( aParty.getId() == newParty.getId() ) {
 				assertEquals( "new party", aParty.getName() );
 			}
 			else {
 				fail( "unknown party" );
 			}
 			if ( isContractPartiesBidirectional ) {
 				assertSame( c, aParty.getContract() );
 			}
 		}
 		s.delete(c);
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Party.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 3 );
 	}
 
 	@Test
 	public void testCreateWithEmptyOneToManyCollectionMergeWithExistingElement() {
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone");
 		Party party = new Party( "party" );
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( c );
 		s.persist( party );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		c.addParty( party );
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = ( Contract ) s.merge( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 0 );
 		if ( checkUpdateCountsAfterAddingExistingElement() ) {
 			assertUpdateCount( isContractVersioned && ! isContractPartiesInverse ? 1 : 0 );
 		}
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = (Contract) s.createCriteria( Contract.class ).uniqueResult();
 		if ( isContractPartiesInverse ) {
 			assertEquals( 0, c.getParties().size() );
 			s.delete( party );
 		}
 		else {
 			assertEquals( 1, c.getParties().size() );
 			party = ( Party ) c.getParties().iterator().next();
 			assertEquals( "party", party.getName() );
 			if ( isContractPartiesBidirectional ) {
 				assertSame( c, party.getContract() );
 			}
 		}
 		s.delete(c);
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Party.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testCreateWithNonEmptyOneToManyCollectionMergeWithNewElement() {
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone");
 		Party party = new Party( "party" );
 		c.addParty( party );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist(c);
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		Party newParty = new Party( "new party" );
 		c.addParty( newParty );
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = ( Contract ) s.merge( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = (Contract) s.createCriteria(Contract.class).uniqueResult();
 		assertEquals( 2, c.getParties().size() );
 		for ( Object o : c.getParties() ) {
 			Party aParty = (Party) o;
 			if ( aParty.getId() == party.getId() ) {
 				assertEquals( "party", aParty.getName() );
 			}
 			else if ( !aParty.getName().equals( newParty.getName() ) ) {
 				fail( "unknown party:" + aParty.getName() );
 			}
 			if ( isContractPartiesBidirectional ) {
 				assertSame( c, aParty.getContract() );
 			}
 		}
 		s.delete(c);
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Party.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 3 );
 	}
 
 	@Test
 	public void testMoveOneToManyElementToNewEntityCollection() {
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone");
 		c.addParty( new Party( "party" ) );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist(c);
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = (Contract) s.createCriteria( Contract.class ).uniqueResult();
 		assertEquals( 1, c.getParties().size() );
 		Party party = ( Party ) c.getParties().iterator().next();
 		assertEquals( "party", party.getName() );
 		if ( isContractPartiesBidirectional ) {
 			assertSame( c, party.getContract() );
 		}
 		c.removeParty( party );
 		Contract c2 = new Contract(null, "david", "phone" );
 		c2.addParty( party );
 		s.save( c2 );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = (Contract) s.createCriteria( Contract.class ).add( Restrictions.idEq( Long.valueOf( c.getId() ) )).uniqueResult();
 		c2 = (Contract) s.createCriteria( Contract.class ).add( Restrictions.idEq( Long.valueOf( c2.getId() ) )).uniqueResult();
 		if ( isContractPartiesInverse ) {
 			assertEquals( 1, c.getParties().size() );
 			party = ( Party ) c.getParties().iterator().next();
 			assertEquals( "party", party.getName() );
 			if ( isContractPartiesBidirectional ) {
 				assertSame( c, party.getContract() );
 			}
 			assertEquals( 0, c2.getParties().size() );
 		}
 		else {
 			assertEquals( 0, c.getParties().size() );
 			assertEquals( 1, c2.getParties().size() );
 			party = ( Party ) c2.getParties().iterator().next();
 			assertEquals( "party", party.getName() );
 			if ( isContractPartiesBidirectional ) {
 				assertSame( c2, party.getContract() );
 			}
 		}
 		s.delete(c);
 		s.delete( c2 );
 		assertEquals( new Long( 0 ), s.createCriteria( Contract.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( new Long( 0 ), s.createCriteria( Party.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 3 );
 	}
 
 	@Test
 	public void testMoveOneToManyElementToExistingEntityCollection() {
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone");
 		c.addParty( new Party( "party" ) );
 		Contract c2 = new Contract(null, "david", "phone" );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( c );
 		s.persist( c2 );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 3 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = (Contract) s.createCriteria( Contract.class ).add( Restrictions.idEq( Long.valueOf( c.getId() ) )).uniqueResult();
 		assertEquals( 1, c.getParties().size() );
 		Party party = ( Party ) c.getParties().iterator().next();
 		assertEquals( "party", party.getName() );
 		if ( isContractPartiesBidirectional ) {
 			assertSame( c, party.getContract() );
 		}
 		c.removeParty( party );
 		c2 = (Contract) s.createCriteria( Contract.class ).add( Restrictions.idEq( Long.valueOf( c2.getId() ) )).uniqueResult();
 		c2.addParty( party );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 0 );
 		assertUpdateCount( isContractVersioned ? 2 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = (Contract) s.createCriteria( Contract.class ).add( Restrictions.idEq( Long.valueOf( c.getId() ) )).uniqueResult();
 		c2 = (Contract) s.createCriteria( Contract.class ).add( Restrictions.idEq( Long.valueOf( c2.getId() ) )).uniqueResult();
 		if ( isContractPartiesInverse ) {
 			assertEquals( 1, c.getParties().size() );
 			party = ( Party ) c.getParties().iterator().next();
 			assertEquals( "party", party.getName() );
 			if ( isContractPartiesBidirectional ) {
 				assertSame( c, party.getContract() );
 			}
 			assertEquals( 0, c2.getParties().size() );
 		}
 		else {
 			assertEquals( 0, c.getParties().size() );
 			assertEquals( 1, c2.getParties().size() );
 			party = ( Party ) c2.getParties().iterator().next();
 			assertEquals( "party", party.getName() );
 			if ( isContractPartiesBidirectional ) {
 				assertSame( c2, party.getContract() );
 			}
 		}
 		s.delete(c);
 		s.delete( c2 );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria( Contract.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria( Party.class ).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 3 );
 	}
 
 	@Test
 	public void testRemoveOneToManyElementUsingUpdate() {
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone");
 		Party party = new Party( "party" );
 		c.addParty( party );
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		c.removeParty( party );
 		assertEquals( 0, c.getParties().size() );
 		if ( isContractPartiesBidirectional ) {
 			assertNull( party.getContract() );
 		}
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( c );
 		s.update( party );
 		t.commit();
 		s.close();
 
 		if ( checkUpdateCountsAfterRemovingElementWithoutDelete() ) {
 			assertUpdateCount( isContractVersioned && ! isContractPartiesInverse ? 1 : 0 );
 		}
 		assertDeleteCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = ( Contract ) s.createCriteria( Contract.class ).uniqueResult();
 		if ( isContractPartiesInverse ) {
 			assertEquals( 1, c.getParties().size() );
 			party = ( Party ) c.getParties().iterator().next();
 			assertEquals( "party", party.getName() );
 			assertSame( c, party.getContract() );
 		}
 		else {
 			assertEquals( 0, c.getParties().size() );
 			party = ( Party ) s.createCriteria( Party.class ).uniqueResult();
 			if ( isContractPartiesBidirectional ) {
 				assertNull( party.getContract() );
 			}
 			s.delete( party );
 		}
 		s.delete( c );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Party.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testRemoveOneToManyElementUsingMerge() {
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone");
 		Party party = new Party( "party" );
 		c.addParty( party );
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		c.removeParty( party );
 		assertEquals( 0, c.getParties().size() );
 		if ( isContractPartiesBidirectional ) {
 			assertNull( party.getContract() );
 		}
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = ( Contract ) s.merge( c );
 		party = ( Party ) s.merge( party );
 		t.commit();
 		s.close();
 
 		if ( checkUpdateCountsAfterRemovingElementWithoutDelete() ) {
 			assertUpdateCount( isContractVersioned && ! isContractPartiesInverse ? 1 : 0 );
 		}
 		assertDeleteCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = ( Contract ) s.createCriteria( Contract.class ).uniqueResult();
 		if ( isContractPartiesInverse ) {
 			assertEquals( 1, c.getParties().size() );
 			party = ( Party ) c.getParties().iterator().next();
 			assertEquals( "party", party.getName() );
 			assertSame( c, party.getContract() );
 		}
 		else {
 			assertEquals( 0, c.getParties().size() );
 			party = ( Party ) s.createCriteria( Party.class ).uniqueResult();
 			if ( isContractPartiesBidirectional ) {
 				assertNull( party.getContract() );
 			}
 			s.delete( party );
 		}
 		s.delete( c );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Party.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testDeleteOneToManyElement() {
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone");
 		Party party = new Party( "party" );
 		c.addParty( party );
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( c );
 		c.removeParty( party );
 		s.delete( party );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		assertDeleteCount( 1 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = ( Contract ) s.createCriteria( Contract.class ).uniqueResult();
 		assertEquals( 0, c.getParties().size() );
 		party = ( Party ) s.createCriteria( Party.class ).uniqueResult();
 		assertNull( party );
 		s.delete( c );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Party.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 1 );
 	}
 
 	@Test
 	public void testRemoveOneToManyElementByDelete() {
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone");
 		Party party = new Party( "party" );
 		c.addParty( party );
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		c.removeParty( party );
 		assertEquals( 0, c.getParties().size() );
 		if ( isContractPartiesBidirectional ) {
 			assertNull( party.getContract() );
 		}
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( c );
 		s.delete( party );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		assertDeleteCount( 1 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = ( Contract ) s.createCriteria( Contract.class ).uniqueResult();
 		assertEquals( 0, c.getParties().size() );
 		s.delete( c );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Party.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 1 );
 	}
 
 	@Test
 	public void testRemoveOneToManyOrphanUsingUpdate() {
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone");
 		ContractVariation cv = new ContractVariation( 1, c );
 		cv.setText( "cv1" );
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		c.getVariations().remove( cv );
 		cv.setContract( null );
 		assertEquals( 0, c.getVariations().size() );
 		if ( isContractVariationsBidirectional ) {
 			assertNull( cv.getContract() );
 		}
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( c );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		assertDeleteCount( 1 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = ( Contract ) s.createCriteria( Contract.class ).uniqueResult();
 		assertEquals( 0, c.getVariations().size() );
 		cv = ( ContractVariation ) s.createCriteria( ContractVariation.class ).uniqueResult();
 		assertNull( cv );
 		s.delete( c );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(ContractVariation.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 1 );
 	}
 
 	@Test
 	public void testRemoveOneToManyOrphanUsingMerge() {
 		Contract c = new Contract( null, "gail", "phone");
 		ContractVariation cv = new ContractVariation( 1, c );
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		c.getVariations().remove( cv );
 		cv.setContract( null );
 		assertEquals( 0, c.getVariations().size() );
 		if ( isContractVariationsBidirectional ) {
 			assertNull( cv.getContract() );
 		}
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = ( Contract ) s.merge( c );
 		cv = ( ContractVariation ) s.merge( cv );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		assertDeleteCount( 1 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = ( Contract ) s.createCriteria( Contract.class ).uniqueResult();
 		assertEquals( 0, c.getVariations().size() );
 		cv = ( ContractVariation ) s.createCriteria( ContractVariation.class ).uniqueResult();
 		assertNull( cv );
 		s.delete( c );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(ContractVariation.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 1 );
 	}
 
 	@Test
 	public void testDeleteOneToManyOrphan() {
 		clearCounts();
 
 		Contract c = new Contract( null, "gail", "phone");
 		ContractVariation cv = new ContractVariation( 1, c );
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist( c );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( c );
 		c.getVariations().remove( cv );
 		cv.setContract( null );
 		assertEquals( 0, c.getVariations().size() );
 		s.delete( cv );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		assertDeleteCount( 1 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = ( Contract ) s.createCriteria( Contract.class ).uniqueResult();
 		assertEquals( 0, c.getVariations().size() );
 		cv = ( ContractVariation ) s.createCriteria( ContractVariation.class ).uniqueResult();
 		assertNull( cv );
 		s.delete( c );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(ContractVariation.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 1 );
 	}
 
 	@Test
 	public void testOneToManyCollectionOptimisticLockingWithMerge() {
 		clearCounts();
 
 		Contract cOrig = new Contract( null, "gail", "phone");
 		Party partyOrig = new Party( "party" );
 		cOrig.addParty( partyOrig );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist(cOrig);
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Contract c = ( Contract ) s.get( Contract.class, cOrig.getId() );
 		Party newParty = new Party( "new party" );
 		c.addParty( newParty );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		cOrig.removeParty( partyOrig );
 		try {
 			s.merge( cOrig );
 			assertFalse( isContractVersioned );
 		}
 		catch (StaleObjectStateException ex) {
 			assertTrue( isContractVersioned);
 		}
 		finally {
 			t.rollback();
 		}
 		s.close();
 		
 		s = openSession();
 		t = s.beginTransaction();
 		c = (Contract) s.createCriteria(Contract.class).uniqueResult();
 		s.delete(c);
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Party.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 3 );
 	}
 
 	@Test
 	public void testOneToManyCollectionOptimisticLockingWithUpdate() {
 		clearCounts();
 
 		Contract cOrig = new Contract( null, "gail", "phone");
 		Party partyOrig = new Party( "party" );
 		cOrig.addParty( partyOrig );
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.persist(cOrig);
 		t.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Contract c = ( Contract ) s.get( Contract.class, cOrig.getId() );
 		Party newParty = new Party( "new party" );
 		c.addParty( newParty );
 		t.commit();
 		s.close();
 
 		assertInsertCount( 1 );
 		assertUpdateCount( isContractVersioned ? 1 : 0 );
 		clearCounts();
 
 		s = openSession();
 		t = s.beginTransaction();
 		cOrig.removeParty( partyOrig );
 		s.update( cOrig );
 		try {
 			t.commit();
 			assertFalse( isContractVersioned );
 		}
-		catch (StaleStateException ex) {
+		catch (TransactionException ex) {
 			t.rollback();
 			assertTrue( isContractVersioned );
 			if ( ! sessionFactory().getSettings().isJdbcBatchVersionedData() ) {
-				assertTrue( StaleObjectStateException.class.isInstance( ex ) );
+				assertTrue( StaleObjectStateException.class.isInstance( ex.getCause() ) );
 			}
 		}
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		c = (Contract) s.createCriteria(Contract.class).uniqueResult();
 		s.createQuery( "delete from Party" ).executeUpdate();
 		s.delete( c );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Contract.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		assertEquals( Long.valueOf( 0 ), s.createCriteria(Party.class).setProjection( Projections.rowCount() ).uniqueResult() );
 		t.commit();
 		s.close();
 	}
 
 	protected void clearCounts() {
 		sessionFactory().getStatistics().clear();
 	}
 
 	protected void assertInsertCount(int expected) {
 		int inserts = ( int ) sessionFactory().getStatistics().getEntityInsertCount();
 		assertEquals( "unexpected insert count", expected, inserts );
 	}
 
 	protected void assertUpdateCount(int expected) {
 		int updates = ( int ) sessionFactory().getStatistics().getEntityUpdateCount();
 		assertEquals( "unexpected update counts", expected, updates );
 	}
 
 	protected void assertDeleteCount(int expected) {
 		int deletes = ( int ) sessionFactory().getStatistics().getEntityDeleteCount();
 		assertEquals( "unexpected delete counts", expected, deletes );
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/interceptor/InterceptorTest.java b/hibernate-core/src/test/java/org/hibernate/test/interceptor/InterceptorTest.java
index 7eadae1682..7a2ca10c57 100755
--- a/hibernate-core/src/test/java/org/hibernate/test/interceptor/InterceptorTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/interceptor/InterceptorTest.java
@@ -1,353 +1,360 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2006-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.interceptor;
 import java.io.Serializable;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Locale;
 import java.util.Queue;
 
 import org.junit.Test;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.Interceptor;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.TransactionException;
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.type.Type;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertSame;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author Gavin King
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public class InterceptorTest extends BaseCoreFunctionalTestCase {
 	@Override
 	public String[] getMappings() {
 		return new String[] { "interceptor/User.hbm.xml", "interceptor/Image.hbm.xml" };
 	}
 
 	@Test
 	public void testCollectionIntercept() {
 		Session s = openSession( new CollectionInterceptor() );
 		Transaction t = s.beginTransaction();
 		User u = new User("Gavin", "nivag");
 		s.persist(u);
 		u.setPassword("vagni");
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		u = (User) s.get(User.class, "Gavin");
 		assertEquals( 2, u.getActions().size() );
 		s.delete(u);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testPropertyIntercept() {
 		Session s = openSession( new PropertyInterceptor() );
 		Transaction t = s.beginTransaction();
 		User u = new User("Gavin", "nivag");
 		s.persist(u);
 		u.setPassword("vagni");
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		u = (User) s.get(User.class, "Gavin");
 		assertNotNull( u.getCreated() );
 		assertNotNull( u.getLastUpdated() );
 		s.delete(u);
 		t.commit();
 		s.close();
 	}
 
 	/**
 	 * Test case from HHH-1921.  Here the interceptor resets the
 	 * current-state to the same thing as the current db state; this
 	 * causes EntityPersister.findDirty() to return no dirty properties.
 	 */
 	@Test
 	@TestForIssue( jiraKey = "HHH-1921" )
 	public void testPropertyIntercept2() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		User u = new User("Josh", "test");
 		s.persist( u );
 		t.commit();
 		s.close();
 
 		s = openSession(
 				new EmptyInterceptor() {
 					public boolean onFlushDirty(Object entity, Serializable id, Object[] currentState, Object[] previousState, String[] propertyNames, Type[] types) {
 						currentState[0] = "test";
 						return true;
 					}
 				}
 		);
 		t = s.beginTransaction();
 		u = ( User ) s.get( User.class, u.getName() );
 		u.setPassword( "nottest" );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		u = (User) s.get(User.class, "Josh");
 		assertEquals("test", u.getPassword());
 		s.delete(u);
 		t.commit();
 		s.close();
 
 	}
 
 	/**
 	 * Test that setting a transaction timeout will cause an Exception to occur
 	 * if the transaction timeout is exceeded.
 	 */
 	@Test
 	public void testTimeout() throws Exception {
 		final int TIMEOUT = 2;
 		final int WAIT = TIMEOUT + 1;
 		Session s = openSession();
 		// Get the transaction and set the timeout BEFORE calling begin()
 		Transaction t = s.getTransaction();
 		t.setTimeout( TIMEOUT );
 		t.begin();
 		// Sleep for an amount of time that exceeds the transaction timeout
 		Thread.sleep( WAIT * 1000 );
         try {
         	// Do something with the transaction and try to commit it
         	s.persist( new User( "john", "test" ) );
         	t.commit();
             fail( "Transaction should have timed out" );
-        } 
-        catch ( TransactionException e ) {
-        	// Insure that the Exception is "transaction timeout expired"
-        	String exceptionActual = e.toString();
+        }
+		catch (TransactionException e) {
+			// Insure that the Exception is "transaction timeout expired"
+			String exceptionActual = e.getCause().toString();
 			String exceptionExpected = "org.hibernate.TransactionException: transaction timeout expired";
 			if ( !exceptionActual.contains( exceptionExpected ) ) {
-        		String msg = String.format( "Transaction failed for the wrong reason.  Expected [%s] but received [%s]",
-        				exceptionExpected, exceptionActual );
-        		fail( msg );
-        				
-        	}
-        } 
+				String msg = String.format(
+						"Transaction failed for the wrong reason.  Expected [%s] but received [%s]",
+						exceptionExpected, exceptionActual
+				);
+				fail( msg );
+
+			}
+		}
 	}
 
 	@Test
 	public void testComponentInterceptor() {
 		final int checkPerm = 500;
 		final String checkComment = "generated from interceptor";
 
 		Session s = openSession(
 				new EmptyInterceptor() {
 					public boolean onSave(Object entity, Serializable id, Object[] state, String[] propertyNames, Type[] types) {
 						if ( state[0] == null ) {
 							Image.Details detail = new Image.Details();
 							detail.setPerm1( checkPerm );
 							detail.setComment( checkComment );
 							state[0] = detail;
 						}
 						return true;
 					}
 				}
 		);
 		s.beginTransaction();
 		Image i = new Image();
 		i.setName( "compincomp" );
 		i = ( Image ) s.merge( i );
 		assertNotNull( i.getDetails() );
 		assertEquals( checkPerm, i.getDetails().getPerm1() );
 		assertEquals( checkComment, i.getDetails().getComment() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		i = ( Image ) s.get( Image.class, i.getId() );
 		assertNotNull( i.getDetails() );
 		assertEquals( checkPerm, i.getDetails().getPerm1() );
 		assertEquals( checkComment, i.getDetails().getComment() );
 		s.delete( i );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testStatefulIntercept() {
 		final StatefulInterceptor statefulInterceptor = new StatefulInterceptor();
 		Session s = openSession( statefulInterceptor );
 		statefulInterceptor.setSession(s);
 
 		Transaction t = s.beginTransaction();
 		User u = new User("Gavin", "nivag");
 		s.persist(u);
 		u.setPassword("vagni");
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		List logs = s.createCriteria(Log.class).list();
 		assertEquals( 2, logs.size() );
 		s.delete(u);
 		s.createQuery( "delete from Log" ).executeUpdate();
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testInitiateIntercept() {
 		final String injectedString = "******";
 		final InstantiateInterceptor initiateInterceptor = new InstantiateInterceptor( injectedString );
 		Session s = openSession( initiateInterceptor );
 
 		Transaction t = s.beginTransaction();
 		User u = new User( "Gavin", "nivag" );
 		s.persist( u );
 		t.commit();
 		s.close();
 
 		assertNull( u.getInjectedString() );
 		u.setPassword( "blah" );
 
 		s = openSession( initiateInterceptor );
 		t = s.beginTransaction();
 
 		User merged = ( User ) s.merge( u );
 		assertEquals( injectedString, merged.getInjectedString() );
 		assertEquals( u.getName(), merged.getName() );
 		assertEquals( u.getPassword(), merged.getPassword() );
 
 		merged.setInjectedString( null );
 
 		User loaded = ( User ) s.load(User.class, merged.getName());
 		// the session-bound instance was not instantiated by the interceptor, load simply returns it
 		assertSame( merged, loaded );
 		assertNull( merged.getInjectedString() );
 
 		// flush the session and evict the merged instance from session to force an actual load
 		s.flush();
 		s.evict( merged );
 
 		User reloaded = ( User ) s.load( User.class, merged.getName() );
 		// Interceptor IS called for instantiating the persistent instance associated to the session when using load
 		assertEquals( injectedString, reloaded.getInjectedString() );
 		assertEquals( u.getName(), reloaded.getName() );
 		assertEquals( u.getPassword(), reloaded.getPassword() );
 
 		s.delete( reloaded );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-6594" )
 	public void testPrepareStatementIntercept() {
 		final Queue<String> expectedSQLs = new LinkedList<String>();
 		// Transaction 1
 		expectedSQLs.add( "insert" );
 		// Transaction 2
 		expectedSQLs.add( "select" );
 		expectedSQLs.add( "select" );
 		// Transaction 3
 		expectedSQLs.add( "select" );
 		expectedSQLs.add( "select" );
 		expectedSQLs.add( "update" );
 		// Transaction 4
 		expectedSQLs.add( "select" );
 		expectedSQLs.add( "delete" );
 
 		final Interceptor interceptor = new EmptyInterceptor() {
 			@Override
 			public String onPrepareStatement(String sql) {
 				assertNotNull( sql );
 				String expectedSql = expectedSQLs.poll().toLowerCase(Locale.ROOT);
 				assertTrue("sql:\n " + sql.toLowerCase(Locale.ROOT) +"\n doesn't start with \n"+expectedSql+"\n", sql.toLowerCase(Locale.ROOT).startsWith( expectedSql ) );
 				return sql;
 			}
 		};
 
 		Session s = openSession(interceptor);
 		Transaction t = s.beginTransaction();
 		User u = new User( "Lukasz", "Antoniak" );
 		s.persist( u );
 		t.commit();
 		s.close();
 
 		s = openSession(interceptor);
 		t = s.beginTransaction();
 		s.get( User.class, "Lukasz" );
 		s.createQuery( "from User u" ).list();
 		t.commit();
 		s.close();
 
 		u.setPassword( "Kinga" );
 		s = openSession(interceptor);
 		t = s.beginTransaction();
 		s.merge( u );
 		t.commit();
 		s.close();
 
 		s = openSession(interceptor);
 		t = s.beginTransaction();
 		s.delete( u );
 		t.commit();
 		s.close();
 
 		assertTrue( expectedSQLs.isEmpty() );
 	}
 
-	@Test(expected = AssertionFailure.class)
 	public void testPrepareStatementFaultIntercept() {
 		final Interceptor interceptor = new EmptyInterceptor() {
 			@Override
 			public String onPrepareStatement(String sql) {
 				return null;
 			}
 		};
 
-		Session s = openSession(interceptor);
-		Transaction t = s.beginTransaction();
-		User u = new User( "Kinga", "Mroz" );
-		s.persist( u );
-		t.commit();
-		s.close();
+		Session s = openSession( interceptor );
+		try {
+
+			Transaction t = s.beginTransaction();
+			User u = new User( "Kinga", "Mroz" );
+			s.persist( u );
+			t.commit();
+		}catch (TransactionException e){
+			assertTrue( e.getCause() instanceof AssertionFailure );
+		}finally {
+			s.close();
+		}
 	}
 }
 
diff --git a/hibernate-core/src/test/java/org/hibernate/test/interfaceproxy/DocumentInterceptor.java b/hibernate-core/src/test/java/org/hibernate/test/interfaceproxy/DocumentInterceptor.java
index 3455384083..749961aa66 100755
--- a/hibernate-core/src/test/java/org/hibernate/test/interfaceproxy/DocumentInterceptor.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/interfaceproxy/DocumentInterceptor.java
@@ -1,94 +1,98 @@
 //$Id: DocumentInterceptor.java 7860 2005-08-11 21:58:23Z oneovthafew $
 package org.hibernate.test.interfaceproxy;
 import java.io.Serializable;
 import java.util.Calendar;
 import java.util.Iterator;
 
 import org.hibernate.CallbackException;
 import org.hibernate.EntityMode;
 import org.hibernate.Interceptor;
 import org.hibernate.Transaction;
 import org.hibernate.type.Type;
 
 /**
  * @author Gavin King
  */
 public class DocumentInterceptor implements Interceptor {
 
-
 	public boolean onLoad(Object entity, Serializable id, Object[] state,
 			String[] propertyNames, Type[] types) throws CallbackException {
 		return false;
 	}
 
 	public boolean onFlushDirty(Object entity, Serializable id,
 			Object[] currentState, Object[] previousState,
 			String[] propertyNames, Type[] types) throws CallbackException {
 		if ( entity instanceof Document ) {
 			currentState[2] = Calendar.getInstance();
 			return true;
 		}
 		else {
 			return false;
 		}
 	}
 
 	public boolean onSave(Object entity, Serializable id, Object[] state,
 			String[] propertyNames, Type[] types) throws CallbackException {
 		if ( entity instanceof Document ) {
 			state[3] = state[2] = Calendar.getInstance();
 			return true;
 		}
 		else {
 			return false;
 		}
 	}
 
 	public void onDelete(Object entity, Serializable id, Object[] state,
 			String[] propertyNames, Type[] types) throws CallbackException {
 
 	}
 
 	public void preFlush(Iterator entities) throws CallbackException {
 
 	}
 
 	public void postFlush(Iterator entities) throws CallbackException {
 
 	}
 
 	public Boolean isTransient(Object entity) {
 		return null;
 	}
 
 	public int[] findDirty(Object entity, Serializable id,
 			Object[] currentState, Object[] previousState,
 			String[] propertyNames, Type[] types) {
 		return null;
 	}
 
 	public Object instantiate(String entityName, EntityMode entityMode, Serializable id) throws CallbackException {
 		return null;
 	}
 
 	public String getEntityName(Object object) throws CallbackException {
 		return null;
 	}
 
 	public Object getEntity(String entityName, Serializable id)
 			throws CallbackException {
 		return null;
 	}
 
 	public void afterTransactionBegin(Transaction tx) {}
 	public void afterTransactionCompletion(Transaction tx) {}
 	public void beforeTransactionCompletion(Transaction tx) {}
 
 	public String onPrepareStatement(String sql) {
 		return sql;
 	}
 
 	public void onCollectionRecreate(Object collection, Serializable key) throws CallbackException {}
 	public void onCollectionRemove(Object collection, Serializable key) throws CallbackException {}
 	public void onCollectionUpdate(Object collection, Serializable key) throws CallbackException {}
+
+	@Override
+	public String inspect(String sql) {
+		return sql;
+	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/jdbc/GeneralWorkTest.java b/hibernate-core/src/test/java/org/hibernate/test/jdbc/GeneralWorkTest.java
index 17f2fb9f2f..26cca92086 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/jdbc/GeneralWorkTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/jdbc/GeneralWorkTest.java
@@ -1,192 +1,192 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.jdbc;
 import java.sql.Connection;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
 
 import org.junit.Test;
 
 import org.hibernate.JDBCException;
 import org.hibernate.Session;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.ReturningWork;
 import org.hibernate.jdbc.Work;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.fail;
 
 /**
  * GeneralWorkTest implementation
  *
  * @author Steve Ebersole
  */
 public class GeneralWorkTest extends BaseCoreFunctionalTestCase {
 	@Override
 	public String getBaseForMappings() {
 		return "org/hibernate/test/jdbc/";
 	}
 
 	@Override
 	public String[] getMappings() {
 		return new String[] { "Mappings.hbm.xml" };
 	}
 
 	@Test
 	public void testGeneralUsage() throws Throwable {
 		final Session session = openSession();
 		session.beginTransaction();
 		session.doWork(
 				new Work() {
 					public void execute(Connection connection) throws SQLException {
 						// in this current form, users must handle try/catches themselves for proper resource release
 						Statement statement = null;
 						try {
-							statement = ((SessionImplementor)session).getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().createStatement();
+							statement = ((SessionImplementor)session).getJdbcCoordinator().getStatementPreparer().createStatement();
 							ResultSet resultSet = null;
 							try {
 								
-								resultSet = ((SessionImplementor)session).getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( statement, "select * from T_JDBC_PERSON" );
+								resultSet = ((SessionImplementor)session).getJdbcCoordinator().getResultSetReturn().extract( statement, "select * from T_JDBC_PERSON" );
 							}
 							finally {
 								releaseQuietly( ((SessionImplementor)session), resultSet, statement );
 							}
 							try {
-								((SessionImplementor)session).getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( statement, "select * from T_JDBC_BOAT" );
+								((SessionImplementor)session).getJdbcCoordinator().getResultSetReturn().extract( statement, "select * from T_JDBC_BOAT" );
 							}
 							finally {
 								releaseQuietly( ((SessionImplementor)session), resultSet, statement );
 							}
 						}
 						finally {
 							releaseQuietly( ((SessionImplementor)session), statement );
 						}
 					}
 				}
 		);
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Test
 	public void testSQLExceptionThrowing() {
 		final Session session = openSession();
 		session.beginTransaction();
 		try {
 			session.doWork(
 					new Work() {
 						public void execute(Connection connection) throws SQLException {
 							Statement statement = null;
 							try {
-								statement = ((SessionImplementor)session).getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().createStatement();
-								((SessionImplementor)session).getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( statement, "select * from non_existent" );
+								statement = ((SessionImplementor)session).getJdbcCoordinator().getStatementPreparer().createStatement();
+								((SessionImplementor)session).getJdbcCoordinator().getResultSetReturn().extract( statement, "select * from non_existent" );
 							}
 							finally {
 								releaseQuietly( ((SessionImplementor)session), statement );
 							}
 						}
 					}
 			);
 			fail( "expecting exception" );
 		}
 		catch ( JDBCException expected ) {
 			// expected outcome
 		}
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Test
 	public void testGeneralReturningUsage() throws Throwable {
 		Session session = openSession();
 		session.beginTransaction();
 		Person p = new Person( "Abe", "Lincoln" );
 		session.save( p );
 		session.getTransaction().commit();
 
 		final Session session2 = openSession();
 		session2.beginTransaction();
 		long count = session2.doReturningWork(
 				new ReturningWork<Long>() {
 					public Long execute(Connection connection) throws SQLException {
 						// in this current form, users must handle try/catches themselves for proper resource release
 						Statement statement = null;
 						long personCount = 0;
 						try {
-							statement = ((SessionImplementor)session2).getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().createStatement();
+							statement = ((SessionImplementor)session2).getJdbcCoordinator().getStatementPreparer().createStatement();
 							ResultSet resultSet = null;
 							try {
-								resultSet = ((SessionImplementor)session2).getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( statement, "select count(*) from T_JDBC_PERSON" );
+								resultSet = ((SessionImplementor)session2).getJdbcCoordinator().getResultSetReturn().extract( statement, "select count(*) from T_JDBC_PERSON" );
 								resultSet.next();
 								personCount = resultSet.getLong( 1 );
 								assertEquals( 1L, personCount );
 							}
 							finally {
 								releaseQuietly( ((SessionImplementor)session2), resultSet, statement );
 							}
 						}
 						finally {
 							releaseQuietly( ((SessionImplementor)session2), statement );
 						}
 						return personCount;
 					}
 				}
 		);
 		session2.getTransaction().commit();
 		session2.close();
 		assertEquals( 1L, count );
 
 		session = openSession();
 		session.beginTransaction();
 		session.delete( p );
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	private void releaseQuietly(SessionImplementor s, Statement statement) {
 		if ( statement == null ) {
 			return;
 		}
 		try {
-			s.getTransactionCoordinator().getJdbcCoordinator().release( statement );
+			s.getJdbcCoordinator().getResourceRegistry().release( statement );
 		}
 		catch (Exception e) {
 			// ignore
 		}
 	}
 
 	private void releaseQuietly(SessionImplementor s, ResultSet resultSet, Statement statement) {
 		if ( resultSet == null ) {
 			return;
 		}
 		try {
-			s.getTransactionCoordinator().getJdbcCoordinator().release( resultSet, statement );
+			s.getJdbcCoordinator().getResourceRegistry().release( resultSet, statement );
 		}
 		catch (Exception e) {
 			// ignore
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/jdbc/internal/AggressiveReleaseTest.java b/hibernate-core/src/test/java/org/hibernate/test/jdbc/internal/AggressiveReleaseTest.java
index 28f2f3884e..0bd51a182f 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/jdbc/internal/AggressiveReleaseTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/jdbc/internal/AggressiveReleaseTest.java
@@ -1,268 +1,268 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.jdbc.internal;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.sql.Statement;
 
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.Session;
 import org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl;
-import org.hibernate.engine.jdbc.internal.LogicalConnectionImpl;
-import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
-import org.hibernate.engine.jdbc.spi.LogicalConnectionImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
+import org.hibernate.resource.jdbc.spi.LogicalConnectionImplementor;
+
 import org.hibernate.test.common.BasicTestingJdbcServiceImpl;
 import org.hibernate.test.common.JdbcConnectionAccessImpl;
 import org.hibernate.test.common.JournalingConnectionObserver;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.junit.Test;
 
 /**
  * @author Steve Ebersole
  */
 public class AggressiveReleaseTest extends BaseCoreFunctionalTestCase {
 	
 	private BasicTestingJdbcServiceImpl services = new BasicTestingJdbcServiceImpl();
 	
 	@Override
 	protected void prepareTest() throws Exception {
 		services.prepare( true );
 
 		Connection connection = null;
 		Statement stmnt = null;
 		try {
 			connection = services.getConnectionProvider().getConnection();
 			stmnt = connection.createStatement();
 			stmnt.execute( "drop table SANDBOX_JDBC_TST if exists" );
 			stmnt.execute( "create table SANDBOX_JDBC_TST ( ID integer, NAME varchar(100) )" );
 		}
 		finally {
 			if ( stmnt != null ) {
 				try {
 					stmnt.close();
 				}
 				catch ( SQLException ignore ) {
 				}
 			}
 			if ( connection != null ) {
 				try {
 					connection.close();
 				}
 				catch ( SQLException ignore ) {
 				}
 			}
 		}
 	}
 	
 	@Override
 	protected void cleanupTest() throws Exception {
 		Connection connection = null;
 		Statement stmnt = null;
 		try {
 			connection = services.getConnectionProvider().getConnection();
 			stmnt = connection.createStatement();
 			stmnt.execute( "drop table SANDBOX_JDBC_TST if exists" );
 		}
 		finally {
 			if ( stmnt != null ) {
 				try {
 					stmnt.close();
 				}
 				catch ( SQLException ignore ) {
 				}
 			}
 			if ( connection != null ) {
 				try {
 					connection.close();
 				}
 				catch ( SQLException ignore ) {
 				}
 			}
 		}
 
 		services.release();
 	}
 	
 	@Test
 	public void testBasicRelease() {
-		Session session = openSession();
-		SessionImplementor sessionImpl = (SessionImplementor) session;
-		
-		LogicalConnectionImpl logicalConnection = new LogicalConnectionImpl( null,
-				ConnectionReleaseMode.AFTER_STATEMENT, services, new JdbcConnectionAccessImpl(
-						services.getConnectionProvider() ) );
-		JdbcCoordinatorImpl jdbcCoord = new JdbcCoordinatorImpl( logicalConnection,
-				sessionImpl.getTransactionCoordinator() );
-		JournalingConnectionObserver observer = new JournalingConnectionObserver();
-		logicalConnection.addObserver( observer );
-
-		try {
-			PreparedStatement ps = jdbcCoord.getStatementPreparer().prepareStatement( "insert into SANDBOX_JDBC_TST( ID, NAME ) values ( ?, ? )" );
-			ps.setLong( 1, 1 );
-			ps.setString( 2, "name" );
-			jdbcCoord.getResultSetReturn().execute( ps );
-			assertTrue( jdbcCoord.hasRegisteredResources() );
-			assertEquals( 1, observer.getPhysicalConnectionObtainedCount() );
-			assertEquals( 0, observer.getPhysicalConnectionReleasedCount() );
-			jdbcCoord.release( ps );
-			assertFalse( jdbcCoord.hasRegisteredResources() );
-			assertEquals( 1, observer.getPhysicalConnectionObtainedCount() );
-			assertEquals( 1, observer.getPhysicalConnectionReleasedCount() );
-		}
-		catch ( SQLException sqle ) {
-			fail( "incorrect exception type : sqlexception" );
-		}
-		finally {
-			session.close();
-		}
-
-		assertFalse( jdbcCoord.hasRegisteredResources() );
+//		Session session = openSession();
+//		SessionImplementor sessionImpl = (SessionImplementor) session;
+//
+//		LogicalConnectionImplementor logicalConnection = new LogicalConnectionImpl( null,
+//				ConnectionReleaseMode.AFTER_STATEMENT, services, new JdbcConnectionAccessImpl(
+//						services.getConnectionProvider() ) );
+//
+//		JdbcCoordinatorImpl jdbcCoord = new JdbcCoordinatorImpl( logicalConnection,
+//				sessionImpl );
+//		JournalingConnectionObserver observer = new JournalingConnectionObserver();
+//		logicalConnection.addObserver( observer );
+//
+//		try {
+//			PreparedStatement ps = jdbcCoord.getStatementPreparer().prepareStatement( "insert into SANDBOX_JDBC_TST( ID, NAME ) values ( ?, ? )" );
+//			ps.setLong( 1, 1 );
+//			ps.setString( 2, "name" );
+//			jdbcCoord.getResultSetReturn().execute( ps );
+//			assertTrue( jdbcCoord.hasRegisteredResources() );
+//			assertEquals( 1, observer.getPhysicalConnectionObtainedCount() );
+//			assertEquals( 0, observer.getPhysicalConnectionReleasedCount() );
+//			jdbcCoord.release( ps );
+//			assertFalse( jdbcCoord.hasRegisteredResources() );
+//			assertEquals( 1, observer.getPhysicalConnectionObtainedCount() );
+//			assertEquals( 1, observer.getPhysicalConnectionReleasedCount() );
+//		}
+//		catch ( SQLException sqle ) {
+//			fail( "incorrect exception type : sqlexception" );
+//		}
+//		finally {
+//			session.close();
+//		}
+//
+//		assertFalse( jdbcCoord.hasRegisteredResources() );
 	}
 
 	@Test
 	public void testReleaseCircumventedByHeldResources() {
-		Session session = openSession();
-		SessionImplementor sessionImpl = (SessionImplementor) session;
-		
-		LogicalConnectionImpl logicalConnection = new LogicalConnectionImpl( null,
-				ConnectionReleaseMode.AFTER_STATEMENT, services, new JdbcConnectionAccessImpl(
-						services.getConnectionProvider() ) );
-		JdbcCoordinatorImpl jdbcCoord = new JdbcCoordinatorImpl( logicalConnection,
-				sessionImpl.getTransactionCoordinator() );
-		JournalingConnectionObserver observer = new JournalingConnectionObserver();
-		logicalConnection.addObserver( observer );
-
-		try {
-			PreparedStatement ps = jdbcCoord.getStatementPreparer().prepareStatement( "insert into SANDBOX_JDBC_TST( ID, NAME ) values ( ?, ? )" );
-			ps.setLong( 1, 1 );
-			ps.setString( 2, "name" );
-			jdbcCoord.getResultSetReturn().execute( ps );
-			assertTrue( jdbcCoord.hasRegisteredResources() );
-			assertEquals( 1, observer.getPhysicalConnectionObtainedCount() );
-			assertEquals( 0, observer.getPhysicalConnectionReleasedCount() );
-			jdbcCoord.release( ps );
-			assertFalse( jdbcCoord.hasRegisteredResources() );
-			assertEquals( 1, observer.getPhysicalConnectionObtainedCount() );
-			assertEquals( 1, observer.getPhysicalConnectionReleasedCount() );
-	
-			// open a result set and hold it open...
-			ps = jdbcCoord.getStatementPreparer().prepareStatement( "select * from SANDBOX_JDBC_TST" );
-			jdbcCoord.getResultSetReturn().extract( ps );
-			assertTrue( jdbcCoord.hasRegisteredResources() );
-			assertEquals( 2, observer.getPhysicalConnectionObtainedCount() );
-			assertEquals( 1, observer.getPhysicalConnectionReleasedCount() );
-	
-			// open a second result set
-			PreparedStatement ps2 = jdbcCoord.getStatementPreparer().prepareStatement( "select * from SANDBOX_JDBC_TST" );
-			jdbcCoord.getResultSetReturn().execute( ps );
-			assertTrue( jdbcCoord.hasRegisteredResources() );
-			assertEquals( 2, observer.getPhysicalConnectionObtainedCount() );
-			assertEquals( 1, observer.getPhysicalConnectionReleasedCount() );
-			// and close it...
-			jdbcCoord.release( ps2 );
-			// the release should be circumvented...
-			assertTrue( jdbcCoord.hasRegisteredResources() );
-			assertEquals( 2, observer.getPhysicalConnectionObtainedCount() );
-			assertEquals( 1, observer.getPhysicalConnectionReleasedCount() );
-	
-			// let the close of the logical connection below release all resources (hopefully)...
-		}
-		catch ( SQLException sqle ) {
-			fail( "incorrect exception type : sqlexception" );
-		}
-		finally {
-			jdbcCoord.close();
-			session.close();
-		}
-
-		assertFalse( jdbcCoord.hasRegisteredResources() );
-		assertEquals( 2, observer.getPhysicalConnectionObtainedCount() );
-		assertEquals( 2, observer.getPhysicalConnectionReleasedCount() );
+//		Session session = openSession();
+//		SessionImplementor sessionImpl = (SessionImplementor) session;
+//
+//		LogicalConnectionImpl logicalConnection = new LogicalConnectionImpl( null,
+//				ConnectionReleaseMode.AFTER_STATEMENT, services, new JdbcConnectionAccessImpl(
+//						services.getConnectionProvider() ) );
+//		JdbcCoordinatorImpl jdbcCoord = new JdbcCoordinatorImpl( logicalConnection,
+//				sessionImpl.getTransactionCoordinator() );
+//		JournalingConnectionObserver observer = new JournalingConnectionObserver();
+//		logicalConnection.addObserver( observer );
+//
+//		try {
+//			PreparedStatement ps = jdbcCoord.getStatementPreparer().prepareStatement( "insert into SANDBOX_JDBC_TST( ID, NAME ) values ( ?, ? )" );
+//			ps.setLong( 1, 1 );
+//			ps.setString( 2, "name" );
+//			jdbcCoord.getResultSetReturn().execute( ps );
+//			assertTrue( jdbcCoord.hasRegisteredResources() );
+//			assertEquals( 1, observer.getPhysicalConnectionObtainedCount() );
+//			assertEquals( 0, observer.getPhysicalConnectionReleasedCount() );
+//			jdbcCoord.release( ps );
+//			assertFalse( jdbcCoord.hasRegisteredResources() );
+//			assertEquals( 1, observer.getPhysicalConnectionObtainedCount() );
+//			assertEquals( 1, observer.getPhysicalConnectionReleasedCount() );
+//
+//			// open a result set and hold it open...
+//			ps = jdbcCoord.getStatementPreparer().prepareStatement( "select * from SANDBOX_JDBC_TST" );
+//			jdbcCoord.getResultSetReturn().extract( ps );
+//			assertTrue( jdbcCoord.hasRegisteredResources() );
+//			assertEquals( 2, observer.getPhysicalConnectionObtainedCount() );
+//			assertEquals( 1, observer.getPhysicalConnectionReleasedCount() );
+//
+//			// open a second result set
+//			PreparedStatement ps2 = jdbcCoord.getStatementPreparer().prepareStatement( "select * from SANDBOX_JDBC_TST" );
+//			jdbcCoord.getResultSetReturn().execute( ps );
+//			assertTrue( jdbcCoord.hasRegisteredResources() );
+//			assertEquals( 2, observer.getPhysicalConnectionObtainedCount() );
+//			assertEquals( 1, observer.getPhysicalConnectionReleasedCount() );
+//			// and close it...
+//			jdbcCoord.release( ps2 );
+//			// the release should be circumvented...
+//			assertTrue( jdbcCoord.hasRegisteredResources() );
+//			assertEquals( 2, observer.getPhysicalConnectionObtainedCount() );
+//			assertEquals( 1, observer.getPhysicalConnectionReleasedCount() );
+//
+//			// let the close of the logical connection below release all resources (hopefully)...
+//		}
+//		catch ( SQLException sqle ) {
+//			fail( "incorrect exception type : sqlexception" );
+//		}
+//		finally {
+//			jdbcCoord.close();
+//			session.close();
+//		}
+//
+//		assertFalse( jdbcCoord.hasRegisteredResources() );
+//		assertEquals( 2, observer.getPhysicalConnectionObtainedCount() );
+//		assertEquals( 2, observer.getPhysicalConnectionReleasedCount() );
 	}
 
 	@Test
 	public void testReleaseCircumventedManually() {
-		Session session = openSession();
-		SessionImplementor sessionImpl = (SessionImplementor) session;
-		
-		LogicalConnectionImpl logicalConnection = new LogicalConnectionImpl( null,
-				ConnectionReleaseMode.AFTER_STATEMENT, services, new JdbcConnectionAccessImpl(
-						services.getConnectionProvider() ) );
-		JdbcCoordinatorImpl jdbcCoord = new JdbcCoordinatorImpl( logicalConnection,
-				sessionImpl.getTransactionCoordinator() );
-		JournalingConnectionObserver observer = new JournalingConnectionObserver();
-		logicalConnection.addObserver( observer );
-
-		try {
-			PreparedStatement ps = jdbcCoord.getStatementPreparer().prepareStatement( "insert into SANDBOX_JDBC_TST( ID, NAME ) values ( ?, ? )" );
-			ps.setLong( 1, 1 );
-			ps.setString( 2, "name" );
-			jdbcCoord.getResultSetReturn().execute( ps );
-			assertTrue( jdbcCoord.hasRegisteredResources() );
-			assertEquals( 1, observer.getPhysicalConnectionObtainedCount() );
-			assertEquals( 0, observer.getPhysicalConnectionReleasedCount() );
-			jdbcCoord.release( ps );
-			assertFalse( jdbcCoord.hasRegisteredResources() );
-			assertEquals( 1, observer.getPhysicalConnectionObtainedCount() );
-			assertEquals( 1, observer.getPhysicalConnectionReleasedCount() );
-	
-			// disable releases...
-			jdbcCoord.disableReleases();
-	
-			// open a result set...
-			ps = jdbcCoord.getStatementPreparer().prepareStatement( "select * from SANDBOX_JDBC_TST" );
-			jdbcCoord.getResultSetReturn().extract( ps );
-			assertTrue( jdbcCoord.hasRegisteredResources() );
-			assertEquals( 2, observer.getPhysicalConnectionObtainedCount() );
-			assertEquals( 1, observer.getPhysicalConnectionReleasedCount() );
-			// and close it...
-			jdbcCoord.release( ps );
-			// the release should be circumvented...
-			assertFalse( jdbcCoord.hasRegisteredResources() );
-			assertEquals( 2, observer.getPhysicalConnectionObtainedCount() );
-			assertEquals( 1, observer.getPhysicalConnectionReleasedCount() );
-	
-			// let the close of the logical connection below release all resources (hopefully)...
-		}
-		catch ( SQLException sqle ) {
-			fail( "incorrect exception type : sqlexception" );
-		}
-		finally {
-			jdbcCoord.close();
-			session.close();
-		}
-
-		assertFalse( jdbcCoord.hasRegisteredResources() );
-		assertEquals( 2, observer.getPhysicalConnectionObtainedCount() );
-		assertEquals( 2, observer.getPhysicalConnectionReleasedCount() );
+//		Session session = openSession();
+//		SessionImplementor sessionImpl = (SessionImplementor) session;
+//
+//		LogicalConnectionImpl logicalConnection = new LogicalConnectionImpl( null,
+//				ConnectionReleaseMode.AFTER_STATEMENT, services, new JdbcConnectionAccessImpl(
+//						services.getConnectionProvider() ) );
+//		JdbcCoordinatorImpl jdbcCoord = new JdbcCoordinatorImpl( logicalConnection,
+//				sessionImpl.getTransactionCoordinator() );
+//		JournalingConnectionObserver observer = new JournalingConnectionObserver();
+//		logicalConnection.addObserver( observer );
+//
+//		try {
+//			PreparedStatement ps = jdbcCoord.getStatementPreparer().prepareStatement( "insert into SANDBOX_JDBC_TST( ID, NAME ) values ( ?, ? )" );
+//			ps.setLong( 1, 1 );
+//			ps.setString( 2, "name" );
+//			jdbcCoord.getResultSetReturn().execute( ps );
+//			assertTrue( jdbcCoord.hasRegisteredResources() );
+//			assertEquals( 1, observer.getPhysicalConnectionObtainedCount() );
+//			assertEquals( 0, observer.getPhysicalConnectionReleasedCount() );
+//			jdbcCoord.release( ps );
+//			assertFalse( jdbcCoord.hasRegisteredResources() );
+//			assertEquals( 1, observer.getPhysicalConnectionObtainedCount() );
+//			assertEquals( 1, observer.getPhysicalConnectionReleasedCount() );
+//
+//			// disable releases...
+//			jdbcCoord.disableReleases();
+//
+//			// open a result set...
+//			ps = jdbcCoord.getStatementPreparer().prepareStatement( "select * from SANDBOX_JDBC_TST" );
+//			jdbcCoord.getResultSetReturn().extract( ps );
+//			assertTrue( jdbcCoord.hasRegisteredResources() );
+//			assertEquals( 2, observer.getPhysicalConnectionObtainedCount() );
+//			assertEquals( 1, observer.getPhysicalConnectionReleasedCount() );
+//			// and close it...
+//			jdbcCoord.release( ps );
+//			// the release should be circumvented...
+//			assertFalse( jdbcCoord.hasRegisteredResources() );
+//			assertEquals( 2, observer.getPhysicalConnectionObtainedCount() );
+//			assertEquals( 1, observer.getPhysicalConnectionReleasedCount() );
+//
+//			// let the close of the logical connection below release all resources (hopefully)...
+//		}
+//		catch ( SQLException sqle ) {
+//			fail( "incorrect exception type : sqlexception" );
+//		}
+//		finally {
+//			jdbcCoord.close();
+//			session.close();
+//		}
+//
+//		assertFalse( jdbcCoord.hasRegisteredResources() );
+//		assertEquals( 2, observer.getPhysicalConnectionObtainedCount() );
+//		assertEquals( 2, observer.getPhysicalConnectionReleasedCount() );
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/jdbc/internal/BasicConnectionTest.java b/hibernate-core/src/test/java/org/hibernate/test/jdbc/internal/BasicConnectionTest.java
index 5c5befed5c..c9ba8b7990 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/jdbc/internal/BasicConnectionTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/jdbc/internal/BasicConnectionTest.java
@@ -1,110 +1,116 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.jdbc.internal;
 
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.sql.Statement;
 
 import org.hibernate.JDBCException;
 import org.hibernate.Session;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.engine.spi.SessionImplementor;
+import org.hibernate.resource.jdbc.ResourceRegistry;
+
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.junit.Test;
 
 /**
  * @author Steve Ebersole
  * @author Brett Meyer
  */
 public class BasicConnectionTest extends BaseCoreFunctionalTestCase {
 
 	@Test
 	public void testExceptionHandling() {
 		Session session = openSession();
 		SessionImplementor sessionImpl = (SessionImplementor) session;
 		boolean caught = false;
 		try {
-			PreparedStatement ps = sessionImpl.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer()
+			PreparedStatement ps = sessionImpl.getJdbcCoordinator().getStatementPreparer()
 					.prepareStatement( "select count(*) from NON_EXISTENT" );
-			sessionImpl.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().execute( ps );
+			sessionImpl.getJdbcCoordinator().getResultSetReturn().execute( ps );
 		}
 		catch ( JDBCException ok ) {
 			caught = true;
 		}
 		finally {
 			session.close();
 		}
 
 		assertTrue( "The connection did not throw a JDBCException as expected", caught );
 	}
 
 	@Test
 	public void testBasicJdbcUsage() throws JDBCException {
 		Session session = openSession();
 		SessionImplementor sessionImpl = (SessionImplementor) session;
-		JdbcCoordinator jdbcCoord = sessionImpl.getTransactionCoordinator().getJdbcCoordinator();
+		JdbcCoordinator jdbcCoord = sessionImpl.getJdbcCoordinator();
 
 		try {
 			Statement statement = jdbcCoord.getStatementPreparer().createStatement();
 			String dropSql = getDialect().getDropTableString( "SANDBOX_JDBC_TST" );
 			try {
 				jdbcCoord.getResultSetReturn().execute( statement, dropSql );
 			}
 			catch ( Exception e ) {
 				// ignore if the DB doesn't support "if exists" and the table doesn't exist
 			}
 			jdbcCoord.getResultSetReturn().execute( statement,
 					"create table SANDBOX_JDBC_TST ( ID integer, NAME varchar(100) )" );
-			assertTrue( jdbcCoord.hasRegisteredResources() );
+			assertTrue( getResourceRegistry( jdbcCoord ).hasRegisteredResources() );
 			assertTrue( jdbcCoord.getLogicalConnection().isPhysicallyConnected() );
-			jdbcCoord.release( statement );
-			assertFalse( jdbcCoord.hasRegisteredResources() );
+			getResourceRegistry( jdbcCoord ).release( statement );
+			assertFalse( getResourceRegistry( jdbcCoord ).hasRegisteredResources() );
 			assertTrue( jdbcCoord.getLogicalConnection().isPhysicallyConnected() ); // after_transaction specified
 
 			PreparedStatement ps = jdbcCoord.getStatementPreparer().prepareStatement(
 					"insert into SANDBOX_JDBC_TST( ID, NAME ) values ( ?, ? )" );
 			ps.setLong( 1, 1 );
 			ps.setString( 2, "name" );
 			jdbcCoord.getResultSetReturn().execute( ps );
 
 			ps = jdbcCoord.getStatementPreparer().prepareStatement( "select * from SANDBOX_JDBC_TST" );
 			jdbcCoord.getResultSetReturn().extract( ps );
 
-			assertTrue( jdbcCoord.hasRegisteredResources() );
+			assertTrue( getResourceRegistry( jdbcCoord ).hasRegisteredResources() );
 		}
 		catch ( SQLException e ) {
 			fail( "incorrect exception type : sqlexception" );
 		}
 		finally {
 			session.close();
 		}
 
-		assertFalse( jdbcCoord.hasRegisteredResources() );
+		assertFalse( getResourceRegistry( jdbcCoord ).hasRegisteredResources() );
+	}
+
+	private ResourceRegistry getResourceRegistry(JdbcCoordinator jdbcCoord) {
+		return jdbcCoord.getResourceRegistry();
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/jdbc/internal/BatchingTest.java b/hibernate-core/src/test/java/org/hibernate/test/jdbc/internal/BatchingTest.java
index 67e7507f24..f599910d94 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/jdbc/internal/BatchingTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/jdbc/internal/BatchingTest.java
@@ -1,208 +1,199 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.jdbc.internal;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertSame;
 import static org.junit.Assert.assertTrue;
 
 import java.sql.PreparedStatement;
 import java.sql.Statement;
 
 import org.hibernate.Session;
+import org.hibernate.Transaction;
 import org.hibernate.engine.jdbc.batch.internal.BasicBatchKey;
 import org.hibernate.engine.jdbc.batch.internal.BatchBuilderImpl;
 import org.hibernate.engine.jdbc.batch.internal.BatchingBatch;
 import org.hibernate.engine.jdbc.batch.internal.NonBatchingBatch;
 import org.hibernate.engine.jdbc.batch.spi.Batch;
 import org.hibernate.engine.jdbc.batch.spi.BatchBuilder;
 import org.hibernate.engine.jdbc.batch.spi.BatchKey;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
-import org.hibernate.engine.jdbc.spi.LogicalConnectionImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
-import org.hibernate.engine.transaction.spi.TransactionImplementor;
 import org.hibernate.jdbc.Expectation;
 import org.hibernate.jdbc.Expectations;
+import org.hibernate.resource.jdbc.spi.LogicalConnectionImplementor;
+import org.hibernate.resource.transaction.TransactionCoordinator;
+
 import org.hibernate.test.common.JournalingBatchObserver;
 import org.hibernate.test.common.JournalingTransactionObserver;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.junit.Test;
 
 /**
  * @author Steve Ebersole
  * @author Brett Meyer
  */
 public class BatchingTest extends BaseCoreFunctionalTestCase implements BatchKey {
 	@Override
 	public int getBatchedStatementCount() {
 		return 1;
 	}
 
 	@Override
 	public Expectation getExpectation() {
 		return Expectations.BASIC;
 	}
 
 	@Test
 	public void testNonBatchingUsage() throws Exception {
 		Session session = openSession();
 		SessionImplementor sessionImpl = (SessionImplementor) session;
 		
-		TransactionCoordinator transactionCoordinator = sessionImpl.getTransactionCoordinator();
-		JournalingTransactionObserver observer = new JournalingTransactionObserver();
-		transactionCoordinator.addObserver( observer );
-
-		final JdbcCoordinator jdbcCoordinator = transactionCoordinator.getJdbcCoordinator();
+		final JdbcCoordinator jdbcCoordinator = sessionImpl.getJdbcCoordinator();
 		LogicalConnectionImplementor logicalConnection = jdbcCoordinator.getLogicalConnection();
 
 		// set up some tables to use
 		Statement statement = jdbcCoordinator.getStatementPreparer().createStatement();
 		String dropSql = getDialect().getDropTableString( "SANDBOX_JDBC_TST" );
 		try {
 			jdbcCoordinator.getResultSetReturn().execute( statement, dropSql );
 		}
 		catch ( Exception e ) {
 			// ignore if the DB doesn't support "if exists" and the table doesn't exist
 		}
 		jdbcCoordinator.getResultSetReturn().execute( statement, "create table SANDBOX_JDBC_TST ( ID integer, NAME varchar(100) )" );
-		assertTrue( jdbcCoordinator.hasRegisteredResources() );
+		assertTrue( jdbcCoordinator.getResourceRegistry().hasRegisteredResources() );
 		assertTrue( logicalConnection.isPhysicallyConnected() );
-		jdbcCoordinator.release( statement );
-		assertFalse( jdbcCoordinator.hasRegisteredResources() );
+		jdbcCoordinator.getResourceRegistry().release( statement );
+		assertFalse( jdbcCoordinator.getResourceRegistry().hasRegisteredResources() );
 		assertTrue( logicalConnection.isPhysicallyConnected() ); // after_transaction specified
 
 		// ok, now we can get down to it...
-		TransactionImplementor txn = transactionCoordinator.getTransaction();  // same as Session#getTransaction
+		Transaction txn = session.getTransaction();  // same as Session#getTransaction
 		txn.begin();
-		assertEquals( 1, observer.getBegins() );
 
 		final String insertSql = "insert into SANDBOX_JDBC_TST( ID, NAME ) values ( ?, ? )";
 
 		final BatchBuilder batchBuilder = new BatchBuilderImpl( -1 );
 		final BatchKey batchKey = new BasicBatchKey( "this", Expectations.BASIC );
 		final Batch insertBatch = batchBuilder.buildBatch( batchKey, jdbcCoordinator );
 
 		final JournalingBatchObserver batchObserver = new JournalingBatchObserver();
 		insertBatch.addObserver( batchObserver );
 
 		assertTrue( "unexpected Batch impl", NonBatchingBatch.class.isInstance( insertBatch ) );
 		PreparedStatement insert = insertBatch.getBatchStatement( insertSql, false );
 		insert.setLong( 1, 1 );
 		insert.setString( 2, "name" );
 		assertEquals( 0, batchObserver.getExplicitExecutionCount() );
 		assertEquals( 0, batchObserver.getImplicitExecutionCount() );
 		insertBatch.addToBatch();
 		assertEquals( 0, batchObserver.getExplicitExecutionCount() );
 		assertEquals( 1, batchObserver.getImplicitExecutionCount() );
-		assertFalse( jdbcCoordinator.hasRegisteredResources() );
+		assertFalse( jdbcCoordinator.getResourceRegistry().hasRegisteredResources() );
 
 		insertBatch.execute();
 		assertEquals( 1, batchObserver.getExplicitExecutionCount() );
 		assertEquals( 1, batchObserver.getImplicitExecutionCount() );
-		assertFalse( jdbcCoordinator.hasRegisteredResources() );
+		assertFalse( jdbcCoordinator.getResourceRegistry().hasRegisteredResources() );
 
 		insertBatch.release();
 
 		txn.commit();
 		session.close();
 	}
 
 	@Test
 	public void testBatchingUsage() throws Exception {
 		Session session = openSession();
 		SessionImplementor sessionImpl = (SessionImplementor) session;
 		
-		TransactionCoordinator transactionCoordinator = sessionImpl.getTransactionCoordinator();
-		JournalingTransactionObserver observer = new JournalingTransactionObserver();
-		transactionCoordinator.addObserver( observer );
-
-		final JdbcCoordinator jdbcCoordinator = transactionCoordinator.getJdbcCoordinator();
+		final JdbcCoordinator jdbcCoordinator = sessionImpl.getJdbcCoordinator();
 		LogicalConnectionImplementor logicalConnection = jdbcCoordinator.getLogicalConnection();
 
 		// set up some tables to use
 		Statement statement = jdbcCoordinator.getStatementPreparer().createStatement();
 		String dropSql = getDialect().getDropTableString( "SANDBOX_JDBC_TST" );
 		try {
 			jdbcCoordinator.getResultSetReturn().execute( statement, dropSql );
 		}
 		catch ( Exception e ) {
 			// ignore if the DB doesn't support "if exists" and the table doesn't exist
 		}		jdbcCoordinator.getResultSetReturn().execute( statement, "create table SANDBOX_JDBC_TST ( ID integer, NAME varchar(100) )" );
-		assertTrue( jdbcCoordinator.hasRegisteredResources() );
+		assertTrue( jdbcCoordinator.getResourceRegistry().hasRegisteredResources() );
 		assertTrue( logicalConnection.isPhysicallyConnected() );
-		jdbcCoordinator.release( statement );
-		assertFalse( jdbcCoordinator.hasRegisteredResources() );
+		jdbcCoordinator.getResourceRegistry().release( statement );
+		assertFalse( jdbcCoordinator.getResourceRegistry().hasRegisteredResources() );
 		assertTrue( logicalConnection.isPhysicallyConnected() ); // after_transaction specified
 
 		// ok, now we can get down to it...
-		TransactionImplementor txn = transactionCoordinator.getTransaction();  // same as Session#getTransaction
+		Transaction txn = session.getTransaction();  // same as Session#getTransaction
 		txn.begin();
-		assertEquals( 1, observer.getBegins() );
 
 		final BatchBuilder batchBuilder = new BatchBuilderImpl( 2 );
 		final BatchKey batchKey = new BasicBatchKey( "this", Expectations.BASIC );
 		final Batch insertBatch = batchBuilder.buildBatch( batchKey, jdbcCoordinator );
 		assertTrue( "unexpected Batch impl", BatchingBatch.class.isInstance( insertBatch ) );
 
 		final JournalingBatchObserver batchObserver = new JournalingBatchObserver();
 		insertBatch.addObserver( batchObserver );
 
 		final String insertSql = "insert into SANDBOX_JDBC_TST( ID, NAME ) values ( ?, ? )";
 
 		PreparedStatement insert = insertBatch.getBatchStatement( insertSql, false );
 		insert.setLong( 1, 1 );
 		insert.setString( 2, "name" );
 		assertEquals( 0, batchObserver.getExplicitExecutionCount() );
 		assertEquals( 0, batchObserver.getImplicitExecutionCount() );
 		insertBatch.addToBatch();
 		assertEquals( 0, batchObserver.getExplicitExecutionCount() );
 		assertEquals( 0, batchObserver.getImplicitExecutionCount() );
-		assertTrue( jdbcCoordinator.hasRegisteredResources() );
+		assertTrue( jdbcCoordinator.getResourceRegistry().hasRegisteredResources() );
 
 		PreparedStatement insert2 = insertBatch.getBatchStatement( insertSql, false );
 		assertSame( insert, insert2 );
 		insert = insert2;
 		insert.setLong( 1, 2 );
 		insert.setString( 2, "another name" );
 		assertEquals( 0, batchObserver.getExplicitExecutionCount() );
 		assertEquals( 0, batchObserver.getImplicitExecutionCount() );
 		insertBatch.addToBatch();
 		assertEquals( 0, batchObserver.getExplicitExecutionCount() );
 		assertEquals( 1, batchObserver.getImplicitExecutionCount() );
-		assertTrue( jdbcCoordinator.hasRegisteredResources() );
+		assertTrue( jdbcCoordinator.getResourceRegistry().hasRegisteredResources() );
 
 		insertBatch.execute();
 		assertEquals( 1, batchObserver.getExplicitExecutionCount() );
 		assertEquals( 1, batchObserver.getImplicitExecutionCount() );
-		assertFalse( jdbcCoordinator.hasRegisteredResources() );
+		assertFalse( jdbcCoordinator.getResourceRegistry().hasRegisteredResources() );
 
 		insertBatch.release();
 
 		txn.commit();
 		session.close();
 	}
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/jpa/cascade/CascadeTest.java b/hibernate-core/src/test/java/org/hibernate/test/jpa/cascade/CascadeTest.java
index ec2ee950ea..92ec49ff25 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/jpa/cascade/CascadeTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/jpa/cascade/CascadeTest.java
@@ -1,330 +1,332 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.jpa.cascade;
 
 import org.jboss.logging.Logger;
 import org.junit.Test;
 
 import org.hibernate.Session;
+import org.hibernate.TransactionException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.test.jpa.AbstractJPATest;
 
+import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * According to the JPA spec, persist()ing an entity should throw an exception
  * when said entity contains a reference to a transient entity through a mapped
  * association where that association is not marked for cascading the persist
  * operation.
  * <p/>
  * This test-case tests that requirement in the various association style
  * scenarios such as many-to-one, one-to-one, many-to-one (property-ref),
  * one-to-one (property-ref).  Additionally, it performs each of these tests
  * in both generated and assigned identifier usages...
  *
  * @author Steve Ebersole
  */
 public class CascadeTest extends AbstractJPATest {
 	private static final Logger log = Logger.getLogger( CascadeTest.class );
 
 	public String[] getMappings() {
 		return new String[] { "jpa/cascade/ParentChild.hbm.xml" };
 	}
 
 	@Test
 	public void testManyToOneGeneratedIdsOnSave() {
 		// NOTES: Child defines a many-to-one back to its Parent.  This
 		// association does not define persist cascading (which is natural;
 		// a child should not be able to create its parent).
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			Parent p = new Parent( "parent" );
 			Child c = new Child( "child" );
 			c.setParent( p );
 			s.save( c );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
-			catch( TransientObjectException e ) {
-				// expected result
-				log.trace( "handled expected exception", e );
+			catch (TransactionException te) {
+				assertTrue( te.getCause() instanceof TransientObjectException );
+				log.trace( "handled expected exception", te );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 	public void testManyToOneGeneratedIds() {
 		// NOTES: Child defines a many-to-one back to its Parent.  This
 		// association does not define persist cascading (which is natural;
 		// a child should not be able to create its parent).
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			Parent p = new Parent( "parent" );
 			Child c = new Child( "child" );
 			c.setParent( p );
 			s.persist( c );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
 			catch( TransientObjectException e ) {
 				// expected result
 				log.trace( "handled expected exception", e );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 	public void testManyToOneAssignedIds() {
 		// NOTES: Child defines a many-to-one back to its Parent.  This
 		// association does not define persist cascading (which is natural;
 		// a child should not be able to create its parent).
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			ParentAssigned p = new ParentAssigned( new Long( 1 ), "parent" );
 			ChildAssigned c = new ChildAssigned( new Long( 2 ), "child" );
 			c.setParent( p );
 			s.persist( c );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
 			catch( TransientObjectException e ) {
 				// expected result
 				log.trace( "handled expected exception", e );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 	public void testOneToOneGeneratedIds() {
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			Parent p = new Parent( "parent" );
 			ParentInfo info = new ParentInfo( "xyz" );
 			p.setInfo( info );
 			info.setOwner( p );
 			s.persist( p );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
 			catch( TransientObjectException e ) {
 				// expected result
 				log.trace( "handled expected exception", e );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 	public void testOneToOneAssignedIds() {
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			ParentAssigned p = new ParentAssigned( new Long( 1 ), "parent" );
 			ParentInfoAssigned info = new ParentInfoAssigned( "something secret" );
 			p.setInfo( info );
 			info.setOwner( p );
 			s.persist( p );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
 			catch( TransientObjectException e ) {
 				// expected result
 				log.trace( "handled expected exception", e );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 	public void testManyToOnePropertyRefGeneratedIds() {
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			Parent p = new Parent( "parent" );
 			Other other = new Other();
 			other.setOwner( p );
 			s.persist( other );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
 			catch( TransientObjectException e ) {
 				// expected result
 				log.trace( "handled expected exception", e );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 	public void testManyToOnePropertyRefAssignedIds() {
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			ParentAssigned p = new ParentAssigned( new Long( 1 ), "parent" );
 			OtherAssigned other = new OtherAssigned( new Long( 2 ) );
 			other.setOwner( p );
 			s.persist( other );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
 			catch( TransientObjectException e ) {
 				// expected result
 				log.trace( "handled expected exception", e );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 	public void testOneToOnePropertyRefGeneratedIds() {
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			Child c2 = new Child( "c2" );
 			ChildInfo info = new ChildInfo( "blah blah blah" );
 			c2.setInfo( info );
 			info.setOwner( c2 );
 			s.persist( c2 );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
 			catch( TransientObjectException e ) {
 				// expected result
 				log.trace( "handled expected exception : " + e );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 	public void testOneToOnePropertyRefAssignedIds() {
 		try {
 			Session s = openSession();
 			s.beginTransaction();
 			ChildAssigned c2 = new ChildAssigned( new Long( 3 ), "c3" );
 			ChildInfoAssigned info = new ChildInfoAssigned( new Long( 4 ), "blah blah blah" );
 			c2.setInfo( info );
 			info.setOwner( c2 );
 			s.persist( c2 );
 			try {
 				s.getTransaction().commit();
 				fail( "expecting TransientObjectException on flush" );
 			}
 			catch( TransientObjectException e ) {
 				// expected result
 				log.trace( "handled expected exception : " + e );
 				s.getTransaction().rollback();
 			}
 			finally {
 				s.close();
 			}
 		}
 		finally {
 			cleanupData();
 		}
 	}
 
 
 	private void cleanupData() {
 		Session s = null;
 		try {
 			s = openSession();
 			s.beginTransaction();
 			s.createQuery( "delete ChildInfoAssigned" ).executeUpdate();
 			s.createQuery( "delete ChildAssigned" ).executeUpdate();
 			s.createQuery( "delete ParentAssigned" ).executeUpdate();
 			s.createQuery( "delete ChildInfoAssigned" ).executeUpdate();
 			s.createQuery( "delete ChildAssigned" ).executeUpdate();
 			s.createQuery( "delete ParentAssigned" ).executeUpdate();
 			s.getTransaction().commit();
 		}
 		catch( Throwable t ) {
 			log.warn( "unable to cleanup test data : " + t );
 		}
 		finally {
 			if ( s != null ) {
 				try {
 					s.close();
 				}
 				catch( Throwable ignore ) {
 				}
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/jpa/txn/TransactionJoiningTest.java b/hibernate-core/src/test/java/org/hibernate/test/jpa/txn/TransactionJoiningTest.java
index db6bb0675b..a71a20d9ae 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/jpa/txn/TransactionJoiningTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/jpa/txn/TransactionJoiningTest.java
@@ -1,125 +1,140 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.jpa.txn;
 
-import org.junit.Test;
-
 import org.hibernate.Session;
+import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Configuration;
-import org.hibernate.cfg.Environment;
 import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.engine.transaction.internal.jta.CMTTransactionFactory;
 import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
-import org.hibernate.engine.transaction.spi.TransactionImplementor;
-import org.hibernate.test.jpa.AbstractJPATest;
+import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorBuilderImpl;
+import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorImpl;
+
+import org.junit.Test;
+
 import org.hibernate.testing.jta.TestingJtaBootstrap;
 import org.hibernate.testing.jta.TestingJtaPlatformImpl;
+import org.hibernate.testing.junit4.ExtraAssertions;
+import org.hibernate.test.jpa.AbstractJPATest;
 
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 
 /**
  * @author Steve Ebersole
  */
 public class TransactionJoiningTest extends AbstractJPATest {
 	@Override
 	public void configure(Configuration cfg) {
 		super.configure( cfg );
 		TestingJtaBootstrap.prepare( cfg.getProperties() );
-		cfg.setProperty( Environment.TRANSACTION_STRATEGY, CMTTransactionFactory.class.getName() );
+		cfg.setProperty(
+				AvailableSettings.TRANSACTION_COORDINATOR_STRATEGY,
+				JtaTransactionCoordinatorBuilderImpl.class.getName()
+		);
 	}
 
 	@Test
 	public void testExplicitJoining() throws Exception {
 		assertFalse( JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
 
-		SessionImplementor session = (SessionImplementor) sessionFactory().withOptions().autoJoinTransactions( false ).openSession();
-		TransactionImplementor transaction = (TransactionImplementor) ( (Session) session ).getTransaction();
+		SessionImplementor session = (SessionImplementor) sessionFactory().withOptions()
+				.autoJoinTransactions( false )
+				.openSession();
+
+		ExtraAssertions.assertTyping( JtaTransactionCoordinatorImpl.class, session.getTransactionCoordinator() );
+		JtaTransactionCoordinatorImpl transactionCoordinator = (JtaTransactionCoordinatorImpl) session.getTransactionCoordinator();
 
-		assertFalse( session.getTransactionCoordinator().isSynchronizationRegistered() );
-		assertFalse( transaction.isParticipating() );
+		assertFalse( transactionCoordinator.isSynchronizationRegistered() );
+		assertFalse( transactionCoordinator.isActive() );
+		assertFalse( transactionCoordinator.isJoined() );
 
 		session.getFlushMode();  // causes a call to TransactionCoordinator#pulse
 
-		assertFalse( session.getTransactionCoordinator().isSynchronizationRegistered() );
-		assertFalse( transaction.isParticipating() );
+		assertFalse( transactionCoordinator.isSynchronizationRegistered() );
+		assertFalse( transactionCoordinator.isActive() );
+		assertFalse( transactionCoordinator.isJoined() );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 
 		assertTrue( JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
-		assertTrue( transaction.isActive() );
-		assertFalse( transaction.isParticipating() );
-		assertFalse( session.getTransactionCoordinator().isSynchronizationRegistered() );
+		assertTrue( transactionCoordinator.isActive() );
+		assertFalse( transactionCoordinator.isJoined() );
+		assertFalse( transactionCoordinator.isSynchronizationRegistered() );
 
 		session.getFlushMode();
 
 		assertTrue( JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
-		assertTrue( transaction.isActive() );
-		assertFalse( session.getTransactionCoordinator().isSynchronizationRegistered() );
-		assertFalse( transaction.isParticipating() );
+		assertTrue( transactionCoordinator.isActive() );
+		assertFalse( transactionCoordinator.isSynchronizationRegistered() );
+		assertFalse( transactionCoordinator.isJoined() );
 
-		transaction.markForJoin();
-		transaction.join();
+		transactionCoordinator.explicitJoin();
 		session.getFlushMode();
 
 		assertTrue( JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
-		assertTrue( transaction.isActive() );
-		assertTrue( session.getTransactionCoordinator().isSynchronizationRegistered() );
-		assertTrue( transaction.isParticipating() );
+		assertTrue( transactionCoordinator.isActive() );
+		assertTrue( transactionCoordinator.isSynchronizationRegistered() );
+		assertTrue( transactionCoordinator.isJoined() );
 
-		( (Session) session ).close();
+		((Session) session).close();
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 	}
 
 	@Test
 	public void testImplicitJoining() throws Exception {
 		assertFalse( JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		assertTrue( JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
 
-		SessionImplementor session = (SessionImplementor) sessionFactory().withOptions().autoJoinTransactions( false ).openSession();
+		SessionImplementor session = (SessionImplementor) sessionFactory().withOptions()
+				.autoJoinTransactions( false )
+				.openSession();
 
 		session.getFlushMode();
 	}
 
 	@Test
 	public void control() throws Exception {
 		assertFalse( JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		assertTrue( JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
 
 		SessionImplementor session = (SessionImplementor) sessionFactory().openSession();
-		TransactionImplementor transaction = (TransactionImplementor) ( (Session) session ).getTransaction();
+		ExtraAssertions.assertTyping( JtaTransactionCoordinatorImpl.class, session.getTransactionCoordinator() );
+		JtaTransactionCoordinatorImpl transactionCoordinator = (JtaTransactionCoordinatorImpl) session.getTransactionCoordinator();
 
-		assertTrue( session.getTransactionCoordinator().isSynchronizationRegistered() );
-		assertTrue( transaction.isParticipating() );
+		assertTrue( transactionCoordinator.isSynchronizationRegistered() );
+		assertTrue( transactionCoordinator.isActive() );
+		assertTrue( transactionCoordinator.isJoined() );
 
 		( (Session) session ).close();
 
-		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();	}
+		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
+	}
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/lazyload/JtaLazyLoadingTest.java b/hibernate-core/src/test/java/org/hibernate/test/lazyload/JtaLazyLoadingTest.java
index 06755ce935..964ca42ae1 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/lazyload/JtaLazyLoadingTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/lazyload/JtaLazyLoadingTest.java
@@ -1,123 +1,119 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2014, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.lazyload;
 
-import java.util.ArrayList;
-import java.util.List;
-
 import org.hibernate.Hibernate;
 import org.hibernate.Session;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
-import org.hibernate.engine.transaction.internal.jta.JtaTransactionFactory;
 
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.jta.TestingJtaBootstrap;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
 
 /**
  * @author Oleksander Dukhno
  */
 public class JtaLazyLoadingTest
 		extends BaseCoreFunctionalTestCase {
 
 	private static final int CHILDREN_SIZE = 3;
 	private Long parentID;
 	private Long lastChildID;
 
 	protected void configure(Configuration cfg) {
 		super.configure( cfg );
 		cfg.setProperty( Environment.ENABLE_LAZY_LOAD_NO_TRANS, "true" );
 
 		TestingJtaBootstrap.prepare( cfg.getProperties() );
-		cfg.setProperty( Environment.TRANSACTION_STRATEGY, JtaTransactionFactory.class.getName() );
+//		cfg.setProperty( Environment.TRANSACTION_STRATEGY, JtaTransactionFactory.class.getName() );
 	}
 
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class<?>[] {
 				Parent.class,
 				Child.class
 		};
 	}
 
 	protected void prepareTest()
 			throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 
 		Parent p = new Parent();
 		for ( int i = 0; i < CHILDREN_SIZE; i++ ) {
 			final Child child = p.makeChild();
 			s.persist( child );
 			lastChildID = child.getId();
 		}
 		s.persist( p );
 		parentID = p.getId();
 
 		s.getTransaction().commit();
 		s.clear();
 		s.close();
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-7971")
 	public void testLazyCollectionLoadingAfterEndTransaction() {
 		Session s = openSession();
 		s.beginTransaction();
 		Parent loadedParent = (Parent) s.load( Parent.class, parentID );
 		s.getTransaction().commit();
 		s.close();
 
 		assertFalse( Hibernate.isInitialized( loadedParent.getChildren() ) );
 
 		int i = 0;
 		for ( Child child : loadedParent.getChildren() ) {
 			i++;
 			assertNotNull( child );
 		}
 
 		assertEquals( CHILDREN_SIZE, i );
 
 		s = openSession();
 		s.beginTransaction();
 		Child loadedChild = (Child) s.load( Child.class, lastChildID );
 		s.getTransaction().commit();
 		s.close();
 
 		Parent p = loadedChild.getParent();
 		int j = 0;
 		for ( Child child : p.getChildren() ) {
 			j++;
 			assertNotNull( child );
 		}
 
 		assertEquals( CHILDREN_SIZE, j );
 	}
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java b/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java
index c49c2c1c52..42478f3af8 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/legacy/FooBarTest.java
@@ -1,1065 +1,1066 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2006-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.legacy;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertSame;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.sql.Time;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.Date;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Locale;
 import java.util.Set;
 import java.util.SortedSet;
 import java.util.TimeZone;
 import java.util.TreeMap;
 import java.util.TreeSet;
 
 import org.hibernate.Criteria;
 import org.hibernate.FetchMode;
 import org.hibernate.FlushMode;
 import org.hibernate.Hibernate;
 import org.hibernate.HibernateException;
 import org.hibernate.LazyInitializationException;
 import org.hibernate.LockMode;
 import org.hibernate.ObjectNotFoundException;
 import org.hibernate.Query;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
+import org.hibernate.TransactionException;
 import org.hibernate.action.spi.BeforeTransactionCompletionProcess;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.criterion.Example;
 import org.hibernate.criterion.MatchMode;
 import org.hibernate.criterion.Order;
 import org.hibernate.criterion.Restrictions;
 import org.hibernate.dialect.DB2Dialect;
 import org.hibernate.dialect.DerbyDialect;
 import org.hibernate.dialect.H2Dialect;
 import org.hibernate.dialect.AbstractHANADialect;
 import org.hibernate.dialect.HSQLDialect;
 import org.hibernate.dialect.InterbaseDialect;
 import org.hibernate.dialect.MckoiDialect;
 import org.hibernate.dialect.MySQLDialect;
 import org.hibernate.dialect.Oracle8iDialect;
 import org.hibernate.dialect.PointbaseDialect;
 import org.hibernate.dialect.PostgreSQL81Dialect;
 import org.hibernate.dialect.PostgreSQLDialect;
 import org.hibernate.dialect.SAPDBDialect;
 import org.hibernate.dialect.Sybase11Dialect;
 import org.hibernate.dialect.SybaseASE15Dialect;
 import org.hibernate.dialect.SybaseDialect;
 import org.hibernate.dialect.TeradataDialect;
 import org.hibernate.dialect.TimesTenDialect;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.internal.util.SerializationHelper;
 import org.hibernate.internal.util.collections.JoinedIterator;
 import org.hibernate.jdbc.AbstractReturningWork;
 import org.hibernate.jdbc.AbstractWork;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.testing.DialectChecks;
 import org.hibernate.testing.FailureExpected;
 import org.hibernate.testing.RequiresDialect;
 import org.hibernate.testing.RequiresDialectFeature;
 import org.hibernate.testing.SkipForDialect;
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.env.ConnectionProviderBuilder;
 import org.hibernate.type.StandardBasicTypes;
 import org.jboss.logging.Logger;
 import org.junit.Test;
 
 public class FooBarTest extends LegacyTestCase {
 	private static final Logger log = Logger.getLogger( FooBarTest.class );
 
 	@Override
 	public String[] getMappings() {
 		return new String[] {
 			"legacy/FooBar.hbm.xml",
 			"legacy/Baz.hbm.xml",
 			"legacy/Qux.hbm.xml",
 			"legacy/Glarch.hbm.xml",
 			"legacy/Fum.hbm.xml",
 			"legacy/Fumm.hbm.xml",
 			"legacy/Fo.hbm.xml",
 			"legacy/One.hbm.xml",
 			"legacy/Many.hbm.xml",
 			"legacy/Immutable.hbm.xml",
 			"legacy/Fee.hbm.xml",
 			"legacy/Vetoer.hbm.xml",
 			"legacy/Holder.hbm.xml",
 			"legacy/Location.hbm.xml",
 			"legacy/Stuff.hbm.xml",
 			"legacy/Container.hbm.xml",
 			"legacy/Simple.hbm.xml",
 			"legacy/XY.hbm.xml"
 		};
 	}
 
 	@Test
 	public void testSaveOrUpdateCopyAny() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Bar bar = new Bar();
 		One one = new One();
 		bar.setObject(one);
 		s.save(bar);
 		GlarchProxy g = bar.getComponent().getGlarch();
 		bar.getComponent().setGlarch(null);
 		s.delete(g);
 		s.flush();
 		assertTrue( s.contains(one) );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Bar bar2 = (Bar) s.merge( bar );
 		s.flush();
 		s.delete(bar2);
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testRefreshProxy() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Glarch g = new Glarch();
 		Serializable gid = s.save(g);
 		s.flush();
 		s.clear();
 		GlarchProxy gp = (GlarchProxy) s.load(Glarch.class, gid);
 		gp.getName(); //force init
 		s.refresh(gp);
 		s.delete(gp);
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@RequiresDialectFeature(
 			value = DialectChecks.SupportsCircularCascadeDeleteCheck.class,
 			comment = "db/dialect does not support circular cascade delete constraints"
 	)
 	public void testOnCascadeDelete() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.subs = new ArrayList();
 		Baz sub = new Baz();
 		sub.superBaz = baz;
 		baz.subs.add(sub);
 		s.save(baz);
 		s.flush();
 		assertTrue( s.createQuery("from Baz").list().size()==2 );
 		s.getTransaction().commit();
 		s.beginTransaction();
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.beginTransaction();
 		assertTrue( s.createQuery("from Baz").list().size()==0 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testRemoveFromIdbag() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setByteBag( new ArrayList() );
 		byte[] bytes = { 12, 13 };
 		baz.getByteBag().add( new byte[] { 10, 45 } );
 		baz.getByteBag().add(bytes);
 		baz.getByteBag().add( new byte[] { 1, 11 } );
 		baz.getByteBag().add( new byte[] { 12 } );
 		s.save(baz);
 		s.flush();
 		baz.getByteBag().remove(bytes);
 		s.flush();
 		baz.getByteBag().add(bytes);
 		s.flush();
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testLoad() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Qux q = new Qux();
 		s.save(q);
 		BarProxy b = new Bar();
 		s.save(b);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		q = (Qux) s.load(Qux.class, q.getKey() );
 		b = (BarProxy) s.load( Foo.class, b.getKey() );
 		b.getKey();
 		assertFalse( Hibernate.isInitialized(b) );
 		b.getBarString();
 		assertTrue( Hibernate.isInitialized(b) );
 		BarProxy b2 = (BarProxy) s.load( Bar.class, b.getKey() );
 		Qux q2 = (Qux) s.load( Qux.class, q.getKey() );
 		assertTrue( "loaded same object", q==q2 );
 		assertTrue( "loaded same object", b==b2 );
 		assertTrue( Math.round( b.getFormula() ) == b.getInt() / 2 );
 		s.delete(q2);
 		s.delete( b2 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testJoin() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		foo.setJoinedProp("foo");
 		s.save( foo );
 		s.flush();
 		foo.setJoinedProp("bar");
 		s.flush();
 		String fid = foo.getKey();
 		s.delete( foo );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Foo foo2 = new Foo();
 		foo2.setJoinedProp("foo");
 		s.save(foo2);
 		s.createQuery( "select foo.id from Foo foo where foo.joinedProp = 'foo'" ).list();
 		assertNull( s.get(Foo.class, fid) );
 		s.delete(foo2);
 		s.getTransaction().commit();
 		s.close();
 
 	}
 
 	@Test
 	public void testDereferenceLazyCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setFooSet( new HashSet() );
 		Foo foo = new Foo();
 		baz.getFooSet().add(foo);
 		s.save(foo);
 		s.save(baz);
 		foo.setBytes( "foobar".getBytes() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = (Foo) s.get( Foo.class, foo.getKey() );
 		assertTrue( Hibernate.isInitialized( foo.getBytes() ) );
 		assertTrue( foo.getBytes().length==6 );
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertTrue( baz.getFooSet().size()==1 );
 		s.getTransaction().commit();
 		s.close();
 
 		sessionFactory().evictCollection("org.hibernate.test.legacy.Baz.fooSet");
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertFalse( Hibernate.isInitialized( baz.getFooSet() ) );
 		baz.setFooSet(null);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = (Foo) s.get( Foo.class, foo.getKey() );
 		assertTrue( foo.getBytes().length==6 );
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertFalse( Hibernate.isInitialized( baz.getFooSet() ) );
 		assertTrue( baz.getFooSet().size()==0 );
 		s.delete(baz);
 		s.delete(foo);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testMoveLazyCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		Baz baz2 = new Baz();
 		baz.setFooSet( new HashSet() );
 		Foo foo = new Foo();
 		baz.getFooSet().add(foo);
 		s.save(foo);
 		s.save(baz);
 		s.save(baz2);
 		foo.setBytes( "foobar".getBytes() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = (Foo) s.get( Foo.class, foo.getKey() );
 		assertTrue( Hibernate.isInitialized( foo.getBytes() ) );
 		assertTrue( foo.getBytes().length==6 );
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertTrue( baz.getFooSet().size()==1 );
 		s.getTransaction().commit();
 		s.close();
 
 		sessionFactory().evictCollection("org.hibernate.test.legacy.Baz.fooSet");
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertFalse( Hibernate.isInitialized( baz.getFooSet() ) );
 		baz2 = (Baz) s.get( Baz.class, baz2.getCode() );
 		baz2.setFooSet( baz.getFooSet() );
 		baz.setFooSet(null);
 		assertFalse( Hibernate.isInitialized( baz2.getFooSet() ) );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = (Foo) s.get( Foo.class, foo.getKey() );
 		assertTrue( foo.getBytes().length==6 );
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		baz2 = (Baz) s.get( Baz.class, baz2.getCode() );
 		assertFalse( Hibernate.isInitialized( baz.getFooSet() ) );
 		assertTrue( baz.getFooSet().size()==0 );
 		assertTrue( Hibernate.isInitialized( baz2.getFooSet() ) ); //fooSet has batching enabled
 		assertTrue( baz2.getFooSet().size()==1 );
 		s.delete(baz);
 		s.delete(baz2);
 		s.delete(foo);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testCriteriaCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz bb = (Baz) s.createCriteria(Baz.class).uniqueResult();
 		assertTrue( bb == null );
 		Baz baz = new Baz();
 		s.save( baz );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Baz b = (Baz) s.createCriteria(Baz.class).uniqueResult();
 		assertTrue( Hibernate.isInitialized( b.getTopGlarchez() ) );
 		assertTrue( b.getTopGlarchez().size() == 0 );
 		s.delete( b );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testQuery() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		Foo foo2 = new Foo();
 		s.save(foo2);
 		foo.setFoo(foo2);
 
 		List list = s.createQuery( "from Foo foo inner join fetch foo.foo" ).list();
 		Foo foof = (Foo) list.get(0);
 		assertTrue( Hibernate.isInitialized( foof.getFoo() ) );
 
 		s.createQuery( "from Baz baz left outer join fetch baz.fooToGlarch" ).list();
 
 		list = s.createQuery( "select foo, bar from Foo foo left outer join foo.foo bar where foo = ?" )
 				.setParameter( 0, foo, s.getTypeHelper().entity(Foo.class) )
 				.list();
 		Object[] row1 = (Object[]) list.get(0);
 		assertTrue( row1[0]==foo && row1[1]==foo2 );
 
 		s.createQuery( "select foo.foo.foo.string from Foo foo where foo.foo = 'bar'" ).list();
 		s.createQuery( "select foo.foo.foo.foo.string from Foo foo where foo.foo = 'bar'" ).list();
 		s.createQuery( "select foo from Foo foo where foo.foo.foo = 'bar'" ).list();
 		s.createQuery( "select foo.foo.foo.foo.string from Foo foo where foo.foo.foo = 'bar'" ).list();
 		s.createQuery( "select foo.foo.foo.string from Foo foo where foo.foo.foo.foo.string = 'bar'" ).list();
 		if ( ! (getDialect() instanceof HSQLDialect) )
 			s.createQuery( "select foo.string from Foo foo where foo.foo.foo.foo = foo.foo.foo" ).list();
 		s.createQuery( "select foo.string from Foo foo where foo.foo.foo = 'bar' and foo.foo.foo.foo = 'baz'" ).list();
 		s.createQuery( "select foo.string from Foo foo where foo.foo.foo.foo.string = 'a' and foo.foo.string = 'b'" )
 				.list();
 
 		s.createQuery( "from Bar bar, foo in elements(bar.baz.fooArray)" ).list();
 
 		//s.find("from Baz as baz where baz.topComponents[baz].name = 'bazzz'");
 
 		if ( (getDialect() instanceof DB2Dialect) && !(getDialect() instanceof DerbyDialect) ) {
 			s.createQuery( "from Foo foo where lower( foo.foo.string ) = 'foo'" ).list();
 			s.createQuery( "from Foo foo where lower( (foo.foo.string || 'foo') || 'bar' ) = 'foo'" ).list();
 			s.createQuery( "from Foo foo where repeat( (foo.foo.string || 'foo') || 'bar', 2 ) = 'foo'" ).list();
 			s.createQuery(
 					"from Bar foo where foo.foo.integer is not null and repeat( (foo.foo.string || 'foo') || 'bar', (5+5)/2 ) = 'foo'"
 			).list();
 			s.createQuery(
 					"from Bar foo where foo.foo.integer is not null or repeat( (foo.foo.string || 'foo') || 'bar', (5+5)/2 ) = 'foo'"
 			).list();
 		}
 		if (getDialect() instanceof SybaseDialect) {
 			s.createQuery( "select baz from Baz as baz join baz.fooArray foo group by baz order by sum(foo.float)" )
 					.iterate();
 		}
 
 		s.createQuery( "from Foo as foo where foo.component.glarch.name is not null" ).list();
 		s.createQuery( "from Foo as foo left outer join foo.component.glarch as glarch where glarch.name = 'foo'" )
 				.list();
 
 		list = s.createQuery( "from Foo" ).list();
 		assertTrue( list.size()==2 && list.get(0) instanceof FooProxy );
 		list = s.createQuery( "from Foo foo left outer join foo.foo" ).list();
 		assertTrue( list.size()==2 && ( (Object[]) list.get(0) )[0] instanceof FooProxy );
 
 		s.createQuery("from Bar, Bar").list();
 		s.createQuery("from Foo, Bar").list();
 		s.createQuery( "from Baz baz left join baz.fooToGlarch, Bar bar join bar.foo" ).list();
 		s.createQuery( "from Baz baz left join baz.fooToGlarch join baz.fooSet" ).list();
 		s.createQuery( "from Baz baz left join baz.fooToGlarch join fetch baz.fooSet foo left join fetch foo.foo" )
 				.list();
 
 		list = s.createQuery(
 				"from Foo foo where foo.string='osama bin laden' and foo.boolean = true order by foo.string asc, foo.component.count desc"
 		).list();
 		assertTrue( "empty query", list.size()==0 );
 		Iterator iter = s.createQuery(
 				"from Foo foo where foo.string='osama bin laden' order by foo.string asc, foo.component.count desc"
 		).iterate();
 		assertTrue( "empty iterator", !iter.hasNext() );
 
 		list = s.createQuery( "select foo.foo from Foo foo" ).list();
 		assertTrue( "query", list.size()==1 );
 		assertTrue( "returned object", list.get(0)==foo.getFoo() );
 		foo.getFoo().setFoo(foo);
 		foo.setString("fizard");
 		//The following test is disabled for databases with no subselects...also for Interbase (not sure why).
 		if (
 				!(getDialect() instanceof MySQLDialect) &&
 				!(getDialect() instanceof HSQLDialect) &&
 				!(getDialect() instanceof MckoiDialect) &&
 				!(getDialect() instanceof SAPDBDialect) &&
 				!(getDialect() instanceof PointbaseDialect) &&
 				!(getDialect() instanceof DerbyDialect)
 		)  {
 			// && !db.equals("weblogic") {
 			if ( !( getDialect() instanceof InterbaseDialect ) ) {
 				list = s.createQuery( "from Foo foo where ? = some elements(foo.component.importantDates)" )
 						.setParameter( 0, new Date(), StandardBasicTypes.DATE )
 						.list();
 				assertTrue( "component query", list.size()==2 );
 			}
 			if( !( getDialect() instanceof TimesTenDialect)) {
 				list = s.createQuery( "from Foo foo where size(foo.component.importantDates) = 3" ).list(); //WAS: 4
 				assertTrue( "component query", list.size()==2 );
 				list = s.createQuery( "from Foo foo where 0 = size(foo.component.importantDates)" ).list();
 				assertTrue( "component query", list.size()==0 );
 			}
 			list = s.createQuery( "from Foo foo where exists elements(foo.component.importantDates)" ).list();
 			assertTrue( "component query", list.size()==2 );
 			s.createQuery( "from Foo foo where not exists (from Bar bar where bar.id = foo.id)" ).list();
 
 			s.createQuery(
 					"select foo.foo from Foo foo where foo = some(select x from Foo x where x.long > foo.foo.long)"
 			).list();
 			s.createQuery( "select foo.foo from Foo foo where foo = some(from Foo x where (x.long > foo.foo.long))" )
 					.list();
 			if ( !( getDialect() instanceof TimesTenDialect)) {
 				s.createQuery(
 						"select foo.foo from Foo foo where foo.long = some( select max(x.long) from Foo x where (x.long > foo.foo.long) group by x.foo )"
 				).list();
 			}
 			s.createQuery(
 					"from Foo foo where foo = some(select x from Foo x where x.long > foo.foo.long) and foo.foo.string='baz'"
 			).list();
 			s.createQuery(
 					"from Foo foo where foo.foo.string='baz' and foo = some(select x from Foo x where x.long > foo.foo.long)"
 			).list();
 			s.createQuery( "from Foo foo where foo = some(select x from Foo x where x.long > foo.foo.long)" ).list();
 
 			s.createQuery(
 					"select foo.string, foo.date, foo.foo.string, foo.id from Foo foo, Baz baz where foo in elements(baz.fooArray) and foo.string like 'foo'"
 			).iterate();
 		}
 		list = s.createQuery( "from Foo foo where foo.component.count is null order by foo.component.count" ).list();
 		assertTrue( "component query", list.size()==0 );
 		list = s.createQuery( "from Foo foo where foo.component.name='foo'" ).list();
 		assertTrue( "component query", list.size()==2 );
 		list = s.createQuery(
 				"select distinct foo.component.name, foo.component.name from Foo foo where foo.component.name='foo'"
 		).list();
 		assertTrue( "component query", list.size()==1 );
 		list = s.createQuery( "select distinct foo.component.name, foo.id from Foo foo where foo.component.name='foo'" )
 				.list();
 		assertTrue( "component query", list.size()==2 );
 		list = s.createQuery( "select foo.foo from Foo foo" ).list();
 		assertTrue( "query", list.size()==2 );
 		list = s.createQuery( "from Foo foo where foo.id=?" )
 				.setParameter( 0, foo.getKey(), StandardBasicTypes.STRING )
 				.list();
 		assertTrue( "id query", list.size()==1 );
 		list = s.createQuery( "from Foo foo where foo.key=?" )
 				.setParameter( 0, foo.getKey(), StandardBasicTypes.STRING )
 				.list();
 		assertTrue( "named id query", list.size()==1 );
 		assertTrue( "id query", list.get(0)==foo );
 		list = s.createQuery( "select foo.foo from Foo foo where foo.string='fizard'" ).list();
 		assertTrue( "query", list.size()==1 );
 		assertTrue( "returned object", list.get(0)==foo.getFoo() );
 		list = s.createQuery( "from Foo foo where foo.component.subcomponent.name='bar'" ).list();
 		assertTrue( "components of components", list.size()==2 );
 		list = s.createQuery( "select foo.foo from Foo foo where foo.foo.id=?" )
 				.setParameter( 0, foo.getFoo().getKey(), StandardBasicTypes.STRING )
 				.list();
 		assertTrue( "by id query", list.size()==1 );
 		assertTrue( "by id returned object", list.get(0)==foo.getFoo() );
 
 		s.createQuery( "from Foo foo where foo.foo = ?" ).setParameter( 0, foo.getFoo(), s.getTypeHelper().entity(Foo.class) ).list();
 
 		assertTrue( !s.createQuery( "from Bar bar where bar.string='a string' or bar.string='a string'" )
 				.iterate()
 				.hasNext() );
 
 		iter = s.createQuery( "select foo.component.name, elements(foo.component.importantDates) from Foo foo where foo.foo.id=?" )
 				.setParameter( 0, foo.getFoo().getKey(), StandardBasicTypes.STRING )
 				.iterate();
 		int i=0;
 		while ( iter.hasNext() ) {
 			i++;
 			Object[] row = (Object[]) iter.next();
 			assertTrue( row[0] instanceof String && ( row[1]==null || row[1] instanceof Date ) );
 		}
 		assertTrue(i==3); //WAS: 4
 		iter = s.createQuery( "select max( elements(foo.component.importantDates) ) from Foo foo group by foo.id" )
 				.iterate();
 		assertTrue( iter.next() instanceof Date );
 
 		list = s.createQuery(
 				"select foo.foo.foo.foo from Foo foo, Foo foo2 where"
 						+ " foo = foo2.foo and not not ( not foo.string='fizard' )"
 						+ " and foo2.string between 'a' and (foo.foo.string)"
 						+ ( ( getDialect() instanceof HSQLDialect || getDialect() instanceof InterbaseDialect || getDialect() instanceof TimesTenDialect || getDialect() instanceof TeradataDialect) ?
 						" and ( foo2.string in ( 'fiz', 'blah') or 1=1 )"
 						:
 						" and ( foo2.string in ( 'fiz', 'blah', foo.foo.string, foo.string, foo2.string ) )"
 				)
 		).list();
 		assertTrue( "complex query", list.size()==1 );
 		assertTrue( "returned object", list.get(0)==foo );
 		foo.setString("from BoogieDown  -tinsel town  =!@#$^&*())");
 		list = s.createQuery( "from Foo foo where foo.string='from BoogieDown  -tinsel town  =!@#$^&*())'" ).list();
 		assertTrue( "single quotes", list.size()==1 );
 		list = s.createQuery( "from Foo foo where not foo.string='foo''bar'" ).list();
 		assertTrue( "single quotes", list.size()==2 );
 		list = s.createQuery( "from Foo foo where foo.component.glarch.next is null" ).list();
 		assertTrue( "query association in component", list.size()==2 );
 		Bar bar = new Bar();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		bar.setBaz(baz);
 		baz.setManyToAny( new ArrayList() );
 		baz.getManyToAny().add(bar);
 		baz.getManyToAny().add(foo);
 		s.save(bar);
 		s.save(baz);
 		list = s.createQuery(
 				" from Bar bar where bar.baz.count=667 and bar.baz.count!=123 and not bar.baz.name='1-E-1'"
 		).list();
 		assertTrue( "query many-to-one", list.size()==1 );
 		list = s.createQuery( " from Bar i where i.baz.name='Bazza'" ).list();
 		assertTrue( "query many-to-one", list.size()==1 );
 
 		Iterator rs = s.createQuery( "select count(distinct foo.foo) from Foo foo" ).iterate();
 		assertTrue( "count", ( (Long) rs.next() ).longValue()==2 );
 		assertTrue( !rs.hasNext() );
 		rs = s.createQuery( "select count(foo.foo.boolean) from Foo foo" ).iterate();
 		assertTrue( "count", ( (Long) rs.next() ).longValue()==2 );
 		assertTrue( !rs.hasNext() );
 		rs = s.createQuery( "select count(*), foo.int from Foo foo group by foo.int" ).iterate();
 		assertTrue( "count(*) group by", ( (Object[]) rs.next() )[0].equals( new Long(3) ) );
 		assertTrue( !rs.hasNext() );
 		rs = s.createQuery( "select sum(foo.foo.int) from Foo foo" ).iterate();
 		assertTrue( "sum", ( (Long) rs.next() ).longValue()==4 );
 		assertTrue( !rs.hasNext() );
 		rs = s.createQuery( "select count(foo) from Foo foo where foo.id=?" )
 				.setParameter( 0, foo.getKey(), StandardBasicTypes.STRING )
 				.iterate();
 		assertTrue( "id query count", ( (Long) rs.next() ).longValue()==1 );
 		assertTrue( !rs.hasNext() );
 
 		s.createQuery( "from Foo foo where foo.boolean = ?" )
 				.setParameter( 0, new Boolean(true), StandardBasicTypes.BOOLEAN )
 				.list();
 
 		s.createQuery( "select new Foo(fo.x) from Fo fo" ).list();
 		s.createQuery( "select new Foo(fo.integer) from Foo fo" ).list();
 
 		list = s.createQuery("select new Foo(fo.x) from Foo fo")
 			//.setComment("projection test")
 			.setCacheable(true)
 			.list();
 		assertTrue(list.size()==3);
 		list = s.createQuery("select new Foo(fo.x) from Foo fo")
 			//.setComment("projection test 2")
 			.setCacheable(true)
 			.list();
 		assertTrue(list.size()==3);
 
 		rs = s.createQuery( "select new Foo(fo.x) from Foo fo" ).iterate();
 		assertTrue( "projection iterate (results)", rs.hasNext() );
 		assertTrue( "projection iterate (return check)", Foo.class.isAssignableFrom( rs.next().getClass() ) );
 
 		ScrollableResults sr = s.createQuery("select new Foo(fo.x) from Foo fo").scroll();
 		assertTrue( "projection scroll (results)", sr.next() );
 		assertTrue( "projection scroll (return check)", Foo.class.isAssignableFrom( sr.get(0).getClass() ) );
 
 		list = s.createQuery( "select foo.long, foo.component.name, foo, foo.foo from Foo foo" ).list();
 		rs = list.iterator();
 		int count=0;
 		while ( rs.hasNext() ) {
 			count++;
 			Object[] row = (Object[]) rs.next();
 			assertTrue( row[0] instanceof Long );
 			assertTrue( row[1] instanceof String );
 			assertTrue( row[2] instanceof Foo );
 			assertTrue( row[3] instanceof Foo );
 		}
 		assertTrue(count!=0);
 		list = s.createQuery( "select avg(foo.float), max(foo.component.name), count(distinct foo.id) from Foo foo" )
 				.list();
 		rs = list.iterator();
 		count=0;
 		while ( rs.hasNext() ) {
 			count++;
 			Object[] row = (Object[]) rs.next();
 			assertTrue( row[0] instanceof Double );
 			assertTrue( row[1] instanceof String );
 			assertTrue( row[2] instanceof Long );
 		}
 		assertTrue(count!=0);
 		list = s.createQuery( "select foo.long, foo.component, foo, foo.foo from Foo foo" ).list();
 		rs = list.iterator();
 		count=0;
 		while ( rs.hasNext() ) {
 			count++;
 			Object[] row = (Object[]) rs.next();
 			assertTrue( row[0] instanceof Long );
 			assertTrue( row[1] instanceof FooComponent );
 			assertTrue( row[2] instanceof Foo );
 			assertTrue( row[3] instanceof Foo );
 		}
 		assertTrue(count!=0);
 
 		s.save( new Holder("ice T") );
 		s.save( new Holder("ice cube") );
 
 		assertTrue( s.createQuery( "from java.lang.Object as o" ).list().size()==15 );
 		assertTrue( s.createQuery( "from Named" ).list().size()==7 );
 		assertTrue( s.createQuery( "from Named n where n.name is not null" ).list().size()==4 );
 		iter = s.createQuery( "from Named n" ).iterate();
 		while ( iter.hasNext() ) {
 			assertTrue( iter.next() instanceof Named );
 		}
 
 		s.save( new Holder("bar") );
 		iter = s.createQuery( "from Named n0, Named n1 where n0.name = n1.name" ).iterate();
 		int cnt = 0;
 		while ( iter.hasNext() ) {
 			Object[] row = (Object[]) iter.next();
 			if ( row[0]!=row[1] ) cnt++;
 		}
 		if ( !(getDialect() instanceof HSQLDialect) ) {
 			assertTrue(cnt==2);
 			assertTrue( s.createQuery( "from Named n0, Named n1 where n0.name = n1.name" ).list().size()==7 );
 		}
 
 		Query qu = s.createQuery("from Named n where n.name = :name");
 		qu.getReturnTypes();
 		qu.getNamedParameters();
 
 		iter = s.createQuery( "from java.lang.Object" ).iterate();
 		int c = 0;
 		while ( iter.hasNext() ) {
 			iter.next();
 			c++;
 		}
 		assertTrue(c==16);
 
 		s.createQuery( "select baz.code, min(baz.count) from Baz baz group by baz.code" ).iterate();
 
 		iter = s.createQuery( "selecT baz from Baz baz where baz.stringDateMap['foo'] is not null or baz.stringDateMap['bar'] = ?" )
 				.setParameter( 0, new Date(), StandardBasicTypes.DATE )
 				.iterate();
 		assertFalse( iter.hasNext() );
 		list = s.createQuery( "select baz from Baz baz where baz.stringDateMap['now'] is not null" ).list();
 		assertTrue( list.size()==1 );
 		list = s.createQuery(
 				"select baz from Baz baz where baz.stringDateMap['now'] is not null and baz.stringDateMap['big bang'] < baz.stringDateMap['now']"
 		).list();
 		assertTrue( list.size()==1 );
 		list = s.createQuery( "select index(date) from Baz baz join baz.stringDateMap date" ).list();
 		System.out.println(list);
 		assertTrue( list.size()==2 );
 
 		s.createQuery(
 				"from Foo foo where foo.integer not between 1 and 5 and foo.string not in ('cde', 'abc') and foo.string is not null and foo.integer<=3"
 		).list();
 
 		s.createQuery( "from Baz baz inner join baz.collectionComponent.nested.foos foo where foo.string is null" )
 				.list();
 		if ( !(getDialect() instanceof MySQLDialect) && !(getDialect() instanceof MckoiDialect) && !(getDialect() instanceof SAPDBDialect) && !(getDialect() instanceof PointbaseDialect) )  {
 			s.createQuery(
 					"from Baz baz inner join baz.fooSet where '1' in (from baz.fooSet foo where foo.string is not null)"
 			).list();
 			s.createQuery(
 					"from Baz baz where 'a' in elements(baz.collectionComponent.nested.foos) and 1.0 in elements(baz.collectionComponent.nested.floats)"
 			).list();
 			s.createQuery(
 					"from Baz baz where 'b' in elements(baz.collectionComponent.nested.foos) and 1.0 in elements(baz.collectionComponent.nested.floats)"
 			).list();
 		}
 
 		s.createQuery( "from Foo foo join foo.foo where foo.foo in ('1','2','3')" ).list();
 		if ( !(getDialect() instanceof HSQLDialect) )
 			s.createQuery( "from Foo foo left join foo.foo where foo.foo in ('1','2','3')" ).list();
 		s.createQuery( "select foo.foo from Foo foo where foo.foo in ('1','2','3')" ).list();
 		s.createQuery( "select foo.foo.string from Foo foo where foo.foo in ('1','2','3')" ).list();
 		s.createQuery( "select foo.foo.string from Foo foo where foo.foo.string in ('1','2','3')" ).list();
 		s.createQuery( "select foo.foo.long from Foo foo where foo.foo.string in ('1','2','3')" ).list();
 		s.createQuery( "select count(*) from Foo foo where foo.foo.string in ('1','2','3') or foo.foo.long in (1,2,3)" )
 				.list();
 		s.createQuery( "select count(*) from Foo foo where foo.foo.string in ('1','2','3') group by foo.foo.long" )
 				.list();
 
 		s.createQuery( "from Foo foo1 left join foo1.foo foo2 left join foo2.foo where foo1.string is not null" )
 				.list();
 		s.createQuery( "from Foo foo1 left join foo1.foo.foo where foo1.string is not null" ).list();
 		s.createQuery( "from Foo foo1 left join foo1.foo foo2 left join foo1.foo.foo foo3 where foo1.string is not null" )
 				.list();
 
 		s.createQuery( "select foo.formula from Foo foo where foo.formula > 0" ).list();
 
 		int len = s.createQuery( "from Foo as foo join foo.foo as foo2 where foo2.id >'a' or foo2.id <'a'" ).list().size();
 		assertTrue(len==2);
 
 		for ( Object entity : s.createQuery( "from Holder" ).list() ) {
 			s.delete( entity );
 		}
 
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		baz = (Baz) s.createQuery("from Baz baz left outer join fetch baz.manyToAny").uniqueResult();
 		assertTrue( Hibernate.isInitialized( baz.getManyToAny() ) );
 		assertTrue( baz.getManyToAny().size()==2 );
 		BarProxy barp = (BarProxy) baz.getManyToAny().get(0);
 		s.createQuery( "from Baz baz join baz.manyToAny" ).list();
 		assertTrue( s.createQuery( "select baz from Baz baz join baz.manyToAny a where index(a) = 0" ).list().size()==1 );
 
 		FooProxy foop = (FooProxy) s.get( Foo.class, foo.getKey() );
 		assertTrue( foop == baz.getManyToAny().get(1) );
 
 		barp.setBaz(baz);
 		assertTrue(
 				s.createQuery( "select bar from Bar bar where bar.baz.stringDateMap['now'] is not null" ).list().size()==1 );
 		assertTrue(
 				s.createQuery(
 						"select bar from Bar bar join bar.baz b where b.stringDateMap['big bang'] < b.stringDateMap['now'] and b.stringDateMap['now'] is not null"
 				).list()
 						.size()==1 );
 		assertTrue(
 				s.createQuery(
 						"select bar from Bar bar where bar.baz.stringDateMap['big bang'] < bar.baz.stringDateMap['now'] and bar.baz.stringDateMap['now'] is not null"
 				).list()
 						.size()==1 );
 
 		list = s.createQuery( "select foo.string, foo.component, foo.id from Bar foo" ).list();
 		assertTrue ( ( (FooComponent) ( (Object[]) list.get(0) )[1] ).getName().equals("foo") );
 		list = s.createQuery( "select elements(baz.components) from Baz baz" ).list();
 		assertTrue( list.size()==2 );
 		list = s.createQuery( "select bc.name from Baz baz join baz.components bc" ).list();
 		assertTrue( list.size()==2 );
 		//list = s.find("select bc from Baz baz join baz.components bc");
 
 		s.createQuery("from Foo foo where foo.integer < 10 order by foo.string").setMaxResults(12).list();
 
 		s.delete(barp);
 		s.delete(baz);
 		s.delete( foop.getFoo() );
 		s.delete(foop);
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCascadeDeleteDetached() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		List list = new ArrayList();
 		list.add( new Fee() );
 		baz.setFees( list );
 		s.save( baz );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		s.getTransaction().commit();
 		s.close();
 
 		assertFalse( Hibernate.isInitialized( baz.getFees() ) );
 
 		s = openSession();
 		s.beginTransaction();
 		s.delete( baz );
 		s.flush();
 		assertFalse( s.createQuery( "from Fee" ).iterate().hasNext() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = new Baz();
 		list = new ArrayList();
 		list.add( new Fee() );
 		list.add( new Fee() );
 		baz.setFees(list);
 		s.save( baz );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		Hibernate.initialize( baz.getFees() );
 		s.getTransaction().commit();
 		s.close();
 
 		assertTrue( baz.getFees().size() == 2 );
 
 		s = openSession();
 		s.beginTransaction();
 		s.delete(baz);
 		s.flush();
 		assertFalse( s.createQuery( "from Fee" ).iterate().hasNext() );
 		s.getTransaction().commit();
 		s.close();
 
 	}
 
 	@Test
 	public void testForeignKeys() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		Foo foo = new Foo();
 		List bag = new ArrayList();
 		bag.add(foo);
 		baz.setIdFooBag(bag);
 		baz.setFoo(foo);
 		s.save(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testNonlazyCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		s.save( baz );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.createCriteria(Baz.class)
 			//.setComment("criteria test")
 			.setFetchMode( "stringDateMap", FetchMode.JOIN )
 			.uniqueResult();
 		assertTrue( Hibernate.isInitialized( baz.getFooToGlarch() ) );
 		assertTrue( Hibernate.isInitialized( baz.getFooComponentToFoo() ) );
 		assertTrue( !Hibernate.isInitialized( baz.getStringSet() ) );
 		assertTrue( Hibernate.isInitialized( baz.getStringDateMap() ) );
 		s.delete(baz);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testReuseDeletedCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		s.flush();
 		s.delete(baz);
 		Baz baz2 = new Baz();
 		baz2.setStringArray( new String[] {"x-y-z"} );
 		s.save(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 		baz2.setStringSet( baz.getStringSet() );
 		baz2.setStringArray( baz.getStringArray() );
 		baz2.setFooArray( baz.getFooArray() );
 
 		s = openSession();
 		s.beginTransaction();
 		s.update(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		assertTrue( baz2.getStringArray().length==3 );
 		assertTrue( baz2.getStringSet().size()==3 );
 		s.delete(baz2);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testPropertyRef() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Holder h = new Holder();
 		h.setName("foo");
 		Holder h2 = new Holder();
 		h2.setName("bar");
 		h.setOtherHolder(h2);
 		Serializable hid = s.save(h);
 		Qux q = new Qux();
 		q.setHolder(h2);
 		Serializable qid = s.save(q);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		h = (Holder) s.load(Holder.class, hid);
 		assertEquals( h.getName(), "foo");
 		assertEquals( h.getOtherHolder().getName(), "bar");
 		Object[] res = (Object[]) s.createQuery( "from Holder h join h.otherHolder oh where h.otherHolder.name = 'bar'" )
 				.list()
 				.get(0);
 		assertTrue( res[0]==h );
 		q = (Qux) s.get(Qux.class, qid);
 		assertTrue( q.getHolder() == h.getOtherHolder() );
 		s.delete(h);
 		s.delete(q);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testQueryCollectionOfValues() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		Glarch g = new Glarch();
 		Serializable gid = s.save(g);
 
 		if ( !(getDialect() instanceof MySQLDialect) && !(getDialect() instanceof HSQLDialect) /*&& !(dialect instanceof MckoiDialect)*/ && !(getDialect() instanceof SAPDBDialect) && !(getDialect() instanceof PointbaseDialect) && !(getDialect() instanceof TimesTenDialect) ) {
 			s.createFilter( baz.getFooArray(), "where size(this.bytes) > 0" ).list();
 			s.createFilter( baz.getFooArray(), "where 0 in elements(this.bytes)" ).list();
 		}
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.createQuery( "from Baz baz join baz.fooSet foo join foo.foo.foo foo2 where foo2.string = 'foo'" ).list();
 		s.createQuery( "from Baz baz join baz.fooArray foo join foo.foo.foo foo2 where foo2.string = 'foo'" ).list();
 		s.createQuery( "from Baz baz join baz.stringDateMap date where index(date) = 'foo'" ).list();
 		s.createQuery( "from Baz baz join baz.topGlarchez g where index(g) = 'A'" ).list();
 		s.createQuery( "select index(g) from Baz baz join baz.topGlarchez g" ).list();
 
 		assertTrue( s.createQuery( "from Baz baz left join baz.stringSet" ).list().size()==3 );
 		baz = (Baz) s.createQuery( "from Baz baz join baz.stringSet str where str='foo'" ).list().get(0);
 		assertTrue( !Hibernate.isInitialized( baz.getStringSet() ) );
 		baz = (Baz) s.createQuery( "from Baz baz left join fetch baz.stringSet" ).list().get(0);
 		assertTrue( Hibernate.isInitialized( baz.getStringSet() ) );
 		assertTrue( s.createQuery( "from Baz baz join baz.stringSet string where string='foo'" ).list().size()==1 );
 		assertTrue( s.createQuery( "from Baz baz inner join baz.components comp where comp.name='foo'" ).list().size()==1 );
 		//List bss = s.find("select baz, ss from Baz baz inner join baz.stringSet ss");
 		s.createQuery( "from Glarch g inner join g.fooComponents comp where comp.fee is not null" ).list();
 		s.createQuery( "from Glarch g inner join g.fooComponents comp join comp.fee fee where fee.count > 0" ).list();
 		s.createQuery( "from Glarch g inner join g.fooComponents comp where comp.fee.count is not null" ).list();
 
 		s.delete(baz);
 		s.delete( s.get(Glarch.class, gid) );
 		s.getTransaction().commit();
 		s.close();
 	}
@@ -3010,1982 +3011,1988 @@ public class FooBarTest extends LegacyTestCase {
 		list1 = s.createQuery( "from Foo foo where foo.string='foo bar'" ).list();
 		assertTrue( "find size", list1.size()==1 );
 		// There is an interbase bug that causes null integers to return as 0, also numeric precision is <= 15
 		assertTrue( "find equals", ( (Foo) list1.get(0) ).equalsFoo(foo) );
 		list2 = s.createQuery( "select foo from Foo foo" ).list();
 		assertTrue( "find size", list2.size()==5 );
 		List list3 = s.createQuery( "from Bar bar where bar.barString='bar bar'" ).list();
 		assertTrue( "find size", list3.size()==1 );
 		assertTrue( "find same instance", list2.contains( list1.get(0) ) && list2.contains( list2.get(0) ) );
 		assertTrue( s.createQuery( "from Trivial" ).list().size()==1 );
 		doDelete( s, "from Trivial" );
 
 		list2 = s.createQuery( "from Foo foo where foo.date = ?" )
 				.setParameter( 0, new java.sql.Date(123), StandardBasicTypes.DATE )
 				.list();
 		assertTrue ( "find by date", list2.size()==4 );
 		Iterator iter = list2.iterator();
 		while ( iter.hasNext() ) {
 			s.delete( iter.next() );
 		}
 		list2 = s.createQuery( "from Foo foo" ).list();
 		assertTrue( "find deleted", list2.size()==0);
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testDeleteRecursive() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo x = new Foo();
 		Foo y = new Foo();
 		x.setFoo( y );
 		y.setFoo( x );
 		s.save( x );
 		s.save( y );
 		s.flush();
 		s.delete( y );
 		s.delete( x );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testReachability() throws Exception {
 		//first for unkeyed collections
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz1 = new Baz();
 		s.save(baz1);
 		Baz baz2 = new Baz();
 		s.save(baz2);
 		baz1.setIntArray( new int[] {1 ,2, 3, 4} );
 		baz1.setFooSet( new HashSet() );
 		Foo foo = new Foo();
 		s.save(foo);
 		baz1.getFooSet().add(foo);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		baz2.setFooSet( baz1.getFooSet() ); baz1.setFooSet(null);
 		baz2.setIntArray( baz1.getIntArray() ); baz1.setIntArray(null);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		assertTrue( "unkeyed reachability", baz2.getIntArray().length==4 );
 		assertTrue( "unkeyed reachability", baz2.getFooSet().size()==1 );
 		assertTrue( "unkeyed reachability", baz1.getIntArray().length==0 );
 		assertTrue( "unkeyed reachability", baz1.getFooSet().size()==0 );
 		//System.out.println( s.print(baz1) + s.print(baz2) );
 		FooProxy fp = (FooProxy) baz2.getFooSet().iterator().next();
 		s.delete(fp);
 		s.delete(baz1);
 		s.delete(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 		//now for collections of collections
 		s = openSession();
 		s.beginTransaction();
 		baz1 = new Baz();
 		s.save(baz1);
 		baz2 = new Baz();
 		s.save(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		s.delete(baz1);
 		s.delete(baz2);
 		s.getTransaction().commit();
 		s.close();
 
 		//now for keyed collections
 		s = openSession();
 		s.beginTransaction();
 		baz1 = new Baz();
 		s.save(baz1);
 		baz2 = new Baz();
 		s.save(baz2);
 		Foo foo1 = new Foo();
 		Foo foo2 = new Foo();
 		s.save(foo1); s.save(foo2);
 		baz1.setFooArray( new Foo[] { foo1, null, foo2 } );
 		baz1.setStringDateMap( new TreeMap() );
 		baz1.getStringDateMap().put("today", new Date( System.currentTimeMillis() ) );
 		baz1.getStringDateMap().put("tomorrow", new Date( System.currentTimeMillis() + 86400000 ) );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		baz2.setFooArray( baz1.getFooArray() ); baz1.setFooArray(null);
 		baz2.setStringDateMap( baz1.getStringDateMap() ); baz1.setStringDateMap(null);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz2 = (Baz) s.load( Baz.class, baz2.getCode() );
 		baz1 = (Baz) s.load( Baz.class, baz1.getCode() );
 		assertTrue( "reachability", baz2.getStringDateMap().size()==2 );
 		assertTrue( "reachability", baz2.getFooArray().length==3 );
 		assertTrue( "reachability", baz1.getStringDateMap().size()==0 );
 		assertTrue( "reachability", baz1.getFooArray().length==0 );
 		assertTrue( "null element", baz2.getFooArray()[1]==null );
 		assertTrue( "non-null element", baz2.getStringDateMap().get("today")!=null );
 		assertTrue( "non-null element", baz2.getStringDateMap().get("tomorrow")!=null );
 		assertTrue( "null element", baz2.getStringDateMap().get("foo")==null );
 		s.delete( baz2.getFooArray()[0] );
 		s.delete( baz2.getFooArray()[2] );
 		s.delete(baz1);
 		s.delete(baz2);
 		s.flush();
 		assertTrue( s.createQuery( "from java.lang.Object" ).list().size()==0 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testPersistentLifecycle() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Qux q = new Qux();
 		s.save(q);
 		q.setStuff("foo bar baz qux");
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		q = (Qux) s.load( Qux.class, q.getKey() );
 		assertTrue( "lifecycle create", q.getCreated() );
 		assertTrue( "lifecycle load", q.getLoaded() );
 		assertTrue( "lifecycle subobject", q.getFoo()!=null );
 		s.delete(q);
 		assertTrue( "lifecycle delete", q.getDeleted() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		assertTrue( "subdeletion", s.createQuery( "from Foo foo" ).list().size()==0);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testIterators() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		for ( int i=0; i<10; i++ ) {
 			Qux q = new Qux();
 			Object qid = s.save(q);
 			assertTrue("not null", qid!=null);
 		}
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Iterator iter = s.createQuery( "from Qux q where q.stuff is null" ).iterate();
 		int count=0;
 		while ( iter.hasNext() ) {
 			Qux q = (Qux) iter.next();
 			q.setStuff("foo");
 			if (count==0 || count==5) iter.remove();
 			count++;
 		}
 		assertTrue("iterate", count==10);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		assertEquals( 8, doDelete( s, "from Qux q where q.stuff=?", "foo", StandardBasicTypes.STRING ) );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		iter = s.createQuery( "from Qux q" ).iterate();
 		assertTrue( "empty iterator", !iter.hasNext() );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testVersioning() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		GlarchProxy g = new Glarch();
 		s.save(g);
 		GlarchProxy g2 = new Glarch();
 		s.save(g2);
 		Serializable gid = s.getIdentifier(g);
 		Serializable g2id = s.getIdentifier(g2);
 		g.setName("glarch");
 		txn.commit();
 		s.close();
 
 		sessionFactory().evict(Glarch.class);
 
 		s = openSession();
 		txn = s.beginTransaction();
 		g = (GlarchProxy) s.load( Glarch.class, gid );
 		s.lock(g, LockMode.UPGRADE);
 		g2 = (GlarchProxy) s.load( Glarch.class, g2id );
 		assertTrue( "version", g.getVersion()==1 );
 		assertTrue( "version", g.getDerivedVersion()==1 );
 		assertTrue( "version", g2.getVersion()==0 );
 		g.setName("foo");
 		assertTrue(
 			"find by version",
 				s.createQuery( "from Glarch g where g.version=2" ).list().size()==1
 		);
 		g.setName("bar");
 		txn.commit();
 		s.close();
 
 		sessionFactory().evict(Glarch.class);
 
 		s = openSession();
 		txn = s.beginTransaction();
 		g = (GlarchProxy) s.load( Glarch.class, gid );
 		g2 = (GlarchProxy) s.load( Glarch.class, g2id );
 		assertTrue( "version", g.getVersion()==3 );
 		assertTrue( "version", g.getDerivedVersion()==3 );
 		assertTrue( "version", g2.getVersion()==0 );
 		g.setNext(null);
 		g2.setNext(g);
 		s.delete(g2);
 		s.delete(g);
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testVersionedCollections() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		GlarchProxy g = new Glarch();
 		s.save(g);
 		g.setProxyArray( new GlarchProxy[] { g } );
 		String gid = (String) s.getIdentifier(g);
 		ArrayList list = new ArrayList();
 		list.add("foo");
 		g.setStrings(list);
 		HashSet set = new HashSet();
 		set.add( g );
 		g.setProxySet( set );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( g.getStrings().size()==1 );
 		assertTrue( g.getProxyArray().length==1 );
 		assertTrue( g.getProxySet().size()==1 );
 		assertTrue( "versioned collection before", g.getVersion() == 1 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( g.getStrings().get(0).equals("foo") );
 		assertTrue( g.getProxyArray()[0]==g );
 		assertTrue( g.getProxySet().iterator().next()==g );
 		assertTrue( "versioned collection before", g.getVersion() == 1 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( "versioned collection before", g.getVersion() == 1 );
 		g.getStrings().add( "bar" );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( "versioned collection after", g.getVersion()==2 );
 		assertTrue( "versioned collection after", g.getStrings().size() == 2 );
 		g.setProxyArray( null );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( "versioned collection after", g.getVersion()==3 );
 		assertTrue( "versioned collection after", g.getProxyArray().length == 0 );
 		g.setFooComponents( new ArrayList() );
 		g.setProxyArray( null );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( "versioned collection after", g.getVersion()==4 );
 		s.delete(g);
 		s.flush();
 		assertTrue( s.createQuery( "from java.lang.Object" ).list().size()==0 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testRecursiveLoad() throws Exception {
 		//Non polymorphic class (there is an implementation optimization
 		//being tested here)
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		GlarchProxy last = new Glarch();
 		s.save(last);
 		last.setOrder( (short) 0 );
 		for (int i=0; i<5; i++) {
 			GlarchProxy next = new Glarch();
 			s.save(next);
 			last.setNext(next);
 			last = next;
 			last.setOrder( (short) (i+1) );
 		}
 		Iterator iter = s.createQuery( "from Glarch g" ).iterate();
 		while ( iter.hasNext() ) {
 			iter.next();
 		}
 		List list = s.createQuery( "from Glarch g" ).list();
 		assertTrue( "recursive find", list.size()==6 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		list = s.createQuery( "from Glarch g" ).list();
 		assertTrue( "recursive iter", list.size()==6 );
 		list = s.createQuery( "from Glarch g where g.next is not null" ).list();
 		assertTrue( "recursive iter", list.size()==5 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		iter = s.createQuery( "from Glarch g order by g.order asc" ).iterate();
 		while ( iter.hasNext() ) {
 			GlarchProxy g = (GlarchProxy) iter.next();
 			assertTrue( "not null", g!=null );
 			iter.remove();
 		}
 		txn.commit();
 		s.close();
 
 		//Same thing but using polymorphic class (no optimisation possible):
 		s = openSession();
 		txn = s.beginTransaction();
 		FooProxy flast = new Bar();
 		s.save(flast);
 		flast.setString( "foo0" );
 		for (int i=0; i<5; i++) {
 			FooProxy foo = new Bar();
 			s.save(foo);
 			flast.setFoo(foo);
 			flast = flast.getFoo();
 			flast.setString( "foo" + (i+1) );
 		}
 		iter = s.createQuery( "from Foo foo" ).iterate();
 		while ( iter.hasNext() ) {
 			iter.next();
 		}
 		list = s.createQuery( "from Foo foo" ).list();
 		assertTrue( "recursive find", list.size()==6 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		list = s.createQuery( "from Foo foo" ).list();
 		assertTrue( "recursive iter", list.size()==6 );
 		iter = list.iterator();
 		while ( iter.hasNext() ) {
 			assertTrue( "polymorphic recursive load", iter.next() instanceof BarProxy );
 		}
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		iter = s.createQuery( "from Foo foo order by foo.string asc" ).iterate();
 		while ( iter.hasNext() ) {
 			BarProxy bar = (BarProxy) iter.next();
 			assertTrue( "not null", bar!=null );
 			iter.remove();
 		}
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testScrollableIterator() throws Exception {
 		// skip if not one of these named dialects
 		boolean match = getDialect() instanceof DB2Dialect
 				|| getDialect() instanceof SybaseDialect
 				|| getDialect() instanceof HSQLDialect
 				|| getDialect() instanceof Oracle8iDialect // 9i/10g too because of inheritence...
 				;
 		if ( ! match ) {
 			return;
 		}
 
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		s.save( new Foo() );
 		s.save( new Foo() );
 		s.save( new Foo() );
 		s.save( new Bar() );
 		Query query = s.createQuery("select f, f.integer from Foo f");
 		assertTrue( query.getReturnTypes().length==2 );
 		ScrollableResults iter = query.scroll();
 		assertTrue( iter.next() );
 		assertTrue( iter.scroll(1) );
 		FooProxy f2 = (FooProxy) iter.get()[0];
 		assertTrue( f2!=null );
 		assertTrue( iter.scroll(-1) );
 		Object f1 = iter.get(0);
 		iter.next();
 		assertTrue( f1!=null && iter.get(0)==f2 );
 		iter.getInteger(1);
 
 		assertTrue( !iter.scroll(100) );
 		assertTrue( iter.first() );
 		assertTrue( iter.scroll(3) );
 		Object f4 = iter.get(0);
 		assertTrue( f4!=null );
 		assertTrue( !iter.next() );
 		assertTrue( iter.first() );
 		assertTrue( iter.get(0)==f1 );
 		assertTrue( iter.last() );
 		assertTrue( iter.get(0)==f4 );
 		assertTrue( iter.previous() );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		query = s.createQuery("select f, f.integer from Foo f");
 		assertTrue( query.getReturnTypes().length==2 );
 		iter = query.scroll();
 		assertTrue( iter.next() );
 		assertTrue( iter.scroll(1) );
 		f2 = (FooProxy) iter.get()[0];
 		assertTrue( f2!=null );
 		assertTrue( f2.getString()!=null  && f2.getComponent().getImportantDates().length > 0 );
 		assertTrue( iter.scroll(-1) );
 		f1 = iter.get(0);
 		iter.next();
 		assertTrue( f1!=null && iter.get(0)==f2 );
 		iter.getInteger(1);
 
 		assertTrue( !iter.scroll(100) );
 		assertTrue( iter.first() );
 		assertTrue( iter.scroll(3) );
 		f4 = iter.get(0);
 		assertTrue( f4!=null );
 		assertTrue( !iter.next() );
 		assertTrue( iter.first() );
 		assertTrue( iter.get(0)==f1 );
 		assertTrue( iter.last() );
 		assertTrue( iter.get(0)==f4 );
 		assertTrue( iter.previous() );
 		int i = 0;
 		for ( Object entity : s.createQuery( "from Foo" ).list() ) {
 			i++;
 			s.delete( entity );
 		}
 		assertEquals( 4, i );
 		s.flush();
 		assertTrue( s.createQuery( "from java.lang.Object" ).list().size()==0 );
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testMultiColumnQueries() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		Foo foo1 = new Foo();
 		s.save(foo1);
 		foo.setFoo(foo1);
 		List l = s.createQuery( "select parent, child from Foo parent, Foo child where parent.foo = child" ).list();
 		assertTrue( "multi-column find", l.size()==1 );
 
 		Iterator rs = s.createQuery(
 				"select count(distinct child.id), count(distinct parent.id) from Foo parent, Foo child where parent.foo = child"
 		).iterate();
 		Object[] row = (Object[]) rs.next();
 		assertTrue( "multi-column count", ( (Long) row[0] ).intValue()==1 );
 		assertTrue( "multi-column count", ( (Long) row[1] ).intValue()==1 );
 		assertTrue( !rs.hasNext() );
 
 		rs = s.createQuery( "select child.id, parent.id, child.long from Foo parent, Foo child where parent.foo = child" )
 				.iterate();
 		row = (Object[]) rs.next();
 		assertTrue( "multi-column id", row[0].equals( foo.getFoo().getKey() ) );
 		assertTrue( "multi-column id", row[1].equals( foo.getKey() ) );
 		assertTrue( "multi-column property", row[2].equals( foo.getFoo().getLong() ) );
 		assertTrue( !rs.hasNext() );
 
 		rs = s.createQuery(
 				"select child.id, parent.id, child.long, child, parent.foo from Foo parent, Foo child where parent.foo = child"
 		).iterate();
 		row = (Object[]) rs.next();
 		assertTrue(
 			foo.getFoo().getKey().equals( row[0] ) &&
 			foo.getKey().equals( row[1] ) &&
 			foo.getFoo().getLong().equals( row[2] ) &&
 			row[3] == foo.getFoo() &&
 			row[3]==row[4]
 		);
 		assertTrue( !rs.hasNext() );
 
 		row = (Object[]) l.get(0);
 		assertTrue( "multi-column find", row[0]==foo && row[1]==foo.getFoo() );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		Iterator iter = s.createQuery(
 				"select parent, child from Foo parent, Foo child where parent.foo = child and parent.string='a string'"
 		).iterate();
 		int deletions=0;
 		while ( iter.hasNext() ) {
 			Object[] pnc = (Object[]) iter.next();
 			s.delete( pnc[0] );
 			s.delete( pnc[1] );
 			deletions++;
 		}
 		assertTrue("multi-column iterate", deletions==1);
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testDeleteTransient() throws Exception {
 		Fee fee = new Fee();
 		Fee fee2 = new Fee();
 		fee2.setAnotherFee(fee);
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		s.save(fee);
 		s.save(fee2);
 		s.flush();
 		fee.setCount(123);
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		s.delete(fee);
 		s.delete(fee2);
 		//foo.setAnotherFee(null);
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		assertTrue( s.createQuery( "from Fee fee" ).list().size()==0 );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testDeleteUpdatedTransient() throws Exception {
 		Fee fee = new Fee();
 		Fee fee2 = new Fee();
 		fee2.setAnotherFee(fee);
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		s.save(fee);
 		s.save(fee2);
 		s.flush();
 		fee.setCount(123);
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		s.update(fee);
 		//fee2.setAnotherFee(null);
 		s.update(fee2);
 		s.delete(fee);
 		s.delete(fee2);
 		tx.commit();
 		s.close();
 		s = openSession();
 		tx = s.beginTransaction();
 		assertTrue( s.createQuery( "from Fee fee" ).list().size()==0 );
 		tx.commit();
 		s.close();
 	}
 
 	@Test
 	public void testUpdateOrder() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Fee fee1 = new Fee();
 		s.save(fee1);
 		Fee fee2 = new Fee();
 		fee1.setFee(fee2);
 		fee2.setFee(fee1);
 		fee2.setFees( new HashSet() );
 		Fee fee3 = new Fee();
 		fee3.setFee(fee1);
 		fee3.setAnotherFee(fee2);
 		fee2.setAnotherFee(fee3);
 		s.save(fee3);
 		s.save(fee2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		fee1.setCount(10);
 		fee2.setCount(20);
 		fee3.setCount(30);
 		s.update(fee1);
 		s.update(fee2);
 		s.update(fee3);
 		s.flush();
 		s.delete(fee1);
 		s.delete(fee2);
 		s.delete(fee3);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		assertTrue( s.createQuery( "from Fee fee" ).list().size()==0 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testUpdateFromTransient() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Fee fee1 = new Fee();
 		s.save(fee1);
 		Fee fee2 = new Fee();
 		fee1.setFee(fee2);
 		fee2.setFee(fee1);
 		fee2.setFees( new HashSet() );
 		Fee fee3 = new Fee();
 		fee3.setFee(fee1);
 		fee3.setAnotherFee(fee2);
 		fee2.setAnotherFee(fee3);
 		s.save(fee3);
 		s.save(fee2);
 		s.getTransaction().commit();
 		s.close();
 
 		fee1.setFi("changed");
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee1);
 		s.getTransaction().commit();
 		s.close();
 
 		Qux q = new Qux("quxxy");
 		q.setTheKey(0);
 		fee1.setQux(q);
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee1);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		fee1 = (Fee) s.load( Fee.class, fee1.getKey() );
 		assertTrue( "updated from transient", fee1.getFi().equals("changed") );
 		assertTrue( "unsaved value", fee1.getQux()!=null );
 		s.delete( fee1.getQux() );
 		fee1.setQux(null);
 		s.getTransaction().commit();
 		s.close();
 
 		fee2.setFi("CHANGED");
 		fee2.getFees().add("an element");
 		fee1.setFi("changed again");
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee2);
 		s.update( fee1 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Fee fee = new Fee();
 		s.load( fee, fee2.getKey() );
 		fee1 = (Fee) s.load( Fee.class, fee1.getKey() );
 		assertTrue( "updated from transient", fee1.getFi().equals("changed again") );
 		assertTrue( "updated from transient", fee.getFi().equals("CHANGED") );
 		assertTrue( "updated collection", fee.getFees().contains("an element") );
 		s.getTransaction().commit();
 		s.close();
 
 		fee.getFees().clear();
 		fee.getFees().add("new element");
 		fee1.setFee(null);
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee);
 		s.saveOrUpdate(fee1);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.load( fee, fee.getKey() );
 		assertTrue( "update", fee.getAnotherFee()!=null );
 		assertTrue( "update", fee.getFee()!=null );
 		assertTrue( "update", fee.getAnotherFee().getFee()==fee.getFee() );
 		assertTrue( "updated collection", fee.getFees().contains("new element") );
 		assertTrue( "updated collection", !fee.getFees().contains("an element") );
 		s.getTransaction().commit();
 		s.close();
 
 		fee.setQux( new Qux("quxy") );
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee);
 		s.getTransaction().commit();
 		s.close();
 
 		fee.getQux().setStuff("xxx");
 
 		s = openSession();
 		s.beginTransaction();
 		s.saveOrUpdate(fee);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.load( fee, fee.getKey() );
 		assertTrue( "cascade update", fee.getQux()!=null );
 		assertTrue( "cascade update", fee.getQux().getStuff().equals("xxx") );
 		assertTrue( "update", fee.getAnotherFee()!=null );
 		assertTrue( "update", fee.getFee()!=null );
 		assertTrue( "update", fee.getAnotherFee().getFee()==fee.getFee() );
 		fee.getAnotherFee().setAnotherFee(null);
 		s.delete(fee);
 		doDelete( s, "from Fee fee" );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		assertTrue( s.createQuery( "from Fee fee" ).list().size()==0 );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testArraysOfTimes() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz() ;
 		s.save(baz);
 		baz.setDefaults();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz.getTimeArray()[2] = new Date(123);
 		baz.getTimeArray()[3] = new java.sql.Time(1234);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		s.delete( baz );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testComponents() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		Foo foo = new Foo();
 //		foo.setComponent( new FooComponent("foo", 69, null, new FooComponent("bar", 96, null, null) ) );
 		s.save(foo);
 		foo.getComponent().setName( "IFA" );
 		txn.commit();
 		s.close();
 
 		foo.setComponent( null );
 
 		s = openSession();
 		txn = s.beginTransaction();
 		s.load( foo, foo.getKey() );
 		assertTrue(
 			"save components",
 			foo.getComponent().getName().equals("IFA") &&
 			foo.getComponent().getSubcomponent().getName().equals("bar")
 		);
 		assertTrue( "cascade save via component", foo.getComponent().getGlarch() != null );
 		foo.getComponent().getSubcomponent().setName("baz");
 		txn.commit();
 		s.close();
 
 		foo.setComponent(null);
 
 		s = openSession();
 		txn = s.beginTransaction();
 		s.load( foo, foo.getKey() );
 		assertTrue(
 			"update components",
 			foo.getComponent().getName().equals("IFA") &&
 			foo.getComponent().getSubcomponent().getName().equals("baz")
 		);
 		s.delete(foo);
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		foo = new Foo();
 		s.save( foo );
 		foo.setCustom( new String[] { "one", "two" } );
 		assertTrue( s.createQuery( "from Foo foo where foo.custom.s1 = 'one'" ).list().get(0)==foo );
 		s.delete( foo );
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testNoForeignKeyViolations() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Glarch g1 = new Glarch();
 		Glarch g2 = new Glarch();
 		g1.setNext(g2);
 		g2.setNext(g1);
 		s.save(g1);
 		s.save(g2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		List l = s.createQuery( "from Glarch g where g.next is not null" ).list();
 		s.delete( l.get(0) );
 		s.delete( l.get(1) );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testLazyCollections() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Qux q = new Qux();
 		s.save(q);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		q = (Qux) s.load( Qux.class, q.getKey() );
 		s.getTransaction().commit();
 		s.close();
 
 		System.out.println("Two exceptions are supposed to occur:");
 		boolean ok = false;
 		try {
 			q.getMoreFums().isEmpty();
 		}
 		catch (LazyInitializationException e) {
 			ok = true;
 		}
 		assertTrue( "lazy collection with one-to-many", ok );
 
 		ok = false;
 		try {
 			q.getFums().isEmpty();
 		}
 		catch (LazyInitializationException e) {
 			ok = true;
 		}
 		assertTrue( "lazy collection with many-to-many", ok );
 
 		s = openSession();
 		s.beginTransaction();
 		q = (Qux) s.load( Qux.class, q.getKey() );
 		s.delete(q);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	@TestForIssue(jiraKey = "HHH-7603")
 	public void testLazyCollectionsTouchedDuringPreCommit() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Qux q = new Qux();
 		s.save( q );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		q = ( Qux ) s.load( Qux.class, q.getKey() );
 		s.getTransaction().commit();
 
 		//clear the session
 		s.clear();
 
 		//now reload the proxy and delete it
 		s.beginTransaction();
 
 		final Qux qToDelete = ( Qux ) s.load( Qux.class, q.getKey() );
 
 		//register a pre commit process that will touch the collection and delete the entity
 		( ( EventSource ) s ).getActionQueue().registerProcess( new BeforeTransactionCompletionProcess() {
 			@Override
 			public void doBeforeTransactionCompletion(SessionImplementor session) {
 				qToDelete.getFums().size();
 			}
 		} );
 
 		s.delete( qToDelete );
 		boolean ok = false;
 		try {
 			s.getTransaction().commit();
 		}
 		catch (LazyInitializationException e) {
 			ok = true;
 			s.getTransaction().rollback();
 		}
+		catch (TransactionException te) {
+			if(te.getCause() instanceof LazyInitializationException) {
+				ok = true;
+			}
+			s.getTransaction().rollback();
+		}
 		finally {
 			s.close();
 		}
 		assertTrue( "lazy collection should have blown in the before trans completion", ok );
 
 		s = openSession();
 		s.beginTransaction();
 		q = ( Qux ) s.load( Qux.class, q.getKey() );
 		s.delete( q );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@SkipForDialect(value = AbstractHANADialect.class, comment = "HANA currently requires specifying table name by 'FOR UPDATE of t1.c1' if there are more than one tables/views/subqueries in the FROM clause")
 	@Test
 	public void testNewSessionLifecycle() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Serializable fid = null;
 		try {
 			Foo f = new Foo();
 			s.save(f);
 			fid = s.getIdentifier(f);
 			s.getTransaction().commit();
 		}
 		catch (Exception e) {
 			s.getTransaction().rollback();
 			throw e;
 		}
 		finally {
 			s.close();
 		}
 
 		s = openSession();
 		s.beginTransaction();
 		try {
 			Foo f = new Foo();
 			s.delete(f);
 			s.getTransaction().commit();
 		}
 		catch (Exception e) {
 			s.getTransaction().rollback();
 		}
 		finally {
 			s.close();
 		}
 
 		s = openSession();
 		s.beginTransaction();
 		try {
 			Foo f = (Foo) s.load(Foo.class, fid, LockMode.UPGRADE);
 
 			s.delete(f);
 			s.flush();
 			s.getTransaction().commit();
 		}
 		catch (Exception e) {
 			s.getTransaction().rollback();
 			throw e;
 		}
 		finally {
 			assertTrue( s.close()==null );
 		}
 	}
 
 	@Test
 	public void testOrderBy() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		s.save(foo);
 		List list = s.createQuery(
 				"select foo from Foo foo, Fee fee where foo.dependent = fee order by foo.string desc, foo.component.count asc, fee.id"
 		).list();
 		assertTrue( "order by", list.size()==1 );
 		Foo foo2 = new Foo();
 		s.save(foo2);
 		foo.setFoo(foo2);
 		list = s.createQuery(
 				"select foo.foo, foo.dependent from Foo foo order by foo.foo.string desc, foo.component.count asc, foo.dependent.id"
 		).list();
 		assertTrue( "order by", list.size()==1 );
 		list = s.createQuery( "select foo from Foo foo order by foo.dependent.id, foo.dependent.fi" ).list();
 		assertTrue( "order by", list.size()==2 );
 		s.delete(foo);
 		s.delete(foo2);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		Many manyB = new Many();
 		s.save(manyB);
 		One oneB = new One();
 		s.save(oneB);
 		oneB.setValue("b");
 		manyB.setOne(oneB);
 		Many manyA = new Many();
 		s.save(manyA);
 		One oneA = new One();
 		s.save(oneA);
 		oneA.setValue("a");
 		manyA.setOne(oneA);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		List results = s.createQuery( "SELECT one FROM " + One.class.getName() + " one ORDER BY one.value ASC" ).list();
 		assertEquals( 2, results.size() );
 		assertEquals( "'a' isn't first element", "a", ( (One) results.get(0) ).getValue() );
 		assertEquals( "'b' isn't second element", "b", ( (One) results.get(1) ).getValue() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		results = s.createQuery( "SELECT many.one FROM " + Many.class.getName() + " many ORDER BY many.one.value ASC, many.one.id" )
 				.list();
 		assertEquals( 2, results.size() );
 		assertEquals( 2, results.size() );
 		assertEquals( "'a' isn't first element", "a", ( (One) results.get(0) ).getValue() );
 		assertEquals( "'b' isn't second element", "b", ( (One) results.get(1) ).getValue() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		oneA = (One)s.load(One.class, oneA.getKey());
 		manyA = (Many)s.load(Many.class, manyA.getKey());
 		oneB = (One)s.load(One.class, oneB.getKey());
 		manyB = (Many)s.load(Many.class, manyB.getKey());
 		s.delete(manyA);
 		s.delete(oneA);
 		s.delete(manyB);
 		s.delete(oneB);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testManyToOne() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		One one = new One();
 		s.save(one);
 		one.setValue( "yada" );
 		Many many = new Many();
 		many.setOne( one );
 		s.save( many );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		one = (One) s.load( One.class, one.getKey() );
 		one.getManies().size();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		many = (Many) s.load( Many.class, many.getKey() );
 		assertTrue( "many-to-one assoc", many.getOne()!=null );
 		s.delete( many.getOne() );
 		s.delete(many);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testSaveDelete() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo f = new Foo();
 		s.save(f);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.delete( s.load( Foo.class, f.getKey() ) );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testProxyArray() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		GlarchProxy g = new Glarch();
 		Glarch g1 = new Glarch();
 		Glarch g2 = new Glarch();
 		g.setProxyArray( new GlarchProxy[] { g1, g2 } );
 		Glarch g3 = new Glarch();
 		s.save(g3);
 		g2.setProxyArray( new GlarchProxy[] {null, g3, g} );
 		Set set = new HashSet();
 		set.add(g1);
 		set.add(g2);
 		g.setProxySet(set);
 		s.save(g);
 		s.save(g1);
 		s.save(g2);
 		Serializable id = s.getIdentifier(g);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, id);
 		assertTrue( "array of proxies", g.getProxyArray().length==2 );
 		assertTrue( "array of proxies", g.getProxyArray()[0]!=null );
 		assertTrue("deferred load test",g.getProxyArray()[1].getProxyArray()[0]==null );
 		assertTrue("deferred load test",g.getProxyArray()[1].getProxyArray()[2]==g );
 		assertTrue( "set of proxies", g.getProxySet().size()==2 );
 		Iterator iter = s.createQuery( "from Glarch g" ).iterate();
 		while ( iter.hasNext() ) {
 			iter.next();
 			iter.remove();
 		}
 		s.getTransaction().commit();
 		s.disconnect();
 		SerializationHelper.deserialize( SerializationHelper.serialize(s) );
 		s.close();
 	}
 
 	@Test
 	public void testCache() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Immutable im = new Immutable();
 		s.save(im);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.load( im, im.getId() );
 		s.getTransaction().commit();
 		s.close();
 
 		final Session s2 = openSession();
 		s2.beginTransaction();
 		s2.load( im, im.getId() );
 		assertEquals(
 				"cached object identity",
 				im,
 				s2.createQuery( "from Immutable im where im = ?" ).setParameter(
 						0, im, s2.getTypeHelper().entity( Immutable.class )
 				).uniqueResult()
 		);
 		s2.doWork(
 				new AbstractWork() {
 					@Override
 					public void execute(Connection connection) throws SQLException {
 						Statement st = connection.createStatement();
 						st.executeUpdate( "delete from immut" );
 					}
 				}
 		);
 		s2.getTransaction().commit();
 		s2.close();
 	}
 
 	@Test
 	public void testFindLoad() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		FooProxy foo = new Foo();
 		s.save(foo);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = (FooProxy) s.createQuery( "from Foo foo" ).list().get(0);
 		FooProxy foo2 = (FooProxy) s.load( Foo.class, foo.getKey() );
 		assertTrue( "find returns same object as load", foo == foo2 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo2 = (FooProxy) s.load( Foo.class, foo.getKey() );
 		foo = (FooProxy) s.createQuery( "from Foo foo" ).list().get(0);
 		assertTrue( "find returns same object as load", foo == foo2 );
 		doDelete( s, "from Foo foo" );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@SkipForDialect(value = AbstractHANADialect.class, comment = "HANA currently requires specifying table name by 'FOR UPDATE of t1.c1' if there are more than one tables/views/subqueries in the FROM clause")
 	@Test
 	public void testRefresh() throws Exception {
 		final Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		s.save( foo );
 		s.flush();
 		s.doWork(
 				new AbstractWork() {
 					@Override
 					public void execute(Connection connection) throws SQLException {
 						final String sql = "update " + getDialect().openQuote() + "foos" + getDialect().closeQuote() + " set long_ = -3";
 						Statement st = connection.createStatement();
 						st.executeUpdate( sql );
 					}
 				}
 		);
 		s.refresh(foo);
 		assertEquals( Long.valueOf( -3l ), foo.getLong() );
 		assertEquals( LockMode.READ, s.getCurrentLockMode( foo ) );
 		s.refresh(foo, LockMode.UPGRADE);
 		if ( getDialect().supportsOuterJoinForUpdate() ) {
 			assertEquals( LockMode.UPGRADE, s.getCurrentLockMode( foo ) );
 		}
 		s.delete(foo);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testAutoFlush() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		FooProxy foo = new Foo();
 		s.save(foo);
 		assertTrue( "autoflush create", s.createQuery( "from Foo foo" ).list().size()==1 );
 		foo.setChar( 'X' );
 		assertTrue( "autoflush update", s.createQuery( "from Foo foo where foo.char='X'" ).list().size()==1 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		foo = (FooProxy) s.load( Foo.class, foo.getKey() );
 		//s.update( new Foo(), foo.getKey() );
 		//assertTrue( s.find("from Foo foo where not foo.char='X'").size()==1, "autoflush update" );
 		if ( !(getDialect() instanceof MySQLDialect) && !(getDialect() instanceof HSQLDialect) && !(getDialect() instanceof PointbaseDialect) )  {
 			foo.setBytes( "osama".getBytes() );
 			assertTrue( "autoflush collection update",
 					s.createQuery( "from Foo foo where 111 in elements(foo.bytes)" ).list().size()==1 );
 			foo.getBytes()[0] = 69;
 			assertTrue( "autoflush collection update",
 					s.createQuery( "from Foo foo where 69 in elements(foo.bytes)" ).list()
 							.size()==1 );
 		}
 		s.delete(foo);
 		assertTrue( "autoflush delete", s.createQuery( "from Foo foo" ).list().size()==0 );
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testVeto() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Vetoer v = new Vetoer();
 		s.save(v);
 		s.save(v);
 		s.getTransaction().commit();
 		s.close();
 		s = openSession();
 		s.beginTransaction();
 		s.update( v );
 		s.update( v );
 		s.delete( v );
 		s.delete( v );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testSerializableType() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Vetoer v = new Vetoer();
 		v.setStrings( new String[] {"foo", "bar", "baz"} );
 		s.save( v ); Serializable id = s.save(v);
 		v.getStrings()[1] = "osama";
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		v = (Vetoer) s.load(Vetoer.class, id);
 		assertTrue( "serializable type", v.getStrings()[1].equals( "osama" ) );
 		s.delete(v); s.delete( v );
 		s.flush();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testAutoFlushCollections() throws Exception {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		baz = (Baz) s.load(Baz.class, baz.getCode());
 		baz.getStringArray()[0] = "bark";
 		Iterator i = s.createQuery( "select elements(baz.stringArray) from Baz baz" ).iterate();
 		boolean found = false;
 		while ( i.hasNext() ) {
 			if ( "bark".equals( i.next() ) ) found = true;
 		}
 		assertTrue(found);
 		baz.setStringArray(null);
 		i = s.createQuery( "select distinct elements(baz.stringArray) from Baz baz" ).iterate();
 		assertTrue( !i.hasNext() );
 		baz.setStringArray( new String[] { "foo", "bar" } );
 		i = s.createQuery( "select elements(baz.stringArray) from Baz baz" ).iterate();
 		assertTrue( i.hasNext() );
 
 		Foo foo = new Foo();
 		s.save(foo);
 		s.flush();
 		baz.setFooArray( new Foo[] {foo} );
 
 		i = s.createQuery( "select foo from Baz baz join baz.fooArray foo" ).iterate();
 		found = false;
 		while ( i.hasNext() ) {
 			if ( foo==i.next() ) found = true;
 		}
 		assertTrue(found);
 
 		baz.getFooArray()[0] = null;
 		i = s.createQuery( "select foo from Baz baz join baz.fooArray foo" ).iterate();
 		assertTrue( !i.hasNext() );
 		baz.getFooArray()[0] = foo;
 		i = s.createQuery( "select elements(baz.fooArray) from Baz baz" ).iterate();
 		assertTrue( i.hasNext() );
 
 		if ( !(getDialect() instanceof MySQLDialect)
 				&& !(getDialect() instanceof HSQLDialect)
 				&& !(getDialect() instanceof InterbaseDialect)
 				&& !(getDialect() instanceof PointbaseDialect)
 				&& !(getDialect() instanceof SAPDBDialect) )  {
 			baz.getFooArray()[0] = null;
 			i = s.createQuery( "from Baz baz where ? in elements(baz.fooArray)" )
 					.setParameter( 0, foo, s.getTypeHelper().entity( Foo.class ) )
 					.iterate();
 			assertTrue( !i.hasNext() );
 			baz.getFooArray()[0] = foo;
 			i = s.createQuery( "select foo from Foo foo where foo in (select elt from Baz baz join baz.fooArray elt)" )
 					.iterate();
 			assertTrue( i.hasNext() );
 		}
 		s.delete(foo);
 		s.delete(baz);
 		tx.commit();
 		s.close();
 	}
 
 	@Test
     @RequiresDialect(value = H2Dialect.class, comment = "this is more like a unit test")
 	public void testUserProvidedConnection() throws Exception {
 		ConnectionProvider dcp = ConnectionProviderBuilder.buildConnectionProvider();
 		Session s = sessionFactory().withOptions().connection( dcp.getConnection() ).openSession();
 		Transaction tx = s.beginTransaction();
 		s.createQuery( "from Fo" ).list();
 		tx.commit();
 		Connection c = s.disconnect();
 		assertTrue( c != null );
 		s.reconnect( c );
 		tx = s.beginTransaction();
 		s.createQuery( "from Fo" ).list();
 		tx.commit();
 		assertTrue( s.close() == c );
 		c.close();
 	}
 
 	@Test
 	public void testCachedCollection() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setDefaults();
 		s.save(baz);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		( (FooComponent) baz.getTopComponents().get(0) ).setCount(99);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		assertTrue( ((FooComponent) baz.getTopComponents().get( 0 )).getCount() == 99 );
 		s.delete( baz );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testComplicatedQuery() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		Foo foo = new Foo();
 		Serializable id = s.save(foo);
 		assertTrue( id != null );
 		Qux q = new Qux("q");
 		foo.getDependent().setQux(q);
 		s.save( q );
 		q.getFoo().setString( "foo2" );
 		//s.flush();
 		//s.connection().commit();
 		assertTrue(
 				s.createQuery( "from Foo foo where foo.dependent.qux.foo.string = 'foo2'" ).iterate().hasNext()
 		);
 		s.delete( foo );
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testLoadAfterDelete() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Foo foo = new Foo();
 		Serializable id = s.save(foo);
 		s.flush();
 		s.delete(foo);
 		boolean err=false;
 		try {
 			s.load(Foo.class, id);
 		}
 		catch (ObjectNotFoundException ode) {
 			err=true;
 		}
 		assertTrue(err);
 		s.flush();
 		err=false;
 		try {
 			( (FooProxy) s.load(Foo.class, id) ).getBool();
 		}
 		catch (ObjectNotFoundException onfe) {
 			err=true;
 		}
 		assertTrue(err);
 		id = FumTest.fumKey( "abc" ); //yuck!!
 		Fo fo = Fo.newFo( (FumCompositeID) id );
 		s.save(fo);
 		s.flush();
 		s.delete(fo);
 		err=false;
 		try {
 			s.load(Fo.class, id);
 		}
 		catch (ObjectNotFoundException ode) {
 			err=true;
 		}
 		assertTrue(err);
 		s.flush();
 		err=false;
 		try {
 			s.load(Fo.class, id);
 		}
 		catch (ObjectNotFoundException onfe) {
 			err=true;
 		}
 		assertTrue(err);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testObjectType() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		GlarchProxy g = new Glarch();
 		Foo foo = new Foo();
 		g.setAny( foo );
 		Serializable gid = s.save( g );
 		s.save(foo);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		g = (GlarchProxy) s.load(Glarch.class, gid);
 		assertTrue( g.getAny()!=null && g.getAny() instanceof FooProxy );
 		s.delete( g.getAny() );
 		s.delete( g );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testAny() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		One one = new One();
 		BarProxy foo = new Bar();
 		foo.setObject(one);
 		Serializable fid = s.save(foo);
 		Serializable oid = one.getKey();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		List results = s.createQuery( "from Bar bar where bar.object.id = ? and bar.object.class = ?" )
 				.setParameter( 0, oid, StandardBasicTypes.LONG )
 				.setParameter( 1, new Character('O'), StandardBasicTypes.CHARACTER )
 				.list();
 		assertEquals( 1, results.size() );
 		results = s.createQuery( "select one from One one, Bar bar where bar.object.id = one.id and bar.object.class = 'O'" )
 				.list();
 		assertEquals( 1, results.size() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		foo = (BarProxy) s.load(Foo.class, fid);
 		assertTrue( foo.getObject()!=null && foo.getObject() instanceof One && s.getIdentifier( foo.getObject() ).equals(oid) );
 		//s.delete( foo.getObject() );
 		s.delete(foo);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testEmbeddedCompositeID() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Location l = new Location();
 		l.setCountryCode("AU");
 		l.setDescription("foo bar");
 		l.setLocale( Locale.getDefault() );
 		l.setStreetName("Brunswick Rd");
 		l.setStreetNumber(300);
 		l.setCity("Melbourne");
 		s.save(l);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.setFlushMode(FlushMode.MANUAL);
 		l = (Location) s.createQuery( "from Location l where l.countryCode = 'AU' and l.description='foo bar'" )
 				.list()
 				.get(0);
 		assertTrue( l.getCountryCode().equals("AU") );
 		assertTrue( l.getCity().equals("Melbourne") );
 		assertTrue( l.getLocale().equals( Locale.getDefault() ) );
 		assertTrue( s.createCriteria(Location.class).add( Restrictions.eq( "streetNumber", new Integer(300) ) ).list().size()==1 );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		l.setDescription("sick're");
 		s.update(l);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		l = new Location();
 		l.setCountryCode("AU");
 		l.setDescription("foo bar");
 		l.setLocale(Locale.ENGLISH);
 		l.setStreetName("Brunswick Rd");
 		l.setStreetNumber(300);
 		l.setCity("Melbourne");
 		assertTrue( l==s.load(Location.class, l) );
 		assertTrue( l.getLocale().equals( Locale.getDefault() ) );
 		s.delete(l);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testAutosaveChildren() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Baz baz = new Baz();
 		Set bars = new HashSet();
 		baz.setCascadingBars(bars);
 		s.save(baz);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		baz.getCascadingBars().add( new Bar() );
 		baz.getCascadingBars().add( new Bar() );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		assertTrue( baz.getCascadingBars().size()==2 );
 		assertTrue( baz.getCascadingBars().iterator().next()!=null );
 		baz.getCascadingBars().clear(); //test all-delete-orphan;
 		s.flush();
 		assertTrue( s.createQuery( "from Bar bar" ).list().size()==0 );
 		s.delete(baz);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testOrphanDelete() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Baz baz = new Baz();
 		Set bars = new HashSet();
 		baz.setCascadingBars(bars);
 		bars.add( new Bar() );
 		bars.add( new Bar() );
 		bars.add( new Bar() );
 		bars.add( new Bar() );
 		s.save(baz);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		bars = baz.getCascadingBars();
 		assertEquals( 4, bars.size() );
 		bars.remove( bars.iterator().next() );
 		assertEquals( 3, s.createQuery( "From Bar bar" ).list().size() );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		baz = (Baz) s.load( Baz.class, baz.getCode() );
 		bars = baz.getCascadingBars();
 		assertEquals( 3, bars.size() );
 		bars.remove( bars.iterator().next() );
 		s.delete(baz);
 		bars.remove( bars.iterator().next() );
 		assertEquals( 0, s.createQuery( "From Bar bar" ).list().size() );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testTransientOrphanDelete() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Baz baz = new Baz();
 		Set bars = new HashSet();
 		baz.setCascadingBars(bars);
 		bars.add( new Bar() );
 		bars.add( new Bar() );
 		bars.add( new Bar() );
 		List foos = new ArrayList();
 		foos.add( new Foo() );
 		foos.add( new Foo() );
 		baz.setFooBag(foos);
 		s.save(baz);
 		Iterator i = new JoinedIterator( new Iterator[] {foos.iterator(), bars.iterator()} );
 		while ( i.hasNext() ) {
 			FooComponent cmp = ( (Foo) i.next() ).getComponent();
 			s.delete( cmp.getGlarch() );
 			cmp.setGlarch(null);
 		}
 		t.commit();
 		s.close();
 
 		bars.remove( bars.iterator().next() );
 		foos.remove(1);
 		s = openSession();
 		t = s.beginTransaction();
 		s.update(baz);
 		assertEquals( 2, s.createQuery( "From Bar bar" ).list().size() );
 		assertEquals( 3, s.createQuery( "From Foo foo" ).list().size() );
 		t.commit();
 		s.close();
 
 		foos.remove(0);
 		s = openSession();
 		t = s.beginTransaction();
 		s.update(baz);
 		bars.remove( bars.iterator().next() );
 		assertEquals( 1, s.createQuery( "From Foo foo" ).list().size() );
 		s.delete(baz);
 		//s.flush();
 		assertEquals( 0, s.createQuery( "From Foo foo" ).list().size() );
 		t.commit();
 		s.close();
 	}
 
 	@TestForIssue( jiraKey = "HHH-8662" )
 	public void testProxiesInCollections() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Baz baz = new Baz();
 		Bar bar = new Bar();
 		Bar bar2 = new Bar();
 		s.save(bar);
 		Serializable bar2id = s.save(bar2);
 		baz.setFooArray( new Foo[] { bar, bar2 } );
 		HashSet set = new HashSet();
 		bar = new Bar();
 		s.save(bar);
 		set.add(bar);
 		baz.setFooSet(set);
 		set = new HashSet();
 		set.add( new Bar() );
 		set.add( new Bar() );
 		baz.setCascadingBars(set);
 		ArrayList list = new ArrayList();
 		list.add( new Foo() );
 		baz.setFooBag(list);
 		Serializable id = s.save(baz);
 		Serializable bid = ( (Bar) baz.getCascadingBars().iterator().next() ).getKey();
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		BarProxy barprox = (BarProxy) s.load(Bar.class, bid);
 		BarProxy bar2prox = (BarProxy) s.load(Bar.class, bar2id);
 		assertTrue(bar2prox instanceof HibernateProxy);
 		assertTrue(barprox instanceof HibernateProxy);
 		baz = (Baz) s.load(Baz.class, id);
 		Iterator i = baz.getCascadingBars().iterator();
 		BarProxy b1 = (BarProxy) i.next();
 		BarProxy b2 = (BarProxy) i.next();
 		assertTrue( ( b1==barprox && !(b2 instanceof HibernateProxy) ) || ( b2==barprox && !(b1 instanceof HibernateProxy) ) ); //one-to-many
 		// <many-to-many fetch="select" is deprecated by HHH-8662; so baz.getFooArray()[0] should not be a HibernateProxy.
 		assertFalse( baz.getFooArray()[0] instanceof HibernateProxy ); //many-to-many
 		assertTrue( baz.getFooArray()[1]==bar2prox );
 		if ( !isOuterJoinFetchingDisabled() ) assertTrue( !(baz.getFooBag().iterator().next() instanceof HibernateProxy) ); //many-to-many outer-join="true"
 		assertTrue( !(baz.getFooSet().iterator().next() instanceof HibernateProxy) ); //one-to-many
 		doDelete( s, "from Baz" );
 		doDelete( s, "from Foo" );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testPSCache() throws Exception {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		for ( int i=0; i<10; i++ ) s.save( new Foo() );
 		Query q = s.createQuery("from Foo");
 		q.setMaxResults(2);
 		q.setFirstResult(5);
 		assertTrue( q.list().size()==2 );
 		q = s.createQuery("from Foo");
 		assertTrue( q.list().size()==10 );
 		assertTrue( q.list().size()==10 );
 		q.setMaxResults(3);
 		q.setFirstResult(3);
 		assertTrue( q.list().size()==3 );
 		q = s.createQuery("from Foo");
 		assertTrue( q.list().size()==10 );
 		txn.commit();
 		s.close();
 
 		s = openSession();
 		txn = s.beginTransaction();
 		q = s.createQuery("from Foo");
 		assertTrue( q.list().size()==10 );
 		q.setMaxResults(5);
 		assertTrue( q.list().size()==5 );
 		doDelete( s, "from Foo" );
 		txn.commit();
 		s.close();
 	}
 
 	@Test
 	public void testForCertain() throws Exception {
 		Glarch g = new Glarch();
 		Glarch g2 = new Glarch();
 		List set = new ArrayList();
 		set.add("foo");
 		g2.setStrings(set);
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Serializable gid = s.save(g);
 		Serializable g2id = s.save(g2);
 		t.commit();
 		assertTrue( g.getVersion()==0 );
 		assertTrue( g2.getVersion()==0 );
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		g = (Glarch) s.get(Glarch.class, gid);
 		g2 = (Glarch) s.get(Glarch.class, g2id);
 		assertTrue( g2.getStrings().size()==1 );
 		s.delete(g);
 		s.delete(g2);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testBagMultipleElements() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Baz baz = new Baz();
 		baz.setBag( new ArrayList() );
 		baz.setByteBag( new ArrayList() );
 		s.save(baz);
 		baz.getBag().add("foo");
 		baz.getBag().add("bar");
 		baz.getByteBag().add( "foo".getBytes() );
 		baz.getByteBag().add( "bar".getBytes() );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		//put in cache
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertTrue( baz.getBag().size()==2 );
 		assertTrue( baz.getByteBag().size()==2 );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		baz = (Baz) s.get( Baz.class, baz.getCode() );
 		assertTrue( baz.getBag().size()==2 );
 		assertTrue( baz.getByteBag().size()==2 );
 		baz.getBag().remove("bar");
  		baz.getBag().add("foo");
  		baz.getByteBag().add( "bar".getBytes() );
 		t.commit();
 		s.close();
 
  		s = openSession();
  		t = s.beginTransaction();
  		baz = (Baz) s.get( Baz.class, baz.getCode() );
  		assertTrue( baz.getBag().size()==2 );
  		assertTrue( baz.getByteBag().size()==3 );
  		s.delete(baz);
  		t.commit();
  		s.close();
  	}
 
 	@Test
 	public void testWierdSession() throws Exception {
  		Session s = openSession();
  		Transaction t = s.beginTransaction();
  		Serializable id =  s.save( new Foo() );
  		t.commit();
  		s.close();
 
  		s = openSession();
  		s.setFlushMode(FlushMode.MANUAL);
 		t = s.beginTransaction();
 		Foo foo = (Foo) s.get(Foo.class, id);
 		t.commit();
 
 		t = s.beginTransaction();
 		s.flush();
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		foo = (Foo) s.get(Foo.class, id);
 		s.delete(foo);
 		t.commit();
 		s.close();
 	}
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/legacy/MultiTableTest.java b/hibernate-core/src/test/java/org/hibernate/test/legacy/MultiTableTest.java
index 759a1d21b5..f54d6a6fbf 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/legacy/MultiTableTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/legacy/MultiTableTest.java
@@ -1,677 +1,677 @@
 //$Id: MultiTableTest.java 10977 2006-12-12 23:28:04Z steve.ebersole@jboss.com $
 package org.hibernate.test.legacy;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertSame;
 import static org.junit.Assert.assertTrue;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.ArrayList;
 import java.util.Date;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
 
 import org.hibernate.Criteria;
 import org.hibernate.FetchMode;
 import org.hibernate.LockMode;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.criterion.Restrictions;
 import org.hibernate.dialect.AbstractHANADialect;
 import org.hibernate.dialect.MySQLDialect;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
 import org.junit.Test;
 
 
 public class MultiTableTest extends LegacyTestCase {
 	@Override
 	protected boolean isCleanupTestDataRequired() {
 		return true;
 	}
 	@Override
 	public String[] getMappings() {
 		return new String[] { "legacy/Multi.hbm.xml", "legacy/MultiExtends.hbm.xml" };
 	}
 
 	@Test
 	public void testCriteria() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Lower l = new Lower();
 		s.save(l);
 		assertTrue( l==s.createCriteria(Top.class).uniqueResult() );
 		s.delete(l);
 		s.flush();
 		Criteria c = s.createCriteria(Lower.class);
 		c.createCriteria("yetanother")
 			.add( Restrictions.isNotNull("id") )
 			.createCriteria("another");
 		c.createCriteria("another").add( Restrictions.isNotNull("id") );
 		c.list();
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testFetchOneToMany() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		s.createCriteria(Po.class).setFetchMode("set", FetchMode.JOIN).list();
 		s.createCriteria(Po.class).setFetchMode("list", FetchMode.JOIN).list();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testNarrow() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery("from Po po, Lower low where low.mypo = po").list();
 		s.createQuery("from Po po join po.set as sm where sm.amount > 0").list();
 		s.createQuery("from Po po join po.top as low where low.foo = 'po'").list();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testJoins() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		s.createQuery( "from Lower l join l.yetanother l2 where lower(l2.name) > 'a'" ).list();
 		s.createQuery( "from Lower l where lower(l.yetanother.top.name) > 'a'" ).list();
 		s.createQuery( "from SubMulti sm join sm.children smc where smc.name > 'a'" ).list();
 		s.createQuery( "select s, ya from Lower s join s.yetanother ya" ).list();
 		s.createQuery( "from Lower s1 join s1.bag s2" ).list();
 		s.createQuery( "from Lower s1 left join s1.bag s2" ).list();
 		s.createQuery( "select s, a from Lower s join s.another a" ).list();
 		s.createQuery( "select s, a from Lower s left join s.another a" ).list();
 		s.createQuery( "from Top s, Lower ls" ).list();
 		s.createQuery( "from Lower ls join ls.set s where s.name > 'a'" ).list();
 		s.createQuery( "from Po po join po.list sm where sm.name > 'a'" ).list();
 		s.createQuery( "from Lower ls inner join ls.another s where s.name is not null" ).list();
 		s.createQuery( "from Lower ls where ls.other.another.name is not null" ).list();
 		s.createQuery( "from Multi m where m.derived like 'F%'" ).list();
 		s.createQuery( "from SubMulti m where m.derived like 'F%'" ).list();
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testSubclassCollection() throws Exception {
 		//if ( getDialect() instanceof HSQLDialect ) return; //TODO: figure out why!?
 		Session s = openSession();
 		s.beginTransaction();
 		SubMulti sm = new SubMulti();
 		SubMulti sm1 = new SubMulti();
 		SubMulti sm2 = new SubMulti();
 		ArrayList list = new ArrayList();
 		ArrayList anotherList = new ArrayList();
 		sm.setChildren(list);
 		sm.setMoreChildren(anotherList);
 		sm.setExtraProp("foo");
 		list.add(sm1);
 		list.add(sm2);
 		anotherList.add(sm1);
 		anotherList.add(sm2);
 		sm1.setParent(sm);
 		sm2.setParent(sm);
 		Serializable id = s.save(sm);
 		s.save(sm1);
 		s.save(sm2);
 		s.getTransaction().commit();
 		s.close();
 
 		sessionFactory().evict(SubMulti.class);
 
 		final Session s2 = openSession();
 		s2.beginTransaction();
 		s2.doWork(
 				new Work() {
 					@Override
 					public void execute(Connection connection) throws SQLException {
 						final String sql = "select * from leafsubsubclass sm, nonleafsubclass m, rootclass s " +
 								"where sm.sid=m.sid and sm.sid=s.id1_ and sm.sid=1";
-						Statement st = ((SessionImplementor)s2).getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().createStatement();
-						((SessionImplementor)session).getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st, sql ).next();
+						Statement st = ((SessionImplementor)s2).getJdbcCoordinator().getStatementPreparer().createStatement();
+						((SessionImplementor)session).getJdbcCoordinator().getResultSetReturn().extract( st, sql ).next();
 					}
 				}
 		);
 		assertTrue(
 				s2.createQuery(
 						"select s from SubMulti as sm join sm.children as s where s.amount>-1 and s.name is null"
 				).list().size()==2 );
 		s2.createQuery( "select c from SubMulti sm join sm.children c" ).list();
 		assertTrue( s2.createQuery( "select elements(sm.children) from SubMulti as sm" ).list().size()==2 );
 		assertTrue(
 				s2.createQuery(
 						"select distinct sm from SubMulti as sm join sm.children as s where s.amount>-1 and s.name is null"
 				).list().size()==1 );
 		sm = (SubMulti) s2.load(SubMulti.class, id);
 		assertTrue( sm.getChildren().size()==2 );
 		assertEquals(
 			s2.createFilter( sm.getMoreChildren(), "select count(*) where this.amount>-1 and this.name is null" ).list().get(0),
 			new Long(2)
 		);
 		assertEquals( "FOO", sm.getDerived() );
 		assertSame(
 				s2.createQuery( "select distinct s from SubMulti s where s.moreChildren[1].amount < 1.0" ).iterate().next(),
 			sm
 		);
 		assertTrue( sm.getMoreChildren().size()==2 );
 		s2.delete(sm);
 		Iterator iter = sm.getChildren().iterator();
 		while ( iter.hasNext() ) {
 			s2.delete( iter.next() );
 		}
 		s2.flush();
 		s2.getTransaction().commit();
 		s2.close();
 
 	}
 
 	@Test
 	public void testCollectionOnly() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Mono m = new Mono();
 		Long id = (Long) s.save(m);
 		t.commit();
 		s.close();
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( m );
 		s.flush();
 		m.setAddress("foo bar");
 		s.flush();
 		s.delete(m);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testQueries() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Long id = ( Long ) s.save( new TrivialClass() );
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		TrivialClass tc = (TrivialClass) s.load(TrivialClass.class, id);
 		s.createQuery( "from TrivialClass s where s.id = 2" ).list();
 		s.createQuery( "select t.count from Top t" ).list();
 		s.createQuery( "from Lower s where s.another.name='name'" ).list();
 		s.createQuery( "from Lower s where s.yetanother.name='name'" ).list();
 		s.createQuery( "from Lower s where s.yetanother.name='name' and s.yetanother.foo is null" ).list();
 		s.createQuery( "from Top s where s.count=1" ).list();
 		s.createQuery( "select s.count from Top s, Lower ls where ls.another=s" ).list();
 		s.createQuery( "select elements(ls.bag), elements(ls.set) from Lower ls" ).list();
 		s.createQuery( "from Lower" ).iterate();
 		s.createQuery( "from Top" ).iterate();
 		s.delete(tc);
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testConstraints() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		SubMulti sm = new SubMulti();
 		sm.setAmount(66.5f);
 		s.save( sm );
 		t.commit();
 		s.close();
 
 		s = openSession();
 //		doDelete( s, "from SubMulti" );
 //		t = s.beginTransaction();
 		t = s.beginTransaction();
 		doDelete( s, "from SubMulti" );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testMultiTable() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Multi multi = new Multi();
 		multi.setExtraProp("extra");
 		multi.setName("name");
 		Top simp = new Top();
 		simp.setDate( new Date() );
 		simp.setName("simp");
 
 		Serializable mid = s.save(multi);
 		Serializable sid = s.save(simp);
 
 		SubMulti sm = new SubMulti();
 		sm.setAmount(66.5f);
 		Serializable smid = s.save(sm);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		multi.setExtraProp( multi.getExtraProp() + "2" );
 		//multi.setCount( multi.getCount() + 1 );
 		multi.setName("new name");
 		s.update( multi );
 		simp.setName("new name");
 		s.update( simp );
 		sm.setAmount(456.7f);
 		s.update( sm );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		multi = (Multi) s.load(Multi.class, mid);
 		assertTrue( multi.getExtraProp().equals("extra2") );
 		multi.setExtraProp( multi.getExtraProp() + "3" );
 		//multi.setCount( multi.getCount() + 1 );
 		assertTrue( multi.getName().equals("new name") );
 		multi.setName("newer name");
 		sm = (SubMulti) s.load(SubMulti.class, smid);
 		assertTrue( sm.getAmount()==456.7f );
 		sm.setAmount(23423f);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		multi = (Multi) s.load(Top.class, mid);
 		simp = (Top) s.load(Top.class, sid);
 		assertTrue( ! (simp instanceof Multi) );
 		assertTrue( multi.getExtraProp().equals("extra23") );
 		//multi.setCount( multi.getCount() + 1 );
 		assertTrue( multi.getName().equals("newer name") );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Iterator iter = s.createQuery( "select\n\nt from Top t where t.count>0" ).iterate();
 		boolean foundSimp = false;
 		boolean foundMulti = false;
 		boolean foundSubMulti = false;
 		while ( iter.hasNext() ) {
 			Object o = iter.next();
 			if ( ( o instanceof Top ) && !( o instanceof Multi) ) foundSimp = true;
 			if ( o instanceof Multi && !(o instanceof SubMulti) ) foundMulti = true;
 			if ( o instanceof SubMulti ) foundSubMulti = true;
 		}
 		assertTrue( foundSimp&&foundMulti&&foundSubMulti );
 		s.createQuery( "from Multi m where m.count>0 and m.extraProp is not null" ).list();
 		s.createQuery( "from Top m where m.count>0 and m.name is not null" ).list();
 		s.createQuery( "from Lower m where m.other is not null" ).list();
 		s.createQuery( "from Multi m where m.other.id = 1" ).list();
 		s.createQuery( "from SubMulti m where m.amount > 0.0" ).list();
 
 		assertTrue(
 				s.createQuery( "from Multi" ).list().size()==2
 		);
 		assertTrue(
 				s.createQuery( "from Multi m where m.class = SubMulti" ).list().size()==1
 		);
 		assertTrue(
 				s.createQuery( "from Top m where m.class = Multi" ).list().size()==1
 		);
 		assertTrue(
 				s.createQuery( "from Top" ).list().size()==3
 		);
 		assertTrue(
 				s.createQuery( "from Lower" ).list().size()==0
 		);
 		assertTrue(
 				s.createQuery( "from SubMulti" ).list().size()==1
 		);
 
 		s.createQuery( "from Lower ls join ls.bag s where s.id is not null" ).list();
 		s.createQuery( "from Lower ls join ls.set s where s.id is not null" ).list();
 		if ( !(getDialect() instanceof MySQLDialect) )
 			s.createQuery( "from SubMulti sm where exists elements(sm.children)" ).list();
 
 		List l = s.createCriteria(Top.class).list();
 		assertTrue( l.size()==3 );
 		assertTrue( s.createCriteria(SubMulti.class).list().size()==1 );
 		assertTrue(
 			s.createCriteria(SubMulti.class)
 				.add( Restrictions.lt("amount", new Float(0)) )
 				.list()
 				.size()==0
 		);
 		assertTrue(
 			s.createCriteria(SubMulti.class)
 				.add( Restrictions.ge("amount", new Float(0)) )
 				.list()
 				.size()==1
 		);
 
 		t.commit();
 		s.close();
 
 		// HANA currently requires specifying table name by 'FOR UPDATE of t1.c1'
 		// if there are more than one tables/views/subqueries in the FROM clause
 		if ( !( getDialect() instanceof AbstractHANADialect ) ) {
 			s = openSession();
 			t = s.beginTransaction();
 			multi = (Multi) s.load( Top.class, mid, LockMode.UPGRADE );
 			simp = (Top) s.load( Top.class, sid );
 			s.lock( simp, LockMode.UPGRADE_NOWAIT );
 			t.commit();
 			s.close();
 		}
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update(multi);
 		s.delete(multi);
 		assertEquals( 2, doDelete( s, "from Top" ) );
 		t.commit();
 		s.close();
 
 	}
 
 	@Test
 	public void testMultiTableGeneratedId() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Multi multi = new Multi();
 		multi.setExtraProp("extra");
 		//multi.setCount(666);
 		multi.setName("name");
 		Top simp = new Top();
 		simp.setDate( new Date() );
 		simp.setName("simp");
 		//simp.setCount(132);
 		Serializable multiId = s.save( multi );
 		Serializable simpId = s.save( simp );
 		SubMulti sm = new SubMulti();
 		sm.setAmount(66.5f);
 		Serializable smId = s.save( sm );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		multi.setExtraProp( multi.getExtraProp() + "2" );
 		//multi.setCount( multi.getCount() + 1 );
 		multi.setName("new name");
 		s.update( multi );
 		simp.setName("new name");
 		s.update( simp );
 		sm.setAmount(456.7f);
 		s.update( sm );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		multi = (Multi) s.load( Multi.class, multiId );
 		assertTrue( multi.getExtraProp().equals("extra2") );
 		multi.setExtraProp( multi.getExtraProp() + "3" );
 		//multi.setCount( multi.getCount() + 1 );
 		assertTrue( multi.getName().equals("new name") );
 		multi.setName("newer name");
 		sm = (SubMulti) s.load( SubMulti.class, smId );
 		assertTrue( sm.getAmount()==456.7f );
 		sm.setAmount(23423f);
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		multi = (Multi) s.load( Top.class, multiId );
 		simp = (Top) s.load( Top.class, simpId );
 		assertTrue( ! (simp instanceof Multi) );
 		assertTrue( multi.getExtraProp().equals("extra23") );
 		//multi.setCount( multi.getCount() + 1 );
 		assertTrue( multi.getName().equals("newer name") );
 		t.commit();
 		s.close();
 
 		s = openSession();
 		t = s.beginTransaction();
 		Iterator iter = s.createQuery( "select\n\nt from Top t where t.count>0" ).iterate();
 		boolean foundSimp = false;
 		boolean foundMulti = false;
 		boolean foundSubMulti = false;
 		while ( iter.hasNext() ) {
 			Object o = iter.next();
 			if ( ( o instanceof Top ) && !( o instanceof Multi) ) foundSimp = true;
 			if ( o instanceof Multi && !(o instanceof SubMulti) ) foundMulti = true;
 			if ( o instanceof SubMulti ) foundSubMulti = true;
 		}
 		assertTrue( foundSimp&&foundMulti&&foundSubMulti );
 		s.createQuery( "from Multi m where m.count>0 and m.extraProp is not null" ).list();
 		s.createQuery( "from Top m where m.count>0 and m.name is not null" ).list();
 		s.createQuery( "from Lower m where m.other is not null" ).list();
 		s.createQuery( "from Multi m where m.other.id = 1" ).list();
 		s.createQuery( "from SubMulti m where m.amount > 0.0" ).list();
 
 		assertTrue(
 				s.createQuery( "from Multi" ).list().size()==2
 		);
 		/*assertTrue(
 			s.find("from m in class Multi where m.class = Multi").size()==1
 		);*/
 		assertTrue(
 				s.createQuery( "from Top" ).list().size()==3
 		);
 		assertTrue(
 				s.createQuery( "from Lower" ).list().size()==0
 		);
 		assertTrue(
 				s.createQuery( "from SubMulti" ).list().size()==1
 		);
 
 		s.createQuery( "from Lower ls join ls.bag s where s.id is not null" ).list();
 		if ( !(getDialect() instanceof MySQLDialect) )
 			s.createQuery( "from SubMulti sm where exists elements(sm.children)" ).list();
 
 		t.commit();
 		s.close();
 
 		// HANA currently requires specifying table name by 'FOR UPDATE of t1.c1'
 		// if there are more than one tables/views/subqueries in the FROM clause
 		if ( !( getDialect() instanceof AbstractHANADialect ) ) {
 			s = openSession();
 			t = s.beginTransaction();
 			multi = (Multi) s.load( Top.class, multiId, LockMode.UPGRADE );
 			simp = (Top) s.load( Top.class, simpId );
 			s.lock( simp, LockMode.UPGRADE_NOWAIT );
 			t.commit();
 			s.close();
 		}
 
 		s = openSession();
 		t = s.beginTransaction();
 		s.update( multi );
 		s.delete(multi);
 		assertEquals( 2, doDelete( s, "from Top" ) );
 		t.commit();
 		s.close();
 
 	}
 
 	@Test
 	public void testMultiTableCollections() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		assertTrue( s.createQuery( "from Top" ).list().size()==0 );
 		Multi multi = new Multi();
 		multi.setExtraProp("extra");
 		multi.setName("name");
 		Top simp = new Top();
 		simp.setDate( new Date() );
 		simp.setName("simp");
 
 		s.save(multi);
 		s.save(simp);
 
 		Lower ls = new Lower();
 		ls.setOther(ls);
 		ls.setAnother(ls);
 		ls.setYetanother(ls);
 		ls.setName("Less Simple");
 		Set set = new HashSet();
 		ls.setSet(set);
 		set.add(multi);
 		set.add(simp);
 		Serializable id = s.save(ls);
 		t.commit();
 		s.close();
 		assertTrue( ls.getOther()==ls && ls.getAnother()==ls && ls.getYetanother()==ls );
 
 		s = openSession();
 		t = s.beginTransaction();
 		ls = (Lower) s.load(Lower.class, id);
 		assertTrue( ls.getOther()==ls && ls.getAnother()==ls && ls.getYetanother()==ls );
 		assertTrue( ls.getSet().size()==2 );
 		Iterator iter = ls.getSet().iterator();
 		int foundMulti = 0;
 		int foundSimple = 0;
 		while ( iter.hasNext() ) {
 			Object o = iter.next();
 			if ( o instanceof Top ) foundSimple++;
 			if ( o instanceof Multi ) foundMulti++;
 		}
 		assertTrue( foundSimple==2 && foundMulti==1 );
 		assertEquals( 3, doDelete( s, "from Top" ) );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testMultiTableManyToOne() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		assertTrue( s.createQuery( "from Top" ).list().size()==0 );
 		Multi multi = new Multi();
 		multi.setExtraProp("extra");
 		multi.setName("name");
 		Top simp = new Top();
 		simp.setDate( new Date() );
 		simp.setName("simp");
 		s.save(multi);
 		Lower ls = new Lower();
 		ls.setOther(ls);
 		ls.setAnother(multi);
 		ls.setYetanother(ls);
 		ls.setName("Less Simple");
 		Serializable id = s.save(ls);
 		t.commit();
 		s.close();
 		assertTrue( ls.getOther()==ls && ls.getAnother()==multi && ls.getYetanother()==ls );
 
 		s = openSession();
 		t = s.beginTransaction();
 		ls = (Lower) s.load(Lower.class, id);
 		assertTrue( ls.getOther()==ls && ls.getYetanother()==ls );
 		assertTrue( ls.getAnother().getName().equals("name") && ls.getAnother() instanceof Multi );
 		s.delete(ls);
 		s.delete( ls.getAnother() );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testMultiTableNativeId() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Multi multi = new Multi();
 		multi.setExtraProp("extra");
 		Long id = (Long) s.save(multi);
 		assertTrue( id!=null );
 		s.delete(multi);
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testCollection() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Multi multi1 = new Multi();
 		multi1.setExtraProp("extra1");
 		Multi multi2 = new Multi();
 		multi2.setExtraProp("extra2");
 		Po po = new Po();
 		multi1.setPo(po); multi2.setPo(po);
 		po.setSet( new HashSet() );
 		po.getSet().add(multi1);
 		po.getSet().add(multi2);
 		po.setList( new ArrayList() );
 		//po.getList().add(null);
 		po.getList().add( new SubMulti() );
 		Serializable id = s.save(po);
 		assertTrue( id!=null );
 		t.commit();
 		s.close();
 		s = openSession();
 		t = s.beginTransaction();
 		po = (Po) s.load(Po.class, id);
 		assertTrue( po.getSet().size()==2 );
 		assertTrue( po.getList().size()==1 );
 		s.delete(po);
 		assertTrue( s.createQuery( "from Top" ).list().size()==0 );
 		t.commit();
 		s.close();
 	}
 
 	@Test
 	public void testOneToOne() throws Exception {
 		Session s = openSession();
 		s.beginTransaction();
 		Lower ls = new Lower();
 		Serializable id = s.save(ls);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.load(Lower.class, id);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 		s.delete( s.load(Lower.class, id) );
 		s.getTransaction().commit();
 		s.close();
 	}
 
 	@Test
 	public void testCollectionPointer() throws Exception {
 		Session sess = openSession();
 		sess.beginTransaction();
 		Lower ls = new Lower();
 		List list = new ArrayList();
 		ls.setBag(list);
 		Top s = new Top();
 		Serializable id = sess.save(ls);
 		sess.save(s);
 		sess.flush();
 		list.add(s);
 		sess.getTransaction().commit();
 		sess.close();
 
 		sess = openSession();
 		sess.beginTransaction();
 		ls = (Lower) sess.load(Lower.class, id);
 		assertTrue( ls.getBag().size()==1 );
 		doDelete( sess, "from java.lang.Object" );
 		sess.getTransaction().commit();
 		sess.close();
 	}
 
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/mixed/DocumentInterceptor.java b/hibernate-core/src/test/java/org/hibernate/test/mixed/DocumentInterceptor.java
index d7818265b0..368bd9049b 100755
--- a/hibernate-core/src/test/java/org/hibernate/test/mixed/DocumentInterceptor.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/mixed/DocumentInterceptor.java
@@ -1,116 +1,120 @@
 //$Id: DocumentInterceptor.java 8670 2005-11-25 17:36:29Z epbernard $
 package org.hibernate.test.mixed;
 
 import java.io.Serializable;
 import java.util.Calendar;
 import java.util.Iterator;
 
 import org.hibernate.CallbackException;
 import org.hibernate.EntityMode;
 import org.hibernate.Interceptor;
 import org.hibernate.Transaction;
 import org.hibernate.type.Type;
 
 /**
  * @author Gavin King
  */
 public class DocumentInterceptor implements Interceptor {
 
 
 	public boolean onLoad(
 			Object entity, Serializable id, Object[] state,
 			String[] propertyNames, Type[] types
 	) throws CallbackException {
 		return false;
 	}
 
 	public boolean onFlushDirty(
 			Object entity, Serializable id,
 			Object[] currentState, Object[] previousState,
 			String[] propertyNames, Type[] types
 	) throws CallbackException {
 		if ( entity instanceof Document ) {
 			currentState[3] = Calendar.getInstance();
 			return true;
 		}
 		else {
 			return false;
 		}
 	}
 
 	public boolean onSave(
 			Object entity, Serializable id, Object[] state,
 			String[] propertyNames, Type[] types
 	) throws CallbackException {
 		if ( entity instanceof Document ) {
 			state[4] = state[3] = Calendar.getInstance();
 			return true;
 		}
 		else {
 			return false;
 		}
 	}
 
 	public void onDelete(
 			Object entity, Serializable id, Object[] state,
 			String[] propertyNames, Type[] types
 	) throws CallbackException {
 
 	}
 
 	public void preFlush(Iterator entities) throws CallbackException {
 
 	}
 
 	public void postFlush(Iterator entities) throws CallbackException {
 
 	}
 
 	public Boolean isTransient(Object entity) {
 		return null;
 	}
 
 	public int[] findDirty(
 			Object entity, Serializable id,
 			Object[] currentState, Object[] previousState,
 			String[] propertyNames, Type[] types
 	) {
 		return null;
 	}
 
 	public Object instantiate(String entityName, EntityMode entityMode, Serializable id) throws CallbackException {
 		return null;
 	}
 
 	public String getEntityName(Object object) throws CallbackException {
 		return null;
 	}
 
 	public Object getEntity(String entityName, Serializable id)
 			throws CallbackException {
 		return null;
 	}
 
 	public void afterTransactionBegin(Transaction tx) {
 	}
 
 	public void afterTransactionCompletion(Transaction tx) {
 	}
 
 	public void beforeTransactionCompletion(Transaction tx) {
 	}
 
 	public String onPrepareStatement(String sql) {
 		return sql;
 	}
 
 	public void onCollectionRecreate(Object collection, Serializable key) throws CallbackException {
 	}
 
 	public void onCollectionRemove(Object collection, Serializable key) throws CallbackException {
 	}
 
 	public void onCollectionUpdate(Object collection, Serializable key) throws CallbackException {
 	}
 
+	@Override
+	public String inspect(String sql) {
+		return sql;
+	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/ops/CreateTest.java b/hibernate-core/src/test/java/org/hibernate/test/ops/CreateTest.java
index 8a266493f7..dacdf0c60d 100755
--- a/hibernate-core/src/test/java/org/hibernate/test/ops/CreateTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/ops/CreateTest.java
@@ -1,241 +1,245 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.ops;
 
 import java.util.ArrayList;
 import java.util.Collection;
 
 import org.junit.Test;
 
 import org.hibernate.PersistentObjectException;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
+import org.hibernate.TransactionException;
 import org.hibernate.exception.ConstraintViolationException;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author Gavin King
  */
 public class CreateTest extends AbstractOperationTestCase {
 	@Test
 	@SuppressWarnings( {"unchecked"})
 	public void testNoUpdatesOnCreateVersionedWithCollection() {
 		clearCounts();
 
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		VersionedEntity root = new VersionedEntity( "root", "root" );
 		VersionedEntity child = new VersionedEntity( "c1", "child-1" );
 		root.getChildren().add( child );
 		child.setParent( root );
 		s.save(root);
 		tx.commit();
 		s.close();
 
 		assertInsertCount( 2 );
 		assertUpdateCount( 0 );
 		assertDeleteCount( 0 );
 
 		s = openSession();
 		tx = s.beginTransaction();
 		s.delete( root );
 		tx.commit();
 		s.close();
 
 		assertUpdateCount( 0 );
 		assertDeleteCount( 2 );
 	}
 
 	@Test
 	public void testCreateTree() {
 		clearCounts();
 
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Node root = new Node("root");
 		Node child = new Node("child");
 		root.addChild(child);
 		s.persist(root);
 		tx.commit();
 		s.close();
 
 		assertInsertCount(2);
 		assertUpdateCount(0);
 
 		s = openSession();
 		tx = s.beginTransaction();
 		System.out.println("getting");
 		root = (Node) s.get(Node.class, "root");
 		Node child2 = new Node("child2");
 		root.addChild(child2);
 		System.out.println("committing");
 		tx.commit();
 		s.close();
 
 		assertInsertCount(3);
 		assertUpdateCount(0);
 	}
 
 	@Test
 	public void testCreateTreeWithGeneratedId() {
 		clearCounts();
 
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		NumberedNode root = new NumberedNode("root");
 		NumberedNode child = new NumberedNode("child");
 		root.addChild(child);
 		s.persist(root);
 		tx.commit();
 		s.close();
 
 		assertInsertCount(2);
 		assertUpdateCount(0);
 
 		s = openSession();
 		tx = s.beginTransaction();
 		root = (NumberedNode) s.get( NumberedNode.class, Long.valueOf( root.getId() ) );
 		NumberedNode child2 = new NumberedNode("child2");
 		root.addChild(child2);
 		tx.commit();
 		s.close();
 
 		assertInsertCount(3);
 		assertUpdateCount(0);
 	}
 
 	@Test
 	public void testCreateException() {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		Node dupe = new Node("dupe");
 		s.persist(dupe);
 		s.persist(dupe);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		s.persist(dupe);
 		try {
 			tx.commit();
 			fail( "Expecting constraint failure" );
 		}
-		catch (ConstraintViolationException cve) {
+		catch (TransactionException te) {
 			//verify that an exception is thrown!
+			assertTrue( te.getCause() instanceof  ConstraintViolationException);
 		}
 		tx.rollback();
 		s.close();
 
 		Node nondupe = new Node("nondupe");
 		nondupe.addChild(dupe);
 
 		s = openSession();
 		tx = s.beginTransaction();
 		s.persist(nondupe);
 		try {
 			tx.commit();
 			assertFalse(true);
 		}
-		catch (ConstraintViolationException cve) {
+		catch (TransactionException te) {
 			//verify that an exception is thrown!
+			assertTrue( te.getCause() instanceof  ConstraintViolationException);
 		}
 		tx.rollback();
 		s.close();
 	}
 
 	@Test
 	public void testCreateExceptionWithGeneratedId() {
 		Session s = openSession();
 		Transaction tx = s.beginTransaction();
 		NumberedNode dupe = new NumberedNode("dupe");
 		s.persist(dupe);
 		s.persist(dupe);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		try {
 			s.persist(dupe);
 			assertFalse(true);
 		}
 		catch (PersistentObjectException poe) {
 			//verify that an exception is thrown!
 		}
 		tx.rollback();
 		s.close();
 
 		NumberedNode nondupe = new NumberedNode("nondupe");
 		nondupe.addChild(dupe);
 
 		s = openSession();
 		tx = s.beginTransaction();
 		try {
 			s.persist(nondupe);
 			assertFalse(true);
 		}
 		catch (PersistentObjectException poe) {
 			//verify that an exception is thrown!
 		}
 		tx.rollback();
 		s.close();
 	}
 
 	@Test
 	@SuppressWarnings( {"unchecked"})
 	public void testBasic() throws Exception {
 		Session s;
 		Transaction tx;
 		s = openSession();
 		tx = s.beginTransaction();
 		Employer er = new Employer();
 		Employee ee = new Employee();
 		s.persist(ee);
 		Collection erColl = new ArrayList();
 		Collection eeColl = new ArrayList();
 		erColl.add(ee);
 		eeColl.add(er);
 		er.setEmployees(erColl);
 		ee.setEmployers(eeColl);
 		tx.commit();
 		s.close();
 
 		s = openSession();
 		tx = s.beginTransaction();
 		er = (Employer) s.load(Employer.class, er.getId() );
 		assertNotNull(er);
 		assertNotNull( er.getEmployees() );
 		assertEquals( 1, er.getEmployees().size() );
 		Employee eeFromDb = (Employee) er.getEmployees().iterator().next();
 		assertEquals( ee.getId(), eeFromDb.getId() );
 		tx.commit();
 		s.close();
 	}
 }
 
diff --git a/hibernate-core/src/test/java/org/hibernate/test/rowid/RowIdTest.java b/hibernate-core/src/test/java/org/hibernate/test/rowid/RowIdTest.java
index a85a0f3ad5..59dc8ddd29 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/rowid/RowIdTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/rowid/RowIdTest.java
@@ -1,108 +1,108 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.rowid;
 
 import java.math.BigDecimal;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.sql.Statement;
 
 import org.junit.Test;
 
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.dialect.Oracle9iDialect;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
 import org.hibernate.testing.RequiresDialect;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 /**
  * @author Gavin King
  */
 @RequiresDialect( value = Oracle9iDialect.class )
 public class RowIdTest extends BaseCoreFunctionalTestCase {
 	public String[] getMappings() {
 		return new String[] { "rowid/Point.hbm.xml" };
 	}
 
 	public String getCacheConcurrencyStrategy() {
 		return null;
 	}
 
 	public boolean createSchema() {
 		return false;
 	}
 
 	public void afterSessionFactoryBuilt() {
 		super.afterSessionFactoryBuilt();
 		final Session session = sessionFactory().openSession();
 		session.doWork(
 				new Work() {
 					@Override
 					public void execute(Connection connection) throws SQLException {
-						Statement st = ((SessionImplementor)session).getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().createStatement();
+						Statement st = ((SessionImplementor)session).getJdbcCoordinator().getStatementPreparer().createStatement();
 						try {
-							((SessionImplementor)session).getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().execute( st, "drop table Point");
+							((SessionImplementor)session).getJdbcCoordinator().getResultSetReturn().execute( st, "drop table Point");
 						}
 						catch (Exception ignored) {
 						}
-						((SessionImplementor)session).getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().execute( st, "create table Point (\"x\" number(19,2) not null, \"y\" number(19,2) not null, description varchar2(255) )");
-						((SessionImplementor)session).getTransactionCoordinator().getJdbcCoordinator().release( st );
+						((SessionImplementor)session).getJdbcCoordinator().getResultSetReturn().execute( st, "create table Point (\"x\" number(19,2) not null, \"y\" number(19,2) not null, description varchar2(255) )");
+						((SessionImplementor)session).getJdbcCoordinator().getResourceRegistry().release( st );
 					}
 				}
 		);
 		session.close();
 	}
 
 	@Test
 	public void testRowId() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Point p = new Point( new BigDecimal(1.0), new BigDecimal(1.0) );
 		s.persist(p);
 		t.commit();
 		s.clear();
 		
 		t = s.beginTransaction();
 		p = (Point) s.createCriteria(Point.class).uniqueResult();
 		p.setDescription("new desc");
 		t.commit();
 		s.clear();
 		
 		t = s.beginTransaction();
 		p = (Point) s.createQuery("from Point").uniqueResult();
 		p.setDescription("new new desc");
 		t.commit();
 		s.clear();
 		
 		t = s.beginTransaction();
 		p = (Point) s.get(Point.class, p);
 		p.setDescription("new new new desc");
 		t.commit();
 		s.close();
 	}
 
 }
 
diff --git a/hibernate-core/src/test/java/org/hibernate/test/sql/autodiscovery/AutoDiscoveryTest.java b/hibernate-core/src/test/java/org/hibernate/test/sql/autodiscovery/AutoDiscoveryTest.java
index 6ba2115086..a4df73778c 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/sql/autodiscovery/AutoDiscoveryTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/sql/autodiscovery/AutoDiscoveryTest.java
@@ -1,157 +1,157 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.sql.autodiscovery;
 
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.ResultSetMetaData;
 import java.sql.SQLException;
 import java.util.List;
 
 import org.hibernate.Session;
 import org.hibernate.boot.model.naming.ImplicitNamingStrategyJpaCompliantImpl;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
 import org.hibernate.loader.custom.NonUniqueDiscoveredSqlAliasException;
 
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.junit.Assert;
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 
 /**
  * @author Steve Ebersole
  */
 public class AutoDiscoveryTest extends BaseCoreFunctionalTestCase {
 	private static final String QUERY_STRING =
 			"select u.name as username, g.name as groupname, m.joindate " +
 					"from t_membership m " +
 					"        inner join t_user u on m.member_id = u.id " +
 					"        inner join t_group g on m.group_id = g.id";
 
 	@Override
 	protected void configure(Configuration configuration) {
 		super.configure( configuration );
 		configuration.setImplicitNamingStrategy( ImplicitNamingStrategyJpaCompliantImpl.INSTANCE );
 	}
 
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[] { Group.class, User.class, Membership.class };
 	}
 
 	@Test( expected = NonUniqueDiscoveredSqlAliasException.class )
 	public void testAutoDiscoveryWithDuplicateColumnLabels() {
 		Session session = openSession();
 		session.beginTransaction();
 		session.save( new User( "steve" ) );
 		session.save( new User( "stliu" ) );
 		session.getTransaction().commit();
 		session.close();
 
 		session = openSession();
 		session.beginTransaction();
 		List results = session.createSQLQuery( "select u.name, u2.name from t_user u, t_user u2 where u.name='steve'" ).list();
 		// this should result in a result set like:
 		//   [0] steve, steve
 		//   [1] steve, stliu
 		// although the rows could be reversed
 		assertEquals( 2, results.size() );
 		final Object[] row1 = (Object[]) results.get( 0 );
 		final Object[] row2 = (Object[]) results.get( 1 );
 		assertEquals( "steve", row1[0] );
 		assertEquals( "steve", row2[0] );
 		if ( "steve".equals( row1[1] ) ) {
 			assertEquals( "stliu", row2[1] );
 		}
 		else {
 			assertEquals( "stliu", row1[1] );
 		}
 		session.getTransaction().commit();
 		session.close();
 
 		session = openSession();
 		session.beginTransaction();
 		session.createQuery( "delete from User" ).executeUpdate();
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Test
 	public void testSqlQueryAutoDiscovery() throws Exception {
 		Session session = openSession();
 		session.beginTransaction();
 		User u = new User( "steve" );
 		Group g = new Group( "developer" );
 		Membership m = new Membership( u, g );
 		session.save( u );
 		session.save( g );
 		session.save( m );
 		session.getTransaction().commit();
 		session.close();
 
 		session = openSession();
 		session.beginTransaction();
 		List result = session.createSQLQuery( QUERY_STRING ).list();
 		Object[] row = (Object[]) result.get( 0 );
 		Assert.assertEquals( "steve", row[0] );
 		Assert.assertEquals( "developer", row[1] );
 		session.delete( m );
 		session.delete( u );
 		session.delete( g );
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Test
 	public void testDialectGetColumnAliasExtractor() throws Exception {
 		Session session = openSession();
 		final SessionImplementor sessionImplementor = (SessionImplementor) session;
 		session.beginTransaction();
 		session.doWork(
 				new Work() {
 					@Override
 					public void execute(Connection connection) throws SQLException {
-						PreparedStatement ps = sessionImplementor.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( QUERY_STRING );
-						ResultSet rs = sessionImplementor.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( ps );
+						PreparedStatement ps = sessionImplementor.getJdbcCoordinator().getStatementPreparer().prepareStatement( QUERY_STRING );
+						ResultSet rs = sessionImplementor.getJdbcCoordinator().getResultSetReturn().extract( ps );
 						try {
 							ResultSetMetaData metadata = rs.getMetaData();
 							String column1Alias = getDialect().getColumnAliasExtractor().extractColumnAlias( metadata, 1 );
 							String column2Alias = getDialect().getColumnAliasExtractor().extractColumnAlias( metadata, 2 );
 							Assert.assertFalse( "bad dialect.getColumnAliasExtractor impl", column1Alias.equals( column2Alias ) );
 						}
 						finally {
-							sessionImplementor.getTransactionCoordinator().getJdbcCoordinator().release( rs, ps );
-							sessionImplementor.getTransactionCoordinator().getJdbcCoordinator().release( ps );
+							sessionImplementor.getJdbcCoordinator().getResourceRegistry().release( rs, ps );
+							sessionImplementor.getJdbcCoordinator().getResourceRegistry().release( ps );
 						}
 					}
 				}
 		);
 		session.getTransaction().commit();
 		session.close();
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/sql/refcursor/CursorFromCallableTest.java b/hibernate-core/src/test/java/org/hibernate/test/sql/refcursor/CursorFromCallableTest.java
index 289538af52..b8afe901e7 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/sql/refcursor/CursorFromCallableTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/sql/refcursor/CursorFromCallableTest.java
@@ -1,145 +1,145 @@
 /* 
  * Hibernate, Relational Persistence for Idiomatic Java
  * 
  * JBoss, Home of Professional Open Source
  * Copyright 2013 Red Hat Inc. and/or its affiliates and other contributors
  * as indicated by the @authors tag. All rights reserved.
  * See the copyright.txt in the distribution for a
  * full listing of individual contributors.
  *
  * This copyrighted material is made available to anyone wishing to use,
  * modify, copy, or redistribute it subject to the terms and conditions
  * of the GNU Lesser General Public License, v. 2.1.
  * This program is distributed in the hope that it will be useful, but WITHOUT A
  * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
  * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
  * You should have received a copy of the GNU Lesser General Public License,
  * v.2.1 along with this distribution; if not, write to the Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
  * MA  02110-1301, USA.
  */
 package org.hibernate.test.sql.refcursor;
 
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Arrays;
 
 import org.junit.After;
 import org.junit.Assert;
 import org.junit.Before;
 import org.junit.Test;
 
 import org.hibernate.Session;
 import org.hibernate.dialect.Oracle8iDialect;
 import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
 import org.hibernate.engine.jdbc.spi.ResultSetReturn;
 import org.hibernate.engine.jdbc.spi.StatementPreparer;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
 import org.hibernate.testing.RequiresDialect;
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 
 /**
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 @RequiresDialect( Oracle8iDialect.class )
 public class CursorFromCallableTest extends BaseCoreFunctionalTestCase {
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class<?>[] { NumValue.class };
 	}
 
 	@Before
 	public void createRefCursorFunction() {
 		executeStatement( "CREATE OR REPLACE FUNCTION f_test_return_cursor RETURN SYS_REFCURSOR " +
 				"IS " +
 				"    l_Cursor SYS_REFCURSOR; " +
 				"BEGIN " +
 				"    OPEN l_Cursor FOR " +
 				"      SELECT 1 AS BOT_NUM " +
 				"           , 'Line 1' AS BOT_VALUE " +
 				"        FROM DUAL " +
 				"      UNION " +
 				"      SELECT 2 AS BOT_NUM " +
 				"           , 'Line 2' AS BOT_VALUE " +
 				"        FROM DUAL; " +
 				"    RETURN(l_Cursor); " +
 				"END f_test_return_cursor;" );
 	}
 
 	@After
 	public void dropRefCursorFunction() {
 		executeStatement( "DROP FUNCTION f_test_return_cursor" );
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-8022" )
 	public void testReadResultSetFromRefCursor() {
 		Session session = openSession();
 		session.getTransaction().begin();
 
 		Assert.assertEquals(
 				Arrays.asList( new NumValue( 1, "Line 1" ), new NumValue( 2, "Line 2" ) ),
 				session.getNamedQuery( "NumValue.getSomeValues" ).list()
 		);
 
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	@Test
 	@TestForIssue( jiraKey = "HHH-7984" )
 	public void testStatementClosing() {
 		Session session = openSession();
 		session.getTransaction().begin();
 		// Reading maximum number of opened cursors requires SYS privileges.
 		// Verify statement closing with JdbcCoordinator#hasRegisteredResources() instead.
 		// BigDecimal maxCursors = (BigDecimal) session.createSQLQuery( "SELECT value FROM v$parameter WHERE name = 'open_cursors'" ).uniqueResult();
 		// for ( int i = 0; i < maxCursors + 10; ++i ) { named_query_execution }
 		Assert.assertEquals(
 				Arrays.asList( new NumValue( 1, "Line 1" ), new NumValue( 2, "Line 2" ) ),
 				session.getNamedQuery( "NumValue.getSomeValues" ).list()
 		);
-		JdbcCoordinator jdbcCoordinator = ( (SessionImplementor) session ).getTransactionCoordinator().getJdbcCoordinator();
+		JdbcCoordinator jdbcCoordinator = ( (SessionImplementor) session ).getJdbcCoordinator();
 		Assert.assertFalse(
 				"Prepared statement and result set should be released after query execution.",
-				jdbcCoordinator.hasRegisteredResources()
+				jdbcCoordinator.getResourceRegistry().hasRegisteredResources()
 		);
 		session.getTransaction().commit();
 		session.close();
 	}
 
 	private void executeStatement(final String sql) {
 		final Session session = openSession();
 		session.getTransaction().begin();
 
 		session.doWork( new Work() {
 			@Override
 			public void execute(Connection connection) throws SQLException {
-				final JdbcCoordinator jdbcCoordinator = ( (SessionImplementor) session ).getTransactionCoordinator().getJdbcCoordinator();
+				final JdbcCoordinator jdbcCoordinator = ( (SessionImplementor) session ).getJdbcCoordinator();
 				final StatementPreparer statementPreparer = jdbcCoordinator.getStatementPreparer();
 				final ResultSetReturn resultSetReturn = jdbcCoordinator.getResultSetReturn();
 				PreparedStatement preparedStatement = null;
 				try {
 					preparedStatement = statementPreparer.prepareStatement( sql );
 					resultSetReturn.execute( preparedStatement );
 				}
 				finally {
 					if ( preparedStatement != null ) {
 						try {
-							jdbcCoordinator.release( preparedStatement );
+							jdbcCoordinator.getResourceRegistry().release( preparedStatement );
 						}
 						catch ( Throwable ignore ) {
 							// ignore...
 						}
 					}
 				}
 			}
 		} );
 
 		session.getTransaction().commit();
 		session.close();
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/tm/CMTTest.java b/hibernate-core/src/test/java/org/hibernate/test/tm/CMTTest.java
index 181c0d51e9..224f659c26 100755
--- a/hibernate-core/src/test/java/org/hibernate/test/tm/CMTTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/tm/CMTTest.java
@@ -1,541 +1,542 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.tm;
 
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import javax.transaction.Transaction;
 
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.EntityMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.criterion.Order;
-import org.hibernate.engine.transaction.internal.jta.CMTTransactionFactory;
+import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorBuilderImpl;
 
 import org.hibernate.testing.DialectChecks;
 import org.hibernate.testing.RequiresDialectFeature;
 import org.hibernate.testing.jta.TestingJtaBootstrap;
 import org.hibernate.testing.jta.TestingJtaPlatformImpl;
 import org.hibernate.testing.junit4.BaseNonConfigCoreFunctionalTestCase;
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertSame;
 import static org.junit.Assert.fail;
 
 /**
  * @author Gavin King
  */
 public class CMTTest extends BaseNonConfigCoreFunctionalTestCase {
 	@Override
 	public String[] getMappings() {
 		return new String[] { "tm/Item.hbm.xml" };
 	}
 
 	@Override
 	protected void addSettings(Map settings) {
 		TestingJtaBootstrap.prepare( settings );
-		settings.put( AvailableSettings.TRANSACTION_STRATEGY, CMTTransactionFactory.class.getName() );
+		//settings.put( AvailableSettings.TRANSACTION_STRATEGY, CMTTransactionFactory.class.getName() );
+		settings.put( AvailableSettings.TRANSACTION_COORDINATOR_STRATEGY, JtaTransactionCoordinatorBuilderImpl.class.getName() );
 		settings.put( AvailableSettings.AUTO_CLOSE_SESSION, "true" );
 		settings.put( AvailableSettings.FLUSH_BEFORE_COMPLETION, "true" );
 		settings.put( AvailableSettings.RELEASE_CONNECTIONS, ConnectionReleaseMode.AFTER_STATEMENT.toString() );
 		settings.put( AvailableSettings.GENERATE_STATISTICS, "true" );
 		settings.put( AvailableSettings.USE_QUERY_CACHE, "true" );
 		settings.put( AvailableSettings.CACHE_REGION_PREFIX, "" );
 		settings.put( AvailableSettings.DEFAULT_ENTITY_MODE, EntityMode.MAP.toString() );
 	}
 
 	@Override
 	public String getCacheConcurrencyStrategy() {
 		return "transactional";
 	}
 
 	@Test
 	public void testConcurrent() throws Exception {
 		sessionFactory().getStatistics().clear();
 		assertEquals( 0, sessionFactory().getStatistics().getUpdateTimestampsCacheHitCount() );
 		assertEquals( 0, sessionFactory().getStatistics().getUpdateTimestampsCachePutCount() );
 		assertEquals( 0, sessionFactory().getStatistics().getUpdateTimestampsCacheMissCount() );
 		assertNotNull( sessionFactory().getEntityPersister( "Item" ).getCacheAccessStrategy() );
 		assertEquals( 0, sessionFactory().getStatistics().getEntityLoadCount() );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		Session s = openSession();
 		Map foo = new HashMap();
 		foo.put( "name", "Foo" );
 		foo.put( "description", "a big foo" );
 		s.persist( "Item", foo );
 		Map bar = new HashMap();
 		bar.put( "name", "Bar" );
 		bar.put( "description", "a small bar" );
 		s.persist( "Item", bar );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 		assertEquals(0, sessionFactory().getStatistics().getUpdateTimestampsCacheHitCount());
 		assertEquals(2, sessionFactory().getStatistics().getUpdateTimestampsCachePutCount()); // One preinvalidate & one invalidate
 		assertEquals(0, sessionFactory().getStatistics().getUpdateTimestampsCacheMissCount());
 
 		sessionFactory().getCache().evictEntityRegion( "Item" );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		Session s1 = openSession();
 		foo = ( Map ) s1.get( "Item", "Foo" );
 		//foo.put("description", "a big red foo");
 		//s1.flush();
 		Transaction tx = TestingJtaPlatformImpl.INSTANCE.getTransactionManager().suspend();
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		Session s2 = openSession();
 		foo = ( Map ) s2.get( "Item", "Foo" );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().resume( tx );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		sessionFactory().getCache().evictEntityRegion( "Item" );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s1 = openSession();
 		s1.createCriteria( "Item" ).list();
 		//foo.put("description", "a big red foo");
 		//s1.flush();
 		tx = TestingJtaPlatformImpl.INSTANCE.getTransactionManager().suspend();
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s2 = openSession();
 		s2.createCriteria( "Item" ).list();
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().resume( tx );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s2 = openSession();
 		s2.createCriteria( "Item" ).list();
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		assertEquals( 7, sessionFactory().getStatistics().getEntityLoadCount() );
 		assertEquals( 0, sessionFactory().getStatistics().getEntityFetchCount() );
 		assertEquals( 3, sessionFactory().getStatistics().getQueryExecutionCount() );
 		assertEquals( 0, sessionFactory().getStatistics().getQueryCacheHitCount() );
 		assertEquals( 0, sessionFactory().getStatistics().getQueryCacheMissCount() );
 		assertEquals( 0, sessionFactory().getStatistics().getUpdateTimestampsCacheHitCount() );
 		assertEquals( 2, sessionFactory().getStatistics().getUpdateTimestampsCachePutCount() );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s = openSession();
 		s.createQuery( "delete from Item" ).executeUpdate();
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 	}
 
 	@Test
 	public void testConcurrentCachedQueries() throws Exception {
 		sessionFactory().getStatistics().clear();
 		cleanupCache();
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		Session s = openSession();
 		Map foo = new HashMap();
 		foo.put( "name", "Foo" );
 		foo.put( "description", "a big foo" );
 		s.persist( "Item", foo );
 		Map bar = new HashMap();
 		bar.put( "name", "Bar" );
 		bar.put( "description", "a small bar" );
 		s.persist( "Item", bar );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		synchronized ( this ) {
 			wait( 1000 );
 		}
 
 		sessionFactory().getStatistics().clear();
 
 		sessionFactory().getCache().evictEntityRegion( "Item" );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		Session s4 = openSession();
 		Transaction tx4 = TestingJtaPlatformImpl.INSTANCE.getTransactionManager().suspend();
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		Session s1 = openSession();
 		List r1 = s1.createCriteria( "Item" ).addOrder( Order.asc( "description" ) )
 				.setCacheable( true ).list();
 		assertEquals( r1.size(), 2 );
 		Transaction tx1 = TestingJtaPlatformImpl.INSTANCE.getTransactionManager().suspend();
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		Session s2 = openSession();
 		List r2 = s2.createCriteria( "Item" ).addOrder( Order.asc( "description" ) )
 				.setCacheable( true ).list();
 		assertEquals( r2.size(), 2 );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		assertEquals( sessionFactory().getStatistics().getSecondLevelCacheHitCount(), 2 );
 		assertEquals( sessionFactory().getStatistics().getSecondLevelCacheMissCount(), 0 );
 		assertEquals( sessionFactory().getStatistics().getEntityLoadCount(), 2 );
 		assertEquals( sessionFactory().getStatistics().getEntityFetchCount(), 0 );
 		assertEquals( sessionFactory().getStatistics().getQueryExecutionCount(), 1 );
 		assertEquals( sessionFactory().getStatistics().getQueryCachePutCount(), 1 );
 		assertEquals( sessionFactory().getStatistics().getQueryCacheHitCount(), 1 );
 		assertEquals( sessionFactory().getStatistics().getQueryCacheMissCount(), 1 );
 		assertEquals( sessionFactory().getStatistics().getUpdateTimestampsCacheHitCount(), 1 );
 		assertEquals( sessionFactory().getStatistics().getUpdateTimestampsCachePutCount(), 0 );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().resume( tx1 );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		Session s3 = openSession();
 		s3.createCriteria( "Item" ).addOrder( Order.asc( "description" ) )
 				.setCacheable( true ).list();
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		assertEquals( sessionFactory().getStatistics().getSecondLevelCacheHitCount(), 4 );
 		assertEquals( sessionFactory().getStatistics().getSecondLevelCacheMissCount(), 0 );
 		assertEquals( sessionFactory().getStatistics().getEntityLoadCount(), 2 );
 		assertEquals( sessionFactory().getStatistics().getEntityFetchCount(), 0 );
 		assertEquals( sessionFactory().getStatistics().getQueryExecutionCount(), 1 );
 		assertEquals( sessionFactory().getStatistics().getQueryCachePutCount(), 1 );
 		assertEquals( sessionFactory().getStatistics().getQueryCacheHitCount(), 2 );
 		assertEquals( sessionFactory().getStatistics().getQueryCacheMissCount(), 1 );
 		assertEquals( sessionFactory().getStatistics().getUpdateTimestampsCacheHitCount(), 2 );
 		assertEquals( sessionFactory().getStatistics().getUpdateTimestampsCachePutCount(), 0 );
 		assertEquals( sessionFactory().getStatistics().getUpdateTimestampsCacheMissCount(), 0 );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().resume( tx4 );
 		List r4 = s4.createCriteria( "Item" ).addOrder( Order.asc( "description" ) )
 				.setCacheable( true ).list();
 		assertEquals( r4.size(), 2 );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		assertEquals( sessionFactory().getStatistics().getSecondLevelCacheHitCount(), 6 );
 		assertEquals( sessionFactory().getStatistics().getSecondLevelCacheMissCount(), 0 );
 		assertEquals( sessionFactory().getStatistics().getEntityLoadCount(), 2 );
 		assertEquals( sessionFactory().getStatistics().getEntityFetchCount(), 0 );
 		assertEquals( sessionFactory().getStatistics().getQueryExecutionCount(), 1 );
 		assertEquals( sessionFactory().getStatistics().getQueryCachePutCount(), 1 );
 		assertEquals( sessionFactory().getStatistics().getQueryCacheHitCount(), 3 );
 		assertEquals( sessionFactory().getStatistics().getQueryCacheMissCount(), 1 );
 		assertEquals( sessionFactory().getStatistics().getUpdateTimestampsCacheHitCount(), 3 );
 		assertEquals( sessionFactory().getStatistics().getUpdateTimestampsCachePutCount(), 0 );
 
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s = openSession();
 		s.createQuery( "delete from Item" ).executeUpdate();
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 	}
 
 	@Test
 	@RequiresDialectFeature(
 			value = DialectChecks.DoesReadCommittedNotCauseWritersToBlockReadersCheck.class,
 			comment = "write locks block readers"
 	)
 	public void testConcurrentCachedDirtyQueries() throws Exception {
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		Session s = openSession();
 		Map foo = new HashMap();
 		foo.put( "name", "Foo" );
 		foo.put( "description", "a big foo" );
 		s.persist( "Item", foo );
 		Map bar = new HashMap();
 		bar.put( "name", "Bar" );
 		bar.put( "description", "a small bar" );
 		s.persist( "Item", bar );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		synchronized ( this ) {
 			wait( 1000 );
 		}
 
 		sessionFactory().getStatistics().clear();
 		cleanupCache();  // we need a clean 2L cache here.
 
 		// open a TX and suspend it
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		Session s4 = openSession();
 		Transaction tx4 = TestingJtaPlatformImpl.INSTANCE.getTransactionManager().suspend();
 
 		// open a new TX and execute a query, this would fill the query cache.
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		Session s1 = openSession();
 		List r1 = s1.createCriteria( "Item" ).addOrder( Order.asc( "description" ) )
 				.setCacheable( true ).list();
 		assertEquals( r1.size(), 2 );
 		foo = ( Map ) r1.get( 0 );
 		// update data and make query cache stale, but TX is suspended
 		foo.put( "description", "a big red foo" );
 		s1.flush();
 		Transaction tx1 = TestingJtaPlatformImpl.INSTANCE.getTransactionManager().suspend();
 
 		// open a new TX and run query again
 		// this TX is committed after query
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		Session s2 = openSession();
 		List r2 = s2.createCriteria( "Item" ).addOrder( Order.asc( "description" ) )
 				.setCacheable( true ).list();
 		assertEquals( r2.size(), 2 );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		assertEquals( 0, sessionFactory().getStatistics().getSecondLevelCacheHitCount() );
 		assertEquals( 0, sessionFactory().getStatistics().getSecondLevelCacheMissCount() );
 		assertEquals( 4, sessionFactory().getStatistics().getEntityLoadCount() );
 		assertEquals( 0, sessionFactory().getStatistics().getEntityFetchCount() );
 		assertEquals( 2, sessionFactory().getStatistics().getQueryExecutionCount() );
 		assertEquals( 2, sessionFactory().getStatistics().getQueryCachePutCount() );
 		assertEquals( 0, sessionFactory().getStatistics().getQueryCacheHitCount() );
 		assertEquals( 2, sessionFactory().getStatistics().getQueryCacheMissCount() );
 
 		// updateTimestampsCache put happens at two places
 		// 1. {@link org.hibernate.engine.spi.ActionQueue#registerCleanupActions} calls preinvalidate
 		// 2. {@link org.hibernate.engine.spi.ActionQueue.AfterTransactionCompletionProcessQueue#afterTransactionCompletion} calls invalidate
 		// but since the TX which the update action happened is not committed yet, so there should be only 1 updateTimestamps put.
 		assertEquals( 1, sessionFactory().getStatistics().getUpdateTimestampsCachePutCount() );
 
 		// updateTimestampsCache hit only happens when the query cache data's timestamp is newer
 		// than the timestamp of when update happens
 		// since there is only 1 update action
 		assertEquals( 1, sessionFactory().getStatistics().getUpdateTimestampsCacheHitCount() );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().resume( tx1 );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		// update action's TX committed, so, invalidate is called, put new timestamp into UpdateTimestampsCache
 		assertEquals( 2, sessionFactory().getStatistics().getUpdateTimestampsCachePutCount() );
 		// but no more query cache lookup here, so it should still 1
 		assertEquals( 1, sessionFactory().getStatistics().getUpdateTimestampsCacheHitCount() );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		Session s3 = openSession();
 		s3.createCriteria( "Item" ).addOrder( Order.asc( "description" ) )
 				.setCacheable( true ).list();
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		assertEquals( 0, sessionFactory().getStatistics().getSecondLevelCacheHitCount() );
 		assertEquals( 0, sessionFactory().getStatistics().getSecondLevelCacheMissCount() );
 		assertEquals( 6, sessionFactory().getStatistics().getEntityLoadCount() );
 		assertEquals( 0, sessionFactory().getStatistics().getEntityFetchCount() );
 		assertEquals( 3, sessionFactory().getStatistics().getQueryExecutionCount() );
 		assertEquals( 3, sessionFactory().getStatistics().getQueryCachePutCount() );
 		assertEquals( 0, sessionFactory().getStatistics().getQueryCacheHitCount() );
 		assertEquals( 3, sessionFactory().getStatistics().getQueryCacheMissCount() );
 		// a new query cache hit and one more update timestamps cache hit, so should be 2
 		assertEquals( 2, sessionFactory().getStatistics().getUpdateTimestampsCacheHitCount() );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().resume( tx4 );
 		List r4 = s4.createCriteria( "Item" ).addOrder( Order.asc( "description" ) )
 				.setCacheable( true ).list();
 		assertEquals( r4.size(), 2 );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		assertEquals( 2, sessionFactory().getStatistics().getSecondLevelCacheHitCount() );
 		assertEquals( 0, sessionFactory().getStatistics().getSecondLevelCacheMissCount() );
 		assertEquals( 6, sessionFactory().getStatistics().getEntityLoadCount() );
 		assertEquals( 0, sessionFactory().getStatistics().getEntityFetchCount() );
 		assertEquals( 3, sessionFactory().getStatistics().getQueryExecutionCount() );
 		assertEquals( 3, sessionFactory().getStatistics().getQueryCachePutCount() );
 		assertEquals( 1, sessionFactory().getStatistics().getQueryCacheHitCount() );
 		assertEquals( 3, sessionFactory().getStatistics().getQueryCacheMissCount() );
 		assertEquals( 3, sessionFactory().getStatistics().getUpdateTimestampsCacheHitCount() );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s = openSession();
 		s.createQuery( "delete from Item" ).executeUpdate();
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 	}
 
 	@Test
 	public void testCMT() throws Exception {
 		sessionFactory().getStatistics().clear();
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		Session s = openSession();
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 		assertFalse( s.isOpen() );
 
 		assertEquals( sessionFactory().getStatistics().getFlushCount(), 0 );
 		assertEquals( sessionFactory().getStatistics().getEntityInsertCount(), 0 );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s = openSession();
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().rollback();
 		assertFalse( s.isOpen() );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s = openSession();
 		Map item = new HashMap();
 		item.put( "name", "The Item" );
 		item.put( "description", "The only item we have" );
 		s.persist( "Item", item );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 		assertFalse( s.isOpen() );
 		assertEquals( sessionFactory().getStatistics().getFlushCount(), 1 );
 		assertEquals( sessionFactory().getStatistics().getEntityInsertCount(), 1 );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s = openSession();
 		item = ( Map ) s.createQuery( "from Item" ).uniqueResult();
 		assertNotNull( item );
 		s.delete( item );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 		assertFalse( s.isOpen() );
 
 		assertEquals( sessionFactory().getStatistics().getTransactionCount(), 4 );
 		assertEquals( sessionFactory().getStatistics().getSuccessfulTransactionCount(), 3 );
 		assertEquals( sessionFactory().getStatistics().getEntityDeleteCount(), 1 );
 		assertEquals( sessionFactory().getStatistics().getEntityInsertCount(), 1 );
 		assertEquals( sessionFactory().getStatistics().getSessionOpenCount(), 4 );
 		assertEquals( sessionFactory().getStatistics().getSessionCloseCount(), 4 );
 		assertEquals( sessionFactory().getStatistics().getQueryExecutionCount(), 1 );
 		assertEquals( sessionFactory().getStatistics().getFlushCount(), 2 );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s = openSession();
 		s.createQuery( "delete from Item" ).executeUpdate();
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 	}
 
 	@Test
 	public void testCurrentSession() throws Exception {
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		Session s = sessionFactory().getCurrentSession();
 		Session s2 = sessionFactory().getCurrentSession();
 		assertSame( s, s2 );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 		assertFalse( s.isOpen() );
 
 		// TODO : would be nice to automate-test that the SF internal map actually gets cleaned up
 		//      i verified that is does currently in my debugger...
 	}
 
 	@Test
 	public void testCurrentSessionWithIterate() throws Exception {
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		Session s = openSession();
 		Map item1 = new HashMap();
 		item1.put( "name", "Item - 1" );
 		item1.put( "description", "The first item" );
 		s.persist( "Item", item1 );
 
 		Map item2 = new HashMap();
 		item2.put( "name", "Item - 2" );
 		item2.put( "description", "The second item" );
 		s.persist( "Item", item2 );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		// First, test iterating the partial iterator; iterate to past
 		// the first, but not the second, item
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s = sessionFactory().getCurrentSession();
 		Iterator itr = s.createQuery( "from Item" ).iterate();
 		if ( !itr.hasNext() ) {
 			fail( "No results in iterator" );
 		}
 		itr.next();
 		if ( !itr.hasNext() ) {
 			fail( "Only one result in iterator" );
 		}
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		// Next, iterate the entire result
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s = sessionFactory().getCurrentSession();
 		itr = s.createQuery( "from Item" ).iterate();
 		if ( !itr.hasNext() ) {
 			fail( "No results in iterator" );
 		}
 		while ( itr.hasNext() ) {
 			itr.next();
 		}
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s = openSession();
 		s.createQuery( "delete from Item" ).executeUpdate();
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 	}
 
 	@Test
 	public void testCurrentSessionWithScroll() throws Exception {
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		Session s = sessionFactory().getCurrentSession();
 		Map item1 = new HashMap();
 		item1.put( "name", "Item - 1" );
 		item1.put( "description", "The first item" );
 		s.persist( "Item", item1 );
 
 		Map item2 = new HashMap();
 		item2.put( "name", "Item - 2" );
 		item2.put( "description", "The second item" );
 		s.persist( "Item", item2 );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		// First, test partially scrolling the result with out closing
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s = sessionFactory().getCurrentSession();
 		ScrollableResults results = s.createQuery( "from Item" ).scroll();
 		results.next();
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		// Next, test partially scrolling the result with closing
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s = sessionFactory().getCurrentSession();
 		results = s.createQuery( "from Item" ).scroll();
 		results.next();
 		results.close();
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		// Next, scroll the entire result (w/o closing)
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s = sessionFactory().getCurrentSession();
 		results = s.createQuery( "from Item" ).scroll();
 		while ( results.next() ) {
 			// do nothing
 		}
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		// Next, scroll the entire result (closing)
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s = sessionFactory().getCurrentSession();
 		results = s.createQuery( "from Item" ).scroll();
 		while ( results.next() ) {
 			// do nothing
 		}
 		results.close();
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		s = sessionFactory().getCurrentSession();
 		s.createQuery( "delete from Item" ).executeUpdate();
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 	}
 
 }
 
diff --git a/hibernate-core/src/test/java/org/hibernate/test/tm/TransactionTimeoutTest.java b/hibernate-core/src/test/java/org/hibernate/test/tm/TransactionTimeoutTest.java
index f24ca4b609..56b25c5790 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/tm/TransactionTimeoutTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/tm/TransactionTimeoutTest.java
@@ -1,96 +1,96 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.tm;
 
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.TransactionException;
 import org.hibernate.boot.model.naming.ImplicitNamingStrategyLegacyHbmImpl;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.dialect.PostgreSQL81Dialect;
 import org.hibernate.dialect.PostgreSQLDialect;
 import org.hibernate.engine.spi.SessionImplementor;
 
 import org.hibernate.testing.SkipForDialect;
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.hibernate.test.jdbc.Person;
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotSame;
 
 /**
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 @TestForIssue(jiraKey = "HHH-6780")
 @SkipForDialect( value ={ PostgreSQL81Dialect.class, PostgreSQLDialect.class}, comment = "PostgreSQL jdbc driver doesn't impl timeout method")
 public class TransactionTimeoutTest extends BaseCoreFunctionalTestCase {
 	@Override
 	public String[] getMappings() {
 		return new String[] {"jdbc/Mappings.hbm.xml"};
 	}
 
 	@Override
 	protected void configure(Configuration configuration) {
 		super.configure( configuration );
 		configuration.setImplicitNamingStrategy( ImplicitNamingStrategyLegacyHbmImpl.INSTANCE );
 	}
 
 	@Test
 	public void testJdbcCoordinatorTransactionTimeoutCheck() {
 		Session session = openSession();
 		Transaction transaction = session.getTransaction();
 		transaction.setTimeout( 2 );
-		assertEquals( -1, ((SessionImplementor)session).getTransactionCoordinator().getJdbcCoordinator().determineRemainingTransactionTimeOutPeriod() );
+		assertEquals( -1, ((SessionImplementor)session).getJdbcCoordinator().determineRemainingTransactionTimeOutPeriod() );
 		transaction.begin();
-		assertNotSame( -1, ((SessionImplementor)session).getTransactionCoordinator().getJdbcCoordinator().determineRemainingTransactionTimeOutPeriod() );
+		assertNotSame( -1, ((SessionImplementor)session).getJdbcCoordinator().determineRemainingTransactionTimeOutPeriod() );
 		transaction.commit();
 		session.close();
 	}
 
 	@Test(expected = TransactionException.class)
 	public void testTransactionTimeoutFailure() throws InterruptedException {
 		Session session = openSession();
 		Transaction transaction = session.getTransaction();
 		transaction.setTimeout( 1 );
-		assertEquals( -1, ((SessionImplementor)session).getTransactionCoordinator().getJdbcCoordinator().determineRemainingTransactionTimeOutPeriod() );
+		assertEquals( -1, ((SessionImplementor)session).getJdbcCoordinator().determineRemainingTransactionTimeOutPeriod() );
 		transaction.begin();
 		Thread.sleep( 1000 );
 		session.persist( new Person( "Lukasz", "Antoniak" ) );
 		transaction.commit();
 		session.close();
 	}
 
 	@Test
 	public void testTransactionTimeoutSuccess() {
 		Session session = openSession();
 		Transaction transaction = session.getTransaction();
 		transaction.setTimeout( 60 );
 		transaction.begin();
 		session.persist( new Person( "Lukasz", "Antoniak" ) );
 		transaction.commit();
 		session.close();
 	}
 }
diff --git a/hibernate-core/src/test/java/org/hibernate/test/transaction/jdbc/TestExpectedUsage.java b/hibernate-core/src/test/java/org/hibernate/test/transaction/jdbc/TestExpectedUsage.java
deleted file mode 100644
index 1926744763..0000000000
--- a/hibernate-core/src/test/java/org/hibernate/test/transaction/jdbc/TestExpectedUsage.java
+++ /dev/null
@@ -1,137 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.test.transaction.jdbc;
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.fail;
-
-import java.sql.PreparedStatement;
-import java.sql.SQLException;
-import java.sql.Statement;
-
-import org.hibernate.ConnectionReleaseMode;
-import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
-import org.hibernate.boot.registry.internal.StandardServiceRegistryImpl;
-import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
-import org.hibernate.engine.jdbc.spi.LogicalConnectionImplementor;
-import org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl;
-import org.hibernate.engine.transaction.spi.TransactionContext;
-import org.hibernate.engine.transaction.spi.TransactionImplementor;
-import org.hibernate.test.common.JournalingTransactionObserver;
-import org.hibernate.test.common.TransactionContextImpl;
-import org.hibernate.test.common.TransactionEnvironmentImpl;
-import org.hibernate.testing.env.ConnectionProviderBuilder;
-import org.hibernate.testing.junit4.BaseUnitTestCase;
-import org.junit.After;
-import org.junit.Before;
-import org.junit.Test;
-
-/**
- * @author Steve Ebersole
- */
-public class TestExpectedUsage extends BaseUnitTestCase {
-	private StandardServiceRegistryImpl serviceRegistry;
-
-	@Before
-	public void setUp() throws Exception {
-		serviceRegistry = (StandardServiceRegistryImpl) new StandardServiceRegistryBuilder()
-				.applySettings( ConnectionProviderBuilder.getConnectionProviderProperties() )
-				.build();
-	}
-
-	@After
-	public void tearDown() throws Exception {
-		serviceRegistry.destroy();
-	}
-
-	@Test
-	public void testBasicUsage() {
-		final TransactionContext transactionContext = new TransactionContextImpl( new TransactionEnvironmentImpl( serviceRegistry ) ) {
-			@Override
-			public ConnectionReleaseMode getConnectionReleaseMode() {
-				return ConnectionReleaseMode.AFTER_TRANSACTION;
-			}
-		};
-
-		TransactionCoordinatorImpl transactionCoordinator = new TransactionCoordinatorImpl( null, transactionContext );
-		JournalingTransactionObserver observer = new JournalingTransactionObserver();
-		transactionCoordinator.addObserver( observer );
-
-		JdbcCoordinator jdbcCoordinator = transactionCoordinator.getJdbcCoordinator();
-		LogicalConnectionImplementor logicalConnection = jdbcCoordinator.getLogicalConnection();
-
-		// set up some tables to use
-		Statement statement = jdbcCoordinator.getStatementPreparer().createStatement();
-		jdbcCoordinator.getResultSetReturn().execute( statement, "drop table SANDBOX_JDBC_TST if exists" );
-		jdbcCoordinator.getResultSetReturn().execute( statement, "create table SANDBOX_JDBC_TST ( ID integer, NAME varchar(100) )" );
-		assertTrue( jdbcCoordinator.hasRegisteredResources() );
-		assertTrue( logicalConnection.isPhysicallyConnected() );
-		jdbcCoordinator.release( statement );
-		assertFalse( jdbcCoordinator.hasRegisteredResources() );
-		assertTrue( logicalConnection.isPhysicallyConnected() ); // after_transaction specified
-
-		// ok, now we can get down to it...
-		TransactionImplementor txn = transactionCoordinator.getTransaction();  // same as Session#getTransaction
-		txn.begin();
-		assertEquals( 1, observer.getBegins() );
-		try {
-			PreparedStatement ps = jdbcCoordinator.getStatementPreparer().prepareStatement( "insert into SANDBOX_JDBC_TST( ID, NAME ) values ( ?, ? )" );
-			ps.setLong( 1, 1 );
-			ps.setString( 2, "name" );
-			jdbcCoordinator.getResultSetReturn().execute( ps );
-			assertTrue( jdbcCoordinator.hasRegisteredResources() );
-			jdbcCoordinator.release( ps );
-			assertFalse( jdbcCoordinator.hasRegisteredResources() );
-
-			ps = jdbcCoordinator.getStatementPreparer().prepareStatement( "select * from SANDBOX_JDBC_TST" );
-			jdbcCoordinator.getResultSetReturn().extract( ps );
-			ps = jdbcCoordinator.getStatementPreparer().prepareStatement( "delete from SANDBOX_JDBC_TST" );
-			jdbcCoordinator.getResultSetReturn().execute( ps );
-			// lets forget to close these...
-			assertTrue( jdbcCoordinator.hasRegisteredResources() );
-
-			// and commit the transaction...
-			txn.commit();
-
-			// we should now have:
-			//		1) no resources because of after_transaction release mode
-			assertFalse( jdbcCoordinator.hasRegisteredResources() );
-			//		2) non-physically connected logical connection, again because of after_transaction release mode
-			assertFalse( logicalConnection.isPhysicallyConnected() );
-			//		3) transaction observer callbacks
-			assertEquals( 1, observer.getBeforeCompletions() );
-			assertEquals( 1, observer.getAfterCompletions() );
-		}
-		catch ( SQLException sqle ) {
-			fail( "incorrect exception type : SQLException" );
-		}
-		finally {
-			logicalConnection.close();
-			transactionContext.getTransactionEnvironment().getSessionFactory().close();
-		}
-	}
-
-}
diff --git a/hibernate-core/src/test/java/org/hibernate/test/transaction/jta/BasicDrivingTest.java b/hibernate-core/src/test/java/org/hibernate/test/transaction/jta/BasicDrivingTest.java
deleted file mode 100644
index 998c122017..0000000000
--- a/hibernate-core/src/test/java/org/hibernate/test/transaction/jta/BasicDrivingTest.java
+++ /dev/null
@@ -1,159 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.test.transaction.jta;
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.fail;
-
-import java.sql.PreparedStatement;
-import java.sql.SQLException;
-import java.sql.Statement;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
-import org.hibernate.boot.registry.internal.StandardServiceRegistryImpl;
-import org.hibernate.cfg.Environment;
-import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
-import org.hibernate.engine.jdbc.spi.LogicalConnectionImplementor;
-import org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl;
-import org.hibernate.engine.transaction.internal.jta.JtaTransactionFactory;
-import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
-import org.hibernate.engine.transaction.spi.TransactionContext;
-import org.hibernate.engine.transaction.spi.TransactionImplementor;
-import org.hibernate.test.common.JournalingTransactionObserver;
-import org.hibernate.test.common.TransactionContextImpl;
-import org.hibernate.test.common.TransactionEnvironmentImpl;
-import org.hibernate.testing.env.ConnectionProviderBuilder;
-import org.hibernate.testing.jta.TestingJtaBootstrap;
-import org.hibernate.testing.junit4.BaseUnitTestCase;
-import org.junit.After;
-import org.junit.Before;
-import org.junit.Test;
-
-/**
- * Testing transaction handling when the JTA transaction facade is the driver.
- *
- * @author Steve Ebersole
- */
-public class BasicDrivingTest extends BaseUnitTestCase {
-	private StandardServiceRegistryImpl serviceRegistry;
-
-	@Before
-	@SuppressWarnings( {"unchecked"})
-	public void setUp() throws Exception {
-		Map configValues = new HashMap();
-		configValues.putAll( ConnectionProviderBuilder.getConnectionProviderProperties() );
-		configValues.put( Environment.TRANSACTION_STRATEGY, JtaTransactionFactory.class.getName() );
-		TestingJtaBootstrap.prepare( configValues );
-		serviceRegistry = (StandardServiceRegistryImpl) new StandardServiceRegistryBuilder()
-				.applySettings( configValues )
-				.build();
-	}
-
-	@After
-	public void tearDown() throws Exception {
-		serviceRegistry.destroy();
-	}
-
-	@Test
-	public void testBasicUsage() throws Throwable {
-		final TransactionContext transactionContext = new TransactionContextImpl( new TransactionEnvironmentImpl( serviceRegistry ) );
-
-		TransactionCoordinatorImpl transactionCoordinator = new TransactionCoordinatorImpl( null, transactionContext );
-		JournalingTransactionObserver observer = new JournalingTransactionObserver();
-		transactionCoordinator.addObserver( observer );
-
-		JdbcCoordinator jdbcCoordinator = transactionCoordinator.getJdbcCoordinator();
-		LogicalConnectionImplementor logicalConnection = jdbcCoordinator.getLogicalConnection();
-
-		// set up some tables to use
-		Statement statement = jdbcCoordinator.getStatementPreparer().createStatement();
-		jdbcCoordinator.getResultSetReturn().execute( statement, "drop table SANDBOX_JDBC_TST if exists" );
-		jdbcCoordinator.getResultSetReturn().execute( statement, "create table SANDBOX_JDBC_TST ( ID integer, NAME varchar(100) )" );
-		assertTrue( jdbcCoordinator.hasRegisteredResources() );
-		assertTrue( logicalConnection.isPhysicallyConnected() );
-		jdbcCoordinator.release( statement );
-		assertFalse( jdbcCoordinator.hasRegisteredResources() );
-		assertFalse( logicalConnection.isPhysicallyConnected() ); // after_statement specified
-
-		// ok, now we can get down to it...
-		TransactionImplementor txn = transactionCoordinator.getTransaction();  // same as Session#getTransaction
-		txn.begin();
-		assertEquals( 1, observer.getBegins() );
-		assertTrue( txn.isInitiator() );
-		try {
-			PreparedStatement ps = jdbcCoordinator.getStatementPreparer().prepareStatement( "insert into SANDBOX_JDBC_TST( ID, NAME ) values ( ?, ? )" );
-			ps.setLong( 1, 1 );
-			ps.setString( 2, "name" );
-			jdbcCoordinator.getResultSetReturn().execute( ps );
-			assertTrue( jdbcCoordinator.hasRegisteredResources() );
-			jdbcCoordinator.release( ps );
-			assertFalse( jdbcCoordinator.hasRegisteredResources() );
-
-			ps = jdbcCoordinator.getStatementPreparer().prepareStatement( "select * from SANDBOX_JDBC_TST" );
-			jdbcCoordinator.getResultSetReturn().extract( ps );
-			ps = jdbcCoordinator.getStatementPreparer().prepareStatement( "delete from SANDBOX_JDBC_TST" );
-			jdbcCoordinator.getResultSetReturn().execute( ps );
-			// lets forget to close these...
-			assertTrue( jdbcCoordinator.hasRegisteredResources() );
-			assertTrue( logicalConnection.isPhysicallyConnected() );
-
-			// and commit the transaction...
-			txn.commit();
-
-			// we should now have:
-			//		1) no resources because of after_transaction release mode
-			assertFalse( jdbcCoordinator.hasRegisteredResources() );
-			//		2) non-physically connected logical connection, again because of after_transaction release mode
-			assertFalse( logicalConnection.isPhysicallyConnected() );
-			//		3) transaction observer callbacks
-			assertEquals( 1, observer.getBeforeCompletions() );
-			assertEquals( 1, observer.getAfterCompletions() );
-		}
-		catch ( SQLException sqle ) {
-			try {
-				serviceRegistry.getService( JtaPlatform.class ).retrieveTransactionManager().rollback();
-			}
-			catch (Exception ignore) {
-			}
-			fail( "incorrect exception type : SQLException" );
-		}
-		catch (Throwable reThrowable) {
-			try {
-				serviceRegistry.getService( JtaPlatform.class ).retrieveTransactionManager().rollback();
-			}
-			catch (Exception ignore) {
-			}
-			throw reThrowable;
-		}
-		finally {
-			logicalConnection.close();
-			transactionContext.getTransactionEnvironment().getSessionFactory().close();
-		}
-	}
-
-}
diff --git a/hibernate-core/src/test/java/org/hibernate/test/transaction/jta/InterceptorCallbackTests.java b/hibernate-core/src/test/java/org/hibernate/test/transaction/jta/InterceptorCallbackTests.java
deleted file mode 100644
index 05bafa0b42..0000000000
--- a/hibernate-core/src/test/java/org/hibernate/test/transaction/jta/InterceptorCallbackTests.java
+++ /dev/null
@@ -1,173 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.test.transaction.jta;
-
-import javax.transaction.NotSupportedException;
-import javax.transaction.SystemException;
-import javax.transaction.TransactionManager;
-
-import org.hibernate.EmptyInterceptor;
-import org.hibernate.Interceptor;
-import org.hibernate.Session;
-import org.hibernate.SessionFactory;
-import org.hibernate.Transaction;
-import org.hibernate.cfg.AvailableSettings;
-import org.hibernate.cfg.Configuration;
-import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.engine.transaction.internal.jta.CMTTransactionFactory;
-import org.hibernate.engine.transaction.internal.jta.JtaTransactionFactory;
-import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
-
-import org.junit.Test;
-
-import org.hibernate.testing.junit4.BaseUnitTestCase;
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.fail;
-
-/**
- * @author Steve Ebersole
- */
-public class InterceptorCallbackTests extends BaseUnitTestCase {
-	@Test
-	public void testManagedTransactionCallbacks() {
-		SessionFactory sf = new Configuration()
-				.setProperty( AvailableSettings.TRANSACTION_STRATEGY, JtaTransactionFactory.SHORT_NAME )
-				.buildSessionFactory();
-
-		JournalingInterceptor interceptor = new JournalingInterceptor();
-
-		try {
-			Session session = sf.withOptions().interceptor( interceptor ).openSession();
-			session.beginTransaction();
-			session.getTransaction().commit();
-			session.close();
-		}
-		finally {
-			sf.close();
-		}
-
-		assertEquals( 1, interceptor.afterStart );
-		assertEquals( 1, interceptor.beforeCompletion );
-		assertEquals( 1, interceptor.afterCompletion );
-	}
-
-	@Test
-	public void testTransactionCallbacks() throws Exception {
-		SessionFactoryImplementor sf = (SessionFactoryImplementor) new Configuration()
-				.setProperty( AvailableSettings.TRANSACTION_STRATEGY, JtaTransactionFactory.SHORT_NAME )
-				.setProperty( AvailableSettings.AUTO_CLOSE_SESSION, "true" )
-				.buildSessionFactory();
-
-		JournalingInterceptor interceptor = new JournalingInterceptor();
-
-		try {
-			JtaPlatform instance = sf.getServiceRegistry().getService( JtaPlatform.class );
-			TransactionManager transactionManager = instance.retrieveTransactionManager();
-
-			// start the cmt
-			transactionManager.begin();
-
-			Session session = sf.withOptions().interceptor( interceptor ).openSession();
-
-			transactionManager.commit();
-
-			if ( session.isOpen() ) {
-				try {
-					session.close();
-				}
-				catch (Exception ignore) {
-				}
-				fail( "auto-close-session setting did not close session" );
-			}
-		}
-		finally {
-			sf.close();
-		}
-
-		assertEquals( 0, interceptor.afterStart );
-		assertEquals( 1, interceptor.beforeCompletion );
-		assertEquals( 1, interceptor.afterCompletion );
-	}
-
-	@Test
-	public void testTransactionCallbacks2() throws Exception {
-		SessionFactoryImplementor sf = (SessionFactoryImplementor) new Configuration()
-				.setProperty( AvailableSettings.TRANSACTION_STRATEGY, CMTTransactionFactory.SHORT_NAME )
-				.setProperty( AvailableSettings.AUTO_CLOSE_SESSION, "true" )
-				.buildSessionFactory();
-
-		JournalingInterceptor interceptor = new JournalingInterceptor();
-
-		try {
-			JtaPlatform instance = sf.getServiceRegistry().getService( JtaPlatform.class );
-			TransactionManager transactionManager = instance.retrieveTransactionManager();
-
-			// start the cmt
-			transactionManager.begin();
-
-			Session session = sf.withOptions().interceptor( interceptor ).openSession();
-
-			transactionManager.commit();
-
-			if ( session.isOpen() ) {
-				try {
-					session.close();
-				}
-				catch (Exception ignore) {
-				}
-				fail( "auto-close-session setting did not close session" );
-			}
-		}
-		finally {
-			sf.close();
-		}
-
-		assertEquals( 0, interceptor.afterStart );
-		assertEquals( 1, interceptor.beforeCompletion );
-		assertEquals( 1, interceptor.afterCompletion );
-	}
-
-	private static class JournalingInterceptor extends EmptyInterceptor implements Interceptor {
-		int afterStart;
-		int beforeCompletion;
-		int afterCompletion;
-
-		@Override
-		public void afterTransactionBegin(Transaction tx) {
-			afterStart++;
-		}
-
-		@Override
-		public void afterTransactionCompletion(Transaction tx) {
-			afterCompletion++;
-		}
-
-		@Override
-		public void beforeTransactionCompletion(Transaction tx) {
-			beforeCompletion++;
-		}
-	}
-
-}
diff --git a/hibernate-core/src/test/java/org/hibernate/test/transaction/jta/ManagedDrivingTest.java b/hibernate-core/src/test/java/org/hibernate/test/transaction/jta/ManagedDrivingTest.java
deleted file mode 100644
index 80e5f654bc..0000000000
--- a/hibernate-core/src/test/java/org/hibernate/test/transaction/jta/ManagedDrivingTest.java
+++ /dev/null
@@ -1,177 +0,0 @@
-/*
- * Hibernate, Relational Persistence for Idiomatic Java
- *
- * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
- * indicated by the @author tags or express copyright attribution
- * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Inc.
- *
- * This copyrighted material is made available to anyone wishing to use, modify,
- * copy, or redistribute it subject to the terms and conditions of the GNU
- * Lesser General Public License, as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
- * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
- * for more details.
- *
- * You should have received a copy of the GNU Lesser General Public License
- * along with this distribution; if not, write to:
- * Free Software Foundation, Inc.
- * 51 Franklin Street, Fifth Floor
- * Boston, MA  02110-1301  USA
- */
-package org.hibernate.test.transaction.jta;
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.fail;
-
-import java.sql.PreparedStatement;
-import java.sql.SQLException;
-import java.sql.Statement;
-import java.util.HashMap;
-import java.util.Map;
-
-import javax.transaction.TransactionManager;
-
-import org.hibernate.ConnectionReleaseMode;
-import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
-import org.hibernate.boot.registry.internal.StandardServiceRegistryImpl;
-import org.hibernate.cfg.Environment;
-import org.hibernate.dialect.H2Dialect;
-import org.hibernate.engine.jdbc.spi.JdbcCoordinator;
-import org.hibernate.engine.jdbc.spi.LogicalConnectionImplementor;
-import org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl;
-import org.hibernate.engine.transaction.internal.jta.CMTTransactionFactory;
-import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
-import org.hibernate.engine.transaction.spi.TransactionContext;
-import org.hibernate.engine.transaction.spi.TransactionImplementor;
-import org.hibernate.test.common.JournalingTransactionObserver;
-import org.hibernate.test.common.TransactionContextImpl;
-import org.hibernate.test.common.TransactionEnvironmentImpl;
-import org.hibernate.testing.RequiresDialect;
-import org.hibernate.testing.jta.TestingJtaBootstrap;
-import org.hibernate.testing.junit4.BaseUnitTestCase;
-import org.junit.After;
-import org.junit.Before;
-import org.junit.Test;
-
-/**
- * Testing transaction facade handling when the transaction is being driven by something other than the facade.
- *
- * @author Steve Ebersole
- */
-@RequiresDialect(H2Dialect.class)
-public class ManagedDrivingTest extends BaseUnitTestCase {
-	private StandardServiceRegistryImpl serviceRegistry;
-
-	@Before
-	@SuppressWarnings( {"unchecked"})
-	public void setUp() throws Exception {
-		Map configValues = new HashMap();
-		TestingJtaBootstrap.prepare( configValues );
-		configValues.put( Environment.TRANSACTION_STRATEGY, CMTTransactionFactory.class.getName() );
-
-		serviceRegistry = (StandardServiceRegistryImpl) new StandardServiceRegistryBuilder()
-				.applySettings( configValues )
-				.build();
-	}
-
-	@After
-	public void tearDown() throws Exception {
-		serviceRegistry.destroy();
-	}
-
-	@Test
-	public void testBasicUsage() throws Throwable {
-		final TransactionContext transactionContext = new TransactionContextImpl( new TransactionEnvironmentImpl( serviceRegistry ) ) {
-			@Override
-			public ConnectionReleaseMode getConnectionReleaseMode() {
-				return ConnectionReleaseMode.AFTER_STATEMENT;
-			}
-		};
-
-		final TransactionCoordinatorImpl transactionCoordinator = new TransactionCoordinatorImpl( null, transactionContext );
-		final JournalingTransactionObserver transactionObserver = new JournalingTransactionObserver();
-		transactionCoordinator.addObserver( transactionObserver );
-
-		JdbcCoordinator jdbcCoordinator = transactionCoordinator.getJdbcCoordinator();
-		LogicalConnectionImplementor logicalConnection = jdbcCoordinator.getLogicalConnection();
-
-		// set up some tables to use
-		Statement statement = jdbcCoordinator.getStatementPreparer().createStatement();
-		jdbcCoordinator.getResultSetReturn().execute( statement, "drop table SANDBOX_JDBC_TST if exists" );
-		jdbcCoordinator.getResultSetReturn().execute( statement, "create table SANDBOX_JDBC_TST ( ID integer, NAME varchar(100) )" );
-		assertTrue( jdbcCoordinator.hasRegisteredResources() );
-		assertTrue( logicalConnection.isPhysicallyConnected() );
-		jdbcCoordinator.release( statement );
-		assertFalse( jdbcCoordinator.hasRegisteredResources() );
-		assertFalse( logicalConnection.isPhysicallyConnected() ); // after_statement specified
-
-		JtaPlatform instance = serviceRegistry.getService( JtaPlatform.class );
-		TransactionManager transactionManager = instance.retrieveTransactionManager();
-
-		// start the cmt
-		transactionManager.begin();
-
-		// ok, now we can get down to it...
-		TransactionImplementor txn = transactionCoordinator.getTransaction();  // same as Session#getTransaction
-		txn.begin();
-		assertEquals( 1, transactionObserver.getBegins() );
-		assertFalse( txn.isInitiator() );
-		try {
-			PreparedStatement ps = jdbcCoordinator.getStatementPreparer().prepareStatement( "insert into SANDBOX_JDBC_TST( ID, NAME ) values ( ?, ? )" );
-			ps.setLong( 1, 1 );
-			ps.setString( 2, "name" );
-			jdbcCoordinator.getResultSetReturn().execute( ps );
-			assertTrue( jdbcCoordinator.hasRegisteredResources() );
-			jdbcCoordinator.release( ps );
-			assertFalse( jdbcCoordinator.hasRegisteredResources() );
-
-			ps = jdbcCoordinator.getStatementPreparer().prepareStatement( "select * from SANDBOX_JDBC_TST" );
-			jdbcCoordinator.getResultSetReturn().extract( ps );
-			ps = jdbcCoordinator.getStatementPreparer().prepareStatement( "delete from SANDBOX_JDBC_TST" );
-			jdbcCoordinator.getResultSetReturn().execute( ps );
-			// lets forget to close these...
-			assertTrue( jdbcCoordinator.hasRegisteredResources() );
-			assertTrue( logicalConnection.isPhysicallyConnected() );
-
-			// and commit the transaction...
-			txn.commit();
-
-			// since txn is not a driver, nothing should have changed...
-			assertTrue( jdbcCoordinator.hasRegisteredResources() );
-			assertTrue( logicalConnection.isPhysicallyConnected() );
-			assertEquals( 0, transactionObserver.getBeforeCompletions() );
-			assertEquals( 0, transactionObserver.getAfterCompletions() );
-
-			transactionManager.commit();
-			assertFalse( jdbcCoordinator.hasRegisteredResources() );
-			assertFalse( logicalConnection.isPhysicallyConnected() );
-			assertEquals( 1, transactionObserver.getBeforeCompletions() );
-			assertEquals( 1, transactionObserver.getAfterCompletions() );
-		}
-		catch ( SQLException sqle ) {
-			try {
-				transactionManager.rollback();
-			}
-			catch (Exception ignore) {
-			}
-			fail( "incorrect exception type : SQLException" );
-		}
-		catch (Throwable reThrowable) {
-			try {
-				transactionManager.rollback();
-			}
-			catch (Exception ignore) {
-			}
-			throw reThrowable;
-		}
-		finally {
-			logicalConnection.close();
-			transactionContext.getTransactionEnvironment().getSessionFactory().close();
-		}
-	}
-}
diff --git a/hibernate-core/src/test/java/org/hibernate/test/typeparameters/TypeParameterTest.java b/hibernate-core/src/test/java/org/hibernate/test/typeparameters/TypeParameterTest.java
index 4ac8c9b213..8024a87d6f 100644
--- a/hibernate-core/src/test/java/org/hibernate/test/typeparameters/TypeParameterTest.java
+++ b/hibernate-core/src/test/java/org/hibernate/test/typeparameters/TypeParameterTest.java
@@ -1,152 +1,152 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2006-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.typeparameters;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.jdbc.Work;
 import org.hibernate.testing.junit4.BaseCoreFunctionalTestCase;
 import org.junit.Test;
 
 /**
  * Test for parameterizable types.
  * 
  * @author Michael Gloegl
  */
 public class TypeParameterTest extends BaseCoreFunctionalTestCase {
 	public String[] getMappings() {
 		return new String[] {
 				"typeparameters/Typedef.hbm.xml",
 				"typeparameters/Widget.hbm.xml"
 		};
 	}
 
 	@Test
 	public void testSave() throws Exception {
 		deleteData();
 
 		Session s = openSession();
 		s.beginTransaction();
 		Widget obj = new Widget();
 		obj.setValueThree(5);
 		final Integer id = (Integer) s.save(obj);
 		s.getTransaction().commit();
 		s.close();
 
 		s = openSession();
 		s.beginTransaction();
 
 		doWork(id, s);
 
 		s.getTransaction().commit();
 		s.close();
 
 		deleteData();
 	}
 	
 	private void doWork(final Integer id, final Session s) {
 		s.doWork(
 				new Work() {
 					@Override
 					public void execute(Connection connection) throws SQLException {
-						PreparedStatement statement = ((SessionImplementor)s).getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( "SELECT * FROM STRANGE_TYPED_OBJECT WHERE ID=?" );
+						PreparedStatement statement = ((SessionImplementor)s).getJdbcCoordinator().getStatementPreparer().prepareStatement( "SELECT * FROM STRANGE_TYPED_OBJECT WHERE ID=?" );
 						statement.setInt(1, id.intValue());
-						ResultSet resultSet = ((SessionImplementor)s).getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( statement );
+						ResultSet resultSet = ((SessionImplementor)s).getJdbcCoordinator().getResultSetReturn().extract( statement );
 
 						assertTrue("A row should have been returned", resultSet.next());
 						assertTrue("Default value should have been mapped to null", resultSet.getObject("VALUE_ONE") == null);
 						assertTrue("Default value should have been mapped to null", resultSet.getObject("VALUE_TWO") == null);
 						assertEquals("Non-Default value should not be changed", resultSet.getInt("VALUE_THREE"), 5);
 						assertTrue("Default value should have been mapped to null", resultSet.getObject("VALUE_FOUR") == null);
 					}
 				}
 		);
 	}
 
 	@Test
 	public void testLoading() throws Exception {
 		initData();
 
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 
 		Widget obj = (Widget) s.createQuery("from Widget o where o.string = :string").setString("string", "all-normal").uniqueResult();
 		assertEquals("Non-Default value incorrectly loaded", obj.getValueOne(), 7);
 		assertEquals("Non-Default value incorrectly loaded", obj.getValueTwo(), 8);
 		assertEquals("Non-Default value incorrectly loaded", obj.getValueThree(), 9);
 		assertEquals("Non-Default value incorrectly loaded", obj.getValueFour(), 10);
 
 		obj = (Widget) s.createQuery("from Widget o where o.string = :string").setString("string", "all-default").uniqueResult();
 		assertEquals("Default value incorrectly loaded", obj.getValueOne(), 1);
 		assertEquals("Default value incorrectly loaded", obj.getValueTwo(), 2);
 		assertEquals("Default value incorrectly loaded", obj.getValueThree(), -1);
 		assertEquals("Default value incorrectly loaded", obj.getValueFour(), -5);
 
 		
 		t.commit();
 		s.close();
 		deleteData();
 	}
 
 	private void initData() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 
 		Widget obj = new Widget();
 		obj.setValueOne(7);
 		obj.setValueTwo(8);
 		obj.setValueThree(9);
 		obj.setValueFour(10);
 		obj.setString("all-normal");
 		s.save(obj);
 
 		obj = new Widget();
 		obj.setValueOne(1);
 		obj.setValueTwo(2);
 		obj.setValueThree(-1);
 		obj.setValueFour(-5);
 		obj.setString("all-default");
 		s.save(obj);
 
 		t.commit();
 		s.close();
 	}
 
 	private void deleteData() throws Exception {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		s.createQuery( "delete from Widget" ).executeUpdate();
 		t.commit();
 		s.close();
 	}
 }
diff --git a/hibernate-ehcache/src/test/java/org/hibernate/test/cache/ehcache/EhCacheTest.java b/hibernate-ehcache/src/test/java/org/hibernate/test/cache/ehcache/EhCacheTest.java
index b36ca4fa4a..203b5309aa 100644
--- a/hibernate-ehcache/src/test/java/org/hibernate/test/cache/ehcache/EhCacheTest.java
+++ b/hibernate-ehcache/src/test/java/org/hibernate/test/cache/ehcache/EhCacheTest.java
@@ -1,206 +1,205 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2007-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.ehcache;
 
 import java.util.Map;
 
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.cfg.Environment;
-import org.hibernate.engine.transaction.internal.jdbc.JdbcTransactionFactory;
 import org.hibernate.stat.SecondLevelCacheStatistics;
 import org.hibernate.stat.Statistics;
 
 import org.hibernate.testing.junit4.BaseNonConfigCoreFunctionalTestCase;
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author Emmanuel Bernard
  * @author Alex Snaps
  */
 public abstract class EhCacheTest extends BaseNonConfigCoreFunctionalTestCase {
 	@Override
 	public String getBaseForMappings() {
 		return "org/hibernate/test/cache/ehcache/";
 	}
 
 	@Override
 	public String[] getMappings() {
 		return new String[] { "Item.hbm.xml" };
 	}
 
 	@Override
 	public String getCacheConcurrencyStrategy() {
 		return "read-write";
 	}
 
 	@Override
 	protected void addSettings(Map settings) {
 		super.addSettings( settings );
 		settings.put( Environment.CACHE_REGION_PREFIX, "" );
 		settings.put( Environment.USE_SECOND_LEVEL_CACHE, "true" );
 		settings.put( Environment.GENERATE_STATISTICS, "true" );
 		settings.put( Environment.USE_STRUCTURED_CACHE, "true" );
-		settings.put( Environment.TRANSACTION_STRATEGY, JdbcTransactionFactory.class.getName() );
+//		settings.put( Environment.TRANSACTION_STRATEGY, JdbcTransactionFactory.class.getName() );
 	}
 
 	@Test
 	public void testQueryCacheInvalidation() {
 		Session s = openSession();
 		Transaction t = s.beginTransaction();
 		Item i = new Item();
 		i.setName( "widget" );
 		i.setDescription( "A really top-quality, full-featured widget." );
 		s.persist( i );
 		t.commit();
 		s.close();
 
 		SecondLevelCacheStatistics slcs = s.getSessionFactory().getStatistics()
 				.getSecondLevelCacheStatistics( Item.class.getName() );
 
 		assertEquals( slcs.getPutCount(), 1 );
 		assertEquals( slcs.getElementCountInMemory(), 1 );
 		assertEquals( slcs.getEntries().size(), 1 );
 
 		s = openSession();
 		t = s.beginTransaction();
 		i = (Item) s.get( Item.class, i.getId() );
 
 		assertEquals( slcs.getHitCount(), 1 );
 		assertEquals( slcs.getMissCount(), 0 );
 
 		i.setDescription( "A bog standard item" );
 
 		t.commit();
 		s.close();
 
 		assertEquals( slcs.getPutCount(), 2 );
 
 		Object entry = slcs.getEntries().get( i.getId() );
 		Map map;
 		map = getMapFromCacheEntry( entry );
 		assertTrue( map.get( "description" ).equals( "A bog standard item" ) );
 		assertTrue( map.get( "name" ).equals( "widget" ) );
 
 		// cleanup
 		s = openSession();
 		t = s.beginTransaction();
 		s.delete( i );
 		t.commit();
 		s.close();
 	}
 
 	protected abstract Map getMapFromCacheEntry(final Object entry);
 
 	@Test
 	public void testEmptySecondLevelCacheEntry() throws Exception {
 		sessionFactory().getCache().evictEntityRegion( Item.class.getName() );
 		Statistics stats = sessionFactory().getStatistics();
 		stats.clear();
 		SecondLevelCacheStatistics statistics = stats.getSecondLevelCacheStatistics( Item.class.getName() );
 		Map cacheEntries = statistics.getEntries();
 		assertEquals( 0, cacheEntries.size() );
 	}
 
 	@SuppressWarnings( { "UnnecessaryBoxing", "UnnecessaryUnboxing", "UnusedAssignment" })
 	@Test
 	public void testStaleWritesLeaveCacheConsistent() {
 		Session s = openSession();
 		Transaction txn = s.beginTransaction();
 		VersionedItem item = new VersionedItem();
 		item.setName( "steve" );
 		item.setDescription( "steve's item" );
 		s.save( item );
 		txn.commit();
 		s.close();
 
 		Long initialVersion = item.getVersion();
 
 		// manually revert the version property
 		item.setVersion( Long.valueOf( item.getVersion().longValue() - 1 ) );
 
 		try {
 			s = openSession();
 			txn = s.beginTransaction();
 			s.update( item );
 			txn.commit();
 			s.close();
 			fail( "expected stale write to fail" );
 		}
 		catch ( Throwable expected ) {
 			// expected behavior here
 			if ( txn != null ) {
 				try {
 					txn.rollback();
 				}
 				catch ( Throwable ignore ) {
 				}
 			}
 		}
 		finally {
 			if ( s != null && s.isOpen() ) {
 				try {
 					s.close();
 				}
 				catch ( Throwable ignore ) {
 				}
 			}
 		}
 
 		// check the version value in the cache...
 		SecondLevelCacheStatistics slcs = sessionFactory().getStatistics()
 				.getSecondLevelCacheStatistics( VersionedItem.class.getName() );
 
 		Object entry = slcs.getEntries().get( item.getId() );
 		Long cachedVersionValue;
 //		if ( entry instanceof ReadWriteCache.Lock ) {
 //			//FIXME don't know what to test here
 //			cachedVersionValue = Long.valueOf( ((ReadWriteCache.Lock) entry).getUnlockTimestamp() );
 //		} else
 		if ( entry.getClass()
 				.getName()
 				.equals( "org.hibernate.cache.ehcache.internal.strategy.AbstractReadWriteEhcacheAccessStrategy$Lock" ) ) {
 			//FIXME don't know what to test here
 		}
 		else {
 			cachedVersionValue = (Long) getMapFromCacheEntry( entry ).get( "_version" );
 			assertEquals( initialVersion.longValue(), cachedVersionValue.longValue() );
 		}
 
 
 		// cleanup
 		s = openSession();
 		txn = s.beginTransaction();
 		item = (VersionedItem) s.load( VersionedItem.class, item.getId() );
 		s.delete( item );
 		txn.commit();
 		s.close();
 
 	}
 
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/internal/EntityManagerFactoryBuilderImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/internal/EntityManagerFactoryBuilderImpl.java
index 750a4e4b1c..ce9c3fb02f 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/internal/EntityManagerFactoryBuilderImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/internal/EntityManagerFactoryBuilderImpl.java
@@ -1,916 +1,916 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.boot.internal;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.StringTokenizer;
 import java.util.concurrent.ConcurrentHashMap;
 import javax.persistence.AttributeConverter;
 import javax.persistence.EntityManagerFactory;
 import javax.persistence.EntityNotFoundException;
 import javax.persistence.PersistenceException;
 import javax.persistence.spi.PersistenceUnitTransactionType;
 import javax.sql.DataSource;
 
 import org.hibernate.Interceptor;
 import org.hibernate.SessionFactory;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.boot.CacheRegionDefinition;
 import org.hibernate.boot.MetadataBuilder;
 import org.hibernate.boot.MetadataSources;
 import org.hibernate.boot.SessionFactoryBuilder;
 import org.hibernate.boot.archive.scan.internal.StandardScanOptions;
 import org.hibernate.boot.cfgxml.internal.ConfigLoader;
 import org.hibernate.boot.cfgxml.spi.LoadedConfig;
 import org.hibernate.boot.model.TypeContributor;
 import org.hibernate.boot.registry.BootstrapServiceRegistry;
 import org.hibernate.boot.registry.BootstrapServiceRegistryBuilder;
 import org.hibernate.boot.registry.StandardServiceRegistry;
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.boot.registry.selector.StrategyRegistrationProvider;
 import org.hibernate.boot.registry.selector.spi.StrategySelector;
 import org.hibernate.boot.spi.MetadataImplementor;
 import org.hibernate.cfg.AttributeConverterDefinition;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.beanvalidation.BeanValidationIntegrator;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.engine.transaction.internal.jdbc.JdbcTransactionFactory;
-import org.hibernate.engine.transaction.internal.jta.CMTTransactionFactory;
 import org.hibernate.id.factory.spi.MutableIdentifierGeneratorFactory;
 import org.hibernate.integrator.spi.Integrator;
 import org.hibernate.internal.log.DeprecationLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.jpa.AvailableSettings;
 import org.hibernate.jpa.boot.spi.EntityManagerFactoryBuilder;
 import org.hibernate.jpa.boot.spi.IntegratorProvider;
 import org.hibernate.jpa.boot.spi.PersistenceUnitDescriptor;
 import org.hibernate.jpa.boot.spi.StrategyRegistrationProviderList;
 import org.hibernate.jpa.boot.spi.TypeContributorList;
 import org.hibernate.jpa.event.spi.JpaIntegrator;
 import org.hibernate.jpa.internal.EntityManagerFactoryImpl;
 import org.hibernate.jpa.internal.EntityManagerMessageLogger;
 import org.hibernate.jpa.internal.schemagen.JpaSchemaGenerator;
 import org.hibernate.jpa.internal.util.LogHelper;
 import org.hibernate.jpa.internal.util.PersistenceUnitTransactionTypeHelper;
 import org.hibernate.jpa.spi.IdentifierGeneratorStrategyProvider;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.proxy.EntityNotFoundDelegate;
+import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorBuilderImpl;
+import org.hibernate.resource.transaction.backend.store.internal.ResourceLocalTransactionCoordinatorBuilderImpl;
 import org.hibernate.secure.spi.GrantedPermission;
 import org.hibernate.secure.spi.JaccPermissionDeclarations;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 
 import org.jboss.jandex.Index;
 import org.jboss.logging.Logger;
 
 import static org.hibernate.cfg.AvailableSettings.JACC_CONTEXT_ID;
 import static org.hibernate.cfg.AvailableSettings.JACC_PREFIX;
 import static org.hibernate.cfg.AvailableSettings.SESSION_FACTORY_NAME;
 import static org.hibernate.jpa.AvailableSettings.CFG_FILE;
 import static org.hibernate.jpa.AvailableSettings.CLASS_CACHE_PREFIX;
 import static org.hibernate.jpa.AvailableSettings.COLLECTION_CACHE_PREFIX;
 import static org.hibernate.jpa.AvailableSettings.DISCARD_PC_ON_CLOSE;
 import static org.hibernate.jpa.AvailableSettings.PERSISTENCE_UNIT_NAME;
 import static org.hibernate.jpa.AvailableSettings.SHARED_CACHE_MODE;
 import static org.hibernate.jpa.AvailableSettings.VALIDATION_MODE;
 
 /**
  * @author Steve Ebersole
  */
 public class EntityManagerFactoryBuilderImpl implements EntityManagerFactoryBuilder {
     private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(
 			EntityManagerMessageLogger.class,
 			EntityManagerFactoryBuilderImpl.class.getName()
 	);
 
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// New settings
 
 	/**
 	 * Names a {@link IntegratorProvider}
 	 */
 	public static final String INTEGRATOR_PROVIDER = "hibernate.integrator_provider";
 	
 	/**
 	 * Names a {@link StrategyRegistrationProviderList}
 	 */
 	public static final String STRATEGY_REGISTRATION_PROVIDERS = "hibernate.strategy_registration_provider";
 	
 	/**
 	 * Names a {@link TypeContributorList}
 	 */
 	public static final String TYPE_CONTRIBUTORS = "hibernate.type_contributors";
 
 	/**
 	 * Names a Jandex {@link Index} instance to use.
 	 */
 	public static final String JANDEX_INDEX = "hibernate.jandex_index";
 
 
 	private final PersistenceUnitDescriptor persistenceUnit;
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// things built in first phase, needed for second phase..
 	private final Map configurationValues;
 	private final StandardServiceRegistry standardServiceRegistry;
 	private final MetadataImplementor metadata;
 	private final SettingsImpl settings;
 
 	/**
 	 * Intended for internal testing only...
 	 */
 	public MetadataImplementor getMetadata() {
 		return metadata;
 	}
 
 	private static class JpaEntityNotFoundDelegate implements EntityNotFoundDelegate, Serializable {
 		/**
 		 * Singleton access
 		 */
 		public static final JpaEntityNotFoundDelegate INSTANCE = new JpaEntityNotFoundDelegate();
 
 		public void handleEntityNotFound(String entityName, Serializable id) {
 			throw new EntityNotFoundException( "Unable to find " + entityName  + " with id " + id );
 		}
 	}
 
 	public EntityManagerFactoryBuilderImpl(PersistenceUnitDescriptor persistenceUnit, Map integrationSettings) {
 		this( persistenceUnit, integrationSettings, null );
 	}
 
 	public EntityManagerFactoryBuilderImpl(
 			PersistenceUnitDescriptor persistenceUnit,
 			Map integrationSettings,
 			ClassLoader providedClassLoader ) {
 		
 		LogHelper.logPersistenceUnitInformation( persistenceUnit );
 
 		this.persistenceUnit = persistenceUnit;
 
 		if ( integrationSettings == null ) {
 			integrationSettings = Collections.emptyMap();
 		}
 
 		// Build the boot-strap service registry, which mainly handles class loader interactions
 		final BootstrapServiceRegistry bsr = buildBootstrapServiceRegistry( integrationSettings, providedClassLoader );
 
 		// merge configuration sources and build the "standard" service registry
 		final StandardServiceRegistryBuilder ssrBuilder = new StandardServiceRegistryBuilder( bsr );
 		final MergedSettings mergedSettings = mergeSettings( persistenceUnit, integrationSettings, ssrBuilder );
 		this.configurationValues = mergedSettings.getConfigurationValues();
 
 		// Build the "standard" service registry
 		ssrBuilder.applySettings( configurationValues );
 		this.settings = configure( ssrBuilder );
 		this.standardServiceRegistry = ssrBuilder.build();
 		configure( standardServiceRegistry, mergedSettings );
 
 		final MetadataSources metadataSources = new MetadataSources( bsr );
 		List<AttributeConverterDefinition> attributeConverterDefinitions = populate( metadataSources, mergedSettings, standardServiceRegistry );
 		final MetadataBuilder metamodelBuilder = metadataSources.getMetadataBuilder( standardServiceRegistry );
 		populate( metamodelBuilder, mergedSettings, standardServiceRegistry, attributeConverterDefinitions );
 		this.metadata = (MetadataImplementor) metamodelBuilder.build();
 
 		withValidatorFactory( configurationValues.get( AvailableSettings.VALIDATION_FACTORY ) );
 
 		// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 		// push back class transformation to the environment; for the time being this only has any effect in EE
 		// container situations, calling back into PersistenceUnitInfo#addClassTransformer
 		final boolean useClassTransformer = "true".equals( configurationValues.remove( AvailableSettings.USE_CLASS_ENHANCER ) );
 		if ( useClassTransformer ) {
 			persistenceUnit.pushClassTransformer( collectNamesOfClassesToEnhance( metadata ) );
 		}
 	}
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	// temporary!
 	@SuppressWarnings("unchecked")
 	public Map getConfigurationValues() {
 		return Collections.unmodifiableMap( configurationValues );
 	}
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 
 	/**
 	 * Builds the {@link BootstrapServiceRegistry} used to eventually build the {@link org.hibernate.boot.registry.StandardServiceRegistryBuilder}; mainly
 	 * used here during instantiation to define class-loading behavior.
 	 *
 	 * @param integrationSettings Any integration settings passed by the EE container or SE application
 	 *
 	 * @return The built BootstrapServiceRegistry
 	 */
 	private BootstrapServiceRegistry buildBootstrapServiceRegistry(
 			Map integrationSettings,
 			ClassLoader providedClassLoader) {
 		final BootstrapServiceRegistryBuilder bsrBuilder = new BootstrapServiceRegistryBuilder();
 		bsrBuilder.applyIntegrator( new JpaIntegrator() );
 
 		final IntegratorProvider integratorProvider = (IntegratorProvider) integrationSettings.get( INTEGRATOR_PROVIDER );
 		if ( integratorProvider != null ) {
 			for ( Integrator integrator : integratorProvider.getIntegrators() ) {
 				bsrBuilder.applyIntegrator( integrator );
 			}
 		}
 		
 		final StrategyRegistrationProviderList strategyRegistrationProviderList
 				= (StrategyRegistrationProviderList) integrationSettings.get( STRATEGY_REGISTRATION_PROVIDERS );
 		if ( strategyRegistrationProviderList != null ) {
 			for ( StrategyRegistrationProvider strategyRegistrationProvider : strategyRegistrationProviderList
 					.getStrategyRegistrationProviders() ) {
 				bsrBuilder.withStrategySelectors( strategyRegistrationProvider );
 			}
 		}
 
 
 		// ClassLoaders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 		if ( persistenceUnit.getClassLoader() != null ) {
 			bsrBuilder.applyClassLoader( persistenceUnit.getClassLoader() );
 		}
 
 		if ( providedClassLoader != null ) {
 			bsrBuilder.applyClassLoader( providedClassLoader );
 		}
 
 		final ClassLoader appClassLoader = (ClassLoader) integrationSettings.get( org.hibernate.cfg.AvailableSettings.APP_CLASSLOADER );
 		if ( appClassLoader != null ) {
 			LOG.debugf(
 					"Found use of deprecated `%s` setting; use `%s` instead.",
 					org.hibernate.cfg.AvailableSettings.APP_CLASSLOADER,
 					org.hibernate.cfg.AvailableSettings.CLASSLOADERS
 			);
 		}
 		final Object classLoadersSetting = integrationSettings.get( org.hibernate.cfg.AvailableSettings.CLASSLOADERS );
 		if ( classLoadersSetting != null ) {
 			if ( java.util.Collection.class.isInstance( classLoadersSetting ) ) {
 				for ( ClassLoader classLoader : (java.util.Collection<ClassLoader>) classLoadersSetting ) {
 					bsrBuilder.applyClassLoader( classLoader );
 				}
 			}
 			else if ( classLoadersSetting.getClass().isArray() ) {
 				for ( ClassLoader classLoader : (ClassLoader[]) classLoadersSetting ) {
 					bsrBuilder.applyClassLoader( classLoader );
 				}
 			}
 			else if ( ClassLoader.class.isInstance( classLoadersSetting ) ) {
 				bsrBuilder.applyClassLoader( (ClassLoader) classLoadersSetting );
 			}
 		}
 
 		return bsrBuilder.build();
 	}
 
 	@SuppressWarnings("unchecked")
 	private MergedSettings mergeSettings(
 			PersistenceUnitDescriptor persistenceUnit,
 			Map<?,?> integrationSettings,
 			StandardServiceRegistryBuilder ssrBuilder) {
 		final MergedSettings mergedSettings = new MergedSettings();
 
 		// first, apply persistence.xml-defined settings
 		if ( persistenceUnit.getProperties() != null ) {
 			mergedSettings.configurationValues.putAll( persistenceUnit.getProperties() );
 		}
 
 		mergedSettings.configurationValues.put( PERSISTENCE_UNIT_NAME, persistenceUnit.getName() );
 
 		final ConfigLoader configLoader = new ConfigLoader( ssrBuilder.getBootstrapServiceRegistry() );
 
 		// see if the persistence.xml settings named a Hibernate config file....
 		final String cfgXmlResourceName1 = (String) mergedSettings.configurationValues.remove( CFG_FILE );
 		if ( StringHelper.isNotEmpty( cfgXmlResourceName1 ) ) {
 			final LoadedConfig loadedCfg = configLoader.loadConfigXmlResource( cfgXmlResourceName1 );
 			processConfigXml( loadedCfg, mergedSettings, ssrBuilder );
 		}
 
 		// see if integration settings named a Hibernate config file....
 		final String cfgXmlResourceName2 = (String) integrationSettings.get( CFG_FILE );
 		if ( StringHelper.isNotEmpty( cfgXmlResourceName2 ) ) {
 			integrationSettings.remove( CFG_FILE );
 			final LoadedConfig loadedCfg = configLoader.loadConfigXmlResource( cfgXmlResourceName2 );
 			processConfigXml( loadedCfg, mergedSettings, ssrBuilder );
 		}
 
 		// finally, apply integration-supplied settings (per JPA spec, integration settings should override other sources)
 		for ( Map.Entry<?,?> entry : integrationSettings.entrySet() ) {
 			if ( entry.getKey() == null ) {
 				continue;
 			}
 
 			if ( entry.getValue() == null ) {
 				mergedSettings.configurationValues.remove( entry.getKey() );
 			}
 			else {
 				mergedSettings.configurationValues.put( entry.getKey(), entry.getValue() );
 			}
 		}
 
 		if ( !mergedSettings.configurationValues.containsKey( VALIDATION_MODE ) ) {
 			if ( persistenceUnit.getValidationMode() != null ) {
 				mergedSettings.configurationValues.put( VALIDATION_MODE, persistenceUnit.getValidationMode() );
 			}
 		}
 
 		if ( !mergedSettings.configurationValues.containsKey( SHARED_CACHE_MODE ) ) {
 			if ( persistenceUnit.getSharedCacheMode() != null ) {
 				mergedSettings.configurationValues.put( SHARED_CACHE_MODE, persistenceUnit.getSharedCacheMode() );
 			}
 		}
 
 		final String jaccContextId = (String) mergedSettings.configurationValues.get( JACC_CONTEXT_ID );
 
 		// here we are going to iterate the merged config settings looking for:
 		//		1) additional JACC permissions
 		//		2) additional cache region declarations
 		//
 		// we will also clean up an references with null entries
 		Iterator itr = mergedSettings.configurationValues.entrySet().iterator();
 		while ( itr.hasNext() ) {
 			final Map.Entry entry = (Map.Entry) itr.next();
 			if ( entry.getValue() == null ) {
 				// remove entries with null values
 				itr.remove();
 				break;
 			}
 
 			if ( String.class.isInstance( entry.getKey() ) && String.class.isInstance( entry.getValue() ) ) {
 				final String keyString = (String) entry.getKey();
 				final String valueString = (String) entry.getValue();
 
 				if ( keyString.startsWith( JACC_PREFIX ) ) {
 					if ( jaccContextId == null ) {
 						LOG.debug(
 								"Found JACC permission grant [%s] in properties, but no JACC context id was specified; ignoring"
 						);
 					}
 					else {
 						mergedSettings.getJaccPermissions( jaccContextId ).addPermissionDeclaration(
 								parseJaccConfigEntry( keyString, valueString )
 						);
 					}
 				}
 				else if ( keyString.startsWith( CLASS_CACHE_PREFIX ) ) {
 					mergedSettings.addCacheRegionDefinition(
 							parseCacheRegionDefinitionEntry(
 									keyString.substring( CLASS_CACHE_PREFIX.length() + 1 ),
 									valueString,
 									CacheRegionDefinition.CacheRegionType.ENTITY
 							)
 					);
 				}
 				else if ( keyString.startsWith( COLLECTION_CACHE_PREFIX ) ) {
 					mergedSettings.addCacheRegionDefinition(
 							parseCacheRegionDefinitionEntry(
 									keyString.substring( COLLECTION_CACHE_PREFIX.length() + 1 ),
 									(String) entry.getValue(),
 									CacheRegionDefinition.CacheRegionType.COLLECTION
 							)
 					);
 				}
 			}
 
 		}
 
 		return mergedSettings;
 	}
 
 	@SuppressWarnings("unchecked")
 	private void processConfigXml(
 			LoadedConfig loadedConfig,
 			MergedSettings mergedSettings,
 			StandardServiceRegistryBuilder ssrBuilder) {
 		if ( ! mergedSettings.configurationValues.containsKey( SESSION_FACTORY_NAME ) ) {
 			// there is not already a SF-name in the merged settings
 			final String sfName = loadedConfig.getSessionFactoryName();
 			if ( sfName != null ) {
 				// but the cfg.xml file we are processing named one..
 				mergedSettings.configurationValues.put( SESSION_FACTORY_NAME, sfName );
 			}
 		}
 
 		mergedSettings.configurationValues.putAll( loadedConfig.getConfigurationValues() );
 		ssrBuilder.configure( loadedConfig );
 	}
 
 	private GrantedPermission parseJaccConfigEntry(String keyString, String valueString) {
 		try {
 			final int roleStart = JACC_PREFIX.length() + 1;
 			final String role = keyString.substring( roleStart, keyString.indexOf( '.', roleStart ) );
 			final int classStart = roleStart + role.length() + 1;
 			final String clazz = keyString.substring( classStart, keyString.length() );
 			return new GrantedPermission( role, clazz, valueString );
 		}
 		catch ( IndexOutOfBoundsException e ) {
 			throw persistenceException( "Illegal usage of " + JACC_PREFIX + ": " + keyString );
 		}
 	}
 
 	private CacheRegionDefinition parseCacheRegionDefinitionEntry(String role, String value, CacheRegionDefinition.CacheRegionType cacheType) {
 		final StringTokenizer params = new StringTokenizer( value, ";, " );
 		if ( !params.hasMoreTokens() ) {
 			StringBuilder error = new StringBuilder( "Illegal usage of " );
 			if ( cacheType == CacheRegionDefinition.CacheRegionType.ENTITY ) {
 				error.append( CLASS_CACHE_PREFIX )
 						.append( ": " )
 						.append( CLASS_CACHE_PREFIX );
 			}
 			else {
 				error.append( COLLECTION_CACHE_PREFIX )
 						.append( ": " )
 						.append( COLLECTION_CACHE_PREFIX );
 			}
 			error.append( '.' )
 					.append( role )
 					.append( ' ' )
 					.append( value )
 					.append( ".  Was expecting configuration (usage[,region[,lazy]]), but found none" );
 			throw persistenceException( error.toString() );
 		}
 
 		String usage = params.nextToken();
 		String region = null;
 		if ( params.hasMoreTokens() ) {
 			region = params.nextToken();
 		}
 		boolean lazyProperty = true;
 		if ( cacheType == CacheRegionDefinition.CacheRegionType.ENTITY ) {
 			if ( params.hasMoreTokens() ) {
 				lazyProperty = "all".equalsIgnoreCase( params.nextToken() );
 			}
 		}
 		else {
 			lazyProperty = false;
 		}
 
 		return new CacheRegionDefinition( cacheType, role, usage, region, lazyProperty );
 	}
 
 	private SettingsImpl configure(StandardServiceRegistryBuilder ssrBuilder) {
 		final SettingsImpl settings = new SettingsImpl();
 
 		applyJdbcConnectionProperties( ssrBuilder );
 		applyTransactionProperties( ssrBuilder, settings );
 
 		// flush before completion validation
 		if ( "true".equals( configurationValues.get( Environment.FLUSH_BEFORE_COMPLETION ) ) ) {
 			ssrBuilder.applySetting( Environment.FLUSH_BEFORE_COMPLETION, "false" );
 			LOG.definingFlushBeforeCompletionIgnoredInHem( Environment.FLUSH_BEFORE_COMPLETION );
 		}
 
 		final Object value = configurationValues.get( DISCARD_PC_ON_CLOSE );
 		if ( value != null ) {
 			settings.setReleaseResourcesOnCloseEnabled( "true".equals( value ) );
 		}
 
 		final StrategySelector strategySelector = ssrBuilder.getBootstrapServiceRegistry().getService( StrategySelector.class );
 		final Object interceptorSetting = configurationValues.remove( AvailableSettings.SESSION_INTERCEPTOR );
 		if ( interceptorSetting != null ) {
 			settings.setSessionInterceptorClass(
 					loadSessionInterceptorClass( interceptorSetting, strategySelector )
 			);
 		}
 
 		return settings;
 	}
 
 	private void applyJdbcConnectionProperties(StandardServiceRegistryBuilder ssrBuilder) {
 		if ( dataSource != null ) {
 			ssrBuilder.applySetting( org.hibernate.cfg.AvailableSettings.DATASOURCE, dataSource );
 		}
 		else if ( persistenceUnit.getJtaDataSource() != null ) {
 			if ( ! ssrBuilder.getSettings().containsKey( org.hibernate.cfg.AvailableSettings.DATASOURCE ) ) {
 				ssrBuilder.applySetting( org.hibernate.cfg.AvailableSettings.DATASOURCE, persistenceUnit.getJtaDataSource() );
 				// HHH-8121 : make the PU-defined value available to EMF.getProperties()
 				configurationValues.put( AvailableSettings.JTA_DATASOURCE, persistenceUnit.getJtaDataSource() );
 			}
 		}
 		else if ( persistenceUnit.getNonJtaDataSource() != null ) {
 			if ( ! ssrBuilder.getSettings().containsKey( org.hibernate.cfg.AvailableSettings.DATASOURCE ) ) {
 				ssrBuilder.applySetting( org.hibernate.cfg.AvailableSettings.DATASOURCE, persistenceUnit.getNonJtaDataSource() );
 				// HHH-8121 : make the PU-defined value available to EMF.getProperties()
 				configurationValues.put( AvailableSettings.NON_JTA_DATASOURCE, persistenceUnit.getNonJtaDataSource() );
 			}
 		}
 		else {
 			final String driver = (String) configurationValues.get( AvailableSettings.JDBC_DRIVER );
 			if ( StringHelper.isNotEmpty( driver ) ) {
 				ssrBuilder.applySetting( org.hibernate.cfg.AvailableSettings.DRIVER, driver );
 			}
 			final String url = (String) configurationValues.get( AvailableSettings.JDBC_URL );
 			if ( StringHelper.isNotEmpty( url ) ) {
 				ssrBuilder.applySetting( org.hibernate.cfg.AvailableSettings.URL, url );
 			}
 			final String user = (String) configurationValues.get( AvailableSettings.JDBC_USER );
 			if ( StringHelper.isNotEmpty( user ) ) {
 				ssrBuilder.applySetting( org.hibernate.cfg.AvailableSettings.USER, user );
 			}
 			final String pass = (String) configurationValues.get( AvailableSettings.JDBC_PASSWORD );
 			if ( StringHelper.isNotEmpty( pass ) ) {
 				ssrBuilder.applySetting( org.hibernate.cfg.AvailableSettings.PASS, pass );
 			}
 		}
 	}
 
 	private void applyTransactionProperties(StandardServiceRegistryBuilder ssrBuilder, SettingsImpl settings) {
 		PersistenceUnitTransactionType txnType = PersistenceUnitTransactionTypeHelper.interpretTransactionType(
 				configurationValues.get( AvailableSettings.TRANSACTION_TYPE )
 		);
 		if ( txnType == null ) {
 			txnType = persistenceUnit.getTransactionType();
 		}
 		if ( txnType == null ) {
 			// is it more appropriate to have this be based on bootstrap entry point (EE vs SE)?
 			txnType = PersistenceUnitTransactionType.RESOURCE_LOCAL;
 		}
 		settings.setTransactionType( txnType );
-		boolean hasTxStrategy = configurationValues.containsKey( Environment.TRANSACTION_STRATEGY );
+		boolean hasTxStrategy = configurationValues.containsKey( Environment.TRANSACTION_COORDINATOR_STRATEGY );
 		if ( hasTxStrategy ) {
-			LOG.overridingTransactionStrategyDangerous( Environment.TRANSACTION_STRATEGY );
+			LOG.overridingTransactionStrategyDangerous( Environment.TRANSACTION_COORDINATOR_STRATEGY );
 		}
 		else {
 			if ( txnType == PersistenceUnitTransactionType.JTA ) {
-				ssrBuilder.applySetting( Environment.TRANSACTION_STRATEGY, CMTTransactionFactory.class );
+				ssrBuilder.applySetting( Environment.TRANSACTION_COORDINATOR_STRATEGY, JtaTransactionCoordinatorBuilderImpl.class );
 			}
 			else if ( txnType == PersistenceUnitTransactionType.RESOURCE_LOCAL ) {
-				ssrBuilder.applySetting( Environment.TRANSACTION_STRATEGY, JdbcTransactionFactory.class );
+				ssrBuilder.applySetting( Environment.TRANSACTION_COORDINATOR_STRATEGY, ResourceLocalTransactionCoordinatorBuilderImpl.class );
 			}
 		}
 	}
 
 	@SuppressWarnings("unchecked")
 	private Class<? extends Interceptor> loadSessionInterceptorClass(Object value, StrategySelector strategySelector) {
 		if ( value == null ) {
 			return null;
 		}
 
 		return Class.class.isInstance( value )
 				? (Class<? extends Interceptor>) value
 				: strategySelector.selectStrategyImplementor( Interceptor.class, value.toString() );
 	}
 
 	private void configure(StandardServiceRegistry ssr, MergedSettings mergedSettings) {
 		final StrategySelector strategySelector = ssr.getService( StrategySelector.class );
 
 		// apply id generators
 		final Object idGeneratorStrategyProviderSetting = configurationValues.remove( AvailableSettings.IDENTIFIER_GENERATOR_STRATEGY_PROVIDER );
 		if ( idGeneratorStrategyProviderSetting != null ) {
 			final IdentifierGeneratorStrategyProvider idGeneratorStrategyProvider =
 					strategySelector.resolveStrategy( IdentifierGeneratorStrategyProvider.class, idGeneratorStrategyProviderSetting );
 			final MutableIdentifierGeneratorFactory identifierGeneratorFactory = ssr.getService( MutableIdentifierGeneratorFactory.class );
 			if ( identifierGeneratorFactory == null ) {
 				throw persistenceException(
 						"Application requested custom identifier generator strategies, " +
 								"but the MutableIdentifierGeneratorFactory could not be found"
 				);
 			}
 			for ( Map.Entry<String,Class<?>> entry : idGeneratorStrategyProvider.getStrategies().entrySet() ) {
 				identifierGeneratorFactory.register( entry.getKey(), entry.getValue() );
 			}
 		}
 	}
 
 	@SuppressWarnings("unchecked")
 	private List<AttributeConverterDefinition> populate(
 			MetadataSources metadataSources,
 			MergedSettings mergedSettings,
 			StandardServiceRegistry ssr) {
 //		final ClassLoaderService classLoaderService = ssr.getService( ClassLoaderService.class );
 //
 //		// todo : make sure MetadataSources/Metadata are capable of handling duplicate sources
 //
 //		// explicit persistence unit mapping files listings
 //		if ( persistenceUnit.getMappingFileNames() != null ) {
 //			for ( String name : persistenceUnit.getMappingFileNames() ) {
 //				metadataSources.addResource( name );
 //			}
 //		}
 //
 //		// explicit persistence unit managed class listings
 //		//		IMPL NOTE : managed-classes can contain class or package names!!!
 //		if ( persistenceUnit.getManagedClassNames() != null ) {
 //			for ( String managedClassName : persistenceUnit.getManagedClassNames() ) {
 //				// try it as a class name first...
 //				final String classFileName = managedClassName.replace( '.', '/' ) + ".class";
 //				final URL classFileUrl = classLoaderService.locateResource( classFileName );
 //				if ( classFileUrl != null ) {
 //					// it is a class
 //					metadataSources.addAnnotatedClassName( managedClassName );
 //					continue;
 //				}
 //
 //				// otherwise, try it as a package name
 //				final String packageInfoFileName = managedClassName.replace( '.', '/' ) + "/package-info.class";
 //				final URL packageInfoFileUrl = classLoaderService.locateResource( packageInfoFileName );
 //				if ( packageInfoFileUrl != null ) {
 //					// it is a package
 //					metadataSources.addPackage( managedClassName );
 //					continue;
 //				}
 //
 //				LOG.debugf(
 //						"Unable to resolve class [%s] named in persistence unit [%s]",
 //						managedClassName,
 //						persistenceUnit.getName()
 //				);
 //			}
 //		}
 
 		List<AttributeConverterDefinition> attributeConverterDefinitions = null;
 
 		// add any explicit Class references passed in
 		final List<Class> loadedAnnotatedClasses = (List<Class>) configurationValues.remove( AvailableSettings.LOADED_CLASSES );
 		if ( loadedAnnotatedClasses != null ) {
 			for ( Class cls : loadedAnnotatedClasses ) {
 				if ( AttributeConverter.class.isAssignableFrom( cls ) ) {
 					if ( attributeConverterDefinitions == null ) {
 						attributeConverterDefinitions = new ArrayList<AttributeConverterDefinition>();
 					}
 					attributeConverterDefinitions.add( AttributeConverterDefinition.from( (Class<? extends AttributeConverter>) cls ) );
 				}
 				else {
 					metadataSources.addAnnotatedClass( cls );
 				}
 			}
 		}
 
 		// add any explicit hbm.xml references passed in
 		final String explicitHbmXmls = (String) configurationValues.remove( AvailableSettings.HBXML_FILES );
 		if ( explicitHbmXmls != null ) {
 			for ( String hbmXml : StringHelper.split( ", ", explicitHbmXmls ) ) {
 				metadataSources.addResource( hbmXml );
 			}
 		}
 
 		// add any explicit orm.xml references passed in
 		final List<String> explicitOrmXmlList = (List<String>) configurationValues.remove( AvailableSettings.XML_FILE_NAMES );
 		if ( explicitOrmXmlList != null ) {
 			for ( String ormXml : explicitOrmXmlList ) {
 				metadataSources.addResource( ormXml );
 			}
 		}
 
 		return attributeConverterDefinitions;
 	}
 
 	private void populate(
 			MetadataBuilder metamodelBuilder,
 			MergedSettings mergedSettings,
 			StandardServiceRegistry ssr,
 			List<AttributeConverterDefinition> attributeConverterDefinitions) {
 		if ( persistenceUnit.getTempClassLoader() != null ) {
 			metamodelBuilder.applyTempClassLoader( persistenceUnit.getTempClassLoader() );
 		}
 
 		metamodelBuilder.applyScanEnvironment( new StandardJpaScanEnvironmentImpl( persistenceUnit ) );
 		metamodelBuilder.applyScanOptions(
 				new StandardScanOptions(
 						(String) configurationValues.get( org.hibernate.cfg.AvailableSettings.SCANNER_DISCOVERY ),
 						persistenceUnit.isExcludeUnlistedClasses()
 				)
 		);
 
 		if ( mergedSettings.cacheRegionDefinitions != null ) {
 			for ( CacheRegionDefinition localCacheRegionDefinition : mergedSettings.cacheRegionDefinitions ) {
 				metamodelBuilder.applyCacheRegionDefinition( localCacheRegionDefinition );
 			}
 		}
 
 		final Object namingStrategySetting = configurationValues.remove( AvailableSettings.NAMING_STRATEGY );
 		if ( namingStrategySetting != null ) {
 			DeprecationLogger.DEPRECATION_LOGGER.logDeprecatedNamingStrategySetting(
 					AvailableSettings.NAMING_STRATEGY,
 					org.hibernate.cfg.AvailableSettings.IMPLICIT_NAMING_STRATEGY,
 					org.hibernate.cfg.AvailableSettings.PHYSICAL_NAMING_STRATEGY
 			);
 		}
 
 		final TypeContributorList typeContributorList = (TypeContributorList) configurationValues.remove(
 				TYPE_CONTRIBUTORS
 		);
 		if ( typeContributorList != null ) {
 			for ( TypeContributor typeContributor : typeContributorList.getTypeContributors() ) {
 				metamodelBuilder.applyTypes( typeContributor );
 			}
 		}
 
 		if ( attributeConverterDefinitions != null ) {
 			for ( AttributeConverterDefinition attributeConverterDefinition : attributeConverterDefinitions ) {
 				metamodelBuilder.applyAttributeConverter( attributeConverterDefinition );
 			}
 		}
 	}
 
 	private List<String> collectNamesOfClassesToEnhance(MetadataImplementor metadata) {
 		final List<String> entityClassNames = new ArrayList<String>();
 		for ( PersistentClass persistentClass : metadata.getEntityBindings() ) {
 			if ( persistentClass.getClassName() != null ) {
 				entityClassNames.add( persistentClass.getClassName() );
 			}
 		}
 		return entityClassNames;
 	}
 
 
 
 
 	// Phase 2 concerns ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private Object validatorFactory;
 	private Object cdiBeanManager;
 	private DataSource dataSource;
 
 	@Override
 	public EntityManagerFactoryBuilder withValidatorFactory(Object validatorFactory) {
 		this.validatorFactory = validatorFactory;
 
 		if ( validatorFactory != null ) {
 			BeanValidationIntegrator.validateFactory( validatorFactory );
 		}
 		return this;
 	}
 
 	@Override
 	public EntityManagerFactoryBuilder withDataSource(DataSource dataSource) {
 		this.dataSource = dataSource;
 
 		return this;
 	}
 
 	@Override
 	public void cancel() {
 		// todo : close the bootstrap registry (not critical, but nice to do)
 	}
 
 	@Override
 	public void generateSchema() {
 		// This seems overkill, but building the SF is necessary to get the Integrators to kick in.
 		// Metamodel will clean this up...
 		try {
 			SessionFactoryBuilder sfBuilder = metadata.getSessionFactoryBuilder();
 			populate( sfBuilder, standardServiceRegistry );
 			sfBuilder.build();
 
 			JpaSchemaGenerator.performGeneration( metadata, configurationValues, standardServiceRegistry );
 		}
 		catch (Exception e) {
 			throw persistenceException( "Unable to build Hibernate SessionFactory", e );
 		}
 
 
 		// release this builder
 		cancel();
 	}
 
 	@SuppressWarnings("unchecked")
 	public EntityManagerFactory build() {
 		SessionFactoryBuilder sfBuilder = metadata.getSessionFactoryBuilder();
 		populate( sfBuilder, standardServiceRegistry );
 
 		SessionFactoryImplementor sessionFactory;
 		try {
 			sessionFactory = (SessionFactoryImplementor) sfBuilder.build();
 		}
 		catch (Exception e) {
 			throw persistenceException( "Unable to build Hibernate SessionFactory", e );
 		}
 
 		JpaSchemaGenerator.performGeneration( metadata, configurationValues, standardServiceRegistry );
 
 		return new EntityManagerFactoryImpl(
 				persistenceUnit.getName(),
 				sessionFactory,
 				metadata,
 				settings,
 				configurationValues
 		);
 	}
 
 	private void populate(SessionFactoryBuilder sfBuilder, StandardServiceRegistry ssr) {
 		final StrategySelector strategySelector = ssr.getService( StrategySelector.class );
 
 		// Locate and apply the requested SessionFactory-level interceptor (if one)
 		final Object sessionFactoryInterceptorSetting = configurationValues.remove( AvailableSettings.INTERCEPTOR );
 		if ( sessionFactoryInterceptorSetting != null ) {
 			final Interceptor sessionFactoryInterceptor =
 					strategySelector.resolveStrategy( Interceptor.class, sessionFactoryInterceptorSetting );
 			sfBuilder.applyInterceptor( sessionFactoryInterceptor );
 		}
 
 		// Locate and apply any requested SessionFactoryObserver
 		final Object sessionFactoryObserverSetting = configurationValues.remove( AvailableSettings.SESSION_FACTORY_OBSERVER );
 		if ( sessionFactoryObserverSetting != null ) {
 			final SessionFactoryObserver suppliedSessionFactoryObserver =
 					strategySelector.resolveStrategy( SessionFactoryObserver.class, sessionFactoryObserverSetting );
 			sfBuilder.addSessionFactoryObservers( suppliedSessionFactoryObserver );
 		}
 
 		sfBuilder.addSessionFactoryObservers( ServiceRegistryCloser.INSTANCE );
 
 		sfBuilder.applyEntityNotFoundDelegate( JpaEntityNotFoundDelegate.INSTANCE );
 
 		if ( this.validatorFactory != null ) {
 			sfBuilder.applyValidatorFactory( validatorFactory );
 		}
 		if ( this.cdiBeanManager != null ) {
 			sfBuilder.applyBeanManager( cdiBeanManager );
 		}
 	}
 
 
 	public static class ServiceRegistryCloser implements SessionFactoryObserver {
 		/**
 		 * Singleton access
 		 */
 		public static final ServiceRegistryCloser INSTANCE = new ServiceRegistryCloser();
 
 		@Override
 		public void sessionFactoryCreated(SessionFactory sessionFactory) {
 			// nothing to do
 		}
 
 		@Override
 		public void sessionFactoryClosed(SessionFactory sessionFactory) {
 			SessionFactoryImplementor sfi = ( (SessionFactoryImplementor) sessionFactory );
 			sfi.getServiceRegistry().destroy();
 			ServiceRegistry basicRegistry = sfi.getServiceRegistry().getParentServiceRegistry();
 			( (ServiceRegistryImplementor) basicRegistry ).destroy();
 		}
 	}
 
 	private PersistenceException persistenceException(String message) {
 		return persistenceException( message, null );
 	}
 
 	private PersistenceException persistenceException(String message, Exception cause) {
 		return new PersistenceException(
 				getExceptionHeader() + message,
 				cause
 		);
 	}
 
 	private String getExceptionHeader() {
 		return "[PersistenceUnit: " + persistenceUnit.getName() + "] ";
 	}
 
 	public static class MergedSettings {
 		private final Map configurationValues = new ConcurrentHashMap( 16, 0.75f, 1 );
 
 		private Map<String, JaccPermissionDeclarations> jaccPermissionsByContextId;
 		private List<CacheRegionDefinition> cacheRegionDefinitions;
 
 		public MergedSettings() {
 		}
 
 		public Map getConfigurationValues() {
 			return configurationValues;
 		}
 
 		public JaccPermissionDeclarations getJaccPermissions(String jaccContextId) {
 			if ( jaccPermissionsByContextId == null ) {
 				jaccPermissionsByContextId = new HashMap<String, JaccPermissionDeclarations>();
 			}
 
 			JaccPermissionDeclarations jaccPermissions = jaccPermissionsByContextId.get( jaccContextId );
 			if ( jaccPermissions == null ) {
 				jaccPermissions = new JaccPermissionDeclarations( jaccContextId );
 				jaccPermissionsByContextId.put( jaccContextId, jaccPermissions );
 			}
 			return jaccPermissions;
 		}
 
 		public void addCacheRegionDefinition(CacheRegionDefinition cacheRegionDefinition) {
 			if ( this.cacheRegionDefinitions == null ) {
 				this.cacheRegionDefinitions = new ArrayList<CacheRegionDefinition>();
 			}
 			this.cacheRegionDefinitions.add( cacheRegionDefinition );
 		}
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/TransactionImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/TransactionImpl.java
index 36d3582b01..8318073e4c 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/TransactionImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/TransactionImpl.java
@@ -1,146 +1,147 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009, 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.internal;
 
 import javax.persistence.EntityTransaction;
 import javax.persistence.PersistenceException;
 import javax.persistence.RollbackException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.jpa.spi.AbstractEntityManagerImpl;
 import org.hibernate.jpa.spi.HibernateEntityManagerImplementor;
+import org.hibernate.resource.transaction.spi.TransactionStatus;
 
 /**
  * @author Gavin King
  * @author Emmanuel Bernard
  */
 public class TransactionImpl implements EntityTransaction {
 
 	private HibernateEntityManagerImplementor entityManager;
 	private Transaction tx;
 	private boolean rollbackOnly;
 
 	public TransactionImpl(AbstractEntityManagerImpl entityManager) {
 		this.entityManager = entityManager;
 	}
 
 	private Session getSession() {
 		return entityManager.getSession();
 	}
 
 	public void begin() {
 		try {
 			rollbackOnly = false;
-			if ( tx != null && tx.isActive() ) {
+			if ( tx != null && tx.getStatus() == TransactionStatus.ACTIVE ) {
 				throw new IllegalStateException( "Transaction already active" );
 			}
 			//entityManager.adjustFlushMode();
 			tx = getSession().beginTransaction();
 		}
 		catch (HibernateException he) {
 			entityManager.throwPersistenceException( he );
 		}
 	}
 
 	public void commit() {
-		if ( tx == null || !tx.isActive() ) {
+		if ( tx == null || tx.getStatus() != TransactionStatus.ACTIVE ) {
 			throw new IllegalStateException( "Transaction not active" );
 		}
 		if ( rollbackOnly ) {
 			tx.rollback();
 			throw new RollbackException( "Transaction marked as rollbackOnly" );
 		}
 		try {
 			tx.commit();
 		}
 		catch (Exception e) {
 			Exception wrappedException;
 			if (e instanceof HibernateException) {
 				wrappedException = entityManager.convert( (HibernateException)e );
 			}
 			else {
 				wrappedException = e;
 			}
 			try {
 				//as per the spec we should rollback if commit fails
 				tx.rollback();
 			}
 			catch (Exception re) {
 				//swallow
 			}
 			throw new RollbackException( "Error while committing the transaction", wrappedException );
 		}
 		finally {
 			rollbackOnly = false;
 		}
 		//if closed and we commit, the mode should have been adjusted already
 		//if ( entityManager.isOpen() ) entityManager.adjustFlushMode();
 	}
 
 	public void rollback() {
-		if ( tx == null || !tx.isActive() ) {
+		if ( tx == null || tx.getStatus() != TransactionStatus.ACTIVE ) {
 			throw new IllegalStateException( "Transaction not active" );
 		}
 		try {
 			tx.rollback();
 		}
 		catch (Exception e) {
 			throw new PersistenceException( "unexpected error when rollbacking", e );
 		}
 		finally {
 			try {
 				if (entityManager !=  null) {
 					Session session = getSession();
 					if ( session != null && session.isOpen() ) session.clear();
 				}
 			}
 			catch (Throwable t) {
 				//we don't really care here since it's only for safety purpose
 			}
 			rollbackOnly = false;
 		}
 	}
 
 	public void setRollbackOnly() {
 		if ( ! isActive() ) throw new IllegalStateException( "Transaction not active" );
 		this.rollbackOnly = true;
 	}
 
 	public boolean getRollbackOnly() {
 		if ( ! isActive() ) throw new IllegalStateException( "Transaction not active" );
 		return rollbackOnly;
 	}
 
 	public boolean isActive() {
 		try {
-			return tx != null && tx.isActive();
+			return tx != null && tx.getStatus() == TransactionStatus.ACTIVE;
 		}
 		catch (RuntimeException e) {
 			throw new PersistenceException( "unexpected error when checking transaction status", e );
 		}
 	}
 
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/AbstractEntityManagerImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/AbstractEntityManagerImpl.java
index e656ad1712..30c2f9bbf7 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/AbstractEntityManagerImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/AbstractEntityManagerImpl.java
@@ -1,1890 +1,1788 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.spi;
 
-import java.io.IOException;
-import java.io.ObjectInputStream;
-import java.io.ObjectOutputStream;
-import java.io.Serializable;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
 import javax.persistence.CacheRetrieveMode;
 import javax.persistence.CacheStoreMode;
 import javax.persistence.EntityExistsException;
 import javax.persistence.EntityGraph;
 import javax.persistence.EntityManager;
 import javax.persistence.EntityNotFoundException;
 import javax.persistence.EntityTransaction;
 import javax.persistence.FlushModeType;
 import javax.persistence.LockModeType;
 import javax.persistence.LockTimeoutException;
 import javax.persistence.NoResultException;
 import javax.persistence.NonUniqueResultException;
 import javax.persistence.OptimisticLockException;
 import javax.persistence.PersistenceContextType;
 import javax.persistence.PersistenceException;
 import javax.persistence.PessimisticLockException;
 import javax.persistence.PessimisticLockScope;
 import javax.persistence.Query;
 import javax.persistence.QueryTimeoutException;
 import javax.persistence.StoredProcedureQuery;
 import javax.persistence.SynchronizationType;
 import javax.persistence.TransactionRequiredException;
 import javax.persistence.Tuple;
 import javax.persistence.TupleElement;
 import javax.persistence.TypedQuery;
 import javax.persistence.criteria.CriteriaBuilder;
 import javax.persistence.criteria.CriteriaDelete;
 import javax.persistence.criteria.CriteriaQuery;
 import javax.persistence.criteria.CriteriaUpdate;
 import javax.persistence.criteria.Selection;
 import javax.persistence.metamodel.Metamodel;
 import javax.persistence.spi.PersistenceUnitTransactionType;
 import javax.transaction.Status;
 import javax.transaction.SystemException;
 import javax.transaction.TransactionManager;
+import java.io.IOException;
+import java.io.ObjectInputStream;
+import java.io.ObjectOutputStream;
+import java.io.Serializable;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.CacheMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.ObjectDeletedException;
 import org.hibernate.ObjectNotFoundException;
 import org.hibernate.QueryException;
 import org.hibernate.SQLQuery;
 import org.hibernate.Session;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.StaleStateException;
+import org.hibernate.TransactionException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.TypeMismatchException;
 import org.hibernate.UnresolvableObjectException;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.boot.registry.classloading.spi.ClassLoadingException;
-import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.lock.LockingStrategyException;
 import org.hibernate.dialect.lock.OptimisticEntityLockException;
 import org.hibernate.dialect.lock.PessimisticEntityLockException;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.query.spi.HQLQueryPlan;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryConstructorReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryRootReturn;
 import org.hibernate.engine.spi.NamedQueryDefinition;
 import org.hibernate.engine.spi.NamedSQLQueryDefinition;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
 import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
-import org.hibernate.engine.transaction.spi.JoinStatus;
-import org.hibernate.engine.transaction.spi.TransactionCoordinator;
-import org.hibernate.engine.transaction.spi.TransactionImplementor;
-import org.hibernate.engine.transaction.synchronization.spi.AfterCompletionAction;
-import org.hibernate.engine.transaction.synchronization.spi.ExceptionMapper;
-import org.hibernate.engine.transaction.synchronization.spi.ManagedFlushChecker;
-import org.hibernate.engine.transaction.synchronization.spi.SynchronizationCallbackCoordinator;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.jpa.AvailableSettings;
 import org.hibernate.jpa.HibernateEntityManagerFactory;
 import org.hibernate.jpa.QueryHints;
 import org.hibernate.jpa.criteria.ValueHandlerFactory;
 import org.hibernate.jpa.criteria.compile.CompilableCriteria;
 import org.hibernate.jpa.criteria.compile.CriteriaCompiler;
 import org.hibernate.jpa.criteria.expression.CompoundSelectionImpl;
 import org.hibernate.jpa.internal.EntityManagerFactoryImpl;
 import org.hibernate.jpa.internal.EntityManagerMessageLogger;
 import org.hibernate.jpa.internal.HEMLogging;
 import org.hibernate.jpa.internal.QueryImpl;
 import org.hibernate.jpa.internal.StoredProcedureQueryImpl;
 import org.hibernate.jpa.internal.TransactionImpl;
 import org.hibernate.jpa.internal.util.CacheModeHelper;
 import org.hibernate.jpa.internal.util.ConfigurationHelper;
 import org.hibernate.jpa.internal.util.LockModeTypeHelper;
 import org.hibernate.procedure.ProcedureCallMemento;
 import org.hibernate.procedure.UnknownSqlResultSetMappingException;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.transform.BasicTransformerAdapter;
 import org.hibernate.type.Type;
 
 /**
  * @author <a href="mailto:gavin@hibernate.org">Gavin King</a>
  * @author Emmanuel Bernard
  * @author Steve Ebersole
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public abstract class AbstractEntityManagerImpl implements HibernateEntityManagerImplementor, Serializable {
 	private static final long serialVersionUID = 78818181L;
 
     private static final EntityManagerMessageLogger LOG = HEMLogging.messageLogger( AbstractEntityManagerImpl.class );
 
 	private static final List<String> ENTITY_MANAGER_SPECIFIC_PROPERTIES = new ArrayList<String>();
 
 	static {
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.LOCK_SCOPE );
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.LOCK_TIMEOUT );
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.FLUSH_MODE );
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE );
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.SHARED_CACHE_STORE_MODE );
 		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( QueryHints.SPEC_HINT_TIMEOUT );
 	}
 
 	private EntityManagerFactoryImpl entityManagerFactory;
 	protected transient TransactionImpl tx = new TransactionImpl( this );
 	private SynchronizationType synchronizationType;
 	private PersistenceUnitTransactionType transactionType;
 	private Map<String, Object> properties;
 	private LockOptions lockOptions;
 
 	protected AbstractEntityManagerImpl(
 			EntityManagerFactoryImpl entityManagerFactory,
 			PersistenceContextType type,  // TODO:  remove as no longer used
 			SynchronizationType synchronizationType,
 			PersistenceUnitTransactionType transactionType,
 			Map properties) {
 		this.entityManagerFactory = entityManagerFactory;
 		this.synchronizationType = synchronizationType;
 		this.transactionType = transactionType;
 
 		this.lockOptions = new LockOptions();
 		this.properties = new HashMap<String, Object>();
 		for ( String key : ENTITY_MANAGER_SPECIFIC_PROPERTIES ) {
 			if ( entityManagerFactory.getProperties().containsKey( key ) ) {
 				this.properties.put( key, entityManagerFactory.getProperties().get( key ) );
 			}
 			if ( properties != null && properties.containsKey( key ) ) {
 				this.properties.put( key, properties.get( key ) );
 			}
 		}
 	}
 
 //	protected PersistenceUnitTransactionType transactionType() {
 //		return transactionType;
 //	}
 //
 //	protected SynchronizationType synchronizationType() {
 //		return synchronizationType;
 //	}
 //
 //	public boolean shouldAutoJoinTransactions() {
 //		// the Session should auto join only if using non-JTA transactions or if the synchronization type
 //		// was specified as SYNCHRONIZED
 //		return transactionType != PersistenceUnitTransactionType.JTA
 //				|| synchronizationType == SynchronizationType.SYNCHRONIZED;
 //	}
 
 	public PersistenceUnitTransactionType getTransactionType() {
 		return transactionType;
 	}
 
 	protected void postInit() {
 		//register in Sync if needed
 		if ( transactionType == PersistenceUnitTransactionType.JTA
 				&& synchronizationType == SynchronizationType.SYNCHRONIZED ) {
 			joinTransaction( false );
 		}
 
 		setDefaultProperties();
 		applyProperties();
 	}
 
 	private void applyProperties() {
 		getSession().setFlushMode( ConfigurationHelper.getFlushMode( properties.get( AvailableSettings.FLUSH_MODE ) ) );
 		setLockOptions( this.properties, this.lockOptions );
 		getSession().setCacheMode(
 				CacheModeHelper.interpretCacheMode(
 						currentCacheStoreMode(),
 						currentCacheRetrieveMode()
 				)
 		);
 	}
 
 	private Query applyProperties(Query query) {
 		if ( lockOptions.getLockMode() != LockMode.NONE ) {
 			query.setLockMode( getLockMode(lockOptions.getLockMode()));
 		}
 		Object queryTimeout;
 		if ( (queryTimeout = getProperties().get(QueryHints.SPEC_HINT_TIMEOUT)) != null ) {
 			query.setHint( QueryHints.SPEC_HINT_TIMEOUT, queryTimeout );
 		}
 		Object lockTimeout;
 		if( (lockTimeout = getProperties().get( AvailableSettings.LOCK_TIMEOUT ))!=null){
 			query.setHint( AvailableSettings.LOCK_TIMEOUT, lockTimeout );
 		}
 		return query;
 	}
 
 	private CacheRetrieveMode currentCacheRetrieveMode() {
 		return determineCacheRetrieveMode( properties );
 	}
 
 	private CacheRetrieveMode determineCacheRetrieveMode(Map<String, Object> settings) {
 		return ( CacheRetrieveMode ) settings.get( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE );
 	}
 
 	private CacheStoreMode currentCacheStoreMode() {
 		return determineCacheStoreMode( properties );
 	}
 
 	private CacheStoreMode determineCacheStoreMode(Map<String, Object> settings) {
 		return ( CacheStoreMode ) settings.get( AvailableSettings.SHARED_CACHE_STORE_MODE );
 	}
 
 	private void setLockOptions(Map<String, Object> props, LockOptions options) {
 		Object lockScope = props.get( AvailableSettings.LOCK_SCOPE );
 		if ( lockScope instanceof String && PessimisticLockScope.valueOf( ( String ) lockScope ) == PessimisticLockScope.EXTENDED ) {
 			options.setScope( true );
 		}
 		else if ( lockScope instanceof PessimisticLockScope ) {
 			boolean extended = PessimisticLockScope.EXTENDED.equals( lockScope );
 			options.setScope( extended );
 		}
 		else if ( lockScope != null ) {
 			throw new PersistenceException( "Unable to parse " + AvailableSettings.LOCK_SCOPE + ": " + lockScope );
 		}
 
 		Object lockTimeout = props.get( AvailableSettings.LOCK_TIMEOUT );
 		int timeout = 0;
 		boolean timeoutSet = false;
 		if ( lockTimeout instanceof String ) {
 			timeout = Integer.parseInt( ( String ) lockTimeout );
 			timeoutSet = true;
 		}
 		else if ( lockTimeout instanceof Number ) {
 			timeout = ( (Number) lockTimeout ).intValue();
 			timeoutSet = true;
 		}
 		else if ( lockTimeout != null ) {
 			throw new PersistenceException( "Unable to parse " + AvailableSettings.LOCK_TIMEOUT + ": " + lockTimeout );
 		}
 		if ( timeoutSet ) {
             if ( timeout == LockOptions.SKIP_LOCKED ) {
                 options.setTimeOut( LockOptions.SKIP_LOCKED );
             }
 			else if ( timeout < 0 ) {
 				options.setTimeOut( LockOptions.WAIT_FOREVER );
 			}
 			else if ( timeout == 0 ) {
 				options.setTimeOut( LockOptions.NO_WAIT );
 			}
 			else {
 				options.setTimeOut( timeout );
 			}
 		}
 	}
 
 	/**
 	 * Sets the default property values for the properties the entity manager supports and which are not already explicitly
 	 * set.
 	 */
 	private void setDefaultProperties() {
 		if ( properties.get( AvailableSettings.FLUSH_MODE ) == null ) {
 			properties.put( AvailableSettings.FLUSH_MODE, getSession().getFlushMode().toString() );
 		}
 		if ( properties.get( AvailableSettings.LOCK_SCOPE ) == null ) {
 			this.properties.put( AvailableSettings.LOCK_SCOPE, PessimisticLockScope.EXTENDED.name() );
 		}
 		if ( properties.get( AvailableSettings.LOCK_TIMEOUT ) == null ) {
 			properties.put( AvailableSettings.LOCK_TIMEOUT, LockOptions.WAIT_FOREVER );
 		}
 		if ( properties.get( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE ) == null ) {
 			properties.put( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE, CacheModeHelper.DEFAULT_RETRIEVE_MODE );
 		}
 		if ( properties.get( AvailableSettings.SHARED_CACHE_STORE_MODE ) == null ) {
 			properties.put( AvailableSettings.SHARED_CACHE_STORE_MODE, CacheModeHelper.DEFAULT_STORE_MODE );
 		}
 	}
 
 	@Override
 	public Query createQuery(String jpaqlString) {
 		checkOpen();
 		try {
 			return applyProperties( new QueryImpl<Object>( internalGetSession().createQuery( jpaqlString ), this ) );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	protected abstract void checkOpen();
 
 	@Override
 	public <T> TypedQuery<T> createQuery(String jpaqlString, Class<T> resultClass) {
 		checkOpen();
 		try {
 			// do the translation
 			org.hibernate.Query hqlQuery = internalGetSession().createQuery( jpaqlString );
 
 			resultClassChecking( resultClass, hqlQuery );
 
 			// finally, build/return the query instance
 			return new QueryImpl<T>( hqlQuery, this );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	protected void resultClassChecking(Class resultClass, org.hibernate.Query hqlQuery) {
 		// make sure the query is a select -> HHH-7192
 		final SessionImplementor session = unwrap( SessionImplementor.class );
 		final HQLQueryPlan queryPlan = session.getFactory().getQueryPlanCache().getHQLQueryPlan(
 				hqlQuery.getQueryString(),
 				false,
 				session.getLoadQueryInfluencers().getEnabledFilters()
 		);
 		if ( queryPlan.getTranslators()[0].isManipulationStatement() ) {
 			throw new IllegalArgumentException( "Update/delete queries cannot be typed" );
 		}
 
 		// do some return type validation checking
 		if ( Object[].class.equals( resultClass ) ) {
 			// no validation needed
 		}
 		else if ( Tuple.class.equals( resultClass ) ) {
 			TupleBuilderTransformer tupleTransformer = new TupleBuilderTransformer( hqlQuery );
 			hqlQuery.setResultTransformer( tupleTransformer  );
 		}
 		else {
 			final Class dynamicInstantiationClass = queryPlan.getDynamicInstantiationResultType();
 			if ( dynamicInstantiationClass != null ) {
 				if ( ! resultClass.isAssignableFrom( dynamicInstantiationClass ) ) {
 					throw new IllegalArgumentException(
 							"Mismatch in requested result type [" + resultClass.getName() +
 									"] and actual result type [" + dynamicInstantiationClass.getName() + "]"
 					);
 				}
 			}
 			else if ( hqlQuery.getReturnTypes().length == 1 ) {
 				// if we have only a single return expression, its java type should match with the requested type
 				if ( !resultClass.isAssignableFrom( hqlQuery.getReturnTypes()[0].getReturnedClass() ) ) {
 					throw new IllegalArgumentException(
 							"Type specified for TypedQuery [" +
 									resultClass.getName() +
 									"] is incompatible with query return type [" +
 									hqlQuery.getReturnTypes()[0].getReturnedClass() + "]"
 					);
 				}
 			}
 			else {
 				throw new IllegalArgumentException(
 						"Cannot create TypedQuery for query with more than one return using requested result type [" +
 								resultClass.getName() + "]"
 				);
 			}
 		}
 	}
 
 	public static class TupleBuilderTransformer extends BasicTransformerAdapter {
 		private List<TupleElement<?>> tupleElements;
 		private Map<String,HqlTupleElementImpl> tupleElementsByAlias;
 
 		public TupleBuilderTransformer(org.hibernate.Query hqlQuery) {
 			final Type[] resultTypes = hqlQuery.getReturnTypes();
 			final int tupleSize = resultTypes.length;
 
 			this.tupleElements = CollectionHelper.arrayList( tupleSize );
 
 			final String[] aliases = hqlQuery.getReturnAliases();
 			final boolean hasAliases = aliases != null && aliases.length > 0;
 			this.tupleElementsByAlias = hasAliases
 					? CollectionHelper.<String, HqlTupleElementImpl>mapOfSize( tupleSize )
 					: Collections.<String, HqlTupleElementImpl>emptyMap();
 
 			for ( int i = 0; i < tupleSize; i++ ) {
 				final HqlTupleElementImpl tupleElement = new HqlTupleElementImpl(
 						i,
 						aliases == null ? null : aliases[i],
 						resultTypes[i]
 				);
 				tupleElements.add( tupleElement );
 				if ( hasAliases ) {
 					final String alias = aliases[i];
 					if ( alias != null ) {
 						tupleElementsByAlias.put( alias, tupleElement );
 					}
 				}
 			}
 		}
 
 		@Override
 		public Object transformTuple(Object[] tuple, String[] aliases) {
 			if ( tuple.length != tupleElements.size() ) {
 				throw new IllegalArgumentException(
 						"Size mismatch between tuple result [" + tuple.length + "] and expected tuple elements [" +
 								tupleElements.size() + "]"
 				);
 			}
 			return new HqlTupleImpl( tuple );
 		}
 
 		public static class HqlTupleElementImpl<X> implements TupleElement<X> {
 			private final int position;
 			private final String alias;
 			private final Type hibernateType;
 
 			public HqlTupleElementImpl(int position, String alias, Type hibernateType) {
 				this.position = position;
 				this.alias = alias;
 				this.hibernateType = hibernateType;
 			}
 
 			@Override
 			public Class getJavaType() {
 				return hibernateType.getReturnedClass();
 			}
 
 			@Override
 			public String getAlias() {
 				return alias;
 			}
 
 			public int getPosition() {
 				return position;
 			}
 
 			public Type getHibernateType() {
 				return hibernateType;
 			}
 		}
 
 		public class HqlTupleImpl implements Tuple {
 			private Object[] tuple;
 
 			public HqlTupleImpl(Object[] tuple) {
 				this.tuple = tuple;
 			}
 
 			@Override
 			public <X> X get(String alias, Class<X> type) {
 				final Object untyped = get( alias );
 				if ( untyped != null ) {
 					if ( ! type.isInstance( untyped ) ) {
 						throw new IllegalArgumentException(
 								String.format(
 										"Requested tuple value [alias=%s, value=%s] cannot be assigned to requested type [%s]",
 										alias,
 										untyped,
 										type.getName()
 								)
 						);
 					}
 				}
 				return (X) untyped;
 			}
 
 			@Override
 			public Object get(String alias) {
 				HqlTupleElementImpl tupleElement = tupleElementsByAlias.get( alias );
 				if ( tupleElement == null ) {
 					throw new IllegalArgumentException( "Unknown alias [" + alias + "]" );
 				}
 				return tuple[ tupleElement.getPosition() ];
 			}
 
 			@Override
 			public <X> X get(int i, Class<X> type) {
 				final Object result = get( i );
 				if ( result != null && ! type.isInstance( result ) ) {
 					throw new IllegalArgumentException(
 							String.format(
 									"Requested tuple value [index=%s, realType=%s] cannot be assigned to requested type [%s]",
 									i,
 									result.getClass().getName(),
 									type.getName()
 							)
 					);
 				}
 				return ( X ) result;
 			}
 
 			@Override
 			public Object get(int i) {
 				if ( i < 0 ) {
 					throw new IllegalArgumentException( "requested tuple index must be greater than zero" );
 				}
 				if ( i > tuple.length ) {
 					throw new IllegalArgumentException( "requested tuple index exceeds actual tuple size" );
 				}
 				return tuple[i];
 			}
 
 			@Override
 			public Object[] toArray() {
 				// todo : make a copy?
 				return tuple;
 			}
 
 			@Override
 			public List<TupleElement<?>> getElements() {
 				return tupleElements;
 			}
 
 			@Override
 			public <X> X get(TupleElement<X> tupleElement) {
 				if ( HqlTupleElementImpl.class.isInstance( tupleElement ) ) {
 					return get( ( (HqlTupleElementImpl) tupleElement ).getPosition(), tupleElement.getJavaType() );
 				}
 				else {
 					return get( tupleElement.getAlias(), tupleElement.getJavaType() );
 				}
 			}
 		}
 	}
 
 	@Override
 	public <T> QueryImpl<T> createQuery(
 			String jpaqlString,
 			Class<T> resultClass,
 			Selection selection,
 			QueryOptions queryOptions) {
 		try {
 			org.hibernate.Query hqlQuery = internalGetSession().createQuery( jpaqlString );
 
 			if ( queryOptions.getValueHandlers() == null ) {
 				if ( queryOptions.getResultMetadataValidator() != null ) {
 					queryOptions.getResultMetadataValidator().validate( hqlQuery.getReturnTypes() );
 				}
 			}
 
 			// determine if we need a result transformer
 			List tupleElements = Tuple.class.equals( resultClass )
 					? ( ( CompoundSelectionImpl<Tuple> ) selection ).getCompoundSelectionItems()
 					: null;
 			if ( queryOptions.getValueHandlers() != null || tupleElements != null ) {
 				hqlQuery.setResultTransformer(
 						new CriteriaQueryTransformer( queryOptions.getValueHandlers(), tupleElements )
 				);
 			}
 			return new QueryImpl<T>( hqlQuery, this, queryOptions.getNamedParameterExplicitTypes() );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	private static class CriteriaQueryTransformer extends BasicTransformerAdapter {
 		private final List<ValueHandlerFactory.ValueHandler> valueHandlers;
 		private final List tupleElements;
 
 		private CriteriaQueryTransformer(List<ValueHandlerFactory.ValueHandler> valueHandlers, List tupleElements) {
 			// todo : should these 2 sizes match *always*?
 			this.valueHandlers = valueHandlers;
 			this.tupleElements = tupleElements;
 		}
 
 		@Override
 		public Object transformTuple(Object[] tuple, String[] aliases) {
 			final Object[] valueHandlerResult;
 			if ( valueHandlers == null ) {
 				valueHandlerResult = tuple;
 			}
 			else {
 				valueHandlerResult = new Object[tuple.length];
 				for ( int i = 0; i < tuple.length; i++ ) {
 					ValueHandlerFactory.ValueHandler valueHandler = valueHandlers.get( i );
 					valueHandlerResult[i] = valueHandler == null
 							? tuple[i]
 							: valueHandler.convert( tuple[i] );
 				}
 			}
 
 			return tupleElements == null
 					? valueHandlerResult.length == 1 ? valueHandlerResult[0] : valueHandlerResult
 					: new TupleImpl( tuple );
 
 		}
 
 		private class TupleImpl implements Tuple {
 			private final Object[] tuples;
 
 			private TupleImpl(Object[] tuples) {
 				if ( tuples.length != tupleElements.size() ) {
 					throw new IllegalArgumentException(
 							"Size mismatch between tuple result [" + tuples.length
 									+ "] and expected tuple elements [" + tupleElements.size() + "]"
 					);
 				}
 				this.tuples = tuples;
 			}
 
 			public <X> X get(TupleElement<X> tupleElement) {
 				int index = tupleElements.indexOf( tupleElement );
 				if ( index < 0 ) {
 					throw new IllegalArgumentException(
 							"Requested tuple element did not correspond to element in the result tuple"
 					);
 				}
 				// index should be "in range" by nature of size check in ctor
 				return ( X ) tuples[index];
 			}
 
 			public Object get(String alias) {
 				int index = -1;
 				if ( alias != null ) {
 					alias = alias.trim();
 					if ( alias.length() > 0 ) {
 						int i = 0;
 						for ( TupleElement selection : ( List<TupleElement> ) tupleElements ) {
 							if ( alias.equals( selection.getAlias() ) ) {
 								index = i;
 								break;
 							}
 							i++;
 						}
 					}
 				}
 				if ( index < 0 ) {
 					throw new IllegalArgumentException(
 							"Given alias [" + alias + "] did not correspond to an element in the result tuple"
 					);
 				}
 				// index should be "in range" by nature of size check in ctor
 				return tuples[index];
 			}
 
 			public <X> X get(String alias, Class<X> type) {
 				final Object untyped = get( alias );
 				if ( untyped != null ) {
 					if ( ! type.isInstance( untyped ) ) {
 						throw new IllegalArgumentException(
 								String.format(
 										"Requested tuple value [alias=%s, value=%s] cannot be assigned to requested type [%s]",
 										alias,
 										untyped,
 										type.getName()
 								)
 						);
 					}
 				}
 				return (X) untyped;
 			}
 
 			public Object get(int i) {
 				if ( i >= tuples.length ) {
 					throw new IllegalArgumentException(
 							"Given index [" + i + "] was outside the range of result tuple size [" + tuples.length + "] "
 					);
 				}
 				return tuples[i];
 			}
 
 			public <X> X get(int i, Class<X> type) {
 				final Object result = get( i );
 				if ( result != null && ! type.isInstance( result ) ) {
 					throw new IllegalArgumentException(
 							String.format(
 									"Requested tuple value [index=%s, realType=%s] cannot be assigned to requested type [%s]",
 									i,
 									result.getClass().getName(),
 									type.getName()
 							)
 					);
 				}
 				return ( X ) result;
 			}
 
 			public Object[] toArray() {
 				return tuples;
 			}
 
 			public List<TupleElement<?>> getElements() {
 				return tupleElements;
 			}
 		}
 	}
 
 	private CriteriaCompiler criteriaCompiler;
 
 	protected CriteriaCompiler criteriaCompiler() {
 		if ( criteriaCompiler == null ) {
 			criteriaCompiler = new CriteriaCompiler( this );
 		}
 		return criteriaCompiler;
 	}
 
 	@Override
 	public <T> TypedQuery<T> createQuery(CriteriaQuery<T> criteriaQuery) {
 		checkOpen();
 		try {
 			return (TypedQuery<T>) criteriaCompiler().compile( (CompilableCriteria) criteriaQuery );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public Query createQuery(CriteriaUpdate criteriaUpdate) {
 		checkOpen();
 		try {
 			return criteriaCompiler().compile( (CompilableCriteria) criteriaUpdate );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public Query createQuery(CriteriaDelete criteriaDelete) {
 		checkOpen();
 		try {
 			return criteriaCompiler().compile( (CompilableCriteria) criteriaDelete );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public Query createNamedQuery(String name) {
 		return buildQueryFromName( name, null );
 	}
 
 	private QueryImpl buildQueryFromName(String name, Class resultType) {
 		checkOpen();
 
 		// we can't just call Session#getNamedQuery because we need to apply stored setting at the JPA Query
 		// level too
 
 		final SessionFactoryImplementor sfi = entityManagerFactory.getSessionFactory();
 
 		final NamedQueryDefinition jpqlDefinition = sfi.getNamedQueryRepository().getNamedQueryDefinition( name );
 		if ( jpqlDefinition != null ) {
 			return createNamedJpqlQuery( jpqlDefinition, resultType );
 		}
 
 		final NamedSQLQueryDefinition nativeQueryDefinition = sfi.getNamedQueryRepository().getNamedSQLQueryDefinition( name );
 		if ( nativeQueryDefinition != null ) {
 			return createNamedSqlQuery( nativeQueryDefinition, resultType );
 		}
 
 		throw convert( new IllegalArgumentException( "No query defined for that name [" + name + "]" ) );
 	}
 
 	protected QueryImpl createNamedJpqlQuery(NamedQueryDefinition namedQueryDefinition, Class resultType) {
 		final org.hibernate.Query hibQuery = ( (SessionImplementor) internalGetSession() ).createQuery( namedQueryDefinition );
 		if ( resultType != null ) {
 			resultClassChecking( resultType, hibQuery );
 		}
 
 		return wrapAsJpaQuery( namedQueryDefinition, hibQuery );
 	}
 
 	protected QueryImpl wrapAsJpaQuery(NamedQueryDefinition namedQueryDefinition, org.hibernate.Query hibQuery) {
 		try {
 			final QueryImpl jpaQuery = new QueryImpl( hibQuery, this );
 			applySavedSettings( namedQueryDefinition, jpaQuery );
 			return jpaQuery;
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	protected void applySavedSettings(NamedQueryDefinition namedQueryDefinition, QueryImpl jpaQuery) {
 		if ( namedQueryDefinition.isCacheable() ) {
 			jpaQuery.setHint( QueryHints.HINT_CACHEABLE, true );
 			if ( namedQueryDefinition.getCacheRegion() != null ) {
 				jpaQuery.setHint( QueryHints.HINT_CACHE_REGION, namedQueryDefinition.getCacheRegion() );
 			}
 		}
 
 		if ( namedQueryDefinition.getCacheMode() != null ) {
 			jpaQuery.setHint( QueryHints.HINT_CACHE_MODE, namedQueryDefinition.getCacheMode() );
 		}
 
 		if ( namedQueryDefinition.isReadOnly() ) {
 			jpaQuery.setHint( QueryHints.HINT_READONLY, true );
 		}
 
 		if ( namedQueryDefinition.getTimeout() != null ) {
 			jpaQuery.setHint( QueryHints.SPEC_HINT_TIMEOUT, namedQueryDefinition.getTimeout() * 1000 );
 		}
 
 		if ( namedQueryDefinition.getFetchSize() != null ) {
 			jpaQuery.setHint( QueryHints.HINT_FETCH_SIZE, namedQueryDefinition.getFetchSize() );
 		}
 
 		if ( namedQueryDefinition.getComment() != null ) {
 			jpaQuery.setHint( QueryHints.HINT_COMMENT, namedQueryDefinition.getComment() );
 		}
 
 		if ( namedQueryDefinition.getFirstResult() != null ) {
 			jpaQuery.setFirstResult( namedQueryDefinition.getFirstResult() );
 		}
 
 		if ( namedQueryDefinition.getMaxResults() != null ) {
 			jpaQuery.setMaxResults( namedQueryDefinition.getMaxResults() );
 		}
 
 		if ( namedQueryDefinition.getLockOptions() != null ) {
 			if ( namedQueryDefinition.getLockOptions().getLockMode() != null ) {
 				jpaQuery.setLockMode(
 						LockModeTypeHelper.getLockModeType( namedQueryDefinition.getLockOptions().getLockMode() )
 				);
 			}
 		}
 
 		if ( namedQueryDefinition.getFlushMode() != null ) {
 			if ( namedQueryDefinition.getFlushMode() == FlushMode.COMMIT ) {
 				jpaQuery.setFlushMode( FlushModeType.COMMIT );
 			}
 			else {
 				jpaQuery.setFlushMode( FlushModeType.AUTO );
 			}
 		}
 	}
 
 	protected QueryImpl createNamedSqlQuery(NamedSQLQueryDefinition namedQueryDefinition, Class resultType) {
 		if ( resultType != null ) {
 			resultClassChecking( resultType, namedQueryDefinition );
 		}
 		return wrapAsJpaQuery(
 				namedQueryDefinition,
 				( (SessionImplementor) internalGetSession() ).createSQLQuery( namedQueryDefinition )
 		);
 	}
 
 	protected void resultClassChecking(Class resultType, NamedSQLQueryDefinition namedQueryDefinition) {
 		final SessionFactoryImplementor sfi = entityManagerFactory.getSessionFactory();
 
 		final NativeSQLQueryReturn[] queryReturns;
 		if ( namedQueryDefinition.getQueryReturns() != null ) {
 			queryReturns = namedQueryDefinition.getQueryReturns();
 		}
 		else if ( namedQueryDefinition.getResultSetRef() != null ) {
 			final ResultSetMappingDefinition rsMapping = sfi.getResultSetMapping( namedQueryDefinition.getResultSetRef() );
 			queryReturns = rsMapping.getQueryReturns();
 		}
 		else {
 			throw new AssertionFailure( "Unsupported named query model. Please report the bug in Hibernate EntityManager");
 		}
 
 		if ( queryReturns.length > 1 ) {
 			throw new IllegalArgumentException( "Cannot create TypedQuery for query with more than one return" );
 		}
 
 		final NativeSQLQueryReturn nativeSQLQueryReturn = queryReturns[0];
 
 		if ( nativeSQLQueryReturn instanceof NativeSQLQueryRootReturn ) {
 			final Class<?> actualReturnedClass;
 			final String entityClassName = ( (NativeSQLQueryRootReturn) nativeSQLQueryReturn ).getReturnEntityName();
 			try {
 				actualReturnedClass = sfi.getServiceRegistry().getService( ClassLoaderService.class ).classForName( entityClassName );
 			}
 			catch ( ClassLoadingException e ) {
 				throw new AssertionFailure(
 						"Unable to load class [" + entityClassName + "] declared on named native query [" +
 								namedQueryDefinition.getName() + "]"
 				);
 			}
 			if ( !resultType.isAssignableFrom( actualReturnedClass ) ) {
 				throw buildIncompatibleException( resultType, actualReturnedClass );
 			}
 		}
 		else if ( nativeSQLQueryReturn instanceof NativeSQLQueryConstructorReturn ) {
 			final NativeSQLQueryConstructorReturn ctorRtn = (NativeSQLQueryConstructorReturn) nativeSQLQueryReturn;
 			if ( !resultType.isAssignableFrom( ctorRtn.getTargetClass() ) ) {
 				throw buildIncompatibleException( resultType, ctorRtn.getTargetClass() );
 			}
 		}
 		else {
 			//TODO support other NativeSQLQueryReturn type. For now let it go.
 		}
 	}
 
 	@Override
 	public <T> TypedQuery<T> createNamedQuery(String name, Class<T> resultClass) {
 		return buildQueryFromName( name, resultClass );
 	}
 
 	private IllegalArgumentException buildIncompatibleException(Class<?> resultClass, Class<?> actualResultClass) {
 		return new IllegalArgumentException(
 				"Type specified for TypedQuery [" + resultClass.getName() +
 						"] is incompatible with query return type [" + actualResultClass + "]"
 		);
 	}
 
 	@Override
 	public Query createNativeQuery(String sqlString) {
 		checkOpen();
 		try {
 			SQLQuery q = internalGetSession().createSQLQuery( sqlString );
 			return new QueryImpl( q, this );
 		}
 		catch ( RuntimeException he ) {
 			throw convert( he );
 		}
 	}
 
 	@Override
 	public Query createNativeQuery(String sqlString, Class resultClass) {
 		checkOpen();
 		try {
 			SQLQuery q = internalGetSession().createSQLQuery( sqlString );
 			q.addEntity( "alias1", resultClass.getName(), LockMode.READ );
 			return new QueryImpl( q, this );
 		}
 		catch ( RuntimeException he ) {
 			throw convert( he );
 		}
 	}
 
 	@Override
 	public Query createNativeQuery(String sqlString, String resultSetMapping) {
 		checkOpen();
 		try {
 			final SQLQuery q = internalGetSession().createSQLQuery( sqlString );
 			q.setResultSetMapping( resultSetMapping );
 			return new QueryImpl( q, this );
 		}
 		catch ( RuntimeException he ) {
 			throw convert( he );
 		}
 	}
 
 	@Override
 	public StoredProcedureQuery createNamedStoredProcedureQuery(String name) {
 		checkOpen();
 		try {
 			final ProcedureCallMemento memento = ( (SessionImplementor) internalGetSession() ).getFactory()
 					.getNamedQueryRepository().getNamedProcedureCallMemento( name );
 			if ( memento == null ) {
 				throw new IllegalArgumentException( "No @NamedStoredProcedureQuery was found with that name : " + name );
 			}
 			final StoredProcedureQueryImpl jpaImpl = new StoredProcedureQueryImpl( memento, this );
 			// apply hints
 			if ( memento.getHintsMap() != null ) {
 				for ( Map.Entry<String,Object> hintEntry : memento.getHintsMap().entrySet() ) {
 					jpaImpl.setHint( hintEntry.getKey(), hintEntry.getValue() );
 				}
 			}
 			return jpaImpl;
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public StoredProcedureQuery createStoredProcedureQuery(String procedureName) {
 		checkOpen();
 		try {
 			return new StoredProcedureQueryImpl(
 					internalGetSession().createStoredProcedureCall( procedureName ),
 					this
 			);
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public StoredProcedureQuery createStoredProcedureQuery(String procedureName, Class... resultClasses) {
 		checkOpen();
 		try {
 			return new StoredProcedureQueryImpl(
 					internalGetSession().createStoredProcedureCall( procedureName, resultClasses ),
 					this
 			);
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public StoredProcedureQuery createStoredProcedureQuery(String procedureName, String... resultSetMappings) {
 		checkOpen();
 		try {
 			try {
 				return new StoredProcedureQueryImpl(
 						internalGetSession().createStoredProcedureCall( procedureName, resultSetMappings ),
 						this
 				);
 			}
 			catch (UnknownSqlResultSetMappingException unknownResultSetMapping) {
 				throw new IllegalArgumentException( unknownResultSetMapping.getMessage(), unknownResultSetMapping );
 			}
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <T> T getReference(Class<T> entityClass, Object primaryKey) {
 		checkOpen();
 		try {
 			return ( T ) internalGetSession().load( entityClass, ( Serializable ) primaryKey );
 		}
 		catch ( MappingException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( TypeMismatchException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( ClassCastException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <A> A find(Class<A> entityClass, Object primaryKey) {
 		checkOpen();
 		return find( entityClass, primaryKey, null, null );
 	}
 
 	@Override
 	public <T> T find(Class<T> entityClass, Object primaryKey, Map<String, Object> properties) {
 		checkOpen();
 		return find( entityClass, primaryKey, null, properties );
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <A> A find(Class<A> entityClass, Object primaryKey, LockModeType lockModeType) {
 		checkOpen();
 		return find( entityClass, primaryKey, lockModeType, null );
 	}
 
 	@Override
 	public <A> A find(Class<A> entityClass, Object primaryKey, LockModeType lockModeType, Map<String, Object> properties) {
 		checkOpen();
 		Session session = internalGetSession();
 		CacheMode previousCacheMode = session.getCacheMode();
 		CacheMode cacheMode = determineAppropriateLocalCacheMode( properties );
 		LockOptions lockOptions = null;
 		try {
 			if ( properties != null && !properties.isEmpty() ) {
 				( (SessionImplementor) session ).getLoadQueryInfluencers()
 						.setFetchGraph( (EntityGraph) properties.get( QueryHints.HINT_FETCHGRAPH ) );
 				( (SessionImplementor) session ).getLoadQueryInfluencers()
 						.setLoadGraph( (EntityGraph) properties.get( QueryHints.HINT_LOADGRAPH ) );
 			}
 			session.setCacheMode( cacheMode );
 			if ( lockModeType != null ) {
 				lockOptions = getLockRequest( lockModeType, properties );
 				if ( !LockModeType.NONE.equals( lockModeType) ) {
 					checkTransactionNeeded();
 				}
 				return ( A ) session.get(
 						entityClass, ( Serializable ) primaryKey, 
 						lockOptions
 				);
 			}
 			else {
 				return ( A ) session.get( entityClass, ( Serializable ) primaryKey );
 			}
 		}
 		catch ( EntityNotFoundException ignored ) {
 			// DefaultLoadEventListener.returnNarrowedProxy may throw ENFE (see HHH-7861 for details),
 			// which find() should not throw.  Find() should return null if the entity was not found.
 			if ( LOG.isDebugEnabled() ) {
 				String entityName = entityClass != null ? entityClass.getName(): null;
 				String identifierValue = primaryKey != null ? primaryKey.toString() : null ;
 				LOG.ignoringEntityNotFound( entityName, identifierValue );
 			}
 			return null;
 		}
 		catch ( ObjectDeletedException e ) {
 			//the spec is silent about people doing remove() find() on the same PC
 			return null;
 		}
 		catch ( ObjectNotFoundException e ) {
 			//should not happen on the entity itself with get
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch ( MappingException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( TypeMismatchException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( ClassCastException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e, lockOptions );
 		}
 		finally {
 			session.setCacheMode( previousCacheMode );
 			( (SessionImplementor) session ).getLoadQueryInfluencers().setFetchGraph( null );
 			( (SessionImplementor) session ).getLoadQueryInfluencers().setLoadGraph( null );
 
 		}
 	}
 
 	public CacheMode determineAppropriateLocalCacheMode(Map<String, Object> localProperties) {
 		CacheRetrieveMode retrieveMode = null;
 		CacheStoreMode storeMode = null;
 		if ( localProperties != null ) {
 			retrieveMode = determineCacheRetrieveMode( localProperties );
 			storeMode = determineCacheStoreMode( localProperties );
 		}
 		if ( retrieveMode == null ) {
 			// use the EM setting
 			retrieveMode = determineCacheRetrieveMode( this.properties );
 		}
 		if ( storeMode == null ) {
 			// use the EM setting
 			storeMode = determineCacheStoreMode( this.properties );
 		}
 		return CacheModeHelper.interpretCacheMode( storeMode, retrieveMode );
 	}
 
 	private void checkTransactionNeeded() {
 		if ( !isTransactionInProgress() ) {
 			throw new TransactionRequiredException(
 					"no transaction is in progress"
 			);
 		}
 	}
 
 	@Override
 	public void persist(Object entity) {
 		checkOpen();
 		try {
 			internalGetSession().persist( entity );
 		}
 		catch ( MappingException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage() ) ) ;
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <A> A merge(A entity) {
 		checkOpen();
 		try {
 			return ( A ) internalGetSession().merge( entity );
 		}
 		catch ( ObjectDeletedException sse ) {
 			throw convert( new IllegalArgumentException( sse ) );
 		}
 		catch ( MappingException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( RuntimeException e ) {
 			//including HibernateException
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public void remove(Object entity) {
 		checkOpen();
 		try {
 			internalGetSession().delete( entity );
 		}
 		catch ( MappingException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( RuntimeException e ) {
 			//including HibernateException
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public void refresh(Object entity) {
 		refresh( entity, null, null );
 	}
 
 	@Override
 	public void refresh(Object entity, Map<String, Object> properties) {
 		refresh( entity, null, properties );
 	}
 
 	@Override
 	public void refresh(Object entity, LockModeType lockModeType) {
 		refresh( entity, lockModeType, null );
 	}
 
 	@Override
 	public void refresh(Object entity, LockModeType lockModeType, Map<String, Object> properties) {
 		checkOpen();
 
 		final Session session = internalGetSession();
 		final CacheMode previousCacheMode = session.getCacheMode();
 		final CacheMode localCacheMode = determineAppropriateLocalCacheMode( properties );
 		LockOptions lockOptions = null;
 		try {
 			session.setCacheMode( localCacheMode );
 			if ( !session.contains( entity ) ) {
 				throw convert ( new IllegalArgumentException( "Entity not managed" ) );
 			}
 			if ( lockModeType != null ) {
 				if ( !LockModeType.NONE.equals( lockModeType) ) {
 					checkTransactionNeeded();
 				}
 
 				lockOptions = getLockRequest( lockModeType, properties );
 				session.refresh( entity, lockOptions );
 			}
 			else {
 				session.refresh( entity );
 			}
 		}
 		catch (MappingException e) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch (RuntimeException e) {
 			throw convert( e, lockOptions );
 		}
 		finally {
 			session.setCacheMode( previousCacheMode );
 		}
 	}
 
 	@Override
 	public boolean contains(Object entity) {
 		checkOpen();
 
 		try {
 			if ( entity != null
 					&& !( entity instanceof HibernateProxy )
 					&& internalGetSession().getSessionFactory().getClassMetadata( entity.getClass() ) == null ) {
 				throw convert( new IllegalArgumentException( "Not an entity:" + entity.getClass() ) );
 			}
 			return internalGetSession().contains( entity );
 		}
 		catch (MappingException e) {
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch (RuntimeException e) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public LockModeType getLockMode(Object entity) {
 		checkOpen();
 
 		if ( !isTransactionInProgress() ) {
 			throw new TransactionRequiredException( "Call to EntityManager#getLockMode should occur within transaction according to spec" );
 		}
 
 		if ( !contains( entity ) ) {
 			throw convert( new IllegalArgumentException( "entity not in the persistence context" ) );
 		}
 
 		return getLockModeType( internalGetSession().getCurrentLockMode( entity ) );
 	}
 
 	@Override
 	public void setProperty(String s, Object o) {
 		checkOpen();
 
 		if ( ENTITY_MANAGER_SPECIFIC_PROPERTIES.contains( s ) ) {
 			properties.put( s, o );
 			applyProperties();
         }
 		else {
 			LOG.debugf("Trying to set a property which is not supported on entity manager level");
 		}
 	}
 
 	@Override
 	public Map<String, Object> getProperties() {
 		return Collections.unmodifiableMap( properties );
 	}
 
 	@Override
 	public void flush() {
 		checkOpen();
 		checkTransactionNeeded();
 
 		try {
 			internalGetSession().flush();
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	/**
 	 * return a Session
 	 *
 	 * @throws IllegalStateException if the entity manager is closed
 	 */
 	public abstract Session getSession();
 
 	/**
 	 * Return a Session (even if the entity manager is closed).
 	 *
 	 * @return A session.
 	 * @deprecated Deprecated in favor of {@link #getRawSession()}
 	 */
 	@Deprecated
 	protected abstract Session getRawSession();
 
 	/**
 	 * Return a Session without any validation checks.
 	 *
 	 * @return A session.
 	 */
 	protected abstract Session internalGetSession();
 
 	@Override
 	public EntityTransaction getTransaction() {
 		if ( transactionType == PersistenceUnitTransactionType.JTA ) {
 			throw new IllegalStateException( "A JTA EntityManager cannot use getTransaction()" );
 		}
 		return tx;
 	}
 
 	@Override
 	public EntityManagerFactoryImpl getEntityManagerFactory() {
 		checkOpen();
 		return internalGetEntityManagerFactory();
 	}
 
 	protected EntityManagerFactoryImpl internalGetEntityManagerFactory() {
 		return entityManagerFactory;
 	}
 
 	@Override
 	public HibernateEntityManagerFactory getFactory() {
 		return entityManagerFactory;
 	}
 
 	@Override
 	public CriteriaBuilder getCriteriaBuilder() {
 
 		checkOpen();
 		return getEntityManagerFactory().getCriteriaBuilder();
 	}
 
 	@Override
 	public Metamodel getMetamodel() {
 		checkOpen();
 		return getEntityManagerFactory().getMetamodel();
 	}
 
 	@Override
 	public void setFlushMode(FlushModeType flushModeType) {
 		checkOpen();
 		if ( flushModeType == FlushModeType.AUTO ) {
 			internalGetSession().setFlushMode( FlushMode.AUTO );
 		}
 		else if ( flushModeType == FlushModeType.COMMIT ) {
 			internalGetSession().setFlushMode( FlushMode.COMMIT );
 		}
 		else {
 			throw new AssertionFailure( "Unknown FlushModeType: " + flushModeType );
 		}
 	}
 
 	@Override
 	public void clear() {
 		checkOpen();
 		try {
 			internalGetSession().clear();
 		}
 		catch (RuntimeException e) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public void detach(Object entity) {
 		checkOpen();
 		try {
 			internalGetSession().evict( entity );
 		}
 		catch (RuntimeException e) {
 			throw convert( e );
 		}
 	}
 
 	/**
 	 * Hibernate can be set in various flush modes that are unknown to
 	 * JPA 2.0. This method can then return null.
 	 * If it returns null, do em.unwrap(Session.class).getFlushMode() to get the
 	 * Hibernate flush mode
 	 */
 	@Override
 	public FlushModeType getFlushMode() {
 		checkOpen();
 
 		FlushMode mode = internalGetSession().getFlushMode();
 		if ( mode == FlushMode.AUTO ) {
 			return FlushModeType.AUTO;
 		}
 		else if ( mode == FlushMode.COMMIT ) {
 			return FlushModeType.COMMIT;
 		}
 		else {
 			// otherwise this is an unknown mode for EJB3
 			return null;
 		}
 	}
 
 	public void lock(Object entity, LockModeType lockMode) {
 		lock( entity, lockMode, null );
 	}
 
 	public void lock(Object entity, LockModeType lockModeType, Map<String, Object> properties) {
 		checkOpen();
 		checkTransactionNeeded();
 
 		LockOptions lockOptions = null;
 
 		try {
 			if ( !contains( entity ) ) {
 				throw new IllegalArgumentException( "entity not in the persistence context" );
 			}
 			lockOptions = getLockRequest( lockModeType, properties );
 			internalGetSession().buildLockRequest( lockOptions ).lock( entity );
 		}
 		catch (RuntimeException e) {
 			throw convert( e, lockOptions );
 		}
 	}
 
 	public LockOptions getLockRequest(LockModeType lockModeType, Map<String, Object> properties) {
 		LockOptions lockOptions = new LockOptions();
 		LockOptions.copy( this.lockOptions, lockOptions );
 		lockOptions.setLockMode( getLockMode( lockModeType ) );
 		if ( properties != null ) {
 			setLockOptions( properties, lockOptions );
 		}
 		return lockOptions;
 	}
 
 	@SuppressWarnings("deprecation")
 	private static LockModeType getLockModeType(LockMode lockMode) {
 		//TODO check that if we have UPGRADE_NOWAIT we have a timeout of zero?
 		return LockModeTypeHelper.getLockModeType( lockMode );
 	}
 
 
 	private static LockMode getLockMode(LockModeType lockMode) {
 		return LockModeTypeHelper.getLockMode( lockMode );
 	}
 
 	public boolean isTransactionInProgress() {
 		return ( ( SessionImplementor ) internalGetSession() ).isTransactionInProgress();
 	}
 
 	private SessionFactoryImplementor sfi() {
 		return (SessionFactoryImplementor) internalGetSession().getSessionFactory();
 	}
 
 	@Override
 	public <T> T unwrap(Class<T> clazz) {
 		checkOpen();
 
 		if ( Session.class.isAssignableFrom( clazz ) ) {
 			return ( T ) internalGetSession();
 		}
 		if ( SessionImplementor.class.isAssignableFrom( clazz ) ) {
 			return ( T ) internalGetSession();
 		}
 		if ( EntityManager.class.isAssignableFrom( clazz ) ) {
 			return ( T ) this;
 		}
 		throw new PersistenceException( "Hibernate cannot unwrap " + clazz );
 	}
 
 	@Override
 	public void markForRollbackOnly() {
         LOG.debugf("Mark transaction for rollback");
 		if ( tx.isActive() ) {
 			tx.setRollbackOnly();
 		}
 		else {
 			//no explicit use of the tx. boundaries methods
 			if ( PersistenceUnitTransactionType.JTA == transactionType ) {
 				TransactionManager transactionManager = sfi().getServiceRegistry().getService( JtaPlatform.class ).retrieveTransactionManager();
 				if ( transactionManager == null ) {
 					throw new PersistenceException(
 							"Using a JTA persistence context wo setting hibernate.transaction.jta.platform"
 					);
 				}
 				try {
 					if ( transactionManager.getStatus() != Status.STATUS_NO_TRANSACTION ) {
 						transactionManager.setRollbackOnly();
 					}
 				}
 				catch (SystemException e) {
 					throw new PersistenceException( "Unable to set the JTA transaction as RollbackOnly", e );
 				}
 			}
 		}
 	}
 
 	@Override
 	public boolean isJoinedToTransaction() {
 		checkOpen();
 
 		final SessionImplementor session = (SessionImplementor) internalGetSession();
-		final TransactionCoordinator transactionCoordinator = session.getTransactionCoordinator();
-		final TransactionImplementor transaction = transactionCoordinator.getTransaction();
-
-		return isOpen() && transaction.getJoinStatus() == JoinStatus.JOINED;
+		return isOpen() && session.getTransactionCoordinator().isJoined();
 	}
 
 	@Override
 	public void joinTransaction() {
 		checkOpen();
 		joinTransaction( true );
 	}
 
 	private void joinTransaction(boolean explicitRequest) {
 		if ( transactionType != PersistenceUnitTransactionType.JTA ) {
 			if ( explicitRequest ) {
 			    LOG.callingJoinTransactionOnNonJtaEntityManager();
 			}
 			return;
 		}
 
 		final SessionImplementor session = (SessionImplementor) internalGetSession();
-		final TransactionCoordinator transactionCoordinator = session.getTransactionCoordinator();
-		final TransactionImplementor transaction = transactionCoordinator.getTransaction();
-
-		transaction.markForJoin();
-		transactionCoordinator.pulse();
-
-		LOG.debug( "Looking for a JTA transaction to join" );
-		if ( ! transactionCoordinator.isTransactionJoinable() ) {
-			if ( explicitRequest ) {
-				// if this is an explicit join request, log a warning so user can track underlying cause
-				// of subsequent exceptions/messages
-				LOG.unableToJoinTransaction(Environment.TRANSACTION_STRATEGY);
-			}
-		}
-
-		try {
-			if ( transaction.getJoinStatus() == JoinStatus.JOINED ) {
-				LOG.debug( "Transaction already joined" );
-				return; // noop
-			}
-
-			// join the transaction and then recheck the status
-			transaction.join();
-			if ( transaction.getJoinStatus() == JoinStatus.NOT_JOINED ) {
-				if ( explicitRequest ) {
-					throw new TransactionRequiredException( "No active JTA transaction on joinTransaction call" );
-				}
-				else {
-					LOG.debug( "Unable to join JTA transaction" );
-					return;
-				}
-			}
-			else if ( transaction.getJoinStatus() == JoinStatus.MARKED_FOR_JOINED ) {
-				throw new AssertionFailure( "Transaction MARKED_FOR_JOINED after isOpen() call" );
-			}
-
-			// register behavior changes
-			final SynchronizationCallbackCoordinator callbackCoordinator = transactionCoordinator.getSynchronizationCallbackCoordinator();
-			callbackCoordinator.setManagedFlushChecker( new ManagedFlushCheckerImpl() );
-			callbackCoordinator.setExceptionMapper( new CallbackExceptionMapperImpl() );
-			callbackCoordinator.setAfterCompletionAction( new AfterCompletionActionImpl( session, transactionType ) );
-		}
-		catch (HibernateException he) {
-			throw convert( he );
-		}
+		session.getTransactionCoordinator().explicitJoin();
 	}
 
 	/**
 	 * returns the underlying session
 	 */
 	public Object getDelegate() {
 		checkOpen();
 		return internalGetSession();
 	}
 
 	private void writeObject(ObjectOutputStream oos) throws IOException {
 		oos.defaultWriteObject();
 	}
 
 	private void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException {
 		ois.defaultReadObject();
 		tx = new TransactionImpl( this );
 	}
 
 	@Override
 	public void handlePersistenceException(PersistenceException e) {
 		if ( e instanceof NoResultException ) {
 			return;
 		}
 		if ( e instanceof NonUniqueResultException ) {
 			return;
 		}
 		if ( e instanceof LockTimeoutException ) {
 			return;
 		}
 		if ( e instanceof QueryTimeoutException ) {
 			return;
 		}
 
 		try {
 			markForRollbackOnly();
 		}
 		catch ( Exception ne ) {
 			//we do not want the subsequent exception to swallow the original one
             LOG.unableToMarkForRollbackOnPersistenceException(ne);
 		}
 	}
 
 	@Override
 	public void throwPersistenceException(PersistenceException e) {
 		handlePersistenceException( e );
 		throw e;
 	}
 
 	@Override
 	public RuntimeException convert(HibernateException e) {
 		//FIXME should we remove all calls to this method and use convert(RuntimeException) ?
 		return convert( e, null );
 	}
 
 	public RuntimeException convert(RuntimeException e) {
 		RuntimeException result = e;
 		if ( e instanceof HibernateException ) {
 			result = convert( (HibernateException) e );
 		}
 		else {
 			markForRollbackOnly();
 		}
 		return result;
 	}
 
 	public RuntimeException convert(RuntimeException e, LockOptions lockOptions) {
 		RuntimeException result = e;
 		if ( e instanceof HibernateException ) {
 			result = convert( (HibernateException) e , lockOptions );
 		}
 		else {
 			markForRollbackOnly();
 		}
 		return result;
 	}
 
 	@Override
 	public RuntimeException convert(HibernateException e, LockOptions lockOptions) {
-		if ( e instanceof StaleStateException ) {
-			final PersistenceException converted = wrapStaleStateException( (StaleStateException) e );
+		Throwable cause = e;
+		if(e instanceof TransactionException){
+			cause = e.getCause();
+		}
+		if ( cause instanceof StaleStateException ) {
+			final PersistenceException converted = wrapStaleStateException( (StaleStateException) cause );
 			handlePersistenceException( converted );
 			return converted;
 		}
-		else if ( e instanceof LockingStrategyException ) {
-			final PersistenceException converted = wrapLockException( e, lockOptions );
+		else if ( cause instanceof LockingStrategyException ) {
+			final PersistenceException converted = wrapLockException( (HibernateException) cause, lockOptions );
 			handlePersistenceException( converted );
 			return converted;
 		}
-		else if ( e instanceof org.hibernate.exception.LockTimeoutException ) {
-			final PersistenceException converted = wrapLockException( e, lockOptions );
+		else if ( cause instanceof org.hibernate.exception.LockTimeoutException ) {
+			final PersistenceException converted = wrapLockException( (HibernateException) cause, lockOptions );
 			handlePersistenceException( converted );
 			return converted;
 		}
-		else if ( e instanceof org.hibernate.PessimisticLockException ) {
-			final PersistenceException converted = wrapLockException( e, lockOptions );
+		else if ( cause instanceof org.hibernate.PessimisticLockException ) {
+			final PersistenceException converted = wrapLockException( (HibernateException) cause, lockOptions );
 			handlePersistenceException( converted );
 			return converted;
 		}
-		else if ( e instanceof org.hibernate.QueryTimeoutException ) {
-			final QueryTimeoutException converted = new QueryTimeoutException( e.getMessage(), e );
+		else if ( cause instanceof org.hibernate.QueryTimeoutException ) {
+			final QueryTimeoutException converted = new QueryTimeoutException( cause.getMessage(), cause );
 			handlePersistenceException( converted );
 			return converted;
 		}
-		else if ( e instanceof ObjectNotFoundException ) {
-			final EntityNotFoundException converted = new EntityNotFoundException( e.getMessage() );
+		else if ( cause instanceof ObjectNotFoundException ) {
+			final EntityNotFoundException converted = new EntityNotFoundException( cause.getMessage() );
 			handlePersistenceException( converted );
 			return converted;
 		}
-		else if ( e instanceof org.hibernate.NonUniqueObjectException ) {
-			final EntityExistsException converted = new EntityExistsException( e.getMessage() );
+		else if ( cause instanceof org.hibernate.NonUniqueObjectException ) {
+			final EntityExistsException converted = new EntityExistsException( cause.getMessage() );
 			handlePersistenceException( converted );
 			return converted;
         }
-		else if ( e instanceof org.hibernate.NonUniqueResultException ) {
-			final NonUniqueResultException converted = new NonUniqueResultException( e.getMessage() );
+		else if ( cause instanceof org.hibernate.NonUniqueResultException ) {
+			final NonUniqueResultException converted = new NonUniqueResultException( cause.getMessage() );
 			handlePersistenceException( converted );
 			return converted;
 		}
-		else if ( e instanceof UnresolvableObjectException ) {
-			final EntityNotFoundException converted = new EntityNotFoundException( e.getMessage() );
+		else if ( cause instanceof UnresolvableObjectException ) {
+			final EntityNotFoundException converted = new EntityNotFoundException( cause.getMessage() );
 			handlePersistenceException( converted );
 			return converted;
 		}
-		else if ( e instanceof QueryException ) {
-			return new IllegalArgumentException( e );
+		else if ( cause instanceof QueryException ) {
+			return new IllegalArgumentException( cause );
 		}
-		else if ( e instanceof TransientObjectException ) {
+		else if ( cause instanceof TransientObjectException ) {
 			try {
 				markForRollbackOnly();
 			}
 			catch ( Exception ne ) {
 				//we do not want the subsequent exception to swallow the original one
 				LOG.unableToMarkForRollbackOnTransientObjectException( ne );
 			}
 			return new IllegalStateException( e ); //Spec 3.2.3 Synchronization rules
 		}
 		else {
-			final PersistenceException converted = new PersistenceException( e );
+			final PersistenceException converted = new PersistenceException( cause );
 			handlePersistenceException( converted );
 			return converted;
 		}
 	}
 
 	@Override
 	public void throwPersistenceException(HibernateException e) {
 		throw convert( e );
 	}
 
 	@Override
 	public PersistenceException wrapStaleStateException(StaleStateException e) {
 		PersistenceException pe;
 		if ( e instanceof StaleObjectStateException ) {
 			final StaleObjectStateException sose = (StaleObjectStateException) e;
 			final Serializable identifier = sose.getIdentifier();
 			if ( identifier != null ) {
 				try {
 					final Object entity = internalGetSession().load( sose.getEntityName(), identifier );
 					if ( entity instanceof Serializable ) {
 						//avoid some user errors regarding boundary crossing
 						pe = new OptimisticLockException( e.getMessage(), e, entity );
 					}
 					else {
 						pe = new OptimisticLockException( e.getMessage(), e );
 					}
 				}
 				catch ( EntityNotFoundException enfe ) {
 					pe = new OptimisticLockException( e.getMessage(), e );
 				}
 			}
 			else {
 				pe = new OptimisticLockException( e.getMessage(), e );
 			}
 		}
 		else {
 			pe = new OptimisticLockException( e.getMessage(), e );
 		}
 		return pe;
 	}
 
 	public PersistenceException wrapLockException(HibernateException e, LockOptions lockOptions) {
 		final PersistenceException pe;
 		if ( e instanceof OptimisticEntityLockException ) {
 			final OptimisticEntityLockException lockException = (OptimisticEntityLockException) e;
 			pe = new OptimisticLockException( lockException.getMessage(), lockException, lockException.getEntity() );
 		}
 		else if ( e instanceof org.hibernate.exception.LockTimeoutException ) {
 			pe = new LockTimeoutException( e.getMessage(), e, null );
 		}
 		else if ( e instanceof PessimisticEntityLockException ) {
 			final PessimisticEntityLockException lockException = (PessimisticEntityLockException) e;
 			if ( lockOptions != null && lockOptions.getTimeOut() > -1 ) {
 				// assume lock timeout occurred if a timeout or NO WAIT was specified
 				pe = new LockTimeoutException( lockException.getMessage(), lockException, lockException.getEntity() );
 			}
 			else {
 				pe = new PessimisticLockException( lockException.getMessage(), lockException, lockException.getEntity() );
 			}
 		}
 		else if ( e instanceof org.hibernate.PessimisticLockException ) {
 			final org.hibernate.PessimisticLockException jdbcLockException = (org.hibernate.PessimisticLockException) e;
 			if ( lockOptions != null && lockOptions.getTimeOut() > -1 ) {
 				// assume lock timeout occurred if a timeout or NO WAIT was specified
 				pe = new LockTimeoutException( jdbcLockException.getMessage(), jdbcLockException, null );
 			}
 			else {
 				pe = new PessimisticLockException( jdbcLockException.getMessage(), jdbcLockException, null );
 			}
 		}
 		else {
 			pe = new OptimisticLockException( e );
 		}
 		return pe;
 	}
-
-	private static class AfterCompletionActionImpl implements AfterCompletionAction {
-		private final SessionImplementor session;
-		private final PersistenceUnitTransactionType transactionType;
-
-		private AfterCompletionActionImpl(SessionImplementor session, PersistenceUnitTransactionType transactionType) {
-			this.session = session;
-			this.transactionType = transactionType;
-		}
-
-		@Override
-		public void doAction(TransactionCoordinator transactionCoordinator, int status) {
-			if ( session.isClosed() ) {
-                LOG.trace("Session was closed; nothing to do");
-				return;
-			}
-
-			final boolean successful = JtaStatusHelper.isCommitted( status );
-			if ( !successful && transactionType == PersistenceUnitTransactionType.JTA ) {
-				( (Session) session ).clear();
-			}
-			session.getTransactionCoordinator().resetJoinStatus();
-		}
-	}
-
-	private static class ManagedFlushCheckerImpl implements ManagedFlushChecker {
-		@Override
-		public boolean shouldDoManagedFlush(TransactionCoordinator coordinator, int jtaStatus) {
-			return !coordinator.getTransactionContext().isClosed()
-					&& !coordinator.getTransactionContext().isFlushModeNever()
-					&& !JtaStatusHelper.isRollback( jtaStatus );
-		}
-	}
-
-	private class CallbackExceptionMapperImpl implements ExceptionMapper {
-		@Override
-		public RuntimeException mapStatusCheckFailure(String message, SystemException systemException) {
-			throw new PersistenceException( message, systemException );
-		}
-
-		@Override
-		public RuntimeException mapManagedFlushFailure(String message, RuntimeException failure) {
-			if ( HibernateException.class.isInstance( failure ) ) {
-				throw convert( failure );
-			}
-			if ( PersistenceException.class.isInstance( failure ) ) {
-				throw failure;
-			}
-			throw new PersistenceException( message, failure );
-		}
-	}
 }
diff --git a/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/beanvalidation/BeanValidationTest.java b/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/beanvalidation/BeanValidationTest.java
index 1e8b4c5db7..b289f70ab5 100644
--- a/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/beanvalidation/BeanValidationTest.java
+++ b/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/beanvalidation/BeanValidationTest.java
@@ -1,92 +1,94 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.test.beanvalidation;
 
 import java.math.BigDecimal;
 import javax.persistence.EntityManager;
+import javax.persistence.PersistenceException;
 import javax.persistence.RollbackException;
 import javax.validation.ConstraintViolationException;
 
 import org.junit.Test;
 
 import org.hibernate.jpa.test.BaseEntityManagerFunctionalTestCase;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * @author Emmanuel Bernard
  */
 public class BeanValidationTest extends BaseEntityManagerFunctionalTestCase {
 	@Test
 	public void testBeanValidationIntegrationOnFlush() {
 		CupHolder ch = new CupHolder();
 		ch.setRadius( new BigDecimal( "12" ) );
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		try {
 			em.persist( ch );
 			em.flush();
 			fail("invalid object should not be persisted");
 		}
 		catch ( ConstraintViolationException e ) {
 			assertEquals( 1, e.getConstraintViolations().size() );
 		}
 		assertTrue(
 				"A constraint violation exception should mark the transaction for rollback",
 				em.getTransaction().getRollbackOnly()
 		);
 		em.getTransaction().rollback();
 		em.close();
 	}
 
 	@Test
 	public void testBeanValidationIntegrationOnCommit() {
 		CupHolder ch = new CupHolder();
 		ch.setRadius( new BigDecimal( "9" ) );
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		em.persist( ch );
 		em.flush();
 		try {
 			ch.setRadius( new BigDecimal( "12" ) );
 			em.getTransaction().commit();
 			fail("invalid object should not be persisted");
 		}
 		catch ( RollbackException e ) {
 			final Throwable cve = e.getCause();
-			assertTrue( cve instanceof ConstraintViolationException );
-			assertEquals( 1, ( (ConstraintViolationException) cve ).getConstraintViolations().size() );
+			assertTrue( cve instanceof PersistenceException );
+			assertTrue( cve.getCause() instanceof ConstraintViolationException );
+			assertEquals( 1, ( (ConstraintViolationException) cve.getCause() ).getConstraintViolations().size() );
 		}
 		em.close();
 	}
 
 	@Override
 	public Class[] getAnnotatedClasses() {
 		return new Class[] {
 				CupHolder.class
 		};
 	}
 }
diff --git a/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/cascade/multicircle/MultiCircleJpaCascadeTest.java b/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/cascade/multicircle/MultiCircleJpaCascadeTest.java
index 4ec860f7bd..2922031bf9 100644
--- a/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/cascade/multicircle/MultiCircleJpaCascadeTest.java
+++ b/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/cascade/multicircle/MultiCircleJpaCascadeTest.java
@@ -1,333 +1,336 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.test.cascade.multicircle;
 
 import javax.persistence.EntityManager;
 import javax.persistence.RollbackException;
 
 import junit.framework.Assert;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 
+import org.hibernate.TransactionException;
 import org.hibernate.TransientPropertyValueException;
 import org.hibernate.jpa.test.BaseEntityManagerFunctionalTestCase;
 import org.hibernate.testing.FailureExpected;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * This test uses a complicated model that requires Hibernate to delay
  * inserts until non-nullable transient entity dependencies are resolved.
  *
  * All IDs are generated from a sequence.
  *
  * JPA cascade types are used (javax.persistence.CascadeType)..
  *
  * This test uses the following model:
  *
  * <code>
  *     ------------------------------ N G
  *     |
  *     |                                1
  *     |                                |
  *     |                                |
  *     |                                N
  *     |
  *     |         E N--------------0,1 * F
  *     |
  *     |         1                      N
  *     |         |                      |
  *     |         |                      |
  *     1         N                      |
  *     *                                |
  *     B * N---1 D * 1------------------
  *     *
  *     N         N
  *     |         |
  *     |         |
  *     1         |
  *               |
  *     C * 1-----
  *</code>
  *
  * In the diagram, all associations are bidirectional;
  * assocations marked with '*' cascade persist, save, merge operations to the
  * associated entities (e.g., B cascades persist to D, but D does not cascade
  * persist to B);
  *
  * b, c, d, e, f, and g are all transient unsaved that are associated with each other.
  *
  * When saving b, the entities are added to the ActionQueue in the following order:
  * c, d (depends on e), f (depends on d, g), e, b, g.
  *
  * Entities are inserted in the following order:
  * c, e, d, b, g, f.
  */
 public class MultiCircleJpaCascadeTest extends BaseEntityManagerFunctionalTestCase {
 	private B b;
 	private C c;
 	private D d;
 	private E e;
 	private F f;
 	private G g;
 	private boolean skipCleanup;
 
 	@Before
 	public void setup() {
 		b = new B();
 		c = new C();
 		d = new D();
 		e = new E();
 		f = new F();
 		g = new G();
 
 		b.getGCollection().add( g );
 		b.setC( c );
 		b.setD( d );
 
 		c.getBCollection().add( b );
 		c.getDCollection().add( d );
 
 		d.getBCollection().add( b );
 		d.setC( c );
 		d.setE( e );
 		d.getFCollection().add( f );
 
 		e.getDCollection().add( d );
 		e.setF( f );
 
 		f.getECollection().add( e );
 		f.setD( d );
 		f.setG( g );
 
 		g.setB( b );
 		g.getFCollection().add( f );
 
 		skipCleanup = false;
 	}
 
 	@After
 	public void cleanup() {
 		if ( ! skipCleanup ) {
 			b.setC( null );
 			b.setD( null );
 			b.getGCollection().remove( g );
 
 			c.getBCollection().remove( b );
 			c.getDCollection().remove( d );
 
 			d.getBCollection().remove( b );
 			d.setC( null );
 			d.setE( null );
 			d.getFCollection().remove( f );
 
 			e.getDCollection().remove( d );
 			e.setF( null );
 
 			f.setD( null );
 			f.getECollection().remove( e );
 			f.setG( null );
 
 			g.setB( null );
 			g.getFCollection().remove( f );
 
 			EntityManager em = getOrCreateEntityManager();
 			em.getTransaction().begin();
 			b = em.merge( b );
 			c = em.merge( c );
 			d = em.merge( d );
 			e = em.merge( e );
 			f = em.merge( f );
 			g = em.merge( g );
 			em.remove( f );
 			em.remove( g );
 			em.remove( b );
 			em.remove( d );
 			em.remove( e );
 			em.remove( c );
 			em.getTransaction().commit();
 			em.close();
 		}
 	}
 
 	@Test
 	public void testPersist() {
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		em.persist( b );
 		em.getTransaction().commit();
 		em.close();
 
 		check();
 	}
 
 	@Test
 	public void testPersistNoCascadeToTransient() {
 		skipCleanup = true;
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		try {
 			em.persist( c );
 			fail( "should have failed." );
 		}
 		catch( IllegalStateException ex ) {
 			assertTrue( TransientPropertyValueException.class.isInstance( ex.getCause() ) );
 			TransientPropertyValueException pve = (TransientPropertyValueException) ex.getCause();
 			assertEquals( G.class.getName(), pve.getTransientEntityName() );
 			assertEquals( F.class.getName(),  pve.getPropertyOwnerEntityName() );
 			assertEquals( "g", pve.getPropertyName() );
 		}
 		em.getTransaction().rollback();
 		em.close();
 	}
 
 	@Test
 	@FailureExpected( jiraKey = "HHH-6999" )
 	// fails on d.e; should pass
 	public void testPersistThenUpdate() {
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		em.persist( b );
 		// remove old e from associations
 		e.getDCollection().remove( d );
 		d.setE( null );
 		f.getECollection().remove( e );
 		e.setF( null );
 		// add new e to associations
 		e = new E();
 		e.getDCollection().add( d );
 		f.getECollection().add( e );
 		d.setE( e );
 		e.setF( f );
 		em.getTransaction().commit();
 		em.close();
 
 		check();
 	}
 
 	@Test
 	public void testPersistThenUpdateNoCascadeToTransient() {
 		// expected to fail, so nothing will be persisted.
 		skipCleanup = true;
 
 		// remove elements from collections and persist
 		c.getBCollection().clear();
 		c.getDCollection().clear();
 
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		em.persist( c );
 		// now add the elements back
 		c.getBCollection().add( b );
 		c.getDCollection().add( d );
 		try {
 			em.getTransaction().commit();
 			fail( "should have thrown IllegalStateException");
 		}
 		catch ( RollbackException ex ) {
 			assertTrue( ex.getCause() instanceof IllegalStateException );
 			IllegalStateException ise = ( IllegalStateException ) ex.getCause();
 			// should fail on entity g (due to no cascade to f.g);
 			// instead it fails on entity e ( due to no cascade to d.e)
 			// because e is not in the process of being saved yet.
 			// when HHH-6999 is fixed, this test should be changed to
 			// check for g and f.g
-			assertTrue( ise.getCause() instanceof TransientPropertyValueException );
-			TransientPropertyValueException tpve = ( TransientPropertyValueException ) ise.getCause();
+			assertTrue( ise.getCause() instanceof TransactionException );
+			Throwable cause = ise.getCause().getCause();
+			assertTrue( cause instanceof TransientPropertyValueException );
+			TransientPropertyValueException tpve = ( TransientPropertyValueException ) cause;
 			assertEquals( E.class.getName(), tpve.getTransientEntityName() );
 			assertEquals( D.class.getName(), tpve.getPropertyOwnerEntityName() );
 			assertEquals( "e", tpve.getPropertyName() );
 		}
 		em.close();
 	}
 
 	@Test
 	public void testMerge() {
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		b = em.merge( b );
 		c = b.getC();
 		d = b.getD();
 		e = d.getE();
 		f = e.getF();
 		g = f.getG();
 		em.getTransaction().commit();
 		em.close();
 
 		check();
 	}
 
 	private void check() {
 		EntityManager em = getOrCreateEntityManager();
 		em.getTransaction().begin();
 		B bRead = em.find( B.class, b.getId() );
 		Assert.assertEquals( b, bRead );
 
 		G gRead = bRead.getGCollection().iterator().next();
 		Assert.assertEquals( g, gRead );
 		C cRead = bRead.getC();
 		Assert.assertEquals( c, cRead );
 		D dRead = bRead.getD();
 		Assert.assertEquals( d, dRead );
 
 		Assert.assertSame( bRead, cRead.getBCollection().iterator().next() );
 		Assert.assertSame( dRead, cRead.getDCollection().iterator().next() );
 
 		Assert.assertSame( bRead, dRead.getBCollection().iterator().next() );
 		Assert.assertEquals( cRead, dRead.getC() );
 		E eRead = dRead.getE();
 		Assert.assertEquals( e, eRead );
 		F fRead = dRead.getFCollection().iterator().next();
 		Assert.assertEquals( f, fRead );
 
 		Assert.assertSame( dRead, eRead.getDCollection().iterator().next() );
 		Assert.assertSame( fRead, eRead.getF() );
 
 		Assert.assertSame( eRead, fRead.getECollection().iterator().next() );
 		Assert.assertSame( dRead, fRead.getD() );
 		Assert.assertSame( gRead, fRead.getG());
 
 		Assert.assertSame( bRead, gRead.getB() );
 		Assert.assertSame( fRead, gRead.getFCollection().iterator().next() );
 
 		em.getTransaction().commit();
 		em.close();
 	}
 
 	@Override
 	protected Class[] getAnnotatedClasses() {
 		return new Class[]{
 				B.class,
 				C.class,
 				D.class,
 				E.class,
 				F.class,
 				G.class
 		};
 	}
 
 }
diff --git a/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/transaction/SynchronizationTypeTest.java b/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/transaction/SynchronizationTypeTest.java
index 05bb4d8e3a..fa3adea9fe 100644
--- a/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/transaction/SynchronizationTypeTest.java
+++ b/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/transaction/SynchronizationTypeTest.java
@@ -1,191 +1,194 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.test.transaction;
 
 import javax.persistence.EntityManager;
 import javax.persistence.LockModeType;
 import javax.persistence.SynchronizationType;
 import javax.persistence.TransactionRequiredException;
 import javax.persistence.criteria.CriteriaDelete;
 import javax.persistence.criteria.CriteriaUpdate;
 import java.util.Map;
 
-import org.hibernate.Session;
-import org.hibernate.Transaction;
-import org.hibernate.jpa.test.BaseEntityManagerFunctionalTestCase;
 import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.engine.transaction.internal.jta.CMTTransaction;
 import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
 import org.hibernate.jpa.AvailableSettings;
+import org.hibernate.jpa.test.BaseEntityManagerFunctionalTestCase;
+import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorImpl;
 
 import org.junit.Test;
 
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.jta.TestingJtaBootstrap;
 import org.hibernate.testing.jta.TestingJtaPlatformImpl;
 import org.hibernate.testing.junit4.ExtraAssertions;
 
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 /**
  * Tests of the JPA 2.1 added {@link SynchronizationType} handling.  {@link SynchronizationType#SYNCHRONIZED} is
  * the same as 2.0 behavior, so we do not explicitly test for that ({@link TransactionJoiningTest} handles it).
  * Tests here specifically test the {@link SynchronizationType#UNSYNCHRONIZED} behavior
  *
  * @author Steve Ebersole
  */
 @TestForIssue( jiraKey = "HHH-7451" )
 public class SynchronizationTypeTest extends BaseEntityManagerFunctionalTestCase {
 	@Override
 	protected void addConfigOptions(Map options) {
 		super.addConfigOptions( options );
 		TestingJtaBootstrap.prepare( options );
 		options.put( AvailableSettings.TRANSACTION_TYPE, "JTA" );
 	}
 
 	@Override
 	protected Class<?>[] getAnnotatedClasses() {
 		return new Class[] { Book.class };
 	}
 
 	@Test
 	public void testUnSynchronizedExplicitJoinHandling() throws Exception {
 		// JPA 2.1 adds this notion allowing to open an EM using a specified "SynchronizationType".
 
 		assertFalse( JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
 
 		EntityManager entityManager = entityManagerFactory().createEntityManager( SynchronizationType.UNSYNCHRONIZED, null );
 		TransactionJoinHandlingChecker.validateExplicitJoiningHandling( entityManager );
 	}
 
 	@Test
 	public void testImplicitJoining() throws Exception {
 		// here the transaction is started before the EM is opened.  Because the SynchronizationType is UNSYNCHRONIZED
 		// though, it should not auto join the transaction
 
 		assertFalse( "setup problem", JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		assertTrue( "setup problem", JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
 
 		EntityManager entityManager = entityManagerFactory().createEntityManager( SynchronizationType.UNSYNCHRONIZED, null );
 		SessionImplementor session = entityManager.unwrap( SessionImplementor.class );
-		Transaction hibernateTransaction = ( (Session) session ).getTransaction();
-		ExtraAssertions.assertTyping( CMTTransaction.class, hibernateTransaction );
-		assertFalse( "EM was auto joined on creation", session.getTransactionCoordinator().isSynchronizationRegistered() );
-		assertFalse( "EM was auto joined on creation", hibernateTransaction.isParticipating() );
+
+		ExtraAssertions.assertTyping( JtaTransactionCoordinatorImpl.class, session.getTransactionCoordinator() );
+		JtaTransactionCoordinatorImpl transactionCoordinator = (JtaTransactionCoordinatorImpl) session.getTransactionCoordinator();
+
+		assertFalse( "EM was auto joined on creation", transactionCoordinator.isSynchronizationRegistered() );
+		assertTrue( "EM was auto joined on creation", transactionCoordinator.isActive() );
+		assertFalse( "EM was auto joined on creation", transactionCoordinator.isJoined() );
 
 		session.getFlushMode();
-		assertFalse( session.getTransactionCoordinator().isSynchronizationRegistered() );
-		assertFalse( hibernateTransaction.isParticipating() );
+		assertFalse( transactionCoordinator.isSynchronizationRegistered() );
+		assertTrue( transactionCoordinator.isActive() );
+		assertFalse( transactionCoordinator.isJoined() );
 
 		entityManager.joinTransaction();
 		assertTrue( JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
-		assertTrue( hibernateTransaction.isActive() );
-		assertTrue( session.getTransactionCoordinator().isSynchronizationRegistered() );
-		assertTrue( hibernateTransaction.isParticipating() );
+		assertTrue( transactionCoordinator.isActive() );
+		assertTrue( transactionCoordinator.isSynchronizationRegistered() );
+		assertTrue( transactionCoordinator.isActive() );
+		assertTrue( transactionCoordinator.isJoined() );
 
 		assertTrue( entityManager.isOpen() );
 		assertTrue( session.isOpen() );
 		entityManager.close();
 		assertFalse( entityManager.isOpen() );
 		assertTrue( session.isOpen() );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 		assertFalse( entityManager.isOpen() );
 		assertFalse( session.isOpen() );
 	}
 
 	@Test
 	public void testDisallowedOperations() throws Exception {
 		// test calling operations that are disallowed while a UNSYNCHRONIZED persistence context is not
 		// yet joined/enlisted
 
 		assertFalse( "setup problem", JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		assertTrue(
 				"setup problem", JtaStatusHelper.isActive(
 				TestingJtaPlatformImpl.INSTANCE
 						.getTransactionManager()
 		)
 		);
 
 		EntityManager entityManager = entityManagerFactory().createEntityManager( SynchronizationType.UNSYNCHRONIZED, null );
 
 		// explicit flushing
 		try {
 			entityManager.flush();
 			fail( "Expecting flush() call to fail" );
 		}
 		catch (TransactionRequiredException expected) {
 		}
 
 		// bulk operations
 		try {
 			entityManager.createQuery( "delete Book" ).executeUpdate();
 			fail( "Expecting executeUpdate() call to fail" );
 		}
 		catch (TransactionRequiredException expected) {
 		}
 
 		try	{
 			entityManager.createQuery( "update Book set name = null" ).executeUpdate();
 			fail( "Expecting executeUpdate() call to fail" );
 		}
 		catch (TransactionRequiredException expected) {
 		}
 
 		try	{
 			CriteriaDelete<Book> deleteCriteria = entityManager.getCriteriaBuilder().createCriteriaDelete( Book.class );
 			deleteCriteria.from( Book.class );
 			entityManager.createQuery( deleteCriteria ).executeUpdate();
 			fail( "Expecting executeUpdate() call to fail" );
 		}
 		catch (TransactionRequiredException expected) {
 		}
 
 		try {
 			CriteriaUpdate<Book> updateCriteria = entityManager.getCriteriaBuilder().createCriteriaUpdate( Book.class );
 			updateCriteria.from( Book.class );
 			updateCriteria.set( Book_.name, (String) null );
 			entityManager.createQuery( updateCriteria ).executeUpdate();
 			fail( "Expecting executeUpdate() call to fail" );
 		}
 		catch (TransactionRequiredException expected) {
 		}
 
 		try {
 			entityManager.createQuery( "select b from Book b" )
 					.setLockMode( LockModeType.PESSIMISTIC_WRITE )
 					.getResultList();
 			fail( "Expecting attempted pessimistic lock query to fail" );
 		}
 		catch (TransactionRequiredException expected) {
 		}
 
 		entityManager.close();
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().rollback();
 	}
 }
diff --git a/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/transaction/TransactionJoinHandlingChecker.java b/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/transaction/TransactionJoinHandlingChecker.java
index 1b41db4d8f..496997d95a 100644
--- a/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/transaction/TransactionJoinHandlingChecker.java
+++ b/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/transaction/TransactionJoinHandlingChecker.java
@@ -1,85 +1,89 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.test.transaction;
 
 import javax.persistence.EntityManager;
 
 import org.hibernate.Session;
 import org.hibernate.Transaction;
 import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.engine.transaction.internal.jta.CMTTransaction;
 import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
+import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorImpl;
 
 import org.hibernate.testing.jta.TestingJtaPlatformImpl;
 import org.hibernate.testing.junit4.ExtraAssertions;
 
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 
 /**
  * Helper for centralized transaction join checking
  *
  * @author Steve Ebersole
  */
 public class TransactionJoinHandlingChecker {
 	static void validateExplicitJoiningHandling(EntityManager entityManager) throws Exception {
 		SessionImplementor session = entityManager.unwrap( SessionImplementor.class );
-		assertFalse( session.getTransactionCoordinator().isSynchronizationRegistered() );
-		Transaction hibernateTransaction = ((Session) session).getTransaction();
-		ExtraAssertions.assertTyping( CMTTransaction.class, hibernateTransaction );
-		assertFalse( hibernateTransaction.isParticipating() );
+
+		ExtraAssertions.assertTyping( JtaTransactionCoordinatorImpl.class, session.getTransactionCoordinator() );
+		JtaTransactionCoordinatorImpl transactionCoordinator = (JtaTransactionCoordinatorImpl) session.getTransactionCoordinator();
+
+		assertFalse( transactionCoordinator.isSynchronizationRegistered() );
+		assertFalse( transactionCoordinator.isActive() );
+		assertFalse( transactionCoordinator.isJoined() );
 
 		session.getFlushMode();
-		assertFalse( session.getTransactionCoordinator().isSynchronizationRegistered() );
-		assertFalse( hibernateTransaction.isParticipating() );
+		assertFalse( transactionCoordinator.isSynchronizationRegistered() );
+		assertFalse( transactionCoordinator.isActive() );
+		assertFalse( transactionCoordinator.isJoined() );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		assertTrue( JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
-		assertTrue( hibernateTransaction.isActive() );
-		assertFalse( hibernateTransaction.isParticipating() );
-		assertFalse( session.getTransactionCoordinator().isSynchronizationRegistered() );
+		assertTrue( transactionCoordinator.isActive() );
+		assertFalse( transactionCoordinator.isJoined() );
+		assertFalse( transactionCoordinator.isSynchronizationRegistered() );
 
 		session.getFlushMode();
 		assertTrue( JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
-		assertTrue( hibernateTransaction.isActive() );
-		assertFalse( session.getTransactionCoordinator().isSynchronizationRegistered() );
-		assertFalse( hibernateTransaction.isParticipating() );
+		assertTrue( transactionCoordinator.isActive() );
+		assertFalse( transactionCoordinator.isSynchronizationRegistered() );
+		assertFalse( transactionCoordinator.isJoined() );
 
 		entityManager.joinTransaction();
 		assertTrue( JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
-		assertTrue( hibernateTransaction.isActive() );
-		assertTrue( session.getTransactionCoordinator().isSynchronizationRegistered() );
-		assertTrue( hibernateTransaction.isParticipating() );
+		assertTrue( transactionCoordinator.isActive() );
+		assertTrue( transactionCoordinator.isSynchronizationRegistered() );
+		assertTrue( transactionCoordinator.isJoined() );
 
 		assertTrue( entityManager.isOpen() );
 		assertTrue( session.isOpen() );
 		entityManager.close();
 		assertFalse( entityManager.isOpen() );
 		assertTrue( session.isOpen() );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 		assertFalse( entityManager.isOpen() );
 		assertFalse( session.isOpen() );
 	}
 }
\ No newline at end of file
diff --git a/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/transaction/TransactionJoiningTest.java b/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/transaction/TransactionJoiningTest.java
index f0f820e0aa..0f8bc5fc1d 100644
--- a/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/transaction/TransactionJoiningTest.java
+++ b/hibernate-entitymanager/src/test/java/org/hibernate/jpa/test/transaction/TransactionJoiningTest.java
@@ -1,206 +1,204 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.test.transaction;
 
-import java.util.Map;
-import java.util.concurrent.CountDownLatch;
 import javax.persistence.EntityManager;
 import javax.persistence.PersistenceException;
 import javax.transaction.Status;
-import javax.transaction.Synchronization;
+import java.util.Map;
+import java.util.concurrent.CountDownLatch;
 
 import org.hibernate.HibernateException;
-import org.hibernate.Session;
-import org.hibernate.Transaction;
 import org.hibernate.engine.spi.SessionImplementor;
-import org.hibernate.engine.transaction.internal.jta.CMTTransaction;
 import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
 import org.hibernate.internal.SessionImpl;
 import org.hibernate.jpa.AvailableSettings;
 import org.hibernate.jpa.test.BaseEntityManagerFunctionalTestCase;
+import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorImpl;
+
+import org.junit.Test;
 
 import org.hibernate.testing.TestForIssue;
 import org.hibernate.testing.jta.TestingJtaBootstrap;
 import org.hibernate.testing.jta.TestingJtaPlatformImpl;
-import org.junit.Test;
+import org.hibernate.testing.junit4.ExtraAssertions;
 
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 
 /**
  * Largely a copy of {@link org.hibernate.test.jpa.txn.TransactionJoiningTest}
  *
  * @author Steve Ebersole
  */
 public class TransactionJoiningTest extends BaseEntityManagerFunctionalTestCase {
 	@Override
 	protected void addConfigOptions(Map options) {
 		super.addConfigOptions( options );
 		TestingJtaBootstrap.prepare( options );
 		options.put( AvailableSettings.TRANSACTION_TYPE, "JTA" );
 	}
 
 	@Test
 	public void testExplicitJoining() throws Exception {
 		assertFalse( JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
 
 		EntityManager entityManager = entityManagerFactory().createEntityManager();
 		TransactionJoinHandlingChecker.validateExplicitJoiningHandling( entityManager );
 	}
 
 	@Test
 	public void testImplicitJoining() throws Exception {
 		// here the transaction is started before the EM is opened...
 
 		assertFalse( JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		EntityManager entityManager = entityManagerFactory().createEntityManager();
 		SessionImplementor session = entityManager.unwrap( SessionImplementor.class );
-		Transaction hibernateTransaction = ( (Session) session ).getTransaction();
-		assertTrue( CMTTransaction.class.isInstance( hibernateTransaction ) );
-		assertTrue( session.getTransactionCoordinator().isSynchronizationRegistered() );
-		assertTrue( hibernateTransaction.isParticipating() );
+
+		ExtraAssertions.assertTyping( JtaTransactionCoordinatorImpl.class, session.getTransactionCoordinator() );
+		JtaTransactionCoordinatorImpl transactionCoordinator = (JtaTransactionCoordinatorImpl) session.getTransactionCoordinator();
+
+		assertTrue( transactionCoordinator.isSynchronizationRegistered() );
+		assertTrue( transactionCoordinator.isActive() );
+		assertTrue( transactionCoordinator.isJoined() );
 
 		assertTrue( entityManager.isOpen() );
 		assertTrue( session.isOpen() );
 		entityManager.close();
 		assertFalse( entityManager.isOpen() );
 		assertTrue( session.isOpen() );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 		assertFalse( entityManager.isOpen() );
 		assertFalse( session.isOpen() );
 	}
 
 	@Test
 	public void testCloseAfterCommit() throws Exception {
 		assertFalse( JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		EntityManager entityManager = entityManagerFactory().createEntityManager();
 		SessionImplementor session = entityManager.unwrap( SessionImplementor.class );
-		Transaction hibernateTransaction = ( (Session) session ).getTransaction();
-		assertTrue( CMTTransaction.class.isInstance( hibernateTransaction ) );
-		assertTrue( session.getTransactionCoordinator().isSynchronizationRegistered() );
-		assertTrue( hibernateTransaction.isParticipating() );
+
+		ExtraAssertions.assertTyping( JtaTransactionCoordinatorImpl.class, session.getTransactionCoordinator() );
+		JtaTransactionCoordinatorImpl transactionCoordinator = (JtaTransactionCoordinatorImpl) session.getTransactionCoordinator();
+
+		assertTrue( transactionCoordinator.isSynchronizationRegistered() );
+		assertTrue( transactionCoordinator.isActive() );
+		assertTrue( transactionCoordinator.isJoined() );
 
 		assertTrue( entityManager.isOpen() );
 		assertTrue( session.isOpen() );
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 		assertTrue( entityManager.isOpen() );
 		assertTrue( session.isOpen() );
 
 		entityManager.close();
 		assertFalse( entityManager.isOpen() );
 		assertFalse( session.isOpen() );
 	}
 
 	@Test
 	public void testImplicitJoiningWithExtraSynchronization() throws Exception {
 		assertFalse( JtaStatusHelper.isActive( TestingJtaPlatformImpl.INSTANCE.getTransactionManager() ) );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 		EntityManager entityManager = entityManagerFactory().createEntityManager();
 		SessionImplementor session = entityManager.unwrap( SessionImplementor.class );
-		Transaction hibernateTransaction = ( (Session) session ).getTransaction();
-		assertTrue( CMTTransaction.class.isInstance( hibernateTransaction ) );
-		assertTrue( session.getTransactionCoordinator().isSynchronizationRegistered() );
-		assertTrue( hibernateTransaction.isParticipating() );
+
+		ExtraAssertions.assertTyping( JtaTransactionCoordinatorImpl.class, session.getTransactionCoordinator() );
+		JtaTransactionCoordinatorImpl transactionCoordinator = (JtaTransactionCoordinatorImpl) session.getTransactionCoordinator();
+
+		assertTrue( transactionCoordinator.isSynchronizationRegistered() );
+		assertTrue( transactionCoordinator.isActive() );
+		assertTrue( transactionCoordinator.isJoined() );
 
 		entityManager.close();
 
-		hibernateTransaction.registerSynchronization(
-				new Synchronization() {
-					public void beforeCompletion() {
-						// nothing to do
-					}
-					public void afterCompletion( int i ) {
-						// nothing to do
-					}
-				}
-		);
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().commit();
 	}
 	
 	/**
 	 * In certain JTA environments (JBossTM, etc.), a background thread (reaper)
 	 * can rollback a transaction if it times out.  These timeouts are rare and
 	 * typically come from server failures.  However, we need to handle the
 	 * multi-threaded nature of the transaction afterCompletion action.
 	 * Emulate a timeout with a simple afterCompletion call in a thread.
 	 * See HHH-7910
 	 */
 	@Test
 	@TestForIssue(jiraKey = "HHH-7910")
 	public void testMultiThreadTransactionTimeout() throws Exception {
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().begin();
 
 		EntityManager em = entityManagerFactory().createEntityManager();
 		final SessionImpl sImpl = em.unwrap( SessionImpl.class );
 
 		final CountDownLatch latch = new CountDownLatch( 1 );
 
 		Thread thread = new Thread() {
 			public void run() {
-				sImpl.getTransactionCoordinator().getSynchronizationCallbackCoordinator()
+				((JtaTransactionCoordinatorImpl)sImpl.getTransactionCoordinator()).getSynchronizationCallbackCoordinator()
 						.afterCompletion( Status.STATUS_ROLLEDBACK );
 				latch.countDown();
 			}
 		};
 		thread.start();
 
 		latch.await();
 
 		boolean caught = false;
 		try {
 			em.persist( new Book( "The Book of Foo", 1 ) );
 		}
 		catch ( PersistenceException e ) {
 			caught = e.getCause().getClass().equals( HibernateException.class );
 		}
 		assertTrue( caught );
 
 		// Ensure that the connection was closed by the background thread.
 		caught = false;
 		try {
 			em.createQuery( "from Book" ).getResultList();
 		}
 		catch ( PersistenceException e ) {
 			// HHH-9312
 			caught = true;
 		}
 		assertTrue( caught );
 
 		TestingJtaPlatformImpl.INSTANCE.getTransactionManager().rollback();
 		em.close();
 	}
 
 	@Override
 	public Class[] getAnnotatedClasses() {
 		return new Class[] {
 				Book.class
 		};
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/strategy/ValidityAuditStrategy.java b/hibernate-envers/src/main/java/org/hibernate/envers/strategy/ValidityAuditStrategy.java
index ede6f3dd0c..8ef259ad1e 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/strategy/ValidityAuditStrategy.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/strategy/ValidityAuditStrategy.java
@@ -1,368 +1,369 @@
 package org.hibernate.envers.strategy;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Date;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.LockOptions;
 import org.hibernate.Session;
 import org.hibernate.action.spi.BeforeTransactionCompletionProcess;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.envers.RevisionType;
 import org.hibernate.envers.boot.internal.EnversService;
 import org.hibernate.envers.configuration.internal.AuditEntitiesConfiguration;
 import org.hibernate.envers.configuration.internal.GlobalConfiguration;
 import org.hibernate.envers.internal.entities.mapper.PersistentCollectionChangeData;
 import org.hibernate.envers.internal.entities.mapper.relation.MiddleComponentData;
 import org.hibernate.envers.internal.entities.mapper.relation.MiddleIdData;
 import org.hibernate.envers.internal.synchronization.SessionCacheCleaner;
 import org.hibernate.envers.internal.tools.query.Parameters;
 import org.hibernate.envers.internal.tools.query.QueryBuilder;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.jdbc.ReturningWork;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.persister.entity.UnionSubclassEntityPersister;
 import org.hibernate.property.Getter;
 import org.hibernate.sql.Update;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.ComponentType;
 import org.hibernate.type.Type;
 
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.MIDDLE_ENTITY_ALIAS;
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.REVISION_PARAMETER;
 
 /**
  * Audit strategy which persists and retrieves audit information using a validity algorithm, based on the
  * start-revision and end-revision of a row in the audit tables.
  * <p>This algorithm works as follows:
  * <ul>
  * <li>For a <strong>new row</strong> that is persisted in an audit table, only the <strong>start-revision</strong> column of that row is set</li>
  * <li>At the same time the <strong>end-revision</strong> field of the <strong>previous</strong> audit row is set to this revision</li>
  * <li>Queries are retrieved using 'between start and end revision', instead of a subquery.</li>
  * </ul>
  * </p>
  * <p/>
  * <p>
  * This has a few important consequences that need to be judged against against each other:
  * <ul>
  * <li>Persisting audit information is a bit slower, because an extra row is updated</li>
  * <li>Retrieving audit information is a lot faster</li>
  * </ul>
  * </p>
  *
  * @author Stephanie Pau
  * @author Adam Warski (adam at warski dot org)
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public class ValidityAuditStrategy implements AuditStrategy {
 	/**
 	 * getter for the revision entity field annotated with @RevisionTimestamp
 	 */
 	private Getter revisionTimestampGetter = null;
 
 	private final SessionCacheCleaner sessionCacheCleaner;
 
 	public ValidityAuditStrategy() {
 		sessionCacheCleaner = new SessionCacheCleaner();
 	}
 
 	@Override
 	public void perform(
 			final Session session,
 			final String entityName,
 			final EnversService enversService,
 			final Serializable id,
 			final Object data,
 			final Object revision) {
 		final AuditEntitiesConfiguration audEntitiesCfg = enversService.getAuditEntitiesConfiguration();
 		final String auditedEntityName = audEntitiesCfg.getAuditEntityName( entityName );
 		final String revisionInfoEntityName = enversService.getAuditEntitiesConfiguration().getRevisionInfoEntityName();
 
 		// Save the audit data
 		session.save( auditedEntityName, data );
 
 		// Update the end date of the previous row.
 		//
 		// When application reuses identifiers of previously removed entities:
 		// The UPDATE statement will no-op if an entity with a given identifier has been
 		// inserted for the first time. But in case a deleted primary key value was
 		// reused, this guarantees correct strategy behavior: exactly one row with
 		// null end date exists for each identifier.
 		final boolean reuseEntityIdentifier = enversService.getGlobalConfiguration().isAllowIdentifierReuse();
 		if ( reuseEntityIdentifier || getRevisionType( enversService, data ) != RevisionType.ADD ) {
 			// Register transaction completion process to guarantee execution of UPDATE statement after INSERT.
 			( (EventSource) session ).getActionQueue().registerProcess( new BeforeTransactionCompletionProcess() {
 				@Override
 				public void doBeforeTransactionCompletion(final SessionImplementor sessionImplementor) {
 					final Queryable productionEntityQueryable = getQueryable( entityName, sessionImplementor );
 					final Queryable rootProductionEntityQueryable = getQueryable(
 							productionEntityQueryable.getRootEntityName(), sessionImplementor
 					);
 					final Queryable auditedEntityQueryable = getQueryable( auditedEntityName, sessionImplementor );
 					final Queryable rootAuditedEntityQueryable = getQueryable(
 							auditedEntityQueryable.getRootEntityName(), sessionImplementor
 					);
 
 					final String updateTableName;
 					if ( UnionSubclassEntityPersister.class.isInstance( rootProductionEntityQueryable ) ) {
 						// this is the condition causing all the problems in terms of the generated SQL UPDATE
 						// the problem being that we currently try to update the in-line view made up of the union query
 						//
 						// this is extremely hacky means to get the root table name for the union subclass style entities.
 						// hacky because it relies on internal behavior of UnionSubclassEntityPersister
 						// !!!!!! NOTICE - using subclass persister, not root !!!!!!
 						updateTableName = auditedEntityQueryable.getSubclassTableName( 0 );
 					}
 					else {
 						updateTableName = rootAuditedEntityQueryable.getTableName();
 					}
 
 					final Type revisionInfoIdType = sessionImplementor.getFactory().getEntityPersister( revisionInfoEntityName ).getIdentifierType();
 					final String revEndColumnName = rootAuditedEntityQueryable.toColumns( enversService.getAuditEntitiesConfiguration().getRevisionEndFieldName() )[0];
 
 					final boolean isRevisionEndTimestampEnabled = enversService.getAuditEntitiesConfiguration().isRevisionEndTimestampEnabled();
 
 					// update audit_ent set REVEND = ? [, REVEND_TSTMP = ?] where (prod_ent_id) = ? and REV <> ? and REVEND is null
 					final Update update = new Update( sessionImplementor.getFactory().getDialect() ).setTableName( updateTableName );
 					// set REVEND = ?
 					update.addColumn( revEndColumnName );
 					// set [, REVEND_TSTMP = ?]
 					if ( isRevisionEndTimestampEnabled ) {
 						update.addColumn(
 								rootAuditedEntityQueryable.toColumns( enversService.getAuditEntitiesConfiguration().getRevisionEndTimestampFieldName() )[0]
 						);
 					}
 
 					// where (prod_ent_id) = ?
 					update.addPrimaryKeyColumns( rootProductionEntityQueryable.getIdentifierColumnNames() );
 					// where REV <> ?
 					update.addWhereColumn(
 							rootAuditedEntityQueryable.toColumns( enversService.getAuditEntitiesConfiguration().getRevisionNumberPath() )[0], "<> ?"
 					);
 					// where REVEND is null
 					update.addWhereColumn( revEndColumnName, " is null" );
 
 					// Now lets execute the sql...
 					final String updateSql = update.toStatementString();
 
 					int rowCount = ( (Session) sessionImplementor ).doReturningWork(
 							new ReturningWork<Integer>() {
 								@Override
 								public Integer execute(Connection connection) throws SQLException {
-									PreparedStatement preparedStatement = sessionImplementor.getTransactionCoordinator()
+									PreparedStatement preparedStatement = sessionImplementor
 											.getJdbcCoordinator().getStatementPreparer().prepareStatement( updateSql );
 
 									try {
 										int index = 1;
 
 										// set REVEND = ?
 										final Number revisionNumber = enversService.getRevisionInfoNumberReader().getRevisionNumber(
 												revision
 										);
 										revisionInfoIdType.nullSafeSet(
 												preparedStatement, revisionNumber, index, sessionImplementor
 										);
 										index += revisionInfoIdType.getColumnSpan( sessionImplementor.getFactory() );
 
 										// set [, REVEND_TSTMP = ?]
 										if ( isRevisionEndTimestampEnabled ) {
 											final Object revEndTimestampObj = revisionTimestampGetter.get( revision );
 											final Date revisionEndTimestamp = convertRevEndTimestampToDate( revEndTimestampObj );
 											final Type revEndTsType = rootAuditedEntityQueryable.getPropertyType(
 													enversService.getAuditEntitiesConfiguration().getRevisionEndTimestampFieldName()
 											);
 											revEndTsType.nullSafeSet(
 													preparedStatement, revisionEndTimestamp, index, sessionImplementor
 											);
 											index += revEndTsType.getColumnSpan( sessionImplementor.getFactory() );
 										}
 
 										// where (prod_ent_id) = ?
 										final Type idType = rootProductionEntityQueryable.getIdentifierType();
 										idType.nullSafeSet( preparedStatement, id, index, sessionImplementor );
 										index += idType.getColumnSpan( sessionImplementor.getFactory() );
 
 										// where REV <> ?
 										final Type revType = rootAuditedEntityQueryable.getPropertyType(
 												enversService.getAuditEntitiesConfiguration().getRevisionNumberPath()
 										);
 										revType.nullSafeSet( preparedStatement, revisionNumber, index, sessionImplementor );
 
 										// where REVEND is null
 										// 		nothing to bind....
 
-										return sessionImplementor.getTransactionCoordinator()
+										return sessionImplementor
 												.getJdbcCoordinator().getResultSetReturn().executeUpdate( preparedStatement );
 									}
 									finally {
-										sessionImplementor.getTransactionCoordinator().getJdbcCoordinator().release(
+										sessionImplementor.getJdbcCoordinator().getResourceRegistry().release(
 												preparedStatement
 										);
+										sessionImplementor.getJdbcCoordinator().afterStatementExecution();
 									}
 								}
 							}
 					);
 
 					if ( rowCount != 1 && ( !reuseEntityIdentifier || ( getRevisionType( enversService, data ) != RevisionType.ADD ) ) ) {
 						throw new RuntimeException(
 								"Cannot update previous revision for entity " + auditedEntityName + " and id " + id
 						);
 					}
 				}
 			});
 		}
 		sessionCacheCleaner.scheduleAuditDataRemoval( session, data );
 	}
 
 	private Queryable getQueryable(String entityName, SessionImplementor sessionImplementor) {
 		return (Queryable) sessionImplementor.getFactory().getEntityPersister( entityName );
 	}
 
 	@Override
 	@SuppressWarnings({"unchecked"})
 	public void performCollectionChange(
 			Session session,
 			String entityName,
 			String propertyName,
 			EnversService enversService,
 			PersistentCollectionChangeData persistentCollectionChangeData, Object revision) {
 		final QueryBuilder qb = new QueryBuilder( persistentCollectionChangeData.getEntityName(), MIDDLE_ENTITY_ALIAS );
 
 		final String originalIdPropName = enversService.getAuditEntitiesConfiguration().getOriginalIdPropName();
 		final Map<String, Object> originalId = (Map<String, Object>) persistentCollectionChangeData.getData().get(
 				originalIdPropName
 		);
 		final String revisionFieldName = enversService.getAuditEntitiesConfiguration().getRevisionFieldName();
 		final String revisionTypePropName = enversService.getAuditEntitiesConfiguration().getRevisionTypePropName();
 
 		// Adding a parameter for each id component, except the rev number and type.
 		for ( Map.Entry<String, Object> originalIdEntry : originalId.entrySet() ) {
 			if ( !revisionFieldName.equals( originalIdEntry.getKey() ) && !revisionTypePropName.equals( originalIdEntry.getKey() ) ) {
 				qb.getRootParameters().addWhereWithParam(
 						originalIdPropName + "." + originalIdEntry.getKey(),
 						true, "=", originalIdEntry.getValue()
 				);
 			}
 		}
 
 		final SessionFactoryImplementor sessionFactory = ((SessionImplementor) session).getFactory();
 		final Type propertyType = sessionFactory.getEntityPersister( entityName ).getPropertyType( propertyName );
 		if ( propertyType.isCollectionType() ) {
 			CollectionType collectionPropertyType = (CollectionType) propertyType;
 			// Handling collection of components.
 			if ( collectionPropertyType.getElementType( sessionFactory ) instanceof ComponentType ) {
 				// Adding restrictions to compare data outside of primary key.
 				for ( Map.Entry<String, Object> dataEntry : persistentCollectionChangeData.getData().entrySet() ) {
 					if ( !originalIdPropName.equals( dataEntry.getKey() ) ) {
 						qb.getRootParameters().addWhereWithParam( dataEntry.getKey(), true, "=", dataEntry.getValue() );
 					}
 				}
 			}
 		}
 
 		addEndRevisionNullRestriction( enversService, qb.getRootParameters() );
 
 		final List<Object> l = qb.toQuery( session ).setLockOptions( LockOptions.UPGRADE ).list();
 
 		// Update the last revision if one exists.
 		// HHH-5967: with collections, the same element can be added and removed multiple times. So even if it's an
 		// ADD, we may need to update the last revision.
 		if ( l.size() > 0 ) {
 			updateLastRevision(
 					session, enversService, l, originalId, persistentCollectionChangeData.getEntityName(), revision
 			);
 		}
 
 		// Save the audit data
 		session.save( persistentCollectionChangeData.getEntityName(), persistentCollectionChangeData.getData() );
 		sessionCacheCleaner.scheduleAuditDataRemoval( session, persistentCollectionChangeData.getData() );
 	}
 
 	private void addEndRevisionNullRestriction(EnversService enversService, Parameters rootParameters) {
 		rootParameters.addWhere( enversService.getAuditEntitiesConfiguration().getRevisionEndFieldName(), true, "is", "null", false );
 	}
 
 	public void addEntityAtRevisionRestriction(
 			GlobalConfiguration globalCfg, QueryBuilder rootQueryBuilder,
 			Parameters parameters, String revisionProperty, String revisionEndProperty, boolean addAlias,
 			MiddleIdData idData, String revisionPropertyPath, String originalIdPropertyName,
 			String alias1, String alias2, boolean inclusive) {
 		addRevisionRestriction( parameters, revisionProperty, revisionEndProperty, addAlias, inclusive );
 	}
 
 	public void addAssociationAtRevisionRestriction(
 			QueryBuilder rootQueryBuilder, Parameters parameters, String revisionProperty,
 			String revisionEndProperty, boolean addAlias, MiddleIdData referencingIdData,
 			String versionsMiddleEntityName, String eeOriginalIdPropertyPath, String revisionPropertyPath,
 			String originalIdPropertyName, String alias1, boolean inclusive, MiddleComponentData... componentDatas) {
 		addRevisionRestriction( parameters, revisionProperty, revisionEndProperty, addAlias, inclusive );
 	}
 
 	public void setRevisionTimestampGetter(Getter revisionTimestampGetter) {
 		this.revisionTimestampGetter = revisionTimestampGetter;
 	}
 
 	private void addRevisionRestriction(
 			Parameters rootParameters, String revisionProperty, String revisionEndProperty,
 			boolean addAlias, boolean inclusive) {
 		// e.revision <= _revision and (e.endRevision > _revision or e.endRevision is null)
 		Parameters subParm = rootParameters.addSubParameters( "or" );
 		rootParameters.addWhereWithNamedParam( revisionProperty, addAlias, inclusive ? "<=" : "<", REVISION_PARAMETER );
 		subParm.addWhereWithNamedParam(
 				revisionEndProperty + ".id", addAlias, inclusive ? ">" : ">=", REVISION_PARAMETER
 		);
 		subParm.addWhere( revisionEndProperty, addAlias, "is", "null", false );
 	}
 
 	@SuppressWarnings({"unchecked"})
 	private RevisionType getRevisionType(EnversService enversService, Object data) {
 		return (RevisionType) ((Map<String, Object>) data).get( enversService.getAuditEntitiesConfiguration().getRevisionTypePropName() );
 	}
 
 	@SuppressWarnings({"unchecked"})
 	private void updateLastRevision(
 			Session session,
 			EnversService enversService,
 			List<Object> l,
 			Object id,
 			String auditedEntityName,
 			Object revision) {
 		// There should be one entry
 		if ( l.size() == 1 ) {
 			// Setting the end revision to be the current rev
 			Object previousData = l.get( 0 );
 			String revisionEndFieldName = enversService.getAuditEntitiesConfiguration().getRevisionEndFieldName();
 			((Map<String, Object>) previousData).put( revisionEndFieldName, revision );
 
 			if ( enversService.getAuditEntitiesConfiguration().isRevisionEndTimestampEnabled() ) {
 				// Determine the value of the revision property annotated with @RevisionTimestamp
 				String revEndTimestampFieldName = enversService.getAuditEntitiesConfiguration().getRevisionEndTimestampFieldName();
 				Object revEndTimestampObj = this.revisionTimestampGetter.get( revision );
 				Date revisionEndTimestamp = convertRevEndTimestampToDate( revEndTimestampObj );
 
 				// Setting the end revision timestamp
 				((Map<String, Object>) previousData).put( revEndTimestampFieldName, revisionEndTimestamp );
 			}
 
 			// Saving the previous version
 			session.save( auditedEntityName, previousData );
 			sessionCacheCleaner.scheduleAuditDataRemoval( session, previousData );
 		}
 		else {
 			throw new RuntimeException( "Cannot find previous revision for entity " + auditedEntityName + " and id " + id );
 		}
 	}
 
 	private Date convertRevEndTimestampToDate(Object revEndTimestampObj) {
 		// convert to a java.util.Date
 		if ( revEndTimestampObj instanceof Date ) {
 			return (Date) revEndTimestampObj;
 		}
 		return new Date( (Long) revEndTimestampObj );
 	}
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/SingleNodeTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/SingleNodeTestCase.java
index 46312de9b1..8c048cf096 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/SingleNodeTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/SingleNodeTestCase.java
@@ -1,170 +1,171 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.functional;
 
-import java.util.Map;
 import javax.transaction.Status;
 import javax.transaction.TransactionManager;
+import java.util.Map;
+
+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
 
 import org.hibernate.cache.infinispan.InfinispanRegionFactory;
 import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
-import org.hibernate.engine.transaction.internal.jta.CMTTransactionFactory;
 import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
-import org.hibernate.engine.transaction.spi.TransactionFactory;
+import org.hibernate.resource.transaction.TransactionCoordinatorBuilder;
+import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorBuilderImpl;
 
-import org.hibernate.testing.junit4.BaseNonConfigCoreFunctionalTestCase;
-import org.hibernate.test.cache.infinispan.tm.JtaPlatformImpl;
 import org.junit.Before;
 
-import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;
-import org.infinispan.manager.EmbeddedCacheManager;
-import org.infinispan.test.fwk.TestCacheManagerFactory;
-import org.infinispan.util.logging.Log;
-import org.infinispan.util.logging.LogFactory;
+import org.hibernate.testing.junit4.BaseNonConfigCoreFunctionalTestCase;
+import org.hibernate.test.cache.infinispan.tm.JtaPlatformImpl;
 
 /**
  * @author Galder Zamarreo
  * @since 3.5
  */
 public abstract class SingleNodeTestCase extends BaseNonConfigCoreFunctionalTestCase {
 	private static final Log log = LogFactory.getLog( SingleNodeTestCase.class );
 	protected TransactionManager tm;
 
 	@Before
 	public void prepare() {
 		tm = getTransactionManager();
 	}
 
 	protected TransactionManager getTransactionManager() {
 		try {
 			Class<? extends JtaPlatform> jtaPlatformClass = getJtaPlatform();
 			if ( jtaPlatformClass == null ) {
 				return null;
 			}
 			else {
 				return jtaPlatformClass.newInstance().retrieveTransactionManager();
 			}
 		}
 		catch (Exception e) {
 			log.error( "Error", e );
 			throw new RuntimeException( e );
 		}
 	}
 
 	@Override
 	public String[] getMappings() {
 		return new String[] {
 				"cache/infinispan/functional/Item.hbm.xml",
 				"cache/infinispan/functional/Customer.hbm.xml",
 				"cache/infinispan/functional/Contact.hbm.xml"
 		};
 	}
 
 	@Override
 	public String getCacheConcurrencyStrategy() {
 		return "transactional";
 	}
 
 	protected Class<? extends RegionFactory> getCacheRegionFactory() {
 		return TestInfinispanRegionFactory.class;
 	}
 
-	protected Class<? extends TransactionFactory> getTransactionFactoryClass() {
-		return CMTTransactionFactory.class;
+	protected Class<? extends TransactionCoordinatorBuilder> getTransactionCoordinatorBuilder() {
+		return JtaTransactionCoordinatorBuilderImpl.class;
 	}
 
 	protected Class<? extends ConnectionProvider> getConnectionProviderClass() {
 		return org.hibernate.test.cache.infinispan.tm.XaConnectionProvider.class;
 	}
 
 	protected Class<? extends JtaPlatform> getJtaPlatform() {
 		return JtaPlatformImpl.class;
 	}
 
 	protected boolean getUseQueryCache() {
 		return true;
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	protected void addSettings(Map settings) {
 		super.addSettings( settings );
 
 		settings.put( Environment.USE_SECOND_LEVEL_CACHE, "true" );
 		settings.put( Environment.GENERATE_STATISTICS, "true" );
 		settings.put( Environment.USE_QUERY_CACHE, String.valueOf( getUseQueryCache() ) );
 		settings.put( Environment.CACHE_REGION_FACTORY, getCacheRegionFactory().getName() );
 
 		if ( getJtaPlatform() != null ) {
 			settings.put( AvailableSettings.JTA_PLATFORM, getJtaPlatform() );
 		}
-		settings.put( Environment.TRANSACTION_STRATEGY, getTransactionFactoryClass().getName() );
+		settings.put( Environment.TRANSACTION_COORDINATOR_STRATEGY, getTransactionCoordinatorBuilder().getName() );
 		settings.put( Environment.CONNECTION_PROVIDER, getConnectionProviderClass().getName() );
 	}
 
 	protected void beginTx() throws Exception {
 		tm.begin();
 	}
 
 	protected void setRollbackOnlyTx() throws Exception {
 		tm.setRollbackOnly();
 	}
 
 	protected void setRollbackOnlyTx(Exception e) throws Exception {
 		log.error( "Error", e );
 		tm.setRollbackOnly();
 		throw e;
 	}
 
 	protected void setRollbackOnlyTxExpected(Exception e) throws Exception {
 		log.debug( "Expected behaivour", e );
 		tm.setRollbackOnly();
 	}
 
 	protected void commitOrRollbackTx() throws Exception {
 		if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 			tm.commit();
 		}
 		else {
 			tm.rollback();
 		}
 	}
 
    public static class TestInfinispanRegionFactory extends InfinispanRegionFactory {
 
       public TestInfinispanRegionFactory() {
          super(); // For reflection-based instantiation
       }
 
       @Override
       protected EmbeddedCacheManager createCacheManager(ConfigurationBuilderHolder holder) {
          return TestCacheManagerFactory.createClusteredCacheManager(holder);
       }
 
    }
 
 }
\ No newline at end of file
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/bulk/BulkOperationsTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/bulk/BulkOperationsTestCase.java
index 5c67f6ec86..2635b56763 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/bulk/BulkOperationsTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/bulk/BulkOperationsTestCase.java
@@ -1,422 +1,423 @@
 /*
  * JBoss, Home of Professional Open Source.
  * Copyright 2009, Red Hat, Inc. and/or it's affiliates, and individual contributors
  * as indicated by the @author tags. See the copyright.txt file in the
  * distribution for a full listing of individual contributors.
  *
  * This is free software; you can redistribute it and/or modify it
  * under the terms of the GNU Lesser General Public License as
  * published by the Free Software Foundation; either version 2.1 of
  * the License, or (at your option) any later version.
  *
  * This software is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * Lesser General Public License for more details.
  *
  * You should have received a copy of the GNU Lesser General Public
  * License along with this software; if not, write to the Free
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
 package org.hibernate.test.cache.infinispan.functional.bulk;
 
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import javax.transaction.Status;
 import javax.transaction.TransactionManager;
 
 import org.hibernate.FlushMode;
 import org.hibernate.Session;
 import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
-import org.hibernate.engine.transaction.internal.jta.CMTTransactionFactory;
 import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
-import org.hibernate.engine.transaction.spi.TransactionFactory;
+import org.hibernate.resource.transaction.TransactionCoordinatorBuilder;
+import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorBuilderImpl;
 import org.hibernate.stat.SecondLevelCacheStatistics;
 
 import org.hibernate.testing.junit4.BaseNonConfigCoreFunctionalTestCase;
 import org.hibernate.test.cache.infinispan.functional.Contact;
 import org.hibernate.test.cache.infinispan.functional.Customer;
 import org.hibernate.test.cache.infinispan.functional.SingleNodeTestCase;
 import org.hibernate.test.cache.infinispan.tm.JtaPlatformImpl;
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNull;
 
 /**
  * BulkOperationsTestCase.
  *
  * @author Galder Zamarreo
  * @since 3.5
  */
 public class BulkOperationsTestCase extends BaseNonConfigCoreFunctionalTestCase {
 	private TransactionManager tm;
 
 	@Override
 	public String[] getMappings() {
 		return new String[] {
 				"cache/infinispan/functional/Contact.hbm.xml",
 				"cache/infinispan/functional/Customer.hbm.xml"
 		};
 	}
 
 	@Override
 	public String getCacheConcurrencyStrategy() {
 		return "transactional";
 	}
 
 	protected Class<? extends RegionFactory> getCacheRegionFactory() {
 		return SingleNodeTestCase.TestInfinispanRegionFactory.class;
 	}
 
-	protected Class<? extends TransactionFactory> getTransactionFactoryClass() {
-		return CMTTransactionFactory.class;
+
+	protected Class<? extends TransactionCoordinatorBuilder> getTransactionCoordinatorBuilder() {
+		return JtaTransactionCoordinatorBuilderImpl.class;
 	}
 
 	protected Class<? extends ConnectionProvider> getConnectionProviderClass() {
 		return org.hibernate.test.cache.infinispan.tm.XaConnectionProvider.class;
 	}
 
 	protected JtaPlatform getJtaPlatform() {
 		return new JtaPlatformImpl();
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	protected void addSettings(Map settings) {
 		super.addSettings( settings );
 
 		settings.put( Environment.USE_SECOND_LEVEL_CACHE, "true" );
 		settings.put( Environment.USE_QUERY_CACHE, "false" );
 		settings.put( Environment.GENERATE_STATISTICS, "true" );
 		settings.put( Environment.CACHE_REGION_FACTORY, getCacheRegionFactory().getName() );
-		settings.put( Environment.TRANSACTION_STRATEGY, getTransactionFactoryClass().getName() );
+		settings.put( Environment.TRANSACTION_COORDINATOR_STRATEGY, getTransactionCoordinatorBuilder().getName() );
 		settings.put( AvailableSettings.JTA_PLATFORM, getJtaPlatform() );
 		settings.put( Environment.CONNECTION_PROVIDER, getConnectionProviderClass().getName() );
 	}
 
 	@Test
 	public void testBulkOperations() throws Throwable {
 		boolean cleanedUp = false;
 		try {
 			tm = getJtaPlatform().retrieveTransactionManager();
 
 			createContacts();
 
 			List<Integer> rhContacts = getContactsByCustomer( "Red Hat" );
 			assertNotNull( "Red Hat contacts exist", rhContacts );
 			assertEquals( "Created expected number of Red Hat contacts", 10, rhContacts.size() );
 
 			SecondLevelCacheStatistics contactSlcs = sessionFactory()
 					.getStatistics()
 					.getSecondLevelCacheStatistics( Contact.class.getName() );
 			assertEquals( 20, contactSlcs.getElementCountInMemory() );
 
 			assertEquals( "Deleted all Red Hat contacts", 10, deleteContacts() );
 			assertEquals( 0, contactSlcs.getElementCountInMemory() );
 
 			List<Integer> jbContacts = getContactsByCustomer( "JBoss" );
 			assertNotNull( "JBoss contacts exist", jbContacts );
 			assertEquals( "JBoss contacts remain", 10, jbContacts.size() );
 
 			for ( Integer id : rhContacts ) {
 				assertNull( "Red Hat contact " + id + " cannot be retrieved", getContact( id ) );
 			}
 			rhContacts = getContactsByCustomer( "Red Hat" );
 			if ( rhContacts != null ) {
 				assertEquals( "No Red Hat contacts remain", 0, rhContacts.size() );
 			}
 
 			updateContacts( "Kabir", "Updated" );
 			assertEquals( 0, contactSlcs.getElementCountInMemory() );
 			for ( Integer id : jbContacts ) {
 				Contact contact = getContact( id );
 				assertNotNull( "JBoss contact " + id + " exists", contact );
 				String expected = ("Kabir".equals( contact.getName() )) ? "Updated" : "2222";
 				assertEquals( "JBoss contact " + id + " has correct TLF", expected, contact.getTlf() );
 			}
 
 			List<Integer> updated = getContactsByTLF( "Updated" );
 			assertNotNull( "Got updated contacts", updated );
 			assertEquals( "Updated contacts", 5, updated.size() );
 
 			updateContactsWithOneManual( "Kabir", "UpdatedAgain" );
 			assertEquals( contactSlcs.getElementCountInMemory(), 0 );
 			for ( Integer id : jbContacts ) {
 				Contact contact = getContact( id );
 				assertNotNull( "JBoss contact " + id + " exists", contact );
 				String expected = ("Kabir".equals( contact.getName() )) ? "UpdatedAgain" : "2222";
 				assertEquals( "JBoss contact " + id + " has correct TLF", expected, contact.getTlf() );
 			}
 
 			updated = getContactsByTLF( "UpdatedAgain" );
 			assertNotNull( "Got updated contacts", updated );
 			assertEquals( "Updated contacts", 5, updated.size() );
 		}
 		catch (Throwable t) {
 			cleanedUp = true;
 			cleanup( true );
 			throw t;
 		}
 		finally {
 			// cleanup the db so we can run this test multiple times w/o restarting the cluster
 			if ( !cleanedUp ) {
 				cleanup( false );
 			}
 		}
 	}
 
 	public void createContacts() throws Exception {
 		tm.begin();
 		try {
 			for ( int i = 0; i < 10; i++ ) {
 				createCustomer( i );
 			}
 		}
 		catch (Exception e) {
 			tm.setRollbackOnly();
 			throw e;
 		}
 		finally {
 			if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 				tm.commit();
 			}
 			else {
 				tm.rollback();
 			}
 		}
 	}
 
 	public int deleteContacts() throws Exception {
 		String deleteHQL = "delete Contact where customer in ";
 		deleteHQL += " (select customer FROM Customer as customer ";
 		deleteHQL += " where customer.name = :cName)";
 
 		tm.begin();
 		try {
 			Session session = sessionFactory().getCurrentSession();
 			int rowsAffected = session.createQuery( deleteHQL ).setFlushMode( FlushMode.AUTO )
 					.setParameter( "cName", "Red Hat" ).executeUpdate();
 			tm.commit();
 			return rowsAffected;
 		}
 		catch (Exception e) {
 			tm.setRollbackOnly();
 			throw e;
 		}
 		finally {
 			if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 				tm.commit();
 			}
 			else {
 				try {
 					tm.rollback();
 				}
 				catch (Exception ee) {
 					// ignored
 				}
 			}
 		}
 	}
 
 	@SuppressWarnings( {"unchecked"})
 	public List<Integer> getContactsByCustomer(String customerName) throws Exception {
 		String selectHQL = "select contact.id from Contact contact";
 		selectHQL += " where contact.customer.name = :cName";
 
 		tm.begin();
 		try {
 
 			Session session = sessionFactory().getCurrentSession();
 			return session.createQuery( selectHQL )
 					.setFlushMode( FlushMode.AUTO )
 					.setParameter( "cName", customerName )
 					.list();
 		}
 		catch (Exception e) {
 			tm.setRollbackOnly();
 			throw e;
 		}
 		finally {
 			if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 				tm.commit();
 			}
 			else {
 				tm.rollback();
 			}
 		}
 	}
 
 	@SuppressWarnings( {"unchecked"})
 	public List<Integer> getContactsByTLF(String tlf) throws Exception {
 		String selectHQL = "select contact.id from Contact contact";
 		selectHQL += " where contact.tlf = :cTLF";
 
 		tm.begin();
 		try {
 			Session session = sessionFactory().getCurrentSession();
 			return session.createQuery( selectHQL )
 					.setFlushMode( FlushMode.AUTO )
 					.setParameter( "cTLF", tlf )
 					.list();
 		}
 		catch (Exception e) {
 			tm.setRollbackOnly();
 			throw e;
 		}
 		finally {
 			if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 				tm.commit();
 			}
 			else {
 				tm.rollback();
 			}
 		}
 	}
 
 	public int updateContacts(String name, String newTLF) throws Exception {
 		String updateHQL = "update Contact set tlf = :cNewTLF where name = :cName";
 		tm.begin();
 		try {
 			Session session = sessionFactory().getCurrentSession();
 			return session.createQuery( updateHQL )
 					.setFlushMode( FlushMode.AUTO )
 					.setParameter( "cNewTLF", newTLF )
 					.setParameter( "cName", name )
 					.executeUpdate();
 		}
 		catch (Exception e) {
 			tm.setRollbackOnly();
 			throw e;
 		}
 		finally {
 			if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 				tm.commit();
 			}
 			else {
 				tm.rollback();
 			}
 		}
 	}
 
 	public int updateContactsWithOneManual(String name, String newTLF) throws Exception {
 		String queryHQL = "from Contact c where c.name = :cName";
 		String updateHQL = "update Contact set tlf = :cNewTLF where name = :cName";
 		tm.begin();
 		try {
 			Session session = sessionFactory().getCurrentSession();
 			@SuppressWarnings("unchecked")
 			List<Contact> list = session.createQuery( queryHQL ).setParameter( "cName", name ).list();
 			list.get( 0 ).setTlf( newTLF );
 			return session.createQuery( updateHQL )
 					.setFlushMode( FlushMode.AUTO )
 					.setParameter( "cNewTLF", newTLF )
 					.setParameter( "cName", name )
 					.executeUpdate();
 		}
 		catch (Exception e) {
 			tm.setRollbackOnly();
 			throw e;
 		}
 		finally {
 			if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 				tm.commit();
 			}
 			else {
 				tm.rollback();
 			}
 		}
 	}
 
 	public Contact getContact(Integer id) throws Exception {
 		tm.begin();
 		try {
 			Session session = sessionFactory().getCurrentSession();
 			return (Contact) session.get( Contact.class, id );
 		}
 		catch (Exception e) {
 			tm.setRollbackOnly();
 			throw e;
 		}
 		finally {
 			if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 				tm.commit();
 			}
 			else {
 				tm.rollback();
 			}
 		}
 	}
 
 	public void cleanup(boolean ignore) throws Exception {
 		String deleteContactHQL = "delete from Contact";
 		String deleteCustomerHQL = "delete from Customer";
 		tm.begin();
 		try {
 			Session session = sessionFactory().getCurrentSession();
 			session.createQuery( deleteContactHQL ).setFlushMode( FlushMode.AUTO ).executeUpdate();
 			session.createQuery( deleteCustomerHQL ).setFlushMode( FlushMode.AUTO ).executeUpdate();
 		}
 		catch (Exception e) {
 			tm.setRollbackOnly();
 			throw e;
 		}
 		finally {
 			if ( tm.getStatus() == Status.STATUS_ACTIVE ) {
 				tm.commit();
 			}
 			else {
 				if ( !ignore ) {
 					try {
 						tm.rollback();
 					}
 					catch (Exception ee) {
 						// ignored
 					}
 				}
 			}
 		}
 	}
 
 	private Customer createCustomer(int id) throws Exception {
 		System.out.println( "CREATE CUSTOMER " + id );
 		try {
 			Customer customer = new Customer();
 			customer.setName( (id % 2 == 0) ? "JBoss" : "Red Hat" );
 			Set<Contact> contacts = new HashSet<Contact>();
 
 			Contact kabir = new Contact();
 			kabir.setCustomer( customer );
 			kabir.setName( "Kabir" );
 			kabir.setTlf( "1111" );
 			contacts.add( kabir );
 
 			Contact bill = new Contact();
 			bill.setCustomer( customer );
 			bill.setName( "Bill" );
 			bill.setTlf( "2222" );
 			contacts.add( bill );
 
 			customer.setContacts( contacts );
 
 			Session s = openSession();
 			s.getTransaction().begin();
 			s.persist( customer );
 			s.getTransaction().commit();
 			s.close();
 
 			return customer;
 		}
 		finally {
 			System.out.println( "CREATE CUSTOMER " + id + " -  END" );
 		}
 	}
 
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/DualNodeTestCase.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/DualNodeTestCase.java
index 68beba1de3..a64e501e6d 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/DualNodeTestCase.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/functional/cluster/DualNodeTestCase.java
@@ -1,196 +1,197 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.functional.cluster;
 
 import java.util.Map;
 
 import org.hibernate.boot.Metadata;
 import org.hibernate.boot.MetadataSources;
 import org.hibernate.boot.registry.StandardServiceRegistry;
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
-import org.hibernate.engine.transaction.internal.jta.CMTTransactionFactory;
+import org.hibernate.resource.transaction.TransactionCoordinatorBuilder;
+import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorBuilderImpl;
 
 import org.hibernate.testing.junit4.BaseNonConfigCoreFunctionalTestCase;
 import org.junit.After;
 import org.junit.Before;
 
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 /**
  * @author Galder Zamarreo
  * @since 3.5
  */
 public abstract class DualNodeTestCase extends BaseNonConfigCoreFunctionalTestCase {
 	private static final Log log = LogFactory.getLog( DualNodeTestCase.class );
 
 	public static final String NODE_ID_PROP = "hibernate.test.cluster.node.id";
 	public static final String NODE_ID_FIELD = "nodeId";
 	public static final String LOCAL = "local";
 	public static final String REMOTE = "remote";
 
 	private SecondNodeEnvironment secondNodeEnvironment;
 
 	@Override
 	public String[] getMappings() {
 		return new String[] {
 				"cache/infinispan/functional/Contact.hbm.xml", "cache/infinispan/functional/Customer.hbm.xml"
 		};
 	}
 
 	@Override
 	public String getCacheConcurrencyStrategy() {
 		return "transactional";
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	protected void addSettings(Map settings) {
 		super.addSettings( settings );
 
 		applyStandardSettings( settings );
 
 		settings.put( NODE_ID_PROP, LOCAL );
 		settings.put( NODE_ID_FIELD, LOCAL );
 	}
 
 	@Override
 	protected void cleanupTest() throws Exception {
 		cleanupTransactionManagement();
 	}
 
 	protected void cleanupTransactionManagement() {
 		DualNodeJtaTransactionManagerImpl.cleanupTransactions();
 		DualNodeJtaTransactionManagerImpl.cleanupTransactionManagers();
 	}
 
 	@Before
 	public void prepare() throws Exception {
 		secondNodeEnvironment = new SecondNodeEnvironment();
 	}
 
 	@After
 	public void unPrepare() {
 		if ( secondNodeEnvironment != null ) {
 			secondNodeEnvironment.shutDown();
 		}
 	}
 
 	protected SecondNodeEnvironment secondNodeEnvironment() {
 		return secondNodeEnvironment;
 	}
 
 	protected Class getCacheRegionFactory() {
 		return ClusterAwareRegionFactory.class;
 	}
 
 	protected Class getConnectionProviderClass() {
 		return DualNodeConnectionProviderImpl.class;
 	}
 
 	protected Class getJtaPlatformClass() {
 		return DualNodeJtaPlatformImpl.class;
 	}
 
-	protected Class getTransactionFactoryClass() {
-		return CMTTransactionFactory.class;
+	protected Class<? extends TransactionCoordinatorBuilder> getTransactionCoordinatorBuilder() {
+		return JtaTransactionCoordinatorBuilderImpl.class;
 	}
 
 	protected void sleep(long ms) {
 		try {
 			Thread.sleep( ms );
 		}
 		catch (InterruptedException e) {
 			log.warn( "Interrupted during sleep", e );
 		}
 	}
 
 	protected boolean getUseQueryCache() {
 		return true;
 	}
 
 	protected void configureSecondNode(StandardServiceRegistryBuilder ssrb) {
 	}
 
 	@SuppressWarnings("unchecked")
 	protected void applyStandardSettings(Map settings) {
 		settings.put( Environment.CONNECTION_PROVIDER, getConnectionProviderClass().getName() );
 		settings.put( AvailableSettings.JTA_PLATFORM, getJtaPlatformClass().getName() );
-		settings.put( Environment.TRANSACTION_STRATEGY, getTransactionFactoryClass().getName() );
+		settings.put( Environment.TRANSACTION_COORDINATOR_STRATEGY, getTransactionCoordinatorBuilder().getName() );
 		settings.put( Environment.CACHE_REGION_FACTORY, getCacheRegionFactory().getName() );
 		settings.put( Environment.USE_QUERY_CACHE, String.valueOf( getUseQueryCache() ) );
 	}
 
 	public class SecondNodeEnvironment {
 		private StandardServiceRegistry serviceRegistry;
 		private SessionFactoryImplementor sessionFactory;
 
 		public SecondNodeEnvironment() {
 			StandardServiceRegistryBuilder ssrb = constructStandardServiceRegistryBuilder();
 			applyStandardSettings( ssrb.getSettings() );
 			ssrb.applySetting( NODE_ID_PROP, REMOTE );
 			ssrb.applySetting( NODE_ID_FIELD, REMOTE );
 			configureSecondNode( ssrb );
 
 			serviceRegistry = ssrb.build();
 
 			MetadataSources metadataSources = new MetadataSources( serviceRegistry );
 			applyMetadataSources( metadataSources );
 
 			Metadata metadata = metadataSources.buildMetadata();
 			applyCacheSettings( metadata );
 			afterMetadataBuilt( metadata );
 
 			sessionFactory = (SessionFactoryImplementor) metadata.buildSessionFactory();
 		}
 
 		public StandardServiceRegistry getServiceRegistry() {
 			return serviceRegistry;
 		}
 
 		public SessionFactoryImplementor getSessionFactory() {
 			return sessionFactory;
 		}
 
 		public void shutDown() {
 			if ( sessionFactory != null ) {
 				try {
 					sessionFactory.close();
 				}
 				catch (Exception ignore) {
 				}
 			}
 			if ( serviceRegistry != null ) {
 				try {
 					StandardServiceRegistryBuilder.destroy( serviceRegistry );
 				}
 				catch (Exception ignore) {
 				}
 			}
 		}
 	}
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/tm/JBossStandaloneJtaExampleTest.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/tm/JBossStandaloneJtaExampleTest.java
index de7cf0049a..8dafd40b7a 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/tm/JBossStandaloneJtaExampleTest.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/tm/JBossStandaloneJtaExampleTest.java
@@ -1,284 +1,285 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors. All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.tm;
 
 import java.util.Properties;
 import javax.naming.Context;
 import javax.naming.InitialContext;
 import javax.naming.Name;
 import javax.naming.NameNotFoundException;
 import javax.naming.Reference;
 import javax.naming.StringRefAddr;
 import javax.transaction.Status;
 import javax.transaction.UserTransaction;
 
 import org.hibernate.Session;
 import org.hibernate.SessionFactory;
 import org.hibernate.boot.Metadata;
 import org.hibernate.boot.MetadataSources;
 import org.hibernate.boot.registry.StandardServiceRegistry;
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.transaction.jta.platform.internal.JBossStandAloneJtaPlatform;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.RootClass;
+import org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorBuilderImpl;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.stat.Statistics;
 
 import org.hibernate.testing.ServiceRegistryBuilder;
 import org.hibernate.testing.jta.JtaAwareConnectionProviderImpl;
 import org.hibernate.test.cache.infinispan.functional.Item;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 
 import org.infinispan.configuration.cache.ConfigurationBuilder;
 import org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 import org.jboss.util.naming.NonSerializableFactory;
 
 import org.jnp.interfaces.NamingContext;
 import org.jnp.server.Main;
 import org.jnp.server.NamingServer;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNull;
 
 /**
  * This is an example test based on http://community.jboss.org/docs/DOC-14617 that shows how to interact with
  * Hibernate configured with Infinispan second level cache provider using JTA transactions.
  *
  * In this test, an XADataSource wrapper is in use where we have associated our transaction manager to it so that
  * commits/rollbacks are propagated to the database as well.
  *
  * @author Galder Zamarreo
  * @since 3.5
  */
 public class JBossStandaloneJtaExampleTest {
    private static final Log log = LogFactory.getLog(JBossStandaloneJtaExampleTest.class);
    private static final JBossStandaloneJTAManagerLookup lookup = new JBossStandaloneJTAManagerLookup();
    Context ctx;
    Main jndiServer;
    private ServiceRegistry serviceRegistry;
 
    @Before
    public void setUp() throws Exception {
       jndiServer = startJndiServer();
       ctx = createJndiContext();
       // Inject configuration to initialise transaction manager from config classloader
       lookup.init(new ConfigurationBuilder().build());
       bindTransactionManager();
       bindUserTransaction();
    }
 
    @After
    public void tearDown() throws Exception {
       try {
          unbind("UserTransaction", ctx);
          unbind("java:/TransactionManager", ctx);
          ctx.close();
          jndiServer.stop();
 	  }
 	  finally {
 		  if ( serviceRegistry != null ) {
 			  ServiceRegistryBuilder.destroy( serviceRegistry );
 		  }
 	  }
    }
    @Test
    public void testPersistAndLoadUnderJta() throws Exception {
       Item item;
       SessionFactory sessionFactory = buildSessionFactory();
       try {
          UserTransaction ut = (UserTransaction) ctx.lookup("UserTransaction");
          ut.begin();
          try {
             Session session = sessionFactory.openSession();
             session.getTransaction().begin();
             item = new Item("anItem", "An item owned by someone");
             session.persist(item);
             session.getTransaction().commit();
             session.close();
          } catch(Exception e) {
             ut.setRollbackOnly();
             throw e;
          } finally {
             if (ut.getStatus() == Status.STATUS_ACTIVE)
                ut.commit();
             else
                ut.rollback();
          }
 
          ut = (UserTransaction) ctx.lookup("UserTransaction");
          ut.begin();
          try {
             Session session = sessionFactory.openSession();
             session.getTransaction().begin();
             Item found = (Item) session.load(Item.class, item.getId());
             Statistics stats = session.getSessionFactory().getStatistics();
             log.info(stats.toString());
             assertEquals(item.getDescription(), found.getDescription());
             assertEquals(0, stats.getSecondLevelCacheMissCount());
             assertEquals(1, stats.getSecondLevelCacheHitCount());
             session.delete(found);
             session.getTransaction().commit();
             session.close();
          } catch(Exception e) {
             ut.setRollbackOnly();
             throw e;
          } finally {
             if (ut.getStatus() == Status.STATUS_ACTIVE)
                ut.commit();
             else
                ut.rollback();
          }
 
          ut = (UserTransaction) ctx.lookup("UserTransaction");
          ut.begin();
          try {
             Session session = sessionFactory.openSession();
             session.getTransaction().begin();
             assertNull(session.get(Item.class, item.getId()));
             session.getTransaction().commit();
             session.close();
          } catch(Exception e) {
             ut.setRollbackOnly();
             throw e;
          } finally {
             if (ut.getStatus() == Status.STATUS_ACTIVE)
                ut.commit();
             else
                ut.rollback();
          }
       } finally {
          if (sessionFactory != null)
             sessionFactory.close();
       }
 
    }
 
    private Main startJndiServer() throws Exception {
       // Create an in-memory jndi
       NamingServer namingServer = new NamingServer();
       NamingContext.setLocal(namingServer);
       Main namingMain = new Main();
       namingMain.setInstallGlobalService(true);
       namingMain.setPort( -1 );
       namingMain.start();
       return namingMain;
    }
 
    private Context createJndiContext() throws Exception {
       Properties props = new Properties();
       props.put( Context.INITIAL_CONTEXT_FACTORY, "org.jnp.interfaces.NamingContextFactory" );
       props.put("java.naming.factory.url.pkgs", "org.jboss.naming:org.jnp.interfaces");
       return new InitialContext(props);
    }
 
    private void bindTransactionManager() throws Exception {
       // as JBossTransactionManagerLookup extends JNDITransactionManagerLookup we must also register the TransactionManager
       bind("java:/TransactionManager", lookup.getTransactionManager(), lookup.getTransactionManager().getClass(), ctx);
    }
 
    private void bindUserTransaction() throws Exception {
       // also the UserTransaction must be registered on jndi: org.hibernate.engine.transaction.internal.jta.JtaTransactionFactory#getUserTransaction() requires this
       bind( "UserTransaction", lookup.getUserTransaction(), lookup.getUserTransaction().getClass(), ctx );
    }
 
    /**
     * Helper method that binds the a non serializable object to the JNDI tree.
     *
     * @param jndiName  Name under which the object must be bound
     * @param who       Object to bind in JNDI
     * @param classType Class type under which should appear the bound object
     * @param ctx       Naming context under which we bind the object
     * @throws Exception Thrown if a naming exception occurs during binding
     */
    private void bind(String jndiName, Object who, Class classType, Context ctx) throws Exception {
       // Ah ! This service isn't serializable, so we use a helper class
       NonSerializableFactory.bind(jndiName, who);
       Name n = ctx.getNameParser("").parse(jndiName);
       while (n.size() > 1) {
          String ctxName = n.get(0);
          try {
             ctx = (Context) ctx.lookup(ctxName);
          } catch (NameNotFoundException e) {
             System.out.println("Creating subcontext:" + ctxName);
             ctx = ctx.createSubcontext(ctxName);
          }
          n = n.getSuffix(1);
       }
 
       // The helper class NonSerializableFactory uses address type nns, we go on to
       // use the helper class to bind the service object in JNDI
       StringRefAddr addr = new StringRefAddr("nns", jndiName);
       Reference ref = new Reference(classType.getName(), addr, NonSerializableFactory.class.getName(), null);
       ctx.rebind(n.get(0), ref);
    }
 
    private void unbind(String jndiName, Context ctx) throws Exception {
       NonSerializableFactory.unbind(jndiName);
       ctx.unbind(jndiName);
    }
 
    private SessionFactory buildSessionFactory() {
       // Extra options located in src/test/resources/hibernate.properties
       StandardServiceRegistryBuilder ssrb = new StandardServiceRegistryBuilder()
               .applySetting( Environment.DIALECT, "HSQL" )
               .applySetting( Environment.HBM2DDL_AUTO, "create-drop" )
               .applySetting( Environment.CONNECTION_PROVIDER, JtaAwareConnectionProviderImpl.class.getName() )
               .applySetting( Environment.JNDI_CLASS, "org.jnp.interfaces.NamingContextFactory" )
-              .applySetting( Environment.TRANSACTION_STRATEGY, "jta" )
+              .applySetting( Environment.TRANSACTION_COORDINATOR_STRATEGY, JtaTransactionCoordinatorBuilderImpl.class.getName() )
               .applySetting( Environment.CURRENT_SESSION_CONTEXT_CLASS, "jta" )
               .applySetting( Environment.RELEASE_CONNECTIONS, "auto" )
               .applySetting( Environment.USE_SECOND_LEVEL_CACHE, "true" )
               .applySetting( Environment.USE_QUERY_CACHE, "true" )
               .applySetting( AvailableSettings.JTA_PLATFORM, new JBossStandAloneJtaPlatform() )
               .applySetting(
                       Environment.CACHE_REGION_FACTORY,
                       "org.hibernate.test.cache.infinispan.functional.SingleNodeTestCase$TestInfinispanRegionFactory"
               );
 
       StandardServiceRegistry serviceRegistry = ssrb.build();
 
       MetadataSources metadataSources = new MetadataSources( serviceRegistry );
       metadataSources.addResource( "org/hibernate/test/cache/infinispan/functional/Item.hbm.xml" );
 
       Metadata metadata = metadataSources.buildMetadata();
       for ( PersistentClass entityBinding : metadata.getEntityBindings() ) {
          if ( entityBinding instanceof RootClass ) {
             ( (RootClass) entityBinding ).setCacheConcurrencyStrategy( "transactional" );
          }
       }
       for ( Collection collectionBinding : metadata.getCollectionBindings() ) {
          collectionBinding.setCacheConcurrencyStrategy( "transactional" );
       }
 
       return metadata.buildSessionFactory();
    }
 }
diff --git a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/tm/JtaPlatformImpl.java b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/tm/JtaPlatformImpl.java
index 20e0674c09..0911384c5d 100644
--- a/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/tm/JtaPlatformImpl.java
+++ b/hibernate-infinispan/src/test/java/org/hibernate/test/cache/infinispan/tm/JtaPlatformImpl.java
@@ -1,74 +1,74 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.test.cache.infinispan.tm;
 
 import javax.transaction.Synchronization;
 import javax.transaction.SystemException;
 import javax.transaction.Transaction;
 import javax.transaction.TransactionManager;
 import javax.transaction.UserTransaction;
 
 import org.hibernate.TransactionException;
 import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
 import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
 
 /**
  * @author Steve Ebersole
  */
 public class JtaPlatformImpl implements JtaPlatform {
 	@Override
-	public TransactionManager retrieveTransactionManager() {
+	public TransactionManager retrieveTransactionManager(){
 		return XaTransactionManagerImpl.getInstance();
 	}
 
 	@Override
 	public UserTransaction retrieveUserTransaction() {
 		throw new TransactionException( "UserTransaction not used in these tests" );
 	}
 
 	@Override
 	public Object getTransactionIdentifier(Transaction transaction) {
 		return transaction;
 	}
 
 	@Override
 	public boolean canRegisterSynchronization() {
 		return JtaStatusHelper.isActive( XaTransactionManagerImpl.getInstance() );
 	}
 
 	@Override
 	public void registerSynchronization(Synchronization synchronization) {
 		try {
 			XaTransactionManagerImpl.getInstance().getTransaction().registerSynchronization( synchronization );
 		}
 		catch (Exception e) {
 			throw new TransactionException( "Could not obtain transaction from TM" );
 		}
 	}
 
 	@Override
 	public int getCurrentStatus() throws SystemException {
 		return JtaStatusHelper.getStatus( XaTransactionManagerImpl.getInstance() );
 	}
 }
