diff --git a/hibernate-core/src/main/java/org/hibernate/action/internal/DelayedPostInsertIdentifier.java b/hibernate-core/src/main/java/org/hibernate/action/internal/DelayedPostInsertIdentifier.java
index bc0bce4be4..8fc69079ed 100644
--- a/hibernate-core/src/main/java/org/hibernate/action/internal/DelayedPostInsertIdentifier.java
+++ b/hibernate-core/src/main/java/org/hibernate/action/internal/DelayedPostInsertIdentifier.java
@@ -1,100 +1,99 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.action.internal;
 
 import java.io.Serializable;
 import java.util.concurrent.atomic.AtomicLong;
 
 /**
  * Acts as a stand-in for an entity identifier which is supposed to be
  * generated on insert (like an IDENTITY column) where the insert needed to
  * be delayed because we were outside a transaction when the persist
  * occurred (save currently still performs the insert).
  * <p/>
  * The stand-in is only used within the {@link org.hibernate.engine.spi.PersistenceContext}
  * in order to distinguish one instance from another; it is never injected into
  * the entity instance or returned to the client...
  *
  * @author Steve Ebersole
  * @author Sanne Grinovero
  */
 public class DelayedPostInsertIdentifier implements Serializable, Comparable<DelayedPostInsertIdentifier> {
-
-	private static final AtomicLong sequence = new AtomicLong( 0 );
+	private static final AtomicLong SEQUENCE = new AtomicLong( 0 );
 
 	private final long identifier;
 
 	/**
 	 * Constructs a DelayedPostInsertIdentifier
 	 */
 	public DelayedPostInsertIdentifier() {
-		long value = sequence.incrementAndGet();
+		long value = SEQUENCE.incrementAndGet();
 		if ( value < 0 ) {
-			synchronized ( sequence ) {
-				value = sequence.incrementAndGet();
+			synchronized (SEQUENCE) {
+				value = SEQUENCE.incrementAndGet();
 				if ( value < 0 ) {
-					sequence.set( 0 );
+					SEQUENCE.set( 0 );
 					value = 0;
 				}
 			}
 		}
 		this.identifier = value;
 	}
 
 	@Override
 	public boolean equals(Object o) {
 		if ( this == o ) {
 			return true;
 		}
 		if ( o == null || getClass() != o.getClass() ) {
 			return false;
 		}
 		final DelayedPostInsertIdentifier that = (DelayedPostInsertIdentifier) o;
 		return identifier == that.identifier;
 	}
 
 	@Override
 	public int hashCode() {
 		return (int) ( identifier ^ ( identifier >>> 32 ) );
 	}
 
 	@Override
 	public String toString() {
 		return "<delayed:" + identifier + ">";
 
 	}
 
 	@Override
 	public int compareTo(DelayedPostInsertIdentifier that) {
 		if ( this.identifier < that.identifier ) {
 			return -1;
 		}
 		else if ( this.identifier > that.identifier ) {
 			return 1;
 		}
 		else {
 			return 0;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/bytecode/enhance/spi/CompositeOwnerTracker.java b/hibernate-core/src/main/java/org/hibernate/bytecode/enhance/spi/CompositeOwnerTracker.java
index f52c6cc64d..de1f0393ca 100644
--- a/hibernate-core/src/main/java/org/hibernate/bytecode/enhance/spi/CompositeOwnerTracker.java
+++ b/hibernate-core/src/main/java/org/hibernate/bytecode/enhance/spi/CompositeOwnerTracker.java
@@ -1,85 +1,85 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.bytecode.enhance.spi;
 
 import org.hibernate.engine.spi.CompositeOwner;
 
 /**
  * small low memory class to keep references to composite owners
  *
  * @author <a href="mailto:stale.pedersen@jboss.org">St√•le W. Pedersen</a>
  */
 public class CompositeOwnerTracker {
 
     private String[] names;
     private CompositeOwner[] owners;
-    private int size = 0;
+    private int size;
 
     public CompositeOwnerTracker() {
         names = new String[1];
         owners = new CompositeOwner[1];
     }
 
     public void add(String name, CompositeOwner owner) {
         for(int i=0; i<size;i++) {
             if(names[i].equals(name)) {
                 owners[i] = owner;
                 return;
             }
         }
         if ( size >= names.length) {
             String[] tmpNames = new String[size+1];
             System.arraycopy(names, 0, tmpNames, 0, size);
             names = tmpNames;
             CompositeOwner[] tmpOwners = new CompositeOwner[size+1];
             System.arraycopy(owners, 0, tmpOwners, 0, size);
             owners = tmpOwners;
         }
         names[size] = name;
         owners[size] = owner;
         size++;
     }
 
     public void callOwner(String fieldName) {
         for(int i=0; i < size;i++) {
             owners[i].$$_hibernate_trackChange(names[i]+fieldName);
         }
     }
 
     public void removeOwner(String name) {
         for(int i=0; i<size;i++) {
             if(names[i].equals(name)) {
                 if(i < size) {
                     for(int j=i; j < size-1;j++) {
                         names[j] = names[j+1];
                         owners[j] = owners[j+1];
                     }
                     names[size-1] = null;
                     owners[size-1] = null;
                     size--;
                 }
             }
         }
     }
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/internal/CacheHelper.java b/hibernate-core/src/main/java/org/hibernate/engine/internal/CacheHelper.java
index cce55f0337..175a72bb00 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/internal/CacheHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/internal/CacheHelper.java
@@ -1,67 +1,69 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.internal;
 
 import java.io.Serializable;
 
 import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.cache.spi.NaturalIdCacheKey;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.cache.spi.access.RegionAccessStrategy;
 import org.hibernate.engine.spi.SessionImplementor;
 
 /**
  * @author Steve Ebersole
  */
-public class CacheHelper {
+public final class CacheHelper {
+	private CacheHelper() {
+	}
 
 	public static Serializable fromSharedCache(
 			SessionImplementor session,
 			NaturalIdCacheKey cacheKey,
 			NaturalIdRegionAccessStrategy cacheAccessStrategy) {
 		return fromSharedCache( session, (Object) cacheKey, cacheAccessStrategy );
 	}
 
 	private static Serializable fromSharedCache(
 			SessionImplementor session,
 			Object cacheKey,
 			RegionAccessStrategy cacheAccessStrategy) {
 		Serializable cachedValue = null;
 		try {
 			session.getEventListenerManager().cacheGetStart();
 			cachedValue = (Serializable) cacheAccessStrategy.get( cacheKey, session.getTimestamp() );
 		}
 		finally {
 			session.getEventListenerManager().cacheGetEnd( cachedValue != null );
 		}
 		return cachedValue;
 	}
 
 	public static Serializable fromSharedCache(
 			SessionImplementor session,
 			CacheKey cacheKey,
 			RegionAccessStrategy cacheAccessStrategy) {
 		return fromSharedCache( session, (Object) cacheKey, cacheAccessStrategy );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/connections/internal/DriverManagerConnectionProviderImpl.java b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/connections/internal/DriverManagerConnectionProviderImpl.java
index 769071861f..fa402300a3 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/jdbc/connections/internal/DriverManagerConnectionProviderImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/jdbc/connections/internal/DriverManagerConnectionProviderImpl.java
@@ -1,309 +1,309 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.jdbc.connections.internal;
 
 import java.sql.Connection;
 import java.sql.Driver;
 import java.sql.SQLException;
 import java.util.Map;
 import java.util.Properties;
 import java.util.concurrent.ConcurrentLinkedQueue;
 import java.util.concurrent.Executors;
 import java.util.concurrent.ScheduledExecutorService;
 import java.util.concurrent.TimeUnit;
 
 import org.hibernate.HibernateException;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Environment;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.UnknownUnwrapTypeException;
 import org.hibernate.service.spi.Configurable;
 import org.hibernate.service.spi.ServiceException;
 import org.hibernate.service.spi.ServiceRegistryAwareService;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.spi.Stoppable;
 
 /**
  * A connection provider that uses the {@link java.sql.DriverManager} directly to open connections and provides
  * a very rudimentary connection pool.
  * <p/>
  * IMPL NOTE : not intended for production use!
  * <p/>
  * Thanks to Oleg Varaksin and his article on object pooling using the {@link java.util.concurrent} package, from
  * which much of the pooling code here is derived.  See http://ovaraksin.blogspot.com/2013/08/simple-and-lightweight-pool.html
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class DriverManagerConnectionProviderImpl
 		implements ConnectionProvider, Configurable, Stoppable, ServiceRegistryAwareService {
 
 	private static final CoreMessageLogger log = CoreLogging.messageLogger( DriverManagerConnectionProviderImpl.class );
 
 	public static final String MIN_SIZE = "hibernate.connection.min_pool_size";
 	public static final String INITIAL_SIZE = "hibernate.connection.initial_pool_size";
 	// in TimeUnit.SECONDS
 	public static final String VALIDATION_INTERVAL = "hibernate.connection.pool_validation_interval";
 
 	private boolean active = true;
 
 	private ConcurrentLinkedQueue<Connection> connections = new ConcurrentLinkedQueue<Connection>();
 	private ConnectionCreator connectionCreator;
 	private ScheduledExecutorService executorService;
 
 
 
 	// create the pool ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private ServiceRegistryImplementor serviceRegistry;
 
 	@Override
 	public void injectServices(ServiceRegistryImplementor serviceRegistry) {
 		this.serviceRegistry = serviceRegistry;
 	}
 
 	@Override
 	public void configure(Map configurationValues) {
 		log.usingHibernateBuiltInConnectionPool();
 
 		connectionCreator = buildCreator( configurationValues );
 
 		final int minSize = ConfigurationHelper.getInt( MIN_SIZE, configurationValues, 1 );
 		final int maxSize = ConfigurationHelper.getInt( AvailableSettings.POOL_SIZE, configurationValues, 20 );
 		final int initialSize = ConfigurationHelper.getInt( INITIAL_SIZE, configurationValues, minSize );
 		final long validationInterval = ConfigurationHelper.getLong( VALIDATION_INTERVAL, configurationValues, 30 );
 
 		log.hibernateConnectionPoolSize( maxSize, minSize );
 
 		log.debugf( "Initializing Connection pool with %s Connections", initialSize );
 		for ( int i = 0; i < initialSize; i++ ) {
 			connections.add( connectionCreator.createConnection() );
 		}
 
 		executorService = Executors.newSingleThreadScheduledExecutor();
 		executorService.scheduleWithFixedDelay(
 				new Runnable() {
-					private boolean primed = false;
+					private boolean primed;
 					@Override
 					public void run() {
 						int size = connections.size();
 
 						if ( !primed && size >= minSize ) {
 							// IMPL NOTE : the purpose of primed is to allow the pool to lazily reach its
 							// defined min-size.
 							log.debug( "Connection pool now considered primed; min-size will be maintained" );
 							primed = true;
 						}
 
 						if ( size < minSize && primed ) {
 							int numberToBeAdded = minSize - size;
 							log.debugf( "Adding %s Connections to the pool", numberToBeAdded );
 							for (int i = 0; i < numberToBeAdded; i++) {
 								connections.add( connectionCreator.createConnection() );
 							}
 						}
 						else if ( size > maxSize ) {
 							int numberToBeRemoved = size - maxSize;
 							log.debugf( "Removing %s Connections from the pool", numberToBeRemoved );
 							for ( int i = 0; i < numberToBeRemoved; i++ ) {
 								Connection connection = connections.poll();
 								try {
 									connection.close();
 								}
 								catch (SQLException e) {
 									log.unableToCloseConnection( e );
 								}
 							}
 						}
 					}
 				},
 				validationInterval,
 				validationInterval,
 				TimeUnit.SECONDS
 		);
 	}
 
 	private ConnectionCreator buildCreator(Map configurationValues) {
 		final ConnectionCreatorBuilder connectionCreatorBuilder = new ConnectionCreatorBuilder( serviceRegistry );
 
 		final String driverClassName = (String) configurationValues.get( AvailableSettings.DRIVER );
 		connectionCreatorBuilder.setDriver( loadDriverIfPossible( driverClassName ) );
 
 		final String url = (String) configurationValues.get( AvailableSettings.URL );
 		if ( url == null ) {
 			final String msg = log.jdbcUrlNotSpecified( AvailableSettings.URL );
 			log.error( msg );
 			throw new HibernateException( msg );
 		}
 		connectionCreatorBuilder.setUrl( url );
 
 		log.usingDriver( driverClassName, url );
 
 		final Properties connectionProps = ConnectionProviderInitiator.getConnectionProperties( configurationValues );
 
 		// if debug level is enabled, then log the password, otherwise mask it
 		if ( log.isDebugEnabled() ) {
 			log.connectionProperties( connectionProps );
 		}
 		else {
 			log.connectionProperties( ConfigurationHelper.maskOut( connectionProps, "password" ) );
 		}
 		connectionCreatorBuilder.setConnectionProps( connectionProps );
 
 		final boolean autoCommit = ConfigurationHelper.getBoolean( AvailableSettings.AUTOCOMMIT, configurationValues, false );
 		log.autoCommitMode( autoCommit );
 		connectionCreatorBuilder.setAutoCommit( autoCommit );
 
 		final Integer isolation = ConfigurationHelper.getInteger( AvailableSettings.ISOLATION, configurationValues );
 		if ( isolation != null ) {
 			log.jdbcIsolationLevel( Environment.isolationLevelToString( isolation ) );
 		}
 		connectionCreatorBuilder.setIsolation( isolation );
 
 		return connectionCreatorBuilder.build();
 	}
 
 	private Driver loadDriverIfPossible(String driverClassName) {
 		if ( driverClassName == null ) {
 			log.debug( "No driver class specified" );
 			return null;
 		}
 
 		if ( serviceRegistry != null ) {
 			final ClassLoaderService classLoaderService = serviceRegistry.getService( ClassLoaderService.class );
 			final Class<Driver> driverClass = classLoaderService.classForName( driverClassName );
 			try {
 				return driverClass.newInstance();
 			}
 			catch ( Exception e ) {
 				throw new ServiceException( "Specified JDBC Driver " + driverClassName + " could not be loaded", e );
 			}
 		}
 
 		try {
 			return (Driver) Class.forName( driverClassName ).newInstance();
 		}
 		catch ( Exception e1 ) {
 			try{
 				return (Driver) ReflectHelper.classForName( driverClassName ).newInstance();
 			}
 			catch ( Exception e2 ) {
 				throw new ServiceException( "Specified JDBC Driver " + driverClassName + " could not be loaded", e2 );
 			}
 		}
 	}
 
 
 	// use the pool ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public Connection getConnection() throws SQLException {
 		if ( !active ) {
 			throw new HibernateException( "Connection pool is no longer active" );
 		}
 
 		Connection connection;
 		if ( (connection = connections.poll()) == null ) {
 			connection = connectionCreator.createConnection();
 		}
 
 		return connection;
 	}
 
 	@Override
 	public void closeConnection(Connection conn) throws SQLException {
 		if (conn == null) {
 			return;
 		}
 
 		this.connections.offer( conn );
 	}
 
 
 	@Override
 	public boolean supportsAggressiveRelease() {
 		return false;
 	}
 
 	@Override
 	public boolean isUnwrappableAs(Class unwrapType) {
 		return ConnectionProvider.class.equals( unwrapType ) ||
 				DriverManagerConnectionProviderImpl.class.isAssignableFrom( unwrapType );
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public <T> T unwrap(Class<T> unwrapType) {
 		if ( ConnectionProvider.class.equals( unwrapType ) ||
 				DriverManagerConnectionProviderImpl.class.isAssignableFrom( unwrapType ) ) {
 			return (T) this;
 		}
 		else {
 			throw new UnknownUnwrapTypeException( unwrapType );
 		}
 	}
 
 
 	// destroy the pool ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public void stop() {
 		if ( !active ) {
 			return;
 		}
 
 		log.cleaningUpConnectionPool( connectionCreator.getUrl() );
 
 		active = false;
 
 		if ( executorService != null ) {
 			executorService.shutdown();
 		}
 		executorService = null;
 
 		for ( Connection connection : connections ) {
 			try {
 				connection.close();
 			}
 			catch (SQLException e) {
 				log.unableToClosePooledConnection( e );
 			}
 		}
 	}
 
 
 	@Override
 	protected void finalize() throws Throwable {
 		if ( active ) {
 			stop();
 		}
 		super.finalize();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/spi/CollectionEntry.java b/hibernate-core/src/main/java/org/hibernate/engine/spi/CollectionEntry.java
index 0f722ed446..f8be946628 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/spi/CollectionEntry.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/spi/CollectionEntry.java
@@ -1,446 +1,446 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.spi;
 
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.util.Collection;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.collection.internal.AbstractPersistentCollection;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.pretty.MessageHelper;
 
 /**
  * We need an entry to tell us all about the current state
  * of a collection with respect to its persistent state
  *
  * @author Gavin King
  */
 public final class CollectionEntry implements Serializable {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, CollectionEntry.class.getName());
 
 	//ATTRIBUTES MAINTAINED BETWEEN FLUSH CYCLES
 
 	// session-start/post-flush persistent state
 	private Serializable snapshot;
 	// allow the CollectionSnapshot to be serialized
 	private String role;
 
 	// "loaded" means the reference that is consistent
 	// with the current database state
 	private transient CollectionPersister loadedPersister;
 	private Serializable loadedKey;
 
 	// ATTRIBUTES USED ONLY DURING FLUSH CYCLE
 
 	// during flush, we navigate the object graph to
 	// collections and decide what to do with them
 	private transient boolean reached;
 	private transient boolean processed;
 	private transient boolean doupdate;
 	private transient boolean doremove;
 	private transient boolean dorecreate;
 	// if we instantiate a collection during the flush() process,
 	// we must ignore it for the rest of the flush()
 	private transient boolean ignore;
 
 	// "current" means the reference that was found during flush()
 	private transient CollectionPersister currentPersister;
 	private transient Serializable currentKey;
 
 	/**
 	 * For newly wrapped collections, or dereferenced collection wrappers
 	 */
 	public CollectionEntry(CollectionPersister persister, PersistentCollection collection) {
 		// new collections that get found + wrapped
 		// during flush shouldn't be ignored
 		ignore = false;
 
 		collection.clearDirty(); //a newly wrapped collection is NOT dirty (or we get unnecessary version updates)
 
 		snapshot = persister.isMutable() ?
 				collection.getSnapshot(persister) :
 				null;
 		collection.setSnapshot(loadedKey, role, snapshot);
 	}
 
 	/**
 	 * For collections just loaded from the database
 	 */
 	public CollectionEntry(
 			final PersistentCollection collection,
 			final CollectionPersister loadedPersister,
 			final Serializable loadedKey,
 			final boolean ignore
 	) {
 		this.ignore=ignore;
 
 		//collection.clearDirty()
 
 		this.loadedKey = loadedKey;
 		setLoadedPersister(loadedPersister);
 
 		collection.setSnapshot(loadedKey, role, null);
 
 		//postInitialize() will be called after initialization
 	}
 
 	/**
 	 * For uninitialized detached collections
 	 */
 	public CollectionEntry(CollectionPersister loadedPersister, Serializable loadedKey) {
 		// detached collection wrappers that get found + reattached
 		// during flush shouldn't be ignored
 		ignore = false;
 
 		//collection.clearDirty()
 
 		this.loadedKey = loadedKey;
 		setLoadedPersister(loadedPersister);
 	}
 
 	/**
 	 * For initialized detached collections
 	 */
 	public CollectionEntry(PersistentCollection collection, SessionFactoryImplementor factory) throws MappingException {
 		// detached collections that get found + reattached
 		// during flush shouldn't be ignored
 		ignore = false;
 
 		loadedKey = collection.getKey();
 		setLoadedPersister( factory.getCollectionPersister( collection.getRole() ) );
 
 		snapshot = collection.getStoredSnapshot();
 	}
 
 	/**
 	 * Used from custom serialization.
 	 *
 	 * @see #serialize
 	 * @see #deserialize
 	 */
 	private CollectionEntry(
 			String role,
 	        Serializable snapshot,
 	        Serializable loadedKey,
 	        SessionFactoryImplementor factory) {
 		this.role = role;
 		this.snapshot = snapshot;
 		this.loadedKey = loadedKey;
 		if ( role != null ) {
 			afterDeserialize( factory );
 		}
 	}
 
 	/**
 	 * Determine if the collection is "really" dirty, by checking dirtiness
 	 * of the collection elements, if necessary
 	 */
 	private void dirty(PersistentCollection collection) throws HibernateException {
 
 		boolean forceDirty = collection.wasInitialized() &&
 				!collection.isDirty() && //optimization
 				getLoadedPersister() != null &&
 				getLoadedPersister().isMutable() && //optimization
 				( collection.isDirectlyAccessible() || getLoadedPersister().getElementType().isMutable() ) && //optimization
 				!collection.equalsSnapshot( getLoadedPersister() );
 
 		if ( forceDirty ) {
 			collection.dirty();
 		}
 
 	}
 
 	public void preFlush(PersistentCollection collection) throws HibernateException {
 		if ( loadedKey == null && collection.getKey() != null ) {
 			loadedKey = collection.getKey();
 		}
 
 		boolean nonMutableChange = collection.isDirty() &&
 				getLoadedPersister()!=null &&
 				!getLoadedPersister().isMutable();
 		if (nonMutableChange) {
 			throw new HibernateException(
 					"changed an immutable collection instance: " +
 					MessageHelper.collectionInfoString( getLoadedPersister().getRole(), getLoadedKey() )
 				);
 		}
 
 		dirty(collection);
 
 		if ( LOG.isDebugEnabled() && collection.isDirty() && getLoadedPersister() != null ) {
 			LOG.debugf( "Collection dirty: %s",
 					MessageHelper.collectionInfoString( getLoadedPersister().getRole(), getLoadedKey() ) );
 		}
 
 		setDoupdate(false);
 		setDoremove(false);
 		setDorecreate(false);
 		setReached(false);
 		setProcessed(false);
 	}
 
 	public void postInitialize(PersistentCollection collection) throws HibernateException {
 		snapshot = getLoadedPersister().isMutable() ?
 				collection.getSnapshot( getLoadedPersister() ) :
 				null;
 		collection.setSnapshot(loadedKey, role, snapshot);
 		if (getLoadedPersister().getBatchSize() > 1) {
 			((AbstractPersistentCollection) collection).getSession().getPersistenceContext().getBatchFetchQueue().removeBatchLoadableCollection(this); 
 		}
 	}
 
 	/**
 	 * Called after a successful flush
 	 */
 	public void postFlush(PersistentCollection collection) throws HibernateException {
 		if ( isIgnore() ) {
 			ignore = false;
 		}
 		else if ( !isProcessed() ) {
 			throw new AssertionFailure( "collection [" + collection.getRole() + "] was not processed by flush()" );
 		}
 		collection.setSnapshot(loadedKey, role, snapshot);
 	}
 
 	/**
 	 * Called after execution of an action
 	 */
 	public void afterAction(PersistentCollection collection) {
 		loadedKey = getCurrentKey();
 		setLoadedPersister( getCurrentPersister() );
 
 		boolean resnapshot = collection.wasInitialized() &&
 				( isDoremove() || isDorecreate() || isDoupdate() );
 		if ( resnapshot ) {
 			snapshot = loadedPersister==null || !loadedPersister.isMutable() ?
 					null :
 					collection.getSnapshot(loadedPersister); //re-snapshot
 		}
 
 		collection.postAction();
 	}
 
 	public Serializable getKey() {
 		return getLoadedKey();
 	}
 
 	public String getRole() {
 		return role;
 	}
 
 	public Serializable getSnapshot() {
 		return snapshot;
 	}
 
-	private boolean fromMerge = false;
+	private boolean fromMerge;
 
 	/**
 	 * Reset the stored snapshot for both the persistent collection and this collection entry. 
 	 * Used during the merge of detached collections.
 	 * 
 	 * @param collection the persistentcollection to be updated
 	 * @param storedSnapshot the new stored snapshot
 	 */
 	public void resetStoredSnapshot(PersistentCollection collection, Serializable storedSnapshot) {
 		LOG.debugf("Reset storedSnapshot to %s for %s", storedSnapshot, this);
 
 		if ( fromMerge ) {
 			return; // EARLY EXIT!
 		}
 
 		snapshot = storedSnapshot;
 		collection.setSnapshot( loadedKey, role, snapshot );
 		fromMerge = true;
 	}
 
 	private void setLoadedPersister(CollectionPersister persister) {
 		loadedPersister = persister;
 		setRole( persister == null ? null : persister.getRole() );
 	}
 
 	void afterDeserialize(SessionFactoryImplementor factory) {
 		loadedPersister = ( factory == null ? null : factory.getCollectionPersister(role) );
 	}
 
 	public boolean wasDereferenced() {
 		return getLoadedKey() == null;
 	}
 
 	public boolean isReached() {
 		return reached;
 	}
 
 	public void setReached(boolean reached) {
 		this.reached = reached;
 	}
 
 	public boolean isProcessed() {
 		return processed;
 	}
 
 	public void setProcessed(boolean processed) {
 		this.processed = processed;
 	}
 
 	public boolean isDoupdate() {
 		return doupdate;
 	}
 
 	public void setDoupdate(boolean doupdate) {
 		this.doupdate = doupdate;
 	}
 
 	public boolean isDoremove() {
 		return doremove;
 	}
 
 	public void setDoremove(boolean doremove) {
 		this.doremove = doremove;
 	}
 
 	public boolean isDorecreate() {
 		return dorecreate;
 	}
 
 	public void setDorecreate(boolean dorecreate) {
 		this.dorecreate = dorecreate;
 	}
 
 	public boolean isIgnore() {
 		return ignore;
 	}
 
 	public CollectionPersister getCurrentPersister() {
 		return currentPersister;
 	}
 
 	public void setCurrentPersister(CollectionPersister currentPersister) {
 		this.currentPersister = currentPersister;
 	}
 
 	/**
 	 * This is only available late during the flush
 	 * cycle
 	 */
 	public Serializable getCurrentKey() {
 		return currentKey;
 	}
 
 	public void setCurrentKey(Serializable currentKey) {
 		this.currentKey = currentKey;
 	}
 
 	/**
 	 * This is only available late during the flush cycle
 	 */
 	public CollectionPersister getLoadedPersister() {
 		return loadedPersister;
 	}
 
 	public Serializable getLoadedKey() {
 		return loadedKey;
 	}
 
 	public void setRole(String role) {
 		this.role = role;
 	}
 
 	@Override
     public String toString() {
 		String result = "CollectionEntry" +
 				MessageHelper.collectionInfoString( loadedPersister.getRole(), loadedKey );
 		if (currentPersister!=null) {
 			result += "->" +
 					MessageHelper.collectionInfoString( currentPersister.getRole(), currentKey );
 		}
 		return result;
 	}
 
 	/**
 	 * Get the collection orphans (entities which were removed from the collection)
 	 */
 	public Collection getOrphans(String entityName, PersistentCollection collection)
 	throws HibernateException {
 		if (snapshot==null) {
 			throw new AssertionFailure("no collection snapshot for orphan delete");
 		}
 		return collection.getOrphans( snapshot, entityName );
 	}
 
 	public boolean isSnapshotEmpty(PersistentCollection collection) {
 		//TODO: does this really need to be here?
 		//      does the collection already have
 		//      it's own up-to-date snapshot?
 		return collection.wasInitialized() &&
 			( getLoadedPersister()==null || getLoadedPersister().isMutable() ) &&
 			collection.isSnapshotEmpty( getSnapshot() );
 	}
 
 
 
 	/**
 	 * Custom serialization routine used during serialization of a
 	 * Session/PersistenceContext for increased performance.
 	 *
 	 * @param oos The stream to which we should write the serial data.
 	 * @throws java.io.IOException
 	 */
 	public void serialize(ObjectOutputStream oos) throws IOException {
 		oos.writeObject( role );
 		oos.writeObject( snapshot );
 		oos.writeObject( loadedKey );
 	}
 
 	/**
 	 * Custom deserialization routine used during deserialization of a
 	 * Session/PersistenceContext for increased performance.
 	 *
 	 * @param ois The stream from which to read the entry.
 	 * @param session The session being deserialized.
 	 * @return The deserialized CollectionEntry
 	 * @throws IOException
 	 * @throws ClassNotFoundException
 	 */
 	public static CollectionEntry deserialize(
 			ObjectInputStream ois,
 	        SessionImplementor session) throws IOException, ClassNotFoundException {
 		return new CollectionEntry(
 				( String ) ois.readObject(),
 		        ( Serializable ) ois.readObject(),
 		        ( Serializable ) ois.readObject(),
 		        ( session == null ? null : session.getFactory() )
 		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/spi/QueryParameters.java b/hibernate-core/src/main/java/org/hibernate/engine/spi/QueryParameters.java
index 1f05ecd788..ce9dbcffd4 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/spi/QueryParameters.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/spi/QueryParameters.java
@@ -1,602 +1,602 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.spi;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.StringTokenizer;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockOptions;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollMode;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.query.spi.HQLQueryPlan;
 import org.hibernate.hql.internal.classic.ParserHelper;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.FilterImpl;
 import org.hibernate.internal.util.EntityPrinter;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * @author Gavin King
  */
 public final class QueryParameters {
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, QueryParameters.class.getName());
 
 	private Type[] positionalParameterTypes;
 	private Object[] positionalParameterValues;
 	private Map<String,TypedValue> namedParameters;
 	private LockOptions lockOptions;
 	private RowSelection rowSelection;
 	private boolean cacheable;
 	private String cacheRegion;
 	private String comment;
 	private List<String> queryHints;
 	private ScrollMode scrollMode;
 	private Serializable[] collectionKeys;
 	private Object optionalObject;
 	private String optionalEntityName;
 	private Serializable optionalId;
 	private boolean isReadOnlyInitialized;
 	private boolean readOnly;
-	private boolean callable = false;
-	private boolean autodiscovertypes = false;
+	private boolean callable;
+	private boolean autodiscovertypes;
 	private boolean isNaturalKeyLookup;
 
 	private final ResultTransformer resultTransformer; // why is all others non final ?
 
 	private String processedSQL;
 	private Type[] processedPositionalParameterTypes;
 	private Object[] processedPositionalParameterValues;
 	
 	private HQLQueryPlan queryPlan;
 
 	public QueryParameters() {
 		this( ArrayHelper.EMPTY_TYPE_ARRAY, ArrayHelper.EMPTY_OBJECT_ARRAY );
 	}
 
 	public QueryParameters(Type type, Object value) {
 		this( new Type[] { type }, new Object[] { value } );
 	}
 
 	public QueryParameters(
 			final Type[] positionalParameterTypes,
 			final Object[] positionalParameterValues,
 			final Object optionalObject,
 			final String optionalEntityName,
 			final Serializable optionalObjectId) {
 		this( positionalParameterTypes, positionalParameterValues );
 		this.optionalObject = optionalObject;
 		this.optionalId = optionalObjectId;
 		this.optionalEntityName = optionalEntityName;
 
 	}
 
 	public QueryParameters(
 			final Type[] positionalParameterTypes,
 			final Object[] positionalParameterValues) {
 		this( positionalParameterTypes, positionalParameterValues, null, null, false, false, false, null, null, null, false, null );
 	}
 
 	public QueryParameters(
 			final Type[] positionalParameterTypes,
 			final Object[] positionalParameterValues,
 			final Serializable[] collectionKeys) {
 		this( positionalParameterTypes, positionalParameterValues, null, collectionKeys );
 	}
 
 	public QueryParameters(
 			final Type[] positionalParameterTypes,
 			final Object[] positionalParameterValues,
 			final Map<String,TypedValue> namedParameters,
 			final Serializable[] collectionKeys) {
 		this(
 				positionalParameterTypes,
 				positionalParameterValues,
 				namedParameters,
 				null,
 				null,
 				false,
 				false,
 				false,
 				null,
 				null,
 				null,
 				collectionKeys,
 				null
 		);
 	}
 
 	public QueryParameters(
 			final Type[] positionalParameterTypes,
 			final Object[] positionalParameterValues,
 			final LockOptions lockOptions,
 			final RowSelection rowSelection,
 			final boolean isReadOnlyInitialized,
 			final boolean readOnly,
 			final boolean cacheable,
 			final String cacheRegion,
 			//final boolean forceCacheRefresh,
 			final String comment,
 			final List<String> queryHints,
 			final boolean isLookupByNaturalKey,
 			final ResultTransformer transformer) {
 		this(
 				positionalParameterTypes,
 				positionalParameterValues,
 				null,
 				lockOptions,
 				rowSelection,
 				isReadOnlyInitialized,
 				readOnly,
 				cacheable,
 				cacheRegion,
 				comment,
 				queryHints,
 				null,
 				transformer
 		);
 		isNaturalKeyLookup = isLookupByNaturalKey;
 	}
 
 	public QueryParameters(
 			final Type[] positionalParameterTypes,
 			final Object[] positionalParameterValues,
 			final Map<String,TypedValue> namedParameters,
 			final LockOptions lockOptions,
 			final RowSelection rowSelection,
 			final boolean isReadOnlyInitialized,
 			final boolean readOnly,
 			final boolean cacheable,
 			final String cacheRegion,
 			//final boolean forceCacheRefresh,
 			final String comment,
 			final List<String> queryHints,
 			final Serializable[] collectionKeys,
 			ResultTransformer transformer) {
 		this.positionalParameterTypes = positionalParameterTypes;
 		this.positionalParameterValues = positionalParameterValues;
 		this.namedParameters = namedParameters;
 		this.lockOptions = lockOptions;
 		this.rowSelection = rowSelection;
 		this.cacheable = cacheable;
 		this.cacheRegion = cacheRegion;
 		//this.forceCacheRefresh = forceCacheRefresh;
 		this.comment = comment;
 		this.queryHints = queryHints;
 		this.collectionKeys = collectionKeys;
 		this.isReadOnlyInitialized = isReadOnlyInitialized;
 		this.readOnly = readOnly;
 		this.resultTransformer = transformer;
 	}
 
 	public QueryParameters(
 			final Type[] positionalParameterTypes,
 			final Object[] positionalParameterValues,
 			final Map<String,TypedValue> namedParameters,
 			final LockOptions lockOptions,
 			final RowSelection rowSelection,
 			final boolean isReadOnlyInitialized,
 			final boolean readOnly,
 			final boolean cacheable,
 			final String cacheRegion,
 			//final boolean forceCacheRefresh,
 			final String comment,
 			final List<String> queryHints,
 			final Serializable[] collectionKeys,
 			final Object optionalObject,
 			final String optionalEntityName,
 			final Serializable optionalId,
 			final ResultTransformer transformer) {
 		this(
 				positionalParameterTypes,
 				positionalParameterValues,
 				namedParameters,
 				lockOptions,
 				rowSelection,
 				isReadOnlyInitialized,
 				readOnly,
 				cacheable,
 				cacheRegion,
 				comment,
 				queryHints,
 				collectionKeys,
 				transformer
 		);
 		this.optionalEntityName = optionalEntityName;
 		this.optionalId = optionalId;
 		this.optionalObject = optionalObject;
 	}
 
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public boolean hasRowSelection() {
 		return rowSelection != null;
 	}
 
 	public Map<String,TypedValue> getNamedParameters() {
 		return namedParameters;
 	}
 
 	public Type[] getPositionalParameterTypes() {
 		return positionalParameterTypes;
 	}
 
 	public Object[] getPositionalParameterValues() {
 		return positionalParameterValues;
 	}
 
 	public RowSelection getRowSelection() {
 		return rowSelection;
 	}
 
 	public ResultTransformer getResultTransformer() {
 		return resultTransformer;
 	}
 
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public void setNamedParameters(Map<String,TypedValue> map) {
 		namedParameters = map;
 	}
 
 	public void setPositionalParameterTypes(Type[] types) {
 		positionalParameterTypes = types;
 	}
 
 	public void setPositionalParameterValues(Object[] objects) {
 		positionalParameterValues = objects;
 	}
 
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public void setRowSelection(RowSelection selection) {
 		rowSelection = selection;
 	}
 
 	public LockOptions getLockOptions() {
 		return lockOptions;
 	}
 
 	public void setLockOptions(LockOptions lockOptions) {
 		this.lockOptions = lockOptions;
 	}
 
 	public void traceParameters(SessionFactoryImplementor factory) throws HibernateException {
 		EntityPrinter print = new EntityPrinter( factory );
 		if ( positionalParameterValues.length != 0 ) {
 			LOG.tracev( "Parameters: {0}", print.toString( positionalParameterTypes, positionalParameterValues ) );
 		}
 		if ( namedParameters != null ) {
 			LOG.tracev( "Named parameters: {0}", print.toString( namedParameters ) );
 		}
 	}
 
 	public boolean isCacheable() {
 		return cacheable;
 	}
 
 	public void setCacheable(boolean b) {
 		cacheable = b;
 	}
 
 	public String getCacheRegion() {
 		return cacheRegion;
 	}
 
 	public void setCacheRegion(String cacheRegion) {
 		this.cacheRegion = cacheRegion;
 	}
 
 	public void validateParameters() throws QueryException {
 		int types = positionalParameterTypes == null ? 0 : positionalParameterTypes.length;
 		int values = positionalParameterValues == null ? 0 : positionalParameterValues.length;
 		if ( types != values ) {
 			throw new QueryException(
 					"Number of positional parameter types:" + types +
 							" does not match number of positional parameters: " + values
 			);
 		}
 	}
 
 	public String getComment() {
 		return comment;
 	}
 
 	public void setComment(String comment) {
 		this.comment = comment;
 	}
 	  
 	public List<String> getQueryHints() {
 		return queryHints;
 	}
 
 	public void setQueryHints(List<String> queryHints) {
 		this.queryHints = queryHints;
 	}
 
 	public ScrollMode getScrollMode() {
 		return scrollMode;
 	}
 
 	public void setScrollMode(ScrollMode scrollMode) {
 		this.scrollMode = scrollMode;
 	}
 
 	public Serializable[] getCollectionKeys() {
 		return collectionKeys;
 	}
 
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public void setCollectionKeys(Serializable[] collectionKeys) {
 		this.collectionKeys = collectionKeys;
 	}
 
 	public String getOptionalEntityName() {
 		return optionalEntityName;
 	}
 
 	public void setOptionalEntityName(String optionalEntityName) {
 		this.optionalEntityName = optionalEntityName;
 	}
 
 	public Serializable getOptionalId() {
 		return optionalId;
 	}
 
 	public void setOptionalId(Serializable optionalId) {
 		this.optionalId = optionalId;
 	}
 
 	public Object getOptionalObject() {
 		return optionalObject;
 	}
 
 	public void setOptionalObject(Object optionalObject) {
 		this.optionalObject = optionalObject;
 	}
 
 	/**
 	 * Has the read-only/modifiable mode been explicitly set?
 	 * @see QueryParameters#setReadOnly(boolean)
 	 * @see QueryParameters#isReadOnly(org.hibernate.engine.spi.SessionImplementor)
 	 *
 	 * @return true, the read-only/modifiable mode was explicitly set
 	 *         false, the read-only/modifiable mode was not explicitly set
 	 */
 	public boolean isReadOnlyInitialized() {
 		return isReadOnlyInitialized;
 	}
 
 	/**
 	 * Should entities and proxies loaded by the Query be put in read-only mode? The
 	 * read-only/modifiable setting must be initialized via QueryParameters#setReadOnly(boolean)
 	 * before calling this method.
 	 *
 	 * @see QueryParameters#isReadOnlyInitialized()
 	 * @see QueryParameters#isReadOnly(org.hibernate.engine.spi.SessionImplementor)
 	 * @see QueryParameters#setReadOnly(boolean)
 	 *
 	 * The read-only/modifiable setting has no impact on entities/proxies returned by the
 	 * query that existed in the session before the query was executed.
 	 *
 	 * @return true, entities and proxies loaded by the Query will be put in read-only mode
 	 *         false, entities and proxies loaded by the Query will be put in modifiable mode
 	 * @throws IllegalStateException if the read-only/modifiable setting has not been
 	 * initialized (i.e., isReadOnlyInitialized() == false).
 	 */
 	public boolean isReadOnly() {
 		if ( ! isReadOnlyInitialized() ) {
 			throw new IllegalStateException( "cannot call isReadOnly() when isReadOnlyInitialized() returns false" );
 		}
 		return readOnly;
 	}
 
 	/**
 	 * Should entities and proxies loaded by the Query be put in read-only mode?  If the
 	 * read-only/modifiable setting was not initialized (i.e., QueryParameters#isReadOnlyInitialized() == false),
 	 * then the default read-only/modifiable setting for the persistence context is returned instead.
 	 * <p/>
 	 * The read-only/modifiable setting has no impact on entities/proxies returned by the
 	 * query that existed in the session before the query was executed.
 	 *
 	 * @param session The originating session
 	 *
 	 * @return {@code true} indicates that entities and proxies loaded by the query will be put in read-only mode;
 	 * {@code false} indicates that entities and proxies loaded by the query will be put in modifiable mode
 	 *
 	 * @see QueryParameters#isReadOnlyInitialized()
 	 * @see QueryParameters#setReadOnly(boolean)
 	 * @see org.hibernate.engine.spi.PersistenceContext#isDefaultReadOnly()
 	 *
 	 * The read-only/modifiable setting has no impact on entities/proxies returned by the
 	 * query that existed in the session before the query was executed.
 	 *
 	 */
 	public boolean isReadOnly(SessionImplementor session) {
 		return isReadOnlyInitialized
 				? isReadOnly()
 				: session.getPersistenceContext().isDefaultReadOnly();
 	}
 
 	/**
 	 * Set the read-only/modifiable mode for entities and proxies loaded by the query.
 	 * <p/>
 	 * The read-only/modifiable setting has no impact on entities/proxies returned by the
 	 * query that existed in the session before the query was executed.
 	 *
 	 * @param readOnly if {@code true}, entities and proxies loaded by the query will be put in read-only mode; if
 	 * {@code false}, entities and proxies loaded by the query will be put in modifiable mode
 	 *
 	 * @see QueryParameters#isReadOnlyInitialized()
 	 * @see QueryParameters#isReadOnly(org.hibernate.engine.spi.SessionImplementor)
 	 * @see QueryParameters#setReadOnly(boolean)
 	 * @see org.hibernate.engine.spi.PersistenceContext#isDefaultReadOnly()
 	 */
 	public void setReadOnly(boolean readOnly) {
 		this.readOnly = readOnly;
 		this.isReadOnlyInitialized = true;
 	}
 
 	public void setCallable(boolean callable) {
 		this.callable = callable;
 	}
 
 	public boolean isCallable() {
 		return callable;
 	}
 
 	public boolean hasAutoDiscoverScalarTypes() {
 		return autodiscovertypes;
 	}
 
 	public void processFilters(String sql, SessionImplementor session) {
 		processFilters( sql, session.getLoadQueryInfluencers().getEnabledFilters(), session.getFactory() );
 	}
 
 	@SuppressWarnings( {"unchecked"})
 	public void processFilters(String sql, Map filters, SessionFactoryImplementor factory) {
 		if ( filters.size() == 0 || !sql.contains( ParserHelper.HQL_VARIABLE_PREFIX ) ) {
 			// HELLA IMPORTANT OPTIMIZATION!!!
 			processedPositionalParameterValues = getPositionalParameterValues();
 			processedPositionalParameterTypes = getPositionalParameterTypes();
 			processedSQL = sql;
 		}
 		else {
 			final Dialect dialect = factory.getDialect();
 			String symbols = new StringBuilder().append( ParserHelper.HQL_SEPARATORS )
 					.append( dialect.openQuote() )
 					.append( dialect.closeQuote() )
 					.toString();
 			StringTokenizer tokens = new StringTokenizer( sql, symbols, true );
 			StringBuilder result = new StringBuilder();
 
 			List parameters = new ArrayList();
 			List parameterTypes = new ArrayList();
 
 			int positionalIndex = 0;
 			while ( tokens.hasMoreTokens() ) {
 				final String token = tokens.nextToken();
 				if ( token.startsWith( ParserHelper.HQL_VARIABLE_PREFIX ) ) {
 					final String filterParameterName = token.substring( 1 );
 					final String[] parts = LoadQueryInfluencers.parseFilterParameterName( filterParameterName );
 					final FilterImpl filter = ( FilterImpl ) filters.get( parts[0] );
 					final Object value = filter.getParameter( parts[1] );
 					final Type type = filter.getFilterDefinition().getParameterType( parts[1] );
 					if ( value != null && Collection.class.isAssignableFrom( value.getClass() ) ) {
 						Iterator itr = ( ( Collection ) value ).iterator();
 						while ( itr.hasNext() ) {
 							Object elementValue = itr.next();
 							result.append( '?' );
 							parameters.add( elementValue );
 							parameterTypes.add( type );
 							if ( itr.hasNext() ) {
 								result.append( ", " );
 							}
 						}
 					}
 					else {
 						result.append( '?' );
 						parameters.add( value );
 						parameterTypes.add( type );
 					}
 				}
 				else {
 					if ( "?".equals( token ) && positionalIndex < getPositionalParameterValues().length ) {
 						parameters.add( getPositionalParameterValues()[positionalIndex] );
 						parameterTypes.add( getPositionalParameterTypes()[positionalIndex] );
 						positionalIndex++;
 					}
 					result.append( token );
 				}
 			}
 			processedPositionalParameterValues = parameters.toArray();
 			processedPositionalParameterTypes = ( Type[] ) parameterTypes.toArray( new Type[parameterTypes.size()] );
 			processedSQL = result.toString();
 		}
 	}
 
 	public String getFilteredSQL() {
 		return processedSQL;
 	}
 
 	public Object[] getFilteredPositionalParameterValues() {
 		return processedPositionalParameterValues;
 	}
 
 	public Type[] getFilteredPositionalParameterTypes() {
 		return processedPositionalParameterTypes;
 	}
 
 	public boolean isNaturalKeyLookup() {
 		return isNaturalKeyLookup;
 	}
 
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public void setNaturalKeyLookup(boolean isNaturalKeyLookup) {
 		this.isNaturalKeyLookup = isNaturalKeyLookup;
 	}
 
 	public void setAutoDiscoverScalarTypes(boolean autodiscovertypes) {
 		this.autodiscovertypes = autodiscovertypes;
 	}
 
 	public QueryParameters createCopyUsing(RowSelection selection) {
 		QueryParameters copy = new QueryParameters(
 				this.positionalParameterTypes,
 				this.positionalParameterValues,
 				this.namedParameters,
 				this.lockOptions,
 				selection,
 				this.isReadOnlyInitialized,
 				this.readOnly,
 				this.cacheable,
 				this.cacheRegion,
 				this.comment,
 				this.queryHints,
 				this.collectionKeys,
 				this.optionalObject,
 				this.optionalEntityName,
 				this.optionalId,
 				this.resultTransformer
 		);
 		copy.processedSQL = this.processedSQL;
 		copy.processedPositionalParameterTypes = this.processedPositionalParameterTypes;
 		copy.processedPositionalParameterValues = this.processedPositionalParameterValues;
 		return copy;
 	}
 
 	public HQLQueryPlan getQueryPlan() {
 		return queryPlan;
 	}
 
 	public void setQueryPlan(HQLQueryPlan queryPlan) {
 		this.queryPlan = queryPlan;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaStatusHelper.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaStatusHelper.java
index 639dea75c7..c817d1c4fd 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaStatusHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/transaction/internal/jta/JtaStatusHelper.java
@@ -1,197 +1,200 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.transaction.internal.jta;
 
 import javax.transaction.Status;
 import javax.transaction.SystemException;
 import javax.transaction.TransactionManager;
 import javax.transaction.UserTransaction;
 
 import org.hibernate.TransactionException;
 
 /**
  * Utility for dealing with JTA statuses.
  *
  * @author Steve Ebersole
  */
-public class JtaStatusHelper {
+public final class JtaStatusHelper {
+	private JtaStatusHelper() {
+	}
+
 	/**
 	 * Extract the status code from a {@link UserTransaction}
 	 *
 	 * @param userTransaction The {@link UserTransaction} from which to extract the status.
 	 *
 	 * @return The transaction status
 	 *
 	 * @throws TransactionException If the {@link UserTransaction} reports the status as unknown
 	 */
 	public static int getStatus(UserTransaction userTransaction) {
 		try {
 			final int status = userTransaction.getStatus();
 			if ( status == Status.STATUS_UNKNOWN ) {
 				throw new TransactionException( "UserTransaction reported transaction status as unknown" );
 			}
 			return status;
 		}
 		catch ( SystemException se ) {
 			throw new TransactionException( "Could not determine transaction status", se );
 		}
 	}
 
 	/**
 	 * Extract the status code from the current {@link javax.transaction.Transaction} associated with the
 	 * given {@link TransactionManager}
 	 *
 	 * @param transactionManager The {@link TransactionManager} from which to extract the status.
 	 *
 	 * @return The transaction status
 	 *
 	 * @throws TransactionException If the {@link TransactionManager} reports the status as unknown
 	 */
 	public static int getStatus(TransactionManager transactionManager) {
 		try {
 			final int status = transactionManager.getStatus();
 			if ( status == Status.STATUS_UNKNOWN ) {
 				throw new TransactionException( "TransactionManager reported transaction status as unknwon" );
 			}
 			return status;
 		}
 		catch ( SystemException se ) {
 			throw new TransactionException( "Could not determine transaction status", se );
 		}
 	}
 
 	/**
 	 * Does the given status code indicate an active transaction?
 	 *
 	 * @param status The transaction status code to check
 	 *
 	 * @return True if the code indicates active; false otherwise.
 	 */
 	public static boolean isActive(int status) {
 		return status == Status.STATUS_ACTIVE;
 	}
 
 	/**
 	 * Does the status code obtained from the given {@link UserTransaction} indicate an active transaction?
 	 *
 	 * @param userTransaction The {@link UserTransaction} whose status is to be checked
 	 *
 	 * @return True if the transaction is active; false otherwise.
 	 */
 	public static boolean isActive(UserTransaction userTransaction) {
 		final int status = getStatus( userTransaction );
 		return isActive( status );
 	}
 
 	/**
 	 * Does the status code obtained from the given {@link TransactionManager} indicate an active transaction?
 	 *
 	 * @param transactionManager The {@link TransactionManager} whose status is to be checked
 	 *
 	 * @return True if the transaction is active; false otherwise.
 	 */
 	public static boolean isActive(TransactionManager transactionManager) {
 		return isActive( getStatus( transactionManager ) );
 	}
 
 	/**
 	 * Does the given status code indicate a rolled back transaction?
 	 *
 	 * @param status The transaction status code to check
 	 *
 	 * @return True if the code indicates a roll back; false otherwise.
 	 */
 	public static boolean isRollback(int status) {
 		return status == Status.STATUS_MARKED_ROLLBACK ||
 				status == Status.STATUS_ROLLING_BACK ||
 				status == Status.STATUS_ROLLEDBACK;
 	}
 
 	/**
 	 * Does the status code obtained from the given {@link UserTransaction} indicate a roll back?
 	 *
 	 * @param userTransaction The {@link UserTransaction} whose status is to be checked
 	 *
 	 * @return True if the transaction indicates roll back; false otherwise.
 	 */
 	public static boolean isRollback(UserTransaction userTransaction) {
 		return isRollback( getStatus( userTransaction ) );
 	}
 
 	/**
 	 * Does the status code obtained from the given {@link TransactionManager} indicate a roll back?
 	 *
 	 * @param transactionManager The {@link TransactionManager} whose status is to be checked
 	 *
 	 * @return True if the transaction indicates roll back; false otherwise.
 	 */
 	public static boolean isRollback(TransactionManager transactionManager) {
 		return isRollback( getStatus( transactionManager ) );
 	}
 
 	/**
 	 * Does the given status code indicate a committed transaction?
 	 *
 	 * @param status The transaction status code to check
 	 *
 	 * @return True if the code indicates a roll back; false otherwise.
 	 */
 	public static boolean isCommitted(int status) {
 		return status == Status.STATUS_COMMITTED;
 	}
 
 	/**
 	 * Does the status code obtained from the given {@link UserTransaction} indicate a commit?
 	 *
 	 * @param userTransaction The {@link UserTransaction} whose status is to be checked
 	 *
 	 * @return True if the transaction indicates commit; false otherwise.
 	 */
 	public static boolean isCommitted(UserTransaction userTransaction) {
 		return isCommitted( getStatus( userTransaction ) );
 	}
 
 	/**
 	 * Does the status code obtained from the given {@link TransactionManager} indicate a commit?
 	 *
 	 * @param transactionManager The {@link TransactionManager} whose status is to be checked
 	 *
 	 * @return True if the transaction indicates commit; false otherwise.
 	 */
 	public static boolean isCommitted(TransactionManager transactionManager) {
 		return isCommitted( getStatus( transactionManager ) );
 	}
 
 	/**
 	 * Does the given status code indicate the transaction has been marked for rollback?
 	 *
 	 * @param status The transaction status code to check
 	 *
 	 * @return True if the code indicates a roll back; false otherwise.
 	 */
 	@SuppressWarnings( {"UnusedDeclaration"})
 	public static boolean isMarkedForRollback(int status) {
 		return status == Status.STATUS_MARKED_ROLLBACK;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/engine/transaction/jta/platform/internal/JBossAppServerJtaPlatform.java b/hibernate-core/src/main/java/org/hibernate/engine/transaction/jta/platform/internal/JBossAppServerJtaPlatform.java
index 77c5a43afc..e6e5d5a517 100644
--- a/hibernate-core/src/main/java/org/hibernate/engine/transaction/jta/platform/internal/JBossAppServerJtaPlatform.java
+++ b/hibernate-core/src/main/java/org/hibernate/engine/transaction/jta/platform/internal/JBossAppServerJtaPlatform.java
@@ -1,81 +1,81 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.engine.transaction.jta.platform.internal;
 
 import javax.transaction.TransactionManager;
 import javax.transaction.UserTransaction;
 
 import org.hibernate.engine.jndi.JndiException;
 
 /**
  * JtaPlatform definition for JBoss Application Server.
  *
  * @author Steve Ebersole
  */
 public class JBossAppServerJtaPlatform extends AbstractJtaPlatform {
 	public static final String AS7_TM_NAME = "java:jboss/TransactionManager";
 	public static final String AS4_TM_NAME = "java:/TransactionManager";
-	public static final String JBOSS__UT_NAME = "java:jboss/UserTransaction";
+	public static final String JBOSS_UT_NAME = "java:jboss/UserTransaction";
 	public static final String UT_NAME = "java:comp/UserTransaction";
 
 	@Override
 	protected boolean canCacheUserTransactionByDefault() {
 		return true;
 	}
 
 	@Override
 	protected boolean canCacheTransactionManagerByDefault() {
 		return true;
 	}
 
 	@Override
 	protected TransactionManager locateTransactionManager() {
 		try {
 			return (TransactionManager) jndiService().locate( AS7_TM_NAME );
 		}
 		catch (JndiException jndiException) {
 			try {
 				return (TransactionManager) jndiService().locate( AS4_TM_NAME );
 			}
 			catch (JndiException jndiExceptionInner) {
 				throw new JndiException( "unable to find transaction manager", jndiException );
 			}
 		}
 	}
 
 	@Override
 	protected UserTransaction locateUserTransaction() {
 		try {
-			return (UserTransaction) jndiService().locate( JBOSS__UT_NAME );
+			return (UserTransaction) jndiService().locate( JBOSS_UT_NAME );
 		}
 		catch (JndiException jndiException) {
 			try {
 				return (UserTransaction) jndiService().locate( UT_NAME );
 			}
 			catch (JndiException jndiExceptionInner) {
 				throw new JndiException( "unable to find UserTransaction", jndiException );
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractLockUpgradeEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractLockUpgradeEventListener.java
index 134ff378ee..d8ba02df51 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractLockUpgradeEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractLockUpgradeEventListener.java
@@ -1,113 +1,116 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.internal;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.ObjectDeletedException;
 import org.hibernate.cache.spi.CacheKey;
 import org.hibernate.cache.spi.access.SoftLock;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.Status;
 import org.hibernate.event.spi.EventSource;
-import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 
 /**
  * A convenience base class for listeners that respond to requests to perform a
  * pessimistic lock upgrade on an entity.
  *
  * @author Gavin King
  */
-public class AbstractLockUpgradeEventListener extends AbstractReassociateEventListener {
-
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, AbstractLockUpgradeEventListener.class.getName() );
+public abstract class AbstractLockUpgradeEventListener extends AbstractReassociateEventListener {
+	private static final Logger log = CoreLogging.logger( AbstractLockUpgradeEventListener.class );
 
 	/**
 	 * Performs a pessimistic lock upgrade on a given entity, if needed.
 	 *
 	 * @param object The entity for which to upgrade the lock.
 	 * @param entry The entity's EntityEntry instance.
 	 * @param lockOptions contains the requested lock mode.
 	 * @param source The session which is the source of the event being processed.
 	 */
 	protected void upgradeLock(Object object, EntityEntry entry, LockOptions lockOptions, EventSource source) {
 
 		LockMode requestedLockMode = lockOptions.getLockMode();
 		if ( requestedLockMode.greaterThan( entry.getLockMode() ) ) {
 			// The user requested a "greater" (i.e. more restrictive) form of
 			// pessimistic lock
 
 			if ( entry.getStatus() != Status.MANAGED ) {
 				throw new ObjectDeletedException(
 						"attempted to lock a deleted instance",
 						entry.getId(),
 						entry.getPersister().getEntityName()
 				);
 			}
 
 			final EntityPersister persister = entry.getPersister();
 
-			if ( LOG.isTraceEnabled() ) {
-				LOG.tracev( "Locking {0} in mode: {1}", MessageHelper.infoString( persister, entry.getId(), source.getFactory() ), requestedLockMode );
+			if ( log.isTraceEnabled() ) {
+				log.tracev(
+						"Locking {0} in mode: {1}",
+						MessageHelper.infoString( persister, entry.getId(), source.getFactory() ),
+						requestedLockMode
+				);
 			}
 
 			final SoftLock lock;
 			final CacheKey ck;
 			if ( persister.hasCache() ) {
 				ck = source.generateCacheKey( entry.getId(), persister.getIdentifierType(), persister.getRootEntityName() );
 				lock = persister.getCacheAccessStrategy().lockItem( ck, entry.getVersion() );
 			}
 			else {
 				ck = null;
 				lock = null;
 			}
 
 			try {
 				if ( persister.isVersioned() && requestedLockMode == LockMode.FORCE  ) {
 					// todo : should we check the current isolation mode explicitly?
 					Object nextVersion = persister.forceVersionIncrement(
 							entry.getId(), entry.getVersion(), source
 					);
 					entry.forceLocked( object, nextVersion );
 				}
 				else {
 					persister.lock( entry.getId(), entry.getVersion(), object, lockOptions, source );
 				}
 				entry.setLockMode(requestedLockMode);
 			}
 			finally {
 				// the database now holds a lock + the object is flushed from the cache,
 				// so release the soft lock
 				if ( persister.hasCache() ) {
 					persister.getCacheAccessStrategy().unlockItem( ck, lock );
 				}
 			}
 
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractReassociateEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractReassociateEventListener.java
index 0a6b164522..d7af53d780 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractReassociateEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractReassociateEventListener.java
@@ -1,105 +1,107 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.internal;
 
 import java.io.Serializable;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.LockMode;
 import org.hibernate.engine.internal.Versioning;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.Status;
 import org.hibernate.event.spi.AbstractEvent;
 import org.hibernate.event.spi.EventSource;
-import org.hibernate.internal.CoreMessageLogger;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.TypeHelper;
 
 /**
  * A convenience base class for listeners that respond to requests to reassociate an entity
  * to a session ( such as through lock() or update() ).
  *
  * @author Gavin King
  */
-public class AbstractReassociateEventListener implements Serializable {
-
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, AbstractReassociateEventListener.class.getName() );
+public abstract class AbstractReassociateEventListener implements Serializable {
+	private static final Logger log = CoreLogging.logger( AbstractReassociateEventListener.class );
 
 	/**
 	 * Associates a given entity (either transient or associated with another session) to
 	 * the given session.
 	 *
 	 * @param event The event triggering the re-association
 	 * @param object The entity to be associated
 	 * @param id The id of the entity.
 	 * @param persister The entity's persister instance.
 	 *
 	 * @return An EntityEntry representing the entity within this session.
 	 */
 	protected final EntityEntry reassociate(AbstractEvent event, Object object, Serializable id, EntityPersister persister) {
 
-		if ( LOG.isTraceEnabled() ) {
-			LOG.tracev( "Reassociating transient instance: {0}", MessageHelper.infoString( persister, id, event.getSession().getFactory() ) );
+		if ( log.isTraceEnabled() ) {
+			log.tracev(
+					"Reassociating transient instance: {0}",
+					MessageHelper.infoString( persister, id, event.getSession().getFactory() )
+			);
 		}
 
 		final EventSource source = event.getSession();
 		final EntityKey key = source.generateEntityKey( id, persister );
 
 		source.getPersistenceContext().checkUniqueness( key, object );
 
 		//get a snapshot
 		Object[] values = persister.getPropertyValues( object );
 		TypeHelper.deepCopy(
 				values,
 				persister.getPropertyTypes(),
 				persister.getPropertyUpdateability(),
 				values,
 				source
 		);
 		Object version = Versioning.getVersion( values, persister );
 
 		EntityEntry newEntry = source.getPersistenceContext().addEntity(
 				object,
 				( persister.isMutable() ? Status.MANAGED : Status.READ_ONLY ),
 				values,
 				key,
 				version,
 				LockMode.NONE,
 				true,
 				persister,
 				false,
 				true //will be ignored, using the existing Entry instead
 		);
 
 		new OnLockVisitor( source, id, object ).process( object, persister );
 
 		persister.afterReassociate( object, source );
 
 		return newEntry;
 
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/internal/DefaultFlushEntityEventListener.java b/hibernate-core/src/main/java/org/hibernate/event/internal/DefaultFlushEntityEventListener.java
index f030d0390d..958c6e5110 100755
--- a/hibernate-core/src/main/java/org/hibernate/event/internal/DefaultFlushEntityEventListener.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/internal/DefaultFlushEntityEventListener.java
@@ -1,680 +1,679 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.internal;
 
 import java.io.Serializable;
 import java.util.Arrays;
 
 import org.hibernate.engine.spi.SelfDirtinessTracker;
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.CustomEntityDirtinessStrategy;
 import org.hibernate.HibernateException;
 import org.hibernate.Session;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.action.internal.DelayedPostInsertIdentifier;
 import org.hibernate.action.internal.EntityUpdateAction;
 import org.hibernate.engine.internal.Nullability;
 import org.hibernate.engine.internal.Versioning;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.spi.Status;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.event.spi.FlushEntityEvent;
 import org.hibernate.event.spi.FlushEntityEventListener;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.type.Type;
 
 /**
  * An event that occurs for each entity instance at flush time
  *
  * @author Gavin King
  */
 public class DefaultFlushEntityEventListener implements FlushEntityEventListener {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
-                                                                       DefaultFlushEntityEventListener.class.getName());
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( DefaultFlushEntityEventListener.class );
 
 	/**
 	 * make sure user didn't mangle the id
 	 */
 	public void checkId(Object object, EntityPersister persister, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( id != null && id instanceof DelayedPostInsertIdentifier ) {
 			// this is a situation where the entity id is assigned by a post-insert generator
 			// and was saved outside the transaction forcing it to be delayed
 			return;
 		}
 
 		if ( persister.canExtractIdOutOfEntity() ) {
 
 			Serializable oid = persister.getIdentifier( object, session );
 			if (id==null) {
 				throw new AssertionFailure("null id in " + persister.getEntityName() + " entry (don't flush the Session after an exception occurs)");
 			}
 			if ( !persister.getIdentifierType().isEqual( id, oid, session.getFactory() ) ) {
 				throw new HibernateException(
 						"identifier of an instance of " +
 						persister.getEntityName() +
 						" was altered from " + id +
 						" to " + oid
 					);
 			}
 		}
 
 	}
 
 	private void checkNaturalId(
 			EntityPersister persister,
 	        EntityEntry entry,
 	        Object[] current,
 	        Object[] loaded,
 	        SessionImplementor session) {
 		if ( persister.hasNaturalIdentifier() && entry.getStatus() != Status.READ_ONLY ) {
 			if ( ! persister.getEntityMetamodel().hasImmutableNaturalId() ) {
 				// SHORT-CUT: if the natural id is mutable (!immutable), no need to do the below checks
 				// EARLY EXIT!!!
 				return;
 			}
 
 			final int[] naturalIdentifierPropertiesIndexes = persister.getNaturalIdentifierProperties();
 			final Type[] propertyTypes = persister.getPropertyTypes();
 			final boolean[] propertyUpdateability = persister.getPropertyUpdateability();
 
 			final Object[] snapshot = loaded == null
 					? session.getPersistenceContext().getNaturalIdSnapshot( entry.getId(), persister )
 					: session.getPersistenceContext().getNaturalIdHelper().extractNaturalIdValues( loaded, persister );
 
 			for ( int i=0; i<naturalIdentifierPropertiesIndexes.length; i++ ) {
 				final int naturalIdentifierPropertyIndex = naturalIdentifierPropertiesIndexes[i];
 				if ( propertyUpdateability[ naturalIdentifierPropertyIndex ] ) {
 					// if the given natural id property is updatable (mutable), there is nothing to check
 					continue;
 				}
 
 				final Type propertyType = propertyTypes[naturalIdentifierPropertyIndex];
 				if ( ! propertyType.isEqual( current[naturalIdentifierPropertyIndex], snapshot[i] ) ) {
 					throw new HibernateException(
 							String.format(
 									"An immutable natural identifier of entity %s was altered from %s to %s",
 									persister.getEntityName(),
 									propertyTypes[naturalIdentifierPropertyIndex].toLoggableString(
 											snapshot[i],
 											session.getFactory()
 									),
 									propertyTypes[naturalIdentifierPropertyIndex].toLoggableString(
 											current[naturalIdentifierPropertyIndex],
 											session.getFactory()
 									)
 							)
 					);
 			   }
 			}
 		}
 	}
 
 	/**
 	 * Flushes a single entity's state to the database, by scheduling
 	 * an update action, if necessary
 	 */
 	public void onFlushEntity(FlushEntityEvent event) throws HibernateException {
 		final Object entity = event.getEntity();
 		final EntityEntry entry = event.getEntityEntry();
 		final EventSource session = event.getSession();
 		final EntityPersister persister = entry.getPersister();
 		final Status status = entry.getStatus();
 		final Type[] types = persister.getPropertyTypes();
 
 		final boolean mightBeDirty = entry.requiresDirtyCheck(entity);
 
 		final Object[] values = getValues( entity, entry, mightBeDirty, session );
 
 		event.setPropertyValues(values);
 
 		//TODO: avoid this for non-new instances where mightBeDirty==false
 		boolean substitute = wrapCollections( session, persister, types, values);
 
 		if ( isUpdateNecessary( event, mightBeDirty ) ) {
 			substitute = scheduleUpdate( event ) || substitute;
 		}
 
 		if ( status != Status.DELETED ) {
 			// now update the object .. has to be outside the main if block above (because of collections)
 			if (substitute) persister.setPropertyValues( entity, values );
 
 			// Search for collections by reachability, updating their role.
 			// We don't want to touch collections reachable from a deleted object
 			if ( persister.hasCollections() ) {
 				new FlushVisitor(session, entity).processEntityPropertyValues(values, types);
 			}
 		}
 
 	}
 
 	private Object[] getValues(Object entity, EntityEntry entry, boolean mightBeDirty, SessionImplementor session) {
 		final Object[] loadedState = entry.getLoadedState();
 		final Status status = entry.getStatus();
 		final EntityPersister persister = entry.getPersister();
 
 		final Object[] values;
 		if ( status == Status.DELETED ) {
 			//grab its state saved at deletion
 			values = entry.getDeletedState();
 		}
 		else if ( !mightBeDirty && loadedState!=null ) {
 			values = loadedState;
 		}
 		else {
 			checkId( entity, persister, entry.getId(), session );
 
 			// grab its current state
 			values = persister.getPropertyValues( entity );
 
 			checkNaturalId( persister, entry, values, loadedState, session );
 		}
 		return values;
 	}
 
 	private boolean wrapCollections(
 			EventSource session,
 			EntityPersister persister,
 			Type[] types,
 			Object[] values
 	) {
 		if ( persister.hasCollections() ) {
 
 			// wrap up any new collections directly referenced by the object
 			// or its components
 
 			// NOTE: we need to do the wrap here even if its not "dirty",
 			// because collections need wrapping but changes to _them_
 			// don't dirty the container. Also, for versioned data, we
 			// need to wrap before calling searchForDirtyCollections
 
 			WrapVisitor visitor = new WrapVisitor(session);
 			// substitutes into values by side-effect
 			visitor.processEntityPropertyValues(values, types);
 			return visitor.isSubstitutionRequired();
 		}
 		else {
 			return false;
 		}
 	}
 
 	private boolean isUpdateNecessary(final FlushEntityEvent event, final boolean mightBeDirty) {
 		final Status status = event.getEntityEntry().getStatus();
 		if ( mightBeDirty || status==Status.DELETED ) {
 			// compare to cached state (ignoring collections unless versioned)
 			dirtyCheck(event);
 			if ( isUpdateNecessary(event) ) {
 				return true;
 			}
 			else {
 				if ( event.getEntityEntry().getPersister().getInstrumentationMetadata().isInstrumented() ) {
 					event.getEntityEntry()
 							.getPersister()
 							.getInstrumentationMetadata()
 							.extractInterceptor( event.getEntity() )
 							.clearDirty();
 				}
 				event.getSession()
 						.getFactory()
 						.getCustomEntityDirtinessStrategy()
 						.resetDirty( event.getEntity(), event.getEntityEntry().getPersister(), event.getSession() );
 				return false;
 			}
 		}
 		else {
 			return hasDirtyCollections( event, event.getEntityEntry().getPersister(), status );
 		}
 	}
 
 	private boolean scheduleUpdate(final FlushEntityEvent event) {
 		final EntityEntry entry = event.getEntityEntry();
 		final EventSource session = event.getSession();
 		final Object entity = event.getEntity();
 		final Status status = entry.getStatus();
 		final EntityPersister persister = entry.getPersister();
 		final Object[] values = event.getPropertyValues();
 
 		if ( LOG.isTraceEnabled() ) {
 			if ( status == Status.DELETED ) {
 				if ( !persister.isMutable() ) {
 					LOG.tracev( "Updating immutable, deleted entity: {0}",
 							MessageHelper.infoString( persister, entry.getId(), session.getFactory() ) );
 				}
 				else if ( !entry.isModifiableEntity() )
 					LOG.tracev( "Updating non-modifiable, deleted entity: {0}",
 							MessageHelper.infoString( persister, entry.getId(), session.getFactory() ) );
 				else
 					LOG.tracev( "Updating deleted entity: ",
 							MessageHelper.infoString( persister, entry.getId(), session.getFactory() ) );
 			}
 			else
 				LOG.tracev( "Updating entity: {0}",
 						MessageHelper.infoString( persister, entry.getId(), session.getFactory() ) );
 		}
 
 		final boolean intercepted = !entry.isBeingReplicated() && handleInterception( event );
 
 		// increment the version number (if necessary)
 		final Object nextVersion = getNextVersion(event);
 
 		// if it was dirtied by a collection only
 		int[] dirtyProperties = event.getDirtyProperties();
 		if ( event.isDirtyCheckPossible() && dirtyProperties == null ) {
 			if ( ! intercepted && !event.hasDirtyCollection() ) {
 				throw new AssertionFailure( "dirty, but no dirty properties" );
 			}
 			dirtyProperties = ArrayHelper.EMPTY_INT_ARRAY;
 		}
 
 		// check nullability but do not doAfterTransactionCompletion command execute
 		// we'll use scheduled updates for that.
 		new Nullability(session).checkNullability( values, persister, true );
 
 		// schedule the update
 		// note that we intentionally do _not_ pass in currentPersistentState!
 		session.getActionQueue().addAction(
 				new EntityUpdateAction(
 						entry.getId(),
 						values,
 						dirtyProperties,
 						event.hasDirtyCollection(),
 						( status == Status.DELETED && ! entry.isModifiableEntity() ?
 								persister.getPropertyValues( entity ) :
 								entry.getLoadedState() ),
 						entry.getVersion(),
 						nextVersion,
 						entity,
 						entry.getRowId(),
 						persister,
 						session
 					)
 			);
 
 		return intercepted;
 	}
 
 	protected boolean handleInterception(FlushEntityEvent event) {
 		SessionImplementor session = event.getSession();
 		EntityEntry entry = event.getEntityEntry();
 		EntityPersister persister = entry.getPersister();
 		Object entity = event.getEntity();
 
 		//give the Interceptor a chance to modify property values
 		final Object[] values = event.getPropertyValues();
 		final boolean intercepted = invokeInterceptor( session, entity, entry, values, persister );
 
 		//now we might need to recalculate the dirtyProperties array
 		if ( intercepted && event.isDirtyCheckPossible() && !event.isDirtyCheckHandledByInterceptor() ) {
 			int[] dirtyProperties;
 			if ( event.hasDatabaseSnapshot() ) {
 				dirtyProperties = persister.findModified( event.getDatabaseSnapshot(), values, entity, session );
 			}
 			else {
 				dirtyProperties = persister.findDirty( values, entry.getLoadedState(), entity, session );
 			}
 			event.setDirtyProperties(dirtyProperties);
 		}
 
 		return intercepted;
 	}
 
 	protected boolean invokeInterceptor(
 			SessionImplementor session,
 			Object entity,
 			EntityEntry entry,
 			final Object[] values,
 			EntityPersister persister) {
 		return session.getInterceptor().onFlushDirty(
 				entity,
 				entry.getId(),
 				values,
 				entry.getLoadedState(),
 				persister.getPropertyNames(),
 				persister.getPropertyTypes()
 		);
 	}
 
 	/**
 	 * Convience method to retreive an entities next version value
 	 */
 	private Object getNextVersion(FlushEntityEvent event) throws HibernateException {
 
 		EntityEntry entry = event.getEntityEntry();
 		EntityPersister persister = entry.getPersister();
 		if ( persister.isVersioned() ) {
 
 			Object[] values = event.getPropertyValues();
 
 			if ( entry.isBeingReplicated() ) {
 				return Versioning.getVersion(values, persister);
 			}
 			else {
 				int[] dirtyProperties = event.getDirtyProperties();
 
 				final boolean isVersionIncrementRequired = isVersionIncrementRequired(
 						event,
 						entry,
 						persister,
 						dirtyProperties
 					);
 
 				final Object nextVersion = isVersionIncrementRequired ?
 						Versioning.increment( entry.getVersion(), persister.getVersionType(), event.getSession() ) :
 						entry.getVersion(); //use the current version
 
 				Versioning.setVersion(values, nextVersion, persister);
 
 				return nextVersion;
 			}
 		}
 		else {
 			return null;
 		}
 
 	}
 
 	private boolean isVersionIncrementRequired(
 			FlushEntityEvent event,
 			EntityEntry entry,
 			EntityPersister persister,
 			int[] dirtyProperties
 	) {
 		final boolean isVersionIncrementRequired = entry.getStatus()!=Status.DELETED && (
 				dirtyProperties==null ||
 				Versioning.isVersionIncrementRequired(
 						dirtyProperties,
 						event.hasDirtyCollection(),
 						persister.getPropertyVersionability()
 				)
 			);
 		return isVersionIncrementRequired;
 	}
 
 	/**
 	 * Performs all necessary checking to determine if an entity needs an SQL update
 	 * to synchronize its state to the database. Modifies the event by side-effect!
 	 * Note: this method is quite slow, avoid calling if possible!
 	 */
 	protected final boolean isUpdateNecessary(FlushEntityEvent event) throws HibernateException {
 
 		EntityPersister persister = event.getEntityEntry().getPersister();
 		Status status = event.getEntityEntry().getStatus();
 
 		if ( !event.isDirtyCheckPossible() ) {
 			return true;
 		}
 		else {
 
 			int[] dirtyProperties = event.getDirtyProperties();
 			if ( dirtyProperties!=null && dirtyProperties.length!=0 ) {
 				return true; //TODO: suck into event class
 			}
 			else {
 				return hasDirtyCollections( event, persister, status );
 			}
 
 		}
 	}
 
 	private boolean hasDirtyCollections(FlushEntityEvent event, EntityPersister persister, Status status) {
 		if ( isCollectionDirtyCheckNecessary(persister, status ) ) {
 			DirtyCollectionSearchVisitor visitor = new DirtyCollectionSearchVisitor(
 					event.getSession(),
 					persister.getPropertyVersionability()
 				);
 			visitor.processEntityPropertyValues( event.getPropertyValues(), persister.getPropertyTypes() );
 			boolean hasDirtyCollections = visitor.wasDirtyCollectionFound();
 			event.setHasDirtyCollection(hasDirtyCollections);
 			return hasDirtyCollections;
 		}
 		else {
 			return false;
 		}
 	}
 
 	private boolean isCollectionDirtyCheckNecessary(EntityPersister persister, Status status) {
 		return ( status == Status.MANAGED || status == Status.READ_ONLY ) &&
 				persister.isVersioned() &&
 				persister.hasCollections();
 	}
 
 	/**
 	 * Perform a dirty check, and attach the results to the event
 	 */
 	protected void dirtyCheck(final FlushEntityEvent event) throws HibernateException {
 
 		final Object entity = event.getEntity();
 		final Object[] values = event.getPropertyValues();
 		final SessionImplementor session = event.getSession();
 		final EntityEntry entry = event.getEntityEntry();
 		final EntityPersister persister = entry.getPersister();
 		final Serializable id = entry.getId();
 		final Object[] loadedState = entry.getLoadedState();
 
 		int[] dirtyProperties = session.getInterceptor().findDirty(
 				entity,
 				id,
 				values,
 				loadedState,
 				persister.getPropertyNames(),
 				persister.getPropertyTypes()
 		);
 
 		if ( dirtyProperties == null ) {
             if(entity instanceof SelfDirtinessTracker) {
                 if(((SelfDirtinessTracker) entity).$$_hibernate_hasDirtyAttributes()) {
                    dirtyProperties = persister.resolveAttributeIndexes(((SelfDirtinessTracker) entity).$$_hibernate_getDirtyAttributes());
                 }
             }
             else {
                 // see if the custom dirtiness strategy can tell us...
                 class DirtyCheckContextImpl implements CustomEntityDirtinessStrategy.DirtyCheckContext {
-                    int[] found = null;
+                    int[] found;
                     @Override
                     public void doDirtyChecking(CustomEntityDirtinessStrategy.AttributeChecker attributeChecker) {
                         found = new DirtyCheckAttributeInfoImpl( event ).visitAttributes( attributeChecker );
                         if ( found != null && found.length == 0 ) {
                             found = null;
                         }
                     }
                 }
                 DirtyCheckContextImpl context = new DirtyCheckContextImpl();
                 session.getFactory().getCustomEntityDirtinessStrategy().findDirty(
                         entity,
                         persister,
                         (Session) session,
                         context
                 );
                 dirtyProperties = context.found;
             }
 		}
 
 		event.setDatabaseSnapshot(null);
 
 		final boolean interceptorHandledDirtyCheck;
 		boolean cannotDirtyCheck;
 
 		if ( dirtyProperties==null ) {
 			// Interceptor returned null, so do the dirtycheck ourself, if possible
 			try {
 				session.getEventListenerManager().dirtyCalculationStart();
 
 				interceptorHandledDirtyCheck = false;
 				// object loaded by update()
 				cannotDirtyCheck = loadedState==null;
 				if ( !cannotDirtyCheck ) {
 					// dirty check against the usual snapshot of the entity
 					dirtyProperties = persister.findDirty( values, loadedState, entity, session );
 				}
 				else if ( entry.getStatus() == Status.DELETED && ! event.getEntityEntry().isModifiableEntity() ) {
 					// A non-modifiable (e.g., read-only or immutable) entity needs to be have
 					// references to transient entities set to null before being deleted. No other
 					// fields should be updated.
 					if ( values != entry.getDeletedState() ) {
 						throw new IllegalStateException(
 								"Entity has status Status.DELETED but values != entry.getDeletedState"
 						);
 					}
 					// Even if loadedState == null, we can dirty-check by comparing currentState and
 					// entry.getDeletedState() because the only fields to be updated are those that
 					// refer to transient entities that are being set to null.
 					// - currentState contains the entity's current property values.
 					// - entry.getDeletedState() contains the entity's current property values with
 					//   references to transient entities set to null.
 					// - dirtyProperties will only contain properties that refer to transient entities
 					final Object[] currentState = persister.getPropertyValues( event.getEntity() );
 					dirtyProperties = persister.findDirty( entry.getDeletedState(), currentState, entity, session );
 					cannotDirtyCheck = false;
 				}
 				else {
 					// dirty check against the database snapshot, if possible/necessary
 					final Object[] databaseSnapshot = getDatabaseSnapshot(session, persister, id);
 					if ( databaseSnapshot != null ) {
 						dirtyProperties = persister.findModified(databaseSnapshot, values, entity, session);
 						cannotDirtyCheck = false;
 						event.setDatabaseSnapshot(databaseSnapshot);
 					}
 				}
 			}
 			finally {
 				session.getEventListenerManager().dirtyCalculationEnd( dirtyProperties != null );
 			}
 		}
 		else {
 			// the Interceptor handled the dirty checking
 			cannotDirtyCheck = false;
 			interceptorHandledDirtyCheck = true;
 		}
 
 		logDirtyProperties( id, dirtyProperties, persister );
 
 		event.setDirtyProperties(dirtyProperties);
 		event.setDirtyCheckHandledByInterceptor(interceptorHandledDirtyCheck);
 		event.setDirtyCheckPossible(!cannotDirtyCheck);
 
 	}
 
 	private class DirtyCheckAttributeInfoImpl implements CustomEntityDirtinessStrategy.AttributeInformation {
 		private final FlushEntityEvent event;
 		private final EntityPersister persister;
 		private final int numberOfAttributes;
-		private int index = 0;
+		private int index;
 
 		private DirtyCheckAttributeInfoImpl(FlushEntityEvent event) {
 			this.event = event;
 			this.persister = event.getEntityEntry().getPersister();
 			this.numberOfAttributes = persister.getPropertyNames().length;
 		}
 
 		@Override
 		public EntityPersister getContainingPersister() {
 			return persister;
 		}
 
 		@Override
 		public int getAttributeIndex() {
 			return index;
 		}
 
 		@Override
 		public String getName() {
 			return persister.getPropertyNames()[ index ];
 		}
 
 		@Override
 		public Type getType() {
 			return persister.getPropertyTypes()[ index ];
 		}
 
 		@Override
 		public Object getCurrentValue() {
 			return event.getPropertyValues()[ index ];
 		}
 
 		Object[] databaseSnapshot;
 
 		@Override
 		public Object getLoadedValue() {
 			if ( databaseSnapshot == null ) {
 				databaseSnapshot = getDatabaseSnapshot( event.getSession(), persister, event.getEntityEntry().getId() );
 			}
 			return databaseSnapshot[ index ];
 		}
 
 		public int[] visitAttributes(CustomEntityDirtinessStrategy.AttributeChecker attributeChecker) {
 			databaseSnapshot = null;
 			index = 0;
 
 			final int[] indexes = new int[ numberOfAttributes ];
 			int count = 0;
 			for ( ; index < numberOfAttributes; index++ ) {
 				if ( attributeChecker.isDirty( this ) ) {
 					indexes[ count++ ] = index;
 				}
 			}
 			return Arrays.copyOf( indexes, count );
 		}
 	}
 
 	private void logDirtyProperties(Serializable id, int[] dirtyProperties, EntityPersister persister) {
 		if ( dirtyProperties != null && dirtyProperties.length > 0 && LOG.isTraceEnabled() ) {
 			final String[] allPropertyNames = persister.getPropertyNames();
 			final String[] dirtyPropertyNames = new String[ dirtyProperties.length ];
 			for ( int i = 0; i < dirtyProperties.length; i++ ) {
 				dirtyPropertyNames[i] = allPropertyNames[ dirtyProperties[i]];
 			}
 			LOG.tracev( "Found dirty properties [{0}] : {1}",
 					MessageHelper.infoString( persister.getEntityName(), id ),
 					dirtyPropertyNames );
 		}
 	}
 
 	private Object[] getDatabaseSnapshot(SessionImplementor session, EntityPersister persister, Serializable id) {
 		if ( persister.isSelectBeforeUpdateRequired() ) {
 			Object[] snapshot = session.getPersistenceContext()
 					.getDatabaseSnapshot(id, persister);
 			if (snapshot==null) {
 				//do we even really need this? the update will fail anyway....
 				if ( session.getFactory().getStatistics().isStatisticsEnabled() ) {
 					session.getFactory().getStatisticsImplementor()
 							.optimisticFailure( persister.getEntityName() );
 				}
 				throw new StaleObjectStateException( persister.getEntityName(), id );
 			}
 			return snapshot;
 		}
 		// TODO: optimize away this lookup for entities w/o unsaved-value="undefined"
 		final EntityKey entityKey = session.generateEntityKey( id, persister );
 		return session.getPersistenceContext().getCachedDatabaseSnapshot( entityKey );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/internal/DirtyCollectionSearchVisitor.java b/hibernate-core/src/main/java/org/hibernate/event/internal/DirtyCollectionSearchVisitor.java
index 283d4bb050..eeeea7f0cd 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/internal/DirtyCollectionSearchVisitor.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/internal/DirtyCollectionSearchVisitor.java
@@ -1,88 +1,88 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.internal;
 
 import org.hibernate.HibernateException;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.type.CollectionType;
 
 /**
  * Do we have a dirty collection here?
  * 1. if it is a new application-instantiated collection, return true (does not occur anymore!)
  * 2. if it is a component, recurse
  * 3. if it is a wrappered collection, ask the collection entry
  *
  * @author Gavin King
  */
 public class DirtyCollectionSearchVisitor extends AbstractVisitor {
 
-	private boolean dirty = false;
+	private boolean dirty;
 	private boolean[] propertyVersionability;
 
 	DirtyCollectionSearchVisitor(EventSource session, boolean[] propertyVersionability) {
 		super(session);
 		this.propertyVersionability = propertyVersionability;
 	}
 
 	boolean wasDirtyCollectionFound() {
 		return dirty;
 	}
 
 	Object processCollection(Object collection, CollectionType type)
 		throws HibernateException {
 
 		if (collection!=null) {
 
 			SessionImplementor session = getSession();
 
 			final PersistentCollection persistentCollection;
 			if ( type.isArrayType() ) {
 				 persistentCollection = session.getPersistenceContext().getCollectionHolder(collection);
 				// if no array holder we found an unwrappered array (this can't occur,
 				// because we now always call wrap() before getting to here)
 				// return (ah==null) ? true : searchForDirtyCollections(ah, type);
 			}
 			else {
 				// if not wrappered yet, its dirty (this can't occur, because
 				// we now always call wrap() before getting to here)
 				// return ( ! (obj instanceof PersistentCollection) ) ?
 				//true : searchForDirtyCollections( (PersistentCollection) obj, type );
 				persistentCollection = (PersistentCollection) collection;
 			}
 
 			if ( persistentCollection.isDirty() ) { //we need to check even if it was not initialized, because of delayed adds!
 				dirty=true;
 				return null; //NOTE: EARLY EXIT!
 			}
 		}
 
 		return null;
 	}
 
 	boolean includeEntityProperty(Object[] values, int i) {
 		return propertyVersionability[i] && super.includeEntityProperty(values, i);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/internal/WrapVisitor.java b/hibernate-core/src/main/java/org/hibernate/event/internal/WrapVisitor.java
index 139012248b..7d0e15eab6 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/internal/WrapVisitor.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/internal/WrapVisitor.java
@@ -1,164 +1,164 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.internal;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.EntityMode;
 import org.hibernate.HibernateException;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.event.spi.EventSource;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.Type;
 
 /**
  * Wrap collections in a Hibernate collection
  * wrapper.
  * @author Gavin King
  */
 public class WrapVisitor extends ProxyVisitor {
+    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( WrapVisitor.class );
 
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, WrapVisitor.class.getName());
-
-	boolean substitute = false;
+	boolean substitute;
 
 	boolean isSubstitutionRequired() {
 		return substitute;
 	}
 
 	WrapVisitor(EventSource session) {
 		super(session);
 	}
 
 	@Override
     Object processCollection(Object collection, CollectionType collectionType)
 	throws HibernateException {
 
 		if ( collection!=null && (collection instanceof PersistentCollection) ) {
 
 			final SessionImplementor session = getSession();
 			PersistentCollection coll = (PersistentCollection) collection;
 			if ( coll.setCurrentSession(session) ) {
 				reattachCollection( coll, collectionType );
 			}
 			return null;
 
 		}
 		else {
 			return processArrayOrNewCollection(collection, collectionType);
 		}
 
 	}
 
 	final Object processArrayOrNewCollection(Object collection, CollectionType collectionType)
 	throws HibernateException {
 
 		final SessionImplementor session = getSession();
 
 		if (collection==null) {
 			//do nothing
 			return null;
 		}
 		else {
 			CollectionPersister persister = session.getFactory().getCollectionPersister( collectionType.getRole() );
 
 			final PersistenceContext persistenceContext = session.getPersistenceContext();
 			//TODO: move into collection type, so we can use polymorphism!
 			if ( collectionType.hasHolder() ) {
 
 				if (collection==CollectionType.UNFETCHED_COLLECTION) return null;
 
 				PersistentCollection ah = persistenceContext.getCollectionHolder(collection);
 				if (ah==null) {
 					ah = collectionType.wrap(session, collection);
 					persistenceContext.addNewCollection( persister, ah );
 					persistenceContext.addCollectionHolder(ah);
 				}
 				return null;
 			}
 			else {
 
 				PersistentCollection persistentCollection = collectionType.wrap(session, collection);
 				persistenceContext.addNewCollection( persister, persistentCollection );
 
 				if ( LOG.isTraceEnabled() ) {
 					LOG.tracev( "Wrapped collection in role: {0}", collectionType.getRole() );
 				}
 
 				return persistentCollection; //Force a substitution!
 
 			}
 
 		}
 
 	}
 
 	@Override
     void processValue(int i, Object[] values, Type[] types) {
 		Object result = processValue( values[i], types[i] );
 		if (result!=null) {
 			substitute = true;
 			values[i] = result;
 		}
 	}
 
 	@Override
     Object processComponent(Object component, CompositeType componentType)
 	throws HibernateException {
 
 		if (component!=null) {
 			Object[] values = componentType.getPropertyValues( component, getSession() );
 			Type[] types = componentType.getSubtypes();
 			boolean substituteComponent = false;
 			for ( int i=0; i<types.length; i++ ) {
 				Object result = processValue( values[i], types[i] );
 				if (result!=null) {
 					values[i] = result;
 					substituteComponent = true;
 				}
 			}
 			if (substituteComponent) {
 				componentType.setPropertyValues( component, values, EntityMode.POJO );
 			}
 		}
 
 		return null;
 	}
 
 	@Override
     void process(Object object, EntityPersister persister) throws HibernateException {
 		final Object[] values = persister.getPropertyValues( object );
 		final Type[] types = persister.getPropertyTypes();
 		processEntityPropertyValues( values, types );
 		if ( isSubstitutionRequired() ) {
 			persister.setPropertyValues( object, values );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/event/spi/EventType.java b/hibernate-core/src/main/java/org/hibernate/event/spi/EventType.java
index 13f25db8a0..1445dd9822 100644
--- a/hibernate-core/src/main/java/org/hibernate/event/spi/EventType.java
+++ b/hibernate-core/src/main/java/org/hibernate/event/spi/EventType.java
@@ -1,172 +1,172 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.event.spi;
 
 import java.lang.reflect.Field;
 import java.security.AccessController;
 import java.security.PrivilegedAction;
 import java.util.Collection;
 import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 
 /**
  * Enumeration of the recognized types of events, including meta-information about each.
  *
  * @author Steve Ebersole
  */
 public class EventType<T> {
 	public static final EventType<LoadEventListener> LOAD = create( "load", LoadEventListener.class );
 	public static final EventType<ResolveNaturalIdEventListener> RESOLVE_NATURAL_ID = create( "resolve-natural-id", ResolveNaturalIdEventListener.class );
 
 	public static final EventType<InitializeCollectionEventListener> INIT_COLLECTION = create( "load-collection", InitializeCollectionEventListener.class );
 
 	public static final EventType<SaveOrUpdateEventListener> SAVE_UPDATE = create( "save-update", SaveOrUpdateEventListener.class );
 	public static final EventType<SaveOrUpdateEventListener> UPDATE = create( "update", SaveOrUpdateEventListener.class );
 	public static final EventType<SaveOrUpdateEventListener> SAVE = create( "save", SaveOrUpdateEventListener.class );
 	public static final EventType<PersistEventListener> PERSIST = create( "create", PersistEventListener.class );
 	public static final EventType<PersistEventListener> PERSIST_ONFLUSH = create( "create-onflush", PersistEventListener.class );
 
 	public static final EventType<MergeEventListener> MERGE = create( "merge", MergeEventListener.class );
 
 	public static final EventType<DeleteEventListener> DELETE = create( "delete", DeleteEventListener.class );
 
 	public static final EventType<ReplicateEventListener> REPLICATE = create( "replicate", ReplicateEventListener.class );
 
 	public static final EventType<FlushEventListener> FLUSH = create( "flush", FlushEventListener.class );
 	public static final EventType<AutoFlushEventListener> AUTO_FLUSH = create( "auto-flush", AutoFlushEventListener.class );
 	public static final EventType<DirtyCheckEventListener> DIRTY_CHECK = create( "dirty-check", DirtyCheckEventListener.class );
 	public static final EventType<FlushEntityEventListener> FLUSH_ENTITY = create( "flush-entity", FlushEntityEventListener.class );
 
 	public static final EventType<ClearEventListener> CLEAR = create( "clear", ClearEventListener.class );
 	public static final EventType<EvictEventListener> EVICT = create( "evict", EvictEventListener.class );
 
 	public static final EventType<LockEventListener> LOCK = create( "lock", LockEventListener.class );
 
 	public static final EventType<RefreshEventListener> REFRESH = create( "refresh", RefreshEventListener.class );
 
 	public static final EventType<PreLoadEventListener> PRE_LOAD = create( "pre-load", PreLoadEventListener.class );
 	public static final EventType<PreDeleteEventListener> PRE_DELETE = create( "pre-delete", PreDeleteEventListener.class );
 	public static final EventType<PreUpdateEventListener> PRE_UPDATE = create( "pre-update", PreUpdateEventListener.class );
 	public static final EventType<PreInsertEventListener> PRE_INSERT = create( "pre-insert", PreInsertEventListener.class );
 
 	public static final EventType<PostLoadEventListener> POST_LOAD = create( "post-load", PostLoadEventListener.class );
 	public static final EventType<PostDeleteEventListener> POST_DELETE = create( "post-delete", PostDeleteEventListener.class );
 	public static final EventType<PostUpdateEventListener> POST_UPDATE = create( "post-update", PostUpdateEventListener.class );
 	public static final EventType<PostInsertEventListener> POST_INSERT = create( "post-insert", PostInsertEventListener.class );
 
 	public static final EventType<PostDeleteEventListener> POST_COMMIT_DELETE = create( "post-commit-delete", PostDeleteEventListener.class );
 	public static final EventType<PostUpdateEventListener> POST_COMMIT_UPDATE = create( "post-commit-update", PostUpdateEventListener.class );
 	public static final EventType<PostInsertEventListener> POST_COMMIT_INSERT = create( "post-commit-insert", PostInsertEventListener.class );
 
 	public static final EventType<PreCollectionRecreateEventListener> PRE_COLLECTION_RECREATE = create( "pre-collection-recreate", PreCollectionRecreateEventListener.class );
 	public static final EventType<PreCollectionRemoveEventListener> PRE_COLLECTION_REMOVE = create( "pre-collection-remove", PreCollectionRemoveEventListener.class );
 	public static final EventType<PreCollectionUpdateEventListener> PRE_COLLECTION_UPDATE = create( "pre-collection-update", PreCollectionUpdateEventListener.class );
 
 	public static final EventType<PostCollectionRecreateEventListener> POST_COLLECTION_RECREATE = create( "post-collection-recreate", PostCollectionRecreateEventListener.class );
 	public static final EventType<PostCollectionRemoveEventListener> POST_COLLECTION_REMOVE = create( "post-collection-remove", PostCollectionRemoveEventListener.class );
 	public static final EventType<PostCollectionUpdateEventListener> POST_COLLECTION_UPDATE = create( "post-collection-update", PostCollectionUpdateEventListener.class );
 
 
 	private static <T> EventType<T> create(String name, Class<T> listenerClass) {
 		return new EventType<T>( name, listenerClass );
 	}
 
 	/**
 	 * Maintain a map of {@link EventType} instances keyed by name for lookup by name as well as {@link #values()}
 	 * resolution.
 	 */
-	public static final Map<String,EventType> eventTypeByNameMap = AccessController.doPrivileged(
+	private static final Map<String,EventType> EVENT_TYPE_BY_NAME_MAP = AccessController.doPrivileged(
 			new PrivilegedAction<Map<String, EventType>>() {
 				@Override
 				public Map<String, EventType> run() {
 					final Map<String, EventType> typeByNameMap = new HashMap<String, EventType>();
 					for ( Field field : EventType.class.getDeclaredFields() ) {
 						if ( EventType.class.isAssignableFrom( field.getType() ) ) {
 							try {
 								final EventType typeField = (EventType) field.get( null );
 								typeByNameMap.put( typeField.eventName(), typeField );
 							}
 							catch (Exception t) {
 								throw new HibernateException( "Unable to initialize EventType map", t );
 							}
 						}
 					}
 					return typeByNameMap;
 				}
 			}
 	);
 
 	/**
 	 * Find an {@link EventType} by its name
 	 *
 	 * @param eventName The name
 	 *
 	 * @return The {@link EventType} instance.
 	 *
 	 * @throws HibernateException If eventName is null, or if eventName does not correlate to any known event type.
 	 */
 	public static EventType resolveEventTypeByName(final String eventName) {
 		if ( eventName == null ) {
 			throw new HibernateException( "event name to resolve cannot be null" );
 		}
-		final EventType eventType = eventTypeByNameMap.get( eventName );
+		final EventType eventType = EVENT_TYPE_BY_NAME_MAP.get( eventName );
 		if ( eventType == null ) {
 			throw new HibernateException( "Unable to locate proper event type for event name [" + eventName + "]" );
 		}
 		return eventType;
 	}
 
 	/**
 	 * Get a collection of all {@link EventType} instances.
 	 *
 	 * @return All {@link EventType} instances
 	 */
 	public static Collection<EventType> values() {
-		return eventTypeByNameMap.values();
+		return EVENT_TYPE_BY_NAME_MAP.values();
 	}
 
 
 	private final String eventName;
 	private final Class<? extends T> baseListenerInterface;
 
 	private EventType(String eventName, Class<? extends T> baseListenerInterface) {
 		this.eventName = eventName;
 		this.baseListenerInterface = baseListenerInterface;
 	}
 
 	public String eventName() {
 		return eventName;
 	}
 
 	public Class baseListenerInterface() {
 		return baseListenerInterface;
 	}
 
 	@Override
 	public String toString() {
 		return eventName();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlLexer.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlLexer.java
index 794eadd7fd..98b9aed667 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlLexer.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlLexer.java
@@ -1,81 +1,74 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.hql.internal.ast;
-import java.io.InputStream;
+
 import java.io.Reader;
 
+import antlr.Token;
+
 import org.hibernate.QueryException;
 import org.hibernate.hql.internal.antlr.HqlBaseLexer;
 
-import antlr.Token;
-
 /**
  * Custom lexer for the HQL grammar.  Extends the base lexer generated by ANTLR
  * in order to keep the grammar source file clean.
  */
 class HqlLexer extends HqlBaseLexer {
-	/**
-	 * A logger for this class. *
-	 */
-	private boolean possibleID = false;
 
-	public HqlLexer(InputStream in) {
-		super( in );
-	}
+	private boolean possibleID;
 
     public HqlLexer(Reader in) {
         super(in);
     }
 
+	@Override
 	public void setTokenObjectClass(String cl) {
 		this.tokenObjectClass = HqlToken.class;
 	}
 
+	@Override
 	protected void setPossibleID(boolean possibleID) {
 		this.possibleID = possibleID;
 	}
 
+	@Override
 	protected Token makeToken(int i) {
 		HqlToken token = ( HqlToken ) super.makeToken( i );
 		token.setPossibleID( possibleID );
 		possibleID = false;
 		return token;
 	}
 
-	public int testLiteralsTable(int i) {
-		int ttype = super.testLiteralsTable( i );
-		return ttype;
-	}
-
+	@Override
 	public void panic() {
 		//overriden to avoid System.exit
 		panic("CharScanner: panic");
 	}
 
+	@Override
 	public void panic(String s) {
 		//overriden to avoid System.exit
 		throw new QueryException(s);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlParser.java
index 5b71dca5f7..0778122e12 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlParser.java
@@ -1,445 +1,440 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast;
 
 import java.io.PrintStream;
 import java.io.PrintWriter;
 import java.io.StringReader;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
 
 import antlr.ASTPair;
 import antlr.MismatchedTokenException;
 import antlr.RecognitionException;
 import antlr.Token;
-import antlr.TokenStream;
 import antlr.TokenStreamException;
 import antlr.collections.AST;
-import org.jboss.logging.Logger;
 
 import org.hibernate.QueryException;
 import org.hibernate.hql.internal.antlr.HqlBaseParser;
 import org.hibernate.hql.internal.antlr.HqlTokenTypes;
 import org.hibernate.hql.internal.ast.util.ASTPrinter;
 import org.hibernate.hql.internal.ast.util.ASTUtil;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * Implements the semantic action methods defined in the HQL base parser to keep the grammar
  * source file a little cleaner.  Extends the parser class generated by ANTLR.
  *
  * @author Joshua Davis (pgmjsd@sourceforge.net)
  */
 public final class HqlParser extends HqlBaseParser {
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(
-			CoreMessageLogger.class,
-			HqlParser.class.getName()
-	);
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( HqlParser.class );
 
 	private final ParseErrorHandler parseErrorHandler;
 	private final ASTPrinter printer = getASTPrinter();
 
 	private static ASTPrinter getASTPrinter() {
 		return new ASTPrinter( org.hibernate.hql.internal.antlr.HqlTokenTypes.class );
 	}
 
 	/**
 	 * Get a HqlParser instance for the given HQL string.
 	 *
 	 * @param hql The HQL query string
 	 *
 	 * @return The parser.
 	 */
 	public static HqlParser getInstance(String hql) {
 		return new HqlParser( hql );
 	}
 
 	private HqlParser(String hql) {
 		// The fix for HHH-558...
 		super( new HqlLexer( new StringReader( hql ) ) );
 		parseErrorHandler = new ErrorCounter( hql );
 		// Create nodes that track line and column number.
 		setASTFactory( new HqlASTFactory() );
 	}
 
 
 	// handle trace logging ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-	private int traceDepth = 0;
+	private int traceDepth;
 
 	@Override
 	public void traceIn(String ruleName) {
 		if ( !LOG.isTraceEnabled() ) return;
 		if ( inputState.guessing > 0 ) return;
 		String prefix = StringHelper.repeat( '-', ( traceDepth++ * 2 ) ) + "-> ";
 		LOG.trace( prefix + ruleName );
 	}
 
 	@Override
 	public void traceOut(String ruleName) {
 		if ( !LOG.isTraceEnabled() ) return;
 		if ( inputState.guessing > 0 ) return;
 		String prefix = "<-" + StringHelper.repeat( '-', ( --traceDepth * 2 ) ) + " ";
 		LOG.trace( prefix + ruleName );
 	}
 
 	@Override
     public void reportError(RecognitionException e) {
 		parseErrorHandler.reportError( e ); // Use the delegate.
 	}
 
 	@Override
     public void reportError(String s) {
 		parseErrorHandler.reportError( s ); // Use the delegate.
 	}
 
 	@Override
     public void reportWarning(String s) {
 		parseErrorHandler.reportWarning( s );
 	}
 
 	public ParseErrorHandler getParseErrorHandler() {
 		return parseErrorHandler;
 	}
 
 	/**
 	 * Overrides the base behavior to retry keywords as identifiers.
 	 *
 	 * @param token The token.
 	 * @param ex    The recognition exception.
 	 * @return AST - The new AST.
 	 * @throws antlr.RecognitionException if the substitution was not possible.
 	 * @throws antlr.TokenStreamException if the substitution was not possible.
 	 */
 	@Override
     public AST handleIdentifierError(Token token, RecognitionException ex) throws RecognitionException, TokenStreamException {
 		// If the token can tell us if it could be an identifier...
 		if ( token instanceof HqlToken ) {
 			HqlToken hqlToken = ( HqlToken ) token;
 			// ... and the token could be an identifer and the error is
 			// a mismatched token error ...
 			if ( hqlToken.isPossibleID() && ( ex instanceof MismatchedTokenException ) ) {
 				MismatchedTokenException mte = ( MismatchedTokenException ) ex;
 				// ... and the expected token type was an identifier, then:
 				if ( mte.expecting == HqlTokenTypes.IDENT ) {
 					// Use the token as an identifier.
 					reportWarning( "Keyword  '"
 							+ token.getText()
 							+ "' is being interpreted as an identifier due to: " + mte.getMessage() );
 					// Add the token to the AST.
 					ASTPair currentAST = new ASTPair();
 					token.setType( HqlTokenTypes.WEIRD_IDENT );
 					astFactory.addASTChild( currentAST, astFactory.create( token ) );
 					consume();
-					AST identifierAST = currentAST.root;
-					return identifierAST;
+					return currentAST.root;
 				}
 			} // if
 		} // if
 		// Otherwise, handle the error normally.
 		return super.handleIdentifierError( token, ex );
 	}
 
 	/**
 	 * Returns an equivalent tree for (NOT (a relop b) ), for example:<pre>
 	 * (NOT (GT a b) ) => (LE a b)
 	 * </pre>
 	 *
 	 * @param x The sub tree to transform, the parent is assumed to be NOT.
 	 * @return AST - The equivalent sub-tree.
 	 */
 	@Override
     public AST negateNode(AST x) {
 		//TODO: switch statements are always evil! We already had bugs because
 		//      of forgotten token types. Use polymorphism for this!
 		switch ( x.getType() ) {
 			case OR:
 				x.setType(AND);
 				x.setText("{and}");
                 x.setFirstChild(negateNode( x.getFirstChild() ));
                 x.getFirstChild().setNextSibling(negateNode( x.getFirstChild().getNextSibling() ));
                 return x;
 			case AND:
 				x.setType(OR);
 				x.setText("{or}");
                 x.setFirstChild(negateNode( x.getFirstChild() ));
                 x.getFirstChild().setNextSibling(negateNode( x.getFirstChild().getNextSibling() ));
 				return x;
 			case EQ:
 				x.setType( NE );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (EQ a b) ) => (NE a b)
 			case NE:
 				x.setType( EQ );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (NE a b) ) => (EQ a b)
 			case GT:
 				x.setType( LE );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (GT a b) ) => (LE a b)
 			case LT:
 				x.setType( GE );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (LT a b) ) => (GE a b)
 			case GE:
 				x.setType( LT );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (GE a b) ) => (LT a b)
 			case LE:
 				x.setType( GT );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (LE a b) ) => (GT a b)
 			case LIKE:
 				x.setType( NOT_LIKE );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (LIKE a b) ) => (NOT_LIKE a b)
 			case NOT_LIKE:
 				x.setType( LIKE );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (NOT_LIKE a b) ) => (LIKE a b)
 			case IN:
 				x.setType( NOT_IN );
 				x.setText( "{not}" + x.getText() );
 				return x;
 			case NOT_IN:
 				x.setType( IN );
 				x.setText( "{not}" + x.getText() );
 				return x;
 			case IS_NULL:
 				x.setType( IS_NOT_NULL );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (IS_NULL a b) ) => (IS_NOT_NULL a b)
 			case IS_NOT_NULL:
 				x.setType( IS_NULL );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (IS_NOT_NULL a b) ) => (IS_NULL a b)
 			case BETWEEN:
 				x.setType( NOT_BETWEEN );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (BETWEEN a b) ) => (NOT_BETWEEN a b)
 			case NOT_BETWEEN:
 				x.setType( BETWEEN );
 				x.setText( "{not}" + x.getText() );
 				return x;	// (NOT (NOT_BETWEEN a b) ) => (BETWEEN a b)
 /* This can never happen because this rule will always eliminate the child NOT.
 			case NOT:
 				return x.getFirstChild();			// (NOT (NOT x) ) => (x)
 */
 			default:
 				AST not = super.negateNode( x );		// Just add a 'not' parent.
                 if ( not != x ) {
                    // relink the next sibling to the new 'not' parent
                     not.setNextSibling(x.getNextSibling());
                     x.setNextSibling(null);
                 }
                 return not;
 		}
 	}
 
 	/**
 	 * Post process equality expressions, clean up the subtree.
 	 *
 	 * @param x The equality expression.
 	 * @return AST - The clean sub-tree.
 	 */
 	@Override
     public AST processEqualityExpression(AST x) {
 		if ( x == null ) {
             LOG.processEqualityExpression();
 			return null;
 		}
 
 		int type = x.getType();
 		if ( type == EQ || type == NE ) {
 			boolean negated = type == NE;
 			if ( x.getNumberOfChildren() == 2 ) {
 				AST a = x.getFirstChild();
 				AST b = a.getNextSibling();
 				// (EQ NULL b) => (IS_NULL b)
 				if ( a.getType() == NULL && b.getType() != NULL ) {
 					return createIsNullParent( b, negated );
 				}
 				// (EQ a NULL) => (IS_NULL a)
 				else if ( b.getType() == NULL && a.getType() != NULL ) {
 					return createIsNullParent( a, negated );
 				}
 				else if ( b.getType() == EMPTY ) {
 					return processIsEmpty( a, negated );
 				}
 				else {
 					return x;
 				}
 			}
 			else {
 				return x;
 			}
 		}
 		else {
 			return x;
 		}
 	}
 
 	private AST createIsNullParent(AST node, boolean negated) {
 		node.setNextSibling( null );
 		int type = negated ? IS_NOT_NULL : IS_NULL;
 		String text = negated ? "is not null" : "is null";
 		return ASTUtil.createParent( astFactory, type, text, node );
 	}
 
 	private AST processIsEmpty(AST node, boolean negated) {
 		node.setNextSibling( null );
 		// NOTE: Because we're using ASTUtil.createParent(), the tree must be created from the bottom up.
 		// IS EMPTY x => (EXISTS (QUERY (SELECT_FROM (FROM x) ) ) )
 		AST ast = createSubquery( node );
 		ast = ASTUtil.createParent( astFactory, EXISTS, "exists", ast );
 		// Add NOT if it's negated.
 		if ( !negated ) {
 			ast = ASTUtil.createParent( astFactory, NOT, "not", ast );
 		}
 		return ast;
 	}
 
 	private AST createSubquery(AST node) {
 		AST ast = ASTUtil.createParent( astFactory, RANGE, "RANGE", node );
 		ast = ASTUtil.createParent( astFactory, FROM, "from", ast );
 		ast = ASTUtil.createParent( astFactory, SELECT_FROM, "SELECT_FROM", ast );
 		ast = ASTUtil.createParent( astFactory, QUERY, "QUERY", ast );
 		return ast;
 	}
 
 	public void showAst(AST ast, PrintStream out) {
 		showAst( ast, new PrintWriter( out ) );
 	}
 
 	private void showAst(AST ast, PrintWriter pw) {
 		printer.showAst( ast, pw );
 	}
 
 	@Override
     public void weakKeywords() throws TokenStreamException {
 
 		int t = LA( 1 );
 		switch ( t ) {
 			case ORDER:
 			case GROUP:
 				// Case 1: Multi token keywords GROUP BY and ORDER BY
 				// The next token ( LT(2) ) should be 'by'... otherwise, this is just an ident.
 				if ( LA( 2 ) != LITERAL_by ) {
 					LT( 1 ).setType( IDENT );
 					if ( LOG.isDebugEnabled() ) {
 						LOG.debugf( "weakKeywords() : new LT(1) token - %s", LT( 1 ) );
 					}
 				}
 				break;
 			default:
 				// Case 2: The current token is after FROM and before '.'.
 			if ( LA( 0 ) == FROM && t != IDENT && LA( 2 ) == DOT ) {
 				HqlToken hqlToken = (HqlToken) LT( 1 );
 				if ( hqlToken.isPossibleID() ) {
 					hqlToken.setType( IDENT );
 					if ( LOG.isDebugEnabled() ) {
 						LOG.debugf( "weakKeywords() : new LT(1) token - %s", LT( 1 ) );
 					}
 				}
 			}
 			break;
 		}
 	}
 
 	@Override
 	public void handleDotIdent() throws TokenStreamException {
 		// This handles HHH-354, where there is a strange property name in a where clause.
 		// If the lookahead contains a DOT then something that isn't an IDENT...
 		if ( LA( 1 ) == DOT && LA( 2 ) != IDENT ) {
 			// See if the second lookahead token can be an identifier.
 			HqlToken t = (HqlToken) LT( 2 );
 			if ( t.isPossibleID() )
 			{
 				// Set it!
 				LT( 2 ).setType( IDENT );
 				if ( LOG.isDebugEnabled() ) {
 					LOG.debugf( "handleDotIdent() : new LT(2) token - %s", LT( 1 ) );
 				}
 			}
 		}
 	}
 
 	@Override
     public void processMemberOf(Token n, AST p, ASTPair currentAST) {
 		// convert MEMBER OF to the equivalent IN ELEMENTS structure...
 		AST inNode = n == null ? astFactory.create( IN, "in" ) : astFactory.create( NOT_IN, "not in" );
 		astFactory.makeASTRoot( currentAST, inNode );
 
 		AST inListNode = astFactory.create( IN_LIST, "inList" );
 		inNode.addChild( inListNode );
 		AST elementsNode = astFactory.create( ELEMENTS, "elements" );
 		inListNode.addChild( elementsNode );
 		elementsNode.addChild( p );
 	}
 
 	private Map<String,Set<String>> treatMap;
 
 	@Override
 	protected void registerTreat(AST pathToTreat, AST treatAs) {
 		final String path = toPathText( pathToTreat );
 		final String subclassName = toPathText( treatAs );
 		LOG.debugf( "Registering discovered request to treat(%s as %s)", path, subclassName );
 
 		if ( treatMap == null ) {
 			treatMap = new HashMap<String, Set<String>>();
 		}
 
 		Set<String> subclassNames = treatMap.get( path );
 		if ( subclassNames == null ) {
 			subclassNames = new HashSet<String>();
 			treatMap.put( path, subclassNames );
 		}
 		subclassNames.add( subclassName );
 	}
 
 	private String toPathText(AST node) {
 		final String text = node.getText();
 		if ( text.equals( "." )
 				&& node.getFirstChild() != null
 				&& node.getFirstChild().getNextSibling() != null
 				&& node.getFirstChild().getNextSibling().getNextSibling() == null ) {
 			return toPathText( node.getFirstChild() ) + '.' + toPathText( node.getFirstChild().getNextSibling() );
 		}
 		return text;
 	}
 
 	public Map<String, Set<String>> getTreatMap() {
 		return treatMap == null ? Collections.<String, Set<String>>emptyMap() : treatMap;
 	}
 
 	static public void panic() {
 		//overriden to avoid System.exit
 		throw new QueryException("Parser: panic");
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlSqlWalker.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlSqlWalker.java
index ef7ed284d4..84cb94a237 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlSqlWalker.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlSqlWalker.java
@@ -1,1290 +1,1289 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Calendar;
 import java.util.Date;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
+import antlr.ASTFactory;
+import antlr.RecognitionException;
+import antlr.SemanticException;
+import antlr.collections.AST;
+
 import org.hibernate.HibernateException;
 import org.hibernate.QueryException;
 import org.hibernate.engine.internal.JoinSequence;
 import org.hibernate.engine.internal.ParameterBinder;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.hql.internal.antlr.HqlSqlBaseWalker;
 import org.hibernate.hql.internal.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.internal.antlr.HqlTokenTypes;
 import org.hibernate.hql.internal.antlr.SqlTokenTypes;
 import org.hibernate.hql.internal.ast.tree.AggregateNode;
 import org.hibernate.hql.internal.ast.tree.AssignmentSpecification;
 import org.hibernate.hql.internal.ast.tree.CollectionFunction;
 import org.hibernate.hql.internal.ast.tree.ConstructorNode;
 import org.hibernate.hql.internal.ast.tree.DeleteStatement;
 import org.hibernate.hql.internal.ast.tree.DotNode;
 import org.hibernate.hql.internal.ast.tree.FromClause;
 import org.hibernate.hql.internal.ast.tree.FromElement;
 import org.hibernate.hql.internal.ast.tree.FromElementFactory;
 import org.hibernate.hql.internal.ast.tree.FromReferenceNode;
 import org.hibernate.hql.internal.ast.tree.IdentNode;
 import org.hibernate.hql.internal.ast.tree.IndexNode;
 import org.hibernate.hql.internal.ast.tree.InsertStatement;
 import org.hibernate.hql.internal.ast.tree.IntoClause;
 import org.hibernate.hql.internal.ast.tree.MethodNode;
 import org.hibernate.hql.internal.ast.tree.OperatorNode;
 import org.hibernate.hql.internal.ast.tree.ParameterContainer;
 import org.hibernate.hql.internal.ast.tree.ParameterNode;
 import org.hibernate.hql.internal.ast.tree.QueryNode;
 import org.hibernate.hql.internal.ast.tree.ResolvableNode;
 import org.hibernate.hql.internal.ast.tree.RestrictableStatement;
 import org.hibernate.hql.internal.ast.tree.ResultVariableRefNode;
 import org.hibernate.hql.internal.ast.tree.SelectClause;
 import org.hibernate.hql.internal.ast.tree.SelectExpression;
 import org.hibernate.hql.internal.ast.tree.UpdateStatement;
 import org.hibernate.hql.internal.ast.util.ASTPrinter;
 import org.hibernate.hql.internal.ast.util.ASTUtil;
 import org.hibernate.hql.internal.ast.util.AliasGenerator;
 import org.hibernate.hql.internal.ast.util.JoinProcessor;
 import org.hibernate.hql.internal.ast.util.LiteralProcessor;
 import org.hibernate.hql.internal.ast.util.NodeTraverser;
 import org.hibernate.hql.internal.ast.util.SessionFactoryHelper;
 import org.hibernate.hql.internal.ast.util.SyntheticAndFactory;
 import org.hibernate.hql.spi.QueryTranslator;
 import org.hibernate.id.BulkInsertionCapableIdentifierGenerator;
 import org.hibernate.id.IdentifierGenerator;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.param.CollectionFilterKeyParameterSpecification;
 import org.hibernate.param.NamedParameterSpecification;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.param.PositionalParameterSpecification;
 import org.hibernate.param.VersionTypeSeedParameterSpecification;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinType;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.ComponentType;
 import org.hibernate.type.DbTimestampType;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 import org.hibernate.usertype.UserVersionType;
-import org.jboss.logging.Logger;
-
-import antlr.ASTFactory;
-import antlr.RecognitionException;
-import antlr.SemanticException;
-import antlr.collections.AST;
 
 /**
  * Implements methods used by the HQL->SQL tree transform grammar (a.k.a. the second phase).
  * <ul>
  * <li>Isolates the Hibernate API-specific code from the ANTLR generated code.</li>
  * <li>Handles the SQL fragments generated by the persisters in order to create the SELECT and FROM clauses,
  * taking into account the joins and projections that are implied by the mappings (persister/queryable).</li>
  * <li>Uses SqlASTFactory to create customized AST nodes.</li>
  * </ul>
  *
  * @see SqlASTFactory
  */
 public class HqlSqlWalker extends HqlSqlBaseWalker implements ErrorReporter, ParameterBinder.NamedParameterSource {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, HqlSqlWalker.class.getName());
+    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( HqlSqlWalker.class );
 
 	private final QueryTranslatorImpl queryTranslatorImpl;
 	private final HqlParser hqlParser;
 	private final SessionFactoryHelper sessionFactoryHelper;
 	private final Map tokenReplacements;
 	private final AliasGenerator aliasGenerator = new AliasGenerator();
 	private final LiteralProcessor literalProcessor;
 	private final ParseErrorHandler parseErrorHandler;
 	private final ASTPrinter printer;
 	private final String collectionFilterRole;
 
-	private FromClause currentFromClause = null;
+	private FromClause currentFromClause;
 	private SelectClause selectClause;
 
 	/**
 	 * Maps each top-level result variable to its SelectExpression;
 	 * (excludes result variables defined in subqueries)
 	 **/
 	private Map<String, SelectExpression> selectExpressionsByResultVariable = new HashMap<String, SelectExpression>();
 
 	private Set<Serializable> querySpaces = new HashSet<Serializable>();
 
 	private int parameterCount;
 	private Map namedParameters = new HashMap();
 	private ArrayList parameters = new ArrayList();
 	private int numberOfParametersInSetClause;
 	private int positionalParameterCount;
 
 	private ArrayList assignmentSpecifications = new ArrayList();
 
 	private JoinType impliedJoinType = JoinType.INNER_JOIN;
 
 	/**
 	 * Create a new tree transformer.
 	 *
 	 * @param qti Back pointer to the query translator implementation that is using this tree transform.
 	 * @param sfi The session factory implementor where the Hibernate mappings can be found.
 	 * @param parser A reference to the phase-1 parser
 	 * @param tokenReplacements Registers the token replacement map with the walker.  This map will
 	 * be used to substitute function names and constants.
 	 * @param collectionRole The collection role name of the collection used as the basis for the
 	 * filter, NULL if this is not a collection filter compilation.
 	 */
 	public HqlSqlWalker(
 			QueryTranslatorImpl qti,
 			SessionFactoryImplementor sfi,
 			HqlParser parser,
 			Map tokenReplacements,
 			String collectionRole) {
 		setASTFactory( new SqlASTFactory( this ) );
 		// Initialize the error handling delegate.
 		this.parseErrorHandler = new ErrorCounter( qti.getQueryString() );
 		this.queryTranslatorImpl = qti;
 		this.sessionFactoryHelper = new SessionFactoryHelper( sfi );
 		this.literalProcessor = new LiteralProcessor( this );
 		this.tokenReplacements = tokenReplacements;
 		this.collectionFilterRole = collectionRole;
 		this.hqlParser = parser;
 		this.printer = new ASTPrinter( SqlTokenTypes.class );
 	}
 
 	// handle trace logging ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-	private int traceDepth = 0;
+	private int traceDepth;
 
 	@Override
 	public void traceIn(String ruleName, AST tree) {
 		if ( !LOG.isTraceEnabled() ) return;
 		if ( inputState.guessing > 0 ) return;
 		String prefix = StringHelper.repeat( '-', ( traceDepth++ * 2 ) ) + "-> ";
 		String traceText = ruleName + " (" + buildTraceNodeName( tree ) + ")";
 		LOG.trace( prefix + traceText );
 	}
 
 	private String buildTraceNodeName(AST tree) {
 		return tree == null
 				? "???"
 				: tree.getText() + " [" + printer.getTokenTypeName( tree.getType() ) + "]";
 	}
 
 	@Override
 	public void traceOut(String ruleName, AST tree) {
 		if ( !LOG.isTraceEnabled() ) return;
 		if ( inputState.guessing > 0 ) return;
 		String prefix = "<-" + StringHelper.repeat( '-', ( --traceDepth * 2 ) ) + " ";
 		LOG.trace( prefix + ruleName );
 	}
 
 	@Override
     protected void prepareFromClauseInputTree(AST fromClauseInput) {
 		if ( !isSubQuery() ) {
 //			// inject param specifications to account for dynamic filter param values
 //			if ( ! getEnabledFilters().isEmpty() ) {
 //				Iterator filterItr = getEnabledFilters().values().iterator();
 //				while ( filterItr.hasNext() ) {
 //					FilterImpl filter = ( FilterImpl ) filterItr.next();
 //					if ( ! filter.getFilterDefinition().getParameterNames().isEmpty() ) {
 //						Iterator paramItr = filter.getFilterDefinition().getParameterNames().iterator();
 //						while ( paramItr.hasNext() ) {
 //							String parameterName = ( String ) paramItr.next();
 //							// currently param filters *only* work with single-column parameter types;
 //							// if that limitation is ever lifted, this logic will need to change to account for that
 //							ParameterNode collectionFilterKeyParameter = ( ParameterNode ) astFactory.create( PARAM, "?" );
 //							DynamicFilterParameterSpecification paramSpec = new DynamicFilterParameterSpecification(
 //									filter.getName(),
 //									parameterName,
 //									filter.getFilterDefinition().getParameterType( parameterName ),
 //									 positionalParameterCount++
 //							);
 //							collectionFilterKeyParameter.setHqlParameterSpecification( paramSpec );
 //							parameters.add( paramSpec );
 //						}
 //					}
 //				}
 //			}
 
 			if ( isFilter() ) {
                 // Handle collection-filter compilation.
 				// IMPORTANT NOTE: This is modifying the INPUT (HQL) tree, not the output tree!
 				QueryableCollection persister = sessionFactoryHelper.getCollectionPersister( collectionFilterRole );
 				Type collectionElementType = persister.getElementType();
 				if ( !collectionElementType.isEntityType() ) {
 					throw new QueryException( "collection of values in filter: this" );
 				}
 
 				String collectionElementEntityName = persister.getElementPersister().getEntityName();
 				ASTFactory inputAstFactory = hqlParser.getASTFactory();
 				AST fromElement = ASTUtil.create( inputAstFactory, HqlTokenTypes.FILTER_ENTITY, collectionElementEntityName );
 				ASTUtil.createSibling( inputAstFactory, HqlTokenTypes.ALIAS, "this", fromElement );
 				fromClauseInput.addChild( fromElement );
 				// Show the modified AST.
                 LOG.debug("prepareFromClauseInputTree() : Filter - Added 'this' as a from element...");
 				queryTranslatorImpl.showHqlAst( hqlParser.getAST() );
 
 				// Create a parameter specification for the collection filter...
 				Type collectionFilterKeyType = sessionFactoryHelper.requireQueryableCollection( collectionFilterRole ).getKeyType();
 				ParameterNode collectionFilterKeyParameter = ( ParameterNode ) astFactory.create( PARAM, "?" );
 				CollectionFilterKeyParameterSpecification collectionFilterKeyParameterSpec = new CollectionFilterKeyParameterSpecification(
 						collectionFilterRole, collectionFilterKeyType, positionalParameterCount++
 				);
 				collectionFilterKeyParameter.setHqlParameterSpecification( collectionFilterKeyParameterSpec );
 				parameters.add( collectionFilterKeyParameterSpec );
 			}
 		}
 	}
 
 	public boolean isFilter() {
 		return collectionFilterRole != null;
 	}
 
 	public String getCollectionFilterRole() {
 		return collectionFilterRole;
 	}
 
 	public SessionFactoryHelper getSessionFactoryHelper() {
 		return sessionFactoryHelper;
 	}
 
 	public Map getTokenReplacements() {
 		return tokenReplacements;
 	}
 
 	public AliasGenerator getAliasGenerator() {
 		return aliasGenerator;
 	}
 
 	public FromClause getCurrentFromClause() {
 		return currentFromClause;
 	}
 
 	public ParseErrorHandler getParseErrorHandler() {
 		return parseErrorHandler;
 	}
 
 	@Override
     public void reportError(RecognitionException e) {
 		parseErrorHandler.reportError( e ); // Use the delegate.
 	}
 
 	@Override
     public void reportError(String s) {
 		parseErrorHandler.reportError( s ); // Use the delegate.
 	}
 
 	@Override
     public void reportWarning(String s) {
 		parseErrorHandler.reportWarning( s );
 	}
 
 	/**
 	 * Returns the set of unique query spaces (a.k.a.
 	 * table names) that occurred in the query.
 	 *
 	 * @return A set of table names (Strings).
 	 */
 	public Set<Serializable> getQuerySpaces() {
 		return querySpaces;
 	}
 
 	@Override
     protected AST createFromElement(String path, AST alias, AST propertyFetch) throws SemanticException {
 		FromElement fromElement = currentFromClause.addFromElement( path, alias );
 		fromElement.setAllPropertyFetch(propertyFetch!=null);
 		return fromElement;
 	}
 
 	@Override
     protected AST createFromFilterElement(AST filterEntity, AST alias) throws SemanticException {
 		FromElement fromElement = currentFromClause.addFromElement( filterEntity.getText(), alias );
 		FromClause fromClause = fromElement.getFromClause();
 		QueryableCollection persister = sessionFactoryHelper.getCollectionPersister( collectionFilterRole );
 		// Get the names of the columns used to link between the collection
 		// owner and the collection elements.
 		String[] keyColumnNames = persister.getKeyColumnNames();
 		String fkTableAlias = persister.isOneToMany()
 				? fromElement.getTableAlias()
 				: fromClause.getAliasGenerator().createName( collectionFilterRole );
 		JoinSequence join = sessionFactoryHelper.createJoinSequence();
 		join.setRoot( persister, fkTableAlias );
 		if ( !persister.isOneToMany() ) {
 			join.addJoin( ( AssociationType ) persister.getElementType(),
 					fromElement.getTableAlias(),
 					JoinType.INNER_JOIN,
 					persister.getElementColumnNames( fkTableAlias ) );
 		}
 		join.addCondition( fkTableAlias, keyColumnNames, " = ?" );
 		fromElement.setJoinSequence( join );
 		fromElement.setFilter( true );
         LOG.debug("createFromFilterElement() : processed filter FROM element.");
 		return fromElement;
 	}
 
 	@Override
     protected void createFromJoinElement(
 	        AST path,
 	        AST alias,
 	        int joinType,
 	        AST fetchNode,
 	        AST propertyFetch,
 	        AST with) throws SemanticException {
 		boolean fetch = fetchNode != null;
 		if ( fetch && isSubQuery() ) {
 			throw new QueryException( "fetch not allowed in subquery from-elements" );
 		}
 		// The path AST should be a DotNode, and it should have been evaluated already.
 		if ( path.getType() != SqlTokenTypes.DOT ) {
 			throw new SemanticException( "Path expected for join!" );
 		}
 		DotNode dot = ( DotNode ) path;
 		JoinType hibernateJoinType = JoinProcessor.toHibernateJoinType( joinType );
 		dot.setJoinType( hibernateJoinType );	// Tell the dot node about the join type.
 		dot.setFetch( fetch );
 		// Generate an explicit join for the root dot node.   The implied joins will be collected and passed up
 		// to the root dot node.
 		dot.resolve( true, false, alias == null ? null : alias.getText() );
 
 		final FromElement fromElement;
 		if ( dot.getDataType() != null && dot.getDataType().isComponentType() ) {
 			if ( dot.getDataType().isAnyType() ) {
 				throw new SemanticException( "An AnyType attribute cannot be join fetched" );
 				// ^^ because the discriminator (aka, the "meta columns") must be known to the SQL in
 				// 		a non-parameterized way.
 			}
 			FromElementFactory factory = new FromElementFactory(
 					getCurrentFromClause(),
 					dot.getLhs().getFromElement(),
 					dot.getPropertyPath(),
 					alias == null ? null : alias.getText(),
 					null,
 					false
 			);
 			fromElement = factory.createComponentJoin( (ComponentType) dot.getDataType() );
 		}
 		else {
 			fromElement = dot.getImpliedJoin();
 			fromElement.setAllPropertyFetch( propertyFetch != null );
 
 			if ( with != null ) {
 				if ( fetch ) {
 					throw new SemanticException( "with-clause not allowed on fetched associations; use filters" );
 				}
 				handleWithFragment( fromElement, with );
 			}
 		}
 
         if ( LOG.isDebugEnabled() ) {
 			LOG.debug("createFromJoinElement() : " + getASTPrinter().showAsString(fromElement, "-- join tree --") );
 		}
 	}
 
 	private void handleWithFragment(FromElement fromElement, AST hqlWithNode) throws SemanticException {
 		try {
 			withClause( hqlWithNode );
 			AST hqlSqlWithNode = returnAST;
             if ( LOG.isDebugEnabled() ) {
 				LOG.debug( "handleWithFragment() : " + getASTPrinter().showAsString(hqlSqlWithNode, "-- with clause --") );
 			}
 			WithClauseVisitor visitor = new WithClauseVisitor( fromElement, queryTranslatorImpl );
 			NodeTraverser traverser = new NodeTraverser( visitor );
 			traverser.traverseDepthFirst( hqlSqlWithNode );
 
 			String withClauseJoinAlias = visitor.getJoinAlias();
 			if ( withClauseJoinAlias == null ) {
 				withClauseJoinAlias = fromElement.getCollectionTableAlias();
 			}
 			else {
 				FromElement referencedFromElement = visitor.getReferencedFromElement();
 				if ( referencedFromElement != fromElement ) {
 					LOG.warnf(
 							"with-clause expressions do not reference the from-clause element to which the " +
 									"with-clause was associated.  The query may not work as expected [%s]",
 							queryTranslatorImpl.getQueryString()
 					);
 				}
 			}
 
 			SqlGenerator sql = new SqlGenerator( getSessionFactoryHelper().getFactory() );
 			sql.whereExpr( hqlSqlWithNode.getFirstChild() );
 
 			fromElement.setWithClauseFragment( withClauseJoinAlias, "(" + sql.getSQL() + ")" );
 		}
 		catch( SemanticException e ) {
 			throw e;
 		}
 		catch( InvalidWithClauseException e ) {
 			throw e;
 		}
 		catch ( Exception e) {
 			throw new SemanticException( e.getMessage() );
 		}
 	}
 
 	private static class WithClauseVisitor implements NodeTraverser.VisitationStrategy {
 		private final FromElement joinFragment;
 		private final QueryTranslatorImpl queryTranslatorImpl;
 
 		private FromElement referencedFromElement;
 		private String joinAlias;
 
 		public WithClauseVisitor(FromElement fromElement, QueryTranslatorImpl queryTranslatorImpl) {
 			this.joinFragment = fromElement;
 			this.queryTranslatorImpl = queryTranslatorImpl;
 		}
 
 		public void visit(AST node) {
             // TODO : currently expects that the individual with expressions apply to the same sql table join.
 			//      This may not be the case for joined-subclass where the property values
 			//      might be coming from different tables in the joined hierarchy.  At some
 			//      point we should expand this to support that capability.  However, that has
 			//      some difficulties:
 			//          1) the biggest is how to handle ORs when the individual comparisons are
 			//              linked to different sql joins.
 			//          2) here we would need to track each comparison individually, along with
 			//              the join alias to which it applies and then pass that information
 			//              back to the FromElement so it can pass it along to the JoinSequence
 			if ( node instanceof DotNode ) {
 				DotNode dotNode = ( DotNode ) node;
 				FromElement fromElement = dotNode.getFromElement();
 				if ( referencedFromElement != null ) {
 					if ( fromElement != referencedFromElement ) {
 						throw new HibernateException( "with-clause referenced two different from-clause elements" );
 					}
 				}
 				else {
 					referencedFromElement = fromElement;
 					joinAlias = extractAppliedAlias( dotNode );
                     // TODO : temporary
 					//      needed because currently persister is the one that
                     // creates and renders the join fragments for inheritance
 					//      hierarchies...
 					if ( !joinAlias.equals( referencedFromElement.getTableAlias() ) ) {
 						throw new InvalidWithClauseException(
 								"with clause can only reference columns in the driving table",
 								queryTranslatorImpl.getQueryString()
 						);
 					}
 				}
 			}
 			else if ( node instanceof ParameterNode ) {
 				applyParameterSpecification( ( ( ParameterNode ) node ).getHqlParameterSpecification() );
 			}
 			else if ( node instanceof ParameterContainer ) {
 				applyParameterSpecifications( ( ParameterContainer ) node );
 			}
 		}
 
 		private void applyParameterSpecifications(ParameterContainer parameterContainer) {
 			if ( parameterContainer.hasEmbeddedParameters() ) {
 				ParameterSpecification[] specs = parameterContainer.getEmbeddedParameters();
 				for ( ParameterSpecification spec : specs ) {
 					applyParameterSpecification( spec );
 				}
 			}
 		}
 
 		private void applyParameterSpecification(ParameterSpecification paramSpec) {
 			joinFragment.addEmbeddedParameter( paramSpec );
 		}
 
 		private String extractAppliedAlias(DotNode dotNode) {
 			return dotNode.getText().substring( 0, dotNode.getText().indexOf( '.' ) );
 		}
 
 		public FromElement getReferencedFromElement() {
 			return referencedFromElement;
 		}
 
 		public String getJoinAlias() {
 			return joinAlias;
 		}
 	}
 
 	/**
 	 * Sets the current 'FROM' context.
 	 *
 	 * @param fromNode      The new 'FROM' context.
 	 * @param inputFromNode The from node from the input AST.
 	 */
 	@Override
     protected void pushFromClause(AST fromNode, AST inputFromNode) {
 		FromClause newFromClause = ( FromClause ) fromNode;
 		newFromClause.setParentFromClause( currentFromClause );
 		currentFromClause = newFromClause;
 	}
 
 	/**
 	 * Returns to the previous 'FROM' context.
 	 */
 	private void popFromClause() {
 		currentFromClause = currentFromClause.getParentFromClause();
 	}
 
 	@Override
     protected void lookupAlias(AST aliasRef)
 			throws SemanticException {
 		FromElement alias = currentFromClause.getFromElement( aliasRef.getText() );
 		FromReferenceNode aliasRefNode = ( FromReferenceNode ) aliasRef;
 		aliasRefNode.setFromElement( alias );
 	}
 
 	@Override
     protected void setImpliedJoinType(int joinType) {
 		impliedJoinType = JoinProcessor.toHibernateJoinType( joinType );
 	}
 
 	public JoinType getImpliedJoinType() {
 		return impliedJoinType;
 	}
 
 	@Override
     protected AST lookupProperty(AST dot, boolean root, boolean inSelect) throws SemanticException {
 		DotNode dotNode = ( DotNode ) dot;
 		FromReferenceNode lhs = dotNode.getLhs();
 		AST rhs = lhs.getNextSibling();
 		switch ( rhs.getType() ) {
 			case SqlTokenTypes.ELEMENTS:
 			case SqlTokenTypes.INDICES:
                 if (LOG.isDebugEnabled()) LOG.debugf("lookupProperty() %s => %s(%s)",
                                                      dotNode.getPath(),
                                                      rhs.getText(),
                                                      lhs.getPath());
 				CollectionFunction f = ( CollectionFunction ) rhs;
 				// Re-arrange the tree so that the collection function is the root and the lhs is the path.
 				f.setFirstChild( lhs );
 				lhs.setNextSibling( null );
 				dotNode.setFirstChild( f );
 				resolve( lhs );			// Don't forget to resolve the argument!
 				f.resolve( inSelect );	// Resolve the collection function now.
 				return f;
 			default:
 				// Resolve everything up to this dot, but don't resolve the placeholders yet.
 				dotNode.resolveFirstChild();
 				return dotNode;
 		}
 	}
 
 	@Override
     protected boolean isNonQualifiedPropertyRef(AST ident) {
 		final String identText = ident.getText();
 		if ( currentFromClause.isFromElementAlias( identText ) ) {
 			return false;
 		}
 
 		List fromElements = currentFromClause.getExplicitFromElements();
 		if ( fromElements.size() == 1 ) {
 			final FromElement fromElement = ( FromElement ) fromElements.get( 0 );
 			try {
 				LOG.tracev( "Attempting to resolve property [{0}] as a non-qualified ref", identText );
 				return fromElement.getPropertyMapping( identText ).toType( identText ) != null;
 			}
 			catch( QueryException e ) {
 				// Should mean that no such property was found
 			}
 		}
 
 		return false;
 	}
 
 	@Override
 	protected AST lookupNonQualifiedProperty(AST property) throws SemanticException {
 		final FromElement fromElement = ( FromElement ) currentFromClause.getExplicitFromElements().get( 0 );
 		AST syntheticDotNode = generateSyntheticDotNodeForNonQualifiedPropertyRef( property, fromElement );
 		return lookupProperty( syntheticDotNode, false, getCurrentClauseType() == HqlSqlTokenTypes.SELECT );
 	}
 
 	private AST generateSyntheticDotNodeForNonQualifiedPropertyRef(AST property, FromElement fromElement) {
 		AST dot = getASTFactory().create( DOT, "{non-qualified-property-ref}" );
 		// TODO : better way?!?
 		( ( DotNode ) dot ).setPropertyPath( ( ( FromReferenceNode ) property ).getPath() );
 
 		IdentNode syntheticAlias = ( IdentNode ) getASTFactory().create( IDENT, "{synthetic-alias}" );
 		syntheticAlias.setFromElement( fromElement );
 		syntheticAlias.setResolved();
 
 		dot.setFirstChild( syntheticAlias );
 		dot.addChild( property );
 
 		return dot;
 	}
 
 	@Override
 	protected void processQuery(AST select, AST query) throws SemanticException {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "processQuery() : %s", query.toStringTree() );
 		}
 
 		try {
 			QueryNode qn = ( QueryNode ) query;
 
 			// Was there an explicit select expression?
 			boolean explicitSelect = select != null && select.getNumberOfChildren() > 0;
 			
 			// Add in the EntityGraph attribute nodes.
 			if (queryTranslatorImpl.getEntityGraphQueryHint() != null) {
 				qn.getFromClause().getFromElements().addAll(
 						queryTranslatorImpl.getEntityGraphQueryHint().toFromElements( qn.getFromClause(), this ) );
 			}
 
 			if ( !explicitSelect ) {
 				// No explicit select expression; render the id and properties
 				// projection lists for every persister in the from clause into
 				// a single 'token node'.
 				//TODO: the only reason we need this stuff now is collection filters,
 				//      we should get rid of derived select clause completely!
 				createSelectClauseFromFromClause( qn );
 			}
 			else {
 				// Use the explicitly declared select expression; determine the
 				// return types indicated by each select token
 				useSelectClause( select );
 			}
 
 			// After that, process the JOINs.
 			// Invoke a delegate to do the work, as this is farily complex.
 			JoinProcessor joinProcessor = new JoinProcessor( this );
 			joinProcessor.processJoins( qn );
 
 			// Attach any mapping-defined "ORDER BY" fragments
 			Iterator itr = qn.getFromClause().getProjectionList().iterator();
 			while ( itr.hasNext() ) {
 				final FromElement fromElement = ( FromElement ) itr.next();
 //			if ( fromElement.isFetch() && fromElement.isCollectionJoin() ) {
 				if ( fromElement.isFetch() && fromElement.getQueryableCollection() != null ) {
 					// Does the collection referenced by this FromElement
 					// specify an order-by attribute?  If so, attach it to
 					// the query's order-by
 					if ( fromElement.getQueryableCollection().hasOrdering() ) {
 						String orderByFragment = fromElement
 								.getQueryableCollection()
 								.getSQLOrderByString( fromElement.getCollectionTableAlias() );
 						qn.getOrderByClause().addOrderFragment( orderByFragment );
 					}
 					if ( fromElement.getQueryableCollection().hasManyToManyOrdering() ) {
 						String orderByFragment = fromElement.getQueryableCollection()
 								.getManyToManyOrderByString( fromElement.getTableAlias() );
 						qn.getOrderByClause().addOrderFragment( orderByFragment );
 					}
 				}
 			}
 		}
 		finally {
 			popFromClause();
 		}
 	}
 
 	protected void postProcessDML(RestrictableStatement statement) throws SemanticException {
 		statement.getFromClause().resolve();
 
 		FromElement fromElement = ( FromElement ) statement.getFromClause().getFromElements().get( 0 );
 		Queryable persister = fromElement.getQueryable();
 		// Make #@%$^#^&# sure no alias is applied to the table name
 		fromElement.setText( persister.getTableName() );
 
 //		// append any filter fragments; the EMPTY_MAP is used under the assumption that
 //		// currently enabled filters should not affect this process
 //		if ( persister.getDiscriminatorType() != null ) {
 //			new SyntheticAndFactory( getASTFactory() ).addDiscriminatorWhereFragment(
 //			        statement,
 //			        persister,
 //			        java.util.Collections.EMPTY_MAP,
 //			        fromElement.getTableAlias()
 //			);
 //		}
 		if ( persister.getDiscriminatorType() != null || ! queryTranslatorImpl.getEnabledFilters().isEmpty() ) {
 			new SyntheticAndFactory( this ).addDiscriminatorWhereFragment(
 			        statement,
 			        persister,
 			        queryTranslatorImpl.getEnabledFilters(),
 			        fromElement.getTableAlias()
 			);
 		}
 
 	}
 
 	@Override
     protected void postProcessUpdate(AST update) throws SemanticException {
 		UpdateStatement updateStatement = ( UpdateStatement ) update;
 
 		postProcessDML( updateStatement );
 	}
 
 	@Override
     protected void postProcessDelete(AST delete) throws SemanticException {
 		postProcessDML( ( DeleteStatement ) delete );
 	}
 
 	@Override
     protected void postProcessInsert(AST insert) throws SemanticException, QueryException {
 		InsertStatement insertStatement = ( InsertStatement ) insert;
 		insertStatement.validate();
 
 		SelectClause selectClause = insertStatement.getSelectClause();
 		Queryable persister = insertStatement.getIntoClause().getQueryable();
 
 		if ( !insertStatement.getIntoClause().isExplicitIdInsertion() ) {
 			// the insert did not explicitly reference the id.  See if
 			//		1) that is allowed
 			//		2) whether we need to alter the SQL tree to account for id
 			final IdentifierGenerator generator = persister.getIdentifierGenerator();
 			if ( !BulkInsertionCapableIdentifierGenerator.class.isInstance( generator ) ) {
 				throw new QueryException(
 						"Invalid identifier generator encountered for implicit id handling as part of bulk insertions"
 				);
 			}
 			final BulkInsertionCapableIdentifierGenerator capableGenerator =
 					BulkInsertionCapableIdentifierGenerator.class.cast( generator );
 			if ( ! capableGenerator.supportsBulkInsertionIdentifierGeneration() ) {
 				throw new QueryException(
 						"Identifier generator reported it does not support implicit id handling as part of bulk insertions"
 				);
 			}
 
             final String fragment = capableGenerator.determineBulkInsertionIdentifierGenerationSelectFragment(
 					sessionFactoryHelper.getFactory().getDialect()
 			);
 			if ( fragment != null ) {
                 // we got a fragment from the generator, so alter the sql tree...
                 //
                 // first, wrap the fragment as a node
                 AST fragmentNode = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, fragment );
                 // next, rearrange the SQL tree to add the fragment node as the first select expression
                 AST originalFirstSelectExprNode = selectClause.getFirstChild();
                 selectClause.setFirstChild( fragmentNode );
                 fragmentNode.setNextSibling( originalFirstSelectExprNode );
                 // finally, prepend the id column name(s) to the insert-spec
                 insertStatement.getIntoClause().prependIdColumnSpec();
 			}
 		}
 
 		if ( sessionFactoryHelper.getFactory().getDialect().supportsParametersInInsertSelect() ) {
 			AST child = selectClause.getFirstChild();
 			int i = 0;
 			while(child != null) {
 				if(child instanceof ParameterNode) {
 					// infer the parameter type from the type listed in the INSERT INTO clause
 					((ParameterNode)child).setExpectedType(insertStatement.getIntoClause()
 							.getInsertionTypes()[selectClause.getParameterPositions().get(i)]);
 					i++;
 				}
 				child = child.getNextSibling();
 			}
 		}
 
 		final boolean includeVersionProperty = persister.isVersioned() &&
 				!insertStatement.getIntoClause().isExplicitVersionInsertion() &&
 				persister.isVersionPropertyInsertable();
 		if ( includeVersionProperty ) {
 			// We need to seed the version value as part of this bulk insert
 			VersionType versionType = persister.getVersionType();
 			AST versionValueNode = null;
 
 			if ( sessionFactoryHelper.getFactory().getDialect().supportsParametersInInsertSelect() ) {
-				int sqlTypes[] = versionType.sqlTypes( sessionFactoryHelper.getFactory() );
+				int[] sqlTypes = versionType.sqlTypes( sessionFactoryHelper.getFactory() );
 				if ( sqlTypes == null || sqlTypes.length == 0 ) {
 					throw new IllegalStateException( versionType.getClass() + ".sqlTypes() returns null or empty array" );
 				}
 				if ( sqlTypes.length > 1 ) {
 					throw new IllegalStateException(
 							versionType.getClass() +
 									".sqlTypes() returns > 1 element; only single-valued versions are allowed."
 					);
 				}
 				versionValueNode = getASTFactory().create( HqlSqlTokenTypes.PARAM, "?" );
 				ParameterSpecification paramSpec = new VersionTypeSeedParameterSpecification( versionType );
 				( ( ParameterNode ) versionValueNode ).setHqlParameterSpecification( paramSpec );
 				parameters.add( 0, paramSpec );
 
 				if ( sessionFactoryHelper.getFactory().getDialect().requiresCastingOfParametersInSelectClause() ) {
 					// we need to wrtap the param in a cast()
 					MethodNode versionMethodNode = ( MethodNode ) getASTFactory().create( HqlSqlTokenTypes.METHOD_CALL, "(" );
 					AST methodIdentNode = getASTFactory().create( HqlSqlTokenTypes.IDENT, "cast" );
 					versionMethodNode.addChild( methodIdentNode );
 					versionMethodNode.initializeMethodNode(methodIdentNode, true );
 					AST castExprListNode = getASTFactory().create( HqlSqlTokenTypes.EXPR_LIST, "exprList" );
 					methodIdentNode.setNextSibling( castExprListNode );
 					castExprListNode.addChild( versionValueNode );
 					versionValueNode.setNextSibling(
 							getASTFactory().create(
 									HqlSqlTokenTypes.IDENT,
 									sessionFactoryHelper.getFactory().getDialect().getTypeName( sqlTypes[0] ) )
 					);
 					processFunction( versionMethodNode, true );
 					versionValueNode = versionMethodNode;
 				}
 			}
 			else {
 				if ( isIntegral( versionType ) ) {
 					try {
 						Object seedValue = versionType.seed( null );
 						versionValueNode = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, seedValue.toString() );
 					}
 					catch( Throwable t ) {
 						throw new QueryException( "could not determine seed value for version on bulk insert [" + versionType + "]" );
 					}
 				}
 				else if ( isDatabaseGeneratedTimestamp( versionType ) ) {
 					String functionName = sessionFactoryHelper.getFactory().getDialect().getCurrentTimestampSQLFunctionName();
 					versionValueNode = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, functionName );
 				}
 				else {
 					throw new QueryException( "cannot handle version type [" + versionType + "] on bulk inserts with dialects not supporting parameters in insert-select statements" );
 				}
 			}
 
 			AST currentFirstSelectExprNode = selectClause.getFirstChild();
 			selectClause.setFirstChild( versionValueNode );
 			versionValueNode.setNextSibling( currentFirstSelectExprNode );
 
 			insertStatement.getIntoClause().prependVersionColumnSpec();
 		}
 
 		if ( insertStatement.getIntoClause().isDiscriminated() ) {
 			String sqlValue = insertStatement.getIntoClause().getQueryable().getDiscriminatorSQLValue();
 			AST discrimValue = getASTFactory().create( HqlSqlTokenTypes.SQL_TOKEN, sqlValue );
 			insertStatement.getSelectClause().addChild( discrimValue );
 		}
 
 	}
 
 	private boolean isDatabaseGeneratedTimestamp(Type type) {
 		// currently only the Hibernate-supplied DbTimestampType is supported here
 		return DbTimestampType.class.isAssignableFrom( type.getClass() );
 	}
 
 	private boolean isIntegral(Type type) {
 		return Long.class.isAssignableFrom( type.getReturnedClass() )
 		       || Integer.class.isAssignableFrom( type.getReturnedClass() )
 		       || long.class.isAssignableFrom( type.getReturnedClass() )
 		       || int.class.isAssignableFrom( type.getReturnedClass() );
 	}
 
 	private void useSelectClause(AST select) throws SemanticException {
 		selectClause = ( SelectClause ) select;
 		selectClause.initializeExplicitSelectClause( currentFromClause );
 	}
 
 	private void createSelectClauseFromFromClause(QueryNode qn) throws SemanticException {
 		AST select = astFactory.create( SELECT_CLAUSE, "{derived select clause}" );
 		AST sibling = qn.getFromClause();
 		qn.setFirstChild( select );
 		select.setNextSibling( sibling );
 		selectClause = ( SelectClause ) select;
 		selectClause.initializeDerivedSelectClause( currentFromClause );
 		LOG.debug( "Derived SELECT clause created." );
 	}
 
 	@Override
     protected void resolve(AST node) throws SemanticException {
 		if ( node != null ) {
 			// This is called when it's time to fully resolve a path expression.
 			ResolvableNode r = ( ResolvableNode ) node;
 			if ( isInFunctionCall() ) {
 				r.resolveInFunctionCall( false, true );
 			}
 			else {
 				r.resolve( false, true );	// Generate implicit joins, only if necessary.
 			}
 		}
 	}
 
 	@Override
     protected void resolveSelectExpression(AST node) throws SemanticException {
 		// This is called when it's time to fully resolve a path expression.
 		int type = node.getType();
 		switch ( type ) {
 			case DOT: {
 				DotNode dot = ( DotNode ) node;
 				dot.resolveSelectExpression();
 				break;
 			}
 			case ALIAS_REF: {
 				// Notify the FROM element that it is being referenced by the select.
 				FromReferenceNode aliasRefNode = ( FromReferenceNode ) node;
 				//aliasRefNode.resolve( false, false, aliasRefNode.getText() ); //TODO: is it kosher to do it here?
 				aliasRefNode.resolve( false, false ); //TODO: is it kosher to do it here?
 				FromElement fromElement = aliasRefNode.getFromElement();
 				if ( fromElement != null ) {
 					fromElement.setIncludeSubclasses( true );
 				}
 				break;
 			}
 			default: {
 				break;
 			}
 		}
 	}
 
 	@Override
     protected void beforeSelectClause() throws SemanticException {
 		// Turn off includeSubclasses on all FromElements.
 		FromClause from = getCurrentFromClause();
 		List fromElements = from.getFromElements();
 		for ( Iterator iterator = fromElements.iterator(); iterator.hasNext(); ) {
 			FromElement fromElement = ( FromElement ) iterator.next();
 			fromElement.setIncludeSubclasses( false );
 		}
 	}
 
 	@Override
     protected AST generatePositionalParameter(AST inputNode) throws SemanticException {
 		if ( namedParameters.size() > 0 ) {
 			throw new SemanticException( "cannot define positional parameter after any named parameters have been defined" );
 		}
 		LOG.warnf(
 				"[DEPRECATION] Encountered positional parameter near line %s, column %s.  Positional parameter " +
 						"are considered deprecated; use named parameters or JPA-style positional parameters instead.",
 				inputNode.getLine(),
 				inputNode.getColumn()
 		);
 		ParameterNode parameter = ( ParameterNode ) astFactory.create( PARAM, "?" );
 		PositionalParameterSpecification paramSpec = new PositionalParameterSpecification(
 				inputNode.getLine(),
 		        inputNode.getColumn(),
 				positionalParameterCount++
 		);
 		parameter.setHqlParameterSpecification( paramSpec );
 		parameters.add( paramSpec );
 		return parameter;
 	}
 
 	@Override
     protected AST generateNamedParameter(AST delimiterNode, AST nameNode) throws SemanticException {
 		String name = nameNode.getText();
 		trackNamedParameterPositions( name );
 
 		// create the node initially with the param name so that it shows
 		// appropriately in the "original text" attribute
 		ParameterNode parameter = ( ParameterNode ) astFactory.create( NAMED_PARAM, name );
 		parameter.setText( "?" );
 
 		NamedParameterSpecification paramSpec = new NamedParameterSpecification(
 				delimiterNode.getLine(),
 		        delimiterNode.getColumn(),
 				name
 		);
 		parameter.setHqlParameterSpecification( paramSpec );
 		parameters.add( paramSpec );
 		return parameter;
 	}
 
 	private void trackNamedParameterPositions(String name) {
 		Integer loc = parameterCount++;
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			namedParameters.put( name, loc );
 		}
 		else if ( o instanceof Integer ) {
 			ArrayList list = new ArrayList( 4 );
 			list.add( o );
 			list.add( loc );
 			namedParameters.put( name, list );
 		}
 		else {
 			( ( ArrayList ) o ).add( loc );
 		}
 	}
 
 	@Override
     protected void processConstant(AST constant) throws SemanticException {
 		literalProcessor.processConstant( constant, true );  // Use the delegate, resolve identifiers as FROM element aliases.
 	}
 
 	@Override
     protected void processBoolean(AST constant) throws SemanticException {
 		literalProcessor.processBoolean( constant );  // Use the delegate.
 	}
 
 	@Override
     protected void processNumericLiteral(AST literal) {
 		literalProcessor.processNumeric( literal );
 	}
 
 	@Override
     protected void processIndex(AST indexOp) throws SemanticException {
 		IndexNode indexNode = ( IndexNode ) indexOp;
 		indexNode.resolve( true, true );
 	}
 
 	@Override
     protected void processFunction(AST functionCall, boolean inSelect) throws SemanticException {
 		MethodNode methodNode = ( MethodNode ) functionCall;
 		methodNode.resolve( inSelect );
 	}
 
 	@Override
     protected void processAggregation(AST node, boolean inSelect) throws SemanticException {
 		AggregateNode aggregateNode = ( AggregateNode ) node;
 		aggregateNode.resolve();
 	}
 
 	@Override
     protected void processConstructor(AST constructor) throws SemanticException {
 		ConstructorNode constructorNode = ( ConstructorNode ) constructor;
 		constructorNode.prepare();
 	}
 
     @Override
     protected void setAlias(AST selectExpr, AST ident) {
         ((SelectExpression) selectExpr).setAlias(ident.getText());
 		// only put the alias (i.e., result variable) in selectExpressionsByResultVariable
 		// if is not defined in a subquery.
 		if ( ! isSubQuery() ) {
 			selectExpressionsByResultVariable.put( ident.getText(), ( SelectExpression ) selectExpr );
 		}
     }
 
 	@Override
     protected boolean isOrderExpressionResultVariableRef(AST orderExpressionNode) throws SemanticException {
 		// ORDER BY is not supported in a subquery
 		// TODO: should an exception be thrown if an ORDER BY is in a subquery?
 		if ( ! isSubQuery() &&
 				orderExpressionNode.getType() == IDENT &&
 				selectExpressionsByResultVariable.containsKey( orderExpressionNode.getText() ) ) {
 			return true;
 		}
 		return false;
 	}
 
 	@Override
     protected void handleResultVariableRef(AST resultVariableRef) throws SemanticException {
 		if ( isSubQuery() ) {
 			throw new SemanticException(
 					"References to result variables in subqueries are not supported."
 			);
 		}
 		( ( ResultVariableRefNode ) resultVariableRef ).setSelectExpression(
 				selectExpressionsByResultVariable.get( resultVariableRef.getText() )
 		);
 	}
 
 	/**
 	 * Returns the locations of all occurrences of the named parameter.
 	 */
 	public int[] getNamedParameterLocations(String name) throws QueryException {
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			throw new QueryException( QueryTranslator.ERROR_NAMED_PARAMETER_DOES_NOT_APPEAR + name, queryTranslatorImpl.getQueryString() );
 		}
 		if ( o instanceof Integer ) {
 			return new int[]{ (Integer) o };
 		}
 		else {
 			return ArrayHelper.toIntArray( (ArrayList) o );
 		}
 	}
 
 	public void addQuerySpaces(Serializable[] spaces) {
 		querySpaces.addAll( Arrays.asList( spaces ) );
 	}
 
 	public Type[] getReturnTypes() {
 		return selectClause.getQueryReturnTypes();
 	}
 
 	public String[] getReturnAliases() {
 		return selectClause.getQueryReturnAliases();
 	}
 
 	public SelectClause getSelectClause() {
 		return selectClause;
 	}
 
 	public FromClause getFinalFromClause() {
 		FromClause top = currentFromClause;
 		while ( top.getParentFromClause() != null ) {
 			top = top.getParentFromClause();
 		}
 		return top;
 	}
 
 	public boolean isShallowQuery() {
 		// select clauses for insert statements should alwasy be treated as shallow
 		return getStatementType() == INSERT || queryTranslatorImpl.isShallowQuery();
 	}
 
 	public Map getEnabledFilters() {
 		return queryTranslatorImpl.getEnabledFilters();
 	}
 
 	public LiteralProcessor getLiteralProcessor() {
 		return literalProcessor;
 	}
 
 	public ASTPrinter getASTPrinter() {
 		return printer;
 	}
 
 	public ArrayList getParameters() {
 		return parameters;
 	}
 
 	public int getNumberOfParametersInSetClause() {
 		return numberOfParametersInSetClause;
 	}
 
 	@Override
     protected void evaluateAssignment(AST eq) throws SemanticException {
 		prepareLogicOperator( eq );
 		Queryable persister = getCurrentFromClause().getFromElement().getQueryable();
 		evaluateAssignment( eq, persister, -1 );
 	}
 
 	private void evaluateAssignment(AST eq, Queryable persister, int targetIndex) {
 		if ( persister.isMultiTable() ) {
 			// no need to even collect this information if the persister is considered multi-table
 			AssignmentSpecification specification = new AssignmentSpecification( eq, persister );
 			if ( targetIndex >= 0 ) {
 				assignmentSpecifications.add( targetIndex, specification );
 			}
 			else {
 				assignmentSpecifications.add( specification );
 			}
 			numberOfParametersInSetClause += specification.getParameters().length;
 		}
 	}
 
 	public ArrayList getAssignmentSpecifications() {
 		return assignmentSpecifications;
 	}
 
 	@Override
     protected AST createIntoClause(String path, AST propertySpec) throws SemanticException {
 		Queryable persister = ( Queryable ) getSessionFactoryHelper().requireClassPersister( path );
 
 		IntoClause intoClause = ( IntoClause ) getASTFactory().create( INTO, persister.getEntityName() );
 		intoClause.setFirstChild( propertySpec );
 		intoClause.initialize( persister );
 
 		addQuerySpaces( persister.getQuerySpaces() );
 
 		return intoClause;
 	}
 
 	@Override
     protected void prepareVersioned(AST updateNode, AST versioned) throws SemanticException {
 		UpdateStatement updateStatement = ( UpdateStatement ) updateNode;
 		FromClause fromClause = updateStatement.getFromClause();
 		if ( versioned != null ) {
 			// Make sure that the persister is versioned
 			Queryable persister = fromClause.getFromElement().getQueryable();
 			if ( !persister.isVersioned() ) {
 				throw new SemanticException( "increment option specified for update of non-versioned entity" );
 			}
 
 			VersionType versionType = persister.getVersionType();
 			if ( versionType instanceof UserVersionType ) {
 				throw new SemanticException( "user-defined version types not supported for increment option" );
 			}
 
 			AST eq = getASTFactory().create( HqlSqlTokenTypes.EQ, "=" );
 			AST versionPropertyNode = generateVersionPropertyNode( persister );
 
 			eq.setFirstChild( versionPropertyNode );
 
 			AST versionIncrementNode = null;
 			if ( isTimestampBasedVersion( versionType ) ) {
 				versionIncrementNode = getASTFactory().create( HqlSqlTokenTypes.PARAM, "?" );
 				ParameterSpecification paramSpec = new VersionTypeSeedParameterSpecification( versionType );
 				( ( ParameterNode ) versionIncrementNode ).setHqlParameterSpecification( paramSpec );
 				parameters.add( 0, paramSpec );
 			}
 			else {
 				// Not possible to simply re-use the versionPropertyNode here as it causes
 				// OOM errors due to circularity :(
 				versionIncrementNode = getASTFactory().create( HqlSqlTokenTypes.PLUS, "+" );
 				versionIncrementNode.setFirstChild( generateVersionPropertyNode( persister ) );
 				versionIncrementNode.addChild( getASTFactory().create( HqlSqlTokenTypes.IDENT, "1" ) );
 			}
 
 			eq.addChild( versionIncrementNode );
 
 			evaluateAssignment( eq, persister, 0 );
 
 			AST setClause = updateStatement.getSetClause();
 			AST currentFirstSetElement = setClause.getFirstChild();
 			setClause.setFirstChild( eq );
 			eq.setNextSibling( currentFirstSetElement );
 		}
 	}
 
 	private boolean isTimestampBasedVersion(VersionType versionType) {
 		final Class javaType = versionType.getReturnedClass();
 		return Date.class.isAssignableFrom( javaType )
 				|| Calendar.class.isAssignableFrom( javaType );
 	}
 
 	private AST generateVersionPropertyNode(Queryable persister) throws SemanticException {
 		String versionPropertyName = persister.getPropertyNames()[ persister.getVersionProperty() ];
 		AST versionPropertyRef = getASTFactory().create( HqlSqlTokenTypes.IDENT, versionPropertyName );
 		AST versionPropertyNode = lookupNonQualifiedProperty( versionPropertyRef );
 		resolve( versionPropertyNode );
 		return versionPropertyNode;
 	}
 
 	@Override
     protected void prepareLogicOperator(AST operator) throws SemanticException {
 		( ( OperatorNode ) operator ).initialize();
 	}
 
 	@Override
     protected void prepareArithmeticOperator(AST operator) throws SemanticException {
 		( ( OperatorNode ) operator ).initialize();
 	}
 
 	@Override
     protected void validateMapPropertyExpression(AST node) throws SemanticException {
 		try {
 			FromReferenceNode fromReferenceNode = (FromReferenceNode) node;
 			QueryableCollection collectionPersister = fromReferenceNode.getFromElement().getQueryableCollection();
 			if ( ! Map.class.isAssignableFrom( collectionPersister.getCollectionType().getReturnedClass() ) ) {
 				throw new SemanticException( "node did not reference a map" );
 			}
 		}
 		catch ( SemanticException se ) {
 			throw se;
 		}
 		catch ( Throwable t ) {
 			throw new SemanticException( "node did not reference a map" );
 		}
 	}
 
 	public Set<String> getTreatAsDeclarationsByPath(String path) {
 		return hqlParser.getTreatMap().get( path );
 	}
 
 	public static void panic() {
 		throw new QueryException( "TreeWalker: panic" );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlToken.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlToken.java
index 0fb1483c95..6d757ca85a 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlToken.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/HqlToken.java
@@ -1,95 +1,95 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.hql.internal.ast;
 
-
 /**
  * A custom token class for the HQL grammar.
  * <p><i>NOTE:<i> This class must be public becuase it is instantiated by the ANTLR library.  Ignore any suggestions
  * by various code 'analyzers' about this class being package local.</p>
  */
 public class HqlToken extends antlr.CommonToken {
 	/**
-	 * True if this token could be an identifier. *
+	 * True if this token could be an identifier.
 	 */
-	private boolean possibleID = false;
+	private boolean possibleID;
 	/**
-	 * The previous token type. *
+	 * The previous token type.
 	 */
 	private int tokenType;
 
 	/**
 	 * Returns true if the token could be an identifier.
 	 *
 	 * @return True if the token could be interpreted as in identifier,
 	 *         false if not.
 	 */
 	public boolean isPossibleID() {
 		return possibleID;
 	}
 
 	/**
 	 * Sets the type of the token, remembering the previous type.
 	 *
 	 * @param t The new token type.
 	 */
+	@Override
 	public void setType(int t) {
 		this.tokenType = getType();
 		super.setType( t );
 	}
 
 	/**
 	 * Returns the previous token type.
 	 *
 	 * @return int - The old token type.
 	 */
 	private int getPreviousType() {
 		return tokenType;
 	}
 
 	/**
 	 * Set to true if this token can be interpreted as an identifier,
 	 * false if not.
 	 *
 	 * @param possibleID True if this is a keyword/identifier, false if not.
 	 */
 	public void setPossibleID(boolean possibleID) {
 		this.possibleID = possibleID;
 	}
 
 	/**
 	 * Returns a string representation of the object.
 	 *
 	 * @return String - The debug string.
 	 */
+	@Override
 	public String toString() {
 		return "[\""
 				+ getText()
 				+ "\",<" + getType() + "> previously: <" + getPreviousType() + ">,line="
 				+ line + ",col="
 				+ col + ",possibleID=" + possibleID + "]";
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/SqlGenerator.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/SqlGenerator.java
index e8339b99c2..8e2f904710 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/SqlGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/SqlGenerator.java
@@ -1,376 +1,379 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast;
 
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.LinkedList;
 import java.util.List;
 
 import antlr.RecognitionException;
 import antlr.collections.AST;
-import org.jboss.logging.Logger;
 
 import org.hibernate.NullPrecedence;
 import org.hibernate.QueryException;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.hql.internal.antlr.SqlGeneratorBase;
 import org.hibernate.hql.internal.antlr.SqlTokenTypes;
 import org.hibernate.hql.internal.ast.tree.FromElement;
 import org.hibernate.hql.internal.ast.tree.FunctionNode;
 import org.hibernate.hql.internal.ast.tree.Node;
 import org.hibernate.hql.internal.ast.tree.ParameterContainer;
 import org.hibernate.hql.internal.ast.tree.ParameterNode;
 import org.hibernate.hql.internal.ast.util.ASTPrinter;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.type.Type;
 
 /**
  * Generates SQL by overriding callback methods in the base class, which does
  * the actual SQL AST walking.
  *
  * @author Joshua Davis
  * @author Steve Ebersole
  */
 public class SqlGenerator extends SqlGeneratorBase implements ErrorReporter {
+    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( SqlGenerator.class );
 
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SqlGenerator.class.getName());
-
-	public static boolean REGRESSION_STYLE_CROSS_JOINS = false;
+	public static boolean REGRESSION_STYLE_CROSS_JOINS;
 
 	/**
 	 * all append invocations on the buf should go through this Output instance variable.
 	 * The value of this variable may be temporarily substituted by sql function processing code
 	 * to catch generated arguments.
 	 * This is because sql function templates need arguments as separate string chunks
 	 * that will be assembled into the target dialect-specific function call.
 	 */
 	private SqlWriter writer = new DefaultWriter();
 
 	private ParseErrorHandler parseErrorHandler;
 	private SessionFactoryImplementor sessionFactory;
 	private LinkedList<SqlWriter> outputStack = new LinkedList<SqlWriter>();
 	private final ASTPrinter printer = new ASTPrinter( SqlTokenTypes.class );
 	private List<ParameterSpecification> collectedParameters = new ArrayList<ParameterSpecification>();
 
 
 	// handle trace logging ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-	private int traceDepth = 0;
+	private int traceDepth;
 
 	@Override
 	public void traceIn(String ruleName, AST tree) {
 		if ( !LOG.isTraceEnabled() ) return;
 		if ( inputState.guessing > 0 ) return;
 		String prefix = StringHelper.repeat( '-', ( traceDepth++ * 2 ) ) + "-> ";
 		String traceText = ruleName + " (" + buildTraceNodeName( tree ) + ")";
 		LOG.trace( prefix + traceText );
 	}
 
 	private String buildTraceNodeName(AST tree) {
 		return tree == null
 				? "???"
 				: tree.getText() + " [" + printer.getTokenTypeName( tree.getType() ) + "]";
 	}
 
 	@Override
 	public void traceOut(String ruleName, AST tree) {
 		if ( !LOG.isTraceEnabled() ) return;
 		if ( inputState.guessing > 0 ) return;
 		String prefix = "<-" + StringHelper.repeat( '-', ( --traceDepth * 2 ) ) + " ";
 		LOG.trace( prefix + ruleName );
 	}
 
 	public List<ParameterSpecification> getCollectedParameters() {
 		return collectedParameters;
 	}
 
 	@Override
     protected void out(String s) {
 		writer.clause( s );
 	}
 
 	@Override
     protected void out(AST n) {
 		if ( n instanceof Node ) {
 			out( ( ( Node ) n ).getRenderText( sessionFactory ) );
 		}
 		else {
 			super.out( n );
 		}
 
 		if ( n instanceof ParameterNode ) {
 			collectedParameters.add( ( ( ParameterNode ) n ).getHqlParameterSpecification() );
 		}
 		else if ( n instanceof ParameterContainer ) {
 			if ( ( ( ParameterContainer ) n ).hasEmbeddedParameters() ) {
 				ParameterSpecification[] specifications = ( ( ParameterContainer ) n ).getEmbeddedParameters();
 				if ( specifications != null ) {
 					collectedParameters.addAll( Arrays.asList( specifications ) );
 				}
 			}
 		}
 	}
 
 	@Override
     protected void commaBetweenParameters(String comma) {
 		writer.commaBetweenParameters( comma );
 	}
 
 	@Override
     public void reportError(RecognitionException e) {
 		parseErrorHandler.reportError( e ); // Use the delegate.
 	}
 
 	@Override
     public void reportError(String s) {
 		parseErrorHandler.reportError( s ); // Use the delegate.
 	}
 
 	@Override
     public void reportWarning(String s) {
 		parseErrorHandler.reportWarning( s );
 	}
 
 	public ParseErrorHandler getParseErrorHandler() {
 		return parseErrorHandler;
 	}
 
 	public SqlGenerator(SessionFactoryImplementor sfi) {
 		super();
 		parseErrorHandler = new ErrorCounter();
 		sessionFactory = sfi;
 	}
 
 	public String getSQL() {
 		return getStringBuilder().toString();
 	}
 
 	@Override
     protected void optionalSpace() {
 		int c = getLastChar();
 		switch ( c ) {
 			case -1:
 				return;
 			case ' ':
 				return;
 			case ')':
 				return;
 			case '(':
 				return;
 			default:
 				out( " " );
 		}
 	}
 
 	@Override
     protected void beginFunctionTemplate(AST node, AST nameNode) {
 		// NOTE for AGGREGATE both nodes are the same; for METHOD the first is the METHOD, the second is the
 		// 		METHOD_NAME
 		FunctionNode functionNode = ( FunctionNode ) node;
 		SQLFunction sqlFunction = functionNode.getSQLFunction();
 		if ( sqlFunction == null ) {
 			// if SQLFunction is null we just write the function out as it appears in the hql statement
 			super.beginFunctionTemplate( node, nameNode );
 		}
 		else {
 			// this function has a registered SQLFunction -> redirect output and catch the arguments
 			outputStack.addFirst( writer );
 			writer = new FunctionArguments();
 		}
 	}
 
 	@Override
     protected void endFunctionTemplate(AST node) {
 		FunctionNode functionNode = ( FunctionNode ) node;
 		SQLFunction sqlFunction = functionNode.getSQLFunction();
 		if ( sqlFunction == null ) {
 			super.endFunctionTemplate( node );
 		}
 		else {
 			final Type functionType = functionNode.getFirstArgumentType();
 			// this function has a registered SQLFunction -> redirect output and catch the arguments
 			FunctionArguments functionArguments = ( FunctionArguments ) writer;
 			writer = outputStack.removeFirst();
 			out( sqlFunction.render( functionType, functionArguments.getArgs(), sessionFactory ) );
 		}
 	}
 
 	// --- Inner classes (moved here from sql-gen.g) ---
 
 	/**
 	 * Writes SQL fragments.
 	 */
 	interface SqlWriter {
 		void clause(String clause);
 
 		/**
 		 * todo remove this hack
 		 * The parameter is either ", " or " , ". This is needed to pass sql generating tests as the old
 		 * sql generator uses " , " in the WHERE and ", " in SELECT.
 		 *
 		 * @param comma either " , " or ", "
 		 */
 		void commaBetweenParameters(String comma);
 	}
 
 	/**
 	 * SQL function processing code redirects generated SQL output to an instance of this class
 	 * which catches function arguments.
 	 */
 	class FunctionArguments implements SqlWriter {
 		private int argInd;
 		private final List<String> args = new ArrayList<String>(3);
 
+		@Override
 		public void clause(String clause) {
 			if ( argInd == args.size() ) {
 				args.add( clause );
 			}
 			else {
 				args.set( argInd, args.get( argInd ) + clause );
 			}
 		}
 
+		@Override
 		public void commaBetweenParameters(String comma) {
 			++argInd;
 		}
 
 		public List getArgs() {
 			return args;
 		}
 	}
 
 	/**
 	 * The default SQL writer.
 	 */
 	class DefaultWriter implements SqlWriter {
+		@Override
 		public void clause(String clause) {
 			getStringBuilder().append( clause );
 		}
 
+		@Override
 		public void commaBetweenParameters(String comma) {
 			getStringBuilder().append( comma );
 		}
 	}
 
     public static void panic() {
 		throw new QueryException( "TreeWalker: panic" );
 	}
 
 	@Override
     protected void fromFragmentSeparator(AST a) {
 		// check two "adjecent" nodes at the top of the from-clause tree
 		AST next = a.getNextSibling();
 		if ( next == null || !hasText( a ) ) {
 			return;
 		}
 
 		FromElement left = ( FromElement ) a;
 		FromElement right = ( FromElement ) next;
 
 		///////////////////////////////////////////////////////////////////////
 		// HACK ALERT !!!!!!!!!!!!!!!!!!!!!!!!!!!!
 		// Attempt to work around "ghost" ImpliedFromElements that occasionally
 		// show up between the actual things being joined.  This consistently
 		// occurs from index nodes (at least against many-to-many).  Not sure
 		// if there are other conditions
 		//
 		// Essentially, look-ahead to the next FromElement that actually
 		// writes something to the SQL
 		while ( right != null && !hasText( right ) ) {
 			right = ( FromElement ) right.getNextSibling();
 		}
 		if ( right == null ) {
 			return;
 		}
 		///////////////////////////////////////////////////////////////////////
 
 		if ( !hasText( right ) ) {
 			return;
 		}
 
 		if ( right.getRealOrigin() == left ||
 		     ( right.getRealOrigin() != null && right.getRealOrigin() == left.getRealOrigin() ) ) {
 			// right represents a joins originating from left; or
 			// both right and left reprersent joins originating from the same FromElement
 			if ( right.getJoinSequence() != null && right.getJoinSequence().isThetaStyle() ) {
 				writeCrossJoinSeparator();
 			}
 			else {
 				out( " " );
 			}
 		}
 		else {
 			// these are just two unrelated table references
 			writeCrossJoinSeparator();
 		}
 	}
 
 	private void writeCrossJoinSeparator() {
 		if ( REGRESSION_STYLE_CROSS_JOINS ) {
 			out( ", " );
 		}
 		else {
 			out( sessionFactory.getDialect().getCrossJoinSeparator() );
 		}
 	}
 
 	@Override
     protected void nestedFromFragment(AST d, AST parent) {
 		// check a set of parent/child nodes in the from-clause tree
 		// to determine if a comma is required between them
 		if ( d != null && hasText( d ) ) {
 			if ( parent != null && hasText( parent ) ) {
 				// again, both should be FromElements
 				FromElement left = ( FromElement ) parent;
 				FromElement right = ( FromElement ) d;
 				if ( right.getRealOrigin() == left ) {
 					// right represents a joins originating from left...
 					if ( right.getJoinSequence() != null && right.getJoinSequence().isThetaStyle() ) {
 						out( ", " );
 					}
 					else {
 						out( " " );
 					}
 				}
 				else {
 					// not so sure this is even valid subtree.  but if it was, it'd
 					// represent two unrelated table references...
 					out( ", " );
 				}
 			}
 			out( d );
 		}
 	}
 
 	@Override
 	protected String renderOrderByElement(String expression, String order, String nulls) {
 		final NullPrecedence nullPrecedence = NullPrecedence.parse( nulls, sessionFactory.getSettings().getDefaultNullPrecedence() );
 		return sessionFactory.getDialect().renderOrderByElement( expression, null, order, nullPrecedence );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/DotNode.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/DotNode.java
index 281b724425..2ccebe1dc4 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/DotNode.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/DotNode.java
@@ -1,722 +1,727 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.tree;
 
-import java.util.Set;
-
 import antlr.SemanticException;
 import antlr.collections.AST;
+
 import org.jboss.logging.Logger;
 
 import org.hibernate.QueryException;
 import org.hibernate.engine.internal.JoinSequence;
 import org.hibernate.hql.internal.CollectionProperties;
 import org.hibernate.hql.internal.antlr.SqlTokenTypes;
 import org.hibernate.hql.internal.ast.util.ASTUtil;
 import org.hibernate.hql.internal.ast.util.ColumnHelper;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.JoinType;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 /**
  * Represents a reference to a property or alias expression.  This should duplicate the relevant behaviors in
  * PathExpressionParser.
  *
  * @author Joshua Davis
  */
 public class DotNode extends FromReferenceNode implements DisplayableNode, SelectExpression {
 
 	///////////////////////////////////////////////////////////////////////////
 	// USED ONLY FOR REGRESSION TESTING!!!!
 	//
 	// todo : obviously get rid of all this junk ;)
 	///////////////////////////////////////////////////////////////////////////
-	public static boolean useThetaStyleImplicitJoins = false;
-	public static boolean REGRESSION_STYLE_JOIN_SUPPRESSION = false;
+	public static boolean useThetaStyleImplicitJoins;
+	public static boolean REGRESSION_STYLE_JOIN_SUPPRESSION;
 	public static interface IllegalCollectionDereferenceExceptionBuilder {
 		public QueryException buildIllegalCollectionDereferenceException(String collectionPropertyName, FromReferenceNode lhs);
 	}
 	public static final IllegalCollectionDereferenceExceptionBuilder DEF_ILLEGAL_COLL_DEREF_EXCP_BUILDER = new IllegalCollectionDereferenceExceptionBuilder() {
 		public QueryException buildIllegalCollectionDereferenceException(String propertyName, FromReferenceNode lhs) {
 			String lhsPath = ASTUtil.getPathText( lhs );
 			return new QueryException( "illegal attempt to dereference collection [" + lhsPath + "] with element property reference [" + propertyName + "]" );
 		}
 	};
 	public static IllegalCollectionDereferenceExceptionBuilder ILLEGAL_COLL_DEREF_EXCP_BUILDER = DEF_ILLEGAL_COLL_DEREF_EXCP_BUILDER;
 	///////////////////////////////////////////////////////////////////////////
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, DotNode.class.getName());
 
-	private static final int DEREF_UNKNOWN = 0;
-	private static final int DEREF_ENTITY = 1;
-	private static final int DEREF_COMPONENT = 2;
-	private static final int DEREF_COLLECTION = 3;
-	private static final int DEREF_PRIMITIVE = 4;
-	private static final int DEREF_IDENTIFIER = 5;
-	private static final int DEREF_JAVA_CONSTANT = 6;
+	public static enum DereferenceType {
+		UNKNOWN,
+		ENTITY,
+		COMPONENT,
+		COLLECTION,
+		PRIMITIVE,
+		IDENTIFIER,
+		JAVA_CONSTANT
+	}
 
 	/**
 	 * The identifier that is the name of the property.
 	 */
 	private String propertyName;
 	/**
 	 * The full path, to the root alias of this dot node.
 	 */
 	private String path;
 	/**
 	 * The unresolved property path relative to this dot node.
 	 */
 	private String propertyPath;
 
 	/**
 	 * The column names that this resolves to.
 	 */
 	private String[] columns;
 
 	/**
 	 * The type of join to create.   Default is an inner join.
 	 */
 	private JoinType joinType = JoinType.INNER_JOIN;
 
 	/**
 	 * Fetch join or not.
 	 */
 	private boolean fetch = false;
 
 	/**
-	 * The type of dereference that hapened (DEREF_xxx).
+	 * The type of dereference that hapened
 	 */
-	private int dereferenceType = DEREF_UNKNOWN;
+	private DereferenceType dereferenceType = DereferenceType.UNKNOWN;
 
 	private FromElement impliedJoin;
 
 	/**
 	 * Sets the join type for this '.' node structure.
 	 *
 	 * @param joinType The type of join to use.
 	 * @see JoinFragment
 	 */
 	public void setJoinType(JoinType joinType) {
 		this.joinType = joinType;
 	}
 
 	private String[] getColumns() throws QueryException {
 		if ( columns == null ) {
 			// Use the table fromElement and the property name to get the array of column names.
 			String tableAlias = getLhs().getFromElement().getTableAlias();
 			columns = getFromElement().toColumns( tableAlias, propertyPath, false );
 		}
 		return columns;
 	}
 
 	@Override
     public String getDisplayText() {
 		StringBuilder buf = new StringBuilder();
 		FromElement fromElement = getFromElement();
 		buf.append( "{propertyName=" ).append( propertyName );
-		buf.append( ",dereferenceType=" ).append( getWalker().getASTPrinter().getTokenTypeName( dereferenceType ) );
+		buf.append( ",dereferenceType=" ).append( dereferenceType.name() );
 		buf.append( ",getPropertyPath=" ).append( propertyPath );
 		buf.append( ",path=" ).append( getPath() );
 		if ( fromElement != null ) {
 			buf.append( ",tableAlias=" ).append( fromElement.getTableAlias() );
 			buf.append( ",className=" ).append( fromElement.getClassName() );
 			buf.append( ",classAlias=" ).append( fromElement.getClassAlias() );
 		}
 		else {
 			buf.append( ",no from element" );
 		}
 		buf.append( '}' );
 		return buf.toString();
 	}
 
 	/**
 	 * Resolves the left hand side of the DOT.
 	 *
 	 * @throws SemanticException
 	 */
 	@Override
     public void resolveFirstChild() throws SemanticException {
 		FromReferenceNode lhs = ( FromReferenceNode ) getFirstChild();
 		SqlNode property = ( SqlNode ) lhs.getNextSibling();
 
 		// Set the attributes of the property reference expression.
 		String propName = property.getText();
 		propertyName = propName;
 		// If the uresolved property path isn't set yet, just use the property name.
 		if ( propertyPath == null ) {
 			propertyPath = propName;
 		}
 		// Resolve the LHS fully, generate implicit joins.  Pass in the property name so that the resolver can
 		// discover foreign key (id) properties.
 		lhs.resolve( true, true, null, this );
 		setFromElement( lhs.getFromElement() );			// The 'from element' that the property is in.
 
 		checkSubclassOrSuperclassPropertyReference( lhs, propName );
 	}
 
 	@Override
     public void resolveInFunctionCall(boolean generateJoin, boolean implicitJoin) throws SemanticException {
 		if ( isResolved() ) {
 			return;
 		}
 		Type propertyType = prepareLhs();			// Prepare the left hand side and get the data type.
 		if ( propertyType!=null && propertyType.isCollectionType() ) {
 			resolveIndex(null);
 		}
 		else {
 			resolveFirstChild();
 			super.resolve(generateJoin, implicitJoin);
 		}
 	}
 
 
 	public void resolveIndex(AST parent) throws SemanticException {
 		if ( isResolved() ) {
 			return;
 		}
 		Type propertyType = prepareLhs();			// Prepare the left hand side and get the data type.
 		dereferenceCollection( ( CollectionType ) propertyType, true, true, null, parent );
 	}
 
 	public void resolve(boolean generateJoin, boolean implicitJoin, String classAlias, AST parent)
 	throws SemanticException {
 		// If this dot has already been resolved, stop now.
 		if ( isResolved() ) {
 			return;
 		}
 		Type propertyType = prepareLhs(); // Prepare the left hand side and get the data type.
 
 		// If there is no data type for this node, and we're at the end of the path (top most dot node), then
 		// this might be a Java constant.
 		if ( propertyType == null ) {
 			if ( parent == null ) {
 				getWalker().getLiteralProcessor().lookupConstant( this );
 			}
 			// If the propertyType is null and there isn't a parent, just
 			// stop now... there was a problem resolving the node anyway.
 			return;
 		}
 
 		if ( propertyType.isComponentType() ) {
 			// The property is a component...
 			checkLhsIsNotCollection();
 			dereferenceComponent( parent );
 			initText();
 		}
 		else if ( propertyType.isEntityType() ) {
 			// The property is another class..
 			checkLhsIsNotCollection();
 			dereferenceEntity( ( EntityType ) propertyType, implicitJoin, classAlias, generateJoin, parent );
 			initText();
 		}
 		else if ( propertyType.isCollectionType() ) {
 			// The property is a collection...
 			checkLhsIsNotCollection();
 			dereferenceCollection( ( CollectionType ) propertyType, implicitJoin, false, classAlias, parent );
 		}
 		else {
 			// Otherwise, this is a primitive type.
 			if ( ! CollectionProperties.isAnyCollectionProperty( propertyName ) ) {
 				checkLhsIsNotCollection();
 			}
-			dereferenceType = DEREF_PRIMITIVE;
+			dereferenceType = DereferenceType.PRIMITIVE;
 			initText();
 		}
 		setResolved();
 	}
 
 	private void initText() {
 		String[] cols = getColumns();
 		String text = StringHelper.join( ", ", cols );
 		if ( cols.length > 1 && getWalker().isComparativeExpressionClause() ) {
 			text = "(" + text + ")";
 		}
 		setText( text );
 	}
 
 	private Type prepareLhs() throws SemanticException {
 		FromReferenceNode lhs = getLhs();
 		lhs.prepareForDot( propertyName );
 		return getDataType();
 	}
 
 	private void dereferenceCollection(CollectionType collectionType, boolean implicitJoin, boolean indexed, String classAlias, AST parent)
 	throws SemanticException {
 
-		dereferenceType = DEREF_COLLECTION;
+		dereferenceType = DereferenceType.COLLECTION;
 		String role = collectionType.getRole();
 
 		//foo.bars.size (also handles deprecated stuff like foo.bars.maxelement for backwardness)
 		boolean isSizeProperty = getNextSibling()!=null &&
 			CollectionProperties.isAnyCollectionProperty( getNextSibling().getText() );
 
 		if ( isSizeProperty ) indexed = true; //yuck!
 
 		QueryableCollection queryableCollection = getSessionFactoryHelper().requireQueryableCollection( role );
 		String propName = getPath();
 		FromClause currentFromClause = getWalker().getCurrentFromClause();
 
 		// determine whether we should use the table name or table alias to qualify the column names...
 		// we need to use the table-name when:
 		//		1) the top-level statement is not a SELECT
 		//		2) the LHS FromElement is *the* FromElement from the top-level statement
 		//
 		// there is a caveat here.. if the update/delete statement are "multi-table" we should continue to use
 		// the alias also, even if the FromElement is the root one...
 		//
 		// in all other cases, we should use the table alias
 		final FromElement lhsFromElement = getLhs().getFromElement();
 		if ( getWalker().getStatementType() != SqlTokenTypes.SELECT ) {
 			if ( isFromElementUpdateOrDeleteRoot( lhsFromElement ) ) {
 				// at this point we know we have the 2 conditions above,
 				// lets see if we have the mentioned "multi-table" caveat...
 				boolean useAlias = false;
 				if ( getWalker().getStatementType() != SqlTokenTypes.INSERT ) {
 					final Queryable persister = lhsFromElement.getQueryable();
 					if ( persister.isMultiTable() ) {
 						useAlias = true;
 					}
 				}
 				if ( ! useAlias ) {
 					final String lhsTableName = lhsFromElement.getQueryable().getTableName();
 					columns = getFromElement().toColumns( lhsTableName, propertyPath, false, true );
 				}
 			}
 		}
 
 		// We do not look for an existing join on the same path, because
 		// it makes sense to join twice on the same collection role
 		FromElementFactory factory = new FromElementFactory(
 		        currentFromClause,
 		        getLhs().getFromElement(),
 		        propName,
 				classAlias,
 		        getColumns(),
 		        implicitJoin
 		);
 		FromElement elem = factory.createCollection( queryableCollection, role, joinType, fetch, indexed );
 
 		LOG.debugf( "dereferenceCollection() : Created new FROM element for %s : %s", propName, elem );
 
 		setImpliedJoin( elem );
 		setFromElement( elem );	// This 'dot' expression now refers to the resulting from element.
 
 		if ( isSizeProperty ) {
 			elem.setText("");
 			elem.setUseWhereFragment(false);
 		}
 
 		if ( !implicitJoin ) {
 			EntityPersister entityPersister = elem.getEntityPersister();
 			if ( entityPersister != null ) {
 				getWalker().addQuerySpaces( entityPersister.getQuerySpaces() );
 			}
 		}
 		getWalker().addQuerySpaces( queryableCollection.getCollectionSpaces() );	// Always add the collection's query spaces.
 	}
 
 	private void dereferenceEntity(EntityType entityType, boolean implicitJoin, String classAlias, boolean generateJoin, AST parent) throws SemanticException {
 		checkForCorrelatedSubquery( "dereferenceEntity" );
 		// three general cases we check here as to whether to render a physical SQL join:
 		// 1) is our parent a DotNode as well?  If so, our property reference is
 		// 		being further de-referenced...
 		// 2) is this a DML statement
 		// 3) we were asked to generate any needed joins (generateJoins==true) *OR*
 		//		we are currently processing a select or from clause
 		// (an additional check is the REGRESSION_STYLE_JOIN_SUPPRESSION check solely intended for the test suite)
 		//
 		// The REGRESSION_STYLE_JOIN_SUPPRESSION is an additional check
 		// intended solely for use within the test suite.  This forces the
 		// implicit join resolution to behave more like the classic parser.
 		// The underlying issue is that classic translator is simply wrong
 		// about its decisions on whether or not to render an implicit join
 		// into a physical SQL join in a lot of cases.  The piece it generally
 		// tends to miss is that INNER joins effect the results by further
 		// restricting the data set!  A particular manifestation of this is
 		// the fact that the classic translator will skip the physical join
 		// for ToOne implicit joins *if the query is shallow*; the result
 		// being that Query.list() and Query.iterate() could return
 		// different number of results!
 		DotNode parentAsDotNode = null;
 		String property = propertyName;
 		final boolean joinIsNeeded;
 
 		if ( isDotNode( parent ) ) {
 			// our parent is another dot node, meaning we are being further dereferenced.
 			// thus we need to generate a join unless the parent refers to the associated
 			// entity's PK (because 'our' table would know the FK).
 			parentAsDotNode = ( DotNode ) parent;
 			property = parentAsDotNode.propertyName;
 			joinIsNeeded = generateJoin && !isReferenceToPrimaryKey( parentAsDotNode.propertyName, entityType );
 		}
 		else if ( ! getWalker().isSelectStatement() ) {
 			// in non-select queries, the only time we should need to join is if we are in a subquery from clause
 			joinIsNeeded = getWalker().getCurrentStatementType() == SqlTokenTypes.SELECT && getWalker().isInFrom();
 		}
 		else if ( REGRESSION_STYLE_JOIN_SUPPRESSION ) {
 			// this is the regression style determination which matches the logic of the classic translator
 			joinIsNeeded = generateJoin && ( !getWalker().isInSelect() || !getWalker().isShallowQuery() );
 		}
 		else {
 			joinIsNeeded = generateJoin || ( getWalker().isInSelect() || getWalker().isInFrom() );
 		}
 
 		if ( joinIsNeeded ) {
 			dereferenceEntityJoin( classAlias, entityType, implicitJoin, parent );
 		}
 		else {
 			dereferenceEntityIdentifier( property, parentAsDotNode );
 		}
 
 	}
 
 	private boolean isDotNode(AST n) {
 		return n != null && n.getType() == SqlTokenTypes.DOT;
 	}
 
 	private void dereferenceEntityJoin(String classAlias, EntityType propertyType, boolean impliedJoin, AST parent)
 	throws SemanticException {
-		dereferenceType = DEREF_ENTITY;
-        if (LOG.isDebugEnabled()) LOG.debugf("dereferenceEntityJoin() : generating join for %s in %s (%s) parent = %s",
-                                             propertyName,
-                                             getFromElement().getClassName(),
-                                             classAlias == null ? "<no alias>" : classAlias,
-                                             ASTUtil.getDebugString(parent));
+		dereferenceType = DereferenceType.ENTITY;
+        if ( LOG.isDebugEnabled() ) {
+			LOG.debugf(
+					"dereferenceEntityJoin() : generating join for %s in %s (%s) parent = %s",
+					propertyName,
+					getFromElement().getClassName(),
+					classAlias == null ? "<no alias>" : classAlias,
+					ASTUtil.getDebugString(parent)
+			);
+		}
 		// Create a new FROM node for the referenced class.
 		String associatedEntityName = propertyType.getAssociatedEntityName();
 		String tableAlias = getAliasGenerator().createName( associatedEntityName );
 
 		String[] joinColumns = getColumns();
 		String joinPath = getPath();
 
 		if ( impliedJoin && getWalker().isInFrom() ) {
 			joinType = getWalker().getImpliedJoinType();
 		}
 
 		FromClause currentFromClause = getWalker().getCurrentFromClause();
 		FromElement elem = currentFromClause.findJoinByPath( joinPath );
 
 ///////////////////////////////////////////////////////////////////////////////
 //
 // This is the piece which recognizes the condition where an implicit join path
 // resolved earlier in a correlated subquery is now being referenced in the
 // outer query.  For 3.0final, we just let this generate a second join (which
 // is exactly how the old parser handles this).  Eventually we need to add this
 // logic back in and complete the logic in FromClause.promoteJoin; however,
 // FromClause.promoteJoin has its own difficulties (see the comments in
 // FromClause.promoteJoin).
 //
 //		if ( elem == null ) {
 //			// see if this joinPath has been used in a "child" FromClause, and if so
 //			// promote that element to the outer query
 //			FromClause currentNodeOwner = getFromElement().getFromClause();
 //			FromClause currentJoinOwner = currentNodeOwner.locateChildFromClauseWithJoinByPath( joinPath );
 //			if ( currentJoinOwner != null && currentNodeOwner != currentJoinOwner ) {
 //				elem = currentJoinOwner.findJoinByPathLocal( joinPath );
 //				if ( elem != null ) {
 //					currentFromClause.promoteJoin( elem );
 //					// EARLY EXIT!!!
 //					return;
 //				}
 //			}
 //		}
 //
 ///////////////////////////////////////////////////////////////////////////////
 
 		boolean found = elem != null;
 		// even though we might find a pre-existing element by join path, for FromElements originating in a from-clause
 		// we should only ever use the found element if the aliases match (null != null here).  Implied joins are
 		// always (?) ok to reuse.
 		boolean useFoundFromElement = found && ( elem.isImplied() || areSame( classAlias, elem.getClassAlias() ) );
 
 		if ( ! useFoundFromElement ) {
 			// If this is an implied join in a from element, then use the impled join type which is part of the
 			// tree parser's state (set by the gramamar actions).
 			JoinSequence joinSequence = getSessionFactoryHelper()
 				.createJoinSequence( impliedJoin, propertyType, tableAlias, joinType, joinColumns );
 
 			// If the lhs of the join is a "component join", we need to go back to the
 			// first non-component-join as the origin to properly link aliases and
 			// join columns
 			FromElement lhsFromElement = getLhs().getFromElement();
 			while ( lhsFromElement != null &&  ComponentJoin.class.isInstance( lhsFromElement ) ) {
 				lhsFromElement = lhsFromElement.getOrigin();
 			}
 			if ( lhsFromElement == null ) {
 				throw new QueryException( "Unable to locate appropriate lhs" );
 			}
 			
 			String role = lhsFromElement.getClassName() + "." + propertyName;
 
 			FromElementFactory factory = new FromElementFactory(
 			        currentFromClause,
 					lhsFromElement,
 					joinPath,
 					classAlias,
 					joinColumns,
 					impliedJoin
 			);
 			elem = factory.createEntityJoin(
 					associatedEntityName,
 					tableAlias,
 					joinSequence,
 					fetch,
 					getWalker().isInFrom(),
 					propertyType,
 					role,
 					joinPath
 			);
 		}
 		else {
 			// NOTE : addDuplicateAlias() already performs nullness checks on the alias.
 			currentFromClause.addDuplicateAlias( classAlias, elem );
 		}
 		setImpliedJoin( elem );
 		getWalker().addQuerySpaces( elem.getEntityPersister().getQuerySpaces() );
 		setFromElement( elem );	// This 'dot' expression now refers to the resulting from element.
 	}
 
 	private boolean areSame(String alias1, String alias2) {
 		// again, null != null here
 		return !StringHelper.isEmpty( alias1 ) && !StringHelper.isEmpty( alias2 ) && alias1.equals( alias2 );
 	}
 
 	private void setImpliedJoin(FromElement elem) {
 		this.impliedJoin = elem;
 		if ( getFirstChild().getType() == SqlTokenTypes.DOT ) {
 			DotNode dotLhs = ( DotNode ) getFirstChild();
 			if ( dotLhs.getImpliedJoin() != null ) {
 				this.impliedJoin = dotLhs.getImpliedJoin();
 			}
 		}
 	}
 
 	@Override
     public FromElement getImpliedJoin() {
 		return impliedJoin;
 	}
 
 	/**
 	 * Is the given property name a reference to the primary key of the associated
 	 * entity construed by the given entity type?
 	 * <p/>
 	 * For example, consider a fragment like order.customer.id
 	 * (where order is a from-element alias).  Here, we'd have:
 	 * propertyName = "id" AND
 	 * owningType = ManyToOneType(Customer)
 	 * and are being asked to determine whether "customer.id" is a reference
 	 * to customer's PK...
 	 *
 	 * @param propertyName The name of the property to check.
 	 * @param owningType The type represeting the entity "owning" the property
 	 * @return True if propertyName references the entity's (owningType->associatedEntity)
 	 * primary key; false otherwise.
 	 */
 	private boolean isReferenceToPrimaryKey(String propertyName, EntityType owningType) {
 		EntityPersister persister = getSessionFactoryHelper()
 				.getFactory()
 				.getEntityPersister( owningType.getAssociatedEntityName() );
 		if ( persister.getEntityMetamodel().hasNonIdentifierPropertyNamedId() ) {
 			// only the identifier property field name can be a reference to the associated entity's PK...
 			return propertyName.equals( persister.getIdentifierPropertyName() ) && owningType.isReferenceToPrimaryKey();
 		}
         // here, we have two possibilities:
         // 1) the property-name matches the explicitly identifier property name
         // 2) the property-name matches the implicit 'id' property name
         // the referenced node text is the special 'id'
         if (EntityPersister.ENTITY_ID.equals(propertyName)) return owningType.isReferenceToPrimaryKey();
         String keyPropertyName = getSessionFactoryHelper().getIdentifierOrUniqueKeyPropertyName(owningType);
         return keyPropertyName != null && keyPropertyName.equals(propertyName) && owningType.isReferenceToPrimaryKey();
 	}
 
 	private void checkForCorrelatedSubquery(String methodName) {
 		if ( isCorrelatedSubselect() ) {
 			LOG.debugf( "%s() : correlated subquery", methodName );
 		}
 	}
 
 	private boolean isCorrelatedSubselect() {
 		return getWalker().isSubQuery() &&
 			getFromElement().getFromClause() != getWalker().getCurrentFromClause();
 	}
 
 	private void checkLhsIsNotCollection() throws SemanticException {
 		if ( getLhs().getDataType() != null && getLhs().getDataType().isCollectionType() ) {
 			throw ILLEGAL_COLL_DEREF_EXCP_BUILDER.buildIllegalCollectionDereferenceException( propertyName, getLhs() );
 		}
 	}
 	private void dereferenceComponent(AST parent) {
-		dereferenceType = DEREF_COMPONENT;
+		dereferenceType = DereferenceType.COMPONENT;
 		setPropertyNameAndPath( parent );
 	}
 
 	private void dereferenceEntityIdentifier(String propertyName, DotNode dotParent) {
 		// special shortcut for id properties, skip the join!
 		// this must only occur at the _end_ of a path expression
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "dereferenceShortcut() : property %s in %s does not require a join.",
 					propertyName,
 					getFromElement().getClassName() );
 		}
 
 		initText();
 		setPropertyNameAndPath( dotParent ); // Set the unresolved path in this node and the parent.
 		// Set the text for the parent.
 		if ( dotParent != null ) {
-			dotParent.dereferenceType = DEREF_IDENTIFIER;
+			dotParent.dereferenceType = DereferenceType.IDENTIFIER;
 			dotParent.setText( getText() );
 			dotParent.columns = getColumns();
 		}
 	}
 
 	private void setPropertyNameAndPath(AST parent) {
 		if ( isDotNode( parent ) ) {
 			DotNode dotNode = ( DotNode ) parent;
 			AST lhs = dotNode.getFirstChild();
 			AST rhs = lhs.getNextSibling();
 			propertyName = rhs.getText();
 			propertyPath = propertyPath + "." + propertyName; // Append the new property name onto the unresolved path.
 			dotNode.propertyPath = propertyPath;
 			LOG.debugf( "Unresolved property path is now '%s'", dotNode.propertyPath );
 		}
 		else {
 			LOG.debugf( "Terminal getPropertyPath = [%s]", propertyPath );
 		}
 	}
 
 	@Override
     public Type getDataType() {
 		if ( super.getDataType() == null ) {
 			FromElement fromElement = getLhs().getFromElement();
 			if ( fromElement == null ) return null;
 			// If the lhs is a collection, use CollectionPropertyMapping
 			Type propertyType = fromElement.getPropertyType( propertyName, propertyPath );
 			LOG.debugf( "getDataType() : %s -> %s", propertyPath, propertyType );
 			super.setDataType( propertyType );
 		}
 		return super.getDataType();
 	}
 
 	public void setPropertyPath(String propertyPath) {
 		this.propertyPath = propertyPath;
 	}
 
 	public String getPropertyPath() {
 		return propertyPath;
 	}
 
 	public FromReferenceNode getLhs() {
 		FromReferenceNode lhs = ( ( FromReferenceNode ) getFirstChild() );
 		if ( lhs == null ) {
 			throw new IllegalStateException( "DOT node with no left-hand-side!" );
 		}
 		return lhs;
 	}
 
 	/**
 	 * Returns the full path of the node.
 	 *
 	 * @return the full path of the node.
 	 */
 	@Override
     public String getPath() {
 		if ( path == null ) {
 			FromReferenceNode lhs = getLhs();
 			if ( lhs == null ) {
 				path = getText();
 			}
 			else {
 				SqlNode rhs = ( SqlNode ) lhs.getNextSibling();
 				path = lhs.getPath() + "." + rhs.getOriginalText();
 			}
 		}
 		return path;
 	}
 
 	public void setFetch(boolean fetch) {
 		this.fetch = fetch;
 	}
 
 	public void setScalarColumnText(int i) throws SemanticException {
 		String[] sqlColumns = getColumns();
 		ColumnHelper.generateScalarColumns( this, sqlColumns, i );
 	}
 
 	/**
 	 * Special method to resolve expressions in the SELECT list.
 	 *
 	 * @throws SemanticException if this cannot be resolved.
 	 */
 	public void resolveSelectExpression() throws SemanticException {
 		if ( getWalker().isShallowQuery() || getWalker().getCurrentFromClause().isSubQuery() ) {
 			resolve(false, true);
 		}
 		else {
 			resolve(true, false);
 			Type type = getDataType();
 			if ( type.isEntityType() ) {
 				FromElement fromElement = getFromElement();
 				fromElement.setIncludeSubclasses( true ); // Tell the destination fromElement to 'includeSubclasses'.
 				if ( useThetaStyleImplicitJoins ) {
 					fromElement.getJoinSequence().setUseThetaStyle( true );	// Use theta style (for regression)
 					// Move the node up, after the origin node.
 					FromElement origin = fromElement.getOrigin();
 					if ( origin != null ) {
 						ASTUtil.makeSiblingOfParent( origin, fromElement );
 					}
 				}
 			}
 		}
 
 		FromReferenceNode lhs = getLhs();
 		while ( lhs != null ) {
 			checkSubclassOrSuperclassPropertyReference( lhs, lhs.getNextSibling().getText() );
 			lhs = ( FromReferenceNode ) lhs.getFirstChild();
 		}
 	}
 
 	public void setResolvedConstant(String text) {
 		path = text;
-		dereferenceType = DEREF_JAVA_CONSTANT;
+		dereferenceType = DereferenceType.JAVA_CONSTANT;
 		setResolved(); // Don't resolve the node again.
 	}
 
 	private boolean checkSubclassOrSuperclassPropertyReference(FromReferenceNode lhs, String propertyName) {
 		if ( lhs != null && !( lhs instanceof IndexNode ) ) {
 			final FromElement source = lhs.getFromElement();
 			if ( source != null ) {
 				source.handlePropertyBeingDereferenced( lhs.getDataType(), propertyName );
 			}
 		}
 		return false;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromClause.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromClause.java
index f20d2ebc31..d1bf7093de 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromClause.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromClause.java
@@ -1,410 +1,411 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.tree;
+
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import antlr.SemanticException;
 import antlr.collections.AST;
-import org.jboss.logging.Logger;
 
 import org.hibernate.hql.internal.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.internal.ast.util.ASTIterator;
 import org.hibernate.hql.internal.ast.util.ASTUtil;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 
 /**
  * Represents the 'FROM' part of a query or subquery, containing all mapped class references.
  *
  * @author josh
  */
 public class FromClause extends HqlSqlWalkerNode implements HqlSqlTokenTypes, DisplayableNode {
+    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( FromClause.class );
 
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, FromClause.class.getName());
 	public static final int ROOT_LEVEL = 1;
 
 	private int level = ROOT_LEVEL;
 	private Set fromElements = new HashSet();
 	private Map fromElementByClassAlias = new HashMap();
 	private Map fromElementByTableAlias = new HashMap();
 	private Map fromElementsByPath = new HashMap();
 
 	/**
 	 * All of the implicit FROM xxx JOIN yyy elements that are the destination of a collection.  These are created from
 	 * index operators on collection property references.
 	 */
 	private Map collectionJoinFromElementsByPath = new HashMap();
 	/**
 	 * Pointer to the parent FROM clause, if there is one.
 	 */
 	private FromClause parentFromClause;
 	/**
 	 * Collection of FROM clauses of which this is the parent.
 	 */
 	private Set childFromClauses;
 	/**
 	 * Counts the from elements as they are added.
 	 */
-	private int fromElementCounter = 0;
+	private int fromElementCounter;
 	/**
 	 * Implied FROM elements to add onto the end of the FROM clause.
 	 */
 	private List impliedElements = new LinkedList();
 
 	/**
 	 * Adds a new from element to the from node.
 	 *
 	 * @param path  The reference to the class.
 	 * @param alias The alias AST.
 	 * @return FromElement - The new FROM element.
 	 */
 	public FromElement addFromElement(String path, AST alias) throws SemanticException {
 		// The path may be a reference to an alias defined in the parent query.
 		String classAlias = ( alias == null ) ? null : alias.getText();
 		checkForDuplicateClassAlias( classAlias );
 		FromElementFactory factory = new FromElementFactory( this, null, path, classAlias, null, false );
 		return factory.addFromElement();
 	}
 
 	void registerFromElement(FromElement element) {
 		fromElements.add( element );
 		String classAlias = element.getClassAlias();
 		if ( classAlias != null ) {
 			// The HQL class alias refers to the class name.
 			fromElementByClassAlias.put( classAlias, element );
 		}
 		// Associate the table alias with the element.
 		String tableAlias = element.getTableAlias();
 		if ( tableAlias != null ) {
 			fromElementByTableAlias.put( tableAlias, element );
 		}
 	}
 
 	void addDuplicateAlias(String alias, FromElement element) {
 		if ( alias != null ) {
 			fromElementByClassAlias.put( alias, element );
 		}
 	}
 
 	private void checkForDuplicateClassAlias(String classAlias) throws SemanticException {
 		if ( classAlias != null && fromElementByClassAlias.containsKey( classAlias ) ) {
 			throw new SemanticException( "Duplicate definition of alias '" + classAlias + "'" );
 		}
 	}
 
 	/**
 	 * Retreives the from-element represented by the given alias.
 	 *
 	 * @param aliasOrClassName The alias by which to locate the from-element.
 	 * @return The from-element assigned the given alias, or null if none.
 	 */
 	public FromElement getFromElement(String aliasOrClassName) {
 		FromElement fromElement = ( FromElement ) fromElementByClassAlias.get( aliasOrClassName );
 		if ( fromElement == null && getSessionFactoryHelper().isStrictJPAQLComplianceEnabled() ) {
 			fromElement = findIntendedAliasedFromElementBasedOnCrazyJPARequirements( aliasOrClassName );
 		}
 		if ( fromElement == null && parentFromClause != null ) {
 			fromElement = parentFromClause.getFromElement( aliasOrClassName );
 		}
 		return fromElement;
 	}
 
 	public FromElement findFromElementBySqlAlias(String sqlAlias) {
 		FromElement fromElement = ( FromElement ) fromElementByTableAlias.get( sqlAlias );
 		if ( fromElement == null && parentFromClause != null ) {
 			fromElement = parentFromClause.getFromElement( sqlAlias );
 		}
 		return fromElement;
 	}
 
 	public FromElement findFromElementByUserOrSqlAlias(String userAlias, String sqlAlias) {
 		FromElement fromElement = null;
 		if ( userAlias != null ) {
 			fromElement = getFromElement( userAlias );
 		}
 
 		if ( fromElement == null ) {
 			fromElement = findFromElementBySqlAlias( sqlAlias );
 		}
 
 		return fromElement;
 	}
 
 	private FromElement findIntendedAliasedFromElementBasedOnCrazyJPARequirements(String specifiedAlias) {
 		Iterator itr = fromElementByClassAlias.entrySet().iterator();
 		while ( itr.hasNext() ) {
 			Map.Entry entry = ( Map.Entry ) itr.next();
 			String alias = ( String ) entry.getKey();
 			if ( alias.equalsIgnoreCase( specifiedAlias ) ) {
 				return ( FromElement ) entry.getValue();
 			}
 		}
 		return null;
 	}
 
 	/**
 	 * Convenience method to check whether a given token represents a from-element alias.
 	 *
 	 * @param possibleAlias The potential from-element alias to check.
 	 * @return True if the possibleAlias is an alias to a from-element visible
 	 *         from this point in the query graph.
 	 */
 	public boolean isFromElementAlias(String possibleAlias) {
 		boolean isAlias = containsClassAlias( possibleAlias );
 		if ( !isAlias && parentFromClause != null ) {
 			// try the parent FromClause...
 			isAlias = parentFromClause.isFromElementAlias( possibleAlias );
 		}
 		return isAlias;
 	}
 
 	/**
 	 * Returns the list of from elements in order.
 	 *
 	 * @return the list of from elements (instances of FromElement).
 	 */
 	public List getFromElements() {
 		return ASTUtil.collectChildren( this, fromElementPredicate );
 	}
 
 	public FromElement getFromElement() {
 		// TODO: not sure about this one
 //		List fromElements = getFromElements();
 //		if ( fromElements == null || fromElements.isEmpty() ) {
 //			throw new QueryException( "Unable to locate from element" );
 //		}
 		return (FromElement) getFromElements().get(0);
 	}
 
 	/**
 	 * Returns the list of from elements that will be part of the result set.
 	 *
 	 * @return the list of from elements that will be part of the result set.
 	 */
 	public List getProjectionList() {
 		return ASTUtil.collectChildren( this, projectionListPredicate );
 	}
 
 	public List getCollectionFetches() {
 		return ASTUtil.collectChildren( this, collectionFetchPredicate );
 	}
 
 	public boolean hasCollectionFecthes() {
 		return getCollectionFetches().size() > 0;
 	}
 
 	public List getExplicitFromElements() {
 		return ASTUtil.collectChildren( this, explicitFromPredicate );
 	}
 
 	private static ASTUtil.FilterPredicate fromElementPredicate = new ASTUtil.IncludePredicate() {
 		@Override
         public boolean include(AST node) {
 			FromElement fromElement = ( FromElement ) node;
 			return fromElement.isFromOrJoinFragment();
 		}
 	};
 
 	private static ASTUtil.FilterPredicate projectionListPredicate = new ASTUtil.IncludePredicate() {
 		@Override
         public boolean include(AST node) {
 			FromElement fromElement = ( FromElement ) node;
 			return fromElement.inProjectionList();
 		}
 	};
 
 	private static ASTUtil.FilterPredicate collectionFetchPredicate = new ASTUtil.IncludePredicate() {
 		@Override
         public boolean include(AST node) {
 			FromElement fromElement = ( FromElement ) node;
 			return fromElement.isFetch() && fromElement.getQueryableCollection() != null;
 		}
 	};
 
 	private static ASTUtil.FilterPredicate explicitFromPredicate = new ASTUtil.IncludePredicate() {
 		@Override
         public boolean include(AST node) {
 			final FromElement fromElement = ( FromElement ) node;
 			return !fromElement.isImplied();
 		}
 	};
 
 	FromElement findCollectionJoin(String path) {
 		return ( FromElement ) collectionJoinFromElementsByPath.get( path );
 	}
 
 	/**
 	 * Look for an existing implicit or explicit join by the
 	 * given path.
 	 */
 	FromElement findJoinByPath(String path) {
 		FromElement elem = findJoinByPathLocal( path );
 		if ( elem == null && parentFromClause != null ) {
 			elem = parentFromClause.findJoinByPath( path );
 		}
 		return elem;
 	}
 
 	FromElement findJoinByPathLocal(String path) {
 		Map joinsByPath = fromElementsByPath;
 		return ( FromElement ) joinsByPath.get( path );
 	}
 
 	void addJoinByPathMap(String path, FromElement destination) {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "addJoinByPathMap() : %s -> %s", path, destination.getDisplayText() );
 		}
 		fromElementsByPath.put( path, destination );
 	}
 
 	/**
 	 * Returns true if the from node contains the class alias name.
 	 *
 	 * @param alias The HQL class alias name.
 	 * @return true if the from node contains the class alias name.
 	 */
 	public boolean containsClassAlias(String alias) {
 		boolean isAlias = fromElementByClassAlias.containsKey( alias );
 		if ( !isAlias && getSessionFactoryHelper().isStrictJPAQLComplianceEnabled() ) {
 			isAlias = findIntendedAliasedFromElementBasedOnCrazyJPARequirements( alias ) != null;
 		}
 		return isAlias;
 	}
 
 	/**
 	 * Returns true if the from node contains the table alias name.
 	 *
 	 * @param alias The SQL table alias name.
 	 * @return true if the from node contains the table alias name.
 	 */
 	public boolean containsTableAlias(String alias) {
 		return fromElementByTableAlias.keySet().contains( alias );
 	}
 
 	public String getDisplayText() {
 		return "FromClause{" +
 				"level=" + level +
 				", fromElementCounter=" + fromElementCounter +
 				", fromElements=" + fromElements.size() +
 				", fromElementByClassAlias=" + fromElementByClassAlias.keySet() +
 				", fromElementByTableAlias=" + fromElementByTableAlias.keySet() +
 				", fromElementsByPath=" + fromElementsByPath.keySet() +
 				", collectionJoinFromElementsByPath=" + collectionJoinFromElementsByPath.keySet() +
 				", impliedElements=" + impliedElements +
 				"}";
 	}
 
 	public void setParentFromClause(FromClause parentFromClause) {
 		this.parentFromClause = parentFromClause;
 		if ( parentFromClause != null ) {
 			level = parentFromClause.getLevel() + 1;
 			parentFromClause.addChild( this );
 		}
 	}
 
 	private void addChild(FromClause fromClause) {
 		if ( childFromClauses == null ) {
 			childFromClauses = new HashSet();
 		}
 		childFromClauses.add( fromClause );
 	}
 
 	public FromClause locateChildFromClauseWithJoinByPath(String path) {
 		if ( childFromClauses != null && !childFromClauses.isEmpty() ) {
 			Iterator children = childFromClauses.iterator();
 			while ( children.hasNext() ) {
 				FromClause child = ( FromClause ) children.next();
 				if ( child.findJoinByPathLocal( path ) != null ) {
 					return child;
 				}
 			}
 		}
 		return null;
 	}
 
 	public void promoteJoin(FromElement elem) {
 		LOG.debugf( "Promoting [%s] to [%s]", elem, this );
 		//TODO: implement functionality
 		//  this might be painful to do here, as the "join post processing" for
 		//  the subquery has already been performed (meaning that for
 		//  theta-join dialects, the join conditions have already been moved
 		//  over to the where clause).  A "simple" solution here might to
 		//  doAfterTransactionCompletion "join post processing" once for the entire query (including
 		//  any subqueries) at one fell swoop
 	}
 
 	public boolean isSubQuery() {
 		// TODO : this is broke for subqueries in statements other than selects...
 		return parentFromClause != null;
 	}
 
 	void addCollectionJoinFromElementByPath(String path, FromElement destination) {
 		LOG.debugf( "addCollectionJoinFromElementByPath() : %s -> %s", path, destination );
 		collectionJoinFromElementsByPath.put( path, destination );	// Add the new node to the map so that we don't create it twice.
 	}
 
 	public FromClause getParentFromClause() {
 		return parentFromClause;
 	}
 
 	public int getLevel() {
 		return level;
 	}
 
 	public int nextFromElementCounter() {
 		return fromElementCounter++;
 	}
 
 	public void resolve() {
 		// Make sure that all from elements registered with this FROM clause are actually in the AST.
 		ASTIterator iter = new ASTIterator( this.getFirstChild() );
 		Set childrenInTree = new HashSet();
 		while ( iter.hasNext() ) {
 			childrenInTree.add( iter.next() );
 		}
 		for ( Iterator iterator = fromElements.iterator(); iterator.hasNext(); ) {
 			FromElement fromElement = ( FromElement ) iterator.next();
 			if ( !childrenInTree.contains( fromElement ) ) {
 				throw new IllegalStateException( "Element not in AST: " + fromElement );
 			}
 		}
 	}
 
 	public void addImpliedFromElement(FromElement element) {
 		impliedElements.add( element );
 	}
 
 	@Override
     public String toString() {
 		return "FromClause{" +
 				"level=" + level +
 				"}";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromElement.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromElement.java
index f6e0612490..339d0c6461 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromElement.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromElement.java
@@ -1,707 +1,705 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.tree;
 
 import java.util.ArrayList;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Set;
 
-import org.jboss.logging.Logger;
-
 import org.hibernate.QueryException;
 import org.hibernate.engine.internal.JoinSequence;
 import org.hibernate.hql.internal.CollectionProperties;
 import org.hibernate.hql.internal.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.internal.antlr.SqlTokenTypes;
 import org.hibernate.hql.internal.ast.TypeDiscriminatorMetadata;
 import org.hibernate.hql.internal.ast.util.ASTUtil;
 import org.hibernate.hql.spi.QueryTranslator;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.DiscriminatorMetadata;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 /**
  * Represents a single mapped class mentioned in an HQL FROM clause.  Each
  * class reference will have the following symbols:
  * <ul>
  * <li>A class name - This is the name of the Java class that is mapped by Hibernate.</li>
  * <li>[optional] an HQL alias for the mapped class.</li>
  * <li>A table name - The name of the table that is mapped to the Java class.</li>
  * <li>A table alias - The alias for the table that will be used in the resulting SQL.</li>
  * </ul>
  *
  * @author josh
  */
 public class FromElement extends HqlSqlWalkerNode implements DisplayableNode, ParameterContainer {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, FromElement.class.getName());
+    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( FromElement.class );
 
 	private String className;
 	private String classAlias;
 	private String tableAlias;
 	private String collectionTableAlias;
 	private FromClause fromClause;
 	private boolean includeSubclasses = true;
-	private boolean collectionJoin = false;
+	private boolean collectionJoin;
 	private FromElement origin;
 	private String[] columns;
 	private String role;
 	private boolean fetch;
 	private boolean isAllPropertyFetch;
-	private boolean filter = false;
+	private boolean filter;
 	private int sequence = -1;
-	private boolean useFromFragment = false;
-	private boolean initialized = false;
+	private boolean useFromFragment;
+	private boolean initialized;
 	private FromElementType elementType;
 	private boolean useWhereFragment = true;
 	private List destinations = new LinkedList();
-	private boolean manyToMany = false;
-	private String withClauseFragment = null;
+	private boolean manyToMany;
+	private String withClauseFragment;
 	private String withClauseJoinAlias;
 	private boolean dereferencedBySuperclassProperty;
 	private boolean dereferencedBySubclassProperty;
 
 	public FromElement() {
 	}
 
 	/**
 	 * Constructor form used to initialize {@link ComponentJoin}
 	 *
 	 * @param fromClause The FROM clause to which this element belongs
 	 * @param origin The origin (LHS) of this element
 	 * @param alias The alias applied to this element
 	 */
 	protected FromElement(
 			FromClause fromClause,
 			FromElement origin,
 			String alias) {
 		this.fromClause = fromClause;
 		this.origin = origin;
 		this.classAlias = alias;
 		this.tableAlias = origin.getTableAlias();
 		super.initialize( fromClause.getWalker() );
 
 	}
 
 	protected void initializeComponentJoin(FromElementType elementType) {
 		fromClause.registerFromElement( this );
 		elementType.applyTreatAsDeclarations( getWalker().getTreatAsDeclarationsByPath( classAlias ) );
 		this.elementType = elementType;
 		initialized = true;
 	}
 
 	public String getCollectionSuffix() {
 		return elementType.getCollectionSuffix();
 	}
 
 	public void setCollectionSuffix(String suffix) {
 		elementType.setCollectionSuffix(suffix);
 	}
 
 	public void initializeCollection(FromClause fromClause, String classAlias, String tableAlias) {
 		doInitialize( fromClause, tableAlias, null, classAlias, null, null );
 		initialized = true;
 	}
 
 	public void initializeEntity(
 	        FromClause fromClause,
 	        String className,
 	        EntityPersister persister,
 	        EntityType type,
 	        String classAlias,
 	        String tableAlias) {
 		doInitialize( fromClause, tableAlias, className, classAlias, persister, type );
 		this.sequence = fromClause.nextFromElementCounter();
 		initialized = true;
 	}
 
 	private void doInitialize(FromClause fromClause, String tableAlias, String className, String classAlias,
 							  EntityPersister persister, EntityType type) {
 		if ( initialized ) {
 			throw new IllegalStateException( "Already initialized!!" );
 		}
 		this.fromClause = fromClause;
 		this.tableAlias = tableAlias;
 		this.className = className;
 		this.classAlias = classAlias;
 		this.elementType = new FromElementType( this, persister, type );
 		// Register the FromElement with the FROM clause, now that we have the names and aliases.
 		fromClause.registerFromElement( this );
 		LOG.debugf( "%s : %s (%s) -> %s", fromClause, className, classAlias == null ? "<no alias>" : classAlias, tableAlias );
 	}
 
 	public EntityPersister getEntityPersister() {
 		return elementType.getEntityPersister();
 	}
 
 	@Override
     public Type getDataType() {
 		return elementType.getDataType();
 	}
 
 	public Type getSelectType() {
 		return elementType.getSelectType();
 	}
 
 	public Queryable getQueryable() {
 		return elementType.getQueryable();
 	}
 
 	public String getClassName() {
 		return className;
 	}
 
 	public String getClassAlias() {
 		return classAlias;
 		//return classAlias == null ? className : classAlias;
 	}
 
 	private String getTableName() {
 		Queryable queryable = getQueryable();
 		return ( queryable != null ) ? queryable.getTableName() : "{none}";
 	}
 
 	public String getTableAlias() {
 		return tableAlias;
 	}
 
 	/**
 	 * Render the identifier select, but in a 'scalar' context (i.e. generate the column alias).
 	 *
 	 * @param i the sequence of the returned type
 	 * @return the identifier select with the column alias.
 	 */
 	String renderScalarIdentifierSelect(int i) {
 		return elementType.renderScalarIdentifierSelect( i );
 	}
 
 	void checkInitialized() {
 		if ( !initialized ) {
 			throw new IllegalStateException( "FromElement has not been initialized!" );
 		}
 	}
 
 	/**
 	 * Returns the identifier select SQL fragment.
 	 *
 	 * @param size The total number of returned types.
 	 * @param k    The sequence of the current returned type.
 	 * @return the identifier select SQL fragment.
 	 */
 	String renderIdentifierSelect(int size, int k) {
 		return elementType.renderIdentifierSelect( size, k );
 	}
 
 	/**
 	 * Returns the property select SQL fragment.
 	 *
 	 * @param size The total number of returned types.
 	 * @param k    The sequence of the current returned type.
 	 * @return the property select SQL fragment.
 	 */
 	String renderPropertySelect(int size, int k) {
 		return elementType.renderPropertySelect( size, k, isAllPropertyFetch );
 	}
 
 	String renderCollectionSelectFragment(int size, int k) {
 		return elementType.renderCollectionSelectFragment( size, k );
 	}
 
 	String renderValueCollectionSelectFragment(int size, int k) {
 		return elementType.renderValueCollectionSelectFragment( size, k );
 	}
 
 	public FromClause getFromClause() {
 		return fromClause;
 	}
 
 	/**
 	 * Returns true if this FromElement was implied by a path, or false if this FROM element is explicitly declared in
 	 * the FROM clause.
 	 *
 	 * @return true if this FromElement was implied by a path, or false if this FROM element is explicitly declared
 	 */
 	public boolean isImplied() {
 		return false;	// This is an explicit FROM element.
 	}
 
 	/**
 	 * Returns additional display text for the AST node.
 	 *
 	 * @return String - The additional display text.
 	 */
 	public String getDisplayText() {
 		StringBuilder buf = new StringBuilder();
 		buf.append( "FromElement{" );
 		appendDisplayText( buf );
 		buf.append( "}" );
 		return buf.toString();
 	}
 
 	protected void appendDisplayText(StringBuilder buf) {
 		buf.append( isImplied() ? (
 				isImpliedInFromClause() ? "implied in FROM clause" : "implied" )
 				: "explicit" );
 		buf.append( "," ).append( isCollectionJoin() ? "collection join" : "not a collection join" );
 		buf.append( "," ).append( fetch ? "fetch join" : "not a fetch join" );
 		buf.append( "," ).append( isAllPropertyFetch ? "fetch all properties" : "fetch non-lazy properties" );
 		buf.append( ",classAlias=" ).append( getClassAlias() );
 		buf.append( ",role=" ).append( role );
 		buf.append( ",tableName=" ).append( getTableName() );
 		buf.append( ",tableAlias=" ).append( getTableAlias() );
 		FromElement origin = getRealOrigin();
 		buf.append( ",origin=" ).append( origin == null ? "null" : origin.getText() );
 		buf.append( ",columns={" );
 		if ( columns != null ) {
 			for ( int i = 0; i < columns.length; i++ ) {
 				buf.append( columns[i] );
 				if ( i < columns.length ) {
 					buf.append( " " );
 				}
 			}
 		}
 		buf.append( ",className=" ).append( className );
 		buf.append( "}" );
 	}
 
 	@Override
     public int hashCode() {
 		return super.hashCode();
 	}
 
 	@Override
     public boolean equals(Object obj) {
 		return super.equals( obj );
 	}
 
 
 	public void setJoinSequence(JoinSequence joinSequence) {
 		elementType.setJoinSequence( joinSequence );
 	}
 
 	public JoinSequence getJoinSequence() {
 		return elementType.getJoinSequence();
 	}
 
 	public void setIncludeSubclasses(boolean includeSubclasses) {
 		if ( !includeSubclasses && isDereferencedBySuperclassOrSubclassProperty() && LOG.isTraceEnabled() )
 			LOG.trace( "Attempt to disable subclass-inclusions : ", new Exception( "Stack-trace source" ) );
 		this.includeSubclasses = includeSubclasses;
 	}
 
 	public boolean isIncludeSubclasses() {
 		return includeSubclasses;
 	}
 
 	public boolean isDereferencedBySuperclassOrSubclassProperty() {
 		return dereferencedBySubclassProperty || dereferencedBySuperclassProperty;
 	}
 
 	public String getIdentityColumn() {
 		final String[] cols = getIdentityColumns();
 		if ( cols.length == 1 ) {
 			return cols[0];
 		}
 		else {
 			return "(" + StringHelper.join( ", ", cols ) + ")";
 		}
 	}
 
 	public String[] getIdentityColumns() {
 		checkInitialized();
 		final String table = getTableAlias();
 		if ( table == null ) {
 			throw new IllegalStateException( "No table alias for node " + this );
 		}
 
 		final String propertyName;
 		if ( getEntityPersister() != null && getEntityPersister().getEntityMetamodel() != null
 				&& getEntityPersister().getEntityMetamodel().hasNonIdentifierPropertyNamedId() ) {
 			propertyName = getEntityPersister().getIdentifierPropertyName();
 		}
 		else {
 			propertyName = EntityPersister.ENTITY_ID;
 		}
 
 		if ( getWalker().getStatementType() == HqlSqlTokenTypes.SELECT ) {
 			return getPropertyMapping( propertyName ).toColumns( table, propertyName );
 		}
 		else {
 			return getPropertyMapping( propertyName ).toColumns( propertyName );
 		}
 	}
 
 	public void setCollectionJoin(boolean collectionJoin) {
 		this.collectionJoin = collectionJoin;
 	}
 
 	public boolean isCollectionJoin() {
 		return collectionJoin;
 	}
 
 	public void setRole(String role) {
 		this.role = role;
 		applyTreatAsDeclarations( getWalker().getTreatAsDeclarationsByPath( role ) );
 	}
 
 	public void applyTreatAsDeclarations(Set<String> treatAsDeclarationsByPath) {
 		elementType.applyTreatAsDeclarations( treatAsDeclarationsByPath );
 	}
 
 	public String getRole() {
 		return role;
 	}
 
 	public void setQueryableCollection(QueryableCollection queryableCollection) {
 		elementType.setQueryableCollection( queryableCollection );
 	}
 
 	public QueryableCollection getQueryableCollection() {
 		return elementType.getQueryableCollection();
 	}
 
 	public void setColumns(String[] columns) {
 		this.columns = columns;
 	}
 
 	public void setOrigin(FromElement origin, boolean manyToMany) {
 		this.origin = origin;
 		this.manyToMany = manyToMany;
 		origin.addDestination( this );
 		if ( origin.getFromClause() == this.getFromClause() ) {
 			// TODO: Figure out a better way to get the FROM elements in a proper tree structure.
 			// If this is not the destination of a many-to-many, add it as a child of the origin.
 			if ( manyToMany ) {
 				ASTUtil.appendSibling( origin, this );
 			}
 			else {
 				if ( !getWalker().isInFrom() && !getWalker().isInSelect() ) {
 					getFromClause().addChild( this );
 				}
 				else {
 					origin.addChild( this );
 				}
 			}
 		}
 		else if ( !getWalker().isInFrom() ) {
 			// HHH-276 : implied joins in a subselect where clause - The destination needs to be added
 			// to the destination's from clause.
 			getFromClause().addChild( this );	// Not sure if this is will fix everything, but it works.
 		}
 		else {
 			// Otherwise, the destination node was implied by the FROM clause and the FROM clause processor
 			// will automatically add it in the right place.
 		}
 	}
 
 	public boolean isManyToMany() {
 		return manyToMany;
 	}
 
 	private void addDestination(FromElement fromElement) {
 		destinations.add( fromElement );
 	}
 
 	public List getDestinations() {
 		return destinations;
 	}
 
 	public FromElement getOrigin() {
 		return origin;
 	}
 
 	public FromElement getRealOrigin() {
 		if ( origin == null ) {
 			return null;
 		}
 		if ( origin.getText() == null || "".equals( origin.getText() ) ) {
 			return origin.getRealOrigin();
 		}
 		return origin;
 	}
 
 	public static final String DISCRIMINATOR_PROPERTY_NAME = "class";
 	private TypeDiscriminatorMetadata typeDiscriminatorMetadata;
 
 	private static class TypeDiscriminatorMetadataImpl implements TypeDiscriminatorMetadata {
 		private final DiscriminatorMetadata persisterDiscriminatorMetadata;
 		private final String alias;
 
 		private TypeDiscriminatorMetadataImpl(
 				DiscriminatorMetadata persisterDiscriminatorMetadata,
 				String alias) {
 			this.persisterDiscriminatorMetadata = persisterDiscriminatorMetadata;
 			this.alias = alias;
 		}
 
 		@Override
 		public String getSqlFragment() {
 			return persisterDiscriminatorMetadata.getSqlFragment( alias );
 		}
 
 		@Override
 		public Type getResolutionType() {
 			return persisterDiscriminatorMetadata.getResolutionType();
 		}
 	}
 
 	public TypeDiscriminatorMetadata getTypeDiscriminatorMetadata() {
 		if ( typeDiscriminatorMetadata == null ) {
 			typeDiscriminatorMetadata = buildTypeDiscriminatorMetadata();
 		}
 		return typeDiscriminatorMetadata;
 	}
 
 	private TypeDiscriminatorMetadata buildTypeDiscriminatorMetadata() {
 		final String aliasToUse = getTableAlias();
 		Queryable queryable = getQueryable();
 		if ( queryable == null ) {
 			QueryableCollection collection = getQueryableCollection();
 			if ( ! collection.getElementType().isEntityType() ) {
 				throw new QueryException( "type discrimination cannot be applied to value collection [" + collection.getRole() + "]" );
 			}
 			queryable = (Queryable) collection.getElementPersister();
 		}
 
 		handlePropertyBeingDereferenced( getDataType(), DISCRIMINATOR_PROPERTY_NAME );
 
 		return new TypeDiscriminatorMetadataImpl( queryable.getTypeDiscriminatorMetadata(), aliasToUse );
 	}
 
 	public Type getPropertyType(String propertyName, String propertyPath) {
 		return elementType.getPropertyType( propertyName, propertyPath );
 	}
 
 	public String[] toColumns(String tableAlias, String path, boolean inSelect) {
 		return elementType.toColumns( tableAlias, path, inSelect );
 	}
 
 	public String[] toColumns(String tableAlias, String path, boolean inSelect, boolean forceAlias) {
 		return elementType.toColumns( tableAlias, path, inSelect, forceAlias );
 	}
 
 	public PropertyMapping getPropertyMapping(String propertyName) {
 		return elementType.getPropertyMapping( propertyName );
 	}
 
 	public void setFetch(boolean fetch) {
 		this.fetch = fetch;
 		// Fetch can't be used with scroll() or iterate().
 		if ( fetch && getWalker().isShallowQuery() ) {
 			throw new QueryException( QueryTranslator.ERROR_CANNOT_FETCH_WITH_ITERATE );
 		}
 	}
 
 	public boolean isFetch() {
 		return fetch;
 	}
 
 	public int getSequence() {
 		return sequence;
 	}
 
 	public void setFilter(boolean b) {
 		filter = b;
 	}
 
 	public boolean isFilter() {
 		return filter;
 	}
 
 	public boolean useFromFragment() {
 		checkInitialized();
 		// If it's not implied or it is implied and it's a many to many join where the target wasn't found.
 		return !isImplied() || this.useFromFragment;
 	}
 
 	public void setUseFromFragment(boolean useFromFragment) {
 		this.useFromFragment = useFromFragment;
 	}
 
 	public boolean useWhereFragment() {
 		return useWhereFragment;
 	}
 
 	public void setUseWhereFragment(boolean b) {
 		useWhereFragment = b;
 	}
 
 
 	public void setCollectionTableAlias(String collectionTableAlias) {
 		this.collectionTableAlias = collectionTableAlias;
 	}
 
 	public String getCollectionTableAlias() {
 		return collectionTableAlias;
 	}
 
 	public boolean isCollectionOfValuesOrComponents() {
 		return elementType.isCollectionOfValuesOrComponents();
 	}
 
 	public boolean isEntity() {
 		return elementType.isEntity();
 	}
 
 	public void setImpliedInFromClause(boolean flag) {
 		throw new UnsupportedOperationException( "Explicit FROM elements can't be implied in the FROM clause!" );
 	}
 
 	public boolean isImpliedInFromClause() {
 		return false;	// Since this is an explicit FROM element, it can't be implied in the FROM clause.
 	}
 
 	public void setInProjectionList(boolean inProjectionList) {
 		// Do nothing, eplicit from elements are *always* in the projection list.
 	}
 
 	public boolean inProjectionList() {
 		return !isImplied() && isFromOrJoinFragment();
 	}
 
 	public boolean isFromOrJoinFragment() {
 		return getType() == SqlTokenTypes.FROM_FRAGMENT || getType() == SqlTokenTypes.JOIN_FRAGMENT;
 	}
 
 	public boolean isAllPropertyFetch() {
 		return isAllPropertyFetch;
 	}
 
 	public void setAllPropertyFetch(boolean fetch) {
 		isAllPropertyFetch = fetch;
 	}
 
 	public String getWithClauseFragment() {
 		return withClauseFragment;
 	}
 
 	public String getWithClauseJoinAlias() {
 		return withClauseJoinAlias;
 	}
 
 	public void setWithClauseFragment(String withClauseJoinAlias, String withClauseFragment) {
 		this.withClauseJoinAlias = withClauseJoinAlias;
 		this.withClauseFragment = withClauseFragment;
 	}
 
 	public boolean hasCacheablePersister() {
 		if ( getQueryableCollection() != null ) {
 			return getQueryableCollection().hasCache();
 		}
 		else {
 			return getQueryable().hasCache();
 		}
 	}
 
 	public void handlePropertyBeingDereferenced(Type propertySource, String propertyName) {
 		if ( getQueryableCollection() != null && CollectionProperties.isCollectionProperty( propertyName ) ) {
 			// propertyName refers to something like collection.size...
 			return;
 		}
 		if ( propertySource.isComponentType() ) {
 			// property name is a sub-path of a component...
 			return;
 		}
 
 		Queryable persister = getQueryable();
 		if ( persister != null ) {
 			try {
 				Queryable.Declarer propertyDeclarer = persister.getSubclassPropertyDeclarer( propertyName );
 				if ( LOG.isTraceEnabled() ) {
 					LOG.tracev( "Handling property dereference [{0} ({1}) -> {2} ({3})]",
 							persister.getEntityName(), getClassAlias(), propertyName, propertyDeclarer );
 				}
 				if ( propertyDeclarer == Queryable.Declarer.SUBCLASS ) {
 					dereferencedBySubclassProperty = true;
 					includeSubclasses = true;
 				}
 				else if ( propertyDeclarer == Queryable.Declarer.SUPERCLASS ) {
 					dereferencedBySuperclassProperty = true;
 				}
 			}
 			catch( QueryException ignore ) {
 				// ignore it; the incoming property could not be found so we
 				// cannot be sure what to do here.  At the very least, the
 				// safest is to simply not apply any dereference toggling...
 
 			}
 		}
 	}
 
 	public boolean isDereferencedBySuperclassProperty() {
 		return dereferencedBySuperclassProperty;
 	}
 
 	public boolean isDereferencedBySubclassProperty() {
 		return dereferencedBySubclassProperty;
 	}
 
 
 	// ParameterContainer impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 	private List<ParameterSpecification> embeddedParameters;
 
 	@Override
 	public void addEmbeddedParameter(ParameterSpecification specification) {
 		if ( embeddedParameters == null ) {
 			embeddedParameters = new ArrayList<ParameterSpecification>();
 		}
 		embeddedParameters.add( specification );
 	}
 
 	@Override
 	public boolean hasEmbeddedParameters() {
 		return embeddedParameters != null && ! embeddedParameters.isEmpty();
 	}
 
 	@Override
 	public ParameterSpecification[] getEmbeddedParameters() {
 		return embeddedParameters.toArray( new ParameterSpecification[ embeddedParameters.size() ] );
 	}
 
 	public ParameterSpecification getIndexCollectionSelectorParamSpec() {
 		return elementType.getIndexCollectionSelectorParamSpec();
 	}
 
 	public void setIndexCollectionSelectorParamSpec(ParameterSpecification indexCollectionSelectorParamSpec) {
 		if ( indexCollectionSelectorParamSpec == null ) {
 			if ( elementType.getIndexCollectionSelectorParamSpec() != null ) {
 				embeddedParameters.remove( elementType.getIndexCollectionSelectorParamSpec() );
 				elementType.setIndexCollectionSelectorParamSpec( null );
 			}
 		}
 		else {
 			elementType.setIndexCollectionSelectorParamSpec( indexCollectionSelectorParamSpec );
 			addEmbeddedParameter( indexCollectionSelectorParamSpec );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromReferenceNode.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromReferenceNode.java
index 9658c4d65d..a1bc4161c2 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromReferenceNode.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/FromReferenceNode.java
@@ -1,145 +1,146 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.hql.internal.ast.tree;
+
 import antlr.SemanticException;
 import antlr.collections.AST;
-import org.jboss.logging.Logger;
 
 import org.hibernate.hql.internal.antlr.HqlSqlTokenTypes;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 
 /**
  * Represents a reference to a FROM element, for example a class alias in a WHERE clause.
  *
  * @author josh
  */
 public abstract class FromReferenceNode extends AbstractSelectExpression
         implements ResolvableNode, DisplayableNode, InitializeableNode, PathNode {
 
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, FromReferenceNode.class.getName() );
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( FromReferenceNode.class );
 
 	private FromElement fromElement;
-	private boolean resolved = false;
+	private boolean resolved;
+
 	public static final int ROOT_LEVEL = 0;
 
 	@Override
     public FromElement getFromElement() {
 		return fromElement;
 	}
 
 	public void setFromElement(FromElement fromElement) {
 		this.fromElement = fromElement;
 	}
 
 	/**
 	 * Resolves the left hand side of the DOT.
 	 *
 	 * @throws SemanticException
 	 */
 	public void resolveFirstChild() throws SemanticException {
 	}
 
 	public String getPath() {
 		return getOriginalText();
 	}
 
 	public boolean isResolved() {
 		return resolved;
 	}
 
 	public void setResolved() {
 		this.resolved = true;
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "Resolved : %s -> %s", this.getPath(), this.getText() );
 		}
 	}
 
 	public String getDisplayText() {
 		StringBuilder buf = new StringBuilder();
 		buf.append( "{" ).append( ( fromElement == null ) ? "no fromElement" : fromElement.getDisplayText() );
 		buf.append( "}" );
 		return buf.toString();
 	}
 
 	public void recursiveResolve(int level, boolean impliedAtRoot, String classAlias) throws SemanticException {
 		recursiveResolve( level, impliedAtRoot, classAlias, this );
 	}
 
 	public void recursiveResolve(int level, boolean impliedAtRoot, String classAlias, AST parent) throws SemanticException {
 		AST lhs = getFirstChild();
 		int nextLevel = level + 1;
 		if ( lhs != null ) {
 			FromReferenceNode n = ( FromReferenceNode ) lhs;
 			n.recursiveResolve( nextLevel, impliedAtRoot, null, this );
 		}
 		resolveFirstChild();
 		boolean impliedJoin = true;
 		if ( level == ROOT_LEVEL && !impliedAtRoot ) {
 			impliedJoin = false;
 		}
 		resolve( true, impliedJoin, classAlias, parent );
 	}
 
 	@Override
     public boolean isReturnableEntity() throws SemanticException {
 		return !isScalar() && fromElement.isEntity();
 	}
 
 	public void resolveInFunctionCall(boolean generateJoin, boolean implicitJoin) throws SemanticException {
 		resolve( generateJoin, implicitJoin );
 	}
 
 	public void resolve(boolean generateJoin, boolean implicitJoin) throws SemanticException {
 		resolve( generateJoin, implicitJoin, null );
 	}
 
 	public void resolve(boolean generateJoin, boolean implicitJoin, String classAlias) throws SemanticException {
 		resolve( generateJoin, implicitJoin, classAlias, null );
 	}
 
 	public void prepareForDot(String propertyName) throws SemanticException {
 	}
 
 	/**
 	 * Sub-classes can override this method if they produce implied joins (e.g. DotNode).
 	 *
 	 * @return an implied join created by this from reference.
 	 */
 	public FromElement getImpliedJoin() {
 		return null;
 	}
 
 	@SuppressWarnings("SimplifiableIfStatement")
 	protected boolean isFromElementUpdateOrDeleteRoot(FromElement element) {
 		if ( element.getFromClause().getParentFromClause() != null ) {
 			// its not even a root...
 			return false;
 		}
 
 		return getWalker().getStatementType() == HqlSqlTokenTypes.DELETE
 				|| getWalker().getStatementType() == HqlSqlTokenTypes.UPDATE;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/IdentNode.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/IdentNode.java
index 154f7b8a6f..7a5fa2daba 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/IdentNode.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/IdentNode.java
@@ -1,381 +1,382 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.tree;
 
 import java.util.List;
 
 import antlr.SemanticException;
 import antlr.collections.AST;
 
 import org.hibernate.QueryException;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.hql.internal.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.internal.antlr.SqlTokenTypes;
 import org.hibernate.hql.internal.ast.util.ColumnHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinType;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.Type;
 
 /**
  * Represents an identifier all by itself, which may be a function name,
  * a class alias, or a form of naked property-ref depending on the
  * context.
  *
  * @author josh
  */
 public class IdentNode extends FromReferenceNode implements SelectExpression {
-
-	private static final int UNKNOWN = 0;
-	private static final int PROPERTY_REF = 1;
-	private static final int COMPONENT_REF = 2;
+	private static enum DereferenceType {
+		UNKNOWN,
+		PROPERTY_REF,
+		COMPONENT_REF
+	}
 
 	private boolean nakedPropertyRef = false;
 
 	public void resolveIndex(AST parent) throws SemanticException {
 		// An ident node can represent an index expression if the ident
 		// represents a naked property ref
 		//      *Note: this makes the assumption (which is currently the case
 		//      in the hql-sql grammar) that the ident is first resolved
 		//      itself (addrExpr -> resolve()).  The other option, if that
 		//      changes, is to call resolve from here; but it is
 		//      currently un-needed overhead.
 		if (!(isResolved() && nakedPropertyRef)) {
 			throw new UnsupportedOperationException();
 		}
 
 		String propertyName = getOriginalText();
 		if (!getDataType().isCollectionType()) {
 			throw new SemanticException("Collection expected; [" + propertyName + "] does not refer to a collection property");
 		}
 
 		// TODO : most of below was taken verbatim from DotNode; should either delegate this logic or super-type it
 		CollectionType type = (CollectionType) getDataType();
 		String role = type.getRole();
 		QueryableCollection queryableCollection = getSessionFactoryHelper().requireQueryableCollection(role);
 
 		String alias = null;  // DotNode uses null here...
 		String columnTableAlias = getFromElement().getTableAlias();
 		JoinType joinType = JoinType.INNER_JOIN;
 		boolean fetch = false;
 
 		FromElementFactory factory = new FromElementFactory(
 				getWalker().getCurrentFromClause(),
 				getFromElement(),
 				propertyName,
 				alias,
 				getFromElement().toColumns(columnTableAlias, propertyName, false),
 				true
 		);
 		FromElement elem = factory.createCollection(queryableCollection, role, joinType, fetch, true);
 		setFromElement(elem);
 		getWalker().addQuerySpaces(queryableCollection.getCollectionSpaces());	// Always add the collection's query spaces.
 	}
 
 	public void resolve(boolean generateJoin, boolean implicitJoin, String classAlias, AST parent) {
 		if (!isResolved()) {
 			if (getWalker().getCurrentFromClause().isFromElementAlias(getText())) {
 				if (resolveAsAlias()) {
 					setResolved();
 					// We represent a from-clause alias
 				}
 			}
 			else if (parent != null && parent.getType() == SqlTokenTypes.DOT) {
 				DotNode dot = (DotNode) parent;
 				if (parent.getFirstChild() == this) {
 					if (resolveAsNakedComponentPropertyRefLHS(dot)) {
 						// we are the LHS of the DOT representing a naked comp-prop-ref
 						setResolved();
 					}
 				}
 				else {
 					if (resolveAsNakedComponentPropertyRefRHS(dot)) {
 						// we are the RHS of the DOT representing a naked comp-prop-ref
 						setResolved();
 					}
 				}
 			}
 			else {
-				int result = resolveAsNakedPropertyRef();
-				if (result == PROPERTY_REF) {
+				DereferenceType result = resolveAsNakedPropertyRef();
+				if (result == DereferenceType.PROPERTY_REF) {
 					// we represent a naked (simple) prop-ref
 					setResolved();
 				}
-				else if (result == COMPONENT_REF) {
+				else if (result == DereferenceType.COMPONENT_REF) {
 					// EARLY EXIT!!!  return so the resolve call explicitly coming from DotNode can
 					// resolve this...
 					return;
 				}
 			}
 
 			// if we are still not resolved, we might represent a constant.
 			//      needed to add this here because the allowance of
 			//      naked-prop-refs in the grammar collides with the
 			//      definition of literals/constants ("nondeterminism").
 			//      TODO: cleanup the grammar so that "processConstants" is always just handled from here
 			if (!isResolved()) {
 				try {
 					getWalker().getLiteralProcessor().processConstant(this, false);
 				}
 				catch (Throwable ignore) {
 					// just ignore it for now, it'll get resolved later...
 				}
 			}
 		}
 	}
 
 	private boolean resolveAsAlias() {
 		final String alias = getText();
 
 		// This is not actually a constant, but a reference to FROM element.
 		final FromElement element = getWalker().getCurrentFromClause().getFromElement( alias );
 		if ( element == null ) {
 			return false;
 		}
 
 		element.applyTreatAsDeclarations( getWalker().getTreatAsDeclarationsByPath( alias ) );
 
 		setType( SqlTokenTypes.ALIAS_REF );
 		setFromElement( element );
 
 		String[] columnExpressions = element.getIdentityColumns();
 
 		// determine whether to apply qualification (table alias) to the column(s)...
 		if ( ! isFromElementUpdateOrDeleteRoot( element ) ) {
 			if ( StringHelper.isNotEmpty( element.getTableAlias() ) ) {
 				// apparently we also need to check that they are not already qualified.  Ugh!
 				columnExpressions = StringHelper.qualifyIfNot( element.getTableAlias(), columnExpressions );
 			}
 		}
 
 		final boolean isInNonDistinctCount = getWalker().isInCount() && ! getWalker().isInCountDistinct();
 		final boolean isCompositeValue = columnExpressions.length > 1;
 		if ( isCompositeValue ) {
 			if ( isInNonDistinctCount && ! getWalker().getSessionFactoryHelper().getFactory().getDialect().supportsTupleCounts() ) {
 				setText( columnExpressions[0] );
 			}
 			else {
 				String joinedFragment = StringHelper.join( ", ", columnExpressions );
 				// avoid wrapping in parenthesis (explicit tuple treatment) if possible due to varied support for
 				// tuple syntax across databases..
 				final boolean shouldSkipWrappingInParenthesis =
 						getWalker().isInCount()
 						|| getWalker().getCurrentTopLevelClauseType() == HqlSqlTokenTypes.ORDER
 						|| getWalker().getCurrentTopLevelClauseType() == HqlSqlTokenTypes.GROUP;
 				if ( ! shouldSkipWrappingInParenthesis ) {
 					joinedFragment = "(" + joinedFragment + ")";
 				}
 				setText( joinedFragment );
 			}
 			return true;
 		}
 		else if ( columnExpressions.length > 0 ) {
 			setText( columnExpressions[0] );
 			return true;
 		}
 
 		return false;
 	}
 
 	private Type getNakedPropertyType(FromElement fromElement) {
 		if (fromElement == null) {
 			return null;
 		}
 		String property = getOriginalText();
 		Type propertyType = null;
 		try {
 			propertyType = fromElement.getPropertyType(property, property);
 		}
-		catch (Throwable t) {
+		catch (Throwable ignore) {
 		}
 		return propertyType;
 	}
 
-	private int resolveAsNakedPropertyRef() {
+	private DereferenceType resolveAsNakedPropertyRef() {
 		FromElement fromElement = locateSingleFromElement();
 		if (fromElement == null) {
-			return UNKNOWN;
+			return DereferenceType.UNKNOWN;
 		}
 		Queryable persister = fromElement.getQueryable();
 		if (persister == null) {
-			return UNKNOWN;
+			return DereferenceType.UNKNOWN;
 		}
 		Type propertyType = getNakedPropertyType(fromElement);
 		if (propertyType == null) {
 			// assume this ident's text does *not* refer to a property on the given persister
-			return UNKNOWN;
+			return DereferenceType.UNKNOWN;
 		}
 
 		if ((propertyType.isComponentType() || propertyType.isAssociationType() )) {
-			return COMPONENT_REF;
+			return DereferenceType.COMPONENT_REF;
 		}
 
 		setFromElement(fromElement);
 		String property = getText();
 		String[] columns = getWalker().isSelectStatement()
 				? persister.toColumns(fromElement.getTableAlias(), property)
 				: persister.toColumns(property);
 		String text = StringHelper.join(", ", columns);
 		setText(columns.length == 1 ? text : "(" + text + ")");
 		setType(SqlTokenTypes.SQL_TOKEN);
 
 		// these pieces are needed for usage in select clause
 		super.setDataType(propertyType);
 		nakedPropertyRef = true;
 
-		return PROPERTY_REF;
+		return DereferenceType.PROPERTY_REF;
 	}
 
 	private boolean resolveAsNakedComponentPropertyRefLHS(DotNode parent) {
 		FromElement fromElement = locateSingleFromElement();
 		if (fromElement == null) {
 			return false;
 		}
 
 		Type componentType = getNakedPropertyType(fromElement);
 		if ( componentType == null ) {
 			throw new QueryException( "Unable to resolve path [" + parent.getPath() + "], unexpected token [" + getOriginalText() + "]" );
 		}
 		if (!componentType.isComponentType()) {
 			throw new QueryException("Property '" + getOriginalText() + "' is not a component.  Use an alias to reference associations or collections.");
 		}
 
-		Type propertyType = null;  // used to set the type of the parent dot node
+		Type propertyType;
 		String propertyPath = getText() + "." + getNextSibling().getText();
 		try {
 			// check to see if our "propPath" actually
 			// represents a property on the persister
 			propertyType = fromElement.getPropertyType(getText(), propertyPath);
 		}
 		catch (Throwable t) {
 			// assume we do *not* refer to a property on the given persister
 			return false;
 		}
 
 		setFromElement(fromElement);
 		parent.setPropertyPath(propertyPath);
 		parent.setDataType(propertyType);
 
 		return true;
 	}
 
 	private boolean resolveAsNakedComponentPropertyRefRHS(DotNode parent) {
 		FromElement fromElement = locateSingleFromElement();
 		if (fromElement == null) {
 			return false;
 		}
 
-		Type propertyType = null;
+		Type propertyType;
 		String propertyPath = parent.getLhs().getText() + "." + getText();
 		try {
 			// check to see if our "propPath" actually
 			// represents a property on the persister
 			propertyType = fromElement.getPropertyType(getText(), propertyPath);
 		}
 		catch (Throwable t) {
 			// assume we do *not* refer to a property on the given persister
 			return false;
 		}
 
 		setFromElement(fromElement);
 		// this piece is needed for usage in select clause
 		super.setDataType(propertyType);
 		nakedPropertyRef = true;
 
 		return true;
 	}
 
 	private FromElement locateSingleFromElement() {
 		List fromElements = getWalker().getCurrentFromClause().getFromElements();
 		if (fromElements == null || fromElements.size() != 1) {
 			// TODO : should this be an error?
 			return null;
 		}
 		FromElement element = (FromElement) fromElements.get(0);
 		if (element.getClassAlias() != null) {
 			// naked property-refs cannot be used with an aliased from element
 			return null;
 		}
 		return element;
 	}
 
 	@Override
     public Type getDataType() {
 		Type type = super.getDataType();
 		if ( type != null ) {
 			return type;
 		}
 		FromElement fe = getFromElement();
 		if ( fe != null ) {
 			return fe.getDataType();
 		}
 		SQLFunction sf = getWalker().getSessionFactoryHelper().findSQLFunction( getText() );
 		if ( sf != null ) {
 			return sf.getReturnType( null, getWalker().getSessionFactoryHelper().getFactory() );
 		}
 		return null;
 	}
 
 	public void setScalarColumnText(int i) throws SemanticException {
 		if (nakedPropertyRef) {
 			// do *not* over-write the column text, as that has already been
 			// "rendered" during resolve
 			ColumnHelper.generateSingleScalarColumn(this, i);
 		}
 		else {
 			FromElement fe = getFromElement();
 			if (fe != null) {
 				setText(fe.renderScalarIdentifierSelect(i));
 			}
 			else {
 				ColumnHelper.generateSingleScalarColumn(this, i);
 			}
 		}
 	}
 
 	@Override
     public String getDisplayText() {
 		StringBuilder buf = new StringBuilder();
 
 		if (getType() == SqlTokenTypes.ALIAS_REF) {
 			buf.append("{alias=").append(getOriginalText());
 			if (getFromElement() == null) {
 				buf.append(", no from element");
 			}
 			else {
 				buf.append(", className=").append(getFromElement().getClassName());
 				buf.append(", tableAlias=").append(getFromElement().getTableAlias());
 			}
 			buf.append("}");
 		}
 		else {
-			buf.append("{originalText=" + getOriginalText()).append("}");
+			buf.append( "{originalText=" ).append( getOriginalText() ).append( "}" );
 		}
 		return buf.toString();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/ImpliedFromElement.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/ImpliedFromElement.java
index 6627d58d40..debedc3821 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/ImpliedFromElement.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/ImpliedFromElement.java
@@ -1,81 +1,79 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.hql.internal.ast.tree;
 
-
 /**
  * Represents a FROM element implied by a path expression or a collection reference.
  *
  * @author josh
  */
 public class ImpliedFromElement extends FromElement {
 	/**
 	 * True if this from element was implied from a path in the FROM clause, but not
 	 * explicitly declard in the from clause.
 	 */
-	private boolean impliedInFromClause = false;
+	private boolean impliedInFromClause;
 
 	/**
 	 * True if this implied from element should be included in the projection list.
 	 */
-	private boolean inProjectionList = false;
+	private boolean inProjectionList;
 
 	public boolean isImplied() {
 		return true;
 	}
 
 	public void setImpliedInFromClause(boolean flag) {
 		impliedInFromClause = flag;
 	}
 
 	public boolean isImpliedInFromClause() {
 		return impliedInFromClause;
 	}
 
 	public void setInProjectionList(boolean inProjectionList) {
 		this.inProjectionList = inProjectionList;
 	}
 
 	public boolean inProjectionList() {
 		return inProjectionList && isFromOrJoinFragment();
 	}
 
 	public boolean isIncludeSubclasses() {
 		return false;	// Never include subclasses for implied from elements.
 	}
 
 	/**
 	 * Returns additional display text for the AST node.
 	 *
 	 * @return String - The additional display text.
 	 */
 	public String getDisplayText() {
 		StringBuilder buf = new StringBuilder();
 		buf.append( "ImpliedFromElement{" );
 		appendDisplayText( buf );
 		buf.append( "}" );
 		return buf.toString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/MapEntryNode.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/MapEntryNode.java
index 223ed20588..c488ed1481 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/MapEntryNode.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/MapEntryNode.java
@@ -1,312 +1,312 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.internal.ast.tree;
 
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import antlr.SemanticException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.hql.internal.NameGenerator;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.AliasGenerator;
 import org.hibernate.sql.SelectExpression;
 import org.hibernate.sql.SelectFragment;
 import org.hibernate.transform.BasicTransformerAdapter;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 /**
  * Tree node representing reference to the entry ({@link Map.Entry}) of a Map association.
  *
  * @author Steve Ebersole
  */
 public class MapEntryNode extends AbstractMapComponentNode implements AggregatedSelectExpression {
 	private static class LocalAliasGenerator implements AliasGenerator {
 		private final int base;
-		private int counter = 0;
+		private int counter;
 
 		private LocalAliasGenerator(int base) {
 			this.base = base;
 		}
 
 		public String generateAlias(String sqlExpression) {
 			return NameGenerator.scalarName( base, counter++ );
 		}
 	}
 
 	private int scalarColumnIndex = -1;
 
 	@Override
 	protected String expressionDescription() {
 		return "entry(*)";
 	}
 
 	@Override
 	public Class getAggregationResultType() {
 		return Map.Entry.class;
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	protected Type resolveType(QueryableCollection collectionPersister) {
 		Type keyType = collectionPersister.getIndexType();
 		Type valueType = collectionPersister.getElementType();
 		types.add( keyType );
 		types.add( valueType );
 		mapEntryBuilder = new MapEntryBuilder();
 
 		// an entry (as an aggregated select expression) does not have a type...
 		return null;
 	}
 
 	@Override
 	protected String[] resolveColumns(QueryableCollection collectionPersister) {
 		List selections = new ArrayList();
 		determineKeySelectExpressions( collectionPersister, selections );
 		determineValueSelectExpressions( collectionPersister, selections );
 
 		String text = "";
 		String[] columns = new String[selections.size()];
 		for ( int i = 0; i < selections.size(); i++ ) {
 			SelectExpression selectExpression = (SelectExpression) selections.get(i);
 			text += ( ", " + selectExpression.getExpression() + " as " + selectExpression.getAlias() );
 			columns[i] = selectExpression.getExpression();
 		}
 
 		text = text.substring( 2 ); //strip leading ", "
 		setText( text );
 		setResolved();
 		return columns;
 	}
 
 	private void determineKeySelectExpressions(QueryableCollection collectionPersister, List selections) {
 		AliasGenerator aliasGenerator = new LocalAliasGenerator( 0 );
 		appendSelectExpressions( collectionPersister.getIndexColumnNames(), selections, aliasGenerator );
 		Type keyType = collectionPersister.getIndexType();
 		if ( keyType.isAssociationType() ) {
 			EntityType entityType = (EntityType) keyType;
 			Queryable keyEntityPersister = ( Queryable ) sfi().getEntityPersister(
 					entityType.getAssociatedEntityName( sfi() )
 			);
 			SelectFragment fragment = keyEntityPersister.propertySelectFragmentFragment(
 					collectionTableAlias(),
 					null,
 					false
 			);
 			appendSelectExpressions( fragment, selections, aliasGenerator );
 		}
 	}
 
 	@SuppressWarnings({"unchecked", "ForLoopReplaceableByForEach"})
 	private void appendSelectExpressions(String[] columnNames, List selections, AliasGenerator aliasGenerator) {
 		 for ( int i = 0; i < columnNames.length; i++ ) {
 			selections.add(
 					new BasicSelectExpression(
 							collectionTableAlias() + '.' + columnNames[i],
 							aliasGenerator.generateAlias( columnNames[i] )
 					)
 			);
 		}
 	}
 
 	@SuppressWarnings({"unchecked", "WhileLoopReplaceableByForEach"})
 	private void appendSelectExpressions(SelectFragment fragment, List selections, AliasGenerator aliasGenerator) {
 		Iterator itr = fragment.getColumns().iterator();
 		while ( itr.hasNext() ) {
 			final String column = (String) itr.next();
 			selections.add(
 					new BasicSelectExpression( column, aliasGenerator.generateAlias( column ) )
 			);
 		}
 	}
 
 	private void determineValueSelectExpressions(QueryableCollection collectionPersister, List selections) {
 		AliasGenerator aliasGenerator = new LocalAliasGenerator( 1 );
 		appendSelectExpressions( collectionPersister.getElementColumnNames(), selections, aliasGenerator );
 		Type valueType = collectionPersister.getElementType();
 		if ( valueType.isAssociationType() ) {
 			EntityType valueEntityType = (EntityType) valueType;
 			Queryable valueEntityPersister = ( Queryable ) sfi().getEntityPersister(
 					valueEntityType.getAssociatedEntityName( sfi() )
 			);
 			SelectFragment fragment = valueEntityPersister.propertySelectFragmentFragment(
 					elementTableAlias(),
 					null,
 					false
 			);
 			appendSelectExpressions( fragment, selections, aliasGenerator );
 		}
 	}
 
 	private String collectionTableAlias() {
 		return getFromElement().getCollectionTableAlias() != null
 				? getFromElement().getCollectionTableAlias()
 				: getFromElement().getTableAlias();
 	}
 
 	private String elementTableAlias() {
 		return getFromElement().getTableAlias();
 	}
 
 	private static class BasicSelectExpression implements SelectExpression {
 		private final String expression;
 		private final String alias;
 
 		private BasicSelectExpression(String expression, String alias) {
 			this.expression = expression;
 			this.alias = alias;
 		}
 
 		@Override
 		public String getExpression() {
 			return expression;
 		}
 
 		@Override
 		public String getAlias() {
 			return alias;
 		}
 	}
 
 	public SessionFactoryImplementor sfi() {
 		return getSessionFactoryHelper().getFactory();
 	}
 
 	@Override
 	public void setText(String s) {
 		if ( isResolved() ) {
 			return;
 		}
 		super.setText( s );
 	}
 
 	@Override
 	public void setScalarColumn(int i) throws SemanticException {
 		this.scalarColumnIndex = i;
 	}
 
 	@Override
 	public int getScalarColumnIndex() {
 		return scalarColumnIndex;
 	}
 
 	@Override
 	public void setScalarColumnText(int i) throws SemanticException {
 	}
 
 	@Override
 	public boolean isScalar() {
 		// Constructors are always considered scalar results.
 		return true;
 	}
 
 	private List types = new ArrayList(4); // size=4 to prevent resizing
 
 	@Override
 	public List getAggregatedSelectionTypeList() {
 		return types;
 	}
 
 	private static final String[] ALIASES = { null, null };
 
 	@Override
 	public String[] getAggregatedAliases() {
 		return ALIASES;
 	}
 
 	private MapEntryBuilder mapEntryBuilder;
 
 	@Override
 	public ResultTransformer getResultTransformer() {
 		return mapEntryBuilder;
 	}
 
 	private static class MapEntryBuilder extends BasicTransformerAdapter {
 		@Override
 		public Object transformTuple(Object[] tuple, String[] aliases) {
 			if ( tuple.length != 2 ) {
 				throw new HibernateException( "Expecting exactly 2 tuples to transform into Map.Entry" );
 			}
 			return new EntryAdapter( tuple[0], tuple[1] );
 		}
 	}
 
 	private static class EntryAdapter implements Map.Entry {
 		private final Object key;
 		private Object value;
 
 		private EntryAdapter(Object key, Object value) {
 			this.key = key;
 			this.value = value;
 		}
 
 		@Override
 		public Object getValue() {
 			return value;
 		}
 
 		@Override
 		public Object getKey() {
 			return key;
 		}
 
 		@Override
 		public Object setValue(Object value) {
 			Object old = this.value;
 			this.value = value;
 			return old;
 		}
 
 		@Override
 		public boolean equals(Object o) {
 			// IMPL NOTE : nulls are considered equal for keys and values according to Map.Entry contract
 			if ( this == o ) {
 				return true;
 			}
 			if ( o == null || getClass() != o.getClass() ) {
 				return false;
 			}
 			EntryAdapter that = ( EntryAdapter ) o;
 
 			// make sure we have the same types...
 			return ( key == null ? that.key == null : key.equals( that.key ) )
 					&& ( value == null ? that.value == null : value.equals( that.value ) );
 
 		}
 
 		@Override
 		public int hashCode() {
 			int keyHash = key == null ? 0 : key.hashCode();
 			int valueHash = value == null ? 0 : value.hashCode();
 			return keyHash ^ valueHash;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/SelectClause.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/SelectClause.java
index fc5601ecc8..dd8351a65d 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/SelectClause.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/tree/SelectClause.java
@@ -1,474 +1,473 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.internal.ast.tree;
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 
 import org.hibernate.QueryException;
 import org.hibernate.hql.internal.antlr.HqlSqlTokenTypes;
 import org.hibernate.hql.internal.antlr.SqlTokenTypes;
 import org.hibernate.hql.internal.ast.util.ASTAppender;
 import org.hibernate.hql.internal.ast.util.ASTIterator;
 import org.hibernate.hql.internal.ast.util.ASTPrinter;
 import org.hibernate.type.Type;
 
 import antlr.SemanticException;
 import antlr.collections.AST;
 
 /**
  * Represents the list of expressions in a SELECT clause.
  *
  * @author josh
  */
 public class SelectClause extends SelectExpressionList {
-
-	private boolean prepared = false;
+	private boolean prepared;
 	private boolean scalarSelect;
 
 	private List fromElementsForLoad = new ArrayList();
 	//private Type[] sqlResultTypes;
 	private Type[] queryReturnTypes;
 	private String[][] columnNames;
 	private List collectionFromElements;
 	private String[] aliases;
 	private int[] columnNamesStartPositions;
 
 	// Currently we can only have one...
 	private AggregatedSelectExpression aggregatedSelectExpression;
 
 	/**
 	 * Does this SelectClause represent a scalar query
 	 *
 	 * @return True if this is a scalara select clause; false otherwise.
 	 */
 	public boolean isScalarSelect() {
 		return scalarSelect;
 	}
 
 	public boolean isDistinct() {
 		return getFirstChild() != null && getFirstChild().getType() == SqlTokenTypes.DISTINCT;
 	}
 
 	/**
 	 * FromElements which need to be accounted for in the load phase (either for return or for fetch).
 	 *
 	 * @return List of appropriate FromElements.
 	 */
 	public List getFromElementsForLoad() {
 		return fromElementsForLoad;
 	}
 
 	/*
 	 * The types represented in the SQL result set.
 	 *
 	 * @return The types represented in the SQL result set.
 	 */
 	/*public Type[] getSqlResultTypes() {
 		return sqlResultTypes;
 	}*/
 
 	/**
 	 * The types actually being returned from this query at the "object level".
 	 *
 	 * @return The query return types.
 	 */
 	public Type[] getQueryReturnTypes() {
 		return queryReturnTypes;
 	}
 	
 	/**
 	 * The HQL aliases, or generated aliases
 	 *
 	 * @return the aliases
 	 */
 	public String[] getQueryReturnAliases() {
 		return aliases;
 	}
 
 	/**
 	 * The column alias names being used in the generated SQL.
 	 *
 	 * @return The SQL column aliases.
 	 */
 	public String[][] getColumnNames() {
 		return columnNames;
 	}
 
 	public AggregatedSelectExpression getAggregatedSelectExpression() {
 		return aggregatedSelectExpression;
 	}
 
 	/**
 	 * Prepares an explicitly defined select clause.
 	 *
 	 * @param fromClause The from clause linked to this select clause.
 	 * @throws SemanticException indicates a semntic issue with the explicit select clause.
 	 */
 	public void initializeExplicitSelectClause(FromClause fromClause) throws SemanticException {
 		if ( prepared ) {
 			throw new IllegalStateException( "SelectClause was already prepared!" );
 		}
 
 		//explicit = true;	// This is an explict Select.
 		//ArrayList sqlResultTypeList = new ArrayList();
 		ArrayList queryReturnTypeList = new ArrayList();
 
 		// First, collect all of the select expressions.
 		// NOTE: This must be done *before* invoking setScalarColumnText() because setScalarColumnText()
 		// changes the AST!!!
 		SelectExpression[] selectExpressions = collectSelectExpressions();
 
         // we only support parameters in select in the case of INSERT...SELECT statements
         if (getParameterPositions().size() > 0 && getWalker().getStatementType() != HqlSqlTokenTypes.INSERT) {
             throw new QueryException("Parameters are only supported in SELECT clauses when used as part of a INSERT INTO DML statement");
         }
 
 		for ( int i = 0; i < selectExpressions.length; i++ ) {
 			SelectExpression selectExpression = selectExpressions[i];
 
 			if ( AggregatedSelectExpression.class.isInstance( selectExpression ) ) {
 				aggregatedSelectExpression = (AggregatedSelectExpression) selectExpression;
 				queryReturnTypeList.addAll( aggregatedSelectExpression.getAggregatedSelectionTypeList() );
 				scalarSelect = true;
 			}
 			else {
 				// we have no choice but to do this check here
 				// this is not very elegant but the "right way" would most likely involve a bigger rewrite so as to
 				// treat ParameterNodes in select clauses as SelectExpressions
 				boolean inSubquery = selectExpression instanceof QueryNode && ((QueryNode) selectExpression).getFromClause().getParentFromClause() != null;
 				if (getWalker().getStatementType() == HqlSqlTokenTypes.INSERT && inSubquery) {
 					// we do not support parameters for subqueries in INSERT...SELECT
 					if (((QueryNode) selectExpression).getSelectClause().getParameterPositions().size() > 0) {
 						throw new QueryException("Use of parameters in subqueries of INSERT INTO DML statements is not supported.");
 					}
                 }
 				
 				Type type = selectExpression.getDataType();
 				if ( type == null ) {
 					throw new IllegalStateException( "No data type for node: " + selectExpression.getClass().getName() + " "
 							+ new ASTPrinter( SqlTokenTypes.class ).showAsString( ( AST ) selectExpression, "" ) );
 				}
 				//sqlResultTypeList.add( type );
 
 				// If the data type is not an association type, it could not have been in the FROM clause.
 				if ( selectExpression.isScalar() ) {
 					scalarSelect = true;
 				}
 
 				if ( isReturnableEntity( selectExpression ) ) {
 					fromElementsForLoad.add( selectExpression.getFromElement() );
 				}
 
 				// Always add the type to the return type list.
 				queryReturnTypeList.add( type );
 			}
 		}
 
 		//init the aliases, after initing the constructornode
 		initAliases(selectExpressions);
 
 		if ( !getWalker().isShallowQuery() ) {
 			// add the fetched entities
 			List fromElements = fromClause.getProjectionList();
 
 			ASTAppender appender = new ASTAppender( getASTFactory(), this );	// Get ready to start adding nodes.
 			int size = fromElements.size();
 	
 			Iterator iterator = fromElements.iterator();
 			for ( int k = 0; iterator.hasNext(); k++ ) {
 				FromElement fromElement = ( FromElement ) iterator.next();
 
 				if ( fromElement.isFetch() ) {
 					FromElement origin = null;
 					if ( fromElement.getRealOrigin() == null ) {
 						// work around that crazy issue where the tree contains
 						// "empty" FromElements (no text); afaict, this is caused
 						// by FromElementFactory.createCollectionJoin()
 						if ( fromElement.getOrigin() == null ) {
 							throw new QueryException( "Unable to determine origin of join fetch [" + fromElement.getDisplayText() + "]" );
 						}
 						else {
 							origin = fromElement.getOrigin();
 						}
 					}
 					else {
 						origin = fromElement.getRealOrigin();
 					}
 					if ( !fromElementsForLoad.contains( origin ) ) {
 						throw new QueryException(
 								"query specified join fetching, but the owner " +
 								"of the fetched association was not present in the select list " +
 								"[" + fromElement.getDisplayText() + "]"
 						);
 					}
 					Type type = fromElement.getSelectType();
 					addCollectionFromElement( fromElement );
 					if ( type != null ) {
 						boolean collectionOfElements = fromElement.isCollectionOfValuesOrComponents();
 						if ( !collectionOfElements ) {
 							// Add the type to the list of returned sqlResultTypes.
 							fromElement.setIncludeSubclasses( true );
 							fromElementsForLoad.add( fromElement );
 							//sqlResultTypeList.add( type );
 							// Generate the select expression.
 							String text = fromElement.renderIdentifierSelect( size, k );
 							SelectExpressionImpl generatedExpr = ( SelectExpressionImpl ) appender.append( SqlTokenTypes.SELECT_EXPR, text, false );
 							if ( generatedExpr != null ) {
 								generatedExpr.setFromElement( fromElement );
 							}
 						}
 					}
 				}
 			}
 
 			// generate id select fragment and then property select fragment for
 			// each expression, just like generateSelectFragments().
 			renderNonScalarSelects( collectSelectExpressions(), fromClause );
 		}
 
 		if ( scalarSelect || getWalker().isShallowQuery() ) {
 			// If there are any scalars (non-entities) selected, render the select column aliases.
 			renderScalarSelects( selectExpressions, fromClause );
 		}
 
 		finishInitialization( /*sqlResultTypeList,*/ queryReturnTypeList );
 	}
 
 	private void finishInitialization(ArrayList queryReturnTypeList) {
 		queryReturnTypes = ( Type[] ) queryReturnTypeList.toArray( new Type[queryReturnTypeList.size()] );
 		initializeColumnNames();
 		prepared = true;
 	}
 
 	private void initializeColumnNames() {
 		// Generate an 2d array of column names, the first dimension is parallel with the
 		// return types array.  The second dimension is the list of column names for each
 		// type.
 
 		// todo: we should really just collect these from the various SelectExpressions, rather than regenerating here
 		columnNames = getSessionFactoryHelper().generateColumnNames( queryReturnTypes );
 		columnNamesStartPositions = new int[ columnNames.length ];
 		int startPosition = 1;
 		for ( int i = 0 ; i < columnNames.length ; i ++ ) {
 			columnNamesStartPositions[ i ] = startPosition;
 			startPosition += columnNames[ i ].length;
 		}
 	}
 
 	public int getColumnNamesStartPosition(int i) {
 		return columnNamesStartPositions[ i ];
 	}
 
 	/**
 	 * Prepares a derived (i.e., not explicitly defined in the query) select clause.
 	 *
 	 * @param fromClause The from clause to which this select clause is linked.
 	 */
 	public void initializeDerivedSelectClause(FromClause fromClause) throws SemanticException {
 		if ( prepared ) {
 			throw new IllegalStateException( "SelectClause was already prepared!" );
 		}
 		//Used to be tested by the TCK but the test is no longer here
 //		if ( getSessionFactoryHelper().isStrictJPAQLComplianceEnabled() && !getWalker().isSubQuery() ) {
 //			// NOTE : the isSubQuery() bit is a temporary hack...
 //			throw new QuerySyntaxException( "JPA-QL compliance requires select clause" );
 //		}
 		List fromElements = fromClause.getProjectionList();
 
 		ASTAppender appender = new ASTAppender( getASTFactory(), this );	// Get ready to start adding nodes.
 		int size = fromElements.size();
 		ArrayList queryReturnTypeList = new ArrayList( size );
 
 		Iterator iterator = fromElements.iterator();
 		for ( int k = 0; iterator.hasNext(); k++ ) {
 			FromElement fromElement = ( FromElement ) iterator.next();
 			Type type = fromElement.getSelectType();
 
 			addCollectionFromElement( fromElement );
 
 			if ( type != null ) {
 				boolean collectionOfElements = fromElement.isCollectionOfValuesOrComponents();
 				if ( !collectionOfElements ) {
 					if ( !fromElement.isFetch() ) {
 						// Add the type to the list of returned sqlResultTypes.
 						queryReturnTypeList.add( type );
 					}
 					fromElementsForLoad.add( fromElement );
 					// Generate the select expression.
 					String text = fromElement.renderIdentifierSelect( size, k );
 					SelectExpressionImpl generatedExpr = ( SelectExpressionImpl ) appender.append( SqlTokenTypes.SELECT_EXPR, text, false );
 					if ( generatedExpr != null ) {
 						generatedExpr.setFromElement( fromElement );
 					}
 				}
 			}
 		}
 
 		// Get all the select expressions (that we just generated) and render the select.
 		SelectExpression[] selectExpressions = collectSelectExpressions();
 
 		if ( getWalker().isShallowQuery() ) {
 			renderScalarSelects( selectExpressions, fromClause );
 		}
 		else {
 			renderNonScalarSelects( selectExpressions, fromClause );
 		}
 		finishInitialization( queryReturnTypeList );
 	}
 	
-	public static boolean VERSION2_SQL = false;
+	public static boolean VERSION2_SQL;
 
 	private void addCollectionFromElement(FromElement fromElement) {
 		if ( fromElement.isFetch() ) {
 			if ( fromElement.getQueryableCollection() != null ) {
 				String suffix;
 				if (collectionFromElements==null) {
 					collectionFromElements = new ArrayList();
 					suffix = VERSION2_SQL ? "__" : "0__";
 				}
 				else {
 					suffix = Integer.toString( collectionFromElements.size() ) + "__";
 				}
 				collectionFromElements.add( fromElement );
 				fromElement.setCollectionSuffix( suffix );
 			}
 		}
 	}
 
 	protected AST getFirstSelectExpression() {
 		AST n = getFirstChild();
 		// Skip 'DISTINCT' and 'ALL', so we return the first expression node.
 		while ( n != null && ( n.getType() == SqlTokenTypes.DISTINCT || n.getType() == SqlTokenTypes.ALL ) ) {
 			n = n.getNextSibling();
 		}
 		return n;
 	}
 
 	private boolean isReturnableEntity(SelectExpression selectExpression) throws SemanticException {
 		FromElement fromElement = selectExpression.getFromElement();
 		boolean isFetchOrValueCollection = fromElement != null && 
 				( fromElement.isFetch() || fromElement.isCollectionOfValuesOrComponents() );
 		if ( isFetchOrValueCollection ) {
 			return false;
 		}
 		else {
 			return selectExpression.isReturnableEntity();
 		}
 	}
 
 	private void renderScalarSelects(SelectExpression[] se, FromClause currentFromClause) throws SemanticException {
 		if ( !currentFromClause.isSubQuery() ) {
 			for ( int i = 0; i < se.length; i++ ) {
 				SelectExpression expr = se[i];
 				expr.setScalarColumn( i );	// Create SQL_TOKEN nodes for the columns.
 			}
 		}
 	}
 	
 	private void initAliases(SelectExpression[] selectExpressions) {
 		if ( aggregatedSelectExpression == null ) {
 			aliases = new String[selectExpressions.length];
 			for ( int i=0; i<selectExpressions.length; i++ ) {
 				String alias = selectExpressions[i].getAlias();
 				aliases[i] = alias==null ? Integer.toString(i) : alias;
 			}
 		}
 		else {
 			aliases = aggregatedSelectExpression.getAggregatedAliases();
 		}
 	}
 
 	private void renderNonScalarSelects(SelectExpression[] selectExpressions, FromClause currentFromClause) 
 	throws SemanticException {
 		ASTAppender appender = new ASTAppender( getASTFactory(), this );
 		final int size = selectExpressions.length;
 		int nonscalarSize = 0;
 		for ( int i = 0; i < size; i++ ) {
 			if ( !selectExpressions[i].isScalar() ) nonscalarSize++;
 		}
 
 		int j = 0;
 		for ( int i = 0; i < size; i++ ) {
 			if ( !selectExpressions[i].isScalar() ) {
 				SelectExpression expr = selectExpressions[i];
 				FromElement fromElement = expr.getFromElement();
 				if ( fromElement != null ) {
 					renderNonScalarIdentifiers( fromElement, nonscalarSize, j, expr, appender );
 					j++;
 				}
 			}
 		}
 
 		if ( !currentFromClause.isSubQuery() ) {
 			// Generate the property select tokens.
 			int k = 0;
 			for ( int i = 0; i < size; i++ ) {
 				if ( !selectExpressions[i].isScalar() ) {
 					FromElement fromElement = selectExpressions[i].getFromElement();
 					if ( fromElement != null ) {
 						renderNonScalarProperties( appender, fromElement, nonscalarSize, k );
 						k++;
 					}
 				}
 			}
 		}
 	}
 
 	private void renderNonScalarIdentifiers(FromElement fromElement, int nonscalarSize, int j, SelectExpression expr, ASTAppender appender) {
 		String text = fromElement.renderIdentifierSelect( nonscalarSize, j );
 		if ( !fromElement.getFromClause().isSubQuery() ) {
 			if ( !scalarSelect && !getWalker().isShallowQuery() ) {
 				//TODO: is this a bit ugly?
 				expr.setText( text );
 			}
 			else {
 				appender.append( SqlTokenTypes.SQL_TOKEN, text, false );
 			}
 		}
 	}
 
 	private void renderNonScalarProperties(ASTAppender appender, FromElement fromElement, int nonscalarSize, int k) {
 		String text = fromElement.renderPropertySelect( nonscalarSize, k );
 		appender.append( SqlTokenTypes.SQL_TOKEN, text, false );
 		if ( fromElement.getQueryableCollection() != null && fromElement.isFetch() ) {
 			text = fromElement.renderCollectionSelectFragment( nonscalarSize, k );
 			appender.append( SqlTokenTypes.SQL_TOKEN, text, false );
 		}
 		// Look through the FromElement's children to find any collections of values that should be fetched...
 		ASTIterator iter = new ASTIterator( fromElement );
 		while ( iter.hasNext() ) {
 			FromElement child = ( FromElement ) iter.next();
 			if ( child.isCollectionOfValuesOrComponents() && child.isFetch() ) {
 				// Need a better way to define the suffixes here...
 				text = child.renderValueCollectionSelectFragment( nonscalarSize, nonscalarSize + k );
 				appender.append( SqlTokenTypes.SQL_TOKEN, text, false );
 			}
 		}
 	}
 
 	public List getCollectionFromElements() {
 		return collectionFromElements;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/util/AliasGenerator.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/util/AliasGenerator.java
index a49ba89bc9..0c3efc6dfa 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/util/AliasGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/util/AliasGenerator.java
@@ -1,45 +1,45 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.util;
 
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * Generates class/table/column aliases during semantic analysis and SQL rendering.
  * <p/>
  * Its essential purpose is to keep an internal counter to ensure that the
  * generated aliases are unique.
  */
 public class AliasGenerator {
-	private int next = 0;
+	private int next;
 
 	private int nextCount() {
 		return next++;
 	}
 
 	public String createName(String name) {
 		return StringHelper.generateAlias( name, nextCount() );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/util/ColumnHelper.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/util/ColumnHelper.java
index 11e2882ba4..099980a1b7 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/util/ColumnHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/ast/util/ColumnHelper.java
@@ -1,71 +1,71 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.ast.util;
 import antlr.ASTFactory;
 import antlr.collections.AST;
 
 import org.hibernate.hql.internal.NameGenerator;
 import org.hibernate.hql.internal.antlr.SqlTokenTypes;
 import org.hibernate.hql.internal.ast.tree.HqlSqlWalkerNode;
 
 /**
  * Provides utility methods for dealing with arrays of SQL column names.
  *
  * @author josh
  */
 public final class ColumnHelper {
 
 	/**
 	 * @deprecated (tell clover to filter this out)
 	 */
 	private ColumnHelper() {
 	}
 
 	public static void generateSingleScalarColumn(HqlSqlWalkerNode node, int i) {
 		ASTFactory factory = node.getASTFactory();
 		ASTUtil.createSibling( factory, SqlTokenTypes.SELECT_COLUMNS, " as " + NameGenerator.scalarName( i, 0 ), node );
 	}
 
 	/**
 	 * Generates the scalar column AST nodes for a given array of SQL columns
 	 */
-	public static void generateScalarColumns(HqlSqlWalkerNode node, String sqlColumns[], int i) {
+	public static void generateScalarColumns(HqlSqlWalkerNode node, String[] sqlColumns, int i) {
 		if ( sqlColumns.length == 1 ) {
 			generateSingleScalarColumn( node, i );
 		}
 		else {
 			ASTFactory factory = node.getASTFactory();
 			AST n = node;
 			n.setText( sqlColumns[0] );	// Use the DOT node to emit the first column name.
 			// Create the column names, folled by the column aliases.
 			for ( int j = 0; j < sqlColumns.length; j++ ) {
 				if ( j > 0 ) {
 					n = ASTUtil.createSibling( factory, SqlTokenTypes.SQL_TOKEN, sqlColumns[j], n );
 				}
 				n = ASTUtil.createSibling( factory, SqlTokenTypes.SELECT_COLUMNS, " as " + NameGenerator.scalarName( i, j ), n );
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/ClauseParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/ClauseParser.java
index f1f84301a6..de3319fa8c 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/ClauseParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/ClauseParser.java
@@ -1,151 +1,144 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.hql.internal.classic;
+
 import java.util.ArrayList;
-import java.util.Iterator;
 import java.util.List;
 
 import org.hibernate.QueryException;
 
 /**
  * Parses the Hibernate query into its constituent clauses.
  */
 public class ClauseParser implements Parser {
-
 	private Parser child;
-	private List selectTokens;
-	private boolean cacheSelectTokens = false;
-	private boolean byExpected = false;
-	private int parenCount = 0;
+	private List<String> selectTokens;
+	private boolean cacheSelectTokens;
+	private boolean byExpected;
+	private int parenCount;
 
+	@Override
 	public void token(String token, QueryTranslatorImpl q) throws QueryException {
 		String lcToken = token.toLowerCase();
 
 		if ( "(".equals( token ) ) {
 			parenCount++;
 		}
 		else if ( ")".equals( token ) ) {
 			parenCount--;
 		}
 
 		if ( byExpected && !lcToken.equals( "by" ) ) {
 			throw new QueryException( "BY expected after GROUP or ORDER: " + token );
 		}
 
 		boolean isClauseStart = parenCount == 0; //ignore subselect keywords
 
 		if ( isClauseStart ) {
 			if ( lcToken.equals( "select" ) ) {
-				selectTokens = new ArrayList();
+				selectTokens = new ArrayList<String>();
 				cacheSelectTokens = true;
 			}
 			else if ( lcToken.equals( "from" ) ) {
 				child = new FromParser();
 				child.start( q );
 				cacheSelectTokens = false;
 			}
 			else if ( lcToken.equals( "where" ) ) {
 				endChild( q );
 				child = new WhereParser();
 				child.start( q );
 			}
 			else if ( lcToken.equals( "order" ) ) {
 				endChild( q );
 				child = new OrderByParser();
 				byExpected = true;
 			}
 			else if ( lcToken.equals( "having" ) ) {
 				endChild( q );
 				child = new HavingParser();
 				child.start( q );
 			}
 			else if ( lcToken.equals( "group" ) ) {
 				endChild( q );
 				child = new GroupByParser();
 				byExpected = true;
 			}
 			else if ( lcToken.equals( "by" ) ) {
 				if ( !byExpected ) throw new QueryException( "GROUP or ORDER expected before BY" );
 				child.start( q );
 				byExpected = false;
 			}
 			else {
 				isClauseStart = false;
 			}
 		}
 
 		if ( !isClauseStart ) {
 			if ( cacheSelectTokens ) {
 				selectTokens.add( token );
 			}
 			else {
 				if ( child == null ) {
 					throw new QueryException( "query must begin with SELECT or FROM: " + token );
 				}
 				else {
 					child.token( token, q );
 				}
 			}
 		}
 
 	}
 
 	private void endChild(QueryTranslatorImpl q) throws QueryException {
 		if ( child == null ) {
 			//null child could occur for no from clause in a filter
 			cacheSelectTokens = false;
 		}
 		else {
 			child.end( q );
 		}
 	}
 
+	@Override
 	public void start(QueryTranslatorImpl q) {
 	}
 
+	@Override
 	public void end(QueryTranslatorImpl q) throws QueryException {
 		endChild( q );
 		if ( selectTokens != null ) {
 			child = new SelectParser();
 			child.start( q );
-			Iterator iter = selectTokens.iterator();
-			while ( iter.hasNext() ) {
-				token( ( String ) iter.next(), q );
+			for ( String selectToken : selectTokens ) {
+				token( selectToken, q );
 			}
 			child.end( q );
 		}
 		byExpected = false;
 		parenCount = 0;
 		cacheSelectTokens = false;
 	}
 
 }
-
-
-
-
-
-
-
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/QueryTranslatorImpl.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/QueryTranslatorImpl.java
index e51d7b0669..3e0814bad2 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/QueryTranslatorImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/QueryTranslatorImpl.java
@@ -1,1129 +1,1129 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.classic;
 
 import java.io.Serializable;
 import java.lang.reflect.Constructor;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.ScrollableResults;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.internal.JoinSequence;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.hql.internal.HolderInstantiator;
 import org.hibernate.hql.internal.NameGenerator;
 import org.hibernate.hql.spi.FilterTranslator;
 import org.hibernate.hql.spi.ParameterTranslations;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.IteratorImpl;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.BasicLoader;
 import org.hibernate.loader.spi.AfterLoadAction;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.PropertyMapping;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.JoinFragment;
 import org.hibernate.sql.JoinType;
 import org.hibernate.sql.QuerySelect;
 import org.hibernate.transform.ResultTransformer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 /**
  * An instance of <tt>QueryTranslator</tt> translates a Hibernate
  * query string to SQL.
  */
 public class QueryTranslatorImpl extends BasicLoader implements FilterTranslator {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, QueryTranslatorImpl.class.getName());
+    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( QueryTranslatorImpl.class );
 
 	private static final String[] NO_RETURN_ALIASES = new String[] {};
 
 	private final String queryIdentifier;
 	private final String queryString;
 
 	private final Map typeMap = new LinkedHashMap();
 	private final Map collections = new LinkedHashMap();
 	private List returnedTypes = new ArrayList();
 	private final List fromTypes = new ArrayList();
 	private final List scalarTypes = new ArrayList();
 	private final Map namedParameters = new HashMap();
 	private final Map aliasNames = new HashMap();
 	private final Map oneToOneOwnerNames = new HashMap();
 	private final Map uniqueKeyOwnerReferences = new HashMap();
 	private final Map decoratedPropertyMappings = new HashMap();
 
 	private final List scalarSelectTokens = new ArrayList();
 	private final List whereTokens = new ArrayList();
 	private final List havingTokens = new ArrayList();
 	private final Map joins = new LinkedHashMap();
 	private final List orderByTokens = new ArrayList();
 	private final List groupByTokens = new ArrayList();
 	private final Set<Serializable> querySpaces = new HashSet<Serializable>();
 	private final Set entitiesToFetch = new HashSet();
 
 	private final Map pathAliases = new HashMap();
 	private final Map pathJoins = new HashMap();
 
 	private Queryable[] persisters;
 	private int[] owners;
 	private EntityType[] ownerAssociationTypes;
 	private String[] names;
 	private boolean[] includeInSelect;
 	private int selectLength;
 	private Type[] returnTypes;
 	private Type[] actualReturnTypes;
 	private String[][] scalarColumnNames;
 	private Map tokenReplacements;
-	private int nameCount = 0;
-	private int parameterCount = 0;
-	private boolean distinct = false;
+	private int nameCount;
+	private int parameterCount;
+	private boolean distinct;
 	private boolean compiled;
 	private String sqlString;
 	private Class holderClass;
 	private Constructor holderConstructor;
 	private boolean hasScalars;
 	private boolean shallowQuery;
 	private QueryTranslatorImpl superQuery;
 
 	private QueryableCollection collectionPersister;
 	private int collectionOwnerColumn = -1;
 	private String collectionOwnerName;
 	private String fetchName;
 
 	private String[] suffixes;
 
 	private Map enabledFilters;
 
 	/**
 	 * Construct a query translator
 	 *
 	 * @param queryIdentifier A unique identifier for the query of which this
 	 * translation is part; typically this is the original, user-supplied query string.
 	 * @param queryString The "preprocessed" query string; at the very least
 	 * already processed by {@link org.hibernate.hql.internal.QuerySplitter}.
 	 * @param enabledFilters Any enabled filters.
 	 * @param factory The session factory.
 	 */
 	public QueryTranslatorImpl(
 			String queryIdentifier,
 	        String queryString,
 	        Map enabledFilters,
 	        SessionFactoryImplementor factory) {
 		super( factory );
 		this.queryIdentifier = queryIdentifier;
 		this.queryString = queryString;
 		this.enabledFilters = enabledFilters;
 	}
 
 	/**
 	 * Construct a query translator; this form used internally.
 	 *
 	 * @param queryString The query string to process.
 	 * @param enabledFilters Any enabled filters.
 	 * @param factory The session factory.
 	 */
 	public QueryTranslatorImpl(
 	        String queryString,
 	        Map enabledFilters,
 	        SessionFactoryImplementor factory) {
 		this( queryString, queryString, enabledFilters, factory );
 	}
 
 	/**
 	 * Compile a subquery.
 	 *
 	 * @param superquery The containing query of the query to be compiled.
 	 *
 	 * @throws org.hibernate.MappingException Indicates problems resolving
 	 * things referenced in the query.
 	 * @throws org.hibernate.QueryException Generally some form of syntatic
 	 * failure.
 	 */
 	void compile(QueryTranslatorImpl superquery) throws QueryException, MappingException {
 		this.tokenReplacements = superquery.tokenReplacements;
 		this.superQuery = superquery;
 		this.shallowQuery = true;
 		this.enabledFilters = superquery.getEnabledFilters();
 		compile();
 	}
 
 
 	/**
 	 * Compile a "normal" query. This method may be called multiple
 	 * times. Subsequent invocations are no-ops.
 	 */
 	public synchronized void compile(
 			Map replacements,
 			boolean scalar) throws QueryException, MappingException {
 		if ( !compiled ) {
 			this.tokenReplacements = replacements;
 			this.shallowQuery = scalar;
 			compile();
 		}
 	}
 
 	/**
 	 * Compile a filter. This method may be called multiple
 	 * times. Subsequent invocations are no-ops.
 	 */
 	public synchronized void compile(
 			String collectionRole,
 			Map replacements,
 			boolean scalar) throws QueryException, MappingException {
 
 		if ( !isCompiled() ) {
 			addFromAssociation( "this", collectionRole );
 			compile( replacements, scalar );
 		}
 	}
 
 	/**
 	 * Compile the query (generate the SQL).
 	 *
 	 * @throws org.hibernate.MappingException Indicates problems resolving
 	 * things referenced in the query.
 	 * @throws org.hibernate.QueryException Generally some form of syntatic
 	 * failure.
 	 */
 	private void compile() throws QueryException, MappingException {
 		LOG.trace( "Compiling query" );
 		try {
 			ParserHelper.parse( new PreprocessingParser( tokenReplacements ),
 					queryString,
 					ParserHelper.HQL_SEPARATORS,
 					this );
 			renderSQL();
 		}
 		catch ( QueryException qe ) {
 			if ( qe.getQueryString() == null ) {
 				throw qe.wrapWithQueryString( queryString );
 			}
 			else {
 				throw qe;
 			}
 		}
 		catch ( MappingException me ) {
 			throw me;
 		}
 		catch ( Exception e ) {
 			LOG.debug( "Unexpected query compilation problem", e );
 			e.printStackTrace();
 			throw new QueryException( "Incorrect query syntax", queryString, e );
 		}
 
 		postInstantiate();
 
 		compiled = true;
 
 	}
 
 	@Override
     public String getSQLString() {
 		return sqlString;
 	}
 
 	public List<String> collectSqlStrings() {
 		return ArrayHelper.toList( new String[] { sqlString } );
 	}
 
 	public String getQueryString() {
 		return queryString;
 	}
 
 	/**
 	 * Persisters for the return values of a <tt>find()</tt> style query.
 	 *
 	 * @return an array of <tt>EntityPersister</tt>s.
 	 */
 	@Override
     protected Loadable[] getEntityPersisters() {
 		return persisters;
 	}
 
 	/**
 	 * Types of the return values of an <tt>iterate()</tt> style query.
 	 *
 	 * @return an array of <tt>Type</tt>s.
 	 */
 	public Type[] getReturnTypes() {
 		return actualReturnTypes;
 	}
 
 	public String[] getReturnAliases() {
 		// return aliases not supported in classic translator!
 		return NO_RETURN_ALIASES;
 	}
 
 	public String[][] getColumnNames() {
 		return scalarColumnNames;
 	}
 
 	private static void logQuery(String hql, String sql) {
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "HQL: %s", hql );
 			LOG.debugf( "SQL: %s", sql );
 		}
 	}
 
 	void setAliasName(String alias, String name) {
 		aliasNames.put( alias, name );
 	}
 
 	public String getAliasName(String alias) {
 		String name = ( String ) aliasNames.get( alias );
 		if ( name == null ) {
 			if ( superQuery != null ) {
 				name = superQuery.getAliasName( alias );
 			}
 			else {
 				name = alias;
 			}
 		}
 		return name;
 	}
 
 	String unalias(String path) {
 		String alias = StringHelper.root( path );
 		String name = getAliasName( alias );
         if (name != null) return name + path.substring(alias.length());
         return path;
 	}
 
 	void addEntityToFetch(String name, String oneToOneOwnerName, AssociationType ownerAssociationType) {
 		addEntityToFetch( name );
 		if ( oneToOneOwnerName != null ) oneToOneOwnerNames.put( name, oneToOneOwnerName );
 		if ( ownerAssociationType != null ) uniqueKeyOwnerReferences.put( name, ownerAssociationType );
 	}
 
 	private void addEntityToFetch(String name) {
 		entitiesToFetch.add( name );
 	}
 
 	private int nextCount() {
 		return ( superQuery == null ) ? nameCount++ : superQuery.nameCount++;
 	}
 
 	String createNameFor(String type) {
 		return StringHelper.generateAlias( type, nextCount() );
 	}
 
 	String createNameForCollection(String role) {
 		return StringHelper.generateAlias( role, nextCount() );
 	}
 
 	private String getType(String name) {
 		String type = ( String ) typeMap.get( name );
 		if ( type == null && superQuery != null ) {
 			type = superQuery.getType( name );
 		}
 		return type;
 	}
 
 	private String getRole(String name) {
 		String role = ( String ) collections.get( name );
 		if ( role == null && superQuery != null ) {
 			role = superQuery.getRole( name );
 		}
 		return role;
 	}
 
 	boolean isName(String name) {
 		return aliasNames.containsKey( name ) ||
 				typeMap.containsKey( name ) ||
 				collections.containsKey( name ) || (
 				superQuery != null && superQuery.isName( name )
 				);
 	}
 
 	PropertyMapping getPropertyMapping(String name) throws QueryException {
 		PropertyMapping decorator = getDecoratedPropertyMapping( name );
 		if ( decorator != null ) return decorator;
 
 		String type = getType( name );
 		if ( type == null ) {
 			String role = getRole( name );
 			if ( role == null ) {
 				throw new QueryException( "alias not found: " + name );
 			}
 			return getCollectionPersister( role ); //.getElementPropertyMapping();
 		}
 		else {
 			Queryable persister = getEntityPersister( type );
 			if ( persister == null ) throw new QueryException( "persistent class not found: " + type );
 			return persister;
 		}
 	}
 
 	private PropertyMapping getDecoratedPropertyMapping(String name) {
 		return ( PropertyMapping ) decoratedPropertyMappings.get( name );
 	}
 
 	void decoratePropertyMapping(String name, PropertyMapping mapping) {
 		decoratedPropertyMappings.put( name, mapping );
 	}
 
 	private Queryable getEntityPersisterForName(String name) throws QueryException {
 		String type = getType( name );
 		Queryable persister = getEntityPersister( type );
 		if ( persister == null ) throw new QueryException( "persistent class not found: " + type );
 		return persister;
 	}
 
 	Queryable getEntityPersisterUsingImports(String className) {
 		final String importedClassName = getFactory().getImportedClassName( className );
 		if ( importedClassName == null ) {
 			return null;
 		}
 		try {
 			return ( Queryable ) getFactory().getEntityPersister( importedClassName );
 		}
 		catch ( MappingException me ) {
 			return null;
 		}
 	}
 
 	Queryable getEntityPersister(String entityName) throws QueryException {
 		try {
 			return ( Queryable ) getFactory().getEntityPersister( entityName );
 		}
 		catch ( Exception e ) {
 			throw new QueryException( "persistent class not found: " + entityName );
 		}
 	}
 
 	QueryableCollection getCollectionPersister(String role) throws QueryException {
 		try {
 			return ( QueryableCollection ) getFactory().getCollectionPersister( role );
 		}
 		catch ( ClassCastException cce ) {
 			throw new QueryException( "collection role is not queryable: " + role );
 		}
 		catch ( Exception e ) {
 			throw new QueryException( "collection role not found: " + role );
 		}
 	}
 
 	void addType(String name, String type) {
 		typeMap.put( name, type );
 	}
 
 	void addCollection(String name, String role) {
 		collections.put( name, role );
 	}
 
 	void addFrom(String name, String type, JoinSequence joinSequence)
 			throws QueryException {
 		addType( name, type );
 		addFrom( name, joinSequence );
 	}
 
 	void addFromCollection(String name, String collectionRole, JoinSequence joinSequence)
 			throws QueryException {
 		//register collection role
 		addCollection( name, collectionRole );
 		addJoin( name, joinSequence );
 	}
 
 	void addFrom(String name, JoinSequence joinSequence)
 			throws QueryException {
 		fromTypes.add( name );
 		addJoin( name, joinSequence );
 	}
 
 	void addFromClass(String name, Queryable classPersister)
 			throws QueryException {
 		JoinSequence joinSequence = new JoinSequence( getFactory() )
 				.setRoot( classPersister, name );
 		//crossJoins.add(name);
 		addFrom( name, classPersister.getEntityName(), joinSequence );
 	}
 
 	void addSelectClass(String name) {
 		returnedTypes.add( name );
 	}
 
 	void addSelectScalar(Type type) {
 		scalarTypes.add( type );
 	}
 
 	void appendWhereToken(String token) {
 		whereTokens.add( token );
 	}
 
 	void appendHavingToken(String token) {
 		havingTokens.add( token );
 	}
 
 	void appendOrderByToken(String token) {
 		orderByTokens.add( token );
 	}
 
 	void appendGroupByToken(String token) {
 		groupByTokens.add( token );
 	}
 
 	void appendScalarSelectToken(String token) {
 		scalarSelectTokens.add( token );
 	}
 
 	void appendScalarSelectTokens(String[] tokens) {
 		scalarSelectTokens.add( tokens );
 	}
 
 	void addFromJoinOnly(String name, JoinSequence joinSequence) throws QueryException {
 		addJoin( name, joinSequence.getFromPart() );
 	}
 
 	void addJoin(String name, JoinSequence joinSequence) throws QueryException {
 		if ( !joins.containsKey( name ) ) joins.put( name, joinSequence );
 	}
 
 	void addNamedParameter(String name) {
 		if ( superQuery != null ) superQuery.addNamedParameter( name );
 		Integer loc = parameterCount++;
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			namedParameters.put( name, loc );
 		}
 		else if ( o instanceof Integer ) {
 			ArrayList list = new ArrayList( 4 );
 			list.add( o );
 			list.add( loc );
 			namedParameters.put( name, list );
 		}
 		else {
 			( ( ArrayList ) o ).add( loc );
 		}
 	}
 
 	@Override
     public int[] getNamedParameterLocs(String name) throws QueryException {
 		Object o = namedParameters.get( name );
 		if ( o == null ) {
 			throw new QueryException( ERROR_NAMED_PARAMETER_DOES_NOT_APPEAR + name, queryString );
 		}
 		if ( o instanceof Integer ) return new int[] { (Integer) o };
 		else {
 			return ArrayHelper.toIntArray( ( ArrayList ) o );
 		}
 	}
 
 	private void renderSQL() throws QueryException, MappingException {
 
 		final int rtsize;
 		if ( returnedTypes.size() == 0 && scalarTypes.size() == 0 ) {
 			//ie no select clause in HQL
 			returnedTypes = fromTypes;
 			rtsize = returnedTypes.size();
 		}
 		else {
 			rtsize = returnedTypes.size();
 			Iterator iter = entitiesToFetch.iterator();
 			while ( iter.hasNext() ) {
 				returnedTypes.add( iter.next() );
 			}
 		}
 		int size = returnedTypes.size();
 		persisters = new Queryable[size];
 		names = new String[size];
 		owners = new int[size];
 		ownerAssociationTypes = new EntityType[size];
 		suffixes = new String[size];
 		includeInSelect = new boolean[size];
 		for ( int i = 0; i < size; i++ ) {
 			String name = ( String ) returnedTypes.get( i );
 			//if ( !isName(name) ) throw new QueryException("unknown type: " + name);
 			persisters[i] = getEntityPersisterForName( name );
 			// TODO: cannot use generateSuffixes() - it handles the initial suffix differently.
 			suffixes[i] = ( size == 1 ) ? "" : Integer.toString( i ) + '_';
 			names[i] = name;
 			includeInSelect[i] = !entitiesToFetch.contains( name );
 			if ( includeInSelect[i] ) selectLength++;
 			if ( name.equals( collectionOwnerName ) ) collectionOwnerColumn = i;
 			String oneToOneOwner = ( String ) oneToOneOwnerNames.get( name );
 			owners[i] = ( oneToOneOwner == null ) ? -1 : returnedTypes.indexOf( oneToOneOwner );
 			ownerAssociationTypes[i] = (EntityType) uniqueKeyOwnerReferences.get( name );
 		}
 
 		if ( ArrayHelper.isAllNegative( owners ) ) owners = null;
 
 		String scalarSelect = renderScalarSelect(); //Must be done here because of side-effect! yuck...
 
 		int scalarSize = scalarTypes.size();
 		hasScalars = scalarTypes.size() != rtsize;
 
 		returnTypes = new Type[scalarSize];
 		for ( int i = 0; i < scalarSize; i++ ) {
 			returnTypes[i] = ( Type ) scalarTypes.get( i );
 		}
 
 		QuerySelect sql = new QuerySelect( getFactory().getDialect() );
 		sql.setDistinct( distinct );
 
 		if ( !shallowQuery ) {
 			renderIdentifierSelect( sql );
 			renderPropertiesSelect( sql );
 		}
 
 		if ( collectionPersister != null ) {
 			sql.addSelectFragmentString( collectionPersister.selectFragment( fetchName, "__" ) );
 		}
 
 		if ( hasScalars || shallowQuery ) sql.addSelectFragmentString( scalarSelect );
 
 		//TODO: for some dialects it would be appropriate to add the renderOrderByPropertiesSelect() to other select strings
 		mergeJoins( sql.getJoinFragment() );
 
 		sql.setWhereTokens( whereTokens.iterator() );
 
 		sql.setGroupByTokens( groupByTokens.iterator() );
 		sql.setHavingTokens( havingTokens.iterator() );
 		sql.setOrderByTokens( orderByTokens.iterator() );
 
 		if ( collectionPersister != null && collectionPersister.hasOrdering() ) {
 			sql.addOrderBy( collectionPersister.getSQLOrderByString( fetchName ) );
 		}
 
 		scalarColumnNames = NameGenerator.generateColumnNames( returnTypes, getFactory() );
 
 		// initialize the Set of queried identifier spaces (ie. tables)
 		Iterator iter = collections.values().iterator();
 		while ( iter.hasNext() ) {
 			CollectionPersister p = getCollectionPersister( ( String ) iter.next() );
 			addQuerySpaces( p.getCollectionSpaces() );
 		}
 		iter = typeMap.keySet().iterator();
 		while ( iter.hasNext() ) {
 			Queryable p = getEntityPersisterForName( ( String ) iter.next() );
 			addQuerySpaces( p.getQuerySpaces() );
 		}
 
 		sqlString = sql.toQueryString();
 
 		if ( holderClass != null ) holderConstructor = ReflectHelper.getConstructor( holderClass, returnTypes );
 
 		if ( hasScalars ) {
 			actualReturnTypes = returnTypes;
 		}
 		else {
 			actualReturnTypes = new Type[selectLength];
 			int j = 0;
 			for ( int i = 0; i < persisters.length; i++ ) {
 				if ( includeInSelect[i] ) {
 					actualReturnTypes[j++] = getFactory().getTypeResolver()
 							.getTypeFactory()
 							.manyToOne( persisters[i].getEntityName(), shallowQuery );
 				}
 			}
 		}
 
 	}
 
 	private void renderIdentifierSelect(QuerySelect sql) {
 		int size = returnedTypes.size();
 
 		for ( int k = 0; k < size; k++ ) {
 			String name = ( String ) returnedTypes.get( k );
 			String suffix = size == 1 ? "" : Integer.toString( k ) + '_';
 			sql.addSelectFragmentString( persisters[k].identifierSelectFragment( name, suffix ) );
 		}
 
 	}
 
 	/*private String renderOrderByPropertiesSelect() {
 		StringBuffer buf = new StringBuffer(10);
 
 		//add the columns we are ordering by to the select ID select clause
 		Iterator iter = orderByTokens.iterator();
 		while ( iter.hasNext() ) {
 			String token = (String) iter.next();
 			if ( token.lastIndexOf(".") > 0 ) {
 				//ie. it is of form "foo.bar", not of form "asc" or "desc"
 				buf.append(StringHelper.COMMA_SPACE).append(token);
 			}
 		}
 
 		return buf.toString();
 	}*/
 
 	private void renderPropertiesSelect(QuerySelect sql) {
 		int size = returnedTypes.size();
 		for ( int k = 0; k < size; k++ ) {
 			String suffix = size == 1 ? "" : Integer.toString( k ) + '_';
 			String name = ( String ) returnedTypes.get( k );
 			sql.addSelectFragmentString( persisters[k].propertySelectFragment( name, suffix, false ) );
 		}
 	}
 
 	/**
 	 * WARNING: side-effecty
 	 */
 	private String renderScalarSelect() {
 
 		boolean isSubselect = superQuery != null;
 
 		StringBuilder buf = new StringBuilder( 20 );
 
 		if ( scalarTypes.size() == 0 ) {
 			//ie. no select clause
 			int size = returnedTypes.size();
 			for ( int k = 0; k < size; k++ ) {
 
 				scalarTypes.add(
 						getFactory().getTypeResolver().getTypeFactory().manyToOne( persisters[k].getEntityName(), shallowQuery )
 				);
 
 				String[] idColumnNames = persisters[k].getIdentifierColumnNames();
 				for ( int i = 0; i < idColumnNames.length; i++ ) {
 					buf.append( returnedTypes.get( k ) ).append( '.' ).append( idColumnNames[i] );
 					if ( !isSubselect ) buf.append( " as " ).append( NameGenerator.scalarName( k, i ) );
 					if ( i != idColumnNames.length - 1 || k != size - 1 ) buf.append( ", " );
 				}
 
 			}
 
 		}
 		else {
 			//there _was_ a select clause
 			Iterator iter = scalarSelectTokens.iterator();
 			int c = 0;
 			boolean nolast = false; //real hacky...
 			int parenCount = 0; // used to count the nesting of parentheses
 			while ( iter.hasNext() ) {
 				Object next = iter.next();
 				if ( next instanceof String ) {
 					String token = ( String ) next;
 
 					if ( "(".equals( token ) ) {
 						parenCount++;
 					}
 					else if ( ")".equals( token ) ) {
 						parenCount--;
 					}
 
 					String lc = token.toLowerCase();
 					if ( lc.equals( ", " ) ) {
 						if ( nolast ) {
 							nolast = false;
 						}
 						else {
 							if ( !isSubselect && parenCount == 0 ) {
 								int x = c++;
 								buf.append( " as " )
 										.append( NameGenerator.scalarName( x, 0 ) );
 							}
 						}
 					}
 					buf.append( token );
 					if ( lc.equals( "distinct" ) || lc.equals( "all" ) ) {
 						buf.append( ' ' );
 					}
 				}
 				else {
 					nolast = true;
 					String[] tokens = ( String[] ) next;
 					for ( int i = 0; i < tokens.length; i++ ) {
 						buf.append( tokens[i] );
 						if ( !isSubselect ) {
 							buf.append( " as " )
 									.append( NameGenerator.scalarName( c, i ) );
 						}
 						if ( i != tokens.length - 1 ) buf.append( ", " );
 					}
 					c++;
 				}
 			}
 			if ( !isSubselect && !nolast ) {
 				int x = c++;
 				buf.append( " as " )
 						.append( NameGenerator.scalarName( x, 0 ) );
 			}
 
 		}
 
 		return buf.toString();
 	}
 
 	private void mergeJoins(JoinFragment ojf) throws MappingException, QueryException {
 
 		Iterator iter = joins.entrySet().iterator();
 		while ( iter.hasNext() ) {
 			Map.Entry me = ( Map.Entry ) iter.next();
 			String name = ( String ) me.getKey();
 			JoinSequence join = ( JoinSequence ) me.getValue();
 			join.setSelector( new JoinSequence.Selector() {
 				public boolean includeSubclasses(String alias) {
 					boolean include = returnedTypes.contains( alias ) && !isShallowQuery();
 					return include;
 				}
 			} );
 
 			if ( typeMap.containsKey( name ) ) {
 				ojf.addFragment( join.toJoinFragment( enabledFilters, true ) );
 			}
 			else if ( collections.containsKey( name ) ) {
 				ojf.addFragment( join.toJoinFragment( enabledFilters, true ) );
 			}
 			else {
 				//name from a super query (a bit inelegant that it shows up here)
 			}
 
 		}
 
 	}
 
 	public final Set<Serializable> getQuerySpaces() {
 		return querySpaces;
 	}
 
 	/**
 	 * Is this query called by scroll() or iterate()?
 	 *
 	 * @return true if it is, false if it is called by find() or list()
 	 */
 	boolean isShallowQuery() {
 		return shallowQuery;
 	}
 
 	void addQuerySpaces(Serializable[] spaces) {
 		Collections.addAll( querySpaces, spaces );
 		if ( superQuery != null ) superQuery.addQuerySpaces( spaces );
 	}
 
 	void setDistinct(boolean distinct) {
 		this.distinct = distinct;
 	}
 
 	boolean isSubquery() {
 		return superQuery != null;
 	}
 
 	/**
 	 * Overrides method from Loader
 	 */
 	@Override
     public CollectionPersister[] getCollectionPersisters() {
 		return collectionPersister == null ? null : new CollectionPersister[] { collectionPersister };
 	}
 
 	@Override
     protected String[] getCollectionSuffixes() {
 		return collectionPersister == null ? null : new String[] { "__" };
 	}
 
 	void setCollectionToFetch(String role, String name, String ownerName, String entityName)
 			throws QueryException {
 		fetchName = name;
 		collectionPersister = getCollectionPersister( role );
 		collectionOwnerName = ownerName;
 		if ( collectionPersister.getElementType().isEntityType() ) {
 			addEntityToFetch( entityName );
 		}
 	}
 
 	@Override
     protected String[] getSuffixes() {
 		return suffixes;
 	}
 
 	@Override
     protected String[] getAliases() {
 		return names;
 	}
 
 	/**
 	 * Used for collection filters
 	 */
 	private void addFromAssociation(final String elementName, final String collectionRole)
 			throws QueryException {
 		//q.addCollection(collectionName, collectionRole);
 		QueryableCollection persister = getCollectionPersister( collectionRole );
 		Type collectionElementType = persister.getElementType();
 		if ( !collectionElementType.isEntityType() ) {
 			throw new QueryException( "collection of values in filter: " + elementName );
 		}
 
 		String[] keyColumnNames = persister.getKeyColumnNames();
 		//if (keyColumnNames.length!=1) throw new QueryException("composite-key collection in filter: " + collectionRole);
 
 		String collectionName;
 		JoinSequence join = new JoinSequence( getFactory() );
 		collectionName = persister.isOneToMany() ?
 				elementName :
 				createNameForCollection( collectionRole );
 		join.setRoot( persister, collectionName );
 		if ( !persister.isOneToMany() ) {
 			//many-to-many
 			addCollection( collectionName, collectionRole );
 			try {
 				join.addJoin( ( AssociationType ) persister.getElementType(),
 						elementName,
 						JoinType.INNER_JOIN,
 						persister.getElementColumnNames(collectionName) );
 			}
 			catch ( MappingException me ) {
 				throw new QueryException( me );
 			}
 		}
 		join.addCondition( collectionName, keyColumnNames, " = ?" );
 		//if ( persister.hasWhere() ) join.addCondition( persister.getSQLWhereString(collectionName) );
 		EntityType elemType = ( EntityType ) collectionElementType;
 		addFrom( elementName, elemType.getAssociatedEntityName(), join );
 
 	}
 
 	String getPathAlias(String path) {
 		return ( String ) pathAliases.get( path );
 	}
 
 	JoinSequence getPathJoin(String path) {
 		return ( JoinSequence ) pathJoins.get( path );
 	}
 
 	void addPathAliasAndJoin(String path, String alias, JoinSequence joinSequence) {
 		pathAliases.put( path, alias );
 		pathJoins.put( path, joinSequence );
 	}
 
 	@Override
 	public List list(SessionImplementor session, QueryParameters queryParameters)
 			throws HibernateException {
 		return list( session, queryParameters, getQuerySpaces(), actualReturnTypes );
 	}
 
 	/**
 	 * Return the query results as an iterator
 	 */
 	@Override
 	public Iterator iterate(QueryParameters queryParameters, EventSource session)
 			throws HibernateException {
 
 		boolean stats = session.getFactory().getStatistics().isStatisticsEnabled();
 		long startTime = 0;
 		if ( stats ) startTime = System.currentTimeMillis();
 
 		try {
 			final List<AfterLoadAction> afterLoadActions = new ArrayList<AfterLoadAction>();
 			final SqlStatementWrapper wrapper = executeQueryStatement( queryParameters, false, afterLoadActions, session );
 			final ResultSet rs = wrapper.getResultSet();
 			final PreparedStatement st = (PreparedStatement) wrapper.getStatement();
 			HolderInstantiator hi = HolderInstantiator.createClassicHolderInstantiator(holderConstructor, queryParameters.getResultTransformer());
 			Iterator result = new IteratorImpl( rs, st, session, queryParameters.isReadOnly( session ), returnTypes, getColumnNames(), hi );
 
 			if ( stats ) {
 				session.getFactory().getStatisticsImplementor().queryExecuted(
 						"HQL: " + queryString,
 						0,
 						System.currentTimeMillis() - startTime
 					);
 			}
 
 			return result;
 
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not execute query using iterate",
 					getSQLString()
 				);
 		}
 
 	}
 
 	public int executeUpdate(QueryParameters queryParameters, SessionImplementor session) throws HibernateException {
 		throw new UnsupportedOperationException( "Not supported!  Use the AST translator...");
 	}
 
 	@Override
     protected boolean[] includeInResultRow() {
 		boolean[] isResultReturned = includeInSelect;
 		if ( hasScalars ) {
 			isResultReturned = new boolean[ returnedTypes.size() ];
 			Arrays.fill( isResultReturned, true );
 		}
 		return isResultReturned;
 	}
 
 
 	@Override
     protected ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer) {
 		return HolderInstantiator.resolveClassicResultTransformer(
 				holderConstructor,
 				resultTransformer
 		);
 	}
 
 	@Override
     protected Object getResultColumnOrRow(Object[] row, ResultTransformer transformer, ResultSet rs, SessionImplementor session)
 			throws SQLException, HibernateException {
 		Object[] resultRow = getResultRow( row, rs, session );
 		return ( holderClass == null && resultRow.length == 1 ?
 				resultRow[ 0 ] :
 				resultRow
 		);
 	}
 
 	@Override
     protected Object[] getResultRow(Object[] row, ResultSet rs, SessionImplementor session)
 			throws SQLException, HibernateException {
 		Object[] resultRow;
 		if ( hasScalars ) {
 			String[][] scalarColumns = getColumnNames();
 			int queryCols = returnTypes.length;
 			resultRow = new Object[queryCols];
 			for ( int i = 0; i < queryCols; i++ ) {
 				resultRow[i] = returnTypes[i].nullSafeGet( rs, scalarColumns[i], session, null );
 			}
 		}
 		else {
 			resultRow = toResultRow( row );
 		}
 		return resultRow;
 	}
 
 	@Override
     protected List getResultList(List results, ResultTransformer resultTransformer) throws QueryException {
 		if ( holderClass != null ) {
 			for ( int i = 0; i < results.size(); i++ ) {
 				Object[] row = ( Object[] ) results.get( i );
 				try {
 					results.set( i, holderConstructor.newInstance( row ) );
 				}
 				catch ( Exception e ) {
 					throw new QueryException( "could not instantiate: " + holderClass, e );
 				}
 			}
 		}
 		return results;
 	}
 
 	private Object[] toResultRow(Object[] row) {
 		if ( selectLength == row.length ) {
 			return row;
 		}
 		else {
 			Object[] result = new Object[selectLength];
 			int j = 0;
 			for ( int i = 0; i < row.length; i++ ) {
 				if ( includeInSelect[i] ) result[j++] = row[i];
 			}
 			return result;
 		}
 	}
 
 	void setHolderClass(Class clazz) {
 		holderClass = clazz;
 	}
 
 	@Override
     protected LockMode[] getLockModes(LockOptions lockOptions) {
 
 		// unfortunately this stuff can't be cached because
 		// it is per-invocation, not constant for the
 		// QueryTranslator instance
 		HashMap nameLockOptions = new HashMap();
 		if ( lockOptions == null) {
 			lockOptions = LockOptions.NONE;
 		}
 
 		if ( lockOptions.getAliasLockCount() > 0 ) {
 			Iterator iter = lockOptions.getAliasLockIterator();
 			while ( iter.hasNext() ) {
 				Map.Entry me = ( Map.Entry ) iter.next();
 				nameLockOptions.put( getAliasName( ( String ) me.getKey() ),
 						me.getValue() );
 			}
 		}
 		LockMode[] lockModesArray = new LockMode[names.length];
 		for ( int i = 0; i < names.length; i++ ) {
 			LockMode lm = ( LockMode ) nameLockOptions.get( names[i] );
 			//if ( lm == null ) lm = LockOptions.NONE;
 			if ( lm == null ) lm = lockOptions.getLockMode();
 			lockModesArray[i] = lm;
 		}
 		return lockModesArray;
 	}
 
 	@Override
     protected String applyLocks(
 			String sql,
 			QueryParameters parameters,
 			Dialect dialect,
 			List<AfterLoadAction> afterLoadActions) throws QueryException {
 		// can't cache this stuff either (per-invocation)
 		final LockOptions lockOptions = parameters.getLockOptions();
 		final String result;
 		if ( lockOptions == null ||
 			( lockOptions.getLockMode() == LockMode.NONE && lockOptions.getAliasLockCount() == 0 ) ) {
 			return sql;
 		}
 		else {
 			LockOptions locks = new LockOptions();
 			locks.setLockMode(lockOptions.getLockMode());
 			locks.setTimeOut(lockOptions.getTimeOut());
 			locks.setScope(lockOptions.getScope());
 			Iterator iter = lockOptions.getAliasLockIterator();
 			while ( iter.hasNext() ) {
 				Map.Entry me = ( Map.Entry ) iter.next();
 				locks.setAliasSpecificLockMode( getAliasName( ( String ) me.getKey() ), (LockMode) me.getValue() );
 			}
 			Map keyColumnNames = null;
 			if ( dialect.forUpdateOfColumns() ) {
 				keyColumnNames = new HashMap();
 				for ( int i = 0; i < names.length; i++ ) {
 					keyColumnNames.put( names[i], persisters[i].getIdentifierColumnNames() );
 				}
 			}
 			result = dialect.applyLocksToSql( sql, locks, keyColumnNames );
 		}
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/WhereParser.java b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/WhereParser.java
index 1aae46493c..6f557529d6 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/WhereParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/internal/classic/WhereParser.java
@@ -1,515 +1,515 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.hql.internal.classic;
 
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.LinkedList;
 import java.util.Map;
 import java.util.Set;
 import java.util.StringTokenizer;
 
 import org.hibernate.MappingException;
 import org.hibernate.QueryException;
 import org.hibernate.engine.internal.JoinSequence;
 import org.hibernate.hql.spi.QueryTranslator;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.persister.collection.CollectionPropertyNames;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.InFragment;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.LiteralType;
 import org.hibernate.type.Type;
 
 /**
  * Parses the where clause of a hibernate query and translates it to an
  * SQL where clause.
  */
 
 // We should reengineer this class so that, rather than the current ad -
 // hoc linear approach to processing a stream of tokens, we instead
 // build up a tree of expressions.
 
 // We would probably refactor to have LogicParser (builds a tree of simple
 // expressions connected by and, or, not), ExpressionParser (translates
 // from OO terms like foo, foo.Bar, foo.Bar.Baz to SQL terms like
 // FOOS.ID, FOOS.BAR_ID, etc) and PathExpressionParser (which does much
 // the same thing it does now)
 
 public class WhereParser implements Parser {
 
 	private final PathExpressionParser pathExpressionParser;
 
 	{
 		pathExpressionParser = new PathExpressionParser();
 		pathExpressionParser.setUseThetaStyleJoin( true ); //Need this, since join condition can appear inside parens!
 	}
 
 	private static final Set EXPRESSION_TERMINATORS = new HashSet();   //tokens that close a sub expression
 	private static final Set EXPRESSION_OPENERS = new HashSet();       //tokens that open a sub expression
 	private static final Set BOOLEAN_OPERATORS = new HashSet();        //tokens that would indicate a sub expression is a boolean expression
 	private static final Map NEGATIONS = new HashMap();
 
 	static {
 		EXPRESSION_TERMINATORS.add( "and" );
 		EXPRESSION_TERMINATORS.add( "or" );
 		EXPRESSION_TERMINATORS.add( ")" );
 		//expressionTerminators.add(","); // deliberately excluded
 
 		EXPRESSION_OPENERS.add( "and" );
 		EXPRESSION_OPENERS.add( "or" );
 		EXPRESSION_OPENERS.add( "(" );
 		//expressionOpeners.add(","); // deliberately excluded
 
 		BOOLEAN_OPERATORS.add( "<" );
 		BOOLEAN_OPERATORS.add( "=" );
 		BOOLEAN_OPERATORS.add( ">" );
 		BOOLEAN_OPERATORS.add( "#" );
 		BOOLEAN_OPERATORS.add( "~" );
 		BOOLEAN_OPERATORS.add( "like" );
 		BOOLEAN_OPERATORS.add( "ilike" );
 		BOOLEAN_OPERATORS.add( "regexp" );
 		BOOLEAN_OPERATORS.add( "rlike" );
 		BOOLEAN_OPERATORS.add( "is" );
 		BOOLEAN_OPERATORS.add( "in" );
 		BOOLEAN_OPERATORS.add( "any" );
 		BOOLEAN_OPERATORS.add( "some" );
 		BOOLEAN_OPERATORS.add( "all" );
 		BOOLEAN_OPERATORS.add( "exists" );
 		BOOLEAN_OPERATORS.add( "between" );
 		BOOLEAN_OPERATORS.add( "<=" );
 		BOOLEAN_OPERATORS.add( ">=" );
 		BOOLEAN_OPERATORS.add( "=>" );
 		BOOLEAN_OPERATORS.add( "=<" );
 		BOOLEAN_OPERATORS.add( "!=" );
 		BOOLEAN_OPERATORS.add( "<>" );
 		BOOLEAN_OPERATORS.add( "!#" );
 		BOOLEAN_OPERATORS.add( "!~" );
 		BOOLEAN_OPERATORS.add( "!<" );
 		BOOLEAN_OPERATORS.add( "!>" );
 		BOOLEAN_OPERATORS.add( "is not" );
 		BOOLEAN_OPERATORS.add( "not like" );
 		BOOLEAN_OPERATORS.add( "not ilike" );
 		BOOLEAN_OPERATORS.add( "not regexp" );
 		BOOLEAN_OPERATORS.add( "not rlike" );
 		BOOLEAN_OPERATORS.add( "not in" );
 		BOOLEAN_OPERATORS.add( "not between" );
 		BOOLEAN_OPERATORS.add( "not exists" );
 
 		NEGATIONS.put( "and", "or" );
 		NEGATIONS.put( "or", "and" );
 		NEGATIONS.put( "<", ">=" );
 		NEGATIONS.put( "=", "<>" );
 		NEGATIONS.put( ">", "<=" );
 		NEGATIONS.put( "#", "!#" );
 		NEGATIONS.put( "~", "!~" );
 		NEGATIONS.put( "like", "not like" );
 		NEGATIONS.put( "ilike", "not ilike" );
 		NEGATIONS.put( "regexp", "not regexp" );
 		NEGATIONS.put( "rlike", "not rlike" );
 		NEGATIONS.put( "is", "is not" );
 		NEGATIONS.put( "in", "not in" );
 		NEGATIONS.put( "exists", "not exists" );
 		NEGATIONS.put( "between", "not between" );
 		NEGATIONS.put( "<=", ">" );
 		NEGATIONS.put( ">=", "<" );
 		NEGATIONS.put( "=>", "<" );
 		NEGATIONS.put( "=<", ">" );
 		NEGATIONS.put( "!=", "=" );
 		NEGATIONS.put( "<>", "=" );
 		NEGATIONS.put( "!#", "#" );
 		NEGATIONS.put( "!~", "~" );
 		NEGATIONS.put( "!<", "<" );
 		NEGATIONS.put( "!>", ">" );
 		NEGATIONS.put( "is not", "is" );
 		NEGATIONS.put( "not like", "like" );
 		NEGATIONS.put( "not ilike", "ilike" );
 		NEGATIONS.put( "not regexp", "regexp" );
 		NEGATIONS.put( "not rlike", "rlike" );
 		NEGATIONS.put( "not in", "in" );
 		NEGATIONS.put( "not between", "between" );
 		NEGATIONS.put( "not exists", "exists" );
 
 	}
 	// Handles things like:
 	// a and b or c
 	// a and ( b or c )
 	// not a and not b
 	// not ( a and b )
 	// x between y and z            (overloaded "and")
 	// x in ( a, b, c )             (overloaded brackets)
 	// not not a
 	// a is not null                (overloaded "not")
 	// etc......
 	// and expressions like
 	// foo = bar                    (maps to: foo.id = bar.id)
 	// foo.Bar = 'foo'              (maps to: foo.bar = 'foo')
 	// foo.Bar.Baz = 1.0            (maps to: foo.bar = bar.id and bar.baz = 1.0)
 	// 1.0 = foo.Bar.Baz            (maps to: bar.baz = 1.0 and foo.Bar = bar.id)
 	// foo.Bar.Baz = a.B.C          (maps to: bar.Baz = b.C and foo.Bar = bar.id and a.B = b.id)
 	// foo.Bar.Baz + a.B.C          (maps to: bar.Baz + b.C and foo.Bar = bar.id and a.B = b.id)
 	// ( foo.Bar.Baz + 1.0 ) < 2.0  (maps to: ( bar.Baz + 1.0 ) < 2.0 and foo.Bar = bar.id)
 
-	private boolean betweenSpecialCase = false;       //Inside a BETWEEN ... AND ... expression
-	private boolean negated = false;
+	private boolean betweenSpecialCase;       //Inside a BETWEEN ... AND ... expression
+	private boolean negated;
 
-	private boolean inSubselect = false;
-	private int bracketsSinceSelect = 0;
+	private boolean inSubselect;
+	private int bracketsSinceSelect;
 	private StringBuilder subselect;
 
-	private boolean expectingPathContinuation = false;
-	private int expectingIndex = 0;
+	private boolean expectingPathContinuation;
+	private int expectingIndex;
 
 	// The following variables are stacks that keep information about each subexpression
 	// in the list of nested subexpressions we are currently processing.
 
 	private LinkedList<Boolean> nots = new LinkedList<Boolean>();           //were an odd or even number of NOTs encountered
 	private LinkedList joins = new LinkedList();          //the join string built up by compound paths inside this expression
 	private LinkedList<Boolean> booleanTests = new LinkedList<Boolean>();   //a flag indicating if the subexpression is known to be boolean
 
 	private String getElementName(PathExpressionParser.CollectionElement element, QueryTranslatorImpl q) throws QueryException {
 		String name;
 		if ( element.isOneToMany ) {
 			name = element.alias;
 		}
 		else {
 			Type type = element.elementType;
 			if ( type.isEntityType() ) { //ie. a many-to-many
 				String entityName = ( ( EntityType ) type ).getAssociatedEntityName();
 				name = pathExpressionParser.continueFromManyToMany( entityName, element.elementColumns, q );
 			}
 			else {
 				throw new QueryException( "illegally dereferenced collection element" );
 			}
 		}
 		return name;
 	}
 
 	public void token(String token, QueryTranslatorImpl q) throws QueryException {
 
 		String lcToken = token.toLowerCase();
 
 		//Cope with [,]
 		if ( token.equals( "[" ) && !expectingPathContinuation ) {
 			expectingPathContinuation = false;
 			if ( expectingIndex == 0 ) throw new QueryException( "unexpected [" );
 			return;
 		}
 		else if ( token.equals( "]" ) ) {
 			expectingIndex--;
 			expectingPathContinuation = true;
 			return;
 		}
 
 		//Cope with a continued path expression (ie. ].baz)
 		if ( expectingPathContinuation ) {
 			boolean pathExpressionContinuesFurther = continuePathExpression( token, q );
 			if ( pathExpressionContinuesFurther ) return; //NOTE: early return
 		}
 
 		//Cope with a subselect
 		if ( !inSubselect && ( lcToken.equals( "select" ) || lcToken.equals( "from" ) ) ) {
 			inSubselect = true;
 			subselect = new StringBuilder( 20 );
 		}
 		if ( inSubselect && token.equals( ")" ) ) {
 			bracketsSinceSelect--;
 
 			if ( bracketsSinceSelect == -1 ) {
 				QueryTranslatorImpl subq = new QueryTranslatorImpl(
 				        subselect.toString(),
 						q.getEnabledFilters(),
 						q.getFactory()
 				);
 				try {
 					subq.compile( q );
 				}
 				catch ( MappingException me ) {
 					throw new QueryException( "MappingException occurred compiling subquery", me );
 				}
 				appendToken( q, subq.getSQLString() );
 				inSubselect = false;
 				bracketsSinceSelect = 0;
 			}
 		}
 		if ( inSubselect ) {
 			if ( token.equals( "(" ) ) bracketsSinceSelect++;
 			subselect.append( token ).append( ' ' );
 			return;
 		}
 
 		//Cope with special cases of AND, NOT, ()
 		specialCasesBefore( lcToken );
 
 		//Close extra brackets we opened
 		if ( !betweenSpecialCase && EXPRESSION_TERMINATORS.contains( lcToken ) ) {
 			closeExpression( q, lcToken );
 		}
 
 		//take note when this is a boolean expression
 		if ( BOOLEAN_OPERATORS.contains( lcToken ) ) {
 			booleanTests.removeLast();
 			booleanTests.addLast( Boolean.TRUE );
 		}
 
 		if ( lcToken.equals( "not" ) ) {
 			nots.addLast(  !(  nots.removeLast() ) );
 			negated = !negated;
 			return; //NOTE: early return
 		}
 
 		//process a token, mapping OO path expressions to SQL expressions
 		doToken( token, q );
 
 		//Open any extra brackets we might need.
 		if ( !betweenSpecialCase && EXPRESSION_OPENERS.contains( lcToken ) ) {
 			openExpression( q, lcToken );
 		}
 
 		//Cope with special cases of AND, NOT, )
 		specialCasesAfter( lcToken );
 
 	}
 
 	public void start(QueryTranslatorImpl q) throws QueryException {
 		token( "(", q );
 	}
 
 	public void end(QueryTranslatorImpl q) throws QueryException {
 		if ( expectingPathContinuation ) {
 			expectingPathContinuation = false;
 			PathExpressionParser.CollectionElement element = pathExpressionParser.lastCollectionElement();
 			if ( element.elementColumns.length != 1 ) throw new QueryException( "path expression ended in composite collection element" );
 			appendToken( q, element.elementColumns[0] );
 			addToCurrentJoin( element );
 		}
 		token( ")", q );
 	}
 
 	private void closeExpression(QueryTranslatorImpl q, String lcToken) {
 		if ( booleanTests.removeLast() ) { //it was a boolean expression
 
 			if ( booleanTests.size() > 0 ) {
 				// the next one up must also be
 				booleanTests.removeLast();
 				booleanTests.addLast( Boolean.TRUE );
 			}
 
 			// Add any joins
 			appendToken( q, ( joins.removeLast() ).toString() );
 
 		}
 		else {
 			StringBuilder join = ( StringBuilder ) joins.removeLast();
 			( ( StringBuilder ) joins.getLast() ).append( join.toString() );
 		}
 
 		if ( nots.removeLast() ) negated = !negated;
 
 		if ( !")".equals( lcToken ) ) appendToken( q, ")" );
 	}
 
 	private void openExpression(QueryTranslatorImpl q, String lcToken) {
 		nots.addLast( Boolean.FALSE );
 		booleanTests.addLast( Boolean.FALSE );
 		joins.addLast( new StringBuilder() );
 		if ( !"(".equals( lcToken ) ) appendToken( q, "(" );
 	}
 
 	private void preprocess(String token, QueryTranslatorImpl q) throws QueryException {
 		// ugly hack for cases like "elements(foo.bar.collection)"
 		// (multi-part path expression ending in elements or indices)
 		String[] tokens = StringHelper.split( ".", token, true );
 		if (
 				tokens.length > 5 &&
 				( CollectionPropertyNames.COLLECTION_ELEMENTS.equals( tokens[tokens.length - 1] )
 				|| CollectionPropertyNames.COLLECTION_INDICES.equals( tokens[tokens.length - 1] ) )
 		) {
 			pathExpressionParser.start( q );
 			for ( int i = 0; i < tokens.length - 3; i++ ) {
 				pathExpressionParser.token( tokens[i], q );
 			}
 			pathExpressionParser.token( null, q );
 			pathExpressionParser.end( q );
 			addJoin( pathExpressionParser.getWhereJoin(), q );
 			pathExpressionParser.ignoreInitialJoin();
 		}
 	}
 
 	private void doPathExpression(String token, QueryTranslatorImpl q) throws QueryException {
 
 		preprocess( token, q );
 
 		StringTokenizer tokens = new StringTokenizer( token, ".", true );
 		pathExpressionParser.start( q );
 		while ( tokens.hasMoreTokens() ) {
 			pathExpressionParser.token( tokens.nextToken(), q );
 		}
 		pathExpressionParser.end( q );
 		if ( pathExpressionParser.isCollectionValued() ) {
 			openExpression( q, "" );
 			appendToken( q, pathExpressionParser.getCollectionSubquery( q.getEnabledFilters() ) );
 			closeExpression( q, "" );
 			// this is ugly here, but needed because its a subquery
 			q.addQuerySpaces( q.getCollectionPersister( pathExpressionParser.getCollectionRole() ).getCollectionSpaces() );
 		}
 		else {
 			if ( pathExpressionParser.isExpectingCollectionIndex() ) {
 				expectingIndex++;
 			}
 			else {
 				addJoin( pathExpressionParser.getWhereJoin(), q );
 				appendToken( q, pathExpressionParser.getWhereColumn() );
 			}
 		}
 	}
 
 	private void addJoin(JoinSequence joinSequence, QueryTranslatorImpl q) throws QueryException {
 		//JoinFragment fromClause = q.createJoinFragment(true);
 		//fromClause.addJoins( join.toJoinFragment().toFromFragmentString(), StringHelper.EMPTY_STRING );
 		q.addFromJoinOnly( pathExpressionParser.getName(), joinSequence );
 		try {
 			addToCurrentJoin( joinSequence.toJoinFragment( q.getEnabledFilters(), true ).toWhereFragmentString() );
 		}
 		catch ( MappingException me ) {
 			throw new QueryException( me );
 		}
 	}
 
 	private void doToken(String token, QueryTranslatorImpl q) throws QueryException {
 		if ( q.isName( StringHelper.root( token ) ) ) { //path expression
 			doPathExpression( q.unalias( token ), q );
 		}
 		else if ( token.startsWith( ParserHelper.HQL_VARIABLE_PREFIX ) ) { //named query parameter
 			q.addNamedParameter( token.substring( 1 ) );
 			appendToken( q, "?" );
 		}
 		else {
 			Queryable persister = q.getEntityPersisterUsingImports( token );
 			if ( persister != null ) { // the name of a class
 				final String discrim = persister.getDiscriminatorSQLValue();
 				if ( InFragment.NULL.equals(discrim) || InFragment.NOT_NULL.equals(discrim) ) {
 					throw new QueryException( "subclass test not allowed for null or not null discriminator" );
 				}
 				else {
 					appendToken( q, discrim );
 				}
 			}
 			else {
 				Object constant;
 				if (
 						token.indexOf( '.' ) > -1 &&
 						( constant = ReflectHelper.getConstantValue( token ) ) != null
 				) {
 					Type type;
 					try {
 						type = q.getFactory().getTypeResolver().heuristicType( constant.getClass().getName() );
 					}
 					catch ( MappingException me ) {
 						throw new QueryException( me );
 					}
 					if ( type == null ) throw new QueryException( QueryTranslator.ERROR_CANNOT_DETERMINE_TYPE + token );
 					try {
 						appendToken( q, ( ( LiteralType ) type ).objectToSQLString( constant, q.getFactory().getDialect() ) );
 					}
 					catch ( Exception e ) {
 						throw new QueryException( QueryTranslator.ERROR_CANNOT_FORMAT_LITERAL + token, e );
 					}
 				}
 				else { //anything else
 
 					String negatedToken = negated ? ( String ) NEGATIONS.get( token.toLowerCase() ) : null;
 					if ( negatedToken != null && ( !betweenSpecialCase || !"or".equals( negatedToken ) ) ) {
 						appendToken( q, negatedToken );
 					}
 					else {
 						appendToken( q, token );
 					}
 				}
 			}
 		}
 	}
 
 	private void addToCurrentJoin(String sql) {
 		( ( StringBuilder ) joins.getLast() ).append( sql );
 	}
 
 	private void addToCurrentJoin(PathExpressionParser.CollectionElement ce)
 			throws QueryException {
 		try {
 			addToCurrentJoin( ce.joinSequence.toJoinFragment().toWhereFragmentString() + ce.indexValue.toString() );
 		}
 		catch ( MappingException me ) {
 			throw new QueryException( me );
 		}
 	}
 
 	private void specialCasesBefore(String lcToken) {
 		if ( lcToken.equals( "between" ) || lcToken.equals( "not between" ) ) {
 			betweenSpecialCase = true;
 		}
 	}
 
 	private void specialCasesAfter(String lcToken) {
 		if ( betweenSpecialCase && lcToken.equals( "and" ) ) {
 			betweenSpecialCase = false;
 		}
 	}
 
 	void appendToken(QueryTranslatorImpl q, String token) {
 		if ( expectingIndex > 0 ) {
 			pathExpressionParser.setLastCollectionElementIndexValue( token );
 		}
 		else {
 			q.appendWhereToken( token );
 		}
 	}
 
 	private boolean continuePathExpression(String token, QueryTranslatorImpl q) throws QueryException {
 
 		expectingPathContinuation = false;
 
 		PathExpressionParser.CollectionElement element = pathExpressionParser.lastCollectionElement();
 
 		if ( token.startsWith( "." ) ) { // the path expression continues after a ]
 
 			doPathExpression( getElementName( element, q ) + token, q ); // careful with this!
 
 			addToCurrentJoin( element );
 			return true; //NOTE: EARLY EXIT!
 
 		}
 
 		else { // the path expression ends at the ]
 			if ( element.elementColumns.length != 1 ) {
 				throw new QueryException( "path expression ended in composite collection element" );
 			}
 			appendToken( q, element.elementColumns[0] );
 			addToCurrentJoin( element );
 			return false;
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/hql/spi/AbstractTableBasedBulkIdHandler.java b/hibernate-core/src/main/java/org/hibernate/hql/spi/AbstractTableBasedBulkIdHandler.java
index 11d2793306..eb6e7f296e 100644
--- a/hibernate-core/src/main/java/org/hibernate/hql/spi/AbstractTableBasedBulkIdHandler.java
+++ b/hibernate-core/src/main/java/org/hibernate/hql/spi/AbstractTableBasedBulkIdHandler.java
@@ -1,184 +1,184 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.hql.spi;
 
 import java.sql.SQLException;
 import java.util.Collections;
 import java.util.List;
 
 import antlr.RecognitionException;
 import antlr.collections.AST;
 
 import org.hibernate.HibernateException;
 import org.hibernate.JDBCException;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.hql.internal.ast.HqlSqlWalker;
 import org.hibernate.hql.internal.ast.SqlGenerator;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.mapping.Table;
 import org.hibernate.param.ParameterSpecification;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.sql.InsertSelect;
 import org.hibernate.sql.Select;
 import org.hibernate.sql.SelectValues;
 
 /**
  * @author Steve Ebersole
  */
-public class AbstractTableBasedBulkIdHandler {
+public abstract class AbstractTableBasedBulkIdHandler {
 	private final SessionFactoryImplementor sessionFactory;
 	private final HqlSqlWalker walker;
 
 	private final String catalog;
 	private final String schema;
 
 	public AbstractTableBasedBulkIdHandler(
 			SessionFactoryImplementor sessionFactory,
 			HqlSqlWalker walker,
 			String catalog,
 			String schema) {
 		this.sessionFactory = sessionFactory;
 		this.walker = walker;
 		this.catalog = catalog;
 		this.schema = schema;
 	}
 
 	protected SessionFactoryImplementor factory() {
 		return sessionFactory;
 	}
 
 	protected HqlSqlWalker walker() {
 		return walker;
 	}
 
 	protected JDBCException convert(SQLException e, String message, String sql) {
 		throw factory().getSQLExceptionHelper().convert( e, message, sql );
 	}
 
 	protected static class ProcessedWhereClause {
 		public static final ProcessedWhereClause NO_WHERE_CLAUSE = new ProcessedWhereClause();
 
 		private final String userWhereClauseFragment;
 		private final List<ParameterSpecification> idSelectParameterSpecifications;
 
 		private ProcessedWhereClause() {
 			this( "", Collections.<ParameterSpecification>emptyList() );
 		}
 
 		public ProcessedWhereClause(String userWhereClauseFragment, List<ParameterSpecification> idSelectParameterSpecifications) {
 			this.userWhereClauseFragment = userWhereClauseFragment;
 			this.idSelectParameterSpecifications = idSelectParameterSpecifications;
 		}
 
 		public String getUserWhereClauseFragment() {
 			return userWhereClauseFragment;
 		}
 
 		public List<ParameterSpecification> getIdSelectParameterSpecifications() {
 			return idSelectParameterSpecifications;
 		}
 	}
 
 	@SuppressWarnings("unchecked")
 	protected ProcessedWhereClause processWhereClause(AST whereClause) {
 		if ( whereClause.getNumberOfChildren() != 0 ) {
 			// If a where clause was specified in the update/delete query, use it to limit the
 			// returned ids here...
 			try {
 				SqlGenerator sqlGenerator = new SqlGenerator( sessionFactory );
 				sqlGenerator.whereClause( whereClause );
 				String userWhereClause = sqlGenerator.getSQL().substring( 7 );  // strip the " where "
 				List<ParameterSpecification> idSelectParameterSpecifications = sqlGenerator.getCollectedParameters();
 
 				return new ProcessedWhereClause( userWhereClause, idSelectParameterSpecifications );
 			}
 			catch ( RecognitionException e ) {
 				throw new HibernateException( "Unable to generate id select for DML operation", e );
 			}
 		}
 		else {
 			return ProcessedWhereClause.NO_WHERE_CLAUSE;
 		}
 	}
 
 	protected String generateIdInsertSelect(Queryable persister, String tableAlias, ProcessedWhereClause whereClause) {
 		Select select = new Select( sessionFactory.getDialect() );
 		SelectValues selectClause = new SelectValues( sessionFactory.getDialect() )
 				.addColumns( tableAlias, persister.getIdentifierColumnNames(), persister.getIdentifierColumnNames() );
 		addAnyExtraIdSelectValues( selectClause );
 		select.setSelectClause( selectClause.render() );
 
 		String rootTableName = persister.getTableName();
 		String fromJoinFragment = persister.fromJoinFragment( tableAlias, true, false );
 		String whereJoinFragment = persister.whereJoinFragment( tableAlias, true, false );
 
 		select.setFromClause( rootTableName + ' ' + tableAlias + fromJoinFragment );
 
 		if ( whereJoinFragment == null ) {
 			whereJoinFragment = "";
 		}
 		else {
 			whereJoinFragment = whereJoinFragment.trim();
 			if ( whereJoinFragment.startsWith( "and" ) ) {
 				whereJoinFragment = whereJoinFragment.substring( 4 );
 			}
 		}
 
 		if ( whereClause.getUserWhereClauseFragment().length() > 0 ) {
 			if ( whereJoinFragment.length() > 0 ) {
 				whereJoinFragment += " and ";
 			}
 		}
 		select.setWhereClause( whereJoinFragment + whereClause.getUserWhereClauseFragment() );
 
 		InsertSelect insert = new InsertSelect( sessionFactory.getDialect() );
 		if ( sessionFactory.getSettings().isCommentsEnabled() ) {
 			insert.setComment( "insert-select for " + persister.getEntityName() + " ids" );
 		}
 		insert.setTableName( determineIdTableName( persister ) );
 		insert.setSelect( select );
 		return insert.toStatementString();
 	}
 
 	protected void addAnyExtraIdSelectValues(SelectValues selectClause) {
 	}
 
 	protected String determineIdTableName(Queryable persister) {
 		// todo : use the identifier/name qualifier service once we pull that over to master
 		return Table.qualify( catalog, schema, persister.getTemporaryIdTableName() );
 	}
 
 	protected String generateIdSubselect(Queryable persister) {
 		return "select " + StringHelper.join( ", ", persister.getIdentifierColumnNames() ) +
 				" from " + determineIdTableName( persister );
 	}
 
 	protected void prepareForUse(Queryable persister, SessionImplementor session) {
 	}
 
 	protected void releaseFromUse(Queryable persister, SessionImplementor session) {
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/GUIDGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/GUIDGenerator.java
index 2c0d52737e..6c1646d613 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/GUIDGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/GUIDGenerator.java
@@ -1,86 +1,84 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
+
 import java.io.Serializable;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 
-import org.jboss.logging.Logger;
-
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.SessionImplementor;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 
 /**
  * Generates <tt>string</tt> values using the SQL Server NEWID() function.
  *
  * @author Joseph Fifield
  */
 public class GUIDGenerator implements IdentifierGenerator {
+    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( GUIDGenerator.class );
 
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, GUIDGenerator.class.getName());
-	private static boolean warned = false;
+	private static boolean WARNED;
 
 	public GUIDGenerator() {
-		if ( ! warned ) {
-			warned = true;
-            LOG.deprecatedUuidGenerator(UUIDGenerator.class.getName(), UUIDGenerationStrategy.class.getName());
+		if ( !WARNED ) {
+			WARNED = true;
+            LOG.deprecatedUuidGenerator( UUIDGenerator.class.getName(), UUIDGenerationStrategy.class.getName() );
 		}
 	}
 
-	public Serializable generate(SessionImplementor session, Object obj)
-	throws HibernateException {
-
+	public Serializable generate(SessionImplementor session, Object obj) throws HibernateException {
 		final String sql = session.getFactory().getDialect().getSelectGUIDString();
 		try {
 			PreparedStatement st = session.getTransactionCoordinator().getJdbcCoordinator().getStatementPreparer().prepareStatement( sql );
 			try {
 				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
 				final String result;
 				try {
 					if ( !rs.next() ) {
 						throw new HibernateException( "The database returned no GUID identity value" );
 					}
 					result = rs.getString(1);
 				}
 				finally {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
 				}
                 LOG.guidGenerated(result);
 				return result;
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 			}
 		}
 		catch (SQLException sqle) {
 			throw session.getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not retrieve GUID",
 					sql
 				);
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/UUIDHexGenerator.java b/hibernate-core/src/main/java/org/hibernate/id/UUIDHexGenerator.java
index b4b12bb4a7..0fd709ebbc 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/UUIDHexGenerator.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/UUIDHexGenerator.java
@@ -1,96 +1,89 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id;
 import java.io.Serializable;
 import java.util.Properties;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.type.Type;
 
 /**
  * <b>uuid</b><br>
  * <br>
  * A <tt>UUIDGenerator</tt> that returns a string of length 32,
  * This string will consist of only hex digits. Optionally,
  * the string may be generated with separators between each
  * component of the UUID.
  *
  * Mapping parameters supported: separator.
  *
  * @author Gavin King
  */
 public class UUIDHexGenerator extends AbstractUUIDGenerator implements Configurable {
-
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, UUIDHexGenerator.class.getName());
 
-	private static boolean warned = false;
+	private static boolean WARNED;
 
 	private String sep = "";
 
 	public UUIDHexGenerator() {
-		if ( ! warned ) {
-			warned = true;
-            LOG.usingUuidHexGenerator(this.getClass().getName(), UUIDGenerator.class.getName());
+		if ( !WARNED ) {
+			WARNED = true;
+            LOG.usingUuidHexGenerator( this.getClass().getName(), UUIDGenerator.class.getName() );
 		}
 	}
 
-	/**
-	 * {@inheritDoc}
-	 */
+	@Override
 	public void configure(Type type, Properties params, Dialect d) {
 		sep = ConfigurationHelper.getString( "separator", params, "" );
 	}
 
-	/**
-	 * {@inheritDoc}
-	 */
+	@Override
 	public Serializable generate(SessionImplementor session, Object obj) {
-		return new StringBuilder( 36 )
-				.append( format( getIP() ) ).append( sep )
-				.append( format( getJVM() ) ).append( sep )
-				.append( format( getHiTime() ) ).append( sep )
-				.append( format( getLoTime() ) ).append( sep )
-				.append( format( getCount() ) )
-				.toString();
+		return format( getIP() ) + sep
+				+ format( getJVM() ) + sep
+				+ format( getHiTime() ) + sep
+				+ format( getLoTime() ) + sep
+				+ format( getCount() );
 	}
 
 	protected String format(int intValue) {
 		String formatted = Integer.toHexString( intValue );
 		StringBuilder buf = new StringBuilder( "00000000" );
 		buf.replace( 8 - formatted.length(), 8, formatted );
 		return buf.toString();
 	}
 
 	protected String format(short shortValue) {
 		String formatted = Integer.toHexString( shortValue );
 		StringBuilder buf = new StringBuilder( "0000" );
 		buf.replace( 4 - formatted.length(), 4, formatted );
 		return buf.toString();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/id/uuid/Helper.java b/hibernate-core/src/main/java/org/hibernate/id/uuid/Helper.java
index 4e6e6b2cd7..548cc9f226 100644
--- a/hibernate-core/src/main/java/org/hibernate/id/uuid/Helper.java
+++ b/hibernate-core/src/main/java/org/hibernate/id/uuid/Helper.java
@@ -1,147 +1,149 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.id.uuid;
 
 import java.net.InetAddress;
 import java.net.UnknownHostException;
 
 import org.hibernate.internal.util.BytesHelper;
 
 /**
  * TODO : javadoc
  *
  * @author Steve Ebersole
  */
-public class Helper {
+public final class Helper {
+	private Helper() {
+	}
 
 	// IP ADDRESS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private static final byte[] ADDRESS_BYTES;
 	private static final int ADDRESS_INT;
 	private static final String ADDRESS_HEX_STRING;
 
 	static {
 		byte[] address;
 		try {
 			address = InetAddress.getLocalHost().getAddress();
 		}
 		catch ( Exception e ) {
 			address = new byte[4];
 		}
 		ADDRESS_BYTES = address;
 		ADDRESS_INT = BytesHelper.toInt( ADDRESS_BYTES );
 		ADDRESS_HEX_STRING = format( ADDRESS_INT );
 	}
 
 	public static byte[] getAddressBytes() {
 		return ADDRESS_BYTES;
 	}
 
 	public static int getAddressInt() {
 		return ADDRESS_INT;
 	}
 
 	public static String getAddressHexString() {
 		return ADDRESS_HEX_STRING;
 	}
 
 
 	// JVM identifier ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private static final byte[] JVM_IDENTIFIER_BYTES;
 	private static final int JVM_IDENTIFIER_INT;
 	private static final String JVM_IDENTIFIER_HEX_STRING;
 
 	static {
 		JVM_IDENTIFIER_INT = (int) ( System.currentTimeMillis() >>> 8 );
 		JVM_IDENTIFIER_BYTES = BytesHelper.fromInt( JVM_IDENTIFIER_INT );
 		JVM_IDENTIFIER_HEX_STRING = format( JVM_IDENTIFIER_INT );
 	}
 
 	public static byte[] getJvmIdentifierBytes() {
 		return JVM_IDENTIFIER_BYTES;
 	}
 
 	public static int getJvmIdentifierInt() {
 		return JVM_IDENTIFIER_INT;
 	}
 
 	public static String getJvmIdentifierHexString() {
 		return JVM_IDENTIFIER_HEX_STRING;
 	}
 
 
 	// counter ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private static short counter = (short) 0;
 
 	/**
 	 * Unique in a millisecond for this JVM instance (unless there are > Short.MAX_VALUE instances created in a
 	 * millisecond)
 	 */
 	public static short getCountShort() {
 		synchronized ( Helper.class ) {
 			if ( counter < 0 ) {
 				counter = 0;
 			}
 			return counter++;
 		}
 	}
 
 	public static byte[] getCountBytes() {
 		return BytesHelper.fromShort( getCountShort() );
 	}
 
 
 	// Helper methods ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public static String format(int value) {
 		final String formatted = Integer.toHexString( value );
 		StringBuilder buf = new StringBuilder( "00000000" );
 		buf.replace( 8 - formatted.length(), 8, formatted );
 		return buf.toString();
 	}
 
 	public static String format(short value) {
 		String formatted = Integer.toHexString( value );
 		StringBuilder buf = new StringBuilder( "0000" );
 		buf.replace( 4 - formatted.length(), 4, formatted );
 		return buf.toString();
 	}
 
 
 	public static void main(String[] args) throws UnknownHostException {
 		byte[] addressBytes = InetAddress.getLocalHost().getAddress();
 		System.out.println( "Raw ip address bytes : " + addressBytes.toString() );
 
 		int addressInt = BytesHelper.toInt( addressBytes );
 		System.out.println( "ip address int : " + addressInt );
 
 		String formatted = Integer.toHexString( addressInt );
 		StringBuilder buf = new StringBuilder( "00000000" );
 		buf.replace( 8 - formatted.length(), 8, formatted );
 		String addressHex = buf.toString();
 		System.out.println( "ip address hex : " + addressHex );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
index 74e69b208a..c09b25b504 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/SessionFactoryImpl.java
@@ -1,1212 +1,1212 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.io.IOException;
 import java.io.InvalidObjectException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 import java.util.Set;
 import java.util.concurrent.ConcurrentHashMap;
 
 import javax.naming.Reference;
 import javax.naming.StringRefAddr;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.Cache;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.CustomEntityDirtinessStrategy;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.HibernateException;
 import org.hibernate.Interceptor;
 import org.hibernate.MappingException;
 import org.hibernate.MultiTenancyStrategy;
 import org.hibernate.ObjectNotFoundException;
 import org.hibernate.Session;
 import org.hibernate.SessionBuilder;
 import org.hibernate.SessionEventListener;
 import org.hibernate.SessionFactory;
 import org.hibernate.SessionFactoryObserver;
 import org.hibernate.StatelessSession;
 import org.hibernate.StatelessSessionBuilder;
 import org.hibernate.TypeHelper;
 import org.hibernate.boot.registry.StandardServiceRegistry;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.boot.registry.classloading.spi.ClassLoadingException;
 import org.hibernate.cache.internal.CacheDataDescriptionImpl;
 import org.hibernate.cache.spi.CollectionRegion;
 import org.hibernate.cache.spi.EntityRegion;
 import org.hibernate.cache.spi.NaturalIdRegion;
 import org.hibernate.cache.spi.QueryCache;
 import org.hibernate.cache.spi.Region;
 import org.hibernate.cache.spi.RegionFactory;
 import org.hibernate.cache.spi.UpdateTimestampsCache;
 import org.hibernate.cache.spi.access.AccessType;
 import org.hibernate.cache.spi.access.CollectionRegionAccessStrategy;
 import org.hibernate.cache.spi.access.EntityRegionAccessStrategy;
 import org.hibernate.cache.spi.access.NaturalIdRegionAccessStrategy;
 import org.hibernate.cache.spi.access.RegionAccessStrategy;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.Settings;
 import org.hibernate.cfg.SettingsFactory;
 import org.hibernate.cfg.annotations.NamedProcedureCallDefinition;
 import org.hibernate.context.internal.JTASessionContext;
 import org.hibernate.context.internal.ManagedSessionContext;
 import org.hibernate.context.internal.ThreadLocalSessionContext;
 import org.hibernate.context.spi.CurrentSessionContext;
 import org.hibernate.context.spi.CurrentTenantIdentifierResolver;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunction;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.config.spi.ConfigurationService;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
 import org.hibernate.engine.jdbc.connections.spi.MultiTenantConnectionProvider;
 import org.hibernate.engine.jdbc.spi.JdbcConnectionAccess;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jndi.spi.JndiService;
 import org.hibernate.engine.profile.Association;
 import org.hibernate.engine.profile.Fetch;
 import org.hibernate.engine.profile.FetchProfile;
 import org.hibernate.engine.query.spi.QueryPlanCache;
 import org.hibernate.engine.spi.CacheImplementor;
 import org.hibernate.engine.spi.FilterDefinition;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.engine.spi.NamedQueryDefinition;
 import org.hibernate.engine.spi.NamedSQLQueryDefinition;
 import org.hibernate.engine.spi.SessionBuilderImplementor;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionOwner;
 import org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl;
 import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
 import org.hibernate.engine.transaction.spi.TransactionEnvironment;
 import org.hibernate.engine.transaction.spi.TransactionFactory;
 import org.hibernate.exception.spi.SQLExceptionConverter;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.id.UUIDGenerator;
 import org.hibernate.id.factory.IdentifierGeneratorFactory;
 import org.hibernate.integrator.spi.Integrator;
 import org.hibernate.integrator.spi.IntegratorService;
 import org.hibernate.mapping.Collection;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.RootClass;
 import org.hibernate.metadata.ClassMetadata;
 import org.hibernate.metadata.CollectionMetadata;
 import org.hibernate.metamodel.binding.EntityBinding;
 import org.hibernate.metamodel.binding.PluralAttributeBinding;
 import org.hibernate.metamodel.source.MetadataImplementor;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Loadable;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.persister.spi.PersisterFactory;
 import org.hibernate.procedure.ProcedureCallMemento;
 import org.hibernate.proxy.EntityNotFoundDelegate;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.service.spi.ServiceRegistryImplementor;
 import org.hibernate.service.spi.SessionFactoryServiceRegistry;
 import org.hibernate.service.spi.SessionFactoryServiceRegistryFactory;
 import org.hibernate.stat.Statistics;
 import org.hibernate.stat.spi.StatisticsImplementor;
 import org.hibernate.tool.hbm2ddl.ImportSqlCommandExtractor;
 import org.hibernate.tool.hbm2ddl.SchemaExport;
 import org.hibernate.tool.hbm2ddl.SchemaUpdate;
 import org.hibernate.tool.hbm2ddl.SchemaValidator;
 import org.hibernate.tuple.entity.EntityTuplizer;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.Type;
 import org.hibernate.type.TypeResolver;
 import org.jboss.logging.Logger;
 
 
 /**
  * Concrete implementation of the <tt>SessionFactory</tt> interface. Has the following
  * responsibilities
  * <ul>
  * <li>caches configuration settings (immutably)
  * <li>caches "compiled" mappings ie. <tt>EntityPersister</tt>s and
  *     <tt>CollectionPersister</tt>s (immutable)
  * <li>caches "compiled" queries (memory sensitive cache)
  * <li>manages <tt>PreparedStatement</tt>s
  * <li> delegates JDBC <tt>Connection</tt> management to the <tt>ConnectionProvider</tt>
  * <li>factory for instances of <tt>SessionImpl</tt>
  * </ul>
  * This class must appear immutable to clients, even if it does all kinds of caching
  * and pooling under the covers. It is crucial that the class is not only thread
  * safe, but also highly concurrent. Synchronization must be used extremely sparingly.
  *
  * @see org.hibernate.engine.jdbc.connections.spi.ConnectionProvider
  * @see org.hibernate.Session
  * @see org.hibernate.hql.spi.QueryTranslator
  * @see org.hibernate.persister.entity.EntityPersister
  * @see org.hibernate.persister.collection.CollectionPersister
  * @author Gavin King
  */
 public final class SessionFactoryImpl
 		implements SessionFactoryImplementor {
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SessionFactoryImpl.class.getName());
 	private static final IdentifierGenerator UUID_GENERATOR = UUIDGenerator.buildSessionFactoryUniqueIdentifierGenerator();
 
 	private final String name;
 	private final String uuid;
 
 	private final transient Map<String,EntityPersister> entityPersisters;
 	private final transient Map<String,ClassMetadata> classMetadata;
 	private final transient Map<String,CollectionPersister> collectionPersisters;
 	private final transient Map<String,CollectionMetadata> collectionMetadata;
 	private final transient Map<String,Set<String>> collectionRolesByEntityParticipant;
 	private final transient Map<String,IdentifierGenerator> identifierGenerators;
 	private final transient NamedQueryRepository namedQueryRepository;
 	private final transient Map<String, FilterDefinition> filters;
 	private final transient Map<String, FetchProfile> fetchProfiles;
 	private final transient Map<String,String> imports;
 	private final transient SessionFactoryServiceRegistry serviceRegistry;
 	private final transient JdbcServices jdbcServices;
 	private final transient Dialect dialect;
 	private final transient Settings settings;
 	private final transient Properties properties;
 	private transient SchemaExport schemaExport;
 	private final transient CurrentSessionContext currentSessionContext;
 	private final transient SQLFunctionRegistry sqlFunctionRegistry;
 	private final transient SessionFactoryObserverChain observer = new SessionFactoryObserverChain();
 	private final transient ConcurrentHashMap<EntityNameResolver,Object> entityNameResolvers = new ConcurrentHashMap<EntityNameResolver, Object>();
 	private final transient QueryPlanCache queryPlanCache;
 	private final transient CacheImplementor cacheAccess;
-	private transient boolean isClosed = false;
+	private transient boolean isClosed;
 	private final transient TypeResolver typeResolver;
 	private final transient TypeHelper typeHelper;
 	private final transient TransactionEnvironment transactionEnvironment;
 	private final transient SessionFactoryOptions sessionFactoryOptions;
 	private final transient CustomEntityDirtinessStrategy customEntityDirtinessStrategy;
 	private final transient CurrentTenantIdentifierResolver currentTenantIdentifierResolver;
 
 	@SuppressWarnings( {"unchecked", "ThrowableResultOfMethodCallIgnored"})
 	public SessionFactoryImpl(
 			final Configuration cfg,
 			Mapping mapping,
 			final ServiceRegistry serviceRegistry,
 			Settings settings,
 			SessionFactoryObserver observer) throws HibernateException {
 			LOG.debug( "Building session factory" );
 
 		sessionFactoryOptions = new SessionFactoryOptions() {
 			private EntityNotFoundDelegate entityNotFoundDelegate;
 
 			@Override
 			public StandardServiceRegistry getServiceRegistry() {
 				return (StandardServiceRegistry) serviceRegistry;
 			}
 
 			@Override
 			public Interceptor getInterceptor() {
 				return cfg.getInterceptor();
 			}
 
 			@Override
 			public EntityNotFoundDelegate getEntityNotFoundDelegate() {
 				if ( entityNotFoundDelegate == null ) {
 					if ( cfg.getEntityNotFoundDelegate() != null ) {
 						entityNotFoundDelegate = cfg.getEntityNotFoundDelegate();
 					}
 					else {
 						entityNotFoundDelegate = new EntityNotFoundDelegate() {
 							public void handleEntityNotFound(String entityName, Serializable id) {
 								throw new ObjectNotFoundException( id, entityName );
 							}
 						};
 					}
 				}
 				return entityNotFoundDelegate;
 			}
 		};
 
 		this.settings = settings;
 
 		this.properties = new Properties();
 		this.properties.putAll( cfg.getProperties() );
 
 		this.serviceRegistry = serviceRegistry.getService( SessionFactoryServiceRegistryFactory.class ).buildServiceRegistry(
 				this,
 				cfg
 		);
         this.jdbcServices = this.serviceRegistry.getService( JdbcServices.class );
         this.dialect = this.jdbcServices.getDialect();
 		this.cacheAccess = this.serviceRegistry.getService( CacheImplementor.class );
 		this.sqlFunctionRegistry = new SQLFunctionRegistry( getDialect(), cfg.getSqlFunctions() );
 		if ( observer != null ) {
 			this.observer.addObserver( observer );
 		}
 
 		this.typeResolver = cfg.getTypeResolver().scope( this );
 		this.typeHelper = new TypeLocatorImpl( typeResolver );
 
 		this.filters = new HashMap<String, FilterDefinition>();
 		this.filters.putAll( cfg.getFilterDefinitions() );
 
 		LOG.debugf( "Session factory constructed with filter configurations : %s", filters );
 		LOG.debugf( "Instantiating session factory with properties: %s", properties );
 
 
 		this.queryPlanCache = new QueryPlanCache( this );
 
 		// todo : everything above here consider implementing as standard SF service.  specifically: stats, caches, types, function-reg
 
 		class IntegratorObserver implements SessionFactoryObserver {
 			private ArrayList<Integrator> integrators = new ArrayList<Integrator>();
 
 			@Override
 			public void sessionFactoryCreated(SessionFactory factory) {
 			}
 
 			@Override
 			public void sessionFactoryClosed(SessionFactory factory) {
 				for ( Integrator integrator : integrators ) {
 					integrator.disintegrate( SessionFactoryImpl.this, SessionFactoryImpl.this.serviceRegistry );
 				}
                 integrators.clear();
 			}
 		}
 
 		final IntegratorObserver integratorObserver = new IntegratorObserver();
 		this.observer.addObserver( integratorObserver );
 		for ( Integrator integrator : serviceRegistry.getService( IntegratorService.class ).getIntegrators() ) {
 			integrator.integrate( cfg, this, this.serviceRegistry );
 			integratorObserver.integrators.add( integrator );
 		}
 
 		//Generators:
 
 		identifierGenerators = new HashMap();
 		Iterator classes = cfg.getClassMappings();
 		while ( classes.hasNext() ) {
 			PersistentClass model = (PersistentClass) classes.next();
 			if ( !model.isInherited() ) {
 				IdentifierGenerator generator = model.getIdentifier().createIdentifierGenerator(
 						cfg.getIdentifierGeneratorFactory(),
 						getDialect(),
 				        settings.getDefaultCatalogName(),
 				        settings.getDefaultSchemaName(),
 				        (RootClass) model
 				);
 				identifierGenerators.put( model.getEntityName(), generator );
 			}
 		}
 
 		imports = new HashMap<String,String>( cfg.getImports() );
 
 		///////////////////////////////////////////////////////////////////////
 		// Prepare persisters and link them up with their cache
 		// region/access-strategy
 
 		final RegionFactory regionFactory = cacheAccess.getRegionFactory();
 		final String cacheRegionPrefix = settings.getCacheRegionPrefix() == null ? "" : settings.getCacheRegionPrefix() + ".";
 		final PersisterFactory persisterFactory = serviceRegistry.getService( PersisterFactory.class );
 
 		// todo : consider removing this silliness and just have EntityPersister directly implement ClassMetadata
 		//		EntityPersister.getClassMetadata() for the internal impls simply "return this";
 		//		collapsing those would allow us to remove this "extra" Map
 		//
 		// todo : similar for CollectionPersister/CollectionMetadata
 
 		entityPersisters = new HashMap();
 		Map entityAccessStrategies = new HashMap();
 		Map<String,ClassMetadata> classMeta = new HashMap<String,ClassMetadata>();
 		classes = cfg.getClassMappings();
 		while ( classes.hasNext() ) {
 			final PersistentClass model = (PersistentClass) classes.next();
 			model.prepareTemporaryTables( mapping, getDialect() );
 			final String cacheRegionName = cacheRegionPrefix + model.getRootClass().getCacheRegionName();
 			// cache region is defined by the root-class in the hierarchy...
 			EntityRegionAccessStrategy accessStrategy = ( EntityRegionAccessStrategy ) entityAccessStrategies.get( cacheRegionName );
 			if ( accessStrategy == null && settings.isSecondLevelCacheEnabled() ) {
 				final AccessType accessType = AccessType.fromExternalName( model.getCacheConcurrencyStrategy() );
 				if ( accessType != null ) {
 					LOG.tracef( "Building shared cache region for entity data [%s]", model.getEntityName() );
 					EntityRegion entityRegion = regionFactory.buildEntityRegion( cacheRegionName, properties, CacheDataDescriptionImpl.decode( model ) );
 					accessStrategy = entityRegion.buildAccessStrategy( accessType );
 					entityAccessStrategies.put( cacheRegionName, accessStrategy );
 					cacheAccess.addCacheRegion( cacheRegionName, entityRegion );
 				}
 			}
 
 			NaturalIdRegionAccessStrategy naturalIdAccessStrategy = null;
 			if ( model.hasNaturalId() && model.getNaturalIdCacheRegionName() != null ) {
 				final String naturalIdCacheRegionName = cacheRegionPrefix + model.getNaturalIdCacheRegionName();
 				naturalIdAccessStrategy = ( NaturalIdRegionAccessStrategy ) entityAccessStrategies.get( naturalIdCacheRegionName );
 
 				if ( naturalIdAccessStrategy == null && settings.isSecondLevelCacheEnabled() ) {
 					final CacheDataDescriptionImpl cacheDataDescription = CacheDataDescriptionImpl.decode( model );
 
 					NaturalIdRegion naturalIdRegion = null;
 					try {
 						naturalIdRegion = regionFactory.buildNaturalIdRegion( naturalIdCacheRegionName, properties,
 								cacheDataDescription );
 					}
 					catch ( UnsupportedOperationException e ) {
 						LOG.warnf(
 								"Shared cache region factory [%s] does not support natural id caching; " +
 										"shared NaturalId caching will be disabled for not be enabled for %s",
 								regionFactory.getClass().getName(),
 								model.getEntityName()
 						);
 					}
 
 					if (naturalIdRegion != null) {
 						naturalIdAccessStrategy = naturalIdRegion.buildAccessStrategy( regionFactory.getDefaultAccessType() );
 						entityAccessStrategies.put( naturalIdCacheRegionName, naturalIdAccessStrategy );
 						cacheAccess.addCacheRegion(  naturalIdCacheRegionName, naturalIdRegion );
 					}
 				}
 			}
 
 			EntityPersister cp = persisterFactory.createEntityPersister(
 					model,
 					accessStrategy,
 					naturalIdAccessStrategy,
 					this,
 					mapping
 			);
 			entityPersisters.put( model.getEntityName(), cp );
 			classMeta.put( model.getEntityName(), cp.getClassMetadata() );
 		}
 		this.classMetadata = Collections.unmodifiableMap(classMeta);
 
 		Map<String,Set<String>> tmpEntityToCollectionRoleMap = new HashMap<String,Set<String>>();
 		collectionPersisters = new HashMap<String,CollectionPersister>();
 		Map<String,CollectionMetadata> tmpCollectionMetadata = new HashMap<String,CollectionMetadata>();
 		Iterator collections = cfg.getCollectionMappings();
 		while ( collections.hasNext() ) {
 			Collection model = (Collection) collections.next();
 			final String cacheRegionName = cacheRegionPrefix + model.getCacheRegionName();
 			final AccessType accessType = AccessType.fromExternalName( model.getCacheConcurrencyStrategy() );
 			CollectionRegionAccessStrategy accessStrategy = null;
 			if ( accessType != null && settings.isSecondLevelCacheEnabled() ) {
 				LOG.tracev( "Building shared cache region for collection data [{0}]", model.getRole() );
 				CollectionRegion collectionRegion = regionFactory.buildCollectionRegion( cacheRegionName, properties, CacheDataDescriptionImpl
 						.decode( model ) );
 				accessStrategy = collectionRegion.buildAccessStrategy( accessType );
 				entityAccessStrategies.put( cacheRegionName, accessStrategy );
 				cacheAccess.addCacheRegion( cacheRegionName, collectionRegion );
 			}
 			CollectionPersister persister = persisterFactory.createCollectionPersister(
 					cfg,
 					model,
 					accessStrategy,
 					this
 			) ;
 			collectionPersisters.put( model.getRole(), persister );
 			tmpCollectionMetadata.put( model.getRole(), persister.getCollectionMetadata() );
 			Type indexType = persister.getIndexType();
 			if ( indexType != null && indexType.isAssociationType() && !indexType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) indexType ).getAssociatedEntityName( this );
 				Set roles = tmpEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet();
 					tmpEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 			Type elementType = persister.getElementType();
 			if ( elementType.isAssociationType() && !elementType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) elementType ).getAssociatedEntityName( this );
 				Set roles = tmpEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet();
 					tmpEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 		}
 		collectionMetadata = Collections.unmodifiableMap( tmpCollectionMetadata );
 		Iterator itr = tmpEntityToCollectionRoleMap.entrySet().iterator();
 		while ( itr.hasNext() ) {
 			final Map.Entry entry = ( Map.Entry ) itr.next();
 			entry.setValue( Collections.unmodifiableSet( ( Set ) entry.getValue() ) );
 		}
 		collectionRolesByEntityParticipant = Collections.unmodifiableMap( tmpEntityToCollectionRoleMap );
 
 		//Named Queries:
 		this.namedQueryRepository = new NamedQueryRepository(
 				cfg.getNamedQueries().values(),
 				cfg.getNamedSQLQueries().values(),
 				cfg.getSqlResultSetMappings().values(),
 				toProcedureCallMementos( cfg.getNamedProcedureCallMap(), cfg.getSqlResultSetMappings() )
 		);
 
 		// after *all* persisters and named queries are registered
 		for ( EntityPersister persister : entityPersisters.values() ) {
 			persister.generateEntityDefinition();
 		}
 
 		for ( EntityPersister persister : entityPersisters.values() ) {
 			persister.postInstantiate();
 			registerEntityNameResolvers( persister );
 		}
 		for ( CollectionPersister persister : collectionPersisters.values() ) {
 			persister.postInstantiate();
 		}
 
 		//JNDI + Serialization:
 
 		name = settings.getSessionFactoryName();
 		try {
 			uuid = (String) UUID_GENERATOR.generate(null, null);
 		}
 		catch (Exception e) {
 			throw new AssertionFailure("Could not generate UUID");
 		}
 		SessionFactoryRegistry.INSTANCE.addSessionFactory(
 				uuid,
 				name,
 				settings.isSessionFactoryNameAlsoJndiName(),
 				this,
 				serviceRegistry.getService( JndiService.class )
 		);
 
 		LOG.debug( "Instantiated session factory" );
 
 		settings.getMultiTableBulkIdStrategy().prepare(
 				jdbcServices,
 				buildLocalConnectionAccess(),
 				cfg.createMappings(),
 				cfg.buildMapping(),
 				properties
 		);
 
 
 		if ( settings.isAutoCreateSchema() ) {
 			new SchemaExport( serviceRegistry, cfg )
 					.setImportSqlCommandExtractor( serviceRegistry.getService( ImportSqlCommandExtractor.class ) )
 					.create( false, true );
 		}
 		if ( settings.isAutoUpdateSchema() ) {
 			new SchemaUpdate( serviceRegistry, cfg ).execute( false, true );
 		}
 		if ( settings.isAutoValidateSchema() ) {
 			new SchemaValidator( serviceRegistry, cfg ).validate();
 		}
 		if ( settings.isAutoDropSchema() ) {
 			schemaExport = new SchemaExport( serviceRegistry, cfg )
 					.setImportSqlCommandExtractor( serviceRegistry.getService( ImportSqlCommandExtractor.class ) );
 		}
 
 		currentSessionContext = buildCurrentSessionContext();
 
 		//checking for named queries
 		if ( settings.isNamedQueryStartupCheckingEnabled() ) {
 			final Map<String,HibernateException> errors = checkNamedQueries();
 			if ( ! errors.isEmpty() ) {
 				StringBuilder failingQueries = new StringBuilder( "Errors in named queries: " );
 				String sep = "";
 				for ( Map.Entry<String,HibernateException> entry : errors.entrySet() ) {
 					LOG.namedQueryError( entry.getKey(), entry.getValue() );
 					failingQueries.append( sep ).append( entry.getKey() );
 					sep = ", ";
 				}
 				throw new HibernateException( failingQueries.toString() );
 			}
 		}
 
 		// this needs to happen after persisters are all ready to go...
 		this.fetchProfiles = new HashMap();
 		itr = cfg.iterateFetchProfiles();
 		while ( itr.hasNext() ) {
 			final org.hibernate.mapping.FetchProfile mappingProfile =
 					( org.hibernate.mapping.FetchProfile ) itr.next();
 			final FetchProfile fetchProfile = new FetchProfile( mappingProfile.getName() );
 			for ( org.hibernate.mapping.FetchProfile.Fetch mappingFetch : mappingProfile.getFetches() ) {
 				// resolve the persister owning the fetch
 				final String entityName = getImportedClassName( mappingFetch.getEntity() );
 				final EntityPersister owner = entityName == null
 						? null
 						: entityPersisters.get( entityName );
 				if ( owner == null ) {
 					throw new HibernateException(
 							"Unable to resolve entity reference [" + mappingFetch.getEntity()
 									+ "] in fetch profile [" + fetchProfile.getName() + "]"
 					);
 				}
 
 				// validate the specified association fetch
 				Type associationType = owner.getPropertyType( mappingFetch.getAssociation() );
 				if ( associationType == null || !associationType.isAssociationType() ) {
 					throw new HibernateException( "Fetch profile [" + fetchProfile.getName() + "] specified an invalid association" );
 				}
 
 				// resolve the style
 				final Fetch.Style fetchStyle = Fetch.Style.parse( mappingFetch.getStyle() );
 
 				// then construct the fetch instance...
 				fetchProfile.addFetch( new Association( owner, mappingFetch.getAssociation() ), fetchStyle );
 				((Loadable) owner).registerAffectingFetchProfile( fetchProfile.getName() );
 			}
 			fetchProfiles.put( fetchProfile.getName(), fetchProfile );
 		}
 
 		this.customEntityDirtinessStrategy = determineCustomEntityDirtinessStrategy();
 		this.currentTenantIdentifierResolver = determineCurrentTenantIdentifierResolver( cfg.getCurrentTenantIdentifierResolver() );
 		this.transactionEnvironment = new TransactionEnvironmentImpl( this );
 		this.observer.sessionFactoryCreated( this );
 	}
 
 	private Map<String, ProcedureCallMemento> toProcedureCallMementos(
 			Map<String, NamedProcedureCallDefinition> definitions,
 			Map<String, ResultSetMappingDefinition> resultSetMappingMap) {
 		final Map<String, ProcedureCallMemento> rtn = new HashMap<String, ProcedureCallMemento>();
 		if ( definitions != null ) {
 			for (String name : definitions.keySet()){
 				rtn.put( name,  definitions.get( name ).toMemento( this, resultSetMappingMap ));
 			}
 		}
 		return rtn;
 	}
 
 	private JdbcConnectionAccess buildLocalConnectionAccess() {
 		return new JdbcConnectionAccess() {
 			@Override
 			public Connection obtainConnection() throws SQLException {
 				return settings.getMultiTenancyStrategy() == MultiTenancyStrategy.NONE
 						? serviceRegistry.getService( ConnectionProvider.class ).getConnection()
 						: serviceRegistry.getService( MultiTenantConnectionProvider.class ).getAnyConnection();
 			}
 
 			@Override
 			public void releaseConnection(Connection connection) throws SQLException {
 				if ( settings.getMultiTenancyStrategy() == MultiTenancyStrategy.NONE ) {
 					serviceRegistry.getService( ConnectionProvider.class ).closeConnection( connection );
 				}
 				else {
 					serviceRegistry.getService( MultiTenantConnectionProvider.class ).releaseAnyConnection( connection );
 				}
 			}
 
 			@Override
 			public boolean supportsAggressiveRelease() {
 				return false;
 			}
 		};
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	private CustomEntityDirtinessStrategy determineCustomEntityDirtinessStrategy() {
 		CustomEntityDirtinessStrategy defaultValue = new CustomEntityDirtinessStrategy() {
 			@Override
 			public boolean canDirtyCheck(Object entity, EntityPersister persister, Session session) {
 				return false;
 			}
 
 			@Override
 			public boolean isDirty(Object entity, EntityPersister persister, Session session) {
 				return false;
 			}
 
 			@Override
 			public void resetDirty(Object entity, EntityPersister persister, Session session) {
 			}
 
 			@Override
 			public void findDirty(
 					Object entity,
 					EntityPersister persister,
 					Session session,
 					DirtyCheckContext dirtyCheckContext) {
 				// todo : implement proper method body
 			}
 		};
 		return serviceRegistry.getService( ConfigurationService.class ).getSetting(
 				AvailableSettings.CUSTOM_ENTITY_DIRTINESS_STRATEGY,
 				CustomEntityDirtinessStrategy.class,
 				defaultValue
 		);
 	}
 
 	@SuppressWarnings({ "unchecked" })
 	private CurrentTenantIdentifierResolver determineCurrentTenantIdentifierResolver(
 			CurrentTenantIdentifierResolver explicitResolver) {
 		if ( explicitResolver != null ) {
 			return explicitResolver;
 		}
 		return serviceRegistry.getService( ConfigurationService.class )
 				.getSetting(
 						AvailableSettings.MULTI_TENANT_IDENTIFIER_RESOLVER,
 						CurrentTenantIdentifierResolver.class,
 						null
 				);
 
 	}
 
 	@SuppressWarnings( {"ThrowableResultOfMethodCallIgnored"})
 	public SessionFactoryImpl(
 			MetadataImplementor metadata,
 			SessionFactoryOptions sessionFactoryOptions,
 			SessionFactoryObserver observer) throws HibernateException {
 
 		final boolean traceEnabled = LOG.isTraceEnabled();
 		final boolean debugEnabled = traceEnabled || LOG.isDebugEnabled();
 		if ( debugEnabled ) {
 			LOG.debug( "Building session factory" );
 		}
 
 		this.sessionFactoryOptions = sessionFactoryOptions;
 
 		this.properties = createPropertiesFromMap(
 				metadata.getServiceRegistry().getService( ConfigurationService.class ).getSettings()
 		);
 
 		// TODO: these should be moved into SessionFactoryOptions
 		this.settings = new SettingsFactory().buildSettings(
 				properties,
 				metadata.getServiceRegistry()
 		);
 
 		this.serviceRegistry =
 				sessionFactoryOptions.getServiceRegistry()
 						.getService( SessionFactoryServiceRegistryFactory.class )
 						.buildServiceRegistry( this, metadata );
 
 		this.jdbcServices = this.serviceRegistry.getService( JdbcServices.class );
 		this.dialect = this.jdbcServices.getDialect();
 		this.cacheAccess = this.serviceRegistry.getService( CacheImplementor.class );
 
 		// TODO: get SQL functions from JdbcServices (HHH-6559)
 		//this.sqlFunctionRegistry = new SQLFunctionRegistry( this.jdbcServices.getSqlFunctions() );
 		this.sqlFunctionRegistry = new SQLFunctionRegistry( this.dialect, new HashMap<String, SQLFunction>() );
 
 		// TODO: get SQL functions from a new service
 		// this.sqlFunctionRegistry = new SQLFunctionRegistry( getDialect(), cfg.getSqlFunctions() );
 
 		if ( observer != null ) {
 			this.observer.addObserver( observer );
 		}
 
 		this.typeResolver = metadata.getTypeResolver().scope( this );
 		this.typeHelper = new TypeLocatorImpl( typeResolver );
 
 		this.filters = new HashMap<String, FilterDefinition>();
 		for ( FilterDefinition filterDefinition : metadata.getFilterDefinitions() ) {
 			filters.put( filterDefinition.getFilterName(), filterDefinition );
 		}
 
 		if ( debugEnabled ) {
 			LOG.debugf( "Session factory constructed with filter configurations : %s", filters );
 			LOG.debugf( "Instantiating session factory with properties: %s", properties );
 		}
 		this.queryPlanCache = new QueryPlanCache( this );
 
 		class IntegratorObserver implements SessionFactoryObserver {
 			private ArrayList<Integrator> integrators = new ArrayList<Integrator>();
 
 			@Override
 			public void sessionFactoryCreated(SessionFactory factory) {
 			}
 
 			@Override
 			public void sessionFactoryClosed(SessionFactory factory) {
 				for ( Integrator integrator : integrators ) {
 					integrator.disintegrate( SessionFactoryImpl.this, SessionFactoryImpl.this.serviceRegistry );
 				}
                 integrators.clear();
 			}
 		}
 
         final IntegratorObserver integratorObserver = new IntegratorObserver();
         this.observer.addObserver(integratorObserver);
         for (Integrator integrator : serviceRegistry.getService(IntegratorService.class).getIntegrators()) {
             integrator.integrate(metadata, this, this.serviceRegistry);
             integratorObserver.integrators.add(integrator);
         }
 
 
 		//Generators:
 
 		identifierGenerators = new HashMap<String,IdentifierGenerator>();
 		for ( EntityBinding entityBinding : metadata.getEntityBindings() ) {
 			if ( entityBinding.isRoot() ) {
 				identifierGenerators.put(
 						entityBinding.getEntity().getName(),
 						entityBinding.getHierarchyDetails().getEntityIdentifier().getIdentifierGenerator()
 				);
 			}
 		}
 
 		///////////////////////////////////////////////////////////////////////
 		// Prepare persisters and link them up with their cache
 		// region/access-strategy
 
 		StringBuilder stringBuilder = new StringBuilder();
 		if ( settings.getCacheRegionPrefix() != null) {
 			stringBuilder
 					.append( settings.getCacheRegionPrefix() )
 					.append( '.' );
 		}
 		final String cacheRegionPrefix = stringBuilder.toString();
 
 		entityPersisters = new HashMap<String,EntityPersister>();
 		Map<String, RegionAccessStrategy> entityAccessStrategies = new HashMap<String, RegionAccessStrategy>();
 		Map<String,ClassMetadata> classMeta = new HashMap<String,ClassMetadata>();
 		for ( EntityBinding model : metadata.getEntityBindings() ) {
 			// TODO: should temp table prep happen when metadata is being built?
 			//model.prepareTemporaryTables( metadata, getDialect() );
 			// cache region is defined by the root-class in the hierarchy...
 			EntityBinding rootEntityBinding = metadata.getRootEntityBinding( model.getEntity().getName() );
 			EntityRegionAccessStrategy accessStrategy = null;
 			if ( settings.isSecondLevelCacheEnabled() &&
 					rootEntityBinding.getHierarchyDetails().getCaching() != null &&
 					model.getHierarchyDetails().getCaching() != null &&
 					model.getHierarchyDetails().getCaching().getAccessType() != null ) {
 				final String cacheRegionName = cacheRegionPrefix + rootEntityBinding.getHierarchyDetails().getCaching().getRegion();
 				accessStrategy = EntityRegionAccessStrategy.class.cast( entityAccessStrategies.get( cacheRegionName ) );
 				if ( accessStrategy == null ) {
 					final AccessType accessType = model.getHierarchyDetails().getCaching().getAccessType();
 					if ( traceEnabled ) {
 						LOG.tracev( "Building cache for entity data [{0}]", model.getEntity().getName() );
 					}
 					EntityRegion entityRegion = settings.getRegionFactory().buildEntityRegion(
 							cacheRegionName, properties, CacheDataDescriptionImpl.decode( model )
 					);
 					accessStrategy = entityRegion.buildAccessStrategy( accessType );
 					entityAccessStrategies.put( cacheRegionName, accessStrategy );
 					cacheAccess.addCacheRegion( cacheRegionName, entityRegion );
 				}
 			}
 			EntityPersister cp = serviceRegistry.getService( PersisterFactory.class ).createEntityPersister(
 					model, accessStrategy, this, metadata
 			);
 			entityPersisters.put( model.getEntity().getName(), cp );
 			classMeta.put( model.getEntity().getName(), cp.getClassMetadata() );
 		}
 		this.classMetadata = Collections.unmodifiableMap(classMeta);
 
 		Map<String,Set<String>> tmpEntityToCollectionRoleMap = new HashMap<String,Set<String>>();
 		collectionPersisters = new HashMap<String,CollectionPersister>();
 		Map<String, CollectionMetadata> tmpCollectionMetadata = new HashMap<String, CollectionMetadata>();
 		for ( PluralAttributeBinding model : metadata.getCollectionBindings() ) {
 			if ( model.getAttribute() == null ) {
 				throw new IllegalStateException( "No attribute defined for a AbstractPluralAttributeBinding: " +  model );
 			}
 			if ( model.getAttribute().isSingular() ) {
 				throw new IllegalStateException(
 						"AbstractPluralAttributeBinding has a Singular attribute defined: " + model.getAttribute().getName()
 				);
 			}
 			final String cacheRegionName = cacheRegionPrefix + model.getCaching().getRegion();
 			final AccessType accessType = model.getCaching().getAccessType();
 			CollectionRegionAccessStrategy accessStrategy = null;
 			if ( accessType != null && settings.isSecondLevelCacheEnabled() ) {
 				if ( traceEnabled ) {
 					LOG.tracev( "Building cache for collection data [{0}]", model.getAttribute().getRole() );
 				}
 				CollectionRegion collectionRegion = settings.getRegionFactory().buildCollectionRegion(
 						cacheRegionName, properties, CacheDataDescriptionImpl.decode( model )
 				);
 				accessStrategy = collectionRegion.buildAccessStrategy( accessType );
 				entityAccessStrategies.put( cacheRegionName, accessStrategy );
 				cacheAccess.addCacheRegion(  cacheRegionName, collectionRegion );
 			}
 			CollectionPersister persister = serviceRegistry
 					.getService( PersisterFactory.class )
 					.createCollectionPersister( metadata, model, accessStrategy, this );
 			collectionPersisters.put( model.getAttribute().getRole(), persister );
 			tmpCollectionMetadata.put( model.getAttribute().getRole(), persister.getCollectionMetadata() );
 			Type indexType = persister.getIndexType();
 			if ( indexType != null && indexType.isAssociationType() && !indexType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) indexType ).getAssociatedEntityName( this );
 				Set<String> roles = tmpEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet<String>();
 					tmpEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 			Type elementType = persister.getElementType();
 			if ( elementType.isAssociationType() && !elementType.isAnyType() ) {
 				String entityName = ( ( AssociationType ) elementType ).getAssociatedEntityName( this );
 				Set<String> roles = tmpEntityToCollectionRoleMap.get( entityName );
 				if ( roles == null ) {
 					roles = new HashSet<String>();
 					tmpEntityToCollectionRoleMap.put( entityName, roles );
 				}
 				roles.add( persister.getRole() );
 			}
 		}
 		collectionMetadata = Collections.unmodifiableMap( tmpCollectionMetadata );
 		for ( Map.Entry<String, Set<String>> entry : tmpEntityToCollectionRoleMap.entrySet() ) {
 			entry.setValue( Collections.unmodifiableSet( entry.getValue() ) );
 		}
 		collectionRolesByEntityParticipant = Collections.unmodifiableMap( tmpEntityToCollectionRoleMap );
 
 
 		//Named Queries:
 		namedQueryRepository = new NamedQueryRepository(
 				metadata.getNamedQueryDefinitions(),
 				metadata.getNamedNativeQueryDefinitions(),
 				metadata.getResultSetMappingDefinitions(),
 				new HashMap<String, ProcedureCallMemento>(  )
 		);
 
 		imports = new HashMap<String,String>();
 		for ( Map.Entry<String,String> importEntry : metadata.getImports() ) {
 			imports.put( importEntry.getKey(), importEntry.getValue() );
 		}
 
 		// after *all* persisters and named queries are registered
 		Iterator iter = entityPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			final EntityPersister persister = ( ( EntityPersister ) iter.next() );
 			persister.postInstantiate();
 			registerEntityNameResolvers( persister );
 
 		}
 		iter = collectionPersisters.values().iterator();
 		while ( iter.hasNext() ) {
 			final CollectionPersister persister = ( ( CollectionPersister ) iter.next() );
 			persister.postInstantiate();
 		}
 
 		//JNDI + Serialization:
 
 		name = settings.getSessionFactoryName();
 		try {
 			uuid = (String) UUID_GENERATOR.generate(null, null);
 		}
 		catch (Exception e) {
 			throw new AssertionFailure("Could not generate UUID");
 		}
 		SessionFactoryRegistry.INSTANCE.addSessionFactory(
 				uuid, 
 				name,
 				settings.isSessionFactoryNameAlsoJndiName(),
 				this,
 				serviceRegistry.getService( JndiService.class )
 		);
 
 		if ( debugEnabled ) {
 			LOG.debug("Instantiated session factory");
 		}
 
 		if ( settings.isAutoCreateSchema() ) {
 			new SchemaExport( metadata )
 					.setImportSqlCommandExtractor( serviceRegistry.getService( ImportSqlCommandExtractor.class ) )
 					.create( false, true );
 		}
 
 		if ( settings.isAutoDropSchema() ) {
 			schemaExport = new SchemaExport( metadata )
 					.setImportSqlCommandExtractor( serviceRegistry.getService( ImportSqlCommandExtractor.class ) );
 		}
 
 		currentSessionContext = buildCurrentSessionContext();
 
 		//checking for named queries
 		if ( settings.isNamedQueryStartupCheckingEnabled() ) {
 			final Map<String,HibernateException> errors = checkNamedQueries();
 			if ( ! errors.isEmpty() ) {
 				StringBuilder failingQueries = new StringBuilder( "Errors in named queries: " );
 				String sep = "";
 				for ( Map.Entry<String,HibernateException> entry : errors.entrySet() ) {
 					LOG.namedQueryError( entry.getKey(), entry.getValue() );
 					failingQueries.append( entry.getKey() ).append( sep );
 					sep = ", ";
 				}
 				throw new HibernateException( failingQueries.toString() );
 			}
 		}
 
 		// this needs to happen after persisters are all ready to go...
 		this.fetchProfiles = new HashMap<String,FetchProfile>();
 		for ( org.hibernate.metamodel.binding.FetchProfile mappingProfile : metadata.getFetchProfiles() ) {
 			final FetchProfile fetchProfile = new FetchProfile( mappingProfile.getName() );
 			for ( org.hibernate.metamodel.binding.FetchProfile.Fetch mappingFetch : mappingProfile.getFetches() ) {
 				// resolve the persister owning the fetch
 				final String entityName = getImportedClassName( mappingFetch.getEntity() );
 				final EntityPersister owner = entityName == null ? null : entityPersisters.get( entityName );
 				if ( owner == null ) {
 					throw new HibernateException(
 							"Unable to resolve entity reference [" + mappingFetch.getEntity()
 									+ "] in fetch profile [" + fetchProfile.getName() + "]"
 					);
 				}
 
 				// validate the specified association fetch
 				Type associationType = owner.getPropertyType( mappingFetch.getAssociation() );
 				if ( associationType == null || ! associationType.isAssociationType() ) {
 					throw new HibernateException( "Fetch profile [" + fetchProfile.getName() + "] specified an invalid association" );
 				}
 
 				// resolve the style
 				final Fetch.Style fetchStyle = Fetch.Style.parse( mappingFetch.getStyle() );
 
 				// then construct the fetch instance...
 				fetchProfile.addFetch( new Association( owner, mappingFetch.getAssociation() ), fetchStyle );
 				( ( Loadable ) owner ).registerAffectingFetchProfile( fetchProfile.getName() );
 			}
 			fetchProfiles.put( fetchProfile.getName(), fetchProfile );
 		}
 
 		this.customEntityDirtinessStrategy = determineCustomEntityDirtinessStrategy();
 		this.currentTenantIdentifierResolver = determineCurrentTenantIdentifierResolver( null );
 		this.transactionEnvironment = new TransactionEnvironmentImpl( this );
 		this.observer.sessionFactoryCreated( this );
 	}
 
 	@SuppressWarnings( {"unchecked"} )
 	private static Properties createPropertiesFromMap(Map map) {
 		Properties properties = new Properties();
 		properties.putAll( map );
 		return properties;
 	}
 
 	public Session openSession() throws HibernateException {
 		return withOptions().openSession();
 	}
 
 	public Session openTemporarySession() throws HibernateException {
 		return withOptions()
 				.autoClose( false )
 				.flushBeforeCompletion( false )
 				.connectionReleaseMode( ConnectionReleaseMode.AFTER_STATEMENT )
 				.openSession();
 	}
 
 	public Session getCurrentSession() throws HibernateException {
 		if ( currentSessionContext == null ) {
 			throw new HibernateException( "No CurrentSessionContext configured!" );
 		}
 		return currentSessionContext.currentSession();
 	}
 
 	@Override
 	public SessionBuilderImplementor withOptions() {
 		return new SessionBuilderImpl( this );
 	}
 
 	@Override
 	public StatelessSessionBuilder withStatelessOptions() {
 		return new StatelessSessionBuilderImpl( this );
 	}
 
 	public StatelessSession openStatelessSession() {
 		return withStatelessOptions().openStatelessSession();
 	}
 
 	public StatelessSession openStatelessSession(Connection connection) {
 		return withStatelessOptions().connection( connection ).openStatelessSession();
 	}
 
 	@Override
 	public void addObserver(SessionFactoryObserver observer) {
 		this.observer.addObserver( observer );
 	}
 
 	public TransactionEnvironment getTransactionEnvironment() {
 		return transactionEnvironment;
 	}
 
 	public Properties getProperties() {
 		return properties;
 	}
 
 	public IdentifierGeneratorFactory getIdentifierGeneratorFactory() {
 		return null;
 	}
 
 	public TypeResolver getTypeResolver() {
 		return typeResolver;
 	}
 
 	private void registerEntityNameResolvers(EntityPersister persister) {
 		if ( persister.getEntityMetamodel() == null || persister.getEntityMetamodel().getTuplizer() == null ) {
 			return;
 		}
 		registerEntityNameResolvers( persister.getEntityMetamodel().getTuplizer() );
 	}
 
 	private void registerEntityNameResolvers(EntityTuplizer tuplizer) {
 		EntityNameResolver[] resolvers = tuplizer.getEntityNameResolvers();
 		if ( resolvers == null ) {
 			return;
 		}
 
 		for ( EntityNameResolver resolver : resolvers ) {
 			registerEntityNameResolver( resolver );
 		}
 	}
 
 	private static final Object ENTITY_NAME_RESOLVER_MAP_VALUE = new Object();
 
 	public void registerEntityNameResolver(EntityNameResolver resolver) {
 		entityNameResolvers.put( resolver, ENTITY_NAME_RESOLVER_MAP_VALUE );
 	}
 
 	@Override
 	public Iterable<EntityNameResolver> iterateEntityNameResolvers() {
 		return entityNameResolvers.keySet();
 	}
 
 	public QueryPlanCache getQueryPlanCache() {
 		return queryPlanCache;
 	}
 
 	private Map<String,HibernateException> checkNamedQueries() throws HibernateException {
 		return namedQueryRepository.checkNamedQueries( queryPlanCache );
 	}
 
 	public EntityPersister getEntityPersister(String entityName) throws MappingException {
 		EntityPersister result = entityPersisters.get(entityName);
 		if ( result == null ) {
 			throw new MappingException( "Unknown entity: " + entityName );
 		}
 		return result;
 	}
 
 	@Override
 	public Map<String, CollectionPersister> getCollectionPersisters() {
 		return collectionPersisters;
 	}
 
 	@Override
 	public Map<String, EntityPersister> getEntityPersisters() {
 		return entityPersisters;
 	}
 
 	public CollectionPersister getCollectionPersister(String role) throws MappingException {
 		CollectionPersister result = collectionPersisters.get(role);
 		if ( result == null ) {
 			throw new MappingException( "Unknown collection role: " + role );
 		}
 		return result;
 	}
 
 	public Settings getSettings() {
 		return settings;
 	}
 
 	@Override
 	public SessionFactoryOptions getSessionFactoryOptions() {
 		return sessionFactoryOptions;
 	}
 
 	public JdbcServices getJdbcServices() {
 		return jdbcServices;
 	}
 
 	public Dialect getDialect() {
 		if ( serviceRegistry == null ) {
 			throw new IllegalStateException( "Cannot determine dialect because serviceRegistry is null." );
 		}
 		return dialect;
 	}
 
 	public Interceptor getInterceptor() {
 		return sessionFactoryOptions.getInterceptor();
 	}
 
 	public SQLExceptionConverter getSQLExceptionConverter() {
 		return getSQLExceptionHelper().getSqlExceptionConverter();
 	}
 
 	public SqlExceptionHelper getSQLExceptionHelper() {
 		return getJdbcServices().getSqlExceptionHelper();
 	}
 
 	public Set<String> getCollectionRolesByEntityParticipant(String entityName) {
 		return collectionRolesByEntityParticipant.get( entityName );
 	}
 
 	@Override
 	public Reference getReference() {
 		// from javax.naming.Referenceable
         LOG.debug( "Returning a Reference to the SessionFactory" );
 		return new Reference(
 				SessionFactoryImpl.class.getName(),
 				new StringRefAddr("uuid", uuid),
 				SessionFactoryRegistry.ObjectFactoryImpl.class.getName(),
 				null
 		);
 	}
 
 	@Override
 	public NamedQueryRepository getNamedQueryRepository() {
 		return namedQueryRepository;
 	}
 
 	public void registerNamedQueryDefinition(String name, NamedQueryDefinition definition) {
 		namedQueryRepository.registerNamedQueryDefinition( name, definition );
 	}
 
 	public NamedQueryDefinition getNamedQuery(String queryName) {
 		return namedQueryRepository.getNamedQueryDefinition( queryName );
 	}
 
 	public void registerNamedSQLQueryDefinition(String name, NamedSQLQueryDefinition definition) {
 		namedQueryRepository.registerNamedSQLQueryDefinition( name, definition );
 	}
 
 	public NamedSQLQueryDefinition getNamedSQLQuery(String queryName) {
 		return namedQueryRepository.getNamedSQLQueryDefinition( queryName );
 	}
 
 	public ResultSetMappingDefinition getResultSetMapping(String mappingName) {
 		return namedQueryRepository.getResultSetMappingDefinition( mappingName );
 	}
 
 	public Type getIdentifierType(String className) throws MappingException {
 		return getEntityPersister(className).getIdentifierType();
 	}
 	public String getIdentifierPropertyName(String className) throws MappingException {
 		return getEntityPersister(className).getIdentifierPropertyName();
 	}
 
 	public Type[] getReturnTypes(String queryString) throws HibernateException {
 		return queryPlanCache.getHQLQueryPlan( queryString, false, Collections.EMPTY_MAP )
 				.getReturnMetadata()
 				.getReturnTypes();
 	}
 
 	public String[] getReturnAliases(String queryString) throws HibernateException {
 		return queryPlanCache.getHQLQueryPlan( queryString, false, Collections.EMPTY_MAP )
 				.getReturnMetadata()
 				.getReturnAliases();
 	}
 
 	public ClassMetadata getClassMetadata(Class persistentClass) throws HibernateException {
 		return getClassMetadata( persistentClass.getName() );
 	}
 
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/SessionImpl.java b/hibernate-core/src/main/java/org/hibernate/internal/SessionImpl.java
index 06a7cd7678..f87d92f7b5 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/SessionImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/SessionImpl.java
@@ -1,1317 +1,1317 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2005-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Reader;
 import java.io.Serializable;
 import java.sql.Blob;
 import java.sql.Clob;
 import java.sql.Connection;
 import java.sql.NClob;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import javax.persistence.EntityNotFoundException;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.CacheMode;
 import org.hibernate.ConnectionReleaseMode;
 import org.hibernate.Criteria;
 import org.hibernate.EmptyInterceptor;
 import org.hibernate.EntityNameResolver;
 import org.hibernate.Filter;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.IdentifierLoadAccess;
 import org.hibernate.Interceptor;
 import org.hibernate.LobHelper;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.NaturalIdLoadAccess;
 import org.hibernate.ObjectDeletedException;
 import org.hibernate.ObjectNotFoundException;
 import org.hibernate.Query;
 import org.hibernate.QueryException;
 import org.hibernate.ReplicationMode;
 import org.hibernate.SQLQuery;
 import org.hibernate.ScrollMode;
 import org.hibernate.ScrollableResults;
 import org.hibernate.Session;
 import org.hibernate.SessionBuilder;
 import org.hibernate.SessionEventListener;
 import org.hibernate.SessionException;
 import org.hibernate.SharedSessionBuilder;
 import org.hibernate.SimpleNaturalIdLoadAccess;
 import org.hibernate.Transaction;
 import org.hibernate.TransientObjectException;
 import org.hibernate.TypeHelper;
 import org.hibernate.UnknownProfileException;
 import org.hibernate.UnresolvableObjectException;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.criterion.NaturalIdentifier;
 import org.hibernate.engine.internal.SessionEventListenerManagerImpl;
 import org.hibernate.engine.internal.StatefulPersistenceContext;
 import org.hibernate.engine.jdbc.LobCreator;
 import org.hibernate.engine.jdbc.NonContextualLobCreator;
 import org.hibernate.engine.query.spi.FilterQueryPlan;
 import org.hibernate.engine.query.spi.HQLQueryPlan;
 import org.hibernate.engine.query.spi.NativeSQLQueryPlan;
 import org.hibernate.engine.query.spi.sql.NativeSQLQuerySpecification;
 import org.hibernate.engine.spi.ActionQueue;
 import org.hibernate.engine.spi.CollectionEntry;
 import org.hibernate.engine.spi.EntityEntry;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.PersistenceContext;
 import org.hibernate.engine.spi.QueryParameters;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionOwner;
 import org.hibernate.engine.spi.Status;
 import org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl;
 import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.engine.transaction.spi.TransactionImplementor;
 import org.hibernate.engine.transaction.spi.TransactionObserver;
 import org.hibernate.event.service.spi.EventListenerGroup;
 import org.hibernate.event.service.spi.EventListenerRegistry;
 import org.hibernate.event.spi.AutoFlushEvent;
 import org.hibernate.event.spi.AutoFlushEventListener;
 import org.hibernate.event.spi.ClearEvent;
 import org.hibernate.event.spi.ClearEventListener;
 import org.hibernate.event.spi.DeleteEvent;
 import org.hibernate.event.spi.DeleteEventListener;
 import org.hibernate.event.spi.DirtyCheckEvent;
 import org.hibernate.event.spi.DirtyCheckEventListener;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.event.spi.EventType;
 import org.hibernate.event.spi.EvictEvent;
 import org.hibernate.event.spi.EvictEventListener;
 import org.hibernate.event.spi.FlushEvent;
 import org.hibernate.event.spi.FlushEventListener;
 import org.hibernate.event.spi.InitializeCollectionEvent;
 import org.hibernate.event.spi.InitializeCollectionEventListener;
 import org.hibernate.event.spi.LoadEvent;
 import org.hibernate.event.spi.LoadEventListener;
 import org.hibernate.event.spi.LoadEventListener.LoadType;
 import org.hibernate.event.spi.LockEvent;
 import org.hibernate.event.spi.LockEventListener;
 import org.hibernate.event.spi.MergeEvent;
 import org.hibernate.event.spi.MergeEventListener;
 import org.hibernate.event.spi.PersistEvent;
 import org.hibernate.event.spi.PersistEventListener;
 import org.hibernate.event.spi.RefreshEvent;
 import org.hibernate.event.spi.RefreshEventListener;
 import org.hibernate.event.spi.ReplicateEvent;
 import org.hibernate.event.spi.ReplicateEventListener;
 import org.hibernate.event.spi.ResolveNaturalIdEvent;
 import org.hibernate.event.spi.ResolveNaturalIdEventListener;
 import org.hibernate.event.spi.SaveOrUpdateEvent;
 import org.hibernate.event.spi.SaveOrUpdateEventListener;
 import org.hibernate.internal.CriteriaImpl.CriterionEntry;
 import org.hibernate.jdbc.ReturningWork;
 import org.hibernate.jdbc.Work;
 import org.hibernate.jdbc.WorkExecutor;
 import org.hibernate.jdbc.WorkExecutorVisitable;
 import org.hibernate.loader.criteria.CriteriaLoader;
 import org.hibernate.loader.custom.CustomLoader;
 import org.hibernate.loader.custom.CustomQuery;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.pretty.MessageHelper;
 import org.hibernate.procedure.ProcedureCall;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.LazyInitializer;
 import org.hibernate.stat.SessionStatistics;
 import org.hibernate.stat.internal.SessionStatisticsImpl;
 import org.hibernate.type.Type;
 import org.jboss.logging.Logger;
 
 /**
  * Concrete implementation of a Session.
  *
  * Exposes two interfaces:<ul>
  *     <li>{@link Session} to the application</li>
  *     <li>{@link org.hibernate.engine.spi.SessionImplementor} to other Hibernate components (SPI)</li>
  * </ul>
  *
  * This class is not thread-safe.
  *
  * @author Gavin King
  * @author Steve Ebersole
  * @author Brett Meyer
  */
 public final class SessionImpl extends AbstractSessionImpl implements EventSource {
 
 	// todo : need to find a clean way to handle the "event source" role
 	// a separate class responsible for generating/dispatching events just duplicates most of the Session methods...
 	// passing around separate interceptor, factory, actionQueue, and persistentContext is not manageable...
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SessionImpl.class.getName());
 
-   private static final boolean tracing = LOG.isTraceEnabled();
+   private static final boolean TRACE_ENABLED = LOG.isTraceEnabled();
 
 	private transient long timestamp;
 
 	private transient SessionOwner sessionOwner;
 
 	private transient ActionQueue actionQueue;
 	private transient StatefulPersistenceContext persistenceContext;
 	private transient TransactionCoordinatorImpl transactionCoordinator;
 	private transient Interceptor interceptor;
 	private transient EntityNameResolver entityNameResolver = new CoordinatingEntityNameResolver();
 
 	private transient ConnectionReleaseMode connectionReleaseMode;
 	private transient FlushMode flushMode = FlushMode.AUTO;
 	private transient CacheMode cacheMode = CacheMode.NORMAL;
 
 	private transient boolean autoClear; //for EJB3
 	private transient boolean autoJoinTransactions = true;
 	private transient boolean flushBeforeCompletionEnabled;
 	private transient boolean autoCloseSessionEnabled;
 
-	private transient int dontFlushFromFind = 0;
+	private transient int dontFlushFromFind;
 
 	private transient LoadQueryInfluencers loadQueryInfluencers;
 
 	private final transient boolean isTransactionCoordinatorShared;
 	private transient TransactionObserver transactionObserver;
 
 	private SessionEventListenerManagerImpl sessionEventsManager = new SessionEventListenerManagerImpl();
 
 	/**
 	 * Constructor used for openSession(...) processing, as well as construction
 	 * of sessions for getCurrentSession().
 	 *
 	 * @param connection The user-supplied connection to use for this session.
 	 * @param factory The factory from which this session was obtained
 	 * @param transactionCoordinator The transaction coordinator to use, may be null to indicate that a new transaction
 	 * coordinator should get created.
 	 * @param autoJoinTransactions Should the session automatically join JTA transactions?
 	 * @param timestamp The timestamp for this session
 	 * @param interceptor The interceptor to be applied to this session
 	 * @param flushBeforeCompletionEnabled Should we auto flush before completion of transaction
 	 * @param autoCloseSessionEnabled Should we auto close after completion of transaction
 	 * @param connectionReleaseMode The mode by which we should release JDBC connections.
 	 * @param tenantIdentifier The tenant identifier to use.  May be null
 	 */
 	SessionImpl(
 			final Connection connection,
 			final SessionFactoryImpl factory,
 			final SessionOwner sessionOwner,
 			final TransactionCoordinatorImpl transactionCoordinator,
 			final boolean autoJoinTransactions,
 			final long timestamp,
 			final Interceptor interceptor,
 			final boolean flushBeforeCompletionEnabled,
 			final boolean autoCloseSessionEnabled,
 			final ConnectionReleaseMode connectionReleaseMode,
 			final String tenantIdentifier) {
 		super( factory, tenantIdentifier );
 		this.timestamp = timestamp;
 		this.sessionOwner = sessionOwner;
 		this.interceptor = interceptor == null ? EmptyInterceptor.INSTANCE : interceptor;
 		this.actionQueue = new ActionQueue( this );
 		this.persistenceContext = new StatefulPersistenceContext( this );
 
 		this.autoCloseSessionEnabled = autoCloseSessionEnabled;
 		this.flushBeforeCompletionEnabled = flushBeforeCompletionEnabled;
 
 		if ( transactionCoordinator == null ) {
 			this.isTransactionCoordinatorShared = false;
 			this.connectionReleaseMode = connectionReleaseMode;
 			this.autoJoinTransactions = autoJoinTransactions;
 
 			this.transactionCoordinator = new TransactionCoordinatorImpl( connection, this );
 			this.transactionCoordinator.getJdbcCoordinator().getLogicalConnection().addObserver(
 					new ConnectionObserverStatsBridge( factory )
 			);
 		}
 		else {
 			if ( connection != null ) {
 				throw new SessionException( "Cannot simultaneously share transaction context and specify connection" );
 			}
 			this.transactionCoordinator = transactionCoordinator;
 			this.isTransactionCoordinatorShared = true;
 			this.autoJoinTransactions = false;
 			if ( autoJoinTransactions ) {
 				LOG.debug(
 						"Session creation specified 'autoJoinTransactions', which is invalid in conjunction " +
 								"with sharing JDBC connection between sessions; ignoring"
 				);
 			}
 			if ( connectionReleaseMode != transactionCoordinator.getJdbcCoordinator().getLogicalConnection().getConnectionReleaseMode() ) {
 				LOG.debug(
 						"Session creation specified 'connectionReleaseMode', which is invalid in conjunction " +
 								"with sharing JDBC connection between sessions; ignoring"
 				);
 			}
 			this.connectionReleaseMode = transactionCoordinator.getJdbcCoordinator().getLogicalConnection().getConnectionReleaseMode();
 
 			// add a transaction observer so that we can handle delegating managed actions back to THIS session
 			// versus the session that created (and therefore "owns") the transaction coordinator
 			transactionObserver = new TransactionObserver() {
 				@Override
 				public void afterBegin(TransactionImplementor transaction) {
 				}
 
 				@Override
 				public void beforeCompletion(TransactionImplementor transaction) {
 					if ( isOpen() && flushBeforeCompletionEnabled ) {
 						SessionImpl.this.managedFlush();
 					}
 					beforeTransactionCompletion( transaction );
 				}
 
 				@Override
 				public void afterCompletion(boolean successful, TransactionImplementor transaction) {
 					afterTransactionCompletion( transaction, successful );
 					if ( isOpen() && autoCloseSessionEnabled ) {
 						managedClose();
 					}
 					transactionCoordinator.removeObserver( this );
 				}
 			};
 
 			transactionCoordinator.addObserver( transactionObserver );
 		}
 
 		loadQueryInfluencers = new LoadQueryInfluencers( factory );
 
 		if (factory.getStatistics().isStatisticsEnabled()) {
 			factory.getStatisticsImplementor().openSession();
 		}
 
-      if (tracing)
+      if ( TRACE_ENABLED )
 		   LOG.tracef( "Opened session at timestamp: %s", timestamp );
 	}
 
 	@Override
 	public SharedSessionBuilder sessionWithOptions() {
 		return new SharedSessionBuilderImpl( this );
 	}
 
 	public void clear() {
 		errorIfClosed();
 		// Do not call checkTransactionSynchStatus() here -- if a delayed
 		// afterCompletion exists, it can cause an infinite loop.
 		pulseTransactionCoordinator();
 		internalClear();
 	}
 
 	private void internalClear() {
 		persistenceContext.clear();
 		actionQueue.clear();
 
 		final ClearEvent event = new ClearEvent( this );
 		for ( ClearEventListener listener : listeners( EventType.CLEAR ) ) {
 			listener.onClear( event );
 		}
 	}
 
 	public long getTimestamp() {
 		checkTransactionSynchStatus();
 		return timestamp;
 	}
 
 	public Connection close() throws HibernateException {
 		LOG.trace( "Closing session" );
 		if ( isClosed() ) {
 			throw new SessionException( "Session was already closed" );
 		}
 
 		if ( factory.getStatistics().isStatisticsEnabled() ) {
 			factory.getStatisticsImplementor().closeSession();
 		}
 		getEventListenerManager().end();
 
 		try {
 			if ( !isTransactionCoordinatorShared ) {
 				return transactionCoordinator.close();
 			}
 			else {
 				if ( getActionQueue().hasAfterTransactionActions() ){
 					LOG.warn( "On close, shared Session had after transaction actions that have not yet been processed" );
 				}
 				else {
 					transactionCoordinator.removeObserver( transactionObserver );
 				}
 				return null;
 			}
 		}
 		finally {
 			setClosed();
 			cleanup();
 		}
 	}
 
 	public ConnectionReleaseMode getConnectionReleaseMode() {
 		return connectionReleaseMode;
 	}
 
 	@Override
 	public boolean shouldAutoJoinTransaction() {
 		return autoJoinTransactions;
 	}
 
 	public boolean isAutoCloseSessionEnabled() {
 		return autoCloseSessionEnabled;
 	}
 
 	public boolean isOpen() {
 		checkTransactionSynchStatus();
 		return !isClosed();
 	}
 
 	public boolean isFlushModeNever() {
 		return FlushMode.isManualFlushMode( getFlushMode() );
 	}
 
 	public boolean isFlushBeforeCompletionEnabled() {
 		return flushBeforeCompletionEnabled;
 	}
 
 	public void managedFlush() {
 		if ( isClosed() ) {
 			LOG.trace( "Skipping auto-flush due to session closed" );
 			return;
 		}
 		LOG.trace( "Automatically flushing session" );
 		flush();
 	}
 
 	@Override
 	public boolean shouldAutoClose() {
 		if ( isClosed() ) {
 			return false;
 		}
 		else if ( sessionOwner != null ) {
 			return sessionOwner.shouldAutoCloseSession();
 		}
 		else {
 			return isAutoCloseSessionEnabled();
 		}
 	}
 
 	public void managedClose() {
 		LOG.trace( "Automatically closing session" );
 		close();
 	}
 
 	public Connection connection() throws HibernateException {
 		errorIfClosed();
 		return transactionCoordinator.getJdbcCoordinator().getLogicalConnection().getConnection();
 	}
 
 	public boolean isConnected() {
 		checkTransactionSynchStatus();
 		return !isClosed() && transactionCoordinator.getJdbcCoordinator().getLogicalConnection().isOpen();
 	}
 
 	public boolean isTransactionInProgress() {
 		checkTransactionSynchStatus();
 		return !isClosed() && transactionCoordinator.isTransactionInProgress();
 	}
 
 	@Override
 	public Connection disconnect() throws HibernateException {
 		errorIfClosed();
 		LOG.debug( "Disconnecting session" );
 		transactionCoordinator.getJdbcCoordinator().releaseResources();
 		return transactionCoordinator.getJdbcCoordinator().getLogicalConnection().manualDisconnect();
 	}
 
 	@Override
 	public void reconnect(Connection conn) throws HibernateException {
 		errorIfClosed();
 		LOG.debug( "Reconnecting session" );
 		checkTransactionSynchStatus();
 		transactionCoordinator.getJdbcCoordinator().getLogicalConnection().manualReconnect( conn );
 	}
 
 	public void setAutoClear(boolean enabled) {
 		errorIfClosed();
 		autoClear = enabled;
 	}
 
 	@Override
 	public void disableTransactionAutoJoin() {
 		errorIfClosed();
 		autoJoinTransactions = false;
 	}
 
 	/**
 	 * Check if there is a Hibernate or JTA transaction in progress and,
 	 * if there is not, flush if necessary, make sure the connection has
 	 * been committed (if it is not in autocommit mode) and run the after
 	 * completion processing
 	 *
 	 * @param success Was the operation a success
 	 */
 	public void afterOperation(boolean success) {
 		if ( ! transactionCoordinator.isTransactionInProgress() ) {
 			transactionCoordinator.afterNonTransactionalQuery( success );
 		}
 	}
 
 	@Override
 	public void afterTransactionBegin(TransactionImplementor hibernateTransaction) {
 		errorIfClosed();
 		interceptor.afterTransactionBegin( hibernateTransaction );
 	}
 
 	@Override
 	public void beforeTransactionCompletion(TransactionImplementor hibernateTransaction) {
 		LOG.trace( "before transaction completion" );
 		actionQueue.beforeTransactionCompletion();
 		try {
 			interceptor.beforeTransactionCompletion( hibernateTransaction );
 		}
 		catch (Throwable t) {
 			LOG.exceptionInBeforeTransactionCompletionInterceptor( t );
 		}
 	}
 
 	@Override
 	public void afterTransactionCompletion(TransactionImplementor hibernateTransaction, boolean successful) {
 		LOG.trace( "after transaction completion" );
 		persistenceContext.afterTransactionCompletion();
 		actionQueue.afterTransactionCompletion( successful );
 
 		getEventListenerManager().transactionCompletion( successful );
 
 		try {
 			interceptor.afterTransactionCompletion( hibernateTransaction );
 		}
 		catch (Throwable t) {
 			LOG.exceptionInAfterTransactionCompletionInterceptor( t );
 		}
 
 		if ( autoClear ) {
 			internalClear();
 		}
 	}
 
 	@Override
 	public String onPrepareStatement(String sql) {
 		errorIfClosed();
 		sql = interceptor.onPrepareStatement( sql );
 		if ( sql == null || sql.length() == 0 ) {
 			throw new AssertionFailure( "Interceptor.onPrepareStatement() returned null or empty string." );
 		}
 		return sql;
 	}
 
 	@Override
 	public SessionEventListenerManagerImpl getEventListenerManager() {
 		return sessionEventsManager;
 	}
 
 	@Override
 	public void addEventListeners(SessionEventListener... listeners) {
 		getEventListenerManager().addListener( listeners );
 	}
 
 	@Override
 	public void startPrepareStatement() {
 		getEventListenerManager().jdbcPrepareStatementStart();
 	}
 
 	@Override
 	public void endPrepareStatement() {
 		getEventListenerManager().jdbcPrepareStatementEnd();
 	}
 
 	@Override
 	public void startStatementExecution() {
 		getEventListenerManager().jdbcExecuteStatementStart();
 	}
 
 	@Override
 	public void endStatementExecution() {
 		getEventListenerManager().jdbcExecuteStatementEnd();
 	}
 
 	@Override
 	public void startBatchExecution() {
 		getEventListenerManager().jdbcExecuteBatchStart();
 	}
 
 	@Override
 	public void endBatchExecution() {
 		getEventListenerManager().jdbcExecuteBatchEnd();
 	}
 
 	/**
 	 * clear all the internal collections, just
 	 * to help the garbage collector, does not
 	 * clear anything that is needed during the
 	 * afterTransactionCompletion() phase
 	 */
 	private void cleanup() {
 		persistenceContext.clear();
 	}
 
 	public LockMode getCurrentLockMode(Object object) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		if ( object == null ) {
 			throw new NullPointerException( "null object passed to getCurrentLockMode()" );
 		}
 		if ( object instanceof HibernateProxy ) {
 			object = ( (HibernateProxy) object ).getHibernateLazyInitializer().getImplementation(this);
 			if ( object == null ) {
 				return LockMode.NONE;
 			}
 		}
 		EntityEntry e = persistenceContext.getEntry(object);
 		if ( e == null ) {
 			throw new TransientObjectException( "Given object not associated with the session" );
 		}
 		if ( e.getStatus() != Status.MANAGED ) {
 			throw new ObjectDeletedException(
 					"The given object was deleted",
 					e.getId(),
 					e.getPersister().getEntityName()
 				);
 		}
 		return e.getLockMode();
 	}
 
 	public Object getEntityUsingInterceptor(EntityKey key) throws HibernateException {
 		errorIfClosed();
 		// todo : should this get moved to PersistentContext?
 		// logically, is PersistentContext the "thing" to which an interceptor gets attached?
 		final Object result = persistenceContext.getEntity(key);
 		if ( result == null ) {
 			final Object newObject = interceptor.getEntity( key.getEntityName(), key.getIdentifier() );
 			if ( newObject != null ) {
 				lock( newObject, LockMode.NONE );
 			}
 			return newObject;
 		}
 		else {
 			return result;
 		}
 	}
 
 	private void checkNoUnresolvedActionsBeforeOperation() {
 		if ( persistenceContext.getCascadeLevel() == 0 && actionQueue.hasUnresolvedEntityInsertActions() ) {
 			throw new IllegalStateException( "There are delayed insert actions before operation as cascade level 0." );
 		}
 	}
 
 	private void checkNoUnresolvedActionsAfterOperation() {
 		if ( persistenceContext.getCascadeLevel() == 0 ) {
 			actionQueue.checkNoUnresolvedActionsAfterOperation();
 		}
 		delayedAfterCompletion();
 	}
 	
 	private void delayedAfterCompletion() {
 		transactionCoordinator.getSynchronizationCallbackCoordinator().processAnyDelayedAfterCompletion();
 	}
 
 	// saveOrUpdate() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void saveOrUpdate(Object object) throws HibernateException {
 		saveOrUpdate( null, object );
 	}
 
 	public void saveOrUpdate(String entityName, Object obj) throws HibernateException {
 		fireSaveOrUpdate( new SaveOrUpdateEvent( entityName, obj, this ) );
 	}
 
 	private void fireSaveOrUpdate(SaveOrUpdateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( SaveOrUpdateEventListener listener : listeners( EventType.SAVE_UPDATE ) ) {
 			listener.onSaveOrUpdate( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 	}
 
 	private <T> Iterable<T> listeners(EventType<T> type) {
 		return eventListenerGroup( type ).listeners();
 	}
 
 	private <T> EventListenerGroup<T> eventListenerGroup(EventType<T> type) {
 		return factory.getServiceRegistry().getService( EventListenerRegistry.class ).getEventListenerGroup( type );
 	}
 
 
 	// save() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public Serializable save(Object obj) throws HibernateException {
 		return save( null, obj );
 	}
 
 	public Serializable save(String entityName, Object object) throws HibernateException {
 		return fireSave( new SaveOrUpdateEvent( entityName, object, this ) );
 	}
 
 	private Serializable fireSave(SaveOrUpdateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( SaveOrUpdateEventListener listener : listeners( EventType.SAVE ) ) {
 			listener.onSaveOrUpdate( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 		return event.getResultId();
 	}
 
 
 	// update() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void update(Object obj) throws HibernateException {
 		update( null, obj );
 	}
 
 	public void update(String entityName, Object object) throws HibernateException {
 		fireUpdate( new SaveOrUpdateEvent( entityName, object, this ) );
 	}
 
 	private void fireUpdate(SaveOrUpdateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( SaveOrUpdateEventListener listener : listeners( EventType.UPDATE ) ) {
 			listener.onSaveOrUpdate( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 	}
 
 
 	// lock() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void lock(String entityName, Object object, LockMode lockMode) throws HibernateException {
 		fireLock( new LockEvent( entityName, object, lockMode, this ) );
 	}
 
 	public LockRequest buildLockRequest(LockOptions lockOptions) {
 		return new LockRequestImpl(lockOptions);
 	}
 
 	public void lock(Object object, LockMode lockMode) throws HibernateException {
 		fireLock( new LockEvent( object, lockMode, this ) );
 	}
 
 	private void fireLock(String entityName, Object object, LockOptions options) {
 		fireLock( new LockEvent( entityName, object, options, this) );
 	}
 
 	private void fireLock( Object object, LockOptions options) {
 		fireLock( new LockEvent( object, options, this ) );
 	}
 
 	private void fireLock(LockEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( LockEventListener listener : listeners( EventType.LOCK ) ) {
 			listener.onLock( event );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// persist() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void persist(String entityName, Object object) throws HibernateException {
 		firePersist( new PersistEvent( entityName, object, this ) );
 	}
 
 	public void persist(Object object) throws HibernateException {
 		persist( null, object );
 	}
 
 	public void persist(String entityName, Object object, Map copiedAlready)
 	throws HibernateException {
 		firePersist( copiedAlready, new PersistEvent( entityName, object, this ) );
 	}
 
 	private void firePersist(Map copiedAlready, PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST ) ) {
 			listener.onPersist( event, copiedAlready );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void firePersist(PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST ) ) {
 			listener.onPersist( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 	}
 
 
 	// persistOnFlush() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void persistOnFlush(String entityName, Object object)
 			throws HibernateException {
 		firePersistOnFlush( new PersistEvent( entityName, object, this ) );
 	}
 
 	public void persistOnFlush(Object object) throws HibernateException {
 		persist( null, object );
 	}
 
 	public void persistOnFlush(String entityName, Object object, Map copiedAlready)
 			throws HibernateException {
 		firePersistOnFlush( copiedAlready, new PersistEvent( entityName, object, this ) );
 	}
 
 	private void firePersistOnFlush(Map copiedAlready, PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST_ONFLUSH ) ) {
 			listener.onPersist( event, copiedAlready );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void firePersistOnFlush(PersistEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( PersistEventListener listener : listeners( EventType.PERSIST_ONFLUSH ) ) {
 			listener.onPersist( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 	}
 
 
 	// merge() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public Object merge(String entityName, Object object) throws HibernateException {
 		return fireMerge( new MergeEvent( entityName, object, this ) );
 	}
 
 	public Object merge(Object object) throws HibernateException {
 		return merge( null, object );
 	}
 
 	public void merge(String entityName, Object object, Map copiedAlready) throws HibernateException {
 		fireMerge( copiedAlready, new MergeEvent( entityName, object, this ) );
 	}
 
 	private Object fireMerge(MergeEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		checkNoUnresolvedActionsBeforeOperation();
 		for ( MergeEventListener listener : listeners( EventType.MERGE ) ) {
 			listener.onMerge( event );
 		}
 		checkNoUnresolvedActionsAfterOperation();
 		return event.getResult();
 	}
 
 	private void fireMerge(Map copiedAlready, MergeEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( MergeEventListener listener : listeners( EventType.MERGE ) ) {
 			listener.onMerge( event, copiedAlready );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// delete() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * Delete a persistent object
 	 */
 	public void delete(Object object) throws HibernateException {
 		fireDelete( new DeleteEvent( object, this ) );
 	}
 
 	/**
 	 * Delete a persistent object (by explicit entity name)
 	 */
 	public void delete(String entityName, Object object) throws HibernateException {
 		fireDelete( new DeleteEvent( entityName, object, this ) );
 	}
 
 	/**
 	 * Delete a persistent object
 	 */
 	public void delete(String entityName, Object object, boolean isCascadeDeleteEnabled, Set transientEntities) throws HibernateException {
 		fireDelete( new DeleteEvent( entityName, object, isCascadeDeleteEnabled, this ), transientEntities );
 	}
 	
 	// TODO: The removeOrphan concept is a temporary "hack" for HHH-6484.  This should be removed once action/task
 	// ordering is improved.
 	public void removeOrphanBeforeUpdates(String entityName, Object child) {
 		fireDelete( new DeleteEvent( entityName, child, false, true, this ) );
 	}
 
 	private void fireDelete(DeleteEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( DeleteEventListener listener : listeners( EventType.DELETE ) ) {
 			listener.onDelete( event );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void fireDelete(DeleteEvent event, Set transientEntities) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( DeleteEventListener listener : listeners( EventType.DELETE ) ) {
 			listener.onDelete( event, transientEntities );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// load()/get() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void load(Object object, Serializable id) throws HibernateException {
 		LoadEvent event = new LoadEvent(id, object, this);
 		fireLoad( event, LoadEventListener.RELOAD );
 	}
 
 	public Object load(Class entityClass, Serializable id) throws HibernateException {
 		return this.byId( entityClass ).getReference( id );
 	}
 
 	public Object load(String entityName, Serializable id) throws HibernateException {
 		return this.byId( entityName ).getReference( id );
 	}
 
 	public Object get(Class entityClass, Serializable id) throws HibernateException {
 		return this.byId( entityClass ).load( id );
 	}
 
 	public Object get(String entityName, Serializable id) throws HibernateException {
 		return this.byId( entityName ).load( id );
 	}
 
 	/**	
 	 * Load the data for the object with the specified id into a newly created object.
 	 * This is only called when lazily initializing a proxy.
 	 * Do NOT return a proxy.
 	 */
 	public Object immediateLoad(String entityName, Serializable id) throws HibernateException {
 		if ( LOG.isDebugEnabled() ) {
 			EntityPersister persister = getFactory().getEntityPersister(entityName);
 			LOG.debugf( "Initializing proxy: %s", MessageHelper.infoString( persister, id, getFactory() ) );
 		}
 
 		LoadEvent event = new LoadEvent(id, entityName, true, this);
 		fireLoad(event, LoadEventListener.IMMEDIATE_LOAD);
 		return event.getResult();
 	}
 
 	public Object internalLoad(String entityName, Serializable id, boolean eager, boolean nullable) throws HibernateException {
 		// todo : remove
 		LoadEventListener.LoadType type = nullable
 				? LoadEventListener.INTERNAL_LOAD_NULLABLE
 				: eager
 						? LoadEventListener.INTERNAL_LOAD_EAGER
 						: LoadEventListener.INTERNAL_LOAD_LAZY;
 		LoadEvent event = new LoadEvent(id, entityName, true, this);
 		fireLoad( event, type );
 		if ( !nullable ) {
 			UnresolvableObjectException.throwIfNull( event.getResult(), id, entityName );
 		}
 		return event.getResult();
 	}
 
 	public Object load(Class entityClass, Serializable id, LockMode lockMode) throws HibernateException {
 		return this.byId( entityClass ).with( new LockOptions( lockMode ) ).getReference( id );
 	}
 
 	public Object load(Class entityClass, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return this.byId( entityClass ).with( lockOptions ).getReference( id );
 	}
 
 	public Object load(String entityName, Serializable id, LockMode lockMode) throws HibernateException {
 		return this.byId( entityName ).with( new LockOptions( lockMode ) ).getReference( id );
 	}
 
 	public Object load(String entityName, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return this.byId( entityName ).with( lockOptions ).getReference( id );
 	}
 
 	public Object get(Class entityClass, Serializable id, LockMode lockMode) throws HibernateException {
 		return this.byId( entityClass ).with( new LockOptions( lockMode ) ).load( id );
 	}
 
 	public Object get(Class entityClass, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return this.byId( entityClass ).with( lockOptions ).load( id );
 	}
 
 	public Object get(String entityName, Serializable id, LockMode lockMode) throws HibernateException {
 		return this.byId( entityName ).with( new LockOptions( lockMode ) ).load( id );
 	}
 
 	public Object get(String entityName, Serializable id, LockOptions lockOptions) throws HibernateException {
 		return this.byId( entityName ).with( lockOptions ).load( id );
 	}
 	
 	@Override
 	public IdentifierLoadAccessImpl byId(String entityName) {
 		return new IdentifierLoadAccessImpl( entityName );
 	}
 
 	@Override
 	public IdentifierLoadAccessImpl byId(Class entityClass) {
 		return new IdentifierLoadAccessImpl( entityClass );
 	}
 
 	@Override
 	public NaturalIdLoadAccess byNaturalId(String entityName) {
 		return new NaturalIdLoadAccessImpl( entityName );
 	}
 
 	@Override
 	public NaturalIdLoadAccess byNaturalId(Class entityClass) {
 		return new NaturalIdLoadAccessImpl( entityClass );
 	}
 
 	@Override
 	public SimpleNaturalIdLoadAccess bySimpleNaturalId(String entityName) {
 		return new SimpleNaturalIdLoadAccessImpl( entityName );
 	}
 
 	@Override
 	public SimpleNaturalIdLoadAccess bySimpleNaturalId(Class entityClass) {
 		return new SimpleNaturalIdLoadAccessImpl( entityClass );
 	}
 
 	private void fireLoad(LoadEvent event, LoadType loadType) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( LoadEventListener listener : listeners( EventType.LOAD ) ) {
 			listener.onLoad( event, loadType );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void fireResolveNaturalId(ResolveNaturalIdEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( ResolveNaturalIdEventListener listener : listeners( EventType.RESOLVE_NATURAL_ID ) ) {
 			listener.onResolveNaturalId( event );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// refresh() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void refresh(Object object) throws HibernateException {
 		refresh( null, object );
 	}
 
 	@Override
 	public void refresh(String entityName, Object object) throws HibernateException {
 		fireRefresh( new RefreshEvent( entityName, object, this ) );
 	}
 
 	public void refresh(Object object, LockMode lockMode) throws HibernateException {
 		fireRefresh( new RefreshEvent( object, lockMode, this ) );
 	}
 
 	public void refresh(Object object, LockOptions lockOptions) throws HibernateException {
 		refresh( null, object, lockOptions );
 	}
 	@Override
 	public void refresh(String entityName, Object object, LockOptions lockOptions) throws HibernateException {
 		fireRefresh( new RefreshEvent( entityName, object, lockOptions, this ) );
 	}
 
 	public void refresh(String entityName, Object object, Map refreshedAlready) throws HibernateException {
 		fireRefresh( refreshedAlready, new RefreshEvent( entityName, object, this ) );
 	}
 
 	private void fireRefresh(RefreshEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( RefreshEventListener listener : listeners( EventType.REFRESH ) ) {
 			listener.onRefresh( event );
 		}
 		delayedAfterCompletion();
 	}
 
 	private void fireRefresh(Map refreshedAlready, RefreshEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( RefreshEventListener listener : listeners( EventType.REFRESH ) ) {
 			listener.onRefresh( event, refreshedAlready );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// replicate() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	public void replicate(Object obj, ReplicationMode replicationMode) throws HibernateException {
 		fireReplicate( new ReplicateEvent( obj, replicationMode, this ) );
 	}
 
 	public void replicate(String entityName, Object obj, ReplicationMode replicationMode)
 	throws HibernateException {
 		fireReplicate( new ReplicateEvent( entityName, obj, replicationMode, this ) );
 	}
 
 	private void fireReplicate(ReplicateEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( ReplicateEventListener listener : listeners( EventType.REPLICATE ) ) {
 			listener.onReplicate( event );
 		}
 		delayedAfterCompletion();
 	}
 
 
 	// evict() operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	/**
 	 * remove any hard references to the entity that are held by the infrastructure
 	 * (references held by application or other persistent instances are okay)
 	 */
 	public void evict(Object object) throws HibernateException {
 		fireEvict( new EvictEvent( object, this ) );
 	}
 
 	private void fireEvict(EvictEvent event) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		for ( EvictEventListener listener : listeners( EventType.EVICT ) ) {
 			listener.onEvict( event );
 		}
 		delayedAfterCompletion();
 	}
 
 	/**
 	 * detect in-memory changes, determine if the changes are to tables
 	 * named in the query and, if so, complete execution the flush
 	 */
 	protected boolean autoFlushIfRequired(Set querySpaces) throws HibernateException {
 		errorIfClosed();
 		if ( ! isTransactionInProgress() ) {
 			// do not auto-flush while outside a transaction
 			return false;
 		}
 		AutoFlushEvent event = new AutoFlushEvent( querySpaces, this );
 		for ( AutoFlushEventListener listener : listeners( EventType.AUTO_FLUSH ) ) {
 			listener.onAutoFlush( event );
 		}
 		return event.isFlushRequired();
 	}
 
 	public boolean isDirty() throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		LOG.debug( "Checking session dirtiness" );
 		if ( actionQueue.areInsertionsOrDeletionsQueued() ) {
 			LOG.debug( "Session dirty (scheduled updates and insertions)" );
 			return true;
 		}
 		DirtyCheckEvent event = new DirtyCheckEvent( this );
 		for ( DirtyCheckEventListener listener : listeners( EventType.DIRTY_CHECK ) ) {
 			listener.onDirtyCheck( event );
 		}
 		delayedAfterCompletion();
 		return event.isDirty();
 	}
 
 	public void flush() throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		if ( persistenceContext.getCascadeLevel() > 0 ) {
 			throw new HibernateException("Flush during cascade is dangerous");
 		}
 		FlushEvent flushEvent = new FlushEvent( this );
 		for ( FlushEventListener listener : listeners( EventType.FLUSH ) ) {
 			listener.onFlush( flushEvent );
 		}
 		delayedAfterCompletion();
 	}
 
 	public void forceFlush(EntityEntry entityEntry) throws HibernateException {
 		errorIfClosed();
 		if ( LOG.isDebugEnabled() ) {
 			LOG.debugf( "Flushing to force deletion of re-saved object: %s",
 					MessageHelper.infoString( entityEntry.getPersister(), entityEntry.getId(), getFactory() ) );
 		}
 
 		if ( persistenceContext.getCascadeLevel() > 0 ) {
 			throw new ObjectDeletedException(
 				"deleted object would be re-saved by cascade (remove deleted object from associations)",
 				entityEntry.getId(),
 				entityEntry.getPersister().getEntityName()
 			);
 		}
 
 		flush();
 	}
 
 	public List list(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		queryParameters.validateParameters();
 		
 		HQLQueryPlan plan = queryParameters.getQueryPlan();
 		if (plan == null) {
 			plan = getHQLQueryPlan( query, false );
 		}
 		
 		autoFlushIfRequired( plan.getQuerySpaces() );
 
 		List results = Collections.EMPTY_LIST;
 		boolean success = false;
 
 		dontFlushFromFind++;   //stops flush being called multiple times if this method is recursively called
 		try {
 			results = plan.performList( queryParameters, this );
 			success = true;
 		}
 		finally {
 			dontFlushFromFind--;
 			afterOperation(success);
 			delayedAfterCompletion();
 		}
 		return results;
 	}
 
 	public int executeUpdate(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		queryParameters.validateParameters();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		autoFlushIfRequired( plan.getQuerySpaces() );
 
 		boolean success = false;
 		int result = 0;
 		try {
 			result = plan.performExecuteUpdate( queryParameters, this );
 			success = true;
 		}
 		finally {
 			afterOperation(success);
 			delayedAfterCompletion();
 		}
 		return result;
 	}
 
     public int executeNativeUpdate(NativeSQLQuerySpecification nativeQuerySpecification,
             QueryParameters queryParameters) throws HibernateException {
         errorIfClosed();
         checkTransactionSynchStatus();
         queryParameters.validateParameters();
         NativeSQLQueryPlan plan = getNativeSQLQueryPlan( nativeQuerySpecification );
 
 
         autoFlushIfRequired( plan.getCustomQuery().getQuerySpaces() );
 
         boolean success = false;
         int result = 0;
         try {
             result = plan.performExecuteUpdate(queryParameters, this);
             success = true;
         } finally {
             afterOperation(success);
     		delayedAfterCompletion();
         }
         return result;
     }
 
 	public Iterator iterate(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		queryParameters.validateParameters();
 		HQLQueryPlan plan = getHQLQueryPlan( query, true );
 		autoFlushIfRequired( plan.getQuerySpaces() );
 
 		dontFlushFromFind++; //stops flush being called multiple times if this method is recursively called
 		try {
 			return plan.performIterate( queryParameters, this );
 		}
 		finally {
 			delayedAfterCompletion();
 			dontFlushFromFind--;
 		}
 	}
 
 	public ScrollableResults scroll(String query, QueryParameters queryParameters) throws HibernateException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		HQLQueryPlan plan = getHQLQueryPlan( query, false );
 		autoFlushIfRequired( plan.getQuerySpaces() );
 		dontFlushFromFind++;
 		try {
 			return plan.performScroll( queryParameters, this );
 		}
 		finally {
 			delayedAfterCompletion();
 			dontFlushFromFind--;
 		}
 	}
 
 	public Query createFilter(Object collection, String queryString) {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		CollectionFilterImpl filter = new CollectionFilterImpl(
 				queryString,
 		        collection,
 		        this,
 		        getFilterQueryPlan( collection, queryString, null, false ).getParameterMetadata()
 		);
 		filter.setComment( queryString );
 		delayedAfterCompletion();
 		return filter;
 	}
 
 	public Query getNamedQuery(String queryName) throws MappingException {
 		errorIfClosed();
 		checkTransactionSynchStatus();
 		Query query = super.getNamedQuery( queryName );
 		delayedAfterCompletion();
 		return query;
 	}
 
 	public Object instantiate(String entityName, Serializable id) throws HibernateException {
 		return instantiate( factory.getEntityPersister( entityName ), id );
 	}
 
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/ClassLoaderHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/ClassLoaderHelper.java
index 78e2f85826..f45e9e633c 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/ClassLoaderHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/ClassLoaderHelper.java
@@ -1,38 +1,40 @@
 /* 
  * Hibernate, Relational Persistence for Idiomatic Java
  * 
  * JBoss, Home of Professional Open Source
  * Copyright 2013 Red Hat Inc. and/or its affiliates and other contributors
  * as indicated by the @authors tag. All rights reserved.
  * See the copyright.txt in the distribution for a
  * full listing of individual contributors.
  *
  * This copyrighted material is made available to anyone wishing to use,
  * modify, copy, or redistribute it subject to the terms and conditions
  * of the GNU Lesser General Public License, v. 2.1.
  * This program is distributed in the hope that it will be useful, but WITHOUT A
  * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
  * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
  * You should have received a copy of the GNU Lesser General Public License,
  * v.2.1 along with this distribution; if not, write to the Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
  * MA  02110-1301, USA.
  */
 package org.hibernate.internal.util;
 
 /**
  * This exists purely to allow custom ClassLoaders to be injected and used
  * prior to ServiceRegistry and ClassLoadingService existence.  This should be
  * replaced in Hibernate 5.
  * 
  * @author Brett Meyer
  */
-public class ClassLoaderHelper {
-	
-	public static ClassLoader overridenClassLoader = null;
+public final class ClassLoaderHelper {
+	private ClassLoaderHelper() {
+	}
+
+	public static ClassLoader overridenClassLoader;
 	
 	public static ClassLoader getContextClassLoader() {
 		return overridenClassLoader != null ?
 			overridenClassLoader : Thread.currentThread().getContextClassLoader();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/JdbcExceptionHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/JdbcExceptionHelper.java
index 5f6cb551f2..a8bb185663 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/JdbcExceptionHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/JdbcExceptionHelper.java
@@ -1,57 +1,60 @@
 package org.hibernate.internal.util;
 
 import java.sql.SQLException;
 
 /**
  * @author Steve Ebersole
  */
-public class JdbcExceptionHelper {
+public final class JdbcExceptionHelper {
+	private JdbcExceptionHelper() {
+	}
+
 	/**
 	 * For the given SQLException, locates the vendor-specific error code.
 	 *
 	 * @param sqlException The exception from which to extract the SQLState
 	 * @return The error code.
 	 */
 	public static int extractErrorCode(SQLException sqlException) {
 		int errorCode = sqlException.getErrorCode();
 		SQLException nested = sqlException.getNextException();
 		while ( errorCode == 0 && nested != null ) {
 			errorCode = nested.getErrorCode();
 			nested = nested.getNextException();
 		}
 		return errorCode;
 	}
 
 	/**
 	 * For the given SQLException, locates the X/Open-compliant SQLState.
 	 *
 	 * @param sqlException The exception from which to extract the SQLState
 	 * @return The SQLState code, or null.
 	 */
 	public static String extractSqlState(SQLException sqlException) {
 		String sqlState = sqlException.getSQLState();
 		SQLException nested = sqlException.getNextException();
 		while ( sqlState == null && nested != null ) {
 			sqlState = nested.getSQLState();
 			nested = nested.getNextException();
 		}
 		return sqlState;
 	}
 
 	/**
 	 * For the given SQLException, locates the X/Open-compliant SQLState's class code.
 	 *
 	 * @param sqlException The exception from which to extract the SQLState class code
 	 * @return The SQLState class code, or null.
 	 */
 	public static String extractSqlStateClassCode(SQLException sqlException) {
 		return determineSqlStateClassCode( extractSqlState( sqlException ) );
 	}
 
 	public static String determineSqlStateClassCode(String sqlState) {
 		if ( sqlState == null || sqlState.length() < 2 ) {
 			return sqlState;
 		}
 		return sqlState.substring( 0, 2 );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/LockModeConverter.java b/hibernate-core/src/main/java/org/hibernate/internal/util/LockModeConverter.java
index fb4362a0ac..d22d4d5be6 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/LockModeConverter.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/LockModeConverter.java
@@ -1,106 +1,109 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util;
 
 import javax.persistence.LockModeType;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.LockMode;
 
 /**
  * Helper to deal with conversions (both directions) between {@link org.hibernate.LockMode} and
  * {@link javax.persistence.LockModeType}.
  *
  * @author Steve Ebersole
  */
-public class LockModeConverter {
+public final class LockModeConverter {
+	private LockModeConverter() {
+	}
+
 	/**
 	 * Convert from the Hibernate specific LockMode to the JPA defined LockModeType.
 	 *
 	 * @param lockMode The Hibernate LockMode.
 	 *
 	 * @return The JPA LockModeType
 	 */
 	public static LockModeType convertToLockModeType(LockMode lockMode) {
 		if ( lockMode == LockMode.NONE ) {
 			return LockModeType.NONE;
 		}
 		else if ( lockMode == LockMode.OPTIMISTIC || lockMode == LockMode.READ ) {
 			return LockModeType.OPTIMISTIC;
 		}
 		else if ( lockMode == LockMode.OPTIMISTIC_FORCE_INCREMENT || lockMode == LockMode.WRITE ) {
 			return LockModeType.OPTIMISTIC_FORCE_INCREMENT;
 		}
 		else if ( lockMode == LockMode.PESSIMISTIC_READ ) {
 			return LockModeType.PESSIMISTIC_READ;
 		}
 		else if ( lockMode == LockMode.PESSIMISTIC_WRITE
 				|| lockMode == LockMode.UPGRADE
 				|| lockMode == LockMode.UPGRADE_NOWAIT
                 || lockMode == LockMode.UPGRADE_SKIPLOCKED) {
 			return LockModeType.PESSIMISTIC_WRITE;
 		}
 		else if ( lockMode == LockMode.PESSIMISTIC_FORCE_INCREMENT
 				|| lockMode == LockMode.FORCE ) {
 			return LockModeType.PESSIMISTIC_FORCE_INCREMENT;
 		}
 		throw new AssertionFailure( "unhandled lock mode " + lockMode );
 	}
 
 
 	/**
 	 * Convert from JPA defined LockModeType to Hibernate specific LockMode.
 	 *
 	 * @param lockMode The JPA LockModeType
 	 *
 	 * @return The Hibernate LockMode.
 	 */
 	public static LockMode convertToLockMode(LockModeType lockMode) {
 		switch ( lockMode ) {
 			case READ:
 			case OPTIMISTIC: {
 				return LockMode.OPTIMISTIC;
 			}
 			case OPTIMISTIC_FORCE_INCREMENT:
 			case WRITE: {
 				return LockMode.OPTIMISTIC_FORCE_INCREMENT;
 			}
 			case PESSIMISTIC_READ: {
 				return LockMode.PESSIMISTIC_READ;
 			}
 			case PESSIMISTIC_WRITE: {
 				return LockMode.PESSIMISTIC_WRITE;
 			}
 			case PESSIMISTIC_FORCE_INCREMENT: {
 				return LockMode.PESSIMISTIC_FORCE_INCREMENT;
 			}
 			case NONE: {
 				return LockMode.NONE;
 			}
 			default: {
 				throw new AssertionFailure( "Unknown LockModeType: " + lockMode );
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/StringHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/StringHelper.java
index b69554fd52..0be2b8d234 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/StringHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/StringHelper.java
@@ -1,786 +1,786 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal.util;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.BitSet;
 import java.util.Iterator;
 import java.util.Locale;
 import java.util.StringTokenizer;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.internal.util.collections.ArrayHelper;
 
 public final class StringHelper {
 
 	private static final int ALIAS_TRUNCATE_LENGTH = 10;
 	public static final String WHITESPACE = " \n\r\f\t";
 
 	private StringHelper() { /* static methods only - hide constructor */
 	}
 	
 	/*public static boolean containsDigits(String string) {
 		for ( int i=0; i<string.length(); i++ ) {
 			if ( Character.isDigit( string.charAt(i) ) ) return true;
 		}
 		return false;
 	}*/
 
 	public static int lastIndexOfLetter(String string) {
 		for ( int i=0; i<string.length(); i++ ) {
 			char character = string.charAt(i);
 			// Include "_".  See HHH-8073
 			if ( !Character.isLetter(character) && !('_'==character) ) return i-1;
 		}
 		return string.length()-1;
 	}
 
 	public static String join(String seperator, String[] strings) {
 		int length = strings.length;
 		if ( length == 0 ) return "";
 		StringBuilder buf = new StringBuilder( length * strings[0].length() )
 				.append( strings[0] );
 		for ( int i = 1; i < length; i++ ) {
 			buf.append( seperator ).append( strings[i] );
 		}
 		return buf.toString();
 	}
 
 	public static String joinWithQualifier(String[] values, String qualifier, String deliminator) {
 		int length = values.length;
 		if ( length == 0 ) return "";
 		StringBuilder buf = new StringBuilder( length * values[0].length() )
 				.append( qualify( qualifier, values[0] ) );
 		for ( int i = 1; i < length; i++ ) {
 			buf.append( deliminator ).append( qualify( qualifier, values[i] ) );
 		}
 		return buf.toString();
 	}
 
 	public static String join(String seperator, Iterator objects) {
 		StringBuilder buf = new StringBuilder();
 		if ( objects.hasNext() ) buf.append( objects.next() );
 		while ( objects.hasNext() ) {
 			buf.append( seperator ).append( objects.next() );
 		}
 		return buf.toString();
 	}
 
 	public static String[] add(String[] x, String sep, String[] y) {
 		final String[] result = new String[x.length];
 		for ( int i = 0; i < x.length; i++ ) {
 			result[i] = x[i] + sep + y[i];
 		}
 		return result;
 	}
 
 	public static String repeat(String string, int times) {
 		StringBuilder buf = new StringBuilder( string.length() * times );
 		for ( int i = 0; i < times; i++ ) buf.append( string );
 		return buf.toString();
 	}
 
 	public static String repeat(String string, int times, String deliminator) {
 		StringBuilder buf = new StringBuilder(  ( string.length() * times ) + ( deliminator.length() * (times-1) ) )
 				.append( string );
 		for ( int i = 1; i < times; i++ ) {
 			buf.append( deliminator ).append( string );
 		}
 		return buf.toString();
 	}
 
 	public static String repeat(char character, int times) {
 		char[] buffer = new char[times];
 		Arrays.fill( buffer, character );
 		return new String( buffer );
 	}
 
 
 	public static String replace(String template, String placeholder, String replacement) {
 		return replace( template, placeholder, replacement, false );
 	}
 
-	public static String[] replace(String templates[], String placeholder, String replacement) {
+	public static String[] replace(String[] templates, String placeholder, String replacement) {
 		String[] result = new String[templates.length];
 		for ( int i =0; i<templates.length; i++ ) {
 			result[i] = replace( templates[i], placeholder, replacement );
 		}
 		return result;
 	}
 
 	public static String replace(String template, String placeholder, String replacement, boolean wholeWords) {
 		return replace( template, placeholder, replacement, wholeWords, false );
 	}
 
 	public static String replace(String template,
 								 String placeholder,
 								 String replacement,
 								 boolean wholeWords,
 								 boolean encloseInParensIfNecessary) {
 		if ( template == null ) {
 			return template;
 		}
 		int loc = template.indexOf( placeholder );
 		if ( loc < 0 ) {
 			return template;
 		}
 		else {
 			String beforePlaceholder = template.substring( 0, loc );
 			String afterPlaceholder = template.substring( loc + placeholder.length() );
 			return replace( beforePlaceholder, afterPlaceholder, placeholder, replacement, wholeWords, encloseInParensIfNecessary );
 		}
 	}
 
 
 	public static String replace(String beforePlaceholder,
 								 String afterPlaceholder,
 								 String placeholder,
 								 String replacement,
 								 boolean wholeWords,
 								 boolean encloseInParensIfNecessary) {
 		final boolean actuallyReplace =
 				! wholeWords ||
 				afterPlaceholder.length() == 0 ||
 				! Character.isJavaIdentifierPart( afterPlaceholder.charAt( 0 ) );
 		boolean encloseInParens =
 				actuallyReplace &&
 				encloseInParensIfNecessary &&
 				! ( getLastNonWhitespaceCharacter( beforePlaceholder ) == '(' ) &&
 				! ( getFirstNonWhitespaceCharacter( afterPlaceholder ) == ')' );		
 		StringBuilder buf = new StringBuilder( beforePlaceholder );
 		if ( encloseInParens ) {
 			buf.append( '(' );
 		}
 		buf.append( actuallyReplace ? replacement : placeholder );
 		if ( encloseInParens ) {
 			buf.append( ')' );
 		}
 		buf.append(
 				replace(
 						afterPlaceholder,
 						placeholder,
 						replacement,
 						wholeWords,
 						encloseInParensIfNecessary
 				)
 		);
 		return buf.toString();
 	}
 
 	public static char getLastNonWhitespaceCharacter(String str) {
 		if ( str != null && str.length() > 0 ) {
 			for ( int i = str.length() - 1 ; i >= 0 ; i-- ) {
 				char ch = str.charAt( i );
 				if ( ! Character.isWhitespace( ch ) ) {
 					return ch;
 				}
 			}
 		}
 		return '\0';
 	}
 
 	public static char getFirstNonWhitespaceCharacter(String str) {
 		if ( str != null && str.length() > 0 ) {
 			for ( int i = 0 ; i < str.length() ; i++ ) {
 				char ch = str.charAt( i );
 				if ( ! Character.isWhitespace( ch ) ) {
 					return ch;
 				}
 			}
 		}
 		return '\0';
 	}
 
 	public static String replaceOnce(String template, String placeholder, String replacement) {
 		if ( template == null ) {
 			return template; // returnign null!
 		}
         int loc = template.indexOf( placeholder );
 		if ( loc < 0 ) {
 			return template;
 		}
 		else {
 			return new StringBuilder( template.substring( 0, loc ) )
 					.append( replacement )
 					.append( template.substring( loc + placeholder.length() ) )
 					.toString();
 		}
 	}
 
 
 	public static String[] split(String seperators, String list) {
 		return split( seperators, list, false );
 	}
 
 	public static String[] split(String seperators, String list, boolean include) {
 		StringTokenizer tokens = new StringTokenizer( list, seperators, include );
 		String[] result = new String[ tokens.countTokens() ];
 		int i = 0;
 		while ( tokens.hasMoreTokens() ) {
 			result[i++] = tokens.nextToken();
 		}
 		return result;
 	}
 
 	public static String unqualify(String qualifiedName) {
 		int loc = qualifiedName.lastIndexOf(".");
 		return ( loc < 0 ) ? qualifiedName : qualifiedName.substring( loc + 1 );
 	}
 
 	public static String qualifier(String qualifiedName) {
 		int loc = qualifiedName.lastIndexOf(".");
 		return ( loc < 0 ) ? "" : qualifiedName.substring( 0, loc );
 	}
 
 	/**
 	 * Collapses a name.  Mainly intended for use with classnames, where an example might serve best to explain.
 	 * Imagine you have a class named <samp>'org.hibernate.internal.util.StringHelper'</samp>; calling collapse on that
 	 * classname will result in <samp>'o.h.u.StringHelper'<samp>.
 	 *
 	 * @param name The name to collapse.
 	 * @return The collapsed name.
 	 */
 	public static String collapse(String name) {
 		if ( name == null ) {
 			return null;
 		}
 		int breakPoint = name.lastIndexOf( '.' );
 		if ( breakPoint < 0 ) {
 			return name;
 		}
 		return collapseQualifier( name.substring( 0, breakPoint ), true ) + name.substring( breakPoint ); // includes last '.'
 	}
 
 	/**
 	 * Given a qualifier, collapse it.
 	 *
 	 * @param qualifier The qualifier to collapse.
 	 * @param includeDots Should we include the dots in the collapsed form?
 	 *
 	 * @return The collapsed form.
 	 */
 	public static String collapseQualifier(String qualifier, boolean includeDots) {
 		StringTokenizer tokenizer = new StringTokenizer( qualifier, "." );
 		String collapsed = Character.toString( tokenizer.nextToken().charAt( 0 ) );
 		while ( tokenizer.hasMoreTokens() ) {
 			if ( includeDots ) {
 				collapsed += '.';
 			}
 			collapsed += tokenizer.nextToken().charAt( 0 );
 		}
 		return collapsed;
 	}
 
 	/**
 	 * Partially unqualifies a qualified name.  For example, with a base of 'org.hibernate' the name
 	 * 'org.hibernate.internal.util.StringHelper' would become 'util.StringHelper'.
 	 *
 	 * @param name The (potentially) qualified name.
 	 * @param qualifierBase The qualifier base.
 	 *
 	 * @return The name itself, or the partially unqualified form if it begins with the qualifier base.
 	 */
 	public static String partiallyUnqualify(String name, String qualifierBase) {
 		if ( name == null || ! name.startsWith( qualifierBase ) ) {
 			return name;
 		}
 		return name.substring( qualifierBase.length() + 1 ); // +1 to start after the following '.'
 	}
 
 	/**
 	 * Cross between {@link #collapse} and {@link #partiallyUnqualify}.  Functions much like {@link #collapse}
 	 * except that only the qualifierBase is collapsed.  For example, with a base of 'org.hibernate' the name
 	 * 'org.hibernate.internal.util.StringHelper' would become 'o.h.util.StringHelper'.
 	 *
 	 * @param name The (potentially) qualified name.
 	 * @param qualifierBase The qualifier base.
 	 *
 	 * @return The name itself if it does not begin with the qualifierBase, or the properly collapsed form otherwise.
 	 */
 	public static String collapseQualifierBase(String name, String qualifierBase) {
 		if ( name == null || ! name.startsWith( qualifierBase ) ) {
 			return collapse( name );
 		}
 		return collapseQualifier( qualifierBase, true ) + name.substring( qualifierBase.length() );
 	}
 
 	public static String[] suffix(String[] columns, String suffix) {
 		if ( suffix == null ) return columns;
 		String[] qualified = new String[columns.length];
 		for ( int i = 0; i < columns.length; i++ ) {
 			qualified[i] = suffix( columns[i], suffix );
 		}
 		return qualified;
 	}
 
 	private static String suffix(String name, String suffix) {
 		return ( suffix == null ) ? name : name + suffix;
 	}
 
 	public static String root(String qualifiedName) {
 		int loc = qualifiedName.indexOf( "." );
 		return ( loc < 0 ) ? qualifiedName : qualifiedName.substring( 0, loc );
 	}
 
 	public static String unroot(String qualifiedName) {
 		int loc = qualifiedName.indexOf( "." );
 		return ( loc < 0 ) ? qualifiedName : qualifiedName.substring( loc+1, qualifiedName.length() );
 	}
 
 	public static boolean booleanValue(String tfString) {
 		String trimmed = tfString.trim().toLowerCase();
 		return trimmed.equals( "true" ) || trimmed.equals( "t" );
 	}
 
 	public static String toString(Object[] array) {
 		int len = array.length;
 		if ( len == 0 ) return "";
 		StringBuilder buf = new StringBuilder( len * 12 );
 		for ( int i = 0; i < len - 1; i++ ) {
 			buf.append( array[i] ).append(", ");
 		}
 		return buf.append( array[len - 1] ).toString();
 	}
 
 	public static String[] multiply(String string, Iterator placeholders, Iterator replacements) {
 		String[] result = new String[]{string};
 		while ( placeholders.hasNext() ) {
 			result = multiply( result, ( String ) placeholders.next(), ( String[] ) replacements.next() );
 		}
 		return result;
 	}
 
 	private static String[] multiply(String[] strings, String placeholder, String[] replacements) {
 		String[] results = new String[replacements.length * strings.length];
 		int n = 0;
 		for ( int i = 0; i < replacements.length; i++ ) {
 			for ( int j = 0; j < strings.length; j++ ) {
 				results[n++] = replaceOnce( strings[j], placeholder, replacements[i] );
 			}
 		}
 		return results;
 	}
 
 	public static int countUnquoted(String string, char character) {
 		if ( '\'' == character ) {
 			throw new IllegalArgumentException( "Unquoted count of quotes is invalid" );
 		}
 		if (string == null)
 			return 0;
 		// Impl note: takes advantage of the fact that an escpaed single quote
 		// embedded within a quote-block can really be handled as two seperate
 		// quote-blocks for the purposes of this method...
 		int count = 0;
 		int stringLength = string.length();
 		boolean inQuote = false;
 		for ( int indx = 0; indx < stringLength; indx++ ) {
 			char c = string.charAt( indx );
 			if ( inQuote ) {
 				if ( '\'' == c ) {
 					inQuote = false;
 				}
 			}
 			else if ( '\'' == c ) {
 				inQuote = true;
 			}
 			else if ( c == character ) {
 				count++;
 			}
 		}
 		return count;
 	}
 
 	public static int[] locateUnquoted(String string, char character) {
 		if ( '\'' == character ) {
 			throw new IllegalArgumentException( "Unquoted count of quotes is invalid" );
 		}
 		if (string == null) {
 			return new int[0];
 		}
 
 		ArrayList locations = new ArrayList( 20 );
 
 		// Impl note: takes advantage of the fact that an escpaed single quote
 		// embedded within a quote-block can really be handled as two seperate
 		// quote-blocks for the purposes of this method...
 		int stringLength = string.length();
 		boolean inQuote = false;
 		for ( int indx = 0; indx < stringLength; indx++ ) {
 			char c = string.charAt( indx );
 			if ( inQuote ) {
 				if ( '\'' == c ) {
 					inQuote = false;
 				}
 			}
 			else if ( '\'' == c ) {
 				inQuote = true;
 			}
 			else if ( c == character ) {
 				locations.add( indx );
 			}
 		}
 		return ArrayHelper.toIntArray( locations );
 	}
 
 	public static boolean isNotEmpty(String string) {
 		return string != null && string.length() > 0;
 	}
 
 	public static boolean isEmpty(String string) {
 		return string == null || string.length() == 0;
 	}
 
 	public static String qualify(String prefix, String name) {
 		if ( name == null || prefix == null ) {
 			throw new NullPointerException( "prefix or name were null attempting to build qualified name" );
 		}
 		return prefix + '.' + name;
 	}
 
 	public static String[] qualify(String prefix, String[] names) {
 		if ( prefix == null ) {
 			return names;
 		}
 		int len = names.length;
 		String[] qualified = new String[len];
 		for ( int i = 0; i < len; i++ ) {
 			qualified[i] = qualify( prefix, names[i] );
 		}
 		return qualified;
 	}
 
 	public static String[] qualifyIfNot(String prefix, String[] names) {
 		if ( prefix == null ) {
 			return names;
 		}
 		int len = names.length;
 		String[] qualified = new String[len];
 		for ( int i = 0; i < len; i++ ) {
 			if ( names[i].indexOf( '.' ) < 0 ) {
 				qualified[i] = qualify( prefix, names[i] );
 			}
 			else {
 				qualified[i] = names[i];
 			}
 		}
 		return qualified;
 	}
 
 	public static int firstIndexOfChar(String sqlString, BitSet keys, int startindex) {
 		for ( int i = startindex, size = sqlString.length(); i < size; i++ ) {
 			if ( keys.get( sqlString.charAt( i ) ) ) {
 				return i;
 			}
 		}
 		return -1;
 
 	}
 
 	public static int firstIndexOfChar(String sqlString, String string, int startindex) {
 		BitSet keys = new BitSet();
 		for ( int i = 0, size = string.length(); i < size; i++ ) {
 			keys.set( string.charAt( i ) );
 		}
 		return firstIndexOfChar( sqlString, keys, startindex );
 
 	}
 
 	public static String truncate(String string, int length) {
 		if ( string.length() <= length ) {
 			return string;
 		}
 		else {
 			return string.substring( 0, length );
 		}
 	}
 
 	public static String generateAlias(String description) {
 		return generateAliasRoot(description) + '_';
 	}
 
 	/**
 	 * Generate a nice alias for the given class name or collection role name and unique integer. Subclasses of
 	 * Loader do <em>not</em> have to use aliases of this form.
 	 *
 	 * @param description The base name (usually an entity-name or collection-role)
 	 * @param unique A uniquing value
 	 *
 	 * @return an alias of the form <samp>foo1_</samp>
 	 */
 	public static String generateAlias(String description, int unique) {
 		return generateAliasRoot(description) +
 			Integer.toString(unique) +
 			'_';
 	}
 
 	/**
 	 * Generates a root alias by truncating the "root name" defined by
 	 * the incoming decription and removing/modifying any non-valid
 	 * alias characters.
 	 *
 	 * @param description The root name from which to generate a root alias.
 	 * @return The generated root alias.
 	 */
 	private static String generateAliasRoot(String description) {
 		String result = truncate( unqualifyEntityName(description), ALIAS_TRUNCATE_LENGTH )
 				// Important to use Locale.ENGLISH.  See HHH-8579.  #toLowerCase() uses the default Locale.  Certain DBs
 				// do not like non-ascii characters in aliases, etc., so ensure consistency/portability here.
 				.toLowerCase(Locale.ENGLISH)
 		        .replace( '/', '_' ) // entityNames may now include slashes for the representations
 				.replace( '$', '_' ); //classname may be an inner class
 		result = cleanAlias( result );
 		if ( Character.isDigit( result.charAt(result.length()-1) ) ) {
 			return result + "x"; //ick!
 		}
 		else {
 			return result;
 		}
 	}
 
 	/**
 	 * Clean the generated alias by removing any non-alpha characters from the
 	 * beginning.
 	 *
 	 * @param alias The generated alias to be cleaned.
 	 * @return The cleaned alias, stripped of any leading non-alpha characters.
 	 */
 	private static String cleanAlias(String alias) {
 		char[] chars = alias.toCharArray();
 		// short cut check...
 		if ( !Character.isLetter( chars[0] ) ) {
 			for ( int i = 1; i < chars.length; i++ ) {
 				// as soon as we encounter our first letter, return the substring
 				// from that position
 				if ( Character.isLetter( chars[i] ) ) {
 					return alias.substring( i );
 				}
 			}
 		}
 		return alias;
 	}
 
 	public static String unqualifyEntityName(String entityName) {
 		String result = unqualify(entityName);
 		int slashPos = result.indexOf( '/' );
 		if ( slashPos > 0 ) {
 			result = result.substring( 0, slashPos - 1 );
 		}
 		return result;
 	}
 	
 	public static String toUpperCase(String str) {
 		return str==null ? null : str.toUpperCase();
 	}
 	
 	public static String toLowerCase(String str) {
 		// Important to use Locale.ENGLISH.  See HHH-8579.  #toLowerCase() uses the default Locale.  Certain DBs do not
 		// like non-ascii characters in aliases, etc., so ensure consistency/portability here.
 		return str==null ? null : str.toLowerCase(Locale.ENGLISH);
 	}
 
 	public static String moveAndToBeginning(String filter) {
 		if ( filter.trim().length()>0 ){
 			filter += " and ";
 			if ( filter.startsWith(" and ") ) filter = filter.substring(4);
 		}
 		return filter;
 	}
 
 	/**
 	 * Determine if the given string is quoted (wrapped by '`' characters at beginning and end).
 	 *
 	 * @param name The name to check.
 	 * @return True if the given string starts and ends with '`'; false otherwise.
 	 */
 	public static boolean isQuoted(String name) {
 		return name != null && name.length() != 0 && name.charAt( 0 ) == '`' && name.charAt( name.length() - 1 ) == '`';
 	}
 
 	/**
 	 * Return a representation of the given name ensuring quoting (wrapped with '`' characters).  If already wrapped
 	 * return name.
 	 *
 	 * @param name The name to quote.
 	 * @return The quoted version.
 	 */
 	public static String quote(String name) {
 		if ( isEmpty( name ) || isQuoted( name ) ) {
 			return name;
 		}
 // Convert the JPA2 specific quoting character (double quote) to Hibernate's (back tick)
         else if ( name.startsWith( "\"" ) && name.endsWith( "\"" ) ) {
             name = name.substring( 1, name.length() - 1 );
         }
 
 		return new StringBuilder( name.length() + 2 ).append('`').append( name ).append( '`' ).toString();
 	}
 
 	/**
 	 * Return the unquoted version of name (stripping the start and end '`' characters if present).
 	 *
 	 * @param name The name to be unquoted.
 	 * @return The unquoted version.
 	 */
 	public static String unquote(String name) {
 		return isQuoted( name ) ? name.substring( 1, name.length() - 1 ) : name;
 	}
 
 	/**
 	 * Determine if the given name is quoted.  It is considered quoted if either:
 	 * <ol>
 	 * <li>starts AND ends with backticks (`)</li>
 	 * <li>starts with dialect-specified {@link org.hibernate.dialect.Dialect#openQuote() open-quote}
 	 * 		AND ends with dialect-specified {@link org.hibernate.dialect.Dialect#closeQuote() close-quote}</li>
 	 * </ol>
 	 *
 	 * @param name The name to check
 	 * @param dialect The dialect (to determine the "real" quoting chars).
 	 *
 	 * @return True if quoted, false otherwise
 	 */
 	public static boolean isQuoted(String name, Dialect dialect) {
 		return name != null
 				&&
 					name.length() != 0
 				&& (
 					name.charAt( 0 ) == '`'
 					&&
 					name.charAt( name.length() - 1 ) == '`'
 					||
 					name.charAt( 0 ) == dialect.openQuote()
 					&&
 					name.charAt( name.length() - 1 ) == dialect.closeQuote()
 				);
 	}
 
 	/**
 	 * Return the unquoted version of name stripping the start and end quote characters.
 	 *
 	 * @param name The name to be unquoted.
 	 * @param dialect The dialect (to determine the "real" quoting chars).
 	 *
 	 * @return The unquoted version.
 	 */
 	public static String unquote(String name, Dialect dialect) {
 		return isQuoted( name, dialect ) ? name.substring( 1, name.length() - 1 ) : name;
 	}
 
 	/**
 	 * Return the unquoted version of name stripping the start and end quote characters.
 	 *
 	 * @param names The names to be unquoted.
 	 * @param dialect The dialect (to determine the "real" quoting chars).
 	 *
 	 * @return The unquoted versions.
 	 */
 	public static String[] unquote(String[] names, Dialect dialect) {
 		if ( names == null ) {
 			return null;
 		}
 		String[] unquoted = new String[ names.length ];
 		for ( int i = 0; i < names.length; i++ ) {
 			unquoted[i] = unquote( names[i], dialect );
 		}
 		return unquoted;
 	}
 
 
 	public static final String BATCH_ID_PLACEHOLDER = "$$BATCH_ID_PLACEHOLDER$$";
 
 	public static StringBuilder buildBatchFetchRestrictionFragment(
 			String alias,
 			String[] columnNames,
 			Dialect dialect) {
 		// the general idea here is to just insert a placeholder that we can easily find later...
 		if ( columnNames.length == 1 ) {
 			// non-composite key
 			return new StringBuilder( StringHelper.qualify( alias, columnNames[0] ) )
 					.append( " in (" ).append( BATCH_ID_PLACEHOLDER ).append( ")" );
 		}
 		else {
 			// composite key - the form to use here depends on what the dialect supports.
 			if ( dialect.supportsRowValueConstructorSyntaxInInList() ) {
 				// use : (col1, col2) in ( (?,?), (?,?), ... )
 				StringBuilder builder = new StringBuilder();
 				builder.append( "(" );
 				boolean firstPass = true;
 				String deliminator = "";
 				for ( String columnName : columnNames ) {
 					builder.append( deliminator ).append( StringHelper.qualify( alias, columnName ) );
 					if ( firstPass ) {
 						firstPass = false;
 						deliminator = ",";
 					}
 				}
 				builder.append( ") in (" );
 				builder.append( BATCH_ID_PLACEHOLDER );
 				builder.append( ")" );
 				return builder;
 			}
 			else {
 				// use : ( (col1 = ? and col2 = ?) or (col1 = ? and col2 = ?) or ... )
 				//		unfortunately most of this building needs to be held off until we know
 				//		the exact number of ids :(
 				return new StringBuilder( "(" ).append( BATCH_ID_PLACEHOLDER ).append( ")" );
 			}
 		}
 	}
 
 	public static String expandBatchIdPlaceholder(
 			String sql,
 			Serializable[] ids,
 			String alias,
 			String[] keyColumnNames,
 			Dialect dialect) {
 		if ( keyColumnNames.length == 1 ) {
 			// non-composite
 			return StringHelper.replace( sql, BATCH_ID_PLACEHOLDER, repeat( "?", ids.length, "," ) );
 		}
 		else {
 			// composite
 			if ( dialect.supportsRowValueConstructorSyntaxInInList() ) {
 				final String tuple = "(" + StringHelper.repeat( "?", keyColumnNames.length, "," );
 				return StringHelper.replace( sql, BATCH_ID_PLACEHOLDER, repeat( tuple, ids.length, "," ) );
 			}
 			else {
 				final String keyCheck = joinWithQualifier( keyColumnNames, alias, " and " );
 				return replace( sql, BATCH_ID_PLACEHOLDER, repeat( keyCheck, ids.length, " or " ) );
 			}
 		}
 	}
 	
 	/**
 	 * Takes a String s and returns a new String[1] with s as the only element.
 	 * If s is null or "", return String[0].
 	 * 
 	 * @param s
 	 * @return String[]
 	 */
 	public static String[] toArrayElement(String s) {
 		return ( s == null || s.length() == 0 ) ? new String[0] : new String[] { s };
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/BoundedConcurrentHashMap.java b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/BoundedConcurrentHashMap.java
index cc2d847041..5fdc3fc23a 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/BoundedConcurrentHashMap.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/BoundedConcurrentHashMap.java
@@ -1,1996 +1,1996 @@
 /*
  * JBoss, Home of Professional Open Source
  * Copyright 2010 Red Hat Inc. and/or its affiliates and other
  * contributors as indicated by the @author tags. All rights reserved.
  * See the copyright.txt in the distribution for a full listing of
  * individual contributors.
  *
  * This is free software; you can redistribute it and/or modify it
  * under the terms of the GNU Lesser General Public License as
  * published by the Free Software Foundation; either version 2.1 of
  * the License, or (at your option) any later version.
  *
  * This software is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
  * Lesser General Public License for more details.
  *
  * You should have received a copy of the GNU Lesser General Public
  * License along with this software; if not, write to the Free
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
 /*
  * Written by Doug Lea with assistance from members of JCP JSR-166
  * Expert Group and released to the public domain, as explained at
  * http://creativecommons.org/licenses/publicdomain
  *
  * Modified for https://jira.jboss.org/jira/browse/ISPN-299
  * Includes ideas described in http://portal.acm.org/citation.cfm?id=1547428
  *
  */
 
 package org.hibernate.internal.util.collections;
 
 import java.io.IOException;
 import java.io.Serializable;
 import java.util.AbstractCollection;
 import java.util.AbstractMap;
 import java.util.AbstractSet;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.ConcurrentModificationException;
 import java.util.Enumeration;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Hashtable;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.Map;
 import java.util.NoSuchElementException;
 import java.util.Set;
 import java.util.concurrent.ConcurrentLinkedQueue;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.locks.ReentrantLock;
 
 import static java.util.Collections.singletonMap;
 import static java.util.Collections.unmodifiableMap;
 
 
 /**
  * A hash table supporting full concurrency of retrievals and
  * adjustable expected concurrency for updates. This class obeys the
  * same functional specification as {@link Hashtable}, and
  * includes versions of methods corresponding to each method of
  * <tt>Hashtable</tt>. However, even though all operations are
  * thread-safe, retrieval operations do <em>not</em> entail locking,
  * and there is <em>not</em> any support for locking the entire table
  * in a way that prevents all access.  This class is fully
  * interoperable with <tt>Hashtable</tt> in programs that rely on its
  * thread safety but not on its synchronization details.
  *
  * <p> Retrieval operations (including <tt>get</tt>) generally do not
  * block, so may overlap with update operations (including
  * <tt>put</tt> and <tt>remove</tt>). Retrievals reflect the results
  * of the most recently <em>completed</em> update operations holding
  * upon their onset.  For aggregate operations such as <tt>putAll</tt>
  * and <tt>clear</tt>, concurrent retrievals may reflect insertion or
  * removal of only some entries.  Similarly, Iterators and
  * Enumerations return elements reflecting the state of the hash table
  * at some point at or since the creation of the iterator/enumeration.
  * They do <em>not</em> throw {@link ConcurrentModificationException}.
  * However, iterators are designed to be used by only one thread at a time.
  *
  * <p> The allowed concurrency among update operations is guided by
  * the optional <tt>concurrencyLevel</tt> constructor argument
  * (default <tt>16</tt>), which is used as a hint for internal sizing.  The
  * table is internally partitioned to try to permit the indicated
  * number of concurrent updates without contention. Because placement
  * in hash tables is essentially random, the actual concurrency will
  * vary.  Ideally, you should choose a value to accommodate as many
  * threads as will ever concurrently modify the table. Using a
  * significantly higher value than you need can waste space and time,
  * and a significantly lower value can lead to thread contention. But
  * overestimates and underestimates within an order of magnitude do
  * not usually have much noticeable impact. A value of one is
  * appropriate when it is known that only one thread will modify and
  * all others will only read. Also, resizing this or any other kind of
  * hash table is a relatively slow operation, so, when possible, it is
  * a good idea to provide estimates of expected table sizes in
  * constructors.
  *
  * <p>This class and its views and iterators implement all of the
  * <em>optional</em> methods of the {@link Map} and {@link Iterator}
  * interfaces.
  *
  * <p>This class is copied from Infinispan, and was originally written
  * by Doug Lea with assistance from members of JCP JSR-166 Expert Group and
  * released to the public domain, as explained at
  * http://creativecommons.org/licenses/publicdomain</p>
  *
  *
  * <p> Like {@link Hashtable} but unlike {@link HashMap}, this class
  * does <em>not</em> allow <tt>null</tt> to be used as a key or value.
  *
  * @author Doug Lea
  * @param <K> the type of keys maintained by this map
  * @param <V> the type of mapped values
  */
 public class BoundedConcurrentHashMap<K, V> extends AbstractMap<K, V>
 		implements ConcurrentMap<K, V>, Serializable {
 	private static final long serialVersionUID = 7249069246763182397L;
 
 	/*
 		* The basic strategy is to subdivide the table among Segments,
 		* each of which itself is a concurrently readable hash table.
 		*/
 
 	/* ---------------- Constants -------------- */
 
 	/**
 	 * The default initial capacity for this table,
 	 * used when not otherwise specified in a constructor.
 	 */
 	static final int DEFAULT_MAXIMUM_CAPACITY = 512;
 
 	/**
 	 * The default load factor for this table, used when not
 	 * otherwise specified in a constructor.
 	 */
 	static final float DEFAULT_LOAD_FACTOR = 0.75f;
 
 	/**
 	 * The default concurrency level for this table, used when not
 	 * otherwise specified in a constructor.
 	 */
 	static final int DEFAULT_CONCURRENCY_LEVEL = 16;
 
 	/**
 	 * The maximum capacity, used if a higher value is implicitly
 	 * specified by either of the constructors with arguments.  MUST
 	 * be a power of two <= 1<<30 to ensure that entries are indexable
 	 * using ints.
 	 */
 	static final int MAXIMUM_CAPACITY = 1 << 30;
 
 	/**
 	 * The maximum number of segments to allow; used to bound
 	 * constructor arguments.
 	 */
 	static final int MAX_SEGMENTS = 1 << 16; // slightly conservative
 
 	/**
 	 * Number of unsynchronized retries in size and containsValue
 	 * methods before resorting to locking. This is used to avoid
 	 * unbounded retries if tables undergo continuous modification
 	 * which would make it impossible to obtain an accurate result.
 	 */
 	static final int RETRIES_BEFORE_LOCK = 2;
 
 	/* ---------------- Fields -------------- */
 
 	/**
 	 * Mask value for indexing into segments. The upper bits of a
 	 * key's hash code are used to choose the segment.
 	 */
 	final int segmentMask;
 
 	/**
 	 * Shift value for indexing within segments.
 	 */
 	final int segmentShift;
 
 	/**
 	 * The segments, each of which is a specialized hash table
 	 */
 	final Segment<K,V>[] segments;
 
 	transient Set<K> keySet;
 	transient Set<Map.Entry<K,V>> entrySet;
 	transient Collection<V> values;
 
 	/* ---------------- Small Utilities -------------- */
 
 	/**
 	 * Applies a supplemental hash function to a given hashCode, which
 	 * defends against poor quality hash functions.  This is critical
 	 * because ConcurrentHashMap uses power-of-two length hash tables,
 	 * that otherwise encounter collisions for hashCodes that do not
 	 * differ in lower or upper bits.
 	 */
 	private static int hash(int h) {
 		// Spread bits to regularize both segment and index locations,
 		// using variant of single-word Wang/Jenkins hash.
 		h += h <<  15 ^ 0xffffcd7d;
 		h ^= h >>> 10;
 		h += h <<   3;
 		h ^= h >>>  6;
 		h += (h <<   2) + (h << 14);
 		return h ^ h >>> 16;
 	}
 
 	/**
 	 * Returns the segment that should be used for key with given hash
 	 * @param hash the hash code for the key
 	 * @return the segment
 	 */
 	final Segment<K,V> segmentFor(int hash) {
 		return segments[hash >>> segmentShift & segmentMask];
 	}
 
 	/* ---------------- Inner Classes -------------- */
 
 	/**
 	 * ConcurrentHashMap list entry. Note that this is never exported
 	 * out as a user-visible Map.Entry.
 	 *
 	 * Because the value field is volatile, not final, it is legal wrt
 	 * the Java Memory Model for an unsynchronized reader to see null
 	 * instead of initial value when read via a data race.  Although a
 	 * reordering leading to this is not likely to ever actually
 	 * occur, the Segment.readValueUnderLock method is used as a
 	 * backup in case a null (pre-initialized) value is ever seen in
 	 * an unsynchronized access method.
 	 */
 	private static class HashEntry<K, V> {
 		final K key;
 		final int hash;
 		volatile V value;
 		final HashEntry<K, V> next;
 
 		HashEntry(K key, int hash, HashEntry<K, V> next, V value) {
 			this.key = key;
 			this.hash = hash;
 			this.next = next;
 			this.value = value;
 		}
 
 		@Override
 		public int hashCode() {
 			int result = 17;
 			result = result * 31 + hash;
 			result = result * 31 + key.hashCode();
 			return result;
 		}
 
 		@Override
 		public boolean equals(Object o) {
 			// HashEntry is internal class, never leaks out of CHM, hence slight optimization
 			if (this == o) {
 				return true;
 			}
 			if (o == null) {
 				return false;
 			}
 			HashEntry<?, ?> other = (HashEntry<?, ?>) o;
 			return hash == other.hash && key.equals(other.key);
 		}
 
 		@SuppressWarnings("unchecked")
 		static <K, V> HashEntry<K, V>[] newArray(int i) {
 			return new HashEntry[i];
 		}
 	}
 
 	private enum Recency {
 		HIR_RESIDENT, LIR_RESIDENT, HIR_NONRESIDENT
 	}
 
 	public enum Eviction {
 		NONE {
 			@Override
 			public <K, V> EvictionPolicy<K, V> make(Segment<K, V> s, int capacity, float lf) {
 				return new NullEvictionPolicy<K, V>();
 			}
 		},
 		LRU {
 			@Override
 			public <K, V> EvictionPolicy<K, V> make(Segment<K, V> s, int capacity, float lf) {
 				return new LRU<K, V>(s,capacity,lf,capacity*10,lf);
 			}
 		},
 		LIRS {
 			@Override
 			public <K, V> EvictionPolicy<K, V> make(Segment<K, V> s, int capacity, float lf) {
 				return new LIRS<K,V>(s,capacity,capacity*10,lf);
 			}
 		};
 
 		abstract <K, V> EvictionPolicy<K, V> make(Segment<K, V> s, int capacity, float lf);
 	}
 
 	public interface EvictionListener<K, V> {
 		void onEntryEviction(Map<K, V> evicted);
 		void onEntryChosenForEviction(V internalCacheEntry);
 	}
 
 	static final class NullEvictionListener<K, V> implements EvictionListener<K, V> {
 		@Override
 		public void onEntryEviction(Map<K, V> evicted) {
 			// Do nothing.
 		}
 		@Override
 		public void onEntryChosenForEviction(V internalCacheEntry) {
 			// Do nothing.
 		}
 	}
 
 	public interface EvictionPolicy<K, V> {
 
 		public final static int MAX_BATCH_SIZE = 64;
 
 		HashEntry<K, V> createNewEntry(K key, int hash, HashEntry<K, V> next, V value);
 
 		/**
 		 * Invokes eviction policy algorithm and returns set of evicted entries.
 		 *
 		 * <p>
 		 * Set cannot be null but could possibly be an empty set.
 		 *
 		 * @return set of evicted entries.
 		 */
 		Set<HashEntry<K, V>> execute();
 
 		/**
 		 * Invoked to notify EvictionPolicy implementation that there has been an attempt to access
 		 * an entry in Segment, however that entry was not present in Segment.
 		 *
 		 * @param e
 		 *            accessed entry in Segment
 		 *
 		 * @return non null set of evicted entries.
 		 */
 		Set<HashEntry<K, V>> onEntryMiss(HashEntry<K, V> e);
 
 		/**
 		 * Invoked to notify EvictionPolicy implementation that an entry in Segment has been
 		 * accessed. Returns true if batching threshold has been reached, false otherwise.
 		 * <p>
 		 * Note that this method is potentially invoked without holding a lock on Segment.
 		 *
 		 * @return true if batching threshold has been reached, false otherwise.
 		 *
 		 * @param e
 		 *            accessed entry in Segment
 		 */
 		boolean onEntryHit(HashEntry<K, V> e);
 
 		/**
 		 * Invoked to notify EvictionPolicy implementation that an entry e has been removed from
 		 * Segment.
 		 *
 		 * @param e
 		 *            removed entry in Segment
 		 */
 		void onEntryRemove(HashEntry<K, V> e);
 
 		/**
 		 * Invoked to notify EvictionPolicy implementation that all Segment entries have been
 		 * cleared.
 		 *
 		 */
 		void clear();
 
 		/**
 		 * Returns type of eviction algorithm (strategy).
 		 *
 		 * @return type of eviction algorithm
 		 */
 		Eviction strategy();
 
 		/**
 		 * Returns true if batching threshold has expired, false otherwise.
 		 * <p>
 		 * Note that this method is potentially invoked without holding a lock on Segment.
 		 *
 		 * @return true if batching threshold has expired, false otherwise.
 		 */
 		boolean thresholdExpired();
 	}
 
 	static class NullEvictionPolicy<K, V> implements EvictionPolicy<K, V> {
 
 		@Override
 		public void clear() {
 			// Do nothing.
 		}
 
 		@Override
 		public Set<HashEntry<K, V>> execute() {
 			return Collections.emptySet();
 		}
 
 		@Override
 		public boolean onEntryHit(HashEntry<K, V> e) {
 			return false;
 		}
 
 		@Override
 		public Set<HashEntry<K, V>> onEntryMiss(HashEntry<K, V> e) {
 			return Collections.emptySet();
 		}
 
 		@Override
 		public void onEntryRemove(HashEntry<K, V> e) {
 			// Do nothing.
 		}
 
 		@Override
 		public boolean thresholdExpired() {
 			return false;
 		}
 
 		@Override
 		public Eviction strategy() {
 			return Eviction.NONE;
 		}
 
 		@Override
 		public HashEntry<K, V> createNewEntry(K key, int hash, HashEntry<K, V> next, V value) {
 			return new HashEntry<K, V>(key, hash, next, value);
 		}
 	}
 
 	static final class LRU<K, V> extends LinkedHashMap<HashEntry<K,V>, V> implements EvictionPolicy<K, V> {
 
 		/** The serialVersionUID */
 		private static final long serialVersionUID = -7645068174197717838L;
 
 		private final ConcurrentLinkedQueue<HashEntry<K, V>> accessQueue;
 		private final Segment<K,V> segment;
 		private final int maxBatchQueueSize;
 		private final int trimDownSize;
 		private final float batchThresholdFactor;
 		private final Set<HashEntry<K, V>> evicted;
 
 		public LRU(Segment<K,V> s, int capacity, float lf, int maxBatchSize, float batchThresholdFactor) {
 			super(capacity, lf, true);
 			this.segment = s;
 			this.trimDownSize = capacity;
 			this.maxBatchQueueSize = maxBatchSize > MAX_BATCH_SIZE ? MAX_BATCH_SIZE : maxBatchSize;
 			this.batchThresholdFactor = batchThresholdFactor;
 			this.accessQueue = new ConcurrentLinkedQueue<HashEntry<K, V>>();
 			this.evicted = new HashSet<HashEntry<K, V>>();
 		}
 
 		@Override
 		public Set<HashEntry<K, V>> execute() {
 			Set<HashEntry<K, V>> evictedCopy = new HashSet<HashEntry<K, V>>();
 			for (HashEntry<K, V> e : accessQueue) {
 				put(e, e.value);
 			}
 			evictedCopy.addAll(evicted);
 			accessQueue.clear();
 			evicted.clear();
 			return evictedCopy;
 		}
 
 		@Override
 		public Set<HashEntry<K, V>> onEntryMiss(HashEntry<K, V> e) {
 			put(e, e.value);
 			if (!evicted.isEmpty()) {
 				Set<HashEntry<K, V>> evictedCopy = new HashSet<HashEntry<K, V>>();
 				evictedCopy.addAll(evicted);
 				evicted.clear();
 				return evictedCopy;
 			} else {
 				return Collections.emptySet();
 			}
 		}
 
 		/*
 			   * Invoked without holding a lock on Segment
 			   */
 		@Override
 		public boolean onEntryHit(HashEntry<K, V> e) {
 			accessQueue.add(e);
 			return accessQueue.size() >= maxBatchQueueSize * batchThresholdFactor;
 		}
 
 		/*
 			   * Invoked without holding a lock on Segment
 			   */
 		@Override
 		public boolean thresholdExpired() {
 			return accessQueue.size() >= maxBatchQueueSize;
 		}
 
 		@Override
 		public void onEntryRemove(HashEntry<K, V> e) {
 			remove(e);
 			// we could have multiple instances of e in accessQueue; remove them all
 			while (accessQueue.remove(e)) {
 				continue;
 			}
 		}
 
 		@Override
 		public void clear() {
 			super.clear();
 			accessQueue.clear();
 		}
 
 		@Override
 		public Eviction strategy() {
 			return Eviction.LRU;
 		}
 
 		protected boolean isAboveThreshold(){
 			return size() > trimDownSize;
 		}
 
 		protected boolean removeEldestEntry(Map.Entry<HashEntry<K,V>,V> eldest){
 			boolean aboveThreshold = isAboveThreshold();
 			if(aboveThreshold){
 				HashEntry<K, V> evictedEntry = eldest.getKey();
 				segment.evictionListener.onEntryChosenForEviction(evictedEntry.value);
 				segment.remove(evictedEntry.key, evictedEntry.hash, null);
 				evicted.add(evictedEntry);
 			}
 			return aboveThreshold;
 		}
 
 		@Override
 		public HashEntry<K, V> createNewEntry(K key, int hash, HashEntry<K, V> next, V value) {
 			return new HashEntry<K, V>(key, hash, next, value);
 		}
 	}
 
 	/**
 	 * Adapted to Infinispan BoundedConcurrentHashMap using LIRS implementation ideas from Charles Fry (fry@google.com)
 	 * See http://code.google.com/p/concurrentlinkedhashmap/source/browse/trunk/src/test/java/com/googlecode/concurrentlinkedhashmap/caches/LirsMap.java
 	 * for original sources
 	 *
 	 */
 	private static final class LIRSHashEntry<K,V> extends HashEntry<K,V> {
 
 		// LIRS stack S
 		private LIRSHashEntry<K, V> previousInStack;
 		private LIRSHashEntry<K, V> nextInStack;
 
 		// LIRS queue Q
 		private LIRSHashEntry<K, V> previousInQueue;
 		private LIRSHashEntry<K, V> nextInQueue;
 		volatile Recency state;
 
 		LIRS<K, V> owner;
 
 
 		LIRSHashEntry(LIRS<K, V> owner, K key, int hash, HashEntry<K, V> next, V value) {
 			super(key,hash,next,value);
 			this.owner = owner;
 			this.state = Recency.HIR_RESIDENT;
 
 			// initially point everything back to self
 			this.previousInStack = this;
 			this.nextInStack = this;
 			this.previousInQueue = this;
 			this.nextInQueue = this;
 		}
 
 		@Override
 		public int hashCode() {
 			int result = 17;
 			result = result * 31 + hash;
 			result = result * 31 + key.hashCode();
 			return result;
 		}
 
 		@Override
 		public boolean equals(Object o) {
 			// HashEntry is internal class, never leaks out of CHM, hence slight optimization
 			if (this == o) {
 				return true;
 			}
 			if (o == null) {
 				return false;
 			}
 			HashEntry<?, ?> other = (HashEntry<?, ?>) o;
 			return hash == other.hash && key.equals(other.key);
 		}
 
 		/**
 		 * Returns true if this entry is in the stack, false otherwise.
 		 */
 		public boolean inStack() {
 			return (nextInStack != null);
 		}
 
 		/**
 		 * Returns true if this entry is in the queue, false otherwise.
 		 */
 		public boolean inQueue() {
 			return (nextInQueue != null);
 		}
 
 		/**
 		 * Records a cache hit.
 		 */
 		public void hit(Set<HashEntry<K, V>> evicted) {
 			switch (state) {
 				case LIR_RESIDENT:
 					hotHit(evicted);
 					break;
 				case HIR_RESIDENT:
 					coldHit(evicted);
 					break;
 				case HIR_NONRESIDENT:
 					throw new IllegalStateException("Can't hit a non-resident entry!");
 				default:
 					throw new AssertionError("Hit with unknown status: " + state);
 			}
 		}
 
 		/**
 		 * Records a cache hit on a hot block.
 		 */
 		private void hotHit(Set<HashEntry<K, V>> evicted) {
 			// See section 3.3 case 1:
 			// "Upon accessing an LIR block X:
 			// This access is guaranteed to be a hit in the cache."
 
 			// "We move it to the top of stack S."
 			boolean onBottom = (owner.stackBottom() == this);
 			moveToStackTop();
 
 			// "If the LIR block is originally located in the bottom of the stack,
 			// we conduct a stack pruning."
 			if (onBottom) {
 				owner.pruneStack(evicted);
 			}
 		}
 
 		/**
 		 * Records a cache hit on a cold block.
 		 */
 		private void coldHit(Set<HashEntry<K, V>> evicted) {
 			// See section 3.3 case 2:
 			// "Upon accessing an HIR resident block X:
 			// This is a hit in the cache."
 
 			// "We move it to the top of stack S."
 			boolean inStack = inStack();
 			moveToStackTop();
 
 			// "There are two cases for block X:"
 			if (inStack) {
 				// "(1) If X is in the stack S, we change its status to LIR."
 				hot();
 
 				// "This block is also removed from list Q."
 				removeFromQueue();
 
 				// "The LIR block in the bottom of S is moved to the end of list Q
 				// with its status changed to HIR."
 				owner.stackBottom().migrateToQueue();
 
 				// "A stack pruning is then conducted."
 				owner.pruneStack(evicted);
 			} else {
 				// "(2) If X is not in stack S, we leave its status in HIR and move
 				// it to the end of list Q."
 				moveToQueueEnd();
 			}
 		}
 
 		/**
 		 * Records a cache miss. This is how new entries join the LIRS stack and
 		 * queue. This is called both when a new entry is first created, and when a
 		 * non-resident entry is re-computed.
 		 */
 		private Set<HashEntry<K, V>> miss() {
 			Set<HashEntry<K, V>> evicted = Collections.emptySet();
 			if (owner.hotSize < owner.maximumHotSize) {
 				warmupMiss();
 			} else {
 				evicted = new HashSet<HashEntry<K,V>>();
 				fullMiss(evicted);
 			}
 
 			// now the missed item is in the cache
 			owner.size++;
 			return evicted;
 		}
 
 		/**
 		 * Records a miss when the hot entry set is not full.
 		 */
 		private void warmupMiss() {
 			// See section 3.3:
 			// "When LIR block set is not full, all the referenced blocks are
 			// given an LIR status until its size reaches L_lirs."
 			hot();
 			moveToStackTop();
 		}
 
 		/**
 		 * Records a miss when the hot entry set is full.
 		 */
 		private void fullMiss(Set<HashEntry<K, V>> evicted) {
 			// See section 3.3 case 3:
 			// "Upon accessing an HIR non-resident block X:
 			// This is a miss."
 
 			// This condition is unspecified in the paper, but appears to be
 			// necessary.
 			if (owner.size >= owner.maximumSize) {
 				// "We remove the HIR resident block at the front of list Q (it then
 				// becomes a non-resident block), and replace it out of the cache."
 				LIRSHashEntry<K, V> evictedNode = owner.queueFront();
 				evicted.add(evictedNode);
 			}
 
 			// "Then we load the requested block X into the freed buffer and place
 			// it on the top of stack S."
 			boolean inStack = inStack();
 			moveToStackTop();
 
 			// "There are two cases for block X:"
 			if (inStack) {
 				// "(1) If X is in stack S, we change its status to LIR and move the
 				// LIR block in the bottom of stack S to the end of list Q with its
 				// status changed to HIR. A stack pruning is then conducted.
 				hot();
 				owner.stackBottom().migrateToQueue();
 				owner.pruneStack(evicted);
 			} else {
 				// "(2) If X is not in stack S, we leave its status in HIR and place
 				// it in the end of list Q."
 				cold();
 			}
 		}
 
 		/**
 		 * Marks this entry as hot.
 		 */
 		private void hot() {
 			if (state != Recency.LIR_RESIDENT) {
 				owner.hotSize++;
 			}
 			state = Recency.LIR_RESIDENT;
 		}
 
 		/**
 		 * Marks this entry as cold.
 		 */
 		private void cold() {
 			if (state == Recency.LIR_RESIDENT) {
 				owner.hotSize--;
 			}
 			state = Recency.HIR_RESIDENT;
 			moveToQueueEnd();
 		}
 
 		/**
 		 * Marks this entry as non-resident.
 		 */
 		@SuppressWarnings("fallthrough")
 		private void nonResident() {
 			switch (state) {
 				case LIR_RESIDENT:
 					owner.hotSize--;
 					// fallthrough
 				case HIR_RESIDENT:
 					owner.size--;
 					break;
 			}
 			state = Recency.HIR_NONRESIDENT;
 		}
 
 		/**
 		 * Returns true if this entry is resident in the cache, false otherwise.
 		 */
 		public boolean isResident() {
 			return (state != Recency.HIR_NONRESIDENT);
 		}
 
 
 		/**
 		 * Temporarily removes this entry from the stack, fixing up neighbor links.
 		 * This entry's links remain unchanged, meaning that {@link #inStack()} will
 		 * continue to return true. This should only be called if this node's links
 		 * will be subsequently changed.
 		 */
 		private void tempRemoveFromStack() {
 			if (inStack()) {
 				previousInStack.nextInStack = nextInStack;
 				nextInStack.previousInStack = previousInStack;
 			}
 		}
 
 		/**
 		 * Removes this entry from the stack.
 		 */
 		private void removeFromStack() {
 			tempRemoveFromStack();
 			previousInStack = null;
 			nextInStack = null;
 		}
 
 		/**
 		 * Inserts this entry before the specified existing entry in the stack.
 		 */
 		private void addToStackBefore(LIRSHashEntry<K,V> existingEntry) {
 			previousInStack = existingEntry.previousInStack;
 			nextInStack = existingEntry;
 			previousInStack.nextInStack = this;
 			nextInStack.previousInStack = this;
 		}
 
 		/**
 		 * Moves this entry to the top of the stack.
 		 */
 		private void moveToStackTop() {
 			tempRemoveFromStack();
 			addToStackBefore(owner.header.nextInStack);
 		}
 
 		/**
 		 * Moves this entry to the bottom of the stack.
 		 */
 		private void moveToStackBottom() {
 			tempRemoveFromStack();
 			addToStackBefore(owner.header);
 		}
 
 		/**
 		 * Temporarily removes this entry from the queue, fixing up neighbor links.
 		 * This entry's links remain unchanged. This should only be called if this
 		 * node's links will be subsequently changed.
 		 */
 		private void tempRemoveFromQueue() {
 			if (inQueue()) {
 				previousInQueue.nextInQueue = nextInQueue;
 				nextInQueue.previousInQueue = previousInQueue;
 			}
 		}
 
 		/**
 		 * Removes this entry from the queue.
 		 */
 		private void removeFromQueue() {
 			tempRemoveFromQueue();
 			previousInQueue = null;
 			nextInQueue = null;
 		}
 
 		/**
 		 * Inserts this entry before the specified existing entry in the queue.
 		 */
 		private void addToQueueBefore(LIRSHashEntry<K,V> existingEntry) {
 			previousInQueue = existingEntry.previousInQueue;
 			nextInQueue = existingEntry;
 			previousInQueue.nextInQueue = this;
 			nextInQueue.previousInQueue = this;
 		}
 
 		/**
 		 * Moves this entry to the end of the queue.
 		 */
 		private void moveToQueueEnd() {
 			tempRemoveFromQueue();
 			addToQueueBefore(owner.header);
 		}
 
 
 		/**
 		 * Moves this entry from the stack to the queue, marking it cold
 		 * (as hot entries must remain in the stack). This should only be called
 		 * on resident entries, as non-resident entries should not be made resident.
 		 * The bottom entry on the queue is always hot due to stack pruning.
 		 */
 		private void migrateToQueue() {
 			removeFromStack();
 			cold();
 		}
 
 		/**
 		 * Moves this entry from the queue to the stack, marking it hot (as cold
 		 * resident entries must remain in the queue).
 		 */
 		private void migrateToStack() {
 			removeFromQueue();
 			if (!inStack()) {
 				moveToStackBottom();
 			}
 			hot();
 		}
 
 		/**
 		 * Evicts this entry, removing it from the queue and setting its status to
 		 * cold non-resident. If the entry is already absent from the stack, it is
 		 * removed from the backing map; otherwise it remains in order for its
 		 * recency to be maintained.
 		 */
 		private void evict() {
 			removeFromQueue();
 			removeFromStack();
 			nonResident();
 			owner = null;
 		}
 
 		/**
 		 * Removes this entry from the cache. This operation is not specified in
 		 * the paper, which does not account for forced eviction.
 		 */
 		private V remove() {
 			boolean wasHot = (state == Recency.LIR_RESIDENT);
 			V result = value;
 			LIRSHashEntry<K,V> end = owner != null? owner.queueEnd():null;
 			evict();
 
 			// attempt to maintain a constant number of hot entries
 			if (wasHot) {
 				if (end != null) {
 					end.migrateToStack();
 				}
 			}
 
 			return result;
 		}
 	}
 
 
 	static final class LIRS<K, V> implements EvictionPolicy<K, V> {
 
 		/**
 		 * The percentage of the cache which is dedicated to hot blocks.
 		 * See section 5.1
 		 */
 		private static final float L_LIRS = 0.95f;
 
 		/** The owning segment */
 		private final Segment<K,V> segment;
 
 		/**
 		 * The accessQueue for reducing lock contention
 		 * See "BP-Wrapper: a system framework making any replacement algorithms
 		 * (almost) lock contention free"
 		 *
 		 * http://www.cse.ohio-state.edu/hpcs/WWW/HTML/publications/abs09-1.html
 		 *
 		 * */
 		private final ConcurrentLinkedQueue<LIRSHashEntry<K, V>> accessQueue;
 
 		/**
 		 * The maxBatchQueueSize
 		 *
 		 * See "BP-Wrapper: a system framework making any replacement algorithms (almost) lock
 		 * contention free"
 		 * */
 		private final int maxBatchQueueSize;
 
 		/** The number of LIRS entries in a segment */
 		private int size;
 
 		private final float batchThresholdFactor;
 
 
 		/**
 		 * This header encompasses two data structures:
 		 *
 		 * <ul>
 		 * <li>The LIRS stack, S, which is maintains recency information. All hot
 		 * entries are on the stack. All cold and non-resident entries which are more
 		 * recent than the least recent hot entry are also stored in the stack (the
 		 * stack is always pruned such that the last entry is hot, and all entries
 		 * accessed more recently than the last hot entry are present in the stack).
 		 * The stack is ordered by recency, with its most recently accessed entry
 		 * at the top, and its least recently accessed entry at the bottom.</li>
 		 *
 		 * <li>The LIRS queue, Q, which enqueues all cold entries for eviction. Cold
 		 * entries (by definition in the queue) may be absent from the stack (due to
 		 * pruning of the stack). Cold entries are added to the end of the queue
 		 * and entries are evicted from the front of the queue.</li>
 		 * </ul>
 		 */
 		private final LIRSHashEntry<K,V> header = new LIRSHashEntry<K,V>(null, null,0,null,null);
 
 		/** The maximum number of hot entries (L_lirs in the paper). */
 		private final int maximumHotSize;
 
 		/** The maximum number of resident entries (L in the paper). */
 		private final int maximumSize ;
 
 		/** The actual number of hot entries. */
-		private int hotSize = 0;
+		private int hotSize;
 
 
 
 		public LIRS(Segment<K,V> s, int capacity, int maxBatchSize, float batchThresholdFactor) {
 			this.segment = s;
 			this.maximumSize = capacity;
 			this.maximumHotSize = calculateLIRSize(capacity);
 			this.maxBatchQueueSize = maxBatchSize > MAX_BATCH_SIZE ? MAX_BATCH_SIZE : maxBatchSize;
 			this.batchThresholdFactor = batchThresholdFactor;
 			this.accessQueue = new ConcurrentLinkedQueue<LIRSHashEntry<K, V>>();
 		}
 
 		private static int calculateLIRSize(int maximumSize) {
 			int result = (int) (L_LIRS * maximumSize);
 			return (result == maximumSize) ? maximumSize - 1 : result;
 		}
 
 		@Override
 		public Set<HashEntry<K, V>> execute() {
 			Set<HashEntry<K, V>> evicted = new HashSet<HashEntry<K, V>>();
 			try {
 				for (LIRSHashEntry<K, V> e : accessQueue) {
 					if(e.isResident()){
 						e.hit(evicted);
 					}
 				}
 				removeFromSegment(evicted);
 			} finally {
 				accessQueue.clear();
 			}
 			return evicted;
 		}
 
 		/**
 		 * Prunes HIR blocks in the bottom of the stack until an HOT block sits in
 		 * the stack bottom. If pruned blocks were resident, then they
 		 * remain in the queue; otherwise they are no longer referenced, and are thus
 		 * removed from the backing map.
 		 */
 		private void pruneStack(Set<HashEntry<K,V>> evicted) {
 			// See section 3.3:
 			// "We define an operation called "stack pruning" on the LIRS
 			// stack S, which removes the HIR blocks in the bottom of
 			// the stack until an LIR block sits in the stack bottom. This
 			// operation serves for two purposes: (1) We ensure the block in
 			// the bottom of the stack always belongs to the LIR block set.
 			// (2) After the LIR block in the bottom is removed, those HIR
 			// blocks contiguously located above it will not have chances to
 			// change their status from HIR to LIR, because their recencies
 			// are larger than the new maximum recency of LIR blocks."
 			LIRSHashEntry<K, V> bottom = stackBottom();
 			while (bottom != null && bottom.state != Recency.LIR_RESIDENT) {
 				bottom.removeFromStack();
 				if (bottom.state == Recency.HIR_NONRESIDENT) {
 					evicted.add(bottom);
 				}
 				bottom = stackBottom();
 			}
 		}
 
 		@Override
 		public Set<HashEntry<K, V>> onEntryMiss(HashEntry<K, V> en) {
 			LIRSHashEntry<K, V> e = (LIRSHashEntry<K, V>) en;
 			Set<HashEntry<K, V>> evicted = e.miss();
 			removeFromSegment(evicted);
 			return evicted;
 		}
 
 		private void removeFromSegment(Set<HashEntry<K, V>> evicted) {
 			for (HashEntry<K, V> e : evicted) {
 				((LIRSHashEntry<K, V>)e).evict();
 				segment.evictionListener.onEntryChosenForEviction(e.value);
 				segment.remove(e.key, e.hash, null);
 			}
 		}
 
 		/*
 			   * Invoked without holding a lock on Segment
 			   */
 		@Override
 		public boolean onEntryHit(HashEntry<K, V> e) {
 			accessQueue.add((LIRSHashEntry<K, V>) e);
 			return accessQueue.size() >= maxBatchQueueSize * batchThresholdFactor;
 		}
 
 		/*
 			   * Invoked without holding a lock on Segment
 			   */
 		@Override
 		public boolean thresholdExpired() {
 			return accessQueue.size() >= maxBatchQueueSize;
 		}
 
 		@Override
 		public void onEntryRemove(HashEntry<K, V> e) {
 
 			((LIRSHashEntry<K,V>)e).remove();
 			// we could have multiple instances of e in accessQueue; remove them all
 			while (accessQueue.remove(e)) {
 			}
 		}
 
 		@Override
 		public void clear() {
 			accessQueue.clear();
 		}
 
 		@Override
 		public Eviction strategy() {
 			return Eviction.LIRS;
 		}
 
 		/**
 		 * Returns the entry at the bottom of the stack.
 		 */
 		private LIRSHashEntry<K, V> stackBottom() {
 			LIRSHashEntry<K, V> bottom = header.previousInStack;
 			return (bottom == header) ? null : bottom;
 		}
 
 		/**
 		 * Returns the entry at the front of the queue.
 		 */
 		private LIRSHashEntry<K, V> queueFront() {
 			LIRSHashEntry<K, V> front = header.nextInQueue;
 			return (front == header) ? null : front;
 		}
 
 		/**
 		 * Returns the entry at the end of the queue.
 		 */
 		private LIRSHashEntry<K, V> queueEnd() {
 			LIRSHashEntry<K, V> end = header.previousInQueue;
 			return (end == header) ? null : end;
 		}
 
 
 		@Override
 		public HashEntry<K, V> createNewEntry(K key, int hash, HashEntry<K, V> next, V value) {
 			return new LIRSHashEntry<K, V>(this,key, hash, next, value);
 		}
 	}
 
 	/**
 	 * Segments are specialized versions of hash tables.  This
 	 * subclasses from ReentrantLock opportunistically, just to
 	 * simplify some locking and avoid separate construction.
 	 */
 	static final class Segment<K,V> extends ReentrantLock {
 		/*
 			   * Segments maintain a table of entry lists that are ALWAYS
 			   * kept in a consistent state, so can be read without locking.
 			   * Next fields of nodes are immutable (final).  All list
 			   * additions are performed at the front of each bin. This
 			   * makes it easy to check changes, and also fast to traverse.
 			   * When nodes would otherwise be changed, new nodes are
 			   * created to replace them. This works well for hash tables
 			   * since the bin lists tend to be short. (The average length
 			   * is less than two for the default load factor threshold.)
 			   *
 			   * Read operations can thus proceed without locking, but rely
 			   * on selected uses of volatiles to ensure that completed
 			   * write operations performed by other threads are
 			   * noticed. For most purposes, the "count" field, tracking the
 			   * number of elements, serves as that volatile variable
 			   * ensuring visibility.  This is convenient because this field
 			   * needs to be read in many read operations anyway:
 			   *
 			   *   - All (unsynchronized) read operations must first read the
 			   *     "count" field, and should not look at table entries if
 			   *     it is 0.
 			   *
 			   *   - All (synchronized) write operations should write to
 			   *     the "count" field after structurally changing any bin.
 			   *     The operations must not take any action that could even
 			   *     momentarily cause a concurrent read operation to see
 			   *     inconsistent data. This is made easier by the nature of
 			   *     the read operations in Map. For example, no operation
 			   *     can reveal that the table has grown but the threshold
 			   *     has not yet been updated, so there are no atomicity
 			   *     requirements for this with respect to reads.
 			   *
 			   * As a guide, all critical volatile reads and writes to the
 			   * count field are marked in code comments.
 			   */
 
 		private static final long serialVersionUID = 2249069246763182397L;
 
 		/**
 		 * The number of elements in this segment's region.
 		 */
 		transient volatile int count;
 
 		/**
 		 * Number of updates that alter the size of the table. This is
 		 * used during bulk-read methods to make sure they see a
 		 * consistent snapshot: If modCounts change during a traversal
 		 * of segments computing size or checking containsValue, then
 		 * we might have an inconsistent view of state so (usually)
 		 * must retry.
 		 */
 		transient int modCount;
 
 		/**
 		 * The table is rehashed when its size exceeds this threshold.
 		 * (The value of this field is always <tt>(int)(capacity *
 		 * loadFactor)</tt>.)
 		 */
 		transient int threshold;
 
 		/**
 		 * The per-segment table.
 		 */
 		transient volatile HashEntry<K,V>[] table;
 
 		/**
 		 * The load factor for the hash table.  Even though this value
 		 * is same for all segments, it is replicated to avoid needing
 		 * links to outer object.
 		 * @serial
 		 */
 		final float loadFactor;
 
 		final int evictCap;
 
 		transient final EvictionPolicy<K, V> eviction;
 
 		transient final EvictionListener<K, V> evictionListener;
 
 		Segment(int cap, int evictCap, float lf, Eviction es, EvictionListener<K, V> listener) {
 			loadFactor = lf;
 			this.evictCap = evictCap;
 			eviction = es.make(this, evictCap, lf);
 			evictionListener = listener;
 			setTable(HashEntry.<K, V> newArray(cap));
 		}
 
 		@SuppressWarnings("unchecked")
 		static <K,V> Segment<K,V>[] newArray(int i) {
 			return new Segment[i];
 		}
 
 		EvictionListener<K, V> getEvictionListener() {
 			return evictionListener;
 		}
 
 		/**
 		 * Sets table to new HashEntry array.
 		 * Call only while holding lock or in constructor.
 		 */
 		void setTable(HashEntry<K,V>[] newTable) {
 			threshold = (int)(newTable.length * loadFactor);
 			table = newTable;
 		}
 
 		/**
 		 * Returns properly casted first entry of bin for given hash.
 		 */
 		HashEntry<K,V> getFirst(int hash) {
 			HashEntry<K,V>[] tab = table;
 			return tab[hash & tab.length - 1];
 		}
 
 		/**
 		 * Reads value field of an entry under lock. Called if value
 		 * field ever appears to be null. This is possible only if a
 		 * compiler happens to reorder a HashEntry initialization with
 		 * its table assignment, which is legal under memory model
 		 * but is not known to ever occur.
 		 */
 		V readValueUnderLock(HashEntry<K,V> e) {
 			lock();
 			try {
 				return e.value;
 			} finally {
 				unlock();
 			}
 		}
 
 		/* Specialized implementations of map methods */
 
 		V get(Object key, int hash) {
 			int c = count;
 			if (c != 0) { // read-volatile
 				V result = null;
 				HashEntry<K, V> e = getFirst(hash);
 				while (e != null) {
 					if (e.hash == hash && key.equals(e.key)) {
 						V v = e.value;
 						if (v != null) {
 							result = v;
 							break;
 						} else {
 							result = readValueUnderLock(e); // recheck
 							break;
 						}
 					}
 					e = e.next;
 				}
 				// a hit
 				if (result != null) {
 					if (eviction.onEntryHit(e)) {
 						Set<HashEntry<K, V>> evicted = attemptEviction(false);
 						notifyEvictionListener(evicted);
 					}
 				}
 				return result;
 			}
 			return null;
 		}
 
 		boolean containsKey(Object key, int hash) {
 			if (count != 0) { // read-volatile
 				HashEntry<K,V> e = getFirst(hash);
 				while (e != null) {
 					if (e.hash == hash && key.equals(e.key)) {
 						return true;
 					}
 					e = e.next;
 				}
 			}
 			return false;
 		}
 
 		boolean containsValue(Object value) {
 			if (count != 0) { // read-volatile
 				HashEntry<K,V>[] tab = table;
 				int len = tab.length;
 				for (int i = 0 ; i < len; i++) {
 					for (HashEntry<K,V> e = tab[i]; e != null; e = e.next) {
 						V v = e.value;
 						if (v == null) {
 							v = readValueUnderLock(e);
 						}
 						if (value.equals(v)) {
 							return true;
 						}
 					}
 				}
 			}
 			return false;
 		}
 
 		boolean replace(K key, int hash, V oldValue, V newValue) {
 			lock();
 			Set<HashEntry<K, V>> evicted = null;
 			try {
 				HashEntry<K, V> e = getFirst(hash);
 				while (e != null && (e.hash != hash || !key.equals(e.key))) {
 					e = e.next;
 				}
 
 				boolean replaced = false;
 				if (e != null && oldValue.equals(e.value)) {
 					replaced = true;
 					e.value = newValue;
 					if (eviction.onEntryHit(e)) {
 						evicted = attemptEviction(true);
 					}
 				}
 				return replaced;
 			} finally {
 				unlock();
 				notifyEvictionListener(evicted);
 			}
 		}
 
 		V replace(K key, int hash, V newValue) {
 			lock();
 			Set<HashEntry<K, V>> evicted = null;
 			try {
 				HashEntry<K, V> e = getFirst(hash);
 				while (e != null && (e.hash != hash || !key.equals(e.key))) {
 					e = e.next;
 				}
 
 				V oldValue = null;
 				if (e != null) {
 					oldValue = e.value;
 					e.value = newValue;
 					if (eviction.onEntryHit(e)) {
 						evicted = attemptEviction(true);
 					}
 				}
 				return oldValue;
 			} finally {
 				unlock();
 				notifyEvictionListener(evicted);
 			}
 		}
 
 		V put(K key, int hash, V value, boolean onlyIfAbsent) {
 			lock();
 			Set<HashEntry<K, V>> evicted = null;
 			try {
 				int c = count;
 				if (c++ > threshold && eviction.strategy() == Eviction.NONE) {
 					rehash();
 				}
 				HashEntry<K, V>[] tab = table;
 				int index = hash & tab.length - 1;
 				HashEntry<K, V> first = tab[index];
 				HashEntry<K, V> e = first;
 				while (e != null && (e.hash != hash || !key.equals(e.key))) {
 					e = e.next;
 				}
 
 				V oldValue;
 				if (e != null) {
 					oldValue = e.value;
 					if (!onlyIfAbsent) {
 						e.value = value;
 						eviction.onEntryHit(e);
 					}
 				} else {
 					oldValue = null;
 					++modCount;
 					count = c; // write-volatile
 					if (eviction.strategy() != Eviction.NONE) {
 						if (c > evictCap) {
 							// remove entries;lower count
 							evicted = eviction.execute();
 							// re-read first
 							first = tab[index];
 						}
 						// add a new entry
 						tab[index] = eviction.createNewEntry(key, hash, first, value);
 						// notify a miss
 						Set<HashEntry<K, V>> newlyEvicted = eviction.onEntryMiss(tab[index]);
 						if (!newlyEvicted.isEmpty()) {
 							if (evicted != null) {
 								evicted.addAll(newlyEvicted);
 							} else {
 								evicted = newlyEvicted;
 							}
 						}
 					} else {
 						tab[index] = eviction.createNewEntry(key, hash, first, value);
 					}
 				}
 				return oldValue;
 			} finally {
 				unlock();
 				notifyEvictionListener(evicted);
 			}
 		}
 
 		void rehash() {
 			HashEntry<K,V>[] oldTable = table;
 			int oldCapacity = oldTable.length;
 			if (oldCapacity >= MAXIMUM_CAPACITY) {
 				return;
 			}
 
 			/*
 					  * Reclassify nodes in each list to new Map.  Because we are
 					  * using power-of-two expansion, the elements from each bin
 					  * must either stay at same index, or move with a power of two
 					  * offset. We eliminate unnecessary node creation by catching
 					  * cases where old nodes can be reused because their next
 					  * fields won't change. Statistically, at the default
 					  * threshold, only about one-sixth of them need cloning when
 					  * a table doubles. The nodes they replace will be garbage
 					  * collectable as soon as they are no longer referenced by any
 					  * reader thread that may be in the midst of traversing table
 					  * right now.
 					  */
 
 			HashEntry<K,V>[] newTable = HashEntry.newArray(oldCapacity<<1);
 			threshold = (int)(newTable.length * loadFactor);
 			int sizeMask = newTable.length - 1;
 			for (int i = 0; i < oldCapacity ; i++) {
 				// We need to guarantee that any existing reads of old Map can
 				//  proceed. So we cannot yet null out each bin.
 				HashEntry<K,V> e = oldTable[i];
 
 				if (e != null) {
 					HashEntry<K,V> next = e.next;
 					int idx = e.hash & sizeMask;
 
 					//  Single node on list
 					if (next == null) {
 						newTable[idx] = e;
 					} else {
 						// Reuse trailing consecutive sequence at same slot
 						HashEntry<K,V> lastRun = e;
 						int lastIdx = idx;
 						for (HashEntry<K,V> last = next;
 							 last != null;
 							 last = last.next) {
 							int k = last.hash & sizeMask;
 							if (k != lastIdx) {
 								lastIdx = k;
 								lastRun = last;
 							}
 						}
 						newTable[lastIdx] = lastRun;
 
 						// Clone all remaining nodes
 						for (HashEntry<K,V> p = e; p != lastRun; p = p.next) {
 							int k = p.hash & sizeMask;
 							HashEntry<K,V> n = newTable[k];
 							newTable[k] = eviction.createNewEntry(p.key, p.hash, n, p.value);
 						}
 					}
 				}
 			}
 			table = newTable;
 		}
 
 		/**
 		 * Remove; match on key only if value null, else match both.
 		 */
 		V remove(Object key, int hash, Object value) {
 			lock();
 			try {
 				int c = count - 1;
 				HashEntry<K, V>[] tab = table;
 				int index = hash & tab.length - 1;
 				HashEntry<K, V> first = tab[index];
 				HashEntry<K, V> e = first;
 				while (e != null && (e.hash != hash || !key.equals(e.key))) {
 					e = e.next;
 				}
 
 				V oldValue = null;
 				if (e != null) {
 					V v = e.value;
 					if (value == null || value.equals(v)) {
 						oldValue = v;
 						// All entries following removed node can stay
 						// in list, but all preceding ones need to be
 						// cloned.
 						++modCount;
 
 						// e was removed
 						eviction.onEntryRemove(e);
 
 						HashEntry<K, V> newFirst = e.next;
 						for (HashEntry<K, V> p = first; p != e; p = p.next) {
 							// TODO A remove operation makes the map behave like all the other keys in the bucket were just added???
 							// allow p to be GC-ed
 							eviction.onEntryRemove(p);
 							newFirst = eviction.createNewEntry(p.key, p.hash, newFirst, p.value);
 							// and notify eviction algorithm about new hash entries
 							eviction.onEntryMiss(newFirst);
 						}
 
 						tab[index] = newFirst;
 						count = c; // write-volatile
 					}
 				}
 				return oldValue;
 			} finally {
 				unlock();
 			}
 		}
 
 		void clear() {
 			if (count != 0) {
 				lock();
 				try {
 					HashEntry<K, V>[] tab = table;
 					for (int i = 0; i < tab.length; i++) {
 						tab[i] = null;
 					}
 					++modCount;
 					eviction.clear();
 					count = 0; // write-volatile
 				} finally {
 					unlock();
 				}
 			}
 		}
 
 		private Set<HashEntry<K, V>> attemptEviction(boolean lockedAlready) {
 			Set<HashEntry<K, V>> evicted = null;
 			boolean obtainedLock = lockedAlready || tryLock();
 			if (!obtainedLock && eviction.thresholdExpired()) {
 				lock();
 				obtainedLock = true;
 			}
 			if (obtainedLock) {
 				try {
 					if (eviction.thresholdExpired()) {
 						evicted = eviction.execute();
 					}
 				} finally {
 					if (!lockedAlready) {
 						unlock();
 					}
 				}
 			}
 			return evicted;
 		}
 
 		private void notifyEvictionListener(Set<HashEntry<K, V>> evicted) {
 			// piggyback listener invocation on callers thread outside lock
 			if (evicted != null) {
 				Map<K, V> evictedCopy;
 				if (evicted.size() == 1) {
 					HashEntry<K, V> evictedEntry = evicted.iterator().next();
 					evictedCopy = singletonMap(evictedEntry.key, evictedEntry.value);
 				} else {
 					evictedCopy = new HashMap<K, V>(evicted.size());
 					for (HashEntry<K, V> he : evicted) {
 						evictedCopy.put(he.key, he.value);
 					}
 					evictedCopy = unmodifiableMap(evictedCopy);
 				}
 				evictionListener.onEntryEviction(evictedCopy);
 			}
 		}
 	}
 
 
 	/* ---------------- Public operations -------------- */
 
 
 	/**
 	 * Creates a new, empty map with the specified maximum capacity, load factor and concurrency
 	 * level.
 	 *
 	 * @param capacity
 	 *            is the upper bound capacity for the number of elements in this map
 	 *
 	 * @param concurrencyLevel
 	 *            the estimated number of concurrently updating threads. The implementation performs
 	 *            internal sizing to try to accommodate this many threads.
 	 *
 	 * @param evictionStrategy
 	 *            the algorithm used to evict elements from this map
 	 *
 	 * @param evictionListener
 	 *            the evicton listener callback to be notified about evicted elements
 	 *
 	 * @throws IllegalArgumentException
 	 *             if the initial capacity is negative or the load factor or concurrencyLevel are
 	 *             nonpositive.
 	 */
 	public BoundedConcurrentHashMap(int capacity, int concurrencyLevel,
 									Eviction evictionStrategy, EvictionListener<K, V> evictionListener) {
 		if (capacity < 0 || concurrencyLevel <= 0) {
 			throw new IllegalArgumentException();
 		}
 
 		concurrencyLevel = Math.min(capacity / 2, concurrencyLevel); // concurrencyLevel cannot be > capacity/2
 		concurrencyLevel = Math.max(concurrencyLevel, 1); // concurrencyLevel cannot be less than 1
 
 		// minimum two elements per segment
 		if (capacity < concurrencyLevel * 2 && capacity != 1) {
 			throw new IllegalArgumentException("Maximum capacity has to be at least twice the concurrencyLevel");
 		}
 
 		if (evictionStrategy == null || evictionListener == null) {
 			throw new IllegalArgumentException();
 		}
 
 		if (concurrencyLevel > MAX_SEGMENTS) {
 			concurrencyLevel = MAX_SEGMENTS;
 		}
 
 		// Find power-of-two sizes best matching arguments
 		int sshift = 0;
 		int ssize = 1;
 		while (ssize < concurrencyLevel) {
 			++sshift;
 			ssize <<= 1;
 		}
 		segmentShift = 32 - sshift;
 		segmentMask = ssize - 1;
 		this.segments = Segment.newArray(ssize);
 
 		if (capacity > MAXIMUM_CAPACITY) {
 			capacity = MAXIMUM_CAPACITY;
 		}
 		int c = capacity / ssize;
 		int cap = 1;
 		while (cap < c) {
 			cap <<= 1;
 		}
 
 		for (int i = 0; i < this.segments.length; ++i) {
 			this.segments[i] = new Segment<K, V>(cap, c, DEFAULT_LOAD_FACTOR, evictionStrategy, evictionListener);
 		}
 	}
 
 	/**
 	 * Creates a new, empty map with the specified maximum capacity, load factor, concurrency
 	 * level and LRU eviction policy.
 	 *
 	 * @param capacity
 	 *            is the upper bound capacity for the number of elements in this map
 	 *
 	 * @param concurrencyLevel
 	 *            the estimated number of concurrently updating threads. The implementation performs
 	 *            internal sizing to try to accommodate this many threads.
 	 *
 	 * @throws IllegalArgumentException
 	 *             if the initial capacity is negative or the load factor or concurrencyLevel are
 	 *             nonpositive.
 	 */
 	public BoundedConcurrentHashMap(int capacity, int concurrencyLevel) {
 		this(capacity, concurrencyLevel, Eviction.LRU);
 	}
 
 	/**
 	 * Creates a new, empty map with the specified maximum capacity, load factor, concurrency
 	 * level and eviction strategy.
 	 *
 	 * @param capacity
 	 *            is the upper bound capacity for the number of elements in this map
 	 *
 	 * @param concurrencyLevel
 	 *            the estimated number of concurrently updating threads. The implementation performs
 	 *            internal sizing to try to accommodate this many threads.
 	 *
 	 * @param evictionStrategy
 	 *            the algorithm used to evict elements from this map
 	 *
 	 * @throws IllegalArgumentException
 	 *             if the initial capacity is negative or the load factor or concurrencyLevel are
 	 *             nonpositive.
 	 */
 	public BoundedConcurrentHashMap(int capacity, int concurrencyLevel, Eviction evictionStrategy) {
 		this(capacity, concurrencyLevel, evictionStrategy, new NullEvictionListener<K, V>());
 	}
 
 	/**
 	 * Creates a new, empty map with the specified maximum capacity, default concurrency
 	 * level and LRU eviction policy.
 	 *
 	 *  @param capacity
 	 *            is the upper bound capacity for the number of elements in this map
 	 *
 	 *
 	 * @throws IllegalArgumentException if the initial capacity of
 	 * elements is negative or the load factor is nonpositive
 	 *
 	 * @since 1.6
 	 */
 	public BoundedConcurrentHashMap(int capacity) {
 		this(capacity, DEFAULT_CONCURRENCY_LEVEL);
 	}
 
 	/**
 	 * Creates a new, empty map with the default maximum capacity
 	 */
 	public BoundedConcurrentHashMap() {
 		this(DEFAULT_MAXIMUM_CAPACITY, DEFAULT_CONCURRENCY_LEVEL);
 	}
 
 	/**
 	 * Returns <tt>true</tt> if this map contains no key-value mappings.
 	 *
 	 * @return <tt>true</tt> if this map contains no key-value mappings
 	 */
 	@Override
 	public boolean isEmpty() {
 		final Segment<K,V>[] segments = this.segments;
 		/*
 			   * We keep track of per-segment modCounts to avoid ABA
 			   * problems in which an element in one segment was added and
 			   * in another removed during traversal, in which case the
 			   * table was never actually empty at any point. Note the
 			   * similar use of modCounts in the size() and containsValue()
 			   * methods, which are the only other methods also susceptible
 			   * to ABA problems.
 			   */
 		int[] mc = new int[segments.length];
 		int mcsum = 0;
 		for (int i = 0; i < segments.length; ++i) {
 			if (segments[i].count != 0) {
 				return false;
 			} else {
 				mcsum += mc[i] = segments[i].modCount;
 			}
 		}
 		// If mcsum happens to be zero, then we know we got a snapshot
 		// before any modifications at all were made.  This is
 		// probably common enough to bother tracking.
 		if (mcsum != 0) {
 			for (int i = 0; i < segments.length; ++i) {
 				if (segments[i].count != 0 || mc[i] != segments[i].modCount) {
 					return false;
 				}
 			}
 		}
 		return true;
 	}
 
 	/**
 	 * Returns the number of key-value mappings in this map.  If the
 	 * map contains more than <tt>Integer.MAX_VALUE</tt> elements, returns
 	 * <tt>Integer.MAX_VALUE</tt>.
 	 *
 	 * @return the number of key-value mappings in this map
 	 */
 	@Override
 	public int size() {
 		final Segment<K,V>[] segments = this.segments;
 		long sum = 0;
 		long check = 0;
 		int[] mc = new int[segments.length];
 		// Try a few times to get accurate count. On failure due to
 		// continuous async changes in table, resort to locking.
 		for (int k = 0; k < RETRIES_BEFORE_LOCK; ++ k) {
 			check = 0;
 			sum = 0;
 			int mcsum = 0;
 			for (int i = 0; i < segments.length; ++ i) {
 				sum += segments[i].count;
 				mcsum += mc[i] = segments[i].modCount;
 			}
 			if (mcsum != 0) {
 				for (int i = 0; i < segments.length; ++ i) {
 					check += segments[i].count;
 					if (mc[i] != segments[i].modCount) {
 						check = -1; // force retry
 						break;
 					}
 				}
 			}
 			if (check == sum) {
 				break;
 			}
 		}
 		if (check != sum) { // Resort to locking all segments
 			sum = 0;
 			for (int i = 0; i < segments.length; ++ i) {
 				segments[i].lock();
 			}
 			try {
 				for (int i = 0; i < segments.length; ++ i) {
 					sum += segments[i].count;
 				}
 			} finally {
 				for (int i = 0; i < segments.length; ++ i) {
 					segments[i].unlock();
 				}
 			}
 		}
 		if (sum > Integer.MAX_VALUE) {
 			return Integer.MAX_VALUE;
 		} else {
 			return (int) sum;
 		}
 	}
 
 	/**
 	 * Returns the value to which the specified key is mapped,
 	 * or {@code null} if this map contains no mapping for the key.
 	 *
 	 * <p>More formally, if this map contains a mapping from a key
 	 * {@code k} to a value {@code v} such that {@code key.equals(k)},
 	 * then this method returns {@code v}; otherwise it returns
 	 * {@code null}.  (There can be at most one such mapping.)
 	 *
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public V get(Object key) {
 		int hash = hash(key.hashCode());
 		return segmentFor(hash).get(key, hash);
 	}
 
 	/**
 	 * Tests if the specified object is a key in this table.
 	 *
 	 * @param  key   possible key
 	 * @return <tt>true</tt> if and only if the specified object
 	 *         is a key in this table, as determined by the
 	 *         <tt>equals</tt> method; <tt>false</tt> otherwise.
 	 * @throws NullPointerException if the specified key is null
 	 */
 	@Override
 	public boolean containsKey(Object key) {
 		int hash = hash(key.hashCode());
 		return segmentFor(hash).containsKey(key, hash);
 	}
 
 	/**
 	 * Returns <tt>true</tt> if this map maps one or more keys to the
 	 * specified value. Note: This method requires a full internal
 	 * traversal of the hash table, and so is much slower than
 	 * method <tt>containsKey</tt>.
 	 *
 	 * @param value value whose presence in this map is to be tested
 	 * @return <tt>true</tt> if this map maps one or more keys to the
 	 *         specified value
 	 * @throws NullPointerException if the specified value is null
 	 */
 	@Override
 	public boolean containsValue(Object value) {
 		if (value == null) {
 			throw new NullPointerException();
 		}
 
 		// See explanation of modCount use above
 
 		final Segment<K, V>[] segments = this.segments;
 		int[] mc = new int[segments.length];
 
 		// Try a few times without locking
 		for (int k = 0; k < RETRIES_BEFORE_LOCK; ++ k) {
 			int mcsum = 0;
 			for (int i = 0; i < segments.length; ++ i) {
 				@SuppressWarnings("unused")
 				int c = segments[i].count; // read-volatile
 				mcsum += mc[i] = segments[i].modCount;
 				if (segments[i].containsValue(value)) {
 					return true;
 				}
 			}
 			boolean cleanSweep = true;
 			if (mcsum != 0) {
 				for (int i = 0; i < segments.length; ++ i) {
 					@SuppressWarnings("unused")
 					int c = segments[i].count; // read-volatile
 					if (mc[i] != segments[i].modCount) {
 						cleanSweep = false;
 						break;
 					}
 				}
 			}
 			if (cleanSweep) {
 				return false;
 			}
 		}
 		// Resort to locking all segments
 		for (int i = 0; i < segments.length; ++ i) {
 			segments[i].lock();
 		}
 		boolean found = false;
 		try {
 			for (int i = 0; i < segments.length; ++ i) {
 				if (segments[i].containsValue(value)) {
 					found = true;
 					break;
 				}
 			}
 		} finally {
 			for (int i = 0; i < segments.length; ++ i) {
 				segments[i].unlock();
 			}
 		}
 		return found;
 	}
 
 	/**
 	 * Legacy method testing if some key maps into the specified value
 	 * in this table.  This method is identical in functionality to
 	 * {@link #containsValue}, and exists solely to ensure
 	 * full compatibility with class {@link Hashtable},
 	 * which supported this method prior to introduction of the
 	 * Java Collections framework.
 
 	 * @param  value a value to search for
 	 * @return <tt>true</tt> if and only if some key maps to the
 	 *         <tt>value</tt> argument in this table as
 	 *         determined by the <tt>equals</tt> method;
 	 *         <tt>false</tt> otherwise
 	 * @throws NullPointerException if the specified value is null
 	 */
 	public boolean contains(Object value) {
 		return containsValue(value);
 	}
 
 	/**
 	 * Maps the specified key to the specified value in this table.
 	 * Neither the key nor the value can be null.
 	 *
 	 * <p> The value can be retrieved by calling the <tt>get</tt> method
 	 * with a key that is equal to the original key.
 	 *
 	 * @param key key with which the specified value is to be associated
 	 * @param value value to be associated with the specified key
 	 * @return the previous value associated with <tt>key</tt>, or
 	 *         <tt>null</tt> if there was no mapping for <tt>key</tt>
 	 * @throws NullPointerException if the specified key or value is null
 	 */
 	@Override
 	public V put(K key, V value) {
 		if (value == null) {
 			throw new NullPointerException();
 		}
 		int hash = hash(key.hashCode());
 		return segmentFor(hash).put(key, hash, value, false);
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @return the previous value associated with the specified key,
 	 *         or <tt>null</tt> if there was no mapping for the key
 	 * @throws NullPointerException if the specified key or value is null
 	 */
 	@Override
 	public V putIfAbsent(K key, V value) {
 		if (value == null) {
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/IdentityMap.java b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/IdentityMap.java
index 2bdadd83a5..ee24b54412 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/collections/IdentityMap.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/collections/IdentityMap.java
@@ -1,270 +1,269 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.internal.util.collections;
 
 import java.io.Serializable;
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.Map;
 import java.util.Set;
 
 /**
  * A <tt>Map</tt> where keys are compared by object identity,
  * rather than <tt>equals()</tt>.
  */
 public final class IdentityMap<K,V> implements Map<K,V> {
-
 	private final Map<IdentityKey<K>,V> map;
 	@SuppressWarnings( {"unchecked"})
 	private transient Entry<IdentityKey<K>,V>[] entryArray = new Entry[0];
-	private transient boolean dirty = false;
+	private transient boolean dirty;
 
 	/**
 	 * Return a new instance of this class, with iteration
 	 * order defined as the order in which entries were added
 	 *
 	 * @param size The size of the map to create
 	 * @return The map
 	 */
 	public static <K,V> IdentityMap<K,V> instantiateSequenced(int size) {
 		return new IdentityMap<K,V>( new LinkedHashMap<IdentityKey<K>,V>( size ) );
 	}
 
 	/**
 	 * Private ctor used in serialization.
 	 *
 	 * @param underlyingMap The delegate map.
 	 */
 	private IdentityMap(Map<IdentityKey<K>,V> underlyingMap) {
 		map = underlyingMap;
 		dirty = true;
 	}
 
 	/**
 	 * Return the map entries (as instances of <tt>Map.Entry</tt> in a collection that
 	 * is safe from concurrent modification). ie. we may safely add new instances to
 	 * the underlying <tt>Map</tt> during iteration of the <tt>entries()</tt>.
 	 *
 	 * @param map The map of entries
 	 * @return Collection
 	 */
 	public static <K,V> Map.Entry<K,V>[] concurrentEntries(Map<K,V> map) {
 		return ( (IdentityMap<K,V>) map ).entryArray();
 	}
 
 	public Iterator<K> keyIterator() {
 		return new KeyIterator<K>( map.keySet().iterator() );
 	}
 
 	@Override
 	public int size() {
 		return map.size();
 	}
 
 	@Override
 	public boolean isEmpty() {
 		return map.isEmpty();
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public boolean containsKey(Object key) {
 		return map.containsKey( new IdentityKey( key ) );
 	}
 
 	@Override
 	public boolean containsValue(Object val) {
 		return map.containsValue(val);
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public V get(Object key) {
 		return map.get( new IdentityKey(key) );
 	}
 
 	@Override
 	public V put(K key, V value) {
 		dirty = true;
 		return map.put( new IdentityKey<K>(key), value );
 	}
 
 	@Override
 	@SuppressWarnings( {"unchecked"})
 	public V remove(Object key) {
 		dirty = true;
 		return map.remove( new IdentityKey(key) );
 	}
 
 	@Override
 	public void putAll(Map<? extends K, ? extends V> otherMap) {
 		for ( Entry<? extends K, ? extends V> entry : otherMap.entrySet() ) {
 			put( entry.getKey(), entry.getValue() );
 		}
 	}
 
 	@Override
 	public void clear() {
 		dirty = true;
 		entryArray = null;
 		map.clear();
 	}
 
 	@Override
 	public Set<K> keySet() {
 		// would need an IdentitySet for this!
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public Collection<V> values() {
 		return map.values();
 	}
 
 	@Override
 	public Set<Entry<K,V>> entrySet() {
 		Set<Entry<K,V>> set = new HashSet<Entry<K,V>>( map.size() );
 		for ( Entry<IdentityKey<K>, V> entry : map.entrySet() ) {
 			set.add( new IdentityMapEntry<K,V>( entry.getKey().getRealKey(), entry.getValue() ) );
 		}
 		return set;
 	}
 
 	@SuppressWarnings( {"unchecked"})
 	public Map.Entry[] entryArray() {
 		if (dirty) {
 			entryArray = new Map.Entry[ map.size() ];
 			Iterator itr = map.entrySet().iterator();
 			int i=0;
 			while ( itr.hasNext() ) {
 				Map.Entry me = (Map.Entry) itr.next();
 				entryArray[i++] = new IdentityMapEntry( ( (IdentityKey) me.getKey() ).key, me.getValue() );
 			}
 			dirty = false;
 		}
 		return entryArray;
 	}
 
 	@Override
     public String toString() {
 		return map.toString();
 	}
 
 	static final class KeyIterator<K> implements Iterator<K> {
 		private final Iterator<IdentityKey<K>> identityKeyIterator;
 
 		private KeyIterator(Iterator<IdentityKey<K>> iterator) {
 			identityKeyIterator = iterator;
 		}
 
 		public boolean hasNext() {
 			return identityKeyIterator.hasNext();
 		}
 
 		public K next() {
 			return identityKeyIterator.next().getRealKey();
 		}
 
 		public void remove() {
 			throw new UnsupportedOperationException();
 		}
 
 	}
 		public static final class IdentityMapEntry<K,V> implements java.util.Map.Entry<K,V> {
 		private final K key;
 		private V value;
 
 		IdentityMapEntry(final K key, final V value) {
 			this.key=key;
 			this.value=value;
 		}
 
 		public K getKey() {
 			return key;
 		}
 
 		public V getValue() {
 			return value;
 		}
 
 		public V setValue(final V value) {
 			V result = this.value;
 			this.value = value;
 			return result;
 		}
 	}
 
 	/**
 	 * We need to base the identity on {@link System#identityHashCode(Object)} but
 	 * attempt to lazily initialize and cache this value: being a native invocation
 	 * it is an expensive value to retrieve.
 	 */
 	public static final class IdentityKey<K> implements Serializable {
 
 		private final K key;
-		private int hash = 0;
+		private int hash;
 
 		IdentityKey(K key) {
 			this.key = key;
 		}
 
 		@SuppressWarnings( {"EqualsWhichDoesntCheckParameterClass"})
 		@Override
 		public boolean equals(Object other) {
 			return key == ( (IdentityKey) other ).key;
 		}
 
 		@Override
 		public int hashCode() {
 			if ( this.hash == 0 ) {
 				//We consider "zero" as non-initialized value
 				final int newHash = System.identityHashCode( key );
 				if ( newHash == 0 ) {
 					//So make sure we don't store zeros as it would trigger initialization again:
 					//any value is fine as long as we're deterministic.
 					this.hash = -1;
 					return -1;
 				}
 				else {
 					this.hash = newHash;
 					return newHash;
 				}
 			}
 			return hash;
 		}
 
 		@Override
 		public String toString() {
 			return key.toString();
 		}
 
 		public K getRealKey() {
 			return key;
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/io/StreamCopier.java b/hibernate-core/src/main/java/org/hibernate/internal/util/io/StreamCopier.java
index 6852125b23..f5cb92fe05 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/io/StreamCopier.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/io/StreamCopier.java
@@ -1,65 +1,68 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util.io;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.OutputStream;
 
 import org.hibernate.HibernateException;
 
 /**
  * Utilities for copying I/O streams.
  *
  * @author Steve Ebersole
  */
-public class StreamCopier {
+public final class StreamCopier {
+	private StreamCopier() {
+	}
+
 	public static final int BUFFER_SIZE = 1024 * 4;
 	public static final byte[] BUFFER = new byte[ BUFFER_SIZE ];
 
 	public static long copy(InputStream from, OutputStream into) {
 		try {
 			long totalRead = 0;
 			while ( true ) {
 				synchronized ( BUFFER ) {
 					int amountRead = from.read( BUFFER );
 					if ( amountRead == -1 ) {
 						break;
 					}
 					into.write( BUFFER, 0, amountRead );
 					totalRead += amountRead;
 					if ( amountRead < BUFFER_SIZE ) {
 						// should mean there is no more data in the stream, no need for next read
 						break;
 					}
 				}
 			}
 			return totalRead;
 		}
 		catch (IOException e ) {
 			throw new HibernateException( "Unable to copy stream content", e );
 		}
 	}
 }
 
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/type/PrimitiveWrapperHelper.java b/hibernate-core/src/main/java/org/hibernate/internal/util/type/PrimitiveWrapperHelper.java
index 89a5ff3579..f0f355f5a1 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/type/PrimitiveWrapperHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/type/PrimitiveWrapperHelper.java
@@ -1,282 +1,285 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util.type;
 
 /**
  * Helper for primitive/wrapper utilities.
  *
  * @author Steve Ebersole
  */
-public class PrimitiveWrapperHelper {
+public final class PrimitiveWrapperHelper {
+	private PrimitiveWrapperHelper() {
+	}
+
 	/**
 	 * Describes a particular primitive/wrapper combo
 	 */
 	public static interface PrimitiveWrapperDescriptor<T> {
 		public Class<T> getPrimitiveClass();
 		public Class<T> getWrapperClass();
 	}
 
 	public static class BooleanDescriptor implements PrimitiveWrapperDescriptor<Boolean> {
 		public static final BooleanDescriptor INSTANCE = new BooleanDescriptor();
 
 		private BooleanDescriptor() {
 		}
 
 		@Override
 		public Class<Boolean> getPrimitiveClass() {
 			return boolean.class;
 		}
 
 		@Override
 		public Class<Boolean> getWrapperClass() {
 			return Boolean.class;
 		}
 	}
 
 	public static class CharacterDescriptor implements PrimitiveWrapperDescriptor<Character> {
 		public static final CharacterDescriptor INSTANCE = new CharacterDescriptor();
 
 		private CharacterDescriptor() {
 		}
 
 		@Override
 		public Class<Character> getPrimitiveClass() {
 			return char.class;
 		}
 
 		@Override
 		public Class<Character> getWrapperClass() {
 			return Character.class;
 		}
 	}
 
 	public static class ByteDescriptor implements PrimitiveWrapperDescriptor<Byte> {
 		public static final ByteDescriptor INSTANCE = new ByteDescriptor();
 
 		private ByteDescriptor() {
 		}
 
 		@Override
 		public Class<Byte> getPrimitiveClass() {
 			return byte.class;
 		}
 
 		@Override
 		public Class<Byte> getWrapperClass() {
 			return Byte.class;
 		}
 	}
 
 	public static class ShortDescriptor implements PrimitiveWrapperDescriptor<Short> {
 		public static final ShortDescriptor INSTANCE = new ShortDescriptor();
 
 		private ShortDescriptor() {
 		}
 
 		@Override
 		public Class<Short> getPrimitiveClass() {
 			return short.class;
 		}
 
 		@Override
 		public Class<Short> getWrapperClass() {
 			return Short.class;
 		}
 	}
 
 	public static class IntegerDescriptor implements PrimitiveWrapperDescriptor<Integer> {
 		public static final IntegerDescriptor INSTANCE = new IntegerDescriptor();
 
 		private IntegerDescriptor() {
 		}
 
 		@Override
 		public Class<Integer> getPrimitiveClass() {
 			return int.class;
 		}
 
 		@Override
 		public Class<Integer> getWrapperClass() {
 			return Integer.class;
 		}
 	}
 
 	public static class LongDescriptor implements PrimitiveWrapperDescriptor<Long> {
 		public static final LongDescriptor INSTANCE = new LongDescriptor();
 
 		private LongDescriptor() {
 		}
 
 		@Override
 		public Class<Long> getPrimitiveClass() {
 			return long.class;
 		}
 
 		@Override
 		public Class<Long> getWrapperClass() {
 			return Long.class;
 		}
 	}
 
 	public static class FloatDescriptor implements PrimitiveWrapperDescriptor<Float> {
 		public static final FloatDescriptor INSTANCE = new FloatDescriptor();
 
 		private FloatDescriptor() {
 		}
 
 		@Override
 		public Class<Float> getPrimitiveClass() {
 			return float.class;
 		}
 
 		@Override
 		public Class<Float> getWrapperClass() {
 			return Float.class;
 		}
 	}
 
 	public static class DoubleDescriptor implements PrimitiveWrapperDescriptor<Double> {
 		public static final DoubleDescriptor INSTANCE = new DoubleDescriptor();
 
 		private DoubleDescriptor() {
 		}
 
 		@Override
 		public Class<Double> getPrimitiveClass() {
 			return double.class;
 		}
 
 		@Override
 		public Class<Double> getWrapperClass() {
 			return Double.class;
 		}
 	}
 
 	@SuppressWarnings("unchecked")
 	public static <X> PrimitiveWrapperDescriptor<X> getDescriptorByPrimitiveType(Class<X> primitiveClazz) {
 		if ( ! primitiveClazz.isPrimitive() ) {
 			throw new IllegalArgumentException( "Given class is not a primitive type : " + primitiveClazz.getName() );
 		}
 
 		if ( boolean.class == primitiveClazz ) {
 			return (PrimitiveWrapperDescriptor<X>) BooleanDescriptor.INSTANCE;
 		}
 
 		if ( char.class == primitiveClazz ) {
 			return (PrimitiveWrapperDescriptor<X>) CharacterDescriptor.INSTANCE;
 		}
 
 		if ( byte.class == primitiveClazz ) {
 			return (PrimitiveWrapperDescriptor<X>) ByteDescriptor.INSTANCE;
 		}
 
 		if ( short.class == primitiveClazz ) {
 			return (PrimitiveWrapperDescriptor<X>) ShortDescriptor.INSTANCE;
 		}
 
 		if ( int.class == primitiveClazz ) {
 			return (PrimitiveWrapperDescriptor<X>) IntegerDescriptor.INSTANCE;
 		}
 
 		if ( long.class == primitiveClazz ) {
 			return (PrimitiveWrapperDescriptor<X>) LongDescriptor.INSTANCE;
 		}
 
 		if ( float.class == primitiveClazz ) {
 			return (PrimitiveWrapperDescriptor<X>) FloatDescriptor.INSTANCE;
 		}
 
 		if ( double.class == primitiveClazz ) {
 			return (PrimitiveWrapperDescriptor<X>) DoubleDescriptor.INSTANCE;
 		}
 
 		if ( void.class == primitiveClazz ) {
 			throw new IllegalArgumentException( "void, as primitive type, has no wrapper equivalent" );
 		}
 
 		throw new IllegalArgumentException( "Unrecognized primitive type class : " + primitiveClazz.getName() );
 	}
 
 	@SuppressWarnings("unchecked")
 	public static <X> PrimitiveWrapperDescriptor<X> getDescriptorByWrapperType(Class<X> wrapperClass) {
 		if ( wrapperClass.isPrimitive() ) {
 			throw new IllegalArgumentException( "Given class is a primitive type : " + wrapperClass.getName() );
 		}
 
 		if ( Boolean.class.equals( wrapperClass ) ) {
 			return (PrimitiveWrapperDescriptor<X>) BooleanDescriptor.INSTANCE;
 		}
 
 		if ( Character.class == wrapperClass ) {
 			return (PrimitiveWrapperDescriptor<X>) CharacterDescriptor.INSTANCE;
 		}
 
 		if ( Byte.class == wrapperClass ) {
 			return (PrimitiveWrapperDescriptor<X>) ByteDescriptor.INSTANCE;
 		}
 
 		if ( Short.class == wrapperClass ) {
 			return (PrimitiveWrapperDescriptor<X>) ShortDescriptor.INSTANCE;
 		}
 
 		if ( Integer.class == wrapperClass ) {
 			return (PrimitiveWrapperDescriptor<X>) IntegerDescriptor.INSTANCE;
 		}
 
 		if ( Long.class == wrapperClass ) {
 			return (PrimitiveWrapperDescriptor<X>) LongDescriptor.INSTANCE;
 		}
 
 		if ( Float.class == wrapperClass ) {
 			return (PrimitiveWrapperDescriptor<X>) FloatDescriptor.INSTANCE;
 		}
 
 		if ( Double.class == wrapperClass ) {
 			return (PrimitiveWrapperDescriptor<X>) DoubleDescriptor.INSTANCE;
 		}
 
 		// most likely void.class, which we can't really handle here
 		throw new IllegalArgumentException( "Unrecognized wrapper type class : " + wrapperClass.getName() );
 	}
 
 	public static boolean isWrapper(Class<?> clazz) {
 		try {
 			getDescriptorByWrapperType( clazz );
 			return true;
 		}
 		catch (Exception e) {
 			return false;
 		}
 	}
 
 	public static boolean arePrimitiveWrapperEquivalents(Class converterDefinedType, Class propertyType) {
 		if ( converterDefinedType.isPrimitive() ) {
 			return getDescriptorByPrimitiveType( converterDefinedType ).getWrapperClass().equals( propertyType );
 		}
 		else if ( propertyType.isPrimitive() ) {
 			return getDescriptorByPrimitiveType( propertyType ).getWrapperClass().equals( converterDefinedType );
 		}
 		return false;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/xml/BufferedXMLEventReader.java b/hibernate-core/src/main/java/org/hibernate/internal/util/xml/BufferedXMLEventReader.java
index 529143c27f..ba06428a2d 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/xml/BufferedXMLEventReader.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/xml/BufferedXMLEventReader.java
@@ -1,196 +1,196 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util.xml;
 
 import java.util.ArrayList;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.ListIterator;
 
 import javax.xml.stream.XMLEventReader;
 import javax.xml.stream.XMLStreamException;
 import javax.xml.stream.events.XMLEvent;
 
 /**
  * Buffers XML events for later re-reading
  *
  * Note, copied from the uPortal project by permission of author.  See
  * https://github.com/Jasig/uPortal/blob/master/uportal-war/src/main/java/org/jasig/portal/xml/stream/BufferedXMLEventReader.java
  *
  * @author Eric Dalquist
  */
 public class BufferedXMLEventReader extends BaseXMLEventReader {
 	private final LinkedList<XMLEvent> eventBuffer = new LinkedList<XMLEvent>();
-	private int eventLimit = 0;
-	private ListIterator<XMLEvent> bufferReader = null;
+	private int eventLimit;
+	private ListIterator<XMLEvent> bufferReader;
 
 	/**
 	 * Create new buffering reader, no buffering is done until {@link #mark(int)} is called.
 	 */
 	public BufferedXMLEventReader(XMLEventReader reader) {
 		super(reader);
 	}
 
 	/**
 	 * Create new buffering reader. Calls {@link #mark(int)} with the specified event limit
 	 * @see #mark(int)
 	 */
 	public BufferedXMLEventReader(XMLEventReader reader, int eventLimit) {
 		super(reader);
 		this.eventLimit = eventLimit;
 	}
 
 	/**
 	 * @return A copy of the current buffer
 	 */
 	public List<XMLEvent> getBuffer() {
 		return new ArrayList<XMLEvent>(this.eventBuffer);
 	}
 
 	/* (non-Javadoc)
 	 * @see org.jasig.portal.xml.stream.BaseXMLEventReader#internalNextEvent()
 	 */
 	@Override
 	protected XMLEvent internalNextEvent() throws XMLStreamException {
 		//If there is an iterator to read from reset was called, use the iterator
 		//until it runs out of events.
 		if (this.bufferReader != null) {
 			final XMLEvent event = this.bufferReader.next();
 
 			//If nothing left in the iterator, remove the reference and fall through to direct reading
 			if (!this.bufferReader.hasNext()) {
 				this.bufferReader = null;
 			}
 
 			return event;
 		}
 
 		//Get the next event from the underlying reader
 		final XMLEvent event = this.getParent().nextEvent();
 
 		//if buffering add the event
 		if (this.eventLimit != 0) {
 			this.eventBuffer.offer(event);
 
 			//If limited buffer size and buffer is too big trim the buffer.
 			if (this.eventLimit > 0 && this.eventBuffer.size() > this.eventLimit) {
 				this.eventBuffer.poll();
 			}
 		}
 
 		return event;
 	}
 
 	@Override
 	public boolean hasNext() {
 		return this.bufferReader != null || super.hasNext();
 	}
 
 	@Override
 	public XMLEvent peek() throws XMLStreamException {
 		if (this.bufferReader != null) {
 			final XMLEvent event = this.bufferReader.next();
 			this.bufferReader.previous(); //move the iterator back
 			return event;
 		}
 		return super.peek();
 	}
 
 	/**
 	 * Same as calling {@link #mark(int)} with -1.
 	 */
 	public void mark() {
 		this.mark(-1);
 	}
 
 	/**
 	 * Start buffering events
 	 * @param eventLimit the maximum number of events to buffer. -1 will buffer all events, 0 will buffer no events.
 	 */
 	public void mark(int eventLimit) {
 		this.eventLimit = eventLimit;
 
 		//Buffering no events now, clear the buffer and buffered reader
 		if (this.eventLimit == 0) {
 			this.eventBuffer.clear();
 			this.bufferReader = null;
 		}
 		//Buffering limited set of events, lets trim the buffer if needed
 		else if (this.eventLimit > 0) {
 			//If there is an iterator check its current position and calculate the new iterator start position
 			int iteratorIndex = 0;
 			if (this.bufferReader != null) {
 				final int nextIndex = this.bufferReader.nextIndex();
 				iteratorIndex = Math.max(0, nextIndex - (this.eventBuffer.size() - this.eventLimit));
 			}
 
 			//Trim the buffer until it is not larger than the limit
 			while (this.eventBuffer.size() > this.eventLimit) {
 				this.eventBuffer.poll();
 			}
 
 			//If there is an iterator re-create it using the newly calculated index
 			if (this.bufferReader != null) {
 				this.bufferReader = this.eventBuffer.listIterator(iteratorIndex);
 			}
 		}
 	}
 
 	/**
 	 * Reset the reader to these start of the buffered events.
 	 */
 	public void reset() {
 		if (this.eventBuffer.isEmpty()) {
 			this.bufferReader = null;
 		}
 		else {
 			this.bufferReader = this.eventBuffer.listIterator();
 		}
 	}
 
 	@Override
 	public void close() throws XMLStreamException {
 		this.mark(0);
 		super.close();
 	}
 
 	/**
 	 * @return The number of events in the buffer.
 	 */
 	public int bufferSize() {
 		return this.eventBuffer.size();
 	}
 
 	/**
 	 * If reading from the buffer after a {@link #reset()} call an {@link IllegalStateException} will be thrown.
 	 */
 	@Override
 	public void remove() {
 		if (this.bufferReader != null && this.bufferReader.hasNext()) {
 			throw new IllegalStateException("Cannot remove a buffered element");
 		}
 
 		super.remove();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/xml/FilteringXMLEventReader.java b/hibernate-core/src/main/java/org/hibernate/internal/util/xml/FilteringXMLEventReader.java
index 5d115f31dd..746a73ec50 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/xml/FilteringXMLEventReader.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/xml/FilteringXMLEventReader.java
@@ -1,141 +1,141 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util.xml;
 
 import java.util.Deque;
 import java.util.LinkedList;
 import java.util.NoSuchElementException;
 
 import javax.xml.namespace.QName;
 import javax.xml.stream.XMLEventReader;
 import javax.xml.stream.XMLStreamException;
 import javax.xml.stream.events.EndElement;
 import javax.xml.stream.events.StartElement;
 import javax.xml.stream.events.XMLEvent;
 
 /**
  * Base class for {@link XMLEventReader}s that want to modify or remove events from the reader stream.
  * If a {@link StartElement} event is removed the subclass's {@link #filterEvent(XMLEvent, boolean)} will
  * not see any events until after the matching {@link EndElement} event.
  *
  * Note, copied from the uPortal project by permission of author.  See
  * https://github.com/Jasig/uPortal/blob/master/uportal-war/src/main/java/org/jasig/portal/xml/stream/FilteringXMLEventReader.java
  *
  * @author Eric Dalquist
  */
 public abstract class FilteringXMLEventReader extends BaseXMLEventReader {
 	private final Deque<QName> prunedElements = new LinkedList<QName>();
-	private XMLEvent peekedEvent = null;
+	private XMLEvent peekedEvent;
 
 	public FilteringXMLEventReader(XMLEventReader reader) {
 		super(reader);
 	}
 
 	@Override
 	protected final XMLEvent internalNextEvent() throws XMLStreamException {
 		return this.internalNext(false);
 	}
 
 	@Override
 	public boolean hasNext() {
 		try {
 			return peekedEvent != null || (super.hasNext() && this.peek() != null);
 		}
 		catch (XMLStreamException e) {
 			throw new RuntimeException(e.getMessage(), e);
 		}
 		catch (NoSuchElementException e) {
 			return false;
 		}
 	}
 
 	@Override
 	public final XMLEvent peek() throws XMLStreamException {
 		if (peekedEvent != null) {
 			return peekedEvent;
 		}
 
 		peekedEvent = internalNext(true);
 		return peekedEvent;
 	}
 
 	protected final XMLEvent internalNext(boolean peek) throws XMLStreamException {
 		XMLEvent event = null;
 
 		if (peekedEvent != null) {
 			event = peekedEvent;
 			peekedEvent = null;
 			return event;
 		}
 
 		do {
 			event = super.getParent().nextEvent();
 
 			//If there are pruned elements in the queue filtering events is still needed
 			if (!prunedElements.isEmpty()) {
 				//If another start element add it to the queue
 				if (event.isStartElement()) {
 					final StartElement startElement = event.asStartElement();
 					prunedElements.push(startElement.getName());
 				}
 				//If end element pop the newest name of the queue and double check that the start/end elements match up
 				else if (event.isEndElement()) {
 					final QName startElementName = prunedElements.pop();
 
 					final EndElement endElement = event.asEndElement();
 					final QName endElementName = endElement.getName();
 
 					if (!startElementName.equals(endElementName)) {
 						throw new IllegalArgumentException("Malformed XMLEvent stream. Expected end element for " + startElementName + " but found end element for " + endElementName);
 					}
 				}
 
 				event = null;
 			}
 			else {
 				final XMLEvent filteredEvent = this.filterEvent(event, peek);
 
 				//If the event is being removed and it is a start element all elements until the matching
 				//end element need to be removed as well
 				if (filteredEvent == null && event.isStartElement()) {
 					final StartElement startElement = event.asStartElement();
 					final QName name = startElement.getName();
 					prunedElements.push(name);
 				}
 
 				event = filteredEvent;
 			}
 		}
 		while (event == null);
 
 		return event;
 	}
 
 	/**
 	 * @param event The current event
 	 * @param peek If the event is from a {@link #peek()} call
 	 * @return The event to return, if null is returned the event is dropped from the stream and the next event will be used.
 	 */
 	protected abstract XMLEvent filterEvent(XMLEvent event, boolean peek);
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/internal/util/xml/XMLStreamConstantsUtils.java b/hibernate-core/src/main/java/org/hibernate/internal/util/xml/XMLStreamConstantsUtils.java
index b79250f109..ba70312a30 100644
--- a/hibernate-core/src/main/java/org/hibernate/internal/util/xml/XMLStreamConstantsUtils.java
+++ b/hibernate-core/src/main/java/org/hibernate/internal/util/xml/XMLStreamConstantsUtils.java
@@ -1,69 +1,72 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.internal.util.xml;
 
 import javax.xml.stream.XMLStreamConstants;
 
 /**
  *
  *
  *
  *
  * Note, copied from the uPortal project by permission of author.  See
  * https://github.com/Jasig/uPortal/blob/master/uportal-war/src/main/java/org/jasig/portal/xml/stream/XMLStreamConstantsUtils.java
  *
  * @author Eric Dalquist
  */
-public class XMLStreamConstantsUtils {
+public final class XMLStreamConstantsUtils {
+	private XMLStreamConstantsUtils() {
+	}
+
 	/**
 	 * Get the human readable event name for the numeric event id
 	 */
 	public static String getEventName(int eventId) {
 		switch (eventId) {
 			case XMLStreamConstants.START_ELEMENT:
 				return "StartElementEvent";
 			case XMLStreamConstants.END_ELEMENT:
 				return "EndElementEvent";
 			case XMLStreamConstants.PROCESSING_INSTRUCTION:
 				return "ProcessingInstructionEvent";
 			case XMLStreamConstants.CHARACTERS:
 				return "CharacterEvent";
 			case XMLStreamConstants.COMMENT:
 				return "CommentEvent";
 			case XMLStreamConstants.START_DOCUMENT:
 				return "StartDocumentEvent";
 			case XMLStreamConstants.END_DOCUMENT:
 				return "EndDocumentEvent";
 			case XMLStreamConstants.ENTITY_REFERENCE:
 				return "EntityReferenceEvent";
 			case XMLStreamConstants.ATTRIBUTE:
 				return "AttributeBase";
 			case XMLStreamConstants.DTD:
 				return "DTDEvent";
 			case XMLStreamConstants.CDATA:
 				return "CDATA";
 		}
 		return "UNKNOWN_EVENT_TYPE";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryParser.java b/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryParser.java
index a60c4b483a..68fdd77821 100755
--- a/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryParser.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryParser.java
@@ -1,340 +1,345 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.custom.sql;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.QueryException;
 import org.hibernate.engine.query.spi.ParameterParser;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.persister.collection.SQLLoadableCollection;
 import org.hibernate.persister.entity.SQLLoadable;
 
 /**
  * @author Gavin King
  * @author Max Andersen
  * @author Steve Ebersole
  * @author Paul Benedict
  */
 public class SQLQueryParser {
 	private static final String HIBERNATE_PLACEHOLDER_PREFIX = "h-";
 	private static final String DOMAIN_PLACEHOLDER = "h-domain";
 	private static final String CATALOG_PLACEHOLDER = "h-catalog";
 	private static final String SCHEMA_PLACEHOLDER = "h-schema";
 
 	private final SessionFactoryImplementor factory;
 	private final String originalQueryString;
 	private final ParserContext context;
 
 	private final Map namedParameters = new HashMap();
-	private long aliasesFound = 0;
+	private long aliasesFound;
 
 	static interface ParserContext {
 		boolean isEntityAlias(String aliasName);
 		SQLLoadable getEntityPersisterByAlias(String alias);
 		String getEntitySuffixByAlias(String alias);
 		boolean isCollectionAlias(String aliasName);
 		SQLLoadableCollection getCollectionPersisterByAlias(String alias);
 		String getCollectionSuffixByAlias(String alias);
 		Map getPropertyResultsMapByAlias(String alias);
 	}
 
 	public SQLQueryParser(String queryString, ParserContext context, SessionFactoryImplementor factory) {
 		this.originalQueryString = queryString;
 		this.context = context;
 		this.factory = factory;
 	}
 
 	public Map getNamedParameters() {
 		return namedParameters;
 	}
 
 	public boolean queryHasAliases() {
 		return aliasesFound>0;
 	}
 
 	public String process() {
 		String processedSql = substituteBrackets( originalQueryString );
 		processedSql = substituteParams( processedSql );
 		return processedSql;
 	}
 
 	// TODO: should "record" how many properties we have reffered to - and if we 
 	//       don't get'em'all we throw an exception! Way better than trial and error ;)
 	private String substituteBrackets(String sqlQuery) throws QueryException {
 
 		StringBuilder result = new StringBuilder( sqlQuery.length() + 20 );
 		int left, right;
 
 		// replace {....} with corresponding column aliases
 		for ( int curr = 0; curr < sqlQuery.length(); curr = right + 1 ) {
 			if ( ( left = sqlQuery.indexOf( '{', curr ) ) < 0 ) {
 				// No additional open braces found in the string, append the
 				// rest of the string in its entirty and quit this loop
 				result.append( sqlQuery.substring( curr ) );
 				break;
 			}
 
 			// apend everything up until the next encountered open brace
 			result.append( sqlQuery.substring( curr, left ) );
 
 			if ( ( right = sqlQuery.indexOf( '}', left + 1 ) ) < 0 ) {
 				throw new QueryException( "Unmatched braces for alias path", sqlQuery );
 			}
 
 			final String aliasPath = sqlQuery.substring( left + 1, right );
 			boolean isPlaceholder = aliasPath.startsWith( HIBERNATE_PLACEHOLDER_PREFIX );
 
 			if ( isPlaceholder ) {
 				// Domain replacement
 				if ( DOMAIN_PLACEHOLDER.equals( aliasPath ) ) {
 					final String catalogName = factory.getSettings().getDefaultCatalogName();
 					if ( catalogName != null ) {
 						result.append( catalogName );
 						result.append( "." );
 					}
 					final String schemaName = factory.getSettings().getDefaultSchemaName();
 					if ( schemaName != null ) {
 						result.append( schemaName );
 						result.append( "." );
 					}
 				}
 				// Schema replacement
 				else if ( SCHEMA_PLACEHOLDER.equals( aliasPath ) ) {
 					final String schemaName = factory.getSettings().getDefaultSchemaName();
 					if ( schemaName != null ) {
 						result.append(schemaName);
 						result.append(".");
 					}
 				} 
 				// Catalog replacement
 				else if ( CATALOG_PLACEHOLDER.equals( aliasPath ) ) {
 					final String catalogName = factory.getSettings().getDefaultCatalogName();
 					if ( catalogName != null ) {
 						result.append( catalogName );
 						result.append( "." );
 					}
 				}
 				else {
 					throw new QueryException( "Unknown placeholder ", aliasPath );
 				}
 			}
 			else {
 				int firstDot = aliasPath.indexOf( '.' );
 				if ( firstDot == -1 ) {
 					if ( context.isEntityAlias( aliasPath ) ) {
 						// it is a simple table alias {foo}
 						result.append( aliasPath );
 						aliasesFound++;
 					} 
 					else {
 						// passing through anything we do not know : to support jdbc escape sequences HB-898
 						result.append( '{' ).append(aliasPath).append( '}' );					
 					}
 				}
 				else {
 					final String aliasName = aliasPath.substring( 0, firstDot );
 					if ( context.isCollectionAlias( aliasName ) ) {
 						// The current alias is referencing the collection to be eagerly fetched
 						String propertyName = aliasPath.substring( firstDot + 1 );
 						result.append( resolveCollectionProperties( aliasName, propertyName ) );
 						aliasesFound++;
 					} 
 					else if ( context.isEntityAlias( aliasName ) ) {
 						// it is a property reference {foo.bar}
 						String propertyName = aliasPath.substring( firstDot + 1 );
 						result.append( resolveProperties( aliasName, propertyName ) );
 						aliasesFound++;
 					}
 					else {
 						// passing through anything we do not know : to support jdbc escape sequences HB-898
 						result.append( '{' ).append(aliasPath).append( '}' );
 					}
 				}
 			}
 		}
 
 		// Possibly handle :something parameters for the query ?
 
 		return result.toString();
 	}	
 
 	private String resolveCollectionProperties(
 			String aliasName,
 			String propertyName) {
 
 		Map fieldResults = context.getPropertyResultsMapByAlias( aliasName );
 		SQLLoadableCollection collectionPersister = context.getCollectionPersisterByAlias( aliasName );
 		String collectionSuffix = context.getCollectionSuffixByAlias( aliasName );
 
 		if ( "*".equals( propertyName ) ) {
 			if( !fieldResults.isEmpty() ) {
 				throw new QueryException("Using return-propertys together with * syntax is not supported.");
 			}
 			
 			String selectFragment = collectionPersister.selectFragment( aliasName, collectionSuffix );
 			aliasesFound++;
 			return selectFragment 
 						+ ", " 
 						+ resolveProperties( aliasName, propertyName );
 		}
 		else if ( "element.*".equals( propertyName ) ) {
 			return resolveProperties( aliasName, "*" );
 		}
 		else {
 			String[] columnAliases;
 
 			// Let return-propertys override whatever the persister has for aliases.
 			columnAliases = ( String[] ) fieldResults.get(propertyName);
 			if ( columnAliases==null ) {
 				columnAliases = collectionPersister.getCollectionPropertyColumnAliases( propertyName, collectionSuffix );
 			}
 			
 			if ( columnAliases == null || columnAliases.length == 0 ) {
 				throw new QueryException(
 						"No column name found for property [" + propertyName + "] for alias [" + aliasName + "]",
 						originalQueryString
 				);
 			}
 			if ( columnAliases.length != 1 ) {
 				// TODO: better error message since we actually support composites if names are explicitly listed.
 				throw new QueryException(
 						"SQL queries only support properties mapped to a single column - property [" +
 						propertyName + "] is mapped to " + columnAliases.length + " columns.",
 						originalQueryString
 				);
 			}
 			aliasesFound++;
 			return columnAliases[0];
 		
 		}
 	}
 	private String resolveProperties(
 			String aliasName,
 	        String propertyName) {
 		Map fieldResults = context.getPropertyResultsMapByAlias( aliasName );
 		SQLLoadable persister = context.getEntityPersisterByAlias( aliasName );
 		String suffix = context.getEntitySuffixByAlias( aliasName );
 
 		if ( "*".equals( propertyName ) ) {
 			if( !fieldResults.isEmpty() ) {
 				throw new QueryException("Using return-propertys together with * syntax is not supported.");
 			}			
 			aliasesFound++;
 			return persister.selectFragment( aliasName, suffix ) ;
 		}
 		else {
 
 			String[] columnAliases;
 
 			// Let return-propertys override whatever the persister has for aliases.
 			columnAliases = (String[]) fieldResults.get( propertyName );
 			if ( columnAliases == null ) {
 				columnAliases = persister.getSubclassPropertyColumnAliases( propertyName, suffix );
 			}
 
 			if ( columnAliases == null || columnAliases.length == 0 ) {
 				throw new QueryException(
 						"No column name found for property [" + propertyName + "] for alias [" + aliasName + "]",
 						originalQueryString
 				);
 			}
 			if ( columnAliases.length != 1 ) {
 				// TODO: better error message since we actually support composites if names are explicitly listed.
 				throw new QueryException(
 						"SQL queries only support properties mapped to a single column - property [" + propertyName + "] is mapped to " + columnAliases.length + " columns.",
 						originalQueryString
 				);
 			}			
 			aliasesFound++;
 			return columnAliases[0];
 		}
 	}
 
 	/**
 	 * Substitues JDBC parameter placeholders (?) for all encountered
 	 * parameter specifications.  It also tracks the positions of these
 	 * parameter specifications within the query string.  This accounts for
 	 * ordinal-params, named-params, and ejb3-positional-params.
 	 *
 	 * @param sqlString The query string.
 	 * @return The SQL query with parameter substitution complete.
 	 */
 	private String substituteParams(String sqlString) {
 		ParameterSubstitutionRecognizer recognizer = new ParameterSubstitutionRecognizer();
 		ParameterParser.parse( sqlString, recognizer );
 
 		namedParameters.clear();
 		namedParameters.putAll( recognizer.namedParameterBindPoints );
 
 		return recognizer.result.toString();
 	}
 
 	public static class ParameterSubstitutionRecognizer implements ParameterParser.Recognizer {
 		StringBuilder result = new StringBuilder();
 		Map namedParameterBindPoints = new HashMap();
-		int parameterCount = 0;
+		int parameterCount;
 
+		@Override
 		public void outParameter(int position) {
 			result.append( '?' );
 		}
 
+		@Override
 		public void ordinalParameter(int position) {
 			result.append( '?' );
 		}
 
+		@Override
 		public void namedParameter(String name, int position) {
 			addNamedParameter( name );
 			result.append( '?' );
 		}
 
+		@Override
 		public void jpaPositionalParameter(String name, int position) {
 			namedParameter( name, position );
 		}
 
+		@Override
 		public void other(char character) {
 			result.append( character );
 		}
 
 		private void addNamedParameter(String name) {
 			Integer loc = parameterCount++;
 			Object o = namedParameterBindPoints.get( name );
 			if ( o == null ) {
 				namedParameterBindPoints.put( name, loc );
 			}
 			else if ( o instanceof Integer ) {
 				ArrayList list = new ArrayList( 4 );
 				list.add( o );
 				list.add( loc );
 				namedParameterBindPoints.put( name, list );
 			}
 			else {
 				( ( List ) o ).add( loc );
 			}
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryReturnProcessor.java b/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryReturnProcessor.java
index 5708666417..6db256c256 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryReturnProcessor.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/custom/sql/SQLQueryReturnProcessor.java
@@ -1,574 +1,573 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.custom.sql;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryCollectionReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryConstructorReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryJoinReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryNonScalarReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryRootReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryScalarReturn;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.loader.BasicLoader;
 import org.hibernate.loader.CollectionAliases;
 import org.hibernate.loader.ColumnEntityAliases;
 import org.hibernate.loader.DefaultEntityAliases;
 import org.hibernate.loader.EntityAliases;
 import org.hibernate.loader.GeneratedCollectionAliases;
 import org.hibernate.loader.custom.CollectionFetchReturn;
 import org.hibernate.loader.custom.CollectionReturn;
 import org.hibernate.loader.custom.ColumnCollectionAliases;
 import org.hibernate.loader.custom.ConstructorReturn;
 import org.hibernate.loader.custom.EntityFetchReturn;
 import org.hibernate.loader.custom.FetchReturn;
 import org.hibernate.loader.custom.NonScalarReturn;
 import org.hibernate.loader.custom.Return;
 import org.hibernate.loader.custom.RootReturn;
 import org.hibernate.loader.custom.ScalarReturn;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.collection.SQLLoadableCollection;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.entity.SQLLoadable;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.EntityType;
 import org.hibernate.type.Type;
 
 /**
  * Responsible for processing the series of {@link org.hibernate.engine.query.spi.sql.NativeSQLQueryReturn returns}
  * defined by a {@link org.hibernate.engine.query.spi.sql.NativeSQLQuerySpecification} and
  * breaking them down into a series of {@link Return returns} for use within the
  * {@link org.hibernate.loader.custom.CustomLoader}.
  *
  * @author Gavin King
  * @author Max Andersen
  * @author Steve Ebersole
  */
 public class SQLQueryReturnProcessor {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class,
-                                                                       SQLQueryReturnProcessor.class.getName());
+    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( SQLQueryReturnProcessor.class );
 
 	private NativeSQLQueryReturn[] queryReturns;
 
 //	private final List persisters = new ArrayList();
 
 	private final Map alias2Return = new HashMap();
 	private final Map alias2OwnerAlias = new HashMap();
 
 	private final Map<String,EntityPersister> alias2Persister = new HashMap<String,EntityPersister>();
 	private final Map alias2Suffix = new HashMap();
 
 	private final Map<String,CollectionPersister> alias2CollectionPersister = new HashMap<String,CollectionPersister>();
 	private final Map alias2CollectionSuffix = new HashMap();
 
 	private final Map entityPropertyResultMaps = new HashMap();
 	private final Map collectionPropertyResultMaps = new HashMap();
 
 //	private final List scalarTypes = new ArrayList();
 //	private final List scalarColumnAliases = new ArrayList();
 
 	private final SessionFactoryImplementor factory;
 
 //	private List collectionOwnerAliases = new ArrayList();
 //	private List collectionAliases = new ArrayList();
 //	private List collectionPersisters = new ArrayList();
 //	private List collectionResults = new ArrayList();
 
-	private int entitySuffixSeed = 0;
-	private int collectionSuffixSeed = 0;
+	private int entitySuffixSeed;
+	private int collectionSuffixSeed;
 
 
 	public SQLQueryReturnProcessor(NativeSQLQueryReturn[] queryReturns, SessionFactoryImplementor factory) {
 		this.queryReturns = queryReturns;
 		this.factory = factory;
 	}
 
 	public class ResultAliasContext {
 		public SQLLoadable getEntityPersister(String alias) {
 			return ( SQLLoadable ) alias2Persister.get( alias );
 		}
 
 		public SQLLoadableCollection getCollectionPersister(String alias) {
 			return ( SQLLoadableCollection ) alias2CollectionPersister.get( alias );
 		}
 
 		public String getEntitySuffix(String alias) {
 			return ( String ) alias2Suffix.get( alias );
 		}
 
 		public String getCollectionSuffix(String alias) {
 			return ( String ) alias2CollectionSuffix.get ( alias );
 		}
 
 		public String getOwnerAlias(String alias) {
 			return ( String ) alias2OwnerAlias.get( alias );
 		}
 
 		public Map getPropertyResultsMap(String alias) {
 			return internalGetPropertyResultsMap( alias );
 		}
 
 		public String[] collectQuerySpaces() {
 			final HashSet<String> spaces = new HashSet<String>();
 			collectQuerySpaces( spaces );
 			return spaces.toArray( new String[ spaces.size() ] );
 		}
 
 		public void collectQuerySpaces(Collection<String> spaces) {
 			for ( EntityPersister persister : alias2Persister.values() ) {
 				Collections.addAll( spaces, (String[]) persister.getQuerySpaces() );
 			}
 			for ( CollectionPersister persister : alias2CollectionPersister.values() ) {
 				final Type elementType = persister.getElementType();
 				if ( elementType.isEntityType() && ! elementType.isAnyType() ) {
 					final Joinable joinable = ( (EntityType) elementType ).getAssociatedJoinable( factory );
 					Collections.addAll( spaces, (String[]) ( (EntityPersister) joinable ).getQuerySpaces() );
 				}
 			}
 		}
 	}
 
 	private Map internalGetPropertyResultsMap(String alias) {
 		NativeSQLQueryReturn rtn = ( NativeSQLQueryReturn ) alias2Return.get( alias );
 		if ( rtn instanceof NativeSQLQueryNonScalarReturn ) {
 			return ( ( NativeSQLQueryNonScalarReturn ) rtn ).getPropertyResultsMap();
 		}
 		else {
 			return null;
 		}
 	}
 
 	private boolean hasPropertyResultMap(String alias) {
 		Map propertyMaps = internalGetPropertyResultsMap( alias );
 		return propertyMaps != null && ! propertyMaps.isEmpty();
 	}
 
 	public ResultAliasContext process() {
 		// first, break down the returns into maps keyed by alias
 		// so that role returns can be more easily resolved to their owners
 		for ( NativeSQLQueryReturn queryReturn : queryReturns ) {
 			if ( queryReturn instanceof NativeSQLQueryNonScalarReturn ) {
 				NativeSQLQueryNonScalarReturn rtn = (NativeSQLQueryNonScalarReturn) queryReturn;
 				alias2Return.put( rtn.getAlias(), rtn );
 				if ( rtn instanceof NativeSQLQueryJoinReturn ) {
 					NativeSQLQueryJoinReturn fetchReturn = (NativeSQLQueryJoinReturn) rtn;
 					alias2OwnerAlias.put( fetchReturn.getAlias(), fetchReturn.getOwnerAlias() );
 				}
 			}
 		}
 
 		// Now, process the returns
 		for ( NativeSQLQueryReturn queryReturn : queryReturns ) {
 			processReturn( queryReturn );
 		}
 
 		return new ResultAliasContext();
 	}
 
 	public List<Return> generateCustomReturns(boolean queryHadAliases) {
 		List<Return> customReturns = new ArrayList<Return>();
 		Map<String,Return> customReturnsByAlias = new HashMap<String,Return>();
 		for ( NativeSQLQueryReturn queryReturn : queryReturns ) {
 			if ( queryReturn instanceof NativeSQLQueryScalarReturn ) {
 				NativeSQLQueryScalarReturn rtn = (NativeSQLQueryScalarReturn) queryReturn;
 				customReturns.add( new ScalarReturn( rtn.getType(), rtn.getColumnAlias() ) );
 			}
 			else if ( queryReturn instanceof NativeSQLQueryRootReturn ) {
 				NativeSQLQueryRootReturn rtn = (NativeSQLQueryRootReturn) queryReturn;
 				String alias = rtn.getAlias();
 				EntityAliases entityAliases;
 				if ( queryHadAliases || hasPropertyResultMap( alias ) ) {
 					entityAliases = new DefaultEntityAliases(
 							(Map) entityPropertyResultMaps.get( alias ),
 							(SQLLoadable) alias2Persister.get( alias ),
 							(String) alias2Suffix.get( alias )
 					);
 				}
 				else {
 					entityAliases = new ColumnEntityAliases(
 							(Map) entityPropertyResultMaps.get( alias ),
 							(SQLLoadable) alias2Persister.get( alias ),
 							(String) alias2Suffix.get( alias )
 					);
 				}
 				RootReturn customReturn = new RootReturn(
 						alias,
 						rtn.getReturnEntityName(),
 						entityAliases,
 						rtn.getLockMode()
 				);
 				customReturns.add( customReturn );
 				customReturnsByAlias.put( rtn.getAlias(), customReturn );
 			}
 			else if ( queryReturn instanceof NativeSQLQueryCollectionReturn ) {
 				NativeSQLQueryCollectionReturn rtn = (NativeSQLQueryCollectionReturn) queryReturn;
 				String alias = rtn.getAlias();
 				SQLLoadableCollection persister = (SQLLoadableCollection) alias2CollectionPersister.get( alias );
 				boolean isEntityElements = persister.getElementType().isEntityType();
 				CollectionAliases collectionAliases;
 				EntityAliases elementEntityAliases = null;
 				if ( queryHadAliases || hasPropertyResultMap( alias ) ) {
 					collectionAliases = new GeneratedCollectionAliases(
 							(Map) collectionPropertyResultMaps.get( alias ),
 							(SQLLoadableCollection) alias2CollectionPersister.get( alias ),
 							(String) alias2CollectionSuffix.get( alias )
 					);
 					if ( isEntityElements ) {
 						elementEntityAliases = new DefaultEntityAliases(
 								(Map) entityPropertyResultMaps.get( alias ),
 								(SQLLoadable) alias2Persister.get( alias ),
 								(String) alias2Suffix.get( alias )
 						);
 					}
 				}
 				else {
 					collectionAliases = new ColumnCollectionAliases(
 							(Map) collectionPropertyResultMaps.get( alias ),
 							(SQLLoadableCollection) alias2CollectionPersister.get( alias )
 					);
 					if ( isEntityElements ) {
 						elementEntityAliases = new ColumnEntityAliases(
 								(Map) entityPropertyResultMaps.get( alias ),
 								(SQLLoadable) alias2Persister.get( alias ),
 								(String) alias2Suffix.get( alias )
 						);
 					}
 				}
 				CollectionReturn customReturn = new CollectionReturn(
 						alias,
 						rtn.getOwnerEntityName(),
 						rtn.getOwnerProperty(),
 						collectionAliases,
 						elementEntityAliases,
 						rtn.getLockMode()
 				);
 				customReturns.add( customReturn );
 				customReturnsByAlias.put( rtn.getAlias(), customReturn );
 			}
 			else if ( queryReturn instanceof NativeSQLQueryJoinReturn ) {
 				NativeSQLQueryJoinReturn rtn = (NativeSQLQueryJoinReturn) queryReturn;
 				String alias = rtn.getAlias();
 				FetchReturn customReturn;
 				NonScalarReturn ownerCustomReturn = (NonScalarReturn) customReturnsByAlias.get( rtn.getOwnerAlias() );
 				if ( alias2CollectionPersister.containsKey( alias ) ) {
 					SQLLoadableCollection persister = (SQLLoadableCollection) alias2CollectionPersister.get( alias );
 					boolean isEntityElements = persister.getElementType().isEntityType();
 					CollectionAliases collectionAliases;
 					EntityAliases elementEntityAliases = null;
 					if ( queryHadAliases || hasPropertyResultMap( alias ) ) {
 						collectionAliases = new GeneratedCollectionAliases(
 								(Map) collectionPropertyResultMaps.get( alias ),
 								persister,
 								(String) alias2CollectionSuffix.get( alias )
 						);
 						if ( isEntityElements ) {
 							elementEntityAliases = new DefaultEntityAliases(
 									(Map) entityPropertyResultMaps.get( alias ),
 									(SQLLoadable) alias2Persister.get( alias ),
 									(String) alias2Suffix.get( alias )
 							);
 						}
 					}
 					else {
 						collectionAliases = new ColumnCollectionAliases(
 								(Map) collectionPropertyResultMaps.get( alias ),
 								persister
 						);
 						if ( isEntityElements ) {
 							elementEntityAliases = new ColumnEntityAliases(
 									(Map) entityPropertyResultMaps.get( alias ),
 									(SQLLoadable) alias2Persister.get( alias ),
 									(String) alias2Suffix.get( alias )
 							);
 						}
 					}
 					customReturn = new CollectionFetchReturn(
 							alias,
 							ownerCustomReturn,
 							rtn.getOwnerProperty(),
 							collectionAliases,
 							elementEntityAliases,
 							rtn.getLockMode()
 					);
 				}
 				else {
 					EntityAliases entityAliases;
 					if ( queryHadAliases || hasPropertyResultMap( alias ) ) {
 						entityAliases = new DefaultEntityAliases(
 								(Map) entityPropertyResultMaps.get( alias ),
 								(SQLLoadable) alias2Persister.get( alias ),
 								(String) alias2Suffix.get( alias )
 						);
 					}
 					else {
 						entityAliases = new ColumnEntityAliases(
 								(Map) entityPropertyResultMaps.get( alias ),
 								(SQLLoadable) alias2Persister.get( alias ),
 								(String) alias2Suffix.get( alias )
 						);
 					}
 					customReturn = new EntityFetchReturn(
 							alias,
 							entityAliases,
 							ownerCustomReturn,
 							rtn.getOwnerProperty(),
 							rtn.getLockMode()
 					);
 				}
 				customReturns.add( customReturn );
 				customReturnsByAlias.put( alias, customReturn );
 			}
 			else if ( NativeSQLQueryConstructorReturn.class.isInstance( queryReturn ) ) {
 				final NativeSQLQueryConstructorReturn constructorReturn = (NativeSQLQueryConstructorReturn) queryReturn;
 				final ScalarReturn[] scalars = new ScalarReturn[ constructorReturn.getColumnReturns().length ];
 				int i = 0;
 				for ( NativeSQLQueryScalarReturn scalarReturn : constructorReturn.getColumnReturns() ) {
 					scalars[i++] = new ScalarReturn( scalarReturn.getType(), scalarReturn.getColumnAlias() );
 				}
 				customReturns.add( new ConstructorReturn( constructorReturn.getTargetClass(), scalars ) );
 			}
 			else {
 				throw new IllegalStateException(
 						"Unrecognized NativeSQLQueryReturn concrete type : " + queryReturn
 				);
 			}
 		}
 		return customReturns;
 	}
 
 	private SQLLoadable getSQLLoadable(String entityName) throws MappingException {
 		EntityPersister persister = factory.getEntityPersister( entityName );
 		if ( !(persister instanceof SQLLoadable) ) {
 			throw new MappingException( "class persister is not SQLLoadable: " + entityName );
 		}
 		return (SQLLoadable) persister;
 	}
 
 	private String generateEntitySuffix() {
 		return BasicLoader.generateSuffixes( entitySuffixSeed++, 1 )[0];
 	}
 
 	private String generateCollectionSuffix() {
 		return collectionSuffixSeed++ + "__";
 	}
 
 	private void processReturn(NativeSQLQueryReturn rtn) {
 		if ( rtn instanceof NativeSQLQueryScalarReturn ) {
 			processScalarReturn( ( NativeSQLQueryScalarReturn ) rtn );
 		}
 		else if ( rtn instanceof NativeSQLQueryRootReturn ) {
 			processRootReturn( ( NativeSQLQueryRootReturn ) rtn );
 		}
 		else if ( rtn instanceof NativeSQLQueryCollectionReturn ) {
 			processCollectionReturn( (NativeSQLQueryCollectionReturn) rtn );
 		}
 		else if ( NativeSQLQueryJoinReturn.class.isInstance( rtn ) ) {
 			processJoinReturn( ( NativeSQLQueryJoinReturn ) rtn );
 		}
 		else if ( NativeSQLQueryConstructorReturn.class.isInstance(  rtn ) ) {
 			processConstructorReturn( (NativeSQLQueryConstructorReturn) rtn );
 		}
 		else {
 			throw new IllegalStateException(
 					"Unrecognized NativeSQLQueryReturn concrete type encountered : " + rtn
 			);
 		}
 	}
 
 	private void processConstructorReturn(NativeSQLQueryConstructorReturn rtn) {
 		//To change body of created methods use File | Settings | File Templates.
 	}
 
 	private void processScalarReturn(NativeSQLQueryScalarReturn typeReturn) {
 //		scalarColumnAliases.add( typeReturn.getColumnAlias() );
 //		scalarTypes.add( typeReturn.getType() );
 	}
 
 	private void processRootReturn(NativeSQLQueryRootReturn rootReturn) {
 		if ( alias2Persister.containsKey( rootReturn.getAlias() ) ) {
 			// already been processed...
 			return;
 		}
 
 		SQLLoadable persister = getSQLLoadable( rootReturn.getReturnEntityName() );
 		addPersister( rootReturn.getAlias(), rootReturn.getPropertyResultsMap(), persister );
 	}
 
 	private void addPersister(String alias, Map propertyResult, SQLLoadable persister) {
 		alias2Persister.put( alias, persister );
 		String suffix = generateEntitySuffix();
 		LOG.tracev( "Mapping alias [{0}] to entity-suffix [{1}]", alias, suffix );
 		alias2Suffix.put( alias, suffix );
 		entityPropertyResultMaps.put( alias, propertyResult );
 	}
 
 	private void addCollection(String role, String alias, Map propertyResults) {
 		SQLLoadableCollection collectionPersister = ( SQLLoadableCollection ) factory.getCollectionPersister( role );
 		alias2CollectionPersister.put( alias, collectionPersister );
 		String suffix = generateCollectionSuffix();
 		LOG.tracev( "Mapping alias [{0}] to collection-suffix [{1}]", alias, suffix );
 		alias2CollectionSuffix.put( alias, suffix );
 		collectionPropertyResultMaps.put( alias, propertyResults );
 
 		if ( collectionPersister.isOneToMany() || collectionPersister.isManyToMany() ) {
 			SQLLoadable persister = ( SQLLoadable ) collectionPersister.getElementPersister();
 			addPersister( alias, filter( propertyResults ), persister );
 		}
 	}
 
 	private Map filter(Map propertyResults) {
 		Map result = new HashMap( propertyResults.size() );
 
 		String keyPrefix = "element.";
 
 		Iterator iter = propertyResults.entrySet().iterator();
 		while ( iter.hasNext() ) {
 			Map.Entry element = ( Map.Entry ) iter.next();
 			String path = ( String ) element.getKey();
 			if ( path.startsWith( keyPrefix ) ) {
 				result.put( path.substring( keyPrefix.length() ), element.getValue() );
 			}
 		}
 
 		return result;
 	}
 
 	private void processCollectionReturn(NativeSQLQueryCollectionReturn collectionReturn) {
 		// we are initializing an owned collection
 		//collectionOwners.add( new Integer(-1) );
 //		collectionOwnerAliases.add( null );
 		String role = collectionReturn.getOwnerEntityName() + '.' + collectionReturn.getOwnerProperty();
 		addCollection(
 				role,
 				collectionReturn.getAlias(),
 				collectionReturn.getPropertyResultsMap()
 		);
 	}
 
 	private void processJoinReturn(NativeSQLQueryJoinReturn fetchReturn) {
 		String alias = fetchReturn.getAlias();
 //		if ( alias2Persister.containsKey( alias ) || collectionAliases.contains( alias ) ) {
 		if ( alias2Persister.containsKey( alias ) || alias2CollectionPersister.containsKey( alias ) ) {
 			// already been processed...
 			return;
 		}
 
 		String ownerAlias = fetchReturn.getOwnerAlias();
 
 		// Make sure the owner alias is known...
 		if ( !alias2Return.containsKey( ownerAlias ) ) {
 			throw new HibernateException( "Owner alias [" + ownerAlias + "] is unknown for alias [" + alias + "]" );
 		}
 
 		// If this return's alias has not been processed yet, do so b4 further processing of this return
 		if ( !alias2Persister.containsKey( ownerAlias ) ) {
 			NativeSQLQueryNonScalarReturn ownerReturn = ( NativeSQLQueryNonScalarReturn ) alias2Return.get(ownerAlias);
 			processReturn( ownerReturn );
 		}
 
 		SQLLoadable ownerPersister = ( SQLLoadable ) alias2Persister.get( ownerAlias );
 		Type returnType = ownerPersister.getPropertyType( fetchReturn.getOwnerProperty() );
 
 		if ( returnType.isCollectionType() ) {
 			String role = ownerPersister.getEntityName() + '.' + fetchReturn.getOwnerProperty();
 			addCollection( role, alias, fetchReturn.getPropertyResultsMap() );
 //			collectionOwnerAliases.add( ownerAlias );
 		}
 		else if ( returnType.isEntityType() ) {
 			EntityType eType = ( EntityType ) returnType;
 			String returnEntityName = eType.getAssociatedEntityName();
 			SQLLoadable persister = getSQLLoadable( returnEntityName );
 			addPersister( alias, fetchReturn.getPropertyResultsMap(), persister );
 		}
 
 	}
 
 //	public List getCollectionAliases() {
 //		return collectionAliases;
 //	}
 //
 //	/*public List getCollectionOwners() {
 //		return collectionOwners;
 //	}*/
 //
 //	public List getCollectionOwnerAliases() {
 //		return collectionOwnerAliases;
 //	}
 //
 //	public List getCollectionPersisters() {
 //		return collectionPersisters;
 //	}
 //
 //	public Map getAlias2Persister() {
 //		return alias2Persister;
 //	}
 //
 //	/*public boolean isCollectionInitializer() {
 //		return isCollectionInitializer;
 //	}*/
 //
 ////	public List getPersisters() {
 ////		return persisters;
 ////	}
 //
 //	public Map getAlias2OwnerAlias() {
 //		return alias2OwnerAlias;
 //	}
 //
 //	public List getScalarTypes() {
 //		return scalarTypes;
 //	}
 //	public List getScalarColumnAliases() {
 //		return scalarColumnAliases;
 //	}
 //
 //	public List getPropertyResults() {
 //		return propertyResults;
 //	}
 //
 //	public List getCollectionPropertyResults() {
 //		return collectionResults;
 //	}
 //
 //
 //	public Map getAlias2Return() {
 //		return alias2Return;
 //	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/EntityLoader.java b/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/EntityLoader.java
index 62fb98cedc..8aa0a2ea24 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/EntityLoader.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/entity/plan/EntityLoader.java
@@ -1,155 +1,155 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.loader.entity.plan;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.loader.plan.exec.query.spi.QueryBuildingParameters;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.type.Type;
 
 /**
  * UniqueEntityLoader implementation that is the main functionality for LoadPlan-based Entity loading.
  * <p/>
  * Can handle batch-loading as well as non-pk, unique-key loading,
  * <p/>
  * Much is ultimately delegated to its superclass, AbstractLoadPlanBasedEntityLoader.  However:
  *
  * Loads an entity instance using outerjoin fetching to fetch associated entities.
  * <br>
  * The <tt>EntityPersister</tt> must implement <tt>Loadable</tt>. For other entities,
  * create a customized subclass of <tt>Loader</tt>.
  *
  * @author Gavin King
  * @author Steve Ebersole
  * @author Gail Badner
  */
 public class EntityLoader extends AbstractLoadPlanBasedEntityLoader  {
 	private static final Logger log = CoreLogging.logger( EntityLoader.class );
 
 	public static Builder forEntity(OuterJoinLoadable persister) {
 		return new Builder( persister );
 	}
 
 	public static class Builder {
 		private final OuterJoinLoadable persister;
 		private int batchSize = 1;
 		private LoadQueryInfluencers influencers = LoadQueryInfluencers.NONE;
 		private LockMode lockMode = LockMode.NONE;
 		private LockOptions lockOptions;
 
 		public Builder(OuterJoinLoadable persister) {
 			this.persister = persister;
 		}
 
 		public Builder withBatchSize(int batchSize) {
 			this.batchSize = batchSize;
 			return this;
 		}
 
 		public Builder withInfluencers(LoadQueryInfluencers influencers) {
 			this.influencers = influencers;
 			return this;
 		}
 
 		public Builder withLockMode(LockMode lockMode) {
 			this.lockMode = lockMode;
 			return this;
 		}
 
 		public Builder withLockOptions(LockOptions lockOptions) {
 			this.lockOptions = lockOptions;
 			return this;
 		}
 
 		public EntityLoader byPrimaryKey() {
 			return byUniqueKey( persister.getIdentifierColumnNames(), persister.getIdentifierType() );
 		}
 
 		public EntityLoader byUniqueKey(String[] keyColumnNames, Type keyType) {
 			return new EntityLoader(
 					persister.getFactory(),
 					persister,
 					keyColumnNames,
 					keyType,
 					new QueryBuildingParameters() {
 						@Override
 						public LoadQueryInfluencers getQueryInfluencers() {
 							return influencers;
 						}
 
 						@Override
 						public int getBatchSize() {
 							return batchSize;
 						}
 
 						@Override
 						public LockMode getLockMode() {
 							return lockMode;
 						}
 
 						@Override
 						public LockOptions getLockOptions() {
 							return lockOptions;
 						}
 					}
 			);
 		}
 	}
 
 	private EntityLoader(
 			SessionFactoryImplementor factory,
 			OuterJoinLoadable persister,
 			String[] uniqueKeyColumnNames,
 			Type uniqueKeyType,
 			QueryBuildingParameters buildingParameters) throws MappingException {
 		super( persister, factory, uniqueKeyColumnNames, uniqueKeyType, buildingParameters );
 		if ( log.isDebugEnabled() ) {
 			if ( buildingParameters.getLockOptions() != null ) {
 				log.debugf(
 						"Static select for entity %s [%s:%s]: %s",
 						getEntityName(),
 						buildingParameters.getLockOptions().getLockMode(),
 						buildingParameters.getLockOptions().getTimeOut(),
 						getStaticLoadQuery().getSqlStatement()
 				);
 			}
 			else if ( buildingParameters.getLockMode() != null ) {
 				log.debugf(
 						"Static select for entity %s [%s]: %s",
 						getEntityName(),
 						buildingParameters.getLockMode(),
 						getStaticLoadQuery().getSqlStatement()
 				);
 			}
 		}
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/spaces/QuerySpacesImpl.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/spaces/QuerySpacesImpl.java
index 5455f6634d..1e5e6a9ea8 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/spaces/QuerySpacesImpl.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/internal/spaces/QuerySpacesImpl.java
@@ -1,188 +1,188 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.build.internal.spaces;
 
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.loader.plan.build.spi.ExpandingCollectionQuerySpace;
 import org.hibernate.loader.plan.build.spi.ExpandingCompositeQuerySpace;
 import org.hibernate.loader.plan.build.spi.ExpandingEntityQuerySpace;
 import org.hibernate.loader.plan.build.spi.ExpandingQuerySpaces;
 import org.hibernate.loader.plan.spi.QuerySpace;
 import org.hibernate.loader.plan.spi.QuerySpaceUidNotRegisteredException;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 
 /**
  * @author Steve Ebersole
  */
 public class QuerySpacesImpl implements ExpandingQuerySpaces {
 	private static final Logger log = CoreLogging.logger( QuerySpacesImpl.class );
 
 	private final SessionFactoryImplementor sessionFactory;
 	private final List<QuerySpace> roots = new ArrayList<QuerySpace>();
 	private final Map<String,QuerySpace> querySpaceByUid = new ConcurrentHashMap<String, QuerySpace>();
 
 	public QuerySpacesImpl(SessionFactoryImplementor sessionFactory) {
 		this.sessionFactory = sessionFactory;
 	}
 
 
 	// QuerySpaces impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public List<QuerySpace> getRootQuerySpaces() {
 		return roots;
 	}
 
 	@Override
 	public QuerySpace findQuerySpaceByUid(String uid) {
 		return querySpaceByUid.get( uid );
 	}
 
 	@Override
 	public QuerySpace getQuerySpaceByUid(String uid) {
 		final QuerySpace space = findQuerySpaceByUid( uid );
 		if ( space == null ) {
 			throw new QuerySpaceUidNotRegisteredException( uid );
 		}
 		return space;
 	}
 
-// ExpandingQuerySpaces impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+	// ExpandingQuerySpaces impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-	private int implicitUidBase = 0;
+	private int implicitUidBase;
 
 	@Override
 	public String generateImplicitUid() {
 		return "<gen:" + implicitUidBase++ + ">";
 	}
 
 	@Override
 	public ExpandingEntityQuerySpace makeRootEntityQuerySpace(String uid, EntityPersister entityPersister) {
 		final ExpandingEntityQuerySpace space = makeEntityQuerySpace( uid, entityPersister, true );
 		roots.add( space );
 		return space;
 	}
 
 	@Override
 	public ExpandingEntityQuerySpace makeEntityQuerySpace(
 			String uid,
 			EntityPersister entityPersister,
 			boolean canJoinsBeRequired) {
 
 		checkQuerySpaceDoesNotExist( uid );
 
 		final EntityQuerySpaceImpl space = new EntityQuerySpaceImpl(
 				entityPersister,
 				uid,
 				this,
 				canJoinsBeRequired
 		);
 		registerQuerySpace( space );
 
 		return space;
 	}
 
 	@Override
 	public ExpandingCollectionQuerySpace makeRootCollectionQuerySpace(String uid, CollectionPersister collectionPersister) {
 		final ExpandingCollectionQuerySpace space = makeCollectionQuerySpace( uid, collectionPersister, true );
 		roots.add( space );
 		return space;
 	}
 
 	@Override
 	public ExpandingCollectionQuerySpace makeCollectionQuerySpace(
 			String uid,
 			CollectionPersister collectionPersister,
 			boolean canJoinsBeRequired) {
 
 		checkQuerySpaceDoesNotExist( uid );
 
 		final ExpandingCollectionQuerySpace space = new CollectionQuerySpaceImpl(
 				collectionPersister,
 				uid,
 				this,
 				canJoinsBeRequired
 		);
 		registerQuerySpace( space );
 
 		return space;
 	}
 
 	@Override
 	public ExpandingCompositeQuerySpace makeCompositeQuerySpace(
 			String uid,
 			CompositePropertyMapping compositePropertyMapping,
 			boolean canJoinsBeRequired) {
 
 		checkQuerySpaceDoesNotExist( uid );
 
 		final ExpandingCompositeQuerySpace space = new CompositeQuerySpaceImpl(
 				compositePropertyMapping,
 				uid,
 				this,
 				canJoinsBeRequired
 		);
 		registerQuerySpace( space );
 
 		return space;
 	}
 
 	@Override
 	public SessionFactoryImplementor getSessionFactory() {
 		return sessionFactory;
 	}
 
 	private void checkQuerySpaceDoesNotExist(String uid) {
 		if ( querySpaceByUid.containsKey( uid ) ) {
 			throw new IllegalStateException( "Encountered duplicate QuerySpace uid : " + uid );
 		}
 	}
 
 	/**
 	 * Feeds a QuerySpace into this spaces group.
 	 *
 	 * @param querySpace The space
 	 */
 	private void registerQuerySpace(QuerySpace querySpace) {
 		log.debugf(
 				"Adding QuerySpace : uid = %s -> %s]",
 				querySpace.getUid(),
 				querySpace
 		);
 		final QuerySpace previous = querySpaceByUid.put( querySpace.getUid(), querySpace );
 		if ( previous != null ) {
 			throw new IllegalStateException( "Encountered duplicate QuerySpace uid : " + querySpace.getUid() );
 		}
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/ExpandingCollectionQuerySpace.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/ExpandingCollectionQuerySpace.java
index e3f6403df7..96995706ab 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/ExpandingCollectionQuerySpace.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/ExpandingCollectionQuerySpace.java
@@ -1,32 +1,32 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.build.spi;
 
 import org.hibernate.loader.plan.spi.CollectionQuerySpace;
 
 /**
  * @author Gail Badner
  */
 public interface ExpandingCollectionQuerySpace extends CollectionQuerySpace, ExpandingQuerySpace {
-}
\ No newline at end of file
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/MetamodelDrivenLoadPlanBuilder.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/MetamodelDrivenLoadPlanBuilder.java
index 0229308605..526516d3a0 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/MetamodelDrivenLoadPlanBuilder.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/build/spi/MetamodelDrivenLoadPlanBuilder.java
@@ -1,71 +1,74 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.build.spi;
 
 import org.hibernate.loader.plan.spi.LoadPlan;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.walking.spi.MetamodelGraphWalker;
 
 /**
  * A metadata-driven builder of LoadPlans.  Coordinates between the {@link MetamodelGraphWalker} and a
  * {@link LoadPlanBuildingAssociationVisitationStrategy}.
  *
  * @author Steve Ebersole
  *
  * @see org.hibernate.persister.walking.spi.MetamodelGraphWalker
  */
-public class MetamodelDrivenLoadPlanBuilder {
+public final class MetamodelDrivenLoadPlanBuilder {
+	private MetamodelDrivenLoadPlanBuilder() {
+	}
+
 	/**
 	 * Coordinates building a LoadPlan that defines just a single root entity return (may have fetches).
 	 * <p/>
 	 * Typically this includes building load plans for entity loading or cascade loading.
 	 *
 	 * @param strategy The strategy defining the load plan shaping
 	 * @param persister The persister for the entity forming the root of the load plan.
 	 *
 	 * @return The built load plan.
 	 */
 	public static LoadPlan buildRootEntityLoadPlan(
 			LoadPlanBuildingAssociationVisitationStrategy strategy,
 			EntityPersister persister) {
 		MetamodelGraphWalker.visitEntity( strategy, persister );
 		return strategy.buildLoadPlan();
 	}
 
 	/**
 	 * Coordinates building a LoadPlan that defines just a single root collection return (may have fetches).
 	 *
 	 * @param strategy The strategy defining the load plan shaping
 	 * @param persister The persister for the collection forming the root of the load plan.
 	 *
 	 * @return The built load plan.
 	 */
 	public static LoadPlan buildRootCollectionLoadPlan(
 			LoadPlanBuildingAssociationVisitationStrategy strategy,
 			CollectionPersister persister) {
 		MetamodelGraphWalker.visitCollection( strategy, persister );
 		return strategy.buildLoadPlan();
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CollectionFetchableIndex.java b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CollectionFetchableIndex.java
index 968b1612e6..750139b771 100644
--- a/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CollectionFetchableIndex.java
+++ b/hibernate-core/src/main/java/org/hibernate/loader/plan/spi/CollectionFetchableIndex.java
@@ -1,38 +1,38 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.loader.plan.spi;
 
 /**
  * A collection index which can be a FetchSource.
  *
  * @author Steve Ebersole
  */
 public interface CollectionFetchableIndex extends FetchSource {
 	/**
 	 * Reference back to the collection to which this index belongs
 	 *
 	 * @return the collection reference.
 	 */
 	public CollectionReference getCollectionReference();
-}
\ No newline at end of file
+}
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/Column.java b/hibernate-core/src/main/java/org/hibernate/mapping/Column.java
index 618accde88..6ef249f91d 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/Column.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/Column.java
@@ -1,367 +1,376 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 import java.io.Serializable;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.sql.Template;
 
 /**
  * A column of a relational database table
  * @author Gavin King
  */
 public class Column implements Selectable, Serializable, Cloneable {
 
 	public static final int DEFAULT_LENGTH = 255;
 	public static final int DEFAULT_PRECISION = 19;
 	public static final int DEFAULT_SCALE = 2;
 
 	private int length=DEFAULT_LENGTH;
 	private int precision=DEFAULT_PRECISION;
 	private int scale=DEFAULT_SCALE;
 	private Value value;
-	private int typeIndex = 0;
+	private int typeIndex;
 	private String name;
 	private boolean nullable=true;
-	private boolean unique=false;
+	private boolean unique;
 	private String sqlType;
 	private Integer sqlTypeCode;
-	private boolean quoted=false;
+	private boolean quoted;
 	int uniqueInteger;
 	private String checkConstraint;
 	private String comment;
 	private String defaultValue;
 	private String customWrite;
 	private String customRead;
 
 	public Column() {
 	}
 
 	public Column(String columnName) {
 		setName(columnName);
 	}
 
 	public int getLength() {
 		return length;
 	}
 	public void setLength(int length) {
 		this.length = length;
 	}
 	public Value getValue() {
 		return value;
 	}
 	public void setValue(Value value) {
 		this.value= value;
 	}
 	public String getName() {
 		return name;
 	}
 	public void setName(String name) {
 		if (
 			StringHelper.isNotEmpty( name ) &&
 			Dialect.QUOTE.indexOf( name.charAt(0) ) > -1 //TODO: deprecated, remove eventually
 		) {
 			quoted=true;
 			this.name=name.substring( 1, name.length()-1 );
 		}
 		else {
 			this.name = name;
 		}
 	}
 
 	/** returns quoted name as it would be in the mapping file. */
 	public String getQuotedName() {
 		return quoted ?
 				"`" + name + "`" :
 				name;
 	}
 
 	public String getQuotedName(Dialect d) {
 		return quoted ?
 			d.openQuote() + name + d.closeQuote() :
 			name;
 	}
 	
 	@Override
 	public String getAlias(Dialect dialect) {
 		final int lastLetter = StringHelper.lastIndexOfLetter( name );
 		final String suffix = Integer.toString(uniqueInteger) + '_';
 
 		String alias = name;
 		if ( lastLetter == -1 ) {
 			alias = "column";
 		}
 		else if ( name.length() > lastLetter + 1 ) {
 			alias = name.substring( 0, lastLetter + 1 );
 		}
 
 		boolean useRawName = name.length() + suffix.length() <= dialect.getMaxAliasLength()
 				&& !quoted && !name.toLowerCase().equals( "rowid" );
 		if ( !useRawName ) {
 			if ( suffix.length() >= dialect.getMaxAliasLength() ) {
 				throw new MappingException( String.format(
 						"Unique suffix [%s] length must be less than maximum [%d]",
 						suffix, dialect.getMaxAliasLength() ) );
 			}
 			if ( alias.length() + suffix.length() > dialect.getMaxAliasLength() ) {
 				alias = alias.substring( 0, dialect.getMaxAliasLength() - suffix.length() );
 			}
 		}
 		return alias + suffix;
 	}
 	
 	/**
 	 * Generate a column alias that is unique across multiple tables
 	 */
+	@Override
 	public String getAlias(Dialect dialect, Table table) {
 		return getAlias(dialect) + table.getUniqueInteger() + '_';
 	}
 
 	public boolean isNullable() {
 		return nullable;
 	}
 
 	public void setNullable(boolean nullable) {
 		this.nullable=nullable;
 	}
 
 	public int getTypeIndex() {
 		return typeIndex;
 	}
 	public void setTypeIndex(int typeIndex) {
 		this.typeIndex = typeIndex;
 	}
 
 	public boolean isUnique() {
 		return unique;
 	}
 
-	//used also for generation of FK names!
+	@Override
 	public int hashCode() {
+		//used also for generation of FK names!
 		return isQuoted() ?
 			name.hashCode() :
 			name.toLowerCase().hashCode();
 	}
 
+	@Override
 	public boolean equals(Object object) {
 		return object instanceof Column && equals( (Column) object );
 	}
 
 	public boolean equals(Column column) {
 		if (null == column) return false;
 		if (this == column) return true;
 
 		return isQuoted() ? 
 			name.equals(column.name) :
 			name.equalsIgnoreCase(column.name);
 	}
 
     public int getSqlTypeCode(Mapping mapping) throws MappingException {
         org.hibernate.type.Type type = getValue().getType();
         try {
             int sqlTypeCode = type.sqlTypes( mapping )[getTypeIndex()];
             if ( getSqlTypeCode() != null && getSqlTypeCode() != sqlTypeCode ) {
                 throw new MappingException( "SQLType code's does not match. mapped as " + sqlTypeCode + " but is " + getSqlTypeCode() );
             }
             return sqlTypeCode;
         }
         catch ( Exception e ) {
             throw new MappingException(
                     "Could not determine type for column " +
                             name +
                             " of type " +
                             type.getClass().getName() +
                             ": " +
                             e.getClass().getName(),
                     e
             );
         }
     }
 
     /**
      * Returns the underlying columns sqltypecode.
      * If null, it is because the sqltype code is unknown.
      *
      * Use #getSqlTypeCode(Mapping) to retreive the sqltypecode used
      * for the columns associated Value/Type.
      *
      * @return sqlTypeCode if it is set, otherwise null.
      */
     public Integer getSqlTypeCode() {
         return sqlTypeCode;
     }
 
     public void setSqlTypeCode(Integer typeCode) {
         sqlTypeCode=typeCode;
     }
 
     public String getSqlType(Dialect dialect, Mapping mapping) throws HibernateException {
         if ( sqlType == null ) {
             sqlType = dialect.getTypeName( getSqlTypeCode( mapping ), getLength(), getPrecision(), getScale() );
         }
         return sqlType;
     }
 
 	public String getSqlType() {
 		return sqlType;
 	}
 
 	public void setSqlType(String sqlType) {
 		this.sqlType = sqlType;
 	}
 
 	public void setUnique(boolean unique) {
 		this.unique = unique;
 	}
 
 	public boolean isQuoted() {
 		return quoted;
 	}
 
+	@Override
 	public String toString() {
 		return getClass().getName() + '(' + getName() + ')';
 	}
 
 	public String getCheckConstraint() {
 		return checkConstraint;
 	}
 
 	public void setCheckConstraint(String checkConstraint) {
 		this.checkConstraint = checkConstraint;
 	}
 
 	public boolean hasCheckConstraint() {
 		return checkConstraint!=null;
 	}
 
+	@Override
 	public String getTemplate(Dialect dialect, SQLFunctionRegistry functionRegistry) {
 		return hasCustomRead()
 				? Template.renderWhereStringTemplate( customRead, dialect, functionRegistry )
 				: Template.TEMPLATE + '.' + getQuotedName( dialect );
 	}
 
 	public boolean hasCustomRead() {
 		return ( customRead != null && customRead.length() > 0 );
 	}
 
 	public String getReadExpr(Dialect dialect) {
 		return hasCustomRead() ? customRead : getQuotedName( dialect );
 	}
 	
 	public String getWriteExpr() {
 		return ( customWrite != null && customWrite.length() > 0 ) ? customWrite : "?";
 	}
-	
+
+	@Override
 	public boolean isFormula() {
 		return false;
 	}
 
+	@Override
 	public String getText(Dialect d) {
 		return getQuotedName(d);
 	}
+
+	@Override
 	public String getText() {
 		return getName();
 	}
 	
 	public int getPrecision() {
 		return precision;
 	}
 	public void setPrecision(int scale) {
 		this.precision = scale;
 	}
 
 	public int getScale() {
 		return scale;
 	}
 	public void setScale(int scale) {
 		this.scale = scale;
 	}
 
 	public String getComment() {
 		return comment;
 	}
 
 	public void setComment(String comment) {
 		this.comment = comment;
 	}
 
 	public String getDefaultValue() {
 		return defaultValue;
 	}
 
 	public void setDefaultValue(String defaultValue) {
 		this.defaultValue = defaultValue;
 	}
 
 	public String getCustomWrite() {
 		return customWrite;
 	}
 
 	public void setCustomWrite(String customWrite) {
 		this.customWrite = customWrite;
 	}
 
 	public String getCustomRead() {
 		return customRead;
 	}
 
 	public void setCustomRead(String customRead) {
 		this.customRead = customRead;
 	}
 
 	public String getCanonicalName() {
 		return quoted ? name : name.toLowerCase();
 	}
 
 	/**
 	 * Shallow copy, the value is not copied
 	 */
 	@Override
 	public Column clone() {
 		Column copy = new Column();
 		copy.setLength( length );
 		copy.setScale( scale );
 		copy.setValue( value );
 		copy.setTypeIndex( typeIndex );
 		copy.setName( getQuotedName() );
 		copy.setNullable( nullable );
 		copy.setPrecision( precision );
 		copy.setUnique( unique );
 		copy.setSqlType( sqlType );
 		copy.setSqlTypeCode( sqlTypeCode );
 		copy.uniqueInteger = uniqueInteger; //usually useless
 		copy.setCheckConstraint( checkConstraint );
 		copy.setComment( comment );
 		copy.setDefaultValue( defaultValue );
 		copy.setCustomRead( customRead );
 		copy.setCustomWrite( customWrite );
 		return copy;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/Formula.java b/hibernate-core/src/main/java/org/hibernate/mapping/Formula.java
index a53f687c41..9bdbe798fe 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/Formula.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/Formula.java
@@ -1,73 +1,87 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 import java.io.Serializable;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.function.SQLFunctionRegistry;
 import org.hibernate.sql.Template;
 
 /**
  * A formula is a derived column value
  * @author Gavin King
  */
 public class Formula implements Selectable, Serializable {
 	private static int formulaUniqueInteger=0;
 
 	private String formula;
 	private int uniqueInteger;
 
 	public Formula() {
 		uniqueInteger = formulaUniqueInteger++;
 	}
 
+	@Override
 	public String getTemplate(Dialect dialect, SQLFunctionRegistry functionRegistry) {
 		return Template.renderWhereStringTemplate(formula, dialect, functionRegistry);
 	}
+
+	@Override
 	public String getText(Dialect dialect) {
 		return getFormula();
 	}
+
+	@Override
 	public String getText() {
 		return getFormula();
 	}
+
+	@Override
 	public String getAlias(Dialect dialect) {
 		return "formula" + Integer.toString(uniqueInteger) + '_';
 	}
+
+	@Override
 	public String getAlias(Dialect dialect, Table table) {
 		return getAlias(dialect);
 	}
+
 	public String getFormula() {
 		return formula;
 	}
+
 	public void setFormula(String string) {
 		formula = string;
 	}
+
+	@Override
 	public boolean isFormula() {
 		return true;
 	}
 
+	@Override
 	public String toString() {
 		return this.getClass().getName() + "( " + formula + " )";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/RootClass.java b/hibernate-core/src/main/java/org/hibernate/mapping/RootClass.java
index 774aa95e5a..1869267221 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/RootClass.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/RootClass.java
@@ -1,355 +1,355 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.io.Serializable;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.MappingException;
 import org.hibernate.engine.OptimisticLockStyle;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.collections.SingletonIterator;
 
 /**
  * The root class of an inheritance hierarchy
  * @author Gavin King
  */
 public class RootClass extends PersistentClass implements TableOwner {
 
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, RootClass.class.getName());
 
 	public static final String DEFAULT_IDENTIFIER_COLUMN_NAME = "id";
 	public static final String DEFAULT_DISCRIMINATOR_COLUMN_NAME = "class";
 
-	private Property identifierProperty; //may be final
-	private KeyValue identifier; //may be final
-	private Property version; //may be final
+	private Property identifierProperty;
+	private KeyValue identifier;
+	private Property version;
 	private boolean polymorphic;
 	private String cacheConcurrencyStrategy;
 	private String cacheRegionName;
 	private String naturalIdCacheRegionName;
 	private boolean lazyPropertiesCacheable = true;
-	private Value discriminator; //may be final
+	private Value discriminator;
 	private boolean mutable = true;
-	private boolean embeddedIdentifier = false; // may be final
+	private boolean embeddedIdentifier;
 	private boolean explicitPolymorphism;
 	private Class entityPersisterClass;
-	private boolean forceDiscriminator = false;
+	private boolean forceDiscriminator;
 	private String where;
 	private Table table;
 	private boolean discriminatorInsertable = true;
-	private int nextSubclassId = 0;
+	private int nextSubclassId;
 	private Property declaredIdentifierProperty;
 	private Property declaredVersion;
 
 	@Override
     int nextSubclassId() {
 		return ++nextSubclassId;
 	}
 
 	@Override
     public int getSubclassId() {
 		return 0;
 	}
 
 	public void setTable(Table table) {
 		this.table=table;
 	}
 	@Override
     public Table getTable() {
 		return table;
 	}
 
 	@Override
     public Property getIdentifierProperty() {
 		return identifierProperty;
 	}
 
 	@Override
     public Property getDeclaredIdentifierProperty() {
 		return declaredIdentifierProperty;
 	}
 
 	public void setDeclaredIdentifierProperty(Property declaredIdentifierProperty) {
 		this.declaredIdentifierProperty = declaredIdentifierProperty;
 	}
 
 	@Override
     public KeyValue getIdentifier() {
 		return identifier;
 	}
 	@Override
     public boolean hasIdentifierProperty() {
 		return identifierProperty!=null;
 	}
 
 	@Override
     public Value getDiscriminator() {
 		return discriminator;
 	}
 
 	@Override
     public boolean isInherited() {
 		return false;
 	}
 	@Override
     public boolean isPolymorphic() {
 		return polymorphic;
 	}
 
 	public void setPolymorphic(boolean polymorphic) {
 		this.polymorphic = polymorphic;
 	}
 
 	@Override
     public RootClass getRootClass() {
 		return this;
 	}
 
 	@Override
     public Iterator getPropertyClosureIterator() {
 		return getPropertyIterator();
 	}
 	@Override
     public Iterator getTableClosureIterator() {
 		return new SingletonIterator( getTable() );
 	}
 	@Override
     public Iterator getKeyClosureIterator() {
 		return new SingletonIterator( getKey() );
 	}
 
 	@Override
     public void addSubclass(Subclass subclass) throws MappingException {
 		super.addSubclass(subclass);
 		setPolymorphic(true);
 	}
 
 	@Override
     public boolean isExplicitPolymorphism() {
 		return explicitPolymorphism;
 	}
 
 	@Override
     public Property getVersion() {
 		return version;
 	}
 
 	@Override
     public Property getDeclaredVersion() {
 		return declaredVersion;
 	}
 
 	public void setDeclaredVersion(Property declaredVersion) {
 		this.declaredVersion = declaredVersion;
 	}
 
 	public void setVersion(Property version) {
 		this.version = version;
 	}
 	@Override
     public boolean isVersioned() {
 		return version!=null;
 	}
 
 	@Override
     public boolean isMutable() {
 		return mutable;
 	}
 	@Override
     public boolean hasEmbeddedIdentifier() {
 		return embeddedIdentifier;
 	}
 
 	@Override
     public Class getEntityPersisterClass() {
 		return entityPersisterClass;
 	}
 
 	@Override
     public Table getRootTable() {
 		return getTable();
 	}
 
 	@Override
     public void setEntityPersisterClass(Class persister) {
 		this.entityPersisterClass = persister;
 	}
 
 	@Override
     public PersistentClass getSuperclass() {
 		return null;
 	}
 
 	@Override
     public KeyValue getKey() {
 		return getIdentifier();
 	}
 
 	public void setDiscriminator(Value discriminator) {
 		this.discriminator = discriminator;
 	}
 
 	public void setEmbeddedIdentifier(boolean embeddedIdentifier) {
 		this.embeddedIdentifier = embeddedIdentifier;
 	}
 
 	public void setExplicitPolymorphism(boolean explicitPolymorphism) {
 		this.explicitPolymorphism = explicitPolymorphism;
 	}
 
 	public void setIdentifier(KeyValue identifier) {
 		this.identifier = identifier;
 	}
 
 	public void setIdentifierProperty(Property identifierProperty) {
 		this.identifierProperty = identifierProperty;
 		identifierProperty.setPersistentClass(this);
 
 	}
 
 	public void setMutable(boolean mutable) {
 		this.mutable = mutable;
 	}
 
 	@Override
     public boolean isDiscriminatorInsertable() {
 		return discriminatorInsertable;
 	}
 
 	public void setDiscriminatorInsertable(boolean insertable) {
 		this.discriminatorInsertable = insertable;
 	}
 
 	@Override
     public boolean isForceDiscriminator() {
 		return forceDiscriminator;
 	}
 
 	public void setForceDiscriminator(boolean forceDiscriminator) {
 		this.forceDiscriminator = forceDiscriminator;
 	}
 
 	@Override
     public String getWhere() {
 		return where;
 	}
 
 	public void setWhere(String string) {
 		where = string;
 	}
 
 	@Override
     public void validate(Mapping mapping) throws MappingException {
 		super.validate(mapping);
 		if ( !getIdentifier().isValid(mapping) ) {
 			throw new MappingException(
 				"identifier mapping has wrong number of columns: " +
 				getEntityName() +
 				" type: " +
 				getIdentifier().getType().getName()
 			);
 		}
 		checkCompositeIdentifier();
 	}
 
 	private void checkCompositeIdentifier() {
 		if ( getIdentifier() instanceof Component ) {
 			Component id = (Component) getIdentifier();
 			if ( !id.isDynamic() ) {
 				final Class idClass = id.getComponentClass();
 				final String idComponendClassName = idClass.getName();
                 if (idClass != null && !ReflectHelper.overridesEquals(idClass)) LOG.compositeIdClassDoesNotOverrideEquals( idComponendClassName );
                 if (!ReflectHelper.overridesHashCode(idClass)) LOG.compositeIdClassDoesNotOverrideHashCode( idComponendClassName );
                 if (!Serializable.class.isAssignableFrom(idClass)) throw new MappingException(
                                                                                               "Composite-id class must implement Serializable: "
                                                                                               + idComponendClassName);
 			}
 		}
 	}
 
 	@Override
     public String getCacheConcurrencyStrategy() {
 		return cacheConcurrencyStrategy;
 	}
 
 	public void setCacheConcurrencyStrategy(String cacheConcurrencyStrategy) {
 		this.cacheConcurrencyStrategy = cacheConcurrencyStrategy;
 	}
 
 	public String getCacheRegionName() {
 		return cacheRegionName==null ? getEntityName() : cacheRegionName;
 	}
 	public void setCacheRegionName(String cacheRegionName) {
 		this.cacheRegionName = cacheRegionName;
 	}
 	
 	@Override
 	public String getNaturalIdCacheRegionName() {
 		return naturalIdCacheRegionName;
 	}
 	public void setNaturalIdCacheRegionName(String naturalIdCacheRegionName) {
 		this.naturalIdCacheRegionName = naturalIdCacheRegionName;
 	}
 	
 	@Override
     public boolean isLazyPropertiesCacheable() {
 		return lazyPropertiesCacheable;
 	}
 
 	public void setLazyPropertiesCacheable(boolean lazyPropertiesCacheable) {
 		this.lazyPropertiesCacheable = lazyPropertiesCacheable;
 	}
 
 	@Override
     public boolean isJoinedSubclass() {
 		return false;
 	}
 
 	@Override
     public java.util.Set getSynchronizedTables() {
 		return synchronizedTables;
 	}
 
 	public Set getIdentityTables() {
 		Set tables = new HashSet();
 		Iterator iter = getSubclassClosureIterator();
 		while ( iter.hasNext() ) {
 			PersistentClass clazz = (PersistentClass) iter.next();
 			if ( clazz.isAbstract() == null || !clazz.isAbstract().booleanValue() ) tables.add( clazz.getIdentityTable() );
 		}
 		return tables;
 	}
 
 	@Override
     public Object accept(PersistentClassVisitor mv) {
 		return mv.accept(this);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/Table.java b/hibernate-core/src/main/java/org/hibernate/mapping/Table.java
index d134690003..7a3ca06838 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/Table.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/Table.java
@@ -1,859 +1,859 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
 
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.HibernateException;
 import org.hibernate.MappingException;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.tool.hbm2ddl.ColumnMetadata;
 import org.hibernate.tool.hbm2ddl.TableMetadata;
 
 /**
  * A relational table
  *
  * @author Gavin King
  */
 public class Table implements RelationalModel, Serializable {
 
 	private String name;
 	private String schema;
 	private String catalog;
 	/**
 	 * contains all columns, including the primary key
 	 */
 	private Map columns = new LinkedHashMap();
 	private KeyValue idValue;
 	private PrimaryKey primaryKey;
 	private Map<String, Index> indexes = new LinkedHashMap<String, Index>();
 	private Map foreignKeys = new LinkedHashMap();
 	private Map<String,UniqueKey> uniqueKeys = new LinkedHashMap<String,UniqueKey>();
 	private int uniqueInteger;
 	private boolean quoted;
 	private boolean schemaQuoted;
 	private boolean catalogQuoted;
 	private List checkConstraints = new ArrayList();
 	private String rowId;
 	private String subselect;
 	private boolean isAbstract;
-	private boolean hasDenormalizedTables = false;
+	private boolean hasDenormalizedTables;
 	private String comment;
 	
 	static class ForeignKeyKey implements Serializable {
 		String referencedClassName;
 		List columns;
 		List referencedColumns;
 
 		ForeignKeyKey(List columns, String referencedClassName, List referencedColumns) {
 			this.referencedClassName = referencedClassName;
 			this.columns = new ArrayList();
 			this.columns.addAll( columns );
 			if ( referencedColumns != null ) {
 				this.referencedColumns = new ArrayList();
 				this.referencedColumns.addAll( referencedColumns );
 			}
 			else {
 				this.referencedColumns = Collections.EMPTY_LIST;
 			}
 		}
 
 		public int hashCode() {
 			return columns.hashCode() + referencedColumns.hashCode();
 		}
 
 		public boolean equals(Object other) {
 			ForeignKeyKey fkk = (ForeignKeyKey) other;
 			return fkk.columns.equals( columns ) &&
 					fkk.referencedClassName.equals( referencedClassName ) && fkk.referencedColumns
 					.equals( referencedColumns );
 		}
 	}
 
 	public Table() { }
 
 	public Table(String name) {
 		this();
 		setName( name );
 	}
 
 	public String getQualifiedName(Dialect dialect, String defaultCatalog, String defaultSchema) {
 		if ( subselect != null ) {
 			return "( " + subselect + " )";
 		}
 		String quotedName = getQuotedName( dialect );
 		String usedSchema = schema == null ?
 				defaultSchema :
 				getQuotedSchema( dialect );
 		String usedCatalog = catalog == null ?
 				defaultCatalog :
 				getQuotedCatalog( dialect );
 		return qualify( usedCatalog, usedSchema, quotedName );
 	}
 
 	public static String qualify(String catalog, String schema, String table) {
 		StringBuilder qualifiedName = new StringBuilder();
 		if ( catalog != null ) {
 			qualifiedName.append( catalog ).append( '.' );
 		}
 		if ( schema != null ) {
 			qualifiedName.append( schema ).append( '.' );
 		}
 		return qualifiedName.append( table ).toString();
 	}
 
 	public String getName() {
 		return name;
 	}
 
 	/**
 	 * returns quoted name as it would be in the mapping file.
 	 */
 	public String getQuotedName() {
 		return quoted ?
 				"`" + name + "`" :
 				name;
 	}
 
 	public String getQuotedName(Dialect dialect) {
 		return quoted ?
 				dialect.openQuote() + name + dialect.closeQuote() :
 				name;
 	}
 
 	/**
 	 * returns quoted name as it is in the mapping file.
 	 */
 	public String getQuotedSchema() {
 		return schemaQuoted ?
 				"`" + schema + "`" :
 				schema;
 	}
 
 	public String getQuotedSchema(Dialect dialect) {
 		return schemaQuoted ?
 				dialect.openQuote() + schema + dialect.closeQuote() :
 				schema;
 	}
 
 	public String getQuotedCatalog() {
 		return catalogQuoted ?
 				"`" + catalog + "`" :
 				catalog;
 	}
 
 	public String getQuotedCatalog(Dialect dialect) {
 		return catalogQuoted ?
 				dialect.openQuote() + catalog + dialect.closeQuote() :
 				catalog;
 	}
 
 	public void setName(String name) {
 		if ( name.charAt( 0 ) == '`' ) {
 			quoted = true;
 			this.name = name.substring( 1, name.length() - 1 );
 		}
 		else {
 			this.name = name;
 		}
 	}
 
 	/**
 	 * Return the column which is identified by column provided as argument.
 	 *
 	 * @param column column with atleast a name.
 	 * @return the underlying column or null if not inside this table. Note: the instance *can* be different than the input parameter, but the name will be the same.
 	 */
 	public Column getColumn(Column column) {
 		if ( column == null ) {
 			return null;
 		}
 
 		Column myColumn = (Column) columns.get( column.getCanonicalName() );
 
 		return column.equals( myColumn ) ?
 				myColumn :
 				null;
 	}
 
 	public Column getColumn(int n) {
 		Iterator iter = columns.values().iterator();
 		for ( int i = 0; i < n - 1; i++ ) {
 			iter.next();
 		}
 		return (Column) iter.next();
 	}
 
 	public void addColumn(Column column) {
 		Column old = getColumn( column );
 		if ( old == null ) {
 			columns.put( column.getCanonicalName(), column );
 			column.uniqueInteger = columns.size();
 		}
 		else {
 			column.uniqueInteger = old.uniqueInteger;
 		}
 	}
 
 	public int getColumnSpan() {
 		return columns.size();
 	}
 
 	public Iterator getColumnIterator() {
 		return columns.values().iterator();
 	}
 
 	public Iterator<Index> getIndexIterator() {
 		return indexes.values().iterator();
 	}
 
 	public Iterator getForeignKeyIterator() {
 		return foreignKeys.values().iterator();
 	}
 
 	public Iterator<UniqueKey> getUniqueKeyIterator() {
 		return getUniqueKeys().values().iterator();
 	}
 
 	Map<String, UniqueKey> getUniqueKeys() {
 		cleanseUniqueKeyMapIfNeeded();
 		return uniqueKeys;
 	}
 
 	private int sizeOfUniqueKeyMapOnLastCleanse = 0;
 
 	private void cleanseUniqueKeyMapIfNeeded() {
 		if ( uniqueKeys.size() == sizeOfUniqueKeyMapOnLastCleanse ) {
 			// nothing to do
 			return;
 		}
 		cleanseUniqueKeyMap();
 		sizeOfUniqueKeyMapOnLastCleanse = uniqueKeys.size();
 	}
 
 	private void cleanseUniqueKeyMap() {
 		// We need to account for a few conditions here...
 		// 	1) If there are multiple unique keys contained in the uniqueKeys Map, we need to deduplicate
 		// 		any sharing the same columns as other defined unique keys; this is needed for the annotation
 		// 		processor since it creates unique constraints automagically for the user
 		//	2) Remove any unique keys that share the same columns as the primary key; again, this is
 		//		needed for the annotation processor to handle @Id @OneToOne cases.  In such cases the
 		//		unique key is unnecessary because a primary key is already unique by definition.  We handle
 		//		this case specifically because some databases fail if you try to apply a unique key to
 		//		the primary key columns which causes schema export to fail in these cases.
 		if ( uniqueKeys.isEmpty() ) {
 			// nothing to do
 			return;
 		}
 		else if ( uniqueKeys.size() == 1 ) {
 			// we have to worry about condition 2 above, but not condition 1
 			final Map.Entry<String,UniqueKey> uniqueKeyEntry = uniqueKeys.entrySet().iterator().next();
 			if ( isSameAsPrimaryKeyColumns( uniqueKeyEntry.getValue() ) ) {
 				uniqueKeys.remove( uniqueKeyEntry.getKey() );
 			}
 		}
 		else {
 			// we have to check both conditions 1 and 2
 			final Iterator<Map.Entry<String,UniqueKey>> uniqueKeyEntries = uniqueKeys.entrySet().iterator();
 			while ( uniqueKeyEntries.hasNext() ) {
 				final Map.Entry<String,UniqueKey> uniqueKeyEntry = uniqueKeyEntries.next();
 				final UniqueKey uniqueKey = uniqueKeyEntry.getValue();
 				boolean removeIt = false;
 
 				// condition 1 : check against other unique keys
 				for ( UniqueKey otherUniqueKey : uniqueKeys.values() ) {
 					// make sure its not the same unique key
 					if ( uniqueKeyEntry.getValue() == otherUniqueKey ) {
 						continue;
 					}
 					if ( otherUniqueKey.getColumns().containsAll( uniqueKey.getColumns() )
 							&& uniqueKey.getColumns().containsAll( otherUniqueKey.getColumns() ) ) {
 						removeIt = true;
 						break;
 					}
 				}
 
 				// condition 2 : check against pk
 				if ( isSameAsPrimaryKeyColumns( uniqueKeyEntry.getValue() ) ) {
 					removeIt = true;
 				}
 
 				if ( removeIt ) {
 					//uniqueKeys.remove( uniqueKeyEntry.getKey() );
 					uniqueKeyEntries.remove();
 				}
 			}
 
 		}
 	}
 
 	private boolean isSameAsPrimaryKeyColumns(UniqueKey uniqueKey) {
 		if ( primaryKey == null || ! primaryKey.columnIterator().hasNext() ) {
 			// happens for many-to-many tables
 			return false;
 		}
 		return primaryKey.getColumns().containsAll( uniqueKey.getColumns() )
 				&& uniqueKey.getColumns().containsAll( primaryKey.getColumns() );
 	}
 
 	@Override
 	public int hashCode() {
 		final int prime = 31;
 		int result = 1;
 		result = prime * result
 			+ ((catalog == null) ? 0 : isCatalogQuoted() ? catalog.hashCode() : catalog.toLowerCase().hashCode());
 		result = prime * result + ((name == null) ? 0 : isQuoted() ? name.hashCode() : name.toLowerCase().hashCode());
 		result = prime * result
 			+ ((schema == null) ? 0 : isSchemaQuoted() ? schema.hashCode() : schema.toLowerCase().hashCode());
 		return result;
 	}
 
 	@Override
 	public boolean equals(Object object) {
 		return object instanceof Table && equals((Table) object);
 	}
 
 	public boolean equals(Table table) {
 		if (null == table) {
 			return false;
 		}
 		if (this == table) {
 			return true;
 		}
 
 		return isQuoted() ? name.equals(table.getName()) : name.equalsIgnoreCase(table.getName())
 			&& ((schema == null && table.getSchema() != null) ? false : (schema == null) ? true : isSchemaQuoted() ? schema.equals(table.getSchema()) : schema.equalsIgnoreCase(table.getSchema()))
 			&& ((catalog == null && table.getCatalog() != null) ? false : (catalog == null) ? true : isCatalogQuoted() ? catalog.equals(table.getCatalog()) : catalog.equalsIgnoreCase(table.getCatalog()));
 	}
 	
 	public void validateColumns(Dialect dialect, Mapping mapping, TableMetadata tableInfo) {
 		Iterator iter = getColumnIterator();
 		while ( iter.hasNext() ) {
 			Column col = (Column) iter.next();
 
 			ColumnMetadata columnInfo = tableInfo.getColumnMetadata( col.getName() );
 
 			if ( columnInfo == null ) {
 				throw new HibernateException( "Missing column: " + col.getName() + " in " + Table.qualify( tableInfo.getCatalog(), tableInfo.getSchema(), tableInfo.getName()));
 			}
 			else {
 				final boolean typesMatch = col.getSqlType( dialect, mapping ).toLowerCase()
 						.startsWith( columnInfo.getTypeName().toLowerCase() )
 						|| columnInfo.getTypeCode() == col.getSqlTypeCode( mapping );
 				if ( !typesMatch ) {
 					throw new HibernateException(
 							"Wrong column type in " +
 							Table.qualify( tableInfo.getCatalog(), tableInfo.getSchema(), tableInfo.getName()) +
 							" for column " + col.getName() +
 							". Found: " + columnInfo.getTypeName().toLowerCase() +
 							", expected: " + col.getSqlType( dialect, mapping )
 					);
 				}
 			}
 		}
 
 	}
 
 	public Iterator sqlAlterStrings(Dialect dialect, Mapping p, TableMetadata tableInfo, String defaultCatalog,
 									String defaultSchema)
 			throws HibernateException {
 
 		StringBuilder root = new StringBuilder( "alter table " )
 				.append( getQualifiedName( dialect, defaultCatalog, defaultSchema ) )
 				.append( ' ' )
 				.append( dialect.getAddColumnString() );
 
 		Iterator iter = getColumnIterator();
 		List results = new ArrayList();
 		
 		while ( iter.hasNext() ) {
 			Column column = (Column) iter.next();
 
 			ColumnMetadata columnInfo = tableInfo.getColumnMetadata( column.getName() );
 
 			if ( columnInfo == null ) {
 				// the column doesnt exist at all.
 				StringBuilder alter = new StringBuilder( root.toString() )
 						.append( ' ' )
 						.append( column.getQuotedName( dialect ) )
 						.append( ' ' )
 						.append( column.getSqlType( dialect, p ) );
 
 				String defaultValue = column.getDefaultValue();
 				if ( defaultValue != null ) {
 					alter.append( " default " ).append( defaultValue );
 				}
 
 				if ( column.isNullable() ) {
 					alter.append( dialect.getNullColumnString() );
 				}
 				else {
 					alter.append( " not null" );
 				}
 
 				if ( column.isUnique() ) {
 					String keyName = Constraint.generateName( "UK_", this, column );
 					UniqueKey uk = getOrCreateUniqueKey( keyName );
 					uk.addColumn( column );
 					alter.append( dialect.getUniqueDelegate()
 							.getColumnDefinitionUniquenessFragment( column ) );
 				}
 
 				if ( column.hasCheckConstraint() && dialect.supportsColumnCheck() ) {
 					alter.append( " check(" )
 							.append( column.getCheckConstraint() )
 							.append( ")" );
 				}
 
 				String columnComment = column.getComment();
 				if ( columnComment != null ) {
 					alter.append( dialect.getColumnComment( columnComment ) );
 				}
 
 				alter.append( dialect.getAddColumnSuffixString() );
 
 				results.add( alter.toString() );
 			}
 
 		}
 
 		return results.iterator();
 	}
 
 	public boolean hasPrimaryKey() {
 		return getPrimaryKey() != null;
 	}
 
 	public String sqlTemporaryTableCreateString(Dialect dialect, Mapping mapping) throws HibernateException {
 		StringBuilder buffer = new StringBuilder( dialect.getCreateTemporaryTableString() )
 				.append( ' ' )
 				.append( name )
 				.append( " (" );
 		Iterator itr = getColumnIterator();
 		while ( itr.hasNext() ) {
 			final Column column = (Column) itr.next();
 			buffer.append( column.getQuotedName( dialect ) ).append( ' ' );
 			buffer.append( column.getSqlType( dialect, mapping ) );
 			if ( column.isNullable() ) {
 				buffer.append( dialect.getNullColumnString() );
 			}
 			else {
 				buffer.append( " not null" );
 			}
 			if ( itr.hasNext() ) {
 				buffer.append( ", " );
 			}
 		}
 		buffer.append( ") " );
 		buffer.append( dialect.getCreateTemporaryTablePostfix() );
 		return buffer.toString();
 	}
 
 	public String sqlCreateString(Dialect dialect, Mapping p, String defaultCatalog, String defaultSchema) {
 		StringBuilder buf = new StringBuilder( hasPrimaryKey() ? dialect.getCreateTableString() : dialect.getCreateMultisetTableString() )
 				.append( ' ' )
 				.append( getQualifiedName( dialect, defaultCatalog, defaultSchema ) )
 				.append( " (" );
 
 		boolean identityColumn = idValue != null && idValue.isIdentityColumn( p.getIdentifierGeneratorFactory(), dialect );
 
 		// Try to find out the name of the primary key to create it as identity if the IdentityGenerator is used
 		String pkname = null;
 		if ( hasPrimaryKey() && identityColumn ) {
 			pkname = ( (Column) getPrimaryKey().getColumnIterator().next() ).getQuotedName( dialect );
 		}
 
 		Iterator iter = getColumnIterator();
 		while ( iter.hasNext() ) {
 			Column col = (Column) iter.next();
 
 			buf.append( col.getQuotedName( dialect ) )
 					.append( ' ' );
 
 			if ( identityColumn && col.getQuotedName( dialect ).equals( pkname ) ) {
 				// to support dialects that have their own identity data type
 				if ( dialect.hasDataTypeInIdentityColumn() ) {
 					buf.append( col.getSqlType( dialect, p ) );
 				}
 				buf.append( ' ' )
 						.append( dialect.getIdentityColumnString( col.getSqlTypeCode( p ) ) );
 			}
 			else {
 
 				buf.append( col.getSqlType( dialect, p ) );
 
 				String defaultValue = col.getDefaultValue();
 				if ( defaultValue != null ) {
 					buf.append( " default " ).append( defaultValue );
 				}
 
 				if ( col.isNullable() ) {
 					buf.append( dialect.getNullColumnString() );
 				}
 				else {
 					buf.append( " not null" );
 				}
 
 			}
 			
 			if ( col.isUnique() ) {
 				String keyName = Constraint.generateName( "UK_", this, col );
 				UniqueKey uk = getOrCreateUniqueKey( keyName );
 				uk.addColumn( col );
 				buf.append( dialect.getUniqueDelegate()
 						.getColumnDefinitionUniquenessFragment( col ) );
 			}
 				
 			if ( col.hasCheckConstraint() && dialect.supportsColumnCheck() ) {
 				buf.append( " check (" )
 						.append( col.getCheckConstraint() )
 						.append( ")" );
 			}
 
 			String columnComment = col.getComment();
 			if ( columnComment != null ) {
 				buf.append( dialect.getColumnComment( columnComment ) );
 			}
 
 			if ( iter.hasNext() ) {
 				buf.append( ", " );
 			}
 
 		}
 		if ( hasPrimaryKey() ) {
 			buf.append( ", " )
 					.append( getPrimaryKey().sqlConstraintString( dialect ) );
 		}
 
 		buf.append( dialect.getUniqueDelegate().getTableCreationUniqueConstraintsFragment( this ) );
 
 		if ( dialect.supportsTableCheck() ) {
 			Iterator chiter = checkConstraints.iterator();
 			while ( chiter.hasNext() ) {
 				buf.append( ", check (" )
 						.append( chiter.next() )
 						.append( ')' );
 			}
 		}
 
 		buf.append( ')' );
 
 		if ( comment != null ) {
 			buf.append( dialect.getTableComment( comment ) );
 		}
 
 		return buf.append( dialect.getTableTypeString() ).toString();
 	}
 
 	public String sqlDropString(Dialect dialect, String defaultCatalog, String defaultSchema) {
 		return dialect.getDropTableString( getQualifiedName( dialect, defaultCatalog, defaultSchema ) );
 	}
 
 	public PrimaryKey getPrimaryKey() {
 		return primaryKey;
 	}
 
 	public void setPrimaryKey(PrimaryKey primaryKey) {
 		this.primaryKey = primaryKey;
 	}
 
 	public Index getOrCreateIndex(String indexName) {
 
 		Index index =  indexes.get( indexName );
 
 		if ( index == null ) {
 			index = new Index();
 			index.setName( indexName );
 			index.setTable( this );
 			indexes.put( indexName, index );
 		}
 
 		return index;
 	}
 
 	public Index getIndex(String indexName) {
 		return  indexes.get( indexName );
 	}
 
 	public Index addIndex(Index index) {
 		Index current =  indexes.get( index.getName() );
 		if ( current != null ) {
 			throw new MappingException( "Index " + index.getName() + " already exists!" );
 		}
 		indexes.put( index.getName(), index );
 		return index;
 	}
 
 	public UniqueKey addUniqueKey(UniqueKey uniqueKey) {
 		UniqueKey current = uniqueKeys.get( uniqueKey.getName() );
 		if ( current != null ) {
 			throw new MappingException( "UniqueKey " + uniqueKey.getName() + " already exists!" );
 		}
 		uniqueKeys.put( uniqueKey.getName(), uniqueKey );
 		return uniqueKey;
 	}
 
 	public UniqueKey createUniqueKey(List keyColumns) {
 		String keyName = Constraint.generateName( "UK_", this, keyColumns );
 		UniqueKey uk = getOrCreateUniqueKey( keyName );
 		uk.addColumns( keyColumns.iterator() );
 		return uk;
 	}
 
 	public UniqueKey getUniqueKey(String keyName) {
 		return uniqueKeys.get( keyName );
 	}
 
 	public UniqueKey getOrCreateUniqueKey(String keyName) {
 		UniqueKey uk = uniqueKeys.get( keyName );
 
 		if ( uk == null ) {
 			uk = new UniqueKey();
 			uk.setName( keyName );
 			uk.setTable( this );
 			uniqueKeys.put( keyName, uk );
 		}
 		return uk;
 	}
 
 	public void createForeignKeys() {
 	}
 
 	public ForeignKey createForeignKey(String keyName, List keyColumns, String referencedEntityName) {
 		return createForeignKey( keyName, keyColumns, referencedEntityName, null );
 	}
 
 	public ForeignKey createForeignKey(String keyName, List keyColumns, String referencedEntityName,
 									   List referencedColumns) {
 		Object key = new ForeignKeyKey( keyColumns, referencedEntityName, referencedColumns );
 
 		ForeignKey fk = (ForeignKey) foreignKeys.get( key );
 		if ( fk == null ) {
 			fk = new ForeignKey();
 			fk.setTable( this );
 			fk.setReferencedEntityName( referencedEntityName );
 			fk.addColumns( keyColumns.iterator() );
 			if ( referencedColumns != null ) {
 				fk.addReferencedColumns( referencedColumns.iterator() );
 			}
 			
 			if ( keyName != null ) {
 				fk.setName( keyName );
 			}
 			else {
 				fk.setName( Constraint.generateName( fk.generatedConstraintNamePrefix(),
 						this, keyColumns ) );
 			}
 			
 			foreignKeys.put( key, fk );
 		}
 
 		if ( keyName != null ) {
 			fk.setName( keyName );
 		}
 
 		return fk;
 	}
 
 
 
 	public String getSchema() {
 		return schema;
 	}
 
 	public void setSchema(String schema) {
 		if ( schema != null && schema.charAt( 0 ) == '`' ) {
 			schemaQuoted = true;
 			this.schema = schema.substring( 1, schema.length() - 1 );
 		}
 		else {
 			this.schema = schema;
 		}
 	}
 
 	public String getCatalog() {
 		return catalog;
 	}
 
 	public void setCatalog(String catalog) {
 		if ( catalog != null && catalog.charAt( 0 ) == '`' ) {
 			catalogQuoted = true;
 			this.catalog = catalog.substring( 1, catalog.length() - 1 );
 		}
 		else {
 			this.catalog = catalog;
 		}
 	}
 
 	// This must be done outside of Table, rather than statically, to ensure
 	// deterministic alias names.  See HHH-2448.
 	public void setUniqueInteger( int uniqueInteger ) {
 		this.uniqueInteger = uniqueInteger;
 	}
 
 	public int getUniqueInteger() {
 		return uniqueInteger;
 	}
 
 	public void setIdentifierValue(KeyValue idValue) {
 		this.idValue = idValue;
 	}
 
 	public KeyValue getIdentifierValue() {
 		return idValue;
 	}
 
 	public boolean isSchemaQuoted() {
 		return schemaQuoted;
 	}
 	public boolean isCatalogQuoted() {
 		return catalogQuoted;
 	}
 
 	public boolean isQuoted() {
 		return quoted;
 	}
 
 	public void setQuoted(boolean quoted) {
 		this.quoted = quoted;
 	}
 
 	public void addCheckConstraint(String constraint) {
 		checkConstraints.add( constraint );
 	}
 
 	public boolean containsColumn(Column column) {
 		return columns.containsValue( column );
 	}
 
 	public String getRowId() {
 		return rowId;
 	}
 
 	public void setRowId(String rowId) {
 		this.rowId = rowId;
 	}
 
 	public String toString() {
 		StringBuilder buf = new StringBuilder().append( getClass().getName() )
 				.append( '(' );
 		if ( getCatalog() != null ) {
 			buf.append( getCatalog() + "." );
 		}
 		if ( getSchema() != null ) {
 			buf.append( getSchema() + "." );
 		}
 		buf.append( getName() ).append( ')' );
 		return buf.toString();
 	}
 
 	public String getSubselect() {
 		return subselect;
 	}
 
 	public void setSubselect(String subselect) {
 		this.subselect = subselect;
 	}
 
 	public boolean isSubselect() {
 		return subselect != null;
 	}
 
 	public boolean isAbstractUnionTable() {
 		return hasDenormalizedTables() && isAbstract;
 	}
 
 	public boolean hasDenormalizedTables() {
 		return hasDenormalizedTables;
 	}
 
 	void setHasDenormalizedTables() {
 		hasDenormalizedTables = true;
 	}
 
 	public void setAbstract(boolean isAbstract) {
 		this.isAbstract = isAbstract;
 	}
 
 	public boolean isAbstract() {
 		return isAbstract;
 	}
 
 	public boolean isPhysicalTable() {
 		return !isSubselect() && !isAbstractUnionTable();
 	}
 
 	public String getComment() {
 		return comment;
 	}
 
 	public void setComment(String comment) {
 		this.comment = comment;
 	}
 
 	public Iterator getCheckConstraintsIterator() {
 		return checkConstraints.iterator();
 	}
 
 	public Iterator sqlCommentStrings(Dialect dialect, String defaultCatalog, String defaultSchema) {
 		List comments = new ArrayList();
 		if ( dialect.supportsCommentOn() ) {
 			String tableName = getQualifiedName( dialect, defaultCatalog, defaultSchema );
 			if ( comment != null ) {
 				StringBuilder buf = new StringBuilder()
 						.append( "comment on table " )
 						.append( tableName )
 						.append( " is '" )
 						.append( comment )
 						.append( "'" );
 				comments.add( buf.toString() );
 			}
 			Iterator iter = getColumnIterator();
 			while ( iter.hasNext() ) {
 				Column column = (Column) iter.next();
 				String columnComment = column.getComment();
 				if ( columnComment != null ) {
 					StringBuilder buf = new StringBuilder()
 							.append( "comment on column " )
 							.append( tableName )
 							.append( '.' )
 							.append( column.getQuotedName( dialect ) )
 							.append( " is '" )
 							.append( columnComment )
 							.append( "'" );
 					comments.add( buf.toString() );
 				}
 			}
 		}
 		return comments.iterator();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/mapping/UniqueKey.java b/hibernate-core/src/main/java/org/hibernate/mapping/UniqueKey.java
index 5e36fc202a..2cfb385bc5 100644
--- a/hibernate-core/src/main/java/org/hibernate/mapping/UniqueKey.java
+++ b/hibernate-core/src/main/java/org/hibernate/mapping/UniqueKey.java
@@ -1,81 +1,82 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.mapping;
-import java.util.*;
+
+import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.Mapping;
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * A relational unique key constraint
  *
  * @author Brett Meyer
  */
 public class UniqueKey extends Constraint {
 	private java.util.Map<Column, String> columnOrderMap = new HashMap<Column, String>(  );
 
 	@Override
     public String sqlConstraintString(
 			Dialect dialect,
 			String constraintName,
 			String defaultCatalog,
 			String defaultSchema) {
 //		return dialect.getUniqueDelegate().uniqueConstraintSql( this );
 		// Not used.
 		return "";
 	}
 
 	@Override
     public String sqlCreateString(Dialect dialect, Mapping p,
     		String defaultCatalog, String defaultSchema) {
 		return dialect.getUniqueDelegate().getAlterTableToAddUniqueKeyCommand(
 				this, defaultCatalog, defaultSchema
 		);
 	}
 
 	@Override
     public String sqlDropString(Dialect dialect, String defaultCatalog,
     		String defaultSchema) {
 		return dialect.getUniqueDelegate().getAlterTableToDropUniqueKeyCommand(
 				this, defaultCatalog, defaultSchema
 		);
 	}
 
 	public void addColumn(Column column, String order) {
 		addColumn( column );
 		if ( StringHelper.isNotEmpty( order ) ) {
 			columnOrderMap.put( column, order );
 		}
 	}
 
 	public Map<Column, String> getColumnOrderMap() {
 		return columnOrderMap;
 	}
 	
 	public String generatedConstraintNamePrefix() {
 		return "UK_";
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
index b064f4d773..a3333c52b5 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/AbstractCollectionPersister.java
@@ -787,1358 +787,1358 @@ public abstract class AbstractCollectionPersister
 
 	public boolean hasWhere() {
 		return hasWhere;
 	}
 
 	protected String getSQLDeleteString() {
 		return sqlDeleteString;
 	}
 
 	protected String getSQLInsertRowString() {
 		return sqlInsertRowString;
 	}
 
 	protected String getSQLUpdateRowString() {
 		return sqlUpdateRowString;
 	}
 
 	protected String getSQLDeleteRowString() {
 		return sqlDeleteRowString;
 	}
 
 	public Type getKeyType() {
 		return keyType;
 	}
 
 	public Type getIndexType() {
 		return indexType;
 	}
 
 	public Type getElementType() {
 		return elementType;
 	}
 
 	/**
 	 * Return the element class of an array, or null otherwise
 	 */
 	public Class getElementClass() { // needed by arrays
 		return elementClass;
 	}
 
 	public Object readElement(ResultSet rs, Object owner, String[] aliases, SessionImplementor session)
 			throws HibernateException, SQLException {
 		return getElementType().nullSafeGet( rs, aliases, session, owner );
 	}
 
 	public Object readIndex(ResultSet rs, String[] aliases, SessionImplementor session)
 			throws HibernateException, SQLException {
 		Object index = getIndexType().nullSafeGet( rs, aliases, session, null );
 		if ( index == null ) {
 			throw new HibernateException( "null index column for collection: " + role );
 		}
 		index = decrementIndexByBase( index );
 		return index;
 	}
 
 	protected Object decrementIndexByBase(Object index) {
 		if ( baseIndex != 0 ) {
             index = (Integer)index - baseIndex;
 		}
 		return index;
 	}
 
 	public Object readIdentifier(ResultSet rs, String alias, SessionImplementor session)
 			throws HibernateException, SQLException {
 		Object id = getIdentifierType().nullSafeGet( rs, alias, session, null );
 		if ( id == null ) {
 			throw new HibernateException( "null identifier column for collection: " + role );
 		}
 		return id;
 	}
 
 	public Object readKey(ResultSet rs, String[] aliases, SessionImplementor session)
 			throws HibernateException, SQLException {
 		return getKeyType().nullSafeGet( rs, aliases, session, null );
 	}
 
 	/**
 	 * Write the key to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeKey(PreparedStatement st, Serializable key, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 
 		if ( key == null ) {
 			throw new NullPointerException( "null key for collection: " + role ); // an assertion
 		}
 		getKeyType().nullSafeSet( st, key, i, session );
 		return i + keyColumnAliases.length;
 	}
 
 	/**
 	 * Write the element to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeElement(PreparedStatement st, Object elt, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		getElementType().nullSafeSet( st, elt, i, elementColumnIsSettable, session );
 		return i + ArrayHelper.countTrue( elementColumnIsSettable );
 
 	}
 
 	/**
 	 * Write the index to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeIndex(PreparedStatement st, Object index, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		getIndexType().nullSafeSet( st, incrementIndexByBase( index ), i, indexColumnIsSettable, session );
 		return i + ArrayHelper.countTrue( indexColumnIsSettable );
 	}
 
 	protected Object incrementIndexByBase(Object index) {
 		if ( baseIndex != 0 ) {
             index = (Integer)index + baseIndex;
 		}
 		return index;
 	}
 
 	/**
 	 * Write the element to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeElementToWhere(PreparedStatement st, Object elt, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		if ( elementIsPureFormula ) {
 			throw new AssertionFailure( "cannot use a formula-based element in the where condition" );
 		}
 		getElementType().nullSafeSet( st, elt, i, elementColumnIsInPrimaryKey, session );
 		return i + elementColumnAliases.length;
 
 	}
 
 	/**
 	 * Write the index to a JDBC <tt>PreparedStatement</tt>
 	 */
 	protected int writeIndexToWhere(PreparedStatement st, Object index, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 		if ( indexContainsFormula ) {
 			throw new AssertionFailure( "cannot use a formula-based index in the where condition" );
 		}
 		getIndexType().nullSafeSet( st, incrementIndexByBase( index ), i, session );
 		return i + indexColumnAliases.length;
 	}
 
 	/**
 	 * Write the identifier to a JDBC <tt>PreparedStatement</tt>
 	 */
 	public int writeIdentifier(PreparedStatement st, Object id, int i, SessionImplementor session)
 			throws HibernateException, SQLException {
 
 		getIdentifierType().nullSafeSet( st, id, i, session );
 		return i + 1;
 	}
 
 	public boolean isPrimitiveArray() {
 		return isPrimitiveArray;
 	}
 
 	public boolean isArray() {
 		return isArray;
 	}
 
 	public String[] getKeyColumnAliases(String suffix) {
 		return new Alias( suffix ).toAliasStrings( keyColumnAliases );
 	}
 
 	public String[] getElementColumnAliases(String suffix) {
 		return new Alias( suffix ).toAliasStrings( elementColumnAliases );
 	}
 
 	public String[] getIndexColumnAliases(String suffix) {
 		if ( hasIndex ) {
 			return new Alias( suffix ).toAliasStrings( indexColumnAliases );
 		}
 		else {
 			return null;
 		}
 	}
 
 	public String getIdentifierColumnAlias(String suffix) {
 		if ( hasIdentifier ) {
 			return new Alias( suffix ).toAliasString( identifierColumnAlias );
 		}
 		else {
 			return null;
 		}
 	}
 
 	public String getIdentifierColumnName() {
 		if ( hasIdentifier ) {
 			return identifierColumnName;
 		}
 		else {
 			return null;
 		}
 	}
 
 	/**
 	 * Generate a list of collection index, key and element columns
 	 */
 	public String selectFragment(String alias, String columnSuffix) {
 		SelectFragment frag = generateSelectFragment( alias, columnSuffix );
 		appendElementColumns( frag, alias );
 		appendIndexColumns( frag, alias );
 		appendIdentifierColumns( frag, alias );
 
 		return frag.toFragmentString()
 				.substring( 2 ); // strip leading ','
 	}
 
 	protected String generateSelectSizeString(boolean isIntegerIndexed) {
 		String selectValue = isIntegerIndexed ?
 				"max(" + getIndexColumnNames()[0] + ") + 1" : // lists, arrays
 				"count(" + getElementColumnNames()[0] + ")"; // sets, maps, bags
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addColumn( selectValue )
 				.toStatementString();
 	}
 
 	protected String generateDetectRowByIndexString() {
 		if ( !hasIndex() ) {
 			return null;
 		}
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getIndexColumnNames(), "=?" )
 				.addCondition( indexFormulas, "=?" )
 				.addColumn( "1" )
 				.toStatementString();
 	}
 
 	protected String generateSelectRowByIndexString() {
 		if ( !hasIndex() ) {
 			return null;
 		}
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getIndexColumnNames(), "=?" )
 				.addCondition( indexFormulas, "=?" )
 				.addColumns( getElementColumnNames(), elementColumnAliases )
 				.addColumns( indexFormulas, indexColumnAliases )
 				.toStatementString();
 	}
 
 	protected String generateDetectRowByElementString() {
 		return new SimpleSelect( dialect )
 				.setTableName( getTableName() )
 				.addCondition( getKeyColumnNames(), "=?" )
 				.addCondition( getElementColumnNames(), "=?" )
 				.addCondition( elementFormulas, "=?" )
 				.addColumn( "1" )
 				.toStatementString();
 	}
 
 	protected SelectFragment generateSelectFragment(String alias, String columnSuffix) {
 		return new SelectFragment()
 				.setSuffix( columnSuffix )
 				.addColumns( alias, keyColumnNames, keyColumnAliases );
 	}
 
 	protected void appendElementColumns(SelectFragment frag, String elemAlias) {
 		for ( int i = 0; i < elementColumnIsSettable.length; i++ ) {
 			if ( elementColumnIsSettable[i] ) {
 				frag.addColumnTemplate( elemAlias, elementColumnReaderTemplates[i], elementColumnAliases[i] );
 			}
 			else {
 				frag.addFormula( elemAlias, elementFormulaTemplates[i], elementColumnAliases[i] );
 			}
 		}
 	}
 
 	protected void appendIndexColumns(SelectFragment frag, String alias) {
 		if ( hasIndex ) {
 			for ( int i = 0; i < indexColumnIsSettable.length; i++ ) {
 				if ( indexColumnIsSettable[i] ) {
 					frag.addColumn( alias, indexColumnNames[i], indexColumnAliases[i] );
 				}
 				else {
 					frag.addFormula( alias, indexFormulaTemplates[i], indexColumnAliases[i] );
 				}
 			}
 		}
 	}
 
 	protected void appendIdentifierColumns(SelectFragment frag, String alias) {
 		if ( hasIdentifier ) {
 			frag.addColumn( alias, identifierColumnName, identifierColumnAlias );
 		}
 	}
 
 	public String[] getIndexColumnNames() {
 		return indexColumnNames;
 	}
 
 	public String[] getIndexFormulas() {
 		return indexFormulas;
 	}
 
 	public String[] getIndexColumnNames(String alias) {
 		return qualify( alias, indexColumnNames, indexFormulaTemplates );
 
 	}
 
 	public String[] getElementColumnNames(String alias) {
 		return qualify( alias, elementColumnNames, elementFormulaTemplates );
 	}
 
 	private static String[] qualify(String alias, String[] columnNames, String[] formulaTemplates) {
 		int span = columnNames.length;
 		String[] result = new String[span];
 		for ( int i = 0; i < span; i++ ) {
 			if ( columnNames[i] == null ) {
 				result[i] = StringHelper.replace( formulaTemplates[i], Template.TEMPLATE, alias );
 			}
 			else {
 				result[i] = StringHelper.qualify( alias, columnNames[i] );
 			}
 		}
 		return result;
 	}
 
 	public String[] getElementColumnNames() {
 		return elementColumnNames; // TODO: something with formulas...
 	}
 
 	public String[] getKeyColumnNames() {
 		return keyColumnNames;
 	}
 
 	public boolean hasIndex() {
 		return hasIndex;
 	}
 
 	public boolean isLazy() {
 		return isLazy;
 	}
 
 	public boolean isInverse() {
 		return isInverse;
 	}
 
 	public String getTableName() {
 		return qualifiedTableName;
 	}
 
 	private BasicBatchKey removeBatchKey;
 
 	public void remove(Serializable id, SessionImplementor session) throws HibernateException {
 		if ( !isInverse && isRowDeleteEnabled() ) {
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Deleting collection: %s",
 						MessageHelper.collectionInfoString( this, id, getFactory() ) );
 			}
 
 			// Remove all the old entries
 
 			try {
 				int offset = 1;
 				PreparedStatement st = null;
 				Expectation expectation = Expectations.appropriateExpectation( getDeleteAllCheckStyle() );
 				boolean callable = isDeleteAllCallable();
 				boolean useBatch = expectation.canBeBatched();
 				String sql = getSQLDeleteString();
 				if ( useBatch ) {
 					if ( removeBatchKey == null ) {
 						removeBatchKey = new BasicBatchKey(
 								getRole() + "#REMOVE",
 								expectation
 								);
 					}
 					st = session.getTransactionCoordinator()
 							.getJdbcCoordinator()
 							.getBatch( removeBatchKey )
 							.getBatchStatement( sql, callable );
 				}
 				else {
 					st = session.getTransactionCoordinator()
 							.getJdbcCoordinator()
 							.getStatementPreparer()
 							.prepareStatement( sql, callable );
 				}
 
 				try {
 					offset += expectation.prepare( st );
 
 					writeKey( st, id, offset, session );
 					if ( useBatch ) {
 						session.getTransactionCoordinator()
 								.getJdbcCoordinator()
 								.getBatch( removeBatchKey )
 								.addToBatch();
 					}
 					else {
 						expectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 					}
 				}
 				catch ( SQLException sqle ) {
 					if ( useBatch ) {
 						session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
 					}
 					throw sqle;
 				}
 				finally {
 					if ( !useBatch ) {
 						session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 					}
 				}
 
 				LOG.debug( "Done deleting collection" );
 			}
 			catch ( SQLException sqle ) {
 				throw sqlExceptionHelper.convert(
 						sqle,
 						"could not delete collection: " +
 								MessageHelper.collectionInfoString( this, id, getFactory() ),
 						getSQLDeleteString()
 						);
 			}
 
 		}
 
 	}
 
 	protected BasicBatchKey recreateBatchKey;
 
 	public void recreate(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( !isInverse && isRowInsertEnabled() ) {
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Inserting collection: %s",
 						MessageHelper.collectionInfoString( this, collection, id, session ) );
 			}
 
 			try {
 				// create all the new entries
 				Iterator entries = collection.entries( this );
 				if ( entries.hasNext() ) {
 					Expectation expectation = Expectations.appropriateExpectation( getInsertCheckStyle() );
 					collection.preInsert( this );
 					int i = 0;
 					int count = 0;
 					while ( entries.hasNext() ) {
 
 						final Object entry = entries.next();
 						if ( collection.entryExists( entry, i ) ) {
 							int offset = 1;
 							PreparedStatement st = null;
 							boolean callable = isInsertCallable();
 							boolean useBatch = expectation.canBeBatched();
 							String sql = getSQLInsertRowString();
 
 							if ( useBatch ) {
 								if ( recreateBatchKey == null ) {
 									recreateBatchKey = new BasicBatchKey(
 											getRole() + "#RECREATE",
 											expectation
 											);
 								}
 								st = session.getTransactionCoordinator()
 										.getJdbcCoordinator()
 										.getBatch( recreateBatchKey )
 										.getBatchStatement( sql, callable );
 							}
 							else {
 								st = session.getTransactionCoordinator()
 										.getJdbcCoordinator()
 										.getStatementPreparer()
 										.prepareStatement( sql, callable );
 							}
 
 							try {
 								offset += expectation.prepare( st );
 
 								// TODO: copy/paste from insertRows()
 								int loc = writeKey( st, id, offset, session );
 								if ( hasIdentifier ) {
 									loc = writeIdentifier( st, collection.getIdentifier( entry, i ), loc, session );
 								}
 								if ( hasIndex /* && !indexIsFormula */) {
 									loc = writeIndex( st, collection.getIndex( entry, i, this ), loc, session );
 								}
 								loc = writeElement( st, collection.getElement( entry ), loc, session );
 
 								if ( useBatch ) {
 									session.getTransactionCoordinator()
 											.getJdbcCoordinator()
 											.getBatch( recreateBatchKey )
 											.addToBatch();
 								}
 								else {
 									expectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 								}
 
 								collection.afterRowInsert( this, entry, i );
 								count++;
 							}
 							catch ( SQLException sqle ) {
 								if ( useBatch ) {
 									session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
 								}
 								throw sqle;
 							}
 							finally {
 								if ( !useBatch ) {
 									session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 								}
 							}
 
 						}
 						i++;
 					}
 
 					LOG.debugf( "Done inserting collection: %s rows inserted", count );
 
 				}
 				else {
 					LOG.debug( "Collection was empty" );
 				}
 			}
 			catch ( SQLException sqle ) {
 				throw sqlExceptionHelper.convert(
 						sqle,
 						"could not insert collection: " +
 								MessageHelper.collectionInfoString( this, collection, id, session ),
 						getSQLInsertRowString()
 						);
 			}
 		}
 	}
 
 	protected boolean isRowDeleteEnabled() {
 		return true;
 	}
 
 	private BasicBatchKey deleteBatchKey;
 
 	public void deleteRows(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( !isInverse && isRowDeleteEnabled() ) {
 
 			if ( LOG.isDebugEnabled() ) {
 				LOG.debugf( "Deleting rows of collection: %s",
 						MessageHelper.collectionInfoString( this, collection, id, session ) );
 			}
 
 			boolean deleteByIndex = !isOneToMany() && hasIndex && !indexContainsFormula;
 			final Expectation expectation = Expectations.appropriateExpectation( getDeleteCheckStyle() );
 			try {
 				// delete all the deleted entries
 				Iterator deletes = collection.getDeletes( this, !deleteByIndex );
 				if ( deletes.hasNext() ) {
 					int offset = 1;
 					int count = 0;
 					while ( deletes.hasNext() ) {
 						PreparedStatement st = null;
 						boolean callable = isDeleteCallable();
 						boolean useBatch = expectation.canBeBatched();
 						String sql = getSQLDeleteRowString();
 
 						if ( useBatch ) {
 							if ( deleteBatchKey == null ) {
 								deleteBatchKey = new BasicBatchKey(
 										getRole() + "#DELETE",
 										expectation
 										);
 							}
 							st = session.getTransactionCoordinator()
 									.getJdbcCoordinator()
 									.getBatch( deleteBatchKey )
 									.getBatchStatement( sql, callable );
 						}
 						else {
 							st = session.getTransactionCoordinator()
 									.getJdbcCoordinator()
 									.getStatementPreparer()
 									.prepareStatement( sql, callable );
 						}
 
 						try {
 							expectation.prepare( st );
 
 							Object entry = deletes.next();
 							int loc = offset;
 							if ( hasIdentifier ) {
 								writeIdentifier( st, entry, loc, session );
 							}
 							else {
 								loc = writeKey( st, id, loc, session );
 								if ( deleteByIndex ) {
 									writeIndexToWhere( st, entry, loc, session );
 								}
 								else {
 									writeElementToWhere( st, entry, loc, session );
 								}
 							}
 
 							if ( useBatch ) {
 								session.getTransactionCoordinator()
 										.getJdbcCoordinator()
 										.getBatch( deleteBatchKey )
 										.addToBatch();
 							}
 							else {
 								expectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 							}
 							count++;
 						}
 						catch ( SQLException sqle ) {
 							if ( useBatch ) {
 								session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
 							}
 							throw sqle;
 						}
 						finally {
 							if ( !useBatch ) {
 								session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 							}
 						}
 
 						LOG.debugf( "Done deleting collection rows: %s deleted", count );
 					}
 				}
 				else {
 					LOG.debug( "No rows to delete" );
 				}
 			}
 			catch ( SQLException sqle ) {
 				throw sqlExceptionHelper.convert(
 						sqle,
 						"could not delete collection rows: " +
 								MessageHelper.collectionInfoString( this, collection, id, session ),
 						getSQLDeleteRowString()
 						);
 			}
 		}
 	}
 
 	protected boolean isRowInsertEnabled() {
 		return true;
 	}
 
 	private BasicBatchKey insertBatchKey;
 
 	public void insertRows(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( !isInverse && isRowInsertEnabled() ) {
 
 			if ( LOG.isDebugEnabled() ) LOG.debugf( "Inserting rows of collection: %s",
 					MessageHelper.collectionInfoString( this, collection, id, session ) );
 
 			try {
 				// insert all the new entries
 				collection.preInsert( this );
 				Iterator entries = collection.entries( this );
 				Expectation expectation = Expectations.appropriateExpectation( getInsertCheckStyle() );
 				boolean callable = isInsertCallable();
 				boolean useBatch = expectation.canBeBatched();
 				String sql = getSQLInsertRowString();
 				int i = 0;
 				int count = 0;
 				while ( entries.hasNext() ) {
 					int offset = 1;
 					Object entry = entries.next();
 					PreparedStatement st = null;
 					if ( collection.needsInserting( entry, i, elementType ) ) {
 
 						if ( useBatch ) {
 							if ( insertBatchKey == null ) {
 								insertBatchKey = new BasicBatchKey(
 										getRole() + "#INSERT",
 										expectation
 										);
 							}
 							if ( st == null ) {
 								st = session.getTransactionCoordinator()
 										.getJdbcCoordinator()
 										.getBatch( insertBatchKey )
 										.getBatchStatement( sql, callable );
 							}
 						}
 						else {
 							st = session.getTransactionCoordinator()
 									.getJdbcCoordinator()
 									.getStatementPreparer()
 									.prepareStatement( sql, callable );
 						}
 
 						try {
 							offset += expectation.prepare( st );
 							// TODO: copy/paste from recreate()
 							offset = writeKey( st, id, offset, session );
 							if ( hasIdentifier ) {
 								offset = writeIdentifier( st, collection.getIdentifier( entry, i ), offset, session );
 							}
 							if ( hasIndex /* && !indexIsFormula */) {
 								offset = writeIndex( st, collection.getIndex( entry, i, this ), offset, session );
 							}
 							writeElement( st, collection.getElement( entry ), offset, session );
 
 							if ( useBatch ) {
 								session.getTransactionCoordinator().getJdbcCoordinator().getBatch( insertBatchKey ).addToBatch();
 							}
 							else {
 								expectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st ), st, -1 );
 							}
 							collection.afterRowInsert( this, entry, i );
 							count++;
 						}
 						catch ( SQLException sqle ) {
 							if ( useBatch ) {
 								session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
 							}
 							throw sqle;
 						}
 						finally {
 							if ( !useBatch ) {
 								session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 							}
 						}
 					}
 					i++;
 				}
 				LOG.debugf( "Done inserting rows: %s inserted", count );
 			}
 			catch ( SQLException sqle ) {
 				throw sqlExceptionHelper.convert(
 						sqle,
 						"could not insert collection rows: " +
 								MessageHelper.collectionInfoString( this, collection, id, session ),
 						getSQLInsertRowString()
 						);
 			}
 
 		}
 	}
 
 	public String getRole() {
 		return role;
 	}
 
 	public String getOwnerEntityName() {
 		return entityName;
 	}
 
 	public EntityPersister getOwnerEntityPersister() {
 		return ownerPersister;
 	}
 
 	public IdentifierGenerator getIdentifierGenerator() {
 		return identifierGenerator;
 	}
 
 	public Type getIdentifierType() {
 		return identifierType;
 	}
 
 	public boolean hasOrphanDelete() {
 		return hasOrphanDelete;
 	}
 
 	public Type toType(String propertyName) throws QueryException {
 		if ( "index".equals( propertyName ) ) {
 			return indexType;
 		}
 		return elementPropertyMapping.toType( propertyName );
 	}
 
 	public abstract boolean isManyToMany();
 
 	public String getManyToManyFilterFragment(String alias, Map enabledFilters) {
 		StringBuilder buffer = new StringBuilder();
 		manyToManyFilterHelper.render( buffer, elementPersister.getFilterAliasGenerator(alias), enabledFilters );
 
 		if ( manyToManyWhereString != null ) {
 			buffer.append( " and " )
 					.append( StringHelper.replace( manyToManyWhereTemplate, Template.TEMPLATE, alias ) );
 		}
 
 		return buffer.toString();
 	}
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public String[] toColumns(String alias, String propertyName) throws QueryException {
 		if ( "index".equals( propertyName ) ) {
 			return qualify( alias, indexColumnNames, indexFormulaTemplates );
 		}
 		return elementPropertyMapping.toColumns( alias, propertyName );
 	}
 
 	private String[] indexFragments;
 
 	/**
 	 * {@inheritDoc}
 	 */
 	public String[] toColumns(String propertyName) throws QueryException {
 		if ( "index".equals( propertyName ) ) {
 			if ( indexFragments == null ) {
 				String[] tmp = new String[indexColumnNames.length];
 				for ( int i = 0; i < indexColumnNames.length; i++ ) {
 					tmp[i] = indexColumnNames[i] == null
 							? indexFormulas[i]
 							: indexColumnNames[i];
 					indexFragments = tmp;
 				}
 			}
 			return indexFragments;
 		}
 
 		return elementPropertyMapping.toColumns( propertyName );
 	}
 
 	public Type getType() {
 		return elementPropertyMapping.getType(); // ==elementType ??
 	}
 
 	public String getName() {
 		return getRole();
 	}
 
 	public EntityPersister getElementPersister() {
 		if ( elementPersister == null ) {
 			throw new AssertionFailure( "not an association" );
 		}
 		return elementPersister;
 	}
 
 	public boolean isCollection() {
 		return true;
 	}
 
 	public Serializable[] getCollectionSpaces() {
 		return spaces;
 	}
 
 	protected abstract String generateDeleteString();
 
 	protected abstract String generateDeleteRowString();
 
 	protected abstract String generateUpdateRowString();
 
 	protected abstract String generateInsertRowString();
 
 	public void updateRows(PersistentCollection collection, Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( !isInverse && collection.isRowUpdatePossible() ) {
 
 			LOG.debugf( "Updating rows of collection: %s#%s", role, id );
 
 			// update all the modified entries
 			int count = doUpdateRows( id, collection, session );
 
 			LOG.debugf( "Done updating rows: %s updated", count );
 		}
 	}
 
 	protected abstract int doUpdateRows(Serializable key, PersistentCollection collection, SessionImplementor session)
 			throws HibernateException;
 
 	public void processQueuedOps(PersistentCollection collection, Serializable key, SessionImplementor session)
 			throws HibernateException {
 		if ( collection.hasQueuedOperations() ) {
 			doProcessQueuedOps( collection, key, session );
 		}
 	}
 
 	protected abstract void doProcessQueuedOps(PersistentCollection collection, Serializable key, SessionImplementor session)
 			throws HibernateException;
 
 	public CollectionMetadata getCollectionMetadata() {
 		return this;
 	}
 
 	public SessionFactoryImplementor getFactory() {
 		return factory;
 	}
 
 	protected String filterFragment(String alias) throws MappingException {
 		return hasWhere() ? " and " + getSQLWhereString( alias ) : "";
 	}
 
 	protected String filterFragment(String alias, Set<String> treatAsDeclarations) throws MappingException {
 		return hasWhere() ? " and " + getSQLWhereString( alias ) : "";
 	}
 
 	public String filterFragment(String alias, Map enabledFilters) throws MappingException {
 		StringBuilder sessionFilterFragment = new StringBuilder();
 		filterHelper.render( sessionFilterFragment, getFilterAliasGenerator(alias), enabledFilters );
 
 		return sessionFilterFragment.append( filterFragment( alias ) ).toString();
 	}
 
 	@Override
 	public String filterFragment(
 			String alias,
 			Map enabledFilters,
 			Set<String> treatAsDeclarations) {
 		StringBuilder sessionFilterFragment = new StringBuilder();
 		filterHelper.render( sessionFilterFragment, getFilterAliasGenerator(alias), enabledFilters );
 
 		return sessionFilterFragment.append( filterFragment( alias, treatAsDeclarations ) ).toString();
 	}
 
 	@Override
 	public String oneToManyFilterFragment(String alias) throws MappingException {
 		return "";
 	}
 
 	@Override
 	public String oneToManyFilterFragment(String alias, Set<String> treatAsDeclarations) {
 		return oneToManyFilterFragment( alias );
 	}
 
 	protected boolean isInsertCallable() {
 		return insertCallable;
 	}
 
 	protected ExecuteUpdateResultCheckStyle getInsertCheckStyle() {
 		return insertCheckStyle;
 	}
 
 	protected boolean isUpdateCallable() {
 		return updateCallable;
 	}
 
 	protected ExecuteUpdateResultCheckStyle getUpdateCheckStyle() {
 		return updateCheckStyle;
 	}
 
 	protected boolean isDeleteCallable() {
 		return deleteCallable;
 	}
 
 	protected ExecuteUpdateResultCheckStyle getDeleteCheckStyle() {
 		return deleteCheckStyle;
 	}
 
 	protected boolean isDeleteAllCallable() {
 		return deleteAllCallable;
 	}
 
 	protected ExecuteUpdateResultCheckStyle getDeleteAllCheckStyle() {
 		return deleteAllCheckStyle;
 	}
 
 	public String toString() {
 		return StringHelper.unqualify( getClass().getName() ) + '(' + role + ')';
 	}
 
 	public boolean isVersioned() {
 		return isVersioned && getOwnerEntityPersister().isVersioned();
 	}
 
 	public String getNodeName() {
 		return nodeName;
 	}
 
 	public String getElementNodeName() {
 		return elementNodeName;
 	}
 
 	public String getIndexNodeName() {
 		return indexNodeName;
 	}
 
 	// TODO: deprecate???
 	protected SQLExceptionConverter getSQLExceptionConverter() {
 		return getSQLExceptionHelper().getSqlExceptionConverter();
 	}
 
 	// TODO: needed???
 	protected SqlExceptionHelper getSQLExceptionHelper() {
 		return sqlExceptionHelper;
 	}
 
 	public CacheEntryStructure getCacheEntryStructure() {
 		return cacheEntryStructure;
 	}
 
 	public boolean isAffectedByEnabledFilters(SessionImplementor session) {
 		return filterHelper.isAffectedBy( session.getEnabledFilters() ) ||
 				( isManyToMany() && manyToManyFilterHelper.isAffectedBy( session.getEnabledFilters() ) );
 	}
 
 	public boolean isSubselectLoadable() {
 		return subselectLoadable;
 	}
 
 	public boolean isMutable() {
 		return isMutable;
 	}
 
 	public String[] getCollectionPropertyColumnAliases(String propertyName, String suffix) {
-		String rawAliases[] = (String[]) collectionPropertyColumnAliases.get( propertyName );
+		String[] rawAliases = (String[]) collectionPropertyColumnAliases.get( propertyName );
 
 		if ( rawAliases == null ) {
 			return null;
 		}
 
-		String result[] = new String[rawAliases.length];
+		String[] result = new String[rawAliases.length];
 		for ( int i = 0; i < rawAliases.length; i++ ) {
 			result[i] = new Alias( suffix ).toUnquotedAliasString( rawAliases[i] );
 		}
 		return result;
 	}
 
 	// TODO: formulas ?
 	public void initCollectionPropertyMap() {
 
 		initCollectionPropertyMap( "key", keyType, keyColumnAliases, keyColumnNames );
 		initCollectionPropertyMap( "element", elementType, elementColumnAliases, elementColumnNames );
 		if ( hasIndex ) {
 			initCollectionPropertyMap( "index", indexType, indexColumnAliases, indexColumnNames );
 		}
 		if ( hasIdentifier ) {
 			initCollectionPropertyMap(
 					"id",
 					identifierType,
 					new String[] { identifierColumnAlias },
 					new String[] { identifierColumnName } );
 		}
 	}
 
 	private void initCollectionPropertyMap(String aliasName, Type type, String[] columnAliases, String[] columnNames) {
 
 		collectionPropertyColumnAliases.put( aliasName, columnAliases );
 		collectionPropertyColumnNames.put( aliasName, columnNames );
 
 		if ( type.isComponentType() ) {
 			CompositeType ct = (CompositeType) type;
 			String[] propertyNames = ct.getPropertyNames();
 			for ( int i = 0; i < propertyNames.length; i++ ) {
 				String name = propertyNames[i];
 				collectionPropertyColumnAliases.put( aliasName + "." + name, columnAliases[i] );
 				collectionPropertyColumnNames.put( aliasName + "." + name, columnNames[i] );
 			}
 		}
 
 	}
 
 	public int getSize(Serializable key, SessionImplementor session) {
 		try {
 			PreparedStatement st = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( sqlSelectSizeString );
 			try {
 				getKeyType().nullSafeSet( st, key, 1, session );
 				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
 					return rs.next() ? rs.getInt( 1 ) - baseIndex : 0;
 				}
 				finally {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
 				}
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw getSQLExceptionHelper().convert(
 					sqle,
 					"could not retrieve collection size: " +
 							MessageHelper.collectionInfoString( this, key, getFactory() ),
 					sqlSelectSizeString
 			);
 		}
 	}
 
 	public boolean indexExists(Serializable key, Object index, SessionImplementor session) {
 		return exists( key, incrementIndexByBase( index ), getIndexType(), sqlDetectRowByIndexString, session );
 	}
 
 	public boolean elementExists(Serializable key, Object element, SessionImplementor session) {
 		return exists( key, element, getElementType(), sqlDetectRowByElementString, session );
 	}
 
 	private boolean exists(Serializable key, Object indexOrElement, Type indexOrElementType, String sql, SessionImplementor session) {
 		try {
 			PreparedStatement st = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( sql );
 			try {
 				getKeyType().nullSafeSet( st, key, 1, session );
 				indexOrElementType.nullSafeSet( st, indexOrElement, keyColumnNames.length + 1, session );
 				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
 					return rs.next();
 				}
 				finally {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
 				}
 			}
 			catch ( TransientObjectException e ) {
 				return false;
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw getSQLExceptionHelper().convert(
 					sqle,
 					"could not check row existence: " +
 							MessageHelper.collectionInfoString( this, key, getFactory() ),
 					sqlSelectSizeString
 			);
 		}
 	}
 
 	public Object getElementByIndex(Serializable key, Object index, SessionImplementor session, Object owner) {
 		try {
 			PreparedStatement st = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( sqlSelectRowByIndexString );
 			try {
 				getKeyType().nullSafeSet( st, key, 1, session );
 				getIndexType().nullSafeSet( st, incrementIndexByBase( index ), keyColumnNames.length + 1, session );
 				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
 					if ( rs.next() ) {
 						return getElementType().nullSafeGet( rs, elementColumnAliases, session, owner );
 					}
 					else {
 						return null;
 					}
 				}
 				finally {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
 				}
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw getSQLExceptionHelper().convert(
 					sqle,
 					"could not read row: " +
 							MessageHelper.collectionInfoString( this, key, getFactory() ),
 					sqlSelectSizeString
 			);
 		}
 	}
 
 	public boolean isExtraLazy() {
 		return isExtraLazy;
 	}
 
 	protected Dialect getDialect() {
 		return dialect;
 	}
 
 	/**
 	 * Intended for internal use only. In fact really only currently used from
 	 * test suite for assertion purposes.
 	 *
 	 * @return The default collection initializer for this persister/collection.
 	 */
 	public CollectionInitializer getInitializer() {
 		return initializer;
 	}
 
 	public int getBatchSize() {
 		return batchSize;
 	}
 
 	public String getMappedByProperty() {
 		return mappedByProperty;
 	}
 
 	private class StandardOrderByAliasResolver implements OrderByAliasResolver {
 		private final String rootAlias;
 
 		private StandardOrderByAliasResolver(String rootAlias) {
 			this.rootAlias = rootAlias;
 		}
 
 		@Override
 		public String resolveTableAlias(String columnReference) {
 			if ( elementPersister == null ) {
 				// we have collection of non-entity elements...
 				return rootAlias;
 			}
 			else {
 				return ( (Loadable) elementPersister ).getTableAliasForColumn( columnReference, rootAlias );
 			}
 		}
 	}
 
 	public abstract FilterAliasGenerator getFilterAliasGenerator(final String rootAlias);
 
 	// ColectionDefinition impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	@Override
 	public CollectionPersister getCollectionPersister() {
 		return this;
 	}
 
 	@Override
 	public CollectionIndexDefinition getIndexDefinition() {
 		if ( ! hasIndex() ) {
 			return null;
 		}
 
 		return new CollectionIndexDefinition() {
 			@Override
 			public CollectionDefinition getCollectionDefinition() {
 				return AbstractCollectionPersister.this;
 			}
 
 			@Override
 			public Type getType() {
 				return getIndexType();
 			}
 
 			@Override
 			public EntityDefinition toEntityDefinition() {
 				if ( !getType().isEntityType() ) {
 					throw new IllegalStateException( "Cannot treat collection index type as entity" );
 				}
 				return (EntityPersister) ( (AssociationType) getIndexType() ).getAssociatedJoinable( getFactory() );
 			}
 
 			@Override
 			public CompositionDefinition toCompositeDefinition() {
 				if ( ! getType().isComponentType() ) {
 					throw new IllegalStateException( "Cannot treat collection index type as composite" );
 				}
 				return new CompositeCollectionElementDefinition() {
 					@Override
 					public String getName() {
 						return "index";
 					}
 
 					@Override
 					public CompositeType getType() {
 						return (CompositeType) getIndexType();
 					}
 
 					@Override
 					public boolean isNullable() {
 						return false;
 					}
 
 					@Override
 					public AttributeSource getSource() {
 						// TODO: what if this is a collection w/in an encapsulated composition attribute?
 						// should return the encapsulated composition attribute instead???
 						return getOwnerEntityPersister();
 					}
 
 					@Override
 					public Iterable<AttributeDefinition> getAttributes() {
 						return CompositionSingularSubAttributesHelper.getCompositeCollectionIndexSubAttributes( this );
 					}
 					@Override
 					public CollectionDefinition getCollectionDefinition() {
 						return AbstractCollectionPersister.this;
 					}
 				};
 			}
 
 			@Override
 			public AnyMappingDefinition toAnyMappingDefinition() {
 				final Type type = getType();
 				if ( ! type.isAnyType() ) {
 					throw new IllegalStateException( "Cannot treat collection index type as ManyToAny" );
 				}
 				return new StandardAnyTypeDefinition( (AnyType) type, isLazy() || isExtraLazy() );
 			}
 		};
 	}
 
 	@Override
 	public CollectionElementDefinition getElementDefinition() {
 		return new CollectionElementDefinition() {
 			@Override
 			public CollectionDefinition getCollectionDefinition() {
 				return AbstractCollectionPersister.this;
 			}
 
 			@Override
 			public Type getType() {
 				return getElementType();
 			}
 
 			@Override
 			public AnyMappingDefinition toAnyMappingDefinition() {
 				final Type type = getType();
 				if ( ! type.isAnyType() ) {
 					throw new IllegalStateException( "Cannot treat collection element type as ManyToAny" );
 				}
 				return new StandardAnyTypeDefinition( (AnyType) type, isLazy() || isExtraLazy() );
 			}
 
 			@Override
 			public EntityDefinition toEntityDefinition() {
 				if ( !getType().isEntityType() ) {
 					throw new IllegalStateException( "Cannot treat collection element type as entity" );
 				}
 				return getElementPersister();
 			}
 
 			@Override
 			public CompositeCollectionElementDefinition toCompositeElementDefinition() {
 
 				if ( ! getType().isComponentType() ) {
 					throw new IllegalStateException( "Cannot treat entity collection element type as composite" );
 				}
 
 				return new CompositeCollectionElementDefinition() {
 					@Override
 					public String getName() {
 						return "";
 					}
 
 					@Override
 					public CompositeType getType() {
 						return (CompositeType) getElementType();
 					}
 
 					@Override
 					public boolean isNullable() {
 						return false;
 					}
 
 					@Override
 					public AttributeSource getSource() {
 						// TODO: what if this is a collection w/in an encapsulated composition attribute?
 						// should return the encapsulated composition attribute instead???
 						return getOwnerEntityPersister();
 					}
 
 					@Override
 					public Iterable<AttributeDefinition> getAttributes() {
 						return CompositionSingularSubAttributesHelper.getCompositeCollectionElementSubAttributes( this );
 					}
 
 					@Override
 					public CollectionDefinition getCollectionDefinition() {
 						return AbstractCollectionPersister.this;
 					}
 				};
 			}
 		};
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/collection/CollectionPropertyNames.java b/hibernate-core/src/main/java/org/hibernate/persister/collection/CollectionPropertyNames.java
index ee0aa6f2cb..dadb0827e9 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/collection/CollectionPropertyNames.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/collection/CollectionPropertyNames.java
@@ -1,43 +1,43 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
- * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
+ * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
- * distributed under license by Red Hat Middleware LLC.
+ * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
- *
  */
 package org.hibernate.persister.collection;
 
-
 /**
  * The names of all the collection properties.
  *
  * @author josh
  */
-public class CollectionPropertyNames {
+public final class CollectionPropertyNames {
+	private CollectionPropertyNames() {
+	}
 
 	public static final String COLLECTION_SIZE = "size";
 	public static final String COLLECTION_ELEMENTS = "elements";
 	public static final String COLLECTION_INDICES = "indices";
 	public static final String COLLECTION_MAX_INDEX = "maxIndex";
 	public static final String COLLECTION_MIN_INDEX = "minIndex";
 	public static final String COLLECTION_MAX_ELEMENT = "maxElement";
 	public static final String COLLECTION_MIN_ELEMENT = "minElement";
 	public static final String COLLECTION_INDEX = "index";
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
index 3390499146..d95b350de4 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/entity/AbstractEntityPersister.java
@@ -1198,2007 +1198,2007 @@ public abstract class AbstractEntityPersister
 			for ( int j = 0; j < colNumbers.length; j++ ) {
 				if ( colNumbers[j]!=-1 ) {
 					columnNumbers.add( colNumbers[j] );
 				}
 			}
 			int[] formNumbers = subclassPropertyFormulaNumberClosure[propertyNumber];
 			for ( int j = 0; j < formNumbers.length; j++ ) {
 				if ( formNumbers[j]!=-1 ) {
 					formulaNumbers.add( formNumbers[j] );
 				}
 			}
 		}
 
 		if ( columnNumbers.size()==0 && formulaNumbers.size()==0 ) {
 			// only one-to-one is lazy fetched
 			return null;
 		}
 
 		return renderSelect( ArrayHelper.toIntArray( tableNumbers ),
 				ArrayHelper.toIntArray( columnNumbers ),
 				ArrayHelper.toIntArray( formulaNumbers ) );
 
 	}
 
 	public Object initializeLazyProperty(String fieldName, Object entity, SessionImplementor session)
 			throws HibernateException {
 
 		final Serializable id = session.getContextEntityIdentifier( entity );
 
 		final EntityEntry entry = session.getPersistenceContext().getEntry( entity );
 		if ( entry == null ) {
 			throw new HibernateException( "entity is not associated with the session: " + id );
 		}
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Initializing lazy properties of: {0}, field access: {1}", MessageHelper.infoString( this, id, getFactory() ), fieldName );
 		}
 
 		if ( hasCache() ) {
 			final CacheKey cacheKey = session.generateCacheKey( id, getIdentifierType(), getEntityName() );
 			final Object ce = CacheHelper.fromSharedCache( session, cacheKey, getCacheAccessStrategy() );
 			if ( ce != null ) {
 				final CacheEntry cacheEntry = (CacheEntry) getCacheEntryStructure().destructure(ce, factory);
 				if ( !cacheEntry.areLazyPropertiesUnfetched() ) {
 					//note early exit here:
 					return initializeLazyPropertiesFromCache( fieldName, entity, session, entry, cacheEntry );
 				}
 			}
 		}
 
 		return initializeLazyPropertiesFromDatastore( fieldName, entity, session, id, entry );
 
 	}
 
 	private Object initializeLazyPropertiesFromDatastore(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final Serializable id,
 			final EntityEntry entry) {
 
 		if ( !hasLazyProperties() ) throw new AssertionFailure( "no lazy properties" );
 
 		LOG.trace( "Initializing lazy properties from datastore" );
 
 		try {
 
 			Object result = null;
 			PreparedStatement ps = null;
 			try {
 				final String lazySelect = getSQLLazySelectString();
 				ResultSet rs = null;
 				try {
 					if ( lazySelect != null ) {
 						// null sql means that the only lazy properties
 						// are shared PK one-to-one associations which are
 						// handled differently in the Type#nullSafeGet code...
 						ps = session.getTransactionCoordinator()
 								.getJdbcCoordinator()
 								.getStatementPreparer()
 								.prepareStatement( lazySelect );
 						getIdentifierType().nullSafeSet( ps, id, 1, session );
 						rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( ps );
 						rs.next();
 					}
 					final Object[] snapshot = entry.getLoadedState();
 					for ( int j = 0; j < lazyPropertyNames.length; j++ ) {
 						Object propValue = lazyPropertyTypes[j].nullSafeGet( rs, lazyPropertyColumnAliases[j], session, entity );
 						if ( initializeLazyProperty( fieldName, entity, session, snapshot, j, propValue ) ) {
 							result = propValue;
 						}
 					}
 				}
 				finally {
 					if ( rs != null ) {
 						session.getTransactionCoordinator().getJdbcCoordinator().release( rs, ps );
 					}
 				}
 			}
 			finally {
 				if ( ps != null ) {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
 				}
 			}
 
 			LOG.trace( "Done initializing lazy properties" );
 
 			return result;
 
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not initialize lazy properties: " +
 					MessageHelper.infoString( this, id, getFactory() ),
 					getSQLLazySelectString()
 				);
 		}
 	}
 
 	private Object initializeLazyPropertiesFromCache(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final EntityEntry entry,
 			final CacheEntry cacheEntry
 	) {
 
 		LOG.trace( "Initializing lazy properties from second-level cache" );
 
 		Object result = null;
 		Serializable[] disassembledValues = cacheEntry.getDisassembledState();
 		final Object[] snapshot = entry.getLoadedState();
 		for ( int j = 0; j < lazyPropertyNames.length; j++ ) {
 			final Object propValue = lazyPropertyTypes[j].assemble(
 					disassembledValues[ lazyPropertyNumbers[j] ],
 					session,
 					entity
 				);
 			if ( initializeLazyProperty( fieldName, entity, session, snapshot, j, propValue ) ) {
 				result = propValue;
 			}
 		}
 
 		LOG.trace( "Done initializing lazy properties" );
 
 		return result;
 	}
 
 	private boolean initializeLazyProperty(
 			final String fieldName,
 			final Object entity,
 			final SessionImplementor session,
 			final Object[] snapshot,
 			final int j,
 			final Object propValue) {
 		setPropertyValue( entity, lazyPropertyNumbers[j], propValue );
 		if ( snapshot != null ) {
 			// object have been loaded with setReadOnly(true); HHH-2236
 			snapshot[ lazyPropertyNumbers[j] ] = lazyPropertyTypes[j].deepCopy( propValue, factory );
 		}
 		return fieldName.equals( lazyPropertyNames[j] );
 	}
 
 	public boolean isBatchable() {
 		return optimisticLockStyle() == OptimisticLockStyle.NONE
 				|| ( !isVersioned() && optimisticLockStyle() == OptimisticLockStyle.VERSION )
 				|| getFactory().getSettings().isJdbcBatchVersionedData();
 	}
 
 	public Serializable[] getQuerySpaces() {
 		return getPropertySpaces();
 	}
 
 	protected Set getLazyProperties() {
 		return lazyProperties;
 	}
 
 	public boolean isBatchLoadable() {
 		return batchSize > 1;
 	}
 
 	public String[] getIdentifierColumnNames() {
 		return rootTableKeyColumnNames;
 	}
 
 	public String[] getIdentifierColumnReaders() {
 		return rootTableKeyColumnReaders;
 	}
 
 	public String[] getIdentifierColumnReaderTemplates() {
 		return rootTableKeyColumnReaderTemplates;
 	}
 
 	protected int getIdentifierColumnSpan() {
 		return identifierColumnSpan;
 	}
 
 	protected String[] getIdentifierAliases() {
 		return identifierAliases;
 	}
 
 	public String getVersionColumnName() {
 		return versionColumnName;
 	}
 
 	protected String getVersionedTableName() {
 		return getTableName( 0 );
 	}
 
 	protected boolean[] getSubclassColumnLazyiness() {
 		return subclassColumnLazyClosure;
 	}
 
 	protected boolean[] getSubclassFormulaLazyiness() {
 		return subclassFormulaLazyClosure;
 	}
 
 	/**
 	 * We can't immediately add to the cache if we have formulas
 	 * which must be evaluated, or if we have the possibility of
 	 * two concurrent updates to the same item being merged on
 	 * the database. This can happen if (a) the item is not
 	 * versioned and either (b) we have dynamic update enabled
 	 * or (c) we have multiple tables holding the state of the
 	 * item.
 	 */
 	public boolean isCacheInvalidationRequired() {
 		return hasFormulaProperties() ||
 				( !isVersioned() && ( entityMetamodel.isDynamicUpdate() || getTableSpan() > 1 ) );
 	}
 
 	public boolean isLazyPropertiesCacheable() {
 		return isLazyPropertiesCacheable;
 	}
 
 	public String selectFragment(String alias, String suffix) {
 		return identifierSelectFragment( alias, suffix ) +
 				propertySelectFragment( alias, suffix, false );
 	}
 
 	public String[] getIdentifierAliases(String suffix) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		// was toUnqotedAliasStrings( getIdentiferColumnNames() ) before - now tried
 		// to remove that unqoting and missing aliases..
 		return new Alias( suffix ).toAliasStrings( getIdentifierAliases() );
 	}
 
 	public String[] getPropertyAliases(String suffix, int i) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		return new Alias( suffix ).toUnquotedAliasStrings( propertyColumnAliases[i] );
 	}
 
 	public String getDiscriminatorAlias(String suffix) {
 		// NOTE: this assumes something about how propertySelectFragment is implemented by the subclass!
 		// was toUnqotedAliasStrings( getdiscriminatorColumnName() ) before - now tried
 		// to remove that unqoting and missing aliases..
 		return entityMetamodel.hasSubclasses() ?
 				new Alias( suffix ).toAliasString( getDiscriminatorAlias() ) :
 				null;
 	}
 
 	public String identifierSelectFragment(String name, String suffix) {
 		return new SelectFragment()
 				.setSuffix( suffix )
 				.addColumns( name, getIdentifierColumnNames(), getIdentifierAliases() )
 				.toFragmentString()
 				.substring( 2 ); //strip leading ", "
 	}
 
 
 	public String propertySelectFragment(String tableAlias, String suffix, boolean allProperties) {
 		return propertySelectFragmentFragment( tableAlias, suffix, allProperties ).toFragmentString();
 	}
 
 	public SelectFragment propertySelectFragmentFragment(
 			String tableAlias,
 			String suffix,
 			boolean allProperties) {
 		SelectFragment select = new SelectFragment()
 				.setSuffix( suffix )
 				.setUsedAliases( getIdentifierAliases() );
 
 		int[] columnTableNumbers = getSubclassColumnTableNumberClosure();
 		String[] columnAliases = getSubclassColumnAliasClosure();
 		String[] columnReaderTemplates = getSubclassColumnReaderTemplateClosure();
 		for ( int i = 0; i < getSubclassColumnClosure().length; i++ ) {
 			boolean selectable = ( allProperties || !subclassColumnLazyClosure[i] ) &&
 				!isSubclassTableSequentialSelect( columnTableNumbers[i] ) &&
 				subclassColumnSelectableClosure[i];
 			if ( selectable ) {
 				String subalias = generateTableAlias( tableAlias, columnTableNumbers[i] );
 				select.addColumnTemplate( subalias, columnReaderTemplates[i], columnAliases[i] );
 			}
 		}
 
 		int[] formulaTableNumbers = getSubclassFormulaTableNumberClosure();
 		String[] formulaTemplates = getSubclassFormulaTemplateClosure();
 		String[] formulaAliases = getSubclassFormulaAliasClosure();
 		for ( int i = 0; i < getSubclassFormulaTemplateClosure().length; i++ ) {
 			boolean selectable = ( allProperties || !subclassFormulaLazyClosure[i] )
 				&& !isSubclassTableSequentialSelect( formulaTableNumbers[i] );
 			if ( selectable ) {
 				String subalias = generateTableAlias( tableAlias, formulaTableNumbers[i] );
 				select.addFormula( subalias, formulaTemplates[i], formulaAliases[i] );
 			}
 		}
 
 		if ( entityMetamodel.hasSubclasses() ) {
 			addDiscriminatorToSelect( select, tableAlias, suffix );
 		}
 
 		if ( hasRowId() ) {
 			select.addColumn( tableAlias, rowIdName, ROWID_ALIAS );
 		}
 
 		return select;
 	}
 
 	public Object[] getDatabaseSnapshot(Serializable id, SessionImplementor session)
 			throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Getting current persistent state for: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		try {
 			PreparedStatement ps = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( getSQLSnapshotSelectString() );
 			try {
 				getIdentifierType().nullSafeSet( ps, id, 1, session );
 				//if ( isVersioned() ) getVersionType().nullSafeSet( ps, version, getIdentifierColumnSpan()+1, session );
 				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					//if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 					//otherwise return the "hydrated" state (ie. associations are not resolved)
 					Type[] types = getPropertyTypes();
 					Object[] values = new Object[types.length];
 					boolean[] includeProperty = getPropertyUpdateability();
 					for ( int i = 0; i < types.length; i++ ) {
 						if ( includeProperty[i] ) {
 							values[i] = types[i].hydrate( rs, getPropertyAliases( "", i ), session, null ); //null owner ok??
 						}
 					}
 					return values;
 				}
 				finally {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, ps );
 				}
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not retrieve snapshot: " + MessageHelper.infoString( this, id, getFactory() ),
 			        getSQLSnapshotSelectString()
 			);
 		}
 
 	}
 
 	@Override
 	public Serializable getIdByUniqueKey(Serializable key, String uniquePropertyName, SessionImplementor session) throws HibernateException {
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracef(
 					"resolving unique key [%s] to identifier for entity [%s]",
 					key,
 					getEntityName()
 			);
 		}
 
 		int propertyIndex = getSubclassPropertyIndex( uniquePropertyName );
 		if ( propertyIndex < 0 ) {
 			throw new HibernateException(
 					"Could not determine Type for property [" + uniquePropertyName + "] on entity [" + getEntityName() + "]"
 			);
 		}
 		Type propertyType = getSubclassPropertyType( propertyIndex );
 
 		try {
 			PreparedStatement ps = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( generateIdByUniqueKeySelectString( uniquePropertyName ) );
 			try {
 				propertyType.nullSafeSet( ps, key, 1, session );
 				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( ps );
 				try {
 					//if there is no resulting row, return null
 					if ( !rs.next() ) {
 						return null;
 					}
 					return (Serializable) getIdentifierType().nullSafeGet( rs, getIdentifierAliases(), session, null );
 				}
 				finally {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, ps );
 				}
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( ps );
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					String.format(
 							"could not resolve unique property [%s] to identifier for entity [%s]",
 							uniquePropertyName,
 							getEntityName()
 					),
 					getSQLSnapshotSelectString()
 			);
 		}
 
 	}
 
 	protected String generateIdByUniqueKeySelectString(String uniquePropertyName) {
 		Select select = new Select( getFactory().getDialect() );
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "resolve id by unique property [" + getEntityName() + "." + uniquePropertyName + "]" );
 		}
 
 		final String rooAlias = getRootAlias();
 
 		select.setFromClause( fromTableFragment( rooAlias ) + fromJoinFragment( rooAlias, true, false ) );
 
 		SelectFragment selectFragment = new SelectFragment();
 		selectFragment.addColumns( rooAlias, getIdentifierColumnNames(), getIdentifierAliases() );
 		select.setSelectClause( selectFragment );
 
 		StringBuilder whereClauseBuffer = new StringBuilder();
 		final int uniquePropertyIndex = getSubclassPropertyIndex( uniquePropertyName );
 		final String uniquePropertyTableAlias = generateTableAlias(
 				rooAlias,
 				getSubclassPropertyTableNumber( uniquePropertyIndex )
 		);
 		String sep = "";
 		for ( String columnTemplate : getSubclassPropertyColumnReaderTemplateClosure()[uniquePropertyIndex] ) {
 			if ( columnTemplate == null ) {
 				continue;
 			}
 			final String columnReference = StringHelper.replace( columnTemplate, Template.TEMPLATE, uniquePropertyTableAlias );
 			whereClauseBuffer.append( sep ).append( columnReference ).append( "=?" );
 			sep = " and ";
 		}
 		for ( String formulaTemplate : getSubclassPropertyFormulaTemplateClosure()[uniquePropertyIndex] ) {
 			if ( formulaTemplate == null ) {
 				continue;
 			}
 			final String formulaReference = StringHelper.replace( formulaTemplate, Template.TEMPLATE, uniquePropertyTableAlias );
 			whereClauseBuffer.append( sep ).append( formulaReference ).append( "=?" );
 			sep = " and ";
 		}
 		whereClauseBuffer.append( whereJoinFragment( rooAlias, true, false ) );
 
 		select.setWhereClause( whereClauseBuffer.toString() );
 
 		return select.setOuterJoins( "", "" ).toStatementString();
 	}
 
 
 	/**
 	 * Generate the SQL that selects the version number by id
 	 */
 	protected String generateSelectVersionString() {
 		SimpleSelect select = new SimpleSelect( getFactory().getDialect() )
 				.setTableName( getVersionedTableName() );
 		if ( isVersioned() ) {
 			select.addColumn( versionColumnName );
 		}
 		else {
 			select.addColumns( rootTableKeyColumnNames );
 		}
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "get version " + getEntityName() );
 		}
 		return select.addCondition( rootTableKeyColumnNames, "=?" ).toStatementString();
 	}
 
 	public boolean[] getPropertyUniqueness() {
 		return propertyUniqueness;
 	}
 
 	protected String generateInsertGeneratedValuesSelectString() {
 		return generateGeneratedValuesSelectString( GenerationTiming.INSERT );
 	}
 
 	protected String generateUpdateGeneratedValuesSelectString() {
 		return generateGeneratedValuesSelectString( GenerationTiming.ALWAYS );
 	}
 
 	private String generateGeneratedValuesSelectString(final GenerationTiming generationTimingToMatch) {
 		Select select = new Select( getFactory().getDialect() );
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "get generated state " + getEntityName() );
 		}
 
 		String[] aliasedIdColumns = StringHelper.qualify( getRootAlias(), getIdentifierColumnNames() );
 
 		// Here we render the select column list based on the properties defined as being generated.
 		// For partial component generation, we currently just re-select the whole component
 		// rather than trying to handle the individual generated portions.
 		String selectClause = concretePropertySelectFragment(
 				getRootAlias(),
 				new InclusionChecker() {
 					@Override
 					public boolean includeProperty(int propertyNumber) {
 						final InDatabaseValueGenerationStrategy generationStrategy
 								= entityMetamodel.getInDatabaseValueGenerationStrategies()[propertyNumber];
 						return generationStrategy != null
 								&& generationStrategy.getGenerationTiming() == generationTimingToMatch;
 					}
 				}
 		);
 		selectClause = selectClause.substring( 2 );
 
 		String fromClause = fromTableFragment( getRootAlias() ) +
 				fromJoinFragment( getRootAlias(), true, false );
 
 		String whereClause = new StringBuilder()
 				.append( StringHelper.join( "=? and ", aliasedIdColumns ) )
 				.append( "=?" )
 				.append( whereJoinFragment( getRootAlias(), true, false ) )
 				.toString();
 
 		return select.setSelectClause( selectClause )
 				.setFromClause( fromClause )
 				.setOuterJoins( "", "" )
 				.setWhereClause( whereClause )
 				.toStatementString();
 	}
 
 	protected static interface InclusionChecker {
 		public boolean includeProperty(int propertyNumber);
 	}
 
 	protected String concretePropertySelectFragment(String alias, final boolean[] includeProperty) {
 		return concretePropertySelectFragment(
 				alias,
 				new InclusionChecker() {
 					public boolean includeProperty(int propertyNumber) {
 						return includeProperty[propertyNumber];
 					}
 				}
 		);
 	}
 
 	protected String concretePropertySelectFragment(String alias, InclusionChecker inclusionChecker) {
 		int propertyCount = getPropertyNames().length;
 		int[] propertyTableNumbers = getPropertyTableNumbersInSelect();
 		SelectFragment frag = new SelectFragment();
 		for ( int i = 0; i < propertyCount; i++ ) {
 			if ( inclusionChecker.includeProperty( i ) ) {
 				frag.addColumnTemplates(
 						generateTableAlias( alias, propertyTableNumbers[i] ),
 						propertyColumnReaderTemplates[i],
 						propertyColumnAliases[i]
 				);
 				frag.addFormulas(
 						generateTableAlias( alias, propertyTableNumbers[i] ),
 						propertyColumnFormulaTemplates[i],
 						propertyColumnAliases[i]
 				);
 			}
 		}
 		return frag.toFragmentString();
 	}
 
 	protected String generateSnapshotSelectString() {
 
 		//TODO: should we use SELECT .. FOR UPDATE?
 
 		Select select = new Select( getFactory().getDialect() );
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			select.setComment( "get current state " + getEntityName() );
 		}
 
 		String[] aliasedIdColumns = StringHelper.qualify( getRootAlias(), getIdentifierColumnNames() );
 		String selectClause = StringHelper.join( ", ", aliasedIdColumns ) +
 				concretePropertySelectFragment( getRootAlias(), getPropertyUpdateability() );
 
 		String fromClause = fromTableFragment( getRootAlias() ) +
 				fromJoinFragment( getRootAlias(), true, false );
 
 		String whereClause = new StringBuilder()
 			.append( StringHelper.join( "=? and ",
 					aliasedIdColumns ) )
 			.append( "=?" )
 			.append( whereJoinFragment( getRootAlias(), true, false ) )
 			.toString();
 
 		/*if ( isVersioned() ) {
 			where.append(" and ")
 				.append( getVersionColumnName() )
 				.append("=?");
 		}*/
 
 		return select.setSelectClause( selectClause )
 				.setFromClause( fromClause )
 				.setOuterJoins( "", "" )
 				.setWhereClause( whereClause )
 				.toStatementString();
 	}
 
 	public Object forceVersionIncrement(Serializable id, Object currentVersion, SessionImplementor session) {
 		if ( !isVersioned() ) {
 			throw new AssertionFailure( "cannot force version increment on non-versioned entity" );
 		}
 
 		if ( isVersionPropertyGenerated() ) {
 			// the difficulty here is exactly what do we update in order to
 			// force the version to be incremented in the db...
 			throw new HibernateException( "LockMode.FORCE is currently not supported for generated version properties" );
 		}
 
 		Object nextVersion = getVersionType().next( currentVersion, session );
         if (LOG.isTraceEnabled()) LOG.trace("Forcing version increment [" + MessageHelper.infoString(this, id, getFactory()) + "; "
                                             + getVersionType().toLoggableString(currentVersion, getFactory()) + " -> "
                                             + getVersionType().toLoggableString(nextVersion, getFactory()) + "]");
 
 		// todo : cache this sql...
 		String versionIncrementString = generateVersionIncrementUpdateString();
 		PreparedStatement st = null;
 		try {
 			st = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( versionIncrementString, false );
 			try {
 				getVersionType().nullSafeSet( st, nextVersion, 1, session );
 				getIdentifierType().nullSafeSet( st, id, 2, session );
 				getVersionType().nullSafeSet( st, currentVersion, 2 + getIdentifierColumnSpan(), session );
 				int rows = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( st );
 				if ( rows != 1 ) {
 					throw new StaleObjectStateException( getEntityName(), id );
 				}
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 			}
 		}
 		catch ( SQLException sqle ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					sqle,
 					"could not retrieve version: " +
 					MessageHelper.infoString( this, id, getFactory() ),
 					getVersionSelectString()
 				);
 		}
 
 		return nextVersion;
 	}
 
 	private String generateVersionIncrementUpdateString() {
 		Update update = new Update( getFactory().getDialect() );
 		update.setTableName( getTableName( 0 ) );
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			update.setComment( "forced version increment" );
 		}
 		update.addColumn( getVersionColumnName() );
 		update.addPrimaryKeyColumns( getIdentifierColumnNames() );
 		update.setVersionColumnName( getVersionColumnName() );
 		return update.toStatementString();
 	}
 
 	/**
 	 * Retrieve the version number
 	 */
 	public Object getCurrentVersion(Serializable id, SessionImplementor session) throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Getting version: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		try {
 			PreparedStatement st = session.getTransactionCoordinator()
 					.getJdbcCoordinator()
 					.getStatementPreparer()
 					.prepareStatement( getVersionSelectString() );
 			try {
 				getIdentifierType().nullSafeSet( st, id, 1, session );
 				ResultSet rs = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( st );
 				try {
 					if ( !rs.next() ) {
 						return null;
 					}
 					if ( !isVersioned() ) {
 						return this;
 					}
 					return getVersionType().nullSafeGet( rs, getVersionColumnName(), session, null );
 				}
 				finally {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( rs, st );
 				}
 			}
 			finally {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( st );
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not retrieve version: " + MessageHelper.infoString( this, id, getFactory() ),
 					getVersionSelectString()
 			);
 		}
 	}
 
 	protected void initLockers() {
 		lockers.put( LockMode.READ, generateLocker( LockMode.READ ) );
 		lockers.put( LockMode.UPGRADE, generateLocker( LockMode.UPGRADE ) );
 		lockers.put( LockMode.UPGRADE_NOWAIT, generateLocker( LockMode.UPGRADE_NOWAIT ) );
 		lockers.put( LockMode.UPGRADE_SKIPLOCKED, generateLocker( LockMode.UPGRADE_SKIPLOCKED ) );
 		lockers.put( LockMode.FORCE, generateLocker( LockMode.FORCE ) );
 		lockers.put( LockMode.PESSIMISTIC_READ, generateLocker( LockMode.PESSIMISTIC_READ ) );
 		lockers.put( LockMode.PESSIMISTIC_WRITE, generateLocker( LockMode.PESSIMISTIC_WRITE ) );
 		lockers.put( LockMode.PESSIMISTIC_FORCE_INCREMENT, generateLocker( LockMode.PESSIMISTIC_FORCE_INCREMENT ) );
 		lockers.put( LockMode.OPTIMISTIC, generateLocker( LockMode.OPTIMISTIC ) );
 		lockers.put( LockMode.OPTIMISTIC_FORCE_INCREMENT, generateLocker( LockMode.OPTIMISTIC_FORCE_INCREMENT ) );
 	}
 
 	protected LockingStrategy generateLocker(LockMode lockMode) {
 		return factory.getDialect().getLockingStrategy( this, lockMode );
 	}
 
 	private LockingStrategy getLocker(LockMode lockMode) {
 		return ( LockingStrategy ) lockers.get( lockMode );
 	}
 
 	public void lock(
 			Serializable id,
 	        Object version,
 	        Object object,
 	        LockMode lockMode,
 	        SessionImplementor session) throws HibernateException {
 		getLocker( lockMode ).lock( id, version, object, LockOptions.WAIT_FOREVER, session );
 	}
 
 	public void lock(
 			Serializable id,
 	        Object version,
 	        Object object,
 	        LockOptions lockOptions,
 	        SessionImplementor session) throws HibernateException {
 		getLocker( lockOptions.getLockMode() ).lock( id, version, object, lockOptions.getTimeOut(), session );
 	}
 
 	public String getRootTableName() {
 		return getSubclassTableName( 0 );
 	}
 
 	public String getRootTableAlias(String drivingAlias) {
 		return drivingAlias;
 	}
 
 	public String[] getRootTableIdentifierColumnNames() {
 		return getRootTableKeyColumnNames();
 	}
 
 	public String[] toColumns(String alias, String propertyName) throws QueryException {
 		return propertyMapping.toColumns( alias, propertyName );
 	}
 
 	public String[] toColumns(String propertyName) throws QueryException {
 		return propertyMapping.getColumnNames( propertyName );
 	}
 
 	public Type toType(String propertyName) throws QueryException {
 		return propertyMapping.toType( propertyName );
 	}
 
 	public String[] getPropertyColumnNames(String propertyName) {
 		return propertyMapping.getColumnNames( propertyName );
 	}
 
 	/**
 	 * Warning:
 	 * When there are duplicated property names in the subclasses
 	 * of the class, this method may return the wrong table
 	 * number for the duplicated subclass property (note that
 	 * SingleTableEntityPersister defines an overloaded form
 	 * which takes the entity name.
 	 */
 	public int getSubclassPropertyTableNumber(String propertyPath) {
 		String rootPropertyName = StringHelper.root(propertyPath);
 		Type type = propertyMapping.toType(rootPropertyName);
 		if ( type.isAssociationType() ) {
 			AssociationType assocType = ( AssociationType ) type;
 			if ( assocType.useLHSPrimaryKey() ) {
 				// performance op to avoid the array search
 				return 0;
 			}
 			else if ( type.isCollectionType() ) {
 				// properly handle property-ref-based associations
 				rootPropertyName = assocType.getLHSPropertyName();
 			}
 		}
 		//Enable for HHH-440, which we don't like:
 		/*if ( type.isComponentType() && !propertyName.equals(rootPropertyName) ) {
 			String unrooted = StringHelper.unroot(propertyName);
 			int idx = ArrayHelper.indexOf( getSubclassColumnClosure(), unrooted );
 			if ( idx != -1 ) {
 				return getSubclassColumnTableNumberClosure()[idx];
 			}
 		}*/
 		int index = ArrayHelper.indexOf( getSubclassPropertyNameClosure(), rootPropertyName); //TODO: optimize this better!
 		return index==-1 ? 0 : getSubclassPropertyTableNumber(index);
 	}
 
 	public Declarer getSubclassPropertyDeclarer(String propertyPath) {
 		int tableIndex = getSubclassPropertyTableNumber( propertyPath );
 		if ( tableIndex == 0 ) {
 			return Declarer.CLASS;
 		}
 		else if ( isClassOrSuperclassTable( tableIndex ) ) {
 			return Declarer.SUPERCLASS;
 		}
 		else {
 			return Declarer.SUBCLASS;
 		}
 	}
 
 	private DiscriminatorMetadata discriminatorMetadata;
 
 	public DiscriminatorMetadata getTypeDiscriminatorMetadata() {
 		if ( discriminatorMetadata == null ) {
 			discriminatorMetadata = buildTypeDiscriminatorMetadata();
 		}
 		return discriminatorMetadata;
 	}
 
 	private DiscriminatorMetadata buildTypeDiscriminatorMetadata() {
 		return new DiscriminatorMetadata() {
 			public String getSqlFragment(String sqlQualificationAlias) {
 				return toColumns( sqlQualificationAlias, ENTITY_CLASS )[0];
 			}
 
 			public Type getResolutionType() {
 				return new DiscriminatorType( getDiscriminatorType(), AbstractEntityPersister.this );
 			}
 		};
 	}
 
 	public static String generateTableAlias(String rootAlias, int tableNumber) {
 		if ( tableNumber == 0 ) {
 			return rootAlias;
 		}
 		StringBuilder buf = new StringBuilder().append( rootAlias );
 		if ( !rootAlias.endsWith( "_" ) ) {
 			buf.append( '_' );
 		}
 		return buf.append( tableNumber ).append( '_' ).toString();
 	}
 
 	public String[] toColumns(String name, final int i) {
 		final String alias = generateTableAlias( name, getSubclassPropertyTableNumber( i ) );
 		String[] cols = getSubclassPropertyColumnNames( i );
 		String[] templates = getSubclassPropertyFormulaTemplateClosure()[i];
 		String[] result = new String[cols.length];
 		for ( int j = 0; j < cols.length; j++ ) {
 			if ( cols[j] == null ) {
 				result[j] = StringHelper.replace( templates[j], Template.TEMPLATE, alias );
 			}
 			else {
 				result[j] = StringHelper.qualify( alias, cols[j] );
 			}
 		}
 		return result;
 	}
 
 	private int getSubclassPropertyIndex(String propertyName) {
 		return ArrayHelper.indexOf(subclassPropertyNameClosure, propertyName);
 	}
 
 	protected String[] getPropertySubclassNames() {
 		return propertySubclassNames;
 	}
 
 	public String[] getPropertyColumnNames(int i) {
 		return propertyColumnNames[i];
 	}
 
 	public String[] getPropertyColumnWriters(int i) {
 		return propertyColumnWriters[i];
 	}
 
 	protected int getPropertyColumnSpan(int i) {
 		return propertyColumnSpans[i];
 	}
 
 	protected boolean hasFormulaProperties() {
 		return hasFormulaProperties;
 	}
 
 	public FetchMode getFetchMode(int i) {
 		return subclassPropertyFetchModeClosure[i];
 	}
 
 	public CascadeStyle getCascadeStyle(int i) {
 		return subclassPropertyCascadeStyleClosure[i];
 	}
 
 	public Type getSubclassPropertyType(int i) {
 		return subclassPropertyTypeClosure[i];
 	}
 
 	public String getSubclassPropertyName(int i) {
 		return subclassPropertyNameClosure[i];
 	}
 
 	public int countSubclassProperties() {
 		return subclassPropertyTypeClosure.length;
 	}
 
 	public String[] getSubclassPropertyColumnNames(int i) {
 		return subclassPropertyColumnNameClosure[i];
 	}
 
 	public boolean isDefinedOnSubclass(int i) {
 		return propertyDefinedOnSubclass[i];
 	}
 
 	@Override
 	public String[][] getSubclassPropertyFormulaTemplateClosure() {
 		return subclassPropertyFormulaTemplateClosure;
 	}
 
 	protected Type[] getSubclassPropertyTypeClosure() {
 		return subclassPropertyTypeClosure;
 	}
 
 	protected String[][] getSubclassPropertyColumnNameClosure() {
 		return subclassPropertyColumnNameClosure;
 	}
 
 	public String[][] getSubclassPropertyColumnReaderClosure() {
 		return subclassPropertyColumnReaderClosure;
 	}
 
 	public String[][] getSubclassPropertyColumnReaderTemplateClosure() {
 		return subclassPropertyColumnReaderTemplateClosure;
 	}
 
 	protected String[] getSubclassPropertyNameClosure() {
 		return subclassPropertyNameClosure;
 	}
 
 	@Override
 	public int[] resolveAttributeIndexes(Set<String> properties) {
 		Iterator<String> iter = properties.iterator();
 		int[] fields = new int[properties.size()];
 		int counter = 0;
 		while(iter.hasNext()) {
 			Integer index = entityMetamodel.getPropertyIndexOrNull( iter.next() );
 			if ( index != null )
 				fields[counter++] = index;
 		}
 		return fields;
 	}
 
 	protected String[] getSubclassPropertySubclassNameClosure() {
 		return subclassPropertySubclassNameClosure;
 	}
 
 	protected String[] getSubclassColumnClosure() {
 		return subclassColumnClosure;
 	}
 
 	protected String[] getSubclassColumnAliasClosure() {
 		return subclassColumnAliasClosure;
 	}
 
 	public String[] getSubclassColumnReaderTemplateClosure() {
 		return subclassColumnReaderTemplateClosure;
 	}
 
 	protected String[] getSubclassFormulaClosure() {
 		return subclassFormulaClosure;
 	}
 
 	protected String[] getSubclassFormulaTemplateClosure() {
 		return subclassFormulaTemplateClosure;
 	}
 
 	protected String[] getSubclassFormulaAliasClosure() {
 		return subclassFormulaAliasClosure;
 	}
 
 	public String[] getSubclassPropertyColumnAliases(String propertyName, String suffix) {
-		String rawAliases[] = ( String[] ) subclassPropertyAliases.get( propertyName );
+		String[] rawAliases = ( String[] ) subclassPropertyAliases.get( propertyName );
 
 		if ( rawAliases == null ) {
 			return null;
 		}
 
-		String result[] = new String[rawAliases.length];
+		String[] result = new String[rawAliases.length];
 		for ( int i = 0; i < rawAliases.length; i++ ) {
 			result[i] = new Alias( suffix ).toUnquotedAliasString( rawAliases[i] );
 		}
 		return result;
 	}
 
 	public String[] getSubclassPropertyColumnNames(String propertyName) {
 		//TODO: should we allow suffixes on these ?
 		return ( String[] ) subclassPropertyColumnNames.get( propertyName );
 	}
 
 
 
 	//This is really ugly, but necessary:
 	/**
 	 * Must be called by subclasses, at the end of their constructors
 	 */
 	protected void initSubclassPropertyAliasesMap(PersistentClass model) throws MappingException {
 
 		// ALIASES
 		internalInitSubclassPropertyAliasesMap( null, model.getSubclassPropertyClosureIterator() );
 
 		// aliases for identifier ( alias.id ); skip if the entity defines a non-id property named 'id'
 		if ( ! entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 			subclassPropertyAliases.put( ENTITY_ID, getIdentifierAliases() );
 			subclassPropertyColumnNames.put( ENTITY_ID, getIdentifierColumnNames() );
 		}
 
 		// aliases named identifier ( alias.idname )
 		if ( hasIdentifierProperty() ) {
 			subclassPropertyAliases.put( getIdentifierPropertyName(), getIdentifierAliases() );
 			subclassPropertyColumnNames.put( getIdentifierPropertyName(), getIdentifierColumnNames() );
 		}
 
 		// aliases for composite-id's
 		if ( getIdentifierType().isComponentType() ) {
 			// Fetch embedded identifiers propertynames from the "virtual" identifier component
 			CompositeType componentId = ( CompositeType ) getIdentifierType();
 			String[] idPropertyNames = componentId.getPropertyNames();
 			String[] idAliases = getIdentifierAliases();
 			String[] idColumnNames = getIdentifierColumnNames();
 
 			for ( int i = 0; i < idPropertyNames.length; i++ ) {
 				if ( entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 					subclassPropertyAliases.put(
 							ENTITY_ID + "." + idPropertyNames[i],
 							new String[] { idAliases[i] }
 					);
 					subclassPropertyColumnNames.put(
 							ENTITY_ID + "." + getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idColumnNames[i] }
 					);
 				}
 //				if (hasIdentifierProperty() && !ENTITY_ID.equals( getIdentifierPropertyName() ) ) {
 				if ( hasIdentifierProperty() ) {
 					subclassPropertyAliases.put(
 							getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idAliases[i] }
 					);
 					subclassPropertyColumnNames.put(
 							getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idColumnNames[i] }
 					);
 				}
 				else {
 					// embedded composite ids ( alias.idname1, alias.idname2 )
 					subclassPropertyAliases.put( idPropertyNames[i], new String[] { idAliases[i] } );
 					subclassPropertyColumnNames.put( idPropertyNames[i],  new String[] { idColumnNames[i] } );
 				}
 			}
 		}
 
 		if ( entityMetamodel.isPolymorphic() ) {
 			subclassPropertyAliases.put( ENTITY_CLASS, new String[] { getDiscriminatorAlias() } );
 			subclassPropertyColumnNames.put( ENTITY_CLASS, new String[] { getDiscriminatorColumnName() } );
 		}
 
 	}
 
 	/**
 	 * Must be called by subclasses, at the end of their constructors
 	 */
 	protected void initSubclassPropertyAliasesMap(EntityBinding model) throws MappingException {
 
 		// ALIASES
 
 		// TODO: Fix when subclasses are working (HHH-6337)
 		//internalInitSubclassPropertyAliasesMap( null, model.getSubclassPropertyClosureIterator() );
 
 		// aliases for identifier ( alias.id ); skip if the entity defines a non-id property named 'id'
 		if ( ! entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 			subclassPropertyAliases.put( ENTITY_ID, getIdentifierAliases() );
 			subclassPropertyColumnNames.put( ENTITY_ID, getIdentifierColumnNames() );
 		}
 
 		// aliases named identifier ( alias.idname )
 		if ( hasIdentifierProperty() ) {
 			subclassPropertyAliases.put( getIdentifierPropertyName(), getIdentifierAliases() );
 			subclassPropertyColumnNames.put( getIdentifierPropertyName(), getIdentifierColumnNames() );
 		}
 
 		// aliases for composite-id's
 		if ( getIdentifierType().isComponentType() ) {
 			// Fetch embedded identifiers propertynames from the "virtual" identifier component
 			CompositeType componentId = ( CompositeType ) getIdentifierType();
 			String[] idPropertyNames = componentId.getPropertyNames();
 			String[] idAliases = getIdentifierAliases();
 			String[] idColumnNames = getIdentifierColumnNames();
 
 			for ( int i = 0; i < idPropertyNames.length; i++ ) {
 				if ( entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 					subclassPropertyAliases.put(
 							ENTITY_ID + "." + idPropertyNames[i],
 							new String[] { idAliases[i] }
 					);
 					subclassPropertyColumnNames.put(
 							ENTITY_ID + "." + getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idColumnNames[i] }
 					);
 				}
 //				if (hasIdentifierProperty() && !ENTITY_ID.equals( getIdentifierPropertyName() ) ) {
 				if ( hasIdentifierProperty() ) {
 					subclassPropertyAliases.put(
 							getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idAliases[i] }
 					);
 					subclassPropertyColumnNames.put(
 							getIdentifierPropertyName() + "." + idPropertyNames[i],
 							new String[] { idColumnNames[i] }
 					);
 				}
 				else {
 					// embedded composite ids ( alias.idname1, alias.idname2 )
 					subclassPropertyAliases.put( idPropertyNames[i], new String[] { idAliases[i] } );
 					subclassPropertyColumnNames.put( idPropertyNames[i],  new String[] { idColumnNames[i] } );
 				}
 			}
 		}
 
 		if ( entityMetamodel.isPolymorphic() ) {
 			subclassPropertyAliases.put( ENTITY_CLASS, new String[] { getDiscriminatorAlias() } );
 			subclassPropertyColumnNames.put( ENTITY_CLASS, new String[] { getDiscriminatorColumnName() } );
 		}
 
 	}
 
 	private void internalInitSubclassPropertyAliasesMap(String path, Iterator propertyIterator) {
 		while ( propertyIterator.hasNext() ) {
 
 			Property prop = ( Property ) propertyIterator.next();
 			String propname = path == null ? prop.getName() : path + "." + prop.getName();
 			if ( prop.isComposite() ) {
 				Component component = ( Component ) prop.getValue();
 				Iterator compProps = component.getPropertyIterator();
 				internalInitSubclassPropertyAliasesMap( propname, compProps );
 			}
 			else {
 				String[] aliases = new String[prop.getColumnSpan()];
 				String[] cols = new String[prop.getColumnSpan()];
 				Iterator colIter = prop.getColumnIterator();
 				int l = 0;
 				while ( colIter.hasNext() ) {
 					Selectable thing = ( Selectable ) colIter.next();
 					aliases[l] = thing.getAlias( getFactory().getDialect(), prop.getValue().getTable() );
 					cols[l] = thing.getText( getFactory().getDialect() ); // TODO: skip formulas?
 					l++;
 				}
 
 				subclassPropertyAliases.put( propname, aliases );
 				subclassPropertyColumnNames.put( propname, cols );
 			}
 		}
 
 	}
 
 	public Object loadByUniqueKey(
 			String propertyName,
 			Object uniqueKey,
 			SessionImplementor session) throws HibernateException {
 		return getAppropriateUniqueKeyLoader( propertyName, session ).loadByUniqueKey( session, uniqueKey );
 	}
 
 	private EntityLoader getAppropriateUniqueKeyLoader(String propertyName, SessionImplementor session) {
 		final boolean useStaticLoader = !session.getLoadQueryInfluencers().hasEnabledFilters()
 				&& !session.getLoadQueryInfluencers().hasEnabledFetchProfiles()
 				&& propertyName.indexOf('.')<0; //ugly little workaround for fact that createUniqueKeyLoaders() does not handle component properties
 
 		if ( useStaticLoader ) {
 			return ( EntityLoader ) uniqueKeyLoaders.get( propertyName );
 		}
 		else {
 			return createUniqueKeyLoader(
 					propertyMapping.toType( propertyName ),
 					propertyMapping.toColumns( propertyName ),
 					session.getLoadQueryInfluencers()
 			);
 		}
 	}
 
 	public int getPropertyIndex(String propertyName) {
 		return entityMetamodel.getPropertyIndex(propertyName);
 	}
 
 	protected void createUniqueKeyLoaders() throws MappingException {
 		Type[] propertyTypes = getPropertyTypes();
 		String[] propertyNames = getPropertyNames();
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( propertyUniqueness[i] ) {
 				//don't need filters for the static loaders
 				uniqueKeyLoaders.put(
 						propertyNames[i],
 						createUniqueKeyLoader(
 								propertyTypes[i],
 								getPropertyColumnNames( i ),
 								LoadQueryInfluencers.NONE
 						)
 				);
 				//TODO: create uk loaders for component properties
 			}
 		}
 	}
 
 	private EntityLoader createUniqueKeyLoader(
 			Type uniqueKeyType,
 			String[] columns,
 			LoadQueryInfluencers loadQueryInfluencers) {
 		if ( uniqueKeyType.isEntityType() ) {
 			String className = ( ( EntityType ) uniqueKeyType ).getAssociatedEntityName();
 			uniqueKeyType = getFactory().getEntityPersister( className ).getIdentifierType();
 		}
 		return new EntityLoader(
 				this,
 				columns,
 				uniqueKeyType,
 				1,
 				LockMode.NONE,
 				getFactory(),
 				loadQueryInfluencers
 		);
 	}
 
 	protected String getSQLWhereString(String alias) {
 		return StringHelper.replace( sqlWhereStringTemplate, Template.TEMPLATE, alias );
 	}
 
 	protected boolean hasWhere() {
 		return sqlWhereString != null;
 	}
 
 	private void initOrdinaryPropertyPaths(Mapping mapping) throws MappingException {
 		for ( int i = 0; i < getSubclassPropertyNameClosure().length; i++ ) {
 			propertyMapping.initPropertyPaths( getSubclassPropertyNameClosure()[i],
 					getSubclassPropertyTypeClosure()[i],
 					getSubclassPropertyColumnNameClosure()[i],
 					getSubclassPropertyColumnReaderClosure()[i],
 					getSubclassPropertyColumnReaderTemplateClosure()[i],
 					getSubclassPropertyFormulaTemplateClosure()[i],
 					mapping );
 		}
 	}
 
 	private void initIdentifierPropertyPaths(Mapping mapping) throws MappingException {
 		String idProp = getIdentifierPropertyName();
 		if ( idProp != null ) {
 			propertyMapping.initPropertyPaths( idProp, getIdentifierType(), getIdentifierColumnNames(),
 					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping );
 		}
 		if ( entityMetamodel.getIdentifierProperty().isEmbedded() ) {
 			propertyMapping.initPropertyPaths( null, getIdentifierType(), getIdentifierColumnNames(),
 					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping );
 		}
 		if ( ! entityMetamodel.hasNonIdentifierPropertyNamedId() ) {
 			propertyMapping.initPropertyPaths( ENTITY_ID, getIdentifierType(), getIdentifierColumnNames(),
 					getIdentifierColumnReaders(), getIdentifierColumnReaderTemplates(), null, mapping );
 		}
 	}
 
 	private void initDiscriminatorPropertyPath(Mapping mapping) throws MappingException {
 		propertyMapping.initPropertyPaths( ENTITY_CLASS,
 				getDiscriminatorType(),
 				new String[]{getDiscriminatorColumnName()},
 				new String[]{getDiscriminatorColumnReaders()},
 				new String[]{getDiscriminatorColumnReaderTemplate()},
 				new String[]{getDiscriminatorFormulaTemplate()},
 				getFactory() );
 	}
 
 	protected void initPropertyPaths(Mapping mapping) throws MappingException {
 		initOrdinaryPropertyPaths(mapping);
 		initOrdinaryPropertyPaths(mapping); //do two passes, for collection property-ref!
 		initIdentifierPropertyPaths(mapping);
 		if ( entityMetamodel.isPolymorphic() ) {
 			initDiscriminatorPropertyPath( mapping );
 		}
 	}
 
 	protected UniqueEntityLoader createEntityLoader(
 			LockMode lockMode,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		//TODO: disable batch loading if lockMode > READ?
 		return BatchingEntityLoaderBuilder.getBuilder( getFactory() )
 				.buildLoader( this, batchSize, lockMode, getFactory(), loadQueryInfluencers );
 	}
 
 	protected UniqueEntityLoader createEntityLoader(
 			LockOptions lockOptions,
 			LoadQueryInfluencers loadQueryInfluencers) throws MappingException {
 		//TODO: disable batch loading if lockMode > READ?
 		return BatchingEntityLoaderBuilder.getBuilder( getFactory() )
 				.buildLoader( this, batchSize, lockOptions, getFactory(), loadQueryInfluencers );
 	}
 
 	/**
 	 * Used internally to create static loaders.  These are the default set of loaders used to handle get()/load()
 	 * processing.  lock() handling is done by the LockingStrategy instances (see {@link #getLocker})
 	 *
 	 * @param lockMode The lock mode to apply to the thing being loaded.
 	 * @return
 	 *
 	 * @throws MappingException
 	 */
 	protected UniqueEntityLoader createEntityLoader(LockMode lockMode) throws MappingException {
 		return createEntityLoader( lockMode, LoadQueryInfluencers.NONE );
 	}
 
 	protected boolean check(int rows, Serializable id, int tableNumber, Expectation expectation, PreparedStatement statement) throws HibernateException {
 		try {
 			expectation.verifyOutcome( rows, statement, -1 );
 		}
 		catch( StaleStateException e ) {
 			if ( !isNullableTable( tableNumber ) ) {
 				if ( getFactory().getStatistics().isStatisticsEnabled() ) {
 					getFactory().getStatisticsImplementor()
 							.optimisticFailure( getEntityName() );
 				}
 				throw new StaleObjectStateException( getEntityName(), id );
 			}
 			return false;
 		}
 		catch( TooManyRowsAffectedException e ) {
 			throw new HibernateException(
 					"Duplicate identifier in table for: " +
 					MessageHelper.infoString( this, id, getFactory() )
 			);
 		}
 		catch ( Throwable t ) {
 			return false;
 		}
 		return true;
 	}
 
 	protected String generateUpdateString(boolean[] includeProperty, int j, boolean useRowId) {
 		return generateUpdateString( includeProperty, j, null, useRowId );
 	}
 
 	/**
 	 * Generate the SQL that updates a row by id (and version)
 	 */
 	protected String generateUpdateString(final boolean[] includeProperty,
 										  final int j,
 										  final Object[] oldFields,
 										  final boolean useRowId) {
 
 		Update update = new Update( getFactory().getDialect() ).setTableName( getTableName( j ) );
 
 		// select the correct row by either pk or rowid
 		if ( useRowId ) {
 			update.addPrimaryKeyColumns( new String[]{rowIdName} ); //TODO: eventually, rowIdName[j]
 		}
 		else {
 			update.addPrimaryKeyColumns( getKeyColumns( j ) );
 		}
 
 		boolean hasColumns = false;
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) 
 					&& !lobProperties.contains( i ) ) {
 				// this is a property of the table, which we are updating
 				update.addColumns( getPropertyColumnNames(i),
 						propertyColumnUpdateable[i], propertyColumnWriters[i] );
 				hasColumns = hasColumns || getPropertyColumnSpan( i ) > 0;
 			}
 		}
 		
 		// HHH-4635
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) ) {
 				// this property belongs on the table and is to be inserted
 				update.addColumns( getPropertyColumnNames(i),
 						propertyColumnUpdateable[i], propertyColumnWriters[i] );
 				hasColumns = true;
 			}
 		}
 
 		if ( j == 0 && isVersioned() && entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.VERSION ) {
 			// this is the root (versioned) table, and we are using version-based
 			// optimistic locking;  if we are not updating the version, also don't
 			// check it (unless this is a "generated" version column)!
 			if ( checkVersion( includeProperty ) ) {
 				update.setVersionColumnName( getVersionColumnName() );
 				hasColumns = true;
 			}
 		}
 		else if ( isAllOrDirtyOptLocking() && oldFields != null ) {
 			// we are using "all" or "dirty" property-based optimistic locking
 
 			boolean[] includeInWhere = entityMetamodel.getOptimisticLockStyle() == OptimisticLockStyle.ALL
 					? getPropertyUpdateability() //optimistic-lock="all", include all updatable properties
 					: includeProperty; 			 //optimistic-lock="dirty", include all properties we are updating this time
 
 			boolean[] versionability = getPropertyVersionability();
 			Type[] types = getPropertyTypes();
 			for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 				boolean include = includeInWhere[i] &&
 						isPropertyOfTable( i, j ) &&
 						versionability[i];
 				if ( include ) {
 					// this property belongs to the table, and it is not specifically
 					// excluded from optimistic locking by optimistic-lock="false"
 					String[] propertyColumnNames = getPropertyColumnNames( i );
 					String[] propertyColumnWriters = getPropertyColumnWriters( i );
 					boolean[] propertyNullness = types[i].toColumnNullness( oldFields[i], getFactory() );
 					for ( int k=0; k<propertyNullness.length; k++ ) {
 						if ( propertyNullness[k] ) {
 							update.addWhereColumn( propertyColumnNames[k], "=" + propertyColumnWriters[k] );
 						}
 						else {
 							update.addWhereColumn( propertyColumnNames[k], " is null" );
 						}
 					}
 				}
 			}
 
 		}
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			update.setComment( "update " + getEntityName() );
 		}
 
 		return hasColumns ? update.toStatementString() : null;
 	}
 
 	private boolean checkVersion(final boolean[] includeProperty) {
 		return includeProperty[ getVersionProperty() ]
 				|| entityMetamodel.isVersionGenerated();
 	}
 
 	protected String generateInsertString(boolean[] includeProperty, int j) {
 		return generateInsertString( false, includeProperty, j );
 	}
 
 	protected String generateInsertString(boolean identityInsert, boolean[] includeProperty) {
 		return generateInsertString( identityInsert, includeProperty, 0 );
 	}
 
 	/**
 	 * Generate the SQL that inserts a row
 	 */
 	protected String generateInsertString(boolean identityInsert, boolean[] includeProperty, int j) {
 
 		// todo : remove the identityInsert param and variations;
 		//   identity-insert strings are now generated from generateIdentityInsertString()
 
 		Insert insert = new Insert( getFactory().getDialect() )
 				.setTableName( getTableName( j ) );
 
 		// add normal properties
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			// the incoming 'includeProperty' array only accounts for insertable defined at the root level, it
 			// does not account for partially generated composites etc.  We also need to account for generation
 			// values
 			if ( isPropertyOfTable( i, j ) ) {
 				if ( !lobProperties.contains( i ) ) {
 					final InDatabaseValueGenerationStrategy generationStrategy = entityMetamodel.getInDatabaseValueGenerationStrategies()[i];
 					if ( generationStrategy != null && generationStrategy.getGenerationTiming().includesInsert() ) {
 						if ( generationStrategy.referenceColumnsInSql() ) {
 							final String[] values;
 							if ( generationStrategy.getReferencedColumnValues() == null ) {
 								values = propertyColumnWriters[i];
 							}
 							else {
 								final int numberOfColumns = propertyColumnWriters[i].length;
 								values = new String[ numberOfColumns ];
 								for ( int x = 0; x < numberOfColumns; x++ ) {
 									if ( generationStrategy.getReferencedColumnValues()[x] != null ) {
 										values[x] = generationStrategy.getReferencedColumnValues()[x];
 									}
 									else {
 										values[x] = propertyColumnWriters[i][x];
 									}
 								}
 							}
 							insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], values );
 						}
 					}
 					else if ( includeProperty[i] ) {
 						insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], propertyColumnWriters[i] );
 					}
 				}
 			}
 		}
 
 		// add the discriminator
 		if ( j == 0 ) {
 			addDiscriminatorToInsert( insert );
 		}
 
 		// add the primary key
 		if ( j == 0 && identityInsert ) {
 			insert.addIdentityColumn( getKeyColumns( 0 )[0] );
 		}
 		else {
 			insert.addColumns( getKeyColumns( j ) );
 		}
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			insert.setComment( "insert " + getEntityName() );
 		}
 		
 		// HHH-4635
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) ) {
 				// this property belongs on the table and is to be inserted
 				insert.addColumns(
 						getPropertyColumnNames(i),
 						propertyColumnInsertable[i],
 						propertyColumnWriters[i]
 				);
 			}
 		}
 
 		String result = insert.toStatementString();
 
 		// append the SQL to return the generated identifier
 		if ( j == 0 && identityInsert && useInsertSelectIdentity() ) { //TODO: suck into Insert
 			result = getFactory().getDialect().appendIdentitySelectToInsert( result );
 		}
 
 		return result;
 	}
 
 	/**
 	 * Used to generate an insery statement against the root table in the
 	 * case of identifier generation strategies where the insert statement
 	 * executions actually generates the identifier value.
 	 *
 	 * @param includeProperty indices of the properties to include in the
 	 * insert statement.
 	 * @return The insert SQL statement string
 	 */
 	protected String generateIdentityInsertString(boolean[] includeProperty) {
 		Insert insert = identityDelegate.prepareIdentifierGeneratingInsert();
 		insert.setTableName( getTableName( 0 ) );
 
 		// add normal properties except lobs
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, 0 ) && !lobProperties.contains( i ) ) {
 				// this property belongs on the table and is to be inserted
 				insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], propertyColumnWriters[i] );
 			}
 		}
 
 		// HHH-4635 & HHH-8103
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, 0 ) ) {
 				insert.addColumns( getPropertyColumnNames(i), propertyColumnInsertable[i], propertyColumnWriters[i] );
 			}
 		}
 
 		// add the discriminator
 		addDiscriminatorToInsert( insert );
 
 		// delegate already handles PK columns
 
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			insert.setComment( "insert " + getEntityName() );
 		}
 
 		return insert.toStatementString();
 	}
 
 	/**
 	 * Generate the SQL that deletes a row by id (and version)
 	 */
 	protected String generateDeleteString(int j) {
 		Delete delete = new Delete()
 				.setTableName( getTableName( j ) )
 				.addPrimaryKeyColumns( getKeyColumns( j ) );
 		if ( j == 0 ) {
 			delete.setVersionColumnName( getVersionColumnName() );
 		}
 		if ( getFactory().getSettings().isCommentsEnabled() ) {
 			delete.setComment( "delete " + getEntityName() );
 		}
 		return delete.toStatementString();
 	}
 
 	protected int dehydrate(
 			Serializable id,
 			Object[] fields,
 			boolean[] includeProperty,
 			boolean[][] includeColumns,
 			int j,
 			PreparedStatement st,
 			SessionImplementor session,
 			boolean isUpdate) throws HibernateException, SQLException {
 		return dehydrate( id, fields, null, includeProperty, includeColumns, j, st, session, 1, isUpdate );
 	}
 
 	/**
 	 * Marshall the fields of a persistent instance to a prepared statement
 	 */
 	protected int dehydrate(
 			final Serializable id,
 			final Object[] fields,
 			final Object rowId,
 			final boolean[] includeProperty,
 			final boolean[][] includeColumns,
 			final int j,
 			final PreparedStatement ps,
 			final SessionImplementor session,
 			int index,
 			boolean isUpdate ) throws SQLException, HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Dehydrating entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		for ( int i = 0; i < entityMetamodel.getPropertySpan(); i++ ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j )
 					&& !lobProperties.contains( i )) {
 				getPropertyTypes()[i].nullSafeSet( ps, fields[i], index, includeColumns[i], session );
 				index += ArrayHelper.countTrue( includeColumns[i] ); //TODO:  this is kinda slow...
 			}
 		}
 		
 		if ( !isUpdate ) {
 			index += dehydrateId( id, rowId, ps, session, index );
 		}
 		
 		// HHH-4635
 		// Oracle expects all Lob properties to be last in inserts
 		// and updates.  Insert them at the end.
 		for ( int i : lobProperties ) {
 			if ( includeProperty[i] && isPropertyOfTable( i, j ) ) {
 				getPropertyTypes()[i].nullSafeSet( ps, fields[i], index, includeColumns[i], session );
 				index += ArrayHelper.countTrue( includeColumns[i] ); //TODO:  this is kinda slow...
 			}
 		}
 		
 		if ( isUpdate ) {
 			index += dehydrateId( id, rowId, ps, session, index );
 		}
 
 		return index;
 
 	}
 	
 	private int dehydrateId( 
 			final Serializable id,
 			final Object rowId,
 			final PreparedStatement ps,
 			final SessionImplementor session,
 			int index ) throws SQLException {
 		if ( rowId != null ) {
 			ps.setObject( index, rowId );
 			return 1;
 		} else if ( id != null ) {
 			getIdentifierType().nullSafeSet( ps, id, index, session );
 			return getIdentifierColumnSpan();
 		}
 		return 0;
 	}
 
 	/**
 	 * Unmarshall the fields of a persistent instance from a result set,
 	 * without resolving associations or collections. Question: should
 	 * this really be here, or should it be sent back to Loader?
 	 */
 	public Object[] hydrate(
 			final ResultSet rs,
 			final Serializable id,
 			final Object object,
 			final Loadable rootLoadable,
 			final String[][] suffixedPropertyColumns,
 			final boolean allProperties,
 			final SessionImplementor session) throws SQLException, HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Hydrating entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 		}
 
 		final AbstractEntityPersister rootPersister = (AbstractEntityPersister) rootLoadable;
 
 		final boolean hasDeferred = rootPersister.hasSequentialSelect();
 		PreparedStatement sequentialSelect = null;
 		ResultSet sequentialResultSet = null;
 		boolean sequentialSelectEmpty = false;
 		try {
 
 			if ( hasDeferred ) {
 				final String sql = rootPersister.getSequentialSelect( getEntityName() );
 				if ( sql != null ) {
 					//TODO: I am not so sure about the exception handling in this bit!
 					sequentialSelect = session.getTransactionCoordinator()
 							.getJdbcCoordinator()
 							.getStatementPreparer()
 							.prepareStatement( sql );
 					rootPersister.getIdentifierType().nullSafeSet( sequentialSelect, id, 1, session );
 					sequentialResultSet = session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().extract( sequentialSelect );
 					if ( !sequentialResultSet.next() ) {
 						// TODO: Deal with the "optional" attribute in the <join> mapping;
 						// this code assumes that optional defaults to "true" because it
 						// doesn't actually seem to work in the fetch="join" code
 						//
 						// Note that actual proper handling of optional-ality here is actually
 						// more involved than this patch assumes.  Remember that we might have
 						// multiple <join/> mappings associated with a single entity.  Really
 						// a couple of things need to happen to properly handle optional here:
 						//  1) First and foremost, when handling multiple <join/>s, we really
 						//      should be using the entity root table as the driving table;
 						//      another option here would be to choose some non-optional joined
 						//      table to use as the driving table.  In all likelihood, just using
 						//      the root table is much simplier
 						//  2) Need to add the FK columns corresponding to each joined table
 						//      to the generated select list; these would then be used when
 						//      iterating the result set to determine whether all non-optional
 						//      data is present
 						// My initial thoughts on the best way to deal with this would be
 						// to introduce a new SequentialSelect abstraction that actually gets
 						// generated in the persisters (ok, SingleTable...) and utilized here.
 						// It would encapsulated all this required optional-ality checking...
 						sequentialSelectEmpty = true;
 					}
 				}
 			}
 
 			final String[] propNames = getPropertyNames();
 			final Type[] types = getPropertyTypes();
 			final Object[] values = new Object[types.length];
 			final boolean[] laziness = getPropertyLaziness();
 			final String[] propSubclassNames = getSubclassPropertySubclassNameClosure();
 
 			for ( int i = 0; i < types.length; i++ ) {
 				if ( !propertySelectable[i] ) {
 					values[i] = BackrefPropertyAccessor.UNKNOWN;
 				}
 				else if ( allProperties || !laziness[i] ) {
 					//decide which ResultSet to get the property value from:
 					final boolean propertyIsDeferred = hasDeferred &&
 							rootPersister.isSubclassPropertyDeferred( propNames[i], propSubclassNames[i] );
 					if ( propertyIsDeferred && sequentialSelectEmpty ) {
 						values[i] = null;
 					}
 					else {
 						final ResultSet propertyResultSet = propertyIsDeferred ? sequentialResultSet : rs;
 						final String[] cols = propertyIsDeferred ? propertyColumnAliases[i] : suffixedPropertyColumns[i];
 						values[i] = types[i].hydrate( propertyResultSet, cols, session, object );
 					}
 				}
 				else {
 					values[i] = LazyPropertyInitializer.UNFETCHED_PROPERTY;
 				}
 			}
 
 			if ( sequentialResultSet != null ) {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( sequentialResultSet, sequentialSelect );
 			}
 
 			return values;
 
 		}
 		finally {
 			if ( sequentialSelect != null ) {
 				session.getTransactionCoordinator().getJdbcCoordinator().release( sequentialSelect );
 			}
 		}
 	}
 
 	protected boolean useInsertSelectIdentity() {
 		return !useGetGeneratedKeys() && getFactory().getDialect().supportsInsertSelectIdentity();
 	}
 
 	protected boolean useGetGeneratedKeys() {
 		return getFactory().getSettings().isGetGeneratedKeysEnabled();
 	}
 
 	protected String getSequentialSelect(String entityName) {
 		throw new UnsupportedOperationException("no sequential selects");
 	}
 
 	/**
 	 * Perform an SQL INSERT, and then retrieve a generated identifier.
 	 * <p/>
 	 * This form is used for PostInsertIdentifierGenerator-style ids (IDENTITY,
 	 * select, etc).
 	 */
 	protected Serializable insert(
 			final Object[] fields,
 			final boolean[] notNull,
 			String sql,
 			final Object object,
 			final SessionImplementor session) throws HibernateException {
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Inserting entity: {0} (native id)", getEntityName() );
 			if ( isVersioned() ) {
 				LOG.tracev( "Version: {0}", Versioning.getVersion( fields, this ) );
 			}
 		}
 
 		Binder binder = new Binder() {
 			public void bindValues(PreparedStatement ps) throws SQLException {
 				dehydrate( null, fields, notNull, propertyColumnInsertable, 0, ps, session, false );
 			}
 			public Object getEntity() {
 				return object;
 			}
 		};
 
 		return identityDelegate.performInsert( sql, session, binder );
 	}
 
 	public String getIdentitySelectString() {
 		//TODO: cache this in an instvar
 		return getFactory().getDialect().getIdentitySelectString(
 				getTableName(0),
 				getKeyColumns(0)[0],
 				getIdentifierType().sqlTypes( getFactory() )[0]
 		);
 	}
 
 	public String getSelectByUniqueKeyString(String propertyName) {
 		return new SimpleSelect( getFactory().getDialect() )
 			.setTableName( getTableName(0) )
 			.addColumns( getKeyColumns(0) )
 			.addCondition( getPropertyColumnNames(propertyName), "=?" )
 			.toStatementString();
 	}
 
 	private BasicBatchKey inserBatchKey;
 
 	/**
 	 * Perform an SQL INSERT.
 	 * <p/>
 	 * This for is used for all non-root tables as well as the root table
 	 * in cases where the identifier value is known before the insert occurs.
 	 */
 	protected void insert(
 			final Serializable id,
 			final Object[] fields,
 			final boolean[] notNull,
 			final int j,
 			final String sql,
 			final Object object,
 			final SessionImplementor session) throws HibernateException {
 
 		if ( isInverseTable( j ) ) {
 			return;
 		}
 
 		//note: it is conceptually possible that a UserType could map null to
 		//	  a non-null value, so the following is arguable:
 		if ( isNullableTable( j ) && isAllNull( fields, j ) ) {
 			return;
 		}
 
 		if ( LOG.isTraceEnabled() ) {
 			LOG.tracev( "Inserting entity: {0}", MessageHelper.infoString( this, id, getFactory() ) );
 			if ( j == 0 && isVersioned() )
 				LOG.tracev( "Version: {0}", Versioning.getVersion( fields, this ) );
 		}
 
 		// TODO : shouldn't inserts be Expectations.NONE?
 		final Expectation expectation = Expectations.appropriateExpectation( insertResultCheckStyles[j] );
 		// we can't batch joined inserts, *especially* not if it is an identity insert;
 		// nor can we batch statements where the expectation is based on an output param
 		final boolean useBatch = j == 0 && expectation.canBeBatched();
 		if ( useBatch && inserBatchKey == null ) {
 			inserBatchKey = new BasicBatchKey(
 					getEntityName() + "#INSERT",
 					expectation
 			);
 		}
 		final boolean callable = isInsertCallable( j );
 
 		try {
 			// Render the SQL query
 			final PreparedStatement insert;
 			if ( useBatch ) {
 				insert = session.getTransactionCoordinator()
 						.getJdbcCoordinator()
 						.getBatch( inserBatchKey )
 						.getBatchStatement( sql, callable );
 			}
 			else {
 				insert = session.getTransactionCoordinator()
 						.getJdbcCoordinator()
 						.getStatementPreparer()
 						.prepareStatement( sql, callable );
 			}
 
 			try {
 				int index = 1;
 				index += expectation.prepare( insert );
 
 				// Write the values of fields onto the prepared statement - we MUST use the state at the time the
 				// insert was issued (cos of foreign key constraints). Not necessarily the object's current state
 
 				dehydrate( id, fields, null, notNull, propertyColumnInsertable, j, insert, session, index, false );
 
 				if ( useBatch ) {
 					session.getTransactionCoordinator().getJdbcCoordinator().getBatch( inserBatchKey ).addToBatch();
 				}
 				else {
 					expectation.verifyOutcome( session.getTransactionCoordinator().getJdbcCoordinator().getResultSetReturn().executeUpdate( insert ), insert, -1 );
 				}
 
 			}
 			catch ( SQLException e ) {
 				if ( useBatch ) {
 					session.getTransactionCoordinator().getJdbcCoordinator().abortBatch();
 				}
 				throw e;
 			}
 			finally {
 				if ( !useBatch ) {
 					session.getTransactionCoordinator().getJdbcCoordinator().release( insert );
 				}
 			}
 		}
 		catch ( SQLException e ) {
 			throw getFactory().getSQLExceptionHelper().convert(
 					e,
 					"could not insert: " + MessageHelper.infoString( this ),
 					sql
 			);
 		}
 
 	}
 
 	/**
 	 * Perform an SQL UPDATE or SQL INSERT
 	 */
 	protected void updateOrInsert(
 			final Serializable id,
 			final Object[] fields,
 			final Object[] oldFields,
 			final Object rowId,
 			final boolean[] includeProperty,
 			final int j,
 			final Object oldVersion,
 			final Object object,
 			final String sql,
 			final SessionImplementor session) throws HibernateException {
 
 		if ( !isInverseTable( j ) ) {
 
 			final boolean isRowToUpdate;
 			if ( isNullableTable( j ) && oldFields != null && isAllNull( oldFields, j ) ) {
 				//don't bother trying to update, we know there is no row there yet
 				isRowToUpdate = false;
 			}
 			else if ( isNullableTable( j ) && isAllNull( fields, j ) ) {
 				//if all fields are null, we might need to delete existing row
 				isRowToUpdate = true;
 				delete( id, oldVersion, j, object, getSQLDeleteStrings()[j], session, null );
 			}
 			else {
 				//there is probably a row there, so try to update
 				//if no rows were updated, we will find out
 				isRowToUpdate = update( id, fields, oldFields, rowId, includeProperty, j, oldVersion, object, sql, session );
 			}
 
 			if ( !isRowToUpdate && !isAllNull( fields, j ) ) {
 				// assume that the row was not there since it previously had only null
 				// values, so do an INSERT instead
 				//TODO: does not respect dynamic-insert
 				insert( id, fields, getPropertyInsertability(), j, getSQLInsertStrings()[j], object, session );
 			}
 
 		}
 
 	}
 
 	private BasicBatchKey updateBatchKey;
 
 	protected boolean update(
 			final Serializable id,
 			final Object[] fields,
 			final Object[] oldFields,
 			final Object rowId,
 			final boolean[] includeProperty,
 			final int j,
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/CompositionSingularSubAttributesHelper.java b/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/CompositionSingularSubAttributesHelper.java
index d507cfb8e9..e3ad7ca12d 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/CompositionSingularSubAttributesHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/CompositionSingularSubAttributesHelper.java
@@ -1,301 +1,302 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.walking.internal;
 
 import java.util.Iterator;
 
-import org.hibernate.FetchMode;
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.FetchStyle;
 import org.hibernate.engine.FetchTiming;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.CascadeStyles;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.AbstractEntityPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.persister.spi.HydratedCompoundValueHandler;
 import org.hibernate.persister.walking.spi.AnyMappingDefinition;
 import org.hibernate.persister.walking.spi.AssociationAttributeDefinition;
 import org.hibernate.persister.walking.spi.AssociationKey;
 import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.AttributeSource;
 import org.hibernate.persister.walking.spi.CollectionDefinition;
 import org.hibernate.persister.walking.spi.CompositeCollectionElementDefinition;
 import org.hibernate.persister.walking.spi.CompositionDefinition;
 import org.hibernate.persister.walking.spi.EntityDefinition;
 import org.hibernate.persister.walking.spi.WalkingException;
 import org.hibernate.type.AnyType;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.Type;
 
 /**
  * A helper for getting attributes from a composition that is known
  * to have only singular attributes; for example, sub-attributes of a
  * composite ID or a composite collection element.
  *
  * TODO: This should be refactored into a delegate and renamed.
  *
  * @author Gail Badner
  */
-public class CompositionSingularSubAttributesHelper {
+public final class CompositionSingularSubAttributesHelper {
+	private CompositionSingularSubAttributesHelper() {
+	}
 
 	/**
 	 * Get composite ID sub-attribute definitions.
 	 *
 	 * @param entityPersister - the entity persister.
 	 *
 	 * @return composite ID sub-attribute definitions.
 	 */
 	public static Iterable<AttributeDefinition> getIdentifierSubAttributes(AbstractEntityPersister entityPersister) {
 		return getSingularSubAttributes(
 				entityPersister,
 				entityPersister,
 				(CompositeType) entityPersister.getIdentifierType(),
 				entityPersister.getTableName(),
 				entityPersister.getRootTableIdentifierColumnNames()
 		);
 	}
 
 	/**
 	 * Get sub-attribute definitions for a composite collection element.
 	 * @param compositionElementDefinition - composite collection element definition.
 	 * @return sub-attribute definitions for a composite collection element.
 	 */
 	public static Iterable<AttributeDefinition> getCompositeCollectionElementSubAttributes(
 			CompositeCollectionElementDefinition compositionElementDefinition) {
 		final QueryableCollection collectionPersister =
 				(QueryableCollection) compositionElementDefinition.getCollectionDefinition().getCollectionPersister();
 		return getSingularSubAttributes(
 				compositionElementDefinition.getSource(),
 				(OuterJoinLoadable) collectionPersister.getOwnerEntityPersister(),
 				(CompositeType) collectionPersister.getElementType(),
 				collectionPersister.getTableName(),
 				collectionPersister.getElementColumnNames()
 		);
 	}
 
 	public static Iterable<AttributeDefinition> getCompositeCollectionIndexSubAttributes(CompositeCollectionElementDefinition compositionElementDefinition){
 		final QueryableCollection collectionPersister =
 				(QueryableCollection) compositionElementDefinition.getCollectionDefinition().getCollectionPersister();
 		return getSingularSubAttributes(
 				compositionElementDefinition.getSource(),
 				(OuterJoinLoadable) collectionPersister.getOwnerEntityPersister(),
 				(CompositeType) collectionPersister.getIndexType(),
 				collectionPersister.getTableName(),
 				collectionPersister.getIndexColumnNames()
 		);
 	}
 
 	private static Iterable<AttributeDefinition> getSingularSubAttributes(
 			final AttributeSource source,
 			final OuterJoinLoadable ownerEntityPersister,
 			final CompositeType compositeType,
 			final String lhsTableName,
 			final String[] lhsColumns) {
 		return new Iterable<AttributeDefinition>() {
 			@Override
 			public Iterator<AttributeDefinition> iterator() {
 				return new Iterator<AttributeDefinition>() {
 					private final int numberOfAttributes = compositeType.getSubtypes().length;
-					private int currentSubAttributeNumber = 0;
-					private int currentColumnPosition = 0;
+					private int currentSubAttributeNumber;
+					private int currentColumnPosition;
 
 					@Override
 					public boolean hasNext() {
 						return currentSubAttributeNumber < numberOfAttributes;
 					}
 
 					@Override
 					public AttributeDefinition next() {
 						final int subAttributeNumber = currentSubAttributeNumber;
 						currentSubAttributeNumber++;
 
 						final String name = compositeType.getPropertyNames()[subAttributeNumber];
 						final Type type = compositeType.getSubtypes()[subAttributeNumber];
 
 						final int columnPosition = currentColumnPosition;
 						final int columnSpan = type.getColumnSpan( ownerEntityPersister.getFactory() );
 						final String[] subAttributeLhsColumns = ArrayHelper.slice( lhsColumns, columnPosition, columnSpan );
 
 
 						final boolean[] propertyNullability = compositeType.getPropertyNullability();
 						final boolean nullable = propertyNullability == null || propertyNullability[subAttributeNumber];
 
 						currentColumnPosition += columnSpan;
 
 						if ( type.isAssociationType() ) {
 							final AssociationType aType = (AssociationType) type;
 							return new AssociationAttributeDefinition() {
 								@Override
 								public AssociationKey getAssociationKey() {
 									return new AssociationKey( lhsTableName, subAttributeLhsColumns );
 								}
 
 
 								@Override
 								public AssociationNature getAssociationNature() {
 									if ( type.isAnyType() ) {
 										return AssociationNature.ANY;
 									}
 									else {
 										// cannot be a collection
 										return AssociationNature.ENTITY;
 									}
 								}
 
 								@Override
 								public EntityDefinition toEntityDefinition() {
 									if ( getAssociationNature() != AssociationNature.ENTITY ) {
 										throw new WalkingException(
 												"Cannot build EntityDefinition from non-entity-typed attribute"
 										);
 									}
 									return (EntityPersister) aType.getAssociatedJoinable( ownerEntityPersister.getFactory() );
 								}
 
 								@Override
 								public AnyMappingDefinition toAnyDefinition() {
 									if ( getAssociationNature() != AssociationNature.ANY ) {
 										throw new WalkingException(
 												"Cannot build AnyMappingDefinition from non-any-typed attribute"
 										);
 									}
 									// todo : not sure how lazy is propogated into the component for a subattribute of type any
 									return new StandardAnyTypeDefinition( (AnyType) aType, false );
 								}
 
 								@Override
 								public CollectionDefinition toCollectionDefinition() {
 									throw new WalkingException( "A collection cannot be mapped to a composite ID sub-attribute." );
 								}
 
 								@Override
 								public FetchStrategy determineFetchPlan(LoadQueryInfluencers loadQueryInfluencers, PropertyPath propertyPath) {
 									return new FetchStrategy( FetchTiming.IMMEDIATE, FetchStyle.JOIN );
 								}
 
 								@Override
 								public CascadeStyle determineCascadeStyle() {
 									return CascadeStyles.NONE;
 								}
 
 								@Override
 								public HydratedCompoundValueHandler getHydratedCompoundValueExtractor() {
 									return null;
 								}
 
 								@Override
 								public String getName() {
 									return name;
 								}
 
 								@Override
 								public AssociationType getType() {
 									return aType;
 								}
 
 								@Override
 								public boolean isNullable() {
 									return nullable;
 								}
 
 								@Override
 								public AttributeSource getSource() {
 									return source;
 								}
 							};
 						}
 						else if ( type.isComponentType() ) {
 							return new CompositionDefinition() {
 								@Override
 								public String getName() {
 									return name;
 								}
 
 								@Override
 								public CompositeType getType() {
 									return (CompositeType) type;
 								}
 
 								@Override
 								public boolean isNullable() {
 									return nullable;
 								}
 
 								@Override
 								public AttributeSource getSource() {
 									return source;
 								}
 
 								@Override
 								public Iterable<AttributeDefinition> getAttributes() {
 									return CompositionSingularSubAttributesHelper.getSingularSubAttributes(
 											this,
 											ownerEntityPersister,
 											(CompositeType) type,
 											lhsTableName,
 											subAttributeLhsColumns
 									);
 								}
 							};
 						}
 						else {
 							return new AttributeDefinition() {
 								@Override
 								public String getName() {
 									return name;
 								}
 
 								@Override
 								public Type getType() {
 									return type;
 								}
 
 								@Override
 								public boolean isNullable() {
 									return nullable;
 								}
 
 								@Override
 								public AttributeSource getSource() {
 									return source;
 								}
 							};
 						}
 					}
 
 					@Override
 					public void remove() {
 						throw new UnsupportedOperationException( "Remove operation not supported here" );
 					}
 				};
 			}
 		};
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/EntityIdentifierDefinitionHelper.java b/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/EntityIdentifierDefinitionHelper.java
index 0f24d1b9d8..ba7a2082d4 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/EntityIdentifierDefinitionHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/EntityIdentifierDefinitionHelper.java
@@ -1,195 +1,197 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.walking.internal;
 
 import org.hibernate.persister.entity.AbstractEntityPersister;
 import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.AttributeSource;
 import org.hibernate.persister.walking.spi.CompositionDefinition;
 import org.hibernate.persister.walking.spi.EncapsulatedEntityIdentifierDefinition;
 import org.hibernate.persister.walking.spi.EntityDefinition;
 import org.hibernate.persister.walking.spi.EntityIdentifierDefinition;
 import org.hibernate.persister.walking.spi.NonEncapsulatedEntityIdentifierDefinition;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.Type;
 
 /**
  * @author Gail Badner
  */
-public class EntityIdentifierDefinitionHelper {
+public final class EntityIdentifierDefinitionHelper {
+	private EntityIdentifierDefinitionHelper() {
+	}
 
 	public static EntityIdentifierDefinition buildSimpleEncapsulatedIdentifierDefinition(final AbstractEntityPersister entityPersister) {
 		return new EncapsulatedEntityIdentifierDefinition() {
 			private final AttributeDefinitionAdapter attr = new AttributeDefinitionAdapter( entityPersister);
 
 			@Override
 			public AttributeDefinition getAttributeDefinition() {
 				return attr;
 			}
 
 			@Override
 			public boolean isEncapsulated() {
 				return true;
 			}
 
 			@Override
 			public EntityDefinition getEntityDefinition() {
 				return entityPersister;
 			}
 		};
 	}
 
 	public static EntityIdentifierDefinition buildEncapsulatedCompositeIdentifierDefinition(
 			final AbstractEntityPersister entityPersister) {
 
 		return new EncapsulatedEntityIdentifierDefinition() {
 			private final CompositionDefinitionAdapter compositionDefinition = new CompositionDefinitionAdapter( entityPersister );
 
 			@Override
 			public AttributeDefinition getAttributeDefinition() {
 				return compositionDefinition;
 			}
 
 			@Override
 			public boolean isEncapsulated() {
 				return true;
 			}
 
 			@Override
 			public EntityDefinition getEntityDefinition() {
 				return entityPersister;
 			}
 		};
 	}
 
 	public static EntityIdentifierDefinition buildNonEncapsulatedCompositeIdentifierDefinition(final AbstractEntityPersister entityPersister) {
 		return new NonEncapsulatedEntityIdentifierDefinition() {
 			private final CompositionDefinitionAdapter compositionDefinition = new CompositionDefinitionAdapter( entityPersister );
 
 			@Override
 			public Iterable<AttributeDefinition> getAttributes() {
 				return compositionDefinition.getAttributes();
 			}
 
 			@Override
 			public Class getSeparateIdentifierMappingClass() {
 				return entityPersister.getEntityMetamodel().getIdentifierProperty().getType().getReturnedClass();
 			}
 
 			@Override
 			public boolean isEncapsulated() {
 				return false;
 			}
 
 			@Override
 			public EntityDefinition getEntityDefinition() {
 				return entityPersister;
 			}
 
 			@Override
 			public Type getCompositeType() {
 				return entityPersister.getEntityMetamodel().getIdentifierProperty().getType();
 			}
 
 			@Override
 			public AttributeSource getSource() {
 				return compositionDefinition;
 			}
 
 			@Override
 			public String getName() {
 				// Not sure this is always kosher.   See org.hibernate.tuple.entity.EntityMetamodel.hasNonIdentifierPropertyNamedId
 				return "id";
 			}
 
 			@Override
 			public CompositeType getType() {
 				return (CompositeType) getCompositeType();
 			}
 
 			@Override
 			public boolean isNullable() {
 				return compositionDefinition.isNullable();
 			}
 		};
 	}
 
 	private static class AttributeDefinitionAdapter implements AttributeDefinition {
 		private final AbstractEntityPersister entityPersister;
 
 		AttributeDefinitionAdapter(AbstractEntityPersister entityPersister) {
 			this.entityPersister = entityPersister;
 		}
 
 		@Override
 		public String getName() {
 			return entityPersister.getEntityMetamodel().getIdentifierProperty().getName();
 		}
 
 		@Override
 		public Type getType() {
 			return entityPersister.getEntityMetamodel().getIdentifierProperty().getType();
 		}
 
 		@Override
 		public boolean isNullable() {
 			return false;
 		}
 
 		@Override
 		public AttributeSource getSource() {
 			return entityPersister;
 		}
 
 		@Override
 		public String toString() {
 			return "<identifier-property:" + getName() + ">";
 		}
 
 		protected AbstractEntityPersister getEntityPersister() {
 			return entityPersister;
 		}
 	}
 
 	private static class CompositionDefinitionAdapter extends AttributeDefinitionAdapter implements CompositionDefinition {
 		CompositionDefinitionAdapter(AbstractEntityPersister entityPersister) {
 			super( entityPersister );
 		}
 
 		@Override
 		public String toString() {
 			return "<identifier-property:" + getName() + ">";
 		}
 
 		@Override
 		public CompositeType getType() {
 			return (CompositeType) super.getType();
 		}
 
 		@Override
 		public Iterable<AttributeDefinition> getAttributes() {
 			return  CompositionSingularSubAttributesHelper.getIdentifierSubAttributes( getEntityPersister() );
 		}
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/FetchStrategyHelper.java b/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/FetchStrategyHelper.java
index 4e5ab48283..231da1437a 100644
--- a/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/FetchStrategyHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/persister/walking/internal/FetchStrategyHelper.java
@@ -1,174 +1,176 @@
 /*
  * jDocBook, processing of DocBook sources
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.persister.walking.internal;
 
 import org.hibernate.FetchMode;
 import org.hibernate.engine.FetchStrategy;
 import org.hibernate.engine.FetchStyle;
 import org.hibernate.engine.FetchTiming;
 import org.hibernate.engine.profile.Fetch;
 import org.hibernate.engine.profile.FetchProfile;
 import org.hibernate.engine.spi.LoadQueryInfluencers;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.loader.PropertyPath;
 import org.hibernate.persister.collection.AbstractCollectionPersister;
 import org.hibernate.persister.collection.CollectionPersister;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.type.AssociationType;
-import org.hibernate.type.EntityType;
 
 /**
  * @author Steve Ebersole
  */
-public class FetchStrategyHelper {
+public final class FetchStrategyHelper {
+	private FetchStrategyHelper() {
+	}
+
 	/**
 	 * Determine the fetch-style (if one) explicitly set for this association via fetch profiles.
 	 * <p/>
 	 * Note that currently fetch profiles only allow specifying join fetching, so this method currently
 	 * returns either (a) FetchStyle.JOIN or (b) null
 	 *
 	 * @param loadQueryInfluencers
 	 * @param persister
 	 * @param path
 	 * @param propertyNumber
 	 *
 	 * @return
 	 */
 	public static FetchStyle determineFetchStyleByProfile(
 			LoadQueryInfluencers loadQueryInfluencers,
 			EntityPersister persister,
 			PropertyPath path,
 			int propertyNumber) {
 		if ( !loadQueryInfluencers.hasEnabledFetchProfiles() ) {
 			// perf optimization
 			return null;
 		}
 
 		// ugh, this stuff has to be made easier...
 		final String fullPath = path.getFullPath();
 		final String rootPropertyName = ( (OuterJoinLoadable) persister ).getSubclassPropertyName( propertyNumber );
 		int pos = fullPath.lastIndexOf( rootPropertyName );
 		final String relativePropertyPath = pos >= 0
 				? fullPath.substring( pos )
 				: rootPropertyName;
 		final String fetchRole = persister.getEntityName() + "." + relativePropertyPath;
 
 		for ( String profileName : loadQueryInfluencers.getEnabledFetchProfileNames() ) {
 			final FetchProfile profile = loadQueryInfluencers.getSessionFactory().getFetchProfile( profileName );
 			final Fetch fetch = profile.getFetchByRole( fetchRole );
 			if ( fetch != null && Fetch.Style.JOIN == fetch.getStyle() ) {
 				return FetchStyle.JOIN;
 			}
 		}
 		return null;
 	}
 
 	/**
 	 *
 	 * @param mappingFetchMode The mapping defined fetch mode
 	 * @param type The association type
 	 * @param sessionFactory The session factory
 	 *
 	 * @return
 	 */
 	public static FetchStyle determineFetchStyleByMetadata(
 			FetchMode mappingFetchMode,
 			AssociationType type,
 			SessionFactoryImplementor sessionFactory) {
 		if ( !type.isEntityType() && !type.isCollectionType() ) {
 			return FetchStyle.SELECT;
 		}
 
 		if ( mappingFetchMode == FetchMode.JOIN ) {
 			return FetchStyle.JOIN;
 		}
 
 		if ( mappingFetchMode == FetchMode.SELECT ) {
 			return FetchStyle.SELECT;
 
 		}
 		if ( type.isEntityType() ) {
 			EntityPersister persister = (EntityPersister) type.getAssociatedJoinable( sessionFactory );
 			if ( persister.isBatchLoadable() ) {
 				return FetchStyle.BATCH;
 			}
 			else if ( !persister.hasProxy() ) {
 				return FetchStyle.JOIN;
 			}
 		}
 		else {
 			CollectionPersister persister = (CollectionPersister) type.getAssociatedJoinable( sessionFactory );
 			if ( persister instanceof AbstractCollectionPersister
 					&& ( (AbstractCollectionPersister) persister ).isSubselectLoadable() ) {
 				return FetchStyle.SUBSELECT;
 			}
 			else if ( persister.getBatchSize() > 0 ) {
 				return FetchStyle.BATCH;
 			}
 		}
 
 		return FetchStyle.SELECT;
 	}
 
 	public static FetchTiming determineFetchTiming(
 			FetchStyle style,
 			AssociationType type,
 			SessionFactoryImplementor sessionFactory) {
 		switch ( style ) {
 			case JOIN: {
 				return FetchTiming.IMMEDIATE;
 			}
 			case BATCH:
 			case SUBSELECT: {
 				return FetchTiming.DELAYED;
 			}
 			default: {
 				// SELECT case, can be either
 				return isSubsequentSelectDelayed( type, sessionFactory )
 						? FetchTiming.DELAYED
 						: FetchTiming.IMMEDIATE;
 			}
 		}
 	}
 
 	private static boolean isSubsequentSelectDelayed(AssociationType type, SessionFactoryImplementor sessionFactory) {
 		if ( type.isAnyType() ) {
 			// we'd need more context here.  this is only kept as part of the property state on the owning entity
 			return false;
 		}
 		else if ( type.isEntityType() ) {
 			return ( (EntityPersister) type.getAssociatedJoinable( sessionFactory ) ).hasProxy();
 		}
 		else {
 			final CollectionPersister cp = ( (CollectionPersister) type.getAssociatedJoinable( sessionFactory ) );
 			return cp.isLazy() || cp.isExtraLazy();
 		}
 	}
 
 	public static boolean isJoinFetched(FetchStrategy fetchStrategy) {
 		return fetchStrategy.getTiming() == FetchTiming.IMMEDIATE
 				&& fetchStrategy.getStyle() == FetchStyle.JOIN;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/proxy/AbstractLazyInitializer.java b/hibernate-core/src/main/java/org/hibernate/proxy/AbstractLazyInitializer.java
index 19865c66a1..67ce17e5e0 100755
--- a/hibernate-core/src/main/java/org/hibernate/proxy/AbstractLazyInitializer.java
+++ b/hibernate-core/src/main/java/org/hibernate/proxy/AbstractLazyInitializer.java
@@ -1,408 +1,408 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.proxy;
 
 import java.io.Serializable;
 
 import javax.naming.NamingException;
 
 import org.hibernate.HibernateException;
 import org.hibernate.LazyInitializationException;
 import org.hibernate.Session;
 import org.hibernate.SessionException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.engine.spi.EntityKey;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.internal.SessionFactoryRegistry;
 import org.hibernate.persister.entity.EntityPersister;
 import org.jboss.logging.Logger;
 
 /**
  * Convenience base class for lazy initialization handlers.  Centralizes the basic plumbing of doing lazy
  * initialization freeing subclasses to acts as essentially adapters to their intended entity mode and/or
  * proxy generation strategy.
  *
  * @author Gavin King
  */
 public abstract class AbstractLazyInitializer implements LazyInitializer {
 	private static final Logger log = Logger.getLogger( AbstractLazyInitializer.class );
 
 	private String entityName;
 	private Serializable id;
 	private Object target;
 	private boolean initialized;
 	private boolean readOnly;
 	private boolean unwrap;
 	private transient SessionImplementor session;
 	private Boolean readOnlyBeforeAttachedToSession;
 
 	private String sessionFactoryUuid;
-	private boolean specjLazyLoad = false;
+	private boolean specjLazyLoad;
 
 	/**
 	 * For serialization from the non-pojo initializers (HHH-3309)
 	 */
 	protected AbstractLazyInitializer() {
 	}
 
 	/**
 	 * Main constructor.
 	 *
 	 * @param entityName The name of the entity being proxied.
 	 * @param id The identifier of the entity being proxied.
 	 * @param session The session owning the proxy.
 	 */
 	protected AbstractLazyInitializer(String entityName, Serializable id, SessionImplementor session) {
 		this.entityName = entityName;
 		this.id = id;
 		// initialize other fields depending on session state
 		if ( session == null ) {
 			unsetSession();
 		}
 		else {
 			setSession( session );
 		}
 	}
 
 	@Override
 	public final String getEntityName() {
 		return entityName;
 	}
 
 	@Override
 	public final Serializable getIdentifier() {
 		return id;
 	}
 
 	@Override
 	public final void setIdentifier(Serializable id) {
 		this.id = id;
 	}
 
 	@Override
 	public final boolean isUninitialized() {
 		return !initialized;
 	}
 
 	@Override
 	public final SessionImplementor getSession() {
 		return session;
 	}
 
 	@Override
 	public final void setSession(SessionImplementor s) throws HibernateException {
 		if ( s != session ) {
 			// check for s == null first, since it is least expensive
 			if ( s == null ) {
 				unsetSession();
 			}
 			else if ( isConnectedToSession() ) {
 				//TODO: perhaps this should be some other RuntimeException...
 				throw new HibernateException( "illegally attempted to associate a proxy with two open Sessions" );
 			}
 			else {
 				// s != null
 				session = s;
 				if ( readOnlyBeforeAttachedToSession == null ) {
 					// use the default read-only/modifiable setting
 					final EntityPersister persister = s.getFactory().getEntityPersister( entityName );
 					setReadOnly( s.getPersistenceContext().isDefaultReadOnly() || !persister.isMutable() );
 				}
 				else {
 					// use the read-only/modifiable setting indicated during deserialization
 					setReadOnly( readOnlyBeforeAttachedToSession );
 					readOnlyBeforeAttachedToSession = null;
 				}
 			}
 		}
 	}
 
 	private static EntityKey generateEntityKeyOrNull(Serializable id, SessionImplementor s, String entityName) {
 		if ( id == null || s == null || entityName == null ) {
 			return null;
 		}
 		return s.generateEntityKey( id, s.getFactory().getEntityPersister( entityName ) );
 	}
 
 	@Override
 	public final void unsetSession() {
 		prepareForPossibleSpecialSpecjInitialization();
 		session = null;
 		readOnly = false;
 		readOnlyBeforeAttachedToSession = null;
 	}
 
 	@Override
 	public final void initialize() throws HibernateException {
 		if ( !initialized ) {
 			if ( specjLazyLoad ) {
 				specialSpecjInitialization();
 			}
 			else if ( session == null ) {
 				throw new LazyInitializationException( "could not initialize proxy - no Session" );
 			}
 			else if ( !session.isOpen() ) {
 				throw new LazyInitializationException( "could not initialize proxy - the owning Session was closed" );
 			}
 			else if ( !session.isConnected() ) {
 				throw new LazyInitializationException( "could not initialize proxy - the owning Session is disconnected" );
 			}
 			else {
 				target = session.immediateLoad( entityName, id );
 				initialized = true;
 				checkTargetState();
 			}
 		}
 		else {
 			checkTargetState();
 		}
 	}
 
 	protected void specialSpecjInitialization() {
 		if ( session == null ) {
 			//we have a detached collection thats set to null, reattach
 			if ( sessionFactoryUuid == null ) {
 				throw new LazyInitializationException( "could not initialize proxy - no Session" );
 			}
 			try {
 				SessionFactoryImplementor sf = (SessionFactoryImplementor)
 						SessionFactoryRegistry.INSTANCE.getSessionFactory( sessionFactoryUuid );
 				SessionImplementor session = (SessionImplementor) sf.openSession();
 				
 				// TODO: On the next major release, add an
 				// 'isJTA' or 'getTransactionFactory' method to Session.
 				boolean isJTA = session.getTransactionCoordinator()
 						.getTransactionContext().getTransactionEnvironment()
 						.getTransactionFactory()
 						.compatibleWithJtaSynchronization();
 				
 				if ( !isJTA ) {
 					// Explicitly handle the transactions only if we're not in
 					// a JTA environment.  A lazy loading temporary session can
 					// be created even if a current session and transaction are
 					// open (ex: session.clear() was used).  We must prevent
 					// multiple transactions.
 					( ( Session) session ).beginTransaction();
 				}
 
 				try {
 					target = session.immediateLoad( entityName, id );
 				}
 				finally {
 					// make sure the just opened temp session gets closed!
 					try {
 						if ( !isJTA ) {
 							( ( Session) session ).getTransaction().commit();
 						}
 						( (Session) session ).close();
 					}
 					catch (Exception e) {
 						log.warn( "Unable to close temporary session used to load lazy proxy associated to no session" );
 					}
 				}
 				initialized = true;
 				checkTargetState();
 			}
 			catch (Exception e) {
 				e.printStackTrace();
 				throw new LazyInitializationException( e.getMessage() );
 			}
 		}
 		else if ( session.isOpen() && session.isConnected() ) {
 			target = session.immediateLoad( entityName, id );
 			initialized = true;
 			checkTargetState();
 		}
 		else {
 			throw new LazyInitializationException( "could not initialize proxy - Session was closed or disced" );
 		}
 	}
 
 	protected void prepareForPossibleSpecialSpecjInitialization() {
 		if ( session != null ) {
 			specjLazyLoad = session.getFactory().getSettings().isInitializeLazyStateOutsideTransactionsEnabled();
 
 			if ( specjLazyLoad && sessionFactoryUuid == null ) {
 				try {
 					sessionFactoryUuid = (String) session.getFactory().getReference().get( "uuid" ).getContent();
 				}
 				catch (NamingException e) {
 					//not much we can do if this fails...
 				}
 			}
 		}
 	}
 
 	private void checkTargetState() {
 		if ( !unwrap ) {
 			if ( target == null ) {
 				getSession().getFactory().getEntityNotFoundDelegate().handleEntityNotFound( entityName, id );
 			}
 		}
 	}
 
 	/**
 	 * Getter for property 'connectedToSession'.
 	 *
 	 * @return Value for property 'connectedToSession'.
 	 */
 	protected final boolean isConnectedToSession() {
 		return getProxyOrNull() != null;
 	}
 
 	private Object getProxyOrNull() {
 		final EntityKey entityKey = generateEntityKeyOrNull( getIdentifier(), session, getEntityName() );
 		if ( entityKey != null && session != null && session.isOpen() ) {
 			return session.getPersistenceContext().getProxy( entityKey );
 		}
 		return null;
 	}
 
 	@Override
 	public final Object getImplementation() {
 		initialize();
 		return target;
 	}
 
 	@Override
 	public final void setImplementation(Object target) {
 		this.target = target;
 		initialized = true;
 	}
 
 	@Override
 	public final Object getImplementation(SessionImplementor s) throws HibernateException {
 		final EntityKey entityKey = generateEntityKeyOrNull( getIdentifier(), s, getEntityName() );
 		return (entityKey == null ? null : s.getPersistenceContext().getEntity( entityKey ));
 	}
 
 	/**
 	 * Getter for property 'target'.
 	 * <p/>
 	 * Same as {@link #getImplementation()} except that this method will not force initialization.
 	 *
 	 * @return Value for property 'target'.
 	 */
 	protected final Object getTarget() {
 		return target;
 	}
 
 	@Override
 	public final boolean isReadOnlySettingAvailable() {
 		return (session != null && !session.isClosed());
 	}
 
 	private void errorIfReadOnlySettingNotAvailable() {
 		if ( session == null ) {
 			throw new TransientObjectException(
 					"Proxy is detached (i.e, session is null). The read-only/modifiable setting is only accessible when the proxy is associated with an open session."
 			);
 		}
 		if ( session.isClosed() ) {
 			throw new SessionException(
 					"Session is closed. The read-only/modifiable setting is only accessible when the proxy is associated with an open session."
 			);
 		}
 	}
 
 	@Override
 	public final boolean isReadOnly() {
 		errorIfReadOnlySettingNotAvailable();
 		return readOnly;
 	}
 
 	@Override
 	public final void setReadOnly(boolean readOnly) {
 		errorIfReadOnlySettingNotAvailable();
 		// only update if readOnly is different from current setting
 		if ( this.readOnly != readOnly ) {
 			final EntityPersister persister = session.getFactory().getEntityPersister( entityName );
 			if ( !persister.isMutable() && !readOnly ) {
 				throw new IllegalStateException( "cannot make proxies for immutable entities modifiable" );
 			}
 			this.readOnly = readOnly;
 			if ( initialized ) {
 				EntityKey key = generateEntityKeyOrNull( getIdentifier(), session, getEntityName() );
 				if ( key != null && session.getPersistenceContext().containsEntity( key ) ) {
 					session.getPersistenceContext().setReadOnly( target, readOnly );
 				}
 			}
 		}
 	}
 
 	/**
 	 * Get the read-only/modifiable setting that should be put in affect when it is
 	 * attached to a session.
 	 * <p/>
 	 * This method should only be called during serialization when read-only/modifiable setting
 	 * is not available (i.e., isReadOnlySettingAvailable() == false)
 	 *
 	 * @return null, if the default setting should be used;
 	 *         true, for read-only;
 	 *         false, for modifiable
 	 *
 	 * @throws IllegalStateException if isReadOnlySettingAvailable() == true
 	 */
 	protected final Boolean isReadOnlyBeforeAttachedToSession() {
 		if ( isReadOnlySettingAvailable() ) {
 			throw new IllegalStateException(
 					"Cannot call isReadOnlyBeforeAttachedToSession when isReadOnlySettingAvailable == true"
 			);
 		}
 		return readOnlyBeforeAttachedToSession;
 	}
 
 	/**
 	 * Set the read-only/modifiable setting that should be put in affect when it is
 	 * attached to a session.
 	 * <p/>
 	 * This method should only be called during deserialization, before associating
 	 * the proxy with a session.
 	 *
 	 * @param readOnlyBeforeAttachedToSession, the read-only/modifiable setting to use when
 	 * associated with a session; null indicates that the default should be used.
 	 *
 	 * @throws IllegalStateException if isReadOnlySettingAvailable() == true
 	 */
 	/* package-private */
 	final void setReadOnlyBeforeAttachedToSession(Boolean readOnlyBeforeAttachedToSession) {
 		if ( isReadOnlySettingAvailable() ) {
 			throw new IllegalStateException(
 					"Cannot call setReadOnlyBeforeAttachedToSession when isReadOnlySettingAvailable == true"
 			);
 		}
 		this.readOnlyBeforeAttachedToSession = readOnlyBeforeAttachedToSession;
 	}
 
 	@Override
 	public boolean isUnwrap() {
 		return unwrap;
 	}
 
 	@Override
 	public void setUnwrap(boolean unwrap) {
 		this.unwrap = unwrap;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/proxy/pojo/javassist/JavassistLazyInitializer.java b/hibernate-core/src/main/java/org/hibernate/proxy/pojo/javassist/JavassistLazyInitializer.java
index a44c9ceb28..a3e4e8c529 100644
--- a/hibernate-core/src/main/java/org/hibernate/proxy/pojo/javassist/JavassistLazyInitializer.java
+++ b/hibernate-core/src/main/java/org/hibernate/proxy/pojo/javassist/JavassistLazyInitializer.java
@@ -1,244 +1,244 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.proxy.pojo.javassist;
 
 import java.io.Serializable;
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Method;
 
 import javassist.util.proxy.MethodFilter;
 import javassist.util.proxy.MethodHandler;
 import javassist.util.proxy.ProxyFactory;
 import javassist.util.proxy.ProxyObject;
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.spi.SessionImplementor;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.pojo.BasicLazyInitializer;
 import org.hibernate.type.CompositeType;
 
 /**
  * A Javassist-based lazy initializer proxy.
  *
  * @author Muga Nishizawa
  */
 public class JavassistLazyInitializer extends BasicLazyInitializer implements MethodHandler {
-
-	private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, JavassistLazyInitializer.class.getName());
+	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( JavassistLazyInitializer.class );
 
 	private static final MethodFilter FINALIZE_FILTER = new MethodFilter() {
 		public boolean isHandled(Method m) {
 			// skip finalize methods
 			return !( m.getParameterTypes().length == 0 && m.getName().equals( "finalize" ) );
 		}
 	};
 
 	private Class[] interfaces;
-	private boolean constructed = false;
+	private boolean constructed;
 
 	private JavassistLazyInitializer(
 			final String entityName,
 			final Class persistentClass,
 			final Class[] interfaces,
 			final Serializable id,
 			final Method getIdentifierMethod,
 			final Method setIdentifierMethod,
 			final CompositeType componentIdType,
 			final SessionImplementor session,
 			final boolean overridesEquals) {
 		super( entityName, persistentClass, id, getIdentifierMethod, setIdentifierMethod, componentIdType, session, overridesEquals );
 		this.interfaces = interfaces;
 	}
 
 	public static HibernateProxy getProxy(
 			final String entityName,
 			final Class persistentClass,
 			final Class[] interfaces,
 			final Method getIdentifierMethod,
 			final Method setIdentifierMethod,
 			CompositeType componentIdType,
 			final Serializable id,
 			final SessionImplementor session) throws HibernateException {
 		// note: interface is assumed to already contain HibernateProxy.class
 		try {
 			final JavassistLazyInitializer instance = new JavassistLazyInitializer(
 					entityName,
 					persistentClass,
 					interfaces,
 					id,
 					getIdentifierMethod,
 					setIdentifierMethod,
 					componentIdType,
 					session,
 					ReflectHelper.overridesEquals(persistentClass)
 			);
 			ProxyFactory factory = new ProxyFactory();
 			factory.setSuperclass( interfaces.length == 1 ? persistentClass : null );
 			factory.setInterfaces( interfaces );
 			factory.setFilter( FINALIZE_FILTER );
 			Class cl = factory.createClass();
 			final HibernateProxy proxy = ( HibernateProxy ) cl.newInstance();
 			( ( ProxyObject ) proxy ).setHandler( instance );
 			instance.constructed = true;
 			return proxy;
 		}
 		catch ( Throwable t ) {
 			LOG.error(LOG.javassistEnhancementFailed(entityName), t);
 			throw new HibernateException(LOG.javassistEnhancementFailed(entityName), t);
 		}
 	}
 
 	public static HibernateProxy getProxy(
 			final Class factory,
 			final String entityName,
 			final Class persistentClass,
 			final Class[] interfaces,
 			final Method getIdentifierMethod,
 			final Method setIdentifierMethod,
 			final CompositeType componentIdType,
 			final Serializable id,
 			final SessionImplementor session,
 			final boolean classOverridesEquals) throws HibernateException {
 
 		final JavassistLazyInitializer instance = new JavassistLazyInitializer(
 				entityName,
 				persistentClass,
 				interfaces, id,
 				getIdentifierMethod,
 				setIdentifierMethod,
 				componentIdType,
 				session,
 				classOverridesEquals
 		);
 
 		final HibernateProxy proxy;
 		try {
 			proxy = ( HibernateProxy ) factory.newInstance();
 		}
 		catch ( Exception e ) {
 			throw new HibernateException(
 					"Javassist Enhancement failed: "
 					+ persistentClass.getName(), e
 			);
 		}
 		( ( ProxyObject ) proxy ).setHandler( instance );
 		instance.constructed = true;
 		return proxy;
 	}
 
 	public static Class getProxyFactory(
 			Class persistentClass,
 			Class[] interfaces) throws HibernateException {
 		// note: interfaces is assumed to already contain HibernateProxy.class
 
 		try {
 			ProxyFactory factory = new ProxyFactory();
 			factory.setSuperclass( interfaces.length == 1 ? persistentClass : null );
 			factory.setInterfaces( interfaces );
 			factory.setFilter( FINALIZE_FILTER );
 			return factory.createClass();
 		}
 		catch ( Throwable t ) {
 			LOG.error(LOG.javassistEnhancementFailed(persistentClass.getName()), t);
 			throw new HibernateException(LOG.javassistEnhancementFailed(persistentClass.getName()), t);
 		}
 	}
 
 	@Override
 	public Object invoke(
 			final Object proxy,
 			final Method thisMethod,
 			final Method proceed,
 			final Object[] args) throws Throwable {
 		if ( this.constructed ) {
 			Object result;
 			try {
 				result = this.invoke( thisMethod, args, proxy );
 			}
 			catch ( Throwable t ) {
 				throw new Exception( t.getCause() );
 			}
 			if ( result == INVOKE_IMPLEMENTATION ) {
 				Object target = getImplementation();
 				final Object returnValue;
 				try {
 					if ( ReflectHelper.isPublic( persistentClass, thisMethod ) ) {
 						if ( !thisMethod.getDeclaringClass().isInstance( target ) ) {
 							throw new ClassCastException( target.getClass().getName() );
 						}
 						returnValue = thisMethod.invoke( target, args );
 					}
 					else {
 						if ( !thisMethod.isAccessible() ) {
 							thisMethod.setAccessible( true );
 						}
 						returnValue = thisMethod.invoke( target, args );
 					}
 					
 					if ( returnValue == target ) {
 						if ( returnValue.getClass().isInstance(proxy) ) {
 							return proxy;
 						}
 						else {
 							LOG.narrowingProxy( returnValue.getClass() );
 						}
 					}
 					return returnValue;
 				}
 				catch ( InvocationTargetException ite ) {
 					throw ite.getTargetException();
 				}
 			}
 			else {
 				return result;
 			}
 		}
 		else {
 			// while constructor is running
 			if ( thisMethod.getName().equals( "getHibernateLazyInitializer" ) ) {
 				return this;
 			}
 			else {
 				return proceed.invoke( proxy, args );
 			}
 		}
 	}
 
 	@Override
 	protected Object serializableProxy() {
 		return new SerializableProxy(
 				getEntityName(),
 				persistentClass,
 				interfaces,
 				getIdentifier(),
 				( isReadOnlySettingAvailable() ? Boolean.valueOf( isReadOnly() ) : isReadOnlyBeforeAttachedToSession() ),
 				getIdentifierMethod,
 				setIdentifierMethod,
 				componentIdType
 		);
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/service/StandardServiceInitiators.java b/hibernate-core/src/main/java/org/hibernate/service/StandardServiceInitiators.java
index 69900c3d74..9df6799c3c 100644
--- a/hibernate-core/src/main/java/org/hibernate/service/StandardServiceInitiators.java
+++ b/hibernate-core/src/main/java/org/hibernate/service/StandardServiceInitiators.java
@@ -1,91 +1,94 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.service;
 
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
 
 import org.hibernate.boot.registry.StandardServiceInitiator;
 import org.hibernate.cache.internal.RegionFactoryInitiator;
 import org.hibernate.engine.config.internal.ConfigurationServiceInitiator;
 import org.hibernate.engine.jdbc.batch.internal.BatchBuilderInitiator;
 import org.hibernate.engine.jdbc.connections.internal.ConnectionProviderInitiator;
 import org.hibernate.engine.jdbc.connections.internal.MultiTenantConnectionProviderInitiator;
 import org.hibernate.engine.jdbc.cursor.internal.RefCursorSupportInitiator;
 import org.hibernate.engine.jdbc.dialect.internal.DialectFactoryInitiator;
 import org.hibernate.engine.jdbc.dialect.internal.DialectResolverInitiator;
 import org.hibernate.engine.jdbc.internal.JdbcServicesInitiator;
 import org.hibernate.engine.jndi.internal.JndiServiceInitiator;
 import org.hibernate.engine.transaction.internal.TransactionFactoryInitiator;
 import org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator;
 import org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformResolverInitiator;
 import org.hibernate.id.factory.internal.MutableIdentifierGeneratorFactoryInitiator;
 import org.hibernate.jmx.internal.JmxServiceInitiator;
 import org.hibernate.persister.internal.PersisterClassResolverInitiator;
 import org.hibernate.persister.internal.PersisterFactoryInitiator;
 import org.hibernate.service.internal.SessionFactoryServiceRegistryFactoryInitiator;
 import org.hibernate.tool.hbm2ddl.ImportSqlCommandExtractorInitiator;
 
 /**
  * Central definition of the standard set of service initiators defined by Hibernate.
  * 
  * @author Steve Ebersole
  */
-public class StandardServiceInitiators {
+public final class StandardServiceInitiators {
+	private StandardServiceInitiators() {
+	}
+
 	public static List<StandardServiceInitiator> LIST = buildStandardServiceInitiatorList();
 
 	private static List<StandardServiceInitiator> buildStandardServiceInitiatorList() {
 		final List<StandardServiceInitiator> serviceInitiators = new ArrayList<StandardServiceInitiator>();
 
 		serviceInitiators.add( ConfigurationServiceInitiator.INSTANCE );
 		serviceInitiators.add( ImportSqlCommandExtractorInitiator.INSTANCE );
 
 		serviceInitiators.add( JndiServiceInitiator.INSTANCE );
 		serviceInitiators.add( JmxServiceInitiator.INSTANCE );
 
 		serviceInitiators.add( PersisterClassResolverInitiator.INSTANCE );
 		serviceInitiators.add( PersisterFactoryInitiator.INSTANCE );
 
 		serviceInitiators.add( ConnectionProviderInitiator.INSTANCE );
 		serviceInitiators.add( MultiTenantConnectionProviderInitiator.INSTANCE );
 		serviceInitiators.add( DialectResolverInitiator.INSTANCE );
 		serviceInitiators.add( DialectFactoryInitiator.INSTANCE );
 		serviceInitiators.add( BatchBuilderInitiator.INSTANCE );
 		serviceInitiators.add( JdbcServicesInitiator.INSTANCE );
 		serviceInitiators.add( RefCursorSupportInitiator.INSTANCE );
 
 		serviceInitiators.add( MutableIdentifierGeneratorFactoryInitiator.INSTANCE);
 
 		serviceInitiators.add( JtaPlatformResolverInitiator.INSTANCE );
 		serviceInitiators.add( JtaPlatformInitiator.INSTANCE );
 		serviceInitiators.add( TransactionFactoryInitiator.INSTANCE );
 
 		serviceInitiators.add( SessionFactoryServiceRegistryFactoryInitiator.INSTANCE );
 
 		serviceInitiators.add( RegionFactoryInitiator.INSTANCE );
 
 		return Collections.unmodifiableList( serviceInitiators );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/QuerySelect.java b/hibernate-core/src/main/java/org/hibernate/sql/QuerySelect.java
index 8a21409a47..9e250256a6 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/QuerySelect.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/QuerySelect.java
@@ -1,212 +1,212 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
 import java.util.HashSet;
 import java.util.Iterator;
 
 import org.hibernate.dialect.Dialect;
 
 /**
  * A translated HQL query
  * @author Gavin King
  */
 public class QuerySelect {
 	private Dialect dialect;
 	private JoinFragment joins;
 	private StringBuilder select = new StringBuilder();
 	private StringBuilder where = new StringBuilder();
 	private StringBuilder groupBy = new StringBuilder();
 	private StringBuilder orderBy = new StringBuilder();
 	private StringBuilder having = new StringBuilder();
 	private String comment;
-	private boolean distinct=false;
+	private boolean distinct;
 
 	private static final HashSet DONT_SPACE_TOKENS = new HashSet();
 	static {
 		//dontSpace.add("'");
 		DONT_SPACE_TOKENS.add(".");
 		DONT_SPACE_TOKENS.add("+");
 		DONT_SPACE_TOKENS.add("-");
 		DONT_SPACE_TOKENS.add("/");
 		DONT_SPACE_TOKENS.add("*");
 		DONT_SPACE_TOKENS.add("<");
 		DONT_SPACE_TOKENS.add(">");
 		DONT_SPACE_TOKENS.add("=");
 		DONT_SPACE_TOKENS.add("#");
 		DONT_SPACE_TOKENS.add("~");
 		DONT_SPACE_TOKENS.add("|");
 		DONT_SPACE_TOKENS.add("&");
 		DONT_SPACE_TOKENS.add("<=");
 		DONT_SPACE_TOKENS.add(">=");
 		DONT_SPACE_TOKENS.add("=>");
 		DONT_SPACE_TOKENS.add("=<");
 		DONT_SPACE_TOKENS.add("!=");
 		DONT_SPACE_TOKENS.add("<>");
 		DONT_SPACE_TOKENS.add("!#");
 		DONT_SPACE_TOKENS.add("!~");
 		DONT_SPACE_TOKENS.add("!<");
 		DONT_SPACE_TOKENS.add("!>");
 		DONT_SPACE_TOKENS.add("("); //for MySQL
 		DONT_SPACE_TOKENS.add(")");
 	}
 
 	public QuerySelect(Dialect dialect) {
 		this.dialect = dialect;
 		joins = new QueryJoinFragment(dialect, false);
 	}
 
 	public JoinFragment getJoinFragment() {
 		return joins;
 	}
 
 	public void addSelectFragmentString(String fragment) {
 		if ( fragment.length()>0 && fragment.charAt(0)==',' ) fragment = fragment.substring(1);
 		fragment = fragment.trim();
 		if ( fragment.length()>0 ) {
 			if ( select.length()>0 ) select.append(", ");
 			select.append(fragment);
 		}
 	}
 
 	public void addSelectColumn(String columnName, String alias) {
 		addSelectFragmentString(columnName + ' ' + alias);
 	}
 
 	public void setDistinct(boolean distinct) {
 		this.distinct = distinct;
 	}
 
 	public void setWhereTokens(Iterator tokens) {
 		//if ( conjunctiveWhere.length()>0 ) conjunctiveWhere.append(" and ");
 		appendTokens(where, tokens);
 	}
 
 	public void prependWhereConditions(String conditions) {
 		if (where.length() > 0) {
 			where.insert(0, conditions + " and ");
 		}
 		else {
 			where.append(conditions);
 		}
 	}
 
 	public void setGroupByTokens(Iterator tokens) {
 		//if ( groupBy.length()>0 ) groupBy.append(" and ");
 		appendTokens(groupBy, tokens);
 	}
 
 	public void setOrderByTokens(Iterator tokens) {
 		//if ( orderBy.length()>0 ) orderBy.append(" and ");
 		appendTokens(orderBy, tokens);
 	}
 
 	public void setHavingTokens(Iterator tokens) {
 		//if ( having.length()>0 ) having.append(" and ");
 		appendTokens(having, tokens);
 	}
 
 	public void addOrderBy(String orderByString) {
 		if ( orderBy.length() > 0 ) orderBy.append(", ");
 		orderBy.append(orderByString);
 	}
 
 	public String toQueryString() {
 		StringBuilder buf = new StringBuilder(50);
 		if (comment!=null) buf.append("/* ").append(comment).append(" */ ");
 		buf.append("select ");
 		if (distinct) buf.append("distinct ");
 		String from = joins.toFromFragmentString();
 		if ( from.startsWith(",") ) {
 			from = from.substring(1);
 		}
 		else if ( from.startsWith(" inner join") ){
 			from = from.substring(11);
 		}
 
 		buf.append( select.toString() )
 			.append(" from")
 			.append(from);
 
 		String outerJoinsAfterWhere = joins.toWhereFragmentString().trim();
 		String whereConditions = where.toString().trim();
 		boolean hasOuterJoinsAfterWhere = outerJoinsAfterWhere.length() > 0;
 		boolean hasWhereConditions = whereConditions.length() > 0;
 		if (hasOuterJoinsAfterWhere || hasWhereConditions) {
 			buf.append(" where ");
 			if (hasOuterJoinsAfterWhere) {
 				buf.append( outerJoinsAfterWhere.substring(4) );
 			}
 			if (hasWhereConditions) {
 				if (hasOuterJoinsAfterWhere) {
 					buf.append(" and (");
 				}
 				buf.append(whereConditions);
 				if (hasOuterJoinsAfterWhere) {
 					buf.append(")");
 				}
 			}
 		}
 
 		if ( groupBy.length() > 0 ) buf.append(" group by ").append( groupBy.toString() );
 		if ( having.length() > 0 ) buf.append(" having ").append( having.toString() );
 		if ( orderBy.length() > 0 ) buf.append(" order by ").append( orderBy.toString() );
 
 		return dialect.transformSelectString( buf.toString() );
 	}
 
 	private static void appendTokens(StringBuilder buf, Iterator iter) {
 		boolean lastSpaceable=true;
 		boolean lastQuoted=false;
 		while ( iter.hasNext() ) {
 			String token = (String) iter.next();
 			boolean spaceable = !DONT_SPACE_TOKENS.contains(token);
 			boolean quoted = token.startsWith("'");
 			if (spaceable && lastSpaceable) {
 				if ( !quoted || !lastQuoted ) buf.append(' ');
 			}
 			lastSpaceable = spaceable;
 			buf.append(token);
 			lastQuoted = token.endsWith("'");
 		}
 	}
 
 	public void setComment(String comment) {
 		this.comment = comment;
 	}
 
 	public QuerySelect copy() {
 		QuerySelect copy = new QuerySelect(dialect);
 		copy.joins = this.joins.copy();
 		copy.select.append( this.select.toString() );
 		copy.where.append( this.where.toString() );
 		copy.groupBy.append( this.groupBy.toString() );
 		copy.orderBy.append( this.orderBy.toString() );
 		copy.having.append( this.having.toString() );
 		copy.comment = this.comment;
 		copy.distinct = this.distinct;
 		return copy;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/sql/SelectFragment.java b/hibernate-core/src/main/java/org/hibernate/sql/SelectFragment.java
index a294e24ef5..9b9393a651 100644
--- a/hibernate-core/src/main/java/org/hibernate/sql/SelectFragment.java
+++ b/hibernate-core/src/main/java/org/hibernate/sql/SelectFragment.java
@@ -1,169 +1,169 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.sql;
 
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 
 import org.hibernate.internal.util.StringHelper;
 
 /**
  * A fragment of an SQL <tt>SELECT</tt> clause
  *
  * @author Gavin King
  */
 public class SelectFragment {
 	private String suffix;
 	private List columns = new ArrayList();
 	//private List aliases = new ArrayList();
 	private List columnAliases = new ArrayList();
 	private String extraSelectList;
 	private String[] usedAliases;
 
 	public SelectFragment() {}
 
 	public List getColumns() {
 		return columns;
 	}
 
 	public String getExtraSelectList() {
 		return extraSelectList;
 	}
 
 	public SelectFragment setUsedAliases(String[] aliases) {
 		usedAliases = aliases;
 		return this;
 	}
 
 	public SelectFragment setExtraSelectList(String extraSelectList) {
 		this.extraSelectList = extraSelectList;
 		return this;
 	}
 
 	public SelectFragment setExtraSelectList(CaseFragment caseFragment, String fragmentAlias) {
 		setExtraSelectList( caseFragment.setReturnColumnName(fragmentAlias, suffix).toFragmentString() );
 		return this;
 	}
 
 	public SelectFragment setSuffix(String suffix) {
 		this.suffix = suffix;
 		return this;
 	}
 
 	public SelectFragment addColumn(String columnName) {
 		addColumn(null, columnName);
 		return this;
 	}
 
 	public SelectFragment addColumns(String[] columnNames) {
 		for (int i=0; i<columnNames.length; i++) addColumn( columnNames[i] );
 		return this;
 	}
 
 	public SelectFragment addColumn(String tableAlias, String columnName) {
 		return addColumn(tableAlias, columnName, columnName);
 	}
 
 	public SelectFragment addColumn(String tableAlias, String columnName, String columnAlias) {
 		columns.add( StringHelper.qualify(tableAlias, columnName) );
 		//columns.add(columnName);
 		//aliases.add(tableAlias);
 		columnAliases.add(columnAlias);
 		return this;
 	}
 
 	public SelectFragment addColumns(String tableAlias, String[] columnNames) {
 		for (int i=0; i<columnNames.length; i++) addColumn( tableAlias, columnNames[i] );
 		return this;
 	}
 
 	public SelectFragment addColumns(String tableAlias, String[] columnNames, String[] columnAliases) {
 		for (int i=0; i<columnNames.length; i++) {
 			if ( columnNames[i]!=null ) addColumn( tableAlias, columnNames[i], columnAliases[i] );
 		}
 		return this;
 	}
 
 	public SelectFragment addFormulas(String tableAlias, String[] formulas, String[] formulaAliases) {
 		for ( int i=0; i<formulas.length; i++ ) {
 			if ( formulas[i]!=null ) addFormula( tableAlias, formulas[i], formulaAliases[i] );
 		}
 		return this;
 	}
 
 	public SelectFragment addFormula(String tableAlias, String formula, String formulaAlias) {
 		columns.add( StringHelper.replace( formula, Template.TEMPLATE, tableAlias ) );
 		columnAliases.add(formulaAlias);
 		return this;
 	}
 
 	public SelectFragment addColumnTemplate(String tableAlias, String columnTemplate, String columnAlias) {
 		// In this context, there's no difference between a column template and a formula.
 		return addFormula( tableAlias, columnTemplate, columnAlias );
 	}
 
-	public SelectFragment addColumnTemplates(String tableAlias, String[] columnTemplates, String columnAliases[]) {
+	public SelectFragment addColumnTemplates(String tableAlias, String[] columnTemplates, String[] columnAliases) {
 		// In this context, there's no difference between a column template and a formula.
 		return addFormulas( tableAlias, columnTemplates, columnAliases );
 	}
 
 	public String toFragmentString() {
 		StringBuilder buf = new StringBuilder( columns.size() * 10 );
 		Iterator iter = columns.iterator();
 		Iterator columnAliasIter = columnAliases.iterator();
 		//HashMap columnsUnique = new HashMap();
 		HashSet columnsUnique = new HashSet();
 		if (usedAliases!=null) columnsUnique.addAll( Arrays.asList(usedAliases) );
 		while ( iter.hasNext() ) {
 			String column = (String) iter.next();
 			String columnAlias = (String) columnAliasIter.next();
 			//TODO: eventually put this back in, once we think all is fixed
 			//Object otherAlias = columnsUnique.put(qualifiedColumn, columnAlias);
 			/*if ( otherAlias!=null && !columnAlias.equals(otherAlias) ) {
 				throw new AssertionFailure("bug in Hibernate SQL alias generation");
 			}*/
 			if ( columnsUnique.add(columnAlias) ) {
 				buf.append(", ")
 					.append(column)
 					.append(" as ");
 				if (suffix==null) {
 					buf.append(columnAlias);
 				}
 				else {
 					buf.append( new Alias(suffix).toAliasString(columnAlias) );
 				}
 			}
 		}
 		if (extraSelectList!=null) {
 			buf.append(", ")
 				.append(extraSelectList);
 		}
 		return buf.toString();
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExport.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExport.java
index adada24997..fcb774973f 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExport.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExport.java
@@ -1,621 +1,621 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.io.BufferedReader;
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.io.Reader;
 import java.io.Writer;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.sql.SQLWarning;
 import java.sql.Statement;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Properties;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.internal.FormatStyle;
 import org.hibernate.engine.jdbc.internal.Formatter;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ConfigHelper;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.metamodel.source.MetadataImplementor;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.engine.config.spi.ConfigurationService;
 import org.hibernate.boot.registry.internal.StandardServiceRegistryImpl;
 import org.hibernate.engine.jdbc.connections.spi.ConnectionProvider;
 
 /**
  * Commandline tool to export table schema to the database. This class may also be called from inside an application.
  *
  * @author Daniel Bradby
  * @author Gavin King
  * @author Steve Ebersole
  */
 public class SchemaExport {
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SchemaExport.class.getName());
 	private static final String DEFAULT_IMPORT_FILE = "/import.sql";
 
 	public static enum Type {
 		CREATE,
 		DROP,
 		NONE,
 		BOTH;
 
 		public boolean doCreate() {
 			return this == BOTH || this == CREATE;
 		}
 
 		public boolean doDrop() {
 			return this == BOTH || this == DROP;
 		}
 	}
 
 	private final ConnectionHelper connectionHelper;
 	private final SqlStatementLogger sqlStatementLogger;
 	private final SqlExceptionHelper sqlExceptionHelper;
 	private final String[] dropSQL;
 	private final String[] createSQL;
 	private final String importFiles;
 
 	private final List<Exception> exceptions = new ArrayList<Exception>();
 
 	private Formatter formatter;
 	private ImportSqlCommandExtractor importSqlCommandExtractor = ImportSqlCommandExtractorInitiator.DEFAULT_EXTRACTOR;
 
-	private String outputFile = null;
+	private String outputFile;
 	private String delimiter;
-	private boolean haltOnError = false;
+	private boolean haltOnError;
 
 	public SchemaExport(ServiceRegistry serviceRegistry, Configuration configuration) {
 		this.connectionHelper = new SuppliedConnectionProviderConnectionHelper(
 				serviceRegistry.getService( ConnectionProvider.class )
 		);
 		this.sqlStatementLogger = serviceRegistry.getService( JdbcServices.class ).getSqlStatementLogger();
 		this.formatter = ( sqlStatementLogger.isFormat() ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
 		this.sqlExceptionHelper = serviceRegistry.getService( JdbcServices.class ).getSqlExceptionHelper();
 
 		this.importFiles = ConfigurationHelper.getString(
 				AvailableSettings.HBM2DDL_IMPORT_FILES,
 				configuration.getProperties(),
 				DEFAULT_IMPORT_FILE
 		);
 
 		final Dialect dialect = serviceRegistry.getService( JdbcServices.class ).getDialect();
 		this.dropSQL = configuration.generateDropSchemaScript( dialect );
 		this.createSQL = configuration.generateSchemaCreationScript( dialect );
 	}
 
 	public SchemaExport(MetadataImplementor metadata) {
 		ServiceRegistry serviceRegistry = metadata.getServiceRegistry();
 		this.connectionHelper = new SuppliedConnectionProviderConnectionHelper(
 				serviceRegistry.getService( ConnectionProvider.class )
 		);
         JdbcServices jdbcServices = serviceRegistry.getService( JdbcServices.class );
 		this.sqlStatementLogger = jdbcServices.getSqlStatementLogger();
 		this.formatter = ( sqlStatementLogger.isFormat() ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
 		this.sqlExceptionHelper = jdbcServices.getSqlExceptionHelper();
 
 		this.importFiles = ConfigurationHelper.getString(
 				AvailableSettings.HBM2DDL_IMPORT_FILES,
 				serviceRegistry.getService( ConfigurationService.class ).getSettings(),
 				DEFAULT_IMPORT_FILE
 		);
 
 		final Dialect dialect = jdbcServices.getDialect();
 		this.dropSQL = metadata.getDatabase().generateDropSchemaScript( dialect );
 		this.createSQL = metadata.getDatabase().generateSchemaCreationScript( dialect );
 	}
 
 	/**
 	 * Create a schema exporter for the given Configuration
 	 *
 	 * @param configuration The configuration from which to build a schema export.
 	 * @throws HibernateException Indicates problem preparing for schema export.
 	 */
 	public SchemaExport(Configuration configuration) {
 		this( configuration, configuration.getProperties() );
 	}
 
 	/**
 	 * Create a schema exporter for the given Configuration, with the given
 	 * database connection properties.
 	 *
 	 * @param configuration The configuration from which to build a schema export.
 	 * @param properties The properties from which to configure connectivity etc.
 	 * @throws HibernateException Indicates problem preparing for schema export.
 	 *
 	 * @deprecated properties may be specified via the Configuration object
 	 */
 	@Deprecated
     public SchemaExport(Configuration configuration, Properties properties) throws HibernateException {
 		final Dialect dialect = Dialect.getDialect( properties );
 
 		Properties props = new Properties();
 		props.putAll( dialect.getDefaultProperties() );
 		props.putAll( properties );
 		this.connectionHelper = new ManagedProviderConnectionHelper( props );
 
 		this.sqlStatementLogger = new SqlStatementLogger( false, true );
 		this.formatter = FormatStyle.DDL.getFormatter();
 		this.sqlExceptionHelper = new SqlExceptionHelper();
 
 		this.importFiles = ConfigurationHelper.getString(
 				AvailableSettings.HBM2DDL_IMPORT_FILES,
 				properties,
 				DEFAULT_IMPORT_FILE
 		);
 
 		this.dropSQL = configuration.generateDropSchemaScript( dialect );
 		this.createSQL = configuration.generateSchemaCreationScript( dialect );
 	}
 
 	/**
 	 * Create a schema exporter for the given Configuration, using the supplied connection for connectivity.
 	 *
 	 * @param configuration The configuration to use.
 	 * @param connection The JDBC connection to use.
 	 * @throws HibernateException Indicates problem preparing for schema export.
 	 */
 	public SchemaExport(Configuration configuration, Connection connection) throws HibernateException {
 		this.connectionHelper = new SuppliedConnectionHelper( connection );
 
 		this.sqlStatementLogger = new SqlStatementLogger( false, true );
 		this.formatter = FormatStyle.DDL.getFormatter();
 		this.sqlExceptionHelper = new SqlExceptionHelper();
 
 		this.importFiles = ConfigurationHelper.getString(
 				AvailableSettings.HBM2DDL_IMPORT_FILES,
 				configuration.getProperties(),
 				DEFAULT_IMPORT_FILE
 		);
 
 		final Dialect dialect = Dialect.getDialect( configuration.getProperties() );
 		this.dropSQL = configuration.generateDropSchemaScript( dialect );
 		this.createSQL = configuration.generateSchemaCreationScript( dialect );
 	}
 
 	public SchemaExport(
 			ConnectionHelper connectionHelper,
 			String[] dropSql,
 			String[] createSql) {
 		this.connectionHelper = connectionHelper;
 		this.dropSQL = dropSql;
 		this.createSQL = createSql;
 		this.importFiles = "";
 		this.sqlStatementLogger = new SqlStatementLogger( false, true );
 		this.sqlExceptionHelper = new SqlExceptionHelper();
 		this.formatter = FormatStyle.DDL.getFormatter();
 	}
 
 	/**
 	 * For generating a export script file, this is the file which will be written.
 	 *
 	 * @param filename The name of the file to which to write the export script.
 	 * @return this
 	 */
 	public SchemaExport setOutputFile(String filename) {
 		outputFile = filename;
 		return this;
 	}
 
 	/**
 	 * Set the end of statement delimiter
 	 *
 	 * @param delimiter The delimiter
 	 * @return this
 	 */
 	public SchemaExport setDelimiter(String delimiter) {
 		this.delimiter = delimiter;
 		return this;
 	}
 
 	/**
 	 * Should we format the sql strings?
 	 *
 	 * @param format Should we format SQL strings
 	 * @return this
 	 */
 	public SchemaExport setFormat(boolean format) {
 		this.formatter = ( format ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
 		return this;
 	}
 
 	/**
 	 * Set <i>import.sql</i> command extractor. By default {@link SingleLineSqlCommandExtractor} is used.
 	 *
 	 * @param importSqlCommandExtractor <i>import.sql</i> command extractor.
 	 * @return this
 	 */
 	public SchemaExport setImportSqlCommandExtractor(ImportSqlCommandExtractor importSqlCommandExtractor) {
 		this.importSqlCommandExtractor = importSqlCommandExtractor;
 		return this;
 	}
 
 	/**
 	 * Should we stop once an error occurs?
 	 *
 	 * @param haltOnError True if export should stop after error.
 	 * @return this
 	 */
 	public SchemaExport setHaltOnError(boolean haltOnError) {
 		this.haltOnError = haltOnError;
 		return this;
 	}
 
 	/**
 	 * Run the schema creation script; drop script is automatically
 	 * executed before running the creation script.
 	 *
 	 * @param script print the DDL to the console
 	 * @param export export the script to the database
 	 */
 	public void create(boolean script, boolean export) {
 		create( Target.interpret( script, export ) );
 	}
 
 	/**
 	 * Run the schema creation script; drop script is automatically
 	 * executed before running the creation script.
 	 *
 	 * @param output the target of the script.
 	 */
 	public void create(Target output) {
 		// need to drop tables before creating so need to specify Type.BOTH
 		execute( output, Type.BOTH );
 	}
 
 	/**
 	 * Run the drop schema script.
 	 *
 	 * @param script print the DDL to the console
 	 * @param export export the script to the database
 	 */
 	public void drop(boolean script, boolean export) {
 		drop( Target.interpret( script, export ) );
 	}
 
 	public void drop(Target output) {
 		execute( output, Type.DROP );
 	}
 
 	public void execute(boolean script, boolean export, boolean justDrop, boolean justCreate) {
 		execute( Target.interpret( script, export ), interpretType( justDrop, justCreate ) );
 	}
 
 	private Type interpretType(boolean justDrop, boolean justCreate) {
 		if ( justDrop ) {
 			return Type.DROP;
 		}
 		else if ( justCreate ) {
 			return Type.CREATE;
 		}
 		else {
 			return Type.BOTH;
 		}
 	}
 
 	public void execute(Target output, Type type) {
 		if ( (outputFile == null && output == Target.NONE) || type == SchemaExport.Type.NONE ) {
 			return;
 		}
 		exceptions.clear();
 
 		LOG.runningHbm2ddlSchemaExport();
 
 		final List<NamedReader> importFileReaders = new ArrayList<NamedReader>();
 		for ( String currentFile : importFiles.split(",") ) {
 			try {
 				final String resourceName = currentFile.trim();
 				InputStream stream = ConfigHelper.getResourceAsStream( resourceName );
 				importFileReaders.add( new NamedReader( resourceName, stream ) );
 			}
 			catch ( HibernateException e ) {
 				LOG.debugf("Import file not found: %s", currentFile);
 			}
 		}
 
 		final List<Exporter> exporters = new ArrayList<Exporter>();
 		try {
 			// prepare exporters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 			if ( output.doScript() ) {
 				exporters.add( new ScriptExporter() );
 			}
 			if ( outputFile != null ) {
 				exporters.add( new FileExporter( outputFile ) );
 			}
 			if ( output.doExport() ) {
 				exporters.add( new DatabaseExporter( connectionHelper, sqlExceptionHelper ) );
 			}
 
 			// perform exporters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 			if ( type.doDrop() ) {
 				perform( dropSQL, exporters );
 			}
 			if ( type.doCreate() ) {
 				perform( createSQL, exporters );
 				if ( ! importFileReaders.isEmpty() ) {
 					for ( NamedReader namedReader : importFileReaders ) {
 						importScript( namedReader, exporters );
 					}
 				}
 			}
 		}
 		catch (Exception e) {
 			exceptions.add( e );
 			LOG.schemaExportUnsuccessful( e );
 		}
 		finally {
 			// release exporters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 			for ( Exporter exporter : exporters ) {
 				try {
 					exporter.release();
 				}
 				catch (Exception ignore) {
 				}
 			}
 
 			// release the named readers from import scripts
 			for ( NamedReader namedReader : importFileReaders ) {
 				try {
 					namedReader.getReader().close();
 				}
 				catch (Exception ignore) {
 				}
 			}
             LOG.schemaExportComplete();
 		}
 	}
 
 	private void perform(String[] sqlCommands, List<Exporter> exporters) {
 		for ( String sqlCommand : sqlCommands ) {
 			String formatted = formatter.format( sqlCommand );
 	        if ( delimiter != null ) {
 				formatted += delimiter;
 			}
 			sqlStatementLogger.logStatement( sqlCommand, formatter );
 			for ( Exporter exporter : exporters ) {
 				try {
 					exporter.export( formatted );
 				}
 				catch (Exception e) {
 					if ( haltOnError ) {
 						throw new HibernateException( "Error during DDL export", e );
 					}
 					exceptions.add( e );
 					LOG.unsuccessfulCreate( sqlCommand );
 					LOG.error( e.getMessage() );
 				}
 			}
 		}
 	}
 
 	private void importScript(NamedReader namedReader, List<Exporter> exporters) throws Exception {
 		BufferedReader reader = new BufferedReader( namedReader.getReader() );
 		String[] statements = importSqlCommandExtractor.extractCommands( reader );
 		if (statements != null) {
 			for ( String statement : statements ) {
 				if ( statement != null ) {
 					String trimmedSql = statement.trim();
 					if ( trimmedSql.endsWith( ";" )) {
 						trimmedSql = trimmedSql.substring( 0, statement.length() - 1 );
 					}
 					if ( !StringHelper.isEmpty( trimmedSql ) ) {
 						try {
 							for ( Exporter exporter : exporters ) {
 								if ( exporter.acceptsImportScripts() ) {
 									exporter.export( trimmedSql );
 								}
 							}
 						}
 						catch ( Exception e ) {
 							throw new ImportScriptException( "Error during statement execution (file: '" + namedReader.getName() + "'): " + trimmedSql, e );
 						}
 					}
 				}
 			}
 		}
 	}
 
 	private static class NamedReader {
 		private final Reader reader;
 		private final String name;
 
 		public NamedReader(String name, InputStream stream) {
 			this.name = name;
 			this.reader = new InputStreamReader( stream );
 		}
 
 		public Reader getReader() {
 			return reader;
 		}
 
 		public String getName() {
 			return name;
 		}
 	}
 
 	private void execute(boolean script, boolean export, Writer fileOutput, Statement statement, final String sql)
 			throws IOException, SQLException {
 		final SqlExceptionHelper sqlExceptionHelper = new SqlExceptionHelper();
 
 		String formatted = formatter.format( sql );
         if (delimiter != null) formatted += delimiter;
         if (script) System.out.println(formatted);
         LOG.debug(formatted);
 		if ( outputFile != null ) {
 			fileOutput.write( formatted + "\n" );
 		}
 		if ( export ) {
 
 			statement.executeUpdate( sql );
 			try {
 				SQLWarning warnings = statement.getWarnings();
 				if ( warnings != null) {
 					sqlExceptionHelper.logAndClearWarnings( connectionHelper.getConnection() );
 				}
 			}
 			catch( SQLException sqle ) {
                 LOG.unableToLogSqlWarnings(sqle);
 			}
 		}
 
 	}
 
 	private static StandardServiceRegistryImpl createServiceRegistry(Properties properties) {
 		Environment.verifyProperties( properties );
 		ConfigurationHelper.resolvePlaceHolders( properties );
 		return (StandardServiceRegistryImpl) new StandardServiceRegistryBuilder().applySettings( properties ).build();
 	}
 
 	public static void main(String[] args) {
 		try {
 			Configuration cfg = new Configuration();
 
 			boolean script = true;
 			boolean drop = false;
 			boolean create = false;
 			boolean halt = false;
 			boolean export = true;
 			String outFile = null;
 			String importFile = DEFAULT_IMPORT_FILE;
 			String propFile = null;
 			boolean format = false;
 			String delim = null;
 
 			for ( int i = 0; i < args.length; i++ ) {
 				if ( args[i].startsWith( "--" ) ) {
 					if ( args[i].equals( "--quiet" ) ) {
 						script = false;
 					}
 					else if ( args[i].equals( "--drop" ) ) {
 						drop = true;
 					}
 					else if ( args[i].equals( "--create" ) ) {
 						create = true;
 					}
 					else if ( args[i].equals( "--haltonerror" ) ) {
 						halt = true;
 					}
 					else if ( args[i].equals( "--text" ) ) {
 						export = false;
 					}
 					else if ( args[i].startsWith( "--output=" ) ) {
 						outFile = args[i].substring( 9 );
 					}
 					else if ( args[i].startsWith( "--import=" ) ) {
 						importFile = args[i].substring( 9 );
 					}
 					else if ( args[i].startsWith( "--properties=" ) ) {
 						propFile = args[i].substring( 13 );
 					}
 					else if ( args[i].equals( "--format" ) ) {
 						format = true;
 					}
 					else if ( args[i].startsWith( "--delimiter=" ) ) {
 						delim = args[i].substring( 12 );
 					}
 					else if ( args[i].startsWith( "--config=" ) ) {
 						cfg.configure( args[i].substring( 9 ) );
 					}
 					else if ( args[i].startsWith( "--naming=" ) ) {
 						cfg.setNamingStrategy(
 								( NamingStrategy ) ReflectHelper.classForName( args[i].substring( 9 ) )
 										.newInstance()
 						);
 					}
 				}
 				else {
 					String filename = args[i];
 					if ( filename.endsWith( ".jar" ) ) {
 						cfg.addJar( new File( filename ) );
 					}
 					else {
 						cfg.addFile( filename );
 					}
 				}
 
 			}
 
 			if ( propFile != null ) {
 				Properties props = new Properties();
 				props.putAll( cfg.getProperties() );
 				props.load( new FileInputStream( propFile ) );
 				cfg.setProperties( props );
 			}
 
 			if (importFile != null) {
 				cfg.setProperty( AvailableSettings.HBM2DDL_IMPORT_FILES, importFile );
 			}
 
 			StandardServiceRegistryImpl serviceRegistry = createServiceRegistry( cfg.getProperties() );
 			try {
 				SchemaExport se = new SchemaExport( serviceRegistry, cfg )
 						.setHaltOnError( halt )
 						.setOutputFile( outFile )
 						.setDelimiter( delim )
 						.setImportSqlCommandExtractor( serviceRegistry.getService( ImportSqlCommandExtractor.class ) );
 				if ( format ) {
 					se.setFormat( true );
 				}
 				se.execute( script, export, drop, create );
 			}
 			finally {
 				serviceRegistry.destroy();
 			}
 		}
 		catch ( Exception e ) {
             LOG.unableToCreateSchema(e);
 			e.printStackTrace();
 		}
 	}
 
 	/**
 	 * Returns a List of all Exceptions which occured during the export.
 	 *
 	 * @return A List containig the Exceptions occured during the export
 	 */
 	public List getExceptions() {
 		return exceptions;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExportTask.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExportTask.java
index 7722c2c388..8dc6d49217 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExportTask.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaExportTask.java
@@ -1,256 +1,256 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.util.Iterator;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Properties;
 
 import org.apache.tools.ant.BuildException;
 import org.apache.tools.ant.DirectoryScanner;
 import org.apache.tools.ant.Project;
 import org.apache.tools.ant.taskdefs.MatchingTask;
 import org.apache.tools.ant.types.FileSet;
 
 import org.hibernate.HibernateException;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 
 /**
  * An Ant task for <tt>SchemaExport</tt>.
  *
  * <pre>
  * &lt;taskdef name="schemaexport"
  *     classname="org.hibernate.tool.hbm2ddl.SchemaExportTask"
  *     classpathref="class.path"/&gt;
  *
  * &lt;schemaexport
  *     properties="${build.classes.dir}/hibernate.properties"
  *     quiet="no"
  *     text="no"
  *     drop="no"
  *     delimiter=";"
  *     output="${build.dir}/schema-export.sql"&gt;
  *     &lt;fileset dir="${build.classes.dir}"&gt;
  *         &lt;include name="*.hbm.xml"/&gt;
  *     &lt;/fileset&gt;
  * &lt;/schemaexport&gt;
  * </pre>
  *
  * @see SchemaExport
  * @author Rong C Ou
  */
 public class SchemaExportTask extends MatchingTask {
 
 	private List fileSets = new LinkedList();
-	private File propertiesFile = null;
-	private File configurationFile = null;
-	private File outputFile = null;
-	private boolean quiet = false;
-	private boolean text = false;
-	private boolean drop = false;
-	private boolean create = false;
-	private boolean haltOnError = false;
-	private String delimiter = null;
-	private String namingStrategy = null;
+	private File propertiesFile;
+	private File configurationFile;
+	private File outputFile;
+	private boolean quiet;
+	private boolean text;
+	private boolean drop;
+	private boolean create;
+	private boolean haltOnError;
+	private String delimiter;
+	private String namingStrategy;
 
 	public void addFileset(FileSet set) {
 		fileSets.add(set);
 	}
 
 	/**
 	 * Set a properties file
 	 * @param propertiesFile the properties file name
 	 */
 	public void setProperties(File propertiesFile) {
 		if ( !propertiesFile.exists() ) {
 			throw new BuildException("Properties file: " + propertiesFile + " does not exist.");
 	}
 
 		log("Using properties file " + propertiesFile, Project.MSG_DEBUG);
 		this.propertiesFile = propertiesFile;
 	}
 
 	/**
 	 * Set a <literal>.cfg.xml</literal> file, which will be
 	 * loaded as a resource, from the classpath
 	 * @param configurationFile the path to the resource
 	 */
 	public void setConfig(File configurationFile) {
 		this.configurationFile = configurationFile;
 	}
 
 	/**
 	 * Enable "quiet" mode. The schema will not be
 	 * written to standard out.
 	 * @param quiet true to enable quiet mode
 	 */
 	public void setQuiet(boolean quiet) {
 		this.quiet = quiet;
 	}
 
 	/**
 	 * Enable "text-only" mode. The schema will not
 	 * be exported to the database.
 	 * @param text true to enable text-only mode
 	 */
 	public void setText(boolean text) {
 		this.text = text;
 	}
 
 	/**
 	 * Enable "drop" mode. Database objects will be
 	 * dropped but not recreated.
 	 * @param drop true to enable drop mode
 	 */
 	public void setDrop(boolean drop) {
 		this.drop = drop;
 	}
 
 	/**
 	 * Enable "create" mode. Database objects will be
 	 * created but not first dropped.
 	 * @param create true to enable create mode
 	 */
 	public void setCreate(boolean create) {
 		this.create = create;
 	}
 
 	/**
 	 * Set the end of statement delimiter for the generated script
 	 * @param delimiter the delimiter
 	 */
 	public void setDelimiter(String delimiter) {
 		this.delimiter = delimiter;
 	}
 
 	/**
 	 * Set the script output file
 	 * @param outputFile the file name
 	 */
 	public void setOutput(File outputFile) {
 		this.outputFile = outputFile;
 	}
 
 	/**
 	 * Execute the task
 	 */
 	@Override
     public void execute() throws BuildException {
 		try {
 			getSchemaExport( getConfiguration() ).execute(!quiet, !text, drop, create);
 		}
 		catch (HibernateException e) {
 			throw new BuildException("Schema text failed: " + e.getMessage(), e);
 		}
 		catch (FileNotFoundException e) {
 			throw new BuildException("File not found: " + e.getMessage(), e);
 		}
 		catch (IOException e) {
 			throw new BuildException("IOException : " + e.getMessage(), e);
 		}
 		catch (Exception e) {
 			throw new BuildException(e);
 		}
 	}
 
 	private String[] getFiles() {
 
 		List files = new LinkedList();
 		for ( Iterator i = fileSets.iterator(); i.hasNext(); ) {
 
 			FileSet fs = (FileSet) i.next();
 			DirectoryScanner ds = fs.getDirectoryScanner( getProject() );
 
 			String[] dsFiles = ds.getIncludedFiles();
 			for (int j = 0; j < dsFiles.length; j++) {
 				File f = new File(dsFiles[j]);
 				if ( !f.isFile() ) {
 					f = new File( ds.getBasedir(), dsFiles[j] );
 				}
 
 				files.add( f.getAbsolutePath() );
 			}
 		}
 
 		return ArrayHelper.toStringArray(files);
 	}
 
 	private Configuration getConfiguration() throws Exception {
 		Configuration cfg = new Configuration();
 		if (namingStrategy!=null) {
 			cfg.setNamingStrategy(
 					(NamingStrategy) ReflectHelper.classForName(namingStrategy).newInstance()
 				);
 		}
 		if (configurationFile != null) {
 			cfg.configure( configurationFile );
 		}
 
 		String[] files = getFiles();
 		for (int i = 0; i < files.length; i++) {
 			String filename = files[i];
 			if ( filename.endsWith(".jar") ) {
 				cfg.addJar( new File(filename) );
 			}
 			else {
 				cfg.addFile(filename);
 			}
 		}
 		return cfg;
 	}
 
 	private SchemaExport getSchemaExport(Configuration cfg) throws HibernateException, IOException {
 		Properties properties = new Properties();
 		properties.putAll( cfg.getProperties() );
 		if (propertiesFile == null) {
 			properties.putAll( getProject().getProperties() );
 		}
 		else {
 			properties.load( new FileInputStream(propertiesFile) );
 		}
 		cfg.setProperties(properties);
 		return new SchemaExport(cfg)
 				.setHaltOnError(haltOnError)
 				.setOutputFile( outputFile.getPath() )
 				.setDelimiter(delimiter);
 	}
 
 	public void setNamingStrategy(String namingStrategy) {
 		this.namingStrategy = namingStrategy;
 	}
 
 	public void setHaltonerror(boolean haltOnError) {
 		this.haltOnError = haltOnError;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdate.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdate.java
index 77ffcc67b6..5067753312 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdate.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdate.java
@@ -1,297 +1,297 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008-2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.io.FileInputStream;
 import java.io.FileWriter;
 import java.io.Writer;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Properties;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
 import org.hibernate.JDBCException;
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.jdbc.internal.FormatStyle;
 import org.hibernate.engine.jdbc.internal.Formatter;
 import org.hibernate.engine.jdbc.spi.JdbcServices;
 import org.hibernate.engine.jdbc.spi.SqlExceptionHelper;
 import org.hibernate.engine.jdbc.spi.SqlStatementLogger;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.config.ConfigurationHelper;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.boot.registry.internal.StandardServiceRegistryImpl;
 
 /**
  * A commandline tool to update a database schema. May also be called from inside an application.
  *
  * @author Christoph Sturm
  * @author Steve Ebersole
  */
 public class SchemaUpdate {
     private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, SchemaUpdate.class.getName());
 
 	private final Configuration configuration;
 	private final ConnectionHelper connectionHelper;
 	private final SqlStatementLogger sqlStatementLogger;
 	private final SqlExceptionHelper sqlExceptionHelper;
 	private final Dialect dialect;
 
 	private final List<Exception> exceptions = new ArrayList<Exception>();
 
 	private Formatter formatter;
 
-	private boolean haltOnError = false;
+	private boolean haltOnError;
 	private boolean format = true;
-	private String outputFile = null;
+	private String outputFile;
 	private String delimiter;
 
 	public SchemaUpdate(Configuration cfg) throws HibernateException {
 		this( cfg, cfg.getProperties() );
 	}
 
 	public SchemaUpdate(Configuration configuration, Properties properties) throws HibernateException {
 		this.configuration = configuration;
 		this.dialect = Dialect.getDialect( properties );
 
 		Properties props = new Properties();
 		props.putAll( dialect.getDefaultProperties() );
 		props.putAll( properties );
 		this.connectionHelper = new ManagedProviderConnectionHelper( props );
 
 		this.sqlExceptionHelper = new SqlExceptionHelper();
 		this.sqlStatementLogger = new SqlStatementLogger( false, true );
 		this.formatter = FormatStyle.DDL.getFormatter();
 	}
 
 	public SchemaUpdate(ServiceRegistry serviceRegistry, Configuration cfg) throws HibernateException {
 		this.configuration = cfg;
 
 		final JdbcServices jdbcServices = serviceRegistry.getService( JdbcServices.class );
 		this.dialect = jdbcServices.getDialect();
 		this.connectionHelper = new SuppliedConnectionProviderConnectionHelper( jdbcServices.getConnectionProvider() );
 
 		this.sqlExceptionHelper = new SqlExceptionHelper();
 		this.sqlStatementLogger = jdbcServices.getSqlStatementLogger();
 		this.formatter = ( sqlStatementLogger.isFormat() ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
 	}
 
 	private static StandardServiceRegistryImpl createServiceRegistry(Properties properties) {
 		Environment.verifyProperties( properties );
 		ConfigurationHelper.resolvePlaceHolders( properties );
 		return (StandardServiceRegistryImpl) new StandardServiceRegistryBuilder().applySettings( properties ).build();
 	}
 
 	public static void main(String[] args) {
 		try {
 			Configuration cfg = new Configuration();
 
 			boolean script = true;
 			// If true then execute db updates, otherwise just generate and display updates
 			boolean doUpdate = true;
 			String propFile = null;
 
 			for ( int i = 0; i < args.length; i++ ) {
 				if ( args[i].startsWith( "--" ) ) {
 					if ( args[i].equals( "--quiet" ) ) {
 						script = false;
 					}
 					else if ( args[i].startsWith( "--properties=" ) ) {
 						propFile = args[i].substring( 13 );
 					}
 					else if ( args[i].startsWith( "--config=" ) ) {
 						cfg.configure( args[i].substring( 9 ) );
 					}
 					else if ( args[i].startsWith( "--text" ) ) {
 						doUpdate = false;
 					}
 					else if ( args[i].startsWith( "--naming=" ) ) {
 						cfg.setNamingStrategy(
 								( NamingStrategy ) ReflectHelper.classForName( args[i].substring( 9 ) ).newInstance()
 						);
 					}
 				}
 				else {
 					cfg.addFile( args[i] );
 				}
 
 			}
 
 			if ( propFile != null ) {
 				Properties props = new Properties();
 				props.putAll( cfg.getProperties() );
 				props.load( new FileInputStream( propFile ) );
 				cfg.setProperties( props );
 			}
 
 			StandardServiceRegistryImpl serviceRegistry = createServiceRegistry( cfg.getProperties() );
 			try {
 				new SchemaUpdate( serviceRegistry, cfg ).execute( script, doUpdate );
 			}
 			finally {
 				serviceRegistry.destroy();
 			}
 		}
 		catch ( Exception e ) {
             LOG.unableToRunSchemaUpdate(e);
 			e.printStackTrace();
 		}
 	}
 
 	/**
 	 * Execute the schema updates
 	 *
 	 * @param script print all DDL to the console
 	 */
 	public void execute(boolean script, boolean doUpdate) {
 		execute( Target.interpret( script, doUpdate ) );
 	}
 	
 	public void execute(Target target) {
         LOG.runningHbm2ddlSchemaUpdate();
 
 		Connection connection = null;
 		Statement stmt = null;
 		Writer outputFileWriter = null;
 
 		exceptions.clear();
 
 		try {
 			DatabaseMetadata meta;
 			try {
                 LOG.fetchingDatabaseMetadata();
 				connectionHelper.prepare( true );
 				connection = connectionHelper.getConnection();
 				meta = new DatabaseMetadata( connection, dialect, configuration );
 				stmt = connection.createStatement();
 			}
 			catch ( SQLException sqle ) {
 				exceptions.add( sqle );
                 LOG.unableToGetDatabaseMetadata(sqle);
 				throw sqle;
 			}
 
             LOG.updatingSchema();
 
 			if ( outputFile != null ) {
                 LOG.writingGeneratedSchemaToFile( outputFile );
 				outputFileWriter = new FileWriter( outputFile );
 			}
 
 			List<SchemaUpdateScript> scripts = configuration.generateSchemaUpdateScriptList( dialect, meta );
 			for ( SchemaUpdateScript script : scripts ) {
 				String formatted = formatter.format( script.getScript() );
 				try {
 					if ( delimiter != null ) {
 						formatted += delimiter;
 					}
 					if ( target.doScript() ) {
 						System.out.println( formatted );
 					}
 					if ( outputFile != null ) {
 						outputFileWriter.write( formatted + "\n" );
 					}
 					if ( target.doExport() ) {
                         LOG.debug( script.getScript() );
 						stmt.executeUpdate( formatted );
 					}
 				}
 				catch ( SQLException e ) {
 					if (!script.isQuiet()) {
 						if ( haltOnError ) {
 							throw new JDBCException( "Error during DDL export", e );
 						}
 						exceptions.add( e );
 	                    LOG.unsuccessful(script.getScript());
 	                    LOG.error(e.getMessage());
 					}
 				}
 			}
 
             LOG.schemaUpdateComplete();
 
 		}
 		catch ( Exception e ) {
 			exceptions.add( e );
             LOG.unableToCompleteSchemaUpdate(e);
 		}
 		finally {
 
 			try {
 				if ( stmt != null ) {
 					stmt.close();
 				}
 				connectionHelper.release();
 			}
 			catch ( Exception e ) {
 				exceptions.add( e );
                 LOG.unableToCloseConnection(e);
 			}
 			try {
 				if( outputFileWriter != null ) {
 					outputFileWriter.close();
 				}
 			}
 			catch(Exception e) {
 				exceptions.add(e);
                 LOG.unableToCloseConnection(e);
 			}
 		}
 	}
 
 	/**
 	 * Returns a List of all Exceptions which occured during the export.
 	 *
 	 * @return A List containig the Exceptions occured during the export
 	 */
 	public List getExceptions() {
 		return exceptions;
 	}
 
 	public void setHaltOnError(boolean haltOnError) {
 		this.haltOnError = haltOnError;
 	}
 
 	public void setFormat(boolean format) {
 		this.formatter = ( format ? FormatStyle.DDL : FormatStyle.NONE ).getFormatter();
 	}
 
 	public void setOutputFile(String outputFile) {
 		this.outputFile = outputFile;
 	}
 
 	public void setDelimiter(String delimiter) {
 		this.delimiter = delimiter;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdateTask.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdateTask.java
index 72e44ea351..d1e67fc2b8 100644
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdateTask.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaUpdateTask.java
@@ -1,240 +1,240 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.util.Iterator;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Properties;
 
 import org.apache.tools.ant.BuildException;
 import org.apache.tools.ant.DirectoryScanner;
 import org.apache.tools.ant.Project;
 import org.apache.tools.ant.taskdefs.MatchingTask;
 import org.apache.tools.ant.types.FileSet;
 
 import org.hibernate.HibernateException;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 
 /**
  * An Ant task for <tt>SchemaUpdate</tt>.
  *
  * <pre>
  * &lt;taskdef name="schemaupdate"
  *     classname="org.hibernate.tool.hbm2ddl.SchemaUpdateTask"
  *     classpathref="class.path"/&gt;
  *
  * &lt;schemaupdate
  *     properties="${build.classes.dir}/hibernate.properties"
  *     quiet="no"
  *     &lt;fileset dir="${build.classes.dir}"&gt;
  *         &lt;include name="*.hbm.xml"/&gt;
  *     &lt;/fileset&gt;
  * &lt;/schemaupdate&gt;
  * </pre>
  *
  * @see SchemaUpdate
  * @author Rong C Ou, Gavin King
  */
 public class SchemaUpdateTask extends MatchingTask {
 
 	private List fileSets = new LinkedList();
-	private File propertiesFile = null;
-	private File configurationFile = null;
-	private File outputFile = null;
-	private boolean quiet = false;
+	private File propertiesFile;
+	private File configurationFile;
+	private File outputFile;
+	private boolean quiet;
 	private boolean text = true;
-	private boolean haltOnError = false;
-	private String delimiter = null;
-	private String namingStrategy = null;
+	private boolean haltOnError;
+	private String delimiter;
+	private String namingStrategy;
 	
 
 	public void addFileset(FileSet set) {
 		fileSets.add(set);
 	}
 
 	/**
 	 * Set a properties file
 	 * @param propertiesFile the properties file name
 	 */
 	public void setProperties(File propertiesFile) {
 		if ( !propertiesFile.exists() ) {
 			throw new BuildException("Properties file: " + propertiesFile + " does not exist.");
 		}
 
 		log("Using properties file " + propertiesFile, Project.MSG_DEBUG);
 		this.propertiesFile = propertiesFile;
 	}
 
 	/**
 	 * Set a <literal>.cfg.xml</literal> file
 	 * @param configurationFile the file name
 	 */
 	public void setConfig(File configurationFile) {
 		this.configurationFile = configurationFile;
 	}
 
 	/**
      * Enable "text-only" mode. The schema will not
 	 * be updated in the database.
 	 * @param text true to enable text-only mode
      */
     public void setText(boolean text) {
         this.text = text;
     }
 
 	/**
 	 * Enable "quiet" mode. The schema will not be
 	 * written to standard out.
 	 * @param quiet true to enable quiet mode
 	 */
 	public void setQuiet(boolean quiet) {
 		this.quiet = quiet;
 	}
 
 	/**
 	 * Execute the task
 	 */
 	@Override
     public void execute() throws BuildException {
 		try {
 			log("Running Hibernate Core SchemaUpdate."); 
 			log("This is an Ant task supporting only mapping files, if you want to use annotations see http://tools.hibernate.org.");
 			Configuration cfg = getConfiguration();
 			getSchemaUpdate(cfg).execute(!quiet, !text);
 		}
 		catch (HibernateException e) {
 			throw new BuildException("Schema text failed: " + e.getMessage(), e);
 		}
 		catch (FileNotFoundException e) {
 			throw new BuildException("File not found: " + e.getMessage(), e);
 		}
 		catch (IOException e) {
 			throw new BuildException("IOException : " + e.getMessage(), e);
 		}
 		catch (Exception e) {
 			throw new BuildException(e);
 		}
 	}
 
 	private String[] getFiles() {
 
 		List files = new LinkedList();
 		for ( Iterator i = fileSets.iterator(); i.hasNext(); ) {
 
 			FileSet fs = (FileSet) i.next();
 			DirectoryScanner ds = fs.getDirectoryScanner( getProject() );
 
 			String[] dsFiles = ds.getIncludedFiles();
 			for (int j = 0; j < dsFiles.length; j++) {
 				File f = new File(dsFiles[j]);
 				if ( !f.isFile() ) {
 					f = new File( ds.getBasedir(), dsFiles[j] );
 				}
 
 				files.add( f.getAbsolutePath() );
 			}
 		}
 
 		return ArrayHelper.toStringArray( files );
 	}
 
 	private Configuration getConfiguration() throws Exception {
 		Configuration cfg = new Configuration();
 		if (namingStrategy!=null) {
 			cfg.setNamingStrategy(
 					(NamingStrategy) ReflectHelper.classForName( namingStrategy ).newInstance()
 				);
 		}
 		if (configurationFile!=null) {
 			cfg.configure( configurationFile );
 		}
 
 		String[] files = getFiles();
 		for (int i = 0; i < files.length; i++) {
 			String filename = files[i];
 			if ( filename.endsWith(".jar") ) {
 				cfg.addJar( new File(filename) );
 			}
 			else {
 				cfg.addFile(filename);
 			}
 		}
 		return cfg;
 	}
 
 	private SchemaUpdate getSchemaUpdate(Configuration cfg) throws HibernateException, IOException {
 		Properties properties = new Properties();
 		properties.putAll( cfg.getProperties() );
 		if (propertiesFile == null) {
 			properties.putAll( getProject().getProperties() );
 		}
 		else {
 			properties.load( new FileInputStream(propertiesFile) );
 		}
 		cfg.setProperties(properties);
 		SchemaUpdate su = new SchemaUpdate(cfg);
 		su.setOutputFile( outputFile.getPath() );
 		su.setDelimiter(delimiter);
 		su.setHaltOnError(haltOnError);
 		return su;
 	}
 
 	public void setNamingStrategy(String namingStrategy) {
 		this.namingStrategy = namingStrategy;
 	}
 
 	public File getOutputFile() {
 		return outputFile;
 	}
 
 	public void setOutputFile(File outputFile) {
 		this.outputFile = outputFile;
 	}
 
 	public boolean isHaltOnError() {
 		return haltOnError;
 	}
 
 	public void setHaltOnError(boolean haltOnError) {
 		this.haltOnError = haltOnError;
 	}
 
 	public String getDelimiter() {
 		return delimiter;
 	}
 
 	public void setDelimiter(String delimiter) {
 		this.delimiter = delimiter;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidatorTask.java b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidatorTask.java
index e74b6d8c97..c230155ace 100755
--- a/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidatorTask.java
+++ b/hibernate-core/src/main/java/org/hibernate/tool/hbm2ddl/SchemaValidatorTask.java
@@ -1,185 +1,185 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  *
  */
 package org.hibernate.tool.hbm2ddl;
 
 import java.io.File;
 import java.io.FileInputStream;
 import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.util.Iterator;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Properties;
 
 import org.apache.tools.ant.BuildException;
 import org.apache.tools.ant.DirectoryScanner;
 import org.apache.tools.ant.Project;
 import org.apache.tools.ant.taskdefs.MatchingTask;
 import org.apache.tools.ant.types.FileSet;
 
 import org.hibernate.HibernateException;
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.NamingStrategy;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.internal.util.collections.ArrayHelper;
 
 /**
  * An Ant task for <tt>SchemaUpdate</tt>.
  *
  * <pre>
  * &lt;taskdef name="schemavalidator"
  *     classname="org.hibernate.tool.hbm2ddl.SchemaValidatorTask"
  *     classpathref="class.path"/&gt;
  *
  * &lt;schemaupdate
  *     properties="${build.classes.dir}/hibernate.properties"
  *     &lt;fileset dir="${build.classes.dir}"&gt;
  *         &lt;include name="*.hbm.xml"/&gt;
  *     &lt;/fileset&gt;
  * &lt;/schemaupdate&gt;
  * </pre>
  *
  * @see SchemaValidator
  * @author Gavin King
  */
 public class SchemaValidatorTask extends MatchingTask {
 
 	private List fileSets = new LinkedList();
-	private File propertiesFile = null;
-	private File configurationFile = null;
-	private String namingStrategy = null;
+	private File propertiesFile;
+	private File configurationFile;
+	private String namingStrategy;
 
 	public void addFileset(FileSet set) {
 		fileSets.add(set);
 	}
 
 	/**
 	 * Set a properties file
 	 * @param propertiesFile the properties file name
 	 */
 	public void setProperties(File propertiesFile) {
 		if ( !propertiesFile.exists() ) {
 			throw new BuildException("Properties file: " + propertiesFile + " does not exist.");
 		}
 
 		log("Using properties file " + propertiesFile, Project.MSG_DEBUG);
 		this.propertiesFile = propertiesFile;
 	}
 
 	/**
 	 * Set a <literal>.cfg.xml</literal> file
 	 * @param configurationFile the file name
 	 */
 	public void setConfig(File configurationFile) {
 		this.configurationFile = configurationFile;
 	}
 
 	/**
 	 * Execute the task
 	 */
 	@Override
     public void execute() throws BuildException {
 		try {
 			Configuration cfg = getConfiguration();
 			getSchemaValidator(cfg).validate();
 		}
 		catch (HibernateException e) {
 			throw new BuildException("Schema text failed: " + e.getMessage(), e);
 		}
 		catch (FileNotFoundException e) {
 			throw new BuildException("File not found: " + e.getMessage(), e);
 		}
 		catch (IOException e) {
 			throw new BuildException("IOException : " + e.getMessage(), e);
 		}
 		catch (Exception e) {
 			throw new BuildException(e);
 		}
 	}
 
 	private String[] getFiles() {
 
 		List files = new LinkedList();
 		for ( Iterator i = fileSets.iterator(); i.hasNext(); ) {
 
 			FileSet fs = (FileSet) i.next();
 			DirectoryScanner ds = fs.getDirectoryScanner( getProject() );
 
 			String[] dsFiles = ds.getIncludedFiles();
 			for (int j = 0; j < dsFiles.length; j++) {
 				File f = new File(dsFiles[j]);
 				if ( !f.isFile() ) {
 					f = new File( ds.getBasedir(), dsFiles[j] );
 				}
 
 				files.add( f.getAbsolutePath() );
 			}
 		}
 
 		return ArrayHelper.toStringArray( files );
 	}
 
 	private Configuration getConfiguration() throws Exception {
 		Configuration cfg = new Configuration();
 		if (namingStrategy!=null) {
 			cfg.setNamingStrategy(
 					(NamingStrategy) ReflectHelper.classForName(namingStrategy).newInstance()
 				);
 		}
 		if (configurationFile!=null) {
 			cfg.configure( configurationFile );
 		}
 
 		String[] files = getFiles();
 		for (int i = 0; i < files.length; i++) {
 			String filename = files[i];
 			if ( filename.endsWith(".jar") ) {
 				cfg.addJar( new File(filename) );
 			}
 			else {
 				cfg.addFile(filename);
 			}
 		}
 		return cfg;
 	}
 
 	private SchemaValidator getSchemaValidator(Configuration cfg) throws HibernateException, IOException {
 		Properties properties = new Properties();
 		properties.putAll( cfg.getProperties() );
 		if (propertiesFile == null) {
 			properties.putAll( getProject().getProperties() );
 		}
 		else {
 			properties.load( new FileInputStream(propertiesFile) );
 		}
 		cfg.setProperties(properties);
 		return new SchemaValidator(cfg);
 	}
 
 	public void setNamingStrategy(String namingStrategy) {
 		this.namingStrategy = namingStrategy;
 	}
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/transform/CacheableResultTransformer.java b/hibernate-core/src/main/java/org/hibernate/transform/CacheableResultTransformer.java
index dc9b20de6b..483403d295 100644
--- a/hibernate-core/src/main/java/org/hibernate/transform/CacheableResultTransformer.java
+++ b/hibernate-core/src/main/java/org/hibernate/transform/CacheableResultTransformer.java
@@ -1,335 +1,335 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 20102011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.transform;
 
 import java.lang.reflect.Array;
 import java.util.Arrays;
 import java.util.List;
 
 import org.hibernate.internal.util.collections.ArrayHelper;
 import org.hibernate.type.Type;
 
 /**
  * A ResultTransformer that is used to transform tuples to a value(s)
  * that can be cached.
  *
  * @author Gail Badner
  */
 public class CacheableResultTransformer implements ResultTransformer {
 
 	// would be nice to be able to have this class extend
 	// PassThroughResultTransformer, but the default constructor
 	// is private (as it should be for a singleton)
 	private final static PassThroughResultTransformer ACTUAL_TRANSFORMER =
 			PassThroughResultTransformer.INSTANCE;
 	private final int tupleLength;
 	private final int tupleSubsetLength;
 
 	// array with the i-th element indicating whether the i-th
 	// expression returned by a query is included in the tuple;
 	// IMPLLEMENTATION NOTE:
 	// "joined" and "fetched" associations may use the same SQL,
 	// but result in different tuple and cached values. This is
 	// because "fetched" associations are excluded from the tuple.
 	//  includeInTuple provides a way to distinguish these 2 cases.
 	private final boolean[] includeInTuple;
 
 	// indexes for tuple that are included in the transformation;
 	// set to null if all elements in the tuple are included
 	private final int[] includeInTransformIndex;
 
 	/**
 	 * Returns a CacheableResultTransformer that is used to transform
 	 * tuples to a value(s) that can be cached.
 	 *
 	 * @param transformer - result transformer that will ultimately be
 	 *        be used (after caching results)
 	 * @param aliases - the aliases that correspond to the tuple;
 	 *        if it is non-null, its length must equal the number
 	 *        of true elements in includeInTuple[]
 	 * @param includeInTuple - array with the i-th element indicating
 	 *        whether the i-th expression returned by a query is
 	 *        included in the tuple; the number of true values equals
 	 *        the length of the tuple that will be transformed;
 	 *        must be non-null
 	 *
 	 * @return a CacheableResultTransformer that is used to transform
 	 *         tuples to a value(s) that can be cached.
 	 */
 	public static CacheableResultTransformer create(
 			ResultTransformer transformer,
 			String[] aliases,
 			boolean[] includeInTuple) {
 		return transformer instanceof TupleSubsetResultTransformer
 				? create( ( TupleSubsetResultTransformer ) transformer, aliases, includeInTuple )
 				: create( includeInTuple );
 	}
 
 	/**
 	 * Returns a CacheableResultTransformer that is used to transform
 	 * tuples to a value(s) that can be cached.
 	 *
 	 * @param transformer - a tuple subset result transformer;
 	 *        must be non-null;
 	 * @param aliases - the aliases that correspond to the tuple;
 	 *        if it is non-null, its length must equal the number
 	 *        of true elements in includeInTuple[]
 	 * @param includeInTuple - array with the i-th element indicating
 	 *        whether the i-th expression returned by a query is
 	 *        included in the tuple; the number of true values equals
 	 *        the length of the tuple that will be transformed;
 	 *        must be non-null
 	 *
 	 * @return a CacheableResultTransformer that is used to transform
 	 *         tuples to a value(s) that can be cached.
 	 */
 	private static CacheableResultTransformer create(
 			TupleSubsetResultTransformer transformer,
 			String[] aliases,
 			boolean[] includeInTuple) {
 		if ( transformer == null ) {
 			throw new IllegalArgumentException( "transformer cannot be null" );
 		}
 		int tupleLength = ArrayHelper.countTrue( includeInTuple );
 		if ( aliases != null && aliases.length != tupleLength ) {
 			throw new IllegalArgumentException(
 					"if aliases is not null, then the length of aliases[] must equal the number of true elements in includeInTuple; " +
 							"aliases.length=" + aliases.length + "tupleLength=" + tupleLength
 			);
 		}
 		return new CacheableResultTransformer(
 				includeInTuple,
 				transformer.includeInTransform( aliases, tupleLength )
 		);
 	}
 
 	/**
 	 * Returns a CacheableResultTransformer that is used to transform
 	 * tuples to a value(s) that can be cached.
 	 *
 	 * @param includeInTuple - array with the i-th element indicating
 	 *        whether the i-th expression returned by a query is
 	 *        included in the tuple; the number of true values equals
 	 *        the length of the tuple that will be transformed;
 	 *        must be non-null
 	 *
 	 * @return a CacheableResultTransformer that is used to transform
 	 *         tuples to a value(s) that can be cached.
 	 */
 	private static CacheableResultTransformer create(boolean[] includeInTuple) {
 		return new CacheableResultTransformer( includeInTuple, null );
 	}
 
 	private CacheableResultTransformer(boolean[] includeInTuple, boolean[] includeInTransform) {
 		if ( includeInTuple == null ) {
 			throw new IllegalArgumentException( "includeInTuple cannot be null" );
 		}
 		this.includeInTuple = includeInTuple;
 		tupleLength = ArrayHelper.countTrue( includeInTuple );
 		tupleSubsetLength = (
 				includeInTransform == null ?
 						tupleLength :
 						ArrayHelper.countTrue( includeInTransform )
 		);
 		if ( tupleSubsetLength == tupleLength ) {
 			includeInTransformIndex = null;
 		}
 		else {
 			includeInTransformIndex = new int[tupleSubsetLength];
 			for ( int i = 0, j = 0 ; i < includeInTransform.length ; i++ ) {
 				if ( includeInTransform[ i ] ) {
 					includeInTransformIndex[ j ] =  i;
 					j++;
 				}
 			}
 		}
 	}
 
 	@Override
-	public Object transformTuple(Object[] tuple, String aliases[]) {
+	public Object transformTuple(Object[] tuple, String[] aliases) {
 		if ( aliases != null && aliases.length != tupleLength ) {
 			throw new IllegalStateException(
 					"aliases expected length is " + tupleLength +
 					"; actual length is " + aliases.length );
 		}
 		// really more correct to pass index( aliases.getClass(), aliases )
 		// as the 2nd arg to the following statement;
 		// passing null instead because it ends up being ignored.
 		return ACTUAL_TRANSFORMER.transformTuple( index( tuple.getClass(), tuple ), null );
 	}
 
 	/**
 	 * Re-transforms, if necessary, a List of values previously
 	 * transformed by this (or an equivalent) CacheableResultTransformer.
 	 * Each element of the list is re-transformed in place (i.e, List
 	 * elements are replaced with re-transformed values) and the original
 	 * List is returned.
 	 * <p/>
 	 * If re-transformation is unnecessary, the original List is returned
 	 * unchanged.
 	 *
 	 * @param transformedResults - results that were previously transformed
 	 * @param aliases - the aliases that correspond to the untransformed tuple;
 	 * @param transformer - the transformer for the re-transformation
 	 * @param includeInTuple indicates the indexes of
 	 *
 	 * @return transformedResults, with each element re-transformed (if nececessary)
 	 */
 	@SuppressWarnings( {"unchecked"})
 	public List retransformResults(
 			List transformedResults,
-			String aliases[],
+			String[] aliases,
 			ResultTransformer transformer,
 			boolean[] includeInTuple) {
 		if ( transformer == null ) {
 			throw new IllegalArgumentException( "transformer cannot be null" );
 		}
 		if ( ! this.equals( create( transformer, aliases, includeInTuple ) ) ) {
 			throw new IllegalStateException(
 					"this CacheableResultTransformer is inconsistent with specified arguments; cannot re-transform"
 			);
 		}
 		boolean requiresRetransform = true;
 		String[] aliasesToUse = aliases == null ? null : index( ( aliases.getClass() ), aliases );
 		if ( transformer == ACTUAL_TRANSFORMER ) {
 			requiresRetransform = false;
 		}
 		else if ( transformer instanceof TupleSubsetResultTransformer ) {
 			requiresRetransform =  ! ( ( TupleSubsetResultTransformer ) transformer ).isTransformedValueATupleElement(
 					aliasesToUse,
 					tupleLength
 			);
 		}
 		if ( requiresRetransform ) {
 			for ( int i = 0 ; i < transformedResults.size() ; i++ ) {
 				Object[] tuple = ACTUAL_TRANSFORMER.untransformToTuple(
 									transformedResults.get( i ),
 									tupleSubsetLength == 1
 				);
 				transformedResults.set( i, transformer.transformTuple( tuple, aliasesToUse ) );
 			}
 		}
 		return transformedResults;
 	}
 
 	/**
 	 * Untransforms, if necessary, a List of values previously
 	 * transformed by this (or an equivalent) CacheableResultTransformer.
 	 * Each element of the list is untransformed in place (i.e, List
 	 * elements are replaced with untransformed values) and the original
 	 * List is returned.
 	 * <p/>
 	 * If not unnecessary, the original List is returned
 	 * unchanged.
 	 * <p/>
 	 * NOTE: If transformed values are a subset of the original
 	 *       tuple, then, on return, elements corresponding to
 	 *       excluded tuple elements will be null.
 	 * @param results - results that were previously transformed
 	 * @return results, with each element untransformed (if nececessary)
 	 */
 	@SuppressWarnings( {"unchecked"})
 	public List untransformToTuples(List results) {
 		if ( includeInTransformIndex == null ) {
 			results = ACTUAL_TRANSFORMER.untransformToTuples(
 					results,
 					tupleSubsetLength == 1
 			);
 		}
 		else {
 			for ( int i = 0 ; i < results.size() ; i++ ) {
 				Object[] tuple = ACTUAL_TRANSFORMER.untransformToTuple(
 									results.get( i ),
 									tupleSubsetLength == 1
 				);
 				results.set( i, unindex( tuple.getClass(), tuple ) );
 			}
 
 		}
 		return results;
 	}
 
 	public Type[] getCachedResultTypes(Type[] tupleResultTypes) {
 		return tupleLength != tupleSubsetLength
 				? index( tupleResultTypes.getClass(), tupleResultTypes )
 				: tupleResultTypes;
 	}
 
 	@Override
 	public List transformList(List list) {
 		return list;
 	}
 
 	private <T> T[] index(Class<? extends T[]> clazz, T[] objects) {
 		T[] objectsIndexed = objects;
 		if ( objects != null &&
 				includeInTransformIndex != null &&
 				objects.length != tupleSubsetLength ) {
 			objectsIndexed = clazz.cast( Array.newInstance( clazz.getComponentType(), tupleSubsetLength ) );
 			for ( int i = 0 ; i < tupleSubsetLength; i++ ) {
 				objectsIndexed[ i ] = objects[ includeInTransformIndex[ i ] ];
 			}
 		}
 		return objectsIndexed;
 	}
 
 	private <T> T[] unindex(Class<? extends T[]> clazz, T[] objects) {
 		T[] objectsUnindexed = objects;
 		if ( objects != null &&
 				includeInTransformIndex != null &&
 				objects.length != tupleLength ) {
 			objectsUnindexed = clazz.cast( Array.newInstance( clazz.getComponentType(), tupleLength ) );
 			for ( int i = 0 ; i < tupleSubsetLength; i++ ) {
 				objectsUnindexed[ includeInTransformIndex[ i ] ] = objects[ i ];
 			}
 		}
 		return objectsUnindexed;
 	}
 
 	@Override
 	public boolean equals(Object o) {
 		if ( this == o ) {
 			return true;
 		}
 		if ( o == null || getClass() != o.getClass() ) {
 			return false;
 		}
 
 		CacheableResultTransformer that = ( CacheableResultTransformer ) o;
 
 		return tupleLength == that.tupleLength
 				&& tupleSubsetLength == that.tupleSubsetLength
 				&& Arrays.equals( includeInTuple, that.includeInTuple )
 				&& Arrays.equals( includeInTransformIndex, that.includeInTransformIndex );
 	}
 
 	@Override
 	public int hashCode() {
 		int result = tupleLength;
 		result = 31 * result + tupleSubsetLength;
 		result = 31 * result + ( includeInTuple != null ? Arrays.hashCode( includeInTuple ) : 0 );
 		result = 31 * result + ( includeInTransformIndex != null ? Arrays.hashCode( includeInTransformIndex ) : 0 );
 		return result;
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/PropertyFactory.java b/hibernate-core/src/main/java/org/hibernate/tuple/PropertyFactory.java
index 9f525e2c2b..c9b5d50990 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/PropertyFactory.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/PropertyFactory.java
@@ -1,510 +1,513 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple;
 
 import java.lang.reflect.Constructor;
 
 import org.hibernate.EntityMode;
 import org.hibernate.FetchMode;
 import org.hibernate.HibernateException;
 import org.hibernate.cfg.NotYetImplementedException;
 import org.hibernate.engine.internal.UnsavedValueFactory;
 import org.hibernate.engine.spi.CascadeStyle;
 import org.hibernate.engine.spi.CascadeStyles;
 import org.hibernate.engine.spi.IdentifierValue;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.VersionValue;
 import org.hibernate.id.IdentifierGenerator;
 import org.hibernate.internal.util.ReflectHelper;
 import org.hibernate.mapping.KeyValue;
 import org.hibernate.mapping.PersistentClass;
 import org.hibernate.mapping.Property;
 import org.hibernate.metamodel.binding.AbstractPluralAttributeBinding;
 import org.hibernate.metamodel.binding.AssociationAttributeBinding;
 import org.hibernate.metamodel.binding.AttributeBinding;
 import org.hibernate.metamodel.binding.BasicAttributeBinding;
 import org.hibernate.metamodel.binding.EntityBinding;
 import org.hibernate.metamodel.binding.SimpleValueBinding;
 import org.hibernate.metamodel.binding.SingularAttributeBinding;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.property.Getter;
 import org.hibernate.property.PropertyAccessor;
 import org.hibernate.property.PropertyAccessorFactory;
 import org.hibernate.tuple.entity.EntityBasedAssociationAttribute;
 import org.hibernate.tuple.entity.EntityBasedBasicAttribute;
 import org.hibernate.tuple.entity.EntityBasedCompositionAttribute;
 import org.hibernate.tuple.entity.VersionProperty;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.Type;
 import org.hibernate.type.VersionType;
 
 /**
  * Responsible for generation of runtime metamodel {@link Property} representations.
  * Makes distinction between identifier, version, and other (standard) properties.
  *
  * @author Steve Ebersole
  */
-public class PropertyFactory {
+public final class PropertyFactory {
+	private PropertyFactory() {
+	}
+
 	/**
 	 * Generates the attribute representation of the identifier for a given entity mapping.
 	 *
 	 * @param mappedEntity The mapping definition of the entity.
 	 * @param generator The identifier value generator to use for this identifier.
 	 * @return The appropriate IdentifierProperty definition.
 	 */
 	public static IdentifierProperty buildIdentifierAttribute(
 			PersistentClass mappedEntity,
 			IdentifierGenerator generator) {
 		String mappedUnsavedValue = mappedEntity.getIdentifier().getNullValue();
 		Type type = mappedEntity.getIdentifier().getType();
 		Property property = mappedEntity.getIdentifierProperty();
 		
 		IdentifierValue unsavedValue = UnsavedValueFactory.getUnsavedIdentifierValue(
 				mappedUnsavedValue,
 				getGetter( property ),
 				type,
 				getConstructor(mappedEntity)
 			);
 
 		if ( property == null ) {
 			// this is a virtual id property...
 			return new IdentifierProperty(
 			        type,
 					mappedEntity.hasEmbeddedIdentifier(),
 					mappedEntity.hasIdentifierMapper(),
 					unsavedValue,
 					generator
 				);
 		}
 		else {
 			return new IdentifierProperty(
 					property.getName(),
 					property.getNodeName(),
 					type,
 					mappedEntity.hasEmbeddedIdentifier(),
 					unsavedValue,
 					generator
 				);
 		}
 	}
 
 	/**
 	 * Generates an IdentifierProperty representation of the for a given entity mapping.
 	 *
 	 * @param mappedEntity The mapping definition of the entity.
 	 * @param generator The identifier value generator to use for this identifier.
 	 * @return The appropriate IdentifierProperty definition.
 	 */
 	public static IdentifierProperty buildIdentifierProperty(
 			EntityBinding mappedEntity,
 			IdentifierGenerator generator) {
 
 		final BasicAttributeBinding property = mappedEntity.getHierarchyDetails().getEntityIdentifier().getValueBinding();
 
 		// TODO: the following will cause an NPE with "virtual" IDs; how should they be set?
 		// (steve) virtual attributes will still be attributes, they will simply be marked as virtual.
 		//		see org.hibernate.metamodel.domain.AbstractAttributeContainer.locateOrCreateVirtualAttribute()
 
 		final String mappedUnsavedValue = property.getUnsavedValue();
 		final Type type = property.getHibernateTypeDescriptor().getResolvedTypeMapping();
 
 		IdentifierValue unsavedValue = UnsavedValueFactory.getUnsavedIdentifierValue(
 				mappedUnsavedValue,
 				getGetter( property ),
 				type,
 				getConstructor( mappedEntity )
 			);
 
 		if ( property == null ) {
 			// this is a virtual id property...
 			return new IdentifierProperty(
 			        type,
 					mappedEntity.getHierarchyDetails().getEntityIdentifier().isEmbedded(),
 					mappedEntity.getHierarchyDetails().getEntityIdentifier().isIdentifierMapper(),
 					unsavedValue,
 					generator
 				);
 		}
 		else {
 			return new IdentifierProperty(
 					property.getAttribute().getName(),
 					null,
 					type,
 					mappedEntity.getHierarchyDetails().getEntityIdentifier().isEmbedded(),
 					unsavedValue,
 					generator
 				);
 		}
 	}
 
 	/**
 	 * Generates a VersionProperty representation for an entity mapping given its
 	 * version mapping Property.
 	 *
 	 * @param property The version mapping Property.
 	 * @param lazyAvailable Is property lazy loading currently available.
 	 * @return The appropriate VersionProperty definition.
 	 */
 	public static VersionProperty buildVersionProperty(
 			EntityPersister persister,
 			SessionFactoryImplementor sessionFactory,
 			int attributeNumber,
 			Property property,
 			boolean lazyAvailable) {
 		String mappedUnsavedValue = ( (KeyValue) property.getValue() ).getNullValue();
 		
 		VersionValue unsavedValue = UnsavedValueFactory.getUnsavedVersionValue(
 				mappedUnsavedValue,
 				getGetter( property ),
 				(VersionType) property.getType(),
 				getConstructor( property.getPersistentClass() )
 		);
 
 		boolean lazy = lazyAvailable && property.isLazy();
 
 		return new VersionProperty(
 				persister,
 				sessionFactory,
 				attributeNumber,
 		        property.getName(),
 		        property.getValue().getType(),
 				new BaselineAttributeInformation.Builder()
 						.setLazy( lazy )
 						.setInsertable( property.isInsertable() )
 						.setUpdateable( property.isUpdateable() )
 						.setValueGenerationStrategy( property.getValueGenerationStrategy() )
 						.setNullable( property.isOptional() )
 						.setDirtyCheckable( property.isUpdateable() && !lazy )
 						.setVersionable( property.isOptimisticLocked() )
 						.setCascadeStyle( property.getCascadeStyle() )
 						.createInformation(),
 		        unsavedValue
 			);
 	}
 
 	/**
 	 * Generates a VersionProperty representation for an entity mapping given its
 	 * version mapping Property.
 	 *
 	 * @param property The version mapping Property.
 	 * @param lazyAvailable Is property lazy loading currently available.
 	 * @return The appropriate VersionProperty definition.
 	 */
 	public static VersionProperty buildVersionProperty(
 			EntityPersister persister,
 			BasicAttributeBinding property,
 			boolean lazyAvailable) {
 		throw new NotYetImplementedException();
 	}
 
 	public static enum NonIdentifierAttributeNature {
 		BASIC,
 		COMPOSITE,
 		ANY,
 		ENTITY,
 		COLLECTION
 	}
 
 	/**
 	 * Generate a non-identifier (and non-version) attribute based on the given mapped property from the given entity
 	 *
 	 * @param property The mapped property.
 	 * @param lazyAvailable Is property lazy loading currently available.
 	 * @return The appropriate NonIdentifierProperty definition.
 	 */
 	public static NonIdentifierAttribute buildEntityBasedAttribute(
 			EntityPersister persister,
 			SessionFactoryImplementor sessionFactory,
 			int attributeNumber,
 			Property property,
 			boolean lazyAvailable) {
 		final Type type = property.getValue().getType();
 
 		final NonIdentifierAttributeNature nature = decode( type );
 
 		// we need to dirty check collections, since they can cause an owner
 		// version number increment
 		
 		// we need to dirty check many-to-ones with not-found="ignore" in order 
 		// to update the cache (not the database), since in this case a null
 		// entity reference can lose information
 		
 		boolean alwaysDirtyCheck = type.isAssociationType() && 
 				( (AssociationType) type ).isAlwaysDirtyChecked(); 
 
 		switch ( nature ) {
 			case BASIC: {
 				return new EntityBasedBasicAttribute(
 						persister,
 						sessionFactory,
 						attributeNumber,
 						property.getName(),
 						type,
 						new BaselineAttributeInformation.Builder()
 								.setLazy( lazyAvailable && property.isLazy() )
 								.setInsertable( property.isInsertable() )
 								.setUpdateable( property.isUpdateable() )
 								.setValueGenerationStrategy( property.getValueGenerationStrategy() )
 								.setNullable( property.isOptional() )
 								.setDirtyCheckable( alwaysDirtyCheck || property.isUpdateable() )
 								.setVersionable( property.isOptimisticLocked() )
 								.setCascadeStyle( property.getCascadeStyle() )
 								.setFetchMode( property.getValue().getFetchMode() )
 								.createInformation()
 				);
 			}
 			case COMPOSITE: {
 				return new EntityBasedCompositionAttribute(
 						persister,
 						sessionFactory,
 						attributeNumber,
 						property.getName(),
 						(CompositeType) type,
 						new BaselineAttributeInformation.Builder()
 								.setLazy( lazyAvailable && property.isLazy() )
 								.setInsertable( property.isInsertable() )
 								.setUpdateable( property.isUpdateable() )
 								.setValueGenerationStrategy( property.getValueGenerationStrategy() )
 								.setNullable( property.isOptional() )
 								.setDirtyCheckable( alwaysDirtyCheck || property.isUpdateable() )
 								.setVersionable( property.isOptimisticLocked() )
 								.setCascadeStyle( property.getCascadeStyle() )
 								.setFetchMode( property.getValue().getFetchMode() )
 								.createInformation()
 				);
 			}
 			case ENTITY:
 			case ANY:
 			case COLLECTION: {
 				return new EntityBasedAssociationAttribute(
 						persister,
 						sessionFactory,
 						attributeNumber,
 						property.getName(),
 						(AssociationType) type,
 						new BaselineAttributeInformation.Builder()
 								.setLazy( lazyAvailable && property.isLazy() )
 								.setInsertable( property.isInsertable() )
 								.setUpdateable( property.isUpdateable() )
 								.setValueGenerationStrategy( property.getValueGenerationStrategy() )
 								.setNullable( property.isOptional() )
 								.setDirtyCheckable( alwaysDirtyCheck || property.isUpdateable() )
 								.setVersionable( property.isOptimisticLocked() )
 								.setCascadeStyle( property.getCascadeStyle() )
 								.setFetchMode( property.getValue().getFetchMode() )
 								.createInformation()
 				);
 			}
 			default: {
 				throw new HibernateException( "Internal error" );
 			}
 		}
 	}
 
 	private static NonIdentifierAttributeNature decode(Type type) {
 		if ( type.isAssociationType() ) {
 			AssociationType associationType = (AssociationType) type;
 
 			if ( type.isComponentType() ) {
 				// an any type is both an association and a composite...
 				return NonIdentifierAttributeNature.ANY;
 			}
 
 			return type.isCollectionType()
 					? NonIdentifierAttributeNature.COLLECTION
 					: NonIdentifierAttributeNature.ENTITY;
 		}
 		else {
 			if ( type.isComponentType() ) {
 				return NonIdentifierAttributeNature.COMPOSITE;
 			}
 
 			return NonIdentifierAttributeNature.BASIC;
 		}
 	}
 
 	@Deprecated
 	public static StandardProperty buildStandardProperty(Property property, boolean lazyAvailable) {
 		final Type type = property.getValue().getType();
 
 		// we need to dirty check collections, since they can cause an owner
 		// version number increment
 
 		// we need to dirty check many-to-ones with not-found="ignore" in order
 		// to update the cache (not the database), since in this case a null
 		// entity reference can lose information
 
 		boolean alwaysDirtyCheck = type.isAssociationType() &&
 				( (AssociationType) type ).isAlwaysDirtyChecked();
 
 		return new StandardProperty(
 				property.getName(),
 				type,
 				lazyAvailable && property.isLazy(),
 				property.isInsertable(),
 				property.isUpdateable(),
 				property.getValueGenerationStrategy(),
 				property.isOptional(),
 				alwaysDirtyCheck || property.isUpdateable(),
 				property.isOptimisticLocked(),
 				property.getCascadeStyle(),
 				property.getValue().getFetchMode()
 		);
 	}
 
 
 	/**
 	 * Generate a "standard" (i.e., non-identifier and non-version) based on the given
 	 * mapped property.
 	 *
 	 * @param property The mapped property.
 	 * @param lazyAvailable Is property lazy loading currently available.
 	 * @return The appropriate NonIdentifierProperty definition.
 	 */
 	public static StandardProperty buildStandardProperty(AttributeBinding property, boolean lazyAvailable) {
 
 		final Type type = property.getHibernateTypeDescriptor().getResolvedTypeMapping();
 
 		// we need to dirty check collections, since they can cause an owner
 		// version number increment
 
 		// we need to dirty check many-to-ones with not-found="ignore" in order
 		// to update the cache (not the database), since in this case a null
 		// entity reference can lose information
 
 		final boolean alwaysDirtyCheck = type.isAssociationType() && ( (AssociationType) type ).isAlwaysDirtyChecked();
 
 		if ( property.getAttribute().isSingular() ) {
 			final SingularAttributeBinding singularAttributeBinding = ( SingularAttributeBinding ) property;
 			final CascadeStyle cascadeStyle = singularAttributeBinding.isAssociation()
 					? ( (AssociationAttributeBinding) singularAttributeBinding ).getCascadeStyle()
 					: CascadeStyles.NONE;
 			final FetchMode fetchMode = singularAttributeBinding.isAssociation()
 					? ( (AssociationAttributeBinding) singularAttributeBinding ).getFetchMode()
 					: FetchMode.DEFAULT;
 
 			return new StandardProperty(
 					singularAttributeBinding.getAttribute().getName(),
 					type,
 					lazyAvailable && singularAttributeBinding.isLazy(),
 					true, // insertable
 					true, // updatable
 					null,
 					singularAttributeBinding.isNullable(),
 					alwaysDirtyCheck || areAllValuesIncludedInUpdate( singularAttributeBinding ),
 					singularAttributeBinding.isIncludedInOptimisticLocking(),
 					cascadeStyle,
 					fetchMode
 			);
 		}
 		else {
 			final AbstractPluralAttributeBinding pluralAttributeBinding = (AbstractPluralAttributeBinding) property;
 			final CascadeStyle cascadeStyle = pluralAttributeBinding.isAssociation()
 					? pluralAttributeBinding.getCascadeStyle()
 					: CascadeStyles.NONE;
 			final FetchMode fetchMode = pluralAttributeBinding.isAssociation()
 					? pluralAttributeBinding.getFetchMode()
 					: FetchMode.DEFAULT;
 
 			return new StandardProperty(
 					pluralAttributeBinding.getAttribute().getName(),
 					type,
 					lazyAvailable && pluralAttributeBinding.isLazy(),
 					// TODO: fix this when HHH-6356 is fixed; for now assume AbstractPluralAttributeBinding is updatable and insertable
 					true, // pluralAttributeBinding.isInsertable(),
 					true, //pluralAttributeBinding.isUpdatable(),
 					null,
 					false, // nullable - not sure what that means for a collection
 					// TODO: fix this when HHH-6356 is fixed; for now assume AbstractPluralAttributeBinding is updatable and insertable
 					//alwaysDirtyCheck || pluralAttributeBinding.isUpdatable(),
 					true,
 					pluralAttributeBinding.isIncludedInOptimisticLocking(),
 					cascadeStyle,
 					fetchMode
 				);
 		}
 	}
 
 	private static boolean areAllValuesIncludedInUpdate(SingularAttributeBinding attributeBinding) {
 		if ( attributeBinding.hasDerivedValue() ) {
 			return false;
 		}
 		for ( SimpleValueBinding valueBinding : attributeBinding.getSimpleValueBindings() ) {
 			if ( ! valueBinding.isIncludeInUpdate() ) {
 				return false;
 			}
 		}
 		return true;
 	}
 
 	private static Constructor getConstructor(PersistentClass persistentClass) {
 		if ( persistentClass == null || !persistentClass.hasPojoRepresentation() ) {
 			return null;
 		}
 
 		try {
 			return ReflectHelper.getDefaultConstructor( persistentClass.getMappedClass() );
 		}
 		catch( Throwable t ) {
 			return null;
 		}
 	}
 
 	private static Constructor getConstructor(EntityBinding entityBinding) {
 		if ( entityBinding == null || entityBinding.getEntity() == null ) {
 			return null;
 		}
 
 		try {
 			return ReflectHelper.getDefaultConstructor( entityBinding.getEntity().getClassReference() );
 		}
 		catch( Throwable t ) {
 			return null;
 		}
 	}
 
 	private static Getter getGetter(Property mappingProperty) {
 		if ( mappingProperty == null || !mappingProperty.getPersistentClass().hasPojoRepresentation() ) {
 			return null;
 		}
 
 		PropertyAccessor pa = PropertyAccessorFactory.getPropertyAccessor( mappingProperty, EntityMode.POJO );
 		return pa.getGetter( mappingProperty.getPersistentClass().getMappedClass(), mappingProperty.getName() );
 	}
 
 	private static Getter getGetter(AttributeBinding mappingProperty) {
 		if ( mappingProperty == null || mappingProperty.getContainer().getClassReference() == null ) {
 			return null;
 		}
 
 		PropertyAccessor pa = PropertyAccessorFactory.getPropertyAccessor( mappingProperty, EntityMode.POJO );
 		return pa.getGetter(
 				mappingProperty.getContainer().getClassReference(),
 				mappingProperty.getAttribute().getName()
 		);
 	}
 
 
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/tuple/component/AbstractCompositionAttribute.java b/hibernate-core/src/main/java/org/hibernate/tuple/component/AbstractCompositionAttribute.java
index 90196a522f..8b40ca7df9 100644
--- a/hibernate-core/src/main/java/org/hibernate/tuple/component/AbstractCompositionAttribute.java
+++ b/hibernate-core/src/main/java/org/hibernate/tuple/component/AbstractCompositionAttribute.java
@@ -1,242 +1,242 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.tuple.component;
 
 import java.util.Iterator;
 
 import org.hibernate.engine.internal.JoinHelper;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.persister.collection.QueryableCollection;
 import org.hibernate.persister.entity.EntityPersister;
 import org.hibernate.persister.entity.Joinable;
 import org.hibernate.persister.entity.OuterJoinLoadable;
 import org.hibernate.persister.walking.spi.AssociationKey;
 import org.hibernate.persister.walking.spi.AttributeDefinition;
 import org.hibernate.persister.walking.spi.AttributeSource;
 import org.hibernate.persister.walking.spi.CompositionDefinition;
 import org.hibernate.tuple.AbstractNonIdentifierAttribute;
 import org.hibernate.tuple.BaselineAttributeInformation;
 import org.hibernate.type.AssociationType;
 import org.hibernate.type.CompositeType;
 import org.hibernate.type.ForeignKeyDirection;
 import org.hibernate.type.Type;
 
 import static org.hibernate.engine.internal.JoinHelper.getLHSColumnNames;
 import static org.hibernate.engine.internal.JoinHelper.getLHSTableName;
 import static org.hibernate.engine.internal.JoinHelper.getRHSColumnNames;
 
 /**
  * A base class for a composite, non-identifier attribute.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractCompositionAttribute
 		extends AbstractNonIdentifierAttribute
 		implements CompositionDefinition {
 
 	private final int columnStartPosition;
 
 	protected AbstractCompositionAttribute(
 			AttributeSource source,
 			SessionFactoryImplementor sessionFactory,
 			int entityBasedAttributeNumber,
 			String attributeName,
 			CompositeType attributeType,
 			int columnStartPosition,
 			BaselineAttributeInformation baselineInfo) {
 		super( source, sessionFactory, entityBasedAttributeNumber, attributeName, attributeType, baselineInfo );
 		this.columnStartPosition = columnStartPosition;
 	}
 
 	@Override
 	public CompositeType getType() {
 		return (CompositeType) super.getType();
 	}
 
 	@Override
 	public Iterable<AttributeDefinition> getAttributes() {
 		return new Iterable<AttributeDefinition>() {
 			@Override
 			public Iterator<AttributeDefinition> iterator() {
 				return new Iterator<AttributeDefinition>() {
 					private final int numberOfAttributes = getType().getSubtypes().length;
-					private int currentSubAttributeNumber = 0;
+					private int currentSubAttributeNumber;
 					private int currentColumnPosition = columnStartPosition;
 
 					@Override
 					public boolean hasNext() {
 						return currentSubAttributeNumber < numberOfAttributes;
 					}
 
 					@Override
 					public AttributeDefinition next() {
 						final int subAttributeNumber = currentSubAttributeNumber;
 						currentSubAttributeNumber++;
 
 						final String name = getType().getPropertyNames()[subAttributeNumber];
 						final Type type = getType().getSubtypes()[subAttributeNumber];
 
 						int columnPosition = currentColumnPosition;
 						currentColumnPosition += type.getColumnSpan( sessionFactory() );
 
 						if ( type.isAssociationType() ) {
 							// we build the association-key here because of the "goofiness" with 'currentColumnPosition'
 							final AssociationKey associationKey;
 							final AssociationType aType = (AssociationType) type;
 							final Joinable joinable = aType.getAssociatedJoinable( sessionFactory() );
 
 							if ( aType.isAnyType() ) {
 								associationKey = new AssociationKey(
 										JoinHelper.getLHSTableName(
 												aType,
 												attributeNumber(),
 												(OuterJoinLoadable) locateOwningPersister()
 										),
 										JoinHelper.getLHSColumnNames(
 												aType,
 												attributeNumber(),
 												columnPosition,
 												(OuterJoinLoadable) locateOwningPersister(),
 												sessionFactory()
 										)
 								);
 							}
 							else if ( aType.getForeignKeyDirection() == ForeignKeyDirection.FOREIGN_KEY_FROM_PARENT ) {
 								final String lhsTableName;
 								final String[] lhsColumnNames;
 
 								if ( joinable.isCollection() ) {
 									final QueryableCollection collectionPersister = (QueryableCollection) joinable;
 									lhsTableName = collectionPersister.getTableName();
 									lhsColumnNames = collectionPersister.getElementColumnNames();
 								}
 								else {
 									final OuterJoinLoadable entityPersister = (OuterJoinLoadable) locateOwningPersister();
 									lhsTableName = getLHSTableName( aType, attributeNumber(), entityPersister );
 									lhsColumnNames = getLHSColumnNames(
 											aType,
 											attributeNumber(),
 											columnPosition,
 											entityPersister,
 											sessionFactory()
 									);
 								}
 								associationKey = new AssociationKey( lhsTableName, lhsColumnNames );
 							}
 							else {
 								associationKey = new AssociationKey(
 										joinable.getTableName(),
 										getRHSColumnNames( aType, sessionFactory() )
 								);
 							}
 
 							final CompositeType cType = getType();
 							final boolean nullable =
 									cType.getPropertyNullability() == null ||
 											cType.getPropertyNullability()[subAttributeNumber];
 
 							return new CompositeBasedAssociationAttribute(
 									AbstractCompositionAttribute.this,
 									sessionFactory(),
 									attributeNumber(),
 									name,
 									(AssociationType) type,
 									new BaselineAttributeInformation.Builder()
 											.setInsertable( AbstractCompositionAttribute.this.isInsertable() )
 											.setUpdateable( AbstractCompositionAttribute.this.isUpdateable() )
 											// todo : handle nested ValueGeneration strategies...
 											//		disallow if our strategy != NEVER
 											.setNullable( nullable )
 											.setDirtyCheckable( true )
 											.setVersionable( AbstractCompositionAttribute.this.isVersionable() )
 											.setCascadeStyle( getType().getCascadeStyle( subAttributeNumber ) )
 											.setFetchMode( getType().getFetchMode( subAttributeNumber ) )
 											.createInformation(),
 									subAttributeNumber,
 									associationKey
 							);
 						}
 						else if ( type.isComponentType() ) {
 							return new CompositionBasedCompositionAttribute(
 									AbstractCompositionAttribute.this,
 									sessionFactory(),
 									attributeNumber(),
 									name,
 									(CompositeType) type,
 									columnPosition,
 									new BaselineAttributeInformation.Builder()
 											.setInsertable( AbstractCompositionAttribute.this.isInsertable() )
 											.setUpdateable( AbstractCompositionAttribute.this.isUpdateable() )
 											// todo : handle nested ValueGeneration strategies...
 											//		disallow if our strategy != NEVER
 											.setNullable( getType().getPropertyNullability()[subAttributeNumber] )
 											.setDirtyCheckable( true )
 											.setVersionable( AbstractCompositionAttribute.this.isVersionable() )
 											.setCascadeStyle( getType().getCascadeStyle( subAttributeNumber ) )
 											.setFetchMode( getType().getFetchMode( subAttributeNumber ) )
 											.createInformation()
 							);
 						}
 						else {
 							final CompositeType cType = getType();
 							final boolean nullable = cType.getPropertyNullability() == null || cType.getPropertyNullability()[subAttributeNumber];
 
 							return new CompositeBasedBasicAttribute(
 									AbstractCompositionAttribute.this,
 									sessionFactory(),
 									subAttributeNumber,
 									name,
 									type,
 									new BaselineAttributeInformation.Builder()
 											.setInsertable( AbstractCompositionAttribute.this.isInsertable() )
 											.setUpdateable( AbstractCompositionAttribute.this.isUpdateable() )
 											// todo : handle nested ValueGeneration strategies...
 											//		disallow if our strategy != NEVER
 											.setNullable( nullable )
 											.setDirtyCheckable( true )
 											.setVersionable( AbstractCompositionAttribute.this.isVersionable() )
 											.setCascadeStyle( getType().getCascadeStyle( subAttributeNumber ) )
 											.setFetchMode( getType().getFetchMode( subAttributeNumber ) )
 											.createInformation()
 							);
 						}
 					}
 
 					@Override
 					public void remove() {
 						throw new UnsupportedOperationException( "Remove operation not supported here" );
 					}
 				};
 			}
 		};
 	}
 
 	protected abstract EntityPersister locateOwningPersister();
 
 	@Override
 	protected String loggableMetadata() {
 		return super.loggableMetadata() + ",composition";
 	}
 }
 
diff --git a/hibernate-core/src/main/java/org/hibernate/type/BasicTypeRegistry.java b/hibernate-core/src/main/java/org/hibernate/type/BasicTypeRegistry.java
index 512f19764f..056db2d272 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/BasicTypeRegistry.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/BasicTypeRegistry.java
@@ -1,169 +1,167 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.io.Serializable;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 
-import org.jboss.logging.Logger;
-
 import org.hibernate.HibernateException;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.usertype.CompositeUserType;
 import org.hibernate.usertype.UserType;
 
 /**
  * A registry of {@link BasicType} instances
  *
  * @author Steve Ebersole
  */
 public class BasicTypeRegistry implements Serializable {
-
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, BasicTypeRegistry.class.getName());
+    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( BasicTypeRegistry.class );
 
 	// TODO : analyze these sizing params; unfortunately this seems to be the only way to give a "concurrencyLevel"
 	private Map<String,BasicType> registry = new ConcurrentHashMap<String, BasicType>( 100, .75f, 1 );
-	private boolean locked = false;
+	private boolean locked;
 
 	public BasicTypeRegistry() {
 		register( BooleanType.INSTANCE );
 		register( NumericBooleanType.INSTANCE );
 		register( TrueFalseType.INSTANCE );
 		register( YesNoType.INSTANCE );
 
 		register( ByteType.INSTANCE );
 		register( CharacterType.INSTANCE );
 		register( ShortType.INSTANCE );
 		register( IntegerType.INSTANCE );
 		register( LongType.INSTANCE );
 		register( FloatType.INSTANCE );
 		register( DoubleType.INSTANCE );
 		register( BigDecimalType.INSTANCE );
 		register( BigIntegerType.INSTANCE );
 
 		register( StringType.INSTANCE );
 		register( StringNVarcharType.INSTANCE );
 		register( CharacterNCharType.INSTANCE );
 		register( UrlType.INSTANCE );
 
 		register( DateType.INSTANCE );
 		register( TimeType.INSTANCE );
 		register( TimestampType.INSTANCE );
 		register( DbTimestampType.INSTANCE );
 		register( CalendarType.INSTANCE );
 		register( CalendarDateType.INSTANCE );
 
 		register( LocaleType.INSTANCE );
 		register( CurrencyType.INSTANCE );
 		register( TimeZoneType.INSTANCE );
 		register( ClassType.INSTANCE );
 		register( UUIDBinaryType.INSTANCE );
 		register( UUIDCharType.INSTANCE );
 		register( PostgresUUIDType.INSTANCE );
 
 		register( BinaryType.INSTANCE );
 		register( WrapperBinaryType.INSTANCE );
 		register( ImageType.INSTANCE );
 		register( CharArrayType.INSTANCE );
 		register( CharacterArrayType.INSTANCE );
 		register( TextType.INSTANCE );
 		register( NTextType.INSTANCE );
 		register( BlobType.INSTANCE );
 		register( MaterializedBlobType.INSTANCE );
 		register( ClobType.INSTANCE );
 		register( NClobType.INSTANCE );
 		register( MaterializedClobType.INSTANCE );
 		register( MaterializedNClobType.INSTANCE );
 		register( SerializableType.INSTANCE );
 
 		register( ObjectType.INSTANCE );
 
 		//noinspection unchecked
 		register( new AdaptedImmutableType( DateType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( TimeType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( TimestampType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( DbTimestampType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( CalendarType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( CalendarDateType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( BinaryType.INSTANCE ) );
 		//noinspection unchecked
 		register( new AdaptedImmutableType( SerializableType.INSTANCE ) );
 	}
 
 	/**
 	 * Constructor version used during shallow copy
 	 *
 	 * @param registeredTypes The type map to copy over
 	 */
 	@SuppressWarnings({ "UnusedDeclaration" })
 	private BasicTypeRegistry(Map<String, BasicType> registeredTypes) {
 		registry.putAll( registeredTypes );
 		locked = true;
 	}
 
 	public void register(BasicType type) {
 		if ( locked ) {
 			throw new HibernateException( "Can not alter TypeRegistry at this time" );
 		}
 
 		if ( type == null ) {
 			throw new HibernateException( "Type to register cannot be null" );
 		}
 
 		if ( type.getRegistrationKeys() == null || type.getRegistrationKeys().length == 0 ) {
 			LOG.typeDefinedNoRegistrationKeys( type );
 		}
 
 		for ( String key : type.getRegistrationKeys() ) {
 			// be safe...
             if (key == null) continue;
             LOG.debugf("Adding type registration %s -> %s", key, type);
 			final Type old = registry.put( key, type );
             if (old != null && old != type) LOG.typeRegistrationOverridesPrevious(key, old);
 		}
 	}
 
 	public void register(UserType type, String[] keys) {
 		register( new CustomType( type, keys ) );
 	}
 
 	public void register(CompositeUserType type, String[] keys) {
 		register( new CompositeCustomType( type, keys ) );
 	}
 
 	public BasicType getRegisteredType(String key) {
 		return registry.get( key );
 	}
 
 	public BasicTypeRegistry shallowCopy() {
 		return new BasicTypeRegistry( this.registry );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/StandardBasicTypes.java b/hibernate-core/src/main/java/org/hibernate/type/StandardBasicTypes.java
index e853fba1a7..1a6b3954fb 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/StandardBasicTypes.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/StandardBasicTypes.java
@@ -1,348 +1,350 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type;
 
 import java.util.HashSet;
 import java.util.Set;
 
 import org.hibernate.type.descriptor.sql.SqlTypeDescriptor;
 
 /**
  * Centralizes access to the standard set of basic {@link Type types}.
  * <p/>
  * Type mappings can be adjusted per {@link org.hibernate.SessionFactory}.  These adjusted mappings can be accessed
  * from the {@link org.hibernate.TypeHelper} instance obtained via {@link org.hibernate.SessionFactory#getTypeHelper()}
  *
  * @see BasicTypeRegistry
  * @see org.hibernate.TypeHelper
  * @see org.hibernate.SessionFactory#getTypeHelper()
  *
  * @author Gavin King
  * @author Steve Ebersole
  */
 @SuppressWarnings( {"UnusedDeclaration"})
-public class StandardBasicTypes {
+public final class StandardBasicTypes {
+	private StandardBasicTypes() {
+	}
 
-	private static final Set<SqlTypeDescriptor> sqlTypeDescriptors = new HashSet<SqlTypeDescriptor>();
+	private static final Set<SqlTypeDescriptor> SQL_TYPE_DESCRIPTORS = new HashSet<SqlTypeDescriptor>();
 
 	/**
 	 * The standard Hibernate type for mapping {@link Boolean} to JDBC {@link java.sql.Types#BIT BIT}.
 	 *
 	 * @see BooleanType
 	 */
 	public static final BooleanType BOOLEAN = BooleanType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link Boolean} to JDBC {@link java.sql.Types#INTEGER INTEGER}.
 	 *
 	 * @see NumericBooleanType
 	 */
 	public static final NumericBooleanType NUMERIC_BOOLEAN = NumericBooleanType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link Boolean} to JDBC {@link java.sql.Types#CHAR CHAR(1)} (using 'T'/'F').
 	 *
 	 * @see TrueFalseType
 	 */
 	public static final TrueFalseType TRUE_FALSE = TrueFalseType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link Boolean} to JDBC {@link java.sql.Types#CHAR CHAR(1)} (using 'Y'/'N').
 	 *
 	 * @see YesNoType
 	 */
 	public static final YesNoType YES_NO = YesNoType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link Byte} to JDBC {@link java.sql.Types#TINYINT TINYINT}.
 	 */
 	public static final ByteType BYTE = ByteType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link Short} to JDBC {@link java.sql.Types#SMALLINT SMALLINT}.
 	 *
 	 * @see ShortType
 	 */
 	public static final ShortType SHORT = ShortType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link Integer} to JDBC {@link java.sql.Types#INTEGER INTEGER}.
 	 *
 	 * @see IntegerType
 	 */
 	public static final IntegerType INTEGER = IntegerType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link Long} to JDBC {@link java.sql.Types#BIGINT BIGINT}.
 	 *
 	 * @see LongType
 	 */
 	public static final LongType LONG = LongType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link Float} to JDBC {@link java.sql.Types#FLOAT FLOAT}.
 	 *
 	 * @see FloatType
 	 */
 	public static final FloatType FLOAT = FloatType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link Double} to JDBC {@link java.sql.Types#DOUBLE DOUBLE}.
 	 *
 	 * @see DoubleType
 	 */
 	public static final DoubleType DOUBLE = DoubleType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link java.math.BigInteger} to JDBC {@link java.sql.Types#NUMERIC NUMERIC}.
 	 *
 	 * @see BigIntegerType
 	 */
 	public static final BigIntegerType BIG_INTEGER = BigIntegerType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link java.math.BigDecimal} to JDBC {@link java.sql.Types#NUMERIC NUMERIC}.
 	 *
 	 * @see BigDecimalType
 	 */
 	public static final BigDecimalType BIG_DECIMAL = BigDecimalType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link Character} to JDBC {@link java.sql.Types#CHAR CHAR(1)}.
 	 *
 	 * @see CharacterType
 	 */
 	public static final CharacterType CHARACTER = CharacterType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link String} to JDBC {@link java.sql.Types#VARCHAR VARCHAR}.
 	 *
 	 * @see StringType
 	 */
 	public static final StringType STRING = StringType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link java.net.URL} to JDBC {@link java.sql.Types#VARCHAR VARCHAR}.
 	 *
 	 * @see UrlType
 	 */
 	public static final UrlType URL = UrlType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link java.util.Date} ({@link java.sql.Time}) to JDBC
 	 * {@link java.sql.Types#TIME TIME}.
 	 *
 	 * @see TimeType
 	 */
 	public static final TimeType TIME = TimeType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link java.util.Date} ({@link java.sql.Date}) to JDBC
 	 * {@link java.sql.Types#DATE DATE}.
 	 *
 	 * @see TimeType
 	 */
 	public static final DateType DATE = DateType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link java.util.Date} ({@link java.sql.Timestamp}) to JDBC
 	 * {@link java.sql.Types#TIMESTAMP TIMESTAMP}.
 	 *
 	 * @see TimeType
 	 */
 	public static final TimestampType TIMESTAMP = TimestampType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link java.util.Calendar} to JDBC
 	 * {@link java.sql.Types#TIMESTAMP TIMESTAMP}.
 	 *
 	 * @see CalendarType
 	 */
 	public static final CalendarType CALENDAR = CalendarType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link java.util.Calendar} to JDBC
 	 * {@link java.sql.Types#DATE DATE}.
 	 *
 	 * @see CalendarDateType
 	 */
 	public static final CalendarDateType CALENDAR_DATE = CalendarDateType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link Class} to JDBC {@link java.sql.Types#VARCHAR VARCHAR}.
 	 *
 	 * @see ClassType
 	 */
 	public static final ClassType CLASS = ClassType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link java.util.Locale} to JDBC {@link java.sql.Types#VARCHAR VARCHAR}.
 	 *
 	 * @see LocaleType
 	 */
 	public static final LocaleType LOCALE = LocaleType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link java.util.Currency} to JDBC {@link java.sql.Types#VARCHAR VARCHAR}.
 	 *
 	 * @see CurrencyType
 	 */
 	public static final CurrencyType CURRENCY = CurrencyType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link java.util.TimeZone} to JDBC {@link java.sql.Types#VARCHAR VARCHAR}.
 	 *
 	 * @see TimeZoneType
 	 */
 	public static final TimeZoneType TIMEZONE = TimeZoneType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link java.util.UUID} to JDBC {@link java.sql.Types#BINARY BINARY}.
 	 *
 	 * @see UUIDBinaryType
 	 */
 	public static final UUIDBinaryType UUID_BINARY = UUIDBinaryType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link java.util.UUID} to JDBC {@link java.sql.Types#CHAR CHAR}.
 	 *
 	 * @see UUIDCharType
 	 */
 	public static final UUIDCharType UUID_CHAR = UUIDCharType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@code byte[]} to JDBC {@link java.sql.Types#VARBINARY VARBINARY}.
 	 *
 	 * @see BinaryType
 	 */
 	public static final BinaryType BINARY = BinaryType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link Byte Byte[]} to JDBC {@link java.sql.Types#VARBINARY VARBINARY}.
 	 *
 	 * @see WrapperBinaryType
 	 */
 	public static final WrapperBinaryType WRAPPER_BINARY = WrapperBinaryType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@code byte[]} to JDBC {@link java.sql.Types#LONGVARBINARY LONGVARBINARY}.
 	 *
 	 * @see ImageType
 	 * @see #MATERIALIZED_BLOB
 	 */
 	public static final ImageType IMAGE = ImageType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link java.sql.Blob} to JDBC {@link java.sql.Types#BLOB BLOB}.
 	 *
 	 * @see BlobType
 	 * @see #MATERIALIZED_BLOB
 	 */
 	public static final BlobType BLOB = BlobType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@code byte[]} to JDBC {@link java.sql.Types#BLOB BLOB}.
 	 *
 	 * @see MaterializedBlobType
 	 * @see #MATERIALIZED_BLOB
 	 * @see #IMAGE
 	 */
 	public static final MaterializedBlobType MATERIALIZED_BLOB = MaterializedBlobType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@code char[]} to JDBC {@link java.sql.Types#VARCHAR VARCHAR}.
 	 *
 	 * @see CharArrayType
 	 */
 	public static final CharArrayType CHAR_ARRAY = CharArrayType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link Character Character[]} to JDBC
 	 * {@link java.sql.Types#VARCHAR VARCHAR}.
 	 *
 	 * @see CharacterArrayType
 	 */
 	public static final CharacterArrayType CHARACTER_ARRAY = CharacterArrayType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link String} to JDBC {@link java.sql.Types#LONGVARCHAR LONGVARCHAR}.
 	 * <p/>
 	 * Similar to a {@link #MATERIALIZED_CLOB}
 	 *
 	 * @see TextType
 	 */
 	public static final TextType TEXT = TextType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link String} to JDBC {@link java.sql.Types#LONGNVARCHAR LONGNVARCHAR}.
 	 * <p/>
 	 * Similar to a {@link #MATERIALIZED_NCLOB}
 	 *
 	 * @see NTextType
 	 */
 	public static final NTextType NTEXT = NTextType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link java.sql.Clob} to JDBC {@link java.sql.Types#CLOB CLOB}.
 	 *
 	 * @see ClobType
 	 * @see #MATERIALIZED_CLOB
 	 */
 	public static final ClobType CLOB = ClobType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link java.sql.NClob} to JDBC {@link java.sql.Types#NCLOB NCLOB}.
 	 *
 	 * @see NClobType
 	 * @see #MATERIALIZED_NCLOB
 	 */
 	public static final NClobType NCLOB = NClobType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link String} to JDBC {@link java.sql.Types#CLOB CLOB}.
 	 *
 	 * @see MaterializedClobType
 	 * @see #MATERIALIZED_CLOB
 	 * @see #TEXT
 	 */
 	public static final MaterializedClobType MATERIALIZED_CLOB = MaterializedClobType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link String} to JDBC {@link java.sql.Types#NCLOB NCLOB}.
 	 *
 	 * @see MaterializedNClobType
 	 * @see #MATERIALIZED_CLOB
 	 * @see #NTEXT
 	 */
 	public static final MaterializedNClobType MATERIALIZED_NCLOB = MaterializedNClobType.INSTANCE;
 
 	/**
 	 * The standard Hibernate type for mapping {@link java.io.Serializable} to JDBC {@link java.sql.Types#VARBINARY VARBINARY}.
 	 * <p/>
 	 * See especially the discussion wrt {@link ClassLoader} determination on {@link SerializableType}
 	 *
 	 * @see SerializableType
 	 */
 	public static final SerializableType SERIALIZABLE = SerializableType.INSTANCE;
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/descriptor/JdbcTypeNameMapper.java b/hibernate-core/src/main/java/org/hibernate/type/descriptor/JdbcTypeNameMapper.java
index 032dc07878..df43463944 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/descriptor/JdbcTypeNameMapper.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/descriptor/JdbcTypeNameMapper.java
@@ -1,107 +1,110 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type.descriptor;
 
 import java.lang.reflect.Field;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.Map;
 
-import org.jboss.logging.Logger;
-
 import org.hibernate.HibernateException;
+import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 
 /**
  * (Badly named) helper for dealing with standard JDBC types as defined by {@link java.sql.Types}
  *
  * @author Steve Ebersole
  */
-public class JdbcTypeNameMapper {
+public final class JdbcTypeNameMapper {
+    private static final CoreMessageLogger LOG = CoreLogging.messageLogger( JdbcTypeNameMapper.class );
 
-    private static final CoreMessageLogger LOG = Logger.getMessageLogger(CoreMessageLogger.class, JdbcTypeNameMapper.class.getName());
 	private static Map<Integer,String> JDBC_TYPE_MAP = buildJdbcTypeMap();
 
 	private static Map<Integer, String> buildJdbcTypeMap() {
 		HashMap<Integer, String> map = new HashMap<Integer, String>();
 		Field[] fields = java.sql.Types.class.getFields();
 		if ( fields == null ) {
 			throw new HibernateException( "Unexpected problem extracting JDBC type mapping codes from java.sql.Types" );
 		}
 		for ( Field field : fields ) {
 			try {
 				final int code = field.getInt( null );
 				String old = map.put( code, field.getName() );
                 if ( old != null ) {
 					LOG.JavaSqlTypesMappedSameCodeMultipleTimes( code, old, field.getName() );
 				}
 			}
 			catch ( IllegalAccessException e ) {
 				throw new HibernateException( "Unable to access JDBC type mapping [" + field.getName() + "]", e );
 			}
 		}
 		return Collections.unmodifiableMap( map );
 	}
 
 	/**
 	 * Determine whether the given JDBC type code represents a standard JDBC type ("standard" being those defined on
 	 * {@link java.sql.Types}).
 	 *
 	 * NOTE : {@link java.sql.Types#OTHER} is also "filtered out" as being non-standard.
 	 *
 	 * @param typeCode The JDBC type code to check
 	 *
 	 * @return {@code true} to indicate the type code is a standard type code; {@code false} otherwise.
 	 */
 	public static boolean isStandardTypeCode(int typeCode) {
 		return isStandardTypeCode( Integer.valueOf( typeCode ) );
 	}
 
 	/**
 	 * Same as call to {@link #isStandardTypeCode(int)}
 	 *
 	 * @see #isStandardTypeCode(int)
 	 */
 	public static boolean isStandardTypeCode(Integer typeCode) {
 		return JDBC_TYPE_MAP.containsKey( typeCode );
 	}
 
 	/**
 	 * Get the type name as in the static field names defined on {@link java.sql.Types}.  If a type code is not
 	 * recognized, it is reported as {@code UNKNOWN(?)} where '?' is replace with the given type code.
 	 *
 	 * Intended as useful for logging purposes...
 	 *
 	 * @param typeCode The type code to find the name for.
 	 *
 	 * @return The type name.
 	 */
 	public static String getTypeName(Integer typeCode) {
 		String name = JDBC_TYPE_MAP.get( typeCode );
 		if ( name == null ) {
 			return "UNKNOWN(" + typeCode + ")";
 		}
 		return name;
 	}
+
+	private JdbcTypeNameMapper() {
+	}
+
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/descriptor/java/DataHelper.java b/hibernate-core/src/main/java/org/hibernate/type/descriptor/java/DataHelper.java
index 60f977bcde..8d7f8101c5 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/descriptor/java/DataHelper.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/descriptor/java/DataHelper.java
@@ -1,317 +1,319 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type.descriptor.java;
 
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.Reader;
 import java.io.StringReader;
 import java.sql.Clob;
 import java.sql.SQLException;
 import java.sql.SQLFeatureNotSupportedException;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.HibernateException;
 import org.hibernate.engine.jdbc.internal.BinaryStreamImpl;
 import org.hibernate.internal.CoreMessageLogger;
 import org.hibernate.engine.jdbc.BinaryStream;
 
 /**
  * A help for dealing with BLOB and CLOB data
  *
  * @author Steve Ebersole
  */
-public class DataHelper {
+public final class DataHelper {
+	private DataHelper() {
+	}
 
 	/** The size of the buffer we will use to deserialize larger streams */
 	private static final int BUFFER_SIZE = 1024 * 4;
 
 	private static final CoreMessageLogger LOG = Logger.getMessageLogger( CoreMessageLogger.class, DataHelper.class.getName() );
 
 	public static boolean isNClob(final Class type) {
 		return java.sql.NClob.class.isAssignableFrom( type );
 	}
 
 	/**
 	 * Extract the contents of the given reader/stream as a string.
 	 * The reader will be closed.
 	 *
 	 * @param reader The reader for the content
 	 *
 	 * @return The content as string
 	 */
 	public static String extractString(Reader reader) {
 		return extractString( reader, BUFFER_SIZE );
 	}
 
 	/**
 	 * Extract the contents of the given reader/stream as a string.
 	 * The reader will be closed.
 	 *
 	 * @param reader The reader for the content
 	 * @param lengthHint if the length is known in advance the implementation can be slightly more efficient
 	 *
 	 * @return The content as string
 	 */
 	public static String extractString(Reader reader, int lengthHint) {
 		// read the Reader contents into a buffer and return the complete string
 		final int bufferSize = getSuggestedBufferSize( lengthHint );
 		final StringBuilder stringBuilder = new StringBuilder( bufferSize );
 		try {
 			char[] buffer = new char[bufferSize];
 			while (true) {
 				int amountRead = reader.read( buffer, 0, bufferSize );
 				if ( amountRead == -1 ) {
 					break;
 				}
 				stringBuilder.append( buffer, 0, amountRead );
 			}
 		}
 		catch ( IOException ioe ) {
 			throw new HibernateException( "IOException occurred reading text", ioe );
 		}
 		finally {
 			try {
 				reader.close();
 			}
 			catch (IOException e) {
 				LOG.unableToCloseStream( e );
 			}
 		}
 		return stringBuilder.toString();
 	}
 
 	/**
 	 * Extracts a portion of the contents of the given reader/stream as a string.
 	 *
 	 * @param characterStream The reader for the content
 	 * @param start The start position/offset (0-based, per general stream/reader contracts).
 	 * @param length The amount to extract
 	 *
 	 * @return The content as string
 	 */
 	private static String extractString(Reader characterStream, long start, int length) {
 		if ( length == 0 ) {
 			return "";
 		}
 		StringBuilder stringBuilder = new StringBuilder( length );
 		try {
 			long skipped = characterStream.skip( start );
 			if ( skipped != start ) {
 				throw new HibernateException( "Unable to skip needed bytes" );
 			}
 			final int bufferSize = getSuggestedBufferSize( length );
 			char[] buffer = new char[bufferSize];
 			int charsRead = 0;
 			while ( true ) {
 				int amountRead = characterStream.read( buffer, 0, bufferSize );
 				if ( amountRead == -1 ) {
 					break;
 				}
 				stringBuilder.append( buffer, 0, amountRead );
 				if ( amountRead < bufferSize ) {
 					// we have read up to the end of stream
 					break;
 				}
 				charsRead += amountRead;
 				if ( charsRead >= length ) {
 					break;
 				}
 			}
 		}
 		catch ( IOException ioe ) {
 			throw new HibernateException( "IOException occurred reading a binary value", ioe );
 		}
 		return stringBuilder.toString();
 	}
 
 	/**
 	 * Extract a portion of a reader, wrapping the portion in a new reader.
 	 *
 	 * @param characterStream The reader for the content
 	 * @param start The start position/offset (0-based, per general stream/reader contracts).
 	 * @param length The amount to extract
 	 *
 	 * @return The content portion as a reader
 	 */
 	public static Object subStream(Reader characterStream, long start, int length) {
 		return new StringReader( extractString( characterStream, start, length ) );
 	}
 
 	/**
 	 * Extract by bytes from the given stream.
 	 *
 	 * @param inputStream The stream of bytes.
 	 *
 	 * @return The contents as a {@code byte[]}
 	 */
 	public static byte[] extractBytes(InputStream inputStream) {
 		if ( BinaryStream.class.isInstance( inputStream ) ) {
 			return ( (BinaryStream ) inputStream ).getBytes();
 		}
 
 		// read the stream contents into a buffer and return the complete byte[]
 		ByteArrayOutputStream outputStream = new ByteArrayOutputStream(BUFFER_SIZE);
 		try {
 			byte[] buffer = new byte[BUFFER_SIZE];
 			while (true) {
 				int amountRead = inputStream.read( buffer );
 				if ( amountRead == -1 ) {
 					break;
 				}
 				outputStream.write( buffer, 0, amountRead );
 			}
 		}
 		catch ( IOException ioe ) {
 			throw new HibernateException( "IOException occurred reading a binary value", ioe );
 		}
 		finally {
 			try {
 				inputStream.close();
 			}
 			catch ( IOException e ) {
 				LOG.unableToCloseInputStream( e );
 			}
 			try {
 				outputStream.close();
 			}
 			catch ( IOException e ) {
 				LOG.unableToCloseOutputStream( e );
 			}
 		}
 		return outputStream.toByteArray();
 	}
 
 	/**
 	 * Extract a portion of the bytes from the given stream.
 	 *
 	 * @param inputStream The stream of bytes.
 	 * @param start The start position/offset (0-based, per general stream/reader contracts).
 	 * @param length The amount to extract
 	 *
 	 * @return The extracted bytes
 	 */
 	public static byte[] extractBytes(InputStream inputStream, long start, int length) {
 		if ( BinaryStream.class.isInstance( inputStream ) && Integer.MAX_VALUE > start ) {
 			byte[] data = ( (BinaryStream ) inputStream ).getBytes();
 			int size = Math.min( length, data.length );
 			byte[] result = new byte[size];
 			System.arraycopy( data, (int) start, result, 0, size );
 			return result;
 		}
 
 		ByteArrayOutputStream outputStream = new ByteArrayOutputStream( length );
 		try {
 			long skipped = inputStream.skip( start );
 			if ( skipped != start ) {
 				throw new HibernateException( "Unable to skip needed bytes" );
 			}
 			byte[] buffer = new byte[BUFFER_SIZE];
 			int bytesRead = 0;
 			while ( true ) {
 				int amountRead = inputStream.read( buffer );
 				if ( amountRead == -1 ) {
 					break;
 				}
 				outputStream.write( buffer, 0, amountRead );
 				if ( amountRead < buffer.length ) {
 					// we have read up to the end of stream
 					break;
 				}
 				bytesRead += amountRead;
 				if ( bytesRead >= length ) {
 					break;
 				}
 			}
 		}
 		catch ( IOException ioe ) {
 			throw new HibernateException( "IOException occurred reading a binary value", ioe );
 		}
 		return outputStream.toByteArray();
 	}
 
 	/**
 	 * Extract a portion of the bytes from the given stream., wrapping them in a new stream.
 	 *
 	 * @param inputStream The stream of bytes.
 	 * @param start The start position/offset (0-based, per general stream/reader contracts).
 	 * @param length The amount to extract
 	 *
 	 * @return The extracted bytes as a stream
 	 */
 	public static InputStream subStream(InputStream inputStream, long start, int length) {
 		return new BinaryStreamImpl( extractBytes( inputStream, start, length ) );
 	}
 
 	/**
 	 * Extract the contents of the given Clob as a string.
 	 *
 	 * @param value The clob to to be extracted from
 	 *
 	 * @return The content as string
 	 */
 	public static String extractString(final Clob value) {
 		try {
 			final Reader characterStream = value.getCharacterStream();
 			final long length = determineLengthForBufferSizing( value );
 			return length > Integer.MAX_VALUE
 					? extractString( characterStream, Integer.MAX_VALUE )
 					: extractString( characterStream, (int) length );
 		}
 		catch ( SQLException e ) {
 			throw new HibernateException( "Unable to access lob stream", e );
 		}
 	}
 
 	/**
 	 * Determine a buffer size for reading the underlying character stream.
 	 *
 	 * @param value The Clob value
 	 *
 	 * @return The appropriate buffer size ({@link java.sql.Clob#length()} by default.
 	 *
 	 * @throws SQLException
 	 */
 	private static long determineLengthForBufferSizing(Clob value) throws SQLException {
 		try {
 			return value.length();
 		}
 		catch ( SQLFeatureNotSupportedException e ) {
 			return BUFFER_SIZE;
 		}
 	}
 
 	/**
 	 * Make sure we allocate a buffer sized not bigger than 2048,
 	 * not higher than what is actually needed, and at least one.
 	 * 
 	 * @param lengthHint the expected size of the full value
 	 * @return the buffer size
 	 */
 	private static int getSuggestedBufferSize(final int lengthHint) {
 		return Math.max( 1, Math.min( lengthHint , BUFFER_SIZE ) );
 	}
 }
diff --git a/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/JdbcTypeJavaClassMappings.java b/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/JdbcTypeJavaClassMappings.java
index e837f1b521..e74f07788b 100644
--- a/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/JdbcTypeJavaClassMappings.java
+++ b/hibernate-core/src/main/java/org/hibernate/type/descriptor/sql/JdbcTypeJavaClassMappings.java
@@ -1,135 +1,141 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.type.descriptor.sql;
 
 import java.math.BigDecimal;
 import java.sql.Blob;
 import java.sql.Clob;
 import java.sql.Date;
 import java.sql.Ref;
 import java.sql.Struct;
 import java.sql.Time;
 import java.sql.Timestamp;
 import java.sql.Types;
 import java.util.Calendar;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.mapping.Array;
 
 /**
  * Presents recommended {@literal JDCB typecode <-> Java Class} mappings.  Currently the mappings contained here come
  * from the recommendations defined by the JDBC spec itself, as outlined at
  * <a href="http://docs.oracle.com/javase/1.5.0/docs/guide/jdbc/getstart/mapping.html#1034737"/>.
  * <p/>
  * Eventually, the plan is to have {@link org.hibernate.dialect.Dialect} and
  * {@link java.sql.DatabaseMetaData#getTypeInfo()} contribute this information.
  *
  * @author Steve Ebersole
  */
 public class JdbcTypeJavaClassMappings {
 	private static final Logger log = Logger.getLogger( JdbcTypeJavaClassMappings.class );
 
-	private static final ConcurrentHashMap<Class, Integer> javaClassToJdbcTypeCodeMap = buildJdbcJavaClassMappings();
-	private static final ConcurrentHashMap<Integer, Class> jdbcTypeCodeToJavaClassMap = transpose( javaClassToJdbcTypeCodeMap );
-
 	public static final JdbcTypeJavaClassMappings INSTANCE = new JdbcTypeJavaClassMappings();
 
+	private final ConcurrentHashMap<Class, Integer> javaClassToJdbcTypeCodeMap;
+	private final ConcurrentHashMap<Integer, Class> jdbcTypeCodeToJavaClassMap;
+
 	private JdbcTypeJavaClassMappings() {
+		javaClassToJdbcTypeCodeMap = buildJdbcJavaClassMappings();
+		jdbcTypeCodeToJavaClassMap = transpose( javaClassToJdbcTypeCodeMap );
 	}
 
 	public int determineJdbcTypeCodeForJavaClass(Class cls) {
-		Integer typeCode = JdbcTypeJavaClassMappings.javaClassToJdbcTypeCodeMap.get( cls );
+		Integer typeCode = javaClassToJdbcTypeCodeMap.get( cls );
 		if ( typeCode != null ) {
 			return typeCode;
 		}
 
 		int specialCode = cls.hashCode();
 		log.debug(
 				"JDBC type code mapping not known for class [" + cls.getName() + "]; using custom code [" + specialCode + "]"
 		);
 		return specialCode;
 	}
 
-	public Class determineJavaClassForJdbcTypeCode(int typeCode) {
-		Class cls = jdbcTypeCodeToJavaClassMap.get( Integer.valueOf( typeCode ) );
+	public Class determineJavaClassForJdbcTypeCode(Integer typeCode) {
+		Class cls = jdbcTypeCodeToJavaClassMap.get( typeCode );
 		if ( cls != null ) {
 			return cls;
 		}
 
 		log.debugf(
 				"Java Class mapping not known for JDBC type code [%s]; using java.lang.Object",
 				typeCode
 		);
 		return Object.class;
 	}
 
+	public Class determineJavaClassForJdbcTypeCode(int typeCode) {
+		return determineJavaClassForJdbcTypeCode( Integer.valueOf( typeCode ) );
+	}
+
 
 	// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 	private static ConcurrentHashMap<Class, Integer> buildJdbcJavaClassMappings() {
 		ConcurrentHashMap<Class, Integer> jdbcJavaClassMappings = new ConcurrentHashMap<Class, Integer>();
 
 		// these mappings are the ones outlined specifically in the spec
 		jdbcJavaClassMappings.put( String.class, Types.VARCHAR );
 		jdbcJavaClassMappings.put( BigDecimal.class, Types.NUMERIC );
 		jdbcJavaClassMappings.put( Boolean.class, Types.BIT );
 		jdbcJavaClassMappings.put( Integer.class, Types.INTEGER );
 		jdbcJavaClassMappings.put( Long.class, Types.BIGINT );
 		jdbcJavaClassMappings.put( Float.class, Types.REAL );
 		jdbcJavaClassMappings.put( Double.class, Types.DOUBLE );
 		jdbcJavaClassMappings.put( byte[].class, Types.LONGVARBINARY );
 		jdbcJavaClassMappings.put( Date.class, Types.DATE );
 		jdbcJavaClassMappings.put( Time.class, Types.TIME );
 		jdbcJavaClassMappings.put( Timestamp.class, Types.TIMESTAMP );
 		jdbcJavaClassMappings.put( Blob.class, Types.BLOB );
 		jdbcJavaClassMappings.put( Clob.class, Types.CLOB );
 		jdbcJavaClassMappings.put( Array.class, Types.ARRAY );
 		jdbcJavaClassMappings.put( Struct.class, Types.STRUCT );
 		jdbcJavaClassMappings.put( Ref.class, Types.REF );
 		jdbcJavaClassMappings.put( Class.class, Types.JAVA_OBJECT );
 
 		// additional "common sense" registrations
 		jdbcJavaClassMappings.put( Character.class, Types.CHAR );
 		jdbcJavaClassMappings.put( char[].class, Types.VARCHAR );
 		jdbcJavaClassMappings.put( Character[].class, Types.VARCHAR );
 		jdbcJavaClassMappings.put( Byte[].class, Types.LONGVARBINARY );
 		jdbcJavaClassMappings.put( Date.class, Types.TIMESTAMP );
 		jdbcJavaClassMappings.put( Calendar.class, Types.TIMESTAMP );
 
 		return jdbcJavaClassMappings;
 	}
 
 	private static ConcurrentHashMap<Integer, Class> transpose(ConcurrentHashMap<Class, Integer> javaClassToJdbcTypeCodeMap) {
 		final ConcurrentHashMap<Integer, Class> transposed = new ConcurrentHashMap<Integer, Class>();
 
 		for ( Map.Entry<Class,Integer> entry : javaClassToJdbcTypeCodeMap.entrySet() ) {
 			transposed.put( entry.getValue(), entry.getKey() );
 		}
 
 		return transposed;
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/HibernatePersistence.java b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/HibernatePersistence.java
index 90fd3640b0..2840d8977f 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/ejb/HibernatePersistence.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/ejb/HibernatePersistence.java
@@ -1,105 +1,105 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA\
  */
 package org.hibernate.ejb;
 
 import javax.persistence.EntityManagerFactory;
 import javax.persistence.spi.PersistenceProvider;
 import javax.persistence.spi.PersistenceUnitInfo;
 import javax.persistence.spi.ProviderUtil;
 
 import java.util.Map;
 
 import org.hibernate.jpa.HibernatePersistenceProvider;
 import org.hibernate.jpa.boot.spi.EntityManagerFactoryBuilder;
 import org.hibernate.jpa.internal.EntityManagerMessageLogger;
 import org.hibernate.jpa.internal.HEMLogging;
 
 /**
  * Hibernate EJB3 persistence provider implementation
  *
  * @deprecated Use {@link HibernatePersistenceProvider} instead
  *
  * @author Gavin King
  */
 @Deprecated
 public class HibernatePersistence extends HibernatePersistenceProvider implements PersistenceProvider, AvailableSettings {
 	private static final EntityManagerMessageLogger log = HEMLogging.messageLogger( HibernatePersistence.class );
 
 	public HibernatePersistence() {
 	}
 
 	@Override
 	public EntityManagerFactory createEntityManagerFactory(String persistenceUnitName, Map properties) {
 		logDeprecation();
 		return super.createEntityManagerFactory( persistenceUnitName, properties );
 	}
 
 	protected void logDeprecation() {
 		log.deprecatedPersistenceProvider(
 				HibernatePersistence.class.getName(),
 				HibernatePersistenceProvider.class.getName()
 		);
 	}
 
 	@Override
 	public EntityManagerFactory createContainerEntityManagerFactory(PersistenceUnitInfo info, Map properties) {
 		logDeprecation();
 		return super.createContainerEntityManagerFactory( info, properties );
 	}
 
 	@Override
 	public void generateSchema(PersistenceUnitInfo info, Map map) {
 		logDeprecation();
 		super.generateSchema( info, map );
 	}
 
 	@Override
 	public boolean generateSchema(String persistenceUnitName, Map map) {
 		logDeprecation();
 		return super.generateSchema( persistenceUnitName, map );
 	}
 
 	@Override
 	public ProviderUtil getProviderUtil() {
 		logDeprecation();
 		return super.getProviderUtil();
 	}
 
 	@Override
 	protected EntityManagerFactoryBuilder getEntityManagerFactoryBuilderOrNull(
 			String persistenceUnitName,
 			Map properties,
 			ClassLoader providedClassLoader) {
 		logDeprecation();
 		return super.getEntityManagerFactoryBuilderOrNull( persistenceUnitName, properties, providedClassLoader );
 	}
 
 	@Override
 	protected EntityManagerFactoryBuilder getEntityManagerFactoryBuilderOrNull(
 			String persistenceUnitName,
 			Map properties) {
 		logDeprecation();
 		return super.getEntityManagerFactoryBuilderOrNull( persistenceUnitName, properties );
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/internal/ParsedPersistenceXmlDescriptor.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/internal/ParsedPersistenceXmlDescriptor.java
index 2f86048ac8..f09c566ee5 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/internal/ParsedPersistenceXmlDescriptor.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/internal/ParsedPersistenceXmlDescriptor.java
@@ -1,202 +1,202 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.boot.internal;
 
 import javax.persistence.SharedCacheMode;
 import javax.persistence.ValidationMode;
 import javax.persistence.spi.PersistenceUnitTransactionType;
 import java.net.URL;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
 import java.util.Properties;
 
 /**
  * Describes the information gleaned from a {@code <persistence-unit/>} element in a {@code persistence.xml} file
  * whether parsed directly by Hibernate or passed to us by an EE container as a
  * {@link javax.persistence.spi.PersistenceUnitInfo}.
  *
  * Easier to consolidate both views into a single contract and extract information through that shared contract.
  *
  * @author Steve Ebersole
  */
 public class ParsedPersistenceXmlDescriptor implements org.hibernate.jpa.boot.spi.PersistenceUnitDescriptor {
 	private final URL persistenceUnitRootUrl;
 
 	private String name;
 	private Object nonJtaDataSource;
 	private Object jtaDataSource;
 	private String providerClassName;
 	private PersistenceUnitTransactionType transactionType;
-	private boolean useQuotedIdentifiers = false;
-	private boolean excludeUnlistedClasses = false;
+	private boolean useQuotedIdentifiers;
+	private boolean excludeUnlistedClasses;
 	private ValidationMode validationMode;
 	private SharedCacheMode sharedCacheMode;
 
 	private Properties properties = new Properties();
 
 	private List<String> classes = new ArrayList<String>();
 	private List<String> mappingFiles = new ArrayList<String>();
 	private List<URL> jarFileUrls = new ArrayList<URL>();
 
 	public ParsedPersistenceXmlDescriptor(URL persistenceUnitRootUrl) {
 		this.persistenceUnitRootUrl = persistenceUnitRootUrl;
 	}
 
 	@Override
 	public URL getPersistenceUnitRootUrl() {
 		return persistenceUnitRootUrl;
 	}
 
 	@Override
 	public String getName() {
 		return name;
 	}
 
 	public void setName(String name) {
 		this.name = name;
 	}
 
 	@Override
 	public Object getNonJtaDataSource() {
 		return nonJtaDataSource;
 	}
 
 	public void setNonJtaDataSource(Object nonJtaDataSource) {
 		this.nonJtaDataSource = nonJtaDataSource;
 	}
 
 	@Override
 	public Object getJtaDataSource() {
 		return jtaDataSource;
 	}
 
 	public void setJtaDataSource(Object jtaDataSource) {
 		this.jtaDataSource = jtaDataSource;
 	}
 
 	@Override
 	public String getProviderClassName() {
 		return providerClassName;
 	}
 
 	public void setProviderClassName(String providerClassName) {
 		this.providerClassName = providerClassName;
 	}
 
 	@Override
 	public PersistenceUnitTransactionType getTransactionType() {
 		return transactionType;
 	}
 
 	public void setTransactionType(PersistenceUnitTransactionType transactionType) {
 		this.transactionType = transactionType;
 	}
 
 	@Override
 	public boolean isUseQuotedIdentifiers() {
 		return useQuotedIdentifiers;
 	}
 
 	public void setUseQuotedIdentifiers(boolean useQuotedIdentifiers) {
 		this.useQuotedIdentifiers = useQuotedIdentifiers;
 	}
 
 	@Override
 	public Properties getProperties() {
 		return properties;
 	}
 
 	@Override
 	public boolean isExcludeUnlistedClasses() {
 		return excludeUnlistedClasses;
 	}
 
 	public void setExcludeUnlistedClasses(boolean excludeUnlistedClasses) {
 		this.excludeUnlistedClasses = excludeUnlistedClasses;
 	}
 
 	@Override
 	public ValidationMode getValidationMode() {
 		return validationMode;
 	}
 
 	public void setValidationMode(String validationMode) {
 		this.validationMode = ValidationMode.valueOf( validationMode );
 	}
 
 	@Override
 	public SharedCacheMode getSharedCacheMode() {
 		return sharedCacheMode;
 	}
 
 	public void setSharedCacheMode(String sharedCacheMode) {
 		this.sharedCacheMode = SharedCacheMode.valueOf( sharedCacheMode );
 	}
 
 	@Override
 	public List<String> getManagedClassNames() {
 		return classes;
 	}
 
 	public void addClasses(String... classes) {
 		addClasses( Arrays.asList( classes ) );
 	}
 
 	public void addClasses(List<String> classes) {
 		this.classes.addAll( classes );
 	}
 
 	@Override
 	public List<String> getMappingFileNames() {
 		return mappingFiles;
 	}
 
 	public void addMappingFiles(String... mappingFiles) {
 		addMappingFiles( Arrays.asList( mappingFiles ) );
 	}
 
 	public void addMappingFiles(List<String> mappingFiles) {
 		this.mappingFiles.addAll( mappingFiles );
 	}
 
 	@Override
 	public List<URL> getJarFileUrls() {
 		return jarFileUrls;
 	}
 
 	public void addJarFileUrl(URL jarFileUrl) {
 		jarFileUrls.add( jarFileUrl );
 	}
 
 	@Override
 	public ClassLoader getClassLoader() {
 		return null;
 	}
 
 	@Override
 	public void pushClassTransformer(List<String> entityClassNames) {
 		// todo : log a message that this is currently not supported...
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/spi/Bootstrap.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/spi/Bootstrap.java
index 6c7434a3f3..b30827bb54 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/spi/Bootstrap.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/spi/Bootstrap.java
@@ -1,64 +1,67 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.boot.spi;
 
 import java.util.Map;
 
 import javax.persistence.spi.PersistenceUnitInfo;
 
 import org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl;
 import org.hibernate.jpa.boot.internal.PersistenceUnitInfoDescriptor;
 
 /**
  * Entry into the bootstrap process.
  *
  * @author Steve Ebersole
  * @author Brett Meyer
  */
 public final class Bootstrap {
+	private Bootstrap() {
+	}
+
 	public static EntityManagerFactoryBuilder getEntityManagerFactoryBuilder(
 			PersistenceUnitDescriptor persistenceUnitDescriptor,
 			Map integration) {
 		return new EntityManagerFactoryBuilderImpl( persistenceUnitDescriptor, integration );
 	}
 	public static EntityManagerFactoryBuilder getEntityManagerFactoryBuilder(
 			PersistenceUnitDescriptor persistenceUnitDescriptor,
 			Map integration,
 			ClassLoader providedClassLoader) {
 		return new EntityManagerFactoryBuilderImpl( persistenceUnitDescriptor, integration, providedClassLoader );
 	}
 
 	public static EntityManagerFactoryBuilder getEntityManagerFactoryBuilder(
 			PersistenceUnitInfo persistenceUnitInfo,
 			Map integration) {
 		return getEntityManagerFactoryBuilder( new PersistenceUnitInfoDescriptor( persistenceUnitInfo ), integration );
 	}
 
 	public static EntityManagerFactoryBuilder getEntityManagerFactoryBuilder(
 			PersistenceUnitInfo persistenceUnitInfo,
 			Map integration,
 			ClassLoader providedClassLoader) {
 		return getEntityManagerFactoryBuilder( new PersistenceUnitInfoDescriptor( persistenceUnitInfo ), integration, providedClassLoader );
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/spi/ProviderChecker.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/spi/ProviderChecker.java
index 02762f8500..062b3fda11 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/spi/ProviderChecker.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/boot/spi/ProviderChecker.java
@@ -1,131 +1,134 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.boot.spi;
 
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.ejb.HibernatePersistence;
 import org.hibernate.jpa.AvailableSettings;
 import org.hibernate.jpa.HibernatePersistenceProvider;
 
 /**
  * Helper for handling checks to see whether Hibernate is the requested
  * {@link javax.persistence.spi.PersistenceProvider}
  *
  * @author Steve Ebersole
  */
-public class ProviderChecker {
+public final class ProviderChecker {
 	private static final Logger log = Logger.getLogger( ProviderChecker.class );
 
 	@SuppressWarnings("deprecation")
 	private static String[] HIBERNATE_PROVIDER_NAMES = new String[] {
 			HibernatePersistenceProvider.class.getName(),
 			HibernatePersistence.class.getName()
 	};
 
 	/**
 	 * Does the descriptor and/or integration request Hibernate as the
 	 * {@link javax.persistence.spi.PersistenceProvider}?  Note that in the case of no requested provider being named
 	 * we assume we are the provider (the calls got to us somehow...)
 	 *
 	 * @param persistenceUnit The {@code <persistence-unit/>} descriptor.
 	 * @param integration The integration values.
 	 *
 	 * @return {@code true} if Hibernate should be the provider; {@code false} otherwise.
 	 */
 	public static boolean isProvider(PersistenceUnitDescriptor persistenceUnit, Map integration) {
 		// See if we (Hibernate) are the persistence provider
 		return hibernateProviderNamesContain( extractRequestedProviderName( persistenceUnit, integration ) );
 	}
 
 	/**
 	 * Is the requested provider name one of the recognized Hibernate provider names?
 	 *
 	 * @param requestedProviderName The requested provider name to check against the recognized Hibernate names.
 	 *
 	 * @return {@code true} if Hibernate should be the provider; {@code false} otherwise.
 	 */
 	public static boolean hibernateProviderNamesContain(String requestedProviderName) {
 		log.tracef(
 				"Checking requested PersistenceProvider name [%s] against Hibernate provider names",
 				requestedProviderName
 		);
 
 		for ( String hibernateProviderName : HIBERNATE_PROVIDER_NAMES ) {
 			if ( requestedProviderName.equals( hibernateProviderName ) ) {
 				return true;
 			}
 		}
 
 		log.tracef( "Found no match against Hibernate provider names" );
 		return false;
 	}
 
 	/**
 	 * Extract the requested persistence provider name using the algorithm Hibernate uses.  Namely, a provider named
 	 * in the 'integration' map (under the key '{@value AvailableSettings#PROVIDER}') is preferred, as per-spec, over
 	 * value specified in persistence unit.
 	 *
 	 * @param persistenceUnit The {@code <persistence-unit/>} descriptor.
 	 * @param integration The integration values.
 	 *
 	 * @return The extracted provider name, or {@code null} if none found.
 	 */
 	public static String extractRequestedProviderName(PersistenceUnitDescriptor persistenceUnit, Map integration) {
 		final String integrationProviderName = extractProviderName( integration );
 		if ( integrationProviderName != null ) {
 			log.debugf( "Integration provided explicit PersistenceProvider [%s]", integrationProviderName );
 			return integrationProviderName;
 		}
 
 		final String persistenceUnitRequestedProvider = extractProviderName( persistenceUnit );
 		if ( persistenceUnitRequestedProvider != null ) {
 			log.debugf(
 					"Persistence-unit [%s] requested PersistenceProvider [%s]",
 					persistenceUnit.getName(),
 					persistenceUnitRequestedProvider
 			);
 			return persistenceUnitRequestedProvider;
 		}
 
 		// NOTE : if no provider requested we assume we are the provider (the calls got to us somehow...)
 		log.debug( "No PersistenceProvider explicitly requested, assuming Hibernate" );
 		return HibernatePersistenceProvider.class.getName();
 	}
 
 	private static String extractProviderName(Map integration) {
 		if ( integration == null ) {
 			return null;
 		}
 		final String setting = (String) integration.get( AvailableSettings.PROVIDER );
 		return setting == null ? null : setting.trim();
 	}
 
 	private static String extractProviderName(PersistenceUnitDescriptor persistenceUnit) {
 		final String persistenceUnitRequestedProvider = persistenceUnit.getProviderClassName();
 		return persistenceUnitRequestedProvider == null ? null : persistenceUnitRequestedProvider.trim();
 	}
+
+	private ProviderChecker() {
+	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/AbstractNode.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/AbstractNode.java
index b2f31bdc5f..f37dc448f3 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/AbstractNode.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/AbstractNode.java
@@ -1,48 +1,49 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.criteria;
+
 import java.io.Serializable;
 
 /**
  * All nodes in a criteria query tree will generally need access to the {@link CriteriaBuilderImpl} from which they
  * come.  This base class provides convenient, consistent support for that.
  *
  * @author Steve Ebersole
  */
-public class AbstractNode implements Serializable {
+public abstract class AbstractNode implements Serializable {
 	private final CriteriaBuilderImpl criteriaBuilder;
 
 	public AbstractNode(CriteriaBuilderImpl criteriaBuilder) {
 		this.criteriaBuilder = criteriaBuilder;
 	}
 
 	/**
 	 * Provides access to the underlying {@link CriteriaBuilderImpl}.
 	 *
 	 * @return The underlying {@link CriteriaBuilderImpl} instance.
 	 */
 	public CriteriaBuilderImpl criteriaBuilder() {
 		return criteriaBuilder;
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/compile/CriteriaCompiler.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/compile/CriteriaCompiler.java
index 6c21243538..07b5d0ba55 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/compile/CriteriaCompiler.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/compile/CriteriaCompiler.java
@@ -1,163 +1,163 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.criteria.compile;
 
 import javax.persistence.Query;
 import javax.persistence.TypedQuery;
 import javax.persistence.criteria.ParameterExpression;
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.jpa.spi.HibernateEntityManagerImplementor;
 import org.hibernate.type.Type;
 
 /**
  * Compiles a JPA criteria query into an executable {@link TypedQuery}.  Its single contract is the {@link #compile}
  * method.
  * <p/>
  * NOTE : This is a temporary implementation which simply translates the criteria query into a JPAQL query string.  A
  * better, long-term solution is being implemented as part of refactoring the JPAQL/HQL translator.
  *
  * @author Steve Ebersole
  */
 public class CriteriaCompiler implements Serializable {
 	private final HibernateEntityManagerImplementor entityManager;
 
 	public CriteriaCompiler(HibernateEntityManagerImplementor entityManager) {
 		this.entityManager = entityManager;
 	}
 
 	public Query compile(CompilableCriteria criteria) {
 		try {
 			criteria.validate();
 		}
 		catch (IllegalStateException ise) {
 			throw new IllegalArgumentException( "Error occurred validating the Criteria", ise );
 		}
 
 		final Map<ParameterExpression<?>, ExplicitParameterInfo<?>> explicitParameterInfoMap =
 				new HashMap<ParameterExpression<?>, ExplicitParameterInfo<?>>();
 
 		final List<ImplicitParameterBinding> implicitParameterBindings = new ArrayList<ImplicitParameterBinding>();
 
 		RenderingContext renderingContext = new RenderingContext() {
-			private int aliasCount = 0;
-			private int explicitParameterCount = 0;
+			private int aliasCount;
+			private int explicitParameterCount;
 
 			public String generateAlias() {
 				return "generatedAlias" + aliasCount++;
 			}
 
 			public String generateParameterName() {
 				return "param" + explicitParameterCount++;
 			}
 
 			@Override
 			@SuppressWarnings("unchecked")
 			public ExplicitParameterInfo registerExplicitParameter(ParameterExpression<?> criteriaQueryParameter) {
 				ExplicitParameterInfo parameterInfo = explicitParameterInfoMap.get( criteriaQueryParameter );
 				if ( parameterInfo == null ) {
 					if ( StringHelper.isNotEmpty( criteriaQueryParameter.getName() ) ) {
 						parameterInfo = new ExplicitParameterInfo(
 								criteriaQueryParameter.getName(),
 								null,
 								criteriaQueryParameter.getJavaType()
 						);
 					}
 					else if ( criteriaQueryParameter.getPosition() != null ) {
 						parameterInfo = new ExplicitParameterInfo(
 								null,
 								criteriaQueryParameter.getPosition(),
 								criteriaQueryParameter.getJavaType()
 						);
 					}
 					else {
 						parameterInfo = new ExplicitParameterInfo(
 								generateParameterName(),
 								null,
 								criteriaQueryParameter.getJavaType()
 						);
 					}
 
 					explicitParameterInfoMap.put( criteriaQueryParameter, parameterInfo );
 				}
 
 				return parameterInfo;
 			}
 
 			public String registerLiteralParameterBinding(final Object literal, final Class javaType) {
 				final String parameterName = generateParameterName();
 				final ImplicitParameterBinding binding = new ImplicitParameterBinding() {
 					public String getParameterName() {
 						return parameterName;
 					}
 
 					public Class getJavaType() {
 						return javaType;
 					}
 
 					public void bind(TypedQuery typedQuery) {
 						typedQuery.setParameter( parameterName, literal );
 					}
 				};
 
 				implicitParameterBindings.add( binding );
 				return parameterName;
 			}
 
 			public String getCastType(Class javaType) {
 				SessionFactoryImplementor factory =
 						( SessionFactoryImplementor ) entityManager.getFactory().getSessionFactory();
 				Type hibernateType = factory.getTypeResolver().heuristicType( javaType.getName() );
 				if ( hibernateType == null ) {
 					throw new IllegalArgumentException(
 							"Could not convert java type [" + javaType.getName() + "] to Hibernate type"
 					);
 				}
 				return hibernateType.getName();
 			}
 		};
 
 		return criteria.interpret( renderingContext ).buildCompiledQuery(
 				entityManager,
 				new InterpretedParameterMetadata() {
 					@Override
 					public Map<ParameterExpression<?>, ExplicitParameterInfo<?>> explicitParameterInfoMap() {
 						return explicitParameterInfoMap;
 					}
 
 					@Override
 					public List<ImplicitParameterBinding> implicitParameterBindings() {
 						return implicitParameterBindings;
 					}
 				}
 		);
 	}
 
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/NullLiteralExpression.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/NullLiteralExpression.java
index 683104026a..deb061ea35 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/NullLiteralExpression.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/expression/NullLiteralExpression.java
@@ -1,53 +1,53 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.criteria.expression;
 
 import java.io.Serializable;
 
 import org.hibernate.jpa.criteria.CriteriaBuilderImpl;
 import org.hibernate.jpa.criteria.ParameterRegistry;
 import org.hibernate.jpa.criteria.compile.RenderingContext;
 
 /**
  * Represents a <tt>NULL</tt>literal expression.
  *
  * @author Steve Ebersole
  */
 public class NullLiteralExpression<T> extends ExpressionImpl<T> implements Serializable {
 	public NullLiteralExpression(CriteriaBuilderImpl criteriaBuilder, Class<T> type) {
 		super( criteriaBuilder, type );
 	}
 
 	public void registerParameters(ParameterRegistry registry) {
 		// nothing to do
 	}
 
 	public String render(RenderingContext renderingContext) {
 		return "null";
 	}
 
 	public String renderProjection(RenderingContext renderingContext) {
 		return render( renderingContext );
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/predicate/BooleanStaticAssertionPredicate.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/predicate/BooleanStaticAssertionPredicate.java
index ae51db3a12..08c902320e 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/predicate/BooleanStaticAssertionPredicate.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/predicate/BooleanStaticAssertionPredicate.java
@@ -1,67 +1,67 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.criteria.predicate;
 
 import java.io.Serializable;
 
 import org.hibernate.jpa.criteria.CriteriaBuilderImpl;
 import org.hibernate.jpa.criteria.ParameterRegistry;
 import org.hibernate.jpa.criteria.compile.RenderingContext;
 
 /**
  * Predicate used to assert a static boolean condition.
  *
  * @author Steve Ebersole
  */
 public class BooleanStaticAssertionPredicate
 		extends AbstractSimplePredicate
 		implements Serializable {
 	private final Boolean assertedValue;
 
 	public BooleanStaticAssertionPredicate(
 			CriteriaBuilderImpl criteriaBuilder,
 			Boolean assertedValue) {
 		super( criteriaBuilder );
 		this.assertedValue = assertedValue;
 	}
 
 	public Boolean getAssertedValue() {
 		return assertedValue;
 	}
 
 	@Override
 	public void registerParameters(ParameterRegistry registry) {
 		// nada
 	}
 
 	@Override
 	public String render(boolean isNegated, RenderingContext renderingContext) {
 		boolean isTrue = getAssertedValue();
 		if ( isNegated ) {
 			isTrue = !isTrue;
 		}
 		return isTrue ? "1=1" : "0=1";
 	}
 
-}
\ No newline at end of file
+}
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/predicate/ImplicitNumericExpressionTypeDeterminer.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/predicate/ImplicitNumericExpressionTypeDeterminer.java
index 832f6657d3..3d2a1616c5 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/predicate/ImplicitNumericExpressionTypeDeterminer.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/criteria/predicate/ImplicitNumericExpressionTypeDeterminer.java
@@ -1,75 +1,78 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.criteria.predicate;
 
 import java.math.BigDecimal;
 import java.math.BigInteger;
 
 /**
  * @author Steve Ebersole
  */
-public class ImplicitNumericExpressionTypeDeterminer {
+public final class ImplicitNumericExpressionTypeDeterminer {
+	private ImplicitNumericExpressionTypeDeterminer() {
+	}
+
 	/**
 	 * Determine the appropriate runtime result type for a numeric expression according to
 	 * section "6.5.7.1 Result Types of Expressions" of the JPA spec.
 	 * <p/>
 	 * Note that it is expected that the caveats about quotient handling have already been handled.
 	 *
 	 * @param types The argument/expression types
 	 *
 	 * @return The appropriate numeric result type.
 	 */
 	public static Class<? extends Number> determineResultType(Class<? extends Number>... types) {
 		Class<? extends Number> result = Number.class;
 
 		for ( Class<? extends Number> type : types ) {
 			if ( Double.class.equals( type ) ) {
 				result = Double.class;
 			}
 			else if ( Float.class.equals( type ) ) {
 				result = Float.class;
 			}
 			else if ( BigDecimal.class.equals( type ) ) {
 				result = BigDecimal.class;
 			}
 			else if ( BigInteger.class.equals( type ) ) {
 				result = BigInteger.class;
 			}
 			else if ( Long.class.equals( type ) ) {
 				result = Long.class;
 			}
 			else if ( isIntegralType( type ) ) {
 				result = Integer.class;
 			}
 		}
 
 		return result;
 	}
 
 	private static boolean isIntegralType(Class<? extends Number> type) {
 		return Integer.class.equals( type ) ||
 				Short.class.equals( type );
 
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/core/package-info.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/core/package-info.java
index 981dcb0e78..982369dc28 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/core/package-info.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/core/package-info.java
@@ -1,32 +1,32 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.event.internal.core;
 
 /**
  * Hibernate EntityManager specific implementations of Hibernate event listeners.  Generally the listeners
  * here either:<ul>
  *     <li>provide tweaks to internal processing to conform with JPA spec</li>
  *     <li>bridge to JPA event callbacks</li>
  * </ul>
- */
\ No newline at end of file
+ */
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/jpa/package-info.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/jpa/package-info.java
index 978b9da95c..7aaeeba5a3 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/jpa/package-info.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/internal/jpa/package-info.java
@@ -1,28 +1,28 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.event.internal.jpa;
 
 /**
  * Classes for integrating with JPA event callbacks
- */
\ No newline at end of file
+ */
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/spi/jpa/package-info.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/spi/jpa/package-info.java
index 2ff6682a86..5f6e2ecf1e 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/spi/jpa/package-info.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/event/spi/jpa/package-info.java
@@ -1,28 +1,28 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.event.spi.jpa;
 
 /**
  * SPI classes for integrating with JPA event callbacks
- */
\ No newline at end of file
+ */
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/metamodel/AbstractManagedType.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/metamodel/AbstractManagedType.java
index 18a668f8c8..8e0364efb4 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/metamodel/AbstractManagedType.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/metamodel/AbstractManagedType.java
@@ -1,497 +1,497 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2009 by Red Hat Inc and/or its affiliates or by
  * third-party contributors as indicated by either @author tags or express
  * copyright attribution statements applied by the authors.  All
  * third-party contributions are distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.internal.metamodel;
 
 import javax.persistence.metamodel.Attribute;
 import javax.persistence.metamodel.Bindable;
 import javax.persistence.metamodel.CollectionAttribute;
 import javax.persistence.metamodel.ListAttribute;
 import javax.persistence.metamodel.ManagedType;
 import javax.persistence.metamodel.MapAttribute;
 import javax.persistence.metamodel.PluralAttribute;
 import javax.persistence.metamodel.SetAttribute;
 import javax.persistence.metamodel.SingularAttribute;
 import java.io.Serializable;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.annotations.common.AssertionFailure;
 
 /**
  * Defines commonality for the JPA {@link ManagedType} hierarchy of interfaces.
  *
  * @author Steve Ebersole
  */
 public abstract class AbstractManagedType<X> 
 		extends AbstractType<X>
 		implements ManagedType<X>, Serializable {
 
 	private final  AbstractManagedType<? super X> superType;
 
 	private final Map<String,Attribute<X, ?>> declaredAttributes
 			= new HashMap<String, Attribute<X,?>>();
 	private final Map<String, SingularAttribute<X, ?>> declaredSingularAttributes
 			= new HashMap<String, SingularAttribute<X,?>>();
 	private final Map<String, PluralAttribute<X, ?, ?>> declaredPluralAttributes
 			= new HashMap<String, PluralAttribute<X,?,?>>();
 
 	protected AbstractManagedType(Class<X> javaType, String typeName, AbstractManagedType<? super X> superType) {
 		super( javaType, typeName );
 		this.superType = superType;
 	}
 
 	protected AbstractManagedType<? super X> getSupertype() {
 		return superType;
 	}
 
-	private boolean locked = false;
+	private boolean locked;
 
 	public Builder<X> getBuilder() {
 		if ( locked ) {
 			throw new IllegalStateException( "Type has been locked" );
 		}
 		return new Builder<X>() {
 			@Override
 			@SuppressWarnings("unchecked")
 			public void addAttribute(Attribute<X,?> attribute) {
 				declaredAttributes.put( attribute.getName(), attribute );
 				final Bindable.BindableType bindableType = ( ( Bindable ) attribute ).getBindableType();
 				switch ( bindableType ) {
 					case SINGULAR_ATTRIBUTE : {
 						declaredSingularAttributes.put( attribute.getName(), (SingularAttribute<X,?>) attribute );
 						break;
 					}
 					case PLURAL_ATTRIBUTE : {
 						declaredPluralAttributes.put(attribute.getName(), (PluralAttribute<X,?,?>) attribute );
 						break;
 					}
 					default : {
 						throw new AssertionFailure( "unknown bindable type: " + bindableType );
 					}
 				}
 			}
 		};
 	}
 
 	public void lock() {
 		locked = true;
 	}
 
 	public static interface Builder<X> {
 		public void addAttribute(Attribute<X,?> attribute);
 	}
 
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public Set<Attribute<? super X, ?>> getAttributes() {
 		HashSet attributes = new HashSet<Attribute<X, ?>>( declaredAttributes.values() );
 		if ( getSupertype() != null ) {
 			attributes.addAll( getSupertype().getAttributes() );
 		}
 		return attributes;
 	}
 
 	@Override
 	public Set<Attribute<X, ?>> getDeclaredAttributes() {
 		return new HashSet<Attribute<X, ?>>( declaredAttributes.values() );
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public Attribute<? super X, ?> getAttribute(String name) {
 		Attribute<? super X, ?> attribute = declaredAttributes.get( name );
 		if ( attribute == null && getSupertype() != null ) {
 			attribute = getSupertype().getAttribute( name );
 		}
 		checkNotNull( "Attribute ", attribute, name );
 		return attribute;
 	}
 
 	@Override
 	public Attribute<X, ?> getDeclaredAttribute(String name) {
 		Attribute<X, ?> attr = declaredAttributes.get( name );
 		checkNotNull( "Attribute ", attr, name );
 		return attr;
 	}
 
 	private void checkNotNull(String attributeType, Attribute<?,?> attribute, String name) {
 
 		if ( attribute == null ) {
 			throw new IllegalArgumentException(
 					String.format(
 							"Unable to locate %s with the the given name [%s] on this ManagedType [%s]",
 							attributeType,
 							name,
 							getTypeName()
 					)
 			);
 		}
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public Set<SingularAttribute<? super X, ?>> getSingularAttributes() {
 		HashSet attributes = new HashSet<SingularAttribute<X, ?>>( declaredSingularAttributes.values() );
 		if ( getSupertype() != null ) {
 			attributes.addAll( getSupertype().getSingularAttributes() );
 		}
 		return attributes;
 	}
 
 	@Override
 	public Set<SingularAttribute<X, ?>> getDeclaredSingularAttributes() {
 		return new HashSet<SingularAttribute<X, ?>>( declaredSingularAttributes.values() );
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public SingularAttribute<? super X, ?> getSingularAttribute(String name) {
 		SingularAttribute<? super X, ?> attribute = declaredSingularAttributes.get( name );
 		if ( attribute == null && getSupertype() != null ) {
 			attribute = getSupertype().getSingularAttribute( name );
 		}
 		checkNotNull( "SingularAttribute ", attribute, name );
 		return attribute;
 	}
 
 	@Override
 	public SingularAttribute<X, ?> getDeclaredSingularAttribute(String name) {
 		final SingularAttribute<X, ?> attr = declaredSingularAttributes.get( name );
 		checkNotNull( "SingularAttribute ", attr, name );
 		return attr;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public <Y> SingularAttribute<? super X, Y> getSingularAttribute(String name, Class<Y> type) {
 		SingularAttribute<? super X, ?> attribute = declaredSingularAttributes.get( name );
 		if ( attribute == null && getSupertype() != null ) {
 			attribute = getSupertype().getSingularAttribute( name );
 		}
 		checkTypeForSingleAttribute( "SingularAttribute ", attribute, name, type );
 		return ( SingularAttribute<? super X, Y> ) attribute;
 	}
 
 	@Override
 	@SuppressWarnings( "unchecked")
 	public <Y> SingularAttribute<X, Y> getDeclaredSingularAttribute(String name, Class<Y> javaType) {
 		final SingularAttribute<X, ?> attr = declaredSingularAttributes.get( name );
 		checkTypeForSingleAttribute( "SingularAttribute ", attr, name, javaType );
 		return ( SingularAttribute<X, Y> ) attr;
 	}
 
 	private <Y> void checkTypeForSingleAttribute(
 			String attributeType,
 			SingularAttribute<?,?> attribute,
 			String name,
 			Class<Y> javaType) {
 		if ( attribute == null || ( javaType != null && !attribute.getBindableJavaType().equals( javaType ) ) ) {
 			if ( isPrimitiveVariant( attribute, javaType ) ) {
 				return;
 			}
 			throw new IllegalArgumentException(
 					attributeType + " named " + name
 					+ ( javaType != null ? " and of type " + javaType.getName() : "" )
 					+ " is not present"
 			);
 		}
 	}
 
 	@SuppressWarnings({ "SimplifiableIfStatement" })
 	protected <Y> boolean isPrimitiveVariant(SingularAttribute<?,?> attribute, Class<Y> javaType) {
 		if ( attribute == null ) {
 			return false;
 		}
 		Class declaredType = attribute.getBindableJavaType();
 
 		if ( declaredType.isPrimitive() ) {
 			return ( Boolean.class.equals( javaType ) && Boolean.TYPE.equals( declaredType ) )
 					|| ( Character.class.equals( javaType ) && Character.TYPE.equals( declaredType ) )
 					|| ( Byte.class.equals( javaType ) && Byte.TYPE.equals( declaredType ) )
 					|| ( Short.class.equals( javaType ) && Short.TYPE.equals( declaredType ) )
 					|| ( Integer.class.equals( javaType ) && Integer.TYPE.equals( declaredType ) )
 					|| ( Long.class.equals( javaType ) && Long.TYPE.equals( declaredType ) )
 					|| ( Float.class.equals( javaType ) && Float.TYPE.equals( declaredType ) )
 					|| ( Double.class.equals( javaType ) && Double.TYPE.equals( declaredType ) );
 		}
 
 		if ( javaType.isPrimitive() ) {
 			return ( Boolean.class.equals( declaredType ) && Boolean.TYPE.equals( javaType ) )
 					|| ( Character.class.equals( declaredType ) && Character.TYPE.equals( javaType ) )
 					|| ( Byte.class.equals( declaredType ) && Byte.TYPE.equals( javaType ) )
 					|| ( Short.class.equals( declaredType ) && Short.TYPE.equals( javaType ) )
 					|| ( Integer.class.equals( declaredType ) && Integer.TYPE.equals( javaType ) )
 					|| ( Long.class.equals( declaredType ) && Long.TYPE.equals( javaType ) )
 					|| ( Float.class.equals( declaredType ) && Float.TYPE.equals( javaType ) )
 					|| ( Double.class.equals( declaredType ) && Double.TYPE.equals( javaType ) );
 		}
 
 		return false;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public Set<PluralAttribute<? super X, ?, ?>> getPluralAttributes() {
 		HashSet attributes = new HashSet<PluralAttribute<? super X, ?, ?>>( declaredPluralAttributes.values() );
 		if ( getSupertype() != null ) {
 			attributes.addAll( getSupertype().getPluralAttributes() );
 		}
 		return attributes;
 	}
 
 	@Override
 	public Set<PluralAttribute<X, ?, ?>> getDeclaredPluralAttributes() {
 		return new HashSet<PluralAttribute<X,?,?>>( declaredPluralAttributes.values() );
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public CollectionAttribute<? super X, ?> getCollection(String name) {
 		PluralAttribute<? super X, ?, ?> attribute = getPluralAttribute( name );
 		if ( attribute == null && getSupertype() != null ) {
 			attribute = getSupertype().getPluralAttribute( name );
 		}
 		basicCollectionCheck( attribute, name );
 		return ( CollectionAttribute<X, ?> ) attribute;
 	}
 
 	private PluralAttribute<? super X, ?, ?> getPluralAttribute(String name) {
 		return declaredPluralAttributes.get( name );
 	}
 
 	private void basicCollectionCheck(PluralAttribute<? super X, ?, ?> attribute, String name) {
 		checkNotNull( "CollectionAttribute", attribute, name );
 		if ( ! CollectionAttribute.class.isAssignableFrom( attribute.getClass() ) ) {
 			throw new IllegalArgumentException( name + " is not a CollectionAttribute: " + attribute.getClass() );
 		}
 	}
 
 	@Override
 	@SuppressWarnings( "unchecked")
 	public CollectionAttribute<X, ?> getDeclaredCollection(String name) {
 		final PluralAttribute<X,?,?> attribute = declaredPluralAttributes.get( name );
 		basicCollectionCheck( attribute, name );
 		return ( CollectionAttribute<X, ?> ) attribute;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public SetAttribute<? super X, ?> getSet(String name) {
 		PluralAttribute<? super X, ?, ?> attribute = getPluralAttribute( name );
 		if ( attribute == null && getSupertype() != null ) {
 			attribute = getSupertype().getPluralAttribute( name );
 		}
 		basicSetCheck( attribute, name );
 		return (SetAttribute<? super X, ?>) attribute;
 	}
 
 	private void basicSetCheck(PluralAttribute<? super X, ?, ?> attribute, String name) {
 		checkNotNull( "SetAttribute", attribute, name );
 		if ( ! SetAttribute.class.isAssignableFrom( attribute.getClass() ) ) {
 			throw new IllegalArgumentException( name + " is not a SetAttribute: " + attribute.getClass() );
 		}
 	}
 
 	@Override
 	@SuppressWarnings( "unchecked")
 	public SetAttribute<X, ?> getDeclaredSet(String name) {
 		final PluralAttribute<X,?,?> attribute = declaredPluralAttributes.get( name );
 		basicSetCheck( attribute, name );
 		return ( SetAttribute<X, ?> ) attribute;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public ListAttribute<? super X, ?> getList(String name) {
 		PluralAttribute<? super X, ?, ?> attribute = getPluralAttribute( name );
 		if ( attribute == null && getSupertype() != null ) {
 			attribute = getSupertype().getPluralAttribute( name );
 		}
 		basicListCheck( attribute, name );
 		return (ListAttribute<? super X, ?>) attribute;
 	}
 
 	private void basicListCheck(PluralAttribute<? super X, ?, ?> attribute, String name) {
 		checkNotNull( "ListAttribute", attribute, name );
 		if ( ! ListAttribute.class.isAssignableFrom( attribute.getClass() ) ) {
 			throw new IllegalArgumentException( name + " is not a ListAttribute: " + attribute.getClass() );
 		}
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public ListAttribute<X, ?> getDeclaredList(String name) {
 		final PluralAttribute<X,?,?> attribute = declaredPluralAttributes.get( name );
 		basicListCheck( attribute, name );
 		return ( ListAttribute<X, ?> ) attribute;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public MapAttribute<? super X, ?, ?> getMap(String name) {
 		PluralAttribute<? super X, ?, ?> attribute = getPluralAttribute( name );
 		if ( attribute == null && getSupertype() != null ) {
 			attribute = getSupertype().getPluralAttribute( name );
 		}
 		basicMapCheck( attribute, name );
 		return (MapAttribute<? super X, ?, ?>) attribute;
 	}
 
 	private void basicMapCheck(PluralAttribute<? super X, ?, ?> attribute, String name) {
 		checkNotNull( "MapAttribute", attribute, name );
 		if ( ! MapAttribute.class.isAssignableFrom( attribute.getClass() ) ) {
 			throw new IllegalArgumentException( name + " is not a MapAttribute: " + attribute.getClass() );
 		}
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public MapAttribute<X, ?, ?> getDeclaredMap(String name) {
 		final PluralAttribute<X,?,?> attribute = declaredPluralAttributes.get( name );
 		basicMapCheck( attribute, name );
 		return ( MapAttribute<X,?,?> ) attribute;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public <E> CollectionAttribute<? super X, E> getCollection(String name, Class<E> elementType) {
 		PluralAttribute<? super X, ?, ?> attribute = declaredPluralAttributes.get( name );
 		if ( attribute == null && getSupertype() != null ) {
 			attribute = getSupertype().getPluralAttribute( name );
 		}
 		checkCollectionElementType( attribute, name, elementType );
 		return ( CollectionAttribute<? super X, E> ) attribute;
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <E> CollectionAttribute<X, E> getDeclaredCollection(String name, Class<E> elementType) {
 		final PluralAttribute<X,?,?> attribute = declaredPluralAttributes.get( name );
 		checkCollectionElementType( attribute, name, elementType );
 		return ( CollectionAttribute<X, E> ) attribute;
 	}
 
 	private <E> void checkCollectionElementType(PluralAttribute<?,?,?> attribute, String name, Class<E> elementType) {
 		checkTypeForPluralAttributes( "CollectionAttribute", attribute, name, elementType, PluralAttribute.CollectionType.COLLECTION );
 	}
 
 	private <E> void checkTypeForPluralAttributes(
 			String attributeType,
 			PluralAttribute<?,?,?> attribute,
 			String name,
 			Class<E> elementType,
 			PluralAttribute.CollectionType collectionType) {
 		if ( attribute == null
 				|| ( elementType != null && !attribute.getBindableJavaType().equals( elementType ) )
 				|| attribute.getCollectionType() != collectionType ) {
 			throw new IllegalArgumentException(
 					attributeType + " named " + name
 					+ ( elementType != null ? " and of element type " + elementType : "" )
 					+ " is not present"
 			);
 		}
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public <E> SetAttribute<? super X, E> getSet(String name, Class<E> elementType) {
 		PluralAttribute<? super X, ?, ?> attribute = declaredPluralAttributes.get( name );
 		if ( attribute == null && getSupertype() != null ) {
 			attribute = getSupertype().getPluralAttribute( name );
 		}
 		checkSetElementType( attribute, name, elementType );
 		return ( SetAttribute<? super X, E> ) attribute;
 	}
 
 	private <E> void checkSetElementType(PluralAttribute<? super X, ?, ?> attribute, String name, Class<E> elementType) {
 		checkTypeForPluralAttributes( "SetAttribute", attribute, name, elementType, PluralAttribute.CollectionType.SET );
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <E> SetAttribute<X, E> getDeclaredSet(String name, Class<E> elementType) {
 		final PluralAttribute<X,?,?> attribute = declaredPluralAttributes.get( name );
 		checkSetElementType( attribute, name, elementType );
 		return ( SetAttribute<X, E> ) attribute;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public <E> ListAttribute<? super X, E> getList(String name, Class<E> elementType) {
 		PluralAttribute<? super X, ?, ?> attribute = declaredPluralAttributes.get( name );
 		if ( attribute == null && getSupertype() != null ) {
 			attribute = getSupertype().getPluralAttribute( name );
 		}
 		checkListElementType( attribute, name, elementType );
 		return ( ListAttribute<? super X, E> ) attribute;
 	}
 
 	private <E> void checkListElementType(PluralAttribute<? super X, ?, ?> attribute, String name, Class<E> elementType) {
 		checkTypeForPluralAttributes( "ListAttribute", attribute, name, elementType, PluralAttribute.CollectionType.LIST );
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <E> ListAttribute<X, E> getDeclaredList(String name, Class<E> elementType) {
 		final PluralAttribute<X,?,?> attribute = declaredPluralAttributes.get( name );
 		checkListElementType( attribute, name, elementType );
 		return ( ListAttribute<X, E> ) attribute;
 	}
 
 	@Override
 	@SuppressWarnings({ "unchecked" })
 	public <K, V> MapAttribute<? super X, K, V> getMap(String name, Class<K> keyType, Class<V> valueType) {
 		PluralAttribute<? super X, ?, ?> attribute = getPluralAttribute( name );
 		if ( attribute == null && getSupertype() != null ) {
 			attribute = getSupertype().getPluralAttribute( name );
 		}
 		checkMapValueType( attribute, name, valueType );
 		final MapAttribute<? super X, K, V> mapAttribute = ( MapAttribute<? super X, K, V> ) attribute;
 		checkMapKeyType( mapAttribute, name, keyType );
 		return mapAttribute;
 	}
 
 	private <V> void checkMapValueType(PluralAttribute<? super X, ?, ?> attribute, String name, Class<V> valueType) {
 		checkTypeForPluralAttributes( "MapAttribute", attribute, name, valueType, PluralAttribute.CollectionType.MAP);
 	}
 
 	private <K,V> void checkMapKeyType(MapAttribute<? super X, K, V> mapAttribute, String name, Class<K> keyType) {
 		if ( mapAttribute.getKeyJavaType() != keyType ) {
 			throw new IllegalArgumentException( "MapAttribute named " + name + " does not support a key of type " + keyType );
 		}
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <K, V> MapAttribute<X, K, V> getDeclaredMap(String name, Class<K> keyType, Class<V> valueType) {
 		final PluralAttribute<X,?,?> attribute = declaredPluralAttributes.get( name );
 		checkMapValueType( attribute, name, valueType );
 		final MapAttribute<X, K, V> mapAttribute = ( MapAttribute<X, K, V> ) attribute;
 		checkMapKeyType( mapAttribute, name, keyType );
 		return mapAttribute;
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/CacheModeHelper.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/CacheModeHelper.java
index dfb1bcd786..9701520b9f 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/CacheModeHelper.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/CacheModeHelper.java
@@ -1,101 +1,104 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.internal.util;
 
 import javax.persistence.CacheRetrieveMode;
 import javax.persistence.CacheStoreMode;
 
 import org.hibernate.CacheMode;
 
 /**
  * Helper to deal with {@link CacheMode} <-> {@link CacheRetrieveMode}/{@link CacheStoreMode}
  * conversions.
  *
  * @author Steve Ebersole
  */
-public class CacheModeHelper {
+public final class CacheModeHelper {
+	private CacheModeHelper() {
+	}
+
 	public static final CacheMode DEFAULT_LEGACY_MODE = CacheMode.NORMAL;
 	public static final CacheStoreMode DEFAULT_STORE_MODE = CacheStoreMode.USE;
 	public static final CacheRetrieveMode DEFAULT_RETRIEVE_MODE = CacheRetrieveMode.USE;
 
 	/**
 	 * Given a JPA {@link CacheStoreMode} and {@link CacheRetrieveMode}, determine the corresponding
 	 * legacy Hibernate {@link CacheMode}.
 	 *
 	 * @param storeMode The JPA shared-cache store mode.
 	 * @param retrieveMode The JPA shared-cache retrieve mode.
 	 *
 	 * @return Corresponding {@link CacheMode}.
 	 */
 	public static CacheMode interpretCacheMode(CacheStoreMode storeMode, CacheRetrieveMode retrieveMode) {
 		if ( storeMode == null ) {
 			storeMode = DEFAULT_STORE_MODE;
 		}
 		if ( retrieveMode == null ) {
 			retrieveMode = DEFAULT_RETRIEVE_MODE;
 		}
 
 		final boolean get = ( CacheRetrieveMode.USE == retrieveMode );
 
 		switch ( storeMode ) {
 			case USE: {
 				return get ? CacheMode.NORMAL : CacheMode.PUT;
 			}
 			case REFRESH: {
 				// really (get == true) here is a bit of an invalid combo...
 				return CacheMode.REFRESH;
 			}
 			case BYPASS: {
 				return get ? CacheMode.GET : CacheMode.IGNORE;
 			}
 			default: {
 				throw new IllegalStateException( "huh? :)" );
 			}
 		}
 	}
 
 	public static CacheStoreMode interpretCacheStoreMode(CacheMode cacheMode) {
 		if ( cacheMode == null ) {
 			cacheMode = DEFAULT_LEGACY_MODE;
 		}
 
 		if ( CacheMode.REFRESH == cacheMode ) {
 			return CacheStoreMode.REFRESH;
 		}
 		if ( CacheMode.NORMAL == cacheMode || CacheMode.PUT == cacheMode ) {
 			return CacheStoreMode.USE;
 		}
 		return CacheStoreMode.BYPASS;
 	}
 
 	public static CacheRetrieveMode interpretCacheRetrieveMode(CacheMode cacheMode) {
 		if ( cacheMode == null ) {
 			cacheMode = DEFAULT_LEGACY_MODE;
 		}
 
 		return ( CacheMode.NORMAL == cacheMode || CacheMode.GET == cacheMode )
 				? CacheRetrieveMode.USE
 				: CacheRetrieveMode.BYPASS;
 	}
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/LockModeTypeHelper.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/LockModeTypeHelper.java
index 3694452bda..6662db8dc4 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/LockModeTypeHelper.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/LockModeTypeHelper.java
@@ -1,73 +1,76 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.internal.util;
 
 import javax.persistence.LockModeType;
 
 import org.hibernate.LockMode;
 import org.hibernate.internal.util.LockModeConverter;
 
 /**
  * Helper to deal with {@link LockModeType} <-> {@link LockMode} conversions.
  *
  * @author Steve Ebersole
  */
-public class LockModeTypeHelper {
+public final class LockModeTypeHelper {
+	private LockModeTypeHelper() {
+	}
+
 	public static LockModeType getLockModeType(LockMode lockMode) {
 		return LockModeConverter.convertToLockModeType( lockMode );
 	}
 
 	public static LockMode getLockMode(LockModeType lockModeType) {
 		return LockModeConverter.convertToLockMode( lockModeType );
 	}
 
 	public static LockMode interpretLockMode(Object value) {
 		if ( value == null ) {
 			return LockMode.NONE;
 		}
 		if ( LockMode.class.isInstance( value ) ) {
 			return (LockMode) value;
 		}
 		else if ( LockModeType.class.isInstance( value ) ) {
 			return getLockMode( (LockModeType) value );
 		}
 		else if ( String.class.isInstance( value ) ) {
 			// first try LockMode name
 			LockMode lockMode = LockMode.valueOf( (String) value );
 			if ( lockMode == null ) {
 				try {
 					lockMode = getLockMode( LockModeType.valueOf( (String) value ) );
 				}
 				catch ( Exception ignore ) {
 				}
 			}
 			if ( lockMode != null ) {
 				return lockMode;
 			}
 		}
 
 		throw new IllegalArgumentException( "Unknown lock mode source : " + value );
 	}
 
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/PersistenceUtilHelper.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/PersistenceUtilHelper.java
index bb7eb4456f..812e4ad0d9 100644
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/PersistenceUtilHelper.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/internal/util/PersistenceUtilHelper.java
@@ -1,404 +1,407 @@
 package org.hibernate.jpa.internal.util;
 
 import javax.persistence.spi.LoadState;
 import java.io.Serializable;
 import java.lang.reflect.Field;
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Method;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.WeakHashMap;
 
 import org.hibernate.HibernateException;
 import org.hibernate.bytecode.instrumentation.internal.FieldInterceptionHelper;
 import org.hibernate.bytecode.instrumentation.spi.FieldInterceptor;
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.proxy.LazyInitializer;
 
 /**
  * Central delegate for handling calls from:<ul>
  *     <li>{@link javax.persistence.PersistenceUtil#isLoaded(Object)}</li>
  *     <li>{@link javax.persistence.PersistenceUtil#isLoaded(Object, String)}</li>
  *     <li>{@link javax.persistence.spi.ProviderUtil#isLoaded(Object)}</li>
  *     <li>{@link javax.persistence.spi.ProviderUtil#isLoadedWithReference(Object, String)}</li>
  *     <li>{@link javax.persistence.spi.ProviderUtil#isLoadedWithoutReference(Object, String)}li>
  * </ul>
  *
  * @author Emmanuel Bernard
  * @author Hardy Ferentschik
  * @author Steve Ebersole
  */
-public class PersistenceUtilHelper {
+public final class PersistenceUtilHelper {
+	private PersistenceUtilHelper() {
+	}
+
 	/**
 	 * Determine if the given object reference represents loaded state.  The reference may be to an entity or a
 	 * persistent collection.
 	 * <p/>
 	 * Return is defined as follows:<ol>
 	 *     <li>
 	 *         If the reference is a {@link HibernateProxy}, we return {@link LoadState#LOADED} if
 	 *         {@link org.hibernate.proxy.LazyInitializer#isUninitialized()} returns {@code false}; else we return
 	 *         {@link LoadState#NOT_LOADED}
 	 *     </li>
 	 *     <li>
 	 *         If the reference is an enhanced (by Hibernate) entity, we return {@link LoadState#LOADED} if
 	 *         {@link org.hibernate.bytecode.instrumentation.spi.FieldInterceptor#isInitialized()} returns {@code true};
 	 *         else we return {@link LoadState#NOT_LOADED}
 	 *     </li>
 	 *     <li>
 	 *         If the reference is a {@link PersistentCollection}, we return {@link LoadState#LOADED} if
 	 *         {@link org.hibernate.collection.spi.PersistentCollection#wasInitialized()} returns {@code true}; else
 	 *         we return {@link LoadState#NOT_LOADED}
 	 *     </li>
 	 *     <li>
 	 *         In all other cases we return {@link LoadState#UNKNOWN}
 	 *     </li>
 	 * </ol>
 	 *
 	 *
 	 * @param reference The object reference to check.
 	 *
 	 * @return The appropriate LoadState (see above)
 	 */
 	public static LoadState isLoaded(Object reference) {
 		if ( reference instanceof HibernateProxy ) {
 			final boolean isInitialized = !( (HibernateProxy) reference ).getHibernateLazyInitializer().isUninitialized();
 			return isInitialized ? LoadState.LOADED : LoadState.NOT_LOADED;
 		}
 		else if ( FieldInterceptionHelper.isInstrumented( reference ) ) {
 			FieldInterceptor interceptor = FieldInterceptionHelper.extractFieldInterceptor( reference );
 			final boolean isInitialized = interceptor == null || interceptor.isInitialized();
 			return isInitialized ? LoadState.LOADED : LoadState.NOT_LOADED;
 		}
 		else if ( reference instanceof PersistentCollection ) {
 			final boolean isInitialized = ( (PersistentCollection) reference ).wasInitialized();
 			return isInitialized ? LoadState.LOADED : LoadState.NOT_LOADED;
 		}
 		else {
 			return LoadState.UNKNOWN;
 		}
 	}
 
 	/**
 	 * Is the given attribute (by name) loaded?  This form must take care to not access the attribute (trigger
 	 * initialization).
 	 *
 	 * @param entity The entity
 	 * @param attributeName The name of the attribute to check
 	 * @param cache The cache we maintain of attribute resolutions
 	 *
 	 * @return The LoadState
 	 */
 	public static LoadState isLoadedWithoutReference(Object entity, String attributeName, MetadataCache cache) {
 		boolean sureFromUs = false;
 		if ( entity instanceof HibernateProxy ) {
 			LazyInitializer li = ( (HibernateProxy) entity ).getHibernateLazyInitializer();
 			if ( li.isUninitialized() ) {
 				// we have an uninitialized proxy, the attribute cannot be loaded
 				return LoadState.NOT_LOADED;
 			}
 			else {
 				// swap the proxy with target (for proper class name resolution)
 				entity = li.getImplementation();
 			}
 			sureFromUs = true;
 		}
 
 		// we are instrumenting but we can't assume we are the only ones
 		if ( FieldInterceptionHelper.isInstrumented( entity ) ) {
 			FieldInterceptor interceptor = FieldInterceptionHelper.extractFieldInterceptor( entity );
 			final boolean isInitialized = interceptor == null || interceptor.isInitialized( attributeName );
 			LoadState state;
 			if (isInitialized && interceptor != null) {
 				// attributeName is loaded according to bytecode enhancement, but is it loaded as far as association?
 				// it's ours, we can read
 				try {
 					final Class entityClass = entity.getClass();
 					final Object attributeValue = cache.getClassMetadata( entityClass )
 							.getAttributeAccess( attributeName )
 							.extractValue( entity );
 					state = isLoaded( attributeValue );
 
 					// it's ours so we know it's loaded
 					if ( state == LoadState.UNKNOWN ) {
 						state = LoadState.LOADED;
 					}
 				}
 				catch (AttributeExtractionException ignore) {
 					state = LoadState.UNKNOWN;
 				}
 			}
 			else if ( interceptor != null ) {
 				state = LoadState.NOT_LOADED;
 			}
 			else if ( sureFromUs ) {
 				// property is loaded according to bytecode enhancement, but is it loaded as far as association?
 				// it's ours, we can read
 				try {
 					final Class entityClass = entity.getClass();
 					final Object attributeValue = cache.getClassMetadata( entityClass )
 							.getAttributeAccess( attributeName )
 							.extractValue( entity );
 					state = isLoaded( attributeValue );
 
 					// it's ours so we know it's loaded
 					if ( state == LoadState.UNKNOWN ) {
 						state = LoadState.LOADED;
 					}
 				}
 				catch (AttributeExtractionException ignore) {
 					state = LoadState.UNKNOWN;
 				}
 			}
 			else {
 				state = LoadState.UNKNOWN;
 			}
 
 			return state;
 		}
 		else {
 			return LoadState.UNKNOWN;
 		}
 	}
 
 
 	/**
 	 * Is the given attribute (by name) loaded?  This form must take care to not access the attribute (trigger
 	 * initialization).
 	 *
 	 * @param entity The entity
 	 * @param attributeName The name of the attribute to check
 	 * @param cache The cache we maintain of attribute resolutions
 	 *
 	 * @return The LoadState
 	 */
 	public static LoadState isLoadedWithReference(Object entity, String attributeName, MetadataCache cache) {
 		if ( entity instanceof HibernateProxy ) {
 			final LazyInitializer li = ( (HibernateProxy) entity ).getHibernateLazyInitializer();
 			if ( li.isUninitialized() ) {
 				// we have an uninitialized proxy, the attribute cannot be loaded
 				return LoadState.NOT_LOADED;
 			}
 			else {
 				// swap the proxy with target (for proper class name resolution)
 				entity = li.getImplementation();
 			}
 		}
 
 		try {
 			final Class entityClass = entity.getClass();
 			final Object attributeValue = cache.getClassMetadata( entityClass )
 					.getAttributeAccess( attributeName )
 					.extractValue( entity );
 			return isLoaded( attributeValue );
 		}
 		catch (AttributeExtractionException ignore) {
 			return LoadState.UNKNOWN;
 		}
 	}
 
 
 	public static class AttributeExtractionException extends HibernateException {
 		public AttributeExtractionException(String message) {
 			super( message );
 		}
 
 		public AttributeExtractionException(String message, Throwable cause) {
 			super( message, cause );
 		}
 	}
 
 	public static interface AttributeAccess {
 		public Object extractValue(Object owner) throws AttributeExtractionException;
 	}
 
 	public static class FieldAttributeAccess implements AttributeAccess {
 		private final String name;
 		private final Field field;
 
 		public FieldAttributeAccess(Field field) {
 			this.name = field.getName();
 			try {
 				field.setAccessible( true );
 			}
 			catch (Exception e) {
 				this.field = null;
 				return;
 			}
 			this.field = field;
 		}
 
 		@Override
 		public Object extractValue(Object owner) {
 			if ( field == null ) {
 				throw new AttributeExtractionException( "Attribute (field) " + name + " is not accessible" );
 			}
 
 			try {
 				return field.get( owner );
 			}
 			catch ( IllegalAccessException e ) {
 				throw new AttributeExtractionException(
 						"Unable to access attribute (field): " + field.getDeclaringClass().getName() + "#" + name,
 						e
 				);
 			}
 		}
 	}
 
 	public static class MethodAttributeAccess implements AttributeAccess {
 		private final String name;
 		private final Method method;
 
 		public MethodAttributeAccess(String attributeName, Method method) {
 			this.name = attributeName;
 			try {
 				method.setAccessible( true );
 			}
 			catch (Exception e) {
 				this.method = null;
 				return;
 			}
 			this.method = method;
 		}
 
 		@Override
 		public Object extractValue(Object owner) {
 			if ( method == null ) {
 				throw new AttributeExtractionException( "Attribute (method) " + name + " is not accessible" );
 			}
 
 			try {
 				return method.invoke( owner );
 			}
 			catch ( IllegalAccessException e ) {
 				throw new AttributeExtractionException(
 						"Unable to access attribute (method): " + method.getDeclaringClass().getName() + "#" + name,
 						e
 				);
 			}
 			catch ( InvocationTargetException e ) {
 				throw new AttributeExtractionException(
 						"Unable to access attribute (method): " + method.getDeclaringClass().getName() + "#" + name,
 						e.getCause()
 				);
 			}
 		}
 	}
 
 	private static class NoSuchAttributeAccess implements AttributeAccess {
 		private final Class clazz;
 		private final String attributeName;
 
 		public NoSuchAttributeAccess(Class clazz, String attributeName) {
 			this.clazz = clazz;
 			this.attributeName = attributeName;
 		}
 
 		@Override
 		public Object extractValue(Object owner) throws AttributeExtractionException {
 			throw new AttributeExtractionException( "No such attribute : " + clazz.getName() + "#" + attributeName );
 		}
 	}
 
 	public static class ClassMetadataCache {
 		private final Class specifiedClass;
 		private List<Class<?>> classHierarchy;
 		private Map<String, AttributeAccess> attributeAccessMap = new HashMap<String, AttributeAccess>();
 
 		public ClassMetadataCache(Class<?> clazz) {
 			this.specifiedClass = clazz;
 			this.classHierarchy = findClassHierarchy( clazz );
 		}
 
 		private static List<Class<?>> findClassHierarchy(Class<?> clazz) {
 			List<Class<?>> classes = new ArrayList<Class<?>>();
 			Class<?> current = clazz;
 			do {
 				classes.add( current );
 				current = current.getSuperclass();
 			} while ( current != null );
 
 			return classes;
 		}
 
 		public AttributeAccess getAttributeAccess(String attributeName) {
 			AttributeAccess attributeAccess = attributeAccessMap.get( attributeName );
 			if ( attributeAccess == null ) {
 				attributeAccess = buildAttributeAccess( attributeName );
 				attributeAccessMap.put( attributeName, attributeAccess );
 			}
 			return attributeAccess;
 		}
 
 		private AttributeAccess buildAttributeAccess(String attributeName) {
 			for ( Class clazz : classHierarchy ) {
 				try {
 					final Field field = clazz.getDeclaredField( attributeName );
 					if ( field != null ) {
 						return new FieldAttributeAccess( field );
 					}
 				}
 				catch ( NoSuchFieldException e ) {
 					final Method method = getMethod( clazz, attributeName );
 					if ( method != null ) {
 						return new MethodAttributeAccess( attributeName, method );
 					}
 				}
 			}
 
 			//we could not find any match
 			return new NoSuchAttributeAccess( specifiedClass, attributeName );
 		}
 	}
 
 	/**
 	 * Returns the method with the specified name or <code>null</code> if it does not exist.
 	 *
 	 * @param clazz The class to check.
 	 * @param attributeName The attribute name.
 	 *
 	 * @return Returns the method with the specified name or <code>null</code> if it does not exist.
 	 */
 	private static Method getMethod(Class<?> clazz, String attributeName) {
 		try {
-			char string[] = attributeName.toCharArray();
+			char[] string = attributeName.toCharArray();
 			string[0] = Character.toUpperCase( string[0] );
 			String casedAttributeName = new String( string );
 			try {
 				return clazz.getDeclaredMethod( "get" + casedAttributeName );
 			}
 			catch ( NoSuchMethodException e ) {
 				return clazz.getDeclaredMethod( "is" + casedAttributeName );
 			}
 		}
 		catch ( NoSuchMethodException e ) {
 			return null;
 		}
 	}
 
 	/**
 	 * Cache hierarchy and member resolution in a weak hash map
 	 */
 	//TODO not really thread-safe
 	public static class MetadataCache implements Serializable {
 		private transient Map<Class<?>, ClassMetadataCache> classCache = new WeakHashMap<Class<?>, ClassMetadataCache>();
 
 
 		private void readObject(java.io.ObjectInputStream stream) {
 			classCache = new WeakHashMap<Class<?>, ClassMetadataCache>();
 		}
 
 		ClassMetadataCache getClassMetadata(Class<?> clazz) {
 			ClassMetadataCache classMetadataCache = classCache.get( clazz );
 			if ( classMetadataCache == null ) {
 				classMetadataCache = new ClassMetadataCache( clazz );
 				classCache.put( clazz, classMetadataCache );
 			}
 			return classMetadataCache;
 		}
 	}
 
 }
diff --git a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/AbstractEntityManagerImpl.java b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/AbstractEntityManagerImpl.java
index 09cbc5e8c8..62d6909944 100755
--- a/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/AbstractEntityManagerImpl.java
+++ b/hibernate-entitymanager/src/main/java/org/hibernate/jpa/spi/AbstractEntityManagerImpl.java
@@ -1,1897 +1,1897 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.jpa.spi;
 
 import javax.persistence.CacheRetrieveMode;
 import javax.persistence.CacheStoreMode;
 import javax.persistence.EntityExistsException;
 import javax.persistence.EntityGraph;
 import javax.persistence.EntityManager;
 import javax.persistence.EntityNotFoundException;
 import javax.persistence.EntityTransaction;
 import javax.persistence.FlushModeType;
 import javax.persistence.LockModeType;
 import javax.persistence.LockTimeoutException;
 import javax.persistence.NoResultException;
 import javax.persistence.NonUniqueResultException;
 import javax.persistence.OptimisticLockException;
 import javax.persistence.PersistenceContextType;
 import javax.persistence.PersistenceException;
 import javax.persistence.PessimisticLockException;
 import javax.persistence.PessimisticLockScope;
 import javax.persistence.Query;
 import javax.persistence.QueryTimeoutException;
 import javax.persistence.StoredProcedureQuery;
 import javax.persistence.SynchronizationType;
 import javax.persistence.TransactionRequiredException;
 import javax.persistence.Tuple;
 import javax.persistence.TupleElement;
 import javax.persistence.TypedQuery;
 import javax.persistence.criteria.CriteriaBuilder;
 import javax.persistence.criteria.CriteriaDelete;
 import javax.persistence.criteria.CriteriaQuery;
 import javax.persistence.criteria.CriteriaUpdate;
 import javax.persistence.criteria.Selection;
 import javax.persistence.metamodel.Metamodel;
 import javax.persistence.spi.PersistenceUnitTransactionType;
 import javax.transaction.Status;
 import javax.transaction.SystemException;
 import javax.transaction.TransactionManager;
 import java.io.IOException;
 import java.io.ObjectInputStream;
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.AssertionFailure;
 import org.hibernate.CacheMode;
 import org.hibernate.FlushMode;
 import org.hibernate.HibernateException;
 import org.hibernate.LockMode;
 import org.hibernate.LockOptions;
 import org.hibernate.MappingException;
 import org.hibernate.ObjectDeletedException;
 import org.hibernate.ObjectNotFoundException;
 import org.hibernate.QueryException;
 import org.hibernate.SQLQuery;
 import org.hibernate.Session;
 import org.hibernate.StaleObjectStateException;
 import org.hibernate.StaleStateException;
 import org.hibernate.TransientObjectException;
 import org.hibernate.TypeMismatchException;
 import org.hibernate.UnresolvableObjectException;
 import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
 import org.hibernate.boot.registry.classloading.spi.ClassLoadingException;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.lock.LockingStrategyException;
 import org.hibernate.dialect.lock.OptimisticEntityLockException;
 import org.hibernate.dialect.lock.PessimisticEntityLockException;
 import org.hibernate.engine.ResultSetMappingDefinition;
 import org.hibernate.engine.query.spi.HQLQueryPlan;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryConstructorReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryReturn;
 import org.hibernate.engine.query.spi.sql.NativeSQLQueryRootReturn;
 import org.hibernate.engine.spi.NamedQueryDefinition;
 import org.hibernate.engine.spi.NamedSQLQueryDefinition;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.engine.transaction.internal.jta.JtaStatusHelper;
 import org.hibernate.engine.transaction.spi.JoinStatus;
 import org.hibernate.engine.transaction.spi.TransactionCoordinator;
 import org.hibernate.engine.transaction.spi.TransactionImplementor;
 import org.hibernate.engine.transaction.synchronization.spi.AfterCompletionAction;
 import org.hibernate.engine.transaction.synchronization.spi.ExceptionMapper;
 import org.hibernate.engine.transaction.synchronization.spi.ManagedFlushChecker;
 import org.hibernate.engine.transaction.synchronization.spi.SynchronizationCallbackCoordinator;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.jpa.AvailableSettings;
 import org.hibernate.jpa.HibernateEntityManagerFactory;
 import org.hibernate.jpa.QueryHints;
 import org.hibernate.jpa.criteria.ValueHandlerFactory;
 import org.hibernate.jpa.criteria.compile.CompilableCriteria;
 import org.hibernate.jpa.criteria.compile.CriteriaCompiler;
 import org.hibernate.jpa.criteria.expression.CompoundSelectionImpl;
 import org.hibernate.jpa.internal.EntityManagerFactoryImpl;
 import org.hibernate.jpa.internal.EntityManagerMessageLogger;
 import org.hibernate.jpa.internal.QueryImpl;
 import org.hibernate.jpa.internal.StoredProcedureQueryImpl;
 import org.hibernate.jpa.internal.TransactionImpl;
 import org.hibernate.jpa.internal.util.CacheModeHelper;
 import org.hibernate.jpa.internal.util.ConfigurationHelper;
 import org.hibernate.jpa.internal.util.LockModeTypeHelper;
 import org.hibernate.procedure.ProcedureCallMemento;
 import org.hibernate.procedure.UnknownSqlResultSetMappingException;
 import org.hibernate.proxy.HibernateProxy;
 import org.hibernate.engine.transaction.jta.platform.spi.JtaPlatform;
 import org.hibernate.transform.BasicTransformerAdapter;
 import org.hibernate.type.Type;
 
 
 /**
  * @author <a href="mailto:gavin@hibernate.org">Gavin King</a>
  * @author Emmanuel Bernard
  * @author Steve Ebersole
  * @author Hardy Ferentschik
  */
 @SuppressWarnings("unchecked")
 public abstract class AbstractEntityManagerImpl implements HibernateEntityManagerImplementor, Serializable {
 	private static final long serialVersionUID = 78818181L;
 
     private static final EntityManagerMessageLogger LOG = Logger.getMessageLogger(EntityManagerMessageLogger.class,
                                                                            AbstractEntityManagerImpl.class.getName());
 
-	private static final List<String> entityManagerSpecificProperties = new ArrayList<String>();
+	private static final List<String> ENTITY_MANAGER_SPECIFIC_PROPERTIES = new ArrayList<String>();
 
 	static {
-		entityManagerSpecificProperties.add( AvailableSettings.LOCK_SCOPE );
-		entityManagerSpecificProperties.add( AvailableSettings.LOCK_TIMEOUT );
-		entityManagerSpecificProperties.add( AvailableSettings.FLUSH_MODE );
-		entityManagerSpecificProperties.add( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE );
-		entityManagerSpecificProperties.add( AvailableSettings.SHARED_CACHE_STORE_MODE );
-		entityManagerSpecificProperties.add( QueryHints.SPEC_HINT_TIMEOUT );
+		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.LOCK_SCOPE );
+		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.LOCK_TIMEOUT );
+		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.FLUSH_MODE );
+		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE );
+		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( AvailableSettings.SHARED_CACHE_STORE_MODE );
+		ENTITY_MANAGER_SPECIFIC_PROPERTIES.add( QueryHints.SPEC_HINT_TIMEOUT );
 	}
 
 	private EntityManagerFactoryImpl entityManagerFactory;
 	protected transient TransactionImpl tx = new TransactionImpl( this );
 	private SynchronizationType synchronizationType;
 	private PersistenceUnitTransactionType transactionType;
 	private Map<String, Object> properties;
 	private LockOptions lockOptions;
 
 	protected AbstractEntityManagerImpl(
 			EntityManagerFactoryImpl entityManagerFactory,
 			PersistenceContextType type,  // TODO:  remove as no longer used
 			SynchronizationType synchronizationType,
 			PersistenceUnitTransactionType transactionType,
 			Map properties) {
 		this.entityManagerFactory = entityManagerFactory;
 		this.synchronizationType = synchronizationType;
 		this.transactionType = transactionType;
 
 		this.lockOptions = new LockOptions();
 		this.properties = new HashMap<String, Object>();
-		for ( String key : entityManagerSpecificProperties ) {
+		for ( String key : ENTITY_MANAGER_SPECIFIC_PROPERTIES ) {
 			if ( entityManagerFactory.getProperties().containsKey( key ) ) {
 				this.properties.put( key, entityManagerFactory.getProperties().get( key ) );
 			}
 			if ( properties != null && properties.containsKey( key ) ) {
 				this.properties.put( key, properties.get( key ) );
 			}
 		}
 	}
 
 //	protected PersistenceUnitTransactionType transactionType() {
 //		return transactionType;
 //	}
 //
 //	protected SynchronizationType synchronizationType() {
 //		return synchronizationType;
 //	}
 //
 //	public boolean shouldAutoJoinTransactions() {
 //		// the Session should auto join only if using non-JTA transactions or if the synchronization type
 //		// was specified as SYNCHRONIZED
 //		return transactionType != PersistenceUnitTransactionType.JTA
 //				|| synchronizationType == SynchronizationType.SYNCHRONIZED;
 //	}
 
 	public PersistenceUnitTransactionType getTransactionType() {
 		return transactionType;
 	}
 
 	protected void postInit() {
 		//register in Sync if needed
 		if ( transactionType == PersistenceUnitTransactionType.JTA
 				&& synchronizationType == SynchronizationType.SYNCHRONIZED ) {
 			joinTransaction( false );
 		}
 
 		setDefaultProperties();
 		applyProperties();
 	}
 
 	private void applyProperties() {
 		getSession().setFlushMode( ConfigurationHelper.getFlushMode( properties.get( AvailableSettings.FLUSH_MODE ) ) );
 		setLockOptions( this.properties, this.lockOptions );
 		getSession().setCacheMode(
 				CacheModeHelper.interpretCacheMode(
 						currentCacheStoreMode(),
 						currentCacheRetrieveMode()
 				)
 		);
 	}
 
 	private Query applyProperties(Query query) {
 		if ( lockOptions.getLockMode() != LockMode.NONE ) {
 			query.setLockMode( getLockMode(lockOptions.getLockMode()));
 		}
 		Object queryTimeout;
 		if ( (queryTimeout = getProperties().get(QueryHints.SPEC_HINT_TIMEOUT)) != null ) {
 			query.setHint ( QueryHints.SPEC_HINT_TIMEOUT, queryTimeout );
 		}
 		Object lockTimeout;
 		if( (lockTimeout = getProperties().get( AvailableSettings.LOCK_TIMEOUT ))!=null){
 			query.setHint( AvailableSettings.LOCK_TIMEOUT, lockTimeout );
 		}
 		return query;
 	}
 
 	private CacheRetrieveMode currentCacheRetrieveMode() {
 		return determineCacheRetrieveMode( properties );
 	}
 
 	private CacheRetrieveMode determineCacheRetrieveMode(Map<String, Object> settings) {
 		return ( CacheRetrieveMode ) settings.get( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE );
 	}
 
 	private CacheStoreMode currentCacheStoreMode() {
 		return determineCacheStoreMode( properties );
 	}
 
 	private CacheStoreMode determineCacheStoreMode(Map<String, Object> settings) {
 		return ( CacheStoreMode ) settings.get( AvailableSettings.SHARED_CACHE_STORE_MODE );
 	}
 
 	private void setLockOptions(Map<String, Object> props, LockOptions options) {
 		Object lockScope = props.get( AvailableSettings.LOCK_SCOPE );
 		if ( lockScope instanceof String && PessimisticLockScope.valueOf( ( String ) lockScope ) == PessimisticLockScope.EXTENDED ) {
 			options.setScope( true );
 		}
 		else if ( lockScope instanceof PessimisticLockScope ) {
 			boolean extended = PessimisticLockScope.EXTENDED.equals( lockScope );
 			options.setScope( extended );
 		}
 		else if ( lockScope != null ) {
 			throw new PersistenceException( "Unable to parse " + AvailableSettings.LOCK_SCOPE + ": " + lockScope );
 		}
 
 		Object lockTimeout = props.get( AvailableSettings.LOCK_TIMEOUT );
 		int timeout = 0;
 		boolean timeoutSet = false;
 		if ( lockTimeout instanceof String ) {
 			timeout = Integer.parseInt( ( String ) lockTimeout );
 			timeoutSet = true;
 		}
 		else if ( lockTimeout instanceof Number ) {
 			timeout = ( (Number) lockTimeout ).intValue();
 			timeoutSet = true;
 		}
 		else if ( lockTimeout != null ) {
 			throw new PersistenceException( "Unable to parse " + AvailableSettings.LOCK_TIMEOUT + ": " + lockTimeout );
 		}
 		if ( timeoutSet ) {
             if ( timeout == LockOptions.SKIP_LOCKED ) {
                 options.setTimeOut( LockOptions.SKIP_LOCKED );
             }
 			else if ( timeout < 0 ) {
 				options.setTimeOut( LockOptions.WAIT_FOREVER );
 			}
 			else if ( timeout == 0 ) {
 				options.setTimeOut( LockOptions.NO_WAIT );
 			}
 			else {
 				options.setTimeOut( timeout );
 			}
 		}
 	}
 
 	/**
 	 * Sets the default property values for the properties the entity manager supports and which are not already explicitly
 	 * set.
 	 */
 	private void setDefaultProperties() {
 		if ( properties.get( AvailableSettings.FLUSH_MODE ) == null ) {
 			properties.put( AvailableSettings.FLUSH_MODE, getSession().getFlushMode().toString() );
 		}
 		if ( properties.get( AvailableSettings.LOCK_SCOPE ) == null ) {
 			this.properties.put( AvailableSettings.LOCK_SCOPE, PessimisticLockScope.EXTENDED.name() );
 		}
 		if ( properties.get( AvailableSettings.LOCK_TIMEOUT ) == null ) {
 			properties.put( AvailableSettings.LOCK_TIMEOUT, LockOptions.WAIT_FOREVER );
 		}
 		if ( properties.get( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE ) == null ) {
 			properties.put( AvailableSettings.SHARED_CACHE_RETRIEVE_MODE, CacheModeHelper.DEFAULT_RETRIEVE_MODE );
 		}
 		if ( properties.get( AvailableSettings.SHARED_CACHE_STORE_MODE ) == null ) {
 			properties.put( AvailableSettings.SHARED_CACHE_STORE_MODE, CacheModeHelper.DEFAULT_STORE_MODE );
 		}
 	}
 
 	@Override
 	public Query createQuery(String jpaqlString) {
 		checkOpen();
 		try {
 			return applyProperties( new QueryImpl<Object>( internalGetSession().createQuery( jpaqlString ), this ) );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	protected abstract void checkOpen();
 
 	@Override
 	public <T> TypedQuery<T> createQuery(String jpaqlString, Class<T> resultClass) {
 		checkOpen();
 		try {
 			// do the translation
 			org.hibernate.Query hqlQuery = internalGetSession().createQuery( jpaqlString );
 
 			resultClassChecking( resultClass, hqlQuery );
 
 			// finally, build/return the query instance
 			return new QueryImpl<T>( hqlQuery, this );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	protected void resultClassChecking(Class resultClass, org.hibernate.Query hqlQuery) {
 		// make sure the query is a select -> HHH-7192
 		final SessionImplementor session = unwrap( SessionImplementor.class );
 		final HQLQueryPlan queryPlan = session.getFactory().getQueryPlanCache().getHQLQueryPlan(
 				hqlQuery.getQueryString(),
 				false,
 				session.getLoadQueryInfluencers().getEnabledFilters()
 		);
 		if ( queryPlan.getTranslators()[0].isManipulationStatement() ) {
 			throw new IllegalArgumentException( "Update/delete queries cannot be typed" );
 		}
 
 		// do some return type validation checking
 		if ( Object[].class.equals( resultClass ) ) {
 			// no validation needed
 		}
 		else if ( Tuple.class.equals( resultClass ) ) {
 			TupleBuilderTransformer tupleTransformer = new TupleBuilderTransformer( hqlQuery );
 			hqlQuery.setResultTransformer( tupleTransformer  );
 		}
 		else {
 			final Class dynamicInstantiationClass = queryPlan.getDynamicInstantiationResultType();
 			if ( dynamicInstantiationClass != null ) {
 				if ( ! resultClass.isAssignableFrom( dynamicInstantiationClass ) ) {
 					throw new IllegalArgumentException(
 							"Mismatch in requested result type [" + resultClass.getName() +
 									"] and actual result type [" + dynamicInstantiationClass.getName() + "]"
 					);
 				}
 			}
 			else if ( hqlQuery.getReturnTypes().length == 1 ) {
 				// if we have only a single return expression, its java type should match with the requested type
 				if ( !resultClass.isAssignableFrom( hqlQuery.getReturnTypes()[0].getReturnedClass() ) ) {
 					throw new IllegalArgumentException(
 							"Type specified for TypedQuery [" +
 									resultClass.getName() +
 									"] is incompatible with query return type [" +
 									hqlQuery.getReturnTypes()[0].getReturnedClass() + "]"
 					);
 				}
 			}
 			else {
 				throw new IllegalArgumentException(
 						"Cannot create TypedQuery for query with more than one return using requested result type [" +
 								resultClass.getName() + "]"
 				);
 			}
 		}
 	}
 
 	public static class TupleBuilderTransformer extends BasicTransformerAdapter {
 		private List<TupleElement<?>> tupleElements;
 		private Map<String,HqlTupleElementImpl> tupleElementsByAlias;
 
 		public TupleBuilderTransformer(org.hibernate.Query hqlQuery) {
 			final Type[] resultTypes = hqlQuery.getReturnTypes();
 			final int tupleSize = resultTypes.length;
 
 			this.tupleElements = CollectionHelper.arrayList( tupleSize );
 
 			final String[] aliases = hqlQuery.getReturnAliases();
 			final boolean hasAliases = aliases != null && aliases.length > 0;
 			this.tupleElementsByAlias = hasAliases
 					? CollectionHelper.<String, HqlTupleElementImpl>mapOfSize( tupleSize )
 					: Collections.<String, HqlTupleElementImpl>emptyMap();
 
 			for ( int i = 0; i < tupleSize; i++ ) {
 				final HqlTupleElementImpl tupleElement = new HqlTupleElementImpl(
 						i,
 						aliases == null ? null : aliases[i],
 						resultTypes[i]
 				);
 				tupleElements.add( tupleElement );
 				if ( hasAliases ) {
 					final String alias = aliases[i];
 					if ( alias != null ) {
 						tupleElementsByAlias.put( alias, tupleElement );
 					}
 				}
 			}
 		}
 
 		@Override
 		public Object transformTuple(Object[] tuple, String[] aliases) {
 			if ( tuple.length != tupleElements.size() ) {
 				throw new IllegalArgumentException(
 						"Size mismatch between tuple result [" + tuple.length + "] and expected tuple elements [" +
 								tupleElements.size() + "]"
 				);
 			}
 			return new HqlTupleImpl( tuple );
 		}
 
 		public static class HqlTupleElementImpl<X> implements TupleElement<X> {
 			private final int position;
 			private final String alias;
 			private final Type hibernateType;
 
 			public HqlTupleElementImpl(int position, String alias, Type hibernateType) {
 				this.position = position;
 				this.alias = alias;
 				this.hibernateType = hibernateType;
 			}
 
 			@Override
 			public Class getJavaType() {
 				return hibernateType.getReturnedClass();
 			}
 
 			@Override
 			public String getAlias() {
 				return alias;
 			}
 
 			public int getPosition() {
 				return position;
 			}
 
 			public Type getHibernateType() {
 				return hibernateType;
 			}
 		}
 
 		public class HqlTupleImpl implements Tuple {
 			private Object[] tuple;
 
 			public HqlTupleImpl(Object[] tuple) {
 				this.tuple = tuple;
 			}
 
 			@Override
 			public <X> X get(String alias, Class<X> type) {
 				final Object untyped = get( alias );
 				if ( untyped != null ) {
 					if ( ! type.isInstance( untyped ) ) {
 						throw new IllegalArgumentException(
 								String.format(
 										"Requested tuple value [alias=%s, value=%s] cannot be assigned to requested type [%s]",
 										alias,
 										untyped,
 										type.getName()
 								)
 						);
 					}
 				}
 				return (X) untyped;
 			}
 
 			@Override
 			public Object get(String alias) {
 				HqlTupleElementImpl tupleElement = tupleElementsByAlias.get( alias );
 				if ( tupleElement == null ) {
 					throw new IllegalArgumentException( "Unknown alias [" + alias + "]" );
 				}
 				return tuple[ tupleElement.getPosition() ];
 			}
 
 			@Override
 			public <X> X get(int i, Class<X> type) {
 				final Object result = get( i );
 				if ( result != null && ! type.isInstance( result ) ) {
 					throw new IllegalArgumentException(
 							String.format(
 									"Requested tuple value [index=%s, realType=%s] cannot be assigned to requested type [%s]",
 									i,
 									result.getClass().getName(),
 									type.getName()
 							)
 					);
 				}
 				return ( X ) result;
 			}
 
 			@Override
 			public Object get(int i) {
 				if ( i < 0 ) {
 					throw new IllegalArgumentException( "requested tuple index must be greater than zero" );
 				}
 				if ( i > tuple.length ) {
 					throw new IllegalArgumentException( "requested tuple index exceeds actual tuple size" );
 				}
 				return tuple[i];
 			}
 
 			@Override
 			public Object[] toArray() {
 				// todo : make a copy?
 				return tuple;
 			}
 
 			@Override
 			public List<TupleElement<?>> getElements() {
 				return tupleElements;
 			}
 
 			@Override
 			public <X> X get(TupleElement<X> tupleElement) {
 				if ( HqlTupleElementImpl.class.isInstance( tupleElement ) ) {
 					return get( ( (HqlTupleElementImpl) tupleElement ).getPosition(), tupleElement.getJavaType() );
 				}
 				else {
 					return get( tupleElement.getAlias(), tupleElement.getJavaType() );
 				}
 			}
 		}
 	}
 
 	@Override
 	public <T> QueryImpl<T> createQuery(
 			String jpaqlString,
 			Class<T> resultClass,
 			Selection selection,
 			QueryOptions queryOptions) {
 		try {
 			org.hibernate.Query hqlQuery = internalGetSession().createQuery( jpaqlString );
 
 			if ( queryOptions.getValueHandlers() == null ) {
 				if ( queryOptions.getResultMetadataValidator() != null ) {
 					queryOptions.getResultMetadataValidator().validate( hqlQuery.getReturnTypes() );
 				}
 			}
 
 			// determine if we need a result transformer
 			List tupleElements = Tuple.class.equals( resultClass )
 					? ( ( CompoundSelectionImpl<Tuple> ) selection ).getCompoundSelectionItems()
 					: null;
 			if ( queryOptions.getValueHandlers() != null || tupleElements != null ) {
 				hqlQuery.setResultTransformer(
 						new CriteriaQueryTransformer( queryOptions.getValueHandlers(), tupleElements )
 				);
 			}
 			return new QueryImpl<T>( hqlQuery, this, queryOptions.getNamedParameterExplicitTypes() );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	private static class CriteriaQueryTransformer extends BasicTransformerAdapter {
 		private final List<ValueHandlerFactory.ValueHandler> valueHandlers;
 		private final List tupleElements;
 
 		private CriteriaQueryTransformer(List<ValueHandlerFactory.ValueHandler> valueHandlers, List tupleElements) {
 			// todo : should these 2 sizes match *always*?
 			this.valueHandlers = valueHandlers;
 			this.tupleElements = tupleElements;
 		}
 
 		@Override
 		public Object transformTuple(Object[] tuple, String[] aliases) {
 			final Object[] valueHandlerResult;
 			if ( valueHandlers == null ) {
 				valueHandlerResult = tuple;
 			}
 			else {
 				valueHandlerResult = new Object[tuple.length];
 				for ( int i = 0; i < tuple.length; i++ ) {
 					ValueHandlerFactory.ValueHandler valueHandler = valueHandlers.get( i );
 					valueHandlerResult[i] = valueHandler == null
 							? tuple[i]
 							: valueHandler.convert( tuple[i] );
 				}
 			}
 
 			return tupleElements == null
 					? valueHandlerResult.length == 1 ? valueHandlerResult[0] : valueHandlerResult
 					: new TupleImpl( tuple );
 
 		}
 
 		private class TupleImpl implements Tuple {
 			private final Object[] tuples;
 
 			private TupleImpl(Object[] tuples) {
 				if ( tuples.length != tupleElements.size() ) {
 					throw new IllegalArgumentException(
 							"Size mismatch between tuple result [" + tuples.length
 									+ "] and expected tuple elements [" + tupleElements.size() + "]"
 					);
 				}
 				this.tuples = tuples;
 			}
 
 			public <X> X get(TupleElement<X> tupleElement) {
 				int index = tupleElements.indexOf( tupleElement );
 				if ( index < 0 ) {
 					throw new IllegalArgumentException(
 							"Requested tuple element did not correspond to element in the result tuple"
 					);
 				}
 				// index should be "in range" by nature of size check in ctor
 				return ( X ) tuples[index];
 			}
 
 			public Object get(String alias) {
 				int index = -1;
 				if ( alias != null ) {
 					alias = alias.trim();
 					if ( alias.length() > 0 ) {
 						int i = 0;
 						for ( TupleElement selection : ( List<TupleElement> ) tupleElements ) {
 							if ( alias.equals( selection.getAlias() ) ) {
 								index = i;
 								break;
 							}
 							i++;
 						}
 					}
 				}
 				if ( index < 0 ) {
 					throw new IllegalArgumentException(
 							"Given alias [" + alias + "] did not correspond to an element in the result tuple"
 					);
 				}
 				// index should be "in range" by nature of size check in ctor
 				return tuples[index];
 			}
 
 			public <X> X get(String alias, Class<X> type) {
 				final Object untyped = get( alias );
 				if ( untyped != null ) {
 					if ( ! type.isInstance( untyped ) ) {
 						throw new IllegalArgumentException(
 								String.format(
 										"Requested tuple value [alias=%s, value=%s] cannot be assigned to requested type [%s]",
 										alias,
 										untyped,
 										type.getName()
 								)
 						);
 					}
 				}
 				return (X) untyped;
 			}
 
 			public Object get(int i) {
 				if ( i >= tuples.length ) {
 					throw new IllegalArgumentException(
 							"Given index [" + i + "] was outside the range of result tuple size [" + tuples.length + "] "
 					);
 				}
 				return tuples[i];
 			}
 
 			public <X> X get(int i, Class<X> type) {
 				final Object result = get( i );
 				if ( result != null && ! type.isInstance( result ) ) {
 					throw new IllegalArgumentException(
 							String.format(
 									"Requested tuple value [index=%s, realType=%s] cannot be assigned to requested type [%s]",
 									i,
 									result.getClass().getName(),
 									type.getName()
 							)
 					);
 				}
 				return ( X ) result;
 			}
 
 			public Object[] toArray() {
 				return tuples;
 			}
 
 			public List<TupleElement<?>> getElements() {
 				return tupleElements;
 			}
 		}
 	}
 
 	private CriteriaCompiler criteriaCompiler;
 
 	protected CriteriaCompiler criteriaCompiler() {
 		if ( criteriaCompiler == null ) {
 			criteriaCompiler = new CriteriaCompiler( this );
 		}
 		return criteriaCompiler;
 	}
 
 	@Override
 	public <T> TypedQuery<T> createQuery(CriteriaQuery<T> criteriaQuery) {
 		checkOpen();
 		try {
 			return (TypedQuery<T>) criteriaCompiler().compile( (CompilableCriteria) criteriaQuery );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public Query createQuery(CriteriaUpdate criteriaUpdate) {
 		checkOpen();
 		try {
 			return criteriaCompiler().compile( (CompilableCriteria) criteriaUpdate );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public Query createQuery(CriteriaDelete criteriaDelete) {
 		checkOpen();
 		try {
 			return criteriaCompiler().compile( (CompilableCriteria) criteriaDelete );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public Query createNamedQuery(String name) {
 		return buildQueryFromName( name, null );
 	}
 
 	private QueryImpl buildQueryFromName(String name, Class resultType) {
 		checkOpen();
 
 		// we can't just call Session#getNamedQuery because we need to apply stored setting at the JPA Query
 		// level too
 
 		final SessionFactoryImplementor sfi = entityManagerFactory.getSessionFactory();
 
 		// first try as hql/jpql query
 		{
 			final NamedQueryDefinition namedQueryDefinition = sfi.getNamedQueryRepository().getNamedQueryDefinition( name );
 			if ( namedQueryDefinition != null ) {
 				return createNamedJpqlQuery( namedQueryDefinition, resultType );
 			}
 		}
 
 		// then as a native (SQL) query
 		{
 			final NamedSQLQueryDefinition namedQueryDefinition = sfi.getNamedQueryRepository().getNamedSQLQueryDefinition( name );
 			if ( namedQueryDefinition != null ) {
 				return createNamedSqlQuery( namedQueryDefinition, resultType );
 			}
 		}
 
 		throw convert( new IllegalArgumentException( "No query defined for that name [" + name + "]" ) );
 	}
 
 	protected QueryImpl createNamedJpqlQuery(NamedQueryDefinition namedQueryDefinition, Class resultType) {
 		final org.hibernate.Query hibQuery = ( (SessionImplementor) internalGetSession() ).createQuery( namedQueryDefinition );
 		if ( resultType != null ) {
 			resultClassChecking( resultType, hibQuery );
 		}
 
 		return wrapAsJpaQuery( namedQueryDefinition, hibQuery );
 	}
 
 	protected QueryImpl wrapAsJpaQuery(NamedQueryDefinition namedQueryDefinition, org.hibernate.Query hibQuery) {
 		try {
 			final QueryImpl jpaQuery = new QueryImpl( hibQuery, this );
 			applySavedSettings( namedQueryDefinition, jpaQuery );
 			return jpaQuery;
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	protected void applySavedSettings(NamedQueryDefinition namedQueryDefinition, QueryImpl jpaQuery) {
 		if ( namedQueryDefinition.isCacheable() ) {
 			jpaQuery.setHint( QueryHints.HINT_CACHEABLE, true );
 			if ( namedQueryDefinition.getCacheRegion() != null ) {
 				jpaQuery.setHint( QueryHints.HINT_CACHE_REGION, namedQueryDefinition.getCacheRegion() );
 			}
 		}
 
 		if ( namedQueryDefinition.getCacheMode() != null ) {
 			jpaQuery.setHint( QueryHints.HINT_CACHE_MODE, namedQueryDefinition.getCacheMode() );
 		}
 
 		if ( namedQueryDefinition.isReadOnly() ) {
 			jpaQuery.setHint( QueryHints.HINT_READONLY, true );
 		}
 
 		if ( namedQueryDefinition.getTimeout() != null ) {
 			jpaQuery.setHint( QueryHints.SPEC_HINT_TIMEOUT, namedQueryDefinition.getTimeout() * 1000 );
 		}
 
 		if ( namedQueryDefinition.getFetchSize() != null ) {
 			jpaQuery.setHint( QueryHints.HINT_FETCH_SIZE, namedQueryDefinition.getFetchSize() );
 		}
 
 		if ( namedQueryDefinition.getComment() != null ) {
 			jpaQuery.setHint( QueryHints.HINT_COMMENT, namedQueryDefinition.getComment() );
 		}
 
 		if ( namedQueryDefinition.getFirstResult() != null ) {
 			jpaQuery.setFirstResult( namedQueryDefinition.getFirstResult() );
 		}
 
 		if ( namedQueryDefinition.getMaxResults() != null ) {
 			jpaQuery.setMaxResults( namedQueryDefinition.getMaxResults() );
 		}
 
 		if ( namedQueryDefinition.getLockOptions() != null ) {
 			if ( namedQueryDefinition.getLockOptions().getLockMode() != null ) {
 				jpaQuery.setLockMode(
 						LockModeTypeHelper.getLockModeType( namedQueryDefinition.getLockOptions().getLockMode() )
 				);
 			}
 		}
 
 		if ( namedQueryDefinition.getFlushMode() != null ) {
 			if ( namedQueryDefinition.getFlushMode() == FlushMode.COMMIT ) {
 				jpaQuery.setFlushMode( FlushModeType.COMMIT );
 			}
 			else {
 				jpaQuery.setFlushMode( FlushModeType.AUTO );
 			}
 		}
 	}
 
 	protected QueryImpl createNamedSqlQuery(NamedSQLQueryDefinition namedQueryDefinition, Class resultType) {
 		if ( resultType != null ) {
 			resultClassChecking( resultType, namedQueryDefinition );
 		}
 		return wrapAsJpaQuery(
 				namedQueryDefinition,
 				( (SessionImplementor) internalGetSession() ).createSQLQuery( namedQueryDefinition )
 		);
 	}
 
 	protected void resultClassChecking(Class resultType, NamedSQLQueryDefinition namedQueryDefinition) {
 		final SessionFactoryImplementor sfi = entityManagerFactory.getSessionFactory();
 
 		final NativeSQLQueryReturn[] queryReturns;
 		if ( namedQueryDefinition.getQueryReturns() != null ) {
 			queryReturns = namedQueryDefinition.getQueryReturns();
 		}
 		else if ( namedQueryDefinition.getResultSetRef() != null ) {
 			final ResultSetMappingDefinition rsMapping = sfi.getResultSetMapping( namedQueryDefinition.getResultSetRef() );
 			queryReturns = rsMapping.getQueryReturns();
 		}
 		else {
 			throw new AssertionFailure( "Unsupported named query model. Please report the bug in Hibernate EntityManager");
 		}
 
 		if ( queryReturns.length > 1 ) {
 			throw new IllegalArgumentException( "Cannot create TypedQuery for query with more than one return" );
 		}
 
 		final NativeSQLQueryReturn nativeSQLQueryReturn = queryReturns[0];
 
 		if ( nativeSQLQueryReturn instanceof NativeSQLQueryRootReturn ) {
 			final Class<?> actualReturnedClass;
 			final String entityClassName = ( (NativeSQLQueryRootReturn) nativeSQLQueryReturn ).getReturnEntityName();
 			try {
 				actualReturnedClass = sfi.getServiceRegistry().getService( ClassLoaderService.class ).classForName( entityClassName );
 			}
 			catch ( ClassLoadingException e ) {
 				throw new AssertionFailure(
 						"Unable to load class [" + entityClassName + "] declared on named native query [" +
 								namedQueryDefinition.getName() + "]"
 				);
 			}
 			if ( !resultType.isAssignableFrom( actualReturnedClass ) ) {
 				throw buildIncompatibleException( resultType, actualReturnedClass );
 			}
 		}
 		else if ( nativeSQLQueryReturn instanceof NativeSQLQueryConstructorReturn ) {
 			final NativeSQLQueryConstructorReturn ctorRtn = (NativeSQLQueryConstructorReturn) nativeSQLQueryReturn;
 			if ( !resultType.isAssignableFrom( ctorRtn.getTargetClass() ) ) {
 				throw buildIncompatibleException( resultType, ctorRtn.getTargetClass() );
 			}
 		}
 		else {
 			//TODO support other NativeSQLQueryReturn type. For now let it go.
 		}
 	}
 
 	@Override
 	public <T> TypedQuery<T> createNamedQuery(String name, Class<T> resultClass) {
 		return buildQueryFromName( name, resultClass );
 	}
 
 	private IllegalArgumentException buildIncompatibleException(Class<?> resultClass, Class<?> actualResultClass) {
 		return new IllegalArgumentException(
 				"Type specified for TypedQuery [" + resultClass.getName() +
 						"] is incompatible with query return type [" + actualResultClass + "]"
 		);
 	}
 
 	@Override
 	public Query createNativeQuery(String sqlString) {
 		checkOpen();
 		try {
 			SQLQuery q = internalGetSession().createSQLQuery( sqlString );
 			return new QueryImpl( q, this );
 		}
 		catch ( RuntimeException he ) {
 			throw convert( he );
 		}
 	}
 
 	@Override
 	public Query createNativeQuery(String sqlString, Class resultClass) {
 		checkOpen();
 		try {
 			SQLQuery q = internalGetSession().createSQLQuery( sqlString );
 			q.addEntity( "alias1", resultClass.getName(), LockMode.READ );
 			return new QueryImpl( q, this );
 		}
 		catch ( RuntimeException he ) {
 			throw convert( he );
 		}
 	}
 
 	@Override
 	public Query createNativeQuery(String sqlString, String resultSetMapping) {
 		checkOpen();
 		try {
 			final SQLQuery q = internalGetSession().createSQLQuery( sqlString );
 			q.setResultSetMapping( resultSetMapping );
 			return new QueryImpl( q, this );
 		}
 		catch ( RuntimeException he ) {
 			throw convert( he );
 		}
 	}
 
 	@Override
 	public StoredProcedureQuery createNamedStoredProcedureQuery(String name) {
 		checkOpen();
 		try {
 			final ProcedureCallMemento memento = ( (SessionImplementor) internalGetSession() ).getFactory()
 					.getNamedQueryRepository().getNamedProcedureCallMemento( name );
 			if ( memento == null ) {
 				throw new IllegalArgumentException( "No @NamedStoredProcedureQuery was found with that name : " + name );
 			}
 			final StoredProcedureQueryImpl jpaImpl = new StoredProcedureQueryImpl( memento, this );
 			// apply hints
 			if ( memento.getHintsMap() != null ) {
 				for ( Map.Entry<String,Object> hintEntry : memento.getHintsMap().entrySet() ) {
 					jpaImpl.setHint( hintEntry.getKey(), hintEntry.getValue() );
 				}
 			}
 			return jpaImpl;
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public StoredProcedureQuery createStoredProcedureQuery(String procedureName) {
 		checkOpen();
 		try {
 			return new StoredProcedureQueryImpl(
 					internalGetSession().createStoredProcedureCall( procedureName ),
 					this
 			);
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public StoredProcedureQuery createStoredProcedureQuery(String procedureName, Class... resultClasses) {
 		checkOpen();
 		try {
 			return new StoredProcedureQueryImpl(
 					internalGetSession().createStoredProcedureCall( procedureName, resultClasses ),
 					this
 			);
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public StoredProcedureQuery createStoredProcedureQuery(String procedureName, String... resultSetMappings) {
 		checkOpen();
 		try {
 			try {
 				return new StoredProcedureQueryImpl(
 						internalGetSession().createStoredProcedureCall( procedureName, resultSetMappings ),
 						this
 				);
 			}
 			catch (UnknownSqlResultSetMappingException unknownResultSetMapping) {
 				throw new IllegalArgumentException( unknownResultSetMapping.getMessage(), unknownResultSetMapping );
 			}
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <T> T getReference(Class<T> entityClass, Object primaryKey) {
 		checkOpen();
 		try {
 			return ( T ) internalGetSession().load( entityClass, ( Serializable ) primaryKey );
 		}
 		catch ( MappingException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( TypeMismatchException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( ClassCastException e ) {
 			throw convert( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <A> A find(Class<A> entityClass, Object primaryKey) {
 		checkOpen();
 		return find( entityClass, primaryKey, null, null );
 	}
 
 	@Override
 	public <T> T find(Class<T> entityClass, Object primaryKey, Map<String, Object> properties) {
 		checkOpen();
 		return find( entityClass, primaryKey, null, properties );
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <A> A find(Class<A> entityClass, Object primaryKey, LockModeType lockModeType) {
 		checkOpen();
 		return find( entityClass, primaryKey, lockModeType, null );
 	}
 
 	@Override
 	public <A> A find(Class<A> entityClass, Object primaryKey, LockModeType lockModeType, Map<String, Object> properties) {
 		checkOpen();
 		Session session = internalGetSession();
 		CacheMode previousCacheMode = session.getCacheMode();
 		CacheMode cacheMode = determineAppropriateLocalCacheMode( properties );
 		LockOptions lockOptions = null;
 		try {
 			if ( properties != null && !properties.isEmpty() ) {
 				( (SessionImplementor) session ).getLoadQueryInfluencers()
 						.setFetchGraph( (EntityGraph) properties.get( QueryHints.HINT_FETCHGRAPH ) );
 				( (SessionImplementor) session ).getLoadQueryInfluencers()
 						.setLoadGraph( (EntityGraph) properties.get( QueryHints.HINT_LOADGRAPH ) );
 			}
 			session.setCacheMode( cacheMode );
 			if ( lockModeType != null ) {
 				lockOptions = getLockRequest( lockModeType, properties );
 				if ( !LockModeType.NONE.equals( lockModeType) ) {
 					checkTransactionNeeded();
 				}
 				return ( A ) session.get(
 						entityClass, ( Serializable ) primaryKey, 
 						lockOptions
 				);
 			}
 			else {
 				return ( A ) session.get( entityClass, ( Serializable ) primaryKey );
 			}
 		}
 		catch ( EntityNotFoundException ignored ) {
 			// DefaultLoadEventListener.returnNarrowedProxy may throw ENFE (see HHH-7861 for details),
 			// which find() should not throw.  Find() should return null if the entity was not found.
 			if ( LOG.isDebugEnabled() ) {
 				String entityName = entityClass != null ? entityClass.getName(): null;
 				String identifierValue = primaryKey != null ? primaryKey.toString() : null ;
 				LOG.ignoringEntityNotFound( entityName, identifierValue );
 			}
 			return null;
 		}
 		catch ( ObjectDeletedException e ) {
 			//the spec is silent about people doing remove() find() on the same PC
 			return null;
 		}
 		catch ( ObjectNotFoundException e ) {
 			//should not happen on the entity itself with get
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch ( MappingException e ) {
 			throw convert ( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( TypeMismatchException e ) {
 			throw convert ( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( ClassCastException e ) {
 			throw convert ( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e, lockOptions );
 		}
 		finally {
 			session.setCacheMode( previousCacheMode );
 			((SessionImplementor)session).getLoadQueryInfluencers().setFetchGraph( null );
 			((SessionImplementor)session).getLoadQueryInfluencers().setLoadGraph( null );
 
 		}
 	}
 
 	public CacheMode determineAppropriateLocalCacheMode(Map<String, Object> localProperties) {
 		CacheRetrieveMode retrieveMode = null;
 		CacheStoreMode storeMode = null;
 		if ( localProperties != null ) {
 			retrieveMode = determineCacheRetrieveMode( localProperties );
 			storeMode = determineCacheStoreMode( localProperties );
 		}
 		if ( retrieveMode == null ) {
 			// use the EM setting
 			retrieveMode = determineCacheRetrieveMode( this.properties );
 		}
 		if ( storeMode == null ) {
 			// use the EM setting
 			storeMode = determineCacheStoreMode( this.properties );
 		}
 		return CacheModeHelper.interpretCacheMode( storeMode, retrieveMode );
 	}
 
 	private void checkTransactionNeeded() {
 		if ( !isTransactionInProgress() ) {
 			throw new TransactionRequiredException(
 					"no transaction is in progress"
 			);
 		}
 	}
 
 	@Override
 	public void persist(Object entity) {
 		checkOpen();
 		try {
 			internalGetSession().persist( entity );
 		}
 		catch ( MappingException e ) {
 			throw convert ( new IllegalArgumentException( e.getMessage() ) ) ;
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	@SuppressWarnings("unchecked")
 	public <A> A merge(A entity) {
 		checkOpen();
 		try {
 			return ( A ) internalGetSession().merge( entity );
 		}
 		catch ( ObjectDeletedException sse ) {
 			throw convert ( new IllegalArgumentException( sse ) );
 		}
 		catch ( MappingException e ) {
 			throw convert ( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( RuntimeException e ) { //including HibernateException
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public void remove(Object entity) {
 		checkOpen();
 		try {
 			internalGetSession().delete( entity );
 		}
 		catch ( MappingException e ) {
 			throw convert ( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( RuntimeException e ) { //including HibernateException
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public void refresh(Object entity) {
 		refresh( entity, null, null );
 	}
 
 	@Override
 	public void refresh(Object entity, Map<String, Object> properties) {
 		refresh( entity, null, properties );
 	}
 
 	@Override
 	public void refresh(Object entity, LockModeType lockModeType) {
 		refresh( entity, lockModeType, null );
 	}
 
 	@Override
 	public void refresh(Object entity, LockModeType lockModeType, Map<String, Object> properties) {
 		checkOpen();
 
 		Session session = internalGetSession();
 		CacheMode previousCacheMode = session.getCacheMode();
 		CacheMode localCacheMode = determineAppropriateLocalCacheMode( properties );
 		LockOptions lockOptions = null;
 		try {
 			session.setCacheMode( localCacheMode );
 			if ( !session.contains( entity ) ) {
 				throw convert ( new IllegalArgumentException( "Entity not managed" ) );
 			}
 			if ( lockModeType != null ) {
 				if ( !LockModeType.NONE.equals( lockModeType) ) {
 					checkTransactionNeeded();
 				}
 
 				lockOptions = getLockRequest( lockModeType, properties );
 				session.refresh( entity, lockOptions );
 			}
 			else {
 				session.refresh( entity );
 			}
 		}
 		catch ( MappingException e ) {
 			throw convert ( new IllegalArgumentException( e.getMessage(), e ) );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e, lockOptions );
 		}
 		finally {
 			session.setCacheMode( previousCacheMode );
 		}
 	}
 
 	@Override
 	public boolean contains(Object entity) {
 		checkOpen();
 
 		try {
 			if ( entity != null
 					&& !( entity instanceof HibernateProxy )
 					&& internalGetSession().getSessionFactory().getClassMetadata( entity.getClass() ) == null ) {
 				throw convert ( new IllegalArgumentException( "Not an entity:" + entity.getClass() ) );
 			}
 			return internalGetSession().contains( entity );
 		}
 		catch ( MappingException e ) {
 			throw new IllegalArgumentException( e.getMessage(), e );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public LockModeType getLockMode(Object entity) {
 		checkOpen();
 
 		if ( !isTransactionInProgress() ) {
 			throw new TransactionRequiredException( "Call to EntityManager#getLockMode should occur within transaction according to spec" );
 		}
 
 		if ( !contains( entity ) ) {
 			throw convert (new IllegalArgumentException( "entity not in the persistence context" ) );
 		}
 
 		return getLockModeType( internalGetSession().getCurrentLockMode( entity ) );
 	}
 
 	@Override
 	public void setProperty(String s, Object o) {
 		checkOpen();
 
-		if ( entityManagerSpecificProperties.contains( s ) ) {
+		if ( ENTITY_MANAGER_SPECIFIC_PROPERTIES.contains( s ) ) {
 			properties.put( s, o );
 			applyProperties();
         }
 		else {
 			LOG.debugf("Trying to set a property which is not supported on entity manager level");
 		}
 	}
 
 	@Override
 	public Map<String, Object> getProperties() {
 		return Collections.unmodifiableMap( properties );
 	}
 
 	@Override
 	public void flush() {
 		checkOpen();
 		checkTransactionNeeded();
 
 		try {
 			internalGetSession().flush();
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	/**
 	 * return a Session
 	 *
 	 * @throws IllegalStateException if the entity manager is closed
 	 */
 	public abstract Session getSession();
 
 	/**
 	 * Return a Session (even if the entity manager is closed).
 	 *
 	 * @return A session.
 	 * @deprecated Deprecated in favor of {@link #getRawSession()}
 	 */
 	@Deprecated
 	protected abstract Session getRawSession();
 
 	/**
 	 * Return a Session without any validation checks.
 	 *
 	 * @return A session.
 	 */
 	protected abstract Session internalGetSession();
 
 	@Override
 	public EntityTransaction getTransaction() {
 		if ( transactionType == PersistenceUnitTransactionType.JTA ) {
 			throw new IllegalStateException( "A JTA EntityManager cannot use getTransaction()" );
 		}
 		return tx;
 	}
 
 	@Override
 	public EntityManagerFactoryImpl getEntityManagerFactory() {
 		checkOpen();
 		return internalGetEntityManagerFactory();
 	}
 
 	protected EntityManagerFactoryImpl internalGetEntityManagerFactory() {
 		return entityManagerFactory;
 	}
 
 	@Override
 	public HibernateEntityManagerFactory getFactory() {
 		return entityManagerFactory;
 	}
 
 	@Override
 	public CriteriaBuilder getCriteriaBuilder() {
 
 		checkOpen();
 		return getEntityManagerFactory().getCriteriaBuilder();
 	}
 
 	@Override
 	public Metamodel getMetamodel() {
 		checkOpen();
 		return getEntityManagerFactory().getMetamodel();
 	}
 
 	@Override
 	public void setFlushMode(FlushModeType flushModeType) {
 		checkOpen();
 		if ( flushModeType == FlushModeType.AUTO ) {
 			internalGetSession().setFlushMode( FlushMode.AUTO );
 		}
 		else if ( flushModeType == FlushModeType.COMMIT ) {
 			internalGetSession().setFlushMode( FlushMode.COMMIT );
 		}
 		else {
 			throw new AssertionFailure( "Unknown FlushModeType: " + flushModeType );
 		}
 	}
 
 	@Override
 	public void clear() {
 		checkOpen();
 		try {
 			internalGetSession().clear();
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	@Override
 	public void detach(Object entity) {
 		checkOpen();
 		try {
 			internalGetSession().evict( entity );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e );
 		}
 	}
 
 	/**
 	 * Hibernate can be set in various flush modes that are unknown to
 	 * JPA 2.0. This method can then return null.
 	 * If it returns null, do em.unwrap(Session.class).getFlushMode() to get the
 	 * Hibernate flush mode
 	 */
 	@Override
 	public FlushModeType getFlushMode() {
 		checkOpen();
 
 		FlushMode mode = internalGetSession().getFlushMode();
 		if ( mode == FlushMode.AUTO ) {
 			return FlushModeType.AUTO;
 		}
 		else if ( mode == FlushMode.COMMIT ) {
 			return FlushModeType.COMMIT;
 		}
 		else {
 			// otherwise this is an unknown mode for EJB3
 			return null;
 		}
 	}
 
 	public void lock(Object entity, LockModeType lockMode) {
 		lock( entity, lockMode, null );
 	}
 
 	public void lock(Object entity, LockModeType lockModeType, Map<String, Object> properties) {
 		checkOpen();
 		checkTransactionNeeded();
 
 		LockOptions lockOptions = null;
 
 		try {
 			if ( !contains( entity ) ) {
 				throw new IllegalArgumentException( "entity not in the persistence context" );
 			}
 			lockOptions = getLockRequest( lockModeType, properties );
 			internalGetSession().buildLockRequest( lockOptions ).lock( entity );
 		}
 		catch ( RuntimeException e ) {
 			throw convert( e, lockOptions );
 		}
 	}
 
 	public LockOptions getLockRequest(LockModeType lockModeType, Map<String, Object> properties) {
 		LockOptions lockOptions = new LockOptions();
 		LockOptions.copy( this.lockOptions, lockOptions );
 		lockOptions.setLockMode( getLockMode( lockModeType ) );
 		if ( properties != null ) {
 			setLockOptions( properties, lockOptions );
 		}
 		return lockOptions;
 	}
 
 	@SuppressWarnings("deprecation")
 	private static LockModeType getLockModeType(LockMode lockMode) {
 		//TODO check that if we have UPGRADE_NOWAIT we have a timeout of zero?
 		return LockModeTypeHelper.getLockModeType( lockMode );
 	}
 
 
 	private static LockMode getLockMode(LockModeType lockMode) {
 		return LockModeTypeHelper.getLockMode( lockMode );
 	}
 
 	public boolean isTransactionInProgress() {
 		return ( ( SessionImplementor ) internalGetSession() ).isTransactionInProgress();
 	}
 
 	private SessionFactoryImplementor sfi() {
 		return (SessionFactoryImplementor) internalGetSession().getSessionFactory();
 	}
 
 	@Override
 	public <T> T unwrap(Class<T> clazz) {
 		checkOpen();
 
 		if ( Session.class.isAssignableFrom( clazz ) ) {
 			return ( T ) internalGetSession();
 		}
 		if ( SessionImplementor.class.isAssignableFrom( clazz ) ) {
 			return ( T ) internalGetSession();
 		}
 		if ( EntityManager.class.isAssignableFrom( clazz ) ) {
 			return ( T ) this;
 		}
 		throw new PersistenceException( "Hibernate cannot unwrap " + clazz );
 	}
 
 	@Override
 	public void markForRollbackOnly() {
         LOG.debugf("Mark transaction for rollback");
 		if ( tx.isActive() ) {
 			tx.setRollbackOnly();
 		}
 		else {
 			//no explicit use of the tx. boundaries methods
 			if ( PersistenceUnitTransactionType.JTA == transactionType ) {
 				TransactionManager transactionManager = sfi().getServiceRegistry().getService( JtaPlatform.class ).retrieveTransactionManager();
 				if ( transactionManager == null ) {
 					throw new PersistenceException(
 							"Using a JTA persistence context wo setting hibernate.transaction.manager_lookup_class"
 					);
 				}
 				try {
                     if ( transactionManager.getStatus() != Status.STATUS_NO_TRANSACTION ) {
                         transactionManager.setRollbackOnly();
                     }
 				}
 				catch ( SystemException e ) {
 					throw new PersistenceException( "Unable to set the JTA transaction as RollbackOnly", e );
 				}
 			}
 		}
 	}
 
 	@Override
 	public boolean isJoinedToTransaction() {
 		checkOpen();
 
 		final SessionImplementor session = (SessionImplementor) internalGetSession();
 		final TransactionCoordinator transactionCoordinator = session.getTransactionCoordinator();
 		final TransactionImplementor transaction = transactionCoordinator.getTransaction();
 
 		return isOpen() && transaction.getJoinStatus() == JoinStatus.JOINED;
 	}
 
 	@Override
 	public void joinTransaction() {
 		checkOpen();
 		joinTransaction( true );
 	}
 
 	private void joinTransaction(boolean explicitRequest) {
 		if ( transactionType != PersistenceUnitTransactionType.JTA ) {
 			if ( explicitRequest ) {
 			    LOG.callingJoinTransactionOnNonJtaEntityManager();
 			}
 			return;
 		}
 
 		final SessionImplementor session = (SessionImplementor) internalGetSession();
 		final TransactionCoordinator transactionCoordinator = session.getTransactionCoordinator();
 		final TransactionImplementor transaction = transactionCoordinator.getTransaction();
 
 		transaction.markForJoin();
 		transactionCoordinator.pulse();
 
 		LOG.debug( "Looking for a JTA transaction to join" );
 		if ( ! transactionCoordinator.isTransactionJoinable() ) {
 			if ( explicitRequest ) {
 				// if this is an explicit join request, log a warning so user can track underlying cause
 				// of subsequent exceptions/messages
 				LOG.unableToJoinTransaction(Environment.TRANSACTION_STRATEGY);
 			}
 		}
 
 		try {
 			if ( transaction.getJoinStatus() == JoinStatus.JOINED ) {
 				LOG.debug( "Transaction already joined" );
 				return; // noop
 			}
 
 			// join the transaction and then recheck the status
 			transaction.join();
 			if ( transaction.getJoinStatus() == JoinStatus.NOT_JOINED ) {
 				if ( explicitRequest ) {
 					throw new TransactionRequiredException( "No active JTA transaction on joinTransaction call" );
 				}
 				else {
 					LOG.debug( "Unable to join JTA transaction" );
 					return;
 				}
 			}
 			else if ( transaction.getJoinStatus() == JoinStatus.MARKED_FOR_JOINED ) {
 				throw new AssertionFailure( "Transaction MARKED_FOR_JOINED after isOpen() call" );
 			}
 
 			// register behavior changes
 			SynchronizationCallbackCoordinator callbackCoordinator = transactionCoordinator.getSynchronizationCallbackCoordinator();
 			callbackCoordinator.setManagedFlushChecker( new ManagedFlushCheckerImpl() );
 			callbackCoordinator.setExceptionMapper( new CallbackExceptionMapperImpl() );
 			callbackCoordinator.setAfterCompletionAction( new AfterCompletionActionImpl( session, transactionType ) );
 		}
 		catch ( HibernateException he ) {
 			throw convert( he );
 		}
 	}
 
 	/**
 	 * returns the underlying session
 	 */
 	public Object getDelegate() {
 		checkOpen();
 		return internalGetSession();
 	}
 
 	private void writeObject(ObjectOutputStream oos) throws IOException {
 		oos.defaultWriteObject();
 	}
 
 	private void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException {
 		ois.defaultReadObject();
 		tx = new TransactionImpl( this );
 	}
 
 	@Override
 	public void handlePersistenceException(PersistenceException e) {
 		if ( e instanceof NoResultException ) {
 			return;
 		}
 		if ( e instanceof NonUniqueResultException ) {
 			return;
 		}
 		if ( e instanceof LockTimeoutException ) {
 			return;
 		}
 		if ( e instanceof QueryTimeoutException ) {
 			return;
 		}
 
 		try {
 			markForRollbackOnly();
 		}
 		catch ( Exception ne ) {
 			//we do not want the subsequent exception to swallow the original one
             LOG.unableToMarkForRollbackOnPersistenceException(ne);
 		}
 	}
 
 	@Override
 	public void throwPersistenceException(PersistenceException e) {
 		handlePersistenceException( e );
 		throw e;
 	}
 
 	@Override
 	public RuntimeException convert(HibernateException e) {
 		//FIXME should we remove all calls to this method and use convert(RuntimeException) ?
 		return convert( e, null );
 	}
 
 	public RuntimeException convert(RuntimeException e) {
 		RuntimeException result = e;
 		if ( e instanceof HibernateException ) {
 			result = convert( ( HibernateException ) e );
 		}
 		else {
 			markForRollbackOnly();
 		}
 		return result;
 	}
 
 	public RuntimeException convert(RuntimeException e, LockOptions lockOptions) {
 		RuntimeException result = e;
 		if ( e instanceof HibernateException ) {
 			result = convert( ( HibernateException ) e , lockOptions );
 		}
 		else {
 			markForRollbackOnly();
 		}
 		return result;
 	}
 
 	@Override
 	public RuntimeException convert(HibernateException e, LockOptions lockOptions) {
 		if ( e instanceof StaleStateException ) {
 			PersistenceException converted = wrapStaleStateException( ( StaleStateException ) e );
 			handlePersistenceException( converted );
 			return converted;
 		}
 		else if ( e instanceof LockingStrategyException ) {
 			PersistenceException converted = wrapLockException( e, lockOptions );
 			handlePersistenceException( converted );
 			return converted;
 		}
 		else if ( e instanceof org.hibernate.exception.LockTimeoutException ) {
 			PersistenceException converted = wrapLockException( e, lockOptions );
 			handlePersistenceException( converted );
 			return converted;
 		}
 		else if ( e instanceof org.hibernate.PessimisticLockException ) {
 			PersistenceException converted = wrapLockException( e, lockOptions );
 			handlePersistenceException( converted );
 			return converted;
 		}
 		else if ( e instanceof org.hibernate.QueryTimeoutException ) {
 			QueryTimeoutException converted = new QueryTimeoutException(e.getMessage(), e);
 			handlePersistenceException( converted );
 			return converted;
 		}
 		else if ( e instanceof ObjectNotFoundException ) {
 			EntityNotFoundException converted = new EntityNotFoundException( e.getMessage() );
 			handlePersistenceException( converted );
 			return converted;
 		}
         else if ( e instanceof org.hibernate.NonUniqueObjectException ) {
             EntityExistsException converted = new EntityExistsException( e.getMessage() );
             handlePersistenceException( converted );
             return converted;
         }
 		else if ( e instanceof org.hibernate.NonUniqueResultException ) {
 			NonUniqueResultException converted = new NonUniqueResultException( e.getMessage() );
 			handlePersistenceException( converted );
 			return converted;
 		}
 		else if ( e instanceof UnresolvableObjectException ) {
 			EntityNotFoundException converted = new EntityNotFoundException( e.getMessage() );
 			handlePersistenceException( converted );
 			return converted;
 		}
 		else if ( e instanceof QueryException ) {
 			return new IllegalArgumentException( e );
 		}
 		else if ( e instanceof TransientObjectException ) {
 			try {
 				markForRollbackOnly();
 			}
 			catch ( Exception ne ) {
 				//we do not want the subsequent exception to swallow the original one
                 LOG.unableToMarkForRollbackOnTransientObjectException(ne);
 			}
 			return new IllegalStateException( e ); //Spec 3.2.3 Synchronization rules
 		}
 		else {
 			PersistenceException converted = new PersistenceException( e );
 			handlePersistenceException( converted );
 			return converted;
 		}
 	}
 
 	@Override
 	public void throwPersistenceException(HibernateException e) {
 		throw convert( e );
 	}
 
 	@Override
 	public PersistenceException wrapStaleStateException(StaleStateException e) {
 		PersistenceException pe;
 		if ( e instanceof StaleObjectStateException ) {
 			StaleObjectStateException sose = ( StaleObjectStateException ) e;
 			Serializable identifier = sose.getIdentifier();
 			if ( identifier != null ) {
 				try {
 					Object entity = internalGetSession().load( sose.getEntityName(), identifier );
 					if ( entity instanceof Serializable ) {
 						//avoid some user errors regarding boundary crossing
 						pe = new OptimisticLockException( e.getMessage(), e, entity );
 					}
 					else {
 						pe = new OptimisticLockException( e.getMessage(), e );
 					}
 				}
 				catch ( EntityNotFoundException enfe ) {
 					pe = new OptimisticLockException( e.getMessage(), e );
 				}
 			}
 			else {
 				pe = new OptimisticLockException( e.getMessage(), e );
 			}
 		}
 		else {
 			pe = new OptimisticLockException( e.getMessage(), e );
 		}
 		return pe;
 	}
 
 	public PersistenceException wrapLockException(HibernateException e, LockOptions lockOptions) {
 		final PersistenceException pe;
 		if ( e instanceof OptimisticEntityLockException ) {
 			final OptimisticEntityLockException lockException = (OptimisticEntityLockException) e;
 			pe = new OptimisticLockException( lockException.getMessage(), lockException, lockException.getEntity() );
 		}
 		else if ( e instanceof org.hibernate.exception.LockTimeoutException ) {
 			pe = new LockTimeoutException( e.getMessage(), e, null );
 		}
 		else if ( e instanceof PessimisticEntityLockException ) {
 			PessimisticEntityLockException lockException = (PessimisticEntityLockException) e;
 			if ( lockOptions != null && lockOptions.getTimeOut() > -1 ) {
 				// assume lock timeout occurred if a timeout or NO WAIT was specified
 				pe = new LockTimeoutException( lockException.getMessage(), lockException, lockException.getEntity() );
 			}
 			else {
 				pe = new PessimisticLockException( lockException.getMessage(), lockException, lockException.getEntity() );
 			}
 		}
 		else if ( e instanceof org.hibernate.PessimisticLockException ) {
 			org.hibernate.PessimisticLockException jdbcLockException = ( org.hibernate.PessimisticLockException ) e;
 			if ( lockOptions != null && lockOptions.getTimeOut() > -1 ) {
 				// assume lock timeout occurred if a timeout or NO WAIT was specified
 				pe = new LockTimeoutException( jdbcLockException.getMessage(), jdbcLockException, null );
 			}
 			else {
 				pe = new PessimisticLockException( jdbcLockException.getMessage(), jdbcLockException, null );
 			}
 		}
 		else {
 			pe = new OptimisticLockException( e );
 		}
 		return pe;
 	}
 
 	private static class AfterCompletionActionImpl implements AfterCompletionAction {
 		private final SessionImplementor session;
 		private final PersistenceUnitTransactionType transactionType;
 
 		private AfterCompletionActionImpl(SessionImplementor session, PersistenceUnitTransactionType transactionType) {
 			this.session = session;
 			this.transactionType = transactionType;
 		}
 
 		@Override
 		public void doAction(TransactionCoordinator transactionCoordinator, int status) {
 			if ( session.isClosed() ) {
                 LOG.trace("Session was closed; nothing to do");
 				return;
 			}
 
 			final boolean successful = JtaStatusHelper.isCommitted( status );
 			if ( !successful && transactionType == PersistenceUnitTransactionType.JTA ) {
 				( (Session) session ).clear();
 			}
 			session.getTransactionCoordinator().resetJoinStatus();
 		}
 	}
 
 	private static class ManagedFlushCheckerImpl implements ManagedFlushChecker {
 		@Override
 		public boolean shouldDoManagedFlush(TransactionCoordinator coordinator, int jtaStatus) {
 			return ! coordinator.getTransactionContext().isClosed() &&
 					! coordinator.getTransactionContext().isFlushModeNever() &&
 					! JtaStatusHelper.isRollback( jtaStatus );
 		}
 	}
 
 	private class CallbackExceptionMapperImpl implements ExceptionMapper {
 		@Override
 		public RuntimeException mapStatusCheckFailure(String message, SystemException systemException) {
 			throw new PersistenceException( message, systemException );
 		}
 
 		@Override
 		public RuntimeException mapManagedFlushFailure(String message, RuntimeException failure) {
 			if ( HibernateException.class.isInstance( failure ) ) {
 				throw convert( failure );
 			}
 			if ( PersistenceException.class.isInstance( failure ) ) {
 				throw failure;
 			}
 			throw new PersistenceException( message, failure );
 		}
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/AuditJoinTable.java b/hibernate-envers/src/main/java/org/hibernate/envers/AuditJoinTable.java
index 2a22d3a9f1..74ce58c678 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/AuditJoinTable.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/AuditJoinTable.java
@@ -1,59 +1,59 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers;
 
 import javax.persistence.JoinColumn;
 import java.lang.annotation.ElementType;
 import java.lang.annotation.Retention;
 import java.lang.annotation.RetentionPolicy;
 import java.lang.annotation.Target;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  */
 @Retention(RetentionPolicy.RUNTIME)
 @Target({ElementType.FIELD, ElementType.METHOD})
 public @interface AuditJoinTable {
 	/**
 	 * Name of the join table. Defaults to a concatenation of the names of the primary table of the entity
 	 * owning the association and of the primary table of the entity referenced by the association.
 	 */
 	String name() default "";
 
 	/**
 	 * The schema of the join table. Defaults to the schema of the entity owning the association.
 	 */
 	String schema() default "";
 
 	/**
 	 * The catalog of the join table. Defaults to the catalog of the entity owning the association.
 	 */
 	String catalog() default "";
 
 	/**
 	 * The foreign key columns of the join table which reference the primary table of the entity that does not
 	 * own the association (i.e. the inverse side of the association).
 	 */
 	JoinColumn[] inverseJoinColumns() default {};
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/MetadataTools.java b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/MetadataTools.java
index 98863cae25..b57ded58f4 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/MetadataTools.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/MetadataTools.java
@@ -1,433 +1,435 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.configuration.internal.metadata;
 
 import javax.persistence.JoinColumn;
 import java.util.Iterator;
 
 import org.dom4j.Attribute;
 import org.dom4j.Document;
 import org.dom4j.Element;
 
 import org.hibernate.envers.internal.tools.StringTools;
 import org.hibernate.mapping.Column;
 import org.hibernate.mapping.Formula;
 import org.hibernate.mapping.Selectable;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  * @author Michal Skowronek (mskowr at o2 dot pl)
  */
-public class MetadataTools {
+public final class MetadataTools {
+	private MetadataTools() {
+	}
 
 	public static Element addNativelyGeneratedId(
 			Element parent, String name, String type,
 			boolean useRevisionEntityWithNativeId) {
 		final Element idMapping = parent.addElement( "id" );
 		idMapping.addAttribute( "name", name ).addAttribute( "type", type );
 
 		final Element generatorMapping = idMapping.addElement( "generator" );
 		if ( useRevisionEntityWithNativeId ) {
 			generatorMapping.addAttribute( "class", "native" );
 		}
 		else {
 			generatorMapping.addAttribute( "class", "org.hibernate.envers.enhanced.OrderedSequenceGenerator" );
 			generatorMapping.addElement( "param" ).addAttribute( "name", "sequence_name" ).setText(
 					"REVISION_GENERATOR"
 			);
 			generatorMapping.addElement( "param" )
 					.addAttribute( "name", "table_name" )
 					.setText( "REVISION_GENERATOR" );
 			generatorMapping.addElement( "param" ).addAttribute( "name", "initial_value" ).setText( "1" );
 			generatorMapping.addElement( "param" ).addAttribute( "name", "increment_size" ).setText( "1" );
 		}
 //        generatorMapping.addAttribute("class", "sequence");
 //        generatorMapping.addElement("param").addAttribute("name", "sequence").setText("custom");
 
 		return idMapping;
 	}
 
 	public static Element addProperty(
 			Element parent,
 			String name,
 			String type,
 			boolean insertable,
 			boolean updateable,
 			boolean key) {
 		final Element propMapping;
 		if ( key ) {
 			propMapping = parent.addElement( "key-property" );
 		}
 		else {
 			propMapping = parent.addElement( "property" );
 		}
 
 		propMapping.addAttribute( "name", name );
 		propMapping.addAttribute( "insert", Boolean.toString( insertable ) );
 		propMapping.addAttribute( "update", Boolean.toString( updateable ) );
 
 		if ( type != null ) {
 			propMapping.addAttribute( "type", type );
 		}
 
 		return propMapping;
 	}
 
 	public static Element addProperty(Element parent, String name, String type, boolean insertable, boolean key) {
 		return addProperty( parent, name, type, insertable, false, key );
 	}
 
 	public static Element addModifiedFlagProperty(Element parent, String propertyName, String suffix) {
 		return addProperty(
 				parent,
 				getModifiedFlagPropertyName( propertyName, suffix ),
 				"boolean",
 				true,
 				false,
 				false
 		);
 	}
 
 	public static String getModifiedFlagPropertyName(String propertyName, String suffix) {
 		return propertyName + suffix;
 	}
 
 	private static void addOrModifyAttribute(Element parent, String name, String value) {
 		final Attribute attribute = parent.attribute( name );
 		if ( attribute == null ) {
 			parent.addAttribute( name, value );
 		}
 		else {
 			attribute.setValue( value );
 		}
 	}
 
 	/**
 	 * Column name shall be wrapped with '`' signs if quotation required.
 	 */
 	public static Element addOrModifyColumn(Element parent, String name) {
 		final Element columnMapping = parent.element( "column" );
 
 		if ( columnMapping == null ) {
 			return addColumn( parent, name, null, null, null, null, null, null );
 		}
 
 		if ( !StringTools.isEmpty( name ) ) {
 			addOrModifyAttribute( columnMapping, "name", name );
 		}
 
 		return columnMapping;
 	}
 
 	/**
 	 * Adds new <code>column</code> element. Method assumes that the value of <code>name</code> attribute is already
 	 * wrapped with '`' signs if quotation required. It shall be invoked when column name is taken directly from configuration
 	 * file and not from {@link org.hibernate.mapping.PersistentClass} descriptor.
 	 */
 	public static Element addColumn(
 			Element parent,
 			String name,
 			Integer length,
 			Integer scale,
 			Integer precision,
 			String sqlType,
 			String customRead,
 			String customWrite) {
 		return addColumn( parent, name, length, scale, precision, sqlType, customRead, customWrite, false );
 	}
 
 	public static Element addColumn(
 			Element parent,
 			String name,
 			Integer length,
 			Integer scale,
 			Integer precision,
 			String sqlType,
 			String customRead,
 			String customWrite,
 			boolean quoted) {
 		final Element columnMapping = parent.addElement( "column" );
 
 		columnMapping.addAttribute( "name", quoted ? "`" + name + "`" : name );
 		if ( length != null ) {
 			columnMapping.addAttribute( "length", length.toString() );
 		}
 		if ( scale != null ) {
 			columnMapping.addAttribute( "scale", Integer.toString( scale ) );
 		}
 		if ( precision != null ) {
 			columnMapping.addAttribute( "precision", Integer.toString( precision ) );
 		}
 		if ( !StringTools.isEmpty( sqlType ) ) {
 			columnMapping.addAttribute( "sql-type", sqlType );
 		}
 
 		if ( !StringTools.isEmpty( customRead ) ) {
 			columnMapping.addAttribute( "read", customRead );
 		}
 		if ( !StringTools.isEmpty( customWrite ) ) {
 			columnMapping.addAttribute( "write", customWrite );
 		}
 
 		return columnMapping;
 	}
 
 	private static Element createEntityCommon(
 			Document document,
 			String type,
 			AuditTableData auditTableData,
 			String discriminatorValue,
 			Boolean isAbstract) {
 		final Element hibernateMapping = document.addElement( "hibernate-mapping" );
 		hibernateMapping.addAttribute( "auto-import", "false" );
 
 		final Element classMapping = hibernateMapping.addElement( type );
 
 		if ( auditTableData.getAuditEntityName() != null ) {
 			classMapping.addAttribute( "entity-name", auditTableData.getAuditEntityName() );
 		}
 
 		if ( discriminatorValue != null ) {
 			classMapping.addAttribute( "discriminator-value", discriminatorValue );
 		}
 
 		if ( !StringTools.isEmpty( auditTableData.getAuditTableName() ) ) {
 			classMapping.addAttribute( "table", auditTableData.getAuditTableName() );
 		}
 
 		if ( !StringTools.isEmpty( auditTableData.getSchema() ) ) {
 			classMapping.addAttribute( "schema", auditTableData.getSchema() );
 		}
 
 		if ( !StringTools.isEmpty( auditTableData.getCatalog() ) ) {
 			classMapping.addAttribute( "catalog", auditTableData.getCatalog() );
 		}
 
 		if ( isAbstract != null ) {
 			classMapping.addAttribute( "abstract", isAbstract.toString() );
 		}
 
 		return classMapping;
 	}
 
 	public static Element createEntity(
 			Document document,
 			AuditTableData auditTableData,
 			String discriminatorValue,
 			Boolean isAbstract) {
 		return createEntityCommon( document, "class", auditTableData, discriminatorValue, isAbstract );
 	}
 
 	public static Element createSubclassEntity(
 			Document document,
 			String subclassType,
 			AuditTableData auditTableData,
 			String extendsEntityName,
 			String discriminatorValue,
 			Boolean isAbstract) {
 		final Element classMapping = createEntityCommon(
 				document,
 				subclassType,
 				auditTableData,
 				discriminatorValue,
 				isAbstract
 		);
 
 		classMapping.addAttribute( "extends", extendsEntityName );
 
 		return classMapping;
 	}
 
 	public static Element createJoin(
 			Element parent,
 			String tableName,
 			String schema,
 			String catalog) {
 		final Element joinMapping = parent.addElement( "join" );
 
 		joinMapping.addAttribute( "table", tableName );
 
 		if ( !StringTools.isEmpty( schema ) ) {
 			joinMapping.addAttribute( "schema", schema );
 		}
 
 		if ( !StringTools.isEmpty( catalog ) ) {
 			joinMapping.addAttribute( "catalog", catalog );
 		}
 
 		return joinMapping;
 	}
 
 	public static void addColumns(Element anyMapping, Iterator selectables) {
 		while ( selectables.hasNext() ) {
 			final Selectable selectable = (Selectable) selectables.next();
 			if ( selectable.isFormula() ) {
 				throw new FormulaNotSupportedException();
 			}
 			addColumn( anyMapping, (Column) selectable );
 		}
 	}
 
 	/**
 	 * Adds <code>column</code> element with the following attributes (unless empty): <code>name</code>,
 	 * <code>length</code>, <code>scale</code>, <code>precision</code>, <code>sql-type</code>, <code>read</code>
 	 * and <code>write</code>.
 	 *
 	 * @param anyMapping Parent element.
 	 * @param column Column descriptor.
 	 */
 	public static void addColumn(Element anyMapping, Column column) {
 		addColumn(
 				anyMapping,
 				column.getName(),
 				column.getLength(),
 				column.getScale(),
 				column.getPrecision(),
 				column.getSqlType(),
 				column.getCustomRead(),
 				column.getCustomWrite(),
 				column.isQuoted()
 		);
 	}
 
 	@SuppressWarnings({"unchecked"})
 	private static void changeNamesInColumnElement(Element element, ColumnNameIterator columnNameIterator) {
 		final Iterator<Element> properties = element.elementIterator();
 		while ( properties.hasNext() ) {
 			final Element property = properties.next();
 
 			if ( "column".equals( property.getName() ) ) {
 				final Attribute nameAttr = property.attribute( "name" );
 				if ( nameAttr != null ) {
 					nameAttr.setText( columnNameIterator.next() );
 				}
 			}
 		}
 	}
 
 	@SuppressWarnings({"unchecked"})
 	public static void prefixNamesInPropertyElement(
 			Element element,
 			String prefix,
 			ColumnNameIterator columnNameIterator,
 			boolean changeToKey,
 			boolean insertable) {
 		final Iterator<Element> properties = element.elementIterator();
 		while ( properties.hasNext() ) {
 			final Element property = properties.next();
 
 			if ( "property".equals( property.getName() ) || "many-to-one".equals( property.getName() ) ) {
 				final Attribute nameAttr = property.attribute( "name" );
 				if ( nameAttr != null ) {
 					nameAttr.setText( prefix + nameAttr.getText() );
 				}
 
 				changeNamesInColumnElement( property, columnNameIterator );
 
 				if ( changeToKey ) {
 					property.setName( "key-" + property.getName() );
 				}
 
 				if ( "property".equals( property.getName() ) ) {
 					final Attribute insert = property.attribute( "insert" );
 					insert.setText( Boolean.toString( insertable ) );
 				}
 			}
 		}
 	}
 
 	/**
 	 * Adds <code>formula</code> element.
 	 *
 	 * @param element Parent element.
 	 * @param formula Formula descriptor.
 	 */
 	public static void addFormula(Element element, Formula formula) {
 		element.addElement( "formula" ).setText( formula.getText() );
 	}
 
 	/**
 	 * Adds all <code>column</code> or <code>formula</code> elements.
 	 *
 	 * @param element Parent element.
 	 * @param columnIterator Iterator pointing at {@link org.hibernate.mapping.Column} and/or
 	 * {@link org.hibernate.mapping.Formula} objects.
 	 */
 	public static void addColumnsOrFormulas(Element element, Iterator columnIterator) {
 		while ( columnIterator.hasNext() ) {
 			final Object o = columnIterator.next();
 			if ( o instanceof Column ) {
 				addColumn( element, (Column) o );
 			}
 			else if ( o instanceof Formula ) {
 				addFormula( element, (Formula) o );
 			}
 		}
 	}
 
 	/**
 	 * An iterator over column names.
 	 */
 	public static abstract class ColumnNameIterator implements Iterator<String> {
 	}
 
 	public static ColumnNameIterator getColumnNameIterator(final Iterator<Selectable> selectableIterator) {
 		return new ColumnNameIterator() {
 			public boolean hasNext() {
 				return selectableIterator.hasNext();
 			}
 
 			public String next() {
 				final Selectable next = selectableIterator.next();
 				if ( next.isFormula() ) {
 					throw new FormulaNotSupportedException();
 				}
 				return ((Column) next).getName();
 			}
 
 			public void remove() {
 				selectableIterator.remove();
 			}
 		};
 	}
 
 	public static ColumnNameIterator getColumnNameIterator(final JoinColumn[] joinColumns) {
 		return new ColumnNameIterator() {
-			int counter = 0;
+			int counter;
 
 			public boolean hasNext() {
 				return counter < joinColumns.length;
 			}
 
 			public String next() {
 				return joinColumns[counter++].name();
 			}
 
 			public void remove() {
 				throw new UnsupportedOperationException();
 			}
 		};
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/reader/ComponentAuditingData.java b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/reader/ComponentAuditingData.java
index 754c26bc60..f3e4c5abfe 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/reader/ComponentAuditingData.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/configuration/internal/metadata/reader/ComponentAuditingData.java
@@ -1,67 +1,67 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.configuration.internal.metadata.reader;
 
 import java.util.Map;
 import java.util.Set;
 
 import static org.hibernate.envers.internal.tools.Tools.newHashMap;
 
 /**
  * Audit mapping meta-data for component.
  *
  * @author Adam Warski (adam at warski dot org)
  * @author Hern&aacut;n Chanfreau
  */
 public class ComponentAuditingData extends PropertyAuditingData implements AuditedPropertiesHolder {
 	private final Map<String, PropertyAuditingData> properties;
 
 	public ComponentAuditingData() {
 		this.properties = newHashMap();
 	}
 
 	@Override
 	public boolean isEmpty() {
 		return properties.isEmpty();
 	}
 
 	@Override
 	public void addPropertyAuditingData(String propertyName, PropertyAuditingData auditingData) {
 		properties.put( propertyName, auditingData );
 	}
 
 	@Override
 	public PropertyAuditingData getPropertyAuditingData(String propertyName) {
 		return properties.get( propertyName );
 	}
 
 	@Override
 	public boolean contains(String propertyName) {
 		return properties.containsKey( propertyName );
 	}
 
 	public Set<String> getPropertyNames() {
 		return properties.keySet();
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/SimpleMapperBuilder.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/SimpleMapperBuilder.java
index 4e545f845b..90a14c8c38 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/SimpleMapperBuilder.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/SimpleMapperBuilder.java
@@ -1,33 +1,33 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities.mapper;
 
 import org.hibernate.envers.internal.entities.PropertyData;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  */
 public interface SimpleMapperBuilder {
 	public void add(PropertyData propertyData);
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/ListCollectionMapper.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/ListCollectionMapper.java
index 6d1ca6ea2c..8468c0628b 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/ListCollectionMapper.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/ListCollectionMapper.java
@@ -1,106 +1,106 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities.mapper.relation;
 
 import java.io.Serializable;
 import java.util.Collection;
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.envers.internal.entities.mapper.PropertyMapper;
 import org.hibernate.envers.internal.entities.mapper.relation.lazy.initializor.Initializor;
 import org.hibernate.envers.internal.entities.mapper.relation.lazy.initializor.ListCollectionInitializor;
 import org.hibernate.envers.internal.entities.mapper.relation.lazy.proxy.ListProxy;
 import org.hibernate.envers.internal.reader.AuditReaderImplementor;
 import org.hibernate.envers.internal.tools.Tools;
 import org.hibernate.envers.tools.Pair;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  */
 public final class ListCollectionMapper extends AbstractCollectionMapper<List> implements PropertyMapper {
 	private final MiddleComponentData elementComponentData;
 	private final MiddleComponentData indexComponentData;
 
 	public ListCollectionMapper(
 			CommonCollectionMapperData commonCollectionMapperData,
 			MiddleComponentData elementComponentData, MiddleComponentData indexComponentData,
 			boolean revisionTypeInId) {
 		super( commonCollectionMapperData, List.class, ListProxy.class, false, revisionTypeInId );
 		this.elementComponentData = elementComponentData;
 		this.indexComponentData = indexComponentData;
 	}
 
 	@Override
 	protected Initializor<List> getInitializor(
 			AuditConfiguration verCfg, AuditReaderImplementor versionsReader,
 			Object primaryKey, Number revision, boolean removed) {
 		return new ListCollectionInitializor(
 				verCfg, versionsReader, commonCollectionMapperData.getQueryGenerator(),
 				primaryKey, revision, removed, elementComponentData, indexComponentData
 		);
 	}
 
 	@Override
 	@SuppressWarnings({"unchecked"})
 	protected Collection getNewCollectionContent(PersistentCollection newCollection) {
 		if ( newCollection == null ) {
 			return null;
 		}
 		else {
 			return Tools.listToIndexElementPairList( (List<Object>) newCollection );
 		}
 	}
 
 	@Override
 	@SuppressWarnings({"unchecked"})
 	protected Collection getOldCollectionContent(Serializable oldCollection) {
 		if ( oldCollection == null ) {
 			return null;
 		}
 		else {
 			return Tools.listToIndexElementPairList( (List<Object>) oldCollection );
 		}
 	}
 
 	@Override
 	@SuppressWarnings({"unchecked"})
 	protected void mapToMapFromObject(
 			SessionImplementor session,
 			Map<String, Object> idData,
 			Map<String, Object> data,
 			Object changed) {
 		final Pair<Integer, Object> indexValuePair = (Pair<Integer, Object>) changed;
 		elementComponentData.getComponentMapper().mapToMapFromObject(
 				session,
 				idData,
 				data,
 				indexValuePair.getSecond()
 		);
 		indexComponentData.getComponentMapper().mapToMapFromObject( session, idData, data, indexValuePair.getFirst() );
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/MapCollectionMapper.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/MapCollectionMapper.java
index fbc3671bcd..e6323e9c15 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/MapCollectionMapper.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/MapCollectionMapper.java
@@ -1,104 +1,104 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities.mapper.relation;
 
 import java.io.Serializable;
 import java.util.Collection;
 import java.util.Map;
 
 import org.hibernate.collection.spi.PersistentCollection;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.envers.internal.entities.mapper.PropertyMapper;
 import org.hibernate.envers.internal.entities.mapper.relation.lazy.initializor.Initializor;
 import org.hibernate.envers.internal.entities.mapper.relation.lazy.initializor.MapCollectionInitializor;
 import org.hibernate.envers.internal.reader.AuditReaderImplementor;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  */
 public class MapCollectionMapper<T extends Map> extends AbstractCollectionMapper<T> implements PropertyMapper {
 	protected final MiddleComponentData elementComponentData;
 	protected final MiddleComponentData indexComponentData;
 
 	public MapCollectionMapper(
 			CommonCollectionMapperData commonCollectionMapperData,
 			Class<? extends T> collectionClass, Class<? extends T> proxyClass,
 			MiddleComponentData elementComponentData, MiddleComponentData indexComponentData,
 			boolean revisionTypeInId) {
 		super( commonCollectionMapperData, collectionClass, proxyClass, false, revisionTypeInId );
 		this.elementComponentData = elementComponentData;
 		this.indexComponentData = indexComponentData;
 	}
 
 	@Override
 	protected Initializor<T> getInitializor(
 			AuditConfiguration verCfg, AuditReaderImplementor versionsReader,
 			Object primaryKey, Number revision, boolean removed) {
 		return new MapCollectionInitializor<T>(
 				verCfg, versionsReader, commonCollectionMapperData.getQueryGenerator(),
 				primaryKey, revision, removed, collectionClass, elementComponentData, indexComponentData
 		);
 	}
 
 	@Override
 	protected Collection getNewCollectionContent(PersistentCollection newCollection) {
 		if ( newCollection == null ) {
 			return null;
 		}
 		else {
 			return ((Map) newCollection).entrySet();
 		}
 	}
 
 	@Override
 	protected Collection getOldCollectionContent(Serializable oldCollection) {
 		if ( oldCollection == null ) {
 			return null;
 		}
 		else {
 			return ((Map) oldCollection).entrySet();
 		}
 	}
 
 	@Override
 	protected void mapToMapFromObject(
 			SessionImplementor session,
 			Map<String, Object> idData,
 			Map<String, Object> data,
 			Object changed) {
 		elementComponentData.getComponentMapper().mapToMapFromObject(
 				session,
 				idData,
 				data,
 				((Map.Entry) changed).getValue()
 		);
 		indexComponentData.getComponentMapper().mapToMapFromObject(
 				session,
 				idData,
 				data,
 				((Map.Entry) changed).getKey()
 		);
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/OneToOnePrimaryKeyJoinColumnMapper.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/OneToOnePrimaryKeyJoinColumnMapper.java
index 7503bc0284..c442463ed0 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/OneToOnePrimaryKeyJoinColumnMapper.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/OneToOnePrimaryKeyJoinColumnMapper.java
@@ -1,88 +1,88 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities.mapper.relation;
 
 import java.io.Serializable;
 
 import org.hibernate.envers.internal.entities.PropertyData;
 import org.hibernate.envers.internal.reader.AuditReaderImplementor;
 import org.hibernate.envers.query.AuditEntity;
 import org.hibernate.persister.entity.EntityPersister;
 
 /**
  * Property mapper for {@link javax.persistence.OneToOne} with {@link javax.persistence.PrimaryKeyJoinColumn} relation.
  *
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public class OneToOnePrimaryKeyJoinColumnMapper extends AbstractOneToOneMapper {
 	public OneToOnePrimaryKeyJoinColumnMapper(
 			String entityName,
 			String referencedEntityName,
 			PropertyData propertyData) {
 		super( entityName, referencedEntityName, propertyData );
 	}
 
 	@Override
 	protected Object queryForReferencedEntity(
 			AuditReaderImplementor versionsReader, EntityInfo referencedEntity,
 			Serializable primaryKey, Number revision) {
 		if ( referencedEntity.isAudited() ) {
 			// Audited relation.
 			return versionsReader.createQuery().forEntitiesAtRevision(
 					referencedEntity.getEntityClass(),
 					referencedEntity.getEntityName(), revision
 			)
 					.add( AuditEntity.id().eq( primaryKey ) )
 					.getSingleResult();
 		}
 		else {
 			// Not audited relation.
 			return createNotAuditedEntityReference(
 					versionsReader, referencedEntity.getEntityClass(),
 					referencedEntity.getEntityName(), primaryKey
 			);
 		}
 	}
 
 	/**
 	 * Create Hibernate proxy or retrieve the complete object of referenced, not audited entity. According to
 	 * {@link org.hibernate.envers.Audited#targetAuditMode()}} documentation, reference shall point to current
 	 * (non-historical) version of an entity.
 	 */
 	private Object createNotAuditedEntityReference(
 			AuditReaderImplementor versionsReader, Class<?> entityClass,
 			String entityName, Serializable primaryKey) {
 		final EntityPersister entityPersister = versionsReader.getSessionImplementor().getFactory().getEntityPersister(
 				entityName
 		);
 		if ( entityPersister.hasProxy() ) {
 			// If possible create a proxy. Returning complete object may affect performance.
 			return versionsReader.getSession().load( entityClass, primaryKey );
 		}
 		else {
 			// If proxy is not allowed (e.g. @Proxy(lazy=false)) construct the original object.
 			return versionsReader.getSession().get( entityClass, primaryKey );
 		}
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/SortedMapCollectionMapper.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/SortedMapCollectionMapper.java
index a9ec7f442a..5b04d239d5 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/SortedMapCollectionMapper.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/SortedMapCollectionMapper.java
@@ -1,66 +1,66 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities.mapper.relation;
 
 import java.util.Comparator;
 import java.util.SortedMap;
 
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.envers.internal.entities.mapper.relation.lazy.initializor.Initializor;
 import org.hibernate.envers.internal.entities.mapper.relation.lazy.initializor.SortedMapCollectionInitializor;
 import org.hibernate.envers.internal.reader.AuditReaderImplementor;
 
 /**
  * @author Michal Skowronek (mskowr at o2 dot pl)
  */
 public final class SortedMapCollectionMapper extends MapCollectionMapper<SortedMap> {
 	private final Comparator comparator;
 
 	public SortedMapCollectionMapper(
 			CommonCollectionMapperData commonCollectionMapperData,
 			Class<? extends SortedMap> collectionClass, Class<? extends SortedMap> proxyClass,
 			MiddleComponentData elementComponentData, MiddleComponentData indexComponentData, Comparator comparator,
 			boolean revisionTypeInId) {
 		super(
 				commonCollectionMapperData,
 				collectionClass,
 				proxyClass,
 				elementComponentData,
 				indexComponentData,
 				revisionTypeInId
 		);
 		this.comparator = comparator;
 	}
 
 	@Override
 	protected Initializor<SortedMap> getInitializor(
 			AuditConfiguration verCfg, AuditReaderImplementor versionsReader,
 			Object primaryKey, Number revision, boolean removed) {
 		return new SortedMapCollectionInitializor(
 				verCfg, versionsReader, commonCollectionMapperData.getQueryGenerator(),
 				primaryKey, revision, removed, collectionClass, elementComponentData, indexComponentData, comparator
 		);
 	}
 
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/ToOneEntityLoader.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/ToOneEntityLoader.java
index 78eedada9a..d26d43e3f8 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/ToOneEntityLoader.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/ToOneEntityLoader.java
@@ -1,101 +1,104 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities.mapper.relation;
 
 import java.io.Serializable;
 
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.envers.internal.entities.mapper.relation.lazy.ToOneDelegateSessionImplementor;
 import org.hibernate.envers.internal.reader.AuditReaderImplementor;
 import org.hibernate.persister.entity.EntityPersister;
 
 /**
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
-public class ToOneEntityLoader {
+public final class ToOneEntityLoader {
+	private ToOneEntityLoader() {
+	}
+
 	/**
 	 * Immediately loads historical entity or its current state when excluded from audit process. Returns {@code null}
 	 * reference if entity has not been found in the database.
 	 */
 	public static Object loadImmediate(
 			AuditReaderImplementor versionsReader,
 			Class<?> entityClass,
 			String entityName,
 			Object entityId,
 			Number revision,
 			boolean removed,
 			AuditConfiguration verCfg) {
 		if ( verCfg.getEntCfg().getNotVersionEntityConfiguration( entityName ) == null ) {
 			// Audited relation, look up entity with Envers.
 			// When user traverses removed entities graph, do not restrict revision type of referencing objects
 			// to ADD or MOD (DEL possible). See HHH-5845.
 			return versionsReader.find( entityClass, entityName, entityId, revision, removed );
 		}
 		else {
 			// Not audited relation, look up entity with Hibernate.
 			return versionsReader.getSessionImplementor().immediateLoad( entityName, (Serializable) entityId );
 		}
 	}
 
 	/**
 	 * Creates proxy of referenced *-to-one entity.
 	 */
 	public static Object createProxy(
 			AuditReaderImplementor versionsReader,
 			Class<?> entityClass,
 			String entityName,
 			Object entityId,
 			Number revision,
 			boolean removed,
 			AuditConfiguration verCfg) {
 		final EntityPersister persister = versionsReader.getSessionImplementor()
 				.getFactory()
 				.getEntityPersister( entityName );
 		return persister.createProxy(
 				(Serializable) entityId,
 				new ToOneDelegateSessionImplementor( versionsReader, entityClass, entityId, revision, removed, verCfg )
 		);
 	}
 
 	/**
 	 * Creates Hibernate proxy or retrieves the complete object of an entity if proxy is not
 	 * allowed (e.g. @Proxy(lazy=false), final class).
 	 */
 	public static Object createProxyOrLoadImmediate(
 			AuditReaderImplementor versionsReader,
 			Class<?> entityClass,
 			String entityName,
 			Object entityId,
 			Number revision,
 			boolean removed,
 			AuditConfiguration verCfg) {
 		final EntityPersister persister = versionsReader.getSessionImplementor()
 				.getFactory()
 				.getEntityPersister( entityName );
 		if ( persister.hasProxy() ) {
 			return createProxy( versionsReader, entityClass, entityName, entityId, revision, removed, verCfg );
 		}
 		return loadImmediate( versionsReader, entityClass, entityName, entityId, revision, removed, verCfg );
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/component/MiddleDummyComponentMapper.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/component/MiddleDummyComponentMapper.java
index 257c50d115..60ac7e9096 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/component/MiddleDummyComponentMapper.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/component/MiddleDummyComponentMapper.java
@@ -1,58 +1,58 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities.mapper.relation.component;
 
 import java.util.Map;
 
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.envers.internal.entities.EntityInstantiator;
 import org.hibernate.envers.internal.tools.query.Parameters;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  */
 public final class MiddleDummyComponentMapper implements MiddleComponentMapper {
 	public Object mapToObjectFromFullMap(
 			EntityInstantiator entityInstantiator, Map<String, Object> data,
 			Object dataObject, Number revision) {
 		return null;
 	}
 
 	@Override
 	public void mapToMapFromObject(
 			SessionImplementor session,
 			Map<String, Object> idData,
 			Map<String, Object> data,
 			Object obj) {
 	}
 
 	@Override
 	public void addMiddleEqualToQuery(
 			Parameters parameters,
 			String idPrefix1,
 			String prefix1,
 			String idPrefix2,
 			String prefix2) {
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/component/MiddleMapKeyIdComponentMapper.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/component/MiddleMapKeyIdComponentMapper.java
index 5298441418..81691c7000 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/component/MiddleMapKeyIdComponentMapper.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/component/MiddleMapKeyIdComponentMapper.java
@@ -1,75 +1,75 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities.mapper.relation.component;
 
 import java.util.Map;
 
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.envers.configuration.internal.AuditEntitiesConfiguration;
 import org.hibernate.envers.internal.entities.EntityInstantiator;
 import org.hibernate.envers.internal.entities.mapper.id.IdMapper;
 import org.hibernate.envers.internal.tools.query.Parameters;
 
 /**
  * A component mapper for the @MapKey mapping: the value of the map's key is the id of the entity. This
  * doesn't have an effect on the data stored in the versions tables, so <code>mapToMapFromObject</code> is
  * empty.
  *
  * @author Adam Warski (adam at warski dot org)
  */
 public final class MiddleMapKeyIdComponentMapper implements MiddleComponentMapper {
 	private final AuditEntitiesConfiguration verEntCfg;
 	private final IdMapper relatedIdMapper;
 
 	public MiddleMapKeyIdComponentMapper(AuditEntitiesConfiguration verEntCfg, IdMapper relatedIdMapper) {
 		this.verEntCfg = verEntCfg;
 		this.relatedIdMapper = relatedIdMapper;
 	}
 
 	@Override
 	public Object mapToObjectFromFullMap(
 			EntityInstantiator entityInstantiator, Map<String, Object> data,
 			Object dataObject, Number revision) {
 		return relatedIdMapper.mapToIdFromMap( (Map) data.get( verEntCfg.getOriginalIdPropName() ) );
 	}
 
 	@Override
 	public void mapToMapFromObject(
 			SessionImplementor session,
 			Map<String, Object> idData,
 			Map<String, Object> data,
 			Object obj) {
 		// Doing nothing.
 	}
 
 	@Override
 	public void addMiddleEqualToQuery(
 			Parameters parameters,
 			String idPrefix1,
 			String prefix1,
 			String idPrefix2,
 			String prefix2) {
 		// Doing nothing.
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/component/MiddleMapKeyPropertyComponentMapper.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/component/MiddleMapKeyPropertyComponentMapper.java
index 1a68b800a1..68d1a9fd6e 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/component/MiddleMapKeyPropertyComponentMapper.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/component/MiddleMapKeyPropertyComponentMapper.java
@@ -1,75 +1,75 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities.mapper.relation.component;
 
 import java.util.Map;
 
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.envers.internal.entities.EntityInstantiator;
 import org.hibernate.envers.internal.tools.ReflectionTools;
 import org.hibernate.envers.internal.tools.query.Parameters;
 
 /**
  * A component mapper for the @MapKey mapping with the name parameter specified: the value of the map's key
  * is a property of the entity. This doesn't have an effect on the data stored in the versions tables,
  * so <code>mapToMapFromObject</code> is empty.
  *
  * @author Adam Warski (adam at warski dot org)
  */
 public class MiddleMapKeyPropertyComponentMapper implements MiddleComponentMapper {
 	private final String propertyName;
 	private final String accessType;
 
 	public MiddleMapKeyPropertyComponentMapper(String propertyName, String accessType) {
 		this.propertyName = propertyName;
 		this.accessType = accessType;
 	}
 
 	@Override
 	public Object mapToObjectFromFullMap(
 			EntityInstantiator entityInstantiator, Map<String, Object> data,
 			Object dataObject, Number revision) {
 		// dataObject is not null, as this mapper can only be used in an index.
 		return ReflectionTools.getGetter( dataObject.getClass(), propertyName, accessType ).get( dataObject );
 	}
 
 	@Override
 	public void mapToMapFromObject(
 			SessionImplementor session,
 			Map<String, Object> idData,
 			Map<String, Object> data,
 			Object obj) {
 		// Doing nothing.
 	}
 
 	@Override
 	public void addMiddleEqualToQuery(
 			Parameters parameters,
 			String idPrefix1,
 			String prefix1,
 			String idPrefix2,
 			String prefix2) {
 		// Doing nothing.
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/component/MiddleStraightComponentMapper.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/component/MiddleStraightComponentMapper.java
index 02275fea4b..48a9410b9c 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/component/MiddleStraightComponentMapper.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/component/MiddleStraightComponentMapper.java
@@ -1,71 +1,71 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities.mapper.relation.component;
 
 import java.util.Map;
 
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.envers.internal.entities.EntityInstantiator;
 import org.hibernate.envers.internal.tools.query.Parameters;
 
 /**
  * A mapper for reading and writing a property straight to/from maps. This mapper cannot be used with middle tables,
  * but only with "fake" bidirectional indexed relations.
  *
  * @author Adam Warski (adam at warski dot org)
  */
 public final class MiddleStraightComponentMapper implements MiddleComponentMapper {
 	private final String propertyName;
 
 	public MiddleStraightComponentMapper(String propertyName) {
 		this.propertyName = propertyName;
 	}
 
 	@Override
 	@SuppressWarnings({"unchecked"})
 	public Object mapToObjectFromFullMap(
 			EntityInstantiator entityInstantiator, Map<String, Object> data,
 			Object dataObject, Number revision) {
 		return data.get( propertyName );
 	}
 
 	@Override
 	public void mapToMapFromObject(
 			SessionImplementor session,
 			Map<String, Object> idData,
 			Map<String, Object> data,
 			Object obj) {
 		idData.put( propertyName, obj );
 	}
 
 	@Override
 	public void addMiddleEqualToQuery(
 			Parameters parameters,
 			String idPrefix1,
 			String prefix1,
 			String idPrefix2,
 			String prefix2) {
 		throw new UnsupportedOperationException( "Cannot use this mapper with a middle table!" );
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/lazy/initializor/ArrayCollectionInitializor.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/lazy/initializor/ArrayCollectionInitializor.java
index 37d1b8ccdb..4923f4250d 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/lazy/initializor/ArrayCollectionInitializor.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/lazy/initializor/ArrayCollectionInitializor.java
@@ -1,79 +1,79 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities.mapper.relation.lazy.initializor;
 
 import java.util.List;
 import java.util.Map;
 
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.envers.internal.entities.mapper.relation.MiddleComponentData;
 import org.hibernate.envers.internal.entities.mapper.relation.query.RelationQueryGenerator;
 import org.hibernate.envers.internal.reader.AuditReaderImplementor;
 
 /**
  * Initializes a map.
  *
  * @author Adam Warski (adam at warski dot org)
  */
 public class ArrayCollectionInitializor extends AbstractCollectionInitializor<Object[]> {
 	private final MiddleComponentData elementComponentData;
 	private final MiddleComponentData indexComponentData;
 
 	public ArrayCollectionInitializor(
 			AuditConfiguration verCfg,
 			AuditReaderImplementor versionsReader,
 			RelationQueryGenerator queryGenerator,
 			Object primaryKey, Number revision, boolean removed,
 			MiddleComponentData elementComponentData,
 			MiddleComponentData indexComponentData) {
 		super( verCfg, versionsReader, queryGenerator, primaryKey, revision, removed );
 
 		this.elementComponentData = elementComponentData;
 		this.indexComponentData = indexComponentData;
 	}
 
 	@Override
 	protected Object[] initializeCollection(int size) {
 		return new Object[size];
 	}
 
 	@Override
 	@SuppressWarnings({"unchecked"})
 	protected void addToCollection(Object[] collection, Object collectionRow) {
 		final Object elementData = ((List) collectionRow).get( elementComponentData.getComponentIndex() );
 		final Object element = elementComponentData.getComponentMapper().mapToObjectFromFullMap(
 				entityInstantiator,
 				(Map<String, Object>) elementData, null, revision
 		);
 
 		final Object indexData = ((List) collectionRow).get( indexComponentData.getComponentIndex() );
 		final Object indexObj = indexComponentData.getComponentMapper().mapToObjectFromFullMap(
 				entityInstantiator,
 				(Map<String, Object>) indexData, element, revision
 		);
 		final int index = ((Number) indexObj).intValue();
 
 		collection[index] = element;
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/AbstractRelationQueryGenerator.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/AbstractRelationQueryGenerator.java
index e30e4626f7..8275b00243 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/AbstractRelationQueryGenerator.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/AbstractRelationQueryGenerator.java
@@ -1,98 +1,98 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities.mapper.relation.query;
 
 import java.util.Collections;
 import java.util.Map;
 
 import org.hibernate.Query;
 import org.hibernate.envers.RevisionType;
 import org.hibernate.envers.configuration.internal.AuditEntitiesConfiguration;
 import org.hibernate.envers.internal.entities.mapper.id.QueryParameterData;
 import org.hibernate.envers.internal.entities.mapper.relation.MiddleIdData;
 import org.hibernate.envers.internal.reader.AuditReaderImplementor;
 import org.hibernate.envers.internal.tools.query.QueryBuilder;
 
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.DEL_REVISION_TYPE_PARAMETER;
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.REVISION_PARAMETER;
 
 /**
  * Base class for implementers of {@code RelationQueryGenerator} contract.
  *
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public abstract class AbstractRelationQueryGenerator implements RelationQueryGenerator {
 	protected final AuditEntitiesConfiguration verEntCfg;
 	protected final MiddleIdData referencingIdData;
 	protected final boolean revisionTypeInId;
 
 	protected AbstractRelationQueryGenerator(
 			AuditEntitiesConfiguration verEntCfg, MiddleIdData referencingIdData,
 			boolean revisionTypeInId) {
 		this.verEntCfg = verEntCfg;
 		this.referencingIdData = referencingIdData;
 		this.revisionTypeInId = revisionTypeInId;
 	}
 
 	/**
 	 * @return Query used to retrieve state of audited entity valid at a given revision.
 	 */
 	protected abstract String getQueryString();
 
 	/**
 	 * @return Query executed to retrieve state of audited entity valid at previous revision
 	 *         or removed during exactly specified revision number. Used only when traversing deleted
 	 *         entities graph.
 	 */
 	protected abstract String getQueryRemovedString();
 
 	@Override
 	public Query getQuery(AuditReaderImplementor versionsReader, Object primaryKey, Number revision, boolean removed) {
 		final Query query = versionsReader.getSession().createQuery( removed ? getQueryRemovedString() : getQueryString() );
 		query.setParameter( DEL_REVISION_TYPE_PARAMETER, RevisionType.DEL );
 		query.setParameter( REVISION_PARAMETER, revision );
 		for ( QueryParameterData paramData : referencingIdData.getPrefixedMapper().mapToQueryParametersFromId(
 				primaryKey
 		) ) {
 			paramData.setParameterValue( query );
 		}
 		return query;
 	}
 
 	protected String getRevisionTypePath() {
 		return revisionTypeInId
 				? verEntCfg.getOriginalIdPropName() + "." + verEntCfg.getRevisionTypePropName()
 				: verEntCfg.getRevisionTypePropName();
 	}
 
 	protected String queryToString(QueryBuilder query) {
 		return queryToString( query, Collections.<String, Object>emptyMap() );
 	}
 
 	protected String queryToString(QueryBuilder query, Map<String, Object> queryParamValues) {
 		final StringBuilder sb = new StringBuilder();
 		query.build( sb, queryParamValues );
 		return sb.toString();
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/QueryConstants.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/QueryConstants.java
index 086bfc2e1f..9e83ca6808 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/QueryConstants.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/QueryConstants.java
@@ -1,43 +1,46 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities.mapper.relation.query;
 
 /**
  * Constants used in JPQL queries.
  *
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
-public class QueryConstants {
+public final class QueryConstants {
+	private QueryConstants() {
+	}
+
 	public static final String REFERENCED_ENTITY_ALIAS = "e__";
 	public static final String REFERENCED_ENTITY_ALIAS_DEF_AUD_STR = "e2__";
 
 	public static final String INDEX_ENTITY_ALIAS = "f__";
 	public static final String INDEX_ENTITY_ALIAS_DEF_AUD_STR = "f2__";
 
 	public static final String MIDDLE_ENTITY_ALIAS = "ee__";
 	public static final String MIDDLE_ENTITY_ALIAS_DEF_AUD_STR = "ee2__";
 
 	public static final String REVISION_PARAMETER = "revision";
 	public static final String DEL_REVISION_TYPE_PARAMETER = "delrevisiontype";
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/ThreeEntityQueryGenerator.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/ThreeEntityQueryGenerator.java
index 5477eaf9e7..74bb27fb88 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/ThreeEntityQueryGenerator.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/ThreeEntityQueryGenerator.java
@@ -1,287 +1,287 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities.mapper.relation.query;
 
 import org.hibernate.envers.configuration.internal.AuditEntitiesConfiguration;
 import org.hibernate.envers.configuration.internal.GlobalConfiguration;
 import org.hibernate.envers.internal.entities.mapper.relation.MiddleComponentData;
 import org.hibernate.envers.internal.entities.mapper.relation.MiddleIdData;
 import org.hibernate.envers.internal.tools.query.Parameters;
 import org.hibernate.envers.internal.tools.query.QueryBuilder;
 import org.hibernate.envers.strategy.AuditStrategy;
 
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.DEL_REVISION_TYPE_PARAMETER;
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.INDEX_ENTITY_ALIAS;
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.INDEX_ENTITY_ALIAS_DEF_AUD_STR;
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.MIDDLE_ENTITY_ALIAS;
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.REFERENCED_ENTITY_ALIAS;
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.REFERENCED_ENTITY_ALIAS_DEF_AUD_STR;
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.REVISION_PARAMETER;
 
 /**
  * Selects data from a relation middle-table and a two related versions entity.
  *
  * @author Adam Warski (adam at warski dot org)
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public final class ThreeEntityQueryGenerator extends AbstractRelationQueryGenerator {
 	private final String queryString;
 	private final String queryRemovedString;
 
 	public ThreeEntityQueryGenerator(
 			GlobalConfiguration globalCfg, AuditEntitiesConfiguration verEntCfg,
 			AuditStrategy auditStrategy, String versionsMiddleEntityName,
 			MiddleIdData referencingIdData, MiddleIdData referencedIdData,
 			MiddleIdData indexIdData, boolean revisionTypeInId,
 			MiddleComponentData... componentData) {
 		super( verEntCfg, referencingIdData, revisionTypeInId );
 
 		/*
 		 * The valid query that we need to create:
 		 *   SELECT new list(ee, e, f) FROM versionsReferencedEntity e, versionsIndexEntity f, middleEntity ee
 		 *   WHERE
 		 * (entities referenced by the middle table; id_ref_ed = id of the referenced entity)
 		 *     ee.id_ref_ed = e.id_ref_ed AND
 		 * (entities referenced by the middle table; id_ref_ind = id of the index entity)
 		 *     ee.id_ref_ind = f.id_ref_ind AND
 		 * (only entities referenced by the association; id_ref_ing = id of the referencing entity)
 		 *     ee.id_ref_ing = :id_ref_ing AND
 		 * (selecting e entities at revision :revision)
 		 *   --> for DefaultAuditStrategy:
 		 *     e.revision = (SELECT max(e2.revision) FROM versionsReferencedEntity e2
 		 *       WHERE e2.revision <= :revision AND e2.id = e.id)
 		 *
 		 *   --> for ValidityAuditStrategy:
 		 *     e.revision <= :revision and (e.endRevision > :revision or e.endRevision is null)
 		 *
 		 *     AND
 		 *
 		 * (selecting f entities at revision :revision)
 		 *   --> for DefaultAuditStrategy:
 		 *     f.revision = (SELECT max(f2.revision) FROM versionsIndexEntity f2
 		 *       WHERE f2.revision <= :revision AND f2.id_ref_ed = f.id_ref_ed)
 		 *
 		 *   --> for ValidityAuditStrategy:
 		 *     f.revision <= :revision and (f.endRevision > :revision or f.endRevision is null)
 		 *
 		 *     AND
 		 *
 		 * (the association at revision :revision)
 		 *   --> for DefaultAuditStrategy:
 		 *     ee.revision = (SELECT max(ee2.revision) FROM middleEntity ee2
 		 *       WHERE ee2.revision <= :revision AND ee2.originalId.* = ee.originalId.*)
 		 *
 		 *   --> for ValidityAuditStrategy:
 		 *     ee.revision <= :revision and (ee.endRevision > :revision or ee.endRevision is null)
 		 *     and ( strtestent1_.REVEND>? or strtestent1_.REVEND is null )
 		 *     and ( strtestent1_.REVEND>? or strtestent1_.REVEND is null )
 		 *     and ( ternarymap0_.REVEND>? or ternarymap0_.REVEND is null )
 		 *
 		 * (only non-deleted entities and associations)
 		 *     ee.revision_type != DEL AND
 		 *     e.revision_type != DEL AND
 		 *     f.revision_type != DEL
 		 */
 		final QueryBuilder commonPart = commonQueryPart(
 				referencedIdData,
 				indexIdData,
 				versionsMiddleEntityName,
 				verEntCfg.getOriginalIdPropName()
 		);
 		final QueryBuilder validQuery = commonPart.deepCopy();
 		final QueryBuilder removedQuery = commonPart.deepCopy();
 		createValidDataRestrictions(
 				globalCfg, auditStrategy, referencedIdData, versionsMiddleEntityName, validQuery,
 				validQuery.getRootParameters(), true, componentData
 		);
 		createValidAndRemovedDataRestrictions(
 				globalCfg, auditStrategy, referencedIdData, versionsMiddleEntityName, removedQuery, componentData
 		);
 
 		queryString = queryToString( validQuery );
 		queryRemovedString = queryToString( removedQuery );
 	}
 
 	/**
 	 * Compute common part for both queries.
 	 */
 	private QueryBuilder commonQueryPart(
 			MiddleIdData referencedIdData, MiddleIdData indexIdData,
 			String versionsMiddleEntityName, String originalIdPropertyName) {
 		final String eeOriginalIdPropertyPath = MIDDLE_ENTITY_ALIAS + "." + originalIdPropertyName;
 		// SELECT new list(ee) FROM middleEntity ee
 		final QueryBuilder qb = new QueryBuilder( versionsMiddleEntityName, MIDDLE_ENTITY_ALIAS );
 		qb.addFrom( referencedIdData.getAuditEntityName(), REFERENCED_ENTITY_ALIAS );
 		qb.addFrom( indexIdData.getAuditEntityName(), INDEX_ENTITY_ALIAS );
 		qb.addProjection(
 				"new list", MIDDLE_ENTITY_ALIAS + ", " + REFERENCED_ENTITY_ALIAS + ", " + INDEX_ENTITY_ALIAS,
 				false, false
 		);
 		// WHERE
 		final Parameters rootParameters = qb.getRootParameters();
 		// ee.id_ref_ed = e.id_ref_ed
 		referencedIdData.getPrefixedMapper().addIdsEqualToQuery(
 				rootParameters, eeOriginalIdPropertyPath, referencedIdData.getOriginalMapper(),
 				REFERENCED_ENTITY_ALIAS + "." + originalIdPropertyName
 		);
 		// ee.id_ref_ind = f.id_ref_ind
 		indexIdData.getPrefixedMapper().addIdsEqualToQuery(
 				rootParameters, eeOriginalIdPropertyPath, indexIdData.getOriginalMapper(),
 				INDEX_ENTITY_ALIAS + "." + originalIdPropertyName
 		);
 		// ee.originalId.id_ref_ing = :id_ref_ing
 		referencingIdData.getPrefixedMapper().addNamedIdEqualsToQuery( rootParameters, originalIdPropertyName, true );
 		return qb;
 	}
 
 	/**
 	 * Creates query restrictions used to retrieve only actual data.
 	 */
 	private void createValidDataRestrictions(
 			GlobalConfiguration globalCfg, AuditStrategy auditStrategy,
 			MiddleIdData referencedIdData, String versionsMiddleEntityName, QueryBuilder qb,
 			Parameters rootParameters, boolean inclusive, MiddleComponentData... componentData) {
 		final String revisionPropertyPath = verEntCfg.getRevisionNumberPath();
 		final String originalIdPropertyName = verEntCfg.getOriginalIdPropName();
 		final String eeOriginalIdPropertyPath = MIDDLE_ENTITY_ALIAS + "." + originalIdPropertyName;
 		final String revisionTypePropName = getRevisionTypePath();
 		// (selecting e entities at revision :revision)
 		// --> based on auditStrategy (see above)
 		auditStrategy.addEntityAtRevisionRestriction(
 				globalCfg,
 				qb,
 				rootParameters,
 				REFERENCED_ENTITY_ALIAS + "." + revisionPropertyPath,
 				REFERENCED_ENTITY_ALIAS + "." + verEntCfg.getRevisionEndFieldName(),
 				false,
 				referencedIdData,
 				revisionPropertyPath,
 				originalIdPropertyName,
 				REFERENCED_ENTITY_ALIAS,
 				REFERENCED_ENTITY_ALIAS_DEF_AUD_STR,
 				true
 		);
 		// (selecting f entities at revision :revision)
 		// --> based on auditStrategy (see above)
 		auditStrategy.addEntityAtRevisionRestriction(
 				globalCfg,
 				qb,
 				rootParameters,
 				INDEX_ENTITY_ALIAS + "." + revisionPropertyPath,
 				INDEX_ENTITY_ALIAS + "." + verEntCfg.getRevisionEndFieldName(),
 				false,
 				referencedIdData,
 				revisionPropertyPath,
 				originalIdPropertyName,
 				INDEX_ENTITY_ALIAS,
 				INDEX_ENTITY_ALIAS_DEF_AUD_STR,
 				true
 		);
 		// (with ee association at revision :revision)
 		// --> based on auditStrategy (see above)
 		auditStrategy.addAssociationAtRevisionRestriction(
 				qb, rootParameters, revisionPropertyPath, verEntCfg.getRevisionEndFieldName(), true,
 				referencingIdData, versionsMiddleEntityName, eeOriginalIdPropertyPath, revisionPropertyPath,
 				originalIdPropertyName, MIDDLE_ENTITY_ALIAS, inclusive, componentData
 		);
 		// ee.revision_type != DEL
 		rootParameters.addWhereWithNamedParam( revisionTypePropName, "!=", DEL_REVISION_TYPE_PARAMETER );
 		// e.revision_type != DEL
 		rootParameters.addWhereWithNamedParam(
 				REFERENCED_ENTITY_ALIAS + "." + revisionTypePropName,
 				false,
 				"!=",
 				DEL_REVISION_TYPE_PARAMETER
 		);
 		// f.revision_type != DEL
 		rootParameters.addWhereWithNamedParam(
 				INDEX_ENTITY_ALIAS + "." + revisionTypePropName,
 				false,
 				"!=",
 				DEL_REVISION_TYPE_PARAMETER
 		);
 	}
 
 	/**
 	 * Create query restrictions used to retrieve actual data and deletions that took place at exactly given revision.
 	 */
 	private void createValidAndRemovedDataRestrictions(
 			GlobalConfiguration globalCfg, AuditStrategy auditStrategy,
 			MiddleIdData referencedIdData, String versionsMiddleEntityName,
 			QueryBuilder remQb, MiddleComponentData... componentData) {
 		final Parameters disjoint = remQb.getRootParameters().addSubParameters( "or" );
 		// Restrictions to match all valid rows.
 		final Parameters valid = disjoint.addSubParameters( "and" );
 		// Restrictions to match all rows deleted at exactly given revision.
 		final Parameters removed = disjoint.addSubParameters( "and" );
 		final String revisionPropertyPath = verEntCfg.getRevisionNumberPath();
 		final String revisionTypePropName = getRevisionTypePath();
 		// Excluding current revision, because we need to match data valid at the previous one.
 		createValidDataRestrictions(
 				globalCfg, auditStrategy, referencedIdData, versionsMiddleEntityName, remQb, valid, false, componentData
 		);
 		// ee.revision = :revision
 		removed.addWhereWithNamedParam( revisionPropertyPath, "=", REVISION_PARAMETER );
 		// e.revision = :revision
 		removed.addWhereWithNamedParam(
 				REFERENCED_ENTITY_ALIAS + "." + revisionPropertyPath,
 				false,
 				"=",
 				REVISION_PARAMETER
 		);
 		// f.revision = :revision
 		removed.addWhereWithNamedParam(
 				INDEX_ENTITY_ALIAS + "." + revisionPropertyPath,
 				false,
 				"=",
 				REVISION_PARAMETER
 		);
 		// ee.revision_type = DEL
 		removed.addWhereWithNamedParam( revisionTypePropName, "=", DEL_REVISION_TYPE_PARAMETER );
 		// e.revision_type = DEL
 		removed.addWhereWithNamedParam(
 				REFERENCED_ENTITY_ALIAS + "." + revisionTypePropName,
 				false,
 				"=",
 				DEL_REVISION_TYPE_PARAMETER
 		);
 		// f.revision_type = DEL
 		removed.addWhereWithNamedParam(
 				INDEX_ENTITY_ALIAS + "." + revisionTypePropName,
 				false,
 				"=",
 				DEL_REVISION_TYPE_PARAMETER
 		);
 	}
 
 	@Override
 	protected String getQueryString() {
 		return queryString;
 	}
 
 	@Override
 	protected String getQueryRemovedString() {
 		return queryRemovedString;
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/TwoEntityOneAuditedQueryGenerator.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/TwoEntityOneAuditedQueryGenerator.java
index 065239c0cd..cfbf1dcddf 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/TwoEntityOneAuditedQueryGenerator.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/TwoEntityOneAuditedQueryGenerator.java
@@ -1,162 +1,162 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities.mapper.relation.query;
 
 import org.hibernate.envers.configuration.internal.AuditEntitiesConfiguration;
 import org.hibernate.envers.internal.entities.mapper.relation.MiddleComponentData;
 import org.hibernate.envers.internal.entities.mapper.relation.MiddleIdData;
 import org.hibernate.envers.internal.tools.query.Parameters;
 import org.hibernate.envers.internal.tools.query.QueryBuilder;
 import org.hibernate.envers.strategy.AuditStrategy;
 
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.DEL_REVISION_TYPE_PARAMETER;
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.MIDDLE_ENTITY_ALIAS;
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.REFERENCED_ENTITY_ALIAS;
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.REVISION_PARAMETER;
 
 /**
  * Selects data from a relation middle-table and a related non-audited entity.
  *
  * @author Adam Warski (adam at warski dot org)
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public final class TwoEntityOneAuditedQueryGenerator extends AbstractRelationQueryGenerator {
 	private final String queryString;
 	private final String queryRemovedString;
 
 	public TwoEntityOneAuditedQueryGenerator(
 			AuditEntitiesConfiguration verEntCfg, AuditStrategy auditStrategy,
 			String versionsMiddleEntityName, MiddleIdData referencingIdData,
 			MiddleIdData referencedIdData, boolean revisionTypeInId,
 			MiddleComponentData... componentData) {
 		super( verEntCfg, referencingIdData, revisionTypeInId );
 
 		/*
 		 * The valid query that we need to create:
 		 *   SELECT new list(ee, e) FROM referencedEntity e, middleEntity ee
 		 *   WHERE
 		 * (entities referenced by the middle table; id_ref_ed = id of the referenced entity)
 		 *     ee.id_ref_ed = e.id_ref_ed AND
 		 * (only entities referenced by the association; id_ref_ing = id of the referencing entity)
 		 *     ee.id_ref_ing = :id_ref_ing AND
 		 *
 		 * (the association at revision :revision)
 		 *   --> for DefaultAuditStrategy:
 		 *     ee.revision = (SELECT max(ee2.revision) FROM middleEntity ee2
 		 *       WHERE ee2.revision <= :revision AND ee2.originalId.* = ee.originalId.*)
 		 *
 		 *   --> for ValidityAuditStrategy:
 		 *     ee.revision <= :revision and (ee.endRevision > :revision or ee.endRevision is null)
 		 *
 		 *     AND
 		 *
 		 * (only non-deleted entities and associations)
 		 *     ee.revision_type != DEL
 		 */
 		final QueryBuilder commonPart = commonQueryPart(
 				referencedIdData,
 				versionsMiddleEntityName,
 				verEntCfg.getOriginalIdPropName()
 		);
 		final QueryBuilder validQuery = commonPart.deepCopy();
 		final QueryBuilder removedQuery = commonPart.deepCopy();
 		createValidDataRestrictions(
 				auditStrategy, versionsMiddleEntityName, validQuery, validQuery.getRootParameters(), componentData
 		);
 		createValidAndRemovedDataRestrictions( auditStrategy, versionsMiddleEntityName, removedQuery, componentData );
 
 		queryString = queryToString( validQuery );
 		queryRemovedString = queryToString( removedQuery );
 	}
 
 	/**
 	 * Compute common part for both queries.
 	 */
 	private QueryBuilder commonQueryPart(
 			MiddleIdData referencedIdData, String versionsMiddleEntityName,
 			String originalIdPropertyName) {
 		final String eeOriginalIdPropertyPath = MIDDLE_ENTITY_ALIAS + "." + originalIdPropertyName;
 		// SELECT new list(ee) FROM middleEntity ee
 		final QueryBuilder qb = new QueryBuilder( versionsMiddleEntityName, MIDDLE_ENTITY_ALIAS );
 		qb.addFrom( referencedIdData.getEntityName(), REFERENCED_ENTITY_ALIAS );
 		qb.addProjection( "new list", MIDDLE_ENTITY_ALIAS + ", " + REFERENCED_ENTITY_ALIAS, false, false );
 		// WHERE
 		final Parameters rootParameters = qb.getRootParameters();
 		// ee.id_ref_ed = e.id_ref_ed
 		referencedIdData.getPrefixedMapper().addIdsEqualToQuery(
 				rootParameters, eeOriginalIdPropertyPath, referencedIdData.getOriginalMapper(), REFERENCED_ENTITY_ALIAS
 		);
 		// ee.originalId.id_ref_ing = :id_ref_ing
 		referencingIdData.getPrefixedMapper().addNamedIdEqualsToQuery( rootParameters, originalIdPropertyName, true );
 		return qb;
 	}
 
 	/**
 	 * Creates query restrictions used to retrieve only actual data.
 	 */
 	private void createValidDataRestrictions(
 			AuditStrategy auditStrategy, String versionsMiddleEntityName, QueryBuilder qb,
 			Parameters rootParameters, MiddleComponentData... componentData) {
 		final String revisionPropertyPath = verEntCfg.getRevisionNumberPath();
 		final String originalIdPropertyName = verEntCfg.getOriginalIdPropName();
 		final String eeOriginalIdPropertyPath = MIDDLE_ENTITY_ALIAS + "." + originalIdPropertyName;
 		// (with ee association at revision :revision)
 		// --> based on auditStrategy (see above)
 		auditStrategy.addAssociationAtRevisionRestriction(
 				qb, rootParameters, revisionPropertyPath, verEntCfg.getRevisionEndFieldName(), true,
 				referencingIdData, versionsMiddleEntityName, eeOriginalIdPropertyPath, revisionPropertyPath,
 				originalIdPropertyName, MIDDLE_ENTITY_ALIAS, true, componentData
 		);
 		// ee.revision_type != DEL
 		rootParameters.addWhereWithNamedParam( getRevisionTypePath(), "!=", DEL_REVISION_TYPE_PARAMETER );
 	}
 
 	/**
 	 * Create query restrictions used to retrieve actual data and deletions that took place at exactly given revision.
 	 */
 	private void createValidAndRemovedDataRestrictions(
 			AuditStrategy auditStrategy, String versionsMiddleEntityName,
 			QueryBuilder remQb, MiddleComponentData... componentData) {
 		final Parameters disjoint = remQb.getRootParameters().addSubParameters( "or" );
 		// Restrictions to match all valid rows.
 		final Parameters valid = disjoint.addSubParameters( "and" );
 		// Restrictions to match all rows deleted at exactly given revision.
 		final Parameters removed = disjoint.addSubParameters( "and" );
 		createValidDataRestrictions( auditStrategy, versionsMiddleEntityName, remQb, valid, componentData );
 		// ee.revision = :revision
 		removed.addWhereWithNamedParam( verEntCfg.getRevisionNumberPath(), "=", REVISION_PARAMETER );
 		// ee.revision_type = DEL
 		removed.addWhereWithNamedParam( getRevisionTypePath(), "=", DEL_REVISION_TYPE_PARAMETER );
 	}
 
 	@Override
 	protected String getQueryString() {
 		return queryString;
 	}
 
 	@Override
 	protected String getQueryRemovedString() {
 		return queryRemovedString;
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/TwoEntityQueryGenerator.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/TwoEntityQueryGenerator.java
index 00d0d9fdf1..15cba29c31 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/TwoEntityQueryGenerator.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/entities/mapper/relation/query/TwoEntityQueryGenerator.java
@@ -1,230 +1,230 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.entities.mapper.relation.query;
 
 import org.hibernate.envers.configuration.internal.AuditEntitiesConfiguration;
 import org.hibernate.envers.configuration.internal.GlobalConfiguration;
 import org.hibernate.envers.internal.entities.mapper.relation.MiddleComponentData;
 import org.hibernate.envers.internal.entities.mapper.relation.MiddleIdData;
 import org.hibernate.envers.internal.tools.query.Parameters;
 import org.hibernate.envers.internal.tools.query.QueryBuilder;
 import org.hibernate.envers.strategy.AuditStrategy;
 
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.DEL_REVISION_TYPE_PARAMETER;
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.MIDDLE_ENTITY_ALIAS;
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.REFERENCED_ENTITY_ALIAS;
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.REFERENCED_ENTITY_ALIAS_DEF_AUD_STR;
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.REVISION_PARAMETER;
 
 /**
  * Selects data from a relation middle-table and a related versions entity.
  *
  * @author Adam Warski (adam at warski dot org)
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public final class TwoEntityQueryGenerator extends AbstractRelationQueryGenerator {
 	private final String queryString;
 	private final String queryRemovedString;
 
 	public TwoEntityQueryGenerator(
 			GlobalConfiguration globalCfg, AuditEntitiesConfiguration verEntCfg,
 			AuditStrategy auditStrategy, String versionsMiddleEntityName,
 			MiddleIdData referencingIdData, MiddleIdData referencedIdData,
 			boolean revisionTypeInId, MiddleComponentData... componentData) {
 		super( verEntCfg, referencingIdData, revisionTypeInId );
 
 		/*
 		 * The valid query that we need to create:
 		 *   SELECT new list(ee, e) FROM versionsReferencedEntity e, middleEntity ee
 		 *   WHERE
 		 * (entities referenced by the middle table; id_ref_ed = id of the referenced entity)
 		 *     ee.id_ref_ed = e.id_ref_ed AND
 		 * (only entities referenced by the association; id_ref_ing = id of the referencing entity)
 		 *     ee.id_ref_ing = :id_ref_ing AND
 		 *
 		 * (selecting e entities at revision :revision)
 		 *   --> for DefaultAuditStrategy:
 		 *     e.revision = (SELECT max(e2.revision) FROM versionsReferencedEntity e2
 		 *       WHERE e2.revision <= :revision AND e2.id = e.id)
 		 *
 		 *   --> for ValidityAuditStrategy:
 		 *     e.revision <= :revision and (e.endRevision > :revision or e.endRevision is null)
 		 *
 		 *     AND
 		 *
 		 * (the association at revision :revision)
 		 *   --> for DefaultAuditStrategy:
 		 *     ee.revision = (SELECT max(ee2.revision) FROM middleEntity ee2
 		 *       WHERE ee2.revision <= :revision AND ee2.originalId.* = ee.originalId.*)
 		 *
 		 *   --> for ValidityAuditStrategy:
 		 *     ee.revision <= :revision and (ee.endRevision > :revision or ee.endRevision is null)
 		 *
 		 * (only non-deleted entities and associations)
 		 *     ee.revision_type != DEL AND
 		 *     e.revision_type != DEL
 		 */
 		final QueryBuilder commonPart = commonQueryPart(
 				referencedIdData,
 				versionsMiddleEntityName,
 				verEntCfg.getOriginalIdPropName()
 		);
 		final QueryBuilder validQuery = commonPart.deepCopy();
 		final QueryBuilder removedQuery = commonPart.deepCopy();
 		createValidDataRestrictions(
 				globalCfg, auditStrategy, referencedIdData, versionsMiddleEntityName, validQuery,
 				validQuery.getRootParameters(), true, componentData
 		);
 		createValidAndRemovedDataRestrictions(
 				globalCfg, auditStrategy, referencedIdData, versionsMiddleEntityName, removedQuery, componentData
 		);
 
 		queryString = queryToString( validQuery );
 		queryRemovedString = queryToString( removedQuery );
 	}
 
 	/**
 	 * Compute common part for both queries.
 	 */
 	private QueryBuilder commonQueryPart(
 			MiddleIdData referencedIdData, String versionsMiddleEntityName,
 			String originalIdPropertyName) {
 		final String eeOriginalIdPropertyPath = MIDDLE_ENTITY_ALIAS + "." + originalIdPropertyName;
 		// SELECT new list(ee) FROM middleEntity ee
 		QueryBuilder qb = new QueryBuilder( versionsMiddleEntityName, MIDDLE_ENTITY_ALIAS );
 		qb.addFrom( referencedIdData.getAuditEntityName(), REFERENCED_ENTITY_ALIAS );
 		qb.addProjection( "new list", MIDDLE_ENTITY_ALIAS + ", " + REFERENCED_ENTITY_ALIAS, false, false );
 		// WHERE
 		final Parameters rootParameters = qb.getRootParameters();
 		// ee.id_ref_ed = e.id_ref_ed
 		referencedIdData.getPrefixedMapper().addIdsEqualToQuery(
 				rootParameters, eeOriginalIdPropertyPath, referencedIdData.getOriginalMapper(),
 				REFERENCED_ENTITY_ALIAS + "." + originalIdPropertyName
 		);
 		// ee.originalId.id_ref_ing = :id_ref_ing
 		referencingIdData.getPrefixedMapper().addNamedIdEqualsToQuery( rootParameters, originalIdPropertyName, true );
 		return qb;
 	}
 
 	/**
 	 * Creates query restrictions used to retrieve only actual data.
 	 */
 	private void createValidDataRestrictions(
 			GlobalConfiguration globalCfg, AuditStrategy auditStrategy, MiddleIdData referencedIdData,
 			String versionsMiddleEntityName, QueryBuilder qb, Parameters rootParameters,
 			boolean inclusive, MiddleComponentData... componentData) {
 		final String revisionPropertyPath = verEntCfg.getRevisionNumberPath();
 		final String originalIdPropertyName = verEntCfg.getOriginalIdPropName();
 		final String eeOriginalIdPropertyPath = MIDDLE_ENTITY_ALIAS + "." + originalIdPropertyName;
 		final String revisionTypePropName = getRevisionTypePath();
 		// (selecting e entities at revision :revision)
 		// --> based on auditStrategy (see above)
 		auditStrategy.addEntityAtRevisionRestriction(
 				globalCfg,
 				qb,
 				rootParameters,
 				REFERENCED_ENTITY_ALIAS + "." + revisionPropertyPath,
 				REFERENCED_ENTITY_ALIAS + "." + verEntCfg.getRevisionEndFieldName(),
 				false,
 				referencedIdData,
 				revisionPropertyPath,
 				originalIdPropertyName,
 				REFERENCED_ENTITY_ALIAS,
 				REFERENCED_ENTITY_ALIAS_DEF_AUD_STR,
 				true
 		);
 		// (with ee association at revision :revision)
 		// --> based on auditStrategy (see above)
 		auditStrategy.addAssociationAtRevisionRestriction(
 				qb, rootParameters, revisionPropertyPath,
 				verEntCfg.getRevisionEndFieldName(), true, referencingIdData, versionsMiddleEntityName,
 				eeOriginalIdPropertyPath, revisionPropertyPath, originalIdPropertyName, MIDDLE_ENTITY_ALIAS,
 				inclusive, componentData
 		);
 		// ee.revision_type != DEL
 		rootParameters.addWhereWithNamedParam( revisionTypePropName, "!=", DEL_REVISION_TYPE_PARAMETER );
 		// e.revision_type != DEL
 		rootParameters.addWhereWithNamedParam(
 				REFERENCED_ENTITY_ALIAS + "." + revisionTypePropName,
 				false,
 				"!=",
 				DEL_REVISION_TYPE_PARAMETER
 		);
 	}
 
 	/**
 	 * Create query restrictions used to retrieve actual data and deletions that took place at exactly given revision.
 	 */
 	private void createValidAndRemovedDataRestrictions(
 			GlobalConfiguration globalCfg, AuditStrategy auditStrategy,
 			MiddleIdData referencedIdData, String versionsMiddleEntityName,
 			QueryBuilder remQb, MiddleComponentData... componentData) {
 		final Parameters disjoint = remQb.getRootParameters().addSubParameters( "or" );
 		// Restrictions to match all valid rows.
 		final Parameters valid = disjoint.addSubParameters( "and" );
 		// Restrictions to match all rows deleted at exactly given revision.
 		final Parameters removed = disjoint.addSubParameters( "and" );
 		final String revisionPropertyPath = verEntCfg.getRevisionNumberPath();
 		final String revisionTypePropName = getRevisionTypePath();
 		// Excluding current revision, because we need to match data valid at the previous one.
 		createValidDataRestrictions(
 				globalCfg,
 				auditStrategy,
 				referencedIdData,
 				versionsMiddleEntityName,
 				remQb,
 				valid,
 				false,
 				componentData
 		);
 		// ee.revision = :revision
 		removed.addWhereWithNamedParam( revisionPropertyPath, "=", REVISION_PARAMETER );
 		// e.revision = :revision
 		removed.addWhereWithNamedParam(
 				REFERENCED_ENTITY_ALIAS + "." + revisionPropertyPath,
 				false,
 				"=",
 				REVISION_PARAMETER
 		);
 		// ee.revision_type = DEL
 		removed.addWhereWithNamedParam( revisionTypePropName, "=", DEL_REVISION_TYPE_PARAMETER );
 		// e.revision_type = DEL
 		removed.addWhereWithNamedParam(
 				REFERENCED_ENTITY_ALIAS + "." + revisionTypePropName,
 				false,
 				"=",
 				DEL_REVISION_TYPE_PARAMETER
 		);
 	}
 
 	@Override
 	protected String getQueryString() {
 		return queryString;
 	}
 
 	@Override
 	protected String getQueryRemovedString() {
 		return queryRemovedString;
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/reader/AuditReaderImpl.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/reader/AuditReaderImpl.java
index 5ae1cc4e4f..77d35c036b 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/reader/AuditReaderImpl.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/reader/AuditReaderImpl.java
@@ -1,348 +1,348 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.reader;
 
 import javax.persistence.NoResultException;
 import java.util.Date;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.hibernate.Criteria;
 import org.hibernate.HibernateException;
 import org.hibernate.NonUniqueResultException;
 import org.hibernate.Session;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.envers.CrossTypeRevisionChangesReader;
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.envers.exception.AuditException;
 import org.hibernate.envers.exception.NotAuditedException;
 import org.hibernate.envers.exception.RevisionDoesNotExistException;
 import org.hibernate.envers.internal.synchronization.AuditProcess;
 import org.hibernate.envers.query.AuditEntity;
 import org.hibernate.envers.query.AuditQueryCreator;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.proxy.HibernateProxy;
 
 import static org.hibernate.envers.internal.tools.ArgumentsTools.checkNotNull;
 import static org.hibernate.envers.internal.tools.ArgumentsTools.checkPositive;
 import static org.hibernate.envers.internal.tools.EntityTools.getTargetClassIfProxied;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  * @author Hern&aacute;n Chanfreau
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public class AuditReaderImpl implements AuditReaderImplementor {
 	private final AuditConfiguration verCfg;
 	private final SessionImplementor sessionImplementor;
 	private final Session session;
 	private final FirstLevelCache firstLevelCache;
 	private final CrossTypeRevisionChangesReader crossTypeRevisionChangesReader;
 
 	public AuditReaderImpl(
 			AuditConfiguration verCfg, Session session,
 			SessionImplementor sessionImplementor) {
 		this.verCfg = verCfg;
 		this.sessionImplementor = sessionImplementor;
 		this.session = session;
 
 		firstLevelCache = new FirstLevelCache();
 		crossTypeRevisionChangesReader = new CrossTypeRevisionChangesReaderImpl( this, verCfg );
 	}
 
 	private void checkSession() {
 		if ( !session.isOpen() ) {
 			throw new IllegalStateException( "The associated entity manager is closed!" );
 		}
 	}
 
 	@Override
 	public SessionImplementor getSessionImplementor() {
 		return sessionImplementor;
 	}
 
 	@Override
 	public Session getSession() {
 		return session;
 	}
 
 	@Override
 	public FirstLevelCache getFirstLevelCache() {
 		return firstLevelCache;
 	}
 
 	@Override
 	public <T> T find(Class<T> cls, Object primaryKey, Number revision) throws
 			IllegalArgumentException, NotAuditedException, IllegalStateException {
 		cls = getTargetClassIfProxied( cls );
 		return this.find( cls, cls.getName(), primaryKey, revision );
 	}
 
 	@Override
 	public <T> T find(Class<T> cls, String entityName, Object primaryKey, Number revision)
 			throws IllegalArgumentException, NotAuditedException, IllegalStateException {
 		return this.find( cls, entityName, primaryKey, revision, false );
 	}
 
 	@Override
 	@SuppressWarnings({"unchecked"})
 	public <T> T find(
 			Class<T> cls,
 			String entityName,
 			Object primaryKey,
 			Number revision,
 			boolean includeDeletions) throws IllegalArgumentException, NotAuditedException, IllegalStateException {
 		cls = getTargetClassIfProxied( cls );
 		checkNotNull( cls, "Entity class" );
 		checkNotNull( entityName, "Entity name" );
 		checkNotNull( primaryKey, "Primary key" );
 		checkNotNull( revision, "Entity revision" );
 		checkPositive( revision, "Entity revision" );
 		checkSession();
 
 		if ( !verCfg.getEntCfg().isVersioned( entityName ) ) {
 			throw new NotAuditedException( entityName, entityName + " is not versioned!" );
 		}
 
 		if ( firstLevelCache.contains( entityName, revision, primaryKey ) ) {
 			return (T) firstLevelCache.get( entityName, revision, primaryKey );
 		}
 
 		Object result;
 		try {
 			// The result is put into the cache by the entity instantiator called from the query
 			result = createQuery().forEntitiesAtRevision( cls, entityName, revision, includeDeletions )
 					.add( AuditEntity.id().eq( primaryKey ) ).getSingleResult();
 		}
 		catch (NoResultException e) {
 			result = null;
 		}
 		catch (NonUniqueResultException e) {
 			throw new AuditException( e );
 		}
 
 		return (T) result;
 	}
 
 	@Override
 	public List<Number> getRevisions(Class<?> cls, Object primaryKey)
 			throws IllegalArgumentException, NotAuditedException, IllegalStateException {
 		cls = getTargetClassIfProxied( cls );
 		return this.getRevisions( cls, cls.getName(), primaryKey );
 	}
 
 	@Override
 	@SuppressWarnings({"unchecked"})
 	public List<Number> getRevisions(Class<?> cls, String entityName, Object primaryKey)
 			throws IllegalArgumentException, NotAuditedException, IllegalStateException {
 		// todo: if a class is not versioned from the beginning, there's a missing ADD rev - what then?
 		cls = getTargetClassIfProxied( cls );
 		checkNotNull( cls, "Entity class" );
 		checkNotNull( entityName, "Entity name" );
 		checkNotNull( primaryKey, "Primary key" );
 		checkSession();
 
 		if ( !verCfg.getEntCfg().isVersioned( entityName ) ) {
 			throw new NotAuditedException( entityName, entityName + " is not versioned!" );
 		}
 
 		return createQuery().forRevisionsOfEntity( cls, entityName, false, true )
 				.addProjection( AuditEntity.revisionNumber() )
 				.addOrder( AuditEntity.revisionNumber().asc() )
 				.add( AuditEntity.id().eq( primaryKey ) )
 				.getResultList();
 	}
 
 	@Override
 	public Date getRevisionDate(Number revision)
 			throws IllegalArgumentException, RevisionDoesNotExistException, IllegalStateException {
 		checkNotNull( revision, "Entity revision" );
 		checkPositive( revision, "Entity revision" );
 		checkSession();
 
 		final Criteria query = verCfg.getRevisionInfoQueryCreator().getRevisionDateQuery( session, revision );
 
 		try {
 			final Object timestampObject = query.uniqueResult();
 			if ( timestampObject == null ) {
 				throw new RevisionDoesNotExistException( revision );
 			}
 
 			// The timestamp object is either a date or a long
 			return timestampObject instanceof Date ? (Date) timestampObject : new Date( (Long) timestampObject );
 		}
 		catch (NonUniqueResultException e) {
 			throw new AuditException( e );
 		}
 	}
 
 	@Override
 	public Number getRevisionNumberForDate(Date date) {
 		checkNotNull( date, "Date of revision" );
 		checkSession();
 
 		final Criteria query = verCfg.getRevisionInfoQueryCreator().getRevisionNumberForDateQuery( session, date );
 
 		try {
 			final Number res = (Number) query.uniqueResult();
 			if ( res == null ) {
 				throw new RevisionDoesNotExistException( date );
 			}
 
 			return res;
 		}
 		catch (NonUniqueResultException e) {
 			throw new AuditException( e );
 		}
 	}
 
 	@Override
 	@SuppressWarnings({"unchecked"})
 	public <T> T findRevision(Class<T> revisionEntityClass, Number revision)
 			throws IllegalArgumentException, RevisionDoesNotExistException, IllegalStateException {
 		revisionEntityClass = getTargetClassIfProxied( revisionEntityClass );
 		checkNotNull( revision, "Entity revision" );
 		checkPositive( revision, "Entity revision" );
 		checkSession();
 
 		final Set<Number> revisions = new HashSet<Number>( 1 );
 		revisions.add( revision );
 		final Criteria query = verCfg.getRevisionInfoQueryCreator().getRevisionsQuery( session, revisions );
 
 		try {
 			final T revisionData = (T) query.uniqueResult();
 
 			if ( revisionData == null ) {
 				throw new RevisionDoesNotExistException( revision );
 			}
 
 			return revisionData;
 		}
 		catch (NonUniqueResultException e) {
 			throw new AuditException( e );
 		}
 	}
 
 	@Override
 	@SuppressWarnings({"unchecked"})
 	public <T> Map<Number, T> findRevisions(Class<T> revisionEntityClass, Set<Number> revisions)
 			throws IllegalArgumentException,
 			IllegalStateException {
 		revisionEntityClass = getTargetClassIfProxied( revisionEntityClass );
 		final Map<Number, T> result = new HashMap<Number, T>( revisions.size() );
 
 		for ( Number revision : revisions ) {
 			checkNotNull( revision, "Entity revision" );
 			checkPositive( revision, "Entity revision" );
 		}
 		checkSession();
 
 		final Criteria query = verCfg.getRevisionInfoQueryCreator().getRevisionsQuery( session, revisions );
 
 		try {
 			final List<T> revisionList = query.list();
 			for ( T revision : revisionList ) {
 				final Number revNo = verCfg.getRevisionInfoNumberReader().getRevisionNumber( revision );
 				result.put( revNo, revision );
 			}
 
 			return result;
 		}
 		catch (HibernateException e) {
 			throw new AuditException( e );
 		}
 	}
 
 	@Override
 	public CrossTypeRevisionChangesReader getCrossTypeRevisionChangesReader() throws AuditException {
 		if ( !verCfg.getGlobalCfg().isTrackEntitiesChangedInRevision() ) {
 			throw new AuditException(
 					"This API is designed for Envers default mechanism of tracking entities modified in a given revision."
 							+ " Extend DefaultTrackingModifiedEntitiesRevisionEntity, utilize @ModifiedEntityNames annotation or set "
 							+ "'org.hibernate.envers.track_entities_changed_in_revision' parameter to true."
 			);
 		}
 		return crossTypeRevisionChangesReader;
 	}
 
 	@Override
 	@SuppressWarnings({"unchecked"})
 	public <T> T getCurrentRevision(Class<T> revisionEntityClass, boolean persist) {
 		revisionEntityClass = getTargetClassIfProxied( revisionEntityClass );
 		if ( !(session instanceof EventSource) ) {
 			throw new IllegalArgumentException( "The provided session is not an EventSource!" );
 		}
 
 		// Obtaining the current audit sync
 		final AuditProcess auditProcess = verCfg.getSyncManager().get( (EventSource) session );
 
 		// And getting the current revision data
 		return (T) auditProcess.getCurrentRevisionData( session, persist );
 	}
 
 	@Override
 	public AuditQueryCreator createQuery() {
 		return new AuditQueryCreator( verCfg, this );
 	}
 
 	@Override
 	public boolean isEntityClassAudited(Class<?> entityClass) {
 		entityClass = getTargetClassIfProxied( entityClass );
 		return this.isEntityNameAudited( entityClass.getName() );
 	}
 
 
 	@Override
 	public boolean isEntityNameAudited(String entityName) {
 		checkNotNull( entityName, "Entity name" );
 		checkSession();
 		return (verCfg.getEntCfg().isVersioned( entityName ));
 	}
 
 	@Override
 	public String getEntityName(Object primaryKey, Number revision, Object entity) throws HibernateException {
 		checkNotNull( primaryKey, "Primary key" );
 		checkNotNull( revision, "Entity revision" );
 		checkPositive( revision, "Entity revision" );
 		checkNotNull( entity, "Entity" );
 		checkSession();
 
 		// Unwrap if necessary
 		if ( entity instanceof HibernateProxy ) {
 			entity = ((HibernateProxy) entity).getHibernateLazyInitializer().getImplementation();
 		}
 		if ( firstLevelCache.containsEntityName( primaryKey, revision, entity ) ) {
 			// it's on envers FLC!
 			return firstLevelCache.getFromEntityNameCache( primaryKey, revision, entity );
 		}
 		else {
 			throw new HibernateException(
 					"Envers can't resolve entityName for historic entity. The id, revision and entity is not on envers first level cache."
 			);
 		}
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/synchronization/work/DelWorkUnit.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/synchronization/work/DelWorkUnit.java
index 04902e3477..56d8a8ed2e 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/synchronization/work/DelWorkUnit.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/synchronization/work/DelWorkUnit.java
@@ -1,120 +1,120 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.synchronization.work;
 
 import java.io.Serializable;
 import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.envers.RevisionType;
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.envers.internal.tools.ArraysTools;
 import org.hibernate.persister.entity.EntityPersister;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public class DelWorkUnit extends AbstractAuditWorkUnit implements AuditWorkUnit {
 	private final Object[] state;
 	private final EntityPersister entityPersister;
 	private final String[] propertyNames;
 
 	public DelWorkUnit(
 			SessionImplementor sessionImplementor, String entityName, AuditConfiguration verCfg,
 			Serializable id, EntityPersister entityPersister, Object[] state) {
 		super( sessionImplementor, entityName, verCfg, id, RevisionType.DEL );
 
 		this.state = state;
 		this.entityPersister = entityPersister;
 		this.propertyNames = entityPersister.getPropertyNames();
 	}
 
 	@Override
 	public boolean containsWork() {
 		return true;
 	}
 
 	@Override
 	public Map<String, Object> generateData(Object revisionData) {
 		final Map<String, Object> data = new HashMap<String, Object>();
 		fillDataWithId( data, revisionData );
 
 		if ( verCfg.getGlobalCfg().isStoreDataAtDelete() ) {
 			verCfg.getEntCfg().get( getEntityName() ).getPropertyMapper().map(
 					sessionImplementor,
 					data,
 					propertyNames,
 					state,
 					state
 			);
 		}
 		else {
 			verCfg.getEntCfg().get( getEntityName() ).getPropertyMapper().map(
 					sessionImplementor,
 					data,
 					propertyNames,
 					null,
 					state
 			);
 		}
 
 		return data;
 	}
 
 	@Override
 	public AuditWorkUnit merge(AddWorkUnit second) {
 		if ( ArraysTools.arraysEqual( second.getState(), state ) ) {
 			// Return null if object's state has not changed.
 			return null;
 		}
 		return new ModWorkUnit( sessionImplementor, entityName, verCfg, id, entityPersister, second.getState(), state );
 	}
 
 	@Override
 	public AuditWorkUnit merge(ModWorkUnit second) {
 		return null;
 	}
 
 	@Override
 	public AuditWorkUnit merge(DelWorkUnit second) {
 		return this;
 	}
 
 	@Override
 	public AuditWorkUnit merge(CollectionChangeWorkUnit second) {
 		return this;
 	}
 
 	@Override
 	public AuditWorkUnit merge(FakeBidirectionalRelationWorkUnit second) {
 		return this;
 	}
 
 	@Override
 	public AuditWorkUnit dispatch(WorkUnitMergeVisitor first) {
 		return first.merge( this );
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/synchronization/work/ModWorkUnit.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/synchronization/work/ModWorkUnit.java
index c8c2f7731c..cf71adc1b8 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/synchronization/work/ModWorkUnit.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/synchronization/work/ModWorkUnit.java
@@ -1,112 +1,112 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.synchronization.work;
 
 import java.io.Serializable;
 import java.util.HashMap;
 import java.util.Map;
 
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.envers.RevisionType;
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.persister.entity.EntityPersister;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  */
 public class ModWorkUnit extends AbstractAuditWorkUnit implements AuditWorkUnit {
 	private final Map<String, Object> data;
 	private final boolean changes;
 
 	private final EntityPersister entityPersister;
 	private final Object[] oldState;
 	private final Object[] newState;
 
 	public ModWorkUnit(
 			SessionImplementor sessionImplementor, String entityName, AuditConfiguration verCfg,
 			Serializable id, EntityPersister entityPersister, Object[] newState, Object[] oldState) {
 		super( sessionImplementor, entityName, verCfg, id, RevisionType.MOD );
 
 		this.entityPersister = entityPersister;
 		this.oldState = oldState;
 		this.newState = newState;
 		data = new HashMap<String, Object>();
 		changes = verCfg.getEntCfg().get( getEntityName() ).getPropertyMapper().map(
 				sessionImplementor, data,
 				entityPersister.getPropertyNames(), newState, oldState
 		);
 	}
 
 	public Map<String, Object> getData() {
 		return data;
 	}
 
 	@Override
 	public boolean containsWork() {
 		return changes;
 	}
 
 	@Override
 	public Map<String, Object> generateData(Object revisionData) {
 		fillDataWithId( data, revisionData );
 
 		return data;
 	}
 
 	@Override
 	public AuditWorkUnit merge(AddWorkUnit second) {
 		return this;
 	}
 
 	@Override
 	public AuditWorkUnit merge(ModWorkUnit second) {
 		// In case of multiple subsequent flushes within single transaction, modification flags need to be
 		// recalculated against initial and final state of the given entity.
 		return new ModWorkUnit(
 				second.sessionImplementor, second.getEntityName(), second.verCfg, second.id,
 				second.entityPersister, second.newState, this.oldState
 		);
 	}
 
 	@Override
 	public AuditWorkUnit merge(DelWorkUnit second) {
 		return second;
 	}
 
 	@Override
 	public AuditWorkUnit merge(CollectionChangeWorkUnit second) {
 		second.mergeCollectionModifiedData( data );
 		return this;
 	}
 
 	@Override
 	public AuditWorkUnit merge(FakeBidirectionalRelationWorkUnit second) {
 		return FakeBidirectionalRelationWorkUnit.merge( second, this, second.getNestedWorkUnit() );
 	}
 
 	@Override
 	public AuditWorkUnit dispatch(WorkUnitMergeVisitor first) {
 		return first.merge( this );
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/MapProxyTool.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/MapProxyTool.java
index 7fdba67aca..411d876cd5 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/MapProxyTool.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/MapProxyTool.java
@@ -1,150 +1,160 @@
 package org.hibernate.envers.internal.tools;
 
-import javassist.*;
-import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
-import org.hibernate.boot.registry.classloading.spi.ClassLoadingException;
-import org.hibernate.envers.internal.entities.PropertyData;
-
 import java.io.Serializable;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
 import java.util.Set;
 
+import javassist.CannotCompileException;
+import javassist.ClassPool;
+import javassist.CtClass;
+import javassist.CtConstructor;
+import javassist.CtField;
+import javassist.CtMethod;
+import javassist.CtNewConstructor;
+import javassist.NotFoundException;
+
+import org.hibernate.boot.registry.classloading.spi.ClassLoaderService;
+import org.hibernate.boot.registry.classloading.spi.ClassLoadingException;
+import org.hibernate.envers.internal.entities.PropertyData;
+
 import static org.hibernate.envers.internal.tools.StringTools.capitalizeFirst;
 import static org.hibernate.envers.internal.tools.StringTools.getLastComponent;
 
 /**
  * @author Lukasz Zuchowski (author at zuchos dot com)
  */
-public class MapProxyTool {
+public final class MapProxyTool {
+	private MapProxyTool() {
+	}
 
-    /**
+	/**
      * @param className               Name of the class to construct (should be unique within class loader)
      * @param map                instance that will be proxied by java bean
      * @param propertyDatas      properties that should java bean declare
      * @param classLoaderService
      * @return new instance of proxy
      * @author Lukasz Zuchowski (author at zuchos dot com)
      * Creates instance of map proxy class. This proxy class will be a java bean with properties from <code>propertyDatas</code>.
      * Instance will proxy calls to instance of the map passed as parameter.
      */
     public static Object newInstanceOfBeanProxyForMap(String className, Map<String, Object> map, Set<PropertyData> propertyDatas, ClassLoaderService classLoaderService) {
         Map<String, Class<?>> properties = prepareProperties(propertyDatas);
         return createNewInstance(map, classForName(className, properties, classLoaderService));
     }
 
     private static Object createNewInstance(Map<String, Object> map, Class aClass) {
         try {
             return aClass.getConstructor(Map.class).newInstance(map);
         } catch (Exception e) {
             throw new RuntimeException(e);
         }
     }
 
     private static Map<String, Class<?>> prepareProperties(Set<PropertyData> propertyDatas) {
         Map<String, Class<?>> properties = new HashMap<String, Class<?>>();
         for (PropertyData propertyData : propertyDatas) {
             properties.put(propertyData.getBeanName(), Object.class);
         }
         return properties;
     }
 
     private static Class loadClass(String className, ClassLoaderService classLoaderService) {
         try {
             return ReflectionTools.loadClass(className, classLoaderService);
         } catch (ClassLoadingException e) {
             return null;
         }
 
     }
 
     /**
      * Generates/loads proxy class for given name with properties for map.
      * @param className name of the class that will be generated/loaded
      * @param properties list of properties that should be exposed via java bean
      * @param classLoaderService
      * @return proxy class that wraps map into java bean
      */
     public static Class classForName(String className, Map<String,Class<?>> properties, ClassLoaderService classLoaderService) {
         Class aClass = loadClass(className, classLoaderService);
         if (aClass == null) {
             aClass = generate(className, properties);
         }
         return aClass;
     }
 
     /**
      * Protected for test only
      */
     protected static Class generate(String className, Map<String, Class<?>> properties) {
         try {
             ClassPool pool = ClassPool.getDefault();
             CtClass cc = pool.makeClass(className);
 
             cc.addInterface(resolveCtClass(Serializable.class));
             cc.addField(new CtField(resolveCtClass(Map.class), "theMap", cc));
             cc.addConstructor(generateConstructor(className, cc));
 
             for (Entry<String, Class<?>> entry : properties.entrySet()) {
 
                 // add getter
                 cc.addMethod(generateGetter(cc, entry.getKey(), entry.getValue()));
 
                 // add setter
                 cc.addMethod(generateSetter(cc, entry.getKey(), entry.getValue()));
             }
             return cc.toClass();
         } catch (Exception e) {
             throw new RuntimeException(e);
         }
     }
 
     private static CtConstructor generateConstructor(String className, CtClass cc) throws NotFoundException, CannotCompileException {
         StringBuffer sb = new StringBuffer();
         sb.append("public ").append(getLastComponent(className)).append("(").append(Map.class.getName()).append(" map)").append("{")
                 .append("this.theMap = map;").append("}");
         System.out.println(sb);
         return CtNewConstructor.make(sb.toString(), cc);
     }
 
     private static CtMethod generateGetter(CtClass declaringClass, String fieldName, Class fieldClass)
             throws CannotCompileException {
 
         String getterName = "get" + capitalizeFirst(fieldName);
 
         StringBuilder sb = new StringBuilder();
         sb.append("public ").append(fieldClass.getName()).append(" ")
                 .append(getterName).append("(){").append("return (").append(fieldClass.getName()).append(")this.theMap.get(\"")
                 .append(fieldName).append("\")").append(";").append("}");
         return CtMethod.make(sb.toString(), declaringClass);
     }
 
     private static CtMethod generateSetter(CtClass declaringClass, String fieldName, Class fieldClass)
             throws CannotCompileException {
 
         String setterName = "set" + capitalizeFirst(fieldName);
 
         StringBuilder sb = new StringBuilder();
         sb.append("public void ").append(setterName).append("(")
                 .append(fieldClass.getName()).append(" ").append(fieldName)
                 .append(")").append("{").append("this.theMap.put(\"").append(fieldName)
                 .append("\",").append(fieldName).append(")").append(";").append("}");
         return CtMethod.make(sb.toString(), declaringClass);
     }
 
     private static CtClass resolveCtClass(Class clazz) throws NotFoundException {
         return resolveCtClass(clazz.getName());
     }
 
 
     private static CtClass resolveCtClass(String clazz) throws NotFoundException {
         try {
             ClassPool pool = ClassPool.getDefault();
             return pool.get(clazz);
         } catch (NotFoundException e) {
             return null;
         }
     }
 
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/MutableInteger.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/MutableInteger.java
index 6b1c79fb21..aaa43ff328 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/MutableInteger.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/MutableInteger.java
@@ -1,58 +1,58 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.tools;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  */
 public class MutableInteger {
-	private int value = 0;
+	private int value;
 
 	public MutableInteger() {
 	}
 
 	public MutableInteger(int value) {
 		this.value = value;
 	}
 
 	public MutableInteger deepCopy() {
 		return new MutableInteger( value );
 	}
 
 	public int getAndIncrease() {
 		return value++;
 	}
 
 	public int get() {
 		return value;
 	}
 
 	public void set(int value) {
 		this.value = value;
 	}
 
 	public void increase() {
 		++value;
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/Triple.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/Triple.java
index 171203010d..0d94b1730f 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/Triple.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/Triple.java
@@ -1,87 +1,87 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.tools;
 
 import org.hibernate.internal.util.compare.EqualsHelper;
 
 /**
  * A triple of objects.
  *
  * @param <T1>
  * @param <T2>
  * @param <T3>
  *
  * @author Adam Warski (adamw@aster.pl)
  */
 public class Triple<T1, T2, T3> {
 	private T1 obj1;
 	private T2 obj2;
 	private T3 obj3;
 
 	public Triple(T1 obj1, T2 obj2, T3 obj3) {
 		this.obj1 = obj1;
 		this.obj2 = obj2;
 		this.obj3 = obj3;
 	}
 
 	public T1 getFirst() {
 		return obj1;
 	}
 
 	public T2 getSecond() {
 		return obj2;
 	}
 
 	public T3 getThird() {
 		return obj3;
 	}
 
 	@Override
 	public boolean equals(Object o) {
 		if ( this == o ) {
 			return true;
 		}
 		if ( !(o instanceof Triple) ) {
 			return false;
 		}
 
 		final Triple other = (Triple) o;
 		return EqualsHelper.equals( obj1, other.obj1 )
 				&& EqualsHelper.equals( obj2, other.obj2 )
 				&& EqualsHelper.equals( obj3, other.obj3 );
 	}
 
 	@Override
 	public int hashCode() {
 		int result;
 		result = (obj1 != null ? obj1.hashCode() : 0);
 		result = 31 * result + (obj2 != null ? obj2.hashCode() : 0);
 		result = 31 * result + (obj3 != null ? obj3.hashCode() : 0);
 		return result;
 	}
 
 	public static <T1, T2, T3> Triple<T1, T2, T3> make(T1 obj1, T2 obj2, T3 obj3) {
 		return new Triple<T1, T2, T3>( obj1, obj2, obj3 );
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/graph/GraphTopologicalSort.java b/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/graph/GraphTopologicalSort.java
index 99e3da169e..fbfe852f8b 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/graph/GraphTopologicalSort.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/internal/tools/graph/GraphTopologicalSort.java
@@ -1,71 +1,74 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.internal.tools.graph;
 
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  */
-public class GraphTopologicalSort {
+public final class GraphTopologicalSort {
+	private GraphTopologicalSort() {
+	}
+
 	/**
 	 * Sorts a graph topologically.
 	 *
 	 * @param definer Defines a graph (values and representations) to sort.
 	 *
 	 * @return Values of the graph, sorted topologically.
 	 */
 	public static <V, R> List<V> sort(GraphDefiner<V, R> definer) {
 		final List<V> values = definer.getValues();
 		final Map<R, Vertex<R>> vertices = new HashMap<R, Vertex<R>>();
 
 		// Creating a vertex for each representation
 		for ( V v : values ) {
 			final R rep = definer.getRepresentation( v );
 			vertices.put( rep, new Vertex<R>( rep ) );
 		}
 
 		// Connecting neighbourhooding vertices
 		for ( V v : values ) {
 			for ( V vn : definer.getNeighbours( v ) ) {
 				vertices.get( definer.getRepresentation( v ) )
 						.addNeighbour( vertices.get( definer.getRepresentation( vn ) ) );
 			}
 		}
 
 		// Sorting the representations
 		final List<R> sortedReps = new TopologicalSort<R>().sort( vertices.values() );
 
 		// Transforming the sorted representations to sorted values
 		final List<V> sortedValues = new ArrayList<V>( sortedReps.size() );
 		for ( R rep : sortedReps ) {
 			sortedValues.add( definer.getValue( rep ) );
 		}
 
 		return sortedValues;
 	}
 }
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AggregatedAuditExpression.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AggregatedAuditExpression.java
index ac232152a5..b5911bc245 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AggregatedAuditExpression.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AggregatedAuditExpression.java
@@ -1,120 +1,123 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query.criteria;
 
 import java.util.ArrayList;
 import java.util.List;
 
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.envers.internal.reader.AuditReaderImplementor;
 import org.hibernate.envers.internal.tools.query.Parameters;
 import org.hibernate.envers.internal.tools.query.QueryBuilder;
 import org.hibernate.envers.query.criteria.internal.CriteriaTools;
 import org.hibernate.envers.query.internal.property.PropertyNameGetter;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public class AggregatedAuditExpression implements AuditCriterion, ExtendableCriterion {
 	private PropertyNameGetter propertyNameGetter;
 	private AggregatedMode mode;
-	private boolean correlate = false; // Correlate subquery with outer query by entity id.
+	// Correlate subquery with outer query by entity id.
+	private boolean correlate;
 	private List<AuditCriterion> criterions;
 
 	public AggregatedAuditExpression(PropertyNameGetter propertyNameGetter, AggregatedMode mode) {
 		this.propertyNameGetter = propertyNameGetter;
 		this.mode = mode;
 		criterions = new ArrayList<AuditCriterion>();
 	}
 
 	public static enum AggregatedMode {
 		MAX,
 		MIN
 	}
 
+	@Override
 	public AggregatedAuditExpression add(AuditCriterion criterion) {
 		criterions.add( criterion );
 		return this;
 	}
 
+	@Override
 	public void addToQuery(
 			AuditConfiguration auditCfg, AuditReaderImplementor versionsReader, String entityName,
 			QueryBuilder qb, Parameters parameters) {
 		String propertyName = CriteriaTools.determinePropertyName(
 				auditCfg,
 				versionsReader,
 				entityName,
 				propertyNameGetter
 		);
 
 		CriteriaTools.checkPropertyNotARelation( auditCfg, entityName, propertyName );
 
 		// Make sure our conditions are ANDed together even if the parent Parameters have a different connective
 		Parameters subParams = parameters.addSubParameters( Parameters.AND );
 		// This will be the aggregated query, containing all the specified conditions
 		QueryBuilder subQb = qb.newSubQueryBuilder();
 
 		// Adding all specified conditions both to the main query, as well as to the
 		// aggregated one.
 		for ( AuditCriterion versionsCriteria : criterions ) {
 			versionsCriteria.addToQuery( auditCfg, versionsReader, entityName, qb, subParams );
 			versionsCriteria.addToQuery( auditCfg, versionsReader, entityName, subQb, subQb.getRootParameters() );
 		}
 
 		// Setting the desired projection of the aggregated query
 		switch ( mode ) {
 			case MIN:
 				subQb.addProjection( "min", propertyName, false );
 				break;
 			case MAX:
 				subQb.addProjection( "max", propertyName, false );
 		}
 
 		// Correlating subquery with the outer query by entity id. See JIRA HHH-7827.
 		if ( correlate ) {
 			final String originalIdPropertyName = auditCfg.getAuditEntCfg().getOriginalIdPropName();
 			auditCfg.getEntCfg().get( entityName ).getIdMapper().addIdsEqualToQuery(
 					subQb.getRootParameters(),
 					subQb.getRootAlias() + "." + originalIdPropertyName,
 					qb.getRootAlias() + "." + originalIdPropertyName
 			);
 		}
 
 		// Adding the constrain on the result of the aggregated criteria
 		subParams.addWhere( propertyName, "=", subQb );
 	}
 
 	/**
 	 * Compute aggregated expression in the context of each entity instance separately. Useful for retrieving latest
 	 * revisions of all entities of a particular type.<br/>
 	 * Implementation note: Correlates subquery with the outer query by entity id.
 	 *
 	 * @return this (for method chaining).
 	 */
 	public AggregatedAuditExpression computeAggregationInInstanceContext() {
 		correlate = true;
 		return this;
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditDisjunction.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditDisjunction.java
index c7c6ed13d6..1423b5078c 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditDisjunction.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditDisjunction.java
@@ -1,63 +1,65 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query.criteria;
 
 import java.util.ArrayList;
 import java.util.List;
 
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.envers.internal.reader.AuditReaderImplementor;
 import org.hibernate.envers.internal.tools.query.Parameters;
 import org.hibernate.envers.internal.tools.query.QueryBuilder;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  */
 public class AuditDisjunction implements AuditCriterion, ExtendableCriterion {
 	private List<AuditCriterion> criterions;
 
 	public AuditDisjunction() {
 		criterions = new ArrayList<AuditCriterion>();
 	}
 
+	@Override
 	public AuditDisjunction add(AuditCriterion criterion) {
 		criterions.add( criterion );
 		return this;
 	}
 
+	@Override
 	public void addToQuery(
 			AuditConfiguration verCfg, AuditReaderImplementor versionsReader, String entityName,
 			QueryBuilder qb, Parameters parameters) {
 		Parameters orParameters = parameters.addSubParameters( Parameters.OR );
 
 		if ( criterions.size() == 0 ) {
 			orParameters.addWhere( "0", false, "=", "1", false );
 		}
 		else {
 			for ( AuditCriterion criterion : criterions ) {
 				criterion.addToQuery( verCfg, versionsReader, entityName, qb, orParameters );
 			}
 		}
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditId.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditId.java
index 6ffcc4cd45..8be9162be2 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditId.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditId.java
@@ -1,84 +1,86 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query.criteria;
 
 import org.hibernate.envers.query.criteria.internal.IdentifierEqAuditExpression;
 import org.hibernate.envers.query.internal.property.EntityPropertyName;
 import org.hibernate.envers.query.internal.property.OriginalIdPropertyName;
 import org.hibernate.envers.query.internal.property.PropertyNameGetter;
 import org.hibernate.envers.query.projection.AuditProjection;
 import org.hibernate.envers.query.projection.internal.PropertyAuditProjection;
 
 /**
  * Create restrictions and projections for the id of an audited entity.
  *
  * @author Adam Warski (adam at warski dot org)
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 @SuppressWarnings({"JavaDoc"})
 public class AuditId<T> extends AuditProperty<T> {
 	public static final String IDENTIFIER_PLACEHOLDER = "$$id$$";
-	private static final PropertyNameGetter identifierPropertyGetter = new EntityPropertyName( IDENTIFIER_PLACEHOLDER );
+	private static final PropertyNameGetter IDENTIFIER_PROPERTY_GETTER = new EntityPropertyName( IDENTIFIER_PLACEHOLDER );
 
 	public AuditId() {
-		super( identifierPropertyGetter );
+		super( IDENTIFIER_PROPERTY_GETTER );
 	}
 
 	/**
 	 * Apply an "equal" constraint
 	 */
+	@Override
 	public AuditCriterion eq(Object id) {
 		return new IdentifierEqAuditExpression( id, true );
 	}
 
 	/**
 	 * Apply a "not equal" constraint
 	 */
+	@Override
 	public AuditCriterion ne(Object id) {
 		return new IdentifierEqAuditExpression( id, false );
 	}
 
 	// Projections
 
 	/**
 	 * Projection counting the values
 	 *
 	 * @param idPropertyName Name of the identifier property
 	 *
 	 * @deprecated Use {@link #count()}.
 	 */
 	public AuditProjection count(String idPropertyName) {
 		return new PropertyAuditProjection( new OriginalIdPropertyName( idPropertyName ), "count", false );
 	}
 
 	@Override
 	public AuditCriterion hasChanged() {
 		throw new UnsupportedOperationException();
 	}
 
 	@Override
 	public AuditCriterion hasNotChanged() {
 		throw new UnsupportedOperationException();
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditRelatedId.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditRelatedId.java
index da90c6d1b0..cff1c2633c 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditRelatedId.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/AuditRelatedId.java
@@ -1,55 +1,55 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query.criteria;
 
 import org.hibernate.envers.query.criteria.internal.RelatedAuditExpression;
 import org.hibernate.envers.query.internal.property.PropertyNameGetter;
 
 /**
  * Create restrictions on an id of an entity related to an audited entity.
  *
  * @author Adam Warski (adam at warski dot org)
  */
 @SuppressWarnings({"JavaDoc"})
 public class AuditRelatedId {
 	private final PropertyNameGetter propertyNameGetter;
 
 	public AuditRelatedId(PropertyNameGetter propertyNameGetter) {
 		this.propertyNameGetter = propertyNameGetter;
 	}
 
 	/**
 	 * Apply an "equal" constraint
 	 */
 	public AuditCriterion eq(Object id) {
 		return new RelatedAuditExpression( propertyNameGetter, id, true );
 	}
 
 	/**
 	 * Apply a "not equal" constraint
 	 */
 	public AuditCriterion ne(Object id) {
 		return new RelatedAuditExpression( propertyNameGetter, id, false );
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/internal/RelatedAuditExpression.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/internal/RelatedAuditExpression.java
index b0c66db63a..ea7aac824a 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/internal/RelatedAuditExpression.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/internal/RelatedAuditExpression.java
@@ -1,71 +1,72 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query.criteria.internal;
 
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.envers.exception.AuditException;
 import org.hibernate.envers.internal.entities.RelationDescription;
 import org.hibernate.envers.internal.reader.AuditReaderImplementor;
 import org.hibernate.envers.internal.tools.query.Parameters;
 import org.hibernate.envers.internal.tools.query.QueryBuilder;
 import org.hibernate.envers.query.criteria.AuditCriterion;
 import org.hibernate.envers.query.internal.property.PropertyNameGetter;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  */
 public class RelatedAuditExpression implements AuditCriterion {
 	private final PropertyNameGetter propertyNameGetter;
 	private final Object id;
 	private final boolean equals;
 
 	public RelatedAuditExpression(PropertyNameGetter propertyNameGetter, Object id, boolean equals) {
 		this.propertyNameGetter = propertyNameGetter;
 		this.id = id;
 		this.equals = equals;
 	}
 
+	@Override
 	public void addToQuery(
 			AuditConfiguration auditCfg, AuditReaderImplementor versionsReader, String entityName,
 			QueryBuilder qb, Parameters parameters) {
 		String propertyName = CriteriaTools.determinePropertyName(
 				auditCfg,
 				versionsReader,
 				entityName,
 				propertyNameGetter
 		);
 
 		RelationDescription relatedEntity = CriteriaTools.getRelatedEntity( auditCfg, entityName, propertyName );
 
 		if ( relatedEntity == null ) {
 			throw new AuditException(
 					"This criterion can only be used on a property that is " +
 							"a relation to another property."
 			);
 		}
 		else {
 			relatedEntity.getIdMapper().addIdEqualsToQuery( parameters, id, null, equals );
 		}
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/internal/RevisionTypeAuditExpression.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/internal/RevisionTypeAuditExpression.java
index b08f371c3f..cf66aa30f6 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/internal/RevisionTypeAuditExpression.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/criteria/internal/RevisionTypeAuditExpression.java
@@ -1,49 +1,50 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query.criteria.internal;
 
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.envers.internal.reader.AuditReaderImplementor;
 import org.hibernate.envers.internal.tools.query.Parameters;
 import org.hibernate.envers.internal.tools.query.QueryBuilder;
 import org.hibernate.envers.query.criteria.AuditCriterion;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  */
 public class RevisionTypeAuditExpression implements AuditCriterion {
 	private Object value;
 	private String op;
 
 	public RevisionTypeAuditExpression(Object value, String op) {
 		this.value = value;
 		this.op = op;
 	}
 
+	@Override
 	public void addToQuery(
 			AuditConfiguration verCfg, AuditReaderImplementor versionsReader, String entityName,
 			QueryBuilder qb, Parameters parameters) {
 		parameters.addWhereWithParam( verCfg.getAuditEntCfg().getRevisionTypePropName(), op, value );
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/impl/EntitiesModifiedAtRevisionQuery.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/impl/EntitiesModifiedAtRevisionQuery.java
index cd1dce0d68..6045bc2dc2 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/impl/EntitiesModifiedAtRevisionQuery.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/impl/EntitiesModifiedAtRevisionQuery.java
@@ -1,67 +1,68 @@
 package org.hibernate.envers.query.internal.impl;
 
 import java.util.ArrayList;
 import java.util.List;
 
 import org.hibernate.Query;
 import org.hibernate.envers.configuration.internal.AuditEntitiesConfiguration;
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.envers.internal.reader.AuditReaderImplementor;
 import org.hibernate.envers.query.criteria.AuditCriterion;
 
 /**
  * In comparison to {@link EntitiesAtRevisionQuery} this query returns an empty collection if an entity
  * of a certain type has not been changed in a given revision.
  *
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  * @see EntitiesAtRevisionQuery
  */
 public class EntitiesModifiedAtRevisionQuery extends AbstractAuditQuery {
 	private final Number revision;
 
 	public EntitiesModifiedAtRevisionQuery(
 			AuditConfiguration verCfg, AuditReaderImplementor versionsReader,
 			Class<?> cls, Number revision) {
 		super( verCfg, versionsReader, cls );
 		this.revision = revision;
 	}
 
 	public EntitiesModifiedAtRevisionQuery(
 			AuditConfiguration verCfg, AuditReaderImplementor versionsReader,
 			Class<?> cls, String entityName, Number revision) {
 		super( verCfg, versionsReader, cls, entityName );
 		this.revision = revision;
 	}
 
+	@Override
 	@SuppressWarnings({"unchecked"})
 	public List list() {
 		/*
          * The query that we need to create:
          *   SELECT new list(e) FROM versionsReferencedEntity e
          *   WHERE
          * (all specified conditions, transformed, on the "e" entity) AND
          * e.revision = :revision
          */
 		AuditEntitiesConfiguration verEntCfg = verCfg.getAuditEntCfg();
 		String revisionPropertyPath = verEntCfg.getRevisionNumberPath();
 		qb.getRootParameters().addWhereWithParam( revisionPropertyPath, "=", revision );
 
 		// all specified conditions
 		for ( AuditCriterion criterion : criterions ) {
 			criterion.addToQuery( verCfg, versionsReader, entityName, qb, qb.getRootParameters() );
 		}
 
 		Query query = buildQuery();
 		List queryResult = query.list();
 
 		if ( hasProjection ) {
 			return queryResult;
 		}
 		else {
 			List result = new ArrayList();
 			entityInstantiator.addInstancesFromVersionsEntities( entityName, result, queryResult, revision );
 
 			return result;
 		}
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/OriginalIdPropertyName.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/OriginalIdPropertyName.java
index 5187efc0e2..a25d8300d4 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/OriginalIdPropertyName.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/OriginalIdPropertyName.java
@@ -1,45 +1,46 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query.internal.property;
 
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.envers.query.criteria.AuditId;
 
 /**
  * Used for specifying restrictions on the identifier.
  *
  * @author Adam Warski (adam at warski dot org)
  * @deprecated To be removed together with {@link AuditId#count(String)} in version 5.0.
  */
 public class OriginalIdPropertyName implements PropertyNameGetter {
 	private final String idPropertyName;
 
 	public OriginalIdPropertyName(String idPropertyName) {
 		this.idPropertyName = idPropertyName;
 	}
 
+	@Override
 	public String get(AuditConfiguration auditCfg) {
 		return auditCfg.getAuditEntCfg().getOriginalIdPropName() + "." + idPropertyName;
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/RevisionNumberPropertyName.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/RevisionNumberPropertyName.java
index 640afaeb13..6aec37975d 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/RevisionNumberPropertyName.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/RevisionNumberPropertyName.java
@@ -1,37 +1,38 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query.internal.property;
 
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 
 /**
  * Used for specifying restrictions on the revision number, corresponding to an audit entity.
  *
  * @author Adam Warski (adam at warski dot org)
  */
 public class RevisionNumberPropertyName implements PropertyNameGetter {
+	@Override
 	public String get(AuditConfiguration auditCfg) {
 		return auditCfg.getAuditEntCfg().getRevisionNumberPath();
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/RevisionPropertyPropertyName.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/RevisionPropertyPropertyName.java
index 64d4f15427..4d95a5d228 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/RevisionPropertyPropertyName.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/RevisionPropertyPropertyName.java
@@ -1,43 +1,44 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query.internal.property;
 
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 
 /**
  * Used for specifying restrictions on a property of the revision entity, which is associated with an audit entity.
  *
  * @author Adam Warski (adam at warski dot org)
  */
 public class RevisionPropertyPropertyName implements PropertyNameGetter {
 	private final String propertyName;
 
 	public RevisionPropertyPropertyName(String propertyName) {
 		this.propertyName = propertyName;
 	}
 
+	@Override
 	public String get(AuditConfiguration auditCfg) {
 		return auditCfg.getAuditEntCfg().getRevisionPropPath( propertyName );
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/RevisionTypePropertyName.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/RevisionTypePropertyName.java
index 33b99d78ae..f88d456c64 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/RevisionTypePropertyName.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/internal/property/RevisionTypePropertyName.java
@@ -1,37 +1,38 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query.internal.property;
 
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 
 /**
  * Used for specifying restrictions on the revision number, corresponding to an audit entity.
  *
  * @author Adam Warski (adam at warski dot org)
  */
 public class RevisionTypePropertyName implements PropertyNameGetter {
+	@Override
 	public String get(AuditConfiguration auditCfg) {
 		return auditCfg.getAuditEntCfg().getRevisionTypePropName();
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/order/internal/PropertyAuditOrder.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/order/internal/PropertyAuditOrder.java
index f1764f9c96..1a0898e2ec 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/order/internal/PropertyAuditOrder.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/order/internal/PropertyAuditOrder.java
@@ -1,46 +1,47 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query.order.internal;
 
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.envers.query.internal.property.PropertyNameGetter;
 import org.hibernate.envers.query.order.AuditOrder;
 import org.hibernate.envers.tools.Pair;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  */
 public class PropertyAuditOrder implements AuditOrder {
 	private final PropertyNameGetter propertyNameGetter;
 	private final boolean asc;
 
 	public PropertyAuditOrder(PropertyNameGetter propertyNameGetter, boolean asc) {
 		this.propertyNameGetter = propertyNameGetter;
 		this.asc = asc;
 	}
 
+	@Override
 	public Pair<String, Boolean> getData(AuditConfiguration auditCfg) {
 		return Pair.make( propertyNameGetter.get( auditCfg ), asc );
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/query/projection/internal/PropertyAuditProjection.java b/hibernate-envers/src/main/java/org/hibernate/envers/query/projection/internal/PropertyAuditProjection.java
index 1f5b889749..60b0b2507a 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/query/projection/internal/PropertyAuditProjection.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/query/projection/internal/PropertyAuditProjection.java
@@ -1,50 +1,51 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2008, Red Hat Middleware LLC or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Middleware LLC.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.envers.query.projection.internal;
 
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.envers.internal.tools.Triple;
 import org.hibernate.envers.query.internal.property.PropertyNameGetter;
 import org.hibernate.envers.query.projection.AuditProjection;
 
 /**
  * @author Adam Warski (adam at warski dot org)
  */
 public class PropertyAuditProjection implements AuditProjection {
 	private final PropertyNameGetter propertyNameGetter;
 	private final String function;
 	private final boolean distinct;
 
 	public PropertyAuditProjection(PropertyNameGetter propertyNameGetter, String function, boolean distinct) {
 		this.propertyNameGetter = propertyNameGetter;
 		this.function = function;
 		this.distinct = distinct;
 	}
 
+	@Override
 	public Triple<String, String, Boolean> getData(AuditConfiguration auditCfg) {
 		String propertyName = propertyNameGetter.get( auditCfg );
 
 		return Triple.make( function, propertyName, distinct );
 	}
-}
\ No newline at end of file
+}
diff --git a/hibernate-envers/src/main/java/org/hibernate/envers/strategy/ValidityAuditStrategy.java b/hibernate-envers/src/main/java/org/hibernate/envers/strategy/ValidityAuditStrategy.java
index d9970f5992..2fedd1839b 100644
--- a/hibernate-envers/src/main/java/org/hibernate/envers/strategy/ValidityAuditStrategy.java
+++ b/hibernate-envers/src/main/java/org/hibernate/envers/strategy/ValidityAuditStrategy.java
@@ -1,420 +1,420 @@
 package org.hibernate.envers.strategy;
 
 import java.io.Serializable;
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.SQLException;
 import java.util.Date;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
 import org.jboss.logging.Logger;
 
 import org.hibernate.LockOptions;
 import org.hibernate.Session;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.engine.spi.SessionFactoryImplementor;
 import org.hibernate.engine.spi.SessionImplementor;
 import org.hibernate.envers.RevisionType;
 import org.hibernate.envers.configuration.internal.AuditEntitiesConfiguration;
 import org.hibernate.envers.configuration.internal.GlobalConfiguration;
 import org.hibernate.envers.configuration.spi.AuditConfiguration;
 import org.hibernate.envers.internal.entities.mapper.PersistentCollectionChangeData;
 import org.hibernate.envers.internal.entities.mapper.relation.MiddleComponentData;
 import org.hibernate.envers.internal.entities.mapper.relation.MiddleIdData;
 import org.hibernate.envers.internal.synchronization.SessionCacheCleaner;
 import org.hibernate.envers.internal.tools.query.Parameters;
 import org.hibernate.envers.internal.tools.query.QueryBuilder;
 import org.hibernate.event.service.spi.EventListenerRegistry;
 import org.hibernate.event.spi.AutoFlushEvent;
 import org.hibernate.event.spi.AutoFlushEventListener;
 import org.hibernate.event.spi.EventSource;
 import org.hibernate.event.spi.EventType;
 import org.hibernate.jdbc.ReturningWork;
 import org.hibernate.persister.entity.Queryable;
 import org.hibernate.persister.entity.UnionSubclassEntityPersister;
 import org.hibernate.property.Getter;
 import org.hibernate.sql.Update;
 import org.hibernate.type.CollectionType;
 import org.hibernate.type.ComponentType;
 import org.hibernate.type.Type;
 
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.MIDDLE_ENTITY_ALIAS;
 import static org.hibernate.envers.internal.entities.mapper.relation.query.QueryConstants.REVISION_PARAMETER;
 
 /**
  * Audit strategy which persists and retrieves audit information using a validity algorithm, based on the
  * start-revision and end-revision of a row in the audit tables.
  * <p>This algorithm works as follows:
  * <ul>
  * <li>For a <strong>new row</strong> that is persisted in an audit table, only the <strong>start-revision</strong> column of that row is set</li>
  * <li>At the same time the <strong>end-revision</strong> field of the <strong>previous</strong> audit row is set to this revision</li>
  * <li>Queries are retrieved using 'between start and end revision', instead of a subquery.</li>
  * </ul>
  * </p>
  * <p/>
  * <p>
  * This has a few important consequences that need to be judged against against each other:
  * <ul>
  * <li>Persisting audit information is a bit slower, because an extra row is updated</li>
  * <li>Retrieving audit information is a lot faster</li>
  * </ul>
  * </p>
  *
  * @author Stephanie Pau
  * @author Adam Warski (adam at warski dot org)
  * @author Lukasz Antoniak (lukasz dot antoniak at gmail dot com)
  */
 public class ValidityAuditStrategy implements AuditStrategy {
 	private static final Logger log = Logger.getLogger( ValidityAuditStrategy.class );
 
 	/**
 	 * getter for the revision entity field annotated with @RevisionTimestamp
 	 */
-	private Getter revisionTimestampGetter = null;
+	private Getter revisionTimestampGetter;
 
 	private final SessionCacheCleaner sessionCacheCleaner;
 
 	public ValidityAuditStrategy() {
 		sessionCacheCleaner = new SessionCacheCleaner();
 	}
 
 	public void perform(
 			final Session session,
 			String entityName,
 			final AuditConfiguration auditCfg,
 			final Serializable id,
 			Object data,
 			final Object revision) {
 		final AuditEntitiesConfiguration audEntitiesCfg = auditCfg.getAuditEntCfg();
 		final String auditedEntityName = audEntitiesCfg.getAuditEntityName( entityName );
 		final String revisionInfoEntityName = auditCfg.getAuditEntCfg().getRevisionInfoEntityName();
 		final SessionImplementor sessionImplementor = (SessionImplementor) session;
 		final Dialect dialect = sessionImplementor.getFactory().getDialect();
 
 		// Save the audit data
 		session.save( auditedEntityName, data );
 		sessionCacheCleaner.scheduleAuditDataRemoval( session, data );
 
 		// Update the end date of the previous row.
 		//
 		// When application reuses identifiers of previously removed entities:
 		// The UPDATE statement will no-op if an entity with a given identifier has been
 		// inserted for the first time. But in case a deleted primary key value was
 		// reused, this guarantees correct strategy behavior: exactly one row with
 		// null end date exists for each identifier.
 		final boolean reuseEntityIdentifier = auditCfg.getGlobalCfg().isAllowIdentifierReuse();
 		if ( reuseEntityIdentifier || getRevisionType( auditCfg, data ) != RevisionType.ADD ) {
 			final Queryable productionEntityQueryable = getQueryable( entityName, sessionImplementor );
 			final Queryable rootProductionEntityQueryable = getQueryable(
 					productionEntityQueryable.getRootEntityName(),
 					sessionImplementor
 			);
 			final Queryable auditedEntityQueryable = getQueryable( auditedEntityName, sessionImplementor );
 			final Queryable rootAuditedEntityQueryable = getQueryable(
 					auditedEntityQueryable.getRootEntityName(),
 					sessionImplementor
 			);
 			final Queryable revisionInfoEntityQueryable = getQueryable( revisionInfoEntityName, sessionImplementor );
 
 			final String updateTableName;
 			if ( UnionSubclassEntityPersister.class.isInstance( rootProductionEntityQueryable ) ) {
 				// this is the condition causing all the problems in terms of the generated SQL UPDATE
 				// the problem being that we currently try to update the in-line view made up of the union query
 				//
 				// this is extremely hacky means to get the root table name for the union subclass style entities.
 				// hacky because it relies on internal behavior of UnionSubclassEntityPersister
 				// !!!!!! NOTICE - using subclass persister, not root !!!!!!
 				updateTableName = auditedEntityQueryable.getSubclassTableName( 0 );
 			}
 			else {
 				updateTableName = rootAuditedEntityQueryable.getTableName();
 			}
 
 
 			// first we need to flush the session in order to have the new audit data inserted
 			// todo: expose org.hibernate.internal.SessionImpl.autoFlushIfRequired via SessionImplementor
 			// for now, we duplicate some of that logic here
 			autoFlushIfRequired( sessionImplementor, rootAuditedEntityQueryable, revisionInfoEntityQueryable );
 
 			final Type revisionInfoIdType = sessionImplementor.getFactory()
 					.getEntityPersister( revisionInfoEntityName )
 					.getIdentifierType();
 			final String revEndColumnName = rootAuditedEntityQueryable.toColumns(
 					auditCfg.getAuditEntCfg()
 							.getRevisionEndFieldName()
 			)[0];
 
 			final boolean isRevisionEndTimestampEnabled = auditCfg.getAuditEntCfg().isRevisionEndTimestampEnabled();
 
 			// update audit_ent set REVEND = ? [, REVEND_TSTMP = ?] where (prod_ent_id) = ? and REV <> ? and REVEND is null
 			final Update update = new Update( dialect ).setTableName( updateTableName );
 			// set REVEND = ?
 			update.addColumn( revEndColumnName );
 			// set [, REVEND_TSTMP = ?]
 			if ( isRevisionEndTimestampEnabled ) {
 				update.addColumn(
 						rootAuditedEntityQueryable.toColumns(
 								auditCfg.getAuditEntCfg().getRevisionEndTimestampFieldName()
 						)[0]
 				);
 			}
 
 			// where (prod_ent_id) = ?
 			update.addPrimaryKeyColumns( rootProductionEntityQueryable.getIdentifierColumnNames() );
 			// where REV <> ?
 			update.addWhereColumn(
 					rootAuditedEntityQueryable.toColumns(
 							auditCfg.getAuditEntCfg().getRevisionNumberPath()
 					)[0],
 					"<> ?"
 			);
 			// where REVEND is null
 			update.addWhereColumn( revEndColumnName, " is null" );
 
 			// Now lets execute the sql...
 			final String updateSql = update.toStatementString();
 
 			int rowCount = session.doReturningWork(
 					new ReturningWork<Integer>() {
 						@Override
 						public Integer execute(Connection connection) throws SQLException {
 							PreparedStatement preparedStatement = sessionImplementor.getTransactionCoordinator()
 									.getJdbcCoordinator()
 									.getStatementPreparer()
 									.prepareStatement( updateSql );
 
 							try {
 								int index = 1;
 
 								// set REVEND = ?
 								final Number revisionNumber = auditCfg.getRevisionInfoNumberReader().getRevisionNumber(
 										revision
 								);
 								revisionInfoIdType.nullSafeSet(
 										preparedStatement,
 										revisionNumber,
 										index,
 										sessionImplementor
 								);
 								index += revisionInfoIdType.getColumnSpan( sessionImplementor.getFactory() );
 
 								// set [, REVEND_TSTMP = ?]
 								if ( isRevisionEndTimestampEnabled ) {
 									final Object revEndTimestampObj = revisionTimestampGetter.get( revision );
 									final Date revisionEndTimestamp = convertRevEndTimestampToDate( revEndTimestampObj );
 									final Type revEndTsType = rootAuditedEntityQueryable.getPropertyType(
 											auditCfg.getAuditEntCfg().getRevisionEndTimestampFieldName()
 									);
 									revEndTsType.nullSafeSet(
 											preparedStatement,
 											revisionEndTimestamp,
 											index,
 											sessionImplementor
 									);
 									index += revEndTsType.getColumnSpan( sessionImplementor.getFactory() );
 								}
 
 								// where (prod_ent_id) = ?
 								final Type idType = rootProductionEntityQueryable.getIdentifierType();
 								idType.nullSafeSet( preparedStatement, id, index, sessionImplementor );
 								index += idType.getColumnSpan( sessionImplementor.getFactory() );
 
 								// where REV <> ?
 								final Type revType = rootAuditedEntityQueryable.getPropertyType(
 										auditCfg.getAuditEntCfg().getRevisionNumberPath()
 								);
 								revType.nullSafeSet( preparedStatement, revisionNumber, index, sessionImplementor );
 
 								// where REVEND is null
 								// 		nothing to bind....
 
 								return sessionImplementor.getTransactionCoordinator()
 										.getJdbcCoordinator()
 										.getResultSetReturn()
 										.executeUpdate( preparedStatement );
 							}
 							finally {
 								sessionImplementor.getTransactionCoordinator().getJdbcCoordinator().release(
 										preparedStatement
 								);
 							}
 						}
 					}
 			);
 
 			if ( rowCount != 1 && ( !reuseEntityIdentifier || ( getRevisionType( auditCfg, data ) != RevisionType.ADD ) ) ) {
 				throw new RuntimeException(
 						"Cannot update previous revision for entity " + auditedEntityName + " and id " + id
 				);
 			}
 		}
 	}
 
 	private Queryable getQueryable(String entityName, SessionImplementor sessionImplementor) {
 		return (Queryable) sessionImplementor.getFactory().getEntityPersister( entityName );
 	}
 
 	private void autoFlushIfRequired(
 			SessionImplementor sessionImplementor,
 			Queryable auditedEntityQueryable,
 			Queryable revisionInfoEntityQueryable) {
 		final Set<String> querySpaces = new HashSet<String>();
 		querySpaces.add( auditedEntityQueryable.getTableName() );
 		querySpaces.add( revisionInfoEntityQueryable.getTableName() );
 		final AutoFlushEvent event = new AutoFlushEvent( querySpaces, (EventSource) sessionImplementor );
 		final Iterable<AutoFlushEventListener> listeners = sessionImplementor.getFactory().getServiceRegistry()
 				.getService( EventListenerRegistry.class )
 				.getEventListenerGroup( EventType.AUTO_FLUSH )
 				.listeners();
 		for ( AutoFlushEventListener listener : listeners ) {
 			listener.onAutoFlush( event );
 		}
 	}
 
 	@SuppressWarnings({"unchecked"})
 	public void performCollectionChange(
 			Session session, String entityName, String propertyName, AuditConfiguration auditCfg,
 			PersistentCollectionChangeData persistentCollectionChangeData, Object revision) {
 		final QueryBuilder qb = new QueryBuilder( persistentCollectionChangeData.getEntityName(), MIDDLE_ENTITY_ALIAS );
 
 		final String originalIdPropName = auditCfg.getAuditEntCfg().getOriginalIdPropName();
 		final Map<String, Object> originalId = (Map<String, Object>) persistentCollectionChangeData.getData().get(
 				originalIdPropName
 		);
 		final String revisionFieldName = auditCfg.getAuditEntCfg().getRevisionFieldName();
 		final String revisionTypePropName = auditCfg.getAuditEntCfg().getRevisionTypePropName();
 
 		// Adding a parameter for each id component, except the rev number and type.
 		for ( Map.Entry<String, Object> originalIdEntry : originalId.entrySet() ) {
 			if ( !revisionFieldName.equals( originalIdEntry.getKey() ) && !revisionTypePropName.equals( originalIdEntry.getKey() ) ) {
 				qb.getRootParameters().addWhereWithParam(
 						originalIdPropName + "." + originalIdEntry.getKey(),
 						true, "=", originalIdEntry.getValue()
 				);
 			}
 		}
 
 		final SessionFactoryImplementor sessionFactory = ((SessionImplementor) session).getFactory();
 		final Type propertyType = sessionFactory.getEntityPersister( entityName ).getPropertyType( propertyName );
 		if ( propertyType.isCollectionType() ) {
 			CollectionType collectionPropertyType = (CollectionType) propertyType;
 			// Handling collection of components.
 			if ( collectionPropertyType.getElementType( sessionFactory ) instanceof ComponentType ) {
 				// Adding restrictions to compare data outside of primary key.
 				for ( Map.Entry<String, Object> dataEntry : persistentCollectionChangeData.getData().entrySet() ) {
 					if ( !originalIdPropName.equals( dataEntry.getKey() ) ) {
 						qb.getRootParameters().addWhereWithParam( dataEntry.getKey(), true, "=", dataEntry.getValue() );
 					}
 				}
 			}
 		}
 
 		addEndRevisionNullRestriction( auditCfg, qb.getRootParameters() );
 
 		final List<Object> l = qb.toQuery( session ).setLockOptions( LockOptions.UPGRADE ).list();
 
 		// Update the last revision if one exists.
 		// HHH-5967: with collections, the same element can be added and removed multiple times. So even if it's an
 		// ADD, we may need to update the last revision.
 		if ( l.size() > 0 ) {
 			updateLastRevision(
 					session,
 					auditCfg,
 					l,
 					originalId,
 					persistentCollectionChangeData.getEntityName(),
 					revision
 			);
 		}
 
 		// Save the audit data
 		session.save( persistentCollectionChangeData.getEntityName(), persistentCollectionChangeData.getData() );
 		sessionCacheCleaner.scheduleAuditDataRemoval( session, persistentCollectionChangeData.getData() );
 	}
 
 	private void addEndRevisionNullRestriction(AuditConfiguration auditCfg, Parameters rootParameters) {
 		rootParameters.addWhere( auditCfg.getAuditEntCfg().getRevisionEndFieldName(), true, "is", "null", false );
 	}
 
 	public void addEntityAtRevisionRestriction(
 			GlobalConfiguration globalCfg, QueryBuilder rootQueryBuilder,
 			Parameters parameters, String revisionProperty, String revisionEndProperty, boolean addAlias,
 			MiddleIdData idData, String revisionPropertyPath, String originalIdPropertyName,
 			String alias1, String alias2, boolean inclusive) {
 		addRevisionRestriction( parameters, revisionProperty, revisionEndProperty, addAlias, inclusive );
 	}
 
 	public void addAssociationAtRevisionRestriction(
 			QueryBuilder rootQueryBuilder, Parameters parameters, String revisionProperty,
 			String revisionEndProperty, boolean addAlias, MiddleIdData referencingIdData,
 			String versionsMiddleEntityName, String eeOriginalIdPropertyPath, String revisionPropertyPath,
 			String originalIdPropertyName, String alias1, boolean inclusive, MiddleComponentData... componentDatas) {
 		addRevisionRestriction( parameters, revisionProperty, revisionEndProperty, addAlias, inclusive );
 	}
 
 	public void setRevisionTimestampGetter(Getter revisionTimestampGetter) {
 		this.revisionTimestampGetter = revisionTimestampGetter;
 	}
 
 	private void addRevisionRestriction(
 			Parameters rootParameters, String revisionProperty, String revisionEndProperty,
 			boolean addAlias, boolean inclusive) {
 		// e.revision <= _revision and (e.endRevision > _revision or e.endRevision is null)
 		Parameters subParm = rootParameters.addSubParameters( "or" );
 		rootParameters.addWhereWithNamedParam( revisionProperty, addAlias, inclusive ? "<=" : "<", REVISION_PARAMETER );
 		subParm.addWhereWithNamedParam(
 				revisionEndProperty + ".id",
 				addAlias,
 				inclusive ? ">" : ">=",
 				REVISION_PARAMETER
 		);
 		subParm.addWhere( revisionEndProperty, addAlias, "is", "null", false );
 	}
 
 	@SuppressWarnings({"unchecked"})
 	private RevisionType getRevisionType(AuditConfiguration auditCfg, Object data) {
 		return (RevisionType) ((Map<String, Object>) data).get( auditCfg.getAuditEntCfg().getRevisionTypePropName() );
 	}
 
 	@SuppressWarnings({"unchecked"})
 	private void updateLastRevision(
 			Session session, AuditConfiguration auditCfg, List<Object> l,
 			Object id, String auditedEntityName, Object revision) {
 		// There should be one entry
 		if ( l.size() == 1 ) {
 			// Setting the end revision to be the current rev
 			Object previousData = l.get( 0 );
 			String revisionEndFieldName = auditCfg.getAuditEntCfg().getRevisionEndFieldName();
 			((Map<String, Object>) previousData).put( revisionEndFieldName, revision );
 
 			if ( auditCfg.getAuditEntCfg().isRevisionEndTimestampEnabled() ) {
 				// Determine the value of the revision property annotated with @RevisionTimestamp
 				String revEndTimestampFieldName = auditCfg.getAuditEntCfg().getRevisionEndTimestampFieldName();
 				Object revEndTimestampObj = this.revisionTimestampGetter.get( revision );
 				Date revisionEndTimestamp = convertRevEndTimestampToDate( revEndTimestampObj );
 
 				// Setting the end revision timestamp
 				((Map<String, Object>) previousData).put( revEndTimestampFieldName, revisionEndTimestamp );
 			}
 
 			// Saving the previous version
 			session.save( auditedEntityName, previousData );
 			sessionCacheCleaner.scheduleAuditDataRemoval( session, previousData );
 		}
 		else {
 			throw new RuntimeException( "Cannot find previous revision for entity " + auditedEntityName + " and id " + id );
 		}
 	}
 
 	private Date convertRevEndTimestampToDate(Object revEndTimestampObj) {
 		// convert to a java.util.Date
 		if ( revEndTimestampObj instanceof Date ) {
 			return (Date) revEndTimestampObj;
 		}
 		return new Date( (Long) revEndTimestampObj );
 	}
 }
 
diff --git a/hibernate-osgi/src/main/java/org/hibernate/osgi/OsgiServiceUtil.java b/hibernate-osgi/src/main/java/org/hibernate/osgi/OsgiServiceUtil.java
index 61b3695dcc..e88e2af2fb 100644
--- a/hibernate-osgi/src/main/java/org/hibernate/osgi/OsgiServiceUtil.java
+++ b/hibernate-osgi/src/main/java/org/hibernate/osgi/OsgiServiceUtil.java
@@ -1,82 +1,85 @@
 /* 
  * Hibernate, Relational Persistence for Idiomatic Java
  * 
  * JBoss, Home of Professional Open Source
  * Copyright 2013 Red Hat Inc. and/or its affiliates and other contributors
  * as indicated by the @authors tag. All rights reserved.
  * See the copyright.txt in the distribution for a
  * full listing of individual contributors.
  *
  * This copyrighted material is made available to anyone wishing to use,
  * modify, copy, or redistribute it subject to the terms and conditions
  * of the GNU Lesser General Public License, v. 2.1.
  * This program is distributed in the hope that it will be useful, but WITHOUT A
  * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
  * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
  * You should have received a copy of the GNU Lesser General Public License,
  * v.2.1 along with this distribution; if not, write to the Free Software
  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
  * MA  02110-1301, USA.
  */
 package org.hibernate.osgi;
 
 import java.lang.reflect.Array;
 
 import org.hibernate.internal.CoreLogging;
 import org.hibernate.internal.CoreMessageLogger;
 import org.osgi.framework.BundleContext;
 import org.osgi.util.tracker.ServiceTracker;
 
 /**
  * Utilities for dealing with OSGi environments
  *
  * @author Brett Meyer
  */
-public class OsgiServiceUtil {
+public final class OsgiServiceUtil {
 	private static final CoreMessageLogger LOG = CoreLogging.messageLogger( OsgiServiceUtil.class );
 
 	/**
 	 * Locate all implementors of the given service contract in the given OSGi buindle context.  Utilizes
 	 * {@link ServiceTracker} (best practice, automatically handles a lot of boilerplate and error conditions).
 	 *
 	 * @param contract The service contract for which to locate implementors
 	 * @param context The OSGi bundle context
 	 * @param T[] The Java type of the service to locate
 	 *
 	 * @return All know implementors
 	 */
 	public static <T> T[] getServiceImpls(Class<T> contract, BundleContext bundleContext) {
 		final ServiceTracker<T, T> serviceTracker = new ServiceTracker<T, T>( bundleContext, contract, null );
 		try {
 			T[] services = (T[]) serviceTracker.getServices();
 			if (services != null) {
 				return services;
 			}
 		}
 		catch ( Exception e ) {
 			LOG.unableToDiscoverOsgiService( contract.getName(), e );
 		}
 		return (T[]) Array.newInstance(contract, 0);
 	}
 
 	/**
 	 * Locate the single implementor of the given service contract in the given OSGi buindle context.  Utilizes
 	 * {@link ServiceTracker#waitForService(long)}
 	 *
 	 * @param contract The service contract for which to locate implementors
 	 * @param context The OSGi bundle context
 	 * @param T[] The Java type of the service to locate
 	 *
 	 * @return All know implementors
 	 */
 	public static <T> T getServiceImpl(Class<T> contract, BundleContext bundleContext) {
 		final ServiceTracker<T, T> serviceTracker = new ServiceTracker<T, T>( bundleContext, contract, null );
 		try {
 			return (T) serviceTracker.waitForService( 1000 );
 		}
 		catch ( Exception e ) {
 			LOG.unableToDiscoverOsgiService( contract.getName(), e );
 			return null;
 		}
 	}
+
+	private OsgiServiceUtil() {
+	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/FailureExpected.java b/hibernate-testing/src/main/java/org/hibernate/testing/FailureExpected.java
index 188b9610e9..eed621a4ce 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/FailureExpected.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/FailureExpected.java
@@ -1,51 +1,51 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing;
 
 import java.lang.annotation.ElementType;
 import java.lang.annotation.Retention;
 import java.lang.annotation.RetentionPolicy;
 import java.lang.annotation.Target;
 
 /**
  * Annotation used to mark a test as an expected failure.
  *
  * @author Hardy Ferentschik
  * @author Steve Ebersole
  */
 @Retention(RetentionPolicy.RUNTIME)
 @Target({ ElementType.METHOD, ElementType.TYPE })
 public @interface FailureExpected {
 	/**
 	 * The key of a JIRA issue which covers this expected failure.
 	 * @return The jira issue key
 	 */
 	String jiraKey();
 
 	/**
 	 * A message explaining the reason for the expected failure.  Optional.
 	 * @return The reason
 	 */
 	String message() default "";
-}
\ No newline at end of file
+}
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/RequiresDialectFeature.java b/hibernate-testing/src/main/java/org/hibernate/testing/RequiresDialectFeature.java
index 841dcf376b..8af33a4205 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/RequiresDialectFeature.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/RequiresDialectFeature.java
@@ -1,58 +1,58 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing;
 
 import java.lang.annotation.ElementType;
 import java.lang.annotation.Retention;
 import java.lang.annotation.RetentionPolicy;
 import java.lang.annotation.Target;
 
 /**
  * Annotation used to indicate that a test should be run only when the current dialect supports the
  * specified feature.
  *
  * @author Hardy Ferentschik
  */
 @Target({ ElementType.METHOD, ElementType.TYPE })
 @Retention(RetentionPolicy.RUNTIME)
 public @interface RequiresDialectFeature {
 	/**
 	 * @return Class which checks the necessary dialect feature
 	 */
 	Class<? extends DialectCheck>[] value();
 
 	/**
 	 * Comment describing the reason why the feature is required.
 	 *
 	 * @return The comment
 	 */
 	String comment() default "";
 
 	/**
 	 * The key of a JIRA issue which relates this this feature requirement.
 	 *
 	 * @return The jira issue key
 	 */
 	String jiraKey() default "";
-}
\ No newline at end of file
+}
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/ServiceRegistryBuilder.java b/hibernate-testing/src/main/java/org/hibernate/testing/ServiceRegistryBuilder.java
index bab28e4d33..27705fa129 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/ServiceRegistryBuilder.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/ServiceRegistryBuilder.java
@@ -1,50 +1,53 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing;
 
 import java.util.Map;
 
 import org.hibernate.boot.registry.StandardServiceRegistryBuilder;
 import org.hibernate.cfg.Environment;
 import org.hibernate.service.ServiceRegistry;
 import org.hibernate.boot.registry.internal.StandardServiceRegistryImpl;
 
 /**
  * @author Steve Ebersole
  */
-public class ServiceRegistryBuilder {
+public final class ServiceRegistryBuilder {
+	private ServiceRegistryBuilder() {
+	}
+
 	public static StandardServiceRegistryImpl buildServiceRegistry() {
 		return buildServiceRegistry( Environment.getProperties() );
 	}
 
 	public static StandardServiceRegistryImpl buildServiceRegistry(Map serviceRegistryConfig) {
 		return (StandardServiceRegistryImpl) new StandardServiceRegistryBuilder()
 				.applySettings( serviceRegistryConfig )
 				.build();
 	}
 
 	public static void destroy(ServiceRegistry serviceRegistry) {
 		( (StandardServiceRegistryImpl) serviceRegistry ).destroy();
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/SkipForDialect.java b/hibernate-testing/src/main/java/org/hibernate/testing/SkipForDialect.java
index 428185761e..172d7540e7 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/SkipForDialect.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/SkipForDialect.java
@@ -1,70 +1,70 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing;
 
 import java.lang.annotation.ElementType;
 import java.lang.annotation.Retention;
 import java.lang.annotation.RetentionPolicy;
 import java.lang.annotation.Target;
 
 import org.hibernate.dialect.Dialect;
 
 /**
  * Annotation used to indicate that a test should be skipped when run against the
  * indicated dialects.
  *
  * @see SkipForDialects
  *
  * @author Hardy Ferentschik
  * @author Steve Ebersole
  */
 @Retention(RetentionPolicy.RUNTIME)
 @Target({ ElementType.METHOD, ElementType.TYPE })
 public @interface SkipForDialect {
 	/**
 	 * The dialects against which to skip the test
 	 * @return The dialects
 	 */
 	Class<? extends Dialect>[] value();
 
 	/**
 	 * Used to indicate if the dialects should be matched strictly (classes equal) or
 	 * non-strictly (instanceof).
 	 * @return Should strict matching be used?
 	 */
 	boolean strictMatching() default false;
 
 	/**
 	 * Comment describing the reason for the skip.
 	 * @return The comment
 	 */
 	String comment() default "";
 
 	/**
 	 * The key of a JIRA issue which covers the reason for this skip.  Eventually we should make this
 	 * a requirement.
 	 * @return The jira issue key
 	 */
 	String jiraKey() default "";
-}
\ No newline at end of file
+}
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/SkipLog.java b/hibernate-testing/src/main/java/org/hibernate/testing/SkipLog.java
index 8c44e40de5..caa42cdf90 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/SkipLog.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/SkipLog.java
@@ -1,43 +1,46 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing;
 
 import org.jboss.logging.Logger;
 
 /**
  * Well-known-location lookup for the test-skip log...
  *
  * @author Steve Ebersole
  */
-public class SkipLog {
+public final class SkipLog {
 	private static final Logger log = Logger.getLogger( SkipLog.class );
 
 	public static void reportSkip(String message) {
 		log.info( "*** skipping test - " + message, new Exception() );
 	}
 
 	public static void reportSkip(String reason, String testDescription) {
 		reportSkip( testDescription + " : " + reason  );
 	}
+
+	private SkipLog() {
+	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/byteman/BytemanHelper.java b/hibernate-testing/src/main/java/org/hibernate/testing/byteman/BytemanHelper.java
index 4c77cfd16e..a86d6379da 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/byteman/BytemanHelper.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/byteman/BytemanHelper.java
@@ -1,69 +1,69 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2012, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.byteman;
 
 import java.util.concurrent.atomic.AtomicInteger;
 
 import org.jboss.byteman.rule.Rule;
 import org.jboss.byteman.rule.helper.Helper;
 import org.jboss.logging.Logger;
 
 /**
  * @author Sanne Grinovero <sanne@hibernate.org> (C) 2011 Red Hat Inc.
  * @author Hardy Ferentschik
  */
 public class BytemanHelper extends Helper {
 	private static final Logger log = Logger.getLogger( BytemanHelper.class );
 
-	public static final AtomicInteger counter = new AtomicInteger();
+	public static final AtomicInteger COUNTER = new AtomicInteger();
 
 	protected BytemanHelper(Rule rule) {
 		super( rule );
 	}
 
 	public void sleepASecond() {
 		try {
 			log.info( "Byteman rule triggered: sleeping a second" );
 			Thread.sleep( 1000 );
 		}
 		catch ( InterruptedException e ) {
 			Thread.currentThread().interrupt();
 			log.error( "unexpected interruption", e );
 		}
 	}
 
 	public void throwNPE(String message) {
 		//Needed because of Bug BYTEMAN-173: can't simply inject a NPE from the rule
 		throw new NullPointerException( message );
 	}
 
 	public void countInvocation() {
 		log.debug( "Increment call count" );
-		counter.incrementAndGet();
+		COUNTER.incrementAndGet();
 	}
 
 	public static int getAndResetInvocationCount() {
-		return counter.getAndSet( 0 );
+		return COUNTER.getAndSet( 0 );
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/env/TestingDatabaseInfo.java b/hibernate-testing/src/main/java/org/hibernate/testing/env/TestingDatabaseInfo.java
index 7ce98e701f..db00f53317 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/env/TestingDatabaseInfo.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/env/TestingDatabaseInfo.java
@@ -1,50 +1,53 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2010, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.env;
 
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.dialect.Dialect;
 import org.hibernate.dialect.H2Dialect;
 
 /**
  * @author Steve Ebersole
  */
-public class TestingDatabaseInfo {
+public final class TestingDatabaseInfo {
 	public static volatile String DRIVER = "org.h2.Driver";
 	public static volatile String URL = "jdbc:h2:mem:db1;DB_CLOSE_DELAY=-1;MVCC=TRUE";
 	public static volatile String USER = "sa";
 	public static volatile String PASS = "";
 
 	public static final Dialect DIALECT = new H2Dialect();
 
 	public static Configuration buildBaseConfiguration() {
 		return new Configuration()
 				.setProperty( Environment.DRIVER, DRIVER )
 				.setProperty( Environment.URL, URL )
 				.setProperty( Environment.USER, USER )
 				.setProperty( Environment.PASS, PASS )
 				.setProperty( Environment.DIALECT, DIALECT.getClass().getName() );
 	}
+
+	private TestingDatabaseInfo() {
+	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/jta/TestingJtaBootstrap.java b/hibernate-testing/src/main/java/org/hibernate/testing/jta/TestingJtaBootstrap.java
index 8f77500c19..b5a2e89d73 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/jta/TestingJtaBootstrap.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/jta/TestingJtaBootstrap.java
@@ -1,44 +1,46 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.jta;
 
 import java.util.Map;
 
 import org.hibernate.cfg.AvailableSettings;
 import org.hibernate.cfg.Environment;
 
 /**
  * @author Steve Ebersole
  */
-public class TestingJtaBootstrap {
+public final class TestingJtaBootstrap {
 	public static final TestingJtaBootstrap INSTANCE = new TestingJtaBootstrap();
 
 	@SuppressWarnings("unchecked")
 	public static void prepare(Map configValues) {
 		configValues.put( AvailableSettings.JTA_PLATFORM, TestingJtaPlatformImpl.INSTANCE );
 		configValues.put( Environment.CONNECTION_PROVIDER, JtaAwareConnectionProviderImpl.class.getName() );
 		configValues.put( "javax.persistence.transactionType", "JTA" );
 	}
 
+	private TestingJtaBootstrap() {
+	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/CustomRunner.java b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/CustomRunner.java
index 2e3b8a6ac0..917ec58de2 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/CustomRunner.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/CustomRunner.java
@@ -1,355 +1,355 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.junit4;
 
 import java.lang.annotation.Annotation;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Comparator;
 import java.util.List;
 
 import org.jboss.logging.Logger;
 import org.junit.BeforeClass;
 import org.junit.Ignore;
 import org.junit.Test;
 import org.junit.runner.manipulation.NoTestsRemainException;
 import org.junit.runner.notification.RunNotifier;
 import org.junit.runners.BlockJUnit4ClassRunner;
 import org.junit.runners.model.FrameworkMethod;
 import org.junit.runners.model.InitializationError;
 import org.junit.runners.model.Statement;
 
 import org.hibernate.dialect.Dialect;
 import org.hibernate.internal.util.StringHelper;
 import org.hibernate.internal.util.collections.CollectionHelper;
 import org.hibernate.testing.DialectCheck;
 import org.hibernate.testing.FailureExpected;
 import org.hibernate.testing.RequiresDialect;
 import org.hibernate.testing.RequiresDialectFeature;
 import org.hibernate.testing.RequiresDialects;
 import org.hibernate.testing.Skip;
 import org.hibernate.testing.SkipForDialect;
 import org.hibernate.testing.SkipForDialects;
 
 /**
  * The Hibernate-specific {@link org.junit.runner.Runner} implementation which layers {@link ExtendedFrameworkMethod}
  * support on top of the standard JUnit {@link FrameworkMethod} for extra information after checking to make sure the
  * test should be run.
  *
  * @author Steve Ebersole
  */
 public class CustomRunner extends BlockJUnit4ClassRunner {
 	private static final Logger log = Logger.getLogger( CustomRunner.class );
 
 	private TestClassMetadata testClassMetadata;
 
 	public CustomRunner(Class<?> clazz) throws InitializationError, NoTestsRemainException {
 		super( clazz );
 	}
 
 	@Override
 	protected void collectInitializationErrors(List<Throwable> errors) {
 		super.collectInitializationErrors( errors );
 		this.testClassMetadata = new TestClassMetadata( getTestClass().getJavaClass() );
 		testClassMetadata.validate( errors );
 	}
 
 	public TestClassMetadata getTestClassMetadata() {
 		return testClassMetadata;
 	}
 
-    private Boolean isAllTestsIgnored = null;
+    private Boolean isAllTestsIgnored;
 
     private boolean isAllTestsIgnored() {
         if ( isAllTestsIgnored == null ) {
             if ( computeTestMethods().isEmpty() ) {
                 isAllTestsIgnored = true;
             }
             else {
                 isAllTestsIgnored = true;
                 for ( FrameworkMethod method : computeTestMethods() ) {
                     Ignore ignore = method.getAnnotation( Ignore.class );
                     if ( ignore == null ) {
                         isAllTestsIgnored = false;
                         break;
                     }
                 }
             }
         }
         return isAllTestsIgnored;
     }
 
     @Override
     protected Statement withBeforeClasses(Statement statement) {
         if ( isAllTestsIgnored() ) {
             return super.withBeforeClasses( statement );
         }
         return new BeforeClassCallbackHandler(
                 this,
                 super.withBeforeClasses( statement )
         );
     }
 
 	@Override
 	protected Statement withAfterClasses(Statement statement) {
         if ( isAllTestsIgnored() ) {
             return super.withAfterClasses( statement );
         }
 		return new AfterClassCallbackHandler(
 				this,
 				super.withAfterClasses( statement )
 		);
 	}
 
 	/**
 	 * {@inheritDoc}
 	 *
 	 * @see org.junit.runners.ParentRunner#classBlock(org.junit.runner.notification.RunNotifier)
 	 */
 	@Override
 	protected Statement classBlock( RunNotifier notifier ) {
 		log.info( BeforeClass.class.getSimpleName() + ": " + getName() );
 
 		return super.classBlock( notifier );
 	}
 
 	@Override
 	protected Statement methodBlock(FrameworkMethod method) {
 		log.info( Test.class.getSimpleName() + ": " + method.getName() );
 
 		final Statement originalMethodBlock = super.methodBlock( method );
 		final ExtendedFrameworkMethod extendedFrameworkMethod = (ExtendedFrameworkMethod) method;
 		return new FailureExpectedHandler( originalMethodBlock, testClassMetadata, extendedFrameworkMethod, testInstance );
 	}
 
 	private Object testInstance;
 
 	protected Object getTestInstance() throws Exception {
 		if ( testInstance == null ) {
 			testInstance = super.createTest();
 		}
 		return testInstance;
 	}
 
 	@Override
 	protected Object createTest() throws Exception {
 		return getTestInstance();
 	}
 
 	private List<FrameworkMethod> computedTestMethods;
 
 	@Override
 	protected List<FrameworkMethod> computeTestMethods() {
 		if ( computedTestMethods == null ) {
 			computedTestMethods = doComputation();
 			sortMethods(computedTestMethods);
 		}
 		return computedTestMethods;
 	}
 
 	protected void sortMethods(List<FrameworkMethod> computedTestMethods) {
 		if ( CollectionHelper.isEmpty( computedTestMethods ) ) {
 			return;
 		}
 		Collections.sort( computedTestMethods, new Comparator<FrameworkMethod>() {
 			@Override
 			public int compare(FrameworkMethod o1, FrameworkMethod o2) {
 				return o1.getName().compareTo( o2.getName() );
 			}
 		} );
 	}
 
 	protected List<FrameworkMethod> doComputation() {
         // Next, get all the test methods as understood by JUnit
         final List<FrameworkMethod> methods = super.computeTestMethods();
 
         // Now process that full list of test methods and build our custom result
         final List<FrameworkMethod> result = new ArrayList<FrameworkMethod>();
 		final boolean doValidation = Boolean.getBoolean( Helper.VALIDATE_FAILURE_EXPECTED );
 		int testCount = 0;
 
 		Ignore virtualIgnore;
 
 		for ( FrameworkMethod frameworkMethod : methods ) {
 			// potentially ignore based on expected failure
             final FailureExpected failureExpected = Helper.locateAnnotation( FailureExpected.class, frameworkMethod, getTestClass() );
 			if ( failureExpected != null && !doValidation ) {
 				virtualIgnore = new IgnoreImpl( Helper.extractIgnoreMessage( failureExpected, frameworkMethod ) );
 			}
 			else {
 				virtualIgnore = convertSkipToIgnore( frameworkMethod );
 			}
 
 			testCount++;
 			log.trace( "adding test " + Helper.extractTestName( frameworkMethod ) + " [#" + testCount + "]" );
 			result.add( new ExtendedFrameworkMethod( frameworkMethod, virtualIgnore, failureExpected ) );
 		}
 		return result;
 	}
 
 	@SuppressWarnings( {"ClassExplicitlyAnnotation"})
 	public static class IgnoreImpl implements Ignore {
 		private final String value;
 
 		public IgnoreImpl(String value) {
 			this.value = value;
 		}
 
 		@Override
 		public String value() {
 			return value;
 		}
 
 		@Override
 		public Class<? extends Annotation> annotationType() {
 			return Ignore.class;
 		}
 	}
 
 	private static Dialect dialect = determineDialect();
 
 	private static Dialect determineDialect() {
 		try {
 			return Dialect.getDialect();
 		}
 		catch( Exception e ) {
 			return new Dialect() {
 			};
 		}
 	}
 
 	protected Ignore convertSkipToIgnore(FrameworkMethod frameworkMethod) {
 		// @Skip
 		Skip skip = Helper.locateAnnotation( Skip.class, frameworkMethod, getTestClass() );
 		if ( skip != null ) {
 			if ( isMatch( skip.condition() ) ) {
 				return buildIgnore( skip );
 			}
 		}
 
 		// @SkipForDialects & @SkipForDialect
 		for ( SkipForDialect skipForDialectAnn : Helper.collectAnnotations(
 				SkipForDialect.class, SkipForDialects.class, frameworkMethod, getTestClass()
 		) ) {
 			for ( Class<? extends Dialect> dialectClass : skipForDialectAnn.value() ) {
 				if ( skipForDialectAnn.strictMatching() ) {
 					if ( dialectClass.equals( dialect.getClass() ) ) {
 						return buildIgnore( skipForDialectAnn );
 					}
 				}
 				else {
 					if ( dialectClass.isInstance( dialect ) ) {
 						return buildIgnore( skipForDialectAnn );
 					}
 				}
 			}
 		}
 
 		// @RequiresDialects & @RequiresDialect
 		for ( RequiresDialect requiresDialectAnn : Helper.collectAnnotations(
 				RequiresDialect.class, RequiresDialects.class, frameworkMethod, getTestClass()
 		) ) {
 			boolean foundMatch = false;
 			for ( Class<? extends Dialect> dialectClass : requiresDialectAnn.value() ) {
 				foundMatch = requiresDialectAnn.strictMatching()
 						? dialectClass.equals( dialect.getClass() )
 						: dialectClass.isInstance( dialect );
 				if ( foundMatch ) {
 					break;
 				}
 			}
 			if ( !foundMatch ) {
 				return buildIgnore( requiresDialectAnn );
 			}
 		}
 
 		// @RequiresDialectFeature
 		RequiresDialectFeature requiresDialectFeatureAnn = Helper.locateAnnotation( RequiresDialectFeature.class, frameworkMethod, getTestClass() );
 		if ( requiresDialectFeatureAnn != null ) {
 			try {
 				boolean foundMatch = false;
 				for ( Class<? extends DialectCheck> checkClass : requiresDialectFeatureAnn.value() ) {
 					foundMatch = checkClass.newInstance().isMatch( dialect );
 					if ( !foundMatch ) {
 						return buildIgnore( requiresDialectFeatureAnn );
 					}
 				}
 			}
 			catch (RuntimeException e) {
 				throw e;
 			}
 			catch (Exception e) {
 				throw new RuntimeException( "Unable to instantiate DialectCheck", e );
 			}
 		}
 
 		return null;
 	}
 
 	private Ignore buildIgnore(Skip skip) {
 		return new IgnoreImpl( "@Skip : " + skip.message() );
 	}
 
 	private Ignore buildIgnore(SkipForDialect skip) {
 		return buildIgnore( "@SkipForDialect match", skip.comment(), skip.jiraKey() );
 	}
 
 	private Ignore buildIgnore(String reason, String comment, String jiraKey) {
 		StringBuilder buffer = new StringBuilder( reason );
 		if ( StringHelper.isNotEmpty( comment ) ) {
 			buffer.append( "; " ).append( comment );
 		}
 
 		if ( StringHelper.isNotEmpty( jiraKey ) ) {
 			buffer.append( " (" ).append( jiraKey ).append( ')' );
 		}
 
 		return new IgnoreImpl( buffer.toString() );
 	}
 
 	private Ignore buildIgnore(RequiresDialect requiresDialect) {
 		return buildIgnore( "@RequiresDialect non-match", requiresDialect.comment(), requiresDialect.jiraKey() );
 	}
 
 	private Ignore buildIgnore(RequiresDialectFeature requiresDialectFeature) {
 		return buildIgnore( "@RequiresDialectFeature non-match", requiresDialectFeature.comment(), requiresDialectFeature.jiraKey() );
 	}
 
 	private boolean isMatch(Class<? extends Skip.Matcher> condition) {
 		try {
 			Skip.Matcher matcher = condition.newInstance();
 			return matcher.isMatch();
 		}
 		catch (Exception e) {
 			throw new MatcherInstantiationException( condition, e );
 		}
 	}
 
 	private static class MatcherInstantiationException extends RuntimeException {
 		private MatcherInstantiationException(Class<? extends Skip.Matcher> matcherClass, Throwable cause) {
 			super( "Unable to instantiate specified Matcher [" + matcherClass.getName(), cause );
 		}
 	}
 
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/ExtraAssertions.java b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/ExtraAssertions.java
index 7866276c2d..997143b850 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/ExtraAssertions.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/ExtraAssertions.java
@@ -1,102 +1,105 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.junit4;
 
 import java.lang.reflect.Field;
 import java.lang.reflect.Modifier;
 import java.sql.Types;
 import java.util.HashMap;
 import java.util.Map;
 
 import org.junit.Assert;
 
 import static org.junit.Assert.fail;
 
 /**
  * @author Steve Ebersole
  */
-public class ExtraAssertions {
+public final class ExtraAssertions {
+	private ExtraAssertions() {
+	}
+
 	public static void assertClassAssignability(Class expected, Class actual) {
 		if ( ! expected.isAssignableFrom( actual ) ) {
 			Assert.fail(
 					"Expected class [" + expected.getName() + "] was not assignable from actual [" +
 							actual.getName() + "]"
 			);
 		}
 	}
 
 	@SuppressWarnings("unchecked")
 	public static <T> T assertTyping(Class<T> expectedType, Object value) {
 		if ( ! expectedType.isInstance( value ) ) {
 			Assert.fail(
 					String.format(
 							"Expecting value of type [%s], but found [%s]",
 							expectedType.getName(),
 							value == null ? "<null>" : value
 					)
 			);
 		}
 		return (T) value;
 	}
 
 	public static void assertJdbcTypeCode(int expected, int actual) {
 		if ( expected != actual ) {
 			final String message = String.format(
 					"JDBC type codes did not match...\n" +
 							"Expected: %s (%s)\n" +
 							"Actual  : %s (%s)",
 					jdbcTypeCodeMap().get( expected ),
 					expected,
 					jdbcTypeCodeMap().get( actual ),
 					actual
 			);
 			fail( message );
 		}
 	}
 
 	private static Map<Integer,String> jdbcTypeCodeMap;
 
 	private static synchronized Map<Integer,String> jdbcTypeCodeMap() {
 		if ( jdbcTypeCodeMap == null ) {
 			jdbcTypeCodeMap = generateJdbcTypeCache();
 		}
 		return jdbcTypeCodeMap;
 	}
 
 	private static Map generateJdbcTypeCache() {
 		final Field[] fields = Types.class.getFields();
 		Map cache = new HashMap( (int)( fields.length * .75 ) + 1 );
 		for ( int i = 0; i < fields.length; i++ ) {
 			final Field field = fields[i];
 			if ( Modifier.isStatic( field.getModifiers() ) ) {
 				try {
 					cache.put( field.get( null ), field.getName() );
 				}
 				catch ( Throwable ignore ) {
 				}
 			}
 		}
 		return cache;
 	}
 }
diff --git a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/Helper.java b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/Helper.java
index 3a9dbdd1b8..bfad1fd5f0 100644
--- a/hibernate-testing/src/main/java/org/hibernate/testing/junit4/Helper.java
+++ b/hibernate-testing/src/main/java/org/hibernate/testing/junit4/Helper.java
@@ -1,160 +1,162 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2011, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.testing.junit4;
 
 import java.lang.annotation.Annotation;
 import java.lang.reflect.Method;
 import java.util.Arrays;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Map;
 
 import org.junit.runners.model.FrameworkMethod;
 import org.junit.runners.model.TestClass;
 
 import org.hibernate.cfg.Configuration;
 import org.hibernate.cfg.Environment;
 import org.hibernate.testing.FailureExpected;
 import org.hibernate.testing.SkipForDialect;
 import org.hibernate.testing.SkipForDialects;
 
 /**
  * Centralized utility functionality
  *
  * @author Steve Ebersole
  */
-public class Helper {
+public final class Helper {
 	public static final String VALIDATE_FAILURE_EXPECTED = "hibernate.test.validatefailureexpected";
 
+	private Helper() {
+	}
 
 	/**
 	 * Standard string content checking.
 	 *
 	 * @param string The string to check
 	 * @return Are its content empty or the reference null?
 	 */
 	public static boolean isNotEmpty(String string) {
 		return string != null && string.length() > 0;
 	}
 
 	/**
 	 * Extract a nice test name representation for display
 	 *
 	 * @param frameworkMethod The test method.
 	 * @return The display representation
 	 */
 	public static String extractTestName(FrameworkMethod frameworkMethod) {
 		return frameworkMethod.getMethod().getDeclaringClass().getName() + '#' + frameworkMethod.getName();
 	}
 
 	/**
 	 * Extract a nice method name representation for display
 	 *
 	 * @param method The method.
 	 * @return The display representation
 	 */
 	public static String extractMethodName(Method method) {
 		return method.getDeclaringClass().getName() + "#" + method.getName();
 	}
 
 	public static <T extends Annotation> T locateAnnotation(
 			Class<T> annotationClass,
 			FrameworkMethod frameworkMethod,
 			TestClass testClass) {
 		T annotation = frameworkMethod.getAnnotation( annotationClass );
 		if ( annotation == null ) {
 			annotation = testClass.getJavaClass().getAnnotation( annotationClass );
 		}
 		return annotation;
 	}
 
 	/**
 	 * @param singularAnnotationClass Singular annotation class (e.g. {@link SkipForDialect}).
 	 * @param pluralAnnotationClass Plural annotation class (e.g. {@link SkipForDialects}). Assuming that the only
 	 * 								declared method is an array of singular annotations.
 	 * @param frameworkMethod Test method.
 	 * @param testClass Test class.
 	 * @param <S> Singular annotation type.
 	 * @param <P> Plural annotation type.
 	 * @return Collection of all singular annotations or an empty list.
 	 */
 	@SuppressWarnings("unchecked")
 	public static <S extends Annotation, P extends Annotation> List<S> collectAnnotations(Class<S> singularAnnotationClass,
 																						  Class<P> pluralAnnotationClass,
 																						  FrameworkMethod frameworkMethod,
 																						  TestClass testClass) {
 		final List<S> collection = new LinkedList<S>();
 		final S singularAnn = Helper.locateAnnotation( singularAnnotationClass, frameworkMethod, testClass );
 		if ( singularAnn != null ) {
 			collection.add( singularAnn );
 		}
 		final P pluralAnn = Helper.locateAnnotation( pluralAnnotationClass, frameworkMethod, testClass );
 		if ( pluralAnn != null ) {
 			try {
 				collection.addAll( Arrays.asList( (S[]) pluralAnnotationClass.getDeclaredMethods()[0].invoke(pluralAnn) ) );
 			}
 			catch ( Exception e ) {
 				throw new RuntimeException( e );
 			}
 		}
 		return collection;
 	}
 
 	public static String extractMessage(FailureExpected failureExpected) {
 		StringBuilder buffer = new StringBuilder();
 		buffer.append( '(' ).append( failureExpected.jiraKey() ).append( ')' );
 		if ( isNotEmpty( failureExpected.message() ) ) {
 			buffer.append( " : " ).append( failureExpected.message() );
 		}
 		return buffer.toString();
 	}
 
 	public static String extractIgnoreMessage(FailureExpected failureExpected, FrameworkMethod frameworkMethod) {
 		return new StringBuilder( "Ignoring test [" )
 				.append( Helper.extractTestName( frameworkMethod ) )
 				.append( "] due to @FailureExpected - " )
 				.append( extractMessage( failureExpected ) )
 				.toString();
 	}
 
 	/**
 	 * @see #createH2Schema(String, Map)
 	 */
 	public static void createH2Schema(String schemaName, Configuration cfg) {
 		createH2Schema( schemaName, cfg.getProperties() );
 	}
 
 	/**
 	 * Create additional H2 schema.
 	 *
 	 * @param schemaName New schema name.
 	 * @param settings Current settings.
 	 */
 	public static void createH2Schema(String schemaName, Map settings) {
 		settings.put(
 				Environment.URL,
 				settings.get( Environment.URL ) + ";INIT=CREATE SCHEMA IF NOT EXISTS " + schemaName
 		);
 	}
 }
diff --git a/shared/config/checkstyle/checkstyle-eventual.xml b/shared/config/checkstyle/checkstyle-eventual.xml
new file mode 100644
index 0000000000..6ad31b79c5
--- /dev/null
+++ b/shared/config/checkstyle/checkstyle-eventual.xml
@@ -0,0 +1,257 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!--
+  ~ Hibernate, Relational Persistence for Idiomatic Java
+  ~
+  ~ Copyright (c) 2013, Red Hat Inc. or third-party contributors as
+  ~ indicated by the @author tags or express copyright attribution
+  ~ statements applied by the authors.  All third-party contributions are
+  ~ distributed under license by Red Hat Inc.
+  ~
+  ~ This copyrighted material is made available to anyone wishing to use, modify,
+  ~ copy, or redistribute it subject to the terms and conditions of the GNU
+  ~ Lesser General Public License, as published by the Free Software Foundation.
+  ~
+  ~ This program is distributed in the hope that it will be useful,
+  ~ but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+  ~ or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
+  ~ for more details.
+  ~
+  ~ You should have received a copy of the GNU Lesser General Public License
+  ~ along with this distribution; if not, write to:
+  ~ Free Software Foundation, Inc.
+  ~ 51 Franklin Street, Fifth Floor
+  ~ Boston, MA  02110-1301  USA
+  -->
+<!DOCTYPE module PUBLIC "-//Puppy Crawl//DTD Check Configuration 1.1//EN" "http://www.puppycrawl.com/dtds/configuration_1_2.dtd">
+<module name="Checker">
+
+    <module name="TreeWalker">
+
+        <!--
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+            General regex checks as part of the TreeWalker
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+        -->
+<!--
+        <module name="Regexp">
+            <property name="format"
+                      value="\A(/\*\n \* Hibernate, Relational Persistence for Idiomatic Java\n \*\n \* Copyright \(c\) \d{4}(-\d{4})?, Red Hat(,)? Inc. (and/or its affiliates )?or third-party contributors as\n \* indicated by the @author tags or express copyright attribution\n \* statements applied by the authors. All third-party contributions are\n \* distributed under license by Red Hat(,)? Inc.\n \*\n \* This copyrighted material is made available to anyone wishing to use, modify,\n \* copy, or redistribute it subject to the terms and conditions of the GNU\n \* Lesser General Public License, as published by the Free Software Foundation.\n \*\n \* This program is distributed in the hope that it will be useful,\n \* but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n \* or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License\n \* for more details.\n \*\n \* You should have received a copy of the GNU Lesser General Public License\n \* along with this distribution; if not, write to:\n \* Free Software Foundation, Inc.\n \* 51 Franklin Street, Fifth Floor\n \* Boston, MA 02110-1301 USA\n \*/)|(/\* ?\n \* Hibernate, Relational Persistence for Idiomatic Java\n \* ?\n \* JBoss, Home of Professional Open Source\n \* Copyright \d{4} Red Hat Inc. and/or its affiliates and other contributors\n \* as indicated by the @authors tag. All rights reserved.\n \* See the copyright.txt in the distribution for a\n \* full listing of individual contributors.\n \*\n \* This copyrighted material is made available to anyone wishing to use,\n \* modify, copy, or redistribute it subject to the terms and conditions\n \* of the GNU Lesser General Public License, v. 2.1.\n \* This program is distributed in the hope that it will be useful, but WITHOUT A\n \* WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A\n \* PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details.\n \* You should have received a copy of the GNU Lesser General Public License,\n \* v.2.1 along with this distribution; if not, write to the Free Software\n \* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,\n \* MA 02110-1301, USA.\n \*/)|(/\*\n \* Hibernate, Relational Persistence for Idiomatic Java\n \*\n \* JBoss, Home of Professional Open Source\n \* Copyright \d{4}(-\d{4})? Red Hat Inc. and/or its affiliates and other contributors\n \* as indicated by the @authors tag. All rights reserved.\n \* See the copyright.txt in the distribution for a\n \* full listing of individual contributors.\n \*\n \* This copyrighted material is made available to anyone wishing to use,\n \* modify, copy, or redistribute it subject to the terms and conditions\n \* of the GNU Lesser General Public License, v. 2.1.\n \* This program is distributed in the hope that it will be useful, but WITHOUT A\n \* WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A\n \* PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details.\n \* You should have received a copy of the GNU Lesser General Public License,\n \* v.2.1 along with this distribution; if not, write to the Free Software\n \* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,\n \* MA 02110-1301, USA.\n \*/)|(/\* ?\n \* JBoss, Home of Professional Open Source\n \* Copyright 2011 Red Hat Inc. and/or its affiliates and other contributors\n \* as indicated by the @authors tag. All rights reserved.\n \* See the copyright.txt in the distribution for a\n \* full listing of individual contributors.\n \*\n \* This copyrighted material is made available to anyone wishing to use,\n \* modify, copy, or redistribute it subject to the terms and conditions\n \* of the GNU Lesser General Public License, v. 2.1.\n \* This program is distributed in the hope that it will be useful, but WITHOUT A\n \* WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A\n \* PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details.\n \* You should have received a copy of the GNU Lesser General Public License,\n \* v.2.1 along with this distribution; if not, write to the Free Software\n \* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,\n \* MA 02110-1301, USA.\n \*/)" />
+            <property name="message" value="Correct header not found" />
+        </module>
+-->
+        <module name="RegexpSinglelineJava">
+            <property name="ignoreComments" value="true" />
+            <property name="format" value="^\t* +\t*\S" />
+            <property name="message" value="Line has leading space characters; indentation should be performed with tabs only." />
+        </module>
+
+<!--
+    For now this is disabled to minimize false conflicts with metamodel branch.
+
+        <module name="RegexpSinglelineJava">
+            <property name="ignoreComments" value="true" />
+            <property name="format" value="\s+$" />
+            <property name="message" value="White spaces at the end of line" />
+        </module>
+-->
+
+        <!--
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+            Annotation checks
+
+            See http://checkstyle.sourceforge.net/config_annotation.html
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+        -->
+        <module name="MissingDeprecated" />
+        <module name="MissingOverride" />
+        <module name="PackageAnnotation" />
+
+
+        <!--
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+            Block checks
+
+            See http://checkstyle.sourceforge.net/config_blocks.html
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+        -->
+        <module name="AvoidNestedBlocks">
+            <property name="allowInSwitchCase" value="true" />
+            <property name="severity" value="warning" />
+        </module>
+        <module name="NeedBraces" />
+        <module name="LeftCurly">
+            <property name="option" value="eol" />
+        </module>
+        <module name="RightCurly">
+            <property name="option" value="alone" />
+        </module>
+
+
+        <!--
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+            Design checks
+
+            See http://checkstyle.sourceforge.net/config_design.html
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+        -->
+        <module name="HideUtilityClassConstructor" />
+        <module name="MutableException" />
+
+
+        <!--
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+            Coding checks
+
+            See http://checkstyle.sourceforge.net/config_coding.html
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+        -->
+        <module name="EmptyStatement" />
+        <module name="EqualsHashCode" />
+        <module name="FinalLocalVariable" />
+        <module name="MissingSwitchDefault" />
+        <module name="ModifiedControlVariable" />
+        <module name="SimplifyBooleanExpression" />
+        <module name="SimplifyBooleanReturn" />
+        <module name="StringLiteralEquality" />
+        <module name="NoFinalizer" />
+        <module name="ExplicitInitialization" />
+        <module name="MissingSwitchDefault" />
+        <module name="DefaultComesLast" />
+        <module name="FallThrough" />
+        <module name="OneStatementPerLine" />
+
+
+        <!--
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+            Import checks
+
+            See http://checkstyle.sourceforge.net/config_imports.html
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+        -->
+        <module name="AvoidStarImport" />
+        <module name="RedundantImport" />
+        <module name="UnusedImports" />
+
+
+        <!--
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+            Javadoc checks
+
+            See http://checkstyle.sourceforge.net/config_javadoc.html
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+        -->
+        <module name="JavadocType">
+            <property name="scope" value="public"/>
+            <property name="allowUnknownTags" value="true" />
+            <property name="allowMissingParamTags" value="true" />
+        </module>
+        <module name="JavadocMethod">
+            <property name="scope" value="public" />
+            <property name="allowUndeclaredRTE" value="true" />
+            <property name="allowMissingPropertyJavadoc" value="true" />
+        </module>
+        <module name="JavadocVariable">
+            <property name="scope" value="public" />
+        </module>
+        <module name="JavadocStyle">
+            <property name="scope" value="public" />
+            <property name="checkEmptyJavadoc" value="true" />
+            <property name="checkFirstSentence" value="false" />
+        </module>
+
+
+        <!--
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+            Misc checks
+
+            See http://checkstyle.sourceforge.net/config_misc.html
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+        -->
+        <module name="UpperEll" />
+        <module name="ArrayTypeStyle" />
+        <module name="TrailingComment">
+            <property name="severity" value="warning" />
+        </module>
+
+
+        <!--
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+            Modifier checks
+
+            See http://checkstyle.sourceforge.net/config_modifier.html
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+        -->
+        <module name="ModifierOrder"/>
+
+
+        <!--
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+            Naming checks
+
+            See http://checkstyle.sourceforge.net/config_naming.html
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+        -->
+        <module name="AbstractClassName">
+            <!-- we are just using this to make sure that classes matching the pattern (Abstract*) have the abstract modifier -->
+            <property name="format" value="^Abstract.*$" />
+            <property name="ignoreName" value="true" />
+        </module>
+        <module name="ClassTypeParameterName" />
+        <module name="ConstantName">
+            <property name="format" value="^[A-Z](_?[A-Z0-9]+)*$|log" />
+        </module>
+        <module name="LocalFinalVariableName" >
+            <property name="severity" value="warning" />
+        </module>
+        <module name="LocalVariableName" />
+        <module name="MemberName" />
+        <!--
+        The org.hibernate.engine.spi.ManagedEntity method names (prefixed with '&&_') muck with this
+        <module name="MethodName" />
+        -->
+        <module name="MethodTypeParameterName" />
+        <module name="PackageName" />
+        <module name="ParameterName" />
+        <module name="StaticVariableName" />
+        <module name="TypeName" />
+
+
+        <!--
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+            Whitespace checks
+
+            See http://checkstyle.sourceforge.net/config_whitespace.html
+            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+        -->
+        <module name="MethodParamPad" />
+        <module name="TypecastParenPad" />
+        <module name="ParenPad">
+            <property name="tokens" value="CTOR_CALL, METHOD_CALL, SUPER_CTOR_CALL" />
+            <property name="option" value="space" />
+        </module>
+
+    </module>
+
+
+    <!--
+        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+        Javadoc checks
+
+        See http://checkstyle.sourceforge.net/config_javadoc.html
+        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+    -->
+    <module name="JavadocPackage">
+        <property name="allowLegacy" value="true" />
+    </module>
+
+
+    <!--
+        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+        Misc checks
+
+        See http://checkstyle.sourceforge.net/config_misc.html
+        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+    -->
+    <module name="NewlineAtEndOfFile" />
+
+</module>
diff --git a/shared/config/checkstyle/checkstyle.xml b/shared/config/checkstyle/checkstyle.xml
index cb92c14394..806f7c2e86 100644
--- a/shared/config/checkstyle/checkstyle.xml
+++ b/shared/config/checkstyle/checkstyle.xml
@@ -1,255 +1,230 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <!--
   ~ Hibernate, Relational Persistence for Idiomatic Java
   ~
   ~ Copyright (c) 2013, Red Hat Inc. or third-party contributors as
   ~ indicated by the @author tags or express copyright attribution
   ~ statements applied by the authors.  All third-party contributions are
   ~ distributed under license by Red Hat Inc.
   ~
   ~ This copyrighted material is made available to anyone wishing to use, modify,
   ~ copy, or redistribute it subject to the terms and conditions of the GNU
   ~ Lesser General Public License, as published by the Free Software Foundation.
   ~
   ~ This program is distributed in the hope that it will be useful,
   ~ but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
   ~ or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
   ~ for more details.
   ~
   ~ You should have received a copy of the GNU Lesser General Public License
   ~ along with this distribution; if not, write to:
   ~ Free Software Foundation, Inc.
   ~ 51 Franklin Street, Fifth Floor
   ~ Boston, MA  02110-1301  USA
   -->
 <!DOCTYPE module PUBLIC "-//Puppy Crawl//DTD Check Configuration 1.1//EN" "http://www.puppycrawl.com/dtds/configuration_1_2.dtd">
 <module name="Checker">
 
     <module name="TreeWalker">
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             General regex checks as part of the TreeWalker
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
-<!--
-        <module name="Regexp">
-            <property name="format"
-                      value="\A(/\*\n \* Hibernate, Relational Persistence for Idiomatic Java\n \*\n \* Copyright \(c\) \d{4}(-\d{4})?, Red Hat(,)? Inc. (and/or its affiliates )?or third-party contributors as\n \* indicated by the @author tags or express copyright attribution\n \* statements applied by the authors. All third-party contributions are\n \* distributed under license by Red Hat(,)? Inc.\n \*\n \* This copyrighted material is made available to anyone wishing to use, modify,\n \* copy, or redistribute it subject to the terms and conditions of the GNU\n \* Lesser General Public License, as published by the Free Software Foundation.\n \*\n \* This program is distributed in the hope that it will be useful,\n \* but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY\n \* or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License\n \* for more details.\n \*\n \* You should have received a copy of the GNU Lesser General Public License\n \* along with this distribution; if not, write to:\n \* Free Software Foundation, Inc.\n \* 51 Franklin Street, Fifth Floor\n \* Boston, MA 02110-1301 USA\n \*/)|(/\* ?\n \* Hibernate, Relational Persistence for Idiomatic Java\n \* ?\n \* JBoss, Home of Professional Open Source\n \* Copyright \d{4} Red Hat Inc. and/or its affiliates and other contributors\n \* as indicated by the @authors tag. All rights reserved.\n \* See the copyright.txt in the distribution for a\n \* full listing of individual contributors.\n \*\n \* This copyrighted material is made available to anyone wishing to use,\n \* modify, copy, or redistribute it subject to the terms and conditions\n \* of the GNU Lesser General Public License, v. 2.1.\n \* This program is distributed in the hope that it will be useful, but WITHOUT A\n \* WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A\n \* PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details.\n \* You should have received a copy of the GNU Lesser General Public License,\n \* v.2.1 along with this distribution; if not, write to the Free Software\n \* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,\n \* MA 02110-1301, USA.\n \*/)|(/\*\n \* Hibernate, Relational Persistence for Idiomatic Java\n \*\n \* JBoss, Home of Professional Open Source\n \* Copyright \d{4}(-\d{4})? Red Hat Inc. and/or its affiliates and other contributors\n \* as indicated by the @authors tag. All rights reserved.\n \* See the copyright.txt in the distribution for a\n \* full listing of individual contributors.\n \*\n \* This copyrighted material is made available to anyone wishing to use,\n \* modify, copy, or redistribute it subject to the terms and conditions\n \* of the GNU Lesser General Public License, v. 2.1.\n \* This program is distributed in the hope that it will be useful, but WITHOUT A\n \* WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A\n \* PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details.\n \* You should have received a copy of the GNU Lesser General Public License,\n \* v.2.1 along with this distribution; if not, write to the Free Software\n \* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,\n \* MA 02110-1301, USA.\n \*/)|(/\* ?\n \* JBoss, Home of Professional Open Source\n \* Copyright 2011 Red Hat Inc. and/or its affiliates and other contributors\n \* as indicated by the @authors tag. All rights reserved.\n \* See the copyright.txt in the distribution for a\n \* full listing of individual contributors.\n \*\n \* This copyrighted material is made available to anyone wishing to use,\n \* modify, copy, or redistribute it subject to the terms and conditions\n \* of the GNU Lesser General Public License, v. 2.1.\n \* This program is distributed in the hope that it will be useful, but WITHOUT A\n \* WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A\n \* PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details.\n \* You should have received a copy of the GNU Lesser General Public License,\n \* v.2.1 along with this distribution; if not, write to the Free Software\n \* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,\n \* MA 02110-1301, USA.\n \*/)" />
-            <property name="message" value="Correct header not found" />
-        </module>
--->
         <module name="RegexpSinglelineJava">
             <property name="ignoreComments" value="true" />
             <property name="format" value="^\t* +\t*\S" />
             <property name="message" value="Line has leading space characters; indentation should be performed with tabs only." />
         </module>
 
-<!--
-    For now this is disabled to minimize false conflicts with metamodel branch.
-
-        <module name="RegexpSinglelineJava">
-            <property name="ignoreComments" value="true" />
-            <property name="format" value="\s+$" />
-            <property name="message" value="White spaces at the end of line" />
-        </module>
--->
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Annotation checks
 
             See http://checkstyle.sourceforge.net/config_annotation.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
         <module name="MissingDeprecated" />
         <module name="MissingOverride" />
         <module name="PackageAnnotation" />
 
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Block checks
 
             See http://checkstyle.sourceforge.net/config_blocks.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
         <module name="AvoidNestedBlocks">
             <property name="allowInSwitchCase" value="true" />
             <property name="severity" value="warning" />
         </module>
         <module name="NeedBraces" />
         <module name="LeftCurly">
             <property name="option" value="eol" />
         </module>
         <module name="RightCurly">
             <property name="option" value="alone" />
         </module>
 
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Design checks
 
             See http://checkstyle.sourceforge.net/config_design.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
-        <module name="HideUtilityClassConstructor" />
+        <module name="HideUtilityClassConstructor">
+            <!-- Some classes in o.h.metamodel on master do this -->
+            <property name="severity" value="warning" />
+        </module>
         <module name="MutableException" />
 
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Coding checks
 
             See http://checkstyle.sourceforge.net/config_coding.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
-        <module name="EmptyStatement" />
+        <module name="EmptyStatement">
+            <property name="severity" value="warning" />
+        </module>
         <module name="EqualsHashCode" />
-        <module name="FinalLocalVariable" />
-        <module name="MissingSwitchDefault" />
-        <module name="ModifiedControlVariable" />
+        <module name="MissingSwitchDefault">
+            <property name="severity" value="warning" />
+        </module>
+        <module name="DefaultComesLast" />
+        <module name="ModifiedControlVariable">
+            <property name="severity" value="warning" />
+        </module>
         <module name="SimplifyBooleanExpression" />
         <module name="SimplifyBooleanReturn" />
         <module name="StringLiteralEquality" />
         <module name="NoFinalizer" />
-        <module name="ExplicitInitialization" />
-        <module name="MissingSwitchDefault" />
-        <module name="DefaultComesLast" />
+        <module name="ExplicitInitialization">
+            <property name="severity" value="warning" />
+        </module>
         <module name="FallThrough" />
         <module name="OneStatementPerLine" />
 
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Import checks
 
             See http://checkstyle.sourceforge.net/config_imports.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
         <module name="AvoidStarImport" />
         <module name="RedundantImport" />
         <module name="UnusedImports" />
 
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-            Javadoc checks
-
-            See http://checkstyle.sourceforge.net/config_javadoc.html
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-        -->
-        <module name="JavadocType">
-            <property name="scope" value="public"/>
-            <property name="allowUnknownTags" value="true" />
-            <property name="allowMissingParamTags" value="true" />
-        </module>
-        <module name="JavadocMethod">
-            <property name="scope" value="public" />
-            <property name="allowUndeclaredRTE" value="true" />
-            <property name="allowMissingPropertyJavadoc" value="true" />
-        </module>
-        <module name="JavadocVariable">
-            <property name="scope" value="public" />
-        </module>
-        <module name="JavadocStyle">
-            <property name="scope" value="public" />
-            <property name="checkEmptyJavadoc" value="true" />
-            <property name="checkFirstSentence" value="false" />
-        </module>
-
-
-        <!--
-            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Misc checks
 
             See http://checkstyle.sourceforge.net/config_misc.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
         <module name="UpperEll" />
-        <module name="ArrayTypeStyle" />
+        <module name="ArrayTypeStyle">
+            <!-- Some classes in o.h.metamodel on master do this -->
+            <property name="severity" value="warning" />
+        </module>
         <module name="TrailingComment">
             <property name="severity" value="warning" />
         </module>
 
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Modifier checks
 
             See http://checkstyle.sourceforge.net/config_modifier.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
         <module name="ModifierOrder"/>
 
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Naming checks
 
             See http://checkstyle.sourceforge.net/config_naming.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
         <module name="AbstractClassName">
             <!-- we are just using this to make sure that classes matching the pattern (Abstract*) have the abstract modifier -->
             <property name="format" value="^Abstract.*$" />
             <property name="ignoreName" value="true" />
         </module>
-        <module name="ClassTypeParameterName" />
+        <module name="ClassTypeParameterName">
+            <property name="format" value="^[A-Z][A-Z0-9]*$" />
+        </module>
         <module name="ConstantName">
             <property name="format" value="^[A-Z](_?[A-Z0-9]+)*$|log" />
+            <!-- Some classes in o.h.metamodel on master violate this -->
+            <property name="severity" value="warning" />
+        </module>
+        <module name="LocalFinalVariableName" >
+            <property name="severity" value="warning" />
         </module>
-        <module name="LocalFinalVariableName" />
         <module name="LocalVariableName" />
         <module name="MemberName" />
         <!--
         The org.hibernate.engine.spi.ManagedEntity method names (prefixed with '&&_') muck with this
         <module name="MethodName" />
         -->
         <module name="MethodTypeParameterName" />
         <module name="PackageName" />
         <module name="ParameterName" />
         <module name="StaticVariableName" />
         <module name="TypeName" />
 
 
         <!--
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Whitespace checks
 
             See http://checkstyle.sourceforge.net/config_whitespace.html
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         -->
         <module name="MethodParamPad" />
         <module name="TypecastParenPad" />
         <module name="ParenPad">
             <property name="tokens" value="CTOR_CALL, METHOD_CALL, SUPER_CTOR_CALL" />
             <property name="option" value="space" />
         </module>
 
     </module>
 
 
     <!--
         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         Javadoc checks
 
         See http://checkstyle.sourceforge.net/config_javadoc.html
         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     -->
     <module name="JavadocPackage">
         <property name="allowLegacy" value="true" />
     </module>
 
 
     <!--
         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         Misc checks
 
         See http://checkstyle.sourceforge.net/config_misc.html
         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     -->
     <module name="NewlineAtEndOfFile" />
 
 </module>
diff --git a/tooling/hibernate-maven-plugin/src/main/java/org/hibernate/bytecode/enhance/plugins/HibernateEnhancementMojo.java b/tooling/hibernate-maven-plugin/src/main/java/org/hibernate/bytecode/enhance/plugins/HibernateEnhancementMojo.java
index 4d8874f941..05f2575263 100644
--- a/tooling/hibernate-maven-plugin/src/main/java/org/hibernate/bytecode/enhance/plugins/HibernateEnhancementMojo.java
+++ b/tooling/hibernate-maven-plugin/src/main/java/org/hibernate/bytecode/enhance/plugins/HibernateEnhancementMojo.java
@@ -1,266 +1,266 @@
 /*
  * Hibernate, Relational Persistence for Idiomatic Java
  *
  * Copyright (c) 2013, Red Hat Inc. or third-party contributors as
  * indicated by the @author tags or express copyright attribution
  * statements applied by the authors.  All third-party contributions are
  * distributed under license by Red Hat Inc.
  *
  * This copyrighted material is made available to anyone wishing to use, modify,
  * copy, or redistribute it subject to the terms and conditions of the GNU
  * Lesser General Public License, as published by the Free Software Foundation.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
  * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Lesser General Public License
  * for more details.
  *
  * You should have received a copy of the GNU Lesser General Public License
  * along with this distribution; if not, write to:
  * Free Software Foundation, Inc.
  * 51 Franklin Street, Fifth Floor
  * Boston, MA  02110-1301  USA
  */
 package org.hibernate.bytecode.enhance.plugins;
 
 import java.io.File;
 import java.io.FileFilter;
 import java.io.FileInputStream;
 import java.io.FileNotFoundException;
 import java.io.FileOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.util.ArrayList;
 import java.util.List;
 
 import javassist.ClassPool;
 import javassist.CtClass;
 import javassist.CtField;
 
 import javax.persistence.Embeddable;
 import javax.persistence.Entity;
 import javax.persistence.ElementCollection;
 import javax.persistence.ManyToMany;
 import javax.persistence.OneToMany;
 import javax.persistence.Transient;
 
 import org.hibernate.bytecode.enhance.spi.EnhancementContext;
 import org.hibernate.bytecode.enhance.spi.Enhancer;
 
 import org.apache.maven.plugin.AbstractMojo;
 import org.apache.maven.plugins.annotations.Mojo;
 import org.apache.maven.plugin.MojoExecutionException;
 import org.apache.maven.plugin.MojoFailureException;
 import org.apache.maven.plugins.annotations.Parameter;
 
 /**
  * This plugin will enhance Entity objects.
  * 
  * @author Jeremy Whiting
  */
 @Mojo(name = "enhance")
 public class HibernateEnhancementMojo extends AbstractMojo implements EnhancementContext {
 
 	/**
 	 * The contexts to use during enhancement.
 	 */
 	private List<File> classes = new ArrayList<File>();
 	private ClassPool pool = new ClassPool( false );
     private final Enhancer enhancer = new Enhancer( this);
 
 	private static final String CLASS_EXTENSION = ".class";
 
 	@Parameter(property="dir", defaultValue="${project.build.outputDirectory}")
-	private String dir = null;
+	private String dir;
 
 	public void execute() throws MojoExecutionException, MojoFailureException {
 		getLog().info( "Started enhance plugin....." );
 		/** Perform a depth first search for files. */
 		File root = new File( this.dir ); 
 		walkDir( root );
 
 		if ( 0 < classes.size() ) {
 			for ( File file : classes ) {
 				processClassFile(file);
 			}
 		}
 
 		getLog().info( "Enhance plugin completed." );
 	}
 
 	/**
 	 * Expects a directory.
 	 */
 	private void walkDir(File dir) {
 
 		walkDir( dir, new FileFilter() {
 
 			@Override
 			public boolean accept(File pathname) {
 				return ( pathname.isFile() && pathname.getName().endsWith( CLASS_EXTENSION ) );
 			}
 		}, new FileFilter() {
 
 			@Override
 			public boolean accept(File pathname) {
 				return ( pathname.isDirectory() );
 			}
 		} );
 	}
 
 	private void walkDir(File dir, FileFilter classesFilter, FileFilter dirFilter) {
 
 		File[] dirs = dir.listFiles( dirFilter );
 		for ( int i = 0; i < dirs.length; i++ ) {
 			walkDir( dirs[i], classesFilter, dirFilter );
 		}
 		dirs = null;
 		File[] files = dir.listFiles( classesFilter );
 		for ( int i = 0; i < files.length; i++ ) {
 			this.classes.add( files[i] );
 		}
 	}
 
 
     /**
      * Atm only process files annotated with either @Entity or @Embeddable
      * @param javaClassFile
      */
     private void processClassFile(File javaClassFile)
             throws MojoExecutionException {
 		try {
 			final CtClass ctClass = getClassPool().makeClass( new FileInputStream( javaClassFile ) );
             if(this.isEntityClass(ctClass))
                 processEntityClassFile(javaClassFile, ctClass);
             else if(this.isCompositeClass(ctClass))
                 processCompositeClassFile(javaClassFile, ctClass);
 
         }
         catch (IOException e) {
             throw new MojoExecutionException(
                     String.format( "Error processing included file [%s]", javaClassFile.getAbsolutePath() ), e );
         }
     }
 
     private void processEntityClassFile(File javaClassFile, CtClass ctClass ) {
         try {
             byte[] result = enhancer.enhance( ctClass.getName(), ctClass.toBytecode() );
             if(result != null)
                 writeEnhancedClass(javaClassFile, result);
         }
         catch (Exception e) {
             getLog().error( "Unable to enhance class [" + ctClass.getName() + "]", e);
             return;
         }
     }
 
     private void processCompositeClassFile(File javaClassFile, CtClass ctClass) {
         try {
             byte[] result = enhancer.enhanceComposite(ctClass.getName(), ctClass.toBytecode());
             if(result != null)
                 writeEnhancedClass(javaClassFile, result);
         }
         catch (Exception e) {
             getLog().error( "Unable to enhance class [" + ctClass.getName() + "]", e);
             return;
         }
     }
 
     private void writeEnhancedClass(File javaClassFile, byte[] result)
             throws MojoExecutionException {
         try {
 			if ( javaClassFile.delete() ) {
                     if ( ! javaClassFile.createNewFile() ) {
                         getLog().error( "Unable to recreate class file [" + javaClassFile.getName() + "]");
                     }
             }
 			else {
 				getLog().error( "Unable to delete class file [" + javaClassFile.getName() + "]");
 			}
 
 			FileOutputStream outputStream = new FileOutputStream( javaClassFile, false );
 			try {
 				outputStream.write( result);
 				outputStream.flush();
 			}
 			finally {
 				try {
 					outputStream.close();
 				}
 				catch ( IOException ignore) {
 				}
 			}
         }
         catch (FileNotFoundException ignore) {
             // should not ever happen because of explicit checks
         }
         catch (IOException e) {
             throw new MojoExecutionException(
                     String.format( "Error processing included file [%s]", javaClassFile.getAbsolutePath() ), e );
         }
     }
 
 	private ClassPool getClassPool() {
 		return this.pool;
 	}
 
     private boolean shouldInclude(CtClass ctClass) {
 		// we currently only handle entity enhancement
 		return ctClass.hasAnnotation( Entity.class );
 	}
 
 	@Override
 	public ClassLoader getLoadingClassLoader() {
 		return getClass().getClassLoader();
 	}
 
 	@Override
 	public boolean isEntityClass(CtClass classDescriptor) {
         return classDescriptor.hasAnnotation(Entity.class);
     }
 
 	@Override
 	public boolean isCompositeClass(CtClass classDescriptor) {
         return classDescriptor.hasAnnotation(Embeddable.class);
 	}
 
 	@Override
 	public boolean doDirtyCheckingInline(CtClass classDescriptor) {
 		return true;
 	}
 
 	@Override
 	public boolean hasLazyLoadableAttributes(CtClass classDescriptor) {
 		return true;
 	}
 
 	@Override
 	public boolean isLazyLoadable(CtField field) {
 		return true;
 	}
 
 	@Override
 	public boolean isPersistentField(CtField ctField) {
 		// current check is to look for @Transient
 		return ! ctField.hasAnnotation( Transient.class );
 	}
 
     @Override
     public boolean isMappedCollection(CtField field) {
         try {
             return (field.getAnnotation(OneToMany.class) != null ||
                     field.getAnnotation(ManyToMany.class) != null ||
                     field.getAnnotation(ElementCollection.class) != null);
         }
         catch (ClassNotFoundException e) {
             return false;
         }
     }
 
 	@Override
 	public CtField[] order(CtField[] persistentFields) {
 		// for now...
 		return persistentFields;
 		// eventually needs to consult the Hibernate metamodel for proper ordering
 	}
 }
